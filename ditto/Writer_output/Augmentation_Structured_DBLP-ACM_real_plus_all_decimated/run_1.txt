cuda
Device: cuda
step: 0, loss: 0.6522428393363953
step: 10, loss: 0.5255300402641296
step: 20, loss: 0.5243816375732422
step: 30, loss: 0.432267963886261
step: 40, loss: 0.27903011441230774
step: 50, loss: 0.2414165735244751
step: 60, loss: 0.13495373725891113
step: 70, loss: 0.2570440173149109
step: 80, loss: 0.15488643944263458
step: 90, loss: 0.3616924285888672
step: 100, loss: 0.11831406503915787
step: 110, loss: 0.03451470658183098
step: 120, loss: 0.18218018114566803
step: 130, loss: 0.17474998533725739
step: 140, loss: 0.14653024077415466
step: 150, loss: 0.06602434813976288
step: 160, loss: 0.17337527871131897
step: 170, loss: 0.1655721217393875
step: 180, loss: 0.09021737426519394
step: 190, loss: 0.054944656789302826
step: 200, loss: 0.0389411523938179
step: 210, loss: 0.09127864241600037
step: 220, loss: 0.11058592051267624
step: 230, loss: 0.14991308748722076
step: 240, loss: 0.0843508318066597
step: 250, loss: 0.09637491405010223
step: 260, loss: 0.07634563744068146
step: 270, loss: 0.08367779850959778
step: 280, loss: 0.07111764699220657
step: 290, loss: 0.12783290445804596
step: 300, loss: 0.07960531115531921
step: 310, loss: 0.05555218085646629
step: 320, loss: 0.03060794249176979
step: 330, loss: 0.006872579921036959
step: 340, loss: 0.009830727241933346
step: 350, loss: 0.11421617120504379
step: 360, loss: 0.03652041777968407
step: 370, loss: 0.019182417541742325
step: 380, loss: 0.04767296463251114
step: 390, loss: 0.049335796386003494
step: 400, loss: 0.09101882576942444
step: 410, loss: 0.09752146899700165
step: 420, loss: 0.04504809156060219
step: 430, loss: 0.01422052551060915
step: 440, loss: 0.030023673549294472
step: 450, loss: 0.06919032335281372
step: 460, loss: 0.0519615076482296
epoch 1: dev_f1=0.9864864864864865, f1=0.9864559819413092, best_f1=0.9864559819413092
step: 0, loss: 0.054272592067718506
step: 10, loss: 0.10863471031188965
step: 20, loss: 0.019361164420843124
step: 30, loss: 0.10483307391405106
step: 40, loss: 0.07537523657083511
step: 50, loss: 0.05834507942199707
step: 60, loss: 0.009174596518278122
step: 70, loss: 0.3317195475101471
step: 80, loss: 0.06073490530252457
step: 90, loss: 0.0881253033876419
step: 100, loss: 0.14029987156391144
step: 110, loss: 0.0936722457408905
step: 120, loss: 0.2758999764919281
step: 130, loss: 0.04339491203427315
step: 140, loss: 0.06666915118694305
step: 150, loss: 0.18479563295841217
step: 160, loss: 0.14214468002319336
step: 170, loss: 0.13474924862384796
step: 180, loss: 0.03642351180315018
step: 190, loss: 0.05479636788368225
step: 200, loss: 0.10869506746530533
step: 210, loss: 0.05150284245610237
step: 220, loss: 0.08494779467582703
step: 230, loss: 0.010873648338019848
step: 240, loss: 0.037798672914505005
step: 250, loss: 0.08137493580579758
step: 260, loss: 0.01862221769988537
step: 270, loss: 0.020339682698249817
step: 280, loss: 0.03841786831617355
step: 290, loss: 0.27860909700393677
step: 300, loss: 0.050371136516332626
step: 310, loss: 0.03437524661421776
step: 320, loss: 0.13853032886981964
step: 330, loss: 0.06262590736150742
step: 340, loss: 0.2051340788602829
step: 350, loss: 0.041238609701395035
step: 360, loss: 0.07741470634937286
step: 370, loss: 0.15171362459659576
step: 380, loss: 0.0848783403635025
step: 390, loss: 0.029383385553956032
step: 400, loss: 0.07680412381887436
step: 410, loss: 0.006318669766187668
step: 420, loss: 0.11075853556394577
step: 430, loss: 0.06944193691015244
step: 440, loss: 0.0965297520160675
step: 450, loss: 0.06636521220207214
step: 460, loss: 0.037767913192510605
epoch 2: dev_f1=0.9910112359550561, f1=0.987598647125141, best_f1=0.987598647125141
step: 0, loss: 0.020370088517665863
step: 10, loss: 0.04365115240216255
step: 20, loss: 0.01150461845099926
step: 30, loss: 0.0052147433161735535
step: 40, loss: 0.017306465655565262
step: 50, loss: 0.023232240229845047
step: 60, loss: 0.14428186416625977
step: 70, loss: 0.08790209889411926
step: 80, loss: 0.037473518401384354
step: 90, loss: 0.019064659252762794
step: 100, loss: 0.0010725910542532802
step: 110, loss: 0.01880343072116375
step: 120, loss: 0.012124533765017986
step: 130, loss: 0.013467025943100452
step: 140, loss: 0.024774255231022835
step: 150, loss: 0.014249059371650219
step: 160, loss: 0.03237916901707649
step: 170, loss: 0.005722559057176113
step: 180, loss: 0.018282899633049965
step: 190, loss: 0.009886231273412704
step: 200, loss: 0.011126816272735596
step: 210, loss: 0.17496895790100098
step: 220, loss: 0.10653845965862274
step: 230, loss: 0.0688716396689415
step: 240, loss: 0.021700527518987656
step: 250, loss: 0.03770211338996887
step: 260, loss: 0.03453323245048523
step: 270, loss: 0.12647956609725952
step: 280, loss: 0.027285737916827202
step: 290, loss: 0.03350314870476723
step: 300, loss: 0.03836771473288536
step: 310, loss: 0.10446589440107346
step: 320, loss: 0.12415602803230286
step: 330, loss: 0.024244148284196854
step: 340, loss: 0.08261033892631531
step: 350, loss: 0.07280799746513367
step: 360, loss: 0.07148879766464233
step: 370, loss: 0.0011608853237703443
step: 380, loss: 0.02880743518471718
step: 390, loss: 0.13030166923999786
step: 400, loss: 0.04750023037195206
step: 410, loss: 0.016228685155510902
step: 420, loss: 0.004798810929059982
step: 430, loss: 0.07450470328330994
step: 440, loss: 0.006429342553019524
step: 450, loss: 0.13820086419582367
step: 460, loss: 0.29507210850715637
epoch 3: dev_f1=0.9943630214205187, f1=0.9841269841269841, best_f1=0.9841269841269841
step: 0, loss: 0.0986756980419159
step: 10, loss: 0.025331929326057434
step: 20, loss: 0.01431491319090128
step: 30, loss: 0.06877104938030243
step: 40, loss: 0.17266544699668884
step: 50, loss: 0.006364402826875448
step: 60, loss: 0.010213619098067284
step: 70, loss: 0.026222193613648415
step: 80, loss: 0.06522909551858902
step: 90, loss: 0.06547319889068604
step: 100, loss: 0.06930050998926163
step: 110, loss: 0.0797891914844513
step: 120, loss: 0.12644053995609283
step: 130, loss: 0.011056223884224892
step: 140, loss: 0.12110430002212524
step: 150, loss: 0.004971869755536318
step: 160, loss: 0.1122475266456604
step: 170, loss: 0.013370448723435402
step: 180, loss: 0.10463794320821762
step: 190, loss: 0.021123824641108513
step: 200, loss: 0.02172219567000866
step: 210, loss: 0.005071382038295269
step: 220, loss: 0.00980082806199789
step: 230, loss: 0.049901995807886124
step: 240, loss: 0.1021038219332695
step: 250, loss: 0.07366737723350525
step: 260, loss: 0.07389052212238312
step: 270, loss: 0.06758178770542145
step: 280, loss: 0.0418238528072834
step: 290, loss: 0.030503584071993828
step: 300, loss: 0.02229161746799946
step: 310, loss: 0.08006749302148819
step: 320, loss: 0.0186697319149971
step: 330, loss: 0.1415354311466217
step: 340, loss: 0.01181041356176138
step: 350, loss: 0.025688160210847855
step: 360, loss: 0.02239934913814068
step: 370, loss: 0.06323736906051636
step: 380, loss: 0.06829316169023514
step: 390, loss: 0.044021833688020706
step: 400, loss: 0.00017005189147312194
step: 410, loss: 0.005648515652865171
step: 420, loss: 0.08185044676065445
step: 430, loss: 0.07963427901268005
step: 440, loss: 0.027193568646907806
step: 450, loss: 0.06572694331407547
step: 460, loss: 0.013340655714273453
epoch 4: dev_f1=0.9943757030371203, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.11365405470132828
step: 10, loss: 0.05447947606444359
step: 20, loss: 0.09711641073226929
step: 30, loss: 0.08717668801546097
step: 40, loss: 0.06964819878339767
step: 50, loss: 0.017881033942103386
step: 60, loss: 0.011508484371006489
step: 70, loss: 0.012527086772024632
step: 80, loss: 0.07360362261533737
step: 90, loss: 0.07706647366285324
step: 100, loss: 0.009121245704591274
step: 110, loss: 0.015646500512957573
step: 120, loss: 0.006642160005867481
step: 130, loss: 0.1027420312166214
step: 140, loss: 0.05657750740647316
step: 150, loss: 0.08308159559965134
step: 160, loss: 0.0232315082103014
step: 170, loss: 0.06533356010913849
step: 180, loss: 0.10071933269500732
step: 190, loss: 0.06469994783401489
step: 200, loss: 0.0500815212726593
step: 210, loss: 0.01633666455745697
step: 220, loss: 0.012100787833333015
step: 230, loss: 0.07172980159521103
step: 240, loss: 0.06683787703514099
step: 250, loss: 0.07320902496576309
step: 260, loss: 0.05671124905347824
step: 270, loss: 0.05749277025461197
step: 280, loss: 0.0957665741443634
step: 290, loss: 0.055656548589468
step: 300, loss: 0.018835706636309624
step: 310, loss: 0.016057580709457397
step: 320, loss: 0.081952303647995
step: 330, loss: 0.06232322379946709
step: 340, loss: 0.005554120056331158
step: 350, loss: 0.12192165851593018
step: 360, loss: 0.014981499873101711
step: 370, loss: 0.025514082983136177
step: 380, loss: 0.08076648414134979
step: 390, loss: 0.029633603990077972
step: 400, loss: 0.020076818764209747
step: 410, loss: 0.013117321766912937
step: 420, loss: 0.04938807338476181
step: 430, loss: 0.1470945179462433
step: 440, loss: 0.015052195638418198
step: 450, loss: 0.012884734198451042
step: 460, loss: 0.028374189510941505
epoch 5: dev_f1=0.9943757030371203, f1=0.9875706214689265, best_f1=0.9854423292273236
step: 0, loss: 0.04987354576587677
step: 10, loss: 0.030105557292699814
step: 20, loss: 0.00441716006025672
step: 30, loss: 0.07191141694784164
step: 40, loss: 0.014450851827859879
step: 50, loss: 0.014702945947647095
step: 60, loss: 0.07176033407449722
step: 70, loss: 0.023328999057412148
step: 80, loss: 0.19500082731246948
step: 90, loss: 0.10955742746591568
step: 100, loss: 0.1704062670469284
step: 110, loss: 0.11922551691532135
step: 120, loss: 0.07064376771450043
step: 130, loss: 0.0723879411816597
step: 140, loss: 0.04125795513391495
step: 150, loss: 0.008814469911158085
step: 160, loss: 0.015078906901180744
step: 170, loss: 0.08235325664281845
step: 180, loss: 0.004717335570603609
step: 190, loss: 0.0699358657002449
step: 200, loss: 0.07725709676742554
step: 210, loss: 0.08288326114416122
step: 220, loss: 0.011339896358549595
step: 230, loss: 0.0011754168663173914
step: 240, loss: 0.06560257077217102
step: 250, loss: 0.06718870997428894
step: 260, loss: 0.0706600472331047
step: 270, loss: 0.06831280887126923
step: 280, loss: 0.1492723971605301
step: 290, loss: 0.0083640580996871
step: 300, loss: 0.0712905153632164
step: 310, loss: 0.10095614939928055
step: 320, loss: 0.013932845555245876
step: 330, loss: 0.025873206555843353
step: 340, loss: 0.021185683086514473
step: 350, loss: 0.11762502044439316
step: 360, loss: 0.01488802395761013
step: 370, loss: 0.019027242437005043
step: 380, loss: 0.05383080616593361
step: 390, loss: 0.0955958440899849
step: 400, loss: 0.07421930879354477
step: 410, loss: 0.01241182442754507
step: 420, loss: 0.035647179931402206
step: 430, loss: 0.13169114291667938
step: 440, loss: 0.029987847432494164
step: 450, loss: 0.06537708640098572
step: 460, loss: 0.027181485667824745
epoch 6: dev_f1=0.9932584269662922, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.05915236100554466
step: 10, loss: 0.03713946044445038
step: 20, loss: 0.03688395023345947
step: 30, loss: 0.06092984601855278
step: 40, loss: 0.15578919649124146
step: 50, loss: 0.017315518110990524
step: 60, loss: 0.07314398139715195
step: 70, loss: 0.0001060098220477812
step: 80, loss: 0.0313548818230629
step: 90, loss: 0.03272959589958191
step: 100, loss: 0.015744538977742195
step: 110, loss: 0.07139528542757034
step: 120, loss: 0.0571560300886631
step: 130, loss: 0.05880293250083923
step: 140, loss: 0.06100459024310112
step: 150, loss: 0.10347138345241547
step: 160, loss: 0.005270023364573717
step: 170, loss: 0.052827104926109314
step: 180, loss: 0.0006687424029223621
step: 190, loss: 0.025553837418556213
step: 200, loss: 0.0747540295124054
step: 210, loss: 0.12005773931741714
step: 220, loss: 0.0795709416270256
step: 230, loss: 0.029687950387597084
step: 240, loss: 0.011556052602827549
step: 250, loss: 0.08052485436201096
step: 260, loss: 0.06774096935987473
step: 270, loss: 0.07117212563753128
step: 280, loss: 0.0993172898888588
step: 290, loss: 0.052561093121767044
step: 300, loss: 0.08817851543426514
step: 310, loss: 0.022376395761966705
step: 320, loss: 0.16315428912639618
step: 330, loss: 0.012504180893301964
step: 340, loss: 0.013390508480370045
step: 350, loss: 0.007244700565934181
step: 360, loss: 0.006770572625100613
step: 370, loss: 0.13646137714385986
step: 380, loss: 0.027683831751346588
step: 390, loss: 0.046418532729148865
step: 400, loss: 0.08053067326545715
step: 410, loss: 0.013389701023697853
step: 420, loss: 0.02966929040849209
step: 430, loss: 0.08100888878107071
step: 440, loss: 0.027817368507385254
step: 450, loss: 0.018651269376277924
step: 460, loss: 0.14421668648719788
epoch 7: dev_f1=0.9921436588103255, f1=0.9876819708846584, best_f1=0.9854423292273236
step: 0, loss: 0.007177574560046196
step: 10, loss: 0.05761506408452988
step: 20, loss: 0.015268920920789242
step: 30, loss: 0.053586747497320175
step: 40, loss: 0.014260689727962017
step: 50, loss: 0.015349647030234337
step: 60, loss: 0.07944747060537338
step: 70, loss: 0.06593476235866547
step: 80, loss: 0.033315643668174744
step: 90, loss: 0.0069610062055289745
step: 100, loss: 0.014760577119886875
step: 110, loss: 0.03437584638595581
step: 120, loss: 0.1204565167427063
step: 130, loss: 0.011859213933348656
step: 140, loss: 0.0791846215724945
step: 150, loss: 0.1659439653158188
step: 160, loss: 0.07484012842178345
step: 170, loss: 0.07425978034734726
step: 180, loss: 0.003344694385305047
step: 190, loss: 0.00673262681812048
step: 200, loss: 0.010581541806459427
step: 210, loss: 0.009381646290421486
step: 220, loss: 0.09020393341779709
step: 230, loss: 0.08699452131986618
step: 240, loss: 0.0296819806098938
step: 250, loss: 0.06396470218896866
step: 260, loss: 0.030657239258289337
step: 270, loss: 0.07097342610359192
step: 280, loss: 0.045628130435943604
step: 290, loss: 0.020119786262512207
step: 300, loss: 0.0709512010216713
step: 310, loss: 0.0760316401720047
step: 320, loss: 0.07815203815698624
step: 330, loss: 0.08556869626045227
step: 340, loss: 0.025339797139167786
step: 350, loss: 0.0021189323160797358
step: 360, loss: 0.008772474713623524
step: 370, loss: 0.03407866880297661
step: 380, loss: 0.008704951032996178
step: 390, loss: 0.04327188432216644
step: 400, loss: 0.015640223398804665
step: 410, loss: 0.06275598704814911
step: 420, loss: 0.004000258632004261
step: 430, loss: 0.00028181521338410676
step: 440, loss: 0.006972568575292826
step: 450, loss: 0.05254873260855675
step: 460, loss: 0.09214139729738235
epoch 8: dev_f1=0.9910112359550561, f1=0.9831271091113611, best_f1=0.9854423292273236
step: 0, loss: 0.06155700609087944
step: 10, loss: 0.05267415568232536
step: 20, loss: 0.016671540215611458
step: 30, loss: 0.0699218213558197
step: 40, loss: 0.013309120200574398
step: 50, loss: 0.02177439257502556
step: 60, loss: 0.0004968565190210938
step: 70, loss: 0.020140064880251884
step: 80, loss: 0.014652812853455544
step: 90, loss: 0.014015286229550838
step: 100, loss: 0.0015448308549821377
step: 110, loss: 0.019578702747821808
step: 120, loss: 0.006295896600931883
step: 130, loss: 0.012723180465400219
step: 140, loss: 0.12573844194412231
step: 150, loss: 0.015519299544394016
step: 160, loss: 0.010249041020870209
step: 170, loss: 0.0320783294737339
step: 180, loss: 0.0039634620770812035
step: 190, loss: 0.0345054529607296
step: 200, loss: 0.0180837269872427
step: 210, loss: 0.052002329379320145
step: 220, loss: 0.005306775216013193
step: 230, loss: 0.10207467526197433
step: 240, loss: 0.03995765000581741
step: 250, loss: 0.1862853616476059
step: 260, loss: 0.013954938389360905
step: 270, loss: 0.03795317932963371
step: 280, loss: 0.06860543042421341
step: 290, loss: 0.007420514710247517
step: 300, loss: 0.03688622638583183
step: 310, loss: 0.012070686556398869
step: 320, loss: 0.07395100593566895
step: 330, loss: 0.12887156009674072
step: 340, loss: 0.00969819724559784
step: 350, loss: 0.04099820554256439
step: 360, loss: 0.010628165677189827
step: 370, loss: 0.010112090967595577
step: 380, loss: 0.008344045840203762
step: 390, loss: 0.07493765652179718
step: 400, loss: 0.08209311217069626
step: 410, loss: 0.05921641364693642
step: 420, loss: 0.011125590652227402
step: 430, loss: 0.030591022223234177
step: 440, loss: 0.0636880174279213
step: 450, loss: 0.12003267556428909
step: 460, loss: 0.012277900241315365
epoch 9: dev_f1=0.9932584269662922, f1=0.9865771812080537, best_f1=0.9854423292273236
step: 0, loss: 0.0021243675146251917
step: 10, loss: 0.025043655186891556
step: 20, loss: 9.14111005840823e-05
step: 30, loss: 0.02552090957760811
step: 40, loss: 0.06251022219657898
step: 50, loss: 0.034979723393917084
step: 60, loss: 0.07860750705003738
step: 70, loss: 0.0370757058262825
step: 80, loss: 0.013625727966427803
step: 90, loss: 0.015858640894293785
step: 100, loss: 0.029898222535848618
step: 110, loss: 0.0034953614231199026
step: 120, loss: 0.13023412227630615
step: 130, loss: 0.0026487589348107576
step: 140, loss: 0.06242409721016884
step: 150, loss: 0.015689805150032043
step: 160, loss: 0.008251108229160309
step: 170, loss: 0.0906347930431366
step: 180, loss: 0.08278157562017441
step: 190, loss: 0.018554408103227615
step: 200, loss: 0.00925601739436388
step: 210, loss: 0.01601673848927021
step: 220, loss: 0.010962595231831074
step: 230, loss: 0.005231545772403479
step: 240, loss: 0.0055399090051651
step: 250, loss: 0.034571610391139984
step: 260, loss: 0.0018860036507248878
step: 270, loss: 0.019776862114667892
step: 280, loss: 0.0018411573255434632
step: 290, loss: 0.07576218992471695
step: 300, loss: 0.10918110609054565
step: 310, loss: 0.0004775688285008073
step: 320, loss: 0.048584360629320145
step: 330, loss: 0.0008208429790101945
step: 340, loss: 0.011242537759244442
step: 350, loss: 0.17721550166606903
step: 360, loss: 0.01277109794318676
step: 370, loss: 0.020785322412848473
step: 380, loss: 0.10095083713531494
step: 390, loss: 0.026249626651406288
step: 400, loss: 0.05006511136889458
step: 410, loss: 0.10237056761980057
step: 420, loss: 0.04796398803591728
step: 430, loss: 0.08574826270341873
step: 440, loss: 0.09103822708129883
step: 450, loss: 0.06778399646282196
step: 460, loss: 0.04104181379079819
epoch 10: dev_f1=0.9932735426008968, f1=0.9854748603351955, best_f1=0.9854423292273236
step: 0, loss: 0.04371965676546097
step: 10, loss: 0.03963352367281914
step: 20, loss: 0.004852975718677044
step: 30, loss: 0.00010514567111385986
step: 40, loss: 0.02931397221982479
step: 50, loss: 0.0017051672330126166
step: 60, loss: 0.0008377388003282249
step: 70, loss: 0.04355939105153084
step: 80, loss: 0.12553079426288605
step: 90, loss: 0.05005408078432083
step: 100, loss: 0.11320068687200546
step: 110, loss: 0.018549956381320953
step: 120, loss: 0.0068520111963152885
step: 130, loss: 0.14449691772460938
step: 140, loss: 0.038815006613731384
step: 150, loss: 0.01364968717098236
step: 160, loss: 0.0020579735282808542
step: 170, loss: 0.011721746996045113
step: 180, loss: 0.03911658376455307
step: 190, loss: 0.018777653574943542
step: 200, loss: 0.05341894552111626
step: 210, loss: 0.00019767887715715915
step: 220, loss: 0.0025731706991791725
step: 230, loss: 0.049575325101614
step: 240, loss: 0.012709802947938442
step: 250, loss: 0.008800076320767403
step: 260, loss: 0.0056380718015134335
step: 270, loss: 0.037479620426893234
step: 280, loss: 0.05499729886651039
step: 290, loss: 0.07364257425069809
step: 300, loss: 0.19077390432357788
step: 310, loss: 3.2695988920750096e-05
step: 320, loss: 0.009806106798350811
step: 330, loss: 6.0232647228986025e-05
step: 340, loss: 0.039347805082798004
step: 350, loss: 0.028779031708836555
step: 360, loss: 0.043089382350444794
step: 370, loss: 0.0574272982776165
step: 380, loss: 0.05614883825182915
step: 390, loss: 0.06728964298963547
step: 400, loss: 0.016195964068174362
step: 410, loss: 0.015282475389540195
step: 420, loss: 0.0038981852121651173
step: 430, loss: 0.0458105094730854
step: 440, loss: 0.014055203646421432
step: 450, loss: 0.046582531183958054
step: 460, loss: 0.0369567796587944
epoch 11: dev_f1=0.995505617977528, f1=0.9898762654668166, best_f1=0.9898762654668166
step: 0, loss: 0.019050046801567078
step: 10, loss: 0.0031870435923337936
step: 20, loss: 0.054651182144880295
step: 30, loss: 0.013535845093429089
step: 40, loss: 0.008781857788562775
step: 50, loss: 0.08070410043001175
step: 60, loss: 0.003699525957927108
step: 70, loss: 0.07833193987607956
step: 80, loss: 0.0010363272158429027
step: 90, loss: 0.0002559016284067184
step: 100, loss: 7.497646583942696e-05
step: 110, loss: 0.025734320282936096
step: 120, loss: 0.025078795850276947
step: 130, loss: 0.0012984287459403276
step: 140, loss: 0.0014035277999937534
step: 150, loss: 0.04293971136212349
step: 160, loss: 0.04902584105730057
step: 170, loss: 0.01565639302134514
step: 180, loss: 0.0005450965836644173
step: 190, loss: 0.02762700989842415
step: 200, loss: 0.03699033707380295
step: 210, loss: 0.06222698464989662
step: 220, loss: 0.05329584702849388
step: 230, loss: 0.019326036795973778
step: 240, loss: 0.03865409269928932
step: 250, loss: 0.03848007693886757
step: 260, loss: 4.936812911182642e-05
step: 270, loss: 0.005472888704389334
step: 280, loss: 0.023179171606898308
step: 290, loss: 0.008908811956644058
step: 300, loss: 0.0574888251721859
step: 310, loss: 0.003482232103124261
step: 320, loss: 0.07436230778694153
step: 330, loss: 0.03615671768784523
step: 340, loss: 0.1424589306116104
step: 350, loss: 0.07067275047302246
step: 360, loss: 0.0029362773057073355
step: 370, loss: 0.0005686701624654233
step: 380, loss: 0.06510761380195618
step: 390, loss: 0.0008392363088205457
step: 400, loss: 0.022148067131638527
step: 410, loss: 0.029219675809144974
step: 420, loss: 0.12296206504106522
step: 430, loss: 0.01577724702656269
step: 440, loss: 0.002735520713031292
step: 450, loss: 0.014855554327368736
step: 460, loss: 0.05154560133814812
epoch 12: dev_f1=0.9943757030371203, f1=0.9865470852017937, best_f1=0.9898762654668166
step: 0, loss: 0.02418193593621254
step: 10, loss: 7.094858301570639e-05
step: 20, loss: 0.00030867717578075826
step: 30, loss: 0.02365461178123951
step: 40, loss: 0.027486320585012436
step: 50, loss: 0.021324656903743744
step: 60, loss: 0.020287256687879562
step: 70, loss: 0.025246979668736458
step: 80, loss: 0.16666220128536224
step: 90, loss: 0.0770067498087883
step: 100, loss: 0.03381992504000664
step: 110, loss: 0.09271954745054245
step: 120, loss: 0.06063004210591316
step: 130, loss: 0.07429876923561096
step: 140, loss: 0.0316559374332428
step: 150, loss: 0.019755877554416656
step: 160, loss: 0.022724483162164688
step: 170, loss: 0.007310828194022179
step: 180, loss: 0.06450062990188599
step: 190, loss: 0.0001611595507711172
step: 200, loss: 0.04577283933758736
step: 210, loss: 0.03339951112866402
step: 220, loss: 0.06388815492391586
step: 230, loss: 0.026682697236537933
step: 240, loss: 0.02212558500468731
step: 250, loss: 0.07400121539831161
step: 260, loss: 0.052379097789525986
step: 270, loss: 0.04877609759569168
step: 280, loss: 0.008673584088683128
step: 290, loss: 0.029021812602877617
step: 300, loss: 5.3136234782868996e-05
step: 310, loss: 0.013263723812997341
step: 320, loss: 0.027689959853887558
step: 330, loss: 0.05570986866950989
step: 340, loss: 0.0005187317728996277
step: 350, loss: 0.03177884221076965
step: 360, loss: 0.021918177604675293
step: 370, loss: 0.0024019877891987562
step: 380, loss: 0.02256186492741108
step: 390, loss: 0.04489470273256302
step: 400, loss: 0.0006447762134484947
step: 410, loss: 0.0004726832848973572
step: 420, loss: 0.018985167145729065
step: 430, loss: 0.05112500861287117
step: 440, loss: 0.07440688461065292
step: 450, loss: 0.02862953022122383
step: 460, loss: 0.11121859401464462
epoch 13: dev_f1=0.9943883277216611, f1=0.9854748603351955, best_f1=0.9898762654668166
step: 0, loss: 0.02556702308356762
step: 10, loss: 0.02735724113881588
step: 20, loss: 0.00048356951447203755
step: 30, loss: 0.02081155776977539
step: 40, loss: 0.00031267316080629826
step: 50, loss: 0.07703526318073273
step: 60, loss: 0.03998768329620361
step: 70, loss: 0.0008149634813889861
step: 80, loss: 0.022923145443201065
step: 90, loss: 0.0001438015460735187
step: 100, loss: 0.04020242393016815
step: 110, loss: 0.021662075072526932
step: 120, loss: 0.022043004631996155
step: 130, loss: 0.03886236250400543
step: 140, loss: 0.0007070880965329707
step: 150, loss: 0.00015854803496040404
step: 160, loss: 3.738200757652521e-05
step: 170, loss: 0.0001755967241479084
step: 180, loss: 0.005964476149529219
step: 190, loss: 0.04817919060587883
step: 200, loss: 0.017762914299964905
step: 210, loss: 0.03551090881228447
step: 220, loss: 0.05396131053566933
step: 230, loss: 0.00018959640874527395
step: 240, loss: 5.83275432290975e-05
step: 250, loss: 0.027693869546055794
step: 260, loss: 0.034768760204315186
step: 270, loss: 0.03433152288198471
step: 280, loss: 0.019446196034550667
step: 290, loss: 0.01819702237844467
step: 300, loss: 3.453583485679701e-05
step: 310, loss: 0.0006749322637915611
step: 320, loss: 0.0008625387563370168
step: 330, loss: 0.04161347448825836
step: 340, loss: 0.016417304053902626
step: 350, loss: 0.04665451496839523
step: 360, loss: 0.04569408297538757
step: 370, loss: 0.037628158926963806
step: 380, loss: 0.04985985904932022
step: 390, loss: 0.0460822619497776
step: 400, loss: 0.02024381048977375
step: 410, loss: 0.004090868402272463
step: 420, loss: 0.020941464230418205
step: 430, loss: 0.000481653114547953
step: 440, loss: 0.013151354156434536
step: 450, loss: 0.00044962222455069423
step: 460, loss: 0.02236408181488514
epoch 14: dev_f1=0.9943757030371203, f1=0.9865470852017937, best_f1=0.9898762654668166
step: 0, loss: 0.00257994350977242
step: 10, loss: 0.0002532666549086571
step: 20, loss: 0.07135768234729767
step: 30, loss: 0.00018014329543802887
step: 40, loss: 0.0002702285419218242
step: 50, loss: 0.020560255274176598
step: 60, loss: 0.03318246081471443
step: 70, loss: 0.023216087371110916
step: 80, loss: 0.0004936876357533038
step: 90, loss: 0.030082806944847107
step: 100, loss: 0.024178553372621536
step: 110, loss: 0.000559612934011966
step: 120, loss: 0.03985988348722458
step: 130, loss: 0.020001698285341263
step: 140, loss: 0.008971389383077621
step: 150, loss: 0.0001718297426123172
step: 160, loss: 0.00025880589964799583
step: 170, loss: 0.02142171375453472
step: 180, loss: 0.025353707373142242
step: 190, loss: 0.017786499112844467
step: 200, loss: 0.0010745953768491745
step: 210, loss: 0.04965084791183472
step: 220, loss: 0.05012533441185951
step: 230, loss: 0.023531224578619003
step: 240, loss: 0.0009216833277605474
step: 250, loss: 0.0008227259968407452
step: 260, loss: 0.04172347113490105
step: 270, loss: 0.00012181566853541881
step: 280, loss: 0.0003244865802116692
step: 290, loss: 0.000289169664029032
step: 300, loss: 0.003960121888667345
step: 310, loss: 0.002231410937383771
step: 320, loss: 0.000257687468547374
step: 330, loss: 0.024521293118596077
step: 340, loss: 0.0010496126487851143
step: 350, loss: 0.006184990052133799
step: 360, loss: 0.029391318559646606
step: 370, loss: 0.0008935372461564839
step: 380, loss: 0.0001636487722862512
step: 390, loss: 0.028370501473546028
step: 400, loss: 0.05841170623898506
step: 410, loss: 0.06786951422691345
step: 420, loss: 0.021741047501564026
step: 430, loss: 0.001837887684814632
step: 440, loss: 0.04025530442595482
step: 450, loss: 0.07251930236816406
step: 460, loss: 0.06291765719652176
epoch 15: dev_f1=0.9943883277216611, f1=0.9876819708846584, best_f1=0.9898762654668166
step: 0, loss: 0.00017123622819781303
step: 10, loss: 0.02127915620803833
step: 20, loss: 0.02390804886817932
step: 30, loss: 0.018068138509988785
step: 40, loss: 0.04856365919113159
step: 50, loss: 0.02145308628678322
step: 60, loss: 0.00015210718265734613
step: 70, loss: 0.03685114160180092
step: 80, loss: 6.496073910966516e-05
step: 90, loss: 0.00010906522948062047
step: 100, loss: 0.018199509009718895
step: 110, loss: 0.12455885112285614
step: 120, loss: 0.05216514691710472
step: 130, loss: 0.07834714651107788
step: 140, loss: 0.024229124188423157
step: 150, loss: 0.05214565992355347
step: 160, loss: 0.00012441881699487567
step: 170, loss: 0.22017697989940643
step: 180, loss: 0.0460018515586853
step: 190, loss: 0.014657787047326565
step: 200, loss: 0.06396960467100143
step: 210, loss: 0.002346510998904705
step: 220, loss: 0.00013906703679822385
step: 230, loss: 0.0017326658125966787
step: 240, loss: 0.04686211422085762
step: 250, loss: 0.00046176218893378973
step: 260, loss: 0.02131570875644684
step: 270, loss: 6.378880061674863e-05
step: 280, loss: 0.08924892544746399
step: 290, loss: 0.04727547988295555
step: 300, loss: 0.028712892904877663
step: 310, loss: 0.02506866864860058
step: 320, loss: 0.024209244176745415
step: 330, loss: 0.026606285944581032
step: 340, loss: 0.044352419674396515
step: 350, loss: 0.01648910529911518
step: 360, loss: 0.0014805449172854424
step: 370, loss: 0.06334124505519867
step: 380, loss: 0.0001813026610761881
step: 390, loss: 0.00012156985030742362
step: 400, loss: 0.011230596341192722
step: 410, loss: 0.042367614805698395
step: 420, loss: 0.012748039327561855
step: 430, loss: 0.039459723979234695
step: 440, loss: 0.03759637102484703
step: 450, loss: 0.008460363373160362
step: 460, loss: 0.0032462573144584894
epoch 16: dev_f1=0.9943883277216611, f1=0.9865470852017937, best_f1=0.9898762654668166
step: 0, loss: 0.05568224564194679
step: 10, loss: 0.023209039121866226
step: 20, loss: 0.014959946274757385
step: 30, loss: 6.529450183734298e-05
step: 40, loss: 0.018483228981494904
step: 50, loss: 0.09003745764493942
step: 60, loss: 7.950570579851046e-05
step: 70, loss: 0.026908177882432938
step: 80, loss: 0.00022400534362532198
step: 90, loss: 0.03465280309319496
step: 100, loss: 0.2172021120786667
step: 110, loss: 0.06879055500030518
step: 120, loss: 8.903977868612856e-05
step: 130, loss: 0.09693293273448944
step: 140, loss: 0.022988827899098396
step: 150, loss: 0.01865086704492569
step: 160, loss: 0.03644299507141113
step: 170, loss: 0.017146408557891846
step: 180, loss: 0.022773919627070427
step: 190, loss: 7.366011413978413e-05
step: 200, loss: 0.0003768807800952345
step: 210, loss: 0.03467033803462982
step: 220, loss: 9.183613292407244e-05
step: 230, loss: 0.02402077615261078
step: 240, loss: 0.029405377805233
step: 250, loss: 0.01893595978617668
step: 260, loss: 0.02766452357172966
step: 270, loss: 0.002605886897072196
step: 280, loss: 0.039199281483888626
step: 290, loss: 0.0001846462837420404
step: 300, loss: 0.012878398410975933
step: 310, loss: 4.125868508708663e-05
step: 320, loss: 0.06888570636510849
step: 330, loss: 0.036347199231386185
step: 340, loss: 0.0006413763621822
step: 350, loss: 0.01129147969186306
step: 360, loss: 0.025409070774912834
step: 370, loss: 0.039158619940280914
step: 380, loss: 0.015427043661475182
step: 390, loss: 0.023750290274620056
step: 400, loss: 6.673377356491983e-05
step: 410, loss: 5.904124191147275e-05
step: 420, loss: 4.05138052883558e-05
step: 430, loss: 0.02296973578631878
step: 440, loss: 0.04169502854347229
step: 450, loss: 7.00790187693201e-05
step: 460, loss: 0.013694112189114094
epoch 17: dev_f1=0.995505617977528, f1=0.9865470852017937, best_f1=0.9898762654668166
step: 0, loss: 0.019311022013425827
step: 10, loss: 0.07816293835639954
step: 20, loss: 0.09142912924289703
step: 30, loss: 0.025730835273861885
step: 40, loss: 0.035811375826597214
step: 50, loss: 9.771930490387604e-05
step: 60, loss: 0.025404416024684906
step: 70, loss: 9.683660027803853e-05
step: 80, loss: 0.002590625314041972
step: 90, loss: 0.004014636855572462
step: 100, loss: 0.0234892126172781
step: 110, loss: 0.019257454201579094
step: 120, loss: 0.016412897035479546
step: 130, loss: 0.01729460060596466
step: 140, loss: 3.224402462365106e-05
step: 150, loss: 0.0005143090384081006
step: 160, loss: 4.346000787336379e-05
step: 170, loss: 0.000280881387880072
step: 180, loss: 0.03170124441385269
step: 190, loss: 0.036899298429489136
step: 200, loss: 0.03132519870996475
step: 210, loss: 0.03939385712146759
step: 220, loss: 0.0001428370305802673
step: 230, loss: 9.467850759392604e-05
step: 240, loss: 0.04345307871699333
step: 250, loss: 0.024017924442887306
step: 260, loss: 0.0001169158422271721
step: 270, loss: 0.021757841110229492
step: 280, loss: 0.020240170881152153
step: 290, loss: 0.03912380337715149
step: 300, loss: 0.026468148455023766
step: 310, loss: 0.02317405305802822
step: 320, loss: 0.028324710205197334
step: 330, loss: 0.0001259579003090039
step: 340, loss: 0.04331309720873833
step: 350, loss: 0.027413425967097282
step: 360, loss: 4.5120825234334916e-05
step: 370, loss: 0.04152972996234894
step: 380, loss: 0.05302128195762634
step: 390, loss: 7.765523332636803e-05
step: 400, loss: 0.030880797654390335
step: 410, loss: 0.05154094472527504
step: 420, loss: 0.02697284147143364
step: 430, loss: 0.022962305694818497
step: 440, loss: 0.03980202600359917
step: 450, loss: 0.0002486923767719418
step: 460, loss: 0.00030988382059149444
epoch 18: dev_f1=0.9943883277216611, f1=0.9865470852017937, best_f1=0.9898762654668166
step: 0, loss: 0.024334244430065155
step: 10, loss: 0.0009752407786436379
step: 20, loss: 0.02102448232471943
step: 30, loss: 0.018387073650956154
step: 40, loss: 7.062066288199276e-05
step: 50, loss: 0.029350925236940384
step: 60, loss: 0.025595059618353844
step: 70, loss: 0.07994770258665085
step: 80, loss: 2.144193604181055e-05
step: 90, loss: 0.032633036375045776
step: 100, loss: 4.058987178723328e-05
step: 110, loss: 0.03414672985672951
step: 120, loss: 0.00018797951634041965
step: 130, loss: 8.599470311310142e-05
step: 140, loss: 0.037852656096220016
step: 150, loss: 0.01633591204881668
step: 160, loss: 0.023449935019016266
step: 170, loss: 0.018175629898905754
step: 180, loss: 0.015569300390779972
step: 190, loss: 9.224508539773524e-05
step: 200, loss: 0.04191061854362488
step: 210, loss: 0.03714988753199577
step: 220, loss: 0.00018928167992271483
step: 230, loss: 0.00017005180416163057
step: 240, loss: 0.020754534751176834
step: 250, loss: 0.019121620804071426
step: 260, loss: 0.01788555458188057
step: 270, loss: 1.717324266792275e-05
step: 280, loss: 0.017453182488679886
step: 290, loss: 6.635490717599168e-05
step: 300, loss: 8.839921792969108e-05
step: 310, loss: 0.01681673899292946
step: 320, loss: 0.06508643925189972
step: 330, loss: 3.6261095374356955e-05
step: 340, loss: 0.06823798269033432
step: 350, loss: 0.024599093943834305
step: 360, loss: 0.046112220734357834
step: 370, loss: 0.0015981593169271946
step: 380, loss: 0.0001636149681871757
step: 390, loss: 0.00040321043343283236
step: 400, loss: 0.023487649857997894
step: 410, loss: 0.04665910080075264
step: 420, loss: 0.001161847379989922
step: 430, loss: 0.07523447275161743
step: 440, loss: 0.06162118539214134
step: 450, loss: 0.023383446037769318
step: 460, loss: 0.02642059698700905
epoch 19: dev_f1=0.995505617977528, f1=0.9854096520763187, best_f1=0.9898762654668166
step: 0, loss: 0.017041372135281563
step: 10, loss: 1.7486127035226673e-05
step: 20, loss: 0.05577170103788376
step: 30, loss: 0.00010073406883748248
step: 40, loss: 0.06605353206396103
step: 50, loss: 0.00025860892492346466
step: 60, loss: 5.434921331470832e-05
step: 70, loss: 0.0316937118768692
step: 80, loss: 1.728484858176671e-05
step: 90, loss: 3.3226511732209474e-05
step: 100, loss: 3.521181861287914e-05
step: 110, loss: 4.0734066715231165e-05
step: 120, loss: 0.04778921976685524
step: 130, loss: 8.299635373987257e-05
step: 140, loss: 0.03962934762239456
step: 150, loss: 0.023549411445856094
step: 160, loss: 0.01571597158908844
step: 170, loss: 0.042627833783626556
step: 180, loss: 0.03674090653657913
step: 190, loss: 0.02032487653195858
step: 200, loss: 0.00011114907829323784
step: 210, loss: 0.01765390671789646
step: 220, loss: 0.039501629769802094
step: 230, loss: 0.03652505949139595
step: 240, loss: 0.004291861318051815
step: 250, loss: 7.2392555011902e-05
step: 260, loss: 0.0254227127879858
step: 270, loss: 6.211358413565904e-05
step: 280, loss: 8.266588702099398e-05
step: 290, loss: 0.001250959699973464
step: 300, loss: 0.0452791191637516
step: 310, loss: 0.0341372974216938
step: 320, loss: 0.025828640908002853
step: 330, loss: 2.372544076933991e-05
step: 340, loss: 0.018107762560248375
step: 350, loss: 0.02415984682738781
step: 360, loss: 0.019036218523979187
step: 370, loss: 0.035852499306201935
step: 380, loss: 0.020197555422782898
step: 390, loss: 0.025464406237006187
step: 400, loss: 0.016719404608011246
step: 410, loss: 0.02656988427042961
step: 420, loss: 0.03412075713276863
step: 430, loss: 2.525243144191336e-05
step: 440, loss: 0.024249445647001266
step: 450, loss: 0.053006820380687714
step: 460, loss: 0.03224324807524681
epoch 20: dev_f1=0.995505617977528, f1=0.9865470852017937, best_f1=0.9898762654668166
