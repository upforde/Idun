cuda
Device: cuda
step: 0, loss: 0.7888215780258179
step: 10, loss: 0.2765897512435913
step: 20, loss: 0.35789844393730164
step: 30, loss: 0.18514280021190643
step: 40, loss: 0.23144032061100006
step: 50, loss: 0.1991969496011734
step: 60, loss: 0.11009997874498367
step: 70, loss: 0.20537671446800232
step: 80, loss: 0.12583278119564056
step: 90, loss: 0.10299092531204224
step: 100, loss: 0.14596709609031677
step: 110, loss: 0.1721615493297577
step: 120, loss: 0.08711609989404678
step: 130, loss: 0.20625512301921844
step: 140, loss: 0.13234299421310425
step: 150, loss: 0.07853987067937851
step: 160, loss: 0.2312270849943161
step: 170, loss: 0.11536471545696259
step: 180, loss: 0.10260964184999466
step: 190, loss: 0.03937221318483353
step: 200, loss: 0.12015405297279358
step: 210, loss: 0.10032009333372116
step: 220, loss: 0.11317966878414154
step: 230, loss: 0.13954822719097137
step: 240, loss: 0.09164968878030777
step: 250, loss: 0.06160381808876991
step: 260, loss: 0.022659825161099434
step: 270, loss: 0.03692039102315903
step: 280, loss: 0.011599252000451088
step: 290, loss: 0.02632928639650345
step: 300, loss: 0.05081980675458908
step: 310, loss: 0.1289849430322647
step: 320, loss: 0.0897308960556984
step: 330, loss: 0.022118404507637024
step: 340, loss: 0.237022265791893
step: 350, loss: 0.3613397777080536
step: 360, loss: 0.09028114378452301
step: 370, loss: 0.027698861435055733
step: 380, loss: 0.025033244863152504
step: 390, loss: 0.07118174433708191
step: 400, loss: 0.10746157914400101
step: 410, loss: 0.008493137545883656
step: 420, loss: 0.04161728918552399
step: 430, loss: 0.042388785630464554
step: 440, loss: 0.06577848643064499
step: 450, loss: 0.08837597817182541
step: 460, loss: 0.14475464820861816
epoch 1: dev_f1=0.9844444444444443, f1=0.9777777777777777, best_f1=0.9777777777777777
step: 0, loss: 0.1277119219303131
step: 10, loss: 0.027450641617178917
step: 20, loss: 0.04576839879155159
step: 30, loss: 0.05136977508664131
step: 40, loss: 0.11960255354642868
step: 50, loss: 0.007723535411059856
step: 60, loss: 0.06366244703531265
step: 70, loss: 0.08005832135677338
step: 80, loss: 0.03563535958528519
step: 90, loss: 0.16002346575260162
step: 100, loss: 0.023050399497151375
step: 110, loss: 0.09736797213554382
step: 120, loss: 0.09417573362588882
step: 130, loss: 0.013851911760866642
step: 140, loss: 0.006203708704560995
step: 150, loss: 0.0038990445900708437
step: 160, loss: 0.07173731178045273
step: 170, loss: 0.01386521477252245
step: 180, loss: 0.16047000885009766
step: 190, loss: 0.11304181814193726
step: 200, loss: 0.05969161167740822
step: 210, loss: 0.03500545769929886
step: 220, loss: 0.11934352666139603
step: 230, loss: 0.035456836223602295
step: 240, loss: 0.021298227831721306
step: 250, loss: 0.03240341693162918
step: 260, loss: 0.06614524126052856
step: 270, loss: 0.20837020874023438
step: 280, loss: 0.0360737182199955
step: 290, loss: 0.09033526480197906
step: 300, loss: 0.006956060882657766
step: 310, loss: 0.08045397698879242
step: 320, loss: 0.04498578608036041
step: 330, loss: 0.19383227825164795
step: 340, loss: 0.015605157241225243
step: 350, loss: 0.06067179888486862
step: 360, loss: 0.1053183376789093
step: 370, loss: 0.011553377844393253
step: 380, loss: 0.10261476784944534
step: 390, loss: 0.07738961279392242
step: 400, loss: 0.11085694283246994
step: 410, loss: 0.012301396578550339
step: 420, loss: 0.04878484085202217
step: 430, loss: 0.08320197463035583
step: 440, loss: 0.08327504992485046
step: 450, loss: 0.17097622156143188
step: 460, loss: 0.09179399907588959
epoch 2: dev_f1=0.9943757030371203, f1=0.9886877828054299, best_f1=0.9886877828054299
step: 0, loss: 0.05536830797791481
step: 10, loss: 0.0807657539844513
step: 20, loss: 0.0018973560072481632
step: 30, loss: 0.013446353375911713
step: 40, loss: 0.00732414098456502
step: 50, loss: 0.011130355298519135
step: 60, loss: 0.09130599349737167
step: 70, loss: 0.012879518792033195
step: 80, loss: 0.22322271764278412
step: 90, loss: 0.02413058839738369
step: 100, loss: 0.020899444818496704
step: 110, loss: 0.015132174827158451
step: 120, loss: 0.015129562467336655
step: 130, loss: 0.08511283248662949
step: 140, loss: 0.07160255312919617
step: 150, loss: 0.057956092059612274
step: 160, loss: 0.11767025291919708
step: 170, loss: 0.09178139269351959
step: 180, loss: 0.049498677253723145
step: 190, loss: 0.08557822555303574
step: 200, loss: 0.01793803833425045
step: 210, loss: 0.0780206248164177
step: 220, loss: 0.01386452279984951
step: 230, loss: 0.08386790752410889
step: 240, loss: 0.04194140061736107
step: 250, loss: 0.04780125990509987
step: 260, loss: 0.031353965401649475
step: 270, loss: 0.005656017921864986
step: 280, loss: 0.02099693939089775
step: 290, loss: 0.09289053082466125
step: 300, loss: 0.003959336318075657
step: 310, loss: 0.09483834356069565
step: 320, loss: 0.028398850932717323
step: 330, loss: 0.08942955732345581
step: 340, loss: 0.14219880104064941
step: 350, loss: 0.019710304215550423
step: 360, loss: 0.05495285615324974
step: 370, loss: 0.03287803381681442
step: 380, loss: 0.07723270356655121
step: 390, loss: 0.034774210304021835
step: 400, loss: 0.042647585272789
step: 410, loss: 0.038413502275943756
step: 420, loss: 0.10862839221954346
step: 430, loss: 0.155337855219841
step: 440, loss: 0.07607831805944443
step: 450, loss: 0.021366415545344353
step: 460, loss: 0.06371516734361649
epoch 3: dev_f1=0.992108229988726, f1=0.9842696629213483, best_f1=0.9886877828054299
step: 0, loss: 0.027390286326408386
step: 10, loss: 0.12816794216632843
step: 20, loss: 0.013870622962713242
step: 30, loss: 0.01978723704814911
step: 40, loss: 0.035130277276039124
step: 50, loss: 0.010968653485178947
step: 60, loss: 0.062199003994464874
step: 70, loss: 0.020809881389141083
step: 80, loss: 0.08766764402389526
step: 90, loss: 0.06106368452310562
step: 100, loss: 0.04337870329618454
step: 110, loss: 0.02183963544666767
step: 120, loss: 0.030429260805249214
step: 130, loss: 0.01643032394349575
step: 140, loss: 0.011133956722915173
step: 150, loss: 0.006919910665601492
step: 160, loss: 0.02922173961997032
step: 170, loss: 0.020476922392845154
step: 180, loss: 0.011166702955961227
step: 190, loss: 0.011895286850631237
step: 200, loss: 0.061329372227191925
step: 210, loss: 0.011343580670654774
step: 220, loss: 0.04527776315808296
step: 230, loss: 0.04230677708983421
step: 240, loss: 0.08459564298391342
step: 250, loss: 0.01422491017729044
step: 260, loss: 0.05912712961435318
step: 270, loss: 0.10023689270019531
step: 280, loss: 0.023410078138113022
step: 290, loss: 0.08222875744104385
step: 300, loss: 0.06757974624633789
step: 310, loss: 0.014128775335848331
step: 320, loss: 0.098823182284832
step: 330, loss: 0.028043869882822037
step: 340, loss: 0.01829594001173973
step: 350, loss: 0.013313183560967445
step: 360, loss: 0.11921323835849762
step: 370, loss: 0.08589328825473785
step: 380, loss: 0.12429966032505035
step: 390, loss: 0.07440363615751266
step: 400, loss: 0.005168015602976084
step: 410, loss: 0.05663010850548744
step: 420, loss: 0.045693255960941315
step: 430, loss: 0.096858911216259
step: 440, loss: 0.042291171848773956
step: 450, loss: 0.01637660339474678
step: 460, loss: 0.0177165437489748
epoch 4: dev_f1=0.9954954954954955, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.018044941127300262
step: 10, loss: 0.013713465072214603
step: 20, loss: 0.004107393324375153
step: 30, loss: 0.0795879140496254
step: 40, loss: 0.12091272324323654
step: 50, loss: 0.036502573639154434
step: 60, loss: 0.016301102936267853
step: 70, loss: 0.051485925912857056
step: 80, loss: 0.07471240311861038
step: 90, loss: 0.07675359398126602
step: 100, loss: 0.05674754083156586
step: 110, loss: 0.10421983897686005
step: 120, loss: 0.0036000399850308895
step: 130, loss: 0.012719389982521534
step: 140, loss: 0.06801952421665192
step: 150, loss: 0.062005218118429184
step: 160, loss: 0.081485316157341
step: 170, loss: 0.0980401411652565
step: 180, loss: 0.05708829686045647
step: 190, loss: 0.06236102804541588
step: 200, loss: 0.011160669848322868
step: 210, loss: 0.03721616789698601
step: 220, loss: 0.12323455512523651
step: 230, loss: 0.030061230063438416
step: 240, loss: 0.07454854249954224
step: 250, loss: 0.019561810418963432
step: 260, loss: 0.07528968900442123
step: 270, loss: 0.07425491511821747
step: 280, loss: 0.03290387988090515
step: 290, loss: 0.015230725519359112
step: 300, loss: 0.0659160315990448
step: 310, loss: 0.026698917150497437
step: 320, loss: 0.06702521443367004
step: 330, loss: 0.09682223945856094
step: 340, loss: 0.2326904833316803
step: 350, loss: 0.06938586384057999
step: 360, loss: 0.020341623574495316
step: 370, loss: 0.14991985261440277
step: 380, loss: 0.08331166952848434
step: 390, loss: 0.00796966627240181
step: 400, loss: 0.014833447523415089
step: 410, loss: 0.021021006628870964
step: 420, loss: 0.01420232281088829
step: 430, loss: 0.06814722716808319
step: 440, loss: 0.00573118356987834
step: 450, loss: 0.0174565427005291
step: 460, loss: 0.0674189031124115
epoch 5: dev_f1=0.9932432432432432, f1=0.9809203142536477, best_f1=0.9854096520763187
step: 0, loss: 0.04877452179789543
step: 10, loss: 0.01945759914815426
step: 20, loss: 0.02443479374051094
step: 30, loss: 0.0005641494644805789
step: 40, loss: 0.018245583400130272
step: 50, loss: 0.07010377198457718
step: 60, loss: 0.1312842071056366
step: 70, loss: 0.045823514461517334
step: 80, loss: 0.06403761357069016
step: 90, loss: 0.09246993064880371
step: 100, loss: 0.048418961465358734
step: 110, loss: 0.007445984054356813
step: 120, loss: 0.016409263014793396
step: 130, loss: 0.061201609671115875
step: 140, loss: 0.06695130467414856
step: 150, loss: 0.0984194353222847
step: 160, loss: 0.03808027133345604
step: 170, loss: 0.1991858035326004
step: 180, loss: 0.06899695098400116
step: 190, loss: 0.03956226259469986
step: 200, loss: 0.05917949974536896
step: 210, loss: 0.09516444802284241
step: 220, loss: 0.06998215615749359
step: 230, loss: 0.029755568131804466
step: 240, loss: 0.020561357960104942
step: 250, loss: 0.12527625262737274
step: 260, loss: 0.035028256475925446
step: 270, loss: 0.11161348968744278
step: 280, loss: 0.00012884438910987228
step: 290, loss: 0.07543592900037766
step: 300, loss: 0.06478553265333176
step: 310, loss: 0.05907899886369705
step: 320, loss: 0.0697547122836113
step: 330, loss: 0.08474799990653992
step: 340, loss: 0.2058105617761612
step: 350, loss: 0.021237226203083992
step: 360, loss: 0.02144002541899681
step: 370, loss: 0.06343106180429459
step: 380, loss: 0.02335856668651104
step: 390, loss: 0.009447519667446613
step: 400, loss: 0.0058759357780218124
step: 410, loss: 0.0030189710669219494
step: 420, loss: 0.07455971837043762
step: 430, loss: 0.017651261761784554
step: 440, loss: 0.014268128201365471
step: 450, loss: 0.055854763835668564
step: 460, loss: 0.016813749447464943
epoch 6: dev_f1=0.9898989898989898, f1=0.9820224719101124, best_f1=0.9854096520763187
step: 0, loss: 0.012946314178407192
step: 10, loss: 0.07407153397798538
step: 20, loss: 0.017665840685367584
step: 30, loss: 0.07213745266199112
step: 40, loss: 0.02524780109524727
step: 50, loss: 0.018646275624632835
step: 60, loss: 0.005244558677077293
step: 70, loss: 0.11976500600576401
step: 80, loss: 0.07199712097644806
step: 90, loss: 0.08753793686628342
step: 100, loss: 0.10067592561244965
step: 110, loss: 0.10001151263713837
step: 120, loss: 0.014464432373642921
step: 130, loss: 0.04722871631383896
step: 140, loss: 0.021064020693302155
step: 150, loss: 0.06131184473633766
step: 160, loss: 0.01311503630131483
step: 170, loss: 0.01219955738633871
step: 180, loss: 0.08345559984445572
step: 190, loss: 0.13328836858272552
step: 200, loss: 0.00046052917605265975
step: 210, loss: 0.027854489162564278
step: 220, loss: 0.07187402993440628
step: 230, loss: 0.07655428349971771
step: 240, loss: 0.07030000537633896
step: 250, loss: 0.06383238732814789
step: 260, loss: 0.020499493926763535
step: 270, loss: 0.10310746729373932
step: 280, loss: 0.05739954859018326
step: 290, loss: 0.008661674335598946
step: 300, loss: 0.002888943301513791
step: 310, loss: 0.03428494557738304
step: 320, loss: 0.012965134344995022
step: 330, loss: 0.060124024748802185
step: 340, loss: 0.09206732362508774
step: 350, loss: 0.012965650297701359
step: 360, loss: 0.07829083502292633
step: 370, loss: 0.007052981294691563
step: 380, loss: 0.013819933868944645
step: 390, loss: 0.019842617213726044
step: 400, loss: 0.1834620088338852
step: 410, loss: 0.07883890718221664
step: 420, loss: 0.008933616802096367
step: 430, loss: 0.005798663478344679
step: 440, loss: 0.010975711047649384
step: 450, loss: 0.008858855813741684
step: 460, loss: 0.009476907551288605
epoch 7: dev_f1=0.9909706546275394, f1=0.9820224719101124, best_f1=0.9854096520763187
step: 0, loss: 0.04669772461056709
step: 10, loss: 0.01882527768611908
step: 20, loss: 0.08480112999677658
step: 30, loss: 0.009891718626022339
step: 40, loss: 0.01772889867424965
step: 50, loss: 0.05304306745529175
step: 60, loss: 0.0302435215562582
step: 70, loss: 0.11260302364826202
step: 80, loss: 0.10980856418609619
step: 90, loss: 0.07799366861581802
step: 100, loss: 0.0034600074868649244
step: 110, loss: 0.022149119526147842
step: 120, loss: 0.06701192259788513
step: 130, loss: 0.014325741678476334
step: 140, loss: 0.016150521114468575
step: 150, loss: 0.035177286714315414
step: 160, loss: 0.00018089209333993495
step: 170, loss: 0.012281028553843498
step: 180, loss: 0.06603095680475235
step: 190, loss: 0.018069982528686523
step: 200, loss: 0.05059197545051575
step: 210, loss: 0.007574322633445263
step: 220, loss: 0.08243366330862045
step: 230, loss: 0.0051190853118896484
step: 240, loss: 0.02792559750378132
step: 250, loss: 0.1716548502445221
step: 260, loss: 0.02686198800802231
step: 270, loss: 2.3699829398537986e-05
step: 280, loss: 0.01662323623895645
step: 290, loss: 0.09247079491615295
step: 300, loss: 0.05838178098201752
step: 310, loss: 0.23821650445461273
step: 320, loss: 0.010239941999316216
step: 330, loss: 0.0004692489164881408
step: 340, loss: 0.02750089392066002
step: 350, loss: 0.03204396739602089
step: 360, loss: 0.10633774846792221
step: 370, loss: 0.12495329976081848
step: 380, loss: 0.005714273080229759
step: 390, loss: 0.05595754459500313
step: 400, loss: 0.010083075612783432
step: 410, loss: 0.01226492878049612
step: 420, loss: 0.029839396476745605
step: 430, loss: 0.035713307559490204
step: 440, loss: 0.016280533745884895
step: 450, loss: 0.025747722014784813
step: 460, loss: 0.0925385132431984
epoch 8: dev_f1=0.9898762654668166, f1=0.9798206278026906, best_f1=0.9854096520763187
step: 0, loss: 0.019107487052679062
step: 10, loss: 0.01374797709286213
step: 20, loss: 0.0030284852255135775
step: 30, loss: 0.030752800405025482
step: 40, loss: 0.0030489375349134207
step: 50, loss: 0.040129367262125015
step: 60, loss: 0.08949616551399231
step: 70, loss: 0.004350039176642895
step: 80, loss: 0.04188846796751022
step: 90, loss: 0.06860428303480148
step: 100, loss: 0.029801327735185623
step: 110, loss: 0.0190258901566267
step: 120, loss: 0.04710600525140762
step: 130, loss: 0.01337799895554781
step: 140, loss: 0.0007255530799739063
step: 150, loss: 0.037407197058200836
step: 160, loss: 2.1729327272623777e-05
step: 170, loss: 0.03627955541014671
step: 180, loss: 0.06661113351583481
step: 190, loss: 0.16295267641544342
step: 200, loss: 0.013046473264694214
step: 210, loss: 0.0013406638754531741
step: 220, loss: 0.1536768525838852
step: 230, loss: 0.061063382774591446
step: 240, loss: 0.030360234901309013
step: 250, loss: 0.11228431016206741
step: 260, loss: 0.0946943461894989
step: 270, loss: 0.044472675770521164
step: 280, loss: 0.00927699077874422
step: 290, loss: 0.010050632059574127
step: 300, loss: 0.08936290442943573
step: 310, loss: 0.07053390145301819
step: 320, loss: 0.13059884309768677
step: 330, loss: 0.04730934277176857
step: 340, loss: 0.08363000303506851
step: 350, loss: 0.05153511092066765
step: 360, loss: 0.09519056230783463
step: 370, loss: 0.14276689291000366
step: 380, loss: 0.0664532333612442
step: 390, loss: 0.010508791543543339
step: 400, loss: 0.013146971352398396
step: 410, loss: 0.11062241345643997
step: 420, loss: 0.05703864246606827
step: 430, loss: 0.00045475171646103263
step: 440, loss: 0.04327349737286568
step: 450, loss: 0.1007172167301178
step: 460, loss: 0.1169886365532875
epoch 9: dev_f1=0.9932584269662922, f1=0.9854748603351955, best_f1=0.9854096520763187
step: 0, loss: 0.008930237963795662
step: 10, loss: 0.028180742636322975
step: 20, loss: 0.00698171928524971
step: 30, loss: 0.013319958001375198
step: 40, loss: 0.055012259632349014
step: 50, loss: 0.025382649153470993
step: 60, loss: 0.019785627722740173
step: 70, loss: 0.0006147546810097992
step: 80, loss: 0.03337738290429115
step: 90, loss: 0.023394916206598282
step: 100, loss: 0.00012293642794247717
step: 110, loss: 0.039567362517118454
step: 120, loss: 0.0554291233420372
step: 130, loss: 0.005677304696291685
step: 140, loss: 0.028056301176548004
step: 150, loss: 0.022629905492067337
step: 160, loss: 0.04020809009671211
step: 170, loss: 0.04249262064695358
step: 180, loss: 0.002006670692935586
step: 190, loss: 0.09677359461784363
step: 200, loss: 0.023546310141682625
step: 210, loss: 0.08632765710353851
step: 220, loss: 0.012938505969941616
step: 230, loss: 0.11295727640390396
step: 240, loss: 0.05605687201023102
step: 250, loss: 0.05532660335302353
step: 260, loss: 0.020748602226376534
step: 270, loss: 0.03767215833067894
step: 280, loss: 0.010329101234674454
step: 290, loss: 5.623624747386202e-05
step: 300, loss: 0.01412403117865324
step: 310, loss: 0.0031632138416171074
step: 320, loss: 0.040855325758457184
step: 330, loss: 0.003275196999311447
step: 340, loss: 0.02731017768383026
step: 350, loss: 4.639528560801409e-05
step: 360, loss: 0.0031525057274848223
step: 370, loss: 0.028453417122364044
step: 380, loss: 0.029806535691022873
step: 390, loss: 0.02514950931072235
step: 400, loss: 0.0674004778265953
step: 410, loss: 0.06352101266384125
step: 420, loss: 0.018475953489542007
step: 430, loss: 0.012294222600758076
step: 440, loss: 0.0018272210145369172
step: 450, loss: 0.0018172384006902575
step: 460, loss: 0.030772190541028976
epoch 10: dev_f1=0.995505617977528, f1=0.9866071428571428, best_f1=0.9866071428571428
step: 0, loss: 0.008027788251638412
step: 10, loss: 0.007304610218852758
step: 20, loss: 0.04390294849872589
step: 30, loss: 0.07430711388587952
step: 40, loss: 0.01847744546830654
step: 50, loss: 0.02585199475288391
step: 60, loss: 0.04517468437552452
step: 70, loss: 0.03673967719078064
step: 80, loss: 0.0058806599117815495
step: 90, loss: 0.00033181594335474074
step: 100, loss: 0.025304678827524185
step: 110, loss: 0.016531942412257195
step: 120, loss: 0.007869448512792587
step: 130, loss: 0.05796006694436073
step: 140, loss: 0.036699939519166946
step: 150, loss: 0.005696524865925312
step: 160, loss: 0.06868790835142136
step: 170, loss: 0.016863826662302017
step: 180, loss: 0.052066680043935776
step: 190, loss: 0.0449901707470417
step: 200, loss: 0.017143329605460167
step: 210, loss: 0.00033447498572058976
step: 220, loss: 0.00014155637472867966
step: 230, loss: 0.022856757044792175
step: 240, loss: 0.001976004336029291
step: 250, loss: 0.13273005187511444
step: 260, loss: 0.007827331312000751
step: 270, loss: 0.0277286134660244
step: 280, loss: 0.08621520549058914
step: 290, loss: 0.10296329855918884
step: 300, loss: 0.02961934544146061
step: 310, loss: 0.10645567625761032
step: 320, loss: 0.04156523942947388
step: 330, loss: 0.0003761686384677887
step: 340, loss: 0.04216674342751503
step: 350, loss: 0.013294024392962456
step: 360, loss: 0.00653908122330904
step: 370, loss: 0.09048134833574295
step: 380, loss: 0.04905666783452034
step: 390, loss: 0.04330061003565788
step: 400, loss: 0.01952136866748333
step: 410, loss: 0.0037712096236646175
step: 420, loss: 0.025392349809408188
step: 430, loss: 0.03916553407907486
step: 440, loss: 0.10472162812948227
step: 450, loss: 0.042726095765829086
step: 460, loss: 0.1270967274904251
epoch 11: dev_f1=0.9921612541993281, f1=0.9821826280623607, best_f1=0.9866071428571428
step: 0, loss: 0.02058475837111473
step: 10, loss: 0.0035886429250240326
step: 20, loss: 0.0010985943954437971
step: 30, loss: 0.0010796361602842808
step: 40, loss: 0.05601146072149277
step: 50, loss: 0.023905226960778236
step: 60, loss: 0.02485952526330948
step: 70, loss: 0.04205870255827904
step: 80, loss: 0.025614747777581215
step: 90, loss: 0.01760808192193508
step: 100, loss: 0.016282938420772552
step: 110, loss: 0.00868164375424385
step: 120, loss: 0.021966319531202316
step: 130, loss: 0.0040645478293299675
step: 140, loss: 0.05711089074611664
step: 150, loss: 0.030696526169776917
step: 160, loss: 0.0033395274076610804
step: 170, loss: 0.022252282127738
step: 180, loss: 0.03480870649218559
step: 190, loss: 0.0001814448623917997
step: 200, loss: 0.04540149122476578
step: 210, loss: 0.025421032682061195
step: 220, loss: 6.722649413859472e-05
step: 230, loss: 0.11549357324838638
step: 240, loss: 0.027354350313544273
step: 250, loss: 0.11168698221445084
step: 260, loss: 0.07882070541381836
step: 270, loss: 0.06829865276813507
step: 280, loss: 0.02318132482469082
step: 290, loss: 0.00010253991786157712
step: 300, loss: 0.03126879781484604
step: 310, loss: 0.06841065734624863
step: 320, loss: 0.06997964531183243
step: 330, loss: 0.03609723970293999
step: 340, loss: 0.044303908944129944
step: 350, loss: 0.056833114475011826
step: 360, loss: 0.026753101497888565
step: 370, loss: 0.001598124741576612
step: 380, loss: 0.04844847321510315
step: 390, loss: 0.10041100531816483
step: 400, loss: 0.03032236546278
step: 410, loss: 0.0026029578875750303
step: 420, loss: 0.09957613050937653
step: 430, loss: 0.001074836589396
step: 440, loss: 0.006244166288524866
step: 450, loss: 0.05292988196015358
step: 460, loss: 0.03702973946928978
epoch 12: dev_f1=0.9943757030371203, f1=0.9832026875699889, best_f1=0.9866071428571428
step: 0, loss: 0.041239190846681595
step: 10, loss: 0.000505439646076411
step: 20, loss: 0.00482524000108242
step: 30, loss: 0.012543700635433197
step: 40, loss: 0.00022332822845783085
step: 50, loss: 0.012641381472349167
step: 60, loss: 0.02709403820335865
step: 70, loss: 0.004250471480190754
step: 80, loss: 0.07369478046894073
step: 90, loss: 0.02179858088493347
step: 100, loss: 0.00014952073979657143
step: 110, loss: 0.004500431474298239
step: 120, loss: 0.014269020408391953
step: 130, loss: 0.06015844643115997
step: 140, loss: 7.284211460500956e-05
step: 150, loss: 0.15930601954460144
step: 160, loss: 4.6413744712481275e-05
step: 170, loss: 0.002026465954259038
step: 180, loss: 0.02400934509932995
step: 190, loss: 0.03715263307094574
step: 200, loss: 0.001571431290358305
step: 210, loss: 0.002609715098515153
step: 220, loss: 0.016463503241539
step: 230, loss: 0.1577446162700653
step: 240, loss: 0.033324770629405975
step: 250, loss: 0.017159326002001762
step: 260, loss: 0.05726214498281479
step: 270, loss: 0.012850041501224041
step: 280, loss: 0.1463228464126587
step: 290, loss: 0.00030018718098290265
step: 300, loss: 0.03948482498526573
step: 310, loss: 0.0027720597572624683
step: 320, loss: 0.03668435662984848
step: 330, loss: 0.08818159997463226
step: 340, loss: 0.04458620399236679
step: 350, loss: 0.10846883058547974
step: 360, loss: 0.028292156755924225
step: 370, loss: 0.05359548702836037
step: 380, loss: 0.02447633258998394
step: 390, loss: 0.08572649210691452
step: 400, loss: 0.05633996054530144
step: 410, loss: 0.054860617965459824
step: 420, loss: 0.052101656794548035
step: 430, loss: 0.01852080598473549
step: 440, loss: 0.0065315356478095055
step: 450, loss: 8.451292524114251e-05
step: 460, loss: 0.0362422876060009
epoch 13: dev_f1=0.9909706546275394, f1=0.9785794813979707, best_f1=0.9866071428571428
step: 0, loss: 8.521329436916858e-05
step: 10, loss: 0.01983531378209591
step: 20, loss: 3.713144178618677e-05
step: 30, loss: 0.021890632808208466
step: 40, loss: 0.026651296764612198
step: 50, loss: 0.018117744475603104
step: 60, loss: 4.961191734764725e-05
step: 70, loss: 7.668377656955272e-05
step: 80, loss: 0.004996075294911861
step: 90, loss: 0.02952054888010025
step: 100, loss: 0.034363191574811935
step: 110, loss: 0.07262181490659714
step: 120, loss: 2.13566509046359e-05
step: 130, loss: 0.016474446281790733
step: 140, loss: 0.00012581708142533898
step: 150, loss: 0.03149954602122307
step: 160, loss: 0.00043933800770901144
step: 170, loss: 0.0014197637792676687
step: 180, loss: 8.731558045838028e-05
step: 190, loss: 0.03368965908885002
step: 200, loss: 5.351361323846504e-05
step: 210, loss: 0.011834326200187206
step: 220, loss: 0.038504499942064285
step: 230, loss: 0.03689347952604294
step: 240, loss: 0.016003375872969627
step: 250, loss: 0.05074943229556084
step: 260, loss: 0.0036799756344407797
step: 270, loss: 0.03779643028974533
step: 280, loss: 0.002763611963018775
step: 290, loss: 0.00028274787473492324
step: 300, loss: 0.024730922654271126
step: 310, loss: 0.051491688936948776
step: 320, loss: 0.04685930907726288
step: 330, loss: 0.0005377879133448005
step: 340, loss: 0.0018814346985891461
step: 350, loss: 0.002220455789938569
step: 360, loss: 0.07969152927398682
step: 370, loss: 0.01925687864422798
step: 380, loss: 0.0009390002815052867
step: 390, loss: 0.0002388373832218349
step: 400, loss: 0.019782982766628265
step: 410, loss: 0.023592639714479446
step: 420, loss: 0.03257333114743233
step: 430, loss: 0.0400584377348423
step: 440, loss: 0.012453391216695309
step: 450, loss: 0.08329764008522034
step: 460, loss: 0.041227713227272034
epoch 14: dev_f1=0.9921259842519685, f1=0.9820627802690582, best_f1=0.9866071428571428
step: 0, loss: 0.00011162715236423537
step: 10, loss: 0.007054702378809452
step: 20, loss: 0.008081696927547455
step: 30, loss: 0.024424737319350243
step: 40, loss: 0.0005726959207095206
step: 50, loss: 0.07041941583156586
step: 60, loss: 0.021334363147616386
step: 70, loss: 0.019026637077331543
step: 80, loss: 0.028059056028723717
step: 90, loss: 0.013493139296770096
step: 100, loss: 0.010112094692885876
step: 110, loss: 0.022406619042158127
step: 120, loss: 0.025673454627394676
step: 130, loss: 0.00014953398203942925
step: 140, loss: 0.028632614761590958
step: 150, loss: 0.04939362034201622
step: 160, loss: 0.01922484114766121
step: 170, loss: 0.03313764929771423
step: 180, loss: 0.0443025641143322
step: 190, loss: 3.456431659287773e-05
step: 200, loss: 0.05509655922651291
step: 210, loss: 0.014047604985535145
step: 220, loss: 0.00011059858661610633
step: 230, loss: 0.006017820909619331
step: 240, loss: 5.4591422667726874e-05
step: 250, loss: 0.0003683636605273932
step: 260, loss: 0.0002904387656599283
step: 270, loss: 0.01822950504720211
step: 280, loss: 0.03455729782581329
step: 290, loss: 0.001310903811827302
step: 300, loss: 0.013242698274552822
step: 310, loss: 6.131737609393895e-05
step: 320, loss: 0.026783501729369164
step: 330, loss: 0.014615627937018871
step: 340, loss: 0.00417717732489109
step: 350, loss: 0.00028436805587261915
step: 360, loss: 0.023198729380965233
step: 370, loss: 0.07881954312324524
step: 380, loss: 8.862472168402746e-05
step: 390, loss: 0.04708683490753174
step: 400, loss: 0.03991331532597542
step: 410, loss: 0.0011104781879112124
step: 420, loss: 0.0033886185847222805
step: 430, loss: 0.040864381939172745
step: 440, loss: 5.234843411017209e-05
step: 450, loss: 0.014983808621764183
step: 460, loss: 0.0159600917249918
epoch 15: dev_f1=0.9910313901345291, f1=0.9832026875699889, best_f1=0.9866071428571428
step: 0, loss: 9.348297317046672e-05
step: 10, loss: 0.00016118896019179374
step: 20, loss: 0.18367089331150055
step: 30, loss: 0.057902347296476364
step: 40, loss: 0.07806256413459778
step: 50, loss: 0.022614736109972
step: 60, loss: 0.041310518980026245
step: 70, loss: 9.112255793297663e-05
step: 80, loss: 0.04174193739891052
step: 90, loss: 4.1796069126576185e-05
step: 100, loss: 0.0004185956495348364
step: 110, loss: 0.0008918934618122876
step: 120, loss: 0.0011244089109823108
step: 130, loss: 0.04905875399708748
step: 140, loss: 0.0011423176620155573
step: 150, loss: 0.0736585184931755
step: 160, loss: 0.024498028680682182
step: 170, loss: 0.02462640404701233
step: 180, loss: 0.020641852170228958
step: 190, loss: 0.07335615158081055
step: 200, loss: 0.05585775524377823
step: 210, loss: 0.022107500582933426
step: 220, loss: 0.07815781980752945
step: 230, loss: 0.0460161417722702
step: 240, loss: 0.02009609527885914
step: 250, loss: 3.1404673791257665e-05
step: 260, loss: 8.076519588939846e-05
step: 270, loss: 0.02103446237742901
step: 280, loss: 0.0177934430539608
step: 290, loss: 9.970100654754788e-05
step: 300, loss: 0.00038017777842469513
step: 310, loss: 0.04354958236217499
step: 320, loss: 0.07248222827911377
step: 330, loss: 0.00010292346269125119
step: 340, loss: 0.0012731784954667091
step: 350, loss: 1.748246722854674e-05
step: 360, loss: 0.0005519616534002125
step: 370, loss: 0.042805422097444534
step: 380, loss: 7.704930612817407e-05
step: 390, loss: 0.0010354998521506786
step: 400, loss: 0.08943703770637512
step: 410, loss: 0.0663428083062172
step: 420, loss: 0.019327985122799873
step: 430, loss: 0.024127081036567688
step: 440, loss: 0.03248964250087738
step: 450, loss: 2.3330598196480423e-05
step: 460, loss: 0.024096008390188217
epoch 16: dev_f1=0.9910112359550561, f1=0.984304932735426, best_f1=0.9866071428571428
step: 0, loss: 0.023670554161071777
step: 10, loss: 0.0004775735142175108
step: 20, loss: 0.02062625251710415
step: 30, loss: 0.026981228962540627
step: 40, loss: 0.04055512696504593
step: 50, loss: 2.6541620172793046e-05
step: 60, loss: 0.008230669423937798
step: 70, loss: 0.0790298730134964
step: 80, loss: 0.00015097692084964365
step: 90, loss: 0.04132015258073807
step: 100, loss: 0.028053682297468185
step: 110, loss: 0.023736534640192986
step: 120, loss: 0.02025303989648819
step: 130, loss: 0.012816229835152626
step: 140, loss: 0.021306684240698814
step: 150, loss: 4.3105250369990245e-05
step: 160, loss: 2.947702341771219e-05
step: 170, loss: 0.07527098804712296
step: 180, loss: 0.021217823028564453
step: 190, loss: 0.04677949845790863
step: 200, loss: 0.03189642354846001
step: 210, loss: 0.05820556730031967
step: 220, loss: 0.045792125165462494
step: 230, loss: 7.447879033861682e-05
step: 240, loss: 0.015099975280463696
step: 250, loss: 0.0002487761958036572
step: 260, loss: 0.021499888971447945
step: 270, loss: 0.06496445834636688
step: 280, loss: 0.021664949133992195
step: 290, loss: 0.023854194208979607
step: 300, loss: 2.611657873785589e-05
step: 310, loss: 0.04482557997107506
step: 320, loss: 0.07693278789520264
step: 330, loss: 0.0001068371202563867
step: 340, loss: 0.0011701296316459775
step: 350, loss: 0.0010334317339584231
step: 360, loss: 0.00020096480147913098
step: 370, loss: 0.0003876969567500055
step: 380, loss: 0.00011296985758235678
step: 390, loss: 8.128562330966815e-05
step: 400, loss: 0.00011797252955147997
step: 410, loss: 0.00010020079935202375
step: 420, loss: 7.856480806367472e-05
step: 430, loss: 0.08304841071367264
step: 440, loss: 0.01927253045141697
step: 450, loss: 0.023807408288121223
step: 460, loss: 0.01924365945160389
epoch 17: dev_f1=0.9921436588103255, f1=0.9810055865921787, best_f1=0.9866071428571428
step: 0, loss: 0.00029142407584004104
step: 10, loss: 0.06839567422866821
step: 20, loss: 0.028045471757650375
step: 30, loss: 4.35893889516592e-05
step: 40, loss: 0.005629987455904484
step: 50, loss: 0.0003685980918817222
step: 60, loss: 0.022185806185007095
step: 70, loss: 0.010678994469344616
step: 80, loss: 7.322261080844328e-05
step: 90, loss: 0.039536818861961365
step: 100, loss: 0.04753261059522629
step: 110, loss: 0.01606087200343609
step: 120, loss: 3.9253951399587095e-05
step: 130, loss: 0.01439356803894043
step: 140, loss: 0.006719775032252073
step: 150, loss: 5.4480115068145096e-05
step: 160, loss: 0.00026528481976129115
step: 170, loss: 6.354048673529178e-05
step: 180, loss: 0.028511477634310722
step: 190, loss: 0.01945197395980358
step: 200, loss: 2.5225159333785996e-05
step: 210, loss: 0.02202889323234558
step: 220, loss: 0.03176884725689888
step: 230, loss: 0.06552357971668243
step: 240, loss: 5.7319488405482844e-05
step: 250, loss: 6.184908124851063e-05
step: 260, loss: 2.2220374376047403e-05
step: 270, loss: 0.045957937836647034
step: 280, loss: 0.02010258287191391
step: 290, loss: 0.038551900535821915
step: 300, loss: 0.000458278605947271
step: 310, loss: 0.016821779310703278
step: 320, loss: 0.03870396316051483
step: 330, loss: 0.023208482190966606
step: 340, loss: 0.03702894598245621
step: 350, loss: 0.022023173049092293
step: 360, loss: 0.019178487360477448
step: 370, loss: 0.02479141764342785
step: 380, loss: 3.3419761166442186e-05
step: 390, loss: 6.742206460330635e-05
step: 400, loss: 0.02119971625506878
step: 410, loss: 0.023110123351216316
step: 420, loss: 0.023877302184700966
step: 430, loss: 0.09147214889526367
step: 440, loss: 0.07302083820104599
step: 450, loss: 0.016076315194368362
step: 460, loss: 2.0317178496043198e-05
epoch 18: dev_f1=0.9932584269662922, f1=0.9820627802690582, best_f1=0.9866071428571428
step: 0, loss: 0.01914680004119873
step: 10, loss: 0.025094879791140556
step: 20, loss: 0.019912566989660263
step: 30, loss: 7.315664697671309e-05
step: 40, loss: 0.06569600850343704
step: 50, loss: 0.00016221587429754436
step: 60, loss: 0.028460834175348282
step: 70, loss: 0.03318287059664726
step: 80, loss: 0.00029414540040306747
step: 90, loss: 0.0486864298582077
step: 100, loss: 0.00029931453173048794
step: 110, loss: 0.06496221572160721
step: 120, loss: 6.766556180082262e-05
step: 130, loss: 0.00012077977589797229
step: 140, loss: 0.059480007737874985
step: 150, loss: 2.397766729700379e-05
step: 160, loss: 0.018452990800142288
step: 170, loss: 4.033014556625858e-05
step: 180, loss: 0.07061195373535156
step: 190, loss: 3.56856471626088e-05
step: 200, loss: 0.06686622649431229
step: 210, loss: 0.02435535006225109
step: 220, loss: 0.02128583937883377
step: 230, loss: 0.000335700751747936
step: 240, loss: 0.023839881643652916
step: 250, loss: 0.022991525009274483
step: 260, loss: 7.920684583950788e-05
step: 270, loss: 0.08271200954914093
step: 280, loss: 0.0403844378888607
step: 290, loss: 7.408874080283567e-05
step: 300, loss: 0.0010673124343156815
step: 310, loss: 0.023440757766366005
step: 320, loss: 0.05224001407623291
step: 330, loss: 0.0002245332725578919
step: 340, loss: 0.007477252744138241
step: 350, loss: 0.01682252623140812
step: 360, loss: 0.00042007467709481716
step: 370, loss: 0.021616725251078606
step: 380, loss: 0.02345941588282585
step: 390, loss: 0.019130069762468338
step: 400, loss: 0.015001139603555202
step: 410, loss: 0.023250170052051544
step: 420, loss: 0.00031856095301918685
step: 430, loss: 0.055384956300258636
step: 440, loss: 0.0001013303262880072
step: 450, loss: 9.535389835946262e-05
step: 460, loss: 0.0002554826787672937
epoch 19: dev_f1=0.9921436588103255, f1=0.9832026875699889, best_f1=0.9866071428571428
step: 0, loss: 0.0001663084258325398
step: 10, loss: 0.022627463564276695
step: 20, loss: 0.018241876736283302
step: 30, loss: 4.5546395995188504e-05
step: 40, loss: 0.023160293698310852
step: 50, loss: 0.0002703358477447182
step: 60, loss: 0.00023439861251972616
step: 70, loss: 7.2774630098138e-05
step: 80, loss: 0.08255284279584885
step: 90, loss: 0.0006201779469847679
step: 100, loss: 0.03957138955593109
step: 110, loss: 7.096022454788908e-05
step: 120, loss: 0.04284176602959633
step: 130, loss: 0.025185110047459602
step: 140, loss: 2.2938911570236087e-05
step: 150, loss: 0.01589767448604107
step: 160, loss: 0.0706930086016655
step: 170, loss: 0.05184560269117355
step: 180, loss: 3.675733751151711e-05
step: 190, loss: 0.00039036961970850825
step: 200, loss: 0.018157396465539932
step: 210, loss: 0.04096827283501625
step: 220, loss: 6.195178866619244e-05
step: 230, loss: 0.05341134965419769
step: 240, loss: 2.5684608772280626e-05
step: 250, loss: 0.02419605478644371
step: 260, loss: 0.03354177623987198
step: 270, loss: 9.350157051812857e-05
step: 280, loss: 0.0009878993732854724
step: 290, loss: 0.06125232204794884
step: 300, loss: 0.10369598120450974
step: 310, loss: 0.01957213133573532
step: 320, loss: 0.045543160289525986
step: 330, loss: 0.042782630771398544
step: 340, loss: 0.036801014095544815
step: 350, loss: 0.04366293177008629
step: 360, loss: 0.01782572828233242
step: 370, loss: 0.06330729275941849
step: 380, loss: 0.04136013239622116
step: 390, loss: 1.8361530237598345e-05
step: 400, loss: 0.02246568165719509
step: 410, loss: 0.01981404982507229
step: 420, loss: 0.02360406517982483
step: 430, loss: 7.173234189394861e-05
step: 440, loss: 9.840075654210523e-05
step: 450, loss: 0.04246393218636513
step: 460, loss: 0.04549013450741768
epoch 20: dev_f1=0.9932279909706545, f1=0.9819413092550789, best_f1=0.9866071428571428
