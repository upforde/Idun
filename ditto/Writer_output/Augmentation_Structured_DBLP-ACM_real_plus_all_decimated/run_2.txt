cuda
Device: cuda
step: 0, loss: 0.7492809295654297
step: 10, loss: 0.5600520372390747
step: 20, loss: 0.3202907145023346
step: 30, loss: 0.6131897568702698
step: 40, loss: 0.5018847584724426
step: 50, loss: 0.4022879898548126
step: 60, loss: 0.19649140536785126
step: 70, loss: 0.20015646517276764
step: 80, loss: 0.11284606158733368
step: 90, loss: 0.2586449086666107
step: 100, loss: 0.08741629868745804
step: 110, loss: 0.11521200090646744
step: 120, loss: 0.10335854440927505
step: 130, loss: 0.09379533678293228
step: 140, loss: 0.11461026221513748
step: 150, loss: 0.04695575684309006
step: 160, loss: 0.14144456386566162
step: 170, loss: 0.03640914708375931
step: 180, loss: 0.04043865203857422
step: 190, loss: 0.210506871342659
step: 200, loss: 0.05753851309418678
step: 210, loss: 0.12626436352729797
step: 220, loss: 0.060202233493328094
step: 230, loss: 0.17277619242668152
step: 240, loss: 0.10004126280546188
step: 250, loss: 0.09588488936424255
step: 260, loss: 0.015056687407195568
step: 270, loss: 0.09479323774576187
step: 280, loss: 0.12359368056058884
step: 290, loss: 0.02196645364165306
step: 300, loss: 0.07652311027050018
step: 310, loss: 0.02411654032766819
step: 320, loss: 0.021278152242302895
step: 330, loss: 0.16095545887947083
step: 340, loss: 0.1255757212638855
step: 350, loss: 0.11496228724718094
step: 360, loss: 0.12966594099998474
step: 370, loss: 0.022095348685979843
step: 380, loss: 0.2085518091917038
step: 390, loss: 0.09332308918237686
step: 400, loss: 0.11053237318992615
step: 410, loss: 0.05560388043522835
step: 420, loss: 0.04528716951608658
step: 430, loss: 0.12354044616222382
step: 440, loss: 0.0525648407638073
step: 450, loss: 0.10942056775093079
step: 460, loss: 0.04650413617491722
epoch 1: dev_f1=0.9820224719101124, f1=0.976324689966178, best_f1=0.976324689966178
step: 0, loss: 0.20155571401119232
step: 10, loss: 0.046747203916311264
step: 20, loss: 0.21406027674674988
step: 30, loss: 0.1993647664785385
step: 40, loss: 0.022675614804029465
step: 50, loss: 0.026500962674617767
step: 60, loss: 0.07362770289182663
step: 70, loss: 0.10364744812250137
step: 80, loss: 0.01712668687105179
step: 90, loss: 0.10001284629106522
step: 100, loss: 0.14467830955982208
step: 110, loss: 0.006675576791167259
step: 120, loss: 0.02432720735669136
step: 130, loss: 0.03759118914604187
step: 140, loss: 0.028841780498623848
step: 150, loss: 0.013270110823214054
step: 160, loss: 0.15236711502075195
step: 170, loss: 0.0937948226928711
step: 180, loss: 0.1267509013414383
step: 190, loss: 0.09414002299308777
step: 200, loss: 0.015793511644005775
step: 210, loss: 0.22841519117355347
step: 220, loss: 0.03184369206428528
step: 230, loss: 0.011324559338390827
step: 240, loss: 0.00907804537564516
step: 250, loss: 0.10456734895706177
step: 260, loss: 0.055231694132089615
step: 270, loss: 0.1250460296869278
step: 280, loss: 0.004504166077822447
step: 290, loss: 0.004778577946126461
step: 300, loss: 0.051030416041612625
step: 310, loss: 0.1213170737028122
step: 320, loss: 0.09108269214630127
step: 330, loss: 0.07141925394535065
step: 340, loss: 0.10101745277643204
step: 350, loss: 0.08543521165847778
step: 360, loss: 0.01889285072684288
step: 370, loss: 0.010123243555426598
step: 380, loss: 0.002509391400963068
step: 390, loss: 0.10648277401924133
step: 400, loss: 0.02187253162264824
step: 410, loss: 0.13520613312721252
step: 420, loss: 0.1651313155889511
step: 430, loss: 0.013430466875433922
step: 440, loss: 0.131839781999588
step: 450, loss: 0.08585314452648163
step: 460, loss: 0.06169283390045166
epoch 2: dev_f1=0.9887640449438202, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.023506755009293556
step: 10, loss: 0.14066815376281738
step: 20, loss: 0.18142950534820557
step: 30, loss: 0.08087165653705597
step: 40, loss: 0.000658330216538161
step: 50, loss: 0.017613006755709648
step: 60, loss: 0.07186450809240341
step: 70, loss: 0.1056554913520813
step: 80, loss: 0.07399886846542358
step: 90, loss: 0.007746363524347544
step: 100, loss: 0.2427007406949997
step: 110, loss: 0.04603512957692146
step: 120, loss: 0.07740369439125061
step: 130, loss: 0.00900404341518879
step: 140, loss: 0.012940958142280579
step: 150, loss: 0.021952606737613678
step: 160, loss: 0.12337658554315567
step: 170, loss: 0.08153215050697327
step: 180, loss: 0.01229368057101965
step: 190, loss: 0.012925175949931145
step: 200, loss: 0.07895675301551819
step: 210, loss: 0.16323676705360413
step: 220, loss: 0.14449909329414368
step: 230, loss: 0.010347912088036537
step: 240, loss: 0.11403056234121323
step: 250, loss: 0.10855185240507126
step: 260, loss: 0.07033474743366241
step: 270, loss: 0.004915809724479914
step: 280, loss: 0.0074738264083862305
step: 290, loss: 0.01704728975892067
step: 300, loss: 0.009445620700716972
step: 310, loss: 0.02684289589524269
step: 320, loss: 0.09251818805932999
step: 330, loss: 0.10656426846981049
step: 340, loss: 0.030360646545886993
step: 350, loss: 0.08143212646245956
step: 360, loss: 0.006251308135688305
step: 370, loss: 0.10071482509374619
step: 380, loss: 0.018619826063513756
step: 390, loss: 0.015862198546528816
step: 400, loss: 0.022932587191462517
step: 410, loss: 0.06391216069459915
step: 420, loss: 0.04213128983974457
step: 430, loss: 0.050765953958034515
step: 440, loss: 0.022501062601804733
step: 450, loss: 0.13322605192661285
step: 460, loss: 0.0811033844947815
epoch 3: dev_f1=0.9898762654668166, f1=0.9898762654668166, best_f1=0.9898762654668166
step: 0, loss: 0.010498753748834133
step: 10, loss: 0.07503000646829605
step: 20, loss: 0.07162740081548691
step: 30, loss: 0.056657448410987854
step: 40, loss: 0.013329402543604374
step: 50, loss: 0.1401263326406479
step: 60, loss: 0.17381544411182404
step: 70, loss: 0.024782972410321236
step: 80, loss: 0.059471894055604935
step: 90, loss: 0.06157510727643967
step: 100, loss: 0.12313203513622284
step: 110, loss: 0.1783229112625122
step: 120, loss: 0.04085564985871315
step: 130, loss: 0.045181211084127426
step: 140, loss: 0.16330097615718842
step: 150, loss: 0.15419290959835052
step: 160, loss: 0.1076899990439415
step: 170, loss: 0.022571707144379616
step: 180, loss: 0.012830153107643127
step: 190, loss: 0.012885172851383686
step: 200, loss: 0.08692502975463867
step: 210, loss: 0.029416972771286964
step: 220, loss: 0.13257159292697906
step: 230, loss: 0.005684257484972477
step: 240, loss: 0.0023153789807111025
step: 250, loss: 0.024855220690369606
step: 260, loss: 0.030168578028678894
step: 270, loss: 0.0845249593257904
step: 280, loss: 0.03435405343770981
step: 290, loss: 0.1297665387392044
step: 300, loss: 0.13539232313632965
step: 310, loss: 0.136296808719635
step: 320, loss: 0.008072142489254475
step: 330, loss: 0.004790713079273701
step: 340, loss: 0.05904761329293251
step: 350, loss: 0.0724501982331276
step: 360, loss: 0.005862665828317404
step: 370, loss: 0.08098243176937103
step: 380, loss: 0.05820157378911972
step: 390, loss: 0.027588699012994766
step: 400, loss: 0.024813799187541008
step: 410, loss: 0.11156868934631348
step: 420, loss: 0.08740273118019104
step: 430, loss: 0.12056317925453186
step: 440, loss: 0.14595547318458557
step: 450, loss: 0.019623545929789543
step: 460, loss: 0.14831238985061646
epoch 4: dev_f1=0.9921259842519685, f1=0.9853107344632768, best_f1=0.9853107344632768
step: 0, loss: 0.006428052671253681
step: 10, loss: 0.04645416513085365
step: 20, loss: 0.024767447263002396
step: 30, loss: 0.016777031123638153
step: 40, loss: 0.055737774819135666
step: 50, loss: 0.06657788157463074
step: 60, loss: 0.04587354138493538
step: 70, loss: 0.007303315680474043
step: 80, loss: 0.05729487165808678
step: 90, loss: 0.02824047952890396
step: 100, loss: 0.0030748590361326933
step: 110, loss: 0.01139879785478115
step: 120, loss: 0.03221980482339859
step: 130, loss: 0.02907445840537548
step: 140, loss: 0.08086933195590973
step: 150, loss: 0.008102779276669025
step: 160, loss: 0.05072009935975075
step: 170, loss: 0.020179256796836853
step: 180, loss: 0.013333805836737156
step: 190, loss: 0.09507337212562561
step: 200, loss: 0.013321205042302608
step: 210, loss: 0.168939009308815
step: 220, loss: 0.021579936146736145
step: 230, loss: 0.07108120620250702
step: 240, loss: 0.05945539474487305
step: 250, loss: 0.005987588316202164
step: 260, loss: 0.07304252684116364
step: 270, loss: 0.00015677252667956054
step: 280, loss: 0.022559896111488342
step: 290, loss: 0.01530924066901207
step: 300, loss: 0.13520830869674683
step: 310, loss: 0.08010542392730713
step: 320, loss: 0.03505010902881622
step: 330, loss: 0.009725368581712246
step: 340, loss: 0.2693965435028076
step: 350, loss: 0.016124282032251358
step: 360, loss: 0.05394571274518967
step: 370, loss: 0.048403214663267136
step: 380, loss: 0.00011305790394544601
step: 390, loss: 0.1959911435842514
step: 400, loss: 0.01512023713439703
step: 410, loss: 0.017521418631076813
step: 420, loss: 0.07285836338996887
step: 430, loss: 0.03518544137477875
step: 440, loss: 0.1563916802406311
step: 450, loss: 0.04017899930477142
step: 460, loss: 0.11283116042613983
epoch 5: dev_f1=0.9932735426008968, f1=0.983277591973244, best_f1=0.983277591973244
step: 0, loss: 0.02385193109512329
step: 10, loss: 0.1129499301314354
step: 20, loss: 0.07540703564882278
step: 30, loss: 0.05826558172702789
step: 40, loss: 0.013952583074569702
step: 50, loss: 0.02914080210030079
step: 60, loss: 0.081743523478508
step: 70, loss: 0.261043518781662
step: 80, loss: 0.057055532932281494
step: 90, loss: 0.05114176496863365
step: 100, loss: 0.22355693578720093
step: 110, loss: 0.11711325496435165
step: 120, loss: 0.12894728779792786
step: 130, loss: 0.022233441472053528
step: 140, loss: 0.013594867661595345
step: 150, loss: 0.039163049310445786
step: 160, loss: 0.08519656956195831
step: 170, loss: 0.06863728910684586
step: 180, loss: 0.06261824816465378
step: 190, loss: 0.07510580122470856
step: 200, loss: 0.04726488143205643
step: 210, loss: 0.008529809303581715
step: 220, loss: 0.06643383949995041
step: 230, loss: 0.020925799384713173
step: 240, loss: 0.07350190728902817
step: 250, loss: 0.06871023029088974
step: 260, loss: 0.04753332585096359
step: 270, loss: 0.05979231745004654
step: 280, loss: 0.027516210451722145
step: 290, loss: 0.007752628531306982
step: 300, loss: 0.019150735810399055
step: 310, loss: 0.02490570954978466
step: 320, loss: 0.07573069632053375
step: 330, loss: 0.06644183397293091
step: 340, loss: 0.011632805690169334
step: 350, loss: 0.014225211925804615
step: 360, loss: 0.11124501377344131
step: 370, loss: 0.05281775817275047
step: 380, loss: 0.09515634179115295
step: 390, loss: 0.026702292263507843
step: 400, loss: 0.05010151118040085
step: 410, loss: 0.07093065977096558
step: 420, loss: 0.05534737929701805
step: 430, loss: 0.020731955766677856
step: 440, loss: 0.029162302613258362
step: 450, loss: 0.008379743434488773
step: 460, loss: 0.02591388113796711
epoch 6: dev_f1=0.9887640449438202, f1=0.9854096520763187, best_f1=0.983277591973244
step: 0, loss: 0.05038044601678848
step: 10, loss: 0.010737921111285686
step: 20, loss: 0.09928667545318604
step: 30, loss: 0.0721680223941803
step: 40, loss: 0.02863886207342148
step: 50, loss: 0.010752363130450249
step: 60, loss: 0.15882007777690887
step: 70, loss: 0.009644421748816967
step: 80, loss: 0.09749449789524078
step: 90, loss: 0.039040472358465195
step: 100, loss: 0.024948008358478546
step: 110, loss: 0.0049073584377765656
step: 120, loss: 0.049575526267290115
step: 130, loss: 0.015531366690993309
step: 140, loss: 0.08368854224681854
step: 150, loss: 0.05220982804894447
step: 160, loss: 0.0978848934173584
step: 170, loss: 0.07211504131555557
step: 180, loss: 0.015699315816164017
step: 190, loss: 0.06298636645078659
step: 200, loss: 0.024446316063404083
step: 210, loss: 0.0748613104224205
step: 220, loss: 0.022838514298200607
step: 230, loss: 0.011823349632322788
step: 240, loss: 0.07220339775085449
step: 250, loss: 0.06411615759134293
step: 260, loss: 0.11558609455823898
step: 270, loss: 0.13446158170700073
step: 280, loss: 0.007748442701995373
step: 290, loss: 0.0888756513595581
step: 300, loss: 0.01061769388616085
step: 310, loss: 0.08150037378072739
step: 320, loss: 0.2582523822784424
step: 330, loss: 0.08269476890563965
step: 340, loss: 0.031205972656607628
step: 350, loss: 0.019450461491942406
step: 360, loss: 0.013805396854877472
step: 370, loss: 0.018234167248010635
step: 380, loss: 0.02994464710354805
step: 390, loss: 0.06465621292591095
step: 400, loss: 0.0407257154583931
step: 410, loss: 0.01384679600596428
step: 420, loss: 0.07543811947107315
step: 430, loss: 0.010699241422116756
step: 440, loss: 0.01843857765197754
step: 450, loss: 0.0015825071604922414
step: 460, loss: 0.07929734885692596
epoch 7: dev_f1=0.9920903954802259, f1=0.983050847457627, best_f1=0.983277591973244
step: 0, loss: 0.06232576072216034
step: 10, loss: 0.01563403010368347
step: 20, loss: 0.007444059941917658
step: 30, loss: 0.016650566831231117
step: 40, loss: 0.009594145230948925
step: 50, loss: 0.028534965589642525
step: 60, loss: 0.011320186778903008
step: 70, loss: 0.01797310635447502
step: 80, loss: 0.04888197034597397
step: 90, loss: 0.005725933704525232
step: 100, loss: 0.022747576236724854
step: 110, loss: 0.006018931046128273
step: 120, loss: 0.1581123322248459
step: 130, loss: 0.015501930378377438
step: 140, loss: 0.08221723139286041
step: 150, loss: 0.019488142803311348
step: 160, loss: 0.00911166612058878
step: 170, loss: 0.052424412220716476
step: 180, loss: 0.02614612877368927
step: 190, loss: 0.08499381691217422
step: 200, loss: 0.023102136328816414
step: 210, loss: 0.061368465423583984
step: 220, loss: 0.022888552397489548
step: 230, loss: 0.0691046267747879
step: 240, loss: 0.08381989598274231
step: 250, loss: 0.00970747321844101
step: 260, loss: 0.004873710218816996
step: 270, loss: 0.002730027539655566
step: 280, loss: 0.07401300966739655
step: 290, loss: 0.08299539983272552
step: 300, loss: 0.0880601555109024
step: 310, loss: 0.023359443992376328
step: 320, loss: 0.05845049023628235
step: 330, loss: 0.042275600135326385
step: 340, loss: 0.022684426978230476
step: 350, loss: 0.0016704510198906064
step: 360, loss: 0.10984344780445099
step: 370, loss: 0.012242959812283516
step: 380, loss: 0.11919140815734863
step: 390, loss: 0.1372767686843872
step: 400, loss: 0.0678677186369896
step: 410, loss: 0.06283210217952728
step: 420, loss: 0.05970213562250137
step: 430, loss: 0.002699363511055708
step: 440, loss: 0.02342401258647442
step: 450, loss: 0.14542773365974426
step: 460, loss: 0.07832739502191544
epoch 8: dev_f1=0.9921612541993281, f1=0.9810479375696767, best_f1=0.983277591973244
step: 0, loss: 0.07901253551244736
step: 10, loss: 0.05553528293967247
step: 20, loss: 0.02550628036260605
step: 30, loss: 0.07244821637868881
step: 40, loss: 0.01522897183895111
step: 50, loss: 0.008438637480139732
step: 60, loss: 0.0821249857544899
step: 70, loss: 0.10697057843208313
step: 80, loss: 0.08693882822990417
step: 90, loss: 0.0471775084733963
step: 100, loss: 0.13269442319869995
step: 110, loss: 0.06589233130216599
step: 120, loss: 0.013242470100522041
step: 130, loss: 0.0378141850233078
step: 140, loss: 0.021010123193264008
step: 150, loss: 0.00959061086177826
step: 160, loss: 0.10115756839513779
step: 170, loss: 0.029720069840550423
step: 180, loss: 0.028204122558236122
step: 190, loss: 0.027659818530082703
step: 200, loss: 0.08301049470901489
step: 210, loss: 0.007484629284590483
step: 220, loss: 0.024529583752155304
step: 230, loss: 0.0037927969824522734
step: 240, loss: 0.045483071357011795
step: 250, loss: 0.008277127519249916
step: 260, loss: 0.03858688101172447
step: 270, loss: 0.015127566643059254
step: 280, loss: 0.012524574995040894
step: 290, loss: 0.039039336144924164
step: 300, loss: 0.1151561588048935
step: 310, loss: 0.025063779205083847
step: 320, loss: 0.012225762940943241
step: 330, loss: 0.13675732910633087
step: 340, loss: 0.07039540261030197
step: 350, loss: 0.012930570170283318
step: 360, loss: 0.022267164662480354
step: 370, loss: 0.05695655941963196
step: 380, loss: 0.045969463884830475
step: 390, loss: 0.04319985955953598
step: 400, loss: 0.0075794002041220665
step: 410, loss: 0.03274133801460266
step: 420, loss: 0.0035324953496456146
step: 430, loss: 0.0393800251185894
step: 440, loss: 0.06642265617847443
step: 450, loss: 0.07082982361316681
step: 460, loss: 0.007386470213532448
epoch 9: dev_f1=0.9943630214205187, f1=0.9853768278965129, best_f1=0.9853768278965129
step: 0, loss: 0.006877474021166563
step: 10, loss: 0.042092837393283844
step: 20, loss: 0.275201678276062
step: 30, loss: 0.00454364437609911
step: 40, loss: 0.03170065954327583
step: 50, loss: 0.022989533841609955
step: 60, loss: 0.015086961910128593
step: 70, loss: 0.10244698077440262
step: 80, loss: 4.9551104893907905e-05
step: 90, loss: 0.04922104254364967
step: 100, loss: 0.005640905350446701
step: 110, loss: 0.001438262639567256
step: 120, loss: 0.010010603815317154
step: 130, loss: 0.07189498096704483
step: 140, loss: 0.08482557535171509
step: 150, loss: 0.003776427824050188
step: 160, loss: 0.0037978675682097673
step: 170, loss: 0.008019700646400452
step: 180, loss: 0.03084728494286537
step: 190, loss: 0.005539417266845703
step: 200, loss: 0.00547052314504981
step: 210, loss: 0.008805639110505581
step: 220, loss: 0.03132890164852142
step: 230, loss: 0.04708588123321533
step: 240, loss: 0.00948941707611084
step: 250, loss: 0.037083644419908524
step: 260, loss: 0.04944589361548424
step: 270, loss: 0.0024223073851317167
step: 280, loss: 0.0034473291598260403
step: 290, loss: 0.005018285010010004
step: 300, loss: 0.15750835835933685
step: 310, loss: 0.00391515763476491
step: 320, loss: 0.08938556909561157
step: 330, loss: 0.006381531711667776
step: 340, loss: 0.04344881325960159
step: 350, loss: 0.03288321942090988
step: 360, loss: 0.014875361695885658
step: 370, loss: 0.045533448457717896
step: 380, loss: 0.07168446481227875
step: 390, loss: 0.08412191271781921
step: 400, loss: 0.1956017017364502
step: 410, loss: 0.054614465683698654
step: 420, loss: 0.07358090579509735
step: 430, loss: 0.004964793566614389
step: 440, loss: 0.04328523576259613
step: 450, loss: 0.0034825738985091448
step: 460, loss: 0.007849887944757938
epoch 10: dev_f1=0.9932279909706545, f1=0.9831271091113611, best_f1=0.9853768278965129
step: 0, loss: 0.011580223217606544
step: 10, loss: 0.03691587224602699
step: 20, loss: 0.01118379458785057
step: 30, loss: 0.0721442773938179
step: 40, loss: 0.005186284426599741
step: 50, loss: 0.061394982039928436
step: 60, loss: 0.017508860677480698
step: 70, loss: 0.0007947880076244473
step: 80, loss: 0.060491956770420074
step: 90, loss: 0.04486477002501488
step: 100, loss: 0.02739311009645462
step: 110, loss: 0.06495242565870285
step: 120, loss: 0.0022344139870256186
step: 130, loss: 0.09306725859642029
step: 140, loss: 0.06625833362340927
step: 150, loss: 0.06715747714042664
step: 160, loss: 0.024368278682231903
step: 170, loss: 0.03479347005486488
step: 180, loss: 0.02410764992237091
step: 190, loss: 0.010645505040884018
step: 200, loss: 0.013601874932646751
step: 210, loss: 0.07565931230783463
step: 220, loss: 0.011719293892383575
step: 230, loss: 0.10719600319862366
step: 240, loss: 0.0018531939713284373
step: 250, loss: 0.004642082843929529
step: 260, loss: 0.04930693656206131
step: 270, loss: 0.06783422082662582
step: 280, loss: 0.028432931751012802
step: 290, loss: 0.006651152856647968
step: 300, loss: 0.02448302134871483
step: 310, loss: 0.02121753618121147
step: 320, loss: 0.03903500735759735
step: 330, loss: 0.03524484112858772
step: 340, loss: 0.043935880064964294
step: 350, loss: 0.021618811413645744
step: 360, loss: 0.01389857567846775
step: 370, loss: 0.09973893314599991
step: 380, loss: 3.830064815701917e-05
step: 390, loss: 0.1337694525718689
step: 400, loss: 0.026536092162132263
step: 410, loss: 0.029694484546780586
step: 420, loss: 0.10455859452486038
step: 430, loss: 6.115573341958225e-05
step: 440, loss: 0.05994319170713425
step: 450, loss: 0.05596005916595459
step: 460, loss: 0.001495577860623598
epoch 11: dev_f1=0.9932735426008968, f1=0.9854423292273236, best_f1=0.9853768278965129
step: 0, loss: 0.00421478133648634
step: 10, loss: 0.00015127527876757085
step: 20, loss: 0.04096759483218193
step: 30, loss: 0.0013988077407702804
step: 40, loss: 0.020743628963828087
step: 50, loss: 0.022834699600934982
step: 60, loss: 0.030153417959809303
step: 70, loss: 0.06993035227060318
step: 80, loss: 0.027458658441901207
step: 90, loss: 0.14317040145397186
step: 100, loss: 0.03372286260128021
step: 110, loss: 0.053862981498241425
step: 120, loss: 0.04394138976931572
step: 130, loss: 0.011657636612653732
step: 140, loss: 0.0006884323665872216
step: 150, loss: 0.00039186564390547574
step: 160, loss: 0.05877555161714554
step: 170, loss: 0.0011995251988992095
step: 180, loss: 0.02788136526942253
step: 190, loss: 0.005165481939911842
step: 200, loss: 0.02213432267308235
step: 210, loss: 0.005197084508836269
step: 220, loss: 0.018600521609187126
step: 230, loss: 0.022701863199472427
step: 240, loss: 7.970167644089088e-05
step: 250, loss: 0.01301946584135294
step: 260, loss: 0.0021948409266769886
step: 270, loss: 0.015791956335306168
step: 280, loss: 0.0005084357690066099
step: 290, loss: 0.05128009617328644
step: 300, loss: 0.08276446163654327
step: 310, loss: 0.02551674284040928
step: 320, loss: 0.036102574318647385
step: 330, loss: 0.08014751225709915
step: 340, loss: 0.07216010242700577
step: 350, loss: 0.03969741612672806
step: 360, loss: 0.07181785255670547
step: 370, loss: 0.02818443812429905
step: 380, loss: 0.00033259307383559644
step: 390, loss: 0.07060901820659637
step: 400, loss: 0.12076100707054138
step: 410, loss: 0.11048269271850586
step: 420, loss: 0.01927163638174534
step: 430, loss: 0.018200306221842766
step: 440, loss: 0.1203693300485611
step: 450, loss: 0.03175068646669388
step: 460, loss: 0.02478973940014839
epoch 12: dev_f1=0.995505617977528, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.008111371658742428
step: 10, loss: 0.008540080860257149
step: 20, loss: 0.022682921960949898
step: 30, loss: 0.01950865052640438
step: 40, loss: 0.0032648409251123667
step: 50, loss: 0.0097214849665761
step: 60, loss: 0.0022455439902842045
step: 70, loss: 0.016810890287160873
step: 80, loss: 0.0012221707729622722
step: 90, loss: 0.01960483007133007
step: 100, loss: 0.014961490407586098
step: 110, loss: 0.032218292355537415
step: 120, loss: 0.004350217059254646
step: 130, loss: 0.0003836460819002241
step: 140, loss: 0.02717783860862255
step: 150, loss: 0.0013441385235637426
step: 160, loss: 0.0681130588054657
step: 170, loss: 0.015780694782733917
step: 180, loss: 0.00014841320808045566
step: 190, loss: 0.0002289053372805938
step: 200, loss: 0.04411902651190758
step: 210, loss: 0.003776132594794035
step: 220, loss: 0.02674802951514721
step: 230, loss: 0.02280186116695404
step: 240, loss: 0.04779450222849846
step: 250, loss: 0.01770133711397648
step: 260, loss: 0.2122836709022522
step: 270, loss: 0.01920073665678501
step: 280, loss: 0.04394450783729553
step: 290, loss: 0.05992778763175011
step: 300, loss: 4.3586835090536624e-05
step: 310, loss: 0.037911951541900635
step: 320, loss: 3.475571793387644e-05
step: 330, loss: 0.06360539048910141
step: 340, loss: 0.027285808697342873
step: 350, loss: 0.016889894381165504
step: 360, loss: 0.0024462295696139336
step: 370, loss: 0.0033078202977776527
step: 380, loss: 0.0015475110849365592
step: 390, loss: 0.10218728333711624
step: 400, loss: 0.020326124504208565
step: 410, loss: 0.016220008954405785
step: 420, loss: 0.12503749132156372
step: 430, loss: 0.0982830598950386
step: 440, loss: 0.052763622254133224
step: 450, loss: 0.005743862595409155
step: 460, loss: 0.021594101563096046
epoch 13: dev_f1=0.9910112359550561, f1=0.9832026875699889, best_f1=0.9854096520763187
step: 0, loss: 0.015617318451404572
step: 10, loss: 0.028554407879710197
step: 20, loss: 9.97386232484132e-05
step: 30, loss: 0.04266439378261566
step: 40, loss: 0.0005747310351580381
step: 50, loss: 0.020201444625854492
step: 60, loss: 0.026522770524024963
step: 70, loss: 0.08931103348731995
step: 80, loss: 0.031901873648166656
step: 90, loss: 0.11774240434169769
step: 100, loss: 5.4111264034872875e-05
step: 110, loss: 0.05068477615714073
step: 120, loss: 0.00465572252869606
step: 130, loss: 0.029392067342996597
step: 140, loss: 0.06387878954410553
step: 150, loss: 0.017909903079271317
step: 160, loss: 0.0001665323943598196
step: 170, loss: 0.00025426491629332304
step: 180, loss: 0.025365328416228294
step: 190, loss: 0.04975767433643341
step: 200, loss: 0.0002624888438731432
step: 210, loss: 0.021606098860502243
step: 220, loss: 0.0018853363581001759
step: 230, loss: 0.03619842231273651
step: 240, loss: 0.00018286920385435224
step: 250, loss: 0.030764449387788773
step: 260, loss: 0.010856634005904198
step: 270, loss: 4.774682020070031e-05
step: 280, loss: 0.023480607196688652
step: 290, loss: 0.0022186494898051023
step: 300, loss: 0.06510267406702042
step: 310, loss: 0.020926859229803085
step: 320, loss: 0.036660317331552505
step: 330, loss: 0.024839552119374275
step: 340, loss: 0.0101091880351305
step: 350, loss: 0.05940564349293709
step: 360, loss: 0.04183726757764816
step: 370, loss: 9.940765448845923e-05
step: 380, loss: 0.015529905445873737
step: 390, loss: 0.046534258872270584
step: 400, loss: 0.07042375206947327
step: 410, loss: 0.017366407439112663
step: 420, loss: 0.00041817425517365336
step: 430, loss: 0.11015493422746658
step: 440, loss: 0.027308400720357895
step: 450, loss: 0.0007838733727112412
step: 460, loss: 0.04193080589175224
epoch 14: dev_f1=0.9932432432432432, f1=0.9832026875699889, best_f1=0.9854096520763187
step: 0, loss: 0.021009990945458412
step: 10, loss: 6.453042442444712e-05
step: 20, loss: 0.07013864815235138
step: 30, loss: 0.0007534348405897617
step: 40, loss: 0.023252813145518303
step: 50, loss: 0.017869170755147934
step: 60, loss: 0.07063364237546921
step: 70, loss: 0.03463400900363922
step: 80, loss: 0.1028609424829483
step: 90, loss: 0.035710617899894714
step: 100, loss: 0.0493910051882267
step: 110, loss: 0.0005563751910813153
step: 120, loss: 0.0011138864792883396
step: 130, loss: 0.021966084837913513
step: 140, loss: 0.0004037336038891226
step: 150, loss: 0.0428447462618351
step: 160, loss: 0.041510600596666336
step: 170, loss: 0.08318938314914703
step: 180, loss: 0.024485846981406212
step: 190, loss: 0.02258814498782158
step: 200, loss: 0.09292437136173248
step: 210, loss: 0.03830273821949959
step: 220, loss: 0.0010786467464640737
step: 230, loss: 0.1032421812415123
step: 240, loss: 0.01919654943048954
step: 250, loss: 0.03020150400698185
step: 260, loss: 0.03359854593873024
step: 270, loss: 0.09350554645061493
step: 280, loss: 0.0001479086495237425
step: 290, loss: 0.022075306624174118
step: 300, loss: 0.04578592628240585
step: 310, loss: 0.0002071720373351127
step: 320, loss: 0.03041515313088894
step: 330, loss: 0.03526071086525917
step: 340, loss: 0.033089011907577515
step: 350, loss: 0.015894023701548576
step: 360, loss: 0.03517406806349754
step: 370, loss: 0.0006203811499290168
step: 380, loss: 3.571172783267684e-05
step: 390, loss: 0.0007060902426019311
step: 400, loss: 0.061069637537002563
step: 410, loss: 8.11162099125795e-05
step: 420, loss: 0.0017109266482293606
step: 430, loss: 0.019897783175110817
step: 440, loss: 0.02441995032131672
step: 450, loss: 0.048449959605932236
step: 460, loss: 0.03778275474905968
epoch 15: dev_f1=0.9921259842519685, f1=0.9842696629213483, best_f1=0.9854096520763187
step: 0, loss: 0.00012615056766662747
step: 10, loss: 0.09072317183017731
step: 20, loss: 0.02229115180671215
step: 30, loss: 0.05106031894683838
step: 40, loss: 0.004415282979607582
step: 50, loss: 0.03668467327952385
step: 60, loss: 0.021465571597218513
step: 70, loss: 0.00037710616015829146
step: 80, loss: 0.03442547097802162
step: 90, loss: 0.0005455832579173148
step: 100, loss: 6.040892185410485e-05
step: 110, loss: 0.00013479612243827432
step: 120, loss: 0.033213142305612564
step: 130, loss: 0.02221587859094143
step: 140, loss: 0.01741967722773552
step: 150, loss: 0.01691846363246441
step: 160, loss: 0.02436615712940693
step: 170, loss: 0.04167522117495537
step: 180, loss: 0.017198845744132996
step: 190, loss: 0.04424925148487091
step: 200, loss: 0.024698495864868164
step: 210, loss: 0.0013510538265109062
step: 220, loss: 0.0003128659736830741
step: 230, loss: 0.00022580494987778366
step: 240, loss: 0.00014586168981622905
step: 250, loss: 0.005798040423542261
step: 260, loss: 0.019691389054059982
step: 270, loss: 0.021661698818206787
step: 280, loss: 4.44300239905715e-05
step: 290, loss: 0.02148171328008175
step: 300, loss: 0.00013540263171307743
step: 310, loss: 0.022487636655569077
step: 320, loss: 6.226898403838277e-05
step: 330, loss: 0.05064453184604645
step: 340, loss: 0.026193317025899887
step: 350, loss: 0.06008807197213173
step: 360, loss: 0.0035723161417990923
step: 370, loss: 0.06453422456979752
step: 380, loss: 0.05887134373188019
step: 390, loss: 0.04312482103705406
step: 400, loss: 7.659836410311982e-05
step: 410, loss: 0.02834252640604973
step: 420, loss: 0.002142152516171336
step: 430, loss: 0.09262187778949738
step: 440, loss: 0.019202878698706627
step: 450, loss: 0.05049411579966545
step: 460, loss: 0.02777083031833172
epoch 16: dev_f1=0.9909706546275394, f1=0.9842696629213483, best_f1=0.9854096520763187
step: 0, loss: 0.023499034345149994
step: 10, loss: 0.04122569039463997
step: 20, loss: 6.249661964830011e-05
step: 30, loss: 0.13336098194122314
step: 40, loss: 0.05618198215961456
step: 50, loss: 0.018320444971323013
step: 60, loss: 0.0002929565089289099
step: 70, loss: 0.031012067571282387
step: 80, loss: 0.0005990933859720826
step: 90, loss: 0.023484285920858383
step: 100, loss: 0.055988628417253494
step: 110, loss: 0.049794893711805344
step: 120, loss: 0.026688750833272934
step: 130, loss: 0.020897263661026955
step: 140, loss: 0.07192335277795792
step: 150, loss: 0.01863296888768673
step: 160, loss: 0.03825584426522255
step: 170, loss: 0.028999367728829384
step: 180, loss: 0.0017124945297837257
step: 190, loss: 0.002880815416574478
step: 200, loss: 0.02318401075899601
step: 210, loss: 0.022681916132569313
step: 220, loss: 0.04156331717967987
step: 230, loss: 0.023347655311226845
step: 240, loss: 0.03505893424153328
step: 250, loss: 0.0004803584888577461
step: 260, loss: 0.024709781631827354
step: 270, loss: 0.0031081996858119965
step: 280, loss: 0.0003111809492111206
step: 290, loss: 0.02008286863565445
step: 300, loss: 0.02414538711309433
step: 310, loss: 0.05286290869116783
step: 320, loss: 0.018628600984811783
step: 330, loss: 0.016055718064308167
step: 340, loss: 0.0001594176865182817
step: 350, loss: 7.453453872585669e-05
step: 360, loss: 4.209069084026851e-05
step: 370, loss: 0.02751435711979866
step: 380, loss: 0.053105127066373825
step: 390, loss: 0.10379640758037567
step: 400, loss: 0.02140786685049534
step: 410, loss: 2.5677614758023992e-05
step: 420, loss: 0.04321349412202835
step: 430, loss: 0.03823995217680931
step: 440, loss: 0.00016471683920826763
step: 450, loss: 0.027462821453809738
step: 460, loss: 0.004599327687174082
epoch 17: dev_f1=0.9909706546275394, f1=0.9842696629213483, best_f1=0.9854096520763187
step: 0, loss: 0.012749191373586655
step: 10, loss: 0.055593471974134445
step: 20, loss: 0.0712517723441124
step: 30, loss: 0.0211504939943552
step: 40, loss: 0.00038558736559934914
step: 50, loss: 0.019176548346877098
step: 60, loss: 0.020287171006202698
step: 70, loss: 0.0004156776121817529
step: 80, loss: 0.005249380599707365
step: 90, loss: 0.09140963107347488
step: 100, loss: 0.04800749570131302
step: 110, loss: 0.09219159930944443
step: 120, loss: 0.018765687942504883
step: 130, loss: 3.9220740291057155e-05
step: 140, loss: 0.00010908504918916151
step: 150, loss: 0.021161746233701706
step: 160, loss: 0.024355709552764893
step: 170, loss: 0.020937306806445122
step: 180, loss: 0.034453365951776505
step: 190, loss: 0.024004656821489334
step: 200, loss: 0.03298529237508774
step: 210, loss: 3.7667381548089907e-05
step: 220, loss: 0.024227343499660492
step: 230, loss: 0.02771681919693947
step: 240, loss: 3.263497637817636e-05
step: 250, loss: 0.0154288150370121
step: 260, loss: 0.025999777019023895
step: 270, loss: 0.02211584895849228
step: 280, loss: 0.0241258405148983
step: 290, loss: 0.03380918130278587
step: 300, loss: 0.01870354637503624
step: 310, loss: 0.04946635663509369
step: 320, loss: 0.03365527093410492
step: 330, loss: 0.0005391441518440843
step: 340, loss: 4.8976689868140966e-05
step: 350, loss: 0.026062704622745514
step: 360, loss: 0.025303373113274574
step: 370, loss: 4.079200516571291e-05
step: 380, loss: 0.008535308763384819
step: 390, loss: 0.06368833780288696
step: 400, loss: 0.00799014326184988
step: 410, loss: 0.020601874217391014
step: 420, loss: 0.0376015231013298
step: 430, loss: 0.062326718121767044
step: 440, loss: 0.030382463708519936
step: 450, loss: 0.00017472317267674953
step: 460, loss: 0.00034070565016008914
epoch 18: dev_f1=0.9920903954802259, f1=0.9841986455981941, best_f1=0.9854096520763187
step: 0, loss: 4.8725345550337806e-05
step: 10, loss: 7.810888200765476e-05
step: 20, loss: 0.0490633063018322
step: 30, loss: 0.00012296643399167806
step: 40, loss: 3.5368266253499314e-05
step: 50, loss: 0.019389484077692032
step: 60, loss: 0.01840764284133911
step: 70, loss: 0.037222493439912796
step: 80, loss: 0.02300824411213398
step: 90, loss: 0.04142102599143982
step: 100, loss: 0.01947394758462906
step: 110, loss: 5.324747326085344e-05
step: 120, loss: 5.629219231195748e-05
step: 130, loss: 0.023125724866986275
step: 140, loss: 0.01935707777738571
step: 150, loss: 0.06405371427536011
step: 160, loss: 4.193601489532739e-05
step: 170, loss: 0.08612371236085892
step: 180, loss: 0.07296858727931976
step: 190, loss: 0.023575235158205032
step: 200, loss: 0.00016202621918637305
step: 210, loss: 0.026317350566387177
step: 220, loss: 0.056374289095401764
step: 230, loss: 0.02319403365254402
step: 240, loss: 0.00014216717681847513
step: 250, loss: 4.522821836872026e-05
step: 260, loss: 0.00014447246212512255
step: 270, loss: 0.010803746990859509
step: 280, loss: 0.017683830112218857
step: 290, loss: 0.04251226410269737
step: 300, loss: 0.0221206434071064
step: 310, loss: 0.026679249480366707
step: 320, loss: 0.026161545887589455
step: 330, loss: 0.0011453985935077071
step: 340, loss: 0.0005027916631661355
step: 350, loss: 4.674409137805924e-05
step: 360, loss: 0.03890620917081833
step: 370, loss: 0.02049151062965393
step: 380, loss: 0.0646287351846695
step: 390, loss: 0.050217095762491226
step: 400, loss: 0.09441427886486053
step: 410, loss: 0.04496443271636963
step: 420, loss: 4.2934490920742974e-05
step: 430, loss: 0.05660426989197731
step: 440, loss: 8.006857387954369e-05
step: 450, loss: 5.16555410285946e-05
step: 460, loss: 0.020849037915468216
epoch 19: dev_f1=0.9909706546275394, f1=0.9842696629213483, best_f1=0.9854096520763187
step: 0, loss: 0.04405068978667259
step: 10, loss: 0.027227027341723442
step: 20, loss: 0.022485792636871338
step: 30, loss: 3.686657873913646e-05
step: 40, loss: 0.0007693097577430308
step: 50, loss: 0.0437624491751194
step: 60, loss: 0.00021468213526532054
step: 70, loss: 0.00012410362251102924
step: 80, loss: 0.044718652963638306
step: 90, loss: 6.071152165532112e-05
step: 100, loss: 8.209468796849251e-05
step: 110, loss: 0.022808009758591652
step: 120, loss: 0.04223309084773064
step: 130, loss: 1.2207648069306742e-05
step: 140, loss: 0.04339056834578514
step: 150, loss: 0.03826133534312248
step: 160, loss: 0.04414794594049454
step: 170, loss: 0.02002817578613758
step: 180, loss: 0.02307785674929619
step: 190, loss: 0.0005437548970803618
step: 200, loss: 1.757176869432442e-05
step: 210, loss: 0.016750311478972435
step: 220, loss: 0.027321526780724525
step: 230, loss: 0.022675298154354095
step: 240, loss: 0.024349257349967957
step: 250, loss: 0.04290011525154114
step: 260, loss: 0.01979106105864048
step: 270, loss: 6.540348113048822e-05
step: 280, loss: 0.041085824370384216
step: 290, loss: 0.019104648381471634
step: 300, loss: 0.019473962485790253
step: 310, loss: 0.021650804206728935
step: 320, loss: 0.03801131248474121
step: 330, loss: 0.09487051516771317
step: 340, loss: 0.043226465582847595
step: 350, loss: 0.025315308943390846
step: 360, loss: 0.021943172439932823
step: 370, loss: 0.06251408904790878
step: 380, loss: 0.040772564709186554
step: 390, loss: 0.06747803837060928
step: 400, loss: 0.05095599591732025
step: 410, loss: 0.03972696140408516
step: 420, loss: 3.3491312933620065e-05
step: 430, loss: 0.01747497171163559
step: 440, loss: 3.041561649297364e-05
step: 450, loss: 0.03715139999985695
step: 460, loss: 0.02456127665936947
epoch 20: dev_f1=0.9909706546275394, f1=0.9842696629213483, best_f1=0.9854096520763187
