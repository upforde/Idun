cuda
Device: cuda
step: 0, loss: 0.5710820555686951
step: 10, loss: 0.2145058959722519
step: 20, loss: 0.16725067794322968
step: 30, loss: 0.4888758659362793
step: 40, loss: 0.43028709292411804
step: 50, loss: 0.18803933262825012
step: 60, loss: 0.32499489188194275
step: 70, loss: 0.40403133630752563
step: 80, loss: 0.31565478444099426
step: 90, loss: 0.40616580843925476
step: 100, loss: 0.2701835036277771
step: 110, loss: 0.37988168001174927
step: 120, loss: 0.13391262292861938
step: 130, loss: 0.12220509350299835
step: 140, loss: 0.22169514000415802
step: 150, loss: 0.3277148902416229
step: 160, loss: 0.23679053783416748
step: 170, loss: 0.12782573699951172
step: 180, loss: 0.10071185976266861
step: 190, loss: 0.08385152369737625
step: 200, loss: 0.14593325555324554
step: 210, loss: 0.2239956557750702
step: 220, loss: 0.1716153770685196
step: 230, loss: 0.1878167986869812
step: 240, loss: 0.30724674463272095
step: 250, loss: 0.17567172646522522
step: 260, loss: 0.1286216378211975
step: 270, loss: 0.2839079201221466
step: 280, loss: 0.06298672407865524
step: 290, loss: 0.3829838037490845
step: 300, loss: 0.18540148437023163
step: 310, loss: 0.04529647156596184
step: 320, loss: 0.057788267731666565
step: 330, loss: 0.2077314704656601
step: 340, loss: 0.12208693474531174
step: 350, loss: 0.1258750706911087
step: 360, loss: 0.012005194090306759
step: 370, loss: 0.11966454982757568
step: 380, loss: 0.15467596054077148
step: 390, loss: 0.17294824123382568
step: 400, loss: 0.07727430015802383
epoch 1: dev_f1=0.6583333333333333, f1=0.6593886462882097, best_f1=0.6593886462882097
step: 0, loss: 0.023246416822075844
step: 10, loss: 0.10912042111158371
step: 20, loss: 0.08696605265140533
step: 30, loss: 0.12395517528057098
step: 40, loss: 0.19607475399971008
step: 50, loss: 0.1577833741903305
step: 60, loss: 0.19011518359184265
step: 70, loss: 0.09647298604249954
step: 80, loss: 0.28264832496643066
step: 90, loss: 0.06773629784584045
step: 100, loss: 0.05868348851799965
step: 110, loss: 0.24946251511573792
step: 120, loss: 0.1161780133843422
step: 130, loss: 0.1368284523487091
step: 140, loss: 0.18543274700641632
step: 150, loss: 0.11158917844295502
step: 160, loss: 0.0834907814860344
step: 170, loss: 0.07077297568321228
step: 180, loss: 0.07262349128723145
step: 190, loss: 0.25464245676994324
step: 200, loss: 0.16453495621681213
step: 210, loss: 0.13674230873584747
step: 220, loss: 0.2306745946407318
step: 230, loss: 0.18793176114559174
step: 240, loss: 0.07082683593034744
step: 250, loss: 0.16561010479927063
step: 260, loss: 0.1481357216835022
step: 270, loss: 0.11467528343200684
step: 280, loss: 0.12840798497200012
step: 290, loss: 0.27537181973457336
step: 300, loss: 0.12565995752811432
step: 310, loss: 0.19848763942718506
step: 320, loss: 0.06415200233459473
step: 330, loss: 0.045205458998680115
step: 340, loss: 0.010906776413321495
step: 350, loss: 0.08552499115467072
step: 360, loss: 0.07134564965963364
step: 370, loss: 0.2481839656829834
step: 380, loss: 0.1417449712753296
step: 390, loss: 0.06760881096124649
step: 400, loss: 0.049329061061143875
epoch 2: dev_f1=0.7099236641221373, f1=0.7120622568093384, best_f1=0.7120622568093384
step: 0, loss: 0.06053663790225983
step: 10, loss: 0.15675990283489227
step: 20, loss: 0.0381515808403492
step: 30, loss: 0.09022917598485947
step: 40, loss: 0.049021631479263306
step: 50, loss: 0.06842658668756485
step: 60, loss: 0.11002691835165024
step: 70, loss: 0.07968220859766006
step: 80, loss: 0.01354430802166462
step: 90, loss: 0.0530225969851017
step: 100, loss: 0.27205711603164673
step: 110, loss: 0.16695654392242432
step: 120, loss: 0.10037249326705933
step: 130, loss: 0.09307853132486343
step: 140, loss: 0.10286320745944977
step: 150, loss: 0.022908851504325867
step: 160, loss: 0.05965321138501167
step: 170, loss: 0.04648413881659508
step: 180, loss: 0.08057321608066559
step: 190, loss: 0.053244929760694504
step: 200, loss: 0.1121697649359703
step: 210, loss: 0.080560103058815
step: 220, loss: 0.11575885117053986
step: 230, loss: 0.29525837302207947
step: 240, loss: 0.11736473441123962
step: 250, loss: 0.15429772436618805
step: 260, loss: 0.1495790183544159
step: 270, loss: 0.08646689355373383
step: 280, loss: 0.03280235081911087
step: 290, loss: 0.2560739815235138
step: 300, loss: 0.17967262864112854
step: 310, loss: 0.1796431690454483
step: 320, loss: 0.13819123804569244
step: 330, loss: 0.08798333257436752
step: 340, loss: 0.07919557392597198
step: 350, loss: 0.13602547347545624
step: 360, loss: 0.05796769633889198
step: 370, loss: 0.09573958069086075
step: 380, loss: 0.042777255177497864
step: 390, loss: 0.097042515873909
step: 400, loss: 0.20908398926258087
epoch 3: dev_f1=0.6950959488272921, f1=0.6652892561983471, best_f1=0.7120622568093384
step: 0, loss: 0.15088127553462982
step: 10, loss: 0.12788449227809906
step: 20, loss: 0.3217950463294983
step: 30, loss: 0.05305234715342522
step: 40, loss: 0.06398361921310425
step: 50, loss: 0.08450082689523697
step: 60, loss: 0.04738009348511696
step: 70, loss: 0.07859855890274048
step: 80, loss: 0.045402541756629944
step: 90, loss: 0.09678361564874649
step: 100, loss: 0.07759672403335571
step: 110, loss: 0.03410554677248001
step: 120, loss: 0.11764748394489288
step: 130, loss: 0.10668639093637466
step: 140, loss: 0.09178236871957779
step: 150, loss: 0.2377290427684784
step: 160, loss: 0.11379455775022507
step: 170, loss: 0.0472412109375
step: 180, loss: 0.11487507820129395
step: 190, loss: 0.1342012584209442
step: 200, loss: 0.05198521912097931
step: 210, loss: 0.075015589594841
step: 220, loss: 0.183987557888031
step: 230, loss: 0.15548044443130493
step: 240, loss: 0.1100664958357811
step: 250, loss: 0.08876671642065048
step: 260, loss: 0.08507957309484482
step: 270, loss: 0.1171136423945427
step: 280, loss: 0.04173634201288223
step: 290, loss: 0.12620338797569275
step: 300, loss: 0.19583597779273987
step: 310, loss: 0.2115839272737503
step: 320, loss: 0.0815960094332695
step: 330, loss: 0.16526556015014648
step: 340, loss: 0.13355574011802673
step: 350, loss: 0.12778721749782562
step: 360, loss: 0.044511932879686356
step: 370, loss: 0.14515362679958344
step: 380, loss: 0.21882499754428864
step: 390, loss: 0.06704618036746979
step: 400, loss: 0.039482202380895615
epoch 4: dev_f1=0.7045009784735813, f1=0.7017543859649122, best_f1=0.7120622568093384
step: 0, loss: 0.1056121364235878
step: 10, loss: 0.13097800314426422
step: 20, loss: 0.05423295497894287
step: 30, loss: 0.09743156284093857
step: 40, loss: 0.07508566230535507
step: 50, loss: 0.14366018772125244
step: 60, loss: 0.049138106405735016
step: 70, loss: 0.056072864681482315
step: 80, loss: 0.03905661776661873
step: 90, loss: 0.09039945155382156
step: 100, loss: 0.09750480204820633
step: 110, loss: 0.17737361788749695
step: 120, loss: 0.05628851056098938
step: 130, loss: 0.15034711360931396
step: 140, loss: 0.0420796200633049
step: 150, loss: 0.08778800815343857
step: 160, loss: 0.02196674607694149
step: 170, loss: 0.06585027277469635
step: 180, loss: 0.20581527054309845
step: 190, loss: 0.031062832102179527
step: 200, loss: 0.045421402901411057
step: 210, loss: 0.12426840513944626
step: 220, loss: 0.06985127180814743
step: 230, loss: 0.16177500784397125
step: 240, loss: 0.05625908449292183
step: 250, loss: 0.05437222123146057
step: 260, loss: 0.12381066381931305
step: 270, loss: 0.12321174144744873
step: 280, loss: 0.11130049079656601
step: 290, loss: 0.03675391525030136
step: 300, loss: 0.13973835110664368
step: 310, loss: 0.06936278194189072
step: 320, loss: 0.07227863371372223
step: 330, loss: 0.16393177211284637
step: 340, loss: 0.030642995610833168
step: 350, loss: 0.0745815634727478
step: 360, loss: 0.11505728214979172
step: 370, loss: 0.09200695157051086
step: 380, loss: 0.1774541586637497
step: 390, loss: 0.17940545082092285
step: 400, loss: 0.22672122716903687
epoch 5: dev_f1=0.7261663286004056, f1=0.6875, best_f1=0.6875
step: 0, loss: 0.10273000597953796
step: 10, loss: 0.054345980286598206
step: 20, loss: 0.2347746342420578
step: 30, loss: 0.06260885298252106
step: 40, loss: 0.06842345744371414
step: 50, loss: 0.128106951713562
step: 60, loss: 0.14753054082393646
step: 70, loss: 0.03466213867068291
step: 80, loss: 0.008261127397418022
step: 90, loss: 0.08205289393663406
step: 100, loss: 0.11383984237909317
step: 110, loss: 0.060009799897670746
step: 120, loss: 0.048956796526908875
step: 130, loss: 0.14497463405132294
step: 140, loss: 0.21014843881130219
step: 150, loss: 0.10082925111055374
step: 160, loss: 0.12165085971355438
step: 170, loss: 0.1497349590063095
step: 180, loss: 0.06547398120164871
step: 190, loss: 0.11662702262401581
step: 200, loss: 0.25403115153312683
step: 210, loss: 0.17867417633533478
step: 220, loss: 0.03421556204557419
step: 230, loss: 0.12628640234470367
step: 240, loss: 0.05648057535290718
step: 250, loss: 0.14910587668418884
step: 260, loss: 0.09380754083395004
step: 270, loss: 0.01733355037868023
step: 280, loss: 0.15328268706798553
step: 290, loss: 0.10453490167856216
step: 300, loss: 0.10379301756620407
step: 310, loss: 0.07275596261024475
step: 320, loss: 0.0629994124174118
step: 330, loss: 0.07538172602653503
step: 340, loss: 0.11082255095243454
step: 350, loss: 0.12478035688400269
step: 360, loss: 0.13708318769931793
step: 370, loss: 0.11028320342302322
step: 380, loss: 0.10434456914663315
step: 390, loss: 0.14510619640350342
step: 400, loss: 0.08843785524368286
epoch 6: dev_f1=0.7333333333333334, f1=0.6839186691312383, best_f1=0.6839186691312383
step: 0, loss: 0.3729243874549866
step: 10, loss: 0.06394579261541367
step: 20, loss: 0.05506765469908714
step: 30, loss: 0.03511209413409233
step: 40, loss: 0.04845810309052467
step: 50, loss: 0.07387907803058624
step: 60, loss: 0.16011756658554077
step: 70, loss: 0.09767495840787888
step: 80, loss: 0.0835585743188858
step: 90, loss: 0.021021226420998573
step: 100, loss: 0.020080722868442535
step: 110, loss: 0.18984133005142212
step: 120, loss: 0.14146742224693298
step: 130, loss: 0.07001437991857529
step: 140, loss: 0.15700405836105347
step: 150, loss: 0.0785590186715126
step: 160, loss: 0.08590922504663467
step: 170, loss: 0.09227710217237473
step: 180, loss: 0.03418339416384697
step: 190, loss: 0.19606152176856995
step: 200, loss: 0.05455292388796806
step: 210, loss: 0.07909496128559113
step: 220, loss: 0.0017451737076044083
step: 230, loss: 0.11784921586513519
step: 240, loss: 0.11960643529891968
step: 250, loss: 0.03442612290382385
step: 260, loss: 0.05942665413022041
step: 270, loss: 0.023098226636648178
step: 280, loss: 0.09449466317892075
step: 290, loss: 0.06932615488767624
step: 300, loss: 0.02191048115491867
step: 310, loss: 0.07651347666978836
step: 320, loss: 0.1256810575723648
step: 330, loss: 0.11525556445121765
step: 340, loss: 0.05573613941669464
step: 350, loss: 0.06031304597854614
step: 360, loss: 0.1161511167883873
step: 370, loss: 0.08159308135509491
step: 380, loss: 0.32514774799346924
step: 390, loss: 0.11427804827690125
step: 400, loss: 0.02167079970240593
epoch 7: dev_f1=0.7327102803738318, f1=0.7076923076923077, best_f1=0.6839186691312383
step: 0, loss: 0.012895329855382442
step: 10, loss: 0.06760133057832718
step: 20, loss: 0.08201952278614044
step: 30, loss: 0.01631283387541771
step: 40, loss: 0.020514024421572685
step: 50, loss: 0.03462560102343559
step: 60, loss: 0.08860188722610474
step: 70, loss: 0.08497928828001022
step: 80, loss: 0.0911964550614357
step: 90, loss: 0.058031778782606125
step: 100, loss: 0.010179447010159492
step: 110, loss: 0.07783814519643784
step: 120, loss: 0.07259956002235413
step: 130, loss: 0.08882983028888702
step: 140, loss: 0.07852257788181305
step: 150, loss: 0.08198283612728119
step: 160, loss: 0.2016802281141281
step: 170, loss: 0.10795397311449051
step: 180, loss: 0.060276128351688385
step: 190, loss: 0.10450424998998642
step: 200, loss: 0.08989009261131287
step: 210, loss: 0.06644820421934128
step: 220, loss: 0.059235766530036926
step: 230, loss: 0.023380432277917862
step: 240, loss: 0.10277681052684784
step: 250, loss: 0.06047642603516579
step: 260, loss: 0.27767452597618103
step: 270, loss: 0.21780435740947723
step: 280, loss: 0.09356606751680374
step: 290, loss: 0.161417618393898
step: 300, loss: 0.1459815800189972
step: 310, loss: 0.10254130512475967
step: 320, loss: 0.08262284100055695
step: 330, loss: 0.10419049859046936
step: 340, loss: 0.06522790342569351
step: 350, loss: 0.08999718725681305
step: 360, loss: 0.04027596861124039
step: 370, loss: 0.12181466072797775
step: 380, loss: 0.024062851443886757
step: 390, loss: 0.12419591844081879
step: 400, loss: 0.032927852123975754
epoch 8: dev_f1=0.7154150197628458, f1=0.6981519507186859, best_f1=0.6839186691312383
step: 0, loss: 0.11911334842443466
step: 10, loss: 0.00843973457813263
step: 20, loss: 0.10265900939702988
step: 30, loss: 0.06025266274809837
step: 40, loss: 0.024132700636982918
step: 50, loss: 0.08235710859298706
step: 60, loss: 0.05163842812180519
step: 70, loss: 0.12118744850158691
step: 80, loss: 0.07779606431722641
step: 90, loss: 0.1759389191865921
step: 100, loss: 0.13507266342639923
step: 110, loss: 0.0065882857888937
step: 120, loss: 0.09254732728004456
step: 130, loss: 0.0656941756606102
step: 140, loss: 0.06384515762329102
step: 150, loss: 0.1498352736234665
step: 160, loss: 0.1828201711177826
step: 170, loss: 0.15429502725601196
step: 180, loss: 0.04433130845427513
step: 190, loss: 0.08252895623445511
step: 200, loss: 0.15272833406925201
step: 210, loss: 0.04112494736909866
step: 220, loss: 0.06753939390182495
step: 230, loss: 0.101191945374012
step: 240, loss: 0.07102818787097931
step: 250, loss: 0.23976069688796997
step: 260, loss: 0.10308075696229935
step: 270, loss: 0.17757472395896912
step: 280, loss: 0.22123359143733978
step: 290, loss: 0.07315685600042343
step: 300, loss: 0.10779087245464325
step: 310, loss: 0.16371168196201324
step: 320, loss: 0.17699062824249268
step: 330, loss: 0.04116903245449066
step: 340, loss: 0.04032374918460846
step: 350, loss: 0.08828476071357727
step: 360, loss: 0.07534795999526978
step: 370, loss: 0.12458095699548721
step: 380, loss: 0.002710535889491439
step: 390, loss: 0.07309268414974213
step: 400, loss: 0.07775213569402695
epoch 9: dev_f1=0.7382297551789078, f1=0.7110266159695818, best_f1=0.7110266159695818
step: 0, loss: 0.018122006207704544
step: 10, loss: 0.017327455803751945
step: 20, loss: 0.06357770413160324
step: 30, loss: 0.06627434492111206
step: 40, loss: 0.16108918190002441
step: 50, loss: 0.12706834077835083
step: 60, loss: 0.21953706443309784
step: 70, loss: 0.049219634383916855
step: 80, loss: 0.17174126207828522
step: 90, loss: 0.08626042306423187
step: 100, loss: 0.04423093795776367
step: 110, loss: 0.08343286067247391
step: 120, loss: 0.09317028522491455
step: 130, loss: 0.057218361645936966
step: 140, loss: 0.06648605316877365
step: 150, loss: 0.08066677302122116
step: 160, loss: 0.010926350019872189
step: 170, loss: 0.073965884745121
step: 180, loss: 0.08187971264123917
step: 190, loss: 0.11885420233011246
step: 200, loss: 0.0883665457367897
step: 210, loss: 0.05390118062496185
step: 220, loss: 0.15537166595458984
step: 230, loss: 0.02472314052283764
step: 240, loss: 0.04419193044304848
step: 250, loss: 0.08329403400421143
step: 260, loss: 0.07426655292510986
step: 270, loss: 0.09539658576250076
step: 280, loss: 0.13068941235542297
step: 290, loss: 0.15860548615455627
step: 300, loss: 0.018288442865014076
step: 310, loss: 0.10258083790540695
step: 320, loss: 0.024661945179104805
step: 330, loss: 0.020221713930368423
step: 340, loss: 0.1280539184808731
step: 350, loss: 0.10444583743810654
step: 360, loss: 0.13775064051151276
step: 370, loss: 0.0821218267083168
step: 380, loss: 0.0691506639122963
step: 390, loss: 0.03874364122748375
step: 400, loss: 0.046414341777563095
epoch 10: dev_f1=0.7351351351351351, f1=0.6869409660107335, best_f1=0.7110266159695818
step: 0, loss: 0.020659100264310837
step: 10, loss: 0.14781425893306732
step: 20, loss: 0.14125794172286987
step: 30, loss: 0.09431597590446472
step: 40, loss: 0.04324398934841156
step: 50, loss: 0.07314858585596085
step: 60, loss: 0.08723665028810501
step: 70, loss: 0.11306154727935791
step: 80, loss: 0.08277983963489532
step: 90, loss: 0.06701050698757172
step: 100, loss: 0.12162325531244278
step: 110, loss: 0.1385340690612793
step: 120, loss: 0.04768441617488861
step: 130, loss: 0.010090343654155731
step: 140, loss: 0.11141330003738403
step: 150, loss: 0.11610610783100128
step: 160, loss: 0.06474435329437256
step: 170, loss: 0.08954961597919464
step: 180, loss: 0.0664193257689476
step: 190, loss: 0.04149646311998367
step: 200, loss: 0.04274378716945648
step: 210, loss: 0.03064299188554287
step: 220, loss: 0.11248160153627396
step: 230, loss: 0.0952613428235054
step: 240, loss: 0.09660927951335907
step: 250, loss: 0.04227752238512039
step: 260, loss: 0.10170876979827881
step: 270, loss: 0.038147855550050735
step: 280, loss: 0.10153298825025558
step: 290, loss: 0.11080125719308853
step: 300, loss: 0.07989068329334259
step: 310, loss: 0.042130015790462494
step: 320, loss: 0.005500864237546921
step: 330, loss: 0.15234248340129852
step: 340, loss: 0.09275738894939423
step: 350, loss: 0.023740947246551514
step: 360, loss: 0.03487974405288696
step: 370, loss: 0.0455661378800869
step: 380, loss: 0.05698311701416969
step: 390, loss: 0.05232391878962517
step: 400, loss: 0.12466030567884445
epoch 11: dev_f1=0.7221172022684309, f1=0.7027027027027026, best_f1=0.7110266159695818
step: 0, loss: 0.03463910147547722
step: 10, loss: 0.0917758122086525
step: 20, loss: 0.0028201730456203222
step: 30, loss: 0.03293449431657791
step: 40, loss: 0.041532743722200394
step: 50, loss: 0.02705920860171318
step: 60, loss: 0.024028530344367027
step: 70, loss: 0.2113627940416336
step: 80, loss: 0.10219565033912659
step: 90, loss: 0.03805183991789818
step: 100, loss: 0.015515382401645184
step: 110, loss: 0.027465570718050003
step: 120, loss: 0.11313414573669434
step: 130, loss: 0.016493845731019974
step: 140, loss: 0.07224946469068527
step: 150, loss: 0.09316316246986389
step: 160, loss: 0.0682876780629158
step: 170, loss: 0.09394008666276932
step: 180, loss: 0.031129490584135056
step: 190, loss: 0.07949291914701462
step: 200, loss: 0.045551400631666183
step: 210, loss: 0.11967842280864716
step: 220, loss: 0.05693946033716202
step: 230, loss: 0.1503685712814331
step: 240, loss: 0.0715051218867302
step: 250, loss: 0.10755806416273117
step: 260, loss: 0.08085408806800842
step: 270, loss: 0.07590453326702118
step: 280, loss: 0.009972702711820602
step: 290, loss: 0.13697615265846252
step: 300, loss: 0.05218016728758812
step: 310, loss: 0.12818370759487152
step: 320, loss: 0.03913979232311249
step: 330, loss: 0.09720402956008911
step: 340, loss: 0.03764292225241661
step: 350, loss: 0.07697655260562897
step: 360, loss: 0.04456480219960213
step: 370, loss: 4.676503886003047e-05
step: 380, loss: 0.012470592744648457
step: 390, loss: 0.03408992663025856
step: 400, loss: 0.06618797034025192
epoch 12: dev_f1=0.739463601532567, f1=0.7079303675048356, best_f1=0.7079303675048356
step: 0, loss: 0.011415165849030018
step: 10, loss: 0.051693424582481384
step: 20, loss: 0.04218560457229614
step: 30, loss: 0.06334202736616135
step: 40, loss: 0.07819323986768723
step: 50, loss: 0.10244232416152954
step: 60, loss: 0.044616036117076874
step: 70, loss: 0.13652023673057556
step: 80, loss: 0.012291805818676949
step: 90, loss: 0.06518413871526718
step: 100, loss: 0.026015490293502808
step: 110, loss: 0.046579308807849884
step: 120, loss: 0.0682840421795845
step: 130, loss: 0.004333908203989267
step: 140, loss: 0.1401776820421219
step: 150, loss: 0.04072180762887001
step: 160, loss: 0.13870596885681152
step: 170, loss: 0.06423533707857132
step: 180, loss: 0.06307786703109741
step: 190, loss: 0.07163096219301224
step: 200, loss: 0.12706983089447021
step: 210, loss: 0.049058981239795685
step: 220, loss: 0.16752079129219055
step: 230, loss: 0.051366109400987625
step: 240, loss: 0.12318746745586395
step: 250, loss: 0.020394083112478256
step: 260, loss: 0.11533569544553757
step: 270, loss: 0.012848620302975178
step: 280, loss: 0.11867079883813858
step: 290, loss: 0.1957792043685913
step: 300, loss: 0.10163502395153046
step: 310, loss: 0.0454828105866909
step: 320, loss: 0.10936958342790604
step: 330, loss: 0.07111447304487228
step: 340, loss: 0.021037857979536057
step: 350, loss: 0.12576924264431
step: 360, loss: 0.03033166006207466
step: 370, loss: 0.099428690969944
step: 380, loss: 0.051428794860839844
step: 390, loss: 0.048801835626363754
step: 400, loss: 0.077875055372715
epoch 13: dev_f1=0.7224489795918367, f1=0.6993865030674846, best_f1=0.7079303675048356
step: 0, loss: 0.10024404525756836
step: 10, loss: 0.026563866063952446
step: 20, loss: 0.12362740188837051
step: 30, loss: 0.07215412706136703
step: 40, loss: 0.1307385265827179
step: 50, loss: 0.14567680656909943
step: 60, loss: 0.030951766297221184
step: 70, loss: 0.027965443208813667
step: 80, loss: 0.0788874551653862
step: 90, loss: 0.08864891529083252
step: 100, loss: 0.013827849179506302
step: 110, loss: 0.12730012834072113
step: 120, loss: 0.046327702701091766
step: 130, loss: 0.10720506310462952
step: 140, loss: 0.012165691703557968
step: 150, loss: 0.0005292652640491724
step: 160, loss: 0.16737818717956543
step: 170, loss: 0.08664809167385101
step: 180, loss: 0.034202344715595245
step: 190, loss: 0.05690992996096611
step: 200, loss: 0.019058318808674812
step: 210, loss: 0.35642924904823303
step: 220, loss: 0.04391657933592796
step: 230, loss: 0.10174452513456345
step: 240, loss: 0.0740409716963768
step: 250, loss: 0.037258099764585495
step: 260, loss: 0.11707117408514023
step: 270, loss: 0.04633994400501251
step: 280, loss: 0.08248185366392136
step: 290, loss: 0.020194608718156815
step: 300, loss: 0.13305683434009552
step: 310, loss: 0.06137676164507866
step: 320, loss: 0.034993067383766174
step: 330, loss: 0.18066726624965668
step: 340, loss: 0.07137780636548996
step: 350, loss: 0.07423226535320282
step: 360, loss: 0.0397820770740509
step: 370, loss: 0.008282904513180256
step: 380, loss: 0.08808625489473343
step: 390, loss: 0.13313992321491241
step: 400, loss: 0.047539953142404556
epoch 14: dev_f1=0.7384044526901669, f1=0.6990654205607476, best_f1=0.7079303675048356
step: 0, loss: 0.08221915364265442
step: 10, loss: 0.05175022780895233
step: 20, loss: 0.021325720474123955
step: 30, loss: 0.044207002967596054
step: 40, loss: 0.014574367552995682
step: 50, loss: 0.015931595116853714
step: 60, loss: 0.039914168417453766
step: 70, loss: 0.005769511219114065
step: 80, loss: 0.016721688210964203
step: 90, loss: 0.18922141194343567
step: 100, loss: 0.06130608171224594
step: 110, loss: 0.035082653164863586
step: 120, loss: 0.022039081901311874
step: 130, loss: 0.07848416268825531
step: 140, loss: 0.03073861449956894
step: 150, loss: 0.04997866600751877
step: 160, loss: 0.07455772161483765
step: 170, loss: 0.018865974619984627
step: 180, loss: 0.08723850548267365
step: 190, loss: 0.06633477658033371
step: 200, loss: 0.03469641134142876
step: 210, loss: 0.17270436882972717
step: 220, loss: 0.048550598323345184
step: 230, loss: 0.09557759761810303
step: 240, loss: 0.04741521179676056
step: 250, loss: 0.027721989899873734
step: 260, loss: 0.07718829810619354
step: 270, loss: 0.08218438923358917
step: 280, loss: 0.012458796612918377
step: 290, loss: 0.03682038560509682
step: 300, loss: 0.028955034911632538
step: 310, loss: 0.03399328887462616
step: 320, loss: 0.058689940720796585
step: 330, loss: 0.08626126497983932
step: 340, loss: 0.0774148628115654
step: 350, loss: 0.054524656385183334
step: 360, loss: 0.09474260360002518
step: 370, loss: 0.06250188499689102
step: 380, loss: 0.1406099796295166
step: 390, loss: 0.1677769273519516
step: 400, loss: 0.03734327852725983
epoch 15: dev_f1=0.7283018867924528, f1=0.7192307692307692, best_f1=0.7079303675048356
step: 0, loss: 0.05221636965870857
step: 10, loss: 0.015609802678227425
step: 20, loss: 0.021962633356451988
step: 30, loss: 0.06702814996242523
step: 40, loss: 0.10298758745193481
step: 50, loss: 0.03853626549243927
step: 60, loss: 0.015158964321017265
step: 70, loss: 0.07470639050006866
step: 80, loss: 0.04589228704571724
step: 90, loss: 0.043841686099767685
step: 100, loss: 0.05104205384850502
step: 110, loss: 0.027538077905774117
step: 120, loss: 0.08426505327224731
step: 130, loss: 0.0735984593629837
step: 140, loss: 0.047288112342357635
step: 150, loss: 0.14029069244861603
step: 160, loss: 0.07500247657299042
step: 170, loss: 0.07451439648866653
step: 180, loss: 0.03745429962873459
step: 190, loss: 0.10303395986557007
step: 200, loss: 0.08709312975406647
step: 210, loss: 0.012669345363974571
step: 220, loss: 0.040785856544971466
step: 230, loss: 0.10350217670202255
step: 240, loss: 0.19189991056919098
step: 250, loss: 0.044366952031850815
step: 260, loss: 0.03215934708714485
step: 270, loss: 0.07827860116958618
step: 280, loss: 0.05483631044626236
step: 290, loss: 0.05144627392292023
step: 300, loss: 0.07737905532121658
step: 310, loss: 0.009591449052095413
step: 320, loss: 0.030265193432569504
step: 330, loss: 0.033944837749004364
step: 340, loss: 0.05582266300916672
step: 350, loss: 0.05891195684671402
step: 360, loss: 0.09870417416095734
step: 370, loss: 0.07091913372278214
step: 380, loss: 0.02436371147632599
step: 390, loss: 0.11051229387521744
step: 400, loss: 0.01497679017484188
epoch 16: dev_f1=0.7272727272727272, f1=0.6876310272536688, best_f1=0.7079303675048356
step: 0, loss: 0.004859877750277519
step: 10, loss: 0.100324347615242
step: 20, loss: 0.05009451508522034
step: 30, loss: 0.022618886083364487
step: 40, loss: 0.06495367735624313
step: 50, loss: 0.0697808638215065
step: 60, loss: 0.03537977859377861
step: 70, loss: 0.056689150631427765
step: 80, loss: 0.020586440339684486
step: 90, loss: 0.1255594789981842
step: 100, loss: 0.03867566958069801
step: 110, loss: 0.06975901126861572
step: 120, loss: 0.056550946086645126
step: 130, loss: 0.06260598450899124
step: 140, loss: 0.1231314092874527
step: 150, loss: 0.06926781684160233
step: 160, loss: 0.049814045429229736
step: 170, loss: 0.024769887328147888
step: 180, loss: 0.02814047411084175
step: 190, loss: 0.15292783081531525
step: 200, loss: 0.049229077994823456
step: 210, loss: 0.004715301562100649
step: 220, loss: 0.09105443954467773
step: 230, loss: 0.07103636115789413
step: 240, loss: 0.057985175400972366
step: 250, loss: 0.020879099145531654
step: 260, loss: 0.13438938558101654
step: 270, loss: 0.17271724343299866
step: 280, loss: 0.08265446126461029
step: 290, loss: 0.07465307414531708
step: 300, loss: 0.1005571261048317
step: 310, loss: 0.012097571045160294
step: 320, loss: 0.10666630417108536
step: 330, loss: 0.03869512677192688
step: 340, loss: 0.07066869735717773
step: 350, loss: 0.04479288309812546
step: 360, loss: 0.10384757816791534
step: 370, loss: 0.07571256160736084
step: 380, loss: 0.19651322066783905
step: 390, loss: 0.05540439486503601
step: 400, loss: 0.12731751799583435
epoch 17: dev_f1=0.7219917012448134, f1=0.6893617021276596, best_f1=0.7079303675048356
step: 0, loss: 0.04158363118767738
step: 10, loss: 0.07156068086624146
step: 20, loss: 0.0325370617210865
step: 30, loss: 0.06890957802534103
step: 40, loss: 0.04169584810733795
step: 50, loss: 0.031936295330524445
step: 60, loss: 0.13928641378879547
step: 70, loss: 0.06203869357705116
step: 80, loss: 0.15286119282245636
step: 90, loss: 0.005861414130777121
step: 100, loss: 0.04605427384376526
step: 110, loss: 0.007031875196844339
step: 120, loss: 0.11181162297725677
step: 130, loss: 0.06266473978757858
step: 140, loss: 0.00996902771294117
step: 150, loss: 0.06378863006830215
step: 160, loss: 0.050526831299066544
step: 170, loss: 0.05491526424884796
step: 180, loss: 0.018538080155849457
step: 190, loss: 0.01074367668479681
step: 200, loss: 0.04113556817173958
step: 210, loss: 0.040561750531196594
step: 220, loss: 0.0063884626142680645
step: 230, loss: 0.05699534714221954
step: 240, loss: 0.024094413965940475
step: 250, loss: 0.10303177684545517
step: 260, loss: 0.03391203656792641
step: 270, loss: 0.02883903682231903
step: 280, loss: 0.07186678051948547
step: 290, loss: 0.04602174833416939
step: 300, loss: 0.05028766021132469
step: 310, loss: 0.016805468127131462
step: 320, loss: 0.06995810568332672
step: 330, loss: 0.024709556251764297
step: 340, loss: 0.01608452759683132
step: 350, loss: 0.029495948925614357
step: 360, loss: 0.03375246375799179
step: 370, loss: 0.023915540426969528
step: 380, loss: 0.04738615080714226
step: 390, loss: 0.07725729048252106
step: 400, loss: 0.09842836111783981
epoch 18: dev_f1=0.7227926078028748, f1=0.6972860125260961, best_f1=0.7079303675048356
step: 0, loss: 0.03645485267043114
step: 10, loss: 0.06722009927034378
step: 20, loss: 0.0505509078502655
step: 30, loss: 0.0696837306022644
step: 40, loss: 0.016436608508229256
step: 50, loss: 0.06590108573436737
step: 60, loss: 0.041445039212703705
step: 70, loss: 0.09322980046272278
step: 80, loss: 0.035696595907211304
step: 90, loss: 0.06073567271232605
step: 100, loss: 0.02213546447455883
step: 110, loss: 0.04551968723535538
step: 120, loss: 0.09732454270124435
step: 130, loss: 0.06596535444259644
step: 140, loss: 0.05132068321108818
step: 150, loss: 0.0532117635011673
step: 160, loss: 0.14146195352077484
step: 170, loss: 0.06862074136734009
step: 180, loss: 0.05677059292793274
step: 190, loss: 0.01819932460784912
step: 200, loss: 0.04776701703667641
step: 210, loss: 0.07943666726350784
step: 220, loss: 0.1155412569642067
step: 230, loss: 0.06461463868618011
step: 240, loss: 0.03370336443185806
step: 250, loss: 0.02939913421869278
step: 260, loss: 0.0448920838534832
step: 270, loss: 0.06888218224048615
step: 280, loss: 0.02332894876599312
step: 290, loss: 0.022202268242836
step: 300, loss: 0.08497002720832825
step: 310, loss: 0.10975315421819687
step: 320, loss: 0.10227743536233902
step: 330, loss: 0.08839091658592224
step: 340, loss: 0.013893306255340576
step: 350, loss: 0.08004038035869598
step: 360, loss: 0.08909279108047485
step: 370, loss: 0.08316013962030411
step: 380, loss: 0.0036797523498535156
step: 390, loss: 0.15131907165050507
step: 400, loss: 0.012380287982523441
epoch 19: dev_f1=0.7073684210526316, f1=0.6825053995680346, best_f1=0.7079303675048356
step: 0, loss: 0.09236247092485428
step: 10, loss: 0.025971081107854843
step: 20, loss: 0.056021228432655334
step: 30, loss: 0.014392979443073273
step: 40, loss: 0.06698141247034073
step: 50, loss: 0.022002406418323517
step: 60, loss: 0.10663866251707077
step: 70, loss: 0.07705798745155334
step: 80, loss: 0.08137587457895279
step: 90, loss: 0.1748121678829193
step: 100, loss: 0.042105454951524734
step: 110, loss: 0.0715968906879425
step: 120, loss: 0.03851833567023277
step: 130, loss: 0.0230939369648695
step: 140, loss: 0.10783232003450394
step: 150, loss: 0.03604791685938835
step: 160, loss: 0.05853705108165741
step: 170, loss: 0.03151474893093109
step: 180, loss: 0.01078870240598917
step: 190, loss: 0.015277102589607239
step: 200, loss: 0.06467051804065704
step: 210, loss: 0.1337745636701584
step: 220, loss: 0.0538349524140358
step: 230, loss: 0.10703855752944946
step: 240, loss: 0.07198396325111389
step: 250, loss: 0.06277178227901459
step: 260, loss: 0.025908291339874268
step: 270, loss: 0.0476253516972065
step: 280, loss: 0.017035210505127907
step: 290, loss: 0.05402277037501335
step: 300, loss: 0.027280882000923157
step: 310, loss: 0.043250247836112976
step: 320, loss: 0.051309358328580856
step: 330, loss: 0.05564882233738899
step: 340, loss: 0.05403999984264374
step: 350, loss: 0.08755514025688171
step: 360, loss: 0.08762675523757935
step: 370, loss: 0.060662612318992615
step: 380, loss: 0.07610888034105301
step: 390, loss: 0.0011350815184414387
step: 400, loss: 0.03171636164188385
epoch 20: dev_f1=0.7127882599580714, f1=0.6795698924731184, best_f1=0.7079303675048356
