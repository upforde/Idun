cuda
Device: cuda
step: 0, loss: 0.6166972517967224
step: 10, loss: 0.3161502480506897
step: 20, loss: 0.32463571429252625
step: 30, loss: 0.3814282715320587
step: 40, loss: 0.15097157657146454
step: 50, loss: 0.21041186153888702
step: 60, loss: 0.20805779099464417
step: 70, loss: 0.2993921637535095
step: 80, loss: 0.37700048089027405
step: 90, loss: 0.3066035807132721
step: 100, loss: 0.35872259736061096
step: 110, loss: 0.3908773362636566
step: 120, loss: 0.17984862625598907
step: 130, loss: 0.07645601034164429
step: 140, loss: 0.21636249125003815
step: 150, loss: 0.12576207518577576
step: 160, loss: 0.21698176860809326
step: 170, loss: 0.46517544984817505
step: 180, loss: 0.2665932774543762
step: 190, loss: 0.11286851018667221
step: 200, loss: 0.15024642646312714
step: 210, loss: 0.058388836681842804
step: 220, loss: 0.12867316603660583
step: 230, loss: 0.19840596616268158
step: 240, loss: 0.11663410812616348
step: 250, loss: 0.05460240691900253
step: 260, loss: 0.1477832794189453
step: 270, loss: 0.26312220096588135
step: 280, loss: 0.19906066358089447
step: 290, loss: 0.43255725502967834
step: 300, loss: 0.11379291862249374
step: 310, loss: 0.112579844892025
step: 320, loss: 0.1286102533340454
step: 330, loss: 0.15713706612586975
step: 340, loss: 0.12101390212774277
step: 350, loss: 0.011430899612605572
step: 360, loss: 0.16226400434970856
step: 370, loss: 0.22899335622787476
step: 380, loss: 0.06154640391469002
epoch 1: dev_f1=0.5442176870748299, f1=0.5848214285714285, best_f1=0.5848214285714285
step: 0, loss: 0.08086521923542023
step: 10, loss: 0.3397882878780365
step: 20, loss: 0.18308576941490173
step: 30, loss: 0.042726244777441025
step: 40, loss: 0.050192687660455704
step: 50, loss: 0.01525968685746193
step: 60, loss: 0.08571343868970871
step: 70, loss: 0.09159254282712936
step: 80, loss: 0.20215916633605957
step: 90, loss: 0.15034613013267517
step: 100, loss: 0.09103411436080933
step: 110, loss: 0.32660216093063354
step: 120, loss: 0.0865776538848877
step: 130, loss: 0.20369559526443481
step: 140, loss: 0.06456796824932098
step: 150, loss: 0.3173859417438507
step: 160, loss: 0.28423190116882324
step: 170, loss: 0.030614333227276802
step: 180, loss: 0.07595774531364441
step: 190, loss: 0.12624506652355194
step: 200, loss: 0.1361350119113922
step: 210, loss: 0.11982392519712448
step: 220, loss: 0.05132743716239929
step: 230, loss: 0.13430160284042358
step: 240, loss: 0.14884699881076813
step: 250, loss: 0.11034858226776123
step: 260, loss: 0.09422421455383301
step: 270, loss: 0.2867538332939148
step: 280, loss: 0.07862651348114014
step: 290, loss: 0.149835005402565
step: 300, loss: 0.20773236453533173
step: 310, loss: 0.11945699900388718
step: 320, loss: 0.1707935780286789
step: 330, loss: 0.017195330932736397
step: 340, loss: 0.14169052243232727
step: 350, loss: 0.09496941417455673
step: 360, loss: 0.28653714060783386
step: 370, loss: 0.31733471155166626
step: 380, loss: 0.07262970507144928
epoch 2: dev_f1=0.7047619047619048, f1=0.6619047619047619, best_f1=0.6619047619047619
step: 0, loss: 0.15094681084156036
step: 10, loss: 0.06103102117776871
step: 20, loss: 0.06927233189344406
step: 30, loss: 0.11059080064296722
step: 40, loss: 0.06433912366628647
step: 50, loss: 0.08715306222438812
step: 60, loss: 0.12948480248451233
step: 70, loss: 0.17190741002559662
step: 80, loss: 0.16340643167495728
step: 90, loss: 0.09327284246683121
step: 100, loss: 0.1458550989627838
step: 110, loss: 0.24153754115104675
step: 120, loss: 0.04819744452834129
step: 130, loss: 0.07993331551551819
step: 140, loss: 0.06755165010690689
step: 150, loss: 0.12037232518196106
step: 160, loss: 0.09319635480642319
step: 170, loss: 0.0270136259496212
step: 180, loss: 0.15274497866630554
step: 190, loss: 0.16087506711483002
step: 200, loss: 0.07810063660144806
step: 210, loss: 0.10301867872476578
step: 220, loss: 0.18686597049236298
step: 230, loss: 0.24250350892543793
step: 240, loss: 0.004898503422737122
step: 250, loss: 0.09775342792272568
step: 260, loss: 0.14280733466148376
step: 270, loss: 0.14023254811763763
step: 280, loss: 0.12991346418857574
step: 290, loss: 0.03881673514842987
step: 300, loss: 0.12713563442230225
step: 310, loss: 0.04538377746939659
step: 320, loss: 0.11009752750396729
step: 330, loss: 0.07610240578651428
step: 340, loss: 0.038748599588871
step: 350, loss: 0.1500248908996582
step: 360, loss: 0.0471157543361187
step: 370, loss: 0.0357820987701416
step: 380, loss: 0.09263987094163895
epoch 3: dev_f1=0.7185929648241205, f1=0.7135678391959798, best_f1=0.7135678391959798
step: 0, loss: 0.11071659624576569
step: 10, loss: 0.03502802923321724
step: 20, loss: 0.08050493896007538
step: 30, loss: 0.12284194678068161
step: 40, loss: 0.02762310393154621
step: 50, loss: 0.09360671788454056
step: 60, loss: 0.06445310264825821
step: 70, loss: 0.0838102176785469
step: 80, loss: 0.04901063069701195
step: 90, loss: 0.0412730872631073
step: 100, loss: 0.06968384236097336
step: 110, loss: 0.26661384105682373
step: 120, loss: 0.0743822231888771
step: 130, loss: 0.07861281931400299
step: 140, loss: 0.041573889553546906
step: 150, loss: 0.14942951500415802
step: 160, loss: 0.08969533443450928
step: 170, loss: 0.19556741416454315
step: 180, loss: 0.08102341741323471
step: 190, loss: 0.0006155545124784112
step: 200, loss: 0.10659767687320709
step: 210, loss: 0.1829269975423813
step: 220, loss: 0.03418785333633423
step: 230, loss: 0.06918656826019287
step: 240, loss: 0.05111505463719368
step: 250, loss: 0.11897348612546921
step: 260, loss: 0.028607992455363274
step: 270, loss: 0.1205950677394867
step: 280, loss: 0.09680367261171341
step: 290, loss: 0.04067853465676308
step: 300, loss: 0.1017124280333519
step: 310, loss: 0.20494519174098969
step: 320, loss: 0.04085588827729225
step: 330, loss: 0.01592039316892624
step: 340, loss: 0.2877195477485657
step: 350, loss: 0.13338568806648254
step: 360, loss: 0.11971031874418259
step: 370, loss: 0.0677715465426445
step: 380, loss: 0.039417605847120285
epoch 4: dev_f1=0.7031250000000001, f1=0.6875000000000001, best_f1=0.7135678391959798
step: 0, loss: 0.11233107000589371
step: 10, loss: 0.09252999722957611
step: 20, loss: 0.0680207759141922
step: 30, loss: 0.05762964487075806
step: 40, loss: 0.0031441794708371162
step: 50, loss: 0.02699057012796402
step: 60, loss: 0.04220122471451759
step: 70, loss: 0.04790594428777695
step: 80, loss: 0.0021072591189295053
step: 90, loss: 0.08133736252784729
step: 100, loss: 0.06300300359725952
step: 110, loss: 0.10821980983018875
step: 120, loss: 0.14893615245819092
step: 130, loss: 0.07377858459949493
step: 140, loss: 0.12714609503746033
step: 150, loss: 0.07552596926689148
step: 160, loss: 0.12305158376693726
step: 170, loss: 0.050382185727357864
step: 180, loss: 0.14164666831493378
step: 190, loss: 0.10254878550767899
step: 200, loss: 0.07453015446662903
step: 210, loss: 0.15127597749233246
step: 220, loss: 0.05220753699541092
step: 230, loss: 0.06232574209570885
step: 240, loss: 0.05246478319168091
step: 250, loss: 0.16865168511867523
step: 260, loss: 0.03688674047589302
step: 270, loss: 0.07390146702528
step: 280, loss: 0.1105441227555275
step: 290, loss: 0.09011071920394897
step: 300, loss: 0.1111615002155304
step: 310, loss: 0.0584648959338665
step: 320, loss: 0.0850200206041336
step: 330, loss: 0.1330460160970688
step: 340, loss: 0.08611078560352325
step: 350, loss: 0.10714004188776016
step: 360, loss: 0.06164109706878662
step: 370, loss: 0.008599556051194668
step: 380, loss: 0.056741636246442795
epoch 5: dev_f1=0.7030878859857482, f1=0.721549636803874, best_f1=0.7135678391959798
step: 0, loss: 0.045453719794750214
step: 10, loss: 0.05546336993575096
step: 20, loss: 0.08361221104860306
step: 30, loss: 0.04688520357012749
step: 40, loss: 0.11532868444919586
step: 50, loss: 0.02639675699174404
step: 60, loss: 0.06978851556777954
step: 70, loss: 0.04029342532157898
step: 80, loss: 0.2076624482870102
step: 90, loss: 0.12841428816318512
step: 100, loss: 0.06361614167690277
step: 110, loss: 0.22093695402145386
step: 120, loss: 0.05559052154421806
step: 130, loss: 0.09682264924049377
step: 140, loss: 0.1548663228750229
step: 150, loss: 0.07302768528461456
step: 160, loss: 0.09770505875349045
step: 170, loss: 0.06118820980191231
step: 180, loss: 0.07502290606498718
step: 190, loss: 0.13629920780658722
step: 200, loss: 0.23723337054252625
step: 210, loss: 0.027827471494674683
step: 220, loss: 0.0756034404039383
step: 230, loss: 0.008529478684067726
step: 240, loss: 0.0482732392847538
step: 250, loss: 0.06233955919742584
step: 260, loss: 0.11307405680418015
step: 270, loss: 0.14744152128696442
step: 280, loss: 0.055570878088474274
step: 290, loss: 0.033337607979774475
step: 300, loss: 0.05808994174003601
step: 310, loss: 0.11022867262363434
step: 320, loss: 0.17550520598888397
step: 330, loss: 0.04716034233570099
step: 340, loss: 0.030576171353459358
step: 350, loss: 0.05160451680421829
step: 360, loss: 0.07917982339859009
step: 370, loss: 0.04511905089020729
step: 380, loss: 0.06774371862411499
epoch 6: dev_f1=0.736842105263158, f1=0.717948717948718, best_f1=0.717948717948718
step: 0, loss: 0.0048540919087827206
step: 10, loss: 0.06671327352523804
step: 20, loss: 0.047382902354002
step: 30, loss: 0.09836716204881668
step: 40, loss: 0.00214770482853055
step: 50, loss: 0.07400359213352203
step: 60, loss: 0.03127777576446533
step: 70, loss: 0.015371555462479591
step: 80, loss: 0.029925808310508728
step: 90, loss: 0.11584711074829102
step: 100, loss: 0.11191923171281815
step: 110, loss: 0.025135112926363945
step: 120, loss: 0.12704098224639893
step: 130, loss: 0.021428562700748444
step: 140, loss: 0.24434107542037964
step: 150, loss: 0.07872925698757172
step: 160, loss: 0.1441529095172882
step: 170, loss: 0.023630743846297264
step: 180, loss: 0.06672009080648422
step: 190, loss: 0.08649488538503647
step: 200, loss: 0.06272964924573898
step: 210, loss: 0.07608792930841446
step: 220, loss: 0.01615135371685028
step: 230, loss: 0.029330139979720116
step: 240, loss: 0.026625093072652817
step: 250, loss: 0.09198083728551865
step: 260, loss: 0.18464301526546478
step: 270, loss: 0.10367441177368164
step: 280, loss: 0.034145668148994446
step: 290, loss: 0.17746944725513458
step: 300, loss: 0.06481034308671951
step: 310, loss: 0.054862625896930695
step: 320, loss: 0.047762855887413025
step: 330, loss: 0.12521761655807495
step: 340, loss: 0.02909877896308899
step: 350, loss: 0.10754024982452393
step: 360, loss: 0.07804011553525925
step: 370, loss: 0.06534256786108017
step: 380, loss: 0.07071195542812347
epoch 7: dev_f1=0.7555555555555555, f1=0.7304785894206549, best_f1=0.7304785894206549
step: 0, loss: 0.08118519932031631
step: 10, loss: 0.03024960681796074
step: 20, loss: 0.10254111886024475
step: 30, loss: 0.03756958246231079
step: 40, loss: 0.049782346934080124
step: 50, loss: 0.13696099817752838
step: 60, loss: 0.04531874507665634
step: 70, loss: 0.07326163351535797
step: 80, loss: 0.06929961591959
step: 90, loss: 0.05930984392762184
step: 100, loss: 0.17073014378547668
step: 110, loss: 0.00010904201917583123
step: 120, loss: 0.08119674026966095
step: 130, loss: 0.04967498034238815
step: 140, loss: 0.04464934766292572
step: 150, loss: 0.05406665802001953
step: 160, loss: 0.050901755690574646
step: 170, loss: 0.05814735218882561
step: 180, loss: 0.039787620306015015
step: 190, loss: 0.08899455517530441
step: 200, loss: 0.09312878549098969
step: 210, loss: 0.04431561753153801
step: 220, loss: 0.058987002819776535
step: 230, loss: 0.02188849076628685
step: 240, loss: 0.048305511474609375
step: 250, loss: 0.12786898016929626
step: 260, loss: 0.07831612229347229
step: 270, loss: 0.025378743186593056
step: 280, loss: 0.017756681889295578
step: 290, loss: 0.03213769197463989
step: 300, loss: 0.032336242496967316
step: 310, loss: 0.07254048436880112
step: 320, loss: 0.09101568162441254
step: 330, loss: 0.04758897051215172
step: 340, loss: 0.058310382068157196
step: 350, loss: 0.07778296619653702
step: 360, loss: 0.06166081503033638
step: 370, loss: 0.02370844967663288
step: 380, loss: 0.01437030266970396
epoch 8: dev_f1=0.7371134020618555, f1=0.7135416666666666, best_f1=0.7304785894206549
step: 0, loss: 0.0035632895305752754
step: 10, loss: 0.05988011509180069
step: 20, loss: 0.06265710294246674
step: 30, loss: 0.01280572172254324
step: 40, loss: 0.03543715924024582
step: 50, loss: 0.06546996533870697
step: 60, loss: 0.0656987875699997
step: 70, loss: 0.0819123238325119
step: 80, loss: 0.11077231168746948
step: 90, loss: 0.0816720724105835
step: 100, loss: 0.04320276156067848
step: 110, loss: 0.07022671401500702
step: 120, loss: 0.031261593103408813
step: 130, loss: 0.05273290351033211
step: 140, loss: 0.034636978060007095
step: 150, loss: 0.002229492412880063
step: 160, loss: 0.06858554482460022
step: 170, loss: 0.08014962077140808
step: 180, loss: 0.0516180694103241
step: 190, loss: 0.06063927337527275
step: 200, loss: 0.21281200647354126
step: 210, loss: 0.025901155546307564
step: 220, loss: 0.08176013827323914
step: 230, loss: 0.02999538742005825
step: 240, loss: 0.09608982503414154
step: 250, loss: 0.05180879309773445
step: 260, loss: 0.050024691969156265
step: 270, loss: 0.06748662889003754
step: 280, loss: 0.03711007162928581
step: 290, loss: 0.053076036274433136
step: 300, loss: 0.0014939449029043317
step: 310, loss: 0.05967779830098152
step: 320, loss: 0.03185952082276344
step: 330, loss: 0.1598384827375412
step: 340, loss: 0.17867060005664825
step: 350, loss: 0.0007491123978979886
step: 360, loss: 0.06078889220952988
step: 370, loss: 0.10503561794757843
step: 380, loss: 0.08453346788883209
epoch 9: dev_f1=0.7244897959183673, f1=0.6925064599483204, best_f1=0.7304785894206549
step: 0, loss: 0.03344322368502617
step: 10, loss: 0.04526199400424957
step: 20, loss: 0.13691183924674988
step: 30, loss: 0.06840543448925018
step: 40, loss: 0.029813392087817192
step: 50, loss: 0.014330988749861717
step: 60, loss: 0.14311304688453674
step: 70, loss: 0.052997007966041565
step: 80, loss: 0.07731558382511139
step: 90, loss: 0.0260457843542099
step: 100, loss: 0.07141377031803131
step: 110, loss: 0.15812057256698608
step: 120, loss: 0.05942608416080475
step: 130, loss: 0.09674438089132309
step: 140, loss: 0.07151711732149124
step: 150, loss: 0.021556831896305084
step: 160, loss: 0.03545161709189415
step: 170, loss: 0.01303041446954012
step: 180, loss: 0.055265624076128006
step: 190, loss: 0.02206587977707386
step: 200, loss: 0.11509159952402115
step: 210, loss: 0.11607597768306732
step: 220, loss: 0.03463774919509888
step: 230, loss: 0.023797620087862015
step: 240, loss: 0.052475959062576294
step: 250, loss: 0.07250496000051498
step: 260, loss: 0.05640670657157898
step: 270, loss: 0.05836406350135803
step: 280, loss: 0.018993288278579712
step: 290, loss: 0.03857843205332756
step: 300, loss: 0.02420923113822937
step: 310, loss: 0.031746767461299896
step: 320, loss: 0.16893085837364197
step: 330, loss: 0.024907484650611877
step: 340, loss: 0.16934293508529663
step: 350, loss: 0.11927063018083572
step: 360, loss: 0.011716033332049847
step: 370, loss: 0.07783913612365723
step: 380, loss: 0.032404474914073944
epoch 10: dev_f1=0.7455012853470436, f1=0.7200000000000001, best_f1=0.7304785894206549
step: 0, loss: 0.036611124873161316
step: 10, loss: 0.03664517402648926
step: 20, loss: 0.06843743473291397
step: 30, loss: 0.05108119174838066
step: 40, loss: 0.051136016845703125
step: 50, loss: 0.03560328856110573
step: 60, loss: 0.05021747574210167
step: 70, loss: 0.0913725197315216
step: 80, loss: 0.003380219917744398
step: 90, loss: 0.07458832859992981
step: 100, loss: 0.09403691440820694
step: 110, loss: 0.02328692190349102
step: 120, loss: 0.08982223272323608
step: 130, loss: 0.006988992914557457
step: 140, loss: 0.07517573237419128
step: 150, loss: 0.07392709702253342
step: 160, loss: 0.03504091873764992
step: 170, loss: 0.02402334474027157
step: 180, loss: 0.0495087094604969
step: 190, loss: 0.049621064215898514
step: 200, loss: 0.054485466331243515
step: 210, loss: 0.03872671723365784
step: 220, loss: 0.06345120072364807
step: 230, loss: 0.02431698888540268
step: 240, loss: 0.06921820342540741
step: 250, loss: 0.010696410201489925
step: 260, loss: 0.21957886219024658
step: 270, loss: 0.13353216648101807
step: 280, loss: 0.02992694079875946
step: 290, loss: 0.03412292152643204
step: 300, loss: 0.012127061374485493
step: 310, loss: 0.03679012507200241
step: 320, loss: 0.048521172255277634
step: 330, loss: 0.0763058215379715
step: 340, loss: 0.033070217818021774
step: 350, loss: 0.05456865578889847
step: 360, loss: 0.05890442058444023
step: 370, loss: 0.09896508604288101
step: 380, loss: 0.07492014765739441
epoch 11: dev_f1=0.7549019607843136, f1=0.717557251908397, best_f1=0.7304785894206549
step: 0, loss: 0.0845581442117691
step: 10, loss: 0.07775174081325531
step: 20, loss: 0.15718212723731995
step: 30, loss: 0.03130394220352173
step: 40, loss: 0.024256207048892975
step: 50, loss: 0.0768071711063385
step: 60, loss: 0.020258475095033646
step: 70, loss: 0.022350553423166275
step: 80, loss: 0.045341163873672485
step: 90, loss: 0.030287660658359528
step: 100, loss: 0.03682537376880646
step: 110, loss: 0.0012122010812163353
step: 120, loss: 0.055974580347537994
step: 130, loss: 0.08003319799900055
step: 140, loss: 0.07082709670066833
step: 150, loss: 0.04081108793616295
step: 160, loss: 0.053475406020879745
step: 170, loss: 0.017374662682414055
step: 180, loss: 0.08972057700157166
step: 190, loss: 0.15160758793354034
step: 200, loss: 0.08431019634008408
step: 210, loss: 6.15642566117458e-05
step: 220, loss: 0.06572456657886505
step: 230, loss: 0.050618790090084076
step: 240, loss: 0.08055233210325241
step: 250, loss: 0.016821471974253654
step: 260, loss: 0.06479038298130035
step: 270, loss: 0.08332587033510208
step: 280, loss: 0.0898057296872139
step: 290, loss: 0.026505621150135994
step: 300, loss: 0.06789272278547287
step: 310, loss: 0.01525193452835083
step: 320, loss: 0.025493117049336433
step: 330, loss: 0.02186252735555172
step: 340, loss: 0.026982447132468224
step: 350, loss: 0.031500011682510376
step: 360, loss: 0.006252054590731859
step: 370, loss: 0.0012584369396790862
step: 380, loss: 0.038678500801324844
epoch 12: dev_f1=0.7549019607843136, f1=0.7104622871046229, best_f1=0.7304785894206549
step: 0, loss: 0.02745657227933407
step: 10, loss: 0.14493924379348755
step: 20, loss: 0.008959010243415833
step: 30, loss: 0.07895383983850479
step: 40, loss: 0.061928246170282364
step: 50, loss: 0.052827201783657074
step: 60, loss: 0.03838944062590599
step: 70, loss: 0.06384485214948654
step: 80, loss: 0.15137864649295807
step: 90, loss: 0.04341009631752968
step: 100, loss: 0.05161549150943756
step: 110, loss: 0.023656189441680908
step: 120, loss: 0.07158427685499191
step: 130, loss: 0.033275749534368515
step: 140, loss: 0.08008784055709839
step: 150, loss: 0.03714587911963463
step: 160, loss: 0.011354395188391209
step: 170, loss: 0.08107300102710724
step: 180, loss: 0.06204596534371376
step: 190, loss: 0.10885041207075119
step: 200, loss: 0.04419536888599396
step: 210, loss: 0.03000050038099289
step: 220, loss: 0.019479552283883095
step: 230, loss: 0.03421594947576523
step: 240, loss: 0.11538361012935638
step: 250, loss: 0.007097771391272545
step: 260, loss: 0.1073514074087143
step: 270, loss: 0.0581061989068985
step: 280, loss: 0.015668006613850594
step: 290, loss: 0.03738036006689072
step: 300, loss: 0.15636992454528809
step: 310, loss: 0.0928460955619812
step: 320, loss: 0.17922255396842957
step: 330, loss: 0.03432513028383255
step: 340, loss: 0.08323190361261368
step: 350, loss: 0.017616264522075653
step: 360, loss: 0.18243645131587982
step: 370, loss: 0.01951458491384983
step: 380, loss: 0.06341095268726349
epoch 13: dev_f1=0.7481296758104737, f1=0.7189873417721518, best_f1=0.7304785894206549
step: 0, loss: 0.001785221160389483
step: 10, loss: 0.034582968801259995
step: 20, loss: 0.02557353675365448
step: 30, loss: 0.045764725655317307
step: 40, loss: 0.00045693747233599424
step: 50, loss: 0.010537016205489635
step: 60, loss: 0.01777566224336624
step: 70, loss: 0.1073351576924324
step: 80, loss: 0.05377940461039543
step: 90, loss: 0.09022782742977142
step: 100, loss: 0.06097082421183586
step: 110, loss: 0.02504182793200016
step: 120, loss: 0.03718116134405136
step: 130, loss: 0.10145606100559235
step: 140, loss: 0.16939887404441833
step: 150, loss: 0.1476796567440033
step: 160, loss: 0.001123593421652913
step: 170, loss: 0.04247277230024338
step: 180, loss: 0.009676105342805386
step: 190, loss: 0.06252021342515945
step: 200, loss: 0.015533102676272392
step: 210, loss: 0.01717381179332733
step: 220, loss: 0.04944084957242012
step: 230, loss: 0.08593054115772247
step: 240, loss: 0.07599257677793503
step: 250, loss: 0.0983102023601532
step: 260, loss: 0.03297148644924164
step: 270, loss: 0.09039821475744247
step: 280, loss: 0.058043017983436584
step: 290, loss: 0.029769934713840485
step: 300, loss: 0.0020566554740071297
step: 310, loss: 0.0037088217213749886
step: 320, loss: 0.025905145332217216
step: 330, loss: 0.09931071102619171
step: 340, loss: 0.07544306665658951
step: 350, loss: 0.11214786022901535
step: 360, loss: 0.27835094928741455
step: 370, loss: 0.02964065782725811
step: 380, loss: 0.0651499480009079
epoch 14: dev_f1=0.7447916666666665, f1=0.7162534435261707, best_f1=0.7304785894206549
step: 0, loss: 0.033303145319223404
step: 10, loss: 0.014378614723682404
step: 20, loss: 0.06488698720932007
step: 30, loss: 0.00543294008821249
step: 40, loss: 0.03791803866624832
step: 50, loss: 0.05106649175286293
step: 60, loss: 0.06684564054012299
step: 70, loss: 0.008072211407124996
step: 80, loss: 0.050440847873687744
step: 90, loss: 0.03406371548771858
step: 100, loss: 0.016004987061023712
step: 110, loss: 0.058136895298957825
step: 120, loss: 0.05491798371076584
step: 130, loss: 0.04917290061712265
step: 140, loss: 0.1260567605495453
step: 150, loss: 0.0662185549736023
step: 160, loss: 0.014866598881781101
step: 170, loss: 0.021892264485359192
step: 180, loss: 0.03344381973147392
step: 190, loss: 0.08447343856096268
step: 200, loss: 0.015253197401762009
step: 210, loss: 0.07224075496196747
step: 220, loss: 0.02880965918302536
step: 230, loss: 0.06740570813417435
step: 240, loss: 5.655650238622911e-05
step: 250, loss: 0.001425694557838142
step: 260, loss: 0.0002517140528652817
step: 270, loss: 0.02159697189927101
step: 280, loss: 0.07360250502824783
step: 290, loss: 0.02704882062971592
step: 300, loss: 0.006335230078548193
step: 310, loss: 0.006581156048923731
step: 320, loss: 0.0005872920155525208
step: 330, loss: 0.054337140172719955
step: 340, loss: 0.03103497065603733
step: 350, loss: 0.020572340115904808
step: 360, loss: 0.004536482505500317
step: 370, loss: 0.03793218731880188
step: 380, loss: 0.04725348949432373
epoch 15: dev_f1=0.745308310991957, f1=0.6983240223463687, best_f1=0.7304785894206549
step: 0, loss: 0.0010906648822128773
step: 10, loss: 0.08086442202329636
step: 20, loss: 0.04235391318798065
step: 30, loss: 0.10014165192842484
step: 40, loss: 0.023310605436563492
step: 50, loss: 0.041515517979860306
step: 60, loss: 0.026107819750905037
step: 70, loss: 0.04210369288921356
step: 80, loss: 0.0007754110847599804
step: 90, loss: 0.020207349210977554
step: 100, loss: 0.01246474776417017
step: 110, loss: 0.0006526904180645943
step: 120, loss: 0.20151230692863464
step: 130, loss: 0.011569269001483917
step: 140, loss: 0.014711407013237476
step: 150, loss: 0.042305998504161835
step: 160, loss: 0.016353789716959
step: 170, loss: 0.09469684958457947
step: 180, loss: 0.08291404694318771
step: 190, loss: 0.043314386159181595
step: 200, loss: 0.00011139806156279519
step: 210, loss: 0.11051163822412491
step: 220, loss: 0.022748399525880814
step: 230, loss: 0.14139217138290405
step: 240, loss: 0.059577714651823044
step: 250, loss: 0.0438055656850338
step: 260, loss: 0.050830572843551636
step: 270, loss: 0.00036259685293771327
step: 280, loss: 0.016742007806897163
step: 290, loss: 0.017666062340140343
step: 300, loss: 0.050406768918037415
step: 310, loss: 0.0374334342777729
step: 320, loss: 0.10230179131031036
step: 330, loss: 0.06861402094364166
step: 340, loss: 0.06966384500265121
step: 350, loss: 0.004679792560636997
step: 360, loss: 0.04904181510210037
step: 370, loss: 0.0047994875349104404
step: 380, loss: 0.03303379565477371
epoch 16: dev_f1=0.7320574162679426, f1=0.711217183770883, best_f1=0.7304785894206549
step: 0, loss: 0.02181839570403099
step: 10, loss: 0.020008979365229607
step: 20, loss: 0.05399220064282417
step: 30, loss: 0.043945327401161194
step: 40, loss: 0.027216201648116112
step: 50, loss: 0.05293672904372215
step: 60, loss: 0.06635802984237671
step: 70, loss: 0.016315476968884468
step: 80, loss: 0.0016103730304166675
step: 90, loss: 0.0431850366294384
step: 100, loss: 0.05202185735106468
step: 110, loss: 0.059022463858127594
step: 120, loss: 0.059742171317338943
step: 130, loss: 0.027645450085401535
step: 140, loss: 0.09340792894363403
step: 150, loss: 0.06915199756622314
step: 160, loss: 0.11345329135656357
step: 170, loss: 0.030887268483638763
step: 180, loss: 3.44162508554291e-05
step: 190, loss: 0.052357856184244156
step: 200, loss: 0.02767295576632023
step: 210, loss: 0.01422213390469551
step: 220, loss: 0.0007547236164100468
step: 230, loss: 0.05617503076791763
step: 240, loss: 0.17023880779743195
step: 250, loss: 0.0009249004651792347
step: 260, loss: 0.005275219213217497
step: 270, loss: 0.06709330528974533
step: 280, loss: 0.010710137896239758
step: 290, loss: 0.023160330951213837
step: 300, loss: 0.01525956578552723
step: 310, loss: 0.010195552371442318
step: 320, loss: 0.09538351744413376
step: 330, loss: 0.04268600046634674
step: 340, loss: 0.08366774767637253
step: 350, loss: 0.0002028097223956138
step: 360, loss: 0.023274486884474754
step: 370, loss: 0.03667883574962616
step: 380, loss: 0.02728286385536194
epoch 17: dev_f1=0.7447916666666665, f1=0.7008086253369272, best_f1=0.7304785894206549
step: 0, loss: 0.038111425936222076
step: 10, loss: 0.002037607366219163
step: 20, loss: 0.043511856347322464
step: 30, loss: 0.021466849371790886
step: 40, loss: 0.049137186259031296
step: 50, loss: 0.057824816554784775
step: 60, loss: 0.004926476627588272
step: 70, loss: 0.03219039365649223
step: 80, loss: 0.033994339406490326
step: 90, loss: 0.05793726071715355
step: 100, loss: 0.025919564068317413
step: 110, loss: 0.044986214488744736
step: 120, loss: 0.0001436728925909847
step: 130, loss: 4.658112447941676e-05
step: 140, loss: 0.004915196448564529
step: 150, loss: 0.10133745521306992
step: 160, loss: 0.018975209444761276
step: 170, loss: 0.03177544102072716
step: 180, loss: 0.0409400537610054
step: 190, loss: 0.03995908051729202
step: 200, loss: 0.06546016782522202
step: 210, loss: 2.624414446472656e-05
step: 220, loss: 0.027982449159026146
step: 230, loss: 0.12863539159297943
step: 240, loss: 0.016507619991898537
step: 250, loss: 0.04577729105949402
step: 260, loss: 0.06119189038872719
step: 270, loss: 0.022047072649002075
step: 280, loss: 0.002693813294172287
step: 290, loss: 0.03236641734838486
step: 300, loss: 0.0019159470684826374
step: 310, loss: 0.024878190830349922
step: 320, loss: 0.0044205584563314915
step: 330, loss: 0.0591089092195034
step: 340, loss: 6.179347110446543e-05
step: 350, loss: 0.01843573898077011
step: 360, loss: 0.07327722758054733
step: 370, loss: 0.164642795920372
step: 380, loss: 6.889161886647344e-05
epoch 18: dev_f1=0.7277486910994764, f1=0.7105263157894737, best_f1=0.7304785894206549
step: 0, loss: 0.013233061879873276
step: 10, loss: 0.09527534246444702
step: 20, loss: 0.025983400642871857
step: 30, loss: 0.04016491398215294
step: 40, loss: 0.0046225013211369514
step: 50, loss: 0.04792463034391403
step: 60, loss: 0.008551615290343761
step: 70, loss: 0.0627790093421936
step: 80, loss: 0.015978390350937843
step: 90, loss: 0.018508533015847206
step: 100, loss: 0.052768781781196594
step: 110, loss: 0.01796969398856163
step: 120, loss: 0.07821420580148697
step: 130, loss: 0.06108046695590019
step: 140, loss: 0.013017208315432072
step: 150, loss: 0.05195546895265579
step: 160, loss: 0.014930041506886482
step: 170, loss: 0.07507571578025818
step: 180, loss: 0.03322087973356247
step: 190, loss: 0.05942445993423462
step: 200, loss: 0.039824068546295166
step: 210, loss: 0.030544400215148926
step: 220, loss: 0.06647354364395142
step: 230, loss: 0.07226478308439255
step: 240, loss: 0.0736478790640831
step: 250, loss: 7.438995817210525e-05
step: 260, loss: 0.004756621550768614
step: 270, loss: 0.014224836602807045
step: 280, loss: 0.02114809863269329
step: 290, loss: 0.01870579645037651
step: 300, loss: 0.00020830947323702276
step: 310, loss: 0.007565877865999937
step: 320, loss: 0.08792978525161743
step: 330, loss: 0.0511300265789032
step: 340, loss: 0.023177755996584892
step: 350, loss: 0.10047569125890732
step: 360, loss: 0.05121795833110809
step: 370, loss: 5.106767639517784e-05
step: 380, loss: 0.016736462712287903
epoch 19: dev_f1=0.7244094488188976, f1=0.7055702917771883, best_f1=0.7304785894206549
step: 0, loss: 0.024899423122406006
step: 10, loss: 0.019107431173324585
step: 20, loss: 0.015750082209706306
step: 30, loss: 0.039399996399879456
step: 40, loss: 0.07480417191982269
step: 50, loss: 0.06060715764760971
step: 60, loss: 0.0005049266619607806
step: 70, loss: 0.07519420236349106
step: 80, loss: 0.01333905104547739
step: 90, loss: 0.04546085000038147
step: 100, loss: 0.054978642612695694
step: 110, loss: 0.09404166042804718
step: 120, loss: 0.005474090110510588
step: 130, loss: 0.0001809717941796407
step: 140, loss: 0.0001324927288806066
step: 150, loss: 0.11754667013883591
step: 160, loss: 0.005218876991420984
step: 170, loss: 0.022929225116968155
step: 180, loss: 0.005215490236878395
step: 190, loss: 0.09804769605398178
step: 200, loss: 0.0560125969350338
step: 210, loss: 0.08406360447406769
step: 220, loss: 0.018606659024953842
step: 230, loss: 0.04714520275592804
step: 240, loss: 0.04984515160322189
step: 250, loss: 0.02855537086725235
step: 260, loss: 0.0043123080395162106
step: 270, loss: 0.023556772619485855
step: 280, loss: 0.0537741594016552
step: 290, loss: 2.7334455808158964e-05
step: 300, loss: 0.0666072815656662
step: 310, loss: 0.010871047154068947
step: 320, loss: 0.029662415385246277
step: 330, loss: 0.013852163217961788
step: 340, loss: 0.03219062462449074
step: 350, loss: 0.018709715455770493
step: 360, loss: 0.0582612119615078
step: 370, loss: 0.04516828805208206
step: 380, loss: 0.016228802502155304
epoch 20: dev_f1=0.7238605898123326, f1=0.7, best_f1=0.7304785894206549
