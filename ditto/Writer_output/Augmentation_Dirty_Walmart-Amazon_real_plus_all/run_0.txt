cuda
Device: cuda
step: 0, loss: 0.8197718262672424
step: 10, loss: 0.47002533078193665
step: 20, loss: 0.37300777435302734
step: 30, loss: 0.30852219462394714
step: 40, loss: 0.38765576481819153
step: 50, loss: 0.42111703753471375
step: 60, loss: 0.38920629024505615
step: 70, loss: 0.11416496336460114
step: 80, loss: 0.27718308568000793
step: 90, loss: 0.27089524269104004
step: 100, loss: 0.24518455564975739
step: 110, loss: 0.15164858102798462
step: 120, loss: 0.3479108512401581
step: 130, loss: 0.09540585428476334
step: 140, loss: 0.164858877658844
step: 150, loss: 0.13830357789993286
step: 160, loss: 0.02555348537862301
step: 170, loss: 0.30759021639823914
step: 180, loss: 0.0978955402970314
step: 190, loss: 0.26967254281044006
step: 200, loss: 0.1968824714422226
step: 210, loss: 0.17946863174438477
step: 220, loss: 0.112830251455307
step: 230, loss: 0.13023360073566437
step: 240, loss: 0.11273376643657684
step: 250, loss: 0.1286448836326599
step: 260, loss: 0.16035930812358856
step: 270, loss: 0.0993945449590683
step: 280, loss: 0.11296740919351578
step: 290, loss: 0.1703891158103943
step: 300, loss: 0.12617500126361847
step: 310, loss: 0.1211196631193161
step: 320, loss: 0.07714449614286423
step: 330, loss: 0.1004219800233841
step: 340, loss: 0.06449083983898163
step: 350, loss: 0.19819514453411102
step: 360, loss: 0.2182759940624237
step: 370, loss: 0.13559465110301971
step: 380, loss: 0.06557647138834
epoch 1: dev_f1=0.5479452054794521, f1=0.48888888888888893, best_f1=0.48888888888888893
step: 0, loss: 0.06756579875946045
step: 10, loss: 0.05883946642279625
step: 20, loss: 0.07749025523662567
step: 30, loss: 0.04570574313402176
step: 40, loss: 0.07862409949302673
step: 50, loss: 0.08004630357027054
step: 60, loss: 0.15397362411022186
step: 70, loss: 0.12682145833969116
step: 80, loss: 0.1204129308462143
step: 90, loss: 0.045535821467638016
step: 100, loss: 0.07149917632341385
step: 110, loss: 0.10475798696279526
step: 120, loss: 0.11943591386079788
step: 130, loss: 0.1267029494047165
step: 140, loss: 0.006225314922630787
step: 150, loss: 0.15531621873378754
step: 160, loss: 0.2021697461605072
step: 170, loss: 0.09984427690505981
step: 180, loss: 0.030977101996541023
step: 190, loss: 0.14425727725028992
step: 200, loss: 0.16252434253692627
step: 210, loss: 0.07027649134397507
step: 220, loss: 0.059353142976760864
step: 230, loss: 0.14581558108329773
step: 240, loss: 0.09847313165664673
step: 250, loss: 0.11979310214519501
step: 260, loss: 0.0707344263792038
step: 270, loss: 0.08975239098072052
step: 280, loss: 0.4916389286518097
step: 290, loss: 0.22039365768432617
step: 300, loss: 0.15612904727458954
step: 310, loss: 0.14428669214248657
step: 320, loss: 0.11422037333250046
step: 330, loss: 0.1431671679019928
step: 340, loss: 0.11240585893392563
step: 350, loss: 0.025874005630612373
step: 360, loss: 0.053859833627939224
step: 370, loss: 0.19834519922733307
step: 380, loss: 0.042772307991981506
epoch 2: dev_f1=0.6428571428571428, f1=0.6799999999999999, best_f1=0.6799999999999999
step: 0, loss: 0.13085031509399414
step: 10, loss: 0.11588389426469803
step: 20, loss: 0.09437114000320435
step: 30, loss: 0.05143332481384277
step: 40, loss: 0.05262066796422005
step: 50, loss: 0.019662801176309586
step: 60, loss: 0.19025075435638428
step: 70, loss: 0.04882883280515671
step: 80, loss: 0.08686710149049759
step: 90, loss: 0.12369496375322342
step: 100, loss: 0.11786247789859772
step: 110, loss: 0.1113084927201271
step: 120, loss: 0.10824517905712128
step: 130, loss: 0.203651562333107
step: 140, loss: 0.02439270168542862
step: 150, loss: 0.14293396472930908
step: 160, loss: 0.08266277611255646
step: 170, loss: 0.08633878827095032
step: 180, loss: 0.09792792797088623
step: 190, loss: 0.043369509279727936
step: 200, loss: 0.05487198010087013
step: 210, loss: 0.07952646166086197
step: 220, loss: 0.06459401547908783
step: 230, loss: 0.11574049293994904
step: 240, loss: 0.07030239701271057
step: 250, loss: 0.0948723629117012
step: 260, loss: 0.09977197647094727
step: 270, loss: 0.06573259830474854
step: 280, loss: 0.1267254501581192
step: 290, loss: 0.1176590844988823
step: 300, loss: 0.09110123664140701
step: 310, loss: 0.022615542635321617
step: 320, loss: 0.1843240112066269
step: 330, loss: 0.10841385275125504
step: 340, loss: 0.06276454776525497
step: 350, loss: 0.09449601918458939
step: 360, loss: 0.03590364381670952
step: 370, loss: 0.10105321556329727
step: 380, loss: 0.31027552485466003
epoch 3: dev_f1=0.7197943444730078, f1=0.6951871657754011, best_f1=0.6951871657754011
step: 0, loss: 0.08593408763408661
step: 10, loss: 0.08085494488477707
step: 20, loss: 0.07582786679267883
step: 30, loss: 0.024419503286480904
step: 40, loss: 0.06824496388435364
step: 50, loss: 0.07550304383039474
step: 60, loss: 0.0441620834171772
step: 70, loss: 0.14011527597904205
step: 80, loss: 0.017845507711172104
step: 90, loss: 0.011402182281017303
step: 100, loss: 0.14317454397678375
step: 110, loss: 0.024555345997214317
step: 120, loss: 0.07823203504085541
step: 130, loss: 0.12842591106891632
step: 140, loss: 0.0005954590742476285
step: 150, loss: 0.10829545557498932
step: 160, loss: 0.0068864841014146805
step: 170, loss: 0.05258550867438316
step: 180, loss: 0.09622029960155487
step: 190, loss: 0.09220749139785767
step: 200, loss: 0.14318117499351501
step: 210, loss: 0.05322999879717827
step: 220, loss: 0.11858309805393219
step: 230, loss: 0.008302259258925915
step: 240, loss: 0.05879904329776764
step: 250, loss: 0.010204819962382317
step: 260, loss: 0.06876464933156967
step: 270, loss: 0.062251169234514236
step: 280, loss: 0.04576950892806053
step: 290, loss: 0.010210598818957806
step: 300, loss: 0.061948515474796295
step: 310, loss: 0.0015913461102172732
step: 320, loss: 0.16094404458999634
step: 330, loss: 0.13879643380641937
step: 340, loss: 0.12479764223098755
step: 350, loss: 0.011971906758844852
step: 360, loss: 0.0695221871137619
step: 370, loss: 0.09620583802461624
step: 380, loss: 0.1786717176437378
epoch 4: dev_f1=0.7304347826086957, f1=0.7247956403269755, best_f1=0.7247956403269755
step: 0, loss: 0.18944807350635529
step: 10, loss: 0.04433835297822952
step: 20, loss: 0.05475526303052902
step: 30, loss: 0.11146603524684906
step: 40, loss: 0.033397212624549866
step: 50, loss: 0.02674442157149315
step: 60, loss: 0.06986098736524582
step: 70, loss: 0.050656743347644806
step: 80, loss: 0.06295893341302872
step: 90, loss: 0.16366009414196014
step: 100, loss: 0.15383844077587128
step: 110, loss: 0.12141098827123642
step: 120, loss: 0.0009061258169822395
step: 130, loss: 0.03604847565293312
step: 140, loss: 0.10280834138393402
step: 150, loss: 0.03881819173693657
step: 160, loss: 0.12363272160291672
step: 170, loss: 0.14227606356143951
step: 180, loss: 0.026531105861067772
step: 190, loss: 0.0680011734366417
step: 200, loss: 0.031534742563962936
step: 210, loss: 0.03438138961791992
step: 220, loss: 0.275433748960495
step: 230, loss: 0.07040704041719437
step: 240, loss: 0.16494837403297424
step: 250, loss: 0.05240434780716896
step: 260, loss: 0.045810092240571976
step: 270, loss: 0.08245252072811127
step: 280, loss: 0.05712740495800972
step: 290, loss: 0.14954642951488495
step: 300, loss: 0.09183413535356522
step: 310, loss: 0.07134923338890076
step: 320, loss: 0.13495048880577087
step: 330, loss: 0.21076864004135132
step: 340, loss: 0.13566908240318298
step: 350, loss: 0.05699731782078743
step: 360, loss: 0.09106657654047012
step: 370, loss: 0.10512521862983704
step: 380, loss: 0.07252921164035797
epoch 5: dev_f1=0.7384615384615385, f1=0.7204030226700252, best_f1=0.7204030226700252
step: 0, loss: 0.020061548799276352
step: 10, loss: 0.1218886524438858
step: 20, loss: 0.06845342367887497
step: 30, loss: 0.03845382109284401
step: 40, loss: 0.03409209102392197
step: 50, loss: 0.11349411308765411
step: 60, loss: 0.057940781116485596
step: 70, loss: 0.0005127211916260421
step: 80, loss: 0.07663197815418243
step: 90, loss: 0.11888640373945236
step: 100, loss: 0.007893510162830353
step: 110, loss: 0.11064411699771881
step: 120, loss: 0.1730462908744812
step: 130, loss: 0.0893373191356659
step: 140, loss: 0.07839746028184891
step: 150, loss: 0.08115057647228241
step: 160, loss: 0.144776850938797
step: 170, loss: 0.12635895609855652
step: 180, loss: 0.07118454575538635
step: 190, loss: 0.1655333787202835
step: 200, loss: 0.16379451751708984
step: 210, loss: 0.08202160149812698
step: 220, loss: 0.05182411149144173
step: 230, loss: 0.10036071389913559
step: 240, loss: 0.03949593007564545
step: 250, loss: 0.01945299655199051
step: 260, loss: 0.07246440649032593
step: 270, loss: 0.09022256731987
step: 280, loss: 0.06987462192773819
step: 290, loss: 0.007049510721117258
step: 300, loss: 0.017611537128686905
step: 310, loss: 0.1486722230911255
step: 320, loss: 0.027279356494545937
step: 330, loss: 0.06919796019792557
step: 340, loss: 0.026507658883929253
step: 350, loss: 0.031357232481241226
step: 360, loss: 0.0866350382566452
step: 370, loss: 0.06348597258329391
step: 380, loss: 0.0052460310980677605
epoch 6: dev_f1=0.721311475409836, f1=0.7235142118863048, best_f1=0.7204030226700252
step: 0, loss: 0.09536246955394745
step: 10, loss: 0.058595795184373856
step: 20, loss: 0.06342435628175735
step: 30, loss: 0.06283431500196457
step: 40, loss: 0.020792007446289062
step: 50, loss: 0.06514830887317657
step: 60, loss: 0.16853898763656616
step: 70, loss: 0.1264810562133789
step: 80, loss: 0.06743282079696655
step: 90, loss: 0.05586385726928711
step: 100, loss: 0.016176365315914154
step: 110, loss: 0.09429546445608139
step: 120, loss: 0.08913236111402512
step: 130, loss: 0.06492754071950912
step: 140, loss: 0.0755738765001297
step: 150, loss: 0.09401556849479675
step: 160, loss: 0.011659014038741589
step: 170, loss: 0.07017005234956741
step: 180, loss: 0.0430447943508625
step: 190, loss: 0.0471048578619957
step: 200, loss: 0.07876573503017426
step: 210, loss: 0.04999209940433502
step: 220, loss: 0.1494956910610199
step: 230, loss: 0.11623936891555786
step: 240, loss: 0.068669892847538
step: 250, loss: 0.054905157536268234
step: 260, loss: 0.0007501946529373527
step: 270, loss: 0.06578121334314346
step: 280, loss: 0.034340616315603256
step: 290, loss: 0.060471951961517334
step: 300, loss: 0.06099890172481537
step: 310, loss: 0.07200192660093307
step: 320, loss: 0.11045273393392563
step: 330, loss: 0.19359177350997925
step: 340, loss: 0.08542061597108841
step: 350, loss: 0.06089586764574051
step: 360, loss: 0.030909452587366104
step: 370, loss: 0.390785276889801
step: 380, loss: 0.11438675224781036
epoch 7: dev_f1=0.7154046997389033, f1=0.711340206185567, best_f1=0.7204030226700252
step: 0, loss: 0.007779245730489492
step: 10, loss: 0.14243073761463165
step: 20, loss: 0.03654434159398079
step: 30, loss: 0.004086242988705635
step: 40, loss: 0.10366715490818024
step: 50, loss: 0.08697216957807541
step: 60, loss: 0.04277738928794861
step: 70, loss: 0.09343372285366058
step: 80, loss: 0.08880968391895294
step: 90, loss: 0.03309715539216995
step: 100, loss: 0.011106020770967007
step: 110, loss: 0.1681017428636551
step: 120, loss: 0.014884480275213718
step: 130, loss: 0.06317303329706192
step: 140, loss: 0.02784840762615204
step: 150, loss: 0.04536653682589531
step: 160, loss: 0.03214700147509575
step: 170, loss: 0.15719692409038544
step: 180, loss: 0.02001991868019104
step: 190, loss: 0.07284104079008102
step: 200, loss: 0.07428723573684692
step: 210, loss: 0.03571145236492157
step: 220, loss: 0.040461521595716476
step: 230, loss: 0.05008900165557861
step: 240, loss: 0.12481101602315903
step: 250, loss: 0.016735579818487167
step: 260, loss: 0.04531051963567734
step: 270, loss: 0.07989366352558136
step: 280, loss: 0.10782404243946075
step: 290, loss: 0.06015544757246971
step: 300, loss: 0.008980981074273586
step: 310, loss: 0.08381529152393341
step: 320, loss: 0.07071499526500702
step: 330, loss: 0.08523833006620407
step: 340, loss: 0.2027309387922287
step: 350, loss: 0.06518877297639847
step: 360, loss: 0.05247128754854202
step: 370, loss: 0.03870566561818123
step: 380, loss: 0.08358099311590195
epoch 8: dev_f1=0.748663101604278, f1=0.7272727272727272, best_f1=0.7272727272727272
step: 0, loss: 0.0616580992937088
step: 10, loss: 0.06922858953475952
step: 20, loss: 0.12105260044336319
step: 30, loss: 0.03602386265993118
step: 40, loss: 0.10782914608716965
step: 50, loss: 0.09292575716972351
step: 60, loss: 0.007734454702585936
step: 70, loss: 0.04103716462850571
step: 80, loss: 0.09544266760349274
step: 90, loss: 0.0033775295596569777
step: 100, loss: 0.17319424450397491
step: 110, loss: 0.003803771687671542
step: 120, loss: 0.007840464822947979
step: 130, loss: 0.1084052324295044
step: 140, loss: 0.057520028203725815
step: 150, loss: 0.15407699346542358
step: 160, loss: 0.057515937834978104
step: 170, loss: 0.06029125675559044
step: 180, loss: 0.07436330616474152
step: 190, loss: 0.013359349220991135
step: 200, loss: 0.008022336289286613
step: 210, loss: 0.11397656053304672
step: 220, loss: 0.0012831126805394888
step: 230, loss: 0.06396473199129105
step: 240, loss: 0.0500158816576004
step: 250, loss: 0.09372130036354065
step: 260, loss: 0.047436803579330444
step: 270, loss: 0.09009372442960739
step: 280, loss: 0.0003491892130114138
step: 290, loss: 0.0797024816274643
step: 300, loss: 0.13063912093639374
step: 310, loss: 0.11699160188436508
step: 320, loss: 0.09743853658437729
step: 330, loss: 0.001121909124776721
step: 340, loss: 0.08242783695459366
step: 350, loss: 0.058021098375320435
step: 360, loss: 0.0708780363202095
step: 370, loss: 0.08442850410938263
step: 380, loss: 0.02564621903002262
epoch 9: dev_f1=0.7446808510638299, f1=0.7421052631578948, best_f1=0.7272727272727272
step: 0, loss: 0.02520129643380642
step: 10, loss: 0.09901057928800583
step: 20, loss: 0.012658674269914627
step: 30, loss: 0.07145895808935165
step: 40, loss: 0.10509687662124634
step: 50, loss: 0.06499408930540085
step: 60, loss: 0.0001832697307690978
step: 70, loss: 0.1497305929660797
step: 80, loss: 0.026259170845150948
step: 90, loss: 0.022738302126526833
step: 100, loss: 0.02080686017870903
step: 110, loss: 7.494922465411946e-05
step: 120, loss: 0.04669729992747307
step: 130, loss: 0.010368462651968002
step: 140, loss: 0.0473836325109005
step: 150, loss: 0.00022700086992699653
step: 160, loss: 0.07789814472198486
step: 170, loss: 0.034623485058546066
step: 180, loss: 0.04959574714303017
step: 190, loss: 0.02672595903277397
step: 200, loss: 0.04050038009881973
step: 210, loss: 0.05206209421157837
step: 220, loss: 0.08563680201768875
step: 230, loss: 0.02286789007484913
step: 240, loss: 0.12090198695659637
step: 250, loss: 0.08617231994867325
step: 260, loss: 0.05609584599733353
step: 270, loss: 0.06344259530305862
step: 280, loss: 0.08438500016927719
step: 290, loss: 0.034008823335170746
step: 300, loss: 0.012720219790935516
step: 310, loss: 0.09789036959409714
step: 320, loss: 0.10139920562505722
step: 330, loss: 0.01835644617676735
step: 340, loss: 0.03553503379225731
step: 350, loss: 0.06520182639360428
step: 360, loss: 0.05184214189648628
step: 370, loss: 0.053909849375486374
step: 380, loss: 0.19588811695575714
epoch 10: dev_f1=0.720626631853786, f1=0.6972010178117048, best_f1=0.7272727272727272
step: 0, loss: 0.05093926191329956
step: 10, loss: 0.05063153803348541
step: 20, loss: 0.04064680263400078
step: 30, loss: 0.01233605295419693
step: 40, loss: 0.1328340619802475
step: 50, loss: 0.054178331047296524
step: 60, loss: 0.0389254130423069
step: 70, loss: 0.09646100550889969
step: 80, loss: 0.09884413331747055
step: 90, loss: 0.08916669338941574
step: 100, loss: 0.08512880653142929
step: 110, loss: 0.011929488740861416
step: 120, loss: 0.03121490776538849
step: 130, loss: 0.043178390711545944
step: 140, loss: 0.02647390030324459
step: 150, loss: 0.08266539871692657
step: 160, loss: 0.10952956974506378
step: 170, loss: 0.16911722719669342
step: 180, loss: 0.009323565289378166
step: 190, loss: 0.02940564788877964
step: 200, loss: 0.12560908496379852
step: 210, loss: 0.03840024024248123
step: 220, loss: 0.0216076523065567
step: 230, loss: 0.03648177161812782
step: 240, loss: 0.015009989030659199
step: 250, loss: 0.04315682500600815
step: 260, loss: 0.07404906302690506
step: 270, loss: 0.09586630016565323
step: 280, loss: 0.03214495629072189
step: 290, loss: 0.025745490565896034
step: 300, loss: 0.049933429807424545
step: 310, loss: 0.09154310077428818
step: 320, loss: 0.046886127442121506
step: 330, loss: 0.06758401542901993
step: 340, loss: 0.0651765689253807
step: 350, loss: 0.0865347683429718
step: 360, loss: 0.06249823048710823
step: 370, loss: 0.008163297548890114
step: 380, loss: 0.07999671995639801
epoch 11: dev_f1=0.7300771208226221, f1=0.7146401985111663, best_f1=0.7272727272727272
step: 0, loss: 0.024207817390561104
step: 10, loss: 0.05760527774691582
step: 20, loss: 0.03787771984934807
step: 30, loss: 0.07872249186038971
step: 40, loss: 0.03732603043317795
step: 50, loss: 0.023662686347961426
step: 60, loss: 0.012924311682581902
step: 70, loss: 0.03771217539906502
step: 80, loss: 0.01830400712788105
step: 90, loss: 0.015563061460852623
step: 100, loss: 0.1420809030532837
step: 110, loss: 0.026201147586107254
step: 120, loss: 0.001010750187560916
step: 130, loss: 0.016060832887887955
step: 140, loss: 0.03686957806348801
step: 150, loss: 0.03206956014037132
step: 160, loss: 0.06533674895763397
step: 170, loss: 0.119266577064991
step: 180, loss: 0.11817649751901627
step: 190, loss: 0.14481709897518158
step: 200, loss: 0.026421494781970978
step: 210, loss: 0.056746404618024826
step: 220, loss: 0.042727161198854446
step: 230, loss: 0.024012167006731033
step: 240, loss: 0.03731245920062065
step: 250, loss: 0.02885442227125168
step: 260, loss: 0.014268314465880394
step: 270, loss: 0.06607531011104584
step: 280, loss: 0.043400514870882034
step: 290, loss: 0.06516258418560028
step: 300, loss: 0.020304251462221146
step: 310, loss: 0.06379222869873047
step: 320, loss: 0.11621776223182678
step: 330, loss: 0.09318843483924866
step: 340, loss: 0.00010078865307150409
step: 350, loss: 0.023748736828565598
step: 360, loss: 0.09976128488779068
step: 370, loss: 0.07899382710456848
step: 380, loss: 0.05424559488892555
epoch 12: dev_f1=0.7248677248677249, f1=0.722077922077922, best_f1=0.7272727272727272
step: 0, loss: 0.02849585935473442
step: 10, loss: 0.04153617098927498
step: 20, loss: 0.0770215168595314
step: 30, loss: 0.06417379528284073
step: 40, loss: 0.04049430415034294
step: 50, loss: 0.04518440365791321
step: 60, loss: 0.05737543851137161
step: 70, loss: 0.06423493474721909
step: 80, loss: 0.12191978842020035
step: 90, loss: 0.011672993190586567
step: 100, loss: 0.14609511196613312
step: 110, loss: 0.04228978231549263
step: 120, loss: 0.002140141325071454
step: 130, loss: 0.03120800107717514
step: 140, loss: 0.03420112654566765
step: 150, loss: 0.0010820310562849045
step: 160, loss: 0.07154147326946259
step: 170, loss: 0.011936667375266552
step: 180, loss: 0.08520825952291489
step: 190, loss: 0.04128356650471687
step: 200, loss: 0.03977156803011894
step: 210, loss: 0.05830620974302292
step: 220, loss: 0.06112757697701454
step: 230, loss: 0.04290354996919632
step: 240, loss: 0.020019574090838432
step: 250, loss: 0.05178963392972946
step: 260, loss: 0.03366377204656601
step: 270, loss: 0.08562225848436356
step: 280, loss: 0.023858357220888138
step: 290, loss: 0.06517469137907028
step: 300, loss: 0.15674972534179688
step: 310, loss: 0.04516112059354782
step: 320, loss: 0.04369058832526207
step: 330, loss: 0.04103902354836464
step: 340, loss: 0.008551846258342266
step: 350, loss: 0.07625762373209
step: 360, loss: 0.02300972118973732
step: 370, loss: 0.09851152449846268
step: 380, loss: 0.10525684058666229
epoch 13: dev_f1=0.726775956284153, f1=0.7029972752043598, best_f1=0.7272727272727272
step: 0, loss: 0.0907953679561615
step: 10, loss: 0.006416454911231995
step: 20, loss: 0.060309674590826035
step: 30, loss: 0.016117732971906662
step: 40, loss: 0.0001341683673672378
step: 50, loss: 0.01403789222240448
step: 60, loss: 0.09067077189683914
step: 70, loss: 0.0576842799782753
step: 80, loss: 0.03361078351736069
step: 90, loss: 0.03766225650906563
step: 100, loss: 0.0732550248503685
step: 110, loss: 0.00029457738855853677
step: 120, loss: 0.043912146240472794
step: 130, loss: 0.02509262040257454
step: 140, loss: 0.07927171140909195
step: 150, loss: 0.04352725297212601
step: 160, loss: 0.008101639337837696
step: 170, loss: 0.010489411652088165
step: 180, loss: 0.051430150866508484
step: 190, loss: 0.041616033762693405
step: 200, loss: 0.024107135832309723
step: 210, loss: 0.07064078748226166
step: 220, loss: 0.01821407489478588
step: 230, loss: 0.056992389261722565
step: 240, loss: 0.06957855075597763
step: 250, loss: 0.050780169665813446
step: 260, loss: 0.09760743379592896
step: 270, loss: 0.1695299595594406
step: 280, loss: 0.09675329923629761
step: 290, loss: 0.035561446100473404
step: 300, loss: 0.0747862160205841
step: 310, loss: 0.09970437735319138
step: 320, loss: 0.08288627117872238
step: 330, loss: 0.04170920327305794
step: 340, loss: 0.09606213867664337
step: 350, loss: 0.09521142393350601
step: 360, loss: 0.049838464707136154
step: 370, loss: 0.052243463695049286
step: 380, loss: 0.03949010744690895
epoch 14: dev_f1=0.7371134020618555, f1=0.7193877551020408, best_f1=0.7272727272727272
step: 0, loss: 0.06636230647563934
step: 10, loss: 0.1424843668937683
step: 20, loss: 0.012508257292211056
step: 30, loss: 0.028709452599287033
step: 40, loss: 0.036388665437698364
step: 50, loss: 0.01600385084748268
step: 60, loss: 0.023109350353479385
step: 70, loss: 0.05354112386703491
step: 80, loss: 0.09549209475517273
step: 90, loss: 0.015425071120262146
step: 100, loss: 0.043059904128313065
step: 110, loss: 0.07927234470844269
step: 120, loss: 0.00693309772759676
step: 130, loss: 0.03088376298546791
step: 140, loss: 0.08306968957185745
step: 150, loss: 0.011418754234910011
step: 160, loss: 0.07723613828420639
step: 170, loss: 0.03875835984945297
step: 180, loss: 0.041363175958395004
step: 190, loss: 0.05208651348948479
step: 200, loss: 0.025510670617222786
step: 210, loss: 0.04862453415989876
step: 220, loss: 0.08434944599866867
step: 230, loss: 0.05929085984826088
step: 240, loss: 0.01520216278731823
step: 250, loss: 0.028666334226727486
step: 260, loss: 0.08798214048147202
step: 270, loss: 0.01961636357009411
step: 280, loss: 0.08344032615423203
step: 290, loss: 0.015575645491480827
step: 300, loss: 0.03393259644508362
step: 310, loss: 0.0634985864162445
step: 320, loss: 0.06283248960971832
step: 330, loss: 0.05299384146928787
step: 340, loss: 0.06954292953014374
step: 350, loss: 0.05846267566084862
step: 360, loss: 0.023871520534157753
step: 370, loss: 3.673601895570755e-05
step: 380, loss: 0.001609046827070415
epoch 15: dev_f1=0.7486338797814207, f1=0.7401574803149608, best_f1=0.7272727272727272
step: 0, loss: 0.04598072171211243
step: 10, loss: 0.06365072727203369
step: 20, loss: 0.020144274458289146
step: 30, loss: 0.020600825548171997
step: 40, loss: 0.06382837146520615
step: 50, loss: 0.06947748363018036
step: 60, loss: 0.021986721083521843
step: 70, loss: 0.014939778484404087
step: 80, loss: 0.03223463520407677
step: 90, loss: 0.03236712887883186
step: 100, loss: 0.01944100856781006
step: 110, loss: 0.02922569215297699
step: 120, loss: 0.02333807945251465
step: 130, loss: 0.071714386343956
step: 140, loss: 0.07664989680051804
step: 150, loss: 0.046561602503061295
step: 160, loss: 0.040802594274282455
step: 170, loss: 0.022245563566684723
step: 180, loss: 0.01843215897679329
step: 190, loss: 0.05051124095916748
step: 200, loss: 0.004328832030296326
step: 210, loss: 0.027003133669495583
step: 220, loss: 0.04771727696061134
step: 230, loss: 0.054295532405376434
step: 240, loss: 0.10092008858919144
step: 250, loss: 0.013465533964335918
step: 260, loss: 0.016861550509929657
step: 270, loss: 0.06139807403087616
step: 280, loss: 0.05691194534301758
step: 290, loss: 0.05809410661458969
step: 300, loss: 0.06586313247680664
step: 310, loss: 0.05361632630228996
step: 320, loss: 4.635561344912276e-05
step: 330, loss: 0.0307561494410038
step: 340, loss: 0.011114072054624557
step: 350, loss: 0.031428150832653046
step: 360, loss: 0.06101774051785469
step: 370, loss: 0.10306774079799652
step: 380, loss: 0.04097861424088478
epoch 16: dev_f1=0.717391304347826, f1=0.7310704960835509, best_f1=0.7272727272727272
step: 0, loss: 5.081922427052632e-05
step: 10, loss: 0.10569887608289719
step: 20, loss: 0.04771033301949501
step: 30, loss: 0.004626796115189791
step: 40, loss: 4.296914266888052e-05
step: 50, loss: 0.006366080138832331
step: 60, loss: 0.0461103580892086
step: 70, loss: 0.048449933528900146
step: 80, loss: 0.016452575102448463
step: 90, loss: 0.08575382828712463
step: 100, loss: 0.10734008252620697
step: 110, loss: 0.11760982125997543
step: 120, loss: 0.018295321613550186
step: 130, loss: 0.030422447249293327
step: 140, loss: 0.010562107898294926
step: 150, loss: 0.05841192603111267
step: 160, loss: 0.004832664038985968
step: 170, loss: 0.08667480945587158
step: 180, loss: 0.03594331443309784
step: 190, loss: 0.042287226766347885
step: 200, loss: 0.08295052498579025
step: 210, loss: 0.046096839010715485
step: 220, loss: 0.09523338079452515
step: 230, loss: 0.0005926751182414591
step: 240, loss: 8.855637133819982e-05
step: 250, loss: 0.02864716574549675
step: 260, loss: 0.039978720247745514
step: 270, loss: 0.04032710939645767
step: 280, loss: 0.002209892263635993
step: 290, loss: 7.982134411577135e-05
step: 300, loss: 0.02970040589570999
step: 310, loss: 0.05940418690443039
step: 320, loss: 0.09787291288375854
step: 330, loss: 0.00026699528098106384
step: 340, loss: 0.03617742285132408
step: 350, loss: 0.008006894029676914
step: 360, loss: 0.035812340676784515
step: 370, loss: 0.04060167819261551
step: 380, loss: 0.013827677816152573
epoch 17: dev_f1=0.7307692307692307, f1=0.7, best_f1=0.7272727272727272
step: 0, loss: 0.04221635311841965
step: 10, loss: 0.08139460533857346
step: 20, loss: 0.03177322819828987
step: 30, loss: 0.0876542404294014
step: 40, loss: 0.046341367065906525
step: 50, loss: 0.03543023392558098
step: 60, loss: 0.014929444529116154
step: 70, loss: 0.020057301968336105
step: 80, loss: 0.02594088762998581
step: 90, loss: 0.048845771700143814
step: 100, loss: 0.03326232731342316
step: 110, loss: 0.033483754843473434
step: 120, loss: 0.03273759037256241
step: 130, loss: 0.0001006132151815109
step: 140, loss: 0.03124123439192772
step: 150, loss: 0.009645486250519753
step: 160, loss: 0.08809312433004379
step: 170, loss: 0.06309565156698227
step: 180, loss: 0.02993021532893181
step: 190, loss: 0.0786525309085846
step: 200, loss: 0.1051025390625
step: 210, loss: 0.008086474612355232
step: 220, loss: 0.14572970569133759
step: 230, loss: 0.026195432990789413
step: 240, loss: 0.014439583756029606
step: 250, loss: 0.018502315506339073
step: 260, loss: 5.3772448154632e-05
step: 270, loss: 0.004541260655969381
step: 280, loss: 0.012021531350910664
step: 290, loss: 0.019235661253333092
step: 300, loss: 0.06862206757068634
step: 310, loss: 0.03136936575174332
step: 320, loss: 0.016705503687262535
step: 330, loss: 0.003144670743495226
step: 340, loss: 0.019116710871458054
step: 350, loss: 0.10454370081424713
step: 360, loss: 0.009340220130980015
step: 370, loss: 0.0014204689068719745
step: 380, loss: 0.05263785272836685
epoch 18: dev_f1=0.7262872628726287, f1=0.7272727272727272, best_f1=0.7272727272727272
step: 0, loss: 0.008917724713683128
step: 10, loss: 0.0254655908793211
step: 20, loss: 0.060418061912059784
step: 30, loss: 0.06356161832809448
step: 40, loss: 0.007076917216181755
step: 50, loss: 0.0240495428442955
step: 60, loss: 0.027778828516602516
step: 70, loss: 0.03606067970395088
step: 80, loss: 0.04318687692284584
step: 90, loss: 0.0013091902947053313
step: 100, loss: 0.095701664686203
step: 110, loss: 0.0894104540348053
step: 120, loss: 0.07445312291383743
step: 130, loss: 0.10135981440544128
step: 140, loss: 0.06981442123651505
step: 150, loss: 0.006780236028134823
step: 160, loss: 0.044883206486701965
step: 170, loss: 0.10708878189325333
step: 180, loss: 0.024713687598705292
step: 190, loss: 0.04383990168571472
step: 200, loss: 0.07631530612707138
step: 210, loss: 0.02877000905573368
step: 220, loss: 0.011396815069019794
step: 230, loss: 0.017989248037338257
step: 240, loss: 0.11365655809640884
step: 250, loss: 0.05535751208662987
step: 260, loss: 3.168641705997288e-05
step: 270, loss: 0.02787715196609497
step: 280, loss: 0.007163903210312128
step: 290, loss: 0.00447905994951725
step: 300, loss: 0.008300191722810268
step: 310, loss: 0.02948184870183468
step: 320, loss: 0.02443980611860752
step: 330, loss: 7.592351903440431e-05
step: 340, loss: 0.07006998360157013
step: 350, loss: 5.4393993195844814e-05
step: 360, loss: 0.07127446681261063
step: 370, loss: 3.763325003092177e-05
step: 380, loss: 0.016949009150266647
epoch 19: dev_f1=0.726775956284153, f1=0.6997389033942559, best_f1=0.7272727272727272
step: 0, loss: 0.002302619395777583
step: 10, loss: 0.045453645288944244
step: 20, loss: 0.026704642921686172
step: 30, loss: 0.0003664190007839352
step: 40, loss: 0.021828657016158104
step: 50, loss: 3.6655481380876154e-05
step: 60, loss: 0.01571659930050373
step: 70, loss: 0.02833072654902935
step: 80, loss: 0.10223385691642761
step: 90, loss: 0.002926839515566826
step: 100, loss: 0.0899823009967804
step: 110, loss: 0.024798020720481873
step: 120, loss: 0.023380741477012634
step: 130, loss: 0.030830226838588715
step: 140, loss: 0.0807323008775711
step: 150, loss: 0.010287501849234104
step: 160, loss: 0.03092251345515251
step: 170, loss: 0.0016510043060407043
step: 180, loss: 0.03204626217484474
step: 190, loss: 0.008373597636818886
step: 200, loss: 0.013525289483368397
step: 210, loss: 0.0003803675062954426
step: 220, loss: 0.05263076350092888
step: 230, loss: 0.025895776227116585
step: 240, loss: 0.004837116226553917
step: 250, loss: 3.822004146059044e-05
step: 260, loss: 0.0018575992435216904
step: 270, loss: 0.05119906738400459
step: 280, loss: 0.04038333520293236
step: 290, loss: 0.03329665586352348
step: 300, loss: 0.027628786861896515
step: 310, loss: 4.2466213926672935e-05
step: 320, loss: 0.033476125448942184
step: 330, loss: 0.04456590488553047
step: 340, loss: 0.03051619790494442
step: 350, loss: 0.03523394092917442
step: 360, loss: 0.0008553501102142036
step: 370, loss: 0.00833548977971077
step: 380, loss: 0.040682580322027206
epoch 20: dev_f1=0.7298050139275766, f1=0.6881720430107526, best_f1=0.7272727272727272
