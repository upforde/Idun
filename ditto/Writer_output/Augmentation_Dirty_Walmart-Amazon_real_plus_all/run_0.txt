cuda
Device: cuda
step: 0, loss: 1.181960105895996
step: 10, loss: 0.23714955151081085
step: 20, loss: 0.23750071227550507
step: 30, loss: 0.7119343280792236
step: 40, loss: 0.437724769115448
step: 50, loss: 0.18328215181827545
step: 60, loss: 0.23269356787204742
step: 70, loss: 0.37790447473526
step: 80, loss: 0.4299764633178711
step: 90, loss: 0.22931940853595734
step: 100, loss: 0.31828850507736206
step: 110, loss: 0.3177632987499237
step: 120, loss: 0.3030276894569397
step: 130, loss: 0.26347815990448
step: 140, loss: 0.14833271503448486
step: 150, loss: 0.413580060005188
step: 160, loss: 0.033399321138858795
step: 170, loss: 0.33529049158096313
step: 180, loss: 0.12664788961410522
step: 190, loss: 0.2181260734796524
step: 200, loss: 0.10953755676746368
step: 210, loss: 0.12782242894172668
step: 220, loss: 0.28214552998542786
step: 230, loss: 0.25493231415748596
step: 240, loss: 0.13215556740760803
step: 250, loss: 0.2049826830625534
step: 260, loss: 0.10836578160524368
step: 270, loss: 0.25432661175727844
step: 280, loss: 0.15948088467121124
step: 290, loss: 0.31310412287712097
step: 300, loss: 0.0389169342815876
step: 310, loss: 0.03539367765188217
step: 320, loss: 0.26220279932022095
step: 330, loss: 0.02984062023460865
step: 340, loss: 0.22359298169612885
step: 350, loss: 0.28842616081237793
step: 360, loss: 0.07893863320350647
step: 370, loss: 0.14599758386611938
step: 380, loss: 0.2299283891916275
epoch 1: dev_f1=0.6613756613756614, f1=0.6648501362397821, best_f1=0.6648501362397821
step: 0, loss: 0.27761662006378174
step: 10, loss: 0.049097489565610886
step: 20, loss: 0.10924006253480911
step: 30, loss: 0.22872979938983917
step: 40, loss: 0.01706596463918686
step: 50, loss: 0.18822602927684784
step: 60, loss: 0.338358074426651
step: 70, loss: 0.03312577307224274
step: 80, loss: 0.08978620916604996
step: 90, loss: 0.07578347623348236
step: 100, loss: 0.11781347543001175
step: 110, loss: 0.10657906532287598
step: 120, loss: 0.13507840037345886
step: 130, loss: 0.2519180178642273
step: 140, loss: 0.4361746609210968
step: 150, loss: 0.2564220726490021
step: 160, loss: 0.017883697524666786
step: 170, loss: 0.14550015330314636
step: 180, loss: 0.17761889100074768
step: 190, loss: 0.042191628366708755
step: 200, loss: 0.13424570858478546
step: 210, loss: 0.06624849885702133
step: 220, loss: 0.1541922241449356
step: 230, loss: 0.04956575483083725
step: 240, loss: 0.07723142206668854
step: 250, loss: 0.19232484698295593
step: 260, loss: 0.09633389860391617
step: 270, loss: 0.21113845705986023
step: 280, loss: 0.17623130977153778
step: 290, loss: 0.11623875051736832
step: 300, loss: 0.020103441551327705
step: 310, loss: 0.1420498788356781
step: 320, loss: 0.09692580997943878
step: 330, loss: 0.032037634402513504
step: 340, loss: 0.26709291338920593
step: 350, loss: 0.0995660200715065
step: 360, loss: 0.19848324358463287
step: 370, loss: 0.1434077024459839
step: 380, loss: 0.15789352357387543
epoch 2: dev_f1=0.7454545454545456, f1=0.687361419068736, best_f1=0.687361419068736
step: 0, loss: 0.12750181555747986
step: 10, loss: 0.10854025185108185
step: 20, loss: 0.08937884867191315
step: 30, loss: 0.0729391947388649
step: 40, loss: 0.008073875680565834
step: 50, loss: 0.0612412765622139
step: 60, loss: 0.1087859645485878
step: 70, loss: 0.3043985962867737
step: 80, loss: 0.1188921108841896
step: 90, loss: 0.12158457189798355
step: 100, loss: 0.13620223104953766
step: 110, loss: 0.1654956340789795
step: 120, loss: 0.07532677054405212
step: 130, loss: 0.20802128314971924
step: 140, loss: 0.14672602713108063
step: 150, loss: 0.25644707679748535
step: 160, loss: 0.1306479573249817
step: 170, loss: 0.1393594592809677
step: 180, loss: 0.15184369683265686
step: 190, loss: 0.07580597698688507
step: 200, loss: 0.04799101501703262
step: 210, loss: 0.3062629997730255
step: 220, loss: 0.10449586808681488
step: 230, loss: 0.0868959054350853
step: 240, loss: 0.2500174641609192
step: 250, loss: 0.081690713763237
step: 260, loss: 0.1698164939880371
step: 270, loss: 0.09299734979867935
step: 280, loss: 0.17086733877658844
step: 290, loss: 0.12368464469909668
step: 300, loss: 0.12692397832870483
step: 310, loss: 0.09347938001155853
step: 320, loss: 0.1388256996870041
step: 330, loss: 0.07214801013469696
step: 340, loss: 0.24729052186012268
step: 350, loss: 0.1148328185081482
step: 360, loss: 0.1103762835264206
step: 370, loss: 0.14069116115570068
step: 380, loss: 0.1394357681274414
epoch 3: dev_f1=0.7570332480818414, f1=0.7230769230769232, best_f1=0.7230769230769232
step: 0, loss: 0.04496243596076965
step: 10, loss: 0.06164383888244629
step: 20, loss: 0.11313605308532715
step: 30, loss: 0.06689000129699707
step: 40, loss: 0.06532011926174164
step: 50, loss: 0.19986769556999207
step: 60, loss: 0.07644599676132202
step: 70, loss: 0.11047378927469254
step: 80, loss: 0.06984767317771912
step: 90, loss: 0.018983779475092888
step: 100, loss: 0.08226955682039261
step: 110, loss: 0.21061193943023682
step: 120, loss: 0.01940236985683441
step: 130, loss: 0.14338363707065582
step: 140, loss: 0.07935779541730881
step: 150, loss: 0.07135755568742752
step: 160, loss: 0.06160875782370567
step: 170, loss: 0.07620099931955338
step: 180, loss: 0.06067509576678276
step: 190, loss: 0.11249573528766632
step: 200, loss: 0.006224812939763069
step: 210, loss: 0.04604562744498253
step: 220, loss: 0.06053119897842407
step: 230, loss: 0.10062350332736969
step: 240, loss: 0.06880994141101837
step: 250, loss: 0.040681060403585434
step: 260, loss: 0.0921739935874939
step: 270, loss: 0.05937103182077408
step: 280, loss: 0.2454088032245636
step: 290, loss: 0.13141493499279022
step: 300, loss: 0.07785120606422424
step: 310, loss: 0.17008505761623383
step: 320, loss: 0.0011903740232810378
step: 330, loss: 0.09855373203754425
step: 340, loss: 0.043916963040828705
step: 350, loss: 0.2832009196281433
step: 360, loss: 0.09507795423269272
step: 370, loss: 0.10975909978151321
step: 380, loss: 0.03607465326786041
epoch 4: dev_f1=0.7454068241469817, f1=0.7186629526462396, best_f1=0.7230769230769232
step: 0, loss: 0.051908064633607864
step: 10, loss: 0.16829423606395721
step: 20, loss: 0.08278334885835648
step: 30, loss: 0.11580977588891983
step: 40, loss: 0.02229936607182026
step: 50, loss: 0.07394351810216904
step: 60, loss: 0.07247073948383331
step: 70, loss: 0.029531722888350487
step: 80, loss: 0.107786625623703
step: 90, loss: 0.1146317720413208
step: 100, loss: 0.06844951957464218
step: 110, loss: 0.05590181425213814
step: 120, loss: 0.057698752731084824
step: 130, loss: 0.2303348034620285
step: 140, loss: 0.07066639512777328
step: 150, loss: 0.09067846089601517
step: 160, loss: 0.055479682981967926
step: 170, loss: 0.038991063833236694
step: 180, loss: 0.07705169916152954
step: 190, loss: 0.04332705959677696
step: 200, loss: 0.05150243639945984
step: 210, loss: 0.010360359214246273
step: 220, loss: 0.048835914582014084
step: 230, loss: 0.11406590789556503
step: 240, loss: 0.24568279087543488
step: 250, loss: 0.11784345656633377
step: 260, loss: 0.005527948960661888
step: 270, loss: 0.15242499113082886
step: 280, loss: 0.22427739202976227
step: 290, loss: 0.06049100309610367
step: 300, loss: 0.04922259598970413
step: 310, loss: 0.07522493600845337
step: 320, loss: 0.1793481856584549
step: 330, loss: 0.10378038883209229
step: 340, loss: 0.056865986436605453
step: 350, loss: 0.03934234008193016
step: 360, loss: 0.08701495081186295
step: 370, loss: 0.041939638555049896
step: 380, loss: 0.14110884070396423
epoch 5: dev_f1=0.768421052631579, f1=0.7310704960835509, best_f1=0.7310704960835509
step: 0, loss: 0.07990404963493347
step: 10, loss: 0.09948842227458954
step: 20, loss: 0.00079639459727332
step: 30, loss: 0.0511133074760437
step: 40, loss: 0.01914251036942005
step: 50, loss: 0.034729115664958954
step: 60, loss: 0.01369511615484953
step: 70, loss: 0.18492907285690308
step: 80, loss: 0.012280041351914406
step: 90, loss: 0.04911394789814949
step: 100, loss: 0.005265533458441496
step: 110, loss: 0.07553116977214813
step: 120, loss: 0.09088439494371414
step: 130, loss: 0.07425986975431442
step: 140, loss: 0.07650629431009293
step: 150, loss: 0.04678034782409668
step: 160, loss: 0.12254901975393295
step: 170, loss: 0.08620835840702057
step: 180, loss: 0.10750163346529007
step: 190, loss: 0.1391102820634842
step: 200, loss: 0.08444689214229584
step: 210, loss: 0.06200186535716057
step: 220, loss: 0.06843903660774231
step: 230, loss: 0.059819430112838745
step: 240, loss: 0.22220253944396973
step: 250, loss: 0.06178000569343567
step: 260, loss: 0.09684509038925171
step: 270, loss: 0.071459099650383
step: 280, loss: 0.09522350132465363
step: 290, loss: 0.14193791151046753
step: 300, loss: 0.0816764160990715
step: 310, loss: 0.13855865597724915
step: 320, loss: 0.05713016912341118
step: 330, loss: 0.030704449862241745
step: 340, loss: 0.11284562200307846
step: 350, loss: 0.028331365436315536
step: 360, loss: 0.08235818892717361
step: 370, loss: 0.10888588428497314
step: 380, loss: 0.04241368919610977
epoch 6: dev_f1=0.76144578313253, f1=0.7093596059113301, best_f1=0.7310704960835509
step: 0, loss: 0.0881565511226654
step: 10, loss: 0.04995886608958244
step: 20, loss: 0.06374289095401764
step: 30, loss: 0.022080030292272568
step: 40, loss: 0.11927104741334915
step: 50, loss: 0.052084896713495255
step: 60, loss: 0.06867524236440659
step: 70, loss: 0.0015372720081359148
step: 80, loss: 0.05893472209572792
step: 90, loss: 0.07966714352369308
step: 100, loss: 0.03359311819076538
step: 110, loss: 0.020663267001509666
step: 120, loss: 0.15784479677677155
step: 130, loss: 0.0923299491405487
step: 140, loss: 0.083165243268013
step: 150, loss: 0.15021063387393951
step: 160, loss: 0.06922551989555359
step: 170, loss: 0.05990830808877945
step: 180, loss: 0.07060308009386063
step: 190, loss: 0.06537570804357529
step: 200, loss: 0.08534050732851028
step: 210, loss: 0.054565828293561935
step: 220, loss: 0.11646619439125061
step: 230, loss: 0.07136009633541107
step: 240, loss: 0.030010651797056198
step: 250, loss: 0.06182760000228882
step: 260, loss: 0.10073990374803543
step: 270, loss: 0.03724795952439308
step: 280, loss: 0.05781874433159828
step: 290, loss: 0.09128502011299133
step: 300, loss: 0.0037907634396106005
step: 310, loss: 0.06539645045995712
step: 320, loss: 0.04951498284935951
step: 330, loss: 0.0023650801740586758
step: 340, loss: 0.11519528180360794
step: 350, loss: 0.05975113809108734
step: 360, loss: 0.016965875402092934
step: 370, loss: 0.033322833478450775
step: 380, loss: 0.06531735509634018
epoch 7: dev_f1=0.7419354838709677, f1=0.6867749419953595, best_f1=0.7310704960835509
step: 0, loss: 0.07031335681676865
step: 10, loss: 0.08098524063825607
step: 20, loss: 0.024212084710597992
step: 30, loss: 0.05161595344543457
step: 40, loss: 0.020843056961894035
step: 50, loss: 0.10243817418813705
step: 60, loss: 0.0156561192125082
step: 70, loss: 0.050227317959070206
step: 80, loss: 0.03686101734638214
step: 90, loss: 0.021305060014128685
step: 100, loss: 0.007435494568198919
step: 110, loss: 0.26767000555992126
step: 120, loss: 0.0638054758310318
step: 130, loss: 0.03229314461350441
step: 140, loss: 0.1888374388217926
step: 150, loss: 0.05224449932575226
step: 160, loss: 0.1579507738351822
step: 170, loss: 0.0927259624004364
step: 180, loss: 0.04719065502285957
step: 190, loss: 0.026890695095062256
step: 200, loss: 0.07903797179460526
step: 210, loss: 0.045967232435941696
step: 220, loss: 0.1559390276670456
step: 230, loss: 0.017099803313612938
step: 240, loss: 0.10102566331624985
step: 250, loss: 0.07232281565666199
step: 260, loss: 0.031212152913212776
step: 270, loss: 0.05120359733700752
step: 280, loss: 0.07072508335113525
step: 290, loss: 0.03027268685400486
step: 300, loss: 0.15064042806625366
step: 310, loss: 0.021363424137234688
step: 320, loss: 0.030019966885447502
step: 330, loss: 0.05000189319252968
step: 340, loss: 0.0024623647332191467
step: 350, loss: 0.09255730360746384
step: 360, loss: 0.0569552518427372
step: 370, loss: 0.16520580649375916
step: 380, loss: 0.06181763857603073
epoch 8: dev_f1=0.7636363636363637, f1=0.7176781002638523, best_f1=0.7310704960835509
step: 0, loss: 0.1106981635093689
step: 10, loss: 0.04985044524073601
step: 20, loss: 0.04603477939963341
step: 30, loss: 0.041427530348300934
step: 40, loss: 0.04356526583433151
step: 50, loss: 0.01659342832863331
step: 60, loss: 0.06461493670940399
step: 70, loss: 0.06649571657180786
step: 80, loss: 0.00015411181084346026
step: 90, loss: 0.11958947032690048
step: 100, loss: 0.05042695999145508
step: 110, loss: 0.03133406490087509
step: 120, loss: 0.034538209438323975
step: 130, loss: 0.06076472997665405
step: 140, loss: 0.05636950954794884
step: 150, loss: 0.08914269506931305
step: 160, loss: 0.001620605238713324
step: 170, loss: 0.010505284182727337
step: 180, loss: 0.07965273410081863
step: 190, loss: 0.02174432761967182
step: 200, loss: 0.016359973698854446
step: 210, loss: 0.04830089211463928
step: 220, loss: 0.06431472301483154
step: 230, loss: 0.006247199140489101
step: 240, loss: 0.0286268163472414
step: 250, loss: 0.1357736736536026
step: 260, loss: 0.0572395883500576
step: 270, loss: 0.02659330889582634
step: 280, loss: 0.01816079393029213
step: 290, loss: 0.07766988128423691
step: 300, loss: 0.016383685171604156
step: 310, loss: 0.08290217816829681
step: 320, loss: 0.05405283719301224
step: 330, loss: 0.07457253336906433
step: 340, loss: 0.09053127467632294
step: 350, loss: 0.1304166615009308
step: 360, loss: 0.022641144692897797
step: 370, loss: 0.0888267233967781
step: 380, loss: 0.13456319272518158
epoch 9: dev_f1=0.7688172043010753, f1=0.709141274238227, best_f1=0.709141274238227
step: 0, loss: 0.0001538228098070249
step: 10, loss: 0.03422408178448677
step: 20, loss: 0.03042132407426834
step: 30, loss: 0.1577637791633606
step: 40, loss: 0.05435064435005188
step: 50, loss: 0.016663603484630585
step: 60, loss: 0.04150371626019478
step: 70, loss: 0.025678599253296852
step: 80, loss: 0.00954471342265606
step: 90, loss: 0.11066792905330658
step: 100, loss: 0.06934767961502075
step: 110, loss: 0.09335758537054062
step: 120, loss: 0.05888039618730545
step: 130, loss: 0.1388256698846817
step: 140, loss: 0.0016061534406617284
step: 150, loss: 0.07457589358091354
step: 160, loss: 0.06766487658023834
step: 170, loss: 0.12321651726961136
step: 180, loss: 0.009501508437097073
step: 190, loss: 0.0809146985411644
step: 200, loss: 0.022952860221266747
step: 210, loss: 0.2076895534992218
step: 220, loss: 0.011407132260501385
step: 230, loss: 0.041323546320199966
step: 240, loss: 0.047540321946144104
step: 250, loss: 0.05456027761101723
step: 260, loss: 0.10148118436336517
step: 270, loss: 0.057657912373542786
step: 280, loss: 0.21342845261096954
step: 290, loss: 0.041782911866903305
step: 300, loss: 0.08719993382692337
step: 310, loss: 0.08556549996137619
step: 320, loss: 0.08771335333585739
step: 330, loss: 0.06367947906255722
step: 340, loss: 0.04686935245990753
step: 350, loss: 0.06663112342357635
step: 360, loss: 0.11022955179214478
step: 370, loss: 0.093157097697258
step: 380, loss: 0.041451554745435715
epoch 10: dev_f1=0.7577319587628867, f1=0.7315789473684211, best_f1=0.709141274238227
step: 0, loss: 0.0212569460272789
step: 10, loss: 0.0529501847922802
step: 20, loss: 0.029312843456864357
step: 30, loss: 0.02838805504143238
step: 40, loss: 0.04704699665307999
step: 50, loss: 0.030422255396842957
step: 60, loss: 0.018178047612309456
step: 70, loss: 0.0003179553896188736
step: 80, loss: 0.08783667534589767
step: 90, loss: 0.03486984223127365
step: 100, loss: 0.002128365682438016
step: 110, loss: 0.08750738948583603
step: 120, loss: 4.20723226852715e-05
step: 130, loss: 0.030261505395174026
step: 140, loss: 0.036799199879169464
step: 150, loss: 0.011224454268813133
step: 160, loss: 0.05943620204925537
step: 170, loss: 0.07913582026958466
step: 180, loss: 0.1251249462366104
step: 190, loss: 0.030248017981648445
step: 200, loss: 0.06193815544247627
step: 210, loss: 0.001359378919005394
step: 220, loss: 0.01456189900636673
step: 230, loss: 0.06976819038391113
step: 240, loss: 0.041560690850019455
step: 250, loss: 0.04859376698732376
step: 260, loss: 0.0747278705239296
step: 270, loss: 0.05164945870637894
step: 280, loss: 0.030361322686076164
step: 290, loss: 0.04285860061645508
step: 300, loss: 0.1514560580253601
step: 310, loss: 0.10726994276046753
step: 320, loss: 0.06827989965677261
step: 330, loss: 0.007149640005081892
step: 340, loss: 0.03701390326023102
step: 350, loss: 0.08047451078891754
step: 360, loss: 0.07886280119419098
step: 370, loss: 0.09636838734149933
step: 380, loss: 0.0709715187549591
epoch 11: dev_f1=0.7641025641025642, f1=0.7405405405405405, best_f1=0.709141274238227
step: 0, loss: 0.0014986377209424973
step: 10, loss: 0.013611234724521637
step: 20, loss: 0.02953164279460907
step: 30, loss: 0.033509910106658936
step: 40, loss: 0.07796191424131393
step: 50, loss: 0.15072882175445557
step: 60, loss: 0.009044744074344635
step: 70, loss: 0.06896144896745682
step: 80, loss: 0.06917344778776169
step: 90, loss: 0.0960446372628212
step: 100, loss: 0.02945517748594284
step: 110, loss: 0.03280195966362953
step: 120, loss: 0.015448336489498615
step: 130, loss: 0.04052477702498436
step: 140, loss: 0.06467954069375992
step: 150, loss: 0.1254112720489502
step: 160, loss: 0.029088865965604782
step: 170, loss: 0.07316663861274719
step: 180, loss: 0.0928054228425026
step: 190, loss: 0.033050138503313065
step: 200, loss: 0.028368208557367325
step: 210, loss: 0.009707680903375149
step: 220, loss: 0.017155814915895462
step: 230, loss: 0.0075391363352537155
step: 240, loss: 0.03719034045934677
step: 250, loss: 0.05088286101818085
step: 260, loss: 0.07501789927482605
step: 270, loss: 0.013390181586146355
step: 280, loss: 0.0010360268643125892
step: 290, loss: 0.011474501341581345
step: 300, loss: 0.04954548180103302
step: 310, loss: 0.03611148148775101
step: 320, loss: 0.06543129682540894
step: 330, loss: 0.07318460941314697
step: 340, loss: 0.09358882904052734
step: 350, loss: 0.0031347349286079407
step: 360, loss: 0.03464489057660103
step: 370, loss: 0.07919648289680481
step: 380, loss: 0.043392013758420944
epoch 12: dev_f1=0.7586206896551724, f1=0.7197943444730078, best_f1=0.709141274238227
step: 0, loss: 0.05757543817162514
step: 10, loss: 0.0189402773976326
step: 20, loss: 0.05275467410683632
step: 30, loss: 0.04747358337044716
step: 40, loss: 0.0018501264275982976
step: 50, loss: 0.09715475887060165
step: 60, loss: 0.05097532644867897
step: 70, loss: 0.0013863918138667941
step: 80, loss: 0.0771995484828949
step: 90, loss: 0.009320157580077648
step: 100, loss: 0.09801147133111954
step: 110, loss: 0.03219567984342575
step: 120, loss: 0.031511832028627396
step: 130, loss: 0.057615429162979126
step: 140, loss: 0.05199933424592018
step: 150, loss: 0.05987461283802986
step: 160, loss: 0.029582468792796135
step: 170, loss: 0.035345062613487244
step: 180, loss: 0.05328512191772461
step: 190, loss: 0.13060489296913147
step: 200, loss: 0.1063680499792099
step: 210, loss: 0.04418431967496872
step: 220, loss: 0.03539341688156128
step: 230, loss: 0.07139822095632553
step: 240, loss: 0.04476568475365639
step: 250, loss: 0.017877940088510513
step: 260, loss: 0.01576288230717182
step: 270, loss: 0.007873374037444592
step: 280, loss: 0.006033375393599272
step: 290, loss: 0.006763170473277569
step: 300, loss: 0.0019846283830702305
step: 310, loss: 0.07977280020713806
step: 320, loss: 0.04766322672367096
step: 330, loss: 0.023905180394649506
step: 340, loss: 0.1224140003323555
step: 350, loss: 0.016977788880467415
step: 360, loss: 0.021303128451108932
step: 370, loss: 0.026141053065657616
step: 380, loss: 0.04408013075590134
epoch 13: dev_f1=0.7417840375586854, f1=0.7170731707317073, best_f1=0.709141274238227
step: 0, loss: 0.02532128617167473
step: 10, loss: 0.021876370534300804
step: 20, loss: 0.0507250651717186
step: 30, loss: 0.018376920372247696
step: 40, loss: 0.12536820769309998
step: 50, loss: 0.014278674498200417
step: 60, loss: 0.057800374925136566
step: 70, loss: 0.0013856750447303057
step: 80, loss: 0.058166615664958954
step: 90, loss: 0.1339568942785263
step: 100, loss: 0.03551957756280899
step: 110, loss: 0.07196573913097382
step: 120, loss: 0.00047296000411733985
step: 130, loss: 0.09400437772274017
step: 140, loss: 0.14057108759880066
step: 150, loss: 0.08507674187421799
step: 160, loss: 0.0555911548435688
step: 170, loss: 0.07780583947896957
step: 180, loss: 0.19166189432144165
step: 190, loss: 0.038750071078538895
step: 200, loss: 0.1553659588098526
step: 210, loss: 0.05068131908774376
step: 220, loss: 0.029128743335604668
step: 230, loss: 0.0019419798627495766
step: 240, loss: 0.041156500577926636
step: 250, loss: 0.024458253756165504
step: 260, loss: 0.03684469684958458
step: 270, loss: 0.09254388511180878
step: 280, loss: 0.05137208104133606
step: 290, loss: 0.016453873366117477
step: 300, loss: 0.010680596344172955
step: 310, loss: 0.15255139768123627
step: 320, loss: 0.10514575988054276
step: 330, loss: 0.15721873939037323
step: 340, loss: 0.09888367354869843
step: 350, loss: 0.024573607370257378
step: 360, loss: 0.017551742494106293
step: 370, loss: 0.08486123383045197
step: 380, loss: 0.0729956403374672
epoch 14: dev_f1=0.7308641975308642, f1=0.699228791773779, best_f1=0.709141274238227
step: 0, loss: 0.02107073739171028
step: 10, loss: 0.015060638077557087
step: 20, loss: 0.00988285057246685
step: 30, loss: 0.024080414324998856
step: 40, loss: 0.01957578770816326
step: 50, loss: 0.04270844906568527
step: 60, loss: 0.10857383161783218
step: 70, loss: 0.053571667522192
step: 80, loss: 0.052133798599243164
step: 90, loss: 0.03481684625148773
step: 100, loss: 0.0367782898247242
step: 110, loss: 0.06432509422302246
step: 120, loss: 0.0402408130466938
step: 130, loss: 0.029966767877340317
step: 140, loss: 0.05620935559272766
step: 150, loss: 0.0003983266942668706
step: 160, loss: 0.06057550758123398
step: 170, loss: 0.03306661173701286
step: 180, loss: 0.026590388268232346
step: 190, loss: 0.024912556633353233
step: 200, loss: 0.07270277291536331
step: 210, loss: 0.05216042697429657
step: 220, loss: 0.019772380590438843
step: 230, loss: 0.04035591334104538
step: 240, loss: 0.08603845536708832
step: 250, loss: 0.09149389714002609
step: 260, loss: 0.022626938298344612
step: 270, loss: 0.07138803601264954
step: 280, loss: 0.02362290397286415
step: 290, loss: 0.026394637301564217
step: 300, loss: 0.07813886553049088
step: 310, loss: 0.0068080248311161995
step: 320, loss: 0.01248541846871376
step: 330, loss: 0.035559818148612976
step: 340, loss: 0.09261387586593628
step: 350, loss: 6.072365431464277e-05
step: 360, loss: 0.014745847322046757
step: 370, loss: 0.08863916248083115
step: 380, loss: 0.03972601145505905
epoch 15: dev_f1=0.7244094488188976, f1=0.7084468664850135, best_f1=0.709141274238227
step: 0, loss: 0.01870843768119812
step: 10, loss: 0.028563616797327995
step: 20, loss: 0.03286665305495262
step: 30, loss: 0.04261438921093941
step: 40, loss: 0.017358381301164627
step: 50, loss: 0.05023375526070595
step: 60, loss: 0.08174194395542145
step: 70, loss: 0.09266230463981628
step: 80, loss: 0.0803644210100174
step: 90, loss: 0.035392679274082184
step: 100, loss: 0.03440230339765549
step: 110, loss: 0.08397963643074036
step: 120, loss: 0.034834444522857666
step: 130, loss: 0.06592007726430893
step: 140, loss: 0.02950725518167019
step: 150, loss: 0.01727931946516037
step: 160, loss: 0.025027791038155556
step: 170, loss: 0.10166811943054199
step: 180, loss: 0.15463200211524963
step: 190, loss: 0.006900487467646599
step: 200, loss: 0.030641959980130196
step: 210, loss: 0.05419464036822319
step: 220, loss: 0.025899112224578857
step: 230, loss: 0.012346738949418068
step: 240, loss: 0.00025551606086082757
step: 250, loss: 0.013321451842784882
step: 260, loss: 0.047809962183237076
step: 270, loss: 0.06436227262020111
step: 280, loss: 0.041507333517074585
step: 290, loss: 0.03176439553499222
step: 300, loss: 0.027465777471661568
step: 310, loss: 0.17879921197891235
step: 320, loss: 0.035298902541399
step: 330, loss: 0.03367866575717926
step: 340, loss: 0.08462237566709518
step: 350, loss: 0.13552720844745636
step: 360, loss: 0.007219655439257622
step: 370, loss: 0.00919626746326685
step: 380, loss: 0.012173887342214584
epoch 16: dev_f1=0.7161803713527852, f1=0.7127071823204421, best_f1=0.709141274238227
step: 0, loss: 0.017811428755521774
step: 10, loss: 0.05746977776288986
step: 20, loss: 0.04154905304312706
step: 30, loss: 0.02597540244460106
step: 40, loss: 0.052762310951948166
step: 50, loss: 0.037026263773441315
step: 60, loss: 0.07694628089666367
step: 70, loss: 0.015039678663015366
step: 80, loss: 0.09065066277980804
step: 90, loss: 0.010518672876060009
step: 100, loss: 0.04500782489776611
step: 110, loss: 0.0787622481584549
step: 120, loss: 0.0015284847468137741
step: 130, loss: 0.025448031723499298
step: 140, loss: 0.016871752217411995
step: 150, loss: 0.16065728664398193
step: 160, loss: 0.03315327689051628
step: 170, loss: 6.875467079225928e-05
step: 180, loss: 0.06462155282497406
step: 190, loss: 0.03691251575946808
step: 200, loss: 0.11166085302829742
step: 210, loss: 0.08753004670143127
step: 220, loss: 0.03284779563546181
step: 230, loss: 0.041484370827674866
step: 240, loss: 0.012146316468715668
step: 250, loss: 0.004274123813956976
step: 260, loss: 0.03746175020933151
step: 270, loss: 0.04589549079537392
step: 280, loss: 0.015842560678720474
step: 290, loss: 0.05428719148039818
step: 300, loss: 0.011325179599225521
step: 310, loss: 0.002463654847815633
step: 320, loss: 0.021385854110121727
step: 330, loss: 0.03732290118932724
step: 340, loss: 0.02190406247973442
step: 350, loss: 0.028815509751439095
step: 360, loss: 0.044872332364320755
step: 370, loss: 0.0017110399203374982
step: 380, loss: 0.03867026045918465
epoch 17: dev_f1=0.7168831168831169, f1=0.7119565217391304, best_f1=0.709141274238227
step: 0, loss: 0.06989902257919312
step: 10, loss: 0.008523445576429367
step: 20, loss: 0.02674751728773117
step: 30, loss: 0.011774483136832714
step: 40, loss: 0.03487832471728325
step: 50, loss: 0.030050065368413925
step: 60, loss: 0.019229531288146973
step: 70, loss: 0.008124137297272682
step: 80, loss: 0.015332721173763275
step: 90, loss: 0.058962926268577576
step: 100, loss: 0.0342528410255909
step: 110, loss: 0.03023494780063629
step: 120, loss: 0.1251770555973053
step: 130, loss: 4.9533227866049856e-05
step: 140, loss: 0.024060847237706184
step: 150, loss: 0.0246342234313488
step: 160, loss: 0.03572254255414009
step: 170, loss: 0.02941436693072319
step: 180, loss: 0.02819741517305374
step: 190, loss: 0.05595390871167183
step: 200, loss: 0.006295759230852127
step: 210, loss: 0.010101018473505974
step: 220, loss: 0.024371935054659843
step: 230, loss: 0.044891711324453354
step: 240, loss: 0.05690288171172142
step: 250, loss: 0.015817683190107346
step: 260, loss: 0.010491381399333477
step: 270, loss: 0.018165091052651405
step: 280, loss: 0.005077183712273836
step: 290, loss: 0.02538016438484192
step: 300, loss: 6.284593837335706e-05
step: 310, loss: 0.05854189023375511
step: 320, loss: 5.994810999254696e-05
step: 330, loss: 0.05702332407236099
step: 340, loss: 0.011485299095511436
step: 350, loss: 0.02501608431339264
step: 360, loss: 0.03318348899483681
step: 370, loss: 0.021620696410536766
step: 380, loss: 0.029875483363866806
epoch 18: dev_f1=0.6944444444444444, f1=0.6816901408450704, best_f1=0.709141274238227
step: 0, loss: 0.034982722252607346
step: 10, loss: 0.09120198339223862
step: 20, loss: 0.025266120210289955
step: 30, loss: 0.05440130829811096
step: 40, loss: 0.040655381977558136
step: 50, loss: 0.04792280122637749
step: 60, loss: 0.007325015962123871
step: 70, loss: 0.00474493857473135
step: 80, loss: 0.0698726624250412
step: 90, loss: 0.13107305765151978
step: 100, loss: 0.09646241366863251
step: 110, loss: 0.06311988830566406
step: 120, loss: 0.01159238163381815
step: 130, loss: 0.10301890969276428
step: 140, loss: 0.04538806155323982
step: 150, loss: 0.0052549829706549644
step: 160, loss: 0.010325508192181587
step: 170, loss: 0.008300661109387875
step: 180, loss: 0.05273161455988884
step: 190, loss: 0.007936050184071064
step: 200, loss: 0.02034715935587883
step: 210, loss: 0.09152188152074814
step: 220, loss: 0.06102319806814194
step: 230, loss: 0.06144486740231514
step: 240, loss: 0.019701210781931877
step: 250, loss: 0.08300498127937317
step: 260, loss: 0.006648502312600613
step: 270, loss: 0.06270351260900497
step: 280, loss: 0.04202503338456154
step: 290, loss: 0.012812264263629913
step: 300, loss: 0.004609581083059311
step: 310, loss: 0.013109295628964901
step: 320, loss: 0.055883344262838364
step: 330, loss: 0.009943114593625069
step: 340, loss: 0.00998824555426836
step: 350, loss: 4.361803803476505e-05
step: 360, loss: 0.004567927680909634
step: 370, loss: 0.004553656093776226
step: 380, loss: 0.0001055531611200422
epoch 19: dev_f1=0.6980609418282547, f1=0.6704871060171921, best_f1=0.709141274238227
step: 0, loss: 0.13815172016620636
step: 10, loss: 0.017979787662625313
step: 20, loss: 0.022101322188973427
step: 30, loss: 0.008408753201365471
step: 40, loss: 0.00025054969592019916
step: 50, loss: 0.04134785756468773
step: 60, loss: 0.08016614615917206
step: 70, loss: 0.00011355004244251177
step: 80, loss: 0.005138561595231295
step: 90, loss: 0.03597835823893547
step: 100, loss: 0.009621826931834221
step: 110, loss: 0.00196667923592031
step: 120, loss: 0.018718531355261803
step: 130, loss: 0.004510882776230574
step: 140, loss: 0.0433308370411396
step: 150, loss: 0.047645263373851776
step: 160, loss: 0.0701986700296402
step: 170, loss: 0.01461978629231453
step: 180, loss: 0.00024163693888112903
step: 190, loss: 5.575850445893593e-05
step: 200, loss: 0.07471495866775513
step: 210, loss: 0.061922311782836914
step: 220, loss: 0.039171189069747925
step: 230, loss: 0.028965292498469353
step: 240, loss: 0.09124713391065598
step: 250, loss: 0.0438976064324379
step: 260, loss: 0.02088124305009842
step: 270, loss: 0.025111490860581398
step: 280, loss: 0.03205493092536926
step: 290, loss: 0.05799464136362076
step: 300, loss: 0.05276042968034744
step: 310, loss: 0.00012197429896332324
step: 320, loss: 0.030780920758843422
step: 330, loss: 0.0046480619348585606
step: 340, loss: 0.06515465676784515
step: 350, loss: 0.00012314126070123166
step: 360, loss: 0.04461684450507164
step: 370, loss: 0.027577050030231476
step: 380, loss: 0.02039135992527008
epoch 20: dev_f1=0.7016574585635359, f1=0.6818181818181819, best_f1=0.709141274238227
