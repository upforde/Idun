cuda
Device: cuda
step: 0, loss: 0.5937055349349976
step: 10, loss: 0.30518975853919983
step: 20, loss: 0.4560256898403168
step: 30, loss: 0.3137895464897156
step: 40, loss: 0.5119006037712097
step: 50, loss: 0.3982708156108856
step: 60, loss: 0.1786927878856659
step: 70, loss: 0.487987220287323
step: 80, loss: 0.2503487467765808
step: 90, loss: 0.34232157468795776
step: 100, loss: 0.26978737115859985
step: 110, loss: 0.33061328530311584
step: 120, loss: 0.12014372646808624
step: 130, loss: 0.19895586371421814
step: 140, loss: 0.1579318344593048
step: 150, loss: 0.13840298354625702
step: 160, loss: 0.3044848144054413
step: 170, loss: 0.20292985439300537
step: 180, loss: 0.15657494962215424
step: 190, loss: 0.2740200161933899
step: 200, loss: 0.21198700368404388
step: 210, loss: 0.25556349754333496
step: 220, loss: 0.19603383541107178
step: 230, loss: 0.27365463972091675
step: 240, loss: 0.2572980225086212
step: 250, loss: 0.24442501366138458
step: 260, loss: 0.2735607326030731
step: 270, loss: 0.10363539308309555
step: 280, loss: 0.3087010383605957
step: 290, loss: 0.014165517874062061
step: 300, loss: 0.019846247509121895
step: 310, loss: 0.11508963257074356
step: 320, loss: 0.07885619252920151
step: 330, loss: 0.07002714276313782
step: 340, loss: 0.06610693037509918
step: 350, loss: 0.032949235290288925
step: 360, loss: 0.5709396004676819
step: 370, loss: 0.1269446462392807
step: 380, loss: 0.16315771639347076
epoch 1: dev_f1=0.6432160804020101, f1=0.6259168704156478, best_f1=0.6259168704156478
step: 0, loss: 0.15973688662052155
step: 10, loss: 0.14470042288303375
step: 20, loss: 0.15614089369773865
step: 30, loss: 0.155516117811203
step: 40, loss: 0.12297871708869934
step: 50, loss: 0.05607111379504204
step: 60, loss: 0.054707158356904984
step: 70, loss: 0.2434767186641693
step: 80, loss: 0.13750550150871277
step: 90, loss: 0.08378563076257706
step: 100, loss: 0.20372159779071808
step: 110, loss: 0.06287776678800583
step: 120, loss: 0.2358892858028412
step: 130, loss: 0.06031438335776329
step: 140, loss: 0.14383529126644135
step: 150, loss: 0.07030326128005981
step: 160, loss: 0.15779951214790344
step: 170, loss: 0.15045741200447083
step: 180, loss: 0.12985073029994965
step: 190, loss: 0.20774300396442413
step: 200, loss: 0.029677653685212135
step: 210, loss: 0.19515582919120789
step: 220, loss: 0.07727336883544922
step: 230, loss: 0.18728865683078766
step: 240, loss: 0.05114718899130821
step: 250, loss: 0.12252196669578552
step: 260, loss: 0.06215988099575043
step: 270, loss: 0.15535184741020203
step: 280, loss: 0.04287954047322273
step: 290, loss: 0.17070744931697845
step: 300, loss: 0.07925402373075485
step: 310, loss: 0.34617409110069275
step: 320, loss: 0.1381271928548813
step: 330, loss: 0.0889766737818718
step: 340, loss: 0.03872978314757347
step: 350, loss: 0.15189525485038757
step: 360, loss: 0.2483726143836975
step: 370, loss: 0.04030227288603783
step: 380, loss: 0.26762697100639343
epoch 2: dev_f1=0.7373493975903614, f1=0.7189873417721518, best_f1=0.7189873417721518
step: 0, loss: 0.09861820936203003
step: 10, loss: 0.15900999307632446
step: 20, loss: 0.11868183314800262
step: 30, loss: 0.11254149675369263
step: 40, loss: 0.058638669550418854
step: 50, loss: 0.12614427506923676
step: 60, loss: 0.2686651051044464
step: 70, loss: 0.08535236865282059
step: 80, loss: 0.3192679286003113
step: 90, loss: 0.10161963850259781
step: 100, loss: 0.1392141729593277
step: 110, loss: 0.1492626667022705
step: 120, loss: 0.08801785111427307
step: 130, loss: 0.07236551493406296
step: 140, loss: 0.13704627752304077
step: 150, loss: 0.05345427989959717
step: 160, loss: 0.24534806609153748
step: 170, loss: 0.21039067208766937
step: 180, loss: 0.13147369027137756
step: 190, loss: 0.05238736420869827
step: 200, loss: 0.05300227180123329
step: 210, loss: 0.08646955341100693
step: 220, loss: 0.07793638855218887
step: 230, loss: 0.07323205471038818
step: 240, loss: 0.1105647087097168
step: 250, loss: 0.14217747747898102
step: 260, loss: 0.10420489311218262
step: 270, loss: 0.04140934348106384
step: 280, loss: 0.15799489617347717
step: 290, loss: 0.04390297457575798
step: 300, loss: 0.03726016730070114
step: 310, loss: 0.12671561539173126
step: 320, loss: 0.022657770663499832
step: 330, loss: 0.1327490508556366
step: 340, loss: 0.16776134073734283
step: 350, loss: 0.11317569017410278
step: 360, loss: 0.3288925290107727
step: 370, loss: 0.19372738897800446
step: 380, loss: 0.13390810787677765
epoch 3: dev_f1=0.7545219638242895, f1=0.7268041237113403, best_f1=0.7268041237113403
step: 0, loss: 0.015192295424640179
step: 10, loss: 0.16886025667190552
step: 20, loss: 0.037503961473703384
step: 30, loss: 0.11318599432706833
step: 40, loss: 0.17082184553146362
step: 50, loss: 0.12203354388475418
step: 60, loss: 0.09145232290029526
step: 70, loss: 0.06236148625612259
step: 80, loss: 0.1257474720478058
step: 90, loss: 0.19577474892139435
step: 100, loss: 0.10624963790178299
step: 110, loss: 0.10461514443159103
step: 120, loss: 0.07470866292715073
step: 130, loss: 0.09357824176549911
step: 140, loss: 0.07967275381088257
step: 150, loss: 0.13747353851795197
step: 160, loss: 0.15515917539596558
step: 170, loss: 0.03931993618607521
step: 180, loss: 0.10210492461919785
step: 190, loss: 0.038480546325445175
step: 200, loss: 0.09254780411720276
step: 210, loss: 0.10737386345863342
step: 220, loss: 0.10756845772266388
step: 230, loss: 0.13229113817214966
step: 240, loss: 0.10156804323196411
step: 250, loss: 0.07642529159784317
step: 260, loss: 0.013509710319340229
step: 270, loss: 0.17707784473896027
step: 280, loss: 0.14009913802146912
step: 290, loss: 0.009927099570631981
step: 300, loss: 0.2098412662744522
step: 310, loss: 0.04602234810590744
step: 320, loss: 0.18488924205303192
step: 330, loss: 0.08673564344644547
step: 340, loss: 0.13951817154884338
step: 350, loss: 0.03344419226050377
step: 360, loss: 0.0758482962846756
step: 370, loss: 0.018209056928753853
step: 380, loss: 0.1940227895975113
epoch 4: dev_f1=0.7810945273631841, f1=0.7630922693266835, best_f1=0.7630922693266835
step: 0, loss: 0.08934535086154938
step: 10, loss: 0.13576357066631317
step: 20, loss: 0.09650878608226776
step: 30, loss: 0.10842163115739822
step: 40, loss: 0.04002844914793968
step: 50, loss: 0.0766155868768692
step: 60, loss: 0.11545239388942719
step: 70, loss: 0.0915502980351448
step: 80, loss: 0.10180466622114182
step: 90, loss: 0.1861085146665573
step: 100, loss: 0.05244024842977524
step: 110, loss: 0.06324254721403122
step: 120, loss: 0.035777702927589417
step: 130, loss: 0.07298175245523453
step: 140, loss: 0.0738147646188736
step: 150, loss: 0.04320034757256508
step: 160, loss: 0.14760464429855347
step: 170, loss: 0.032055359333753586
step: 180, loss: 0.119109608232975
step: 190, loss: 0.03215731680393219
step: 200, loss: 0.054623037576675415
step: 210, loss: 0.09609431028366089
step: 220, loss: 0.1972091943025589
step: 230, loss: 0.22078368067741394
step: 240, loss: 0.03139687329530716
step: 250, loss: 0.09046756476163864
step: 260, loss: 0.136264368891716
step: 270, loss: 0.040035560727119446
step: 280, loss: 0.08649149537086487
step: 290, loss: 0.029319265857338905
step: 300, loss: 0.042565058916807175
step: 310, loss: 0.09787409007549286
step: 320, loss: 0.08833947777748108
step: 330, loss: 0.056509073823690414
step: 340, loss: 0.12476269900798798
step: 350, loss: 0.2448616623878479
step: 360, loss: 0.02301744557917118
step: 370, loss: 0.15911290049552917
step: 380, loss: 0.030375396832823753
epoch 5: dev_f1=0.7727272727272727, f1=0.7636363636363637, best_f1=0.7630922693266835
step: 0, loss: 0.08007132261991501
step: 10, loss: 0.08264485746622086
step: 20, loss: 0.11442993581295013
step: 30, loss: 0.05816396325826645
step: 40, loss: 0.15066209435462952
step: 50, loss: 0.024911288172006607
step: 60, loss: 0.05885687842965126
step: 70, loss: 0.0708201676607132
step: 80, loss: 0.09068538248538971
step: 90, loss: 0.049811553210020065
step: 100, loss: 0.06539591401815414
step: 110, loss: 0.07569031417369843
step: 120, loss: 0.15170902013778687
step: 130, loss: 0.1562858372926712
step: 140, loss: 0.08281761407852173
step: 150, loss: 0.08572790771722794
step: 160, loss: 0.04227709025144577
step: 170, loss: 0.06589167565107346
step: 180, loss: 0.05725723132491112
step: 190, loss: 0.08417051285505295
step: 200, loss: 0.08626023679971695
step: 210, loss: 0.03548420965671539
step: 220, loss: 0.1018691286444664
step: 230, loss: 0.11001609265804291
step: 240, loss: 0.2573665678501129
step: 250, loss: 0.046601954847574234
step: 260, loss: 0.07710203528404236
step: 270, loss: 0.07527011632919312
step: 280, loss: 0.07725930213928223
step: 290, loss: 0.07770384103059769
step: 300, loss: 0.02467712201178074
step: 310, loss: 0.06018625572323799
step: 320, loss: 0.1509033441543579
step: 330, loss: 0.05969163030385971
step: 340, loss: 0.08293382823467255
step: 350, loss: 0.07719925045967102
step: 360, loss: 0.044178418815135956
step: 370, loss: 0.0888284295797348
step: 380, loss: 0.07167432457208633
epoch 6: dev_f1=0.7578947368421052, f1=0.7225130890052356, best_f1=0.7630922693266835
step: 0, loss: 0.09288857877254486
step: 10, loss: 0.09801892191171646
step: 20, loss: 0.040938522666692734
step: 30, loss: 0.024517729878425598
step: 40, loss: 0.008934173732995987
step: 50, loss: 0.07258148491382599
step: 60, loss: 0.06150658428668976
step: 70, loss: 0.006733879446983337
step: 80, loss: 0.0016200505197048187
step: 90, loss: 0.06243434548377991
step: 100, loss: 0.15233846008777618
step: 110, loss: 0.03463597595691681
step: 120, loss: 0.117217056453228
step: 130, loss: 0.02489933930337429
step: 140, loss: 0.041708432137966156
step: 150, loss: 0.07209689170122147
step: 160, loss: 0.06935368478298187
step: 170, loss: 0.1388205736875534
step: 180, loss: 0.09898548573255539
step: 190, loss: 0.01583053544163704
step: 200, loss: 0.09113886952400208
step: 210, loss: 0.047122590243816376
step: 220, loss: 0.16308672726154327
step: 230, loss: 0.06637009233236313
step: 240, loss: 0.040777020156383514
step: 250, loss: 0.05826430767774582
step: 260, loss: 0.10811018943786621
step: 270, loss: 0.03581361100077629
step: 280, loss: 0.06458663940429688
step: 290, loss: 0.1324204057455063
step: 300, loss: 0.08176271617412567
step: 310, loss: 0.08233406394720078
step: 320, loss: 0.07374582439661026
step: 330, loss: 0.053067903965711594
step: 340, loss: 0.026197947561740875
step: 350, loss: 0.03910638019442558
step: 360, loss: 0.15788227319717407
step: 370, loss: 0.057222794741392136
step: 380, loss: 0.0283771101385355
epoch 7: dev_f1=0.7473684210526317, f1=0.7229551451187335, best_f1=0.7630922693266835
step: 0, loss: 0.05434824153780937
step: 10, loss: 0.08578217774629593
step: 20, loss: 0.16553539037704468
step: 30, loss: 0.11436258256435394
step: 40, loss: 0.07556986063718796
step: 50, loss: 0.07367859780788422
step: 60, loss: 0.07799340784549713
step: 70, loss: 0.05635767802596092
step: 80, loss: 0.028823114931583405
step: 90, loss: 0.08325221389532089
step: 100, loss: 0.14814241230487823
step: 110, loss: 0.02910446748137474
step: 120, loss: 0.005682462826371193
step: 130, loss: 0.04031787067651749
step: 140, loss: 0.06896904855966568
step: 150, loss: 0.01616489142179489
step: 160, loss: 0.1437583863735199
step: 170, loss: 0.06636189669370651
step: 180, loss: 0.07027512788772583
step: 190, loss: 0.07028473168611526
step: 200, loss: 0.022888895124197006
step: 210, loss: 0.08879102766513824
step: 220, loss: 0.12008161842823029
step: 230, loss: 0.047307275235652924
step: 240, loss: 0.10676390677690506
step: 250, loss: 0.06275726109743118
step: 260, loss: 0.0438186340034008
step: 270, loss: 0.04288669303059578
step: 280, loss: 0.0460822619497776
step: 290, loss: 0.024996059015393257
step: 300, loss: 0.1003984808921814
step: 310, loss: 0.08738628029823303
step: 320, loss: 0.08182552456855774
step: 330, loss: 0.033767640590667725
step: 340, loss: 0.09232517331838608
step: 350, loss: 0.07222452759742737
step: 360, loss: 0.03514726087450981
step: 370, loss: 0.08465678989887238
step: 380, loss: 0.06366518884897232
epoch 8: dev_f1=0.7506172839506173, f1=0.761904761904762, best_f1=0.7630922693266835
step: 0, loss: 0.0033645490184426308
step: 10, loss: 0.006599568296223879
step: 20, loss: 0.11667238175868988
step: 30, loss: 0.05581815168261528
step: 40, loss: 0.06099709868431091
step: 50, loss: 0.11568406224250793
step: 60, loss: 0.01683821901679039
step: 70, loss: 0.0029895741026848555
step: 80, loss: 0.05416842922568321
step: 90, loss: 0.0672416016459465
step: 100, loss: 0.06162526458501816
step: 110, loss: 0.04124891012907028
step: 120, loss: 0.0845692902803421
step: 130, loss: 0.04942411184310913
step: 140, loss: 0.011818887665867805
step: 150, loss: 0.19576099514961243
step: 160, loss: 0.07178303599357605
step: 170, loss: 0.04228353500366211
step: 180, loss: 0.10013584792613983
step: 190, loss: 0.015754729509353638
step: 200, loss: 0.031253084540367126
step: 210, loss: 0.0372588187456131
step: 220, loss: 0.06738394498825073
step: 230, loss: 0.08234371989965439
step: 240, loss: 0.03634319081902504
step: 250, loss: 0.10765181481838226
step: 260, loss: 0.026554049924016
step: 270, loss: 0.06363643705844879
step: 280, loss: 0.04329237341880798
step: 290, loss: 0.00046083133202046156
step: 300, loss: 0.0017456376226618886
step: 310, loss: 0.08251408487558365
step: 320, loss: 0.07080501317977905
step: 330, loss: 0.2088991403579712
step: 340, loss: 0.11376544088125229
step: 350, loss: 0.03795522451400757
step: 360, loss: 0.166342094540596
step: 370, loss: 0.09033631533384323
step: 380, loss: 0.11706138402223587
epoch 9: dev_f1=0.7191601049868767, f1=0.7184986595174263, best_f1=0.7630922693266835
step: 0, loss: 0.012832163833081722
step: 10, loss: 0.13157153129577637
step: 20, loss: 0.045551788061857224
step: 30, loss: 0.07439929246902466
step: 40, loss: 0.06301737576723099
step: 50, loss: 0.025526879355311394
step: 60, loss: 0.10779325664043427
step: 70, loss: 0.09359477460384369
step: 80, loss: 0.08031796663999557
step: 90, loss: 0.05846203491091728
step: 100, loss: 0.05140256509184837
step: 110, loss: 0.0398426428437233
step: 120, loss: 0.13301023840904236
step: 130, loss: 0.02378946729004383
step: 140, loss: 0.05870310962200165
step: 150, loss: 0.1259138286113739
step: 160, loss: 0.028136761859059334
step: 170, loss: 0.018639778718352318
step: 180, loss: 0.10428080707788467
step: 190, loss: 0.09643644839525223
step: 200, loss: 0.06712886691093445
step: 210, loss: 0.19503477215766907
step: 220, loss: 0.02143748849630356
step: 230, loss: 0.04010762646794319
step: 240, loss: 0.02696061134338379
step: 250, loss: 0.031983762979507446
step: 260, loss: 0.09526436775922775
step: 270, loss: 0.04145398363471031
step: 280, loss: 0.12035578489303589
step: 290, loss: 0.04929235950112343
step: 300, loss: 0.026951458305120468
step: 310, loss: 0.05774642527103424
step: 320, loss: 0.02420184202492237
step: 330, loss: 0.1564115583896637
step: 340, loss: 0.07179789245128632
step: 350, loss: 0.047510165721178055
step: 360, loss: 0.0007250774069689214
step: 370, loss: 0.02330373041331768
step: 380, loss: 0.06049741059541702
epoch 10: dev_f1=0.748663101604278, f1=0.7303370786516852, best_f1=0.7630922693266835
step: 0, loss: 0.08957386016845703
step: 10, loss: 0.07443482428789139
step: 20, loss: 0.10375448316335678
step: 30, loss: 0.10707414150238037
step: 40, loss: 0.10079926997423172
step: 50, loss: 0.06240538880228996
step: 60, loss: 0.10583895444869995
step: 70, loss: 0.0792880430817604
step: 80, loss: 0.09881647676229477
step: 90, loss: 0.047625623643398285
step: 100, loss: 0.0652700811624527
step: 110, loss: 0.0758533701300621
step: 120, loss: 0.057090189307928085
step: 130, loss: 0.013162885792553425
step: 140, loss: 0.05887175723910332
step: 150, loss: 0.12253628671169281
step: 160, loss: 0.00021313408797141165
step: 170, loss: 0.1939399689435959
step: 180, loss: 0.1310034692287445
step: 190, loss: 0.05016757920384407
step: 200, loss: 0.04573921114206314
step: 210, loss: 0.05355231836438179
step: 220, loss: 0.022665899246931076
step: 230, loss: 0.07940320670604706
step: 240, loss: 0.055288176983594894
step: 250, loss: 0.08438102155923843
step: 260, loss: 0.00018128259398508817
step: 270, loss: 0.05309934541583061
step: 280, loss: 0.1010085940361023
step: 290, loss: 0.032439082860946655
step: 300, loss: 0.02300778590142727
step: 310, loss: 0.020317379385232925
step: 320, loss: 0.0020094348583370447
step: 330, loss: 0.03906618058681488
step: 340, loss: 0.1062653437256813
step: 350, loss: 0.1602829098701477
step: 360, loss: 0.07297581434249878
step: 370, loss: 0.027281958609819412
step: 380, loss: 0.08536934852600098
epoch 11: dev_f1=0.7309644670050761, f1=0.7164948453608248, best_f1=0.7630922693266835
step: 0, loss: 0.07336623966693878
step: 10, loss: 0.052894510328769684
step: 20, loss: 0.10094574093818665
step: 30, loss: 0.05783332511782646
step: 40, loss: 0.0711727887392044
step: 50, loss: 0.045942310243844986
step: 60, loss: 0.05527566000819206
step: 70, loss: 0.047678619623184204
step: 80, loss: 0.05190933868288994
step: 90, loss: 0.10116739571094513
step: 100, loss: 0.04352649673819542
step: 110, loss: 0.02984490804374218
step: 120, loss: 0.10315148532390594
step: 130, loss: 0.08924352377653122
step: 140, loss: 0.08757129311561584
step: 150, loss: 0.06065259501338005
step: 160, loss: 0.12900274991989136
step: 170, loss: 0.04426872357726097
step: 180, loss: 0.0860944539308548
step: 190, loss: 0.07019156962633133
step: 200, loss: 0.036438941955566406
step: 210, loss: 0.11432085186243057
step: 220, loss: 0.07127244770526886
step: 230, loss: 0.07809276878833771
step: 240, loss: 0.04982146993279457
step: 250, loss: 0.13799943029880524
step: 260, loss: 0.038032930344343185
step: 270, loss: 0.07782438397407532
step: 280, loss: 0.04589519649744034
step: 290, loss: 0.11100811511278152
step: 300, loss: 0.06926319003105164
step: 310, loss: 0.039430368691682816
step: 320, loss: 0.07404738664627075
step: 330, loss: 0.08806125819683075
step: 340, loss: 0.04009860381484032
step: 350, loss: 0.10943475365638733
step: 360, loss: 0.051047373563051224
step: 370, loss: 0.11378102004528046
step: 380, loss: 0.07166992872953415
epoch 12: dev_f1=0.7481662591687043, f1=0.7157360406091372, best_f1=0.7630922693266835
step: 0, loss: 0.07233889400959015
step: 10, loss: 0.06460993736982346
step: 20, loss: 0.07740285247564316
step: 30, loss: 0.059632088989019394
step: 40, loss: 0.08025040477514267
step: 50, loss: 0.04203830659389496
step: 60, loss: 0.020614955574274063
step: 70, loss: 0.04275386407971382
step: 80, loss: 0.01498312409967184
step: 90, loss: 0.06905125081539154
step: 100, loss: 0.08617262542247772
step: 110, loss: 0.037449393421411514
step: 120, loss: 0.1029338464140892
step: 130, loss: 0.02564992569386959
step: 140, loss: 0.06355087459087372
step: 150, loss: 0.08362500369548798
step: 160, loss: 0.11100704967975616
step: 170, loss: 0.08857028931379318
step: 180, loss: 0.020396966487169266
step: 190, loss: 0.030873090028762817
step: 200, loss: 0.04154070094227791
step: 210, loss: 0.03851531445980072
step: 220, loss: 0.09429344534873962
step: 230, loss: 0.04709069803357124
step: 240, loss: 0.0004316579143051058
step: 250, loss: 0.036561060696840286
step: 260, loss: 0.14542850852012634
step: 270, loss: 0.04557791352272034
step: 280, loss: 0.024489155039191246
step: 290, loss: 0.04957108944654465
step: 300, loss: 0.07065258175134659
step: 310, loss: 0.05248558521270752
step: 320, loss: 0.027125617489218712
step: 330, loss: 0.088217593729496
step: 340, loss: 0.10907294601202011
step: 350, loss: 0.07736017554998398
step: 360, loss: 0.09617006778717041
step: 370, loss: 0.04701825976371765
step: 380, loss: 0.14571288228034973
epoch 13: dev_f1=0.7329842931937172, f1=0.7401574803149608, best_f1=0.7630922693266835
step: 0, loss: 0.04801886901259422
step: 10, loss: 0.11818719655275345
step: 20, loss: 0.04181097075343132
step: 30, loss: 0.08193498849868774
step: 40, loss: 0.05571362376213074
step: 50, loss: 0.01736946403980255
step: 60, loss: 0.08145877718925476
step: 70, loss: 0.05587397888302803
step: 80, loss: 0.07834377139806747
step: 90, loss: 0.02953767217695713
step: 100, loss: 0.019234295934438705
step: 110, loss: 0.04468071833252907
step: 120, loss: 0.053239937871694565
step: 130, loss: 0.022174255922436714
step: 140, loss: 0.09369482845067978
step: 150, loss: 0.06923674046993256
step: 160, loss: 0.0951259657740593
step: 170, loss: 0.07295321673154831
step: 180, loss: 0.07715806365013123
step: 190, loss: 0.016804520040750504
step: 200, loss: 0.11690744012594223
step: 210, loss: 0.06626832485198975
step: 220, loss: 0.050020981580019
step: 230, loss: 0.05897299200296402
step: 240, loss: 0.07400475442409515
step: 250, loss: 0.11384498327970505
step: 260, loss: 0.07428348809480667
step: 270, loss: 0.14675840735435486
step: 280, loss: 0.015807069838047028
step: 290, loss: 8.382517262361944e-05
step: 300, loss: 0.05553186684846878
step: 310, loss: 0.024723216891288757
step: 320, loss: 0.08977670222520828
step: 330, loss: 0.06701523065567017
step: 340, loss: 0.07553112506866455
step: 350, loss: 0.05843355879187584
step: 360, loss: 0.17623618245124817
step: 370, loss: 0.08117149025201797
step: 380, loss: 0.02501162514090538
epoch 14: dev_f1=0.7219512195121951, f1=0.6903553299492386, best_f1=0.7630922693266835
step: 0, loss: 0.08141359686851501
step: 10, loss: 0.05044589936733246
step: 20, loss: 0.07907083630561829
step: 30, loss: 0.04106183350086212
step: 40, loss: 0.09280505776405334
step: 50, loss: 0.021802186965942383
step: 60, loss: 0.0508388914167881
step: 70, loss: 0.08160838484764099
step: 80, loss: 0.03368246182799339
step: 90, loss: 0.08387742936611176
step: 100, loss: 0.05577212572097778
step: 110, loss: 0.03558920696377754
step: 120, loss: 0.031567905098199844
step: 130, loss: 0.015522638335824013
step: 140, loss: 0.026083000004291534
step: 150, loss: 0.08600976318120956
step: 160, loss: 0.043785370886325836
step: 170, loss: 0.056605927646160126
step: 180, loss: 0.1596507579088211
step: 190, loss: 0.03547752648591995
step: 200, loss: 0.05192034691572189
step: 210, loss: 0.021601181477308273
step: 220, loss: 0.013638440519571304
step: 230, loss: 0.08705159276723862
step: 240, loss: 0.042744144797325134
step: 250, loss: 0.06042838841676712
step: 260, loss: 0.030584314838051796
step: 270, loss: 0.13310734927654266
step: 280, loss: 0.15008406341075897
step: 290, loss: 0.05002180114388466
step: 300, loss: 0.061042752116918564
step: 310, loss: 0.04358532652258873
step: 320, loss: 0.044369809329509735
step: 330, loss: 0.05392039194703102
step: 340, loss: 0.18007966876029968
step: 350, loss: 0.0140774454921484
step: 360, loss: 0.05692242085933685
step: 370, loss: 0.09357082098722458
step: 380, loss: 0.02233070321381092
epoch 15: dev_f1=0.7252747252747253, f1=0.7011494252873564, best_f1=0.7630922693266835
step: 0, loss: 0.10484166443347931
step: 10, loss: 0.10133015364408493
step: 20, loss: 0.05255549028515816
step: 30, loss: 0.01595417596399784
step: 40, loss: 0.024942537769675255
step: 50, loss: 0.12010475993156433
step: 60, loss: 0.031447675079107285
step: 70, loss: 0.0180532094091177
step: 80, loss: 0.04892774671316147
step: 90, loss: 0.034402310848236084
step: 100, loss: 0.027261165902018547
step: 110, loss: 0.0003867295745294541
step: 120, loss: 0.0006598148611374199
step: 130, loss: 0.01564517244696617
step: 140, loss: 0.028210915625095367
step: 150, loss: 0.09168162196874619
step: 160, loss: 0.03570385277271271
step: 170, loss: 0.04573444649577141
step: 180, loss: 0.006608226336538792
step: 190, loss: 0.009047551080584526
step: 200, loss: 0.04141988977789879
step: 210, loss: 0.04433654248714447
step: 220, loss: 0.043474916368722916
step: 230, loss: 0.034207481890916824
step: 240, loss: 0.05371113121509552
step: 250, loss: 0.06444864720106125
step: 260, loss: 0.03637716919183731
step: 270, loss: 0.0176763366907835
step: 280, loss: 0.05205655097961426
step: 290, loss: 0.02609437145292759
step: 300, loss: 0.00012180317571619526
step: 310, loss: 0.018257489427924156
step: 320, loss: 0.03616523742675781
step: 330, loss: 0.06231937184929848
step: 340, loss: 0.08918668329715729
step: 350, loss: 0.07892128080129623
step: 360, loss: 0.030553724616765976
step: 370, loss: 0.1127769723534584
step: 380, loss: 0.07292475551366806
epoch 16: dev_f1=0.736842105263158, f1=0.7202072538860104, best_f1=0.7630922693266835
step: 0, loss: 0.047053609043359756
step: 10, loss: 0.03777685761451721
step: 20, loss: 0.13513724505901337
step: 30, loss: 0.024254607036709785
step: 40, loss: 0.05005589872598648
step: 50, loss: 0.07079239189624786
step: 60, loss: 0.04189114645123482
step: 70, loss: 0.00923524983227253
step: 80, loss: 0.09281516820192337
step: 90, loss: 0.0013740541180595756
step: 100, loss: 0.05242820084095001
step: 110, loss: 0.0570722296833992
step: 120, loss: 0.030220113694667816
step: 130, loss: 0.023803047835826874
step: 140, loss: 0.019718628376722336
step: 150, loss: 0.03933420777320862
step: 160, loss: 0.004238671623170376
step: 170, loss: 0.009998822584748268
step: 180, loss: 0.056879475712776184
step: 190, loss: 0.05618470907211304
step: 200, loss: 0.11040244996547699
step: 210, loss: 0.04231896996498108
step: 220, loss: 0.05060344561934471
step: 230, loss: 0.1475204974412918
step: 240, loss: 0.0700196698307991
step: 250, loss: 0.08159394562244415
step: 260, loss: 0.07318593561649323
step: 270, loss: 0.02423928678035736
step: 280, loss: 0.05768457427620888
step: 290, loss: 0.09280892461538315
step: 300, loss: 0.007649021688848734
step: 310, loss: 0.006717185489833355
step: 320, loss: 0.0768836960196495
step: 330, loss: 0.0044502015225589275
step: 340, loss: 0.0325411893427372
step: 350, loss: 0.08263836801052094
step: 360, loss: 0.14473065733909607
step: 370, loss: 0.01716013252735138
step: 380, loss: 0.05950068309903145
epoch 17: dev_f1=0.7247956403269755, f1=0.6743515850144093, best_f1=0.7630922693266835
step: 0, loss: 0.07933943718671799
step: 10, loss: 0.10775262117385864
step: 20, loss: 0.12026885151863098
step: 30, loss: 0.04804578423500061
step: 40, loss: 0.026125632226467133
step: 50, loss: 0.053328413516283035
step: 60, loss: 0.02651371620595455
step: 70, loss: 0.0281804371625185
step: 80, loss: 0.05032265931367874
step: 90, loss: 0.06768779456615448
step: 100, loss: 0.12384698539972305
step: 110, loss: 0.012553076259791851
step: 120, loss: 0.04814154654741287
step: 130, loss: 0.030632534995675087
step: 140, loss: 9.14234624360688e-05
step: 150, loss: 0.020110653713345528
step: 160, loss: 0.0069185895845294
step: 170, loss: 0.0006435626419261098
step: 180, loss: 0.1288454532623291
step: 190, loss: 0.001088985474780202
step: 200, loss: 0.11669223755598068
step: 210, loss: 0.026833971962332726
step: 220, loss: 3.229740104870871e-05
step: 230, loss: 0.045771658420562744
step: 240, loss: 0.018751349300146103
step: 250, loss: 0.016113396733999252
step: 260, loss: 0.0440390408039093
step: 270, loss: 0.11028968542814255
step: 280, loss: 0.011316346004605293
step: 290, loss: 0.004982799291610718
step: 300, loss: 0.034453097730875015
step: 310, loss: 0.19097252190113068
step: 320, loss: 0.04653581231832504
step: 330, loss: 0.11085694283246994
step: 340, loss: 0.07363191246986389
step: 350, loss: 0.07008663564920425
step: 360, loss: 0.03444990888237953
step: 370, loss: 0.024434510618448257
step: 380, loss: 0.034984275698661804
epoch 18: dev_f1=0.7174447174447175, f1=0.693121693121693, best_f1=0.7630922693266835
step: 0, loss: 0.03575240448117256
step: 10, loss: 0.026050440967082977
step: 20, loss: 5.5638563935644925e-05
step: 30, loss: 0.06343763321638107
step: 40, loss: 0.0680449903011322
step: 50, loss: 0.02515341527760029
step: 60, loss: 0.1360178142786026
step: 70, loss: 0.08807190507650375
step: 80, loss: 0.017922228202223778
step: 90, loss: 0.028582578524947166
step: 100, loss: 0.04212576150894165
step: 110, loss: 3.418955020606518e-05
step: 120, loss: 0.03553229942917824
step: 130, loss: 0.1015460416674614
step: 140, loss: 8.980149868875742e-05
step: 150, loss: 0.0017118984833359718
step: 160, loss: 0.012943710200488567
step: 170, loss: 0.09444290399551392
step: 180, loss: 0.0014048146549612284
step: 190, loss: 0.10900488495826721
step: 200, loss: 0.019572608172893524
step: 210, loss: 0.03690752014517784
step: 220, loss: 0.029619796201586723
step: 230, loss: 0.030043624341487885
step: 240, loss: 0.008348725736141205
step: 250, loss: 0.029673872515559196
step: 260, loss: 4.35793335782364e-05
step: 270, loss: 0.03885294497013092
step: 280, loss: 0.0303113404661417
step: 290, loss: 0.02501833811402321
step: 300, loss: 0.04114089906215668
step: 310, loss: 0.046421200037002563
step: 320, loss: 0.017129112035036087
step: 330, loss: 0.049594081938266754
step: 340, loss: 0.04578455165028572
step: 350, loss: 0.0008153684320859611
step: 360, loss: 0.09748921543359756
step: 370, loss: 0.032611433416604996
step: 380, loss: 0.04409308731555939
epoch 19: dev_f1=0.7078651685393258, f1=0.6705539358600584, best_f1=0.7630922693266835
step: 0, loss: 0.03644896298646927
step: 10, loss: 0.10031655430793762
step: 20, loss: 2.5067000024137087e-05
step: 30, loss: 0.008533522486686707
step: 40, loss: 0.01350333634763956
step: 50, loss: 0.13941411674022675
step: 60, loss: 0.010226218029856682
step: 70, loss: 0.047986578196287155
step: 80, loss: 0.06301580369472504
step: 90, loss: 0.03340987116098404
step: 100, loss: 0.02202269621193409
step: 110, loss: 0.0026279736775904894
step: 120, loss: 0.01954398676753044
step: 130, loss: 0.06472162902355194
step: 140, loss: 0.04710236191749573
step: 150, loss: 0.011429402977228165
step: 160, loss: 0.05658057704567909
step: 170, loss: 0.06045982614159584
step: 180, loss: 0.02402152121067047
step: 190, loss: 0.06260301172733307
step: 200, loss: 0.03395073860883713
step: 210, loss: 0.004736636765301228
step: 220, loss: 0.03168021887540817
step: 230, loss: 0.001323889009654522
step: 240, loss: 0.044152531772851944
step: 250, loss: 0.045847758650779724
step: 260, loss: 0.03749031946063042
step: 270, loss: 0.08422887325286865
step: 280, loss: 0.02190633863210678
step: 290, loss: 0.0667530819773674
step: 300, loss: 3.8846133975312114e-05
step: 310, loss: 0.05626450106501579
step: 320, loss: 0.03034335747361183
step: 330, loss: 0.048980168998241425
step: 340, loss: 0.04432031512260437
step: 350, loss: 0.015114306472241879
step: 360, loss: 0.04951326176524162
step: 370, loss: 0.037257712334394455
step: 380, loss: 0.03715931624174118
epoch 20: dev_f1=0.7081081081081081, f1=0.6875, best_f1=0.7630922693266835
