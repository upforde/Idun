cuda
Device: cuda
step: 0, loss: 0.8050146698951721
step: 10, loss: 0.05823706090450287
step: 20, loss: 0.25496092438697815
step: 30, loss: 0.3149677515029907
step: 40, loss: 0.5559104084968567
step: 50, loss: 0.31186556816101074
step: 60, loss: 0.16087743639945984
step: 70, loss: 0.23760777711868286
step: 80, loss: 0.4252656400203705
step: 90, loss: 0.37972310185432434
step: 100, loss: 0.35868173837661743
step: 110, loss: 0.345324844121933
step: 120, loss: 0.19068248569965363
step: 130, loss: 0.26360777020454407
step: 140, loss: 0.05834193155169487
step: 150, loss: 0.21357595920562744
step: 160, loss: 0.24497298896312714
step: 170, loss: 0.23966211080551147
step: 180, loss: 0.1432679444551468
step: 190, loss: 0.15171130001544952
step: 200, loss: 0.12976105511188507
step: 210, loss: 0.1703536957502365
step: 220, loss: 0.010545911267399788
step: 230, loss: 0.1507188379764557
step: 240, loss: 0.2022281438112259
step: 250, loss: 0.17504887282848358
step: 260, loss: 0.15148191154003143
step: 270, loss: 0.16827237606048584
step: 280, loss: 0.15407922863960266
step: 290, loss: 0.13372565805912018
step: 300, loss: 0.1356784850358963
step: 310, loss: 0.19040165841579437
step: 320, loss: 0.21487343311309814
step: 330, loss: 0.0921434685587883
step: 340, loss: 0.14963796734809875
step: 350, loss: 0.08227822184562683
step: 360, loss: 0.15294316411018372
step: 370, loss: 0.19494956731796265
step: 380, loss: 0.2101350873708725
epoch 1: dev_f1=0.6806282722513088, f1=0.6597938144329897, best_f1=0.6597938144329897
step: 0, loss: 0.15031000971794128
step: 10, loss: 0.1351706087589264
step: 20, loss: 0.25835859775543213
step: 30, loss: 0.2978396415710449
step: 40, loss: 0.13890185952186584
step: 50, loss: 0.43646183609962463
step: 60, loss: 0.17508265376091003
step: 70, loss: 0.19180968403816223
step: 80, loss: 0.0463218092918396
step: 90, loss: 0.18067286908626556
step: 100, loss: 0.20640337467193604
step: 110, loss: 0.10210860520601273
step: 120, loss: 0.17171457409858704
step: 130, loss: 0.16888165473937988
step: 140, loss: 0.09463045746088028
step: 150, loss: 0.029501672834157944
step: 160, loss: 0.08722416311502457
step: 170, loss: 0.032839901745319366
step: 180, loss: 0.1560828685760498
step: 190, loss: 0.12921424210071564
step: 200, loss: 0.032776787877082825
step: 210, loss: 0.12032702565193176
step: 220, loss: 0.14486873149871826
step: 230, loss: 0.10745376348495483
step: 240, loss: 0.11770541220903397
step: 250, loss: 0.11689641326665878
step: 260, loss: 0.12158370763063431
step: 270, loss: 0.18887974321842194
step: 280, loss: 0.1848185658454895
step: 290, loss: 0.23663392663002014
step: 300, loss: 0.12349455803632736
step: 310, loss: 0.14238566160202026
step: 320, loss: 0.042023446410894394
step: 330, loss: 0.11805716156959534
step: 340, loss: 0.07664275914430618
step: 350, loss: 0.14794208109378815
step: 360, loss: 0.07087838649749756
step: 370, loss: 0.09412587434053421
step: 380, loss: 0.14144065976142883
epoch 2: dev_f1=0.689156626506024, f1=0.7245657568238213, best_f1=0.7245657568238213
step: 0, loss: 0.10394655168056488
step: 10, loss: 0.17575934529304504
step: 20, loss: 0.024977639317512512
step: 30, loss: 0.06043016538023949
step: 40, loss: 0.02724004164338112
step: 50, loss: 0.04066956415772438
step: 60, loss: 0.15464574098587036
step: 70, loss: 0.21908998489379883
step: 80, loss: 0.08176721632480621
step: 90, loss: 0.09792991727590561
step: 100, loss: 0.18144243955612183
step: 110, loss: 0.1170535758137703
step: 120, loss: 0.02264760620892048
step: 130, loss: 0.18372774124145508
step: 140, loss: 0.1711638867855072
step: 150, loss: 0.1651410460472107
step: 160, loss: 0.04887339100241661
step: 170, loss: 0.1202315241098404
step: 180, loss: 0.08500239998102188
step: 190, loss: 0.14010076224803925
step: 200, loss: 0.037878379225730896
step: 210, loss: 0.19275569915771484
step: 220, loss: 0.10825403779745102
step: 230, loss: 0.11221498250961304
step: 240, loss: 0.11407863348722458
step: 250, loss: 0.07873230427503586
step: 260, loss: 0.1158507838845253
step: 270, loss: 0.06922570616006851
step: 280, loss: 0.11351706087589264
step: 290, loss: 0.07338764518499374
step: 300, loss: 0.2984788417816162
step: 310, loss: 0.08324974775314331
step: 320, loss: 0.20350387692451477
step: 330, loss: 0.06894714385271072
step: 340, loss: 0.05309227108955383
step: 350, loss: 0.1008484959602356
step: 360, loss: 0.0639028251171112
step: 370, loss: 0.2677980065345764
step: 380, loss: 0.06368369609117508
epoch 3: dev_f1=0.7313019390581716, f1=0.7061994609164419, best_f1=0.7061994609164419
step: 0, loss: 0.1478661745786667
step: 10, loss: 0.1055259108543396
step: 20, loss: 0.10698370635509491
step: 30, loss: 0.10326310992240906
step: 40, loss: 0.07384222745895386
step: 50, loss: 0.06334807723760605
step: 60, loss: 0.13396169245243073
step: 70, loss: 0.03041621670126915
step: 80, loss: 0.04844871163368225
step: 90, loss: 0.03667560592293739
step: 100, loss: 0.029151378199458122
step: 110, loss: 0.06694676727056503
step: 120, loss: 0.014091386459767818
step: 130, loss: 0.04941822215914726
step: 140, loss: 0.0889066755771637
step: 150, loss: 0.11469245702028275
step: 160, loss: 0.1583985984325409
step: 170, loss: 0.1248980388045311
step: 180, loss: 0.12802696228027344
step: 190, loss: 0.06228455901145935
step: 200, loss: 0.17431171238422394
step: 210, loss: 0.25230538845062256
step: 220, loss: 0.10722486674785614
step: 230, loss: 0.0041337767615914345
step: 240, loss: 0.1770910620689392
step: 250, loss: 0.08761894702911377
step: 260, loss: 0.12213880568742752
step: 270, loss: 0.10678897053003311
step: 280, loss: 0.05286087095737457
step: 290, loss: 0.11895639449357986
step: 300, loss: 0.2170969694852829
step: 310, loss: 0.1314767599105835
step: 320, loss: 0.12166135013103485
step: 330, loss: 0.057951219379901886
step: 340, loss: 0.01807384379208088
step: 350, loss: 0.11469774693250656
step: 360, loss: 0.15373563766479492
step: 370, loss: 0.24480018019676208
step: 380, loss: 0.07978973537683487
epoch 4: dev_f1=0.7, f1=0.7007299270072993, best_f1=0.7061994609164419
step: 0, loss: 0.10256960242986679
step: 10, loss: 0.0790659487247467
step: 20, loss: 0.038358423858881
step: 30, loss: 0.04679057374596596
step: 40, loss: 0.10315947234630585
step: 50, loss: 0.12211906164884567
step: 60, loss: 0.02315964736044407
step: 70, loss: 0.10683965682983398
step: 80, loss: 0.1298387199640274
step: 90, loss: 0.039581961929798126
step: 100, loss: 0.10739082098007202
step: 110, loss: 0.057046785950660706
step: 120, loss: 0.010287582874298096
step: 130, loss: 0.022826477885246277
step: 140, loss: 0.02086060494184494
step: 150, loss: 0.1723860502243042
step: 160, loss: 0.022362230345606804
step: 170, loss: 0.08008868992328644
step: 180, loss: 0.08046593517065048
step: 190, loss: 0.14896737039089203
step: 200, loss: 0.11538967490196228
step: 210, loss: 0.08037621527910233
step: 220, loss: 0.06736671179533005
step: 230, loss: 0.08580156415700912
step: 240, loss: 0.030618561431765556
step: 250, loss: 0.13345114886760712
step: 260, loss: 0.08152362704277039
step: 270, loss: 0.07086773961782455
step: 280, loss: 0.0757933035492897
step: 290, loss: 0.07863209396600723
step: 300, loss: 0.13343890011310577
step: 310, loss: 0.05677448585629463
step: 320, loss: 0.03388968110084534
step: 330, loss: 0.14266224205493927
step: 340, loss: 0.07498175650835037
step: 350, loss: 0.17586660385131836
step: 360, loss: 0.04291978478431702
step: 370, loss: 0.028982825577259064
step: 380, loss: 0.15289343893527985
epoch 5: dev_f1=0.6794520547945204, f1=0.7184986595174263, best_f1=0.7061994609164419
step: 0, loss: 0.047298308461904526
step: 10, loss: 0.11960555613040924
step: 20, loss: 0.009406138211488724
step: 30, loss: 0.08331933617591858
step: 40, loss: 0.057414207607507706
step: 50, loss: 0.03405466303229332
step: 60, loss: 0.06910447031259537
step: 70, loss: 0.12342062592506409
step: 80, loss: 0.10801450908184052
step: 90, loss: 0.1222120150923729
step: 100, loss: 0.03119855374097824
step: 110, loss: 0.08829644322395325
step: 120, loss: 0.049874503165483475
step: 130, loss: 0.08392130583524704
step: 140, loss: 0.14652448892593384
step: 150, loss: 0.1284063160419464
step: 160, loss: 0.05997474119067192
step: 170, loss: 0.12168138474225998
step: 180, loss: 0.06428573280572891
step: 190, loss: 0.03812134638428688
step: 200, loss: 0.12380246818065643
step: 210, loss: 0.01447295118123293
step: 220, loss: 0.14957855641841888
step: 230, loss: 0.06054292619228363
step: 240, loss: 0.09239326417446136
step: 250, loss: 0.1567186564207077
step: 260, loss: 0.08942024409770966
step: 270, loss: 0.04761213809251785
step: 280, loss: 0.04063466936349869
step: 290, loss: 0.054946839809417725
step: 300, loss: 0.04732106998562813
step: 310, loss: 0.04886908456683159
step: 320, loss: 0.0938957929611206
step: 330, loss: 0.06327375769615173
step: 340, loss: 0.06309954822063446
step: 350, loss: 0.05132141709327698
step: 360, loss: 0.11546102911233902
step: 370, loss: 0.04116284102201462
step: 380, loss: 0.1044241189956665
epoch 6: dev_f1=0.7301587301587302, f1=0.7395833333333334, best_f1=0.7061994609164419
step: 0, loss: 0.1586073935031891
step: 10, loss: 0.17241951823234558
step: 20, loss: 0.0955965518951416
step: 30, loss: 0.06470728665590286
step: 40, loss: 0.13105252385139465
step: 50, loss: 0.06802820414304733
step: 60, loss: 0.09579324722290039
step: 70, loss: 0.03625111281871796
step: 80, loss: 0.0406833253800869
step: 90, loss: 0.045769426971673965
step: 100, loss: 0.016767747700214386
step: 110, loss: 0.06597445905208588
step: 120, loss: 0.17373086512088776
step: 130, loss: 0.06584884971380234
step: 140, loss: 0.03565991669893265
step: 150, loss: 0.029946178197860718
step: 160, loss: 0.022147495299577713
step: 170, loss: 0.14178501069545746
step: 180, loss: 0.027287734672427177
step: 190, loss: 0.07498182356357574
step: 200, loss: 0.08492705971002579
step: 210, loss: 0.015133572742342949
step: 220, loss: 0.1201067566871643
step: 230, loss: 0.034770119935274124
step: 240, loss: 0.14646628499031067
step: 250, loss: 0.06390107423067093
step: 260, loss: 0.015232783742249012
step: 270, loss: 0.03365320339798927
step: 280, loss: 0.027322139590978622
step: 290, loss: 0.19093672931194305
step: 300, loss: 0.1610354781150818
step: 310, loss: 0.028725089505314827
step: 320, loss: 0.10529360920190811
step: 330, loss: 0.1137692853808403
step: 340, loss: 0.05876735970377922
step: 350, loss: 0.16087913513183594
step: 360, loss: 0.07576154917478561
step: 370, loss: 0.07635790854692459
step: 380, loss: 0.11568835377693176
epoch 7: dev_f1=0.7302452316076293, f1=0.7320954907161804, best_f1=0.7061994609164419
step: 0, loss: 0.11702471971511841
step: 10, loss: 0.0974687933921814
step: 20, loss: 0.020090535283088684
step: 30, loss: 0.04709794744849205
step: 40, loss: 0.024865997955203056
step: 50, loss: 0.0592900812625885
step: 60, loss: 0.10614258795976639
step: 70, loss: 0.050000958144664764
step: 80, loss: 0.18067143857479095
step: 90, loss: 0.05643486976623535
step: 100, loss: 0.07211168855428696
step: 110, loss: 0.08785393834114075
step: 120, loss: 0.08258827775716782
step: 130, loss: 0.058908287435770035
step: 140, loss: 0.005763591732829809
step: 150, loss: 0.023031866177916527
step: 160, loss: 0.13197532296180725
step: 170, loss: 0.07187841087579727
step: 180, loss: 0.011561131104826927
step: 190, loss: 0.08190259337425232
step: 200, loss: 0.06145435944199562
step: 210, loss: 0.14853806793689728
step: 220, loss: 0.12194718420505524
step: 230, loss: 0.08428642898797989
step: 240, loss: 0.1628349870443344
step: 250, loss: 0.09431637078523636
step: 260, loss: 0.10220389813184738
step: 270, loss: 0.06569197028875351
step: 280, loss: 0.1557234227657318
step: 290, loss: 0.13102050125598907
step: 300, loss: 0.009867777116596699
step: 310, loss: 0.000261036679148674
step: 320, loss: 0.02940097078680992
step: 330, loss: 0.1479242593050003
step: 340, loss: 0.09489535540342331
step: 350, loss: 0.030426528304815292
step: 360, loss: 0.01426890678703785
step: 370, loss: 0.06233944371342659
step: 380, loss: 0.0436212494969368
epoch 8: dev_f1=0.7591623036649214, f1=0.765625, best_f1=0.765625
step: 0, loss: 0.05660206079483032
step: 10, loss: 0.04613904282450676
step: 20, loss: 0.09963203966617584
step: 30, loss: 0.09002212435007095
step: 40, loss: 0.1116887629032135
step: 50, loss: 0.11556359380483627
step: 60, loss: 0.10558615624904633
step: 70, loss: 0.020673202350735664
step: 80, loss: 0.09050170332193375
step: 90, loss: 0.025024566799402237
step: 100, loss: 0.14752154052257538
step: 110, loss: 0.115479476749897
step: 120, loss: 0.05924458056688309
step: 130, loss: 0.05619332566857338
step: 140, loss: 0.06321299076080322
step: 150, loss: 0.09536004811525345
step: 160, loss: 0.06581518054008484
step: 170, loss: 0.016518019139766693
step: 180, loss: 0.17228414118289948
step: 190, loss: 0.018563132733106613
step: 200, loss: 0.07041018456220627
step: 210, loss: 0.06520508229732513
step: 220, loss: 0.050002750009298325
step: 230, loss: 0.024389419704675674
step: 240, loss: 0.10190577059984207
step: 250, loss: 0.04370715469121933
step: 260, loss: 0.10405047982931137
step: 270, loss: 0.06831321865320206
step: 280, loss: 0.1103082224726677
step: 290, loss: 0.03998605161905289
step: 300, loss: 0.11631213873624802
step: 310, loss: 0.05551563575863838
step: 320, loss: 0.02076202630996704
step: 330, loss: 0.061273615807294846
step: 340, loss: 0.16178330779075623
step: 350, loss: 0.11695421487092972
step: 360, loss: 0.07059752941131592
step: 370, loss: 0.021325094625353813
step: 380, loss: 0.03876510262489319
epoch 9: dev_f1=0.7546174142480211, f1=0.7390180878552972, best_f1=0.765625
step: 0, loss: 0.08102873712778091
step: 10, loss: 0.02209865301847458
step: 20, loss: 0.024344196543097496
step: 30, loss: 0.05857846140861511
step: 40, loss: 0.05819305032491684
step: 50, loss: 0.08156927675008774
step: 60, loss: 0.07851239293813705
step: 70, loss: 0.11617255210876465
step: 80, loss: 0.023895980790257454
step: 90, loss: 0.04355430230498314
step: 100, loss: 0.010472926311194897
step: 110, loss: 0.035031888633966446
step: 120, loss: 0.09620949625968933
step: 130, loss: 0.09033435583114624
step: 140, loss: 0.1493968814611435
step: 150, loss: 0.023266952484846115
step: 160, loss: 0.15273906290531158
step: 170, loss: 0.10835772752761841
step: 180, loss: 0.22614647448062897
step: 190, loss: 0.07059665769338608
step: 200, loss: 0.046477049589157104
step: 210, loss: 0.13529711961746216
step: 220, loss: 0.14233002066612244
step: 230, loss: 0.06726167351007462
step: 240, loss: 0.056271687150001526
step: 250, loss: 0.05027979612350464
step: 260, loss: 0.11879678815603256
step: 270, loss: 0.15701700747013092
step: 280, loss: 0.05267531797289848
step: 290, loss: 0.11011244356632233
step: 300, loss: 0.11248470842838287
step: 310, loss: 0.034530382603406906
step: 320, loss: 0.05542450398206711
step: 330, loss: 0.08495255559682846
step: 340, loss: 0.07277137786149979
step: 350, loss: 0.03616271913051605
step: 360, loss: 0.0703059732913971
step: 370, loss: 0.24243244528770447
step: 380, loss: 0.10295790433883667
epoch 10: dev_f1=0.743455497382199, f1=0.7258883248730965, best_f1=0.765625
step: 0, loss: 0.016786355525255203
step: 10, loss: 0.11842183023691177
step: 20, loss: 0.0576702244579792
step: 30, loss: 0.12946510314941406
step: 40, loss: 0.08598175644874573
step: 50, loss: 0.05455707013607025
step: 60, loss: 0.00258850259706378
step: 70, loss: 0.03757891058921814
step: 80, loss: 0.07939683645963669
step: 90, loss: 0.0025789663195610046
step: 100, loss: 0.02150208316743374
step: 110, loss: 0.010420331731438637
step: 120, loss: 0.18973079323768616
step: 130, loss: 0.026978813111782074
step: 140, loss: 0.09845485538244247
step: 150, loss: 0.003981396555900574
step: 160, loss: 0.021976258605718613
step: 170, loss: 0.14677947759628296
step: 180, loss: 0.03357451781630516
step: 190, loss: 0.0001770631643012166
step: 200, loss: 0.10445433109998703
step: 210, loss: 0.1504553258419037
step: 220, loss: 0.025125712156295776
step: 230, loss: 0.028404440730810165
step: 240, loss: 0.07753252238035202
step: 250, loss: 0.042187247425317764
step: 260, loss: 0.06311511248350143
step: 270, loss: 0.07053257524967194
step: 280, loss: 0.041871000081300735
step: 290, loss: 0.009672473184764385
step: 300, loss: 0.08428412675857544
step: 310, loss: 0.08921428769826889
step: 320, loss: 0.03354715183377266
step: 330, loss: 0.0004934465396218002
step: 340, loss: 0.06318306177854538
step: 350, loss: 0.01773027330636978
step: 360, loss: 0.026807082816958427
step: 370, loss: 0.05084484815597534
step: 380, loss: 0.04942621290683746
epoch 11: dev_f1=0.7233009708737864, f1=0.7416267942583731, best_f1=0.765625
step: 0, loss: 0.03217390552163124
step: 10, loss: 0.060262031853199005
step: 20, loss: 0.095016710460186
step: 30, loss: 0.10533030331134796
step: 40, loss: 0.08070585131645203
step: 50, loss: 0.0663122907280922
step: 60, loss: 0.05307813733816147
step: 70, loss: 0.0030875594820827246
step: 80, loss: 0.12457127124071121
step: 90, loss: 0.09363138675689697
step: 100, loss: 0.02622763067483902
step: 110, loss: 0.060144174844026566
step: 120, loss: 0.016715096309781075
step: 130, loss: 0.12583279609680176
step: 140, loss: 0.052593670785427094
step: 150, loss: 0.05774346739053726
step: 160, loss: 0.17692050337791443
step: 170, loss: 0.04368118569254875
step: 180, loss: 0.02869504690170288
step: 190, loss: 0.026302441954612732
step: 200, loss: 0.06414693593978882
step: 210, loss: 0.05349902808666229
step: 220, loss: 0.06391560286283493
step: 230, loss: 0.015401506796479225
step: 240, loss: 0.12161334604024887
step: 250, loss: 0.04473468288779259
step: 260, loss: 0.1193319633603096
step: 270, loss: 0.03138400986790657
step: 280, loss: 0.1252230554819107
step: 290, loss: 0.02255931682884693
step: 300, loss: 0.022487111389636993
step: 310, loss: 0.03621751442551613
step: 320, loss: 0.02119367942214012
step: 330, loss: 0.022583652287721634
step: 340, loss: 0.08391079306602478
step: 350, loss: 0.06997236609458923
step: 360, loss: 0.0734420195221901
step: 370, loss: 0.1884944587945938
step: 380, loss: 0.123754121363163
epoch 12: dev_f1=0.708433734939759, f1=0.7281553398058251, best_f1=0.765625
step: 0, loss: 0.04142852872610092
step: 10, loss: 0.012497765012085438
step: 20, loss: 0.023114817216992378
step: 30, loss: 0.01926466077566147
step: 40, loss: 0.02668612450361252
step: 50, loss: 0.06616606563329697
step: 60, loss: 0.07770217955112457
step: 70, loss: 0.06249983236193657
step: 80, loss: 0.10208852589130402
step: 90, loss: 0.03168351203203201
step: 100, loss: 0.019912172108888626
step: 110, loss: 0.09070347249507904
step: 120, loss: 0.012903561815619469
step: 130, loss: 0.054269418120384216
step: 140, loss: 0.019611777737736702
step: 150, loss: 0.06807469576597214
step: 160, loss: 0.07303027808666229
step: 170, loss: 0.020718291401863098
step: 180, loss: 0.14390619099140167
step: 190, loss: 0.09470470249652863
step: 200, loss: 0.16516104340553284
step: 210, loss: 0.06458268314599991
step: 220, loss: 0.034155528992414474
step: 230, loss: 0.07347291707992554
step: 240, loss: 0.04227262735366821
step: 250, loss: 0.044961437582969666
step: 260, loss: 7.455649028997868e-05
step: 270, loss: 0.00904977135360241
step: 280, loss: 0.05913667753338814
step: 290, loss: 0.03847383335232735
step: 300, loss: 0.030044114217162132
step: 310, loss: 0.03429976850748062
step: 320, loss: 0.02202569879591465
step: 330, loss: 0.038425859063863754
step: 340, loss: 0.02528361976146698
step: 350, loss: 0.013867256231606007
step: 360, loss: 0.064106784760952
step: 370, loss: 0.0637379065155983
step: 380, loss: 0.05302077904343605
epoch 13: dev_f1=0.743455497382199, f1=0.7258883248730965, best_f1=0.765625
step: 0, loss: 0.017431434243917465
step: 10, loss: 0.07554549723863602
step: 20, loss: 0.0020556997042149305
step: 30, loss: 0.00022363144671544433
step: 40, loss: 0.05412137880921364
step: 50, loss: 0.025295928120613098
step: 60, loss: 0.07144685089588165
step: 70, loss: 0.06751739233732224
step: 80, loss: 0.0951654389500618
step: 90, loss: 0.044859010726213455
step: 100, loss: 0.08600911498069763
step: 110, loss: 0.05167325586080551
step: 120, loss: 0.17332614958286285
step: 130, loss: 0.05408839136362076
step: 140, loss: 0.08440244197845459
step: 150, loss: 0.03698774054646492
step: 160, loss: 0.013604262843728065
step: 170, loss: 0.0432840920984745
step: 180, loss: 0.06184376776218414
step: 190, loss: 0.03339561074972153
step: 200, loss: 0.06705641001462936
step: 210, loss: 0.019566655158996582
step: 220, loss: 0.055099569261074066
step: 230, loss: 0.014168016612529755
step: 240, loss: 0.1636333018541336
step: 250, loss: 0.0076674846932291985
step: 260, loss: 0.0811176523566246
step: 270, loss: 0.11693271994590759
step: 280, loss: 0.0025304220616817474
step: 290, loss: 0.054777320474386215
step: 300, loss: 0.026177426800131798
step: 310, loss: 0.30495455861091614
step: 320, loss: 0.051097530871629715
step: 330, loss: 0.0482073575258255
step: 340, loss: 0.01702248677611351
step: 350, loss: 0.05873460695147514
step: 360, loss: 0.13398772478103638
step: 370, loss: 0.015664709731936455
step: 380, loss: 0.04144160449504852
epoch 14: dev_f1=0.7349081364829396, f1=0.7034120734908137, best_f1=0.765625
step: 0, loss: 0.04141198843717575
step: 10, loss: 0.0565217025578022
step: 20, loss: 0.02072114497423172
step: 30, loss: 0.03152250498533249
step: 40, loss: 0.03387396037578583
step: 50, loss: 0.009459511376917362
step: 60, loss: 0.013785112649202347
step: 70, loss: 0.06272666901350021
step: 80, loss: 0.030151741579174995
step: 90, loss: 0.031366702169179916
step: 100, loss: 0.08703191578388214
step: 110, loss: 0.006978166755288839
step: 120, loss: 0.10527287423610687
step: 130, loss: 0.021839193999767303
step: 140, loss: 0.003546311752870679
step: 150, loss: 0.04066750034689903
step: 160, loss: 0.1143762618303299
step: 170, loss: 0.08497726917266846
step: 180, loss: 0.058454595506191254
step: 190, loss: 0.031124407425522804
step: 200, loss: 0.04661108925938606
step: 210, loss: 0.07327772676944733
step: 220, loss: 0.059283629059791565
step: 230, loss: 0.12196175009012222
step: 240, loss: 0.04345783218741417
step: 250, loss: 0.08278471231460571
step: 260, loss: 2.6217303457087837e-05
step: 270, loss: 0.01428113505244255
step: 280, loss: 0.02602679841220379
step: 290, loss: 0.05328875780105591
step: 300, loss: 0.02608386054635048
step: 310, loss: 0.0768798440694809
step: 320, loss: 0.05678433179855347
step: 330, loss: 0.03758625686168671
step: 340, loss: 0.017606893554329872
step: 350, loss: 0.006313705816864967
step: 360, loss: 8.511734631611034e-05
step: 370, loss: 0.10753459483385086
step: 380, loss: 0.01890333741903305
epoch 15: dev_f1=0.73, f1=0.7067669172932332, best_f1=0.765625
step: 0, loss: 0.02068568579852581
step: 10, loss: 0.06496741622686386
step: 20, loss: 0.005734001751989126
step: 30, loss: 0.022310849279165268
step: 40, loss: 0.031184663996100426
step: 50, loss: 0.023712318390607834
step: 60, loss: 0.033680230379104614
step: 70, loss: 0.022439898923039436
step: 80, loss: 0.06954396516084671
step: 90, loss: 0.04605098441243172
step: 100, loss: 0.09919880330562592
step: 110, loss: 0.12895837426185608
step: 120, loss: 0.04488871991634369
step: 130, loss: 0.0676758736371994
step: 140, loss: 0.03568674996495247
step: 150, loss: 0.028240539133548737
step: 160, loss: 0.025397880002856255
step: 170, loss: 0.05494830384850502
step: 180, loss: 0.03301862254738808
step: 190, loss: 0.03923425450921059
step: 200, loss: 0.0428227074444294
step: 210, loss: 0.12132251262664795
step: 220, loss: 0.002921666717156768
step: 230, loss: 0.04444205388426781
step: 240, loss: 0.019871298223733902
step: 250, loss: 0.00616114679723978
step: 260, loss: 0.032698921859264374
step: 270, loss: 0.07425615191459656
step: 280, loss: 0.03622317686676979
step: 290, loss: 0.039396852254867554
step: 300, loss: 0.11040832102298737
step: 310, loss: 0.04859771952033043
step: 320, loss: 0.057496070861816406
step: 330, loss: 0.071419857442379
step: 340, loss: 3.060989547520876e-05
step: 350, loss: 0.010160544887185097
step: 360, loss: 0.022551851347088814
step: 370, loss: 2.469423270667903e-05
step: 380, loss: 0.13322174549102783
epoch 16: dev_f1=0.7371273712737126, f1=0.7040000000000001, best_f1=0.765625
step: 0, loss: 0.05199652910232544
step: 10, loss: 0.016510726884007454
step: 20, loss: 0.028461942449212074
step: 30, loss: 0.05826728045940399
step: 40, loss: 0.06675108522176743
step: 50, loss: 0.011381745338439941
step: 60, loss: 0.07430073618888855
step: 70, loss: 0.0007123580435290933
step: 80, loss: 0.012251581996679306
step: 90, loss: 0.006540510803461075
step: 100, loss: 0.0501447468996048
step: 110, loss: 0.004084402229636908
step: 120, loss: 3.1349773053079844e-05
step: 130, loss: 0.018025312572717667
step: 140, loss: 0.0010275813983753324
step: 150, loss: 0.0778699591755867
step: 160, loss: 0.03427811339497566
step: 170, loss: 0.005503453314304352
step: 180, loss: 0.06469981372356415
step: 190, loss: 0.08989600092172623
step: 200, loss: 0.040798451751470566
step: 210, loss: 0.00012050873192492872
step: 220, loss: 0.18342112004756927
step: 230, loss: 0.009644702076911926
step: 240, loss: 0.08666469901800156
step: 250, loss: 0.038384586572647095
step: 260, loss: 0.10582832992076874
step: 270, loss: 0.10000497102737427
step: 280, loss: 0.15058301389217377
step: 290, loss: 0.0012617800384759903
step: 300, loss: 0.0504637211561203
step: 310, loss: 0.05848809704184532
step: 320, loss: 0.059274230152368546
step: 330, loss: 0.025495046749711037
step: 340, loss: 0.0035781103651970625
step: 350, loss: 0.00025649432791396976
step: 360, loss: 0.07603225857019424
step: 370, loss: 0.010260985232889652
step: 380, loss: 0.007542879320681095
epoch 17: dev_f1=0.7461139896373058, f1=0.7193877551020408, best_f1=0.765625
step: 0, loss: 0.05759130045771599
step: 10, loss: 0.011458685621619225
step: 20, loss: 0.021292325109243393
step: 30, loss: 0.023684360086917877
step: 40, loss: 0.00013951271830592304
step: 50, loss: 0.0003398794215172529
step: 60, loss: 0.02426942251622677
step: 70, loss: 0.05110767111182213
step: 80, loss: 0.020918000489473343
step: 90, loss: 0.013763701543211937
step: 100, loss: 0.025088060647249222
step: 110, loss: 0.0006268743309192359
step: 120, loss: 0.05232459679245949
step: 130, loss: 0.03975295647978783
step: 140, loss: 0.02619168534874916
step: 150, loss: 0.04275285080075264
step: 160, loss: 0.022010724991559982
step: 170, loss: 0.08738783001899719
step: 180, loss: 0.012195482850074768
step: 190, loss: 0.00463120685890317
step: 200, loss: 0.042511235922575
step: 210, loss: 0.02081434428691864
step: 220, loss: 0.06166624650359154
step: 230, loss: 3.1291128834709525e-05
step: 240, loss: 0.04529185965657234
step: 250, loss: 0.057281140238046646
step: 260, loss: 0.03407737985253334
step: 270, loss: 0.056036192923784256
step: 280, loss: 0.0193910114467144
step: 290, loss: 0.053109701722860336
step: 300, loss: 0.0005826056003570557
step: 310, loss: 0.005259053781628609
step: 320, loss: 0.016397668048739433
step: 330, loss: 0.037296444177627563
step: 340, loss: 0.05403634160757065
step: 350, loss: 0.015703830868005753
step: 360, loss: 0.04808414354920387
step: 370, loss: 0.01869523711502552
step: 380, loss: 0.038479894399642944
epoch 18: dev_f1=0.7356948228882835, f1=0.7061994609164419, best_f1=0.765625
step: 0, loss: 0.0001476780598750338
step: 10, loss: 0.06813976913690567
step: 20, loss: 0.0340038537979126
step: 30, loss: 0.008559701964259148
step: 40, loss: 6.316370127024129e-05
step: 50, loss: 0.04803932085633278
step: 60, loss: 0.010507501661777496
step: 70, loss: 0.06235384941101074
step: 80, loss: 0.07348491251468658
step: 90, loss: 0.0814431831240654
step: 100, loss: 0.027272773906588554
step: 110, loss: 0.07184401154518127
step: 120, loss: 0.014346549287438393
step: 130, loss: 0.06774461269378662
step: 140, loss: 0.027904614806175232
step: 150, loss: 0.11593105643987656
step: 160, loss: 0.024404719471931458
step: 170, loss: 0.0409703366458416
step: 180, loss: 0.06505121290683746
step: 190, loss: 5.342760050552897e-05
step: 200, loss: 0.04965561255812645
step: 210, loss: 0.0939997062087059
step: 220, loss: 0.033087752759456635
step: 230, loss: 0.04638762027025223
step: 240, loss: 0.061403147876262665
step: 250, loss: 0.018382344394922256
step: 260, loss: 0.05900534242391586
step: 270, loss: 0.02028997242450714
step: 280, loss: 0.014806048013269901
step: 290, loss: 0.037192657589912415
step: 300, loss: 0.019513648003339767
step: 310, loss: 0.0005184081383049488
step: 320, loss: 0.009800181724131107
step: 330, loss: 0.006797412876039743
step: 340, loss: 0.10620741546154022
step: 350, loss: 0.02592921443283558
step: 360, loss: 0.014351990073919296
step: 370, loss: 0.0225002970546484
step: 380, loss: 0.07927850633859634
epoch 19: dev_f1=0.7234042553191489, f1=0.7058823529411764, best_f1=0.765625
step: 0, loss: 0.006852418649941683
step: 10, loss: 0.009055006317794323
step: 20, loss: 0.026660997420549393
step: 30, loss: 0.02075190469622612
step: 40, loss: 0.03639322891831398
step: 50, loss: 0.025829864665865898
step: 60, loss: 0.003164533292874694
step: 70, loss: 0.016388295218348503
step: 80, loss: 0.0067555163986980915
step: 90, loss: 0.031273555010557175
step: 100, loss: 0.014646532014012337
step: 110, loss: 0.031695861369371414
step: 120, loss: 0.0968635231256485
step: 130, loss: 0.009811246767640114
step: 140, loss: 0.053771261125802994
step: 150, loss: 0.052701860666275024
step: 160, loss: 0.0675354078412056
step: 170, loss: 0.03619863837957382
step: 180, loss: 0.016611924394965172
step: 190, loss: 0.10994113981723785
step: 200, loss: 0.0035529606975615025
step: 210, loss: 0.05247211828827858
step: 220, loss: 0.055387113243341446
step: 230, loss: 6.224806566024199e-05
step: 240, loss: 0.0005288239917717874
step: 250, loss: 0.04481089115142822
step: 260, loss: 0.031281739473342896
step: 270, loss: 0.0018857098184525967
step: 280, loss: 0.02075101062655449
step: 290, loss: 0.0004915865720249712
step: 300, loss: 3.426481271162629e-05
step: 310, loss: 0.046740319579839706
step: 320, loss: 0.06710196286439896
step: 330, loss: 0.04283082112669945
step: 340, loss: 0.034726306796073914
step: 350, loss: 0.04956328868865967
step: 360, loss: 0.0052621676586568356
step: 370, loss: 0.04828289523720741
step: 380, loss: 0.02670374885201454
epoch 20: dev_f1=0.7243243243243244, f1=0.7065217391304348, best_f1=0.765625
