cuda
Device: cuda
step: 0, loss: 1.022698163986206
step: 10, loss: 0.646176278591156
step: 20, loss: 0.3858000636100769
step: 30, loss: 0.14085502922534943
step: 40, loss: 0.5313882231712341
step: 50, loss: 0.32019564509391785
step: 60, loss: 0.3140428364276886
step: 70, loss: 0.31143537163734436
step: 80, loss: 0.23147444427013397
step: 90, loss: 0.3142075836658478
step: 100, loss: 0.5726917386054993
step: 110, loss: 0.15939053893089294
step: 120, loss: 0.28744956851005554
step: 130, loss: 0.18724428117275238
step: 140, loss: 0.17977041006088257
step: 150, loss: 0.22521980106830597
step: 160, loss: 0.12081167846918106
step: 170, loss: 0.056692373007535934
step: 180, loss: 0.18839189410209656
step: 190, loss: 0.7180604338645935
step: 200, loss: 0.18126708269119263
step: 210, loss: 0.10170359909534454
step: 220, loss: 0.29359012842178345
step: 230, loss: 0.09543163329362869
step: 240, loss: 0.03034909814596176
step: 250, loss: 0.3052045404911041
step: 260, loss: 0.13005687296390533
step: 270, loss: 0.015521250665187836
step: 280, loss: 0.14637155830860138
step: 290, loss: 0.24955546855926514
step: 300, loss: 0.10616976022720337
step: 310, loss: 0.37854716181755066
step: 320, loss: 0.08990608155727386
step: 330, loss: 0.3465293347835541
step: 340, loss: 0.18396659195423126
step: 350, loss: 0.2713375687599182
step: 360, loss: 0.12338493764400482
step: 370, loss: 0.386214017868042
step: 380, loss: 0.2703651487827301
epoch 1: dev_f1=0.6327683615819208, f1=0.5994397759103641, best_f1=0.5994397759103641
step: 0, loss: 0.07752270251512527
step: 10, loss: 0.39623820781707764
step: 20, loss: 0.30434542894363403
step: 30, loss: 0.026427922770380974
step: 40, loss: 0.10389228910207748
step: 50, loss: 0.10574577003717422
step: 60, loss: 0.12475407868623734
step: 70, loss: 0.1978205144405365
step: 80, loss: 0.36376896500587463
step: 90, loss: 0.047163352370262146
step: 100, loss: 0.14900442957878113
step: 110, loss: 0.21157029271125793
step: 120, loss: 0.03361223265528679
step: 130, loss: 0.23951880633831024
step: 140, loss: 0.23586082458496094
step: 150, loss: 0.18018662929534912
step: 160, loss: 0.1659015715122223
step: 170, loss: 0.051882822066545486
step: 180, loss: 0.12112698704004288
step: 190, loss: 0.3456755578517914
step: 200, loss: 0.15285241603851318
step: 210, loss: 0.19044050574302673
step: 220, loss: 0.20229394733905792
step: 230, loss: 0.21585336327552795
step: 240, loss: 0.05217953771352768
step: 250, loss: 0.15382453799247742
step: 260, loss: 0.08511988073587418
step: 270, loss: 0.18957149982452393
step: 280, loss: 0.07375569641590118
step: 290, loss: 0.11708047986030579
step: 300, loss: 0.10864130407571793
step: 310, loss: 0.1193382516503334
step: 320, loss: 0.15167421102523804
step: 330, loss: 0.3033457398414612
step: 340, loss: 0.21015913784503937
step: 350, loss: 0.03588747978210449
step: 360, loss: 0.13536524772644043
step: 370, loss: 0.14622481167316437
step: 380, loss: 0.2634679675102234
epoch 2: dev_f1=0.6881720430107526, f1=0.6965699208443272, best_f1=0.6965699208443272
step: 0, loss: 0.03939540311694145
step: 10, loss: 0.07198603451251984
step: 20, loss: 0.05298057571053505
step: 30, loss: 0.08820100128650665
step: 40, loss: 0.22893749177455902
step: 50, loss: 0.06761587411165237
step: 60, loss: 0.08321137726306915
step: 70, loss: 0.07178406417369843
step: 80, loss: 0.07875431329011917
step: 90, loss: 0.10223813354969025
step: 100, loss: 0.09248032420873642
step: 110, loss: 0.1485193520784378
step: 120, loss: 0.06642169505357742
step: 130, loss: 0.1262207180261612
step: 140, loss: 0.040748611092567444
step: 150, loss: 0.01981588453054428
step: 160, loss: 0.1462392807006836
step: 170, loss: 0.19540822505950928
step: 180, loss: 0.0642431229352951
step: 190, loss: 0.2511020302772522
step: 200, loss: 0.10968590527772903
step: 210, loss: 0.16098752617835999
step: 220, loss: 0.19038689136505127
step: 230, loss: 0.0544295497238636
step: 240, loss: 0.10316389799118042
step: 250, loss: 0.07196303457021713
step: 260, loss: 0.018093615770339966
step: 270, loss: 0.06496924161911011
step: 280, loss: 0.05342097952961922
step: 290, loss: 0.1255301833152771
step: 300, loss: 0.16528718173503876
step: 310, loss: 0.0871417447924614
step: 320, loss: 0.029828622937202454
step: 330, loss: 0.2499290108680725
step: 340, loss: 0.22740043699741364
step: 350, loss: 0.2548167109489441
step: 360, loss: 0.11788433790206909
step: 370, loss: 0.10422927141189575
step: 380, loss: 0.050120558589696884
epoch 3: dev_f1=0.7330097087378641, f1=0.7058823529411765, best_f1=0.7058823529411765
step: 0, loss: 0.10722697526216507
step: 10, loss: 0.025854168459773064
step: 20, loss: 0.10033734887838364
step: 30, loss: 0.12337695062160492
step: 40, loss: 0.08190838247537613
step: 50, loss: 0.11222703009843826
step: 60, loss: 0.13391047716140747
step: 70, loss: 0.05866766721010208
step: 80, loss: 0.08613016456365585
step: 90, loss: 0.13043354451656342
step: 100, loss: 0.17650845646858215
step: 110, loss: 0.06550323963165283
step: 120, loss: 0.21968083083629608
step: 130, loss: 0.1433723121881485
step: 140, loss: 0.21145857870578766
step: 150, loss: 0.11216142773628235
step: 160, loss: 0.11709490418434143
step: 170, loss: 0.10717401653528214
step: 180, loss: 0.05123789235949516
step: 190, loss: 0.05272180587053299
step: 200, loss: 0.16155162453651428
step: 210, loss: 0.03194549307227135
step: 220, loss: 0.36452218890190125
step: 230, loss: 0.2177838683128357
step: 240, loss: 0.17811492085456848
step: 250, loss: 0.13467711210250854
step: 260, loss: 0.1133042722940445
step: 270, loss: 0.04560580477118492
step: 280, loss: 0.12047398835420609
step: 290, loss: 0.03567222133278847
step: 300, loss: 0.045780934393405914
step: 310, loss: 0.206308051943779
step: 320, loss: 0.07519420981407166
step: 330, loss: 0.012737831100821495
step: 340, loss: 0.2478412538766861
step: 350, loss: 0.03516291454434395
step: 360, loss: 0.2882062494754791
step: 370, loss: 0.11346130818128586
step: 380, loss: 0.05336030200123787
epoch 4: dev_f1=0.7564766839378239, f1=0.6717948717948719, best_f1=0.6717948717948719
step: 0, loss: 0.06862223148345947
step: 10, loss: 0.034271400421857834
step: 20, loss: 0.037706248462200165
step: 30, loss: 0.1171557754278183
step: 40, loss: 0.05265030264854431
step: 50, loss: 0.07264193147420883
step: 60, loss: 0.056197624653577805
step: 70, loss: 0.023722583428025246
step: 80, loss: 0.10581455379724503
step: 90, loss: 0.1618775874376297
step: 100, loss: 0.061848901212215424
step: 110, loss: 0.2315337359905243
step: 120, loss: 0.09095395356416702
step: 130, loss: 0.02240048162639141
step: 140, loss: 0.1545659303665161
step: 150, loss: 0.07109668850898743
step: 160, loss: 0.06622476130723953
step: 170, loss: 0.13604575395584106
step: 180, loss: 0.09552643448114395
step: 190, loss: 0.09009785950183868
step: 200, loss: 0.11643318831920624
step: 210, loss: 0.0882883295416832
step: 220, loss: 0.05293526127934456
step: 230, loss: 0.051083240658044815
step: 240, loss: 0.1442975401878357
step: 250, loss: 0.2061329036951065
step: 260, loss: 0.030682068318128586
step: 270, loss: 0.06552787870168686
step: 280, loss: 0.15272381901741028
step: 290, loss: 0.06271238625049591
step: 300, loss: 0.09414539486169815
step: 310, loss: 0.06442146748304367
step: 320, loss: 0.08045611530542374
step: 330, loss: 0.06006956100463867
step: 340, loss: 0.04912064969539642
step: 350, loss: 0.1407145857810974
step: 360, loss: 0.08969953656196594
step: 370, loss: 0.013714873231947422
step: 380, loss: 0.11478748917579651
epoch 5: dev_f1=0.7651331719128329, f1=0.7201946472019465, best_f1=0.7201946472019465
step: 0, loss: 0.06756183505058289
step: 10, loss: 0.0762995183467865
step: 20, loss: 0.10225129127502441
step: 30, loss: 0.049413640052080154
step: 40, loss: 0.10987601429224014
step: 50, loss: 0.05294044315814972
step: 60, loss: 0.035718221217393875
step: 70, loss: 0.10829097777605057
step: 80, loss: 0.07681754976511002
step: 90, loss: 0.0403442420065403
step: 100, loss: 0.030041243880987167
step: 110, loss: 0.05549721419811249
step: 120, loss: 0.09394635260105133
step: 130, loss: 0.13308607041835785
step: 140, loss: 0.0291197057813406
step: 150, loss: 0.12455964088439941
step: 160, loss: 0.04679546877741814
step: 170, loss: 0.12801231443881989
step: 180, loss: 0.0522618293762207
step: 190, loss: 0.3052673637866974
step: 200, loss: 0.14711888134479523
step: 210, loss: 0.1857621818780899
step: 220, loss: 0.03726990148425102
step: 230, loss: 0.13547314703464508
step: 240, loss: 0.12343932688236237
step: 250, loss: 0.04629315808415413
step: 260, loss: 0.11232876777648926
step: 270, loss: 0.1289333999156952
step: 280, loss: 0.0935007631778717
step: 290, loss: 0.07908429950475693
step: 300, loss: 0.045290932059288025
step: 310, loss: 0.266029417514801
step: 320, loss: 0.011479699984192848
step: 330, loss: 0.042787693440914154
step: 340, loss: 0.1379459798336029
step: 350, loss: 0.1555432826280594
step: 360, loss: 0.05379811301827431
step: 370, loss: 0.13312968611717224
step: 380, loss: 0.13692042231559753
epoch 6: dev_f1=0.7445255474452556, f1=0.6906474820143885, best_f1=0.7201946472019465
step: 0, loss: 0.1807638704776764
step: 10, loss: 0.0189505722373724
step: 20, loss: 0.026416003704071045
step: 30, loss: 0.14366514980793
step: 40, loss: 0.04046005755662918
step: 50, loss: 0.043827082961797714
step: 60, loss: 0.05586531385779381
step: 70, loss: 0.0025965890381485224
step: 80, loss: 0.04334484040737152
step: 90, loss: 0.041736334562301636
step: 100, loss: 0.06192943453788757
step: 110, loss: 0.017463453114032745
step: 120, loss: 0.041433077305555344
step: 130, loss: 0.05930967628955841
step: 140, loss: 0.07884237915277481
step: 150, loss: 0.04076181724667549
step: 160, loss: 0.047218743711709976
step: 170, loss: 0.06581534445285797
step: 180, loss: 0.07328055053949356
step: 190, loss: 0.06616919487714767
step: 200, loss: 0.09429047256708145
step: 210, loss: 0.05216138809919357
step: 220, loss: 0.014778685756027699
step: 230, loss: 0.14793646335601807
step: 240, loss: 0.044864848256111145
step: 250, loss: 0.05124865099787712
step: 260, loss: 0.01326580811291933
step: 270, loss: 0.02057238481938839
step: 280, loss: 0.03261420503258705
step: 290, loss: 0.04597293213009834
step: 300, loss: 0.020147893577814102
step: 310, loss: 0.03701777756214142
step: 320, loss: 0.033676087856292725
step: 330, loss: 0.16005253791809082
step: 340, loss: 0.0685025230050087
step: 350, loss: 0.028180532157421112
step: 360, loss: 0.1144467368721962
step: 370, loss: 0.04835265874862671
step: 380, loss: 0.09620797634124756
epoch 7: dev_f1=0.7237163814180928, f1=0.7076167076167075, best_f1=0.7201946472019465
step: 0, loss: 0.03849348798394203
step: 10, loss: 0.04799520596861839
step: 20, loss: 0.10600907355546951
step: 30, loss: 0.03146237134933472
step: 40, loss: 0.04779205098748207
step: 50, loss: 0.04681040719151497
step: 60, loss: 0.02607402577996254
step: 70, loss: 0.05801701918244362
step: 80, loss: 0.1304953545331955
step: 90, loss: 0.042983874678611755
step: 100, loss: 0.05934900417923927
step: 110, loss: 0.042119912803173065
step: 120, loss: 0.05416753888130188
step: 130, loss: 0.057290565222501755
step: 140, loss: 0.03157178685069084
step: 150, loss: 0.11028013378381729
step: 160, loss: 0.059238988906145096
step: 170, loss: 0.09472163021564484
step: 180, loss: 0.03622163459658623
step: 190, loss: 0.08699912577867508
step: 200, loss: 0.15634089708328247
step: 210, loss: 0.011890332214534283
step: 220, loss: 0.06382707506418228
step: 230, loss: 0.007093118503689766
step: 240, loss: 0.1307404637336731
step: 250, loss: 0.09716508537530899
step: 260, loss: 0.09992097318172455
step: 270, loss: 0.04115908965468407
step: 280, loss: 0.12496070563793182
step: 290, loss: 0.3467157483100891
step: 300, loss: 0.13202248513698578
step: 310, loss: 0.027114372700452805
step: 320, loss: 0.03512812778353691
step: 330, loss: 0.1295544058084488
step: 340, loss: 0.04095187038183212
step: 350, loss: 0.05856957286596298
step: 360, loss: 0.04808642342686653
step: 370, loss: 0.059766434133052826
step: 380, loss: 0.07925566285848618
epoch 8: dev_f1=0.7538461538461538, f1=0.7286821705426356, best_f1=0.7201946472019465
step: 0, loss: 0.045679476112127304
step: 10, loss: 0.0333787240087986
step: 20, loss: 0.16047103703022003
step: 30, loss: 0.05231889709830284
step: 40, loss: 0.0008047267911024392
step: 50, loss: 0.024279505014419556
step: 60, loss: 0.022018251940608025
step: 70, loss: 0.07599901407957077
step: 80, loss: 0.10503964871168137
step: 90, loss: 0.045952342450618744
step: 100, loss: 0.013006096705794334
step: 110, loss: 0.05070560425519943
step: 120, loss: 0.07587333023548126
step: 130, loss: 0.06852297484874725
step: 140, loss: 0.03285473212599754
step: 150, loss: 0.02995697222650051
step: 160, loss: 0.010273252613842487
step: 170, loss: 0.14352251589298248
step: 180, loss: 0.0547214038670063
step: 190, loss: 0.03669872134923935
step: 200, loss: 0.11936305463314056
step: 210, loss: 0.01961214654147625
step: 220, loss: 0.21310503780841827
step: 230, loss: 0.09016454964876175
step: 240, loss: 0.09121191501617432
step: 250, loss: 0.032154764980077744
step: 260, loss: 0.13307467103004456
step: 270, loss: 0.06253628432750702
step: 280, loss: 0.07318916916847229
step: 290, loss: 0.06037217006087303
step: 300, loss: 0.08134203404188156
step: 310, loss: 0.08361983299255371
step: 320, loss: 0.10236619412899017
step: 330, loss: 0.06612968444824219
step: 340, loss: 0.10470201820135117
step: 350, loss: 0.13701839745044708
step: 360, loss: 0.07122472673654556
step: 370, loss: 0.060472141951322556
step: 380, loss: 0.08221972733736038
epoch 9: dev_f1=0.7655502392344496, f1=0.7383863080684596, best_f1=0.7383863080684596
step: 0, loss: 0.08035670220851898
step: 10, loss: 0.04760764166712761
step: 20, loss: 0.054012931883335114
step: 30, loss: 0.044415395706892014
step: 40, loss: 0.13481158018112183
step: 50, loss: 0.023910081014037132
step: 60, loss: 0.05310436710715294
step: 70, loss: 0.21789227426052094
step: 80, loss: 0.08099386841058731
step: 90, loss: 0.017305372282862663
step: 100, loss: 0.042120128870010376
step: 110, loss: 0.048912983387708664
step: 120, loss: 0.06456221640110016
step: 130, loss: 0.025206753984093666
step: 140, loss: 0.12108942121267319
step: 150, loss: 0.13027174770832062
step: 160, loss: 0.03792363405227661
step: 170, loss: 0.06494206190109253
step: 180, loss: 0.03920406475663185
step: 190, loss: 0.04959607869386673
step: 200, loss: 0.08061545342206955
step: 210, loss: 0.08284579962491989
step: 220, loss: 0.02832101844251156
step: 230, loss: 0.11089954525232315
step: 240, loss: 0.07485607266426086
step: 250, loss: 0.14681613445281982
step: 260, loss: 0.006813954096287489
step: 270, loss: 0.033184681087732315
step: 280, loss: 0.07989578694105148
step: 290, loss: 0.05720986798405647
step: 300, loss: 0.07941463589668274
step: 310, loss: 0.06057249382138252
step: 320, loss: 0.08863160759210587
step: 330, loss: 0.021278059110045433
step: 340, loss: 0.06872361153364182
step: 350, loss: 0.028595231473445892
step: 360, loss: 0.038074906915426254
step: 370, loss: 0.09041433781385422
step: 380, loss: 0.0801829844713211
epoch 10: dev_f1=0.7410926365795725, f1=0.7263922518159805, best_f1=0.7383863080684596
step: 0, loss: 0.0006745816208422184
step: 10, loss: 0.03351607173681259
step: 20, loss: 0.13181447982788086
step: 30, loss: 0.0051181139424443245
step: 40, loss: 0.009761265479028225
step: 50, loss: 0.073001928627491
step: 60, loss: 0.040794990956783295
step: 70, loss: 0.0760163888335228
step: 80, loss: 0.07009632885456085
step: 90, loss: 0.028985485434532166
step: 100, loss: 0.0683145672082901
step: 110, loss: 0.021427487954497337
step: 120, loss: 0.08462074398994446
step: 130, loss: 0.061619020998477936
step: 140, loss: 0.026926981285214424
step: 150, loss: 0.1577572375535965
step: 160, loss: 0.05069253221154213
step: 170, loss: 0.0005897453520447016
step: 180, loss: 0.05158253014087677
step: 190, loss: 0.009835679084062576
step: 200, loss: 0.05554385483264923
step: 210, loss: 0.019766608253121376
step: 220, loss: 0.025809425860643387
step: 230, loss: 0.014838945120573044
step: 240, loss: 0.07549019902944565
step: 250, loss: 0.034233156591653824
step: 260, loss: 0.055290210992097855
step: 270, loss: 0.06781860440969467
step: 280, loss: 0.011535433121025562
step: 290, loss: 0.04311046376824379
step: 300, loss: 0.0714557096362114
step: 310, loss: 0.07593244314193726
step: 320, loss: 0.03633428364992142
step: 330, loss: 0.11108076572418213
step: 340, loss: 0.04125966504216194
step: 350, loss: 0.04822918027639389
step: 360, loss: 0.09508804976940155
step: 370, loss: 0.07211428135633469
step: 380, loss: 0.05936615914106369
epoch 11: dev_f1=0.7470449172576832, f1=0.7132867132867134, best_f1=0.7383863080684596
step: 0, loss: 0.0341419018805027
step: 10, loss: 0.025847267359495163
step: 20, loss: 0.02162037417292595
step: 30, loss: 0.0750097781419754
step: 40, loss: 0.07856571674346924
step: 50, loss: 0.00800355151295662
step: 60, loss: 0.03036259114742279
step: 70, loss: 0.04481334984302521
step: 80, loss: 0.09641905128955841
step: 90, loss: 0.010871370323002338
step: 100, loss: 0.052987005561590195
step: 110, loss: 0.012648019008338451
step: 120, loss: 0.12685784697532654
step: 130, loss: 0.02808658964931965
step: 140, loss: 0.008794961497187614
step: 150, loss: 0.03995352238416672
step: 160, loss: 0.12025253474712372
step: 170, loss: 0.025683781132102013
step: 180, loss: 0.06567812711000443
step: 190, loss: 0.00033473962685093284
step: 200, loss: 0.11893853545188904
step: 210, loss: 0.03985022008419037
step: 220, loss: 0.026568230241537094
step: 230, loss: 0.07514510303735733
step: 240, loss: 0.04411279037594795
step: 250, loss: 0.07653509825468063
step: 260, loss: 0.030804812908172607
step: 270, loss: 0.06406213343143463
step: 280, loss: 0.05730277672410011
step: 290, loss: 0.1490122228860855
step: 300, loss: 0.04921889677643776
step: 310, loss: 0.03484126552939415
step: 320, loss: 0.01883639022707939
step: 330, loss: 0.05107012391090393
step: 340, loss: 0.05757131800055504
step: 350, loss: 0.1316383332014084
step: 360, loss: 0.03402957320213318
step: 370, loss: 0.07351303100585938
step: 380, loss: 0.047740183770656586
epoch 12: dev_f1=0.7488372093023257, f1=0.7255369928400954, best_f1=0.7383863080684596
step: 0, loss: 0.06082058697938919
step: 10, loss: 0.014314503408968449
step: 20, loss: 0.08272945135831833
step: 30, loss: 0.02104787714779377
step: 40, loss: 0.028025390580296516
step: 50, loss: 0.20084857940673828
step: 60, loss: 0.14761468768119812
step: 70, loss: 0.05593142658472061
step: 80, loss: 0.06476344168186188
step: 90, loss: 0.05514328181743622
step: 100, loss: 0.04767123609781265
step: 110, loss: 0.03006335347890854
step: 120, loss: 0.00405926164239645
step: 130, loss: 0.14089885354042053
step: 140, loss: 0.06454617530107498
step: 150, loss: 0.012463757768273354
step: 160, loss: 0.004581756424158812
step: 170, loss: 0.045915018767118454
step: 180, loss: 0.0827341079711914
step: 190, loss: 0.019900131970643997
step: 200, loss: 0.04112113639712334
step: 210, loss: 0.030904939398169518
step: 220, loss: 0.040106624364852905
step: 230, loss: 0.03645579144358635
step: 240, loss: 0.0245774257928133
step: 250, loss: 0.0608353465795517
step: 260, loss: 0.07389312982559204
step: 270, loss: 0.009730199351906776
step: 280, loss: 0.07443717867136002
step: 290, loss: 0.021709565073251724
step: 300, loss: 0.010225153528153896
step: 310, loss: 0.09359290450811386
step: 320, loss: 0.037826333194971085
step: 330, loss: 0.09930343180894852
step: 340, loss: 0.07697562128305435
step: 350, loss: 0.07642312347888947
step: 360, loss: 0.004362862091511488
step: 370, loss: 0.095386803150177
step: 380, loss: 0.07407517731189728
epoch 13: dev_f1=0.760705289672544, f1=0.7487179487179487, best_f1=0.7383863080684596
step: 0, loss: 0.004366768524050713
step: 10, loss: 0.07684960961341858
step: 20, loss: 0.00048634636914357543
step: 30, loss: 0.021273069083690643
step: 40, loss: 0.05646608769893646
step: 50, loss: 0.0635882243514061
step: 60, loss: 0.0073364838026463985
step: 70, loss: 0.0064741685055196285
step: 80, loss: 0.0841769203543663
step: 90, loss: 0.05624040216207504
step: 100, loss: 4.0785755118122324e-05
step: 110, loss: 4.798411828232929e-05
step: 120, loss: 0.006677558179944754
step: 130, loss: 0.017438653856515884
step: 140, loss: 0.08277170360088348
step: 150, loss: 0.06727028638124466
step: 160, loss: 0.025597482919692993
step: 170, loss: 0.10792674124240875
step: 180, loss: 0.035491347312927246
step: 190, loss: 0.054163724184036255
step: 200, loss: 0.11827675998210907
step: 210, loss: 0.0363963358104229
step: 220, loss: 0.024981021881103516
step: 230, loss: 0.027861859649419785
step: 240, loss: 0.11088205128908157
step: 250, loss: 0.03622785583138466
step: 260, loss: 0.12854379415512085
step: 270, loss: 0.05737689882516861
step: 280, loss: 0.027398815378546715
step: 290, loss: 0.016235409304499626
step: 300, loss: 0.010800765827298164
step: 310, loss: 0.016038963571190834
step: 320, loss: 0.013212176039814949
step: 330, loss: 0.0033214353024959564
step: 340, loss: 0.0211316030472517
step: 350, loss: 0.015074009075760841
step: 360, loss: 0.09898717701435089
step: 370, loss: 0.05829843506217003
step: 380, loss: 0.06572859734296799
epoch 14: dev_f1=0.7331670822942644, f1=0.7240506329113923, best_f1=0.7383863080684596
step: 0, loss: 0.019557559862732887
step: 10, loss: 0.025534633547067642
step: 20, loss: 0.02024916745722294
step: 30, loss: 0.07542674243450165
step: 40, loss: 0.03704482689499855
step: 50, loss: 0.009552772156894207
step: 60, loss: 0.005388934165239334
step: 70, loss: 0.03800226002931595
step: 80, loss: 0.04921664297580719
step: 90, loss: 0.05154211074113846
step: 100, loss: 0.05441531538963318
step: 110, loss: 0.06321026384830475
step: 120, loss: 0.026493795216083527
step: 130, loss: 3.332034248160198e-05
step: 140, loss: 0.06796517223119736
step: 150, loss: 0.00873593334108591
step: 160, loss: 0.004915885627269745
step: 170, loss: 0.01844666711986065
step: 180, loss: 0.058366768062114716
step: 190, loss: 0.0855093002319336
step: 200, loss: 0.03608120232820511
step: 210, loss: 0.026499303057789803
step: 220, loss: 0.046173837035894394
step: 230, loss: 0.04845985770225525
step: 240, loss: 0.1663091480731964
step: 250, loss: 0.12865063548088074
step: 260, loss: 0.0296461284160614
step: 270, loss: 0.051969826221466064
step: 280, loss: 0.07843214273452759
step: 290, loss: 0.0007628751336596906
step: 300, loss: 0.009187317453324795
step: 310, loss: 0.06462221592664719
step: 320, loss: 0.028871191665530205
step: 330, loss: 0.014130054041743279
step: 340, loss: 0.019429363310337067
step: 350, loss: 0.010562306270003319
step: 360, loss: 0.0016581133240833879
step: 370, loss: 0.1184106171131134
step: 380, loss: 6.079286686144769e-05
epoch 15: dev_f1=0.7341176470588235, f1=0.7242206235011991, best_f1=0.7383863080684596
step: 0, loss: 0.01968756876885891
step: 10, loss: 0.032345373183488846
step: 20, loss: 6.887382187414914e-05
step: 30, loss: 0.03901126980781555
step: 40, loss: 0.015814654529094696
step: 50, loss: 0.013843974098563194
step: 60, loss: 0.0773443728685379
step: 70, loss: 0.01230830978602171
step: 80, loss: 0.0608244314789772
step: 90, loss: 0.045673515647649765
step: 100, loss: 0.047885119915008545
step: 110, loss: 0.008648202754557133
step: 120, loss: 0.07031165808439255
step: 130, loss: 0.07441835850477219
step: 140, loss: 0.08383015543222427
step: 150, loss: 0.012675006873905659
step: 160, loss: 0.08379236608743668
step: 170, loss: 0.0013571078889071941
step: 180, loss: 0.0012175532756373286
step: 190, loss: 0.002204585587605834
step: 200, loss: 0.09371867030858994
step: 210, loss: 0.0038931292947381735
step: 220, loss: 0.017371337860822678
step: 230, loss: 0.004379931837320328
step: 240, loss: 0.10958153754472733
step: 250, loss: 0.13700802624225616
step: 260, loss: 0.0015478176064789295
step: 270, loss: 0.01731552928686142
step: 280, loss: 0.011677099391818047
step: 290, loss: 0.014731674455106258
step: 300, loss: 0.12842237949371338
step: 310, loss: 0.057808730751276016
step: 320, loss: 0.024930458515882492
step: 330, loss: 0.02754526399075985
step: 340, loss: 0.0700840950012207
step: 350, loss: 0.01469454076141119
step: 360, loss: 0.10637637227773666
step: 370, loss: 0.06423573195934296
step: 380, loss: 0.0006619322812184691
epoch 16: dev_f1=0.7310704960835509, f1=0.7089947089947092, best_f1=0.7383863080684596
step: 0, loss: 0.09293542057275772
step: 10, loss: 0.0444122739136219
step: 20, loss: 0.07201290130615234
step: 30, loss: 0.07854466140270233
step: 40, loss: 0.08909706771373749
step: 50, loss: 0.02794680930674076
step: 60, loss: 0.03956717997789383
step: 70, loss: 0.0010688456241041422
step: 80, loss: 0.05772870033979416
step: 90, loss: 0.012612207792699337
step: 100, loss: 0.030658114701509476
step: 110, loss: 0.002660857979208231
step: 120, loss: 0.01627982221543789
step: 130, loss: 0.013826360926032066
step: 140, loss: 0.06773481518030167
step: 150, loss: 0.048066645860672
step: 160, loss: 0.029136639088392258
step: 170, loss: 0.04278535395860672
step: 180, loss: 0.0062842825427651405
step: 190, loss: 0.07530317455530167
step: 200, loss: 0.044536326080560684
step: 210, loss: 0.05900019407272339
step: 220, loss: 0.03889378905296326
step: 230, loss: 0.0850134864449501
step: 240, loss: 0.08482839912176132
step: 250, loss: 0.04766177386045456
step: 260, loss: 0.08518719673156738
step: 270, loss: 0.00481839245185256
step: 280, loss: 0.06092844903469086
step: 290, loss: 0.010281922295689583
step: 300, loss: 0.01520126685500145
step: 310, loss: 0.10624037683010101
step: 320, loss: 0.020540282130241394
step: 330, loss: 0.04688245803117752
step: 340, loss: 0.041229430586099625
step: 350, loss: 0.1217200979590416
step: 360, loss: 0.007374565117061138
step: 370, loss: 0.023998543620109558
step: 380, loss: 0.06333229690790176
epoch 17: dev_f1=0.7214854111405835, f1=0.7128205128205127, best_f1=0.7383863080684596
step: 0, loss: 0.08566724509000778
step: 10, loss: 0.0418524444103241
step: 20, loss: 0.004562315531075001
step: 30, loss: 0.021417485550045967
step: 40, loss: 0.048514049500226974
step: 50, loss: 0.061903782188892365
step: 60, loss: 0.04002695530653
step: 70, loss: 0.028690317645668983
step: 80, loss: 0.0005350700812414289
step: 90, loss: 0.08907471597194672
step: 100, loss: 0.04117973893880844
step: 110, loss: 0.005697242915630341
step: 120, loss: 0.02463931404054165
step: 130, loss: 3.983798887929879e-05
step: 140, loss: 0.00818564835935831
step: 150, loss: 0.1275080442428589
step: 160, loss: 0.032748281955718994
step: 170, loss: 0.08810547739267349
step: 180, loss: 0.0018689786083996296
step: 190, loss: 0.015547748655080795
step: 200, loss: 0.0345953069627285
step: 210, loss: 0.02407924458384514
step: 220, loss: 0.13172155618667603
step: 230, loss: 0.030322398990392685
step: 240, loss: 0.034878529608249664
step: 250, loss: 0.03615366294980049
step: 260, loss: 0.034772839397192
step: 270, loss: 0.028181595727801323
step: 280, loss: 0.0636887475848198
step: 290, loss: 0.03990573063492775
step: 300, loss: 0.011349298059940338
step: 310, loss: 0.07418053597211838
step: 320, loss: 0.0366608127951622
step: 330, loss: 0.007619769312441349
step: 340, loss: 0.03289069980382919
step: 350, loss: 0.023735275492072105
step: 360, loss: 0.03588128089904785
step: 370, loss: 0.11062081903219223
step: 380, loss: 0.038050152361392975
epoch 18: dev_f1=0.7409326424870466, f1=0.717557251908397, best_f1=0.7383863080684596
step: 0, loss: 0.08920427411794662
step: 10, loss: 0.037666283547878265
step: 20, loss: 0.16912643611431122
step: 30, loss: 0.013687171041965485
step: 40, loss: 0.07441075891256332
step: 50, loss: 0.024525433778762817
step: 60, loss: 0.0381605438888073
step: 70, loss: 0.06281225383281708
step: 80, loss: 0.011481126770377159
step: 90, loss: 0.03172892704606056
step: 100, loss: 0.027667388319969177
step: 110, loss: 0.04591573029756546
step: 120, loss: 0.06702642142772675
step: 130, loss: 0.00154655403457582
step: 140, loss: 0.0696490928530693
step: 150, loss: 0.01604435220360756
step: 160, loss: 0.019584737718105316
step: 170, loss: 0.03258662298321724
step: 180, loss: 0.07868600636720657
step: 190, loss: 2.8638676667469554e-05
step: 200, loss: 0.06007394939661026
step: 210, loss: 0.027328845113515854
step: 220, loss: 0.03187241777777672
step: 230, loss: 0.07376299798488617
step: 240, loss: 0.008928423747420311
step: 250, loss: 0.03618703782558441
step: 260, loss: 0.04886539652943611
step: 270, loss: 0.005476155783981085
step: 280, loss: 0.016191931441426277
step: 290, loss: 0.030319226905703545
step: 300, loss: 0.07985414564609528
step: 310, loss: 0.017039265483617783
step: 320, loss: 3.861438744934276e-05
step: 330, loss: 0.04600570350885391
step: 340, loss: 0.043207261711359024
step: 350, loss: 0.03155284747481346
step: 360, loss: 4.4159060053061694e-05
step: 370, loss: 0.08354116976261139
step: 380, loss: 0.01661704108119011
epoch 19: dev_f1=0.7180851063829788, f1=0.6979166666666666, best_f1=0.7383863080684596
step: 0, loss: 0.01392797939479351
step: 10, loss: 0.006669409107416868
step: 20, loss: 0.06875459849834442
step: 30, loss: 0.03583364188671112
step: 40, loss: 0.011814038269221783
step: 50, loss: 1.8737948266789317e-05
step: 60, loss: 0.0007007157546468079
step: 70, loss: 0.06826220452785492
step: 80, loss: 0.01901504024863243
step: 90, loss: 0.03719552978873253
step: 100, loss: 0.0018239363562315702
step: 110, loss: 0.05670061334967613
step: 120, loss: 0.06586889922618866
step: 130, loss: 0.06770171970129013
step: 140, loss: 0.0003291541070211679
step: 150, loss: 0.0012865912867709994
step: 160, loss: 0.022580569609999657
step: 170, loss: 0.012943151406943798
step: 180, loss: 0.05072392523288727
step: 190, loss: 0.003823116421699524
step: 200, loss: 0.00741391209885478
step: 210, loss: 0.0003519709571264684
step: 220, loss: 0.019800055772066116
step: 230, loss: 0.0033260418567806482
step: 240, loss: 0.006282329559326172
step: 250, loss: 0.02853241190314293
step: 260, loss: 0.04061058908700943
step: 270, loss: 0.05819931998848915
step: 280, loss: 0.10707246512174606
step: 290, loss: 0.046962637454271317
step: 300, loss: 0.040794745087623596
step: 310, loss: 0.012715307995676994
step: 320, loss: 0.0868292823433876
step: 330, loss: 0.010810836218297482
step: 340, loss: 0.023638373240828514
step: 350, loss: 0.050798673182725906
step: 360, loss: 0.07557012140750885
step: 370, loss: 0.011432099156081676
step: 380, loss: 0.014826036989688873
epoch 20: dev_f1=0.7301587301587302, f1=0.7028423772609819, best_f1=0.7383863080684596
