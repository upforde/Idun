cuda
Device: cuda
step: 0, loss: 0.7515921592712402
step: 10, loss: 0.2568119466304779
step: 20, loss: 0.3731095492839813
step: 30, loss: 0.1590866595506668
step: 40, loss: 0.3968590795993805
step: 50, loss: 0.2069709599018097
step: 60, loss: 0.46264490485191345
step: 70, loss: 0.1721072643995285
step: 80, loss: 0.25584936141967773
step: 90, loss: 0.29482993483543396
step: 100, loss: 0.14877980947494507
step: 110, loss: 0.5286967754364014
step: 120, loss: 0.27983883023262024
step: 130, loss: 0.4148501753807068
step: 140, loss: 0.3704867959022522
step: 150, loss: 0.28123557567596436
step: 160, loss: 0.4181535243988037
step: 170, loss: 0.03598179295659065
step: 180, loss: 0.04007771238684654
step: 190, loss: 0.028174398466944695
step: 200, loss: 0.2653784453868866
step: 210, loss: 0.3023780584335327
step: 220, loss: 0.1083650141954422
step: 230, loss: 0.3291698098182678
step: 240, loss: 0.04905249923467636
step: 250, loss: 0.04792307689785957
step: 260, loss: 0.20523524284362793
step: 270, loss: 0.027894239872694016
step: 280, loss: 0.07182580232620239
step: 290, loss: 0.11829692870378494
step: 300, loss: 0.07858900725841522
step: 310, loss: 0.3351467549800873
step: 320, loss: 0.16871671378612518
step: 330, loss: 0.3088206350803375
step: 340, loss: 0.13321906328201294
step: 350, loss: 0.06122082844376564
step: 360, loss: 0.23760215938091278
step: 370, loss: 0.03906529024243355
step: 380, loss: 0.24694746732711792
epoch 1: dev_f1=0.5555555555555556, f1=0.5248618784530387, best_f1=0.5248618784530387
step: 0, loss: 0.15307332575321198
step: 10, loss: 0.08383943140506744
step: 20, loss: 0.27103742957115173
step: 30, loss: 0.17902378737926483
step: 40, loss: 0.2974873185157776
step: 50, loss: 0.10496634244918823
step: 60, loss: 0.046872589737176895
step: 70, loss: 0.11537983268499374
step: 80, loss: 0.13752970099449158
step: 90, loss: 0.08317515254020691
step: 100, loss: 0.170624777674675
step: 110, loss: 0.08400838822126389
step: 120, loss: 0.25948524475097656
step: 130, loss: 0.07732166349887848
step: 140, loss: 0.10619866847991943
step: 150, loss: 0.24963384866714478
step: 160, loss: 0.1444341093301773
step: 170, loss: 0.13102738559246063
step: 180, loss: 0.45668119192123413
step: 190, loss: 0.24244683980941772
step: 200, loss: 0.1940287947654724
step: 210, loss: 0.16156716644763947
step: 220, loss: 0.06332554668188095
step: 230, loss: 0.14875800907611847
step: 240, loss: 0.028305629268288612
step: 250, loss: 0.17028895020484924
step: 260, loss: 0.09303160011768341
step: 270, loss: 0.08513910323381424
step: 280, loss: 0.0816490650177002
step: 290, loss: 0.08047349750995636
step: 300, loss: 0.01713770255446434
step: 310, loss: 0.2241525799036026
step: 320, loss: 0.09205175936222076
step: 330, loss: 0.056394077837467194
step: 340, loss: 0.11215213686227798
step: 350, loss: 0.10178210586309433
step: 360, loss: 0.12369827181100845
step: 370, loss: 0.08067147433757782
step: 380, loss: 0.02326059527695179
epoch 2: dev_f1=0.7020785219399538, f1=0.674473067915691, best_f1=0.674473067915691
step: 0, loss: 0.11218471825122833
step: 10, loss: 0.12107225507497787
step: 20, loss: 0.1823028028011322
step: 30, loss: 0.05373145639896393
step: 40, loss: 0.18939729034900665
step: 50, loss: 0.0523478202521801
step: 60, loss: 0.11803437024354935
step: 70, loss: 0.11973635107278824
step: 80, loss: 0.09076434373855591
step: 90, loss: 0.19512057304382324
step: 100, loss: 0.13088779151439667
step: 110, loss: 0.10063129663467407
step: 120, loss: 0.1640545278787613
step: 130, loss: 0.10895195603370667
step: 140, loss: 0.09540924429893494
step: 150, loss: 0.1461460292339325
step: 160, loss: 0.11890870332717896
step: 170, loss: 0.02463141456246376
step: 180, loss: 0.07890865206718445
step: 190, loss: 0.0943656638264656
step: 200, loss: 0.069473497569561
step: 210, loss: 0.1064000129699707
step: 220, loss: 0.20015333592891693
step: 230, loss: 0.21056076884269714
step: 240, loss: 0.15315254032611847
step: 250, loss: 0.11613697558641434
step: 260, loss: 0.05876290425658226
step: 270, loss: 0.11625627428293228
step: 280, loss: 0.1159685030579567
step: 290, loss: 0.13701112568378448
step: 300, loss: 0.14639635384082794
step: 310, loss: 0.09054933488368988
step: 320, loss: 0.014355555176734924
step: 330, loss: 0.09761764854192734
step: 340, loss: 0.04600353538990021
step: 350, loss: 0.0860866978764534
step: 360, loss: 0.19331245124340057
step: 370, loss: 0.10186214745044708
step: 380, loss: 0.1451180875301361
epoch 3: dev_f1=0.7066974595842958, f1=0.6976744186046513, best_f1=0.6976744186046513
step: 0, loss: 0.1726999580860138
step: 10, loss: 0.1610017567873001
step: 20, loss: 0.030082497745752335
step: 30, loss: 0.041430793702602386
step: 40, loss: 0.1866137534379959
step: 50, loss: 0.12231051176786423
step: 60, loss: 0.1052541732788086
step: 70, loss: 0.04038701206445694
step: 80, loss: 0.10384514927864075
step: 90, loss: 0.08087048679590225
step: 100, loss: 0.20577259361743927
step: 110, loss: 0.0415005199611187
step: 120, loss: 0.05896831676363945
step: 130, loss: 0.04284963384270668
step: 140, loss: 0.1217980831861496
step: 150, loss: 0.10963456332683563
step: 160, loss: 0.1083049550652504
step: 170, loss: 0.04586237668991089
step: 180, loss: 0.03791987523436546
step: 190, loss: 0.06427828967571259
step: 200, loss: 0.06607334315776825
step: 210, loss: 0.02681661956012249
step: 220, loss: 0.07603361457586288
step: 230, loss: 0.08698452264070511
step: 240, loss: 0.02343297190964222
step: 250, loss: 0.18371473252773285
step: 260, loss: 0.11351020634174347
step: 270, loss: 0.23558324575424194
step: 280, loss: 0.11881030350923538
step: 290, loss: 0.048249732702970505
step: 300, loss: 0.17526878416538239
step: 310, loss: 0.10355055332183838
step: 320, loss: 0.09961685538291931
step: 330, loss: 0.15816280245780945
step: 340, loss: 0.10571122914552689
step: 350, loss: 0.07585552334785461
step: 360, loss: 0.06783804297447205
step: 370, loss: 0.036428920924663544
step: 380, loss: 0.06085812672972679
epoch 4: dev_f1=0.689119170984456, f1=0.671957671957672, best_f1=0.6976744186046513
step: 0, loss: 0.12350770086050034
step: 10, loss: 0.10852319002151489
step: 20, loss: 0.15170173346996307
step: 30, loss: 0.07099315524101257
step: 40, loss: 0.0795309841632843
step: 50, loss: 0.04357105866074562
step: 60, loss: 0.17582567036151886
step: 70, loss: 0.11763042211532593
step: 80, loss: 0.08989154547452927
step: 90, loss: 0.22816967964172363
step: 100, loss: 0.01852942444384098
step: 110, loss: 0.05788043141365051
step: 120, loss: 0.05900711938738823
step: 130, loss: 0.02218496799468994
step: 140, loss: 0.10566321015357971
step: 150, loss: 0.16019855439662933
step: 160, loss: 0.023529162630438805
step: 170, loss: 0.16726844012737274
step: 180, loss: 0.06476905941963196
step: 190, loss: 0.11789807677268982
step: 200, loss: 0.10777077078819275
step: 210, loss: 0.03422772139310837
step: 220, loss: 0.04904458299279213
step: 230, loss: 0.1312696933746338
step: 240, loss: 0.0935380756855011
step: 250, loss: 0.1405370980501175
step: 260, loss: 0.2037682831287384
step: 270, loss: 0.12593717873096466
step: 280, loss: 0.16660131514072418
step: 290, loss: 0.08294487744569778
step: 300, loss: 0.09805767983198166
step: 310, loss: 0.1589750200510025
step: 320, loss: 0.13008397817611694
step: 330, loss: 0.025117948651313782
step: 340, loss: 0.07468249648809433
step: 350, loss: 0.1741454303264618
step: 360, loss: 0.16957339644432068
step: 370, loss: 0.0924421176314354
step: 380, loss: 0.14948956668376923
epoch 5: dev_f1=0.7183098591549296, f1=0.6523809523809525, best_f1=0.6523809523809525
step: 0, loss: 0.09484366327524185
step: 10, loss: 0.08918554335832596
step: 20, loss: 0.053658731281757355
step: 30, loss: 0.10368415713310242
step: 40, loss: 0.0218247901648283
step: 50, loss: 0.17601338028907776
step: 60, loss: 0.06342080235481262
step: 70, loss: 0.06598103791475296
step: 80, loss: 0.08873458951711655
step: 90, loss: 0.11055228859186172
step: 100, loss: 0.13205398619174957
step: 110, loss: 0.034503038972616196
step: 120, loss: 0.07360398024320602
step: 130, loss: 0.18483661115169525
step: 140, loss: 0.04475696384906769
step: 150, loss: 0.09253212809562683
step: 160, loss: 0.08235716819763184
step: 170, loss: 0.04864228516817093
step: 180, loss: 0.0396369993686676
step: 190, loss: 0.028205422684550285
step: 200, loss: 0.07712692767381668
step: 210, loss: 0.011195124126970768
step: 220, loss: 0.03898846358060837
step: 230, loss: 0.058813225477933884
step: 240, loss: 0.09746114909648895
step: 250, loss: 0.10017625987529755
step: 260, loss: 0.1076694056391716
step: 270, loss: 0.08629260212182999
step: 280, loss: 0.07627858221530914
step: 290, loss: 0.09578055143356323
step: 300, loss: 0.09131676703691483
step: 310, loss: 0.2454584687948227
step: 320, loss: 0.13657744228839874
step: 330, loss: 0.0470312125980854
step: 340, loss: 0.035687532275915146
step: 350, loss: 0.16790325939655304
step: 360, loss: 0.07688392698764801
step: 370, loss: 0.25664976239204407
step: 380, loss: 0.05838251858949661
epoch 6: dev_f1=0.7421686746987951, f1=0.7009803921568627, best_f1=0.7009803921568627
step: 0, loss: 0.06856577098369598
step: 10, loss: 0.022117754444479942
step: 20, loss: 0.07993048429489136
step: 30, loss: 0.1376645714044571
step: 40, loss: 0.08656574040651321
step: 50, loss: 0.044384244829416275
step: 60, loss: 0.06485559046268463
step: 70, loss: 0.10949664562940598
step: 80, loss: 0.052824124693870544
step: 90, loss: 0.04847605153918266
step: 100, loss: 0.11137598752975464
step: 110, loss: 0.08288227766752243
step: 120, loss: 0.13785074651241302
step: 130, loss: 0.03192128241062164
step: 140, loss: 0.06880046427249908
step: 150, loss: 0.07833171635866165
step: 160, loss: 0.06398188322782516
step: 170, loss: 0.030810944736003876
step: 180, loss: 0.08627304434776306
step: 190, loss: 0.13851676881313324
step: 200, loss: 0.041998133063316345
step: 210, loss: 0.08325418829917908
step: 220, loss: 0.06281571835279465
step: 230, loss: 0.018006455153226852
step: 240, loss: 0.03075757436454296
step: 250, loss: 0.11670681089162827
step: 260, loss: 0.07989627122879028
step: 270, loss: 0.0037921597249805927
step: 280, loss: 0.33669164776802063
step: 290, loss: 0.09729095548391342
step: 300, loss: 0.05513431504368782
step: 310, loss: 0.05884401127696037
step: 320, loss: 0.026955392211675644
step: 330, loss: 0.024599457159638405
step: 340, loss: 0.03375028446316719
step: 350, loss: 0.09484492242336273
step: 360, loss: 0.1020938903093338
step: 370, loss: 0.06445103883743286
step: 380, loss: 0.09331312030553818
epoch 7: dev_f1=0.7303921568627452, f1=0.7061855670103092, best_f1=0.7009803921568627
step: 0, loss: 0.11391675472259521
step: 10, loss: 0.0767771527171135
step: 20, loss: 0.12817861139774323
step: 30, loss: 0.041778869926929474
step: 40, loss: 0.09604403376579285
step: 50, loss: 0.1121501550078392
step: 60, loss: 0.037019792944192886
step: 70, loss: 0.09216291457414627
step: 80, loss: 0.012163521721959114
step: 90, loss: 0.07475768029689789
step: 100, loss: 0.03940179571509361
step: 110, loss: 0.037476133555173874
step: 120, loss: 0.06692232936620712
step: 130, loss: 0.09769563376903534
step: 140, loss: 0.041530005633831024
step: 150, loss: 0.04717409238219261
step: 160, loss: 0.13542397320270538
step: 170, loss: 0.030475886538624763
step: 180, loss: 0.12536749243736267
step: 190, loss: 0.02568753995001316
step: 200, loss: 0.02375687286257744
step: 210, loss: 0.1478101760149002
step: 220, loss: 0.05681239441037178
step: 230, loss: 0.08723695576190948
step: 240, loss: 0.028611117973923683
step: 250, loss: 0.022469930350780487
step: 260, loss: 0.013689195737242699
step: 270, loss: 0.07758764922618866
step: 280, loss: 0.06081794574856758
step: 290, loss: 0.08556875586509705
step: 300, loss: 0.07367159426212311
step: 310, loss: 0.0220258217304945
step: 320, loss: 0.05326244607567787
step: 330, loss: 0.02136990986764431
step: 340, loss: 0.03491931036114693
step: 350, loss: 0.017201822251081467
step: 360, loss: 0.08498158305883408
step: 370, loss: 0.07576902210712433
step: 380, loss: 0.015379044227302074
epoch 8: dev_f1=0.7577319587628867, f1=0.6900269541778975, best_f1=0.6900269541778975
step: 0, loss: 0.05439475551247597
step: 10, loss: 0.10528596490621567
step: 20, loss: 0.09159284830093384
step: 30, loss: 0.08818358182907104
step: 40, loss: 0.13506118953227997
step: 50, loss: 0.012894184328615665
step: 60, loss: 0.07943720370531082
step: 70, loss: 0.017576035112142563
step: 80, loss: 0.0363144613802433
step: 90, loss: 0.043804943561553955
step: 100, loss: 0.030796285718679428
step: 110, loss: 0.03786570206284523
step: 120, loss: 0.061409514397382736
step: 130, loss: 0.03673133626580238
step: 140, loss: 0.09561935812234879
step: 150, loss: 0.04891003668308258
step: 160, loss: 0.09085938334465027
step: 170, loss: 0.020065661519765854
step: 180, loss: 0.1625673919916153
step: 190, loss: 0.07765576988458633
step: 200, loss: 0.3253508508205414
step: 210, loss: 0.036989420652389526
step: 220, loss: 0.0597505159676075
step: 230, loss: 0.03505021706223488
step: 240, loss: 0.03312591090798378
step: 250, loss: 0.1112871915102005
step: 260, loss: 0.0074790045619010925
step: 270, loss: 0.06353020668029785
step: 280, loss: 0.05285070091485977
step: 290, loss: 0.07038214802742004
step: 300, loss: 0.12374864518642426
step: 310, loss: 0.06330318003892899
step: 320, loss: 0.029496178030967712
step: 330, loss: 0.007807382382452488
step: 340, loss: 0.03332221508026123
step: 350, loss: 0.05734372138977051
step: 360, loss: 0.050282664597034454
step: 370, loss: 0.02307986654341221
step: 380, loss: 0.08685987442731857
epoch 9: dev_f1=0.7260579064587974, f1=0.6743648960739029, best_f1=0.6900269541778975
step: 0, loss: 0.008129174821078777
step: 10, loss: 0.07868222147226334
step: 20, loss: 0.038751281797885895
step: 30, loss: 0.07002171874046326
step: 40, loss: 0.0400158166885376
step: 50, loss: 0.06789510697126389
step: 60, loss: 0.09541209787130356
step: 70, loss: 0.031192056834697723
step: 80, loss: 0.09663637727499008
step: 90, loss: 0.06968566030263901
step: 100, loss: 0.07042832672595978
step: 110, loss: 0.019174810498952866
step: 120, loss: 0.10609929263591766
step: 130, loss: 0.1314200758934021
step: 140, loss: 0.0807662233710289
step: 150, loss: 0.10793954879045486
step: 160, loss: 0.07228227704763412
step: 170, loss: 0.06113230064511299
step: 180, loss: 0.04343143478035927
step: 190, loss: 0.049538515508174896
step: 200, loss: 0.020778531208634377
step: 210, loss: 0.1371840089559555
step: 220, loss: 0.027058910578489304
step: 230, loss: 0.08301550894975662
step: 240, loss: 0.023737270385026932
step: 250, loss: 0.04492298141121864
step: 260, loss: 0.056673839688301086
step: 270, loss: 0.07596881687641144
step: 280, loss: 0.06004651263356209
step: 290, loss: 0.05939510464668274
step: 300, loss: 0.0603196881711483
step: 310, loss: 0.05673466995358467
step: 320, loss: 0.04247046634554863
step: 330, loss: 0.06800264865159988
step: 340, loss: 0.002054890850558877
step: 350, loss: 0.025675106793642044
step: 360, loss: 0.025680936872959137
step: 370, loss: 0.08828070759773254
step: 380, loss: 0.003991615958511829
epoch 10: dev_f1=0.7268408551068883, f1=0.6941747572815534, best_f1=0.6900269541778975
step: 0, loss: 0.06764430552721024
step: 10, loss: 0.034362196922302246
step: 20, loss: 0.00019951147260144353
step: 30, loss: 0.037707164883613586
step: 40, loss: 0.06455927342176437
step: 50, loss: 0.0002872991026379168
step: 60, loss: 0.03410966321825981
step: 70, loss: 0.05622426047921181
step: 80, loss: 0.04824134707450867
step: 90, loss: 0.07593723386526108
step: 100, loss: 0.10132494568824768
step: 110, loss: 0.002385156461969018
step: 120, loss: 0.010880447924137115
step: 130, loss: 0.056404441595077515
step: 140, loss: 0.08488670736551285
step: 150, loss: 0.0260305218398571
step: 160, loss: 0.05256224051117897
step: 170, loss: 0.05236104130744934
step: 180, loss: 0.11301626265048981
step: 190, loss: 0.04041922837495804
step: 200, loss: 0.0038622566498816013
step: 210, loss: 0.03896546736359596
step: 220, loss: 0.057168859988451004
step: 230, loss: 0.04552459344267845
step: 240, loss: 0.1320948451757431
step: 250, loss: 0.059252407401800156
step: 260, loss: 0.0774737149477005
step: 270, loss: 0.04239121824502945
step: 280, loss: 0.05978625640273094
step: 290, loss: 0.039476312696933746
step: 300, loss: 0.07463143020868301
step: 310, loss: 0.009618262760341167
step: 320, loss: 0.045063141733407974
step: 330, loss: 0.06849204003810883
step: 340, loss: 0.07542607933282852
step: 350, loss: 0.04935256019234657
step: 360, loss: 0.1285613775253296
step: 370, loss: 0.10008139163255692
step: 380, loss: 0.20744581520557404
epoch 11: dev_f1=0.7518796992481204, f1=0.6954314720812182, best_f1=0.6900269541778975
step: 0, loss: 0.016091663390398026
step: 10, loss: 0.053536731749773026
step: 20, loss: 0.015141434967517853
step: 30, loss: 0.044934287667274475
step: 40, loss: 0.03407736122608185
step: 50, loss: 0.0156681090593338
step: 60, loss: 0.11784850060939789
step: 70, loss: 0.00460902601480484
step: 80, loss: 0.04658162593841553
step: 90, loss: 0.06213696300983429
step: 100, loss: 0.04051538184285164
step: 110, loss: 0.05114106088876724
step: 120, loss: 0.04923151805996895
step: 130, loss: 0.015378089621663094
step: 140, loss: 0.03440285101532936
step: 150, loss: 0.015288636088371277
step: 160, loss: 0.17458757758140564
step: 170, loss: 0.030034780502319336
step: 180, loss: 0.011718886904418468
step: 190, loss: 0.02435189113020897
step: 200, loss: 0.06986218690872192
step: 210, loss: 0.09415528178215027
step: 220, loss: 0.07501908391714096
step: 230, loss: 0.050468266010284424
step: 240, loss: 0.032664570957422256
step: 250, loss: 0.08155497163534164
step: 260, loss: 0.08885257691144943
step: 270, loss: 0.0034289692994207144
step: 280, loss: 0.06655564159154892
step: 290, loss: 0.0017561180284246802
step: 300, loss: 0.08025394380092621
step: 310, loss: 0.03926888108253479
step: 320, loss: 0.04099349305033684
step: 330, loss: 0.12319320440292358
step: 340, loss: 0.08302947133779526
step: 350, loss: 0.03374071046710014
step: 360, loss: 0.18029730021953583
step: 370, loss: 0.053054969757795334
step: 380, loss: 0.17579242587089539
epoch 12: dev_f1=0.7533875338753386, f1=0.6739130434782608, best_f1=0.6900269541778975
step: 0, loss: 0.08355125784873962
step: 10, loss: 0.012615896761417389
step: 20, loss: 0.06996863335371017
step: 30, loss: 9.169024997390807e-05
step: 40, loss: 0.050522372126579285
step: 50, loss: 0.04876497760415077
step: 60, loss: 0.016903243958950043
step: 70, loss: 0.05191564932465553
step: 80, loss: 0.0257126297801733
step: 90, loss: 0.1271986961364746
step: 100, loss: 0.04440442472696304
step: 110, loss: 0.03832833841443062
step: 120, loss: 0.07793167233467102
step: 130, loss: 0.07298889756202698
step: 140, loss: 0.06642068922519684
step: 150, loss: 0.08028983324766159
step: 160, loss: 0.07435207068920135
step: 170, loss: 0.040006496012210846
step: 180, loss: 0.0378781221807003
step: 190, loss: 0.029092565178871155
step: 200, loss: 0.03390750288963318
step: 210, loss: 0.07733118534088135
step: 220, loss: 0.009559537284076214
step: 230, loss: 0.046084899455308914
step: 240, loss: 0.1205761730670929
step: 250, loss: 0.00015976255235727876
step: 260, loss: 0.14402297139167786
step: 270, loss: 0.03470136597752571
step: 280, loss: 0.1252845972776413
step: 290, loss: 0.05409468337893486
step: 300, loss: 0.0697406530380249
step: 310, loss: 0.004663254600018263
step: 320, loss: 0.08654560893774033
step: 330, loss: 0.014373606070876122
step: 340, loss: 0.04202260076999664
step: 350, loss: 0.026878975331783295
step: 360, loss: 0.03886239230632782
step: 370, loss: 0.014328248798847198
step: 380, loss: 0.16469310224056244
epoch 13: dev_f1=0.7277353689567431, f1=0.6789473684210526, best_f1=0.6900269541778975
step: 0, loss: 0.012936897575855255
step: 10, loss: 0.04438412934541702
step: 20, loss: 0.003606590908020735
step: 30, loss: 0.043076109141111374
step: 40, loss: 0.01611199788749218
step: 50, loss: 0.041444819420576096
step: 60, loss: 5.656242137774825e-05
step: 70, loss: 0.004653227515518665
step: 80, loss: 0.13180536031723022
step: 90, loss: 0.07515595853328705
step: 100, loss: 0.04082323983311653
step: 110, loss: 0.0394696407020092
step: 120, loss: 0.055539537221193314
step: 130, loss: 0.026012102141976357
step: 140, loss: 0.1119312271475792
step: 150, loss: 0.047817811369895935
step: 160, loss: 0.0560898594558239
step: 170, loss: 0.0027645519003272057
step: 180, loss: 0.10527792572975159
step: 190, loss: 0.03556519374251366
step: 200, loss: 0.09172974526882172
step: 210, loss: 0.05135626345872879
step: 220, loss: 0.05774784833192825
step: 230, loss: 0.023691032081842422
step: 240, loss: 0.028264392167329788
step: 250, loss: 0.0870952382683754
step: 260, loss: 0.0023122630082070827
step: 270, loss: 0.10632751137018204
step: 280, loss: 0.012019899673759937
step: 290, loss: 3.961717811762355e-05
step: 300, loss: 0.09443209320306778
step: 310, loss: 0.04337663948535919
step: 320, loss: 5.341976066119969e-05
step: 330, loss: 0.14599311351776123
step: 340, loss: 0.02941444329917431
step: 350, loss: 0.018165849149227142
step: 360, loss: 0.007319205440580845
step: 370, loss: 0.06152644008398056
step: 380, loss: 0.06196160241961479
epoch 14: dev_f1=0.7178217821782177, f1=0.6649616368286445, best_f1=0.6900269541778975
step: 0, loss: 0.007530516479164362
step: 10, loss: 0.018187208101153374
step: 20, loss: 0.052225787192583084
step: 30, loss: 0.0683819055557251
step: 40, loss: 0.02092132717370987
step: 50, loss: 0.0020053668413311243
step: 60, loss: 0.13603278994560242
step: 70, loss: 0.02857150509953499
step: 80, loss: 0.04880166053771973
step: 90, loss: 0.02671324834227562
step: 100, loss: 0.02465086616575718
step: 110, loss: 0.05460270121693611
step: 120, loss: 0.07778297364711761
step: 130, loss: 0.00018979990272782743
step: 140, loss: 0.00017211375234182924
step: 150, loss: 0.04867422953248024
step: 160, loss: 0.02669738233089447
step: 170, loss: 0.006114332005381584
step: 180, loss: 0.08402527868747711
step: 190, loss: 0.05637914687395096
step: 200, loss: 0.018300116062164307
step: 210, loss: 0.046829793602228165
step: 220, loss: 0.05593288317322731
step: 230, loss: 0.03271190822124481
step: 240, loss: 0.03455965593457222
step: 250, loss: 0.027987267822027206
step: 260, loss: 0.032104697078466415
step: 270, loss: 0.022933516651391983
step: 280, loss: 0.012618076987564564
step: 290, loss: 0.027514180168509483
step: 300, loss: 0.06401753425598145
step: 310, loss: 0.06774739921092987
step: 320, loss: 0.058045644313097
step: 330, loss: 0.042615193873643875
step: 340, loss: 0.059625592082738876
step: 350, loss: 0.0017026955028995872
step: 360, loss: 0.0011048418236896396
step: 370, loss: 0.019298862665891647
step: 380, loss: 0.002406203420832753
epoch 15: dev_f1=0.7317073170731708, f1=0.6865671641791045, best_f1=0.6900269541778975
step: 0, loss: 0.05484757944941521
step: 10, loss: 0.04359555244445801
step: 20, loss: 0.02014780603349209
step: 30, loss: 0.06284287571907043
step: 40, loss: 0.03170522302389145
step: 50, loss: 0.008575190789997578
step: 60, loss: 0.09849420934915543
step: 70, loss: 0.03179270401597023
step: 80, loss: 0.0416647307574749
step: 90, loss: 0.07143989950418472
step: 100, loss: 0.00038431596476584673
step: 110, loss: 0.01726316474378109
step: 120, loss: 0.05707591772079468
step: 130, loss: 0.09802456200122833
step: 140, loss: 0.008419781923294067
step: 150, loss: 0.08735832571983337
step: 160, loss: 0.030346296727657318
step: 170, loss: 0.0981583371758461
step: 180, loss: 0.11710440367460251
step: 190, loss: 0.03169708698987961
step: 200, loss: 0.003125834744423628
step: 210, loss: 4.697962503996678e-05
step: 220, loss: 0.1320192962884903
step: 230, loss: 0.011784028261899948
step: 240, loss: 0.03937096893787384
step: 250, loss: 0.0036960646975785494
step: 260, loss: 0.04867622256278992
step: 270, loss: 0.0038015975151211023
step: 280, loss: 0.029175108298659325
step: 290, loss: 0.04888908192515373
step: 300, loss: 0.016372818499803543
step: 310, loss: 0.020808253437280655
step: 320, loss: 0.00934857688844204
step: 330, loss: 0.019786929711699486
step: 340, loss: 0.037097636610269547
step: 350, loss: 0.034083765000104904
step: 360, loss: 0.10475229471921921
step: 370, loss: 0.030733855441212654
step: 380, loss: 0.049022164195775986
epoch 16: dev_f1=0.7263157894736842, f1=0.6738544474393531, best_f1=0.6900269541778975
step: 0, loss: 0.024256031960248947
step: 10, loss: 0.024822475388646126
step: 20, loss: 0.06285151839256287
step: 30, loss: 0.019672546535730362
step: 40, loss: 0.04248617962002754
step: 50, loss: 0.0003981050103902817
step: 60, loss: 0.01734212599694729
step: 70, loss: 0.01700386218726635
step: 80, loss: 0.034036096185445786
step: 90, loss: 0.010221804492175579
step: 100, loss: 0.007607606705278158
step: 110, loss: 0.026847004890441895
step: 120, loss: 0.015427439473569393
step: 130, loss: 0.02626298926770687
step: 140, loss: 0.02234978787600994
step: 150, loss: 0.0056156557984650135
step: 160, loss: 0.01636979542672634
step: 170, loss: 0.13952259719371796
step: 180, loss: 0.005897752940654755
step: 190, loss: 0.010672545991837978
step: 200, loss: 0.03412924334406853
step: 210, loss: 0.07459211349487305
step: 220, loss: 0.02931727096438408
step: 230, loss: 0.037406738847494125
step: 240, loss: 0.02760441042482853
step: 250, loss: 0.06429407745599747
step: 260, loss: 0.018031075596809387
step: 270, loss: 0.015593066811561584
step: 280, loss: 0.0007562620448879898
step: 290, loss: 0.013071945868432522
step: 300, loss: 0.08596377819776535
step: 310, loss: 0.11441773176193237
step: 320, loss: 0.0009517952566966414
step: 330, loss: 0.029249943792819977
step: 340, loss: 0.025585660710930824
step: 350, loss: 0.05356749892234802
step: 360, loss: 0.06971961259841919
step: 370, loss: 0.0005241286708042026
step: 380, loss: 0.07168401777744293
epoch 17: dev_f1=0.7228915662650602, f1=0.6798029556650247, best_f1=0.6900269541778975
step: 0, loss: 4.2183048208244145e-05
step: 10, loss: 0.06958014518022537
step: 20, loss: 0.0029353892896324396
step: 30, loss: 0.030775317922234535
step: 40, loss: 0.06167525425553322
step: 50, loss: 0.039989348500967026
step: 60, loss: 0.018089041113853455
step: 70, loss: 0.00013423383643385023
step: 80, loss: 0.004370613023638725
step: 90, loss: 0.009402642026543617
step: 100, loss: 0.06872561573982239
step: 110, loss: 0.02894631400704384
step: 120, loss: 0.041844021528959274
step: 130, loss: 0.10413718223571777
step: 140, loss: 0.026358187198638916
step: 150, loss: 3.1302788556786254e-05
step: 160, loss: 0.04662945494055748
step: 170, loss: 0.013794817961752415
step: 180, loss: 0.0950135886669159
step: 190, loss: 0.05910569429397583
step: 200, loss: 0.036225445568561554
step: 210, loss: 0.14101050794124603
step: 220, loss: 0.04667588323354721
step: 230, loss: 0.05070861428976059
step: 240, loss: 0.01406770944595337
step: 250, loss: 0.04583147540688515
step: 260, loss: 0.014840043149888515
step: 270, loss: 0.04574936255812645
step: 280, loss: 5.44370777788572e-05
step: 290, loss: 0.013137531466782093
step: 300, loss: 0.05299784615635872
step: 310, loss: 0.03833971917629242
step: 320, loss: 0.04669280722737312
step: 330, loss: 0.011224436573684216
step: 340, loss: 0.03145555406808853
step: 350, loss: 0.15379320085048676
step: 360, loss: 0.039695896208286285
step: 370, loss: 0.00016235483053606004
step: 380, loss: 0.08667181432247162
epoch 18: dev_f1=0.7202216066481995, f1=0.6342857142857143, best_f1=0.6900269541778975
step: 0, loss: 0.06567177176475525
step: 10, loss: 0.026473598554730415
step: 20, loss: 0.017895348370075226
step: 30, loss: 0.08685879409313202
step: 40, loss: 0.13253988325595856
step: 50, loss: 0.01901395618915558
step: 60, loss: 0.07638873159885406
step: 70, loss: 0.005435012746602297
step: 80, loss: 0.10898575186729431
step: 90, loss: 0.019123349338769913
step: 100, loss: 0.04289189353585243
step: 110, loss: 0.09829601645469666
step: 120, loss: 0.04433966055512428
step: 130, loss: 0.0006886190385557711
step: 140, loss: 0.0030386659782379866
step: 150, loss: 0.01900252141058445
step: 160, loss: 0.05541008710861206
step: 170, loss: 0.016310695558786392
step: 180, loss: 0.05343562364578247
step: 190, loss: 2.9179009288782254e-05
step: 200, loss: 0.041317250579595566
step: 210, loss: 0.03355628252029419
step: 220, loss: 0.11200912296772003
step: 230, loss: 0.0446556955575943
step: 240, loss: 0.023056279867887497
step: 250, loss: 0.0006029169308021665
step: 260, loss: 0.03383305296301842
step: 270, loss: 0.052231449633836746
step: 280, loss: 0.0016487244283780456
step: 290, loss: 0.09454388171434402
step: 300, loss: 0.02279992587864399
step: 310, loss: 0.06324197351932526
step: 320, loss: 0.15815061330795288
step: 330, loss: 0.037718936800956726
step: 340, loss: 0.001180154038593173
step: 350, loss: 0.02822418138384819
step: 360, loss: 0.016337523236870766
step: 370, loss: 0.04306763410568237
step: 380, loss: 0.03905859962105751
epoch 19: dev_f1=0.7195767195767196, f1=0.6520547945205479, best_f1=0.6900269541778975
step: 0, loss: 4.172826811554842e-05
step: 10, loss: 0.0150214321911335
step: 20, loss: 0.004917647689580917
step: 30, loss: 0.004046208690851927
step: 40, loss: 0.07424721121788025
step: 50, loss: 0.060894712805747986
step: 60, loss: 0.007987754419445992
step: 70, loss: 0.002812481950968504
step: 80, loss: 0.02428632788360119
step: 90, loss: 0.06946420669555664
step: 100, loss: 0.057054586708545685
step: 110, loss: 0.023584552109241486
step: 120, loss: 0.0402163565158844
step: 130, loss: 0.020538462325930595
step: 140, loss: 0.09126412868499756
step: 150, loss: 0.022103533148765564
step: 160, loss: 0.038715679198503494
step: 170, loss: 0.017519298940896988
step: 180, loss: 0.09539640694856644
step: 190, loss: 0.012034919112920761
step: 200, loss: 0.01359349861741066
step: 210, loss: 0.01773104816675186
step: 220, loss: 0.058613140136003494
step: 230, loss: 0.06473683565855026
step: 240, loss: 0.0014970469055697322
step: 250, loss: 0.0020348848775029182
step: 260, loss: 0.0564119778573513
step: 270, loss: 0.018756568431854248
step: 280, loss: 0.003833572380244732
step: 290, loss: 0.02657916583120823
step: 300, loss: 0.07394104450941086
step: 310, loss: 0.11203057318925858
step: 320, loss: 0.010284975171089172
step: 330, loss: 0.012806219048798084
step: 340, loss: 0.01855524629354477
step: 350, loss: 0.01617095246911049
step: 360, loss: 0.0012500963639467955
step: 370, loss: 0.02807939425110817
step: 380, loss: 0.046936556696891785
epoch 20: dev_f1=0.7166666666666668, f1=0.6345609065155806, best_f1=0.6900269541778975
