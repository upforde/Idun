cuda
Device: cuda
step: 0, loss: 0.5936973690986633
step: 10, loss: 0.23216818273067474
step: 20, loss: 0.20850947499275208
step: 30, loss: 0.147891104221344
step: 40, loss: 0.32827621698379517
step: 50, loss: 0.5071058869361877
step: 60, loss: 0.3582465946674347
step: 70, loss: 0.24080851674079895
step: 80, loss: 0.33287420868873596
step: 90, loss: 0.34714770317077637
step: 100, loss: 0.4376218318939209
step: 110, loss: 0.20320282876491547
step: 120, loss: 0.2548200488090515
step: 130, loss: 0.3722338080406189
step: 140, loss: 0.18887610733509064
step: 150, loss: 0.33922359347343445
step: 160, loss: 0.2425137758255005
step: 170, loss: 0.14956289529800415
step: 180, loss: 0.16993001103401184
step: 190, loss: 0.12880167365074158
step: 200, loss: 0.07845326513051987
step: 210, loss: 0.21134667098522186
step: 220, loss: 0.33586832880973816
step: 230, loss: 0.11566150188446045
step: 240, loss: 0.1581171751022339
step: 250, loss: 0.37567079067230225
step: 260, loss: 0.2477124035358429
step: 270, loss: 0.08609582483768463
step: 280, loss: 0.18606944382190704
step: 290, loss: 0.12194465845823288
step: 300, loss: 0.12928538024425507
step: 310, loss: 0.2846260070800781
step: 320, loss: 0.1331159770488739
step: 330, loss: 0.19268269836902618
step: 340, loss: 0.022772381082177162
step: 350, loss: 0.12355479598045349
step: 360, loss: 0.17936500906944275
step: 370, loss: 0.04757728800177574
step: 380, loss: 0.22171393036842346
epoch 1: dev_f1=0.5799457994579945, f1=0.5584045584045584, best_f1=0.5584045584045584
step: 0, loss: 0.2911376953125
step: 10, loss: 0.015886131674051285
step: 20, loss: 0.14707455039024353
step: 30, loss: 0.17852701246738434
step: 40, loss: 0.09528433531522751
step: 50, loss: 0.15273956954479218
step: 60, loss: 0.2371809184551239
step: 70, loss: 0.10875076800584793
step: 80, loss: 0.1828785538673401
step: 90, loss: 0.10069787502288818
step: 100, loss: 0.2669503688812256
step: 110, loss: 0.06081676483154297
step: 120, loss: 0.2931278944015503
step: 130, loss: 0.06198553740978241
step: 140, loss: 0.09933897107839584
step: 150, loss: 0.10703343152999878
step: 160, loss: 0.0936870351433754
step: 170, loss: 0.12820002436637878
step: 180, loss: 0.08275499939918518
step: 190, loss: 0.0625380426645279
step: 200, loss: 0.02271522581577301
step: 210, loss: 0.2610294818878174
step: 220, loss: 0.25651973485946655
step: 230, loss: 0.07379642128944397
step: 240, loss: 0.09524262696504593
step: 250, loss: 0.07700952887535095
step: 260, loss: 0.09336050599813461
step: 270, loss: 0.37759676575660706
step: 280, loss: 0.10196942090988159
step: 290, loss: 0.06983329355716705
step: 300, loss: 0.1183563768863678
step: 310, loss: 0.2672464847564697
step: 320, loss: 0.07853417098522186
step: 330, loss: 0.20675577223300934
step: 340, loss: 0.038292620331048965
step: 350, loss: 0.10765894502401352
step: 360, loss: 0.1255228966474533
step: 370, loss: 0.08086396753787994
step: 380, loss: 0.10677912831306458
epoch 2: dev_f1=0.684085510688836, f1=0.7066974595842958, best_f1=0.7066974595842958
step: 0, loss: 0.023463845252990723
step: 10, loss: 0.19374088943004608
step: 20, loss: 0.09648408740758896
step: 30, loss: 0.0798516497015953
step: 40, loss: 0.07154343277215958
step: 50, loss: 0.028415890410542488
step: 60, loss: 0.2242724746465683
step: 70, loss: 0.12223696708679199
step: 80, loss: 0.07002502679824829
step: 90, loss: 0.01851678267121315
step: 100, loss: 0.07572108507156372
step: 110, loss: 0.09336096048355103
step: 120, loss: 0.21665555238723755
step: 130, loss: 0.0705709382891655
step: 140, loss: 0.028398364782333374
step: 150, loss: 0.11417853087186813
step: 160, loss: 0.12578517198562622
step: 170, loss: 0.14099466800689697
step: 180, loss: 0.3314036726951599
step: 190, loss: 0.04728182777762413
step: 200, loss: 0.07741481810808182
step: 210, loss: 0.14478743076324463
step: 220, loss: 0.14754177629947662
step: 230, loss: 0.03730480372905731
step: 240, loss: 0.1786586046218872
step: 250, loss: 0.0903792753815651
step: 260, loss: 0.09273527562618256
step: 270, loss: 0.06727597862482071
step: 280, loss: 0.06697209924459457
step: 290, loss: 0.133615642786026
step: 300, loss: 0.07710617780685425
step: 310, loss: 0.1595684289932251
step: 320, loss: 0.1797744333744049
step: 330, loss: 0.21424530446529388
step: 340, loss: 0.07218416780233383
step: 350, loss: 0.0901033878326416
step: 360, loss: 0.07720552384853363
step: 370, loss: 0.1511903554201126
step: 380, loss: 0.22595833241939545
epoch 3: dev_f1=0.6991869918699186, f1=0.6629834254143646, best_f1=0.6629834254143646
step: 0, loss: 0.0681518092751503
step: 10, loss: 0.07713984698057175
step: 20, loss: 0.05562802031636238
step: 30, loss: 0.07070165127515793
step: 40, loss: 0.01594695635139942
step: 50, loss: 0.03775212913751602
step: 60, loss: 0.06779208779335022
step: 70, loss: 0.07011212408542633
step: 80, loss: 0.043083157390356064
step: 90, loss: 0.0327446274459362
step: 100, loss: 0.18502914905548096
step: 110, loss: 0.13158412277698517
step: 120, loss: 0.047446735203266144
step: 130, loss: 0.04368598014116287
step: 140, loss: 0.13451577723026276
step: 150, loss: 0.06432302296161652
step: 160, loss: 0.03409794345498085
step: 170, loss: 0.029185285791754723
step: 180, loss: 0.05028804391622543
step: 190, loss: 0.08501549810171127
step: 200, loss: 0.15671563148498535
step: 210, loss: 0.07765401154756546
step: 220, loss: 0.09534914046525955
step: 230, loss: 0.028306320309638977
step: 240, loss: 0.2111709862947464
step: 250, loss: 0.12025898694992065
step: 260, loss: 0.2418409287929535
step: 270, loss: 0.037960708141326904
step: 280, loss: 0.1606375128030777
step: 290, loss: 0.04912000149488449
step: 300, loss: 0.08224531263113022
step: 310, loss: 0.028515111654996872
step: 320, loss: 0.05020777881145477
step: 330, loss: 0.09014499187469482
step: 340, loss: 0.12336046993732452
step: 350, loss: 0.10033950954675674
step: 360, loss: 0.051528990268707275
step: 370, loss: 0.007426358759403229
step: 380, loss: 0.06796533614397049
epoch 4: dev_f1=0.7575757575757577, f1=0.7418546365914787, best_f1=0.7418546365914787
step: 0, loss: 0.1185179129242897
step: 10, loss: 0.16644804179668427
step: 20, loss: 0.0744299665093422
step: 30, loss: 0.06550736725330353
step: 40, loss: 0.04900282993912697
step: 50, loss: 0.07543259114027023
step: 60, loss: 0.07744505256414413
step: 70, loss: 0.0438009575009346
step: 80, loss: 0.041218895465135574
step: 90, loss: 0.0907539501786232
step: 100, loss: 0.15070566534996033
step: 110, loss: 0.06650590151548386
step: 120, loss: 0.032804448157548904
step: 130, loss: 0.09782472997903824
step: 140, loss: 0.06264602392911911
step: 150, loss: 0.0014190529473125935
step: 160, loss: 0.04992924630641937
step: 170, loss: 0.03867486119270325
step: 180, loss: 0.10953618586063385
step: 190, loss: 0.09693972021341324
step: 200, loss: 0.0652497187256813
step: 210, loss: 0.06275200098752975
step: 220, loss: 0.07204420864582062
step: 230, loss: 0.07822944223880768
step: 240, loss: 0.106410913169384
step: 250, loss: 0.2660345733165741
step: 260, loss: 0.07025744020938873
step: 270, loss: 0.09850608557462692
step: 280, loss: 0.030544506385922432
step: 290, loss: 0.13578712940216064
step: 300, loss: 0.10163094848394394
step: 310, loss: 0.02000892534852028
step: 320, loss: 0.10870750993490219
step: 330, loss: 0.05664714425802231
step: 340, loss: 0.022562460973858833
step: 350, loss: 0.10260499268770218
step: 360, loss: 0.08223778754472733
step: 370, loss: 0.032646242529153824
step: 380, loss: 0.0014278186718001962
epoch 5: dev_f1=0.7623762376237624, f1=0.7450980392156864, best_f1=0.7450980392156864
step: 0, loss: 0.11285627633333206
step: 10, loss: 0.11548613756895065
step: 20, loss: 0.13086669147014618
step: 30, loss: 0.06381462514400482
step: 40, loss: 0.0692877322435379
step: 50, loss: 0.027846895158290863
step: 60, loss: 0.06493974477052689
step: 70, loss: 0.015315747819840908
step: 80, loss: 0.11572010815143585
step: 90, loss: 0.10050765424966812
step: 100, loss: 0.04318038374185562
step: 110, loss: 0.12035530805587769
step: 120, loss: 0.04583989828824997
step: 130, loss: 0.026653872802853584
step: 140, loss: 0.10521641373634338
step: 150, loss: 0.05179951339960098
step: 160, loss: 0.0005011585308238864
step: 170, loss: 0.033870384097099304
step: 180, loss: 0.11814117431640625
step: 190, loss: 0.03883086517453194
step: 200, loss: 0.05615011602640152
step: 210, loss: 0.04541129618883133
step: 220, loss: 0.03649074211716652
step: 230, loss: 0.11294969171285629
step: 240, loss: 0.05750911310315132
step: 250, loss: 0.1197158545255661
step: 260, loss: 0.003059714799746871
step: 270, loss: 0.08239882439374924
step: 280, loss: 0.07146041840314865
step: 290, loss: 0.08509597927331924
step: 300, loss: 0.28628435730934143
step: 310, loss: 0.0330975204706192
step: 320, loss: 0.09536845237016678
step: 330, loss: 0.03827885910868645
step: 340, loss: 0.10015738010406494
step: 350, loss: 0.20256812870502472
step: 360, loss: 0.05295490100979805
step: 370, loss: 0.08776619285345078
step: 380, loss: 0.09833482652902603
epoch 6: dev_f1=0.7250608272506084, f1=0.6896551724137931, best_f1=0.7450980392156864
step: 0, loss: 0.13204661011695862
step: 10, loss: 0.13565005362033844
step: 20, loss: 0.09262728691101074
step: 30, loss: 0.0014381443616002798
step: 40, loss: 0.20192871987819672
step: 50, loss: 0.08366300910711288
step: 60, loss: 0.035430535674095154
step: 70, loss: 0.09467455744743347
step: 80, loss: 0.08735845983028412
step: 90, loss: 0.050214894115924835
step: 100, loss: 0.03350778669118881
step: 110, loss: 0.004171561915427446
step: 120, loss: 0.029012959450483322
step: 130, loss: 0.08141282945871353
step: 140, loss: 0.009763740003108978
step: 150, loss: 0.06626687198877335
step: 160, loss: 0.045833099633455276
step: 170, loss: 0.011549269780516624
step: 180, loss: 0.11880768835544586
step: 190, loss: 0.05055774003267288
step: 200, loss: 0.052947208285331726
step: 210, loss: 0.16051159799098969
step: 220, loss: 0.16799700260162354
step: 230, loss: 0.1077679991722107
step: 240, loss: 0.09760668873786926
step: 250, loss: 0.04034241661429405
step: 260, loss: 0.07490076869726181
step: 270, loss: 0.034296613186597824
step: 280, loss: 0.05707581713795662
step: 290, loss: 0.03588905930519104
step: 300, loss: 0.14941124618053436
step: 310, loss: 0.08285887539386749
step: 320, loss: 0.17147402465343475
step: 330, loss: 0.06774973124265671
step: 340, loss: 0.000927829765714705
step: 350, loss: 0.116063691675663
step: 360, loss: 0.1553393006324768
step: 370, loss: 0.11845491081476212
step: 380, loss: 0.036731570959091187
epoch 7: dev_f1=0.7420147420147422, f1=0.7291139240506329, best_f1=0.7450980392156864
step: 0, loss: 0.037445228546857834
step: 10, loss: 0.03315974026918411
step: 20, loss: 0.12512294948101044
step: 30, loss: 0.09283875674009323
step: 40, loss: 0.10293282568454742
step: 50, loss: 0.21119755506515503
step: 60, loss: 0.03677470609545708
step: 70, loss: 0.08935735374689102
step: 80, loss: 0.072781503200531
step: 90, loss: 0.07915057241916656
step: 100, loss: 0.05263302102684975
step: 110, loss: 0.10637901723384857
step: 120, loss: 0.0665644034743309
step: 130, loss: 0.07775130867958069
step: 140, loss: 0.1101098582148552
step: 150, loss: 0.016237447038292885
step: 160, loss: 0.07717613130807877
step: 170, loss: 0.1287550926208496
step: 180, loss: 0.03561406955122948
step: 190, loss: 0.02146800421178341
step: 200, loss: 0.087702676653862
step: 210, loss: 0.10630644857883453
step: 220, loss: 0.05770972743630409
step: 230, loss: 0.05149013549089432
step: 240, loss: 0.042876262217760086
step: 250, loss: 0.09501482546329498
step: 260, loss: 0.08517339825630188
step: 270, loss: 0.034513209015131
step: 280, loss: 0.14440253376960754
step: 290, loss: 0.26778802275657654
step: 300, loss: 0.03265179321169853
step: 310, loss: 0.02406223490834236
step: 320, loss: 0.05922963470220566
step: 330, loss: 0.14786434173583984
step: 340, loss: 0.037243105471134186
step: 350, loss: 0.09198544919490814
step: 360, loss: 0.0006050121155567467
step: 370, loss: 0.050537362694740295
step: 380, loss: 0.057034607976675034
epoch 8: dev_f1=0.7176220806794056, f1=0.7317073170731707, best_f1=0.7450980392156864
step: 0, loss: 0.1273663341999054
step: 10, loss: 0.10253631323575974
step: 20, loss: 0.08473038673400879
step: 30, loss: 0.09528764337301254
step: 40, loss: 0.01860406994819641
step: 50, loss: 0.02163936011493206
step: 60, loss: 0.055634744465351105
step: 70, loss: 0.09082076698541641
step: 80, loss: 0.0755925104022026
step: 90, loss: 0.03272692859172821
step: 100, loss: 0.010285316035151482
step: 110, loss: 0.08809658885002136
step: 120, loss: 0.07154595106840134
step: 130, loss: 0.014176199212670326
step: 140, loss: 0.04272887855768204
step: 150, loss: 0.06824444979429245
step: 160, loss: 0.09183209389448166
step: 170, loss: 0.022833429276943207
step: 180, loss: 0.23178182542324066
step: 190, loss: 0.0013203676789999008
step: 200, loss: 0.06227685511112213
step: 210, loss: 0.2652963101863861
step: 220, loss: 0.15036843717098236
step: 230, loss: 0.023531097918748856
step: 240, loss: 0.06417153775691986
step: 250, loss: 0.0721149668097496
step: 260, loss: 0.058923766016960144
step: 270, loss: 0.04748065024614334
step: 280, loss: 0.04420796409249306
step: 290, loss: 0.05385257676243782
step: 300, loss: 0.08617845922708511
step: 310, loss: 0.01745651103556156
step: 320, loss: 0.08462261408567429
step: 330, loss: 0.10073871165513992
step: 340, loss: 0.022942837327718735
step: 350, loss: 0.0874495878815651
step: 360, loss: 0.09313283115625381
step: 370, loss: 0.10258761048316956
step: 380, loss: 0.08320993930101395
epoch 9: dev_f1=0.7481662591687043, f1=0.7178217821782177, best_f1=0.7450980392156864
step: 0, loss: 0.028105266392230988
step: 10, loss: 0.00036006898153573275
step: 20, loss: 0.12463603168725967
step: 30, loss: 0.040521278977394104
step: 40, loss: 0.09033825993537903
step: 50, loss: 0.07361450791358948
step: 60, loss: 0.09424356371164322
step: 70, loss: 0.04113325849175453
step: 80, loss: 0.044470224529504776
step: 90, loss: 0.04533888399600983
step: 100, loss: 0.10902874171733856
step: 110, loss: 0.042733389884233475
step: 120, loss: 0.09586996585130692
step: 130, loss: 0.025142831727862358
step: 140, loss: 0.008361143991351128
step: 150, loss: 0.011921512894332409
step: 160, loss: 0.09649068862199783
step: 170, loss: 0.03261115774512291
step: 180, loss: 0.02723878249526024
step: 190, loss: 0.015121916308999062
step: 200, loss: 0.07996638119220734
step: 210, loss: 0.08411676436662674
step: 220, loss: 0.06910882145166397
step: 230, loss: 0.02990436553955078
step: 240, loss: 0.0004999845987185836
step: 250, loss: 0.03212156891822815
step: 260, loss: 0.10301077365875244
step: 270, loss: 0.11713679134845734
step: 280, loss: 0.042389918118715286
step: 290, loss: 0.050824958831071854
step: 300, loss: 0.03846083581447601
step: 310, loss: 0.052787911146879196
step: 320, loss: 0.06758126616477966
step: 330, loss: 0.08653062582015991
step: 340, loss: 0.11115923523902893
step: 350, loss: 0.028909500688314438
step: 360, loss: 0.011637134477496147
step: 370, loss: 0.059603992849588394
step: 380, loss: 0.052073605358600616
epoch 10: dev_f1=0.7295285359801489, f1=0.7135416666666666, best_f1=0.7450980392156864
step: 0, loss: 0.0153910331428051
step: 10, loss: 0.0626562312245369
step: 20, loss: 0.06901523470878601
step: 30, loss: 0.04264353960752487
step: 40, loss: 0.09281337261199951
step: 50, loss: 0.03439349681138992
step: 60, loss: 0.06370846182107925
step: 70, loss: 0.016756441444158554
step: 80, loss: 0.10943999141454697
step: 90, loss: 0.05223454162478447
step: 100, loss: 0.0002728350227698684
step: 110, loss: 0.10239123553037643
step: 120, loss: 0.11063273996114731
step: 130, loss: 0.04851245507597923
step: 140, loss: 0.10847514122724533
step: 150, loss: 0.05276183411478996
step: 160, loss: 0.029881389811635017
step: 170, loss: 0.05018262192606926
step: 180, loss: 0.051687370985746384
step: 190, loss: 0.020127560943365097
step: 200, loss: 0.004250564146786928
step: 210, loss: 0.05579785257577896
step: 220, loss: 0.02527766302227974
step: 230, loss: 0.0482340082526207
step: 240, loss: 0.03501170873641968
step: 250, loss: 0.00036376292700879276
step: 260, loss: 0.1030643954873085
step: 270, loss: 0.04151930287480354
step: 280, loss: 0.029197905212640762
step: 290, loss: 0.057638462632894516
step: 300, loss: 0.07266915589570999
step: 310, loss: 0.08479674905538559
step: 320, loss: 0.04958806931972504
step: 330, loss: 0.046499576419591904
step: 340, loss: 0.0818757489323616
step: 350, loss: 0.08503390848636627
step: 360, loss: 0.08619146049022675
step: 370, loss: 0.031009668484330177
step: 380, loss: 0.018443917855620384
epoch 11: dev_f1=0.7550000000000001, f1=0.744186046511628, best_f1=0.7450980392156864
step: 0, loss: 0.037726029753685
step: 10, loss: 0.12331876903772354
step: 20, loss: 0.04425651952624321
step: 30, loss: 0.008373380638659
step: 40, loss: 0.13529282808303833
step: 50, loss: 0.02109573595225811
step: 60, loss: 0.027632124722003937
step: 70, loss: 0.037321094423532486
step: 80, loss: 0.04370907321572304
step: 90, loss: 0.10313495993614197
step: 100, loss: 0.10547328740358353
step: 110, loss: 0.05204681307077408
step: 120, loss: 0.10663195699453354
step: 130, loss: 0.1028035432100296
step: 140, loss: 0.06557118147611618
step: 150, loss: 0.0472322441637516
step: 160, loss: 0.24663366377353668
step: 170, loss: 0.07089722901582718
step: 180, loss: 0.04718684405088425
step: 190, loss: 0.040294915437698364
step: 200, loss: 0.01045573316514492
step: 210, loss: 0.03162851929664612
step: 220, loss: 0.052014511078596115
step: 230, loss: 0.05029892176389694
step: 240, loss: 0.023519648239016533
step: 250, loss: 0.060991015285253525
step: 260, loss: 0.05176687240600586
step: 270, loss: 0.012874742969870567
step: 280, loss: 0.0024406674783676863
step: 290, loss: 0.04024206101894379
step: 300, loss: 0.012313580140471458
step: 310, loss: 0.015242774970829487
step: 320, loss: 0.09589754045009613
step: 330, loss: 0.01059850212186575
step: 340, loss: 0.03540278598666191
step: 350, loss: 0.034819595515728
step: 360, loss: 0.05308493226766586
step: 370, loss: 0.04128078743815422
step: 380, loss: 0.07016032934188843
epoch 12: dev_f1=0.7575757575757577, f1=0.7263157894736842, best_f1=0.7450980392156864
step: 0, loss: 0.046241406351327896
step: 10, loss: 0.013353556394577026
step: 20, loss: 0.052159633487463
step: 30, loss: 0.010782772675156593
step: 40, loss: 0.01108198519796133
step: 50, loss: 0.04940904304385185
step: 60, loss: 0.0624622218310833
step: 70, loss: 7.589285087306052e-05
step: 80, loss: 0.0716141015291214
step: 90, loss: 0.08143065124750137
step: 100, loss: 0.15421929955482483
step: 110, loss: 0.04871591180562973
step: 120, loss: 0.05892352759838104
step: 130, loss: 0.01429461594671011
step: 140, loss: 0.038814034312963486
step: 150, loss: 0.005254756659269333
step: 160, loss: 0.0021457597613334656
step: 170, loss: 0.12601704895496368
step: 180, loss: 0.09680226445198059
step: 190, loss: 0.06574060767889023
step: 200, loss: 0.0002029990719165653
step: 210, loss: 0.058746688067913055
step: 220, loss: 0.06493139266967773
step: 230, loss: 0.05999983847141266
step: 240, loss: 0.023919856175780296
step: 250, loss: 0.09793730080127716
step: 260, loss: 0.00011972511856583878
step: 270, loss: 0.05906578525900841
step: 280, loss: 0.07198307663202286
step: 290, loss: 0.08549593389034271
step: 300, loss: 0.026154566556215286
step: 310, loss: 0.0002119254641002044
step: 320, loss: 0.036485593765974045
step: 330, loss: 0.026784243062138557
step: 340, loss: 0.07440581917762756
step: 350, loss: 0.026447243988513947
step: 360, loss: 0.06157276779413223
step: 370, loss: 0.05267876386642456
step: 380, loss: 0.02741418220102787
epoch 13: dev_f1=0.7238979118329466, f1=0.7174447174447175, best_f1=0.7450980392156864
step: 0, loss: 0.030530188232660294
step: 10, loss: 0.056010205298662186
step: 20, loss: 0.04607493057847023
step: 30, loss: 0.03447209671139717
step: 40, loss: 0.14775505661964417
step: 50, loss: 3.1335584935732186e-05
step: 60, loss: 0.16095149517059326
step: 70, loss: 0.04371257126331329
step: 80, loss: 0.03894735872745514
step: 90, loss: 0.027200305834412575
step: 100, loss: 0.10397522896528244
step: 110, loss: 0.04962729290127754
step: 120, loss: 0.04056285321712494
step: 130, loss: 0.06235981732606888
step: 140, loss: 0.03969123959541321
step: 150, loss: 0.040516506880521774
step: 160, loss: 0.025871561840176582
step: 170, loss: 0.0785604789853096
step: 180, loss: 0.022223282605409622
step: 190, loss: 0.11836908012628555
step: 200, loss: 0.048123158514499664
step: 210, loss: 0.04996994882822037
step: 220, loss: 0.058364611119031906
step: 230, loss: 0.026665648445487022
step: 240, loss: 0.01734401471912861
step: 250, loss: 0.043594472110271454
step: 260, loss: 0.04093923419713974
step: 270, loss: 0.029592588543891907
step: 280, loss: 0.048791032284498215
step: 290, loss: 0.03738352656364441
step: 300, loss: 0.0678180679678917
step: 310, loss: 0.0665544718503952
step: 320, loss: 0.018205955624580383
step: 330, loss: 0.032902829349040985
step: 340, loss: 0.08911959826946259
step: 350, loss: 0.0952184647321701
step: 360, loss: 0.012318233959376812
step: 370, loss: 0.042432982474565506
step: 380, loss: 0.003586498787626624
epoch 14: dev_f1=0.7379679144385027, f1=0.7016574585635359, best_f1=0.7450980392156864
step: 0, loss: 0.025941211730241776
step: 10, loss: 0.005804699845612049
step: 20, loss: 0.04567710682749748
step: 30, loss: 0.051993537694215775
step: 40, loss: 0.08958189189434052
step: 50, loss: 0.09399119764566422
step: 60, loss: 0.03218258544802666
step: 70, loss: 0.004117604345083237
step: 80, loss: 0.04988280311226845
step: 90, loss: 0.007893918082118034
step: 100, loss: 0.011808912269771099
step: 110, loss: 0.03905123099684715
step: 120, loss: 0.025696247816085815
step: 130, loss: 2.1557447325903922e-05
step: 140, loss: 0.023002078756690025
step: 150, loss: 0.05220557004213333
step: 160, loss: 0.07683181762695312
step: 170, loss: 0.03033570945262909
step: 180, loss: 0.006034466437995434
step: 190, loss: 0.01477228756994009
step: 200, loss: 0.03538043797016144
step: 210, loss: 0.02974027954041958
step: 220, loss: 0.022568510845303535
step: 230, loss: 0.031767405569553375
step: 240, loss: 0.00672246003523469
step: 250, loss: 0.021961897611618042
step: 260, loss: 0.016760118305683136
step: 270, loss: 0.033065877854824066
step: 280, loss: 0.010705807246267796
step: 290, loss: 0.0037930759135633707
step: 300, loss: 0.08442983031272888
step: 310, loss: 0.0030407821759581566
step: 320, loss: 0.052297331392765045
step: 330, loss: 0.002329782349988818
step: 340, loss: 0.023598259314894676
step: 350, loss: 0.01866552233695984
step: 360, loss: 0.04433901980519295
step: 370, loss: 0.029404709115624428
step: 380, loss: 0.03800345957279205
epoch 15: dev_f1=0.7412935323383084, f1=0.732824427480916, best_f1=0.7450980392156864
step: 0, loss: 0.02651219815015793
step: 10, loss: 0.04457395523786545
step: 20, loss: 0.010013706982135773
step: 30, loss: 0.06634047627449036
step: 40, loss: 0.05851462855935097
step: 50, loss: 0.005968550685793161
step: 60, loss: 0.033926259726285934
step: 70, loss: 0.04897596314549446
step: 80, loss: 0.045417893677949905
step: 90, loss: 0.087985560297966
step: 100, loss: 0.019513485953211784
step: 110, loss: 0.04521749168634415
step: 120, loss: 0.019461587071418762
step: 130, loss: 0.10459542274475098
step: 140, loss: 0.037128910422325134
step: 150, loss: 0.002159183844923973
step: 160, loss: 0.05942931026220322
step: 170, loss: 0.07301826030015945
step: 180, loss: 0.06928469240665436
step: 190, loss: 0.08350255340337753
step: 200, loss: 0.008036529645323753
step: 210, loss: 0.03913094475865364
step: 220, loss: 0.05360972881317139
step: 230, loss: 0.01906409114599228
step: 240, loss: 0.11814823001623154
step: 250, loss: 0.07374127954244614
step: 260, loss: 0.044586990028619766
step: 270, loss: 0.07526732236146927
step: 280, loss: 0.058159030973911285
step: 290, loss: 0.026808660477399826
step: 300, loss: 0.03404839709401131
step: 310, loss: 0.005550080444663763
step: 320, loss: 0.03476567566394806
step: 330, loss: 0.16162914037704468
step: 340, loss: 0.0032352993730455637
step: 350, loss: 0.03254111483693123
step: 360, loss: 0.1024615690112114
step: 370, loss: 0.028502827510237694
step: 380, loss: 0.027759509161114693
epoch 16: dev_f1=0.712871287128713, f1=0.711340206185567, best_f1=0.7450980392156864
step: 0, loss: 0.02504371479153633
step: 10, loss: 0.07733672112226486
step: 20, loss: 5.91237549087964e-05
step: 30, loss: 0.041692253202199936
step: 40, loss: 0.056628838181495667
step: 50, loss: 0.009235434234142303
step: 60, loss: 0.024560116231441498
step: 70, loss: 0.061963342130184174
step: 80, loss: 0.10675522685050964
step: 90, loss: 0.03327886015176773
step: 100, loss: 0.0004116044146940112
step: 110, loss: 0.07376208901405334
step: 120, loss: 0.04553923010826111
step: 130, loss: 0.015268119052052498
step: 140, loss: 0.016722368076443672
step: 150, loss: 0.019912634044885635
step: 160, loss: 0.012733223848044872
step: 170, loss: 0.03843246027827263
step: 180, loss: 0.027481749653816223
step: 190, loss: 0.08371590822935104
step: 200, loss: 0.0032516303472220898
step: 210, loss: 0.05925663188099861
step: 220, loss: 0.022905144840478897
step: 230, loss: 0.08791828900575638
step: 240, loss: 0.023045971989631653
step: 250, loss: 0.016449889168143272
step: 260, loss: 0.043779294937849045
step: 270, loss: 0.09164372086524963
step: 280, loss: 0.0007255803793668747
step: 290, loss: 0.031142907217144966
step: 300, loss: 0.01701221987605095
step: 310, loss: 4.996794450562447e-05
step: 320, loss: 0.06226798892021179
step: 330, loss: 0.029142292216420174
step: 340, loss: 0.0069754100404679775
step: 350, loss: 0.08250251412391663
step: 360, loss: 0.05944114550948143
step: 370, loss: 0.025927476584911346
step: 380, loss: 0.031130297109484673
epoch 17: dev_f1=0.7107843137254902, f1=0.7193877551020408, best_f1=0.7450980392156864
step: 0, loss: 0.004352354444563389
step: 10, loss: 0.07208853960037231
step: 20, loss: 0.020670149475336075
step: 30, loss: 0.00587197532877326
step: 40, loss: 0.06709890067577362
step: 50, loss: 0.03729758411645889
step: 60, loss: 0.05789070948958397
step: 70, loss: 0.04851040616631508
step: 80, loss: 0.031571559607982635
step: 90, loss: 0.019514668732881546
step: 100, loss: 0.007523910142481327
step: 110, loss: 0.058349259197711945
step: 120, loss: 0.017427433282136917
step: 130, loss: 0.033178772777318954
step: 140, loss: 0.05871393531560898
step: 150, loss: 0.07906058430671692
step: 160, loss: 0.019396059215068817
step: 170, loss: 0.03841203451156616
step: 180, loss: 0.03725762665271759
step: 190, loss: 0.05182772874832153
step: 200, loss: 0.033118437975645065
step: 210, loss: 0.016857942566275597
step: 220, loss: 0.12940190732479095
step: 230, loss: 0.011511866934597492
step: 240, loss: 0.050827037543058395
step: 250, loss: 0.009472070261836052
step: 260, loss: 0.015368911437690258
step: 270, loss: 0.04526554048061371
step: 280, loss: 0.020330365747213364
step: 290, loss: 0.010096668265759945
step: 300, loss: 0.07738430052995682
step: 310, loss: 0.0060719093307852745
step: 320, loss: 0.05199417471885681
step: 330, loss: 0.04128124937415123
step: 340, loss: 0.046645645052194595
step: 350, loss: 0.03897379711270332
step: 360, loss: 0.028493238613009453
step: 370, loss: 0.04135562479496002
step: 380, loss: 0.06691941618919373
epoch 18: dev_f1=0.7012345679012345, f1=0.7286821705426356, best_f1=0.7450980392156864
step: 0, loss: 0.002709653228521347
step: 10, loss: 0.022209692746400833
step: 20, loss: 0.000916601566132158
step: 30, loss: 0.020767662674188614
step: 40, loss: 0.08115603774785995
step: 50, loss: 2.9687998903682455e-05
step: 60, loss: 0.000742355186957866
step: 70, loss: 0.07434201240539551
step: 80, loss: 0.052393075078725815
step: 90, loss: 0.12170016020536423
step: 100, loss: 0.11321001499891281
step: 110, loss: 0.0020321260672062635
step: 120, loss: 0.06579208374023438
step: 130, loss: 0.013836788944900036
step: 140, loss: 0.04895029589533806
step: 150, loss: 0.05621214210987091
step: 160, loss: 0.03307385742664337
step: 170, loss: 0.10180965065956116
step: 180, loss: 2.858117841242347e-05
step: 190, loss: 0.0097248125821352
step: 200, loss: 0.0694500133395195
step: 210, loss: 0.0533912256360054
step: 220, loss: 0.06153978034853935
step: 230, loss: 0.04069673269987106
step: 240, loss: 0.04062121734023094
step: 250, loss: 0.0341486819088459
step: 260, loss: 0.07220752537250519
step: 270, loss: 0.0003704754344653338
step: 280, loss: 0.011903016828000546
step: 290, loss: 0.014639545232057571
step: 300, loss: 0.01873871684074402
step: 310, loss: 0.003177346894517541
step: 320, loss: 0.031107481569051743
step: 330, loss: 0.000645680062007159
step: 340, loss: 0.019431592896580696
step: 350, loss: 0.10427409410476685
step: 360, loss: 0.02090360037982464
step: 370, loss: 0.012304577976465225
step: 380, loss: 0.08342362195253372
epoch 19: dev_f1=0.7046632124352331, f1=0.7200000000000001, best_f1=0.7450980392156864
step: 0, loss: 0.04060392454266548
step: 10, loss: 0.019492700695991516
step: 20, loss: 0.0014195586554706097
step: 30, loss: 0.0525321327149868
step: 40, loss: 0.00852997787296772
step: 50, loss: 0.026212308555841446
step: 60, loss: 0.08808024227619171
step: 70, loss: 0.06593819707632065
step: 80, loss: 0.04884758219122887
step: 90, loss: 0.027440210804343224
step: 100, loss: 0.04463573545217514
step: 110, loss: 0.03358469158411026
step: 120, loss: 0.016136817634105682
step: 130, loss: 0.044037334620952606
step: 140, loss: 0.09288555383682251
step: 150, loss: 0.041999317705631256
step: 160, loss: 0.0004368860099930316
step: 170, loss: 0.0003903311735484749
step: 180, loss: 0.062256041914224625
step: 190, loss: 0.14107461273670197
step: 200, loss: 0.0458633117377758
step: 210, loss: 0.01072139572352171
step: 220, loss: 0.005914538167417049
step: 230, loss: 0.006403263658285141
step: 240, loss: 0.031788334250450134
step: 250, loss: 0.08537749946117401
step: 260, loss: 0.013626460917294025
step: 270, loss: 0.006955136079341173
step: 280, loss: 0.00030277969199232757
step: 290, loss: 0.02823817916214466
step: 300, loss: 0.0821814090013504
step: 310, loss: 0.06358759850263596
step: 320, loss: 0.07860471308231354
step: 330, loss: 0.04828143119812012
step: 340, loss: 0.08445069193840027
step: 350, loss: 1.5675617760280147e-05
step: 360, loss: 0.08692628145217896
step: 370, loss: 0.008004417642951012
step: 380, loss: 0.03523772209882736
epoch 20: dev_f1=0.709141274238227, f1=0.711484593837535, best_f1=0.7450980392156864
