cuda
Device: cuda
step: 0, loss: 0.6318089962005615
step: 10, loss: 0.3671462833881378
step: 20, loss: 0.13595877587795258
step: 30, loss: 0.05184387043118477
step: 40, loss: 0.3736298680305481
step: 50, loss: 0.14594736695289612
step: 60, loss: 0.39462339878082275
step: 70, loss: 0.5484713315963745
step: 80, loss: 0.4417553246021271
step: 90, loss: 0.21221157908439636
step: 100, loss: 0.1697256863117218
step: 110, loss: 0.31644779443740845
step: 120, loss: 0.3101818561553955
step: 130, loss: 0.2456711381673813
step: 140, loss: 0.19520196318626404
step: 150, loss: 0.12968149781227112
step: 160, loss: 0.12307713180780411
step: 170, loss: 0.1939065307378769
step: 180, loss: 0.3496136963367462
step: 190, loss: 0.27116429805755615
step: 200, loss: 0.1211433857679367
step: 210, loss: 0.14691272377967834
step: 220, loss: 0.29404541850090027
step: 230, loss: 0.13300418853759766
step: 240, loss: 0.1926385462284088
step: 250, loss: 0.25182098150253296
step: 260, loss: 0.2598527669906616
step: 270, loss: 0.07978915423154831
step: 280, loss: 0.11705512553453445
step: 290, loss: 0.4788261950016022
step: 300, loss: 0.17747825384140015
step: 310, loss: 0.03982878476381302
step: 320, loss: 0.11217979341745377
step: 330, loss: 0.12232846766710281
step: 340, loss: 0.034861233085393906
step: 350, loss: 0.20363079011440277
step: 360, loss: 0.039110586047172546
step: 370, loss: 0.1192963719367981
step: 380, loss: 0.3515598177909851
epoch 1: dev_f1=0.6280991735537189, f1=0.6323907455012855, best_f1=0.6323907455012855
step: 0, loss: 0.20858845114707947
step: 10, loss: 0.05659035965800285
step: 20, loss: 0.17452548444271088
step: 30, loss: 0.06944926083087921
step: 40, loss: 0.11027850210666656
step: 50, loss: 0.14715127646923065
step: 60, loss: 0.14927946031093597
step: 70, loss: 0.2143467217683792
step: 80, loss: 0.2271384298801422
step: 90, loss: 0.21367545425891876
step: 100, loss: 0.036004286259412766
step: 110, loss: 0.19317252933979034
step: 120, loss: 0.04564649239182472
step: 130, loss: 0.21992716193199158
step: 140, loss: 0.16201260685920715
step: 150, loss: 0.09396802634000778
step: 160, loss: 0.22277560830116272
step: 170, loss: 0.16247889399528503
step: 180, loss: 0.035246592015028
step: 190, loss: 0.22216682136058807
step: 200, loss: 0.03700139746069908
step: 210, loss: 0.08884524554014206
step: 220, loss: 0.1386411190032959
step: 230, loss: 0.10612081736326218
step: 240, loss: 0.0683017373085022
step: 250, loss: 0.029985714703798294
step: 260, loss: 0.07225372642278671
step: 270, loss: 0.17907966673374176
step: 280, loss: 0.110650435090065
step: 290, loss: 0.19430993497371674
step: 300, loss: 0.3487330973148346
step: 310, loss: 0.06755831837654114
step: 320, loss: 0.166789248585701
step: 330, loss: 0.0439646877348423
step: 340, loss: 0.05396021530032158
step: 350, loss: 0.00807457696646452
step: 360, loss: 0.16649006307125092
step: 370, loss: 0.20120206475257874
step: 380, loss: 0.14665095508098602
epoch 2: dev_f1=0.6894736842105263, f1=0.690909090909091, best_f1=0.690909090909091
step: 0, loss: 0.168141707777977
step: 10, loss: 0.04907914251089096
step: 20, loss: 0.13689851760864258
step: 30, loss: 0.1418624073266983
step: 40, loss: 0.08449649065732956
step: 50, loss: 0.11177095025777817
step: 60, loss: 0.07840108871459961
step: 70, loss: 0.12892058491706848
step: 80, loss: 0.10299587994813919
step: 90, loss: 0.08507537841796875
step: 100, loss: 0.07909182459115982
step: 110, loss: 0.06684380024671555
step: 120, loss: 0.19580307602882385
step: 130, loss: 0.07906333357095718
step: 140, loss: 0.15451087057590485
step: 150, loss: 0.11249257624149323
step: 160, loss: 0.12807947397232056
step: 170, loss: 0.15338584780693054
step: 180, loss: 0.08828234672546387
step: 190, loss: 0.09022688865661621
step: 200, loss: 0.10724160820245743
step: 210, loss: 0.1593600958585739
step: 220, loss: 0.041416190564632416
step: 230, loss: 0.20768336951732635
step: 240, loss: 0.14259536564350128
step: 250, loss: 0.3035663664340973
step: 260, loss: 0.12281829118728638
step: 270, loss: 0.16834047436714172
step: 280, loss: 0.1858576536178589
step: 290, loss: 0.08489732444286346
step: 300, loss: 0.14329038560390472
step: 310, loss: 0.36705532670021057
step: 320, loss: 0.15774951875209808
step: 330, loss: 0.10607101023197174
step: 340, loss: 0.033125489950180054
step: 350, loss: 0.31732118129730225
step: 360, loss: 0.1538463979959488
step: 370, loss: 0.21804361045360565
step: 380, loss: 0.016545776277780533
epoch 3: dev_f1=0.7688311688311688, f1=0.741687979539642, best_f1=0.741687979539642
step: 0, loss: 0.11573877930641174
step: 10, loss: 0.04147423431277275
step: 20, loss: 0.12068920582532883
step: 30, loss: 0.08273724466562271
step: 40, loss: 0.009796478785574436
step: 50, loss: 0.025436796247959137
step: 60, loss: 0.09522004425525665
step: 70, loss: 0.09619935601949692
step: 80, loss: 0.08776454627513885
step: 90, loss: 0.10339454561471939
step: 100, loss: 0.18812064826488495
step: 110, loss: 0.18997734785079956
step: 120, loss: 0.22596555948257446
step: 130, loss: 0.17089444398880005
step: 140, loss: 0.07862650603055954
step: 150, loss: 0.15227484703063965
step: 160, loss: 0.10299438238143921
step: 170, loss: 0.08971135318279266
step: 180, loss: 0.18038035929203033
step: 190, loss: 0.1401863694190979
step: 200, loss: 0.023387350142002106
step: 210, loss: 0.06442835181951523
step: 220, loss: 0.12077372521162033
step: 230, loss: 0.35220223665237427
step: 240, loss: 0.06148407980799675
step: 250, loss: 0.15728560090065002
step: 260, loss: 0.06220477819442749
step: 270, loss: 0.04413330927491188
step: 280, loss: 0.20782995223999023
step: 290, loss: 0.21938708424568176
step: 300, loss: 0.0552702359855175
step: 310, loss: 0.2023008018732071
step: 320, loss: 0.04152049124240875
step: 330, loss: 0.05238207057118416
step: 340, loss: 0.038114819675683975
step: 350, loss: 0.04750550910830498
step: 360, loss: 0.09295814484357834
step: 370, loss: 0.0974605605006218
step: 380, loss: 0.1115739718079567
epoch 4: dev_f1=0.743142144638404, f1=0.7121212121212122, best_f1=0.741687979539642
step: 0, loss: 0.093626968562603
step: 10, loss: 0.06275519728660583
step: 20, loss: 0.04705942049622536
step: 30, loss: 0.0785108134150505
step: 40, loss: 0.03387342393398285
step: 50, loss: 0.13265489041805267
step: 60, loss: 0.18016767501831055
step: 70, loss: 0.055656738579273224
step: 80, loss: 0.08813846111297607
step: 90, loss: 0.024188853800296783
step: 100, loss: 0.0822121724486351
step: 110, loss: 0.11305972933769226
step: 120, loss: 0.012003815732896328
step: 130, loss: 0.13606888055801392
step: 140, loss: 0.06398648768663406
step: 150, loss: 0.017199687659740448
step: 160, loss: 0.058651410043239594
step: 170, loss: 0.16121676564216614
step: 180, loss: 0.048801299184560776
step: 190, loss: 0.7814856171607971
step: 200, loss: 0.16113370656967163
step: 210, loss: 0.16962291300296783
step: 220, loss: 0.27081549167633057
step: 230, loss: 0.05638202279806137
step: 240, loss: 0.10797049850225449
step: 250, loss: 0.08758170902729034
step: 260, loss: 0.09241551160812378
step: 270, loss: 0.02916434034705162
step: 280, loss: 0.21295998990535736
step: 290, loss: 0.11742394417524338
step: 300, loss: 0.038949400186538696
step: 310, loss: 0.06475268304347992
step: 320, loss: 0.07791534066200256
step: 330, loss: 0.051382504403591156
step: 340, loss: 0.168343648314476
step: 350, loss: 0.15360140800476074
step: 360, loss: 0.07994253933429718
step: 370, loss: 0.05142132192850113
step: 380, loss: 0.09259869903326035
epoch 5: dev_f1=0.7354497354497355, f1=0.7135416666666666, best_f1=0.741687979539642
step: 0, loss: 0.08691499382257462
step: 10, loss: 0.00255822972394526
step: 20, loss: 0.10194084048271179
step: 30, loss: 0.16448138654232025
step: 40, loss: 0.06929778307676315
step: 50, loss: 0.0943058580160141
step: 60, loss: 0.0723000168800354
step: 70, loss: 0.16757668554782867
step: 80, loss: 0.04999949783086777
step: 90, loss: 0.1194506511092186
step: 100, loss: 0.14811387658119202
step: 110, loss: 0.19009846448898315
step: 120, loss: 0.038840919733047485
step: 130, loss: 0.03725577890872955
step: 140, loss: 0.18629659712314606
step: 150, loss: 0.09912600368261337
step: 160, loss: 0.08964727818965912
step: 170, loss: 0.06095176935195923
step: 180, loss: 0.027414217591285706
step: 190, loss: 0.05662304535508156
step: 200, loss: 0.07570366561412811
step: 210, loss: 0.14635267853736877
step: 220, loss: 0.06625500321388245
step: 230, loss: 0.06325136870145798
step: 240, loss: 0.15608662366867065
step: 250, loss: 0.0727463811635971
step: 260, loss: 0.059011124074459076
step: 270, loss: 0.014707718975841999
step: 280, loss: 0.018874891102313995
step: 290, loss: 0.04259631037712097
step: 300, loss: 0.11001528799533844
step: 310, loss: 0.09555156528949738
step: 320, loss: 0.1852560192346573
step: 330, loss: 0.06884492188692093
step: 340, loss: 0.10808612406253815
step: 350, loss: 0.024567604064941406
step: 360, loss: 0.09481548517942429
step: 370, loss: 0.08876229077577591
step: 380, loss: 0.050039686262607574
epoch 6: dev_f1=0.7417840375586854, f1=0.691764705882353, best_f1=0.741687979539642
step: 0, loss: 0.02117599919438362
step: 10, loss: 0.11720384657382965
step: 20, loss: 0.05577770620584488
step: 30, loss: 0.09003312140703201
step: 40, loss: 0.03234885632991791
step: 50, loss: 0.24604664742946625
step: 60, loss: 0.10709962248802185
step: 70, loss: 0.057333432137966156
step: 80, loss: 0.06417649239301682
step: 90, loss: 0.0493885837495327
step: 100, loss: 0.1118345633149147
step: 110, loss: 0.04372956231236458
step: 120, loss: 0.07895520329475403
step: 130, loss: 0.01872885227203369
step: 140, loss: 0.12084639072418213
step: 150, loss: 0.0174667090177536
step: 160, loss: 0.04070388153195381
step: 170, loss: 0.04693182185292244
step: 180, loss: 0.08776284009218216
step: 190, loss: 0.04989241436123848
step: 200, loss: 0.17946843802928925
step: 210, loss: 0.0383002944290638
step: 220, loss: 0.06763923168182373
step: 230, loss: 0.139630988240242
step: 240, loss: 0.05893591418862343
step: 250, loss: 0.06836364418268204
step: 260, loss: 0.2160031646490097
step: 270, loss: 0.12622149288654327
step: 280, loss: 0.026810791343450546
step: 290, loss: 0.043437499552965164
step: 300, loss: 0.09634552896022797
step: 310, loss: 0.07351935654878616
step: 320, loss: 0.04540654271841049
step: 330, loss: 0.09320268779993057
step: 340, loss: 0.05193597450852394
step: 350, loss: 0.0040254718624055386
step: 360, loss: 0.0350201353430748
step: 370, loss: 0.04663967713713646
step: 380, loss: 0.05901045724749565
epoch 7: dev_f1=0.7358024691358025, f1=0.6886075949367089, best_f1=0.741687979539642
step: 0, loss: 0.04766654223203659
step: 10, loss: 0.055954571813344955
step: 20, loss: 0.018368631601333618
step: 30, loss: 0.02693944238126278
step: 40, loss: 0.08860671520233154
step: 50, loss: 0.057265885174274445
step: 60, loss: 0.09036316722631454
step: 70, loss: 0.05158999189734459
step: 80, loss: 0.03068140521645546
step: 90, loss: 0.015303637832403183
step: 100, loss: 0.14442990720272064
step: 110, loss: 0.0637085884809494
step: 120, loss: 0.046239279210567474
step: 130, loss: 0.07235310971736908
step: 140, loss: 0.09569451212882996
step: 150, loss: 0.04352469742298126
step: 160, loss: 0.06077905744314194
step: 170, loss: 0.000969913846347481
step: 180, loss: 0.016583049669861794
step: 190, loss: 0.05693300440907478
step: 200, loss: 0.10575320571660995
step: 210, loss: 0.033366572111845016
step: 220, loss: 0.04061698541045189
step: 230, loss: 0.05894862115383148
step: 240, loss: 0.05527927353978157
step: 250, loss: 0.06419514119625092
step: 260, loss: 0.08872956782579422
step: 270, loss: 0.05943714454770088
step: 280, loss: 0.07232934236526489
step: 290, loss: 0.08329647779464722
step: 300, loss: 0.09563598781824112
step: 310, loss: 0.08701492846012115
step: 320, loss: 0.04096584767103195
step: 330, loss: 0.012496697716414928
step: 340, loss: 0.038227301090955734
step: 350, loss: 0.08185025304555893
step: 360, loss: 0.051337964832782745
step: 370, loss: 0.06524523347616196
step: 380, loss: 0.04691515862941742
epoch 8: dev_f1=0.7368421052631577, f1=0.6831460674157304, best_f1=0.741687979539642
step: 0, loss: 0.04900640249252319
step: 10, loss: 0.06278804689645767
step: 20, loss: 0.10314337909221649
step: 30, loss: 0.05610644444823265
step: 40, loss: 0.0017731525003910065
step: 50, loss: 0.04124614968895912
step: 60, loss: 0.05405624955892563
step: 70, loss: 0.05271173641085625
step: 80, loss: 0.006866798736155033
step: 90, loss: 0.11594988405704498
step: 100, loss: 0.005083455704152584
step: 110, loss: 0.045629069209098816
step: 120, loss: 0.07670792192220688
step: 130, loss: 0.0034575622994452715
step: 140, loss: 0.11265912652015686
step: 150, loss: 0.07002198696136475
step: 160, loss: 0.07421372830867767
step: 170, loss: 0.15499518811702728
step: 180, loss: 0.009033357724547386
step: 190, loss: 0.02519942820072174
step: 200, loss: 0.08479584753513336
step: 210, loss: 0.00984193105250597
step: 220, loss: 0.16330444812774658
step: 230, loss: 0.07225405424833298
step: 240, loss: 0.029623765498399734
step: 250, loss: 0.04361942410469055
step: 260, loss: 0.011227203533053398
step: 270, loss: 0.07381090521812439
step: 280, loss: 0.01706971973180771
step: 290, loss: 0.17873603105545044
step: 300, loss: 0.03644845262169838
step: 310, loss: 0.09411051124334335
step: 320, loss: 0.008579466491937637
step: 330, loss: 0.03027908131480217
step: 340, loss: 0.1339414417743683
step: 350, loss: 0.06178991496562958
step: 360, loss: 8.455412171315402e-05
step: 370, loss: 0.03490816801786423
step: 380, loss: 0.035886652767658234
epoch 9: dev_f1=0.6894865525672371, f1=0.6804123711340206, best_f1=0.741687979539642
step: 0, loss: 0.07810179889202118
step: 10, loss: 0.10359477996826172
step: 20, loss: 0.064407579600811
step: 30, loss: 0.008626635186374187
step: 40, loss: 0.16763174533843994
step: 50, loss: 0.10599680244922638
step: 60, loss: 0.0872756764292717
step: 70, loss: 9.781568223843351e-05
step: 80, loss: 0.0010164097184315324
step: 90, loss: 0.05932636186480522
step: 100, loss: 0.003434081096202135
step: 110, loss: 0.0593588650226593
step: 120, loss: 0.0050902399234473705
step: 130, loss: 0.00010044005466625094
step: 140, loss: 0.012261309660971165
step: 150, loss: 0.003988193813711405
step: 160, loss: 0.031107991933822632
step: 170, loss: 0.09558619558811188
step: 180, loss: 0.00625850073993206
step: 190, loss: 0.05417564883828163
step: 200, loss: 0.2581864297389984
step: 210, loss: 0.040877651423215866
step: 220, loss: 0.032905809581279755
step: 230, loss: 0.034240078181028366
step: 240, loss: 0.09562572836875916
step: 250, loss: 0.02393312379717827
step: 260, loss: 0.05196927860379219
step: 270, loss: 0.06797921657562256
step: 280, loss: 0.08806344121694565
step: 290, loss: 0.02682477794587612
step: 300, loss: 0.03921766206622124
step: 310, loss: 0.04166305437684059
step: 320, loss: 0.026142876595258713
step: 330, loss: 0.0367964431643486
step: 340, loss: 0.05494076758623123
step: 350, loss: 0.058734260499477386
step: 360, loss: 0.04513775557279587
step: 370, loss: 0.05517122521996498
step: 380, loss: 0.09226081520318985
epoch 10: dev_f1=0.7457627118644068, f1=0.7021791767554478, best_f1=0.741687979539642
step: 0, loss: 0.07173503935337067
step: 10, loss: 0.025026598945260048
step: 20, loss: 0.004529042635113001
step: 30, loss: 0.0670771673321724
step: 40, loss: 0.09005025774240494
step: 50, loss: 0.08908821642398834
step: 60, loss: 0.027715960517525673
step: 70, loss: 0.0354413278400898
step: 80, loss: 0.013402353040874004
step: 90, loss: 0.038086824119091034
step: 100, loss: 0.07218114286661148
step: 110, loss: 0.017349541187286377
step: 120, loss: 0.014132561162114143
step: 130, loss: 0.0172079149633646
step: 140, loss: 0.025811323896050453
step: 150, loss: 0.017361262813210487
step: 160, loss: 0.07381147891283035
step: 170, loss: 0.053731612861156464
step: 180, loss: 0.10578539967536926
step: 190, loss: 0.004804924130439758
step: 200, loss: 0.07043643295764923
step: 210, loss: 0.0297418013215065
step: 220, loss: 0.007125605829060078
step: 230, loss: 0.0025217831134796143
step: 240, loss: 0.021790795028209686
step: 250, loss: 6.806290912209079e-05
step: 260, loss: 0.055994343012571335
step: 270, loss: 0.07713549584150314
step: 280, loss: 0.0340866781771183
step: 290, loss: 0.03628115728497505
step: 300, loss: 0.03994908556342125
step: 310, loss: 0.01704368181526661
step: 320, loss: 0.0687437355518341
step: 330, loss: 0.008148720487952232
step: 340, loss: 0.0352090448141098
step: 350, loss: 0.008847120217978954
step: 360, loss: 0.03605351224541664
step: 370, loss: 0.03309152275323868
step: 380, loss: 0.06600350886583328
epoch 11: dev_f1=0.7391304347826088, f1=0.6780487804878049, best_f1=0.741687979539642
step: 0, loss: 0.019963417202234268
step: 10, loss: 0.0072046429850161076
step: 20, loss: 0.14919213950634003
step: 30, loss: 0.014947638846933842
step: 40, loss: 0.09146042168140411
step: 50, loss: 0.06832492351531982
step: 60, loss: 0.02589283511042595
step: 70, loss: 0.0021316453348845243
step: 80, loss: 0.0435258150100708
step: 90, loss: 0.03109230101108551
step: 100, loss: 0.026772234588861465
step: 110, loss: 0.0001121404638979584
step: 120, loss: 0.05760327726602554
step: 130, loss: 6.119118188507855e-05
step: 140, loss: 0.0583663210272789
step: 150, loss: 0.025396011769771576
step: 160, loss: 0.04566352069377899
step: 170, loss: 0.007568416651338339
step: 180, loss: 0.09481282532215118
step: 190, loss: 0.002012220909819007
step: 200, loss: 0.06411249190568924
step: 210, loss: 0.007676573004573584
step: 220, loss: 9.705546108307317e-05
step: 230, loss: 0.14479319751262665
step: 240, loss: 0.07267851382493973
step: 250, loss: 0.0004886799724772573
step: 260, loss: 0.08653252571821213
step: 270, loss: 0.05998145043849945
step: 280, loss: 0.026507869362831116
step: 290, loss: 0.05441824719309807
step: 300, loss: 0.07221014052629471
step: 310, loss: 0.03655782341957092
step: 320, loss: 0.009068887680768967
step: 330, loss: 0.0709586963057518
step: 340, loss: 0.005454077385365963
step: 350, loss: 0.019602539017796516
step: 360, loss: 0.15051376819610596
step: 370, loss: 0.047279004007577896
step: 380, loss: 0.027903638780117035
epoch 12: dev_f1=0.7365591397849462, f1=0.670391061452514, best_f1=0.741687979539642
step: 0, loss: 0.009859313257038593
step: 10, loss: 0.01935136690735817
step: 20, loss: 0.04018547385931015
step: 30, loss: 0.16056695580482483
step: 40, loss: 0.001057349843904376
step: 50, loss: 0.02217448316514492
step: 60, loss: 0.028840474784374237
step: 70, loss: 0.03506004065275192
step: 80, loss: 0.05042681470513344
step: 90, loss: 0.04849334806203842
step: 100, loss: 0.038962703198194504
step: 110, loss: 0.07010874897241592
step: 120, loss: 0.08089318126440048
step: 130, loss: 0.1564704328775406
step: 140, loss: 0.04798218607902527
step: 150, loss: 0.03245948255062103
step: 160, loss: 0.04858023300766945
step: 170, loss: 0.058402854949235916
step: 180, loss: 0.003685534466058016
step: 190, loss: 0.015276767313480377
step: 200, loss: 0.11088908463716507
step: 210, loss: 0.0564737543463707
step: 220, loss: 0.039832718670368195
step: 230, loss: 0.09518544375896454
step: 240, loss: 0.05168405920267105
step: 250, loss: 0.054250724613666534
step: 260, loss: 0.008735422044992447
step: 270, loss: 0.07164691388607025
step: 280, loss: 0.04136332869529724
step: 290, loss: 0.049721915274858475
step: 300, loss: 0.049328479915857315
step: 310, loss: 0.0019111623987555504
step: 320, loss: 0.13515469431877136
step: 330, loss: 0.01315043494105339
step: 340, loss: 0.06394601613283157
step: 350, loss: 0.022592594847083092
step: 360, loss: 0.1323683112859726
step: 370, loss: 0.0195976160466671
step: 380, loss: 0.055542852729558945
epoch 13: dev_f1=0.7123287671232876, f1=0.6855791962174941, best_f1=0.741687979539642
step: 0, loss: 0.06066953018307686
step: 10, loss: 0.11962182074785233
step: 20, loss: 0.06185728684067726
step: 30, loss: 0.04951390624046326
step: 40, loss: 0.008336331695318222
step: 50, loss: 0.04130762442946434
step: 60, loss: 0.010643486864864826
step: 70, loss: 0.011977637186646461
step: 80, loss: 0.0070916274562478065
step: 90, loss: 0.15846417844295502
step: 100, loss: 0.03611815348267555
step: 110, loss: 0.04826688766479492
step: 120, loss: 0.022190630435943604
step: 130, loss: 0.10004866868257523
step: 140, loss: 0.0011336617171764374
step: 150, loss: 0.001963067566975951
step: 160, loss: 0.04629608988761902
step: 170, loss: 0.00844576209783554
step: 180, loss: 0.07429929822683334
step: 190, loss: 0.012220194563269615
step: 200, loss: 0.058364782482385635
step: 210, loss: 0.01426179800182581
step: 220, loss: 0.12233177572488785
step: 230, loss: 0.08166272193193436
step: 240, loss: 0.08261929452419281
step: 250, loss: 0.04971809685230255
step: 260, loss: 0.014611526392400265
step: 270, loss: 0.04406808316707611
step: 280, loss: 0.010635229758918285
step: 290, loss: 0.02613897994160652
step: 300, loss: 0.08119302988052368
step: 310, loss: 0.11379622668027878
step: 320, loss: 0.026429491117596626
step: 330, loss: 0.10748312622308731
step: 340, loss: 0.05153088644146919
step: 350, loss: 0.06494301557540894
step: 360, loss: 5.907930608373135e-05
step: 370, loss: 0.09792697429656982
step: 380, loss: 0.06149481609463692
epoch 14: dev_f1=0.7068493150684931, f1=0.6457142857142857, best_f1=0.741687979539642
step: 0, loss: 0.030492296442389488
step: 10, loss: 0.004451093729585409
step: 20, loss: 0.00016714709636289626
step: 30, loss: 0.00309158256277442
step: 40, loss: 0.0005905550788156688
step: 50, loss: 0.03386727347970009
step: 60, loss: 0.00021900387946516275
step: 70, loss: 0.012756542302668095
step: 80, loss: 0.03671732917428017
step: 90, loss: 0.03018968552350998
step: 100, loss: 0.028075866401195526
step: 110, loss: 0.005513810086995363
step: 120, loss: 0.012101126834750175
step: 130, loss: 0.06122661009430885
step: 140, loss: 0.07899464666843414
step: 150, loss: 0.01909399777650833
step: 160, loss: 0.06237858906388283
step: 170, loss: 0.0005920252879150212
step: 180, loss: 0.026287885382771492
step: 190, loss: 0.004796500783413649
step: 200, loss: 0.009019159711897373
step: 210, loss: 0.023726411163806915
step: 220, loss: 0.037079669535160065
step: 230, loss: 0.03342906013131142
step: 240, loss: 0.023837659507989883
step: 250, loss: 0.05474907159805298
step: 260, loss: 0.011602945625782013
step: 270, loss: 0.08319579064846039
step: 280, loss: 0.011498892679810524
step: 290, loss: 0.010577984154224396
step: 300, loss: 0.02839432656764984
step: 310, loss: 0.05549057573080063
step: 320, loss: 0.0691542774438858
step: 330, loss: 0.038528747856616974
step: 340, loss: 0.00015034519310574979
step: 350, loss: 0.01688876561820507
step: 360, loss: 0.017056331038475037
step: 370, loss: 0.04883376136422157
step: 380, loss: 0.01576624996960163
epoch 15: dev_f1=0.7132169576059851, f1=0.6564102564102564, best_f1=0.741687979539642
step: 0, loss: 0.0693519115447998
step: 10, loss: 0.03885606676340103
step: 20, loss: 0.0881623774766922
step: 30, loss: 0.0010006810771301389
step: 40, loss: 0.08334965258836746
step: 50, loss: 7.84353687777184e-05
step: 60, loss: 0.023387953639030457
step: 70, loss: 0.10382302850484848
step: 80, loss: 0.009259470738470554
step: 90, loss: 0.051508355885744095
step: 100, loss: 0.06269616633653641
step: 110, loss: 0.11353829503059387
step: 120, loss: 0.03885394334793091
step: 130, loss: 0.024522893130779266
step: 140, loss: 0.0010445602238178253
step: 150, loss: 0.02928387187421322
step: 160, loss: 0.0314023420214653
step: 170, loss: 0.05943949893116951
step: 180, loss: 0.0013962845550850034
step: 190, loss: 0.14661750197410583
step: 200, loss: 0.03287353366613388
step: 210, loss: 0.12630422413349152
step: 220, loss: 0.013547342270612717
step: 230, loss: 0.02392405830323696
step: 240, loss: 0.009092343971133232
step: 250, loss: 0.051680512726306915
step: 260, loss: 0.01694268360733986
step: 270, loss: 0.0005319462507031858
step: 280, loss: 0.0009099083254113793
step: 290, loss: 0.005336525849997997
step: 300, loss: 0.017347710207104683
step: 310, loss: 0.0052289292216300964
step: 320, loss: 0.047428131103515625
step: 330, loss: 0.0011813681339845061
step: 340, loss: 0.011391831561923027
step: 350, loss: 0.025278549641370773
step: 360, loss: 0.01113554835319519
step: 370, loss: 3.0036298994673416e-05
step: 380, loss: 0.000749143015127629
epoch 16: dev_f1=0.6991869918699186, f1=0.6406685236768802, best_f1=0.741687979539642
step: 0, loss: 2.8903996280860156e-05
step: 10, loss: 0.015073896385729313
step: 20, loss: 0.024614444002509117
step: 30, loss: 0.019273046404123306
step: 40, loss: 0.0584493987262249
step: 50, loss: 0.004566406365483999
step: 60, loss: 0.009124559350311756
step: 70, loss: 0.0034635255578905344
step: 80, loss: 0.009508449584245682
step: 90, loss: 0.009116631001234055
step: 100, loss: 0.021267380565404892
step: 110, loss: 0.05612259358167648
step: 120, loss: 0.05722542107105255
step: 130, loss: 0.10642121732234955
step: 140, loss: 0.02944989874958992
step: 150, loss: 0.026397231966257095
step: 160, loss: 0.0126521410420537
step: 170, loss: 0.02721579559147358
step: 180, loss: 0.09997335076332092
step: 190, loss: 0.04439248889684677
step: 200, loss: 0.041410889476537704
step: 210, loss: 0.03462814539670944
step: 220, loss: 0.021262336522340775
step: 230, loss: 0.1200285404920578
step: 240, loss: 0.008838916197419167
step: 250, loss: 0.07601609826087952
step: 260, loss: 9.07141002244316e-05
step: 270, loss: 0.012312967330217361
step: 280, loss: 0.04289388284087181
step: 290, loss: 0.019802991300821304
step: 300, loss: 0.09339720755815506
step: 310, loss: 0.022995594888925552
step: 320, loss: 0.07277315109968185
step: 330, loss: 0.06593865901231766
step: 340, loss: 0.01598992757499218
step: 350, loss: 0.14094889163970947
step: 360, loss: 0.025749335065484047
step: 370, loss: 0.029952198266983032
step: 380, loss: 0.0808306336402893
epoch 17: dev_f1=0.7048710601719199, f1=0.6451612903225806, best_f1=0.741687979539642
step: 0, loss: 0.006694067269563675
step: 10, loss: 0.0003058085567317903
step: 20, loss: 0.036325372755527496
step: 30, loss: 0.003064734861254692
step: 40, loss: 0.06251060217618942
step: 50, loss: 0.04687843844294548
step: 60, loss: 0.037419479340314865
step: 70, loss: 0.028052236884832382
step: 80, loss: 0.06162944808602333
step: 90, loss: 0.027246948331594467
step: 100, loss: 0.06428121775388718
step: 110, loss: 0.1327694058418274
step: 120, loss: 0.0483911968767643
step: 130, loss: 0.008778181858360767
step: 140, loss: 0.10476627945899963
step: 150, loss: 0.02286556176841259
step: 160, loss: 0.03526102751493454
step: 170, loss: 0.022911466658115387
step: 180, loss: 0.021958936005830765
step: 190, loss: 0.01670979894697666
step: 200, loss: 0.007106561679393053
step: 210, loss: 0.06284432858228683
step: 220, loss: 0.02261124737560749
step: 230, loss: 0.012339736334979534
step: 240, loss: 0.016618303954601288
step: 250, loss: 0.04075639322400093
step: 260, loss: 0.029352758079767227
step: 270, loss: 0.013982417993247509
step: 280, loss: 5.6961805967148393e-05
step: 290, loss: 0.0040365904569625854
step: 300, loss: 0.00043264555279165506
step: 310, loss: 0.009072499349713326
step: 320, loss: 0.008559802547097206
step: 330, loss: 0.008296207524836063
step: 340, loss: 3.056132482015528e-05
step: 350, loss: 0.0031946480739861727
step: 360, loss: 0.12296871095895767
step: 370, loss: 0.03568786010146141
step: 380, loss: 0.049658894538879395
epoch 18: dev_f1=0.711864406779661, f1=0.6666666666666667, best_f1=0.741687979539642
step: 0, loss: 0.08756544440984726
step: 10, loss: 0.06964372098445892
step: 20, loss: 0.014909221790730953
step: 30, loss: 0.0001743007596815005
step: 40, loss: 0.012394709512591362
step: 50, loss: 0.03978293761610985
step: 60, loss: 0.00484009413048625
step: 70, loss: 0.005973986349999905
step: 80, loss: 0.003114713355898857
step: 90, loss: 0.10225219279527664
step: 100, loss: 0.0809776559472084
step: 110, loss: 0.043838053941726685
step: 120, loss: 0.002798972651362419
step: 130, loss: 0.004282249137759209
step: 140, loss: 0.0001193316129501909
step: 150, loss: 0.00016051987768150866
step: 160, loss: 0.04443389177322388
step: 170, loss: 0.06072984263300896
step: 180, loss: 0.03452107682824135
step: 190, loss: 0.03149089217185974
step: 200, loss: 0.039769627153873444
step: 210, loss: 0.009741894900798798
step: 220, loss: 0.06991145014762878
step: 230, loss: 0.01593347080051899
step: 240, loss: 0.02034684643149376
step: 250, loss: 0.07336434721946716
step: 260, loss: 0.013547965325415134
step: 270, loss: 0.07997666299343109
step: 280, loss: 0.14802537858486176
step: 290, loss: 0.03789187967777252
step: 300, loss: 0.025526966899633408
step: 310, loss: 0.04404240474104881
step: 320, loss: 0.0005888233426958323
step: 330, loss: 0.017552779987454414
step: 340, loss: 0.03137180954217911
step: 350, loss: 0.0020186672918498516
step: 360, loss: 0.056559864431619644
step: 370, loss: 0.01664864271879196
step: 380, loss: 0.004184288904070854
epoch 19: dev_f1=0.7317073170731707, f1=0.668555240793201, best_f1=0.741687979539642
step: 0, loss: 0.0046810973435640335
step: 10, loss: 0.03813641518354416
step: 20, loss: 0.0005754815065301955
step: 30, loss: 0.05674823001027107
step: 40, loss: 0.051866140216588974
step: 50, loss: 0.03254435583949089
step: 60, loss: 0.017867833375930786
step: 70, loss: 0.07484234869480133
step: 80, loss: 0.008116387762129307
step: 90, loss: 0.006063244305551052
step: 100, loss: 0.00466545345261693
step: 110, loss: 0.010597114451229572
step: 120, loss: 0.00038193483487702906
step: 130, loss: 0.0034618631470948458
step: 140, loss: 0.06453562527894974
step: 150, loss: 0.009234555065631866
step: 160, loss: 0.01989087648689747
step: 170, loss: 0.0840463638305664
step: 180, loss: 0.044233426451683044
step: 190, loss: 0.02202862873673439
step: 200, loss: 0.001949152909219265
step: 210, loss: 0.014941079542040825
step: 220, loss: 0.01648574508726597
step: 230, loss: 0.011684952303767204
step: 240, loss: 0.03528358414769173
step: 250, loss: 0.056420084089040756
step: 260, loss: 0.010402210056781769
step: 270, loss: 0.062782883644104
step: 280, loss: 0.027235975489020348
step: 290, loss: 0.043587394058704376
step: 300, loss: 0.009478326886892319
step: 310, loss: 0.004114486742764711
step: 320, loss: 0.018870245665311813
step: 330, loss: 0.0003410591452848166
step: 340, loss: 0.0021521360613405704
step: 350, loss: 0.01742730662226677
step: 360, loss: 0.00048809879808686674
step: 370, loss: 0.049386151134967804
step: 380, loss: 0.0144704170525074
epoch 20: dev_f1=0.7130919220055711, f1=0.6551724137931034, best_f1=0.741687979539642
