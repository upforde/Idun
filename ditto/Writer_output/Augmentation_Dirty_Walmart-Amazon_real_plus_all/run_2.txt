cuda
Device: cuda
step: 0, loss: 0.6034718155860901
step: 10, loss: 0.31085994839668274
step: 20, loss: 0.22305655479431152
step: 30, loss: 0.3733670115470886
step: 40, loss: 0.23111355304718018
step: 50, loss: 0.30741459131240845
step: 60, loss: 0.13060207664966583
step: 70, loss: 0.354282945394516
step: 80, loss: 0.43065062165260315
step: 90, loss: 0.32588326930999756
step: 100, loss: 0.3670942187309265
step: 110, loss: 0.28247353434562683
step: 120, loss: 0.3145294189453125
step: 130, loss: 0.12638582289218903
step: 140, loss: 0.30786725878715515
step: 150, loss: 0.43238914012908936
step: 160, loss: 0.22865113615989685
step: 170, loss: 0.17084744572639465
step: 180, loss: 0.18553395569324493
step: 190, loss: 0.1342773735523224
step: 200, loss: 0.3673152029514313
step: 210, loss: 0.1338372677564621
step: 220, loss: 0.1114671528339386
step: 230, loss: 0.043078284710645676
step: 240, loss: 0.11401252448558807
step: 250, loss: 0.2144017219543457
step: 260, loss: 0.21741551160812378
step: 270, loss: 0.256163090467453
step: 280, loss: 0.08271332830190659
step: 290, loss: 0.1297113299369812
step: 300, loss: 0.15797381103038788
step: 310, loss: 0.0634143203496933
step: 320, loss: 0.16098862886428833
step: 330, loss: 0.3399791717529297
step: 340, loss: 0.10112455487251282
step: 350, loss: 0.2762547731399536
step: 360, loss: 0.05349292606115341
step: 370, loss: 0.12613168358802795
step: 380, loss: 0.09206070005893707
epoch 1: dev_f1=0.6082474226804122, f1=0.6410256410256411, best_f1=0.6410256410256411
step: 0, loss: 0.14717532694339752
step: 10, loss: 0.1648813784122467
step: 20, loss: 0.265565425157547
step: 30, loss: 0.11571232974529266
step: 40, loss: 0.07730375230312347
step: 50, loss: 0.04194962978363037
step: 60, loss: 0.11752301454544067
step: 70, loss: 0.19262288510799408
step: 80, loss: 0.09898985177278519
step: 90, loss: 0.22042380273342133
step: 100, loss: 0.15130308270454407
step: 110, loss: 0.1822686642408371
step: 120, loss: 0.15852965414524078
step: 130, loss: 0.054765600711107254
step: 140, loss: 0.1850610226392746
step: 150, loss: 0.26544079184532166
step: 160, loss: 0.12943746149539948
step: 170, loss: 0.036945782601833344
step: 180, loss: 0.04752708971500397
step: 190, loss: 0.1309686005115509
step: 200, loss: 0.16443578898906708
step: 210, loss: 0.0848841443657875
step: 220, loss: 0.2917972803115845
step: 230, loss: 0.043705690652132034
step: 240, loss: 0.06080663949251175
step: 250, loss: 0.09457270056009293
step: 260, loss: 0.11676383763551712
step: 270, loss: 0.1495448350906372
step: 280, loss: 0.1918308138847351
step: 290, loss: 0.2235623151063919
step: 300, loss: 0.029553059488534927
step: 310, loss: 0.08865303546190262
step: 320, loss: 0.028346050530672073
step: 330, loss: 0.1365531086921692
step: 340, loss: 0.08350610733032227
step: 350, loss: 0.06757613271474838
step: 360, loss: 0.07600995153188705
step: 370, loss: 0.13979074358940125
step: 380, loss: 0.2651098668575287
epoch 2: dev_f1=0.6797752808988764, f1=0.6902173913043479, best_f1=0.6902173913043479
step: 0, loss: 0.14891093969345093
step: 10, loss: 0.09819164872169495
step: 20, loss: 0.10159260034561157
step: 30, loss: 0.05815762281417847
step: 40, loss: 0.020569970831274986
step: 50, loss: 0.06251674890518188
step: 60, loss: 0.08263544738292694
step: 70, loss: 0.0978853851556778
step: 80, loss: 0.09679154306650162
step: 90, loss: 0.03377585858106613
step: 100, loss: 0.2766024172306061
step: 110, loss: 0.12280258536338806
step: 120, loss: 0.1591593325138092
step: 130, loss: 0.09395980834960938
step: 140, loss: 0.13991017639636993
step: 150, loss: 0.16291961073875427
step: 160, loss: 0.07504855841398239
step: 170, loss: 0.0976233258843422
step: 180, loss: 0.14086946845054626
step: 190, loss: 0.04622086137533188
step: 200, loss: 0.07078193128108978
step: 210, loss: 0.17810264229774475
step: 220, loss: 0.07983468472957611
step: 230, loss: 0.11231177300214767
step: 240, loss: 0.16312569379806519
step: 250, loss: 0.07878492772579193
step: 260, loss: 0.05112846568226814
step: 270, loss: 0.141402468085289
step: 280, loss: 0.00922310072928667
step: 290, loss: 0.02017739787697792
step: 300, loss: 0.1408626288175583
step: 310, loss: 0.07251992076635361
step: 320, loss: 0.23557095229625702
step: 330, loss: 0.1105126291513443
step: 340, loss: 0.2822810709476471
step: 350, loss: 0.14306682348251343
step: 360, loss: 0.18398185074329376
step: 370, loss: 0.23573759198188782
step: 380, loss: 0.1693057119846344
epoch 3: dev_f1=0.7448979591836734, f1=0.7082294264339153, best_f1=0.7082294264339153
step: 0, loss: 0.10821332782506943
step: 10, loss: 0.14963661134243011
step: 20, loss: 0.08491802960634232
step: 30, loss: 0.05069076642394066
step: 40, loss: 0.03360741585493088
step: 50, loss: 0.17100436985492706
step: 60, loss: 0.08823802322149277
step: 70, loss: 0.08550776541233063
step: 80, loss: 0.02161867544054985
step: 90, loss: 0.060874972492456436
step: 100, loss: 0.11375141143798828
step: 110, loss: 0.06434838473796844
step: 120, loss: 0.14234639704227448
step: 130, loss: 0.05470392107963562
step: 140, loss: 0.10338331758975983
step: 150, loss: 0.09803032130002975
step: 160, loss: 0.08998987823724747
step: 170, loss: 0.10028377920389175
step: 180, loss: 0.07867660373449326
step: 190, loss: 0.09850170463323593
step: 200, loss: 0.1666969507932663
step: 210, loss: 0.16183890402317047
step: 220, loss: 0.10362134128808975
step: 230, loss: 0.0374414399266243
step: 240, loss: 0.07969964295625687
step: 250, loss: 0.06801124662160873
step: 260, loss: 0.036726560443639755
step: 270, loss: 0.10169671475887299
step: 280, loss: 0.05009462684392929
step: 290, loss: 0.04070219770073891
step: 300, loss: 0.17597629129886627
step: 310, loss: 0.04536553472280502
step: 320, loss: 0.12361187487840652
step: 330, loss: 0.15053987503051758
step: 340, loss: 0.057915519922971725
step: 350, loss: 0.041723135858774185
step: 360, loss: 0.02874351292848587
step: 370, loss: 0.21648816764354706
step: 380, loss: 0.1346966028213501
epoch 4: dev_f1=0.7082294264339153, f1=0.7240506329113923, best_f1=0.7082294264339153
step: 0, loss: 0.03184409812092781
step: 10, loss: 0.2096758931875229
step: 20, loss: 0.08584970980882645
step: 30, loss: 0.09302300214767456
step: 40, loss: 0.06797976046800613
step: 50, loss: 0.06787794828414917
step: 60, loss: 0.10740436613559723
step: 70, loss: 0.06548739969730377
step: 80, loss: 0.09513313323259354
step: 90, loss: 0.15157637000083923
step: 100, loss: 0.1167377382516861
step: 110, loss: 0.09248457849025726
step: 120, loss: 0.02260318025946617
step: 130, loss: 0.01836194097995758
step: 140, loss: 0.17632877826690674
step: 150, loss: 0.06485385447740555
step: 160, loss: 0.10647211968898773
step: 170, loss: 0.11656560003757477
step: 180, loss: 0.12295260280370712
step: 190, loss: 0.054475221782922745
step: 200, loss: 0.288081556558609
step: 210, loss: 0.2398083209991455
step: 220, loss: 0.05404346436262131
step: 230, loss: 0.14657555520534515
step: 240, loss: 0.057384900748729706
step: 250, loss: 0.08211854845285416
step: 260, loss: 0.09164545685052872
step: 270, loss: 0.06611894816160202
step: 280, loss: 0.12753544747829437
step: 290, loss: 0.03765473887324333
step: 300, loss: 0.1469215452671051
step: 310, loss: 0.05140543729066849
step: 320, loss: 0.15600557625293732
step: 330, loss: 0.0978691503405571
step: 340, loss: 0.11219510436058044
step: 350, loss: 0.09699464589357376
step: 360, loss: 0.03359035402536392
step: 370, loss: 0.10182256996631622
step: 380, loss: 0.05628591403365135
epoch 5: dev_f1=0.7216981132075472, f1=0.7427184466019418, best_f1=0.7082294264339153
step: 0, loss: 0.05961510166525841
step: 10, loss: 0.005162338260561228
step: 20, loss: 0.002704882761463523
step: 30, loss: 0.10899392515420914
step: 40, loss: 0.1117938831448555
step: 50, loss: 0.07948237657546997
step: 60, loss: 0.10025986284017563
step: 70, loss: 0.10376515239477158
step: 80, loss: 0.0463520772755146
step: 90, loss: 0.033477332442998886
step: 100, loss: 0.04061559960246086
step: 110, loss: 0.039191748946905136
step: 120, loss: 0.07654478400945663
step: 130, loss: 0.04733901098370552
step: 140, loss: 0.09515409171581268
step: 150, loss: 0.0646313950419426
step: 160, loss: 0.12952665984630585
step: 170, loss: 0.05721860006451607
step: 180, loss: 0.14227548241615295
step: 190, loss: 0.16855892539024353
step: 200, loss: 0.03367232903838158
step: 210, loss: 0.06445392221212387
step: 220, loss: 0.06534849107265472
step: 230, loss: 0.0884416326880455
step: 240, loss: 0.10265250504016876
step: 250, loss: 0.046334024518728256
step: 260, loss: 0.09959486871957779
step: 270, loss: 0.06857140362262726
step: 280, loss: 0.16154202818870544
step: 290, loss: 0.12156716734170914
step: 300, loss: 0.003024646546691656
step: 310, loss: 0.13864190876483917
step: 320, loss: 0.01658419519662857
step: 330, loss: 0.07596978545188904
step: 340, loss: 0.04483938589692116
step: 350, loss: 0.050286006182432175
step: 360, loss: 0.11696881800889969
step: 370, loss: 0.06061485782265663
step: 380, loss: 0.07359172403812408
epoch 6: dev_f1=0.7254408060453401, f1=0.72, best_f1=0.7082294264339153
step: 0, loss: 0.047577325254678726
step: 10, loss: 0.055295489728450775
step: 20, loss: 0.04985858127474785
step: 30, loss: 0.08655229210853577
step: 40, loss: 0.08152911812067032
step: 50, loss: 0.007503974717110395
step: 60, loss: 0.050147730857133865
step: 70, loss: 0.09019536525011063
step: 80, loss: 0.07590465992689133
step: 90, loss: 0.042811863124370575
step: 100, loss: 0.020593512803316116
step: 110, loss: 0.058720946311950684
step: 120, loss: 0.05865802615880966
step: 130, loss: 0.004608146846294403
step: 140, loss: 0.04324694722890854
step: 150, loss: 0.08788743615150452
step: 160, loss: 0.12501513957977295
step: 170, loss: 0.03580781817436218
step: 180, loss: 0.19009555876255035
step: 190, loss: 0.1727927029132843
step: 200, loss: 0.03337811678647995
step: 210, loss: 0.0565069355070591
step: 220, loss: 0.03333716094493866
step: 230, loss: 0.023635266348719597
step: 240, loss: 0.04738425090909004
step: 250, loss: 0.05555974319577217
step: 260, loss: 0.05452869459986687
step: 270, loss: 0.0546761229634285
step: 280, loss: 0.08445406705141068
step: 290, loss: 0.030246157199144363
step: 300, loss: 0.07813260704278946
step: 310, loss: 0.11800772696733475
step: 320, loss: 0.08273183554410934
step: 330, loss: 0.06725651025772095
step: 340, loss: 0.004366369917988777
step: 350, loss: 0.21753144264221191
step: 360, loss: 0.045734573155641556
step: 370, loss: 0.05245860293507576
step: 380, loss: 0.06661062687635422
epoch 7: dev_f1=0.7604938271604939, f1=0.7373493975903614, best_f1=0.7373493975903614
step: 0, loss: 0.037204641848802567
step: 10, loss: 0.03696221113204956
step: 20, loss: 0.03860406577587128
step: 30, loss: 0.11086732149124146
step: 40, loss: 0.0787503570318222
step: 50, loss: 0.05157772824168205
step: 60, loss: 0.044175997376441956
step: 70, loss: 0.042456671595573425
step: 80, loss: 0.038187425583601
step: 90, loss: 0.053470008075237274
step: 100, loss: 0.04691823199391365
step: 110, loss: 0.10944542288780212
step: 120, loss: 0.025010673329234123
step: 130, loss: 0.07883324474096298
step: 140, loss: 0.1444624960422516
step: 150, loss: 0.02317110076546669
step: 160, loss: 0.032027438282966614
step: 170, loss: 0.061136070638895035
step: 180, loss: 0.039381884038448334
step: 190, loss: 0.06215761601924896
step: 200, loss: 0.034664005041122437
step: 210, loss: 0.061001770198345184
step: 220, loss: 0.05658900365233421
step: 230, loss: 0.06949684768915176
step: 240, loss: 0.07719345390796661
step: 250, loss: 0.08034204691648483
step: 260, loss: 0.016303271055221558
step: 270, loss: 0.0227322019636631
step: 280, loss: 0.039103638380765915
step: 290, loss: 0.013176670297980309
step: 300, loss: 0.0917169451713562
step: 310, loss: 0.04469782114028931
step: 320, loss: 0.04730372875928879
step: 330, loss: 0.09196323901414871
step: 340, loss: 0.0648738369345665
step: 350, loss: 0.015017276629805565
step: 360, loss: 0.018555112183094025
step: 370, loss: 0.130346417427063
step: 380, loss: 0.0012792294146493077
epoch 8: dev_f1=0.7310704960835509, f1=0.7154046997389033, best_f1=0.7373493975903614
step: 0, loss: 0.06496962159872055
step: 10, loss: 0.06651680916547775
step: 20, loss: 0.05782047659158707
step: 30, loss: 0.09774414449930191
step: 40, loss: 0.024393649771809578
step: 50, loss: 0.01899784244596958
step: 60, loss: 0.04928598552942276
step: 70, loss: 0.02240036614239216
step: 80, loss: 0.15689976513385773
step: 90, loss: 0.00038910278817638755
step: 100, loss: 0.05449333414435387
step: 110, loss: 0.027268817648291588
step: 120, loss: 0.04005395621061325
step: 130, loss: 0.05374249070882797
step: 140, loss: 0.06523710489273071
step: 150, loss: 0.13716839253902435
step: 160, loss: 0.10501749813556671
step: 170, loss: 0.03529360145330429
step: 180, loss: 0.06055516004562378
step: 190, loss: 0.06157425045967102
step: 200, loss: 0.02432715706527233
step: 210, loss: 0.010744065046310425
step: 220, loss: 0.15955959260463715
step: 230, loss: 0.05274045094847679
step: 240, loss: 0.08242717385292053
step: 250, loss: 0.21963420510292053
step: 260, loss: 0.03712182864546776
step: 270, loss: 0.05546880513429642
step: 280, loss: 0.1058158427476883
step: 290, loss: 0.062161535024642944
step: 300, loss: 0.06078304722905159
step: 310, loss: 0.07447316497564316
step: 320, loss: 0.1359138786792755
step: 330, loss: 0.05023975297808647
step: 340, loss: 0.05346572771668434
step: 350, loss: 0.055402591824531555
step: 360, loss: 0.06490586698055267
step: 370, loss: 0.041701652109622955
step: 380, loss: 0.10107924044132233
epoch 9: dev_f1=0.7427055702917772, f1=0.7301587301587302, best_f1=0.7373493975903614
step: 0, loss: 0.06626161932945251
step: 10, loss: 0.07091360539197922
step: 20, loss: 0.06848013401031494
step: 30, loss: 0.029458139091730118
step: 40, loss: 0.018832115456461906
step: 50, loss: 0.2337411791086197
step: 60, loss: 0.061258699744939804
step: 70, loss: 0.027960047125816345
step: 80, loss: 0.039814166724681854
step: 90, loss: 0.09228504449129105
step: 100, loss: 0.06479129195213318
step: 110, loss: 0.027534490451216698
step: 120, loss: 0.04896938428282738
step: 130, loss: 0.005273416638374329
step: 140, loss: 0.021927496418356895
step: 150, loss: 0.10529346764087677
step: 160, loss: 0.045213308185338974
step: 170, loss: 0.08324514329433441
step: 180, loss: 0.07279998809099197
step: 190, loss: 0.06671623885631561
step: 200, loss: 0.09511135518550873
step: 210, loss: 0.001531727146357298
step: 220, loss: 0.027742182835936546
step: 230, loss: 0.11376243084669113
step: 240, loss: 0.0908127948641777
step: 250, loss: 0.1453421264886856
step: 260, loss: 0.028576305136084557
step: 270, loss: 0.11573252081871033
step: 280, loss: 0.07578407227993011
step: 290, loss: 0.1426028162240982
step: 300, loss: 0.027084216475486755
step: 310, loss: 0.016718994826078415
step: 320, loss: 0.11556616425514221
step: 330, loss: 0.058508455753326416
step: 340, loss: 0.06167137250304222
step: 350, loss: 0.14218029379844666
step: 360, loss: 0.04720892384648323
step: 370, loss: 0.10238601267337799
step: 380, loss: 0.039996109902858734
epoch 10: dev_f1=0.7540983606557378, f1=0.7039106145251397, best_f1=0.7373493975903614
step: 0, loss: 0.023219188675284386
step: 10, loss: 0.046304505318403244
step: 20, loss: 0.1404048502445221
step: 30, loss: 0.07755209505558014
step: 40, loss: 0.10064713656902313
step: 50, loss: 0.01895153895020485
step: 60, loss: 0.04299439117312431
step: 70, loss: 0.05820469558238983
step: 80, loss: 0.05195903778076172
step: 90, loss: 0.023190515115857124
step: 100, loss: 0.07400099188089371
step: 110, loss: 0.01787654124200344
step: 120, loss: 0.07491886615753174
step: 130, loss: 0.0816745012998581
step: 140, loss: 0.034906864166259766
step: 150, loss: 0.004623435903340578
step: 160, loss: 0.08409220725297928
step: 170, loss: 0.0015774474013596773
step: 180, loss: 0.04989025369286537
step: 190, loss: 0.028856314718723297
step: 200, loss: 0.08627912402153015
step: 210, loss: 0.10474532842636108
step: 220, loss: 0.0008042099652811885
step: 230, loss: 0.09113279730081558
step: 240, loss: 0.02529117278754711
step: 250, loss: 0.07785781472921371
step: 260, loss: 0.01174493320286274
step: 270, loss: 0.07791648060083389
step: 280, loss: 0.16602595150470734
step: 290, loss: 0.05892729386687279
step: 300, loss: 0.020786520093679428
step: 310, loss: 0.029227150604128838
step: 320, loss: 0.16541075706481934
step: 330, loss: 0.029480919241905212
step: 340, loss: 0.00736276526004076
step: 350, loss: 0.047515857964754105
step: 360, loss: 0.016276469454169273
step: 370, loss: 0.10448934137821198
step: 380, loss: 0.08280009776353836
epoch 11: dev_f1=0.7308641975308642, f1=0.7142857142857143, best_f1=0.7373493975903614
step: 0, loss: 0.06486280262470245
step: 10, loss: 0.010049383156001568
step: 20, loss: 0.036547765135765076
step: 30, loss: 0.020153574645519257
step: 40, loss: 0.05655749887228012
step: 50, loss: 0.1193036139011383
step: 60, loss: 0.023600097745656967
step: 70, loss: 0.02917252480983734
step: 80, loss: 0.07385365664958954
step: 90, loss: 0.09162461012601852
step: 100, loss: 0.09076875448226929
step: 110, loss: 0.15514616668224335
step: 120, loss: 0.04375758394598961
step: 130, loss: 0.046458300203084946
step: 140, loss: 0.09140277653932571
step: 150, loss: 0.0006577310268767178
step: 160, loss: 0.04741942882537842
step: 170, loss: 0.1770232915878296
step: 180, loss: 0.11086682230234146
step: 190, loss: 0.05955485999584198
step: 200, loss: 0.028991863131523132
step: 210, loss: 0.09622412919998169
step: 220, loss: 0.06635578721761703
step: 230, loss: 0.052438367158174515
step: 240, loss: 0.016525259241461754
step: 250, loss: 0.05233823508024216
step: 260, loss: 0.09179340302944183
step: 270, loss: 0.09452176839113235
step: 280, loss: 0.09987104684114456
step: 290, loss: 0.035263970494270325
step: 300, loss: 0.061938002705574036
step: 310, loss: 0.1065300852060318
step: 320, loss: 0.08733034133911133
step: 330, loss: 0.039311185479164124
step: 340, loss: 0.11159507930278778
step: 350, loss: 0.05525435134768486
step: 360, loss: 0.03119870088994503
step: 370, loss: 0.08015000075101852
step: 380, loss: 0.11392809450626373
epoch 12: dev_f1=0.7421052631578948, f1=0.7200000000000001, best_f1=0.7373493975903614
step: 0, loss: 0.027333807200193405
step: 10, loss: 0.01987583562731743
step: 20, loss: 0.05381226912140846
step: 30, loss: 0.07006032764911652
step: 40, loss: 0.04415297880768776
step: 50, loss: 0.16989034414291382
step: 60, loss: 0.016275130212306976
step: 70, loss: 0.03076682612299919
step: 80, loss: 0.07150007784366608
step: 90, loss: 0.0003337590314913541
step: 100, loss: 0.07111646980047226
step: 110, loss: 0.03096919320523739
step: 120, loss: 0.006549980491399765
step: 130, loss: 0.051288917660713196
step: 140, loss: 0.09221941977739334
step: 150, loss: 0.03075697086751461
step: 160, loss: 0.013399791903793812
step: 170, loss: 0.00010483137157279998
step: 180, loss: 0.022320261225104332
step: 190, loss: 0.1546606868505478
step: 200, loss: 0.07440556585788727
step: 210, loss: 0.05669257417321205
step: 220, loss: 0.034055449068546295
step: 230, loss: 0.062286440283060074
step: 240, loss: 0.0846274197101593
step: 250, loss: 0.09148117899894714
step: 260, loss: 0.059423673897981644
step: 270, loss: 0.03665108606219292
step: 280, loss: 0.0012700229417532682
step: 290, loss: 0.04436146840453148
step: 300, loss: 0.1064208373427391
step: 310, loss: 0.005166731774806976
step: 320, loss: 0.11251766234636307
step: 330, loss: 0.11825291067361832
step: 340, loss: 0.02124672941863537
step: 350, loss: 0.01674412563443184
step: 360, loss: 0.037895459681749344
step: 370, loss: 0.08400087058544159
step: 380, loss: 0.02420315332710743
epoch 13: dev_f1=0.7242990654205607, f1=0.7259953161592505, best_f1=0.7373493975903614
step: 0, loss: 0.09299370646476746
step: 10, loss: 0.007333460263907909
step: 20, loss: 0.01679224893450737
step: 30, loss: 0.03205597400665283
step: 40, loss: 0.06895025074481964
step: 50, loss: 0.15333327651023865
step: 60, loss: 0.03104184754192829
step: 70, loss: 0.00010936252510873601
step: 80, loss: 0.031166337430477142
step: 90, loss: 0.0873657613992691
step: 100, loss: 0.05697881057858467
step: 110, loss: 0.04548558592796326
step: 120, loss: 0.02504456602036953
step: 130, loss: 0.10817138850688934
step: 140, loss: 0.11576887965202332
step: 150, loss: 0.04999425262212753
step: 160, loss: 0.08579310774803162
step: 170, loss: 0.05606405809521675
step: 180, loss: 0.09759966284036636
step: 190, loss: 0.019003817811608315
step: 200, loss: 0.08180321007966995
step: 210, loss: 0.06565260887145996
step: 220, loss: 0.05353957787156105
step: 230, loss: 0.028582094237208366
step: 240, loss: 0.04376072436571121
step: 250, loss: 0.045678071677684784
step: 260, loss: 0.05492408946156502
step: 270, loss: 0.029797762632369995
step: 280, loss: 0.03166883811354637
step: 290, loss: 0.05824188515543938
step: 300, loss: 7.927245314931497e-05
step: 310, loss: 0.06541117280721664
step: 320, loss: 0.07669106870889664
step: 330, loss: 0.023375140503048897
step: 340, loss: 0.040030587464571
step: 350, loss: 0.056454822421073914
step: 360, loss: 0.051430344581604004
step: 370, loss: 0.05902469903230667
step: 380, loss: 0.03160959854722023
epoch 14: dev_f1=0.7486338797814207, f1=0.7045454545454547, best_f1=0.7373493975903614
step: 0, loss: 0.0018570919055491686
step: 10, loss: 0.0716465562582016
step: 20, loss: 0.06515561789274216
step: 30, loss: 0.09523182362318039
step: 40, loss: 0.05612596124410629
step: 50, loss: 0.039362139999866486
step: 60, loss: 0.05475378409028053
step: 70, loss: 0.06056753173470497
step: 80, loss: 0.04723862186074257
step: 90, loss: 0.04610475152730942
step: 100, loss: 0.06631507724523544
step: 110, loss: 0.05250271037220955
step: 120, loss: 0.051718614995479584
step: 130, loss: 0.02983364462852478
step: 140, loss: 0.13159383833408356
step: 150, loss: 0.06454882025718689
step: 160, loss: 0.0793398842215538
step: 170, loss: 0.05207014083862305
step: 180, loss: 0.023714492097496986
step: 190, loss: 0.042422328144311905
step: 200, loss: 0.06098908558487892
step: 210, loss: 0.03897346556186676
step: 220, loss: 0.04471239075064659
step: 230, loss: 0.016457652673125267
step: 240, loss: 0.016513265669345856
step: 250, loss: 0.07980611175298691
step: 260, loss: 0.09168687462806702
step: 270, loss: 0.020355701446533203
step: 280, loss: 0.02951713092625141
step: 290, loss: 0.0010187155567109585
step: 300, loss: 0.04157576337456703
step: 310, loss: 0.12493289262056351
step: 320, loss: 0.027987534180283546
step: 330, loss: 0.035502221435308456
step: 340, loss: 0.06679102033376694
step: 350, loss: 0.09410354495048523
step: 360, loss: 0.0252984706312418
step: 370, loss: 0.020134318619966507
step: 380, loss: 0.01273945439606905
epoch 15: dev_f1=0.7210526315789473, f1=0.7093333333333335, best_f1=0.7373493975903614
step: 0, loss: 0.07309097051620483
step: 10, loss: 0.041041698306798935
step: 20, loss: 0.029154466465115547
step: 30, loss: 0.02208295464515686
step: 40, loss: 0.04308382421731949
step: 50, loss: 0.0014802285004407167
step: 60, loss: 0.010183260776102543
step: 70, loss: 0.03936174139380455
step: 80, loss: 0.009298210963606834
step: 90, loss: 0.0566401407122612
step: 100, loss: 0.117271289229393
step: 110, loss: 0.1176898181438446
step: 120, loss: 0.11127562075853348
step: 130, loss: 0.015756648033857346
step: 140, loss: 0.0857880711555481
step: 150, loss: 0.06635390222072601
step: 160, loss: 0.030099963769316673
step: 170, loss: 0.10260739922523499
step: 180, loss: 0.017648248001933098
step: 190, loss: 0.0008537540561519563
step: 200, loss: 0.07413957267999649
step: 210, loss: 0.0029753248672932386
step: 220, loss: 0.01371174305677414
step: 230, loss: 0.00851532630622387
step: 240, loss: 0.017099404707551003
step: 250, loss: 0.03246285021305084
step: 260, loss: 0.14236775040626526
step: 270, loss: 0.0218588188290596
step: 280, loss: 0.10974006354808807
step: 290, loss: 0.04550608992576599
step: 300, loss: 0.028997652232646942
step: 310, loss: 0.012391307391226292
step: 320, loss: 0.04474795609712601
step: 330, loss: 0.02656172215938568
step: 340, loss: 0.012786473147571087
step: 350, loss: 0.0645095631480217
step: 360, loss: 0.009260909631848335
step: 370, loss: 0.004324087407439947
step: 380, loss: 0.008847564458847046
epoch 16: dev_f1=0.7164948453608248, f1=0.6965699208443272, best_f1=0.7373493975903614
step: 0, loss: 0.030094552785158157
step: 10, loss: 0.01415970828384161
step: 20, loss: 0.03416910767555237
step: 30, loss: 0.025715529918670654
step: 40, loss: 0.06922705471515656
step: 50, loss: 0.0003524734638631344
step: 60, loss: 0.0018105281051248312
step: 70, loss: 0.041739270091056824
step: 80, loss: 0.02820293791592121
step: 90, loss: 0.001644812524318695
step: 100, loss: 0.051521092653274536
step: 110, loss: 0.026194516569375992
step: 120, loss: 0.009582456201314926
step: 130, loss: 0.03454527631402016
step: 140, loss: 0.06057712435722351
step: 150, loss: 0.053192898631095886
step: 160, loss: 0.012366858310997486
step: 170, loss: 0.10000433027744293
step: 180, loss: 0.025294167920947075
step: 190, loss: 0.02693956345319748
step: 200, loss: 0.02664700709283352
step: 210, loss: 0.02348996140062809
step: 220, loss: 0.05559389293193817
step: 230, loss: 0.04414483904838562
step: 240, loss: 0.07161898910999298
step: 250, loss: 0.03274622932076454
step: 260, loss: 0.06251473724842072
step: 270, loss: 0.0944964662194252
step: 280, loss: 0.04390183463692665
step: 290, loss: 0.08765985816717148
step: 300, loss: 0.032399605959653854
step: 310, loss: 0.06896470487117767
step: 320, loss: 0.0005054789362475276
step: 330, loss: 0.00637663621455431
step: 340, loss: 0.04123980924487114
step: 350, loss: 0.023859666660428047
step: 360, loss: 0.05925939232110977
step: 370, loss: 0.011654719710350037
step: 380, loss: 0.0005118518020026386
epoch 17: dev_f1=0.7263157894736842, f1=0.6880000000000001, best_f1=0.7373493975903614
step: 0, loss: 0.05176156759262085
step: 10, loss: 0.0005526324966922402
step: 20, loss: 0.0946521982550621
step: 30, loss: 0.01417145412415266
step: 40, loss: 0.0023929961025714874
step: 50, loss: 0.00044165662257000804
step: 60, loss: 0.03624102100729942
step: 70, loss: 0.00046633376041427255
step: 80, loss: 0.015752548351883888
step: 90, loss: 0.03865152969956398
step: 100, loss: 0.014617789536714554
step: 110, loss: 0.00570277962833643
step: 120, loss: 0.04901720955967903
step: 130, loss: 0.0748279020190239
step: 140, loss: 7.741425361018628e-05
step: 150, loss: 3.9623115299036726e-05
step: 160, loss: 4.916748366667889e-05
step: 170, loss: 0.0323881097137928
step: 180, loss: 0.011263932101428509
step: 190, loss: 0.0003331317566335201
step: 200, loss: 0.0488346628844738
step: 210, loss: 0.05222344398498535
step: 220, loss: 0.09373445063829422
step: 230, loss: 0.00024170421238522977
step: 240, loss: 0.04724983870983124
step: 250, loss: 0.1143244057893753
step: 260, loss: 0.025337062776088715
step: 270, loss: 0.03464217111468315
step: 280, loss: 0.03108144737780094
step: 290, loss: 0.1194174587726593
step: 300, loss: 0.08157732337713242
step: 310, loss: 0.014020254835486412
step: 320, loss: 0.03610226511955261
step: 330, loss: 0.013987391255795956
step: 340, loss: 0.06151214987039566
step: 350, loss: 0.07735642790794373
step: 360, loss: 0.03043365105986595
step: 370, loss: 0.02931281551718712
step: 380, loss: 0.03423885628581047
epoch 18: dev_f1=0.7046070460704608, f1=0.6978021978021979, best_f1=0.7373493975903614
step: 0, loss: 0.05885133519768715
step: 10, loss: 0.00045673802378587425
step: 20, loss: 0.031098516657948494
step: 30, loss: 0.0005247128428891301
step: 40, loss: 0.014156666584312916
step: 50, loss: 0.012463526800274849
step: 60, loss: 0.01598012074828148
step: 70, loss: 0.02391582913696766
step: 80, loss: 0.008578676730394363
step: 90, loss: 0.07665354758501053
step: 100, loss: 0.0025731599889695644
step: 110, loss: 0.05442490428686142
step: 120, loss: 0.033018339425325394
step: 130, loss: 0.011075704358518124
step: 140, loss: 0.04178549349308014
step: 150, loss: 0.07559963315725327
step: 160, loss: 0.01277022436261177
step: 170, loss: 0.0374559722840786
step: 180, loss: 0.00032698383438400924
step: 190, loss: 0.008237387053668499
step: 200, loss: 0.03503914549946785
step: 210, loss: 0.03967375308275223
step: 220, loss: 0.0440184660255909
step: 230, loss: 0.12345920503139496
step: 240, loss: 0.004204866010695696
step: 250, loss: 0.008602115325629711
step: 260, loss: 0.009087812155485153
step: 270, loss: 0.00013849568495061249
step: 280, loss: 0.012205943465232849
step: 290, loss: 0.04520715773105621
step: 300, loss: 0.00013842785847373307
step: 310, loss: 0.03395042568445206
step: 320, loss: 0.032141707837581635
step: 330, loss: 0.021679149940609932
step: 340, loss: 0.07481025904417038
step: 350, loss: 0.003906720317900181
step: 360, loss: 0.0017516540829092264
step: 370, loss: 0.03327585756778717
step: 380, loss: 0.03832533583045006
epoch 19: dev_f1=0.7112299465240641, f1=0.695890410958904, best_f1=0.7373493975903614
step: 0, loss: 0.03553232178092003
step: 10, loss: 0.02322838082909584
step: 20, loss: 0.060024410486221313
step: 30, loss: 0.0015447004698216915
step: 40, loss: 0.021695714443922043
step: 50, loss: 0.028475096449255943
step: 60, loss: 0.07141665369272232
step: 70, loss: 0.03799356520175934
step: 80, loss: 0.03238043561577797
step: 90, loss: 0.03099079057574272
step: 100, loss: 0.1242097020149231
step: 110, loss: 0.023980574682354927
step: 120, loss: 0.002818482229486108
step: 130, loss: 0.00016258787945844233
step: 140, loss: 0.018021538853645325
step: 150, loss: 0.036859456449747086
step: 160, loss: 0.001203028718009591
step: 170, loss: 0.02810341864824295
step: 180, loss: 0.043239425867795944
step: 190, loss: 0.004084314219653606
step: 200, loss: 0.03888751193881035
step: 210, loss: 0.032845593988895416
step: 220, loss: 0.0022039958275854588
step: 230, loss: 0.0006878492422401905
step: 240, loss: 0.05679494887590408
step: 250, loss: 0.0016642503906041384
step: 260, loss: 0.040750641375780106
step: 270, loss: 0.01895928382873535
step: 280, loss: 0.00017812702571973205
step: 290, loss: 0.0065338145941495895
step: 300, loss: 0.05438270792365074
step: 310, loss: 0.08567207306623459
step: 320, loss: 0.08738473802804947
step: 330, loss: 0.03046805039048195
step: 340, loss: 0.03782520815730095
step: 350, loss: 0.04168429598212242
step: 360, loss: 0.0001417200401192531
step: 370, loss: 0.06821812689304352
step: 380, loss: 0.04580811783671379
epoch 20: dev_f1=0.707774798927614, f1=0.6885245901639343, best_f1=0.7373493975903614
