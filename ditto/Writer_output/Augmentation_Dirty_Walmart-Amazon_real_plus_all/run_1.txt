cuda
Device: cuda
step: 0, loss: 0.7172132730484009
step: 10, loss: 0.3191480040550232
step: 20, loss: 0.16183459758758545
step: 30, loss: 0.4862811267375946
step: 40, loss: 0.2355167716741562
step: 50, loss: 0.3052181303501129
step: 60, loss: 0.5245182514190674
step: 70, loss: 0.2256411910057068
step: 80, loss: 0.33307209610939026
step: 90, loss: 0.1050734892487526
step: 100, loss: 0.33230578899383545
step: 110, loss: 0.15415561199188232
step: 120, loss: 0.243602454662323
step: 130, loss: 0.22380107641220093
step: 140, loss: 0.29001763463020325
step: 150, loss: 0.18579909205436707
step: 160, loss: 0.2509826719760895
step: 170, loss: 0.34140560030937195
step: 180, loss: 0.3083287477493286
step: 190, loss: 0.22776523232460022
step: 200, loss: 0.28944745659828186
step: 210, loss: 0.05581565946340561
step: 220, loss: 0.28098881244659424
step: 230, loss: 0.21299013495445251
step: 240, loss: 0.0610099732875824
step: 250, loss: 0.12187686562538147
step: 260, loss: 0.13818596303462982
step: 270, loss: 0.18062734603881836
step: 280, loss: 0.11421328783035278
step: 290, loss: 0.13661448657512665
step: 300, loss: 0.2667459547519684
step: 310, loss: 0.028738269582390785
step: 320, loss: 0.02882516384124756
step: 330, loss: 0.06430573016405106
step: 340, loss: 0.21175488829612732
step: 350, loss: 0.07461264729499817
step: 360, loss: 0.09181977808475494
step: 370, loss: 0.16592884063720703
step: 380, loss: 0.2523896396160126
epoch 1: dev_f1=0.5284974093264249, f1=0.5815217391304348, best_f1=0.5815217391304348
step: 0, loss: 0.19754256308078766
step: 10, loss: 0.18107296526432037
step: 20, loss: 0.23120024800300598
step: 30, loss: 0.1437211036682129
step: 40, loss: 0.27212029695510864
step: 50, loss: 0.06615172326564789
step: 60, loss: 0.08204779773950577
step: 70, loss: 0.1455652117729187
step: 80, loss: 0.029424767941236496
step: 90, loss: 0.030142785981297493
step: 100, loss: 0.10358351469039917
step: 110, loss: 0.0703398808836937
step: 120, loss: 0.07686255872249603
step: 130, loss: 0.06043439731001854
step: 140, loss: 0.13695389032363892
step: 150, loss: 0.32980889081954956
step: 160, loss: 0.0421437993645668
step: 170, loss: 0.21609748899936676
step: 180, loss: 0.08313126116991043
step: 190, loss: 0.032492298632860184
step: 200, loss: 0.1254843771457672
step: 210, loss: 0.046032775193452835
step: 220, loss: 0.040088675916194916
step: 230, loss: 0.10884752869606018
step: 240, loss: 0.0383148193359375
step: 250, loss: 0.11684271693229675
step: 260, loss: 0.21532148122787476
step: 270, loss: 0.05027984455227852
step: 280, loss: 0.15596216917037964
step: 290, loss: 0.23326730728149414
step: 300, loss: 0.41295403242111206
step: 310, loss: 0.02763245813548565
step: 320, loss: 0.23923687636852264
step: 330, loss: 0.08755965530872345
step: 340, loss: 0.15802499651908875
step: 350, loss: 0.27112340927124023
step: 360, loss: 0.0400468185544014
step: 370, loss: 0.1281694769859314
step: 380, loss: 0.14680342376232147
epoch 2: dev_f1=0.7101449275362319, f1=0.7000000000000001, best_f1=0.7000000000000001
step: 0, loss: 0.0852271020412445
step: 10, loss: 0.16448602080345154
step: 20, loss: 0.1058260127902031
step: 30, loss: 0.11161203682422638
step: 40, loss: 0.08348453789949417
step: 50, loss: 0.03781982138752937
step: 60, loss: 0.01680563949048519
step: 70, loss: 0.1277894228696823
step: 80, loss: 0.15761470794677734
step: 90, loss: 0.08653654158115387
step: 100, loss: 0.07766646146774292
step: 110, loss: 0.2906178832054138
step: 120, loss: 0.09449684619903564
step: 130, loss: 0.08166196942329407
step: 140, loss: 0.14524787664413452
step: 150, loss: 0.14522218704223633
step: 160, loss: 0.09361475706100464
step: 170, loss: 0.13144201040267944
step: 180, loss: 0.1002187505364418
step: 190, loss: 0.05727607011795044
step: 200, loss: 0.07411248236894608
step: 210, loss: 0.06109526380896568
step: 220, loss: 0.13902582228183746
step: 230, loss: 0.1284841150045395
step: 240, loss: 0.032155219465494156
step: 250, loss: 0.042332082986831665
step: 260, loss: 0.17457816004753113
step: 270, loss: 0.06859053671360016
step: 280, loss: 0.07555736601352692
step: 290, loss: 0.22625449299812317
step: 300, loss: 0.0795622169971466
step: 310, loss: 0.15740126371383667
step: 320, loss: 0.09764822572469711
step: 330, loss: 0.11479674279689789
step: 340, loss: 0.09421154111623764
step: 350, loss: 0.0964445099234581
step: 360, loss: 0.04766864702105522
step: 370, loss: 0.024928942322731018
step: 380, loss: 0.08680534362792969
epoch 3: dev_f1=0.7098445595854923, f1=0.7154046997389033, best_f1=0.7000000000000001
step: 0, loss: 0.01985662430524826
step: 10, loss: 0.09939348697662354
step: 20, loss: 0.11230028420686722
step: 30, loss: 0.1610335260629654
step: 40, loss: 0.08938434720039368
step: 50, loss: 0.07228170335292816
step: 60, loss: 0.03551448881626129
step: 70, loss: 0.27931779623031616
step: 80, loss: 0.032595254480838776
step: 90, loss: 0.029167264699935913
step: 100, loss: 0.13960231840610504
step: 110, loss: 0.24475401639938354
step: 120, loss: 0.14192521572113037
step: 130, loss: 0.14269140362739563
step: 140, loss: 0.08616107702255249
step: 150, loss: 0.02785547822713852
step: 160, loss: 0.09652186930179596
step: 170, loss: 0.09168396890163422
step: 180, loss: 0.07500394433736801
step: 190, loss: 0.11552675813436508
step: 200, loss: 0.04931863397359848
step: 210, loss: 0.06371855735778809
step: 220, loss: 0.08715840429067612
step: 230, loss: 0.05209377780556679
step: 240, loss: 0.07566813379526138
step: 250, loss: 0.12886369228363037
step: 260, loss: 0.0448676273226738
step: 270, loss: 0.0017129641491919756
step: 280, loss: 0.22677449882030487
step: 290, loss: 0.13226795196533203
step: 300, loss: 0.14630126953125
step: 310, loss: 0.12108103185892105
step: 320, loss: 0.10337866842746735
step: 330, loss: 0.1982412487268448
step: 340, loss: 0.11517554521560669
step: 350, loss: 0.05523906648159027
step: 360, loss: 0.12086998671293259
step: 370, loss: 0.037000346928834915
step: 380, loss: 0.06131040304899216
epoch 4: dev_f1=0.7250608272506084, f1=0.6940874035989718, best_f1=0.6940874035989718
step: 0, loss: 0.11560961604118347
step: 10, loss: 0.06748740375041962
step: 20, loss: 0.02770114503800869
step: 30, loss: 0.10587748140096664
step: 40, loss: 0.07933379709720612
step: 50, loss: 0.030856342986226082
step: 60, loss: 0.058113787323236465
step: 70, loss: 0.08713535219430923
step: 80, loss: 0.06480734795331955
step: 90, loss: 0.1451033055782318
step: 100, loss: 0.021166013553738594
step: 110, loss: 0.12248222529888153
step: 120, loss: 0.09922122210264206
step: 130, loss: 0.13854296505451202
step: 140, loss: 0.08897712081670761
step: 150, loss: 0.06487853080034256
step: 160, loss: 0.06363379955291748
step: 170, loss: 0.25040555000305176
step: 180, loss: 0.04664245620369911
step: 190, loss: 0.2507483661174774
step: 200, loss: 0.16265439987182617
step: 210, loss: 0.08980070799589157
step: 220, loss: 0.10466302931308746
step: 230, loss: 0.09735418856143951
step: 240, loss: 0.14537988603115082
step: 250, loss: 0.12354464083909988
step: 260, loss: 0.05927679315209389
step: 270, loss: 0.11565295606851578
step: 280, loss: 0.1640595942735672
step: 290, loss: 0.07995817065238953
step: 300, loss: 0.005507863592356443
step: 310, loss: 0.07029181718826294
step: 320, loss: 0.14681100845336914
step: 330, loss: 0.007177657913416624
step: 340, loss: 0.10818669945001602
step: 350, loss: 0.05580658093094826
step: 360, loss: 0.1060955598950386
step: 370, loss: 0.24209392070770264
step: 380, loss: 0.07634520530700684
epoch 5: dev_f1=0.75, f1=0.7519181585677749, best_f1=0.7519181585677749
step: 0, loss: 0.11462275683879852
step: 10, loss: 0.09480559080839157
step: 20, loss: 0.08116935938596725
step: 30, loss: 0.016162175685167313
step: 40, loss: 0.04480456933379173
step: 50, loss: 0.04255014285445213
step: 60, loss: 0.0433950237929821
step: 70, loss: 0.02942686155438423
step: 80, loss: 0.1950337439775467
step: 90, loss: 0.013187509030103683
step: 100, loss: 0.03119596652686596
step: 110, loss: 0.05839988589286804
step: 120, loss: 0.1277913898229599
step: 130, loss: 0.04189030081033707
step: 140, loss: 0.09511613845825195
step: 150, loss: 0.12899260222911835
step: 160, loss: 0.07996392250061035
step: 170, loss: 0.14066936075687408
step: 180, loss: 0.08167408406734467
step: 190, loss: 0.1401233971118927
step: 200, loss: 0.09605229645967484
step: 210, loss: 0.02839295007288456
step: 220, loss: 0.060691505670547485
step: 230, loss: 0.06276534497737885
step: 240, loss: 0.03300046548247337
step: 250, loss: 0.009710959158837795
step: 260, loss: 0.02957168035209179
step: 270, loss: 0.029790157452225685
step: 280, loss: 0.10505896806716919
step: 290, loss: 0.12838038802146912
step: 300, loss: 0.10190839320421219
step: 310, loss: 0.06365779787302017
step: 320, loss: 0.0870608538389206
step: 330, loss: 0.06425701826810837
step: 340, loss: 0.06835301220417023
step: 350, loss: 0.05439644679427147
step: 360, loss: 0.13042499125003815
step: 370, loss: 0.0732194259762764
step: 380, loss: 0.12195637077093124
epoch 6: dev_f1=0.7423167848699763, f1=0.703883495145631, best_f1=0.7519181585677749
step: 0, loss: 0.08156007528305054
step: 10, loss: 0.023780398070812225
step: 20, loss: 0.030901750549674034
step: 30, loss: 0.10514411330223083
step: 40, loss: 0.03596416488289833
step: 50, loss: 0.03870708867907524
step: 60, loss: 0.2985459268093109
step: 70, loss: 0.0928112119436264
step: 80, loss: 0.1297682821750641
step: 90, loss: 0.045332349836826324
step: 100, loss: 0.0716148391366005
step: 110, loss: 0.0485013946890831
step: 120, loss: 0.06880836933851242
step: 130, loss: 0.19954849779605865
step: 140, loss: 0.10911896079778671
step: 150, loss: 0.07076747715473175
step: 160, loss: 0.08718845248222351
step: 170, loss: 0.09931829571723938
step: 180, loss: 0.04615793377161026
step: 190, loss: 0.11278542876243591
step: 200, loss: 0.06453927606344223
step: 210, loss: 0.022065002471208572
step: 220, loss: 0.0780123919248581
step: 230, loss: 0.07306528091430664
step: 240, loss: 0.04236285388469696
step: 250, loss: 0.10723284631967545
step: 260, loss: 0.09200126677751541
step: 270, loss: 0.11408475041389465
step: 280, loss: 0.18337079882621765
step: 290, loss: 0.0220034196972847
step: 300, loss: 0.08040769398212433
step: 310, loss: 0.1777258962392807
step: 320, loss: 0.05731657147407532
step: 330, loss: 0.054111674427986145
step: 340, loss: 0.0391026996076107
step: 350, loss: 0.08340964466333389
step: 360, loss: 0.0737578272819519
step: 370, loss: 0.07493463158607483
step: 380, loss: 0.06437559425830841
epoch 7: dev_f1=0.7258485639686684, f1=0.7112299465240641, best_f1=0.7519181585677749
step: 0, loss: 0.07763957977294922
step: 10, loss: 0.05322371795773506
step: 20, loss: 0.04471755772829056
step: 30, loss: 0.011469164863228798
step: 40, loss: 0.07856325805187225
step: 50, loss: 0.04823823645710945
step: 60, loss: 0.024919483810663223
step: 70, loss: 0.07077346742153168
step: 80, loss: 0.05747086554765701
step: 90, loss: 0.0010457627940922976
step: 100, loss: 0.04073653742671013
step: 110, loss: 0.06383233517408371
step: 120, loss: 0.09646470099687576
step: 130, loss: 0.020286748185753822
step: 140, loss: 0.0923016145825386
step: 150, loss: 0.03209218010306358
step: 160, loss: 0.09117396920919418
step: 170, loss: 0.09456612169742584
step: 180, loss: 0.01911100745201111
step: 190, loss: 0.034287385642528534
step: 200, loss: 0.12048345059156418
step: 210, loss: 0.20707975327968597
step: 220, loss: 0.09361584484577179
step: 230, loss: 0.03458176180720329
step: 240, loss: 0.06604986637830734
step: 250, loss: 0.06389259546995163
step: 260, loss: 0.0463353767991066
step: 270, loss: 0.03407894819974899
step: 280, loss: 0.1724727600812912
step: 290, loss: 0.12308449298143387
step: 300, loss: 0.04402526840567589
step: 310, loss: 0.10439770668745041
step: 320, loss: 0.10766346007585526
step: 330, loss: 0.060777172446250916
step: 340, loss: 0.001028541475534439
step: 350, loss: 0.10723298043012619
step: 360, loss: 0.07065661251544952
step: 370, loss: 0.02528572827577591
step: 380, loss: 0.07959935069084167
epoch 8: dev_f1=0.7024390243902439, f1=0.6762589928057554, best_f1=0.7519181585677749
step: 0, loss: 0.038884859532117844
step: 10, loss: 0.09845288842916489
step: 20, loss: 0.028494663536548615
step: 30, loss: 0.027281899005174637
step: 40, loss: 0.03624674677848816
step: 50, loss: 0.017717227339744568
step: 60, loss: 0.007557351607829332
step: 70, loss: 0.04452824220061302
step: 80, loss: 0.014907591976225376
step: 90, loss: 0.02888687700033188
step: 100, loss: 0.059384655207395554
step: 110, loss: 0.04186138138175011
step: 120, loss: 0.11961645632982254
step: 130, loss: 0.03714488074183464
step: 140, loss: 0.08498559892177582
step: 150, loss: 0.06164127588272095
step: 160, loss: 0.1359991431236267
step: 170, loss: 0.08514142781496048
step: 180, loss: 0.04202139005064964
step: 190, loss: 0.03829669952392578
step: 200, loss: 0.06806357949972153
step: 210, loss: 0.019076060503721237
step: 220, loss: 0.11821470409631729
step: 230, loss: 0.08410730212926865
step: 240, loss: 0.0005766992690041661
step: 250, loss: 0.028509313240647316
step: 260, loss: 0.11829157173633575
step: 270, loss: 0.15161950886249542
step: 280, loss: 0.034571629017591476
step: 290, loss: 0.07419655472040176
step: 300, loss: 0.06529080867767334
step: 310, loss: 0.16148844361305237
step: 320, loss: 0.02243107371032238
step: 330, loss: 0.02801365591585636
step: 340, loss: 0.10968553274869919
step: 350, loss: 0.0750429704785347
step: 360, loss: 0.05733446776866913
step: 370, loss: 0.04292909428477287
step: 380, loss: 0.025441177189350128
epoch 9: dev_f1=0.7052631578947368, f1=0.679245283018868, best_f1=0.7519181585677749
step: 0, loss: 0.07724806666374207
step: 10, loss: 0.08829578757286072
step: 20, loss: 0.08082091808319092
step: 30, loss: 0.006356259807944298
step: 40, loss: 0.14273351430892944
step: 50, loss: 0.11740502715110779
step: 60, loss: 0.08449030667543411
step: 70, loss: 0.1365787386894226
step: 80, loss: 0.08674328774213791
step: 90, loss: 0.1650276631116867
step: 100, loss: 0.00917544774711132
step: 110, loss: 0.04298801347613335
step: 120, loss: 0.10080981999635696
step: 130, loss: 0.012954662553966045
step: 140, loss: 0.08754724264144897
step: 150, loss: 0.08700808137655258
step: 160, loss: 0.07791030406951904
step: 170, loss: 0.06721126288175583
step: 180, loss: 0.04677566513419151
step: 190, loss: 0.10523636639118195
step: 200, loss: 0.03847002238035202
step: 210, loss: 0.11176834255456924
step: 220, loss: 0.040584906935691833
step: 230, loss: 0.05353311449289322
step: 240, loss: 0.05835771560668945
step: 250, loss: 0.08528856188058853
step: 260, loss: 0.009068015031516552
step: 270, loss: 0.17179375886917114
step: 280, loss: 0.09885579347610474
step: 290, loss: 0.04585897549986839
step: 300, loss: 0.09334360063076019
step: 310, loss: 0.12435834109783173
step: 320, loss: 0.0847562849521637
step: 330, loss: 0.03248924762010574
step: 340, loss: 0.06683748960494995
step: 350, loss: 0.0873357281088829
step: 360, loss: 0.011830068193376064
step: 370, loss: 0.08063935488462448
step: 380, loss: 0.08021745830774307
epoch 10: dev_f1=0.7102272727272727, f1=0.6855524079320112, best_f1=0.7519181585677749
step: 0, loss: 0.04151696711778641
step: 10, loss: 0.12198615074157715
step: 20, loss: 0.10368862748146057
step: 30, loss: 0.0003095635329373181
step: 40, loss: 0.029352011159062386
step: 50, loss: 0.10486934334039688
step: 60, loss: 0.019974540919065475
step: 70, loss: 0.02830430120229721
step: 80, loss: 0.018616516143083572
step: 90, loss: 0.07445164769887924
step: 100, loss: 0.09317994117736816
step: 110, loss: 0.04015696793794632
step: 120, loss: 0.06119263544678688
step: 130, loss: 0.10736129432916641
step: 140, loss: 0.0902763307094574
step: 150, loss: 0.024366457015275955
step: 160, loss: 0.03427747264504433
step: 170, loss: 0.039297591894865036
step: 180, loss: 0.00082500179996714
step: 190, loss: 0.07783607393503189
step: 200, loss: 0.01304860133677721
step: 210, loss: 0.11057156324386597
step: 220, loss: 0.04326118156313896
step: 230, loss: 0.05421361327171326
step: 240, loss: 0.1066785603761673
step: 250, loss: 0.00027561080059967935
step: 260, loss: 0.09072057902812958
step: 270, loss: 0.05093909427523613
step: 280, loss: 0.029998548328876495
step: 290, loss: 0.07630381733179092
step: 300, loss: 0.11905419081449509
step: 310, loss: 0.12596258521080017
step: 320, loss: 0.1368379294872284
step: 330, loss: 0.05227122828364372
step: 340, loss: 0.09845539182424545
step: 350, loss: 0.03303023427724838
step: 360, loss: 0.034016143530607224
step: 370, loss: 0.10226825624704361
step: 380, loss: 0.09659451246261597
epoch 11: dev_f1=0.7277486910994764, f1=0.7272727272727273, best_f1=0.7519181585677749
step: 0, loss: 0.03836434707045555
step: 10, loss: 0.02243986167013645
step: 20, loss: 0.017537618055939674
step: 30, loss: 0.052839040756225586
step: 40, loss: 0.03658389672636986
step: 50, loss: 0.1040787324309349
step: 60, loss: 0.0718754306435585
step: 70, loss: 0.011309218592941761
step: 80, loss: 0.005773594137281179
step: 90, loss: 0.031136205419898033
step: 100, loss: 0.12789449095726013
step: 110, loss: 0.05006684362888336
step: 120, loss: 0.028365887701511383
step: 130, loss: 0.01619170792400837
step: 140, loss: 0.04038557410240173
step: 150, loss: 0.1374858021736145
step: 160, loss: 0.07592444121837616
step: 170, loss: 0.04830015450716019
step: 180, loss: 0.047864947468042374
step: 190, loss: 0.028108229860663414
step: 200, loss: 0.0750773698091507
step: 210, loss: 0.026507169008255005
step: 220, loss: 0.10377240180969238
step: 230, loss: 0.04356442764401436
step: 240, loss: 0.016572024673223495
step: 250, loss: 0.026060443371534348
step: 260, loss: 0.037878140807151794
step: 270, loss: 0.04808078706264496
step: 280, loss: 0.045646507292985916
step: 290, loss: 0.0428876057267189
step: 300, loss: 0.15248921513557434
step: 310, loss: 0.05388232320547104
step: 320, loss: 0.026488006114959717
step: 330, loss: 0.05701387673616409
step: 340, loss: 0.03728330880403519
step: 350, loss: 0.13816821575164795
step: 360, loss: 0.10994737595319748
step: 370, loss: 0.03618192672729492
step: 380, loss: 0.04936430975794792
epoch 12: dev_f1=0.7195767195767196, f1=0.6984126984126985, best_f1=0.7519181585677749
step: 0, loss: 0.03504856675863266
step: 10, loss: 0.037369947880506516
step: 20, loss: 0.056011684238910675
step: 30, loss: 0.05476895347237587
step: 40, loss: 0.08566392213106155
step: 50, loss: 0.007983502000570297
step: 60, loss: 0.03147756680846214
step: 70, loss: 0.0509432815015316
step: 80, loss: 0.015099565498530865
step: 90, loss: 0.0226703193038702
step: 100, loss: 0.0675833523273468
step: 110, loss: 0.03520815819501877
step: 120, loss: 0.04884845018386841
step: 130, loss: 0.09595648944377899
step: 140, loss: 0.02099938690662384
step: 150, loss: 0.07529404759407043
step: 160, loss: 0.00015208727563731372
step: 170, loss: 0.01445857435464859
step: 180, loss: 0.02293122373521328
step: 190, loss: 0.05852651968598366
step: 200, loss: 0.0020055912900716066
step: 210, loss: 0.0839226022362709
step: 220, loss: 0.1039673238992691
step: 230, loss: 0.05793401598930359
step: 240, loss: 0.10458994656801224
step: 250, loss: 0.06424770504236221
step: 260, loss: 0.0748063325881958
step: 270, loss: 0.05875031277537346
step: 280, loss: 0.09029310941696167
step: 290, loss: 0.052980389446020126
step: 300, loss: 6.880017463117838e-05
step: 310, loss: 0.06271512061357498
step: 320, loss: 0.09819301217794418
step: 330, loss: 0.02256874367594719
step: 340, loss: 0.02826249785721302
step: 350, loss: 0.10670950263738632
step: 360, loss: 0.03289453312754631
step: 370, loss: 0.10282542556524277
step: 380, loss: 0.12117385864257812
epoch 13: dev_f1=0.7253333333333334, f1=0.6774193548387096, best_f1=0.7519181585677749
step: 0, loss: 0.06368985027074814
step: 10, loss: 0.03804019093513489
step: 20, loss: 0.046563584357500076
step: 30, loss: 0.08485958725214005
step: 40, loss: 0.010796959511935711
step: 50, loss: 0.004952870309352875
step: 60, loss: 0.002156173810362816
step: 70, loss: 0.010265215300023556
step: 80, loss: 0.13348689675331116
step: 90, loss: 0.08317777514457703
step: 100, loss: 0.049558427184820175
step: 110, loss: 0.08746899664402008
step: 120, loss: 0.06165299937129021
step: 130, loss: 0.0003657527850009501
step: 140, loss: 0.21304352581501007
step: 150, loss: 0.01481068879365921
step: 160, loss: 0.07931641489267349
step: 170, loss: 0.021358245983719826
step: 180, loss: 0.08513323217630386
step: 190, loss: 0.0002986913896165788
step: 200, loss: 0.16585490107536316
step: 210, loss: 0.05000276118516922
step: 220, loss: 0.09965412318706512
step: 230, loss: 0.09939595311880112
step: 240, loss: 0.047195933759212494
step: 250, loss: 0.02582664042711258
step: 260, loss: 0.08434406667947769
step: 270, loss: 0.07318545132875443
step: 280, loss: 0.0911937803030014
step: 290, loss: 0.039542026817798615
step: 300, loss: 0.0684257298707962
step: 310, loss: 0.046251438558101654
step: 320, loss: 0.038934383541345596
step: 330, loss: 0.01054440252482891
step: 340, loss: 0.039149124175310135
step: 350, loss: 0.04865776374936104
step: 360, loss: 0.012130394577980042
step: 370, loss: 0.11740706115961075
step: 380, loss: 0.07195565104484558
epoch 14: dev_f1=0.7346938775510203, f1=0.7277353689567431, best_f1=0.7519181585677749
step: 0, loss: 0.01386383268982172
step: 10, loss: 0.08917678147554398
step: 20, loss: 0.01563645713031292
step: 30, loss: 0.016127698123455048
step: 40, loss: 0.07600857317447662
step: 50, loss: 0.03110545128583908
step: 60, loss: 3.221145743736997e-05
step: 70, loss: 0.047191787511110306
step: 80, loss: 0.05867088586091995
step: 90, loss: 0.0770736038684845
step: 100, loss: 0.07285650819540024
step: 110, loss: 0.030087601393461227
step: 120, loss: 0.03354020044207573
step: 130, loss: 0.016719674691557884
step: 140, loss: 0.018339302390813828
step: 150, loss: 0.03831047937273979
step: 160, loss: 0.04775068908929825
step: 170, loss: 0.03647945076227188
step: 180, loss: 0.046576764434576035
step: 190, loss: 0.00017465367272961885
step: 200, loss: 0.04110483080148697
step: 210, loss: 0.027267562225461006
step: 220, loss: 0.0373573824763298
step: 230, loss: 0.014721045270562172
step: 240, loss: 0.030157122761011124
step: 250, loss: 0.07053399831056595
step: 260, loss: 0.02361132763326168
step: 270, loss: 0.054452408105134964
step: 280, loss: 0.0868917927145958
step: 290, loss: 0.11820998787879944
step: 300, loss: 0.06151089817285538
step: 310, loss: 0.05947156623005867
step: 320, loss: 0.03599771112203598
step: 330, loss: 0.05436141788959503
step: 340, loss: 0.08721441775560379
step: 350, loss: 0.032300837337970734
step: 360, loss: 0.01910679042339325
step: 370, loss: 0.03648059070110321
step: 380, loss: 0.05741805583238602
epoch 15: dev_f1=0.7226890756302521, f1=0.6411764705882353, best_f1=0.7519181585677749
step: 0, loss: 0.030133256688714027
step: 10, loss: 0.054252345114946365
step: 20, loss: 0.059994347393512726
step: 30, loss: 0.05207952484488487
step: 40, loss: 0.06260067969560623
step: 50, loss: 0.08957310020923615
step: 60, loss: 0.10457803308963776
step: 70, loss: 0.08082275837659836
step: 80, loss: 0.053574711084365845
step: 90, loss: 0.0519600510597229
step: 100, loss: 0.02715551108121872
step: 110, loss: 0.055190954357385635
step: 120, loss: 0.03974773734807968
step: 130, loss: 0.04553190618753433
step: 140, loss: 0.02741144597530365
step: 150, loss: 0.027694469317793846
step: 160, loss: 0.03479747846722603
step: 170, loss: 0.03518671542406082
step: 180, loss: 0.02360612526535988
step: 190, loss: 0.038219451904296875
step: 200, loss: 0.04216489940881729
step: 210, loss: 0.05700533092021942
step: 220, loss: 0.00015258099301718175
step: 230, loss: 0.02893243171274662
step: 240, loss: 0.04647419601678848
step: 250, loss: 0.01902788132429123
step: 260, loss: 0.021162455901503563
step: 270, loss: 0.005605395883321762
step: 280, loss: 0.07278763502836227
step: 290, loss: 0.042251575738191605
step: 300, loss: 0.1099676787853241
step: 310, loss: 0.08324918150901794
step: 320, loss: 0.07440335303544998
step: 330, loss: 0.07118421792984009
step: 340, loss: 0.09201639145612717
step: 350, loss: 0.004277145490050316
step: 360, loss: 0.000717246497515589
step: 370, loss: 0.05912024900317192
step: 380, loss: 0.007523438427597284
epoch 16: dev_f1=0.7313019390581716, f1=0.6724137931034484, best_f1=0.7519181585677749
step: 0, loss: 0.0006425065803341568
step: 10, loss: 0.001123506110161543
step: 20, loss: 0.00020176474936306477
step: 30, loss: 0.034029629081487656
step: 40, loss: 0.05321871489286423
step: 50, loss: 0.010862717404961586
step: 60, loss: 0.014079523272812366
step: 70, loss: 0.07491142302751541
step: 80, loss: 0.052442193031311035
step: 90, loss: 0.08249141275882721
step: 100, loss: 0.02312990091741085
step: 110, loss: 0.03684765100479126
step: 120, loss: 0.017553983256220818
step: 130, loss: 0.0023628477938473225
step: 140, loss: 0.051927387714385986
step: 150, loss: 0.030023859813809395
step: 160, loss: 0.017912261188030243
step: 170, loss: 0.0010438631288707256
step: 180, loss: 0.04223271459341049
step: 190, loss: 0.021860184147953987
step: 200, loss: 0.06518881767988205
step: 210, loss: 0.0012312993640080094
step: 220, loss: 0.1253262460231781
step: 230, loss: 0.04972904920578003
step: 240, loss: 0.024222150444984436
step: 250, loss: 0.16875822842121124
step: 260, loss: 0.1761866956949234
step: 270, loss: 0.11103376001119614
step: 280, loss: 0.06206341087818146
step: 290, loss: 0.1706942766904831
step: 300, loss: 0.04595678299665451
step: 310, loss: 0.0586971677839756
step: 320, loss: 0.0260635893791914
step: 330, loss: 0.08505607396364212
step: 340, loss: 0.05025250092148781
step: 350, loss: 0.013853205367922783
step: 360, loss: 0.11066831648349762
step: 370, loss: 0.04460546746850014
step: 380, loss: 0.05384209752082825
epoch 17: dev_f1=0.7236180904522613, f1=0.6954314720812182, best_f1=0.7519181585677749
step: 0, loss: 0.06611983478069305
step: 10, loss: 0.014080589637160301
step: 20, loss: 0.02558421529829502
step: 30, loss: 0.012286904267966747
step: 40, loss: 0.043881844729185104
step: 50, loss: 0.08771562576293945
step: 60, loss: 0.029736632481217384
step: 70, loss: 0.03862592205405235
step: 80, loss: 0.10682154446840286
step: 90, loss: 0.1020219624042511
step: 100, loss: 0.02844318188726902
step: 110, loss: 0.11161039024591446
step: 120, loss: 0.13208046555519104
step: 130, loss: 0.025523196905851364
step: 140, loss: 0.00010910737910307944
step: 150, loss: 0.017921769991517067
step: 160, loss: 0.01841333881020546
step: 170, loss: 0.042050041258335114
step: 180, loss: 0.013566064648330212
step: 190, loss: 0.019827507436275482
step: 200, loss: 0.06715916842222214
step: 210, loss: 0.050495631992816925
step: 220, loss: 0.0187935009598732
step: 230, loss: 0.04513949900865555
step: 240, loss: 0.017323607578873634
step: 250, loss: 0.038960397243499756
step: 260, loss: 0.07176864147186279
step: 270, loss: 0.018585840240120888
step: 280, loss: 0.026278715580701828
step: 290, loss: 0.06538745015859604
step: 300, loss: 4.1161074477713555e-05
step: 310, loss: 0.032896362245082855
step: 320, loss: 0.0292581245303154
step: 330, loss: 0.002391138579696417
step: 340, loss: 0.00019782062736339867
step: 350, loss: 0.0001019194969558157
step: 360, loss: 0.057570379227399826
step: 370, loss: 0.022773083299398422
step: 380, loss: 0.015871254727244377
epoch 18: dev_f1=0.7311827956989247, f1=0.7, best_f1=0.7519181585677749
step: 0, loss: 0.022394049912691116
step: 10, loss: 0.03919441998004913
step: 20, loss: 0.01624700240790844
step: 30, loss: 0.012548640370368958
step: 40, loss: 0.02987096831202507
step: 50, loss: 0.01271862629801035
step: 60, loss: 0.01866675727069378
step: 70, loss: 0.026381712406873703
step: 80, loss: 0.0439160019159317
step: 90, loss: 0.03462136164307594
step: 100, loss: 0.030469469726085663
step: 110, loss: 0.05865984782576561
step: 120, loss: 0.036657825112342834
step: 130, loss: 0.027263585478067398
step: 140, loss: 0.0012775770155712962
step: 150, loss: 0.07494238018989563
step: 160, loss: 0.09265590459108353
step: 170, loss: 0.026210932061076164
step: 180, loss: 0.08022390305995941
step: 190, loss: 0.006377981975674629
step: 200, loss: 0.060916345566511154
step: 210, loss: 0.08420610427856445
step: 220, loss: 0.05709482729434967
step: 230, loss: 0.04191116988658905
step: 240, loss: 0.004109748173505068
step: 250, loss: 0.026401247829198837
step: 260, loss: 0.11284084618091583
step: 270, loss: 0.02523585967719555
step: 280, loss: 0.05373440310359001
step: 290, loss: 0.03654628247022629
step: 300, loss: 0.003137886058539152
step: 310, loss: 0.03736411780118942
step: 320, loss: 0.029542522504925728
step: 330, loss: 0.03925582766532898
step: 340, loss: 0.051139410585165024
step: 350, loss: 0.01195965614169836
step: 360, loss: 0.020075496286153793
step: 370, loss: 0.03732694312930107
step: 380, loss: 0.012338776141405106
epoch 19: dev_f1=0.7226890756302521, f1=0.6512968299711815, best_f1=0.7519181585677749
step: 0, loss: 0.06995740532875061
step: 10, loss: 0.021869247779250145
step: 20, loss: 0.05185914412140846
step: 30, loss: 0.06980142742395401
step: 40, loss: 0.001991148805245757
step: 50, loss: 0.06145375594496727
step: 60, loss: 0.04335656017065048
step: 70, loss: 0.0006833029328845441
step: 80, loss: 0.007631886284798384
step: 90, loss: 0.07348596304655075
step: 100, loss: 2.841114292095881e-05
step: 110, loss: 0.030177023261785507
step: 120, loss: 0.0003645863907877356
step: 130, loss: 0.090709388256073
step: 140, loss: 0.010780606418848038
step: 150, loss: 0.0009219440398737788
step: 160, loss: 0.02304987981915474
step: 170, loss: 0.006142401602119207
step: 180, loss: 0.01274009421467781
step: 190, loss: 0.028849296271800995
step: 200, loss: 0.0007072789594531059
step: 210, loss: 0.0327194444835186
step: 220, loss: 0.0011404423275962472
step: 230, loss: 0.024409888312220573
step: 240, loss: 0.007769057992845774
step: 250, loss: 5.4171006922842935e-05
step: 260, loss: 0.004905455745756626
step: 270, loss: 0.07356821745634079
step: 280, loss: 0.00044577685184776783
step: 290, loss: 0.018866300582885742
step: 300, loss: 0.08548669517040253
step: 310, loss: 0.029210224747657776
step: 320, loss: 0.020353535190224648
step: 330, loss: 0.06477049738168716
step: 340, loss: 0.049613602459430695
step: 350, loss: 0.048784684389829636
step: 360, loss: 0.005206850823014975
step: 370, loss: 0.04196719452738762
step: 380, loss: 0.0003197084297426045
epoch 20: dev_f1=0.7247956403269755, f1=0.6814404432132963, best_f1=0.7519181585677749
