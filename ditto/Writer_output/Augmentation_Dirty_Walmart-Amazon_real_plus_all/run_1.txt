cuda
Device: cuda
step: 0, loss: 0.856529176235199
step: 10, loss: 0.3105669915676117
step: 20, loss: 0.2582054138183594
step: 30, loss: 0.3488312363624573
step: 40, loss: 0.4406296908855438
step: 50, loss: 0.3781110346317291
step: 60, loss: 0.14998462796211243
step: 70, loss: 0.2325323224067688
step: 80, loss: 0.2092532515525818
step: 90, loss: 0.5197848081588745
step: 100, loss: 0.29951971769332886
step: 110, loss: 0.36725422739982605
step: 120, loss: 0.6270790696144104
step: 130, loss: 0.38420411944389343
step: 140, loss: 0.3642084002494812
step: 150, loss: 0.34753963351249695
step: 160, loss: 0.5898621678352356
step: 170, loss: 0.23917599022388458
step: 180, loss: 0.16065116226673126
step: 190, loss: 0.20470093190670013
step: 200, loss: 0.11708386242389679
step: 210, loss: 0.1881323605775833
step: 220, loss: 0.39774441719055176
step: 230, loss: 0.13505135476589203
step: 240, loss: 0.18378590047359467
step: 250, loss: 0.27231118083000183
step: 260, loss: 0.2577565312385559
step: 270, loss: 0.0120643749833107
step: 280, loss: 0.05162327364087105
step: 290, loss: 0.1503695547580719
step: 300, loss: 0.029250292107462883
step: 310, loss: 0.12137118726968765
step: 320, loss: 0.10100772976875305
step: 330, loss: 0.39578673243522644
step: 340, loss: 0.03648575767874718
step: 350, loss: 0.09408756345510483
step: 360, loss: 0.120430588722229
step: 370, loss: 0.07916775345802307
step: 380, loss: 0.02182614989578724
epoch 1: dev_f1=0.616822429906542, f1=0.6361556064073227, best_f1=0.6361556064073227
step: 0, loss: 0.05269096791744232
step: 10, loss: 0.03470572829246521
step: 20, loss: 0.11066608875989914
step: 30, loss: 0.00884345080703497
step: 40, loss: 0.09780444204807281
step: 50, loss: 0.23354139924049377
step: 60, loss: 0.06572635471820831
step: 70, loss: 0.19217707216739655
step: 80, loss: 0.260936439037323
step: 90, loss: 0.06959512084722519
step: 100, loss: 0.08631456643342972
step: 110, loss: 0.1996249407529831
step: 120, loss: 0.1643567532300949
step: 130, loss: 0.3106064200401306
step: 140, loss: 0.23982928693294525
step: 150, loss: 0.18887174129486084
step: 160, loss: 0.05111706256866455
step: 170, loss: 0.07466401904821396
step: 180, loss: 0.16592761874198914
step: 190, loss: 0.33957284688949585
step: 200, loss: 0.22818079590797424
step: 210, loss: 0.12460324168205261
step: 220, loss: 0.15242256224155426
step: 230, loss: 0.061650052666664124
step: 240, loss: 0.17107589542865753
step: 250, loss: 0.13837575912475586
step: 260, loss: 0.039008110761642456
step: 270, loss: 0.19704508781433105
step: 280, loss: 0.11468980461359024
step: 290, loss: 0.11129391193389893
step: 300, loss: 0.08761812746524811
step: 310, loss: 0.12394897639751434
step: 320, loss: 0.1294933706521988
step: 330, loss: 0.06480147689580917
step: 340, loss: 0.18668943643569946
step: 350, loss: 0.19415608048439026
step: 360, loss: 0.12424519658088684
step: 370, loss: 0.11933008581399918
step: 380, loss: 0.2539725601673126
epoch 2: dev_f1=0.6990740740740741, f1=0.6893203883495145, best_f1=0.6893203883495145
step: 0, loss: 0.031184274703264236
step: 10, loss: 0.08413316309452057
step: 20, loss: 0.07472286373376846
step: 30, loss: 0.1448107659816742
step: 40, loss: 0.22584550082683563
step: 50, loss: 0.047152310609817505
step: 60, loss: 0.04063395410776138
step: 70, loss: 0.05362870544195175
step: 80, loss: 0.09264515340328217
step: 90, loss: 0.10391299426555634
step: 100, loss: 0.26117372512817383
step: 110, loss: 0.13454657793045044
step: 120, loss: 0.04733329638838768
step: 130, loss: 0.11125553399324417
step: 140, loss: 0.12713873386383057
step: 150, loss: 0.08740683645009995
step: 160, loss: 0.12045267224311829
step: 170, loss: 0.1059826985001564
step: 180, loss: 0.05671404302120209
step: 190, loss: 0.09860146790742874
step: 200, loss: 0.035305455327034
step: 210, loss: 0.09029916673898697
step: 220, loss: 0.07955823093652725
step: 230, loss: 0.14229698479175568
step: 240, loss: 0.01534029096364975
step: 250, loss: 0.07907614856958389
step: 260, loss: 0.03115767240524292
step: 270, loss: 0.06113807111978531
step: 280, loss: 0.116059809923172
step: 290, loss: 0.06859239190816879
step: 300, loss: 0.18381144106388092
step: 310, loss: 0.11867661029100418
step: 320, loss: 0.08497796207666397
step: 330, loss: 0.019520269706845284
step: 340, loss: 0.10316044837236404
step: 350, loss: 0.1433836966753006
step: 360, loss: 0.1481112390756607
step: 370, loss: 0.11792962998151779
step: 380, loss: 0.07012373208999634
epoch 3: dev_f1=0.7591240875912411, f1=0.7285714285714286, best_f1=0.7285714285714286
step: 0, loss: 0.024742376059293747
step: 10, loss: 0.1582595258951187
step: 20, loss: 0.12083260715007782
step: 30, loss: 0.072858065366745
step: 40, loss: 0.036771565675735474
step: 50, loss: 0.06161368265748024
step: 60, loss: 0.19436496496200562
step: 70, loss: 0.030777541920542717
step: 80, loss: 0.15746018290519714
step: 90, loss: 0.12901242077350616
step: 100, loss: 0.048691004514694214
step: 110, loss: 0.009252850897610188
step: 120, loss: 0.06958913803100586
step: 130, loss: 0.05843591317534447
step: 140, loss: 0.08985118567943573
step: 150, loss: 0.11967028677463531
step: 160, loss: 0.15955623984336853
step: 170, loss: 0.05386766791343689
step: 180, loss: 0.10118205100297928
step: 190, loss: 0.05200270190834999
step: 200, loss: 0.020048653706908226
step: 210, loss: 0.21665535867214203
step: 220, loss: 0.17521707713603973
step: 230, loss: 0.15527774393558502
step: 240, loss: 0.15597502887248993
step: 250, loss: 0.09525757282972336
step: 260, loss: 0.04042449966073036
step: 270, loss: 0.13382303714752197
step: 280, loss: 0.06677238643169403
step: 290, loss: 0.07668688148260117
step: 300, loss: 0.02086680755019188
step: 310, loss: 0.08965801447629929
step: 320, loss: 0.028201451525092125
step: 330, loss: 0.10785725712776184
step: 340, loss: 0.08273427933454514
step: 350, loss: 0.057534556835889816
step: 360, loss: 0.04919586330652237
step: 370, loss: 0.042138151824474335
step: 380, loss: 0.13725057244300842
epoch 4: dev_f1=0.7783251231527094, f1=0.7403598971722366, best_f1=0.7403598971722366
step: 0, loss: 0.06172677129507065
step: 10, loss: 0.15560869872570038
step: 20, loss: 0.08184632658958435
step: 30, loss: 0.24181143939495087
step: 40, loss: 0.03186798095703125
step: 50, loss: 0.02116437442600727
step: 60, loss: 0.03976869210600853
step: 70, loss: 0.12917311489582062
step: 80, loss: 0.08312349021434784
step: 90, loss: 0.09869775921106339
step: 100, loss: 0.11515887826681137
step: 110, loss: 0.10054398328065872
step: 120, loss: 0.032504159957170486
step: 130, loss: 0.1037876158952713
step: 140, loss: 0.02601105533540249
step: 150, loss: 0.04713621735572815
step: 160, loss: 0.1482328623533249
step: 170, loss: 0.04814383387565613
step: 180, loss: 0.09001459181308746
step: 190, loss: 0.09424946457147598
step: 200, loss: 0.04828900471329689
step: 210, loss: 0.10886070132255554
step: 220, loss: 0.042103953659534454
step: 230, loss: 0.07414677739143372
step: 240, loss: 0.19607463479042053
step: 250, loss: 0.18763001263141632
step: 260, loss: 0.028654221445322037
step: 270, loss: 0.026798129081726074
step: 280, loss: 0.08179668337106705
step: 290, loss: 0.05100866034626961
step: 300, loss: 0.0952097624540329
step: 310, loss: 0.11862867325544357
step: 320, loss: 0.020393500104546547
step: 330, loss: 0.16330112516880035
step: 340, loss: 0.12619999051094055
step: 350, loss: 0.03070766106247902
step: 360, loss: 0.10460762679576874
step: 370, loss: 0.02998087927699089
step: 380, loss: 0.05201581493020058
epoch 5: dev_f1=0.7465437788018433, f1=0.6821345707656613, best_f1=0.7403598971722366
step: 0, loss: 0.09438453614711761
step: 10, loss: 0.06386125832796097
step: 20, loss: 0.13549049198627472
step: 30, loss: 0.014181168749928474
step: 40, loss: 0.14916500449180603
step: 50, loss: 0.05392937362194061
step: 60, loss: 0.009813228622078896
step: 70, loss: 0.02906256727874279
step: 80, loss: 0.12032082676887512
step: 90, loss: 0.05335867032408714
step: 100, loss: 0.21958376467227936
step: 110, loss: 0.042711611837148666
step: 120, loss: 0.09473572671413422
step: 130, loss: 0.03275598958134651
step: 140, loss: 0.009738863445818424
step: 150, loss: 0.06107940152287483
step: 160, loss: 0.08202199637889862
step: 170, loss: 0.11567182838916779
step: 180, loss: 0.1438957005739212
step: 190, loss: 0.05266067385673523
step: 200, loss: 0.13786688446998596
step: 210, loss: 0.04593725502490997
step: 220, loss: 0.107569120824337
step: 230, loss: 0.1917489767074585
step: 240, loss: 0.05931643769145012
step: 250, loss: 0.09643201529979706
step: 260, loss: 0.02067693881690502
step: 270, loss: 0.019318167120218277
step: 280, loss: 0.13600346446037292
step: 290, loss: 0.07491016387939453
step: 300, loss: 0.13180828094482422
step: 310, loss: 0.05859718844294548
step: 320, loss: 0.06492770463228226
step: 330, loss: 0.08549073338508606
step: 340, loss: 0.07566757500171661
step: 350, loss: 0.0874287337064743
step: 360, loss: 0.043454863131046295
step: 370, loss: 0.058574557304382324
step: 380, loss: 0.1221349686384201
epoch 6: dev_f1=0.7375565610859729, f1=0.7272727272727273, best_f1=0.7403598971722366
step: 0, loss: 0.2144753783941269
step: 10, loss: 0.08237023651599884
step: 20, loss: 0.08716427534818649
step: 30, loss: 0.06653226166963577
step: 40, loss: 0.052718158811330795
step: 50, loss: 0.14335113763809204
step: 60, loss: 0.07953190058469772
step: 70, loss: 0.15611740946769714
step: 80, loss: 0.06116703897714615
step: 90, loss: 0.006785931997001171
step: 100, loss: 0.19322596490383148
step: 110, loss: 0.07061321288347244
step: 120, loss: 0.003532794304192066
step: 130, loss: 0.16072764992713928
step: 140, loss: 0.06509160250425339
step: 150, loss: 0.17120739817619324
step: 160, loss: 0.001113573438487947
step: 170, loss: 0.11409744620323181
step: 180, loss: 0.03562852367758751
step: 190, loss: 0.07133936882019043
step: 200, loss: 0.09037169069051743
step: 210, loss: 0.11299696564674377
step: 220, loss: 0.09686155617237091
step: 230, loss: 0.09885954111814499
step: 240, loss: 0.05477774143218994
step: 250, loss: 0.09802567958831787
step: 260, loss: 0.11565354466438293
step: 270, loss: 0.050077397376298904
step: 280, loss: 0.213588148355484
step: 290, loss: 0.2163582742214203
step: 300, loss: 0.08169523626565933
step: 310, loss: 0.01662607118487358
step: 320, loss: 0.046388592571020126
step: 330, loss: 0.044237714260816574
step: 340, loss: 0.04161126911640167
step: 350, loss: 0.04084845632314682
step: 360, loss: 0.016078609973192215
step: 370, loss: 0.03353191167116165
step: 380, loss: 0.10048133134841919
epoch 7: dev_f1=0.7354260089686099, f1=0.7175925925925926, best_f1=0.7403598971722366
step: 0, loss: 0.08661549538373947
step: 10, loss: 0.05090627074241638
step: 20, loss: 0.08773510158061981
step: 30, loss: 0.08530876040458679
step: 40, loss: 0.04171959310770035
step: 50, loss: 0.06639937311410904
step: 60, loss: 0.09686779230833054
step: 70, loss: 0.033304959535598755
step: 80, loss: 0.043348342180252075
step: 90, loss: 0.06166849285364151
step: 100, loss: 0.11267625540494919
step: 110, loss: 0.06804823130369186
step: 120, loss: 0.04692241549491882
step: 130, loss: 0.09560838341712952
step: 140, loss: 0.2547720968723297
step: 150, loss: 0.11914514750242233
step: 160, loss: 0.07334443181753159
step: 170, loss: 0.14914937317371368
step: 180, loss: 0.08474592119455338
step: 190, loss: 0.04012968763709068
step: 200, loss: 0.10599596798419952
step: 210, loss: 0.04198263958096504
step: 220, loss: 0.07185845822095871
step: 230, loss: 0.014767688699066639
step: 240, loss: 0.022127166390419006
step: 250, loss: 0.03343411535024643
step: 260, loss: 0.10611117631196976
step: 270, loss: 0.1805524230003357
step: 280, loss: 0.037066515535116196
step: 290, loss: 0.07674984633922577
step: 300, loss: 0.07838186621665955
step: 310, loss: 0.06845032423734665
step: 320, loss: 0.033030565828084946
step: 330, loss: 0.00610122038051486
step: 340, loss: 0.08433136343955994
step: 350, loss: 0.06271729618310928
step: 360, loss: 0.02200472354888916
step: 370, loss: 0.09863019734621048
step: 380, loss: 0.17458327114582062
epoch 8: dev_f1=0.7688442211055277, f1=0.7525252525252525, best_f1=0.7403598971722366
step: 0, loss: 0.07294744998216629
step: 10, loss: 0.0985485315322876
step: 20, loss: 0.02476143091917038
step: 30, loss: 0.018420089036226273
step: 40, loss: 0.028470341116189957
step: 50, loss: 0.05610272288322449
step: 60, loss: 0.036612607538700104
step: 70, loss: 0.054139260202646255
step: 80, loss: 0.0064009795896708965
step: 90, loss: 0.10189902037382126
step: 100, loss: 0.013693828135728836
step: 110, loss: 0.0981658399105072
step: 120, loss: 0.06336792558431625
step: 130, loss: 0.06493277102708817
step: 140, loss: 0.1261383444070816
step: 150, loss: 0.10079503059387207
step: 160, loss: 0.072010338306427
step: 170, loss: 0.06108849123120308
step: 180, loss: 0.04343676194548607
step: 190, loss: 0.035650696605443954
step: 200, loss: 0.02308322675526142
step: 210, loss: 0.058576881885528564
step: 220, loss: 0.013292214833199978
step: 230, loss: 0.10220445692539215
step: 240, loss: 0.09401426464319229
step: 250, loss: 0.06289198249578476
step: 260, loss: 0.07450288534164429
step: 270, loss: 0.054039180278778076
step: 280, loss: 0.06570827215909958
step: 290, loss: 0.08060358464717865
step: 300, loss: 0.06553980708122253
step: 310, loss: 0.10410556197166443
step: 320, loss: 0.09232202172279358
step: 330, loss: 0.026314694434404373
step: 340, loss: 0.04546887427568436
step: 350, loss: 0.043056096881628036
step: 360, loss: 0.04360489174723625
step: 370, loss: 0.16059468686580658
step: 380, loss: 0.045785628259181976
epoch 9: dev_f1=0.746341463414634, f1=0.7390180878552972, best_f1=0.7403598971722366
step: 0, loss: 0.015218810178339481
step: 10, loss: 0.10489232838153839
step: 20, loss: 0.12357531487941742
step: 30, loss: 0.03600504994392395
step: 40, loss: 0.030504874885082245
step: 50, loss: 0.02600831352174282
step: 60, loss: 0.00027560078888200223
step: 70, loss: 0.008436322212219238
step: 80, loss: 0.017285965383052826
step: 90, loss: 0.09457345306873322
step: 100, loss: 0.022808365523815155
step: 110, loss: 0.02801411971449852
step: 120, loss: 0.03959735482931137
step: 130, loss: 0.04296761378645897
step: 140, loss: 0.016601022332906723
step: 150, loss: 0.07203375548124313
step: 160, loss: 0.02629913203418255
step: 170, loss: 0.06241685897111893
step: 180, loss: 0.020298562943935394
step: 190, loss: 0.01856776885688305
step: 200, loss: 0.04602601379156113
step: 210, loss: 0.03398126736283302
step: 220, loss: 0.014383159577846527
step: 230, loss: 0.023166632279753685
step: 240, loss: 0.044458404183387756
step: 250, loss: 0.1102026030421257
step: 260, loss: 0.06465739011764526
step: 270, loss: 0.05864245444536209
step: 280, loss: 0.011087917722761631
step: 290, loss: 0.043273136019706726
step: 300, loss: 0.05419931933283806
step: 310, loss: 0.0009299110970459878
step: 320, loss: 0.014260867610573769
step: 330, loss: 0.04963008314371109
step: 340, loss: 0.05065065622329712
step: 350, loss: 0.201070636510849
step: 360, loss: 0.09426161646842957
step: 370, loss: 0.031547363847494125
step: 380, loss: 0.028877710923552513
epoch 10: dev_f1=0.7410926365795725, f1=0.7004830917874396, best_f1=0.7403598971722366
step: 0, loss: 0.015023532323539257
step: 10, loss: 0.049841444939374924
step: 20, loss: 0.009672035463154316
step: 30, loss: 0.03320330008864403
step: 40, loss: 0.09939098358154297
step: 50, loss: 0.06553000211715698
step: 60, loss: 0.06982959806919098
step: 70, loss: 0.08284378051757812
step: 80, loss: 0.1016111820936203
step: 90, loss: 0.08287688344717026
step: 100, loss: 0.012442534789443016
step: 110, loss: 0.014221242628991604
step: 120, loss: 0.04333358258008957
step: 130, loss: 0.49648401141166687
step: 140, loss: 0.10226686298847198
step: 150, loss: 0.00045006279833614826
step: 160, loss: 0.21160830557346344
step: 170, loss: 0.06086450070142746
step: 180, loss: 0.0329897366464138
step: 190, loss: 0.03490610420703888
step: 200, loss: 0.07574636489152908
step: 210, loss: 0.05928119271993637
step: 220, loss: 0.04285005107522011
step: 230, loss: 0.10148154199123383
step: 240, loss: 0.06478454917669296
step: 250, loss: 0.11794231086969376
step: 260, loss: 0.01611371710896492
step: 270, loss: 0.06219126656651497
step: 280, loss: 0.08124189078807831
step: 290, loss: 0.030895445495843887
step: 300, loss: 0.03267630189657211
step: 310, loss: 0.10684939473867416
step: 320, loss: 0.03684311360120773
step: 330, loss: 0.029154391959309578
step: 340, loss: 0.03144511207938194
step: 350, loss: 0.04380520433187485
step: 360, loss: 0.05094895884394646
step: 370, loss: 0.08113887906074524
step: 380, loss: 0.011000365018844604
epoch 11: dev_f1=0.760705289672544, f1=0.7193877551020408, best_f1=0.7403598971722366
step: 0, loss: 0.0690104067325592
step: 10, loss: 0.040242768824100494
step: 20, loss: 0.021517708897590637
step: 30, loss: 0.02032502181828022
step: 40, loss: 0.0912473276257515
step: 50, loss: 0.0005348880076780915
step: 60, loss: 0.019064847379922867
step: 70, loss: 0.044098079204559326
step: 80, loss: 0.0751810297369957
step: 90, loss: 0.09762430191040039
step: 100, loss: 0.006973618641495705
step: 110, loss: 0.021420633420348167
step: 120, loss: 0.00042523269075900316
step: 130, loss: 0.033720023930072784
step: 140, loss: 0.07621456682682037
step: 150, loss: 0.04084315896034241
step: 160, loss: 0.06575977802276611
step: 170, loss: 0.0034521992783993483
step: 180, loss: 0.015050158835947514
step: 190, loss: 0.09632391482591629
step: 200, loss: 0.03216090053319931
step: 210, loss: 0.02506030537188053
step: 220, loss: 0.03211340308189392
step: 230, loss: 0.14998939633369446
step: 240, loss: 0.0015127169899642467
step: 250, loss: 0.049162618815898895
step: 260, loss: 0.04015754908323288
step: 270, loss: 0.1338823139667511
step: 280, loss: 0.11247975379228592
step: 290, loss: 0.1125643327832222
step: 300, loss: 0.022498682141304016
step: 310, loss: 0.03677821904420853
step: 320, loss: 0.1162613183259964
step: 330, loss: 0.01363835483789444
step: 340, loss: 0.17597275972366333
step: 350, loss: 0.07734397798776627
step: 360, loss: 0.03180708736181259
step: 370, loss: 0.026717856526374817
step: 380, loss: 0.002993876114487648
epoch 12: dev_f1=0.7511737089201878, f1=0.7078384798099762, best_f1=0.7403598971722366
step: 0, loss: 0.028103260323405266
step: 10, loss: 0.017199162393808365
step: 20, loss: 0.00019399983284529299
step: 30, loss: 0.009947407990694046
step: 40, loss: 0.0022199517115950584
step: 50, loss: 0.008135455660521984
step: 60, loss: 0.09406551718711853
step: 70, loss: 0.06677889823913574
step: 80, loss: 0.015310455113649368
step: 90, loss: 0.049086641520261765
step: 100, loss: 0.03540947288274765
step: 110, loss: 0.0573759488761425
step: 120, loss: 0.05844259634613991
step: 130, loss: 0.0146544324234128
step: 140, loss: 0.17726367712020874
step: 150, loss: 0.122646264731884
step: 160, loss: 0.027863338589668274
step: 170, loss: 0.01517542265355587
step: 180, loss: 0.03740592673420906
step: 190, loss: 0.05394861847162247
step: 200, loss: 0.06408517807722092
step: 210, loss: 0.032057441771030426
step: 220, loss: 0.08048714697360992
step: 230, loss: 0.08427255600690842
step: 240, loss: 0.024633238092064857
step: 250, loss: 0.11696706712245941
step: 260, loss: 0.04309779778122902
step: 270, loss: 0.008738799951970577
step: 280, loss: 0.025793546810746193
step: 290, loss: 0.07472431659698486
step: 300, loss: 0.01696033403277397
step: 310, loss: 0.02684730477631092
step: 320, loss: 0.024688569828867912
step: 330, loss: 0.03778444230556488
step: 340, loss: 0.026890769600868225
step: 350, loss: 0.003626805730164051
step: 360, loss: 0.04574577510356903
step: 370, loss: 0.0255357064306736
step: 380, loss: 0.06291850656270981
epoch 13: dev_f1=0.7543424317617866, f1=0.7046632124352331, best_f1=0.7403598971722366
step: 0, loss: 0.026805175468325615
step: 10, loss: 0.0478338822722435
step: 20, loss: 5.4946576710790396e-05
step: 30, loss: 0.014649154618382454
step: 40, loss: 0.04206449165940285
step: 50, loss: 0.16468890011310577
step: 60, loss: 0.1411914825439453
step: 70, loss: 0.015214690938591957
step: 80, loss: 0.006593028083443642
step: 90, loss: 0.02963149920105934
step: 100, loss: 0.045620255172252655
step: 110, loss: 0.018721099942922592
step: 120, loss: 0.02442042902112007
step: 130, loss: 0.061582762748003006
step: 140, loss: 0.0708405077457428
step: 150, loss: 0.06587328016757965
step: 160, loss: 0.024069974198937416
step: 170, loss: 0.03118951991200447
step: 180, loss: 0.06626144051551819
step: 190, loss: 0.00019334237731527537
step: 200, loss: 0.10992560535669327
step: 210, loss: 0.10085828602313995
step: 220, loss: 0.022511953487992287
step: 230, loss: 0.08359651267528534
step: 240, loss: 0.03591993823647499
step: 250, loss: 0.0014843533281236887
step: 260, loss: 0.03547446057200432
step: 270, loss: 0.0002768075792118907
step: 280, loss: 0.06520306318998337
step: 290, loss: 0.046734970062971115
step: 300, loss: 0.00841059722006321
step: 310, loss: 0.04330743849277496
step: 320, loss: 0.028485622256994247
step: 330, loss: 0.005469230934977531
step: 340, loss: 0.043891433626413345
step: 350, loss: 0.059362322092056274
step: 360, loss: 0.025763235986232758
step: 370, loss: 0.049330584704875946
step: 380, loss: 0.027831172570586205
epoch 14: dev_f1=0.75, f1=0.7116883116883116, best_f1=0.7403598971722366
step: 0, loss: 0.0324871726334095
step: 10, loss: 0.07779526710510254
step: 20, loss: 0.09008360654115677
step: 30, loss: 0.017452461645007133
step: 40, loss: 0.013740524649620056
step: 50, loss: 0.003331769024953246
step: 60, loss: 0.015359322540462017
step: 70, loss: 0.1361001878976822
step: 80, loss: 0.013449066318571568
step: 90, loss: 0.0026045104023069143
step: 100, loss: 0.02806900627911091
step: 110, loss: 0.0036800189409404993
step: 120, loss: 0.03644884377717972
step: 130, loss: 0.0354963093996048
step: 140, loss: 0.02416355349123478
step: 150, loss: 0.0031227541621774435
step: 160, loss: 0.010730376467108727
step: 170, loss: 0.03643088787794113
step: 180, loss: 0.10950156301259995
step: 190, loss: 0.02823781967163086
step: 200, loss: 0.0006154769798740745
step: 210, loss: 0.019222278147935867
step: 220, loss: 0.07288149744272232
step: 230, loss: 0.09006276726722717
step: 240, loss: 0.028390584513545036
step: 250, loss: 0.0278162844479084
step: 260, loss: 0.010794755071401596
step: 270, loss: 0.020638415589928627
step: 280, loss: 0.03254037722945213
step: 290, loss: 0.040576107800006866
step: 300, loss: 0.0006549983518198133
step: 310, loss: 0.07206211984157562
step: 320, loss: 0.008409482426941395
step: 330, loss: 0.029640473425388336
step: 340, loss: 0.05633452534675598
step: 350, loss: 0.00013130616571288556
step: 360, loss: 0.01488305814564228
step: 370, loss: 0.02535625547170639
step: 380, loss: 0.008653642609715462
epoch 15: dev_f1=0.7427055702917772, f1=0.7123287671232876, best_f1=0.7403598971722366
step: 0, loss: 0.0004463721998035908
step: 10, loss: 7.437140448018909e-05
step: 20, loss: 0.005602738354355097
step: 30, loss: 0.05044420436024666
step: 40, loss: 0.010095184668898582
step: 50, loss: 0.15080837905406952
step: 60, loss: 0.009501012973487377
step: 70, loss: 0.0014243408804759383
step: 80, loss: 0.0069993785582482815
step: 90, loss: 0.13004063069820404
step: 100, loss: 0.00017287128139287233
step: 110, loss: 0.029461713507771492
step: 120, loss: 0.04851162061095238
step: 130, loss: 0.14638474583625793
step: 140, loss: 0.0493735745549202
step: 150, loss: 0.05057353898882866
step: 160, loss: 0.010246568359434605
step: 170, loss: 0.09089435636997223
step: 180, loss: 0.07205086201429367
step: 190, loss: 0.00047484293463639915
step: 200, loss: 0.10326080024242401
step: 210, loss: 0.011755808256566525
step: 220, loss: 0.009907769039273262
step: 230, loss: 0.017612671479582787
step: 240, loss: 0.011957830749452114
step: 250, loss: 0.04244770109653473
step: 260, loss: 0.09762963652610779
step: 270, loss: 0.021904991939663887
step: 280, loss: 0.024013139307498932
step: 290, loss: 0.048287972807884216
step: 300, loss: 0.13786856830120087
step: 310, loss: 0.00016391454846598208
step: 320, loss: 0.040560487657785416
step: 330, loss: 0.02082524634897709
step: 340, loss: 0.01645459420979023
step: 350, loss: 0.06665223091840744
step: 360, loss: 0.08195142447948456
step: 370, loss: 0.0838686004281044
step: 380, loss: 0.044726110994815826
epoch 16: dev_f1=0.7684729064039408, f1=0.7146529562982005, best_f1=0.7403598971722366
step: 0, loss: 0.008756473660469055
step: 10, loss: 0.03151153028011322
step: 20, loss: 0.022934384644031525
step: 30, loss: 0.04681050032377243
step: 40, loss: 0.014528756961226463
step: 50, loss: 0.01640944369137287
step: 60, loss: 0.01373909693211317
step: 70, loss: 0.006007663439959288
step: 80, loss: 0.09073124825954437
step: 90, loss: 0.04246490076184273
step: 100, loss: 0.052656084299087524
step: 110, loss: 0.10094847530126572
step: 120, loss: 4.372362309368327e-05
step: 130, loss: 0.03313424438238144
step: 140, loss: 0.011248522438108921
step: 150, loss: 0.04045524820685387
step: 160, loss: 0.07891149818897247
step: 170, loss: 0.06046289578080177
step: 180, loss: 0.00037487997906282544
step: 190, loss: 0.02210189588367939
step: 200, loss: 0.023690728470683098
step: 210, loss: 0.005174495745450258
step: 220, loss: 0.01904871128499508
step: 230, loss: 0.013074904680252075
step: 240, loss: 0.012132938951253891
step: 250, loss: 0.012756960466504097
step: 260, loss: 0.05281852185726166
step: 270, loss: 0.05405166372656822
step: 280, loss: 0.051004935055971146
step: 290, loss: 0.010650401003658772
step: 300, loss: 0.0002572743396740407
step: 310, loss: 0.030043648555874825
step: 320, loss: 0.02417686954140663
step: 330, loss: 0.00874256156384945
step: 340, loss: 6.070916788303293e-05
step: 350, loss: 0.026329288259148598
step: 360, loss: 0.0006174349691718817
step: 370, loss: 4.926834662910551e-05
step: 380, loss: 0.003412747522816062
epoch 17: dev_f1=0.7314578005115089, f1=0.7018469656992085, best_f1=0.7403598971722366
step: 0, loss: 0.03882572054862976
step: 10, loss: 0.014848417602479458
step: 20, loss: 0.015972306951880455
step: 30, loss: 0.012822982855141163
step: 40, loss: 0.0600903145968914
step: 50, loss: 0.023523449897766113
step: 60, loss: 0.052159566432237625
step: 70, loss: 0.004354564473032951
step: 80, loss: 0.08572054654359818
step: 90, loss: 0.05194266512989998
step: 100, loss: 0.002412097528576851
step: 110, loss: 0.035113878548145294
step: 120, loss: 0.0031069181859493256
step: 130, loss: 0.0970875546336174
step: 140, loss: 0.049554552882909775
step: 150, loss: 0.047337792813777924
step: 160, loss: 0.032731350511312485
step: 170, loss: 0.00822500977665186
step: 180, loss: 0.05831266567111015
step: 190, loss: 0.0031357333064079285
step: 200, loss: 0.039176780730485916
step: 210, loss: 0.058173034340143204
step: 220, loss: 0.05515359342098236
step: 230, loss: 0.0013436103472486138
step: 240, loss: 0.016456810757517815
step: 250, loss: 0.0017151603242382407
step: 260, loss: 0.08782365173101425
step: 270, loss: 0.007749880198389292
step: 280, loss: 0.04871160164475441
step: 290, loss: 0.0002581504231784493
step: 300, loss: 0.018526708707213402
step: 310, loss: 0.017048321664333344
step: 320, loss: 0.00021693723101634532
step: 330, loss: 0.07365009933710098
step: 340, loss: 0.014245805330574512
step: 350, loss: 0.06384307891130447
step: 360, loss: 0.00035787344677373767
step: 370, loss: 0.016551772132515907
step: 380, loss: 0.031285934150218964
epoch 18: dev_f1=0.7345844504021448, f1=0.7087912087912088, best_f1=0.7403598971722366
step: 0, loss: 0.000296293554129079
step: 10, loss: 0.00676471134647727
step: 20, loss: 0.08225980401039124
step: 30, loss: 2.92242784780683e-05
step: 40, loss: 0.006835180800408125
step: 50, loss: 0.02761099301278591
step: 60, loss: 0.024286797270178795
step: 70, loss: 0.01582767814397812
step: 80, loss: 0.05778619274497032
step: 90, loss: 0.0017733556451275945
step: 100, loss: 0.0001435327430954203
step: 110, loss: 0.014586551114916801
step: 120, loss: 0.0012855364475399256
step: 130, loss: 0.0054792058654129505
step: 140, loss: 0.06210031360387802
step: 150, loss: 0.0032891668379306793
step: 160, loss: 0.00015180211630649865
step: 170, loss: 0.02559790387749672
step: 180, loss: 0.01630324311554432
step: 190, loss: 0.008936186321079731
step: 200, loss: 0.016791172325611115
step: 210, loss: 0.03289207071065903
step: 220, loss: 0.0003024682227987796
step: 230, loss: 0.03966078534722328
step: 240, loss: 0.028307516127824783
step: 250, loss: 0.04641608148813248
step: 260, loss: 3.143318463116884e-05
step: 270, loss: 0.05805385857820511
step: 280, loss: 0.007405110634863377
step: 290, loss: 0.03370160236954689
step: 300, loss: 0.003293351037427783
step: 310, loss: 0.09791859239339828
step: 320, loss: 0.011018422432243824
step: 330, loss: 0.016081925481557846
step: 340, loss: 0.009019090794026852
step: 350, loss: 0.0003376407257746905
step: 360, loss: 0.02071060985326767
step: 370, loss: 0.03618333116173744
step: 380, loss: 0.034066833555698395
epoch 19: dev_f1=0.7102272727272727, f1=0.7011494252873564, best_f1=0.7403598971722366
step: 0, loss: 0.03416111320257187
step: 10, loss: 0.009780815802514553
step: 20, loss: 0.062441229820251465
step: 30, loss: 0.002724111545830965
step: 40, loss: 0.001507495529949665
step: 50, loss: 0.04234365373849869
step: 60, loss: 0.026161877438426018
step: 70, loss: 0.06444841623306274
step: 80, loss: 5.4673182603437454e-05
step: 90, loss: 0.00010802609904203564
step: 100, loss: 0.013464732095599174
step: 110, loss: 0.01627928577363491
step: 120, loss: 0.0044281939044594765
step: 130, loss: 0.18037652969360352
step: 140, loss: 0.02268272079527378
step: 150, loss: 0.006814034190028906
step: 160, loss: 0.08486957848072052
step: 170, loss: 0.04045252129435539
step: 180, loss: 0.018862377852201462
step: 190, loss: 0.010849729180335999
step: 200, loss: 0.04874205216765404
step: 210, loss: 0.022957753390073776
step: 220, loss: 0.01914845034480095
step: 230, loss: 0.04512258246541023
step: 240, loss: 0.025450441986322403
step: 250, loss: 0.009046254679560661
step: 260, loss: 0.008175721392035484
step: 270, loss: 0.031065931543707848
step: 280, loss: 0.00492646312341094
step: 290, loss: 0.014458409510552883
step: 300, loss: 0.010352377779781818
step: 310, loss: 0.017862357199192047
step: 320, loss: 0.08439971506595612
step: 330, loss: 0.00690285163000226
step: 340, loss: 0.05796549469232559
step: 350, loss: 0.07060189545154572
step: 360, loss: 0.07771409302949905
step: 370, loss: 0.0003506567736621946
step: 380, loss: 6.256938650039956e-05
epoch 20: dev_f1=0.7262569832402234, f1=0.7008547008547008, best_f1=0.7403598971722366
