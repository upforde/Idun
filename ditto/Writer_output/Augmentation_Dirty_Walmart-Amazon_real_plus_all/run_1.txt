cuda
Device: cuda
step: 0, loss: 0.6439034342765808
step: 10, loss: 0.27473825216293335
step: 20, loss: 0.23857112228870392
step: 30, loss: 0.3761700987815857
step: 40, loss: 0.3151494562625885
step: 50, loss: 0.1424010545015335
step: 60, loss: 0.30510014295578003
step: 70, loss: 0.4417206346988678
step: 80, loss: 0.3585483133792877
step: 90, loss: 0.23870699107646942
step: 100, loss: 0.2875995934009552
step: 110, loss: 0.1969703584909439
step: 120, loss: 0.35011225938796997
step: 130, loss: 0.2044953852891922
step: 140, loss: 0.276798278093338
step: 150, loss: 0.18032923340797424
step: 160, loss: 0.43824678659439087
step: 170, loss: 0.08349937945604324
step: 180, loss: 0.12095405906438828
step: 190, loss: 0.21267101168632507
step: 200, loss: 0.23984470963478088
step: 210, loss: 0.1385478675365448
step: 220, loss: 0.2698957622051239
step: 230, loss: 0.19269675016403198
step: 240, loss: 0.22460423409938812
step: 250, loss: 0.1345270723104477
step: 260, loss: 0.19290854036808014
step: 270, loss: 0.10926718264818192
step: 280, loss: 0.1917235553264618
step: 290, loss: 0.03970523551106453
step: 300, loss: 0.2071797251701355
step: 310, loss: 0.19813808798789978
step: 320, loss: 0.05140961706638336
step: 330, loss: 0.2583826780319214
step: 340, loss: 0.10228657722473145
step: 350, loss: 0.31029611825942993
step: 360, loss: 0.030314570292830467
step: 370, loss: 0.05589348450303078
step: 380, loss: 0.3228384554386139
epoch 1: dev_f1=0.6191780821917807, f1=0.6426592797783933, best_f1=0.6426592797783933
step: 0, loss: 0.18860599398612976
step: 10, loss: 0.21660199761390686
step: 20, loss: 0.16517756879329681
step: 30, loss: 0.08950433880090714
step: 40, loss: 0.20686602592468262
step: 50, loss: 0.1582719087600708
step: 60, loss: 0.29534026980400085
step: 70, loss: 0.07850132137537003
step: 80, loss: 0.05408085510134697
step: 90, loss: 0.43229836225509644
step: 100, loss: 0.10304372757673264
step: 110, loss: 0.05467284470796585
step: 120, loss: 0.10034962743520737
step: 130, loss: 0.10361164063215256
step: 140, loss: 0.23225870728492737
step: 150, loss: 0.1048610582947731
step: 160, loss: 0.15857446193695068
step: 170, loss: 0.08190613985061646
step: 180, loss: 0.1991383135318756
step: 190, loss: 0.1502573937177658
step: 200, loss: 0.02033059112727642
step: 210, loss: 0.1600274294614792
step: 220, loss: 0.1312853842973709
step: 230, loss: 0.07548399269580841
step: 240, loss: 0.08341814577579498
step: 250, loss: 0.10298675298690796
step: 260, loss: 0.09200876206159592
step: 270, loss: 0.11692525446414948
step: 280, loss: 0.05143527686595917
step: 290, loss: 0.09282764792442322
step: 300, loss: 0.255107581615448
step: 310, loss: 0.038436900824308395
step: 320, loss: 0.049198418855667114
step: 330, loss: 0.16050474345684052
step: 340, loss: 0.32476896047592163
step: 350, loss: 0.12270437926054001
step: 360, loss: 0.1862165927886963
step: 370, loss: 0.15268296003341675
step: 380, loss: 0.12220144271850586
epoch 2: dev_f1=0.7061728395061728, f1=0.7100000000000001, best_f1=0.7100000000000001
step: 0, loss: 0.17781774699687958
step: 10, loss: 0.2078571617603302
step: 20, loss: 0.1252581924200058
step: 30, loss: 0.08042609691619873
step: 40, loss: 0.18795175850391388
step: 50, loss: 0.08413014560937881
step: 60, loss: 0.05736909806728363
step: 70, loss: 0.06915833801031113
step: 80, loss: 0.10370253026485443
step: 90, loss: 0.2096596211194992
step: 100, loss: 0.09106305241584778
step: 110, loss: 0.08624688535928726
step: 120, loss: 0.04802877828478813
step: 130, loss: 0.07375416904687881
step: 140, loss: 0.16544772684574127
step: 150, loss: 0.05834461376070976
step: 160, loss: 0.19051042199134827
step: 170, loss: 0.13378988206386566
step: 180, loss: 0.011460131965577602
step: 190, loss: 0.09935232251882553
step: 200, loss: 0.08526210486888885
step: 210, loss: 0.04023219645023346
step: 220, loss: 0.16441933810710907
step: 230, loss: 0.1462807059288025
step: 240, loss: 0.07746818661689758
step: 250, loss: 0.04325132444500923
step: 260, loss: 0.23306791484355927
step: 270, loss: 0.15434372425079346
step: 280, loss: 0.015767794102430344
step: 290, loss: 0.23347273468971252
step: 300, loss: 0.18308667838573456
step: 310, loss: 0.1673405021429062
step: 320, loss: 0.04621680825948715
step: 330, loss: 0.18127921223640442
step: 340, loss: 0.1946403980255127
step: 350, loss: 0.16074317693710327
step: 360, loss: 0.05546316131949425
step: 370, loss: 0.09753638505935669
step: 380, loss: 0.044700734317302704
epoch 3: dev_f1=0.6919191919191918, f1=0.6907216494845362, best_f1=0.7100000000000001
step: 0, loss: 0.10196951776742935
step: 10, loss: 0.15118514001369476
step: 20, loss: 0.06874800473451614
step: 30, loss: 0.16648486256599426
step: 40, loss: 0.07277394831180573
step: 50, loss: 0.04189607873558998
step: 60, loss: 0.018512187525629997
step: 70, loss: 0.04554414004087448
step: 80, loss: 0.15544594824314117
step: 90, loss: 0.13973155617713928
step: 100, loss: 0.029253346845507622
step: 110, loss: 0.15463879704475403
step: 120, loss: 0.18511006236076355
step: 130, loss: 0.2605527639389038
step: 140, loss: 0.026194671168923378
step: 150, loss: 0.1667042076587677
step: 160, loss: 0.501819372177124
step: 170, loss: 0.09433431923389435
step: 180, loss: 0.376986026763916
step: 190, loss: 0.11131611466407776
step: 200, loss: 0.062115468084812164
step: 210, loss: 0.06745237857103348
step: 220, loss: 0.12441536784172058
step: 230, loss: 0.06806577742099762
step: 240, loss: 0.15174998342990875
step: 250, loss: 0.06575517356395721
step: 260, loss: 0.09649791568517685
step: 270, loss: 0.1776953935623169
step: 280, loss: 0.0560108944773674
step: 290, loss: 0.06578648835420609
step: 300, loss: 0.048865702003240585
step: 310, loss: 0.040916524827480316
step: 320, loss: 0.04575513303279877
step: 330, loss: 0.03489544987678528
step: 340, loss: 0.2171029895544052
step: 350, loss: 0.0865103229880333
step: 360, loss: 0.05837681517004967
step: 370, loss: 0.10395344346761703
step: 380, loss: 0.10959721356630325
epoch 4: dev_f1=0.738095238095238, f1=0.7500000000000001, best_f1=0.7500000000000001
step: 0, loss: 0.12295686453580856
step: 10, loss: 0.1354125738143921
step: 20, loss: 0.030152905732393265
step: 30, loss: 0.09860242903232574
step: 40, loss: 0.07083120942115784
step: 50, loss: 0.046184733510017395
step: 60, loss: 0.21500661969184875
step: 70, loss: 0.10360894352197647
step: 80, loss: 0.04640349745750427
step: 90, loss: 0.11084490269422531
step: 100, loss: 0.12255168706178665
step: 110, loss: 0.04476189985871315
step: 120, loss: 0.05255300924181938
step: 130, loss: 0.028419096022844315
step: 140, loss: 0.08872468769550323
step: 150, loss: 0.08361586183309555
step: 160, loss: 0.05251025781035423
step: 170, loss: 0.01604250632226467
step: 180, loss: 0.13875693082809448
step: 190, loss: 0.06468941271305084
step: 200, loss: 0.02961491234600544
step: 210, loss: 0.0715213492512703
step: 220, loss: 0.05550207942724228
step: 230, loss: 0.2725426256656647
step: 240, loss: 0.06641335040330887
step: 250, loss: 0.1010970026254654
step: 260, loss: 0.09294725954532623
step: 270, loss: 0.02805679477751255
step: 280, loss: 0.1710769236087799
step: 290, loss: 0.0854136273264885
step: 300, loss: 0.026749789714813232
step: 310, loss: 0.05097327381372452
step: 320, loss: 0.07453224062919617
step: 330, loss: 0.16441862285137177
step: 340, loss: 0.12147239595651627
step: 350, loss: 0.01701175607740879
step: 360, loss: 0.03573627397418022
step: 370, loss: 0.11062421649694443
step: 380, loss: 0.10383132845163345
epoch 5: dev_f1=0.7106598984771575, f1=0.6947890818858561, best_f1=0.7500000000000001
step: 0, loss: 0.08623921126127243
step: 10, loss: 0.035173870623111725
step: 20, loss: 0.020186619833111763
step: 30, loss: 0.03319866582751274
step: 40, loss: 0.03401222825050354
step: 50, loss: 0.11892011016607285
step: 60, loss: 0.030737610533833504
step: 70, loss: 0.20961859822273254
step: 80, loss: 0.13559149205684662
step: 90, loss: 0.06308546662330627
step: 100, loss: 0.08930682390928268
step: 110, loss: 0.08988571166992188
step: 120, loss: 0.14728957414627075
step: 130, loss: 0.10009611397981644
step: 140, loss: 0.032901547849178314
step: 150, loss: 0.026521572843194008
step: 160, loss: 0.0708324983716011
step: 170, loss: 0.08399683237075806
step: 180, loss: 0.05590982735157013
step: 190, loss: 0.09836255013942719
step: 200, loss: 0.04436160624027252
step: 210, loss: 0.13660798966884613
step: 220, loss: 0.06159069389104843
step: 230, loss: 0.020500900223851204
step: 240, loss: 0.16087079048156738
step: 250, loss: 0.005620016250759363
step: 260, loss: 0.05554348602890968
step: 270, loss: 0.03588182479143143
step: 280, loss: 0.024882590398192406
step: 290, loss: 0.05598161742091179
step: 300, loss: 0.07719684392213821
step: 310, loss: 0.05293707549571991
step: 320, loss: 0.02694566920399666
step: 330, loss: 0.0507797934114933
step: 340, loss: 0.10864319652318954
step: 350, loss: 0.06756757199764252
step: 360, loss: 0.10097663849592209
step: 370, loss: 0.09558612108230591
step: 380, loss: 0.06397715955972672
epoch 6: dev_f1=0.736842105263158, f1=0.7272727272727272, best_f1=0.7500000000000001
step: 0, loss: 0.022396210581064224
step: 10, loss: 0.09997505694627762
step: 20, loss: 0.08923941850662231
step: 30, loss: 0.053063951432704926
step: 40, loss: 0.09162861108779907
step: 50, loss: 0.07595179975032806
step: 60, loss: 0.048218585550785065
step: 70, loss: 0.07772693783044815
step: 80, loss: 0.1512444019317627
step: 90, loss: 0.11028623580932617
step: 100, loss: 0.060877520591020584
step: 110, loss: 0.12703366577625275
step: 120, loss: 0.0757766142487526
step: 130, loss: 0.0225823987275362
step: 140, loss: 0.06906644999980927
step: 150, loss: 0.1375737339258194
step: 160, loss: 0.09769820421934128
step: 170, loss: 0.3159312307834625
step: 180, loss: 0.06126164644956589
step: 190, loss: 0.12068648636341095
step: 200, loss: 0.06683491170406342
step: 210, loss: 0.07508059591054916
step: 220, loss: 0.038121309131383896
step: 230, loss: 0.07608158886432648
step: 240, loss: 0.01173472125083208
step: 250, loss: 0.07968039810657501
step: 260, loss: 0.09108874946832657
step: 270, loss: 0.19123287498950958
step: 280, loss: 0.02456493303179741
step: 290, loss: 0.004647829104214907
step: 300, loss: 0.11836855858564377
step: 310, loss: 0.03593748062849045
step: 320, loss: 0.06287035346031189
step: 330, loss: 0.05704183131456375
step: 340, loss: 0.08334428071975708
step: 350, loss: 0.19537490606307983
step: 360, loss: 0.1313517540693283
step: 370, loss: 0.13160033524036407
step: 380, loss: 0.057541921734809875
epoch 7: dev_f1=0.7452830188679247, f1=0.7281553398058251, best_f1=0.7281553398058251
step: 0, loss: 0.025565236806869507
step: 10, loss: 0.0576196126639843
step: 20, loss: 0.15438531339168549
step: 30, loss: 0.010903085581958294
step: 40, loss: 0.09330248832702637
step: 50, loss: 0.07686808705329895
step: 60, loss: 0.05280463770031929
step: 70, loss: 0.024607576429843903
step: 80, loss: 0.16170978546142578
step: 90, loss: 0.09320377558469772
step: 100, loss: 0.01682085357606411
step: 110, loss: 0.0025859898887574673
step: 120, loss: 0.12300488352775574
step: 130, loss: 0.07302138954401016
step: 140, loss: 0.0007431639824062586
step: 150, loss: 0.10252266377210617
step: 160, loss: 0.04644235596060753
step: 170, loss: 0.14674721658229828
step: 180, loss: 0.033938489854335785
step: 190, loss: 0.022873593494296074
step: 200, loss: 0.1118709146976471
step: 210, loss: 0.06826113909482956
step: 220, loss: 0.029358860105276108
step: 230, loss: 0.026722198352217674
step: 240, loss: 0.03233535587787628
step: 250, loss: 0.04932687431573868
step: 260, loss: 0.03849153593182564
step: 270, loss: 0.10608787089586258
step: 280, loss: 0.10541589558124542
step: 290, loss: 0.03534994646906853
step: 300, loss: 0.08354923874139786
step: 310, loss: 0.049463916569948196
step: 320, loss: 0.06638295203447342
step: 330, loss: 0.06988747417926788
step: 340, loss: 0.11242388188838959
step: 350, loss: 0.06284663081169128
step: 360, loss: 0.0478907972574234
step: 370, loss: 0.061982110142707825
step: 380, loss: 0.02524809166789055
epoch 8: dev_f1=0.7058823529411764, f1=0.7287671232876712, best_f1=0.7281553398058251
step: 0, loss: 0.03398212045431137
step: 10, loss: 0.04976138472557068
step: 20, loss: 0.07013890147209167
step: 30, loss: 0.026707079261541367
step: 40, loss: 0.03260830044746399
step: 50, loss: 0.10245773196220398
step: 60, loss: 0.050778165459632874
step: 70, loss: 0.07185479253530502
step: 80, loss: 0.015067046508193016
step: 90, loss: 0.10574013739824295
step: 100, loss: 0.02903580106794834
step: 110, loss: 0.08106527477502823
step: 120, loss: 0.08146081864833832
step: 130, loss: 0.05439191311597824
step: 140, loss: 0.07079817354679108
step: 150, loss: 0.10315311700105667
step: 160, loss: 0.0870075672864914
step: 170, loss: 0.010143297724425793
step: 180, loss: 0.05204390361905098
step: 190, loss: 0.10464198887348175
step: 200, loss: 0.09470789134502411
step: 210, loss: 0.08053694665431976
step: 220, loss: 0.04889293015003204
step: 230, loss: 0.019479962065815926
step: 240, loss: 0.06586634367704391
step: 250, loss: 0.16288262605667114
step: 260, loss: 0.02712891437113285
step: 270, loss: 0.059764314442873
step: 280, loss: 0.07381746172904968
step: 290, loss: 0.00978555902838707
step: 300, loss: 0.13237208127975464
step: 310, loss: 0.05703233182430267
step: 320, loss: 0.056164443492889404
step: 330, loss: 0.12385205179452896
step: 340, loss: 0.028478341177105904
step: 350, loss: 0.07729209959506989
step: 360, loss: 0.09195418655872345
step: 370, loss: 0.09262827783823013
step: 380, loss: 0.04075098782777786
epoch 9: dev_f1=0.7024390243902439, f1=0.72, best_f1=0.7281553398058251
step: 0, loss: 0.05110322684049606
step: 10, loss: 0.07692866027355194
step: 20, loss: 0.014175744727253914
step: 30, loss: 0.05561922863125801
step: 40, loss: 0.08533606678247452
step: 50, loss: 0.012820066884160042
step: 60, loss: 0.025046061724424362
step: 70, loss: 0.0972282737493515
step: 80, loss: 0.09045662730932236
step: 90, loss: 0.001720276428386569
step: 100, loss: 0.06870781630277634
step: 110, loss: 0.07936470955610275
step: 120, loss: 0.05103971064090729
step: 130, loss: 0.0067960419692099094
step: 140, loss: 0.09556836634874344
step: 150, loss: 0.10225512087345123
step: 160, loss: 0.08775665611028671
step: 170, loss: 0.1380997598171234
step: 180, loss: 0.037343528121709824
step: 190, loss: 0.06423786282539368
step: 200, loss: 0.1008169874548912
step: 210, loss: 0.022999092936515808
step: 220, loss: 0.07197937369346619
step: 230, loss: 0.053637344390153885
step: 240, loss: 0.05743006244301796
step: 250, loss: 0.03743026778101921
step: 260, loss: 0.01202770322561264
step: 270, loss: 0.058987535536289215
step: 280, loss: 0.05943728983402252
step: 290, loss: 0.15975739061832428
step: 300, loss: 0.08134268969297409
step: 310, loss: 0.008334184996783733
step: 320, loss: 0.052591849118471146
step: 330, loss: 0.09408175945281982
step: 340, loss: 0.09254055470228195
step: 350, loss: 0.05337492749094963
step: 360, loss: 0.020959697663784027
step: 370, loss: 0.20172756910324097
step: 380, loss: 0.026251690462231636
epoch 10: dev_f1=0.7444168734491315, f1=0.7365728900255755, best_f1=0.7281553398058251
step: 0, loss: 0.06605961173772812
step: 10, loss: 0.045038774609565735
step: 20, loss: 0.04022292047739029
step: 30, loss: 0.07732198387384415
step: 40, loss: 0.04947597533464432
step: 50, loss: 0.07585404813289642
step: 60, loss: 0.01596446894109249
step: 70, loss: 0.032886870205402374
step: 80, loss: 0.07095877081155777
step: 90, loss: 0.09341523051261902
step: 100, loss: 0.00741790933534503
step: 110, loss: 0.025938579812645912
step: 120, loss: 0.06362301856279373
step: 130, loss: 0.10648919641971588
step: 140, loss: 0.11890412867069244
step: 150, loss: 0.06005990877747536
step: 160, loss: 0.04201820492744446
step: 170, loss: 0.020985987037420273
step: 180, loss: 0.013665088452398777
step: 190, loss: 0.09896565973758698
step: 200, loss: 0.010733355768024921
step: 210, loss: 0.02750072069466114
step: 220, loss: 0.0003581491473596543
step: 230, loss: 0.03266865760087967
step: 240, loss: 0.11351726949214935
step: 250, loss: 0.029901422560214996
step: 260, loss: 0.025285692885518074
step: 270, loss: 0.07601216435432434
step: 280, loss: 0.00581855233758688
step: 290, loss: 0.03026914782822132
step: 300, loss: 0.06797894835472107
step: 310, loss: 0.07700369507074356
step: 320, loss: 0.05111432448029518
step: 330, loss: 0.13636887073516846
step: 340, loss: 0.03833125904202461
step: 350, loss: 0.04898151755332947
step: 360, loss: 0.06602517515420914
step: 370, loss: 0.05869400128722191
step: 380, loss: 0.03330853208899498
epoch 11: dev_f1=0.7223587223587223, f1=0.7222222222222223, best_f1=0.7281553398058251
step: 0, loss: 0.04193609952926636
step: 10, loss: 0.01036424282938242
step: 20, loss: 0.04095184803009033
step: 30, loss: 0.02383105643093586
step: 40, loss: 0.014873763546347618
step: 50, loss: 0.06708166748285294
step: 60, loss: 0.035410210490226746
step: 70, loss: 0.0758897140622139
step: 80, loss: 0.04928659275174141
step: 90, loss: 0.033295463770627975
step: 100, loss: 0.0849580317735672
step: 110, loss: 0.05069433152675629
step: 120, loss: 0.06099633872509003
step: 130, loss: 3.967302473029122e-05
step: 140, loss: 0.011694347485899925
step: 150, loss: 0.042755041271448135
step: 160, loss: 0.04375310614705086
step: 170, loss: 0.02019631490111351
step: 180, loss: 0.03278590366244316
step: 190, loss: 0.020972616970539093
step: 200, loss: 0.1931522935628891
step: 210, loss: 0.05015811324119568
step: 220, loss: 0.06396632641553879
step: 230, loss: 0.029489777982234955
step: 240, loss: 0.10928770154714584
step: 250, loss: 0.006113826762884855
step: 260, loss: 0.04635617882013321
step: 270, loss: 0.00940519105643034
step: 280, loss: 0.010491295717656612
step: 290, loss: 0.10385347157716751
step: 300, loss: 0.033869341015815735
step: 310, loss: 0.07816703617572784
step: 320, loss: 0.06215813755989075
step: 330, loss: 0.08055133372545242
step: 340, loss: 7.871046545915306e-05
step: 350, loss: 0.01327313669025898
step: 360, loss: 0.08985474705696106
step: 370, loss: 0.09177126735448837
step: 380, loss: 0.05061742290854454
epoch 12: dev_f1=0.7241379310344828, f1=0.7455012853470436, best_f1=0.7281553398058251
step: 0, loss: 0.03893151879310608
step: 10, loss: 0.05018183961510658
step: 20, loss: 0.02821986749768257
step: 30, loss: 0.058517519384622574
step: 40, loss: 0.021209003403782845
step: 50, loss: 0.0007467825780622661
step: 60, loss: 0.05375833064317703
step: 70, loss: 0.13878151774406433
step: 80, loss: 0.08070368319749832
step: 90, loss: 0.044414911419153214
step: 100, loss: 0.12694984674453735
step: 110, loss: 0.17312076687812805
step: 120, loss: 0.1526382714509964
step: 130, loss: 0.04673521965742111
step: 140, loss: 0.09058571606874466
step: 150, loss: 0.04686420038342476
step: 160, loss: 0.13479351997375488
step: 170, loss: 0.06467414647340775
step: 180, loss: 0.056776341050863266
step: 190, loss: 0.013118664734065533
step: 200, loss: 0.08466407656669617
step: 210, loss: 0.06483261287212372
step: 220, loss: 0.016260992735624313
step: 230, loss: 0.06410901248455048
step: 240, loss: 0.036726921796798706
step: 250, loss: 0.08233370631933212
step: 260, loss: 0.11238361150026321
step: 270, loss: 0.002362868282943964
step: 280, loss: 0.05679816007614136
step: 290, loss: 0.005012070294469595
step: 300, loss: 0.060955293476581573
step: 310, loss: 0.09654031693935394
step: 320, loss: 0.030636504292488098
step: 330, loss: 0.027035778388381004
step: 340, loss: 0.045437879860401154
step: 350, loss: 0.00010917452891590074
step: 360, loss: 0.01990620046854019
step: 370, loss: 0.11225371807813644
step: 380, loss: 0.0629882887005806
epoch 13: dev_f1=0.6962616822429907, f1=0.7002398081534772, best_f1=0.7281553398058251
step: 0, loss: 0.07795823365449905
step: 10, loss: 0.10599438846111298
step: 20, loss: 0.022785788401961327
step: 30, loss: 0.058732617646455765
step: 40, loss: 0.04962920770049095
step: 50, loss: 0.03809703513979912
step: 60, loss: 0.03273589164018631
step: 70, loss: 0.029514502733945847
step: 80, loss: 0.0037590793799608946
step: 90, loss: 0.07129060477018356
step: 100, loss: 0.02349809743463993
step: 110, loss: 0.060428958386182785
step: 120, loss: 0.04510793089866638
step: 130, loss: 0.05270957946777344
step: 140, loss: 0.13971562683582306
step: 150, loss: 0.028488794341683388
step: 160, loss: 0.04410692676901817
step: 170, loss: 0.027244985103607178
step: 180, loss: 0.011822382919490337
step: 190, loss: 0.0002715675800573081
step: 200, loss: 0.018000982701778412
step: 210, loss: 0.020311854779720306
step: 220, loss: 5.5780641559977084e-05
step: 230, loss: 2.4944152755779214e-05
step: 240, loss: 0.051244646310806274
step: 250, loss: 0.0762324333190918
step: 260, loss: 0.030545935034751892
step: 270, loss: 0.028151722624897957
step: 280, loss: 0.017572151497006416
step: 290, loss: 0.0965685248374939
step: 300, loss: 0.0811891257762909
step: 310, loss: 0.02431504987180233
step: 320, loss: 0.0879194363951683
step: 330, loss: 0.012260484509170055
step: 340, loss: 0.06437815725803375
step: 350, loss: 0.12559348344802856
step: 360, loss: 0.04034985974431038
step: 370, loss: 0.03392941877245903
step: 380, loss: 0.013413450680673122
epoch 14: dev_f1=0.7010869565217391, f1=0.7175141242937854, best_f1=0.7281553398058251
step: 0, loss: 0.10304419696331024
step: 10, loss: 0.02447366714477539
step: 20, loss: 0.015132220461964607
step: 30, loss: 0.02766939252614975
step: 40, loss: 0.015878506004810333
step: 50, loss: 0.03154277056455612
step: 60, loss: 0.03680019825696945
step: 70, loss: 0.07743683457374573
step: 80, loss: 0.0017077085794880986
step: 90, loss: 7.897090108599514e-05
step: 100, loss: 0.0003010367217939347
step: 110, loss: 0.0970296561717987
step: 120, loss: 0.054897043853998184
step: 130, loss: 0.09839197248220444
step: 140, loss: 0.16350184381008148
step: 150, loss: 0.0052280183881521225
step: 160, loss: 0.005888844840228558
step: 170, loss: 0.1017971932888031
step: 180, loss: 0.00014602576266042888
step: 190, loss: 0.02717173844575882
step: 200, loss: 0.02039053849875927
step: 210, loss: 0.044169068336486816
step: 220, loss: 0.05771958455443382
step: 230, loss: 0.018009569495916367
step: 240, loss: 0.05775519087910652
step: 250, loss: 0.049535058438777924
step: 260, loss: 0.030578341335058212
step: 270, loss: 0.01749221608042717
step: 280, loss: 0.04009825736284256
step: 290, loss: 0.04689178615808487
step: 300, loss: 7.498008926631883e-05
step: 310, loss: 0.028815599158406258
step: 320, loss: 0.09740106016397476
step: 330, loss: 0.06783630698919296
step: 340, loss: 0.04153360798954964
step: 350, loss: 0.007382330484688282
step: 360, loss: 0.1492125689983368
step: 370, loss: 0.05029745399951935
step: 380, loss: 0.004023618996143341
epoch 15: dev_f1=0.7184986595174263, f1=0.7103825136612021, best_f1=0.7281553398058251
step: 0, loss: 0.0563889816403389
step: 10, loss: 0.06889113783836365
step: 20, loss: 0.008919267915189266
step: 30, loss: 0.13332317769527435
step: 40, loss: 0.20174142718315125
step: 50, loss: 0.0015627755783498287
step: 60, loss: 0.013556065037846565
step: 70, loss: 0.09412660449743271
step: 80, loss: 0.04993842542171478
step: 90, loss: 0.05195329710841179
step: 100, loss: 0.051097285002470016
step: 110, loss: 0.02758897840976715
step: 120, loss: 0.014228949323296547
step: 130, loss: 0.07221002876758575
step: 140, loss: 0.0443434976041317
step: 150, loss: 0.003092039842158556
step: 160, loss: 0.050928402692079544
step: 170, loss: 0.14447858929634094
step: 180, loss: 0.11142096668481827
step: 190, loss: 0.1159578263759613
step: 200, loss: 0.11128203570842743
step: 210, loss: 0.03805968165397644
step: 220, loss: 7.162945257732645e-05
step: 230, loss: 0.018923871219158173
step: 240, loss: 0.0385550931096077
step: 250, loss: 0.02885235846042633
step: 260, loss: 0.06961088627576828
step: 270, loss: 0.006851379293948412
step: 280, loss: 0.032134637236595154
step: 290, loss: 0.023799926042556763
step: 300, loss: 0.05316701531410217
step: 310, loss: 0.027268216013908386
step: 320, loss: 0.023305408656597137
step: 330, loss: 0.026490582153201103
step: 340, loss: 0.03409463167190552
step: 350, loss: 0.0882180705666542
step: 360, loss: 0.0504472479224205
step: 370, loss: 0.005974976811558008
step: 380, loss: 0.1041543260216713
epoch 16: dev_f1=0.716577540106952, f1=0.7292225201072386, best_f1=0.7281553398058251
step: 0, loss: 0.01971299946308136
step: 10, loss: 0.057985156774520874
step: 20, loss: 0.03698454797267914
step: 30, loss: 0.06577056646347046
step: 40, loss: 0.0134583143517375
step: 50, loss: 0.005418242886662483
step: 60, loss: 0.003409225959330797
step: 70, loss: 0.031114837154746056
step: 80, loss: 0.06117050349712372
step: 90, loss: 0.015659483149647713
step: 100, loss: 0.03828487917780876
step: 110, loss: 0.08457264304161072
step: 120, loss: 2.7811040126834996e-05
step: 130, loss: 0.011535758152604103
step: 140, loss: 0.02651284635066986
step: 150, loss: 0.01375542301684618
step: 160, loss: 0.0012969315284863114
step: 170, loss: 0.04099477827548981
step: 180, loss: 0.0008522595162503421
step: 190, loss: 0.020471710711717606
step: 200, loss: 0.00016755772230681032
step: 210, loss: 0.0032416065223515034
step: 220, loss: 0.10048266500234604
step: 230, loss: 0.0565846785902977
step: 240, loss: 0.05793144553899765
step: 250, loss: 0.04212871566414833
step: 260, loss: 0.00784240197390318
step: 270, loss: 0.14887499809265137
step: 280, loss: 0.019146237522363663
step: 290, loss: 0.03301861137151718
step: 300, loss: 0.06933299452066422
step: 310, loss: 0.0001791443646652624
step: 320, loss: 0.027429379522800446
step: 330, loss: 0.008802215568721294
step: 340, loss: 0.009143553674221039
step: 350, loss: 0.013031143695116043
step: 360, loss: 0.00868112500756979
step: 370, loss: 0.013446370139718056
step: 380, loss: 0.05804448947310448
epoch 17: dev_f1=0.707182320441989, f1=0.7138810198300283, best_f1=0.7281553398058251
step: 0, loss: 0.025087134912610054
step: 10, loss: 0.0016126082045957446
step: 20, loss: 0.1124805435538292
step: 30, loss: 0.023375727236270905
step: 40, loss: 0.056720081716775894
step: 50, loss: 0.021452561020851135
step: 60, loss: 0.019404662773013115
step: 70, loss: 0.020613064989447594
step: 80, loss: 0.1034795269370079
step: 90, loss: 0.0031532514840364456
step: 100, loss: 0.00018735634512268007
step: 110, loss: 0.023589814081788063
step: 120, loss: 0.0001348633668385446
step: 130, loss: 0.027516786009073257
step: 140, loss: 0.015344241634011269
step: 150, loss: 0.11401743441820145
step: 160, loss: 0.01278721820563078
step: 170, loss: 0.00019724815501831472
step: 180, loss: 0.02324024587869644
step: 190, loss: 0.015712672844529152
step: 200, loss: 0.0329810306429863
step: 210, loss: 0.03435664251446724
step: 220, loss: 0.09351687133312225
step: 230, loss: 0.0027628690004348755
step: 240, loss: 0.10640934854745865
step: 250, loss: 0.003953772131353617
step: 260, loss: 0.021901847794651985
step: 270, loss: 0.03262205794453621
step: 280, loss: 0.019930733367800713
step: 290, loss: 0.025830432772636414
step: 300, loss: 5.102774957777001e-05
step: 310, loss: 0.032053712755441666
step: 320, loss: 0.105317622423172
step: 330, loss: 0.06879741698503494
step: 340, loss: 0.018483495339751244
step: 350, loss: 0.1506725698709488
step: 360, loss: 0.03126903250813484
step: 370, loss: 0.09082924574613571
step: 380, loss: 0.052816569805145264
epoch 18: dev_f1=0.6994535519125683, f1=0.7055555555555556, best_f1=0.7281553398058251
step: 0, loss: 0.05704232305288315
step: 10, loss: 0.024517446756362915
step: 20, loss: 0.014836038462817669
step: 30, loss: 0.06739486008882523
step: 40, loss: 0.05862622335553169
step: 50, loss: 0.03333210200071335
step: 60, loss: 0.04922941327095032
step: 70, loss: 0.02048303559422493
step: 80, loss: 0.07303560525178909
step: 90, loss: 0.007298556622117758
step: 100, loss: 0.0025207544676959515
step: 110, loss: 0.033738356083631516
step: 120, loss: 0.01103910431265831
step: 130, loss: 0.02399451844394207
step: 140, loss: 5.995641913614236e-05
step: 150, loss: 0.024895079433918
step: 160, loss: 0.01844983920454979
step: 170, loss: 0.014863068237900734
step: 180, loss: 0.0927366316318512
step: 190, loss: 0.09547466039657593
step: 200, loss: 0.05985962226986885
step: 210, loss: 0.06124745309352875
step: 220, loss: 0.00924444105476141
step: 230, loss: 0.11094946414232254
step: 240, loss: 0.03860367089509964
step: 250, loss: 0.018594294786453247
step: 260, loss: 0.0001249464403372258
step: 270, loss: 0.07292452454566956
step: 280, loss: 0.030358729884028435
step: 290, loss: 0.00469567347317934
step: 300, loss: 0.010048442520201206
step: 310, loss: 0.02649214118719101
step: 320, loss: 3.891775486408733e-05
step: 330, loss: 0.06335395574569702
step: 340, loss: 0.008340083062648773
step: 350, loss: 0.04396066442131996
step: 360, loss: 0.055203650146722794
step: 370, loss: 0.07849707454442978
step: 380, loss: 0.03879998251795769
epoch 19: dev_f1=0.6890756302521008, f1=0.7008547008547008, best_f1=0.7281553398058251
step: 0, loss: 0.02622108906507492
step: 10, loss: 0.008484982885420322
step: 20, loss: 0.008803300559520721
step: 30, loss: 0.003076067892834544
step: 40, loss: 0.021486420184373856
step: 50, loss: 0.04544577747583389
step: 60, loss: 0.017169995233416557
step: 70, loss: 0.06119279935956001
step: 80, loss: 0.011740969493985176
step: 90, loss: 0.005171367432922125
step: 100, loss: 0.057132281363010406
step: 110, loss: 0.03359536454081535
step: 120, loss: 0.04920192062854767
step: 130, loss: 0.04362786188721657
step: 140, loss: 0.07306968420743942
step: 150, loss: 0.08416762948036194
step: 160, loss: 0.0680774450302124
step: 170, loss: 0.08459131419658661
step: 180, loss: 0.013079698197543621
step: 190, loss: 0.004432076122611761
step: 200, loss: 0.003853228408843279
step: 210, loss: 0.0202019140124321
step: 220, loss: 0.01712770201265812
step: 230, loss: 0.030627189204096794
step: 240, loss: 0.005115012638270855
step: 250, loss: 7.277680560946465e-05
step: 260, loss: 0.06167695298790932
step: 270, loss: 0.052634622901678085
step: 280, loss: 0.08574984222650528
step: 290, loss: 8.772781438892707e-05
step: 300, loss: 0.03894462436437607
step: 310, loss: 0.03373261168599129
step: 320, loss: 0.007243197876960039
step: 330, loss: 0.04186461493372917
step: 340, loss: 0.1287931203842163
step: 350, loss: 0.05100275203585625
step: 360, loss: 0.02216123603284359
step: 370, loss: 0.10633647441864014
step: 380, loss: 0.03170217201113701
epoch 20: dev_f1=0.6890756302521008, f1=0.7008547008547008, best_f1=0.7281553398058251
