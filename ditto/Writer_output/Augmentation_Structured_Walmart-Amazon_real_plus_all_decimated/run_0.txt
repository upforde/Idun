cuda
Device: cuda
step: 0, loss: 0.6921446323394775
step: 10, loss: 0.11112809926271439
step: 20, loss: 0.2341592013835907
step: 30, loss: 0.304649293422699
step: 40, loss: 0.3011895418167114
step: 50, loss: 0.39153313636779785
step: 60, loss: 0.33105164766311646
step: 70, loss: 0.29018843173980713
step: 80, loss: 0.20258180797100067
step: 90, loss: 0.34979116916656494
step: 100, loss: 0.322267085313797
step: 110, loss: 0.28455623984336853
step: 120, loss: 0.4713713526725769
step: 130, loss: 0.2750474512577057
step: 140, loss: 0.16118204593658447
step: 150, loss: 0.12740425765514374
step: 160, loss: 0.23317083716392517
step: 170, loss: 0.27287009358406067
step: 180, loss: 0.11352912336587906
step: 190, loss: 0.253746896982193
step: 200, loss: 0.3314642906188965
step: 210, loss: 0.24284934997558594
step: 220, loss: 0.18315765261650085
step: 230, loss: 0.2048518806695938
step: 240, loss: 0.14639219641685486
step: 250, loss: 0.33878791332244873
step: 260, loss: 0.048100318759679794
step: 270, loss: 0.19404855370521545
step: 280, loss: 0.2200019508600235
step: 290, loss: 0.26897284388542175
step: 300, loss: 0.3378615379333496
step: 310, loss: 0.05220436677336693
step: 320, loss: 0.38343727588653564
step: 330, loss: 0.06055370345711708
step: 340, loss: 0.13292646408081055
step: 350, loss: 0.31380516290664673
step: 360, loss: 0.07395128160715103
step: 370, loss: 0.1626613289117813
step: 380, loss: 0.050338972359895706
epoch 1: dev_f1=0.6138107416879796, f1=0.6277372262773723, best_f1=0.6277372262773723
step: 0, loss: 0.169016033411026
step: 10, loss: 0.07209368050098419
step: 20, loss: 0.13048821687698364
step: 30, loss: 0.07919865846633911
step: 40, loss: 0.08109685778617859
step: 50, loss: 0.07998724281787872
step: 60, loss: 0.045971546322107315
step: 70, loss: 0.18131513893604279
step: 80, loss: 0.11042515188455582
step: 90, loss: 0.09302791208028793
step: 100, loss: 0.16991479694843292
step: 110, loss: 0.01484706625342369
step: 120, loss: 0.2690061628818512
step: 130, loss: 0.08179369568824768
step: 140, loss: 0.028970487415790558
step: 150, loss: 0.09797509759664536
step: 160, loss: 0.11352547258138657
step: 170, loss: 0.1913571059703827
step: 180, loss: 0.050664711743593216
step: 190, loss: 0.02870568260550499
step: 200, loss: 0.11494135111570358
step: 210, loss: 0.14106237888336182
step: 220, loss: 0.06232837587594986
step: 230, loss: 0.09186851978302002
step: 240, loss: 0.0026060151867568493
step: 250, loss: 0.06741693615913391
step: 260, loss: 0.24650351703166962
step: 270, loss: 0.04864681884646416
step: 280, loss: 0.09978336095809937
step: 290, loss: 0.14713752269744873
step: 300, loss: 0.11414080113172531
step: 310, loss: 0.07856028527021408
step: 320, loss: 0.11590652912855148
step: 330, loss: 0.005068931262940168
step: 340, loss: 0.1809222549200058
step: 350, loss: 0.10956557840108871
step: 360, loss: 0.12729239463806152
step: 370, loss: 0.2367771416902542
step: 380, loss: 0.044987186789512634
epoch 2: dev_f1=0.6963350785340314, f1=0.7214854111405835, best_f1=0.7214854111405835
step: 0, loss: 0.11283531785011292
step: 10, loss: 0.09834486991167068
step: 20, loss: 0.1495073139667511
step: 30, loss: 0.016912110149860382
step: 40, loss: 0.042072687298059464
step: 50, loss: 0.12630732357501984
step: 60, loss: 0.23967628180980682
step: 70, loss: 0.110697902739048
step: 80, loss: 0.05064007267355919
step: 90, loss: 0.08633830398321152
step: 100, loss: 0.09522108733654022
step: 110, loss: 0.07966279983520508
step: 120, loss: 0.038189422339200974
step: 130, loss: 0.14659781754016876
step: 140, loss: 0.06974198669195175
step: 150, loss: 0.05830652639269829
step: 160, loss: 0.039761416614055634
step: 170, loss: 0.13242332637310028
step: 180, loss: 0.04410422965884209
step: 190, loss: 0.10513617098331451
step: 200, loss: 0.07790961116552353
step: 210, loss: 0.17205661535263062
step: 220, loss: 0.14080019295215607
step: 230, loss: 0.029294010251760483
step: 240, loss: 0.02508583851158619
step: 250, loss: 0.0983211100101471
step: 260, loss: 0.09940383583307266
step: 270, loss: 0.05427958071231842
step: 280, loss: 0.073088638484478
step: 290, loss: 0.00883548241108656
step: 300, loss: 0.04727594926953316
step: 310, loss: 0.08904725313186646
step: 320, loss: 0.07762204855680466
step: 330, loss: 0.04601452872157097
step: 340, loss: 0.026508713141083717
step: 350, loss: 0.08226948231458664
step: 360, loss: 0.022893186658620834
step: 370, loss: 0.18348364531993866
step: 380, loss: 0.07177747786045074
epoch 3: dev_f1=0.6951871657754011, f1=0.6787564766839378, best_f1=0.7214854111405835
step: 0, loss: 0.07321923971176147
step: 10, loss: 0.07595884799957275
step: 20, loss: 0.14182011783123016
step: 30, loss: 0.1029912531375885
step: 40, loss: 0.08115518093109131
step: 50, loss: 0.12070318311452866
step: 60, loss: 0.04591713473200798
step: 70, loss: 0.1483391374349594
step: 80, loss: 0.000860593921970576
step: 90, loss: 0.035102225840091705
step: 100, loss: 0.08519266545772552
step: 110, loss: 0.09685806930065155
step: 120, loss: 0.05407736077904701
step: 130, loss: 0.09091442823410034
step: 140, loss: 0.031955111771821976
step: 150, loss: 0.10515639930963516
step: 160, loss: 0.06220250949263573
step: 170, loss: 0.1761549413204193
step: 180, loss: 0.05318956822156906
step: 190, loss: 0.09512988477945328
step: 200, loss: 0.038921650499105453
step: 210, loss: 0.055131856352090836
step: 220, loss: 0.08489963412284851
step: 230, loss: 0.029093360528349876
step: 240, loss: 0.17186450958251953
step: 250, loss: 0.25720736384391785
step: 260, loss: 0.03409813717007637
step: 270, loss: 0.021837297827005386
step: 280, loss: 0.04172390326857567
step: 290, loss: 0.05209730565547943
step: 300, loss: 0.016321875154972076
step: 310, loss: 0.05387374386191368
step: 320, loss: 0.13415472209453583
step: 330, loss: 0.042106058448553085
step: 340, loss: 0.054922766983509064
step: 350, loss: 0.07838588207960129
step: 360, loss: 0.02417256310582161
step: 370, loss: 0.18574164807796478
step: 380, loss: 0.09103485941886902
epoch 4: dev_f1=0.7352185089974292, f1=0.7253886010362695, best_f1=0.7253886010362695
step: 0, loss: 0.023306338116526604
step: 10, loss: 0.153702512383461
step: 20, loss: 0.03218144178390503
step: 30, loss: 0.0945652648806572
step: 40, loss: 0.010719561949372292
step: 50, loss: 0.08738388866186142
step: 60, loss: 0.05733482539653778
step: 70, loss: 0.03757169842720032
step: 80, loss: 0.05722581967711449
step: 90, loss: 0.30645182728767395
step: 100, loss: 0.04964909702539444
step: 110, loss: 0.06433984637260437
step: 120, loss: 0.02785804308950901
step: 130, loss: 0.049849770963191986
step: 140, loss: 0.07564378529787064
step: 150, loss: 0.053896065801382065
step: 160, loss: 0.03711722418665886
step: 170, loss: 0.03216627985239029
step: 180, loss: 0.013504426926374435
step: 190, loss: 0.058507371693849564
step: 200, loss: 0.03754838556051254
step: 210, loss: 0.01686239242553711
step: 220, loss: 0.053415242582559586
step: 230, loss: 0.014270143583416939
step: 240, loss: 0.03995101526379585
step: 250, loss: 0.02370339073240757
step: 260, loss: 0.09205203503370285
step: 270, loss: 0.12173570692539215
step: 280, loss: 0.10018309950828552
step: 290, loss: 0.07831308245658875
step: 300, loss: 0.06452377140522003
step: 310, loss: 0.03600836545228958
step: 320, loss: 0.082613006234169
step: 330, loss: 0.06063693016767502
step: 340, loss: 0.07348265498876572
step: 350, loss: 0.004142399877309799
step: 360, loss: 0.10758569836616516
step: 370, loss: 0.27683258056640625
step: 380, loss: 0.07612736523151398
epoch 5: dev_f1=0.7381546134663343, f1=0.7295918367346937, best_f1=0.7295918367346937
step: 0, loss: 0.04487038776278496
step: 10, loss: 0.06532572954893112
step: 20, loss: 0.01536150649189949
step: 30, loss: 0.015473728068172932
step: 40, loss: 0.027316726744174957
step: 50, loss: 0.03353136032819748
step: 60, loss: 0.0969550609588623
step: 70, loss: 0.0027403468266129494
step: 80, loss: 0.04366142675280571
step: 90, loss: 0.016199707984924316
step: 100, loss: 0.019589165225625038
step: 110, loss: 0.05835270881652832
step: 120, loss: 0.01107512041926384
step: 130, loss: 0.22936172783374786
step: 140, loss: 0.11106685549020767
step: 150, loss: 0.026537485420703888
step: 160, loss: 0.0178229957818985
step: 170, loss: 0.09667032212018967
step: 180, loss: 0.10396185517311096
step: 190, loss: 0.06332240998744965
step: 200, loss: 0.07394246011972427
step: 210, loss: 0.05107691138982773
step: 220, loss: 0.05104142427444458
step: 230, loss: 0.23594999313354492
step: 240, loss: 0.06406287103891373
step: 250, loss: 0.09383372962474823
step: 260, loss: 0.056434694677591324
step: 270, loss: 0.04457216337323189
step: 280, loss: 0.030623022466897964
step: 290, loss: 0.030023695901036263
step: 300, loss: 0.05621625855565071
step: 310, loss: 0.06922092288732529
step: 320, loss: 0.041317787021398544
step: 330, loss: 0.0009284770349040627
step: 340, loss: 0.09541697055101395
step: 350, loss: 0.0695294663310051
step: 360, loss: 0.12846481800079346
step: 370, loss: 0.011993631720542908
step: 380, loss: 0.026387082412838936
epoch 6: dev_f1=0.7365853658536586, f1=0.7218045112781954, best_f1=0.7295918367346937
step: 0, loss: 0.008316232822835445
step: 10, loss: 0.06535568833351135
step: 20, loss: 0.009200168773531914
step: 30, loss: 0.07128145545721054
step: 40, loss: 0.0017782349605113268
step: 50, loss: 0.01057102158665657
step: 60, loss: 0.07113614678382874
step: 70, loss: 0.06058748811483383
step: 80, loss: 0.036212559789419174
step: 90, loss: 0.01191524975001812
step: 100, loss: 0.08161600679159164
step: 110, loss: 0.22354915738105774
step: 120, loss: 0.0515192411839962
step: 130, loss: 0.05655767023563385
step: 140, loss: 0.02239842340350151
step: 150, loss: 0.02795158512890339
step: 160, loss: 0.007365134544670582
step: 170, loss: 0.14846836030483246
step: 180, loss: 0.0076664043590426445
step: 190, loss: 0.016503706574440002
step: 200, loss: 0.04811321571469307
step: 210, loss: 0.04008594900369644
step: 220, loss: 0.0830649733543396
step: 230, loss: 0.00247368891723454
step: 240, loss: 0.1389644891023636
step: 250, loss: 0.006472585257142782
step: 260, loss: 0.027289997786283493
step: 270, loss: 0.09915877878665924
step: 280, loss: 0.010553304105997086
step: 290, loss: 0.014598531648516655
step: 300, loss: 0.22261659801006317
step: 310, loss: 0.006982593797147274
step: 320, loss: 0.11116620898246765
step: 330, loss: 0.009170973673462868
step: 340, loss: 0.05743224173784256
step: 350, loss: 0.0015742689138278365
step: 360, loss: 0.05673894286155701
step: 370, loss: 0.14550334215164185
step: 380, loss: 0.05519750341773033
epoch 7: dev_f1=0.749414519906323, f1=0.7482014388489209, best_f1=0.7482014388489209
step: 0, loss: 0.008615931496024132
step: 10, loss: 0.05406041070818901
step: 20, loss: 0.0024066914338618517
step: 30, loss: 0.02635679952800274
step: 40, loss: 0.017452439293265343
step: 50, loss: 0.06385307759046555
step: 60, loss: 0.020158279687166214
step: 70, loss: 0.003578834468498826
step: 80, loss: 0.026446856558322906
step: 90, loss: 0.10854524374008179
step: 100, loss: 0.025943055748939514
step: 110, loss: 0.12200294435024261
step: 120, loss: 0.030848512426018715
step: 130, loss: 0.032744407653808594
step: 140, loss: 0.08262648433446884
step: 150, loss: 0.10426881909370422
step: 160, loss: 0.1870156079530716
step: 170, loss: 0.054773177951574326
step: 180, loss: 0.035145409405231476
step: 190, loss: 0.005629519931972027
step: 200, loss: 0.003273331793025136
step: 210, loss: 0.0857134684920311
step: 220, loss: 0.01526658609509468
step: 230, loss: 0.015587235800921917
step: 240, loss: 0.009218115359544754
step: 250, loss: 0.07003901153802872
step: 260, loss: 0.04644305631518364
step: 270, loss: 0.001112537458539009
step: 280, loss: 0.005556168034672737
step: 290, loss: 0.1120728924870491
step: 300, loss: 0.02739236131310463
step: 310, loss: 0.10275933891534805
step: 320, loss: 0.0009033175883814692
step: 330, loss: 0.07821261137723923
step: 340, loss: 0.01874798908829689
step: 350, loss: 0.01258856151252985
step: 360, loss: 0.011174778454005718
step: 370, loss: 0.08067982643842697
step: 380, loss: 0.06533250212669373
epoch 8: dev_f1=0.7187499999999999, f1=0.6666666666666667, best_f1=0.7482014388489209
step: 0, loss: 0.08605697005987167
step: 10, loss: 0.13841578364372253
step: 20, loss: 0.001478443038649857
step: 30, loss: 0.00697588175535202
step: 40, loss: 0.1075412705540657
step: 50, loss: 0.024722779169678688
step: 60, loss: 0.0004161858814768493
step: 70, loss: 0.11458853632211685
step: 80, loss: 0.0029099928215146065
step: 90, loss: 0.043439511209726334
step: 100, loss: 0.021999139338731766
step: 110, loss: 0.05698291212320328
step: 120, loss: 0.05400494486093521
step: 130, loss: 0.027300074696540833
step: 140, loss: 0.17229613661766052
step: 150, loss: 0.01627102866768837
step: 160, loss: 0.037324029952287674
step: 170, loss: 0.1393110305070877
step: 180, loss: 0.00011499477841425687
step: 190, loss: 0.02264043129980564
step: 200, loss: 0.028505118563771248
step: 210, loss: 0.00924686435610056
step: 220, loss: 0.024244079366326332
step: 230, loss: 0.0652422085404396
step: 240, loss: 0.02874040976166725
step: 250, loss: 0.027249708771705627
step: 260, loss: 0.042683910578489304
step: 270, loss: 0.037005700170993805
step: 280, loss: 0.11396579444408417
step: 290, loss: 0.04599375277757645
step: 300, loss: 0.02288203500211239
step: 310, loss: 0.0011444977717474103
step: 320, loss: 0.09348179399967194
step: 330, loss: 0.026495831087231636
step: 340, loss: 0.029808789491653442
step: 350, loss: 0.004830579273402691
step: 360, loss: 0.03109177201986313
step: 370, loss: 0.042537566274404526
step: 380, loss: 0.023327849805355072
epoch 9: dev_f1=0.7411167512690356, f1=0.7295918367346937, best_f1=0.7482014388489209
step: 0, loss: 0.03400479629635811
step: 10, loss: 0.042393963783979416
step: 20, loss: 0.04247201606631279
step: 30, loss: 0.00012247805716469884
step: 40, loss: 0.031916238367557526
step: 50, loss: 0.021007904782891273
step: 60, loss: 8.068142778938636e-05
step: 70, loss: 0.05759231746196747
step: 80, loss: 0.004590398166328669
step: 90, loss: 0.051796313375234604
step: 100, loss: 0.047463059425354004
step: 110, loss: 0.03943699598312378
step: 120, loss: 0.008226076140999794
step: 130, loss: 0.08549408614635468
step: 140, loss: 0.06364583969116211
step: 150, loss: 0.13543200492858887
step: 160, loss: 0.04869053140282631
step: 170, loss: 0.0023283050395548344
step: 180, loss: 0.047538019716739655
step: 190, loss: 0.057895760983228683
step: 200, loss: 0.039084091782569885
step: 210, loss: 0.024844229221343994
step: 220, loss: 0.02839318849146366
step: 230, loss: 0.024484146386384964
step: 240, loss: 0.0010357374558225274
step: 250, loss: 0.09328760206699371
step: 260, loss: 0.04498367756605148
step: 270, loss: 0.06455247104167938
step: 280, loss: 0.0252168420702219
step: 290, loss: 0.06552233546972275
step: 300, loss: 0.026141531765460968
step: 310, loss: 0.039650384336709976
step: 320, loss: 0.001583907287567854
step: 330, loss: 0.03966135159134865
step: 340, loss: 0.013301768340170383
step: 350, loss: 0.0086241839453578
step: 360, loss: 0.0092675955966115
step: 370, loss: 0.02226436696946621
step: 380, loss: 0.12410079687833786
epoch 10: dev_f1=0.7091836734693878, f1=0.7091836734693878, best_f1=0.7482014388489209
step: 0, loss: 0.009966936893761158
step: 10, loss: 0.007698111701756716
step: 20, loss: 0.02134256809949875
step: 30, loss: 0.010498620569705963
step: 40, loss: 0.0017865581903606653
step: 50, loss: 0.10038938373327255
step: 60, loss: 0.03693631663918495
step: 70, loss: 0.023616675287485123
step: 80, loss: 0.003956857603043318
step: 90, loss: 0.09092974662780762
step: 100, loss: 0.004401411861181259
step: 110, loss: 0.08833099901676178
step: 120, loss: 0.016002509742975235
step: 130, loss: 0.0416543185710907
step: 140, loss: 0.05635201558470726
step: 150, loss: 0.018489543348550797
step: 160, loss: 0.001859035692177713
step: 170, loss: 0.03791232779622078
step: 180, loss: 0.041327957063913345
step: 190, loss: 0.05362118035554886
step: 200, loss: 0.03488828241825104
step: 210, loss: 0.017962021753191948
step: 220, loss: 0.08028070628643036
step: 230, loss: 0.047894787043333054
step: 240, loss: 0.02412058785557747
step: 250, loss: 0.042916882783174515
step: 260, loss: 0.0006514733540825546
step: 270, loss: 0.00012280046939849854
step: 280, loss: 0.03833532705903053
step: 290, loss: 0.05906906723976135
step: 300, loss: 0.011166035197675228
step: 310, loss: 0.08905767649412155
step: 320, loss: 0.0317678339779377
step: 330, loss: 0.05548328906297684
step: 340, loss: 0.053417082875967026
step: 350, loss: 0.042349688708782196
step: 360, loss: 0.13251663744449615
step: 370, loss: 0.04597185552120209
step: 380, loss: 0.00012935750419273973
epoch 11: dev_f1=0.7132867132867134, f1=0.738095238095238, best_f1=0.7482014388489209
step: 0, loss: 0.06576293706893921
step: 10, loss: 0.0005692217382602394
step: 20, loss: 0.09225919842720032
step: 30, loss: 0.007818079553544521
step: 40, loss: 0.09291013330221176
step: 50, loss: 0.07157059758901596
step: 60, loss: 0.005877115298062563
step: 70, loss: 0.05820170417428017
step: 80, loss: 0.017996713519096375
step: 90, loss: 0.03480716049671173
step: 100, loss: 0.02645743265748024
step: 110, loss: 0.33459028601646423
step: 120, loss: 0.03163807466626167
step: 130, loss: 0.011185950599610806
step: 140, loss: 0.009895573370158672
step: 150, loss: 0.04494309052824974
step: 160, loss: 0.019932951778173447
step: 170, loss: 0.1108081266283989
step: 180, loss: 0.02372700534760952
step: 190, loss: 0.18209512531757355
step: 200, loss: 0.006621297914534807
step: 210, loss: 0.00048683761269785464
step: 220, loss: 0.02973855659365654
step: 230, loss: 0.0033979900181293488
step: 240, loss: 0.041380107402801514
step: 250, loss: 0.014445565640926361
step: 260, loss: 0.0007512677693739533
step: 270, loss: 0.032256048172712326
step: 280, loss: 0.015021991916000843
step: 290, loss: 0.04013645648956299
step: 300, loss: 0.006310837343335152
step: 310, loss: 0.01886681653559208
step: 320, loss: 0.013389798812568188
step: 330, loss: 0.028700485825538635
step: 340, loss: 0.006818715948611498
step: 350, loss: 0.031455088406801224
step: 360, loss: 0.0008331704302690923
step: 370, loss: 0.014215103350579739
step: 380, loss: 0.06548121571540833
epoch 12: dev_f1=0.715, f1=0.724935732647815, best_f1=0.7482014388489209
step: 0, loss: 0.00542397890239954
step: 10, loss: 0.001057048444636166
step: 20, loss: 0.023043669760227203
step: 30, loss: 0.003325260942801833
step: 40, loss: 0.022388704121112823
step: 50, loss: 0.012803643941879272
step: 60, loss: 0.06003997102379799
step: 70, loss: 0.013006328605115414
step: 80, loss: 0.00031313596991822124
step: 90, loss: 0.055034808814525604
step: 100, loss: 0.010726310312747955
step: 110, loss: 0.07956255972385406
step: 120, loss: 0.004519286099821329
step: 130, loss: 0.009891771711409092
step: 140, loss: 0.16647592186927795
step: 150, loss: 0.1013328954577446
step: 160, loss: 0.0009012906230054796
step: 170, loss: 0.020686788484454155
step: 180, loss: 0.0075503019616007805
step: 190, loss: 0.03422659635543823
step: 200, loss: 0.0012188446708023548
step: 210, loss: 0.036979060620069504
step: 220, loss: 0.03042626567184925
step: 230, loss: 0.003632737323641777
step: 240, loss: 0.021690376102924347
step: 250, loss: 0.002422303892672062
step: 260, loss: 0.007711825426667929
step: 270, loss: 0.010967325419187546
step: 280, loss: 0.04655958339571953
step: 290, loss: 0.007867744192481041
step: 300, loss: 0.08080729842185974
step: 310, loss: 0.028908539563417435
step: 320, loss: 0.00028302642749622464
step: 330, loss: 0.05861404538154602
step: 340, loss: 0.017090201377868652
step: 350, loss: 0.0009718472720123827
step: 360, loss: 0.0768575370311737
step: 370, loss: 0.004094376694411039
step: 380, loss: 0.046697378158569336
epoch 13: dev_f1=0.7139240506329113, f1=0.7168831168831169, best_f1=0.7482014388489209
step: 0, loss: 0.030561363324522972
step: 10, loss: 0.023465953767299652
step: 20, loss: 0.01551134418696165
step: 30, loss: 0.0015247507253661752
step: 40, loss: 0.07623399794101715
step: 50, loss: 0.07277711480855942
step: 60, loss: 0.00011205333430552855
step: 70, loss: 0.020835455507040024
step: 80, loss: 0.11528033018112183
step: 90, loss: 0.004728052299469709
step: 100, loss: 0.0004886147798970342
step: 110, loss: 0.002436369424685836
step: 120, loss: 0.004996596835553646
step: 130, loss: 0.03529919683933258
step: 140, loss: 0.00015545047062914819
step: 150, loss: 5.403592876973562e-05
step: 160, loss: 0.022616872563958168
step: 170, loss: 4.371417162474245e-05
step: 180, loss: 0.021138235926628113
step: 190, loss: 0.01827831193804741
step: 200, loss: 0.010294497013092041
step: 210, loss: 0.00010421369370305911
step: 220, loss: 0.017561115324497223
step: 230, loss: 0.016217771917581558
step: 240, loss: 5.2768220484722406e-05
step: 250, loss: 0.013272472657263279
step: 260, loss: 0.027046162635087967
step: 270, loss: 0.003496242454275489
step: 280, loss: 0.00028350550564937294
step: 290, loss: 0.0014635830884799361
step: 300, loss: 0.005837175529450178
step: 310, loss: 0.02972542867064476
step: 320, loss: 0.00375937856733799
step: 330, loss: 0.07295483350753784
step: 340, loss: 0.002079564379528165
step: 350, loss: 0.020611776039004326
step: 360, loss: 0.03443704918026924
step: 370, loss: 4.737256313092075e-05
step: 380, loss: 0.02360295131802559
epoch 14: dev_f1=0.7309644670050761, f1=0.7258883248730965, best_f1=0.7482014388489209
step: 0, loss: 0.03290579095482826
step: 10, loss: 0.044561341404914856
step: 20, loss: 0.033599529415369034
step: 30, loss: 0.00023320052423514426
step: 40, loss: 0.06482957303524017
step: 50, loss: 0.00012499272997956723
step: 60, loss: 0.10176675766706467
step: 70, loss: 0.015638090670108795
step: 80, loss: 0.013655295595526695
step: 90, loss: 0.0474335215985775
step: 100, loss: 0.010198340751230717
step: 110, loss: 0.07463978976011276
step: 120, loss: 0.04369766637682915
step: 130, loss: 0.02413228712975979
step: 140, loss: 0.006357231643050909
step: 150, loss: 0.008842604234814644
step: 160, loss: 0.000367150641977787
step: 170, loss: 0.046781089156866074
step: 180, loss: 0.05045018345117569
step: 190, loss: 0.0012991448165848851
step: 200, loss: 0.00043709835154004395
step: 210, loss: 0.003066623816266656
step: 220, loss: 0.08040038496255875
step: 230, loss: 3.789929542108439e-05
step: 240, loss: 0.009062843397259712
step: 250, loss: 0.03794688358902931
step: 260, loss: 0.001962881302461028
step: 270, loss: 0.0005520417471416295
step: 280, loss: 0.012603649869561195
step: 290, loss: 0.0012077797437086701
step: 300, loss: 8.891900506569073e-05
step: 310, loss: 0.002257703570649028
step: 320, loss: 0.09269749373197556
step: 330, loss: 0.0028941668570041656
step: 340, loss: 0.02188209816813469
step: 350, loss: 0.006188292521983385
step: 360, loss: 0.05671883374452591
step: 370, loss: 0.0015685302205383778
step: 380, loss: 0.028722437098622322
epoch 15: dev_f1=0.7164948453608248, f1=0.7031250000000001, best_f1=0.7482014388489209
step: 0, loss: 0.00013869551185052842
step: 10, loss: 0.002301292959600687
step: 20, loss: 0.008530057035386562
step: 30, loss: 5.8817178796743974e-05
step: 40, loss: 0.0051661464385688305
step: 50, loss: 6.008125637890771e-05
step: 60, loss: 0.0214767474681139
step: 70, loss: 0.03824261948466301
step: 80, loss: 0.01507499534636736
step: 90, loss: 0.023764729499816895
step: 100, loss: 0.032538726925849915
step: 110, loss: 0.03344736620783806
step: 120, loss: 0.003904013428837061
step: 130, loss: 0.0011665322817862034
step: 140, loss: 3.442418892518617e-05
step: 150, loss: 0.01595504768192768
step: 160, loss: 0.0013456919696182013
step: 170, loss: 0.006467331666499376
step: 180, loss: 7.629967149114236e-05
step: 190, loss: 0.04269668459892273
step: 200, loss: 0.0052788639441132545
step: 210, loss: 0.03502339497208595
step: 220, loss: 3.095633292105049e-05
step: 230, loss: 0.013491868041455746
step: 240, loss: 0.01729142852127552
step: 250, loss: 0.030999407172203064
step: 260, loss: 0.015324248932301998
step: 270, loss: 0.01357948686927557
step: 280, loss: 0.028122877702116966
step: 290, loss: 0.17829233407974243
step: 300, loss: 0.030088119208812714
step: 310, loss: 0.00024066866899374872
step: 320, loss: 3.083714182139374e-05
step: 330, loss: 0.00010701085557229817
step: 340, loss: 0.044964082539081573
step: 350, loss: 0.004837058484554291
step: 360, loss: 0.051998596638441086
step: 370, loss: 0.05213639512658119
step: 380, loss: 0.017830077558755875
epoch 16: dev_f1=0.7105263157894737, f1=0.7120418848167539, best_f1=0.7482014388489209
step: 0, loss: 0.005941253621131182
step: 10, loss: 3.2683918107068166e-05
step: 20, loss: 8.767106919549406e-05
step: 30, loss: 0.0021545439958572388
step: 40, loss: 0.0002858484804164618
step: 50, loss: 0.0668288841843605
step: 60, loss: 0.008140270598232746
step: 70, loss: 0.05931956321001053
step: 80, loss: 0.020479775965213776
step: 90, loss: 0.0010164876002818346
step: 100, loss: 0.007716567721217871
step: 110, loss: 0.03113146871328354
step: 120, loss: 0.002214644104242325
step: 130, loss: 0.0012364296708256006
step: 140, loss: 0.08768799901008606
step: 150, loss: 0.000564117799513042
step: 160, loss: 0.00015552215336356312
step: 170, loss: 0.022221587598323822
step: 180, loss: 0.03372367098927498
step: 190, loss: 0.0020866948179900646
step: 200, loss: 0.011290006339550018
step: 210, loss: 0.0003097861190326512
step: 220, loss: 0.0011777074541896582
step: 230, loss: 0.03085995465517044
step: 240, loss: 0.00010369742085458711
step: 250, loss: 0.0029914446640759706
step: 260, loss: 0.09773340076208115
step: 270, loss: 0.00016401981702074409
step: 280, loss: 0.013314381241798401
step: 290, loss: 0.0021146524231880903
step: 300, loss: 0.08670505881309509
step: 310, loss: 0.00624989066272974
step: 320, loss: 0.04650533199310303
step: 330, loss: 0.03808576986193657
step: 340, loss: 0.0041190749034285545
step: 350, loss: 0.027043038979172707
step: 360, loss: 0.003798761172220111
step: 370, loss: 0.045544300228357315
step: 380, loss: 0.00031340611167252064
epoch 17: dev_f1=0.7046632124352331, f1=0.6997389033942559, best_f1=0.7482014388489209
step: 0, loss: 0.016433998942375183
step: 10, loss: 0.00010362954344600439
step: 20, loss: 4.593971243593842e-05
step: 30, loss: 0.00040688872104510665
step: 40, loss: 0.01459202915430069
step: 50, loss: 0.04203398898243904
step: 60, loss: 0.0002270054683322087
step: 70, loss: 5.250919275567867e-05
step: 80, loss: 0.024061884731054306
step: 90, loss: 0.03443971276283264
step: 100, loss: 0.0011900459649041295
step: 110, loss: 0.0007178814266808331
step: 120, loss: 0.018666956573724747
step: 130, loss: 0.03653183579444885
step: 140, loss: 0.0786135271191597
step: 150, loss: 0.026234548538923264
step: 160, loss: 0.1048838272690773
step: 170, loss: 0.008811582811176777
step: 180, loss: 0.0120734553784132
step: 190, loss: 0.012601624242961407
step: 200, loss: 0.02664278820157051
step: 210, loss: 0.022913912311196327
step: 220, loss: 0.021517783403396606
step: 230, loss: 1.974752376554534e-05
step: 240, loss: 4.018258914584294e-05
step: 250, loss: 0.023959610611200333
step: 260, loss: 0.034929752349853516
step: 270, loss: 4.5036027586320415e-05
step: 280, loss: 0.038267046213150024
step: 290, loss: 0.04130370542407036
step: 300, loss: 0.022690923884510994
step: 310, loss: 0.0009878792334347963
step: 320, loss: 0.0062624188140034676
step: 330, loss: 0.023515917360782623
step: 340, loss: 0.05843619629740715
step: 350, loss: 5.533735384233296e-05
step: 360, loss: 0.018740052357316017
step: 370, loss: 0.013683807104825974
step: 380, loss: 0.012704001739621162
epoch 18: dev_f1=0.7187499999999999, f1=0.7086614173228346, best_f1=0.7482014388489209
step: 0, loss: 0.005984901916235685
step: 10, loss: 0.0004907667171210051
step: 20, loss: 0.00027650673291645944
step: 30, loss: 0.07305936515331268
step: 40, loss: 0.021345442160964012
step: 50, loss: 0.0004719225689768791
step: 60, loss: 0.000632085429970175
step: 70, loss: 0.010875663720071316
step: 80, loss: 0.012370438314974308
step: 90, loss: 0.05212975665926933
step: 100, loss: 0.016358178108930588
step: 110, loss: 0.0020804477389901876
step: 120, loss: 0.0001484214299125597
step: 130, loss: 0.07220962643623352
step: 140, loss: 0.003893285058438778
step: 150, loss: 0.018350863829255104
step: 160, loss: 0.02054717391729355
step: 170, loss: 0.03463926538825035
step: 180, loss: 0.0014425116823986173
step: 190, loss: 0.0036991089582443237
step: 200, loss: 7.970954902702942e-05
step: 210, loss: 0.005954013671725988
step: 220, loss: 2.0295083231758326e-05
step: 230, loss: 8.899377280613407e-05
step: 240, loss: 0.00022180781525094062
step: 250, loss: 5.740276901633479e-05
step: 260, loss: 0.0028734952211380005
step: 270, loss: 0.00019597858772613108
step: 280, loss: 0.03711826354265213
step: 290, loss: 0.00011566995817702264
step: 300, loss: 0.010139737278223038
step: 310, loss: 0.03441409766674042
step: 320, loss: 5.386697739595547e-05
step: 330, loss: 0.040204569697380066
step: 340, loss: 0.02163074165582657
step: 350, loss: 0.031956300139427185
step: 360, loss: 0.022919578477740288
step: 370, loss: 0.0008247322402894497
step: 380, loss: 2.6229010472889058e-05
epoch 19: dev_f1=0.7157894736842104, f1=0.7112299465240641, best_f1=0.7482014388489209
step: 0, loss: 0.0017924353014677763
step: 10, loss: 4.1381321352673694e-05
step: 20, loss: 0.00043114216532558203
step: 30, loss: 3.7928435631329194e-05
step: 40, loss: 2.5446835934417322e-05
step: 50, loss: 0.00015641990466974676
step: 60, loss: 3.392758662812412e-05
step: 70, loss: 0.022198539227247238
step: 80, loss: 0.047835707664489746
step: 90, loss: 0.05468519777059555
step: 100, loss: 0.05236572399735451
step: 110, loss: 0.001650236896239221
step: 120, loss: 6.552720151375979e-05
step: 130, loss: 0.0006547172088176012
step: 140, loss: 0.005295256618410349
step: 150, loss: 0.0001648313191253692
step: 160, loss: 0.015016254968941212
step: 170, loss: 0.00130289769731462
step: 180, loss: 0.026899201795458794
step: 190, loss: 0.0005721515044569969
step: 200, loss: 0.06030166894197464
step: 210, loss: 0.015338324941694736
step: 220, loss: 0.007865207269787788
step: 230, loss: 0.02905690297484398
step: 240, loss: 0.04129743576049805
step: 250, loss: 0.04304816201329231
step: 260, loss: 0.00015425359015353024
step: 270, loss: 7.868419197620824e-05
step: 280, loss: 1.9024837456527166e-05
step: 290, loss: 4.983065809938125e-05
step: 300, loss: 0.00038722489261999726
step: 310, loss: 0.002151941880583763
step: 320, loss: 5.587097257375717e-05
step: 330, loss: 0.00011201365850865841
step: 340, loss: 0.0001005085650831461
step: 350, loss: 0.009670042432844639
step: 360, loss: 2.7536338166100904e-05
step: 370, loss: 0.039721034467220306
step: 380, loss: 0.015260598622262478
epoch 20: dev_f1=0.7139107611548556, f1=0.7112299465240641, best_f1=0.7482014388489209
