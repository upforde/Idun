cuda
Device: cuda
step: 0, loss: 0.5832355618476868
step: 10, loss: 0.294499009847641
step: 20, loss: 0.3840445280075073
step: 30, loss: 0.3759500980377197
step: 40, loss: 0.1415664255619049
step: 50, loss: 0.3177834749221802
step: 60, loss: 0.40735191106796265
step: 70, loss: 0.5612050294876099
step: 80, loss: 0.16108256578445435
step: 90, loss: 0.1599694937467575
step: 100, loss: 0.2403993308544159
step: 110, loss: 0.2525782287120819
step: 120, loss: 0.3275635838508606
step: 130, loss: 0.3219268023967743
step: 140, loss: 0.4585518538951874
step: 150, loss: 0.45106279850006104
step: 160, loss: 0.31385424733161926
step: 170, loss: 0.37071123719215393
step: 180, loss: 0.3933086097240448
step: 190, loss: 0.2901044189929962
step: 200, loss: 0.3013625741004944
step: 210, loss: 0.28182917833328247
step: 220, loss: 0.24881073832511902
step: 230, loss: 0.17257459461688995
step: 240, loss: 0.3333314061164856
step: 250, loss: 0.4643711447715759
step: 260, loss: 0.1525498628616333
step: 270, loss: 0.11403585225343704
step: 280, loss: 0.08326268196105957
step: 290, loss: 0.21667735278606415
step: 300, loss: 0.1570098102092743
step: 310, loss: 0.037172093987464905
step: 320, loss: 0.06951386481523514
step: 330, loss: 0.10576535016298294
step: 340, loss: 0.20742914080619812
step: 350, loss: 0.16858415305614471
step: 360, loss: 0.30209967494010925
step: 370, loss: 0.2143423706293106
step: 380, loss: 0.1566065102815628
epoch 1: dev_f1=0.6160164271047228, f1=0.616600790513834, best_f1=0.616600790513834
step: 0, loss: 0.11320506036281586
step: 10, loss: 0.16172382235527039
step: 20, loss: 0.04242187738418579
step: 30, loss: 0.3971330523490906
step: 40, loss: 0.019803376868367195
step: 50, loss: 0.09742598980665207
step: 60, loss: 0.0388173945248127
step: 70, loss: 0.13699202239513397
step: 80, loss: 0.24938128888607025
step: 90, loss: 0.09758509695529938
step: 100, loss: 0.07827126234769821
step: 110, loss: 0.06110326945781708
step: 120, loss: 0.12319447100162506
step: 130, loss: 0.19003500044345856
step: 140, loss: 0.14251986145973206
step: 150, loss: 0.09469165652990341
step: 160, loss: 0.09406279027462006
step: 170, loss: 0.062187038362026215
step: 180, loss: 0.32775405049324036
step: 190, loss: 0.04005734622478485
step: 200, loss: 0.06334985792636871
step: 210, loss: 0.08159113675355911
step: 220, loss: 0.04836920648813248
step: 230, loss: 0.12032192200422287
step: 240, loss: 0.060552168637514114
step: 250, loss: 0.1311769038438797
step: 260, loss: 0.05214838683605194
step: 270, loss: 0.07173877954483032
step: 280, loss: 0.018317973241209984
step: 290, loss: 0.18206709623336792
step: 300, loss: 0.18926864862442017
step: 310, loss: 0.22048234939575195
step: 320, loss: 0.021253881976008415
step: 330, loss: 0.05822218582034111
step: 340, loss: 0.14993001520633698
step: 350, loss: 0.07736890763044357
step: 360, loss: 0.06976103782653809
step: 370, loss: 0.12919354438781738
step: 380, loss: 0.10168918967247009
epoch 2: dev_f1=0.6651583710407241, f1=0.6651376146788991, best_f1=0.6651376146788991
step: 0, loss: 0.2024688571691513
step: 10, loss: 0.13069269061088562
step: 20, loss: 0.143110454082489
step: 30, loss: 0.08543266355991364
step: 40, loss: 0.1793067306280136
step: 50, loss: 0.026604119688272476
step: 60, loss: 0.04165403172373772
step: 70, loss: 0.030932631343603134
step: 80, loss: 0.15019287168979645
step: 90, loss: 0.06498529762029648
step: 100, loss: 0.1460491567850113
step: 110, loss: 0.007605713792145252
step: 120, loss: 0.07577061653137207
step: 130, loss: 0.18119528889656067
step: 140, loss: 0.06911014765501022
step: 150, loss: 0.07528480142354965
step: 160, loss: 0.06221882253885269
step: 170, loss: 0.019350169226527214
step: 180, loss: 0.05485016107559204
step: 190, loss: 0.017748704180121422
step: 200, loss: 0.08245617896318436
step: 210, loss: 0.1486211121082306
step: 220, loss: 0.0050187986344099045
step: 230, loss: 0.029076892882585526
step: 240, loss: 0.15760105848312378
step: 250, loss: 0.04368017986416817
step: 260, loss: 0.05531342327594757
step: 270, loss: 0.08649472147226334
step: 280, loss: 0.04103254899382591
step: 290, loss: 0.019898412749171257
step: 300, loss: 0.08442217111587524
step: 310, loss: 0.10859915614128113
step: 320, loss: 0.03450696915388107
step: 330, loss: 0.0010781240416690707
step: 340, loss: 0.005976573564112186
step: 350, loss: 0.10120800137519836
step: 360, loss: 0.01959189400076866
step: 370, loss: 0.11953755468130112
step: 380, loss: 0.10959046334028244
epoch 3: dev_f1=0.7219251336898397, f1=0.7204030226700252, best_f1=0.7204030226700252
step: 0, loss: 0.0916161984205246
step: 10, loss: 0.018407797440886497
step: 20, loss: 0.057175636291503906
step: 30, loss: 0.05217933654785156
step: 40, loss: 0.03788561001420021
step: 50, loss: 0.1674603968858719
step: 60, loss: 0.09887556731700897
step: 70, loss: 0.059420809149742126
step: 80, loss: 0.06015538051724434
step: 90, loss: 0.10076874494552612
step: 100, loss: 0.17357094585895538
step: 110, loss: 0.04224226251244545
step: 120, loss: 0.07468904554843903
step: 130, loss: 0.031920142471790314
step: 140, loss: 0.00530638825148344
step: 150, loss: 0.05001726746559143
step: 160, loss: 0.07914532721042633
step: 170, loss: 0.11127343773841858
step: 180, loss: 0.1706266701221466
step: 190, loss: 0.10089275240898132
step: 200, loss: 0.12013997882604599
step: 210, loss: 0.03214799240231514
step: 220, loss: 0.07010333240032196
step: 230, loss: 0.07035966217517853
step: 240, loss: 0.07112143933773041
step: 250, loss: 0.0031065300572663546
step: 260, loss: 0.06512300670146942
step: 270, loss: 0.04533448815345764
step: 280, loss: 0.07559002190828323
step: 290, loss: 0.06371206045150757
step: 300, loss: 0.024775713682174683
step: 310, loss: 0.00018370203906670213
step: 320, loss: 0.05325333774089813
step: 330, loss: 0.05213585123419762
step: 340, loss: 0.04685875028371811
step: 350, loss: 0.06769988685846329
step: 360, loss: 0.010548016987740993
step: 370, loss: 0.016266928985714912
step: 380, loss: 0.03247053548693657
epoch 4: dev_f1=0.7231920199501246, f1=0.743142144638404, best_f1=0.743142144638404
step: 0, loss: 0.09743906557559967
step: 10, loss: 0.05018565058708191
step: 20, loss: 0.04483865201473236
step: 30, loss: 0.019436461851000786
step: 40, loss: 0.07844218611717224
step: 50, loss: 0.0005601609591394663
step: 60, loss: 0.05307877063751221
step: 70, loss: 0.12248622626066208
step: 80, loss: 0.06995644420385361
step: 90, loss: 0.03309742733836174
step: 100, loss: 0.08869437873363495
step: 110, loss: 0.048993490636348724
step: 120, loss: 0.1372733861207962
step: 130, loss: 0.06841908395290375
step: 140, loss: 0.04997657611966133
step: 150, loss: 0.07520343363285065
step: 160, loss: 0.10927347093820572
step: 170, loss: 0.004862239584326744
step: 180, loss: 0.006206737365573645
step: 190, loss: 0.02797893062233925
step: 200, loss: 0.19268359243869781
step: 210, loss: 0.0872734785079956
step: 220, loss: 0.013300323858857155
step: 230, loss: 0.05983179062604904
step: 240, loss: 0.032160624861717224
step: 250, loss: 0.3112708032131195
step: 260, loss: 0.014152726158499718
step: 270, loss: 0.023609710857272148
step: 280, loss: 0.19530339539051056
step: 290, loss: 0.20149433612823486
step: 300, loss: 0.05903778225183487
step: 310, loss: 0.020511412993073463
step: 320, loss: 0.10330799221992493
step: 330, loss: 0.04937954619526863
step: 340, loss: 0.0011435815831646323
step: 350, loss: 0.057085443288087845
step: 360, loss: 0.08104684203863144
step: 370, loss: 0.03254764527082443
step: 380, loss: 0.010155674070119858
epoch 5: dev_f1=0.7139240506329113, f1=0.7116883116883116, best_f1=0.743142144638404
step: 0, loss: 0.07080400735139847
step: 10, loss: 0.02561092935502529
step: 20, loss: 0.0006592530407942832
step: 30, loss: 0.0761183500289917
step: 40, loss: 0.01726815477013588
step: 50, loss: 0.043197859078645706
step: 60, loss: 0.05632202327251434
step: 70, loss: 0.07530692219734192
step: 80, loss: 0.046743329614400864
step: 90, loss: 0.0006287501892074943
step: 100, loss: 0.04035556688904762
step: 110, loss: 0.04558616131544113
step: 120, loss: 0.04384332522749901
step: 130, loss: 0.041220735758543015
step: 140, loss: 0.09581729024648666
step: 150, loss: 0.06187605857849121
step: 160, loss: 0.04872332140803337
step: 170, loss: 0.06771709769964218
step: 180, loss: 0.11024656891822815
step: 190, loss: 0.047466814517974854
step: 200, loss: 0.061260052025318146
step: 210, loss: 0.06714704632759094
step: 220, loss: 0.07740956544876099
step: 230, loss: 0.07008987665176392
step: 240, loss: 0.0025092866271734238
step: 250, loss: 0.07317206263542175
step: 260, loss: 0.10488534718751907
step: 270, loss: 0.045929454267024994
step: 280, loss: 0.08090045303106308
step: 290, loss: 0.07323137670755386
step: 300, loss: 0.07977554947137833
step: 310, loss: 0.15417475998401642
step: 320, loss: 0.01855216547846794
step: 330, loss: 0.06142905727028847
step: 340, loss: 0.04429759085178375
step: 350, loss: 0.054597094655036926
step: 360, loss: 0.043063871562480927
step: 370, loss: 0.01931227557361126
step: 380, loss: 0.03636949509382248
epoch 6: dev_f1=0.7428571428571429, f1=0.7106017191977076, best_f1=0.7106017191977076
step: 0, loss: 0.09852352738380432
step: 10, loss: 0.012492802925407887
step: 20, loss: 0.06551267206668854
step: 30, loss: 0.02135833352804184
step: 40, loss: 0.017088668420910835
step: 50, loss: 0.05301664024591446
step: 60, loss: 0.1385435163974762
step: 70, loss: 0.021574988961219788
step: 80, loss: 0.05518414452672005
step: 90, loss: 0.011181287467479706
step: 100, loss: 0.07751291245222092
step: 110, loss: 0.03350771218538284
step: 120, loss: 0.012710963375866413
step: 130, loss: 0.008909710682928562
step: 140, loss: 0.02008248306810856
step: 150, loss: 0.10069788992404938
step: 160, loss: 0.15213526785373688
step: 170, loss: 0.11574912071228027
step: 180, loss: 0.1463278979063034
step: 190, loss: 0.024838726967573166
step: 200, loss: 0.03078664280474186
step: 210, loss: 0.0009646835969761014
step: 220, loss: 0.044073689728975296
step: 230, loss: 0.04777080938220024
step: 240, loss: 0.04516281560063362
step: 250, loss: 0.007867613807320595
step: 260, loss: 0.09180530905723572
step: 270, loss: 0.0018049714853987098
step: 280, loss: 0.02158716507256031
step: 290, loss: 0.07875961810350418
step: 300, loss: 0.12852120399475098
step: 310, loss: 0.09495493769645691
step: 320, loss: 0.07304009050130844
step: 330, loss: 0.031947944313287735
step: 340, loss: 0.043680161237716675
step: 350, loss: 0.01780790090560913
step: 360, loss: 0.02776694856584072
step: 370, loss: 0.007633577100932598
step: 380, loss: 0.003040025010704994
epoch 7: dev_f1=0.7309644670050761, f1=0.7103274559193955, best_f1=0.7106017191977076
step: 0, loss: 0.02383442595601082
step: 10, loss: 0.08930329233407974
step: 20, loss: 0.01483224704861641
step: 30, loss: 0.13205915689468384
step: 40, loss: 0.023382576182484627
step: 50, loss: 0.10012377798557281
step: 60, loss: 0.08434703946113586
step: 70, loss: 0.02118133381009102
step: 80, loss: 0.0443112812936306
step: 90, loss: 0.0006606355891562998
step: 100, loss: 0.024973740801215172
step: 110, loss: 0.08993583917617798
step: 120, loss: 0.07070951163768768
step: 130, loss: 0.012332758866250515
step: 140, loss: 0.06152696534991264
step: 150, loss: 0.012983089312911034
step: 160, loss: 0.007339087314903736
step: 170, loss: 0.005263240542262793
step: 180, loss: 0.00021493618260137737
step: 190, loss: 0.0010421640472486615
step: 200, loss: 0.005523651372641325
step: 210, loss: 0.010668658651411533
step: 220, loss: 0.15466712415218353
step: 230, loss: 0.09967219829559326
step: 240, loss: 0.05011053383350372
step: 250, loss: 0.052726324647665024
step: 260, loss: 0.0614236555993557
step: 270, loss: 0.05994139984250069
step: 280, loss: 0.044042717665433884
step: 290, loss: 0.019260726869106293
step: 300, loss: 0.09139755368232727
step: 310, loss: 0.03106568194925785
step: 320, loss: 0.06376126408576965
step: 330, loss: 0.007484310306608677
step: 340, loss: 0.041764769703149796
step: 350, loss: 0.017178956419229507
step: 360, loss: 0.03930741548538208
step: 370, loss: 0.03421471640467644
step: 380, loss: 0.037387482821941376
epoch 8: dev_f1=0.7125307125307127, f1=0.7, best_f1=0.7106017191977076
step: 0, loss: 0.04427272081375122
step: 10, loss: 0.05198279768228531
step: 20, loss: 0.04393676295876503
step: 30, loss: 0.09737156331539154
step: 40, loss: 0.008899630978703499
step: 50, loss: 0.02673998847603798
step: 60, loss: 0.04179055616259575
step: 70, loss: 0.36931511759757996
step: 80, loss: 0.005041155964136124
step: 90, loss: 0.007425007876008749
step: 100, loss: 0.00014244340127334
step: 110, loss: 0.021503226831555367
step: 120, loss: 0.011896569281816483
step: 130, loss: 0.04069420322775841
step: 140, loss: 0.06666643917560577
step: 150, loss: 0.0005640449235215783
step: 160, loss: 0.0026993397623300552
step: 170, loss: 0.060455065220594406
step: 180, loss: 0.03174012899398804
step: 190, loss: 0.00038960925303399563
step: 200, loss: 0.000291949138045311
step: 210, loss: 0.03919171914458275
step: 220, loss: 0.010243968106806278
step: 230, loss: 0.021220002323389053
step: 240, loss: 0.04433020204305649
step: 250, loss: 0.014014908112585545
step: 260, loss: 0.0012248553102836013
step: 270, loss: 0.10146799683570862
step: 280, loss: 0.057003822177648544
step: 290, loss: 0.014170450158417225
step: 300, loss: 0.04388825595378876
step: 310, loss: 0.03519003838300705
step: 320, loss: 0.04080403596162796
step: 330, loss: 0.21213681995868683
step: 340, loss: 0.008683992549777031
step: 350, loss: 0.036074332892894745
step: 360, loss: 0.00021882321743760258
step: 370, loss: 0.029839985072612762
step: 380, loss: 0.0011502092238515615
epoch 9: dev_f1=0.6775067750677507, f1=0.6991869918699186, best_f1=0.7106017191977076
step: 0, loss: 0.02209487557411194
step: 10, loss: 0.06140857934951782
step: 20, loss: 0.11235707998275757
step: 30, loss: 0.012183287180960178
step: 40, loss: 0.0062451739795506
step: 50, loss: 0.0011787224793806672
step: 60, loss: 0.043737221509218216
step: 70, loss: 0.06891316920518875
step: 80, loss: 0.03739945963025093
step: 90, loss: 0.08563029766082764
step: 100, loss: 0.05178005248308182
step: 110, loss: 0.015267148613929749
step: 120, loss: 0.0022732557263225317
step: 130, loss: 0.04483663663268089
step: 140, loss: 0.05517679452896118
step: 150, loss: 0.018515855073928833
step: 160, loss: 0.011673235334455967
step: 170, loss: 0.1020149439573288
step: 180, loss: 0.02692440338432789
step: 190, loss: 0.004740309435874224
step: 200, loss: 0.000162134732818231
step: 210, loss: 0.08453844487667084
step: 220, loss: 0.06112942472100258
step: 230, loss: 0.08599460124969482
step: 240, loss: 0.07450013607740402
step: 250, loss: 0.04639897122979164
step: 260, loss: 0.03142150491476059
step: 270, loss: 0.00021063321037217975
step: 280, loss: 0.06405748426914215
step: 290, loss: 0.06676904112100601
step: 300, loss: 0.011469373479485512
step: 310, loss: 0.15891902148723602
step: 320, loss: 0.09311863780021667
step: 330, loss: 0.12325230985879898
step: 340, loss: 0.0929756835103035
step: 350, loss: 0.05533144995570183
step: 360, loss: 0.09939182549715042
step: 370, loss: 0.00035694552934728563
step: 380, loss: 0.007417561020702124
epoch 10: dev_f1=0.7307692307692308, f1=0.7227722772277227, best_f1=0.7106017191977076
step: 0, loss: 0.0010091998847201467
step: 10, loss: 0.0009073220426216722
step: 20, loss: 0.02412308380007744
step: 30, loss: 0.017361251637339592
step: 40, loss: 0.016813628375530243
step: 50, loss: 0.005266194697469473
step: 60, loss: 0.04203685000538826
step: 70, loss: 0.21276196837425232
step: 80, loss: 0.04201248288154602
step: 90, loss: 0.00021743981051258743
step: 100, loss: 0.00011927916057175025
step: 110, loss: 0.02675935998558998
step: 120, loss: 0.0006049523362889886
step: 130, loss: 0.06212913990020752
step: 140, loss: 0.004496986046433449
step: 150, loss: 0.04107221961021423
step: 160, loss: 0.017169514670968056
step: 170, loss: 0.02983851358294487
step: 180, loss: 0.028638381510972977
step: 190, loss: 0.01010671816766262
step: 200, loss: 0.0004480919742491096
step: 210, loss: 0.09101729840040207
step: 220, loss: 0.026815693825483322
step: 230, loss: 0.009041606448590755
step: 240, loss: 0.03527145832777023
step: 250, loss: 0.06548723578453064
step: 260, loss: 0.08484606444835663
step: 270, loss: 0.05481492355465889
step: 280, loss: 0.005213198252022266
step: 290, loss: 0.02765544131398201
step: 300, loss: 0.07167571783065796
step: 310, loss: 0.00013390106323640794
step: 320, loss: 0.006211601663380861
step: 330, loss: 0.04529885947704315
step: 340, loss: 0.03726235404610634
step: 350, loss: 0.08353246748447418
step: 360, loss: 0.026773247867822647
step: 370, loss: 0.24805401265621185
step: 380, loss: 0.0012795195216313004
epoch 11: dev_f1=0.7292817679558011, f1=0.6937669376693768, best_f1=0.7106017191977076
step: 0, loss: 0.01919744536280632
step: 10, loss: 0.03551042079925537
step: 20, loss: 0.030765095725655556
step: 30, loss: 0.07261711359024048
step: 40, loss: 0.044655948877334595
step: 50, loss: 0.007866429165005684
step: 60, loss: 0.00041957577923312783
step: 70, loss: 0.05014757439494133
step: 80, loss: 0.004712629597634077
step: 90, loss: 0.021047323942184448
step: 100, loss: 0.05364834517240524
step: 110, loss: 0.00044086421257816255
step: 120, loss: 0.0357232540845871
step: 130, loss: 0.0002476285444572568
step: 140, loss: 0.038626786321401596
step: 150, loss: 0.020436568185687065
step: 160, loss: 0.0019375595729798079
step: 170, loss: 0.00015273400640580803
step: 180, loss: 0.047225628048181534
step: 190, loss: 9.892422531265765e-05
step: 200, loss: 0.01316836941987276
step: 210, loss: 0.03731503710150719
step: 220, loss: 0.04282265901565552
step: 230, loss: 0.056027851998806
step: 240, loss: 0.009170802310109138
step: 250, loss: 0.00903968047350645
step: 260, loss: 0.004510756116360426
step: 270, loss: 0.003685229690745473
step: 280, loss: 0.04401332139968872
step: 290, loss: 0.00011110523337265477
step: 300, loss: 0.006519997958093882
step: 310, loss: 0.004670430440455675
step: 320, loss: 0.00032695455593056977
step: 330, loss: 0.003575537819415331
step: 340, loss: 0.026340652257204056
step: 350, loss: 0.08349409699440002
step: 360, loss: 0.04521486535668373
step: 370, loss: 0.024539420381188393
step: 380, loss: 0.020759904757142067
epoch 12: dev_f1=0.7061855670103092, f1=0.6857142857142857, best_f1=0.7106017191977076
step: 0, loss: 0.043077029287815094
step: 10, loss: 0.0527179054915905
step: 20, loss: 0.022253232076764107
step: 30, loss: 0.007599369622766972
step: 40, loss: 0.018824763596057892
step: 50, loss: 0.011001598089933395
step: 60, loss: 0.024424098432064056
step: 70, loss: 0.055400460958480835
step: 80, loss: 0.08655402064323425
step: 90, loss: 0.00012605228403117508
step: 100, loss: 0.04388647526502609
step: 110, loss: 0.07978679984807968
step: 120, loss: 0.042883921414613724
step: 130, loss: 0.006718969903886318
step: 140, loss: 0.03832700476050377
step: 150, loss: 0.06110883876681328
step: 160, loss: 0.03252435475587845
step: 170, loss: 0.001534052425995469
step: 180, loss: 0.03728906437754631
step: 190, loss: 0.010877474211156368
step: 200, loss: 0.01048972923308611
step: 210, loss: 0.24976080656051636
step: 220, loss: 0.06206592917442322
step: 230, loss: 0.0005685884971171618
step: 240, loss: 0.12933087348937988
step: 250, loss: 0.015423470176756382
step: 260, loss: 0.010036102496087551
step: 270, loss: 0.07933828234672546
step: 280, loss: 0.00023791253624949604
step: 290, loss: 0.03476189076900482
step: 300, loss: 0.0289528276771307
step: 310, loss: 0.06023259833455086
step: 320, loss: 4.4995998905505985e-05
step: 330, loss: 0.0559452660381794
step: 340, loss: 0.15395797789096832
step: 350, loss: 0.00752588827162981
step: 360, loss: 0.0088975103572011
step: 370, loss: 0.035975996404886246
step: 380, loss: 0.007974701933562756
epoch 13: dev_f1=0.7168831168831169, f1=0.7002518891687657, best_f1=0.7106017191977076
step: 0, loss: 0.03738275542855263
step: 10, loss: 0.0220558550208807
step: 20, loss: 0.0019185884157195687
step: 30, loss: 0.0065790521912276745
step: 40, loss: 0.05649496242403984
step: 50, loss: 0.02752654254436493
step: 60, loss: 0.015279059298336506
step: 70, loss: 0.0028190307784825563
step: 80, loss: 0.0911957398056984
step: 90, loss: 6.762552220607176e-05
step: 100, loss: 0.0011750225676223636
step: 110, loss: 9.591831621946767e-05
step: 120, loss: 0.023736311122775078
step: 130, loss: 0.024122633039951324
step: 140, loss: 0.003178649116307497
step: 150, loss: 0.09727485477924347
step: 160, loss: 0.07063546776771545
step: 170, loss: 0.0005511900526471436
step: 180, loss: 0.005129862576723099
step: 190, loss: 0.00016938403132371604
step: 200, loss: 0.015527413226664066
step: 210, loss: 0.0012113971170037985
step: 220, loss: 0.024456117302179337
step: 230, loss: 0.005808635614812374
step: 240, loss: 0.016018269583582878
step: 250, loss: 0.0348217599093914
step: 260, loss: 0.012456883676350117
step: 270, loss: 0.0029333829879760742
step: 280, loss: 0.04368668422102928
step: 290, loss: 0.005425317212939262
step: 300, loss: 0.04400942847132683
step: 310, loss: 0.00703827291727066
step: 320, loss: 0.02909049019217491
step: 330, loss: 0.026961151510477066
step: 340, loss: 0.009287864901125431
step: 350, loss: 0.008943995460867882
step: 360, loss: 0.024818263947963715
step: 370, loss: 0.047892358154058456
step: 380, loss: 0.0009920685552060604
epoch 14: dev_f1=0.7109826589595377, f1=0.7031700288184439, best_f1=0.7106017191977076
step: 0, loss: 0.010657275095582008
step: 10, loss: 0.025403914973139763
step: 20, loss: 0.03469119593501091
step: 30, loss: 0.018790114670991898
step: 40, loss: 0.030811356380581856
step: 50, loss: 0.028772536665201187
step: 60, loss: 0.023361297324299812
step: 70, loss: 0.0007119181100279093
step: 80, loss: 0.017947379499673843
step: 90, loss: 0.02831430546939373
step: 100, loss: 0.0016899615293368697
step: 110, loss: 0.023772113025188446
step: 120, loss: 0.03474836423993111
step: 130, loss: 0.025609273463487625
step: 140, loss: 0.0038018147461116314
step: 150, loss: 0.00019141248776577413
step: 160, loss: 0.07078985124826431
step: 170, loss: 0.005961832124739885
step: 180, loss: 0.05812249705195427
step: 190, loss: 0.0020216878037899733
step: 200, loss: 0.005453481804579496
step: 210, loss: 0.03958223760128021
step: 220, loss: 5.502705607796088e-05
step: 230, loss: 0.008271589875221252
step: 240, loss: 0.0015039806021377444
step: 250, loss: 0.0018866818863898516
step: 260, loss: 0.00046845219912938774
step: 270, loss: 0.00021535450650844723
step: 280, loss: 0.10330624878406525
step: 290, loss: 0.0014068485470488667
step: 300, loss: 0.0023774041328579187
step: 310, loss: 0.019488263875246048
step: 320, loss: 0.004814003594219685
step: 330, loss: 0.0022366298362612724
step: 340, loss: 0.0015249637654051185
step: 350, loss: 0.0008836989291012287
step: 360, loss: 0.0012784060090780258
step: 370, loss: 0.04680941253900528
step: 380, loss: 0.006680072285234928
epoch 15: dev_f1=0.7314578005115089, f1=0.7301587301587302, best_f1=0.7106017191977076
step: 0, loss: 0.017245909199118614
step: 10, loss: 0.02766912244260311
step: 20, loss: 0.02839083783328533
step: 30, loss: 0.004948396235704422
step: 40, loss: 0.0024447976611554623
step: 50, loss: 0.05232765153050423
step: 60, loss: 0.020550107583403587
step: 70, loss: 0.052518170326948166
step: 80, loss: 0.025424662977457047
step: 90, loss: 0.01645524986088276
step: 100, loss: 0.00326571986079216
step: 110, loss: 0.017957959324121475
step: 120, loss: 0.047196365892887115
step: 130, loss: 0.003039994277060032
step: 140, loss: 0.036096587777137756
step: 150, loss: 0.012411466799676418
step: 160, loss: 0.0018032245570793748
step: 170, loss: 0.10699675977230072
step: 180, loss: 0.0002770679129753262
step: 190, loss: 0.0030992073006927967
step: 200, loss: 0.024852829053997993
step: 210, loss: 0.03795440122485161
step: 220, loss: 0.00158510182518512
step: 230, loss: 0.08947618305683136
step: 240, loss: 0.012973204255104065
step: 250, loss: 0.033590760082006454
step: 260, loss: 0.005859720055013895
step: 270, loss: 0.035327229648828506
step: 280, loss: 0.001085428288206458
step: 290, loss: 0.03569258376955986
step: 300, loss: 0.0007658038521185517
step: 310, loss: 0.028322454541921616
step: 320, loss: 0.005916825029999018
step: 330, loss: 0.0008151670335792005
step: 340, loss: 0.07924196869134903
step: 350, loss: 0.007502617780119181
step: 360, loss: 0.05541705712676048
step: 370, loss: 0.014330490492284298
step: 380, loss: 0.0001012720531434752
epoch 16: dev_f1=0.7253886010362695, f1=0.7393617021276595, best_f1=0.7106017191977076
step: 0, loss: 0.000996889779344201
step: 10, loss: 0.03320932015776634
step: 20, loss: 0.035400230437517166
step: 30, loss: 0.005213819444179535
step: 40, loss: 0.0006321794935502112
step: 50, loss: 3.4121330827474594e-05
step: 60, loss: 0.01129916962236166
step: 70, loss: 0.0011371015571057796
step: 80, loss: 0.009633621200919151
step: 90, loss: 0.0004736039263661951
step: 100, loss: 0.007874534465372562
step: 110, loss: 0.0004700528224930167
step: 120, loss: 9.840291022555903e-05
step: 130, loss: 0.0008622120367363095
step: 140, loss: 0.02290746383368969
step: 150, loss: 0.019914597272872925
step: 160, loss: 0.00015358593373093754
step: 170, loss: 0.00028948902036063373
step: 180, loss: 0.0015527000650763512
step: 190, loss: 0.004502110183238983
step: 200, loss: 0.05251646041870117
step: 210, loss: 0.0005532381474040449
step: 220, loss: 0.04458253085613251
step: 230, loss: 0.022957606241106987
step: 240, loss: 0.0011516502127051353
step: 250, loss: 0.017027895897626877
step: 260, loss: 0.018948979675769806
step: 270, loss: 0.030461426824331284
step: 280, loss: 0.02319885790348053
step: 290, loss: 0.025862356647849083
step: 300, loss: 0.0014048906741663814
step: 310, loss: 0.05515699088573456
step: 320, loss: 0.006127502769231796
step: 330, loss: 0.010513504967093468
step: 340, loss: 0.01824200712144375
step: 350, loss: 3.815237869275734e-05
step: 360, loss: 0.00011761608766391873
step: 370, loss: 0.10479002445936203
step: 380, loss: 0.022050298750400543
epoch 17: dev_f1=0.7354497354497355, f1=0.7301587301587302, best_f1=0.7106017191977076
step: 0, loss: 0.00010459798795636743
step: 10, loss: 0.0249125137925148
step: 20, loss: 0.028902309015393257
step: 30, loss: 0.023418212309479713
step: 40, loss: 0.009984769858419895
step: 50, loss: 0.013669630512595177
step: 60, loss: 0.017702747136354446
step: 70, loss: 0.012320386245846748
step: 80, loss: 0.01506554614752531
step: 90, loss: 0.009529681876301765
step: 100, loss: 0.03959076106548309
step: 110, loss: 0.0012416476383805275
step: 120, loss: 0.008459718897938728
step: 130, loss: 0.00015192368300631642
step: 140, loss: 0.00010642497363733128
step: 150, loss: 0.038828156888484955
step: 160, loss: 0.0031026219949126244
step: 170, loss: 0.00016060769848991185
step: 180, loss: 0.040837544947862625
step: 190, loss: 0.02821974828839302
step: 200, loss: 0.07075925916433334
step: 210, loss: 0.01887322962284088
step: 220, loss: 0.028155477717518806
step: 230, loss: 0.0117306774482131
step: 240, loss: 0.0014077743981033564
step: 250, loss: 0.054162267595529556
step: 260, loss: 0.05775722488760948
step: 270, loss: 0.03429160639643669
step: 280, loss: 0.02984604239463806
step: 290, loss: 0.0008356848848052323
step: 300, loss: 0.03378885239362717
step: 310, loss: 7.631298649357632e-05
step: 320, loss: 0.0022700494155287743
step: 330, loss: 7.602594268973917e-05
step: 340, loss: 0.00784846767783165
step: 350, loss: 0.02844623103737831
step: 360, loss: 0.05801886320114136
step: 370, loss: 7.481026841560379e-05
step: 380, loss: 0.000407789513701573
epoch 18: dev_f1=0.7100000000000001, f1=0.7263427109974423, best_f1=0.7106017191977076
step: 0, loss: 0.000720554031431675
step: 10, loss: 0.001453353208489716
step: 20, loss: 0.00023716868599876761
step: 30, loss: 0.023926516994833946
step: 40, loss: 0.00541619211435318
step: 50, loss: 0.0006272542523220181
step: 60, loss: 0.00898582674562931
step: 70, loss: 0.01611262373626232
step: 80, loss: 0.01905687153339386
step: 90, loss: 0.006801893934607506
step: 100, loss: 0.060126010328531265
step: 110, loss: 0.0019252594793215394
step: 120, loss: 0.11390447616577148
step: 130, loss: 0.03133881837129593
step: 140, loss: 0.013009247370064259
step: 150, loss: 7.182136323535815e-05
step: 160, loss: 0.0033174087293446064
step: 170, loss: 3.466553971520625e-05
step: 180, loss: 0.0005224571214057505
step: 190, loss: 0.0037890677340328693
step: 200, loss: 0.04659479111433029
step: 210, loss: 0.0010072573786601424
step: 220, loss: 0.003478005761280656
step: 230, loss: 6.725758430548012e-05
step: 240, loss: 0.00010258497059112415
step: 250, loss: 0.051672179251909256
step: 260, loss: 0.0013412481639534235
step: 270, loss: 0.018117446452379227
step: 280, loss: 3.971971818828024e-05
step: 290, loss: 0.00011270443064859137
step: 300, loss: 0.002669229172170162
step: 310, loss: 0.03181401640176773
step: 320, loss: 0.00026963770505972207
step: 330, loss: 0.10499770939350128
step: 340, loss: 0.0001348597725154832
step: 350, loss: 0.027862083166837692
step: 360, loss: 0.0007175705977715552
step: 370, loss: 0.10437588393688202
step: 380, loss: 0.00021628456306643784
epoch 19: dev_f1=0.7202072538860104, f1=0.7315789473684211, best_f1=0.7106017191977076
step: 0, loss: 8.762156357988715e-05
step: 10, loss: 0.012355051003396511
step: 20, loss: 0.0004868056275881827
step: 30, loss: 0.002787885023280978
step: 40, loss: 6.431361543945968e-05
step: 50, loss: 6.653519085375592e-05
step: 60, loss: 0.051354359835386276
step: 70, loss: 4.8748152039479464e-05
step: 80, loss: 0.16826938092708588
step: 90, loss: 0.009180950932204723
step: 100, loss: 0.00012403217260725796
step: 110, loss: 0.01751670241355896
step: 120, loss: 0.0003574758011382073
step: 130, loss: 0.025284625589847565
step: 140, loss: 0.016161348670721054
step: 150, loss: 0.000715005851816386
step: 160, loss: 0.00015852348587941378
step: 170, loss: 0.010604132898151875
step: 180, loss: 0.02700849249958992
step: 190, loss: 0.035268448293209076
step: 200, loss: 0.0001790130918379873
step: 210, loss: 8.332350989803672e-05
step: 220, loss: 0.011464342474937439
step: 230, loss: 0.022235766053199768
step: 240, loss: 0.008174559101462364
step: 250, loss: 0.0025692065246403217
step: 260, loss: 0.004812529776245356
step: 270, loss: 0.008419930934906006
step: 280, loss: 0.01462540216743946
step: 290, loss: 3.1660430977353826e-05
step: 300, loss: 0.004536274820566177
step: 310, loss: 0.013993831351399422
step: 320, loss: 0.0058965133503079414
step: 330, loss: 0.03900197148323059
step: 340, loss: 0.030025668442249298
step: 350, loss: 0.00033675922895781696
step: 360, loss: 0.013749081641435623
step: 370, loss: 0.024742139503359795
step: 380, loss: 0.03114471212029457
epoch 20: dev_f1=0.7180851063829788, f1=0.7306666666666668, best_f1=0.7106017191977076
