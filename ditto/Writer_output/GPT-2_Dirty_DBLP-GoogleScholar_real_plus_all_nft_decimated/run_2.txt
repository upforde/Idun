cuda
Device: cuda
step: 0, loss: 0.634486973285675
step: 10, loss: 0.5542963743209839
step: 20, loss: 0.4341350197792053
step: 30, loss: 0.40896841883659363
step: 40, loss: 0.41099441051483154
step: 50, loss: 0.3672712445259094
step: 60, loss: 0.3565947711467743
step: 70, loss: 0.5627524852752686
step: 80, loss: 0.17668206989765167
step: 90, loss: 0.220132976770401
step: 100, loss: 0.25813907384872437
step: 110, loss: 0.2870889902114868
step: 120, loss: 0.37869468331336975
step: 130, loss: 0.3633897602558136
step: 140, loss: 0.16796821355819702
step: 150, loss: 0.45290714502334595
step: 160, loss: 0.28670236468315125
step: 170, loss: 0.311392217874527
step: 180, loss: 0.2364274263381958
step: 190, loss: 0.22848372161388397
step: 200, loss: 0.24687862396240234
step: 210, loss: 0.1393883228302002
step: 220, loss: 0.29342812299728394
step: 230, loss: 0.1458192616701126
step: 240, loss: 0.14945822954177856
step: 250, loss: 0.1303439736366272
step: 260, loss: 0.04431440308690071
step: 270, loss: 0.15280650556087494
step: 280, loss: 0.07311549782752991
step: 290, loss: 0.06252284348011017
step: 300, loss: 0.0765947550535202
step: 310, loss: 0.06029447913169861
step: 320, loss: 0.37162184715270996
step: 330, loss: 0.04289728030562401
step: 340, loss: 0.1841287910938263
step: 350, loss: 0.27788108587265015
step: 360, loss: 0.24844570457935333
step: 370, loss: 0.06150546297430992
step: 380, loss: 0.09470292925834656
step: 390, loss: 0.19456003606319427
step: 400, loss: 0.1338912844657898
step: 410, loss: 0.1532665342092514
step: 420, loss: 0.10084952414035797
step: 430, loss: 0.07254208624362946
step: 440, loss: 0.06462281197309494
step: 450, loss: 0.04354444146156311
step: 460, loss: 0.19094793498516083
step: 470, loss: 0.02994012087583542
step: 480, loss: 0.2113208770751953
step: 490, loss: 0.014400140382349491
step: 500, loss: 0.19933481514453888
step: 510, loss: 0.08614203333854675
step: 520, loss: 0.020651791244745255
step: 530, loss: 0.05090588331222534
epoch 1: dev_f1=0.7332200509770603, f1=0.7036559139784947, best_f1=0.7036559139784947
step: 0, loss: 0.014024282805621624
step: 10, loss: 0.16363482177257538
step: 20, loss: 0.07543247938156128
step: 30, loss: 0.031253159046173096
step: 40, loss: 0.09014789760112762
step: 50, loss: 0.05699777603149414
step: 60, loss: 0.06123699992895126
step: 70, loss: 0.04211324080824852
step: 80, loss: 0.01951475627720356
step: 90, loss: 0.18373480439186096
step: 100, loss: 0.10354595631361008
step: 110, loss: 0.06833912432193756
step: 120, loss: 0.17792145907878876
step: 130, loss: 0.10484008491039276
step: 140, loss: 0.04933064430952072
step: 150, loss: 0.04000752046704292
step: 160, loss: 0.03276939317584038
step: 170, loss: 0.02548595517873764
step: 180, loss: 0.07860137522220612
step: 190, loss: 0.04612364619970322
step: 200, loss: 0.09497201442718506
step: 210, loss: 0.025121843442320824
step: 220, loss: 0.17056860029697418
step: 230, loss: 0.127093106508255
step: 240, loss: 0.09819501638412476
step: 250, loss: 0.08843930065631866
step: 260, loss: 0.029413897544145584
step: 270, loss: 0.06913919001817703
step: 280, loss: 0.06911908835172653
step: 290, loss: 0.038589075207710266
step: 300, loss: 0.07432476431131363
step: 310, loss: 0.02153013087809086
step: 320, loss: 0.09764156490564346
step: 330, loss: 0.05194573849439621
step: 340, loss: 0.007996954023838043
step: 350, loss: 0.07074345648288727
step: 360, loss: 0.306163489818573
step: 370, loss: 0.02217632345855236
step: 380, loss: 0.1776762157678604
step: 390, loss: 0.008755743503570557
step: 400, loss: 0.11720913648605347
step: 410, loss: 0.15257787704467773
step: 420, loss: 0.054654866456985474
step: 430, loss: 0.1040969267487526
step: 440, loss: 0.028879303485155106
step: 450, loss: 0.04471445083618164
step: 460, loss: 0.13605737686157227
step: 470, loss: 0.05654364079236984
step: 480, loss: 0.03437983617186546
step: 490, loss: 0.1253625899553299
step: 500, loss: 0.03319917619228363
step: 510, loss: 0.1722763180732727
step: 520, loss: 0.06750699877738953
step: 530, loss: 0.1131526529788971
epoch 2: dev_f1=0.7550931946250543, f1=0.7381898454746137, best_f1=0.7381898454746137
step: 0, loss: 0.05401751399040222
step: 10, loss: 0.23254087567329407
step: 20, loss: 0.03347524255514145
step: 30, loss: 0.01465489249676466
step: 40, loss: 0.014993028715252876
step: 50, loss: 0.05557960644364357
step: 60, loss: 0.0892932265996933
step: 70, loss: 0.07159249484539032
step: 80, loss: 0.13998697698116302
step: 90, loss: 0.032765407115221024
step: 100, loss: 0.08103180676698685
step: 110, loss: 0.06746623665094376
step: 120, loss: 0.31417497992515564
step: 130, loss: 0.13202255964279175
step: 140, loss: 0.07020328938961029
step: 150, loss: 0.11089648306369781
step: 160, loss: 0.04191192612051964
step: 170, loss: 0.1282804310321808
step: 180, loss: 0.0024123219773173332
step: 190, loss: 0.11376375705003738
step: 200, loss: 0.009706595912575722
step: 210, loss: 0.11105479300022125
step: 220, loss: 0.04072011634707451
step: 230, loss: 0.1791665256023407
step: 240, loss: 0.13562025129795074
step: 250, loss: 0.10990182310342789
step: 260, loss: 0.04864600673317909
step: 270, loss: 0.03195382282137871
step: 280, loss: 0.08465036749839783
step: 290, loss: 0.22547590732574463
step: 300, loss: 0.015151768922805786
step: 310, loss: 0.018847452476620674
step: 320, loss: 0.08281047642230988
step: 330, loss: 0.06602704524993896
step: 340, loss: 0.0685286894440651
step: 350, loss: 0.07185433804988861
step: 360, loss: 0.036896444857120514
step: 370, loss: 0.04216884821653366
step: 380, loss: 0.04652253910899162
step: 390, loss: 0.02861824817955494
step: 400, loss: 0.015028481371700764
step: 410, loss: 0.01474171131849289
step: 420, loss: 0.021725382655858994
step: 430, loss: 0.08761612325906754
step: 440, loss: 0.13152144849300385
step: 450, loss: 0.1148262768983841
step: 460, loss: 0.10273662209510803
step: 470, loss: 0.13737517595291138
step: 480, loss: 0.013575614430010319
step: 490, loss: 0.049725573509931564
step: 500, loss: 0.1599593162536621
step: 510, loss: 0.10417773574590683
step: 520, loss: 0.011633051559329033
step: 530, loss: 0.018594132736325264
epoch 3: dev_f1=0.7613793103448276, f1=0.7430426716141002, best_f1=0.7430426716141002
step: 0, loss: 0.11684274673461914
step: 10, loss: 0.005161596462130547
step: 20, loss: 0.0387650765478611
step: 30, loss: 0.05763697624206543
step: 40, loss: 0.0191950723528862
step: 50, loss: 0.030511334538459778
step: 60, loss: 0.02199508622288704
step: 70, loss: 0.05423630028963089
step: 80, loss: 0.02367992512881756
step: 90, loss: 0.0011376937618479133
step: 100, loss: 0.010948371142148972
step: 110, loss: 0.022257013246417046
step: 120, loss: 0.13089826703071594
step: 130, loss: 0.006642444059252739
step: 140, loss: 0.03937268257141113
step: 150, loss: 0.014845507219433784
step: 160, loss: 0.03267097845673561
step: 170, loss: 0.015891117975115776
step: 180, loss: 0.01754174195230007
step: 190, loss: 0.0033114065881818533
step: 200, loss: 0.0521065779030323
step: 210, loss: 0.003589825937524438
step: 220, loss: 0.00828179158270359
step: 230, loss: 0.0921088233590126
step: 240, loss: 0.04870009049773216
step: 250, loss: 0.01947704143822193
step: 260, loss: 0.03359159082174301
step: 270, loss: 0.1803434044122696
step: 280, loss: 0.057751432061195374
step: 290, loss: 0.05499408766627312
step: 300, loss: 0.004128947854042053
step: 310, loss: 0.012345532886683941
step: 320, loss: 0.006206621415913105
step: 330, loss: 0.14902710914611816
step: 340, loss: 0.0848601683974266
step: 350, loss: 0.0010658499086275697
step: 360, loss: 0.03134068846702576
step: 370, loss: 0.02367737889289856
step: 380, loss: 0.06808686256408691
step: 390, loss: 0.013970866799354553
step: 400, loss: 0.060723185539245605
step: 410, loss: 0.06810091435909271
step: 420, loss: 0.038650788366794586
step: 430, loss: 0.07011091709136963
step: 440, loss: 0.09320587664842606
step: 450, loss: 0.11866329610347748
step: 460, loss: 0.029540758579969406
step: 470, loss: 0.04715948924422264
step: 480, loss: 0.04164384678006172
step: 490, loss: 0.14774639904499054
step: 500, loss: 0.039870020002126694
step: 510, loss: 0.051471419632434845
step: 520, loss: 0.15328583121299744
step: 530, loss: 0.0009971284307539463
epoch 4: dev_f1=0.7852378835037794, f1=0.7695789950203712, best_f1=0.7695789950203712
step: 0, loss: 0.04916105046868324
step: 10, loss: 0.015948915854096413
step: 20, loss: 0.0558045469224453
step: 30, loss: 0.007099868264049292
step: 40, loss: 0.015413898974657059
step: 50, loss: 0.06658776104450226
step: 60, loss: 0.03866299241781235
step: 70, loss: 0.05265984311699867
step: 80, loss: 0.021058641374111176
step: 90, loss: 0.03546447306871414
step: 100, loss: 0.009685271419584751
step: 110, loss: 0.032198481261730194
step: 120, loss: 0.010052809491753578
step: 130, loss: 0.03593652322888374
step: 140, loss: 0.03209242597222328
step: 150, loss: 0.06740745902061462
step: 160, loss: 0.060486603528261185
step: 170, loss: 0.055018454790115356
step: 180, loss: 0.1583450883626938
step: 190, loss: 0.08598091453313828
step: 200, loss: 0.055019136518239975
step: 210, loss: 0.009018171578645706
step: 220, loss: 0.0190727598965168
step: 230, loss: 0.0010080146603286266
step: 240, loss: 0.04860542714595795
step: 250, loss: 0.14045317471027374
step: 260, loss: 0.15891866385936737
step: 270, loss: 0.006962563376873732
step: 280, loss: 0.01981525681912899
step: 290, loss: 0.05186646804213524
step: 300, loss: 0.0056147705763578415
step: 310, loss: 0.0054497867822647095
step: 320, loss: 0.013169847428798676
step: 330, loss: 0.034711066633462906
step: 340, loss: 0.023069055750966072
step: 350, loss: 0.04505876824259758
step: 360, loss: 0.0003761219559237361
step: 370, loss: 0.0031957339961081743
step: 380, loss: 0.01422515045851469
step: 390, loss: 0.0036707359831780195
step: 400, loss: 0.026042964309453964
step: 410, loss: 0.004881096538156271
step: 420, loss: 0.016311436891555786
step: 430, loss: 0.01544265914708376
step: 440, loss: 0.09323542565107346
step: 450, loss: 0.024318229407072067
step: 460, loss: 0.0002754743327386677
step: 470, loss: 0.17090249061584473
step: 480, loss: 0.0705731064081192
step: 490, loss: 0.008575036190450191
step: 500, loss: 0.13024218380451202
step: 510, loss: 0.11984406411647797
step: 520, loss: 0.015720341354608536
step: 530, loss: 0.025139281526207924
epoch 5: dev_f1=0.812933025404157, f1=0.8053878309335811, best_f1=0.8053878309335811
step: 0, loss: 0.007641607895493507
step: 10, loss: 0.028805812820792198
step: 20, loss: 0.004628350026905537
step: 30, loss: 0.04478016495704651
step: 40, loss: 0.0290993545204401
step: 50, loss: 0.0028631852474063635
step: 60, loss: 0.005339121911674738
step: 70, loss: 0.0008750941487960517
step: 80, loss: 0.004443275276571512
step: 90, loss: 0.03907781094312668
step: 100, loss: 0.00714475242421031
step: 110, loss: 0.034448977559804916
step: 120, loss: 0.030354660004377365
step: 130, loss: 0.0003671059384942055
step: 140, loss: 0.0045930915512144566
step: 150, loss: 0.0014435388147830963
step: 160, loss: 0.010674599558115005
step: 170, loss: 0.008938191458582878
step: 180, loss: 0.010657882317900658
step: 190, loss: 0.0804533064365387
step: 200, loss: 0.04075746610760689
step: 210, loss: 0.009239342994987965
step: 220, loss: 0.11351505666971207
step: 230, loss: 0.075463205575943
step: 240, loss: 0.055497463792562485
step: 250, loss: 0.03217121958732605
step: 260, loss: 0.007042706478387117
step: 270, loss: 0.019498178735375404
step: 280, loss: 0.08498040586709976
step: 290, loss: 0.025847291573882103
step: 300, loss: 0.035158608108758926
step: 310, loss: 0.04387397691607475
step: 320, loss: 0.0010846431832760572
step: 330, loss: 0.005586665123701096
step: 340, loss: 0.043931830674409866
step: 350, loss: 0.053757455199956894
step: 360, loss: 0.05793542042374611
step: 370, loss: 0.050657592713832855
step: 380, loss: 0.05772601068019867
step: 390, loss: 0.024431707337498665
step: 400, loss: 0.023705411702394485
step: 410, loss: 0.0031974297016859055
step: 420, loss: 0.004709845408797264
step: 430, loss: 0.015609108842909336
step: 440, loss: 0.0012677150079980493
step: 450, loss: 0.005132934078574181
step: 460, loss: 0.0018467383924871683
step: 470, loss: 0.03649517893791199
step: 480, loss: 0.15084297955036163
step: 490, loss: 0.04456866905093193
step: 500, loss: 0.001013040542602539
step: 510, loss: 0.00196565012447536
step: 520, loss: 0.10175979137420654
step: 530, loss: 0.038812268525362015
epoch 6: dev_f1=0.7685631629701061, f1=0.7390029325513195, best_f1=0.8053878309335811
step: 0, loss: 0.019476301968097687
step: 10, loss: 0.010131202638149261
step: 20, loss: 0.00988954957574606
step: 30, loss: 0.004016811493784189
step: 40, loss: 0.006156485062092543
step: 50, loss: 0.002037029480561614
step: 60, loss: 0.000621552811935544
step: 70, loss: 0.009174490347504616
step: 80, loss: 0.026217972859740257
step: 90, loss: 0.004023823421448469
step: 100, loss: 0.0008308368269354105
step: 110, loss: 0.0602269247174263
step: 120, loss: 0.0072057368233799934
step: 130, loss: 0.16985788941383362
step: 140, loss: 0.014097427949309349
step: 150, loss: 0.0007825485081411898
step: 160, loss: 0.0004270778445061296
step: 170, loss: 0.010853503830730915
step: 180, loss: 0.029305163770914078
step: 190, loss: 0.006263411603868008
step: 200, loss: 0.018513469025492668
step: 210, loss: 0.06868809461593628
step: 220, loss: 0.011085868813097477
step: 230, loss: 0.0001479634956922382
step: 240, loss: 0.019856875762343407
step: 250, loss: 0.004636453464627266
step: 260, loss: 0.0018059104913845658
step: 270, loss: 0.07099232822656631
step: 280, loss: 0.026370402425527573
step: 290, loss: 0.0008869689190760255
step: 300, loss: 0.005678399931639433
step: 310, loss: 0.0017586940666660666
step: 320, loss: 0.0105690136551857
step: 330, loss: 0.0012422797735780478
step: 340, loss: 0.06376995891332626
step: 350, loss: 0.062095921486616135
step: 360, loss: 0.11886388808488846
step: 370, loss: 0.0013181695248931646
step: 380, loss: 0.010521147400140762
step: 390, loss: 0.0670449510216713
step: 400, loss: 0.00828469917178154
step: 410, loss: 0.007907865568995476
step: 420, loss: 0.007079679518938065
step: 430, loss: 0.0019234984647482634
step: 440, loss: 0.02143593691289425
step: 450, loss: 0.04501526057720184
step: 460, loss: 0.06691320985555649
step: 470, loss: 0.0004539683577604592
step: 480, loss: 0.025014299899339676
step: 490, loss: 0.005401792470365763
step: 500, loss: 0.017797473818063736
step: 510, loss: 0.022946342825889587
step: 520, loss: 0.00362261850386858
step: 530, loss: 0.00443390803411603
epoch 7: dev_f1=0.7915518824609734, f1=0.7922616305849839, best_f1=0.8053878309335811
step: 0, loss: 0.001920696347951889
step: 10, loss: 0.0063465735875070095
step: 20, loss: 0.0024815972428768873
step: 30, loss: 0.0031931805424392223
step: 40, loss: 0.009515902027487755
step: 50, loss: 0.0006369216134771705
step: 60, loss: 0.002351171337068081
step: 70, loss: 0.0555720254778862
step: 80, loss: 0.0035037093330174685
step: 90, loss: 0.00125675939489156
step: 100, loss: 0.0016052124556154013
step: 110, loss: 0.021622098982334137
step: 120, loss: 0.005782844964414835
step: 130, loss: 0.1183297261595726
step: 140, loss: 0.0003024101024493575
step: 150, loss: 0.025119341909885406
step: 160, loss: 0.000650402158498764
step: 170, loss: 0.00368672632612288
step: 180, loss: 0.0011213429970666766
step: 190, loss: 0.034460268914699554
step: 200, loss: 0.0060128928162157536
step: 210, loss: 0.011561159044504166
step: 220, loss: 0.01352862548083067
step: 230, loss: 0.003298128256574273
step: 240, loss: 0.0008670833776704967
step: 250, loss: 0.0007216348312795162
step: 260, loss: 0.002904641442000866
step: 270, loss: 0.04784339293837547
step: 280, loss: 0.00024149665841832757
step: 290, loss: 0.07660982012748718
step: 300, loss: 0.0006709627341479063
step: 310, loss: 0.09266417473554611
step: 320, loss: 0.03198644518852234
step: 330, loss: 0.0054803770035505295
step: 340, loss: 0.003888071281835437
step: 350, loss: 0.009260297752916813
step: 360, loss: 0.046917617321014404
step: 370, loss: 0.002325429581105709
step: 380, loss: 0.06135040894150734
step: 390, loss: 0.005393073428422213
step: 400, loss: 0.11794209480285645
step: 410, loss: 0.007121667265892029
step: 420, loss: 0.011720258742570877
step: 430, loss: 0.004659528378397226
step: 440, loss: 0.0027432655915617943
step: 450, loss: 0.0011431261664256454
step: 460, loss: 0.060251712799072266
step: 470, loss: 0.01805558241903782
step: 480, loss: 0.01964690536260605
step: 490, loss: 0.009381473064422607
step: 500, loss: 0.00139350607059896
step: 510, loss: 0.0026520369574427605
step: 520, loss: 0.025150960311293602
step: 530, loss: 0.0026938808150589466
epoch 8: dev_f1=0.7786885245901639, f1=0.7769652650822669, best_f1=0.8053878309335811
step: 0, loss: 0.005125503055751324
step: 10, loss: 0.006301843095570803
step: 20, loss: 0.002022398402914405
step: 30, loss: 0.014415805228054523
step: 40, loss: 0.0025350332725793123
step: 50, loss: 0.06754553318023682
step: 60, loss: 0.0040883333422243595
step: 70, loss: 9.062173921847716e-05
step: 80, loss: 0.002770282095298171
step: 90, loss: 0.005134242121130228
step: 100, loss: 0.0059565589763224125
step: 110, loss: 0.0009696616907604039
step: 120, loss: 0.0013733238447457552
step: 130, loss: 0.08301213383674622
step: 140, loss: 0.0003671841404866427
step: 150, loss: 0.003667022567242384
step: 160, loss: 0.0008693851996213198
step: 170, loss: 0.002058759331703186
step: 180, loss: 0.0035628757905215025
step: 190, loss: 0.004777208436280489
step: 200, loss: 0.00023502430121880025
step: 210, loss: 0.0008170986548066139
step: 220, loss: 0.0008815450128167868
step: 230, loss: 0.0014182917075231671
step: 240, loss: 0.0015129438834264874
step: 250, loss: 0.0024221623316407204
step: 260, loss: 0.003878099611029029
step: 270, loss: 0.10906574875116348
step: 280, loss: 0.0006460637087002397
step: 290, loss: 0.01729566417634487
step: 300, loss: 0.007721375208348036
step: 310, loss: 0.01778930053114891
step: 320, loss: 0.0072972122579813
step: 330, loss: 0.0003836570249404758
step: 340, loss: 0.0024638306349515915
step: 350, loss: 0.008293313905596733
step: 360, loss: 0.00019063854415435344
step: 370, loss: 0.0004580952227115631
step: 380, loss: 0.0017821388319134712
step: 390, loss: 0.005450987257063389
step: 400, loss: 0.0015269971918314695
step: 410, loss: 0.006216611247509718
step: 420, loss: 0.0003505101485643536
step: 430, loss: 9.850205242400989e-05
step: 440, loss: 0.002157473936676979
step: 450, loss: 0.0012710940791293979
step: 460, loss: 0.0012218583142384887
step: 470, loss: 0.00023858417989686131
step: 480, loss: 0.00015296658966690302
step: 490, loss: 0.0008696829318068922
step: 500, loss: 0.0015281129162758589
step: 510, loss: 0.0018056206172332168
step: 520, loss: 0.0005609185318462551
step: 530, loss: 0.016605084761977196
epoch 9: dev_f1=0.7603305785123967, f1=0.7329020332717192, best_f1=0.8053878309335811
step: 0, loss: 0.0006270548910833895
step: 10, loss: 0.00035480453516356647
step: 20, loss: 0.004588710609823465
step: 30, loss: 0.0013239751569926739
step: 40, loss: 0.003331016283482313
step: 50, loss: 0.03147200122475624
step: 60, loss: 0.0032190640922635794
step: 70, loss: 0.010464263148605824
step: 80, loss: 0.0031692807096987963
step: 90, loss: 0.006931263022124767
step: 100, loss: 0.01437334343791008
step: 110, loss: 0.0015846978640183806
step: 120, loss: 0.003879518248140812
step: 130, loss: 0.011992030777037144
step: 140, loss: 0.0015474633546546102
step: 150, loss: 0.021266711875796318
step: 160, loss: 0.00037512261769734323
step: 170, loss: 0.0002881097316276282
step: 180, loss: 0.00040958067984320223
step: 190, loss: 0.00022669175814371556
step: 200, loss: 0.006697661243379116
step: 210, loss: 0.0006931436946615577
step: 220, loss: 5.3834315622225404e-05
step: 230, loss: 0.07095303386449814
step: 240, loss: 0.0005716560990549624
step: 250, loss: 0.0020678741857409477
step: 260, loss: 0.0055654156021773815
step: 270, loss: 0.002078282879665494
step: 280, loss: 0.0001256251853192225
step: 290, loss: 0.04078473895788193
step: 300, loss: 0.004229272250086069
step: 310, loss: 0.003037267131730914
step: 320, loss: 0.00029136447119526565
step: 330, loss: 0.0006780839757993817
step: 340, loss: 0.001708455616608262
step: 350, loss: 0.001588088576681912
step: 360, loss: 0.005663870368152857
step: 370, loss: 0.000196508874068968
step: 380, loss: 0.007860282436013222
step: 390, loss: 0.00014631537487730384
step: 400, loss: 8.621333836345002e-05
step: 410, loss: 0.019627101719379425
step: 420, loss: 0.0006209358689375222
step: 430, loss: 0.004638931713998318
step: 440, loss: 8.63655805005692e-05
step: 450, loss: 0.00418513547629118
step: 460, loss: 0.0022750641219317913
step: 470, loss: 0.0009282317478209734
step: 480, loss: 0.030055291950702667
step: 490, loss: 0.00032922776881605387
step: 500, loss: 0.00015719073417130858
step: 510, loss: 0.0036577186547219753
step: 520, loss: 0.003531834576278925
step: 530, loss: 0.0002714343136176467
epoch 10: dev_f1=0.762414800389484, f1=0.7592319054652881, best_f1=0.8053878309335811
step: 0, loss: 0.0010160495294257998
step: 10, loss: 0.01018526591360569
step: 20, loss: 0.000818194355815649
step: 30, loss: 0.0004223960277158767
step: 40, loss: 0.00014465628191828728
step: 50, loss: 0.001771342009305954
step: 60, loss: 0.0001250157511094585
step: 70, loss: 0.0010078250197693706
step: 80, loss: 0.0016308468766510487
step: 90, loss: 0.003066638018935919
step: 100, loss: 6.738271622452885e-05
step: 110, loss: 0.00010016621672548354
step: 120, loss: 0.0002600178122520447
step: 130, loss: 0.00014881632523611188
step: 140, loss: 5.050508116255514e-05
step: 150, loss: 0.0018421384738758206
step: 160, loss: 0.00017067942826543003
step: 170, loss: 0.003302389057353139
step: 180, loss: 0.037416983395814896
step: 190, loss: 0.00018308752623852342
step: 200, loss: 0.00038822603528387845
step: 210, loss: 0.00017281751206610352
step: 220, loss: 0.00019174773478880525
step: 230, loss: 8.632258686702698e-05
step: 240, loss: 0.005199565552175045
step: 250, loss: 0.001959068002179265
step: 260, loss: 0.010608691722154617
step: 270, loss: 5.076069646747783e-05
step: 280, loss: 0.0006755903013981879
step: 290, loss: 0.0017747964011505246
step: 300, loss: 0.001005251775495708
step: 310, loss: 4.410921974340454e-05
step: 320, loss: 0.07776046544313431
step: 330, loss: 0.003553721122443676
step: 340, loss: 0.0001105687115341425
step: 350, loss: 0.000379272474674508
step: 360, loss: 0.050560131669044495
step: 370, loss: 0.03064899519085884
step: 380, loss: 7.035431917756796e-05
step: 390, loss: 0.043398283421993256
step: 400, loss: 0.00015817790699657053
step: 410, loss: 0.002079792320728302
step: 420, loss: 0.00028814180404879153
step: 430, loss: 5.564056846196763e-05
step: 440, loss: 0.00024067469348665327
step: 450, loss: 0.06235015392303467
step: 460, loss: 0.006319876294583082
step: 470, loss: 0.00011627809726633132
step: 480, loss: 0.0005449877353385091
step: 490, loss: 0.0019306652247905731
step: 500, loss: 0.15048344433307648
step: 510, loss: 0.010841785930097103
step: 520, loss: 0.00017682950419839472
step: 530, loss: 0.0005303653888404369
epoch 11: dev_f1=0.8084153983885407, f1=0.7996389891696751, best_f1=0.8053878309335811
step: 0, loss: 0.03857574239373207
step: 10, loss: 0.0034296202939003706
step: 20, loss: 0.0014536915114149451
step: 30, loss: 0.030479377135634422
step: 40, loss: 0.13486720621585846
step: 50, loss: 0.0008891250472515821
step: 60, loss: 0.0006960015161894262
step: 70, loss: 0.015093639492988586
step: 80, loss: 0.0003417908737901598
step: 90, loss: 0.003568011336028576
step: 100, loss: 0.01496745366603136
step: 110, loss: 0.004538920242339373
step: 120, loss: 0.00602291664108634
step: 130, loss: 0.00462054368108511
step: 140, loss: 0.010381319560110569
step: 150, loss: 0.0007524831453338265
step: 160, loss: 0.01663491316139698
step: 170, loss: 0.0010329089127480984
step: 180, loss: 0.0020935307256877422
step: 190, loss: 0.000506183598190546
step: 200, loss: 0.00014197142445482314
step: 210, loss: 0.00040575212915427983
step: 220, loss: 0.001212577917613089
step: 230, loss: 0.0050268410705029964
step: 240, loss: 0.0001130265009123832
step: 250, loss: 0.002651830669492483
step: 260, loss: 0.0016318297712132335
step: 270, loss: 9.335154754808173e-05
step: 280, loss: 0.007326439023017883
step: 290, loss: 0.03070083074271679
step: 300, loss: 0.0002347529079997912
step: 310, loss: 0.00024477529223077
step: 320, loss: 0.001366733806207776
step: 330, loss: 0.013915413990616798
step: 340, loss: 0.007411389146000147
step: 350, loss: 9.644719830248505e-05
step: 360, loss: 0.00041927769780158997
step: 370, loss: 0.00032712589018046856
step: 380, loss: 0.00029012825689278543
step: 390, loss: 0.0030888516921550035
step: 400, loss: 0.000573345401789993
step: 410, loss: 0.0005202539614401758
step: 420, loss: 0.0013061508070677519
step: 430, loss: 7.024626393103972e-05
step: 440, loss: 0.002514453837648034
step: 450, loss: 0.009228438138961792
step: 460, loss: 0.00013973942259326577
step: 470, loss: 2.6784187866724096e-05
step: 480, loss: 0.0021832557395100594
step: 490, loss: 0.0032228343188762665
step: 500, loss: 0.0009688095306046307
step: 510, loss: 0.005828108172863722
step: 520, loss: 0.0005558443954214454
step: 530, loss: 0.002013182733207941
epoch 12: dev_f1=0.7896027464443355, f1=0.7747747747747747, best_f1=0.8053878309335811
step: 0, loss: 0.005171030759811401
step: 10, loss: 0.0002481583214830607
step: 20, loss: 0.06045127660036087
step: 30, loss: 0.0005059483228251338
step: 40, loss: 0.00016571857850067317
step: 50, loss: 0.00019538648484740406
step: 60, loss: 0.0005350614082999527
step: 70, loss: 0.00012299811351113021
step: 80, loss: 0.010245073586702347
step: 90, loss: 0.00023271073587238789
step: 100, loss: 0.007668538484722376
step: 110, loss: 0.0009341220138594508
step: 120, loss: 0.06879346072673798
step: 130, loss: 0.00014792078582104295
step: 140, loss: 0.0015647037653252482
step: 150, loss: 0.0006334822974167764
step: 160, loss: 0.0007681581191718578
step: 170, loss: 0.0001379713648930192
step: 180, loss: 0.0001530669251224026
step: 190, loss: 0.0006932461401447654
step: 200, loss: 2.935057091235649e-05
step: 210, loss: 0.005823996849358082
step: 220, loss: 0.00327321863733232
step: 230, loss: 4.2036917875520885e-05
step: 240, loss: 0.013711052015423775
step: 250, loss: 0.002086698543280363
step: 260, loss: 0.05985923483967781
step: 270, loss: 0.001491656992584467
step: 280, loss: 0.006927786394953728
step: 290, loss: 0.02392692118883133
step: 300, loss: 0.0006463252939283848
step: 310, loss: 0.0007333584944717586
step: 320, loss: 6.233925523702055e-05
step: 330, loss: 0.00012185119703644887
step: 340, loss: 7.435215957229957e-05
step: 350, loss: 0.0011434955522418022
step: 360, loss: 0.0009134395513683558
step: 370, loss: 4.8961028369376436e-05
step: 380, loss: 0.0002930540940724313
step: 390, loss: 0.00014800849021412432
step: 400, loss: 0.00968362856656313
step: 410, loss: 0.011039221659302711
step: 420, loss: 0.0017677189316600561
step: 430, loss: 0.0007126369164325297
step: 440, loss: 0.004640583880245686
step: 450, loss: 0.001437074621208012
step: 460, loss: 0.00042426897562108934
step: 470, loss: 7.935181929497048e-05
step: 480, loss: 0.0029769146349281073
step: 490, loss: 0.0007402010960504413
step: 500, loss: 0.001590500702150166
step: 510, loss: 0.0005499043618328869
step: 520, loss: 8.794403402134776e-05
step: 530, loss: 0.00032074557384476066
epoch 13: dev_f1=0.7870967741935484, f1=0.7755868544600939, best_f1=0.8053878309335811
step: 0, loss: 0.0004985922132618725
step: 10, loss: 0.0002956781245302409
step: 20, loss: 0.02310931868851185
step: 30, loss: 0.0007657369715161622
step: 40, loss: 0.0006611471762880683
step: 50, loss: 0.00013301969738677144
step: 60, loss: 0.00034803853486664593
step: 70, loss: 0.00015734271437395364
step: 80, loss: 0.0001697581319604069
step: 90, loss: 5.338576374924742e-05
step: 100, loss: 6.041842789272778e-05
step: 110, loss: 2.0253919501556084e-05
step: 120, loss: 0.00011925565922865644
step: 130, loss: 6.19696220383048e-05
step: 140, loss: 9.786335431272164e-05
step: 150, loss: 4.655998418456875e-05
step: 160, loss: 0.0008938229293562472
step: 170, loss: 3.6784684198210016e-05
step: 180, loss: 3.5452438169158995e-05
step: 190, loss: 0.0002666344225872308
step: 200, loss: 0.04902735352516174
step: 210, loss: 4.128831278649159e-05
step: 220, loss: 5.104980664327741e-05
step: 230, loss: 0.0012480848236009479
step: 240, loss: 0.0002724848745856434
step: 250, loss: 0.0002749849227257073
step: 260, loss: 0.001800450379960239
step: 270, loss: 0.0010628210147842765
step: 280, loss: 3.252463648095727e-05
step: 290, loss: 0.001073224819265306
step: 300, loss: 0.00015122316835913807
step: 310, loss: 0.0001687355834292248
step: 320, loss: 0.00019150765729136765
step: 330, loss: 0.0002303774090250954
step: 340, loss: 0.0002535132225602865
step: 350, loss: 0.002670564455911517
step: 360, loss: 7.181434193626046e-05
step: 370, loss: 0.07909342646598816
step: 380, loss: 0.005714740138500929
step: 390, loss: 0.0003915647102985531
step: 400, loss: 0.0022045923396945
step: 410, loss: 0.0001253202062798664
step: 420, loss: 0.003976327367126942
step: 430, loss: 0.0034390545915812254
step: 440, loss: 0.010971271432936192
step: 450, loss: 0.00014271715190261602
step: 460, loss: 0.00022011650435160846
step: 470, loss: 0.00500506954267621
step: 480, loss: 0.00011167106276843697
step: 490, loss: 0.00046648678835481405
step: 500, loss: 6.288076110649854e-05
step: 510, loss: 0.012940844520926476
step: 520, loss: 0.001451303018257022
step: 530, loss: 7.02308607287705e-05
epoch 14: dev_f1=0.78574650428507, f1=0.7782764811490125, best_f1=0.8053878309335811
step: 0, loss: 0.00038561050314456224
step: 10, loss: 0.0001616479130461812
step: 20, loss: 5.5395164963556454e-05
step: 30, loss: 0.07355184108018875
step: 40, loss: 0.0008977772668004036
step: 50, loss: 0.003213294316083193
step: 60, loss: 0.0027053430676460266
step: 70, loss: 6.955346907489002e-05
step: 80, loss: 0.0595673993229866
step: 90, loss: 0.000252467580139637
step: 100, loss: 0.00014462300168816
step: 110, loss: 0.0037589112762361765
step: 120, loss: 0.0001393581769661978
step: 130, loss: 0.0015236189356073737
step: 140, loss: 0.00011432050814619288
step: 150, loss: 0.03513973206281662
step: 160, loss: 0.001299807452596724
step: 170, loss: 2.88774972432293e-05
step: 180, loss: 0.008923332206904888
step: 190, loss: 0.0005284827202558517
step: 200, loss: 0.000885196786839515
step: 210, loss: 6.970568938413635e-05
step: 220, loss: 0.001070532132871449
step: 230, loss: 0.0006002470618113875
step: 240, loss: 4.8027093725977466e-05
step: 250, loss: 0.0012416617246344686
step: 260, loss: 8.982240979094058e-05
step: 270, loss: 0.00675320765003562
step: 280, loss: 0.00035867057158611715
step: 290, loss: 6.13583906670101e-05
step: 300, loss: 0.0001177920275949873
step: 310, loss: 0.0002547537151258439
step: 320, loss: 3.611521242419258e-05
step: 330, loss: 0.0006339831743389368
step: 340, loss: 0.0004785069322679192
step: 350, loss: 0.0008076733211055398
step: 360, loss: 0.000665891682729125
step: 370, loss: 1.7013142496580258e-05
step: 380, loss: 3.318175004096702e-05
step: 390, loss: 0.002630055183544755
step: 400, loss: 5.387826240621507e-05
step: 410, loss: 4.0133385482477024e-05
step: 420, loss: 0.001400512526743114
step: 430, loss: 0.0006839144043624401
step: 440, loss: 0.00024907311308197677
step: 450, loss: 0.00018263027595821768
step: 460, loss: 0.002935426076874137
step: 470, loss: 6.0234160628169775e-05
step: 480, loss: 0.00012266052362974733
step: 490, loss: 2.806910742947366e-05
step: 500, loss: 0.00020257044525351375
step: 510, loss: 0.003434405429288745
step: 520, loss: 0.006216602399945259
step: 530, loss: 0.00016834534471854568
epoch 15: dev_f1=0.7650375939849625, f1=0.7448405253283302, best_f1=0.8053878309335811
step: 0, loss: 0.0002695975126698613
step: 10, loss: 6.604793452424929e-05
step: 20, loss: 3.161897257086821e-05
step: 30, loss: 3.905693665728904e-05
step: 40, loss: 0.0003638504131231457
step: 50, loss: 0.0011948597384616733
step: 60, loss: 0.06473661214113235
step: 70, loss: 0.00011496258957777172
step: 80, loss: 6.0780716012232006e-05
step: 90, loss: 0.00015118940791580826
step: 100, loss: 0.00023997975222300738
step: 110, loss: 0.0005935185472480953
step: 120, loss: 9.163188224192709e-05
step: 130, loss: 0.02248266711831093
step: 140, loss: 9.055321424966678e-05
step: 150, loss: 0.0002895434736274183
step: 160, loss: 3.8327470974763855e-05
step: 170, loss: 9.105751087190583e-05
step: 180, loss: 0.00042758628842420876
step: 190, loss: 0.000339936203090474
step: 200, loss: 4.815828651771881e-05
step: 210, loss: 0.0005529374466277659
step: 220, loss: 0.00010000979818869382
step: 230, loss: 3.6666326195700094e-05
step: 240, loss: 6.685389234917238e-05
step: 250, loss: 0.00014370046847034246
step: 260, loss: 7.610518514411524e-05
step: 270, loss: 0.0007217447855509818
step: 280, loss: 6.622934597544372e-05
step: 290, loss: 0.0006696757627651095
step: 300, loss: 0.0005302073550410569
step: 310, loss: 8.482023986289278e-05
step: 320, loss: 0.00013565184781327844
step: 330, loss: 0.0003673742467071861
step: 340, loss: 7.609669410157949e-05
step: 350, loss: 2.1099533114465885e-05
step: 360, loss: 0.0008630838128738105
step: 370, loss: 4.886341776000336e-05
step: 380, loss: 8.770148269832134e-05
step: 390, loss: 0.0007537470082752407
step: 400, loss: 0.00020231529197189957
step: 410, loss: 7.194579666247591e-05
step: 420, loss: 5.2347382734296843e-05
step: 430, loss: 0.00041634621447883546
step: 440, loss: 0.0007324889884330332
step: 450, loss: 0.0005452230689115822
step: 460, loss: 3.422446388867684e-05
step: 470, loss: 8.721736230654642e-05
step: 480, loss: 0.0001295063557336107
step: 490, loss: 4.061283470946364e-05
step: 500, loss: 0.00012714207696262747
step: 510, loss: 3.235544136259705e-05
step: 520, loss: 0.00011452860780991614
step: 530, loss: 3.0918734410079196e-05
epoch 16: dev_f1=0.7847490347490348, f1=0.7675885492479378, best_f1=0.8053878309335811
step: 0, loss: 0.0020296801812946796
step: 10, loss: 8.610499207861722e-05
step: 20, loss: 1.706904913589824e-05
step: 30, loss: 0.0010694361990317702
step: 40, loss: 8.98475045687519e-05
step: 50, loss: 0.0005801122752018273
step: 60, loss: 4.262478250893764e-05
step: 70, loss: 0.0003014488029293716
step: 80, loss: 6.808024045312777e-05
step: 90, loss: 3.257206844864413e-05
step: 100, loss: 0.0007617478258907795
step: 110, loss: 8.713638817425817e-05
step: 120, loss: 0.00013515385217033327
step: 130, loss: 0.000900326413102448
step: 140, loss: 2.24735849769786e-05
step: 150, loss: 4.8613655962981284e-05
step: 160, loss: 0.00010823713819263503
step: 170, loss: 8.713429269846529e-05
step: 180, loss: 0.0023643660824745893
step: 190, loss: 0.00035574534558691084
step: 200, loss: 6.202062650118023e-05
step: 210, loss: 4.777828144142404e-05
step: 220, loss: 0.0019049361580982804
step: 230, loss: 0.00022086151875555515
step: 240, loss: 0.00024106536875478923
step: 250, loss: 0.0005117993569001555
step: 260, loss: 6.156696326797828e-05
step: 270, loss: 2.9658875064342283e-05
step: 280, loss: 3.37880956067238e-05
step: 290, loss: 2.980474164360203e-05
step: 300, loss: 0.0002327595284441486
step: 310, loss: 3.795458178501576e-05
step: 320, loss: 6.42311351839453e-05
step: 330, loss: 0.00015403302677441388
step: 340, loss: 2.2459142201114446e-05
step: 350, loss: 0.00010363502951804549
step: 360, loss: 2.239952482341323e-05
step: 370, loss: 0.000477059802506119
step: 380, loss: 0.0002641190367285162
step: 390, loss: 0.00022220760001800954
step: 400, loss: 0.00821694079786539
step: 410, loss: 3.460106017882936e-05
step: 420, loss: 2.76481168839382e-05
step: 430, loss: 3.0315006370074116e-05
step: 440, loss: 4.120961602893658e-05
step: 450, loss: 7.352276588790119e-05
step: 460, loss: 2.4552706236136146e-05
step: 470, loss: 7.808301597833633e-05
step: 480, loss: 7.206301961559802e-05
step: 490, loss: 0.0026576765812933445
step: 500, loss: 0.00029831455321982503
step: 510, loss: 0.0011116282548755407
step: 520, loss: 3.4252298064529896e-05
step: 530, loss: 0.006764392368495464
epoch 17: dev_f1=0.8079777365491652, f1=0.7932804479701354, best_f1=0.8053878309335811
step: 0, loss: 8.768913539825007e-05
step: 10, loss: 0.0004401933401823044
step: 20, loss: 0.047650888562202454
step: 30, loss: 4.5168599172029644e-05
step: 40, loss: 0.011607005260884762
step: 50, loss: 0.0001813523267628625
step: 60, loss: 1.8175294826505706e-05
step: 70, loss: 6.486367055913433e-05
step: 80, loss: 0.00032097959774546325
step: 90, loss: 8.01906717242673e-05
step: 100, loss: 3.8084046536823735e-05
step: 110, loss: 0.0033702633809298277
step: 120, loss: 1.9959727069362998e-05
step: 130, loss: 3.0287237677839585e-05
step: 140, loss: 3.381658098078333e-05
step: 150, loss: 0.00019000729662366211
step: 160, loss: 0.0005026192520745099
step: 170, loss: 2.8254351491341367e-05
step: 180, loss: 5.357444388209842e-05
step: 190, loss: 5.6299577408935875e-05
step: 200, loss: 0.0002304892404936254
step: 210, loss: 0.07334568351507187
step: 220, loss: 4.8407855501864105e-05
step: 230, loss: 3.4503831557231024e-05
step: 240, loss: 3.2641826692270115e-05
step: 250, loss: 5.2447488997131586e-05
step: 260, loss: 5.6278400734299794e-05
step: 270, loss: 0.0002656487631611526
step: 280, loss: 3.7651472666766495e-05
step: 290, loss: 6.851083162473515e-05
step: 300, loss: 8.043250272748992e-05
step: 310, loss: 0.007934929803013802
step: 320, loss: 4.4164738937979564e-05
step: 330, loss: 2.3822603907319717e-05
step: 340, loss: 0.00014666037168353796
step: 350, loss: 0.0004342756583355367
step: 360, loss: 0.0008147599874064326
step: 370, loss: 0.00022348560742102563
step: 380, loss: 0.0010728930355980992
step: 390, loss: 0.003170486306771636
step: 400, loss: 0.00022703464492224157
step: 410, loss: 3.445756738074124e-05
step: 420, loss: 6.337741069728509e-05
step: 430, loss: 2.5055251171579584e-05
step: 440, loss: 0.00020243228937033564
step: 450, loss: 0.00014218315482139587
step: 460, loss: 7.486279355362058e-05
step: 470, loss: 2.3721568140899763e-05
step: 480, loss: 2.479446084180381e-05
step: 490, loss: 6.468168430728838e-05
step: 500, loss: 0.00017132317589130253
step: 510, loss: 0.003639490809291601
step: 520, loss: 0.0007658340036869049
step: 530, loss: 0.0034815603867173195
epoch 18: dev_f1=0.797335870599429, f1=0.7810707456978968, best_f1=0.8053878309335811
step: 0, loss: 4.47470010840334e-05
step: 10, loss: 5.327509643393569e-05
step: 20, loss: 4.3393058149376884e-05
step: 30, loss: 8.832127787172794e-05
step: 40, loss: 0.0031055808067321777
step: 50, loss: 7.10193780832924e-05
step: 60, loss: 0.00012839611736126244
step: 70, loss: 5.5891745432745665e-05
step: 80, loss: 0.0003740374813787639
step: 90, loss: 4.967119821230881e-05
step: 100, loss: 0.0005494910292327404
step: 110, loss: 4.179742609267123e-05
step: 120, loss: 2.3375183445750736e-05
step: 130, loss: 0.001019444316625595
step: 140, loss: 0.003966725431382656
step: 150, loss: 0.00038666947511956096
step: 160, loss: 0.0017314325086772442
step: 170, loss: 0.0002819595392793417
step: 180, loss: 9.027560736285523e-05
step: 190, loss: 0.00016390877135563642
step: 200, loss: 0.00013801011664327234
step: 210, loss: 0.00037951092235744
step: 220, loss: 6.217422924237326e-05
step: 230, loss: 0.0005373323219828308
step: 240, loss: 2.9220196665846743e-05
step: 250, loss: 0.000115771203127224
step: 260, loss: 4.766836354974657e-05
step: 270, loss: 0.0008571354555897415
step: 280, loss: 5.264501305646263e-05
step: 290, loss: 4.053409429616295e-05
step: 300, loss: 2.3856029656599276e-05
step: 310, loss: 5.582016092375852e-05
step: 320, loss: 6.314710481092334e-05
step: 330, loss: 0.01489381305873394
step: 340, loss: 3.409807322896086e-05
step: 350, loss: 3.281359022366814e-05
step: 360, loss: 1.721052649372723e-05
step: 370, loss: 3.566033410606906e-05
step: 380, loss: 3.988004755228758e-05
step: 390, loss: 3.6582991015166044e-05
step: 400, loss: 7.996021304279566e-05
step: 410, loss: 2.1006113456678577e-05
step: 420, loss: 4.4811691623181105e-05
step: 430, loss: 0.0033049029298126698
step: 440, loss: 2.1486985133378766e-05
step: 450, loss: 0.031058648601174355
step: 460, loss: 6.609340198338032e-05
step: 470, loss: 3.88120643037837e-05
step: 480, loss: 0.0013141981326043606
step: 490, loss: 0.028403757140040398
step: 500, loss: 4.947893103235401e-05
step: 510, loss: 0.00014846841804683208
step: 520, loss: 4.8944679292617366e-05
step: 530, loss: 2.6478224754100665e-05
epoch 19: dev_f1=0.7988826815642458, f1=0.782608695652174, best_f1=0.8053878309335811
step: 0, loss: 0.00019668291497509927
step: 10, loss: 0.0003320460964459926
step: 20, loss: 1.4777992873860057e-05
step: 30, loss: 4.7004494263092056e-05
step: 40, loss: 3.945167554775253e-05
step: 50, loss: 0.0004456894821487367
step: 60, loss: 0.00033037731191143394
step: 70, loss: 0.0020038371440023184
step: 80, loss: 3.8009729905752465e-05
step: 90, loss: 8.587430784245953e-05
step: 100, loss: 2.8507291062851436e-05
step: 110, loss: 8.378682105103508e-05
step: 120, loss: 0.006682629697024822
step: 130, loss: 3.0295717806438915e-05
step: 140, loss: 3.69785848306492e-05
step: 150, loss: 8.806148980511352e-05
step: 160, loss: 5.1233189878985286e-05
step: 170, loss: 1.7411730368621647e-05
step: 180, loss: 0.006461669225245714
step: 190, loss: 2.1814819774590433e-05
step: 200, loss: 0.10539936274290085
step: 210, loss: 7.221935811685398e-05
step: 220, loss: 0.0004453993169590831
step: 230, loss: 3.960337198805064e-05
step: 240, loss: 0.00010898100299527869
step: 250, loss: 2.6016599804279394e-05
step: 260, loss: 2.9523389457608573e-05
step: 270, loss: 0.0001290041400352493
step: 280, loss: 7.499464845750481e-05
step: 290, loss: 0.0002193192922277376
step: 300, loss: 3.896738780895248e-05
step: 310, loss: 0.027049517259001732
step: 320, loss: 5.161389344721101e-05
step: 330, loss: 0.00021784004638902843
step: 340, loss: 0.0019509249832481146
step: 350, loss: 9.869565110420808e-05
step: 360, loss: 8.03667280706577e-05
step: 370, loss: 0.0001370971731375903
step: 380, loss: 2.5133276722044684e-05
step: 390, loss: 2.4775075871730223e-05
step: 400, loss: 0.0008003396214917302
step: 410, loss: 4.0574639569967985e-05
step: 420, loss: 0.0013940958306193352
step: 430, loss: 5.646396675729193e-05
step: 440, loss: 3.2981271942844614e-05
step: 450, loss: 8.890540630090982e-05
step: 460, loss: 3.3038126275641844e-05
step: 470, loss: 2.3591366698383354e-05
step: 480, loss: 0.0003084978670813143
step: 490, loss: 0.00013145396951586008
step: 500, loss: 0.010616681538522243
step: 510, loss: 5.29058524989523e-05
step: 520, loss: 3.5954039049101993e-05
step: 530, loss: 8.087302558124065e-05
epoch 20: dev_f1=0.8020589611605055, f1=0.7817925856405442, best_f1=0.8053878309335811
