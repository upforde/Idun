cuda
Device: cuda
step: 0, loss: 0.6084892749786377
step: 10, loss: 0.46419021487236023
step: 20, loss: 0.3157910108566284
step: 30, loss: 0.352604478597641
step: 40, loss: 0.21688030660152435
step: 50, loss: 0.29132530093193054
step: 60, loss: 0.31499797105789185
step: 70, loss: 0.4296838939189911
step: 80, loss: 0.18669143319129944
step: 90, loss: 0.33199164271354675
step: 100, loss: 0.2082609236240387
step: 110, loss: 0.2477252185344696
step: 120, loss: 0.37501266598701477
step: 130, loss: 0.44415247440338135
step: 140, loss: 0.4002857208251953
step: 150, loss: 0.15935690701007843
step: 160, loss: 0.33772364258766174
step: 170, loss: 0.10648350417613983
step: 180, loss: 0.19958211481571198
step: 190, loss: 0.0957794338464737
step: 200, loss: 0.15645582973957062
step: 210, loss: 0.23114299774169922
step: 220, loss: 0.11617148667573929
step: 230, loss: 0.06520377099514008
step: 240, loss: 0.07623901218175888
step: 250, loss: 0.17848923802375793
step: 260, loss: 0.25932690501213074
step: 270, loss: 0.11079894006252289
step: 280, loss: 0.06798654794692993
step: 290, loss: 0.2459033578634262
step: 300, loss: 0.33888089656829834
step: 310, loss: 0.06846699863672256
step: 320, loss: 0.12179234623908997
step: 330, loss: 0.12652023136615753
step: 340, loss: 0.052191220223903656
step: 350, loss: 0.09900064021348953
step: 360, loss: 0.033807165920734406
step: 370, loss: 0.11428987979888916
step: 380, loss: 0.16830840706825256
step: 390, loss: 0.12663762271404266
step: 400, loss: 0.10685143619775772
step: 410, loss: 0.07721932977437973
step: 420, loss: 0.08804003149271011
step: 430, loss: 0.06118600443005562
step: 440, loss: 0.18355897068977356
step: 450, loss: 0.23297461867332458
step: 460, loss: 0.1705802083015442
step: 470, loss: 0.05711362138390541
step: 480, loss: 0.03539183363318443
step: 490, loss: 0.09608327597379684
step: 500, loss: 0.20252765715122223
step: 510, loss: 0.03527386486530304
step: 520, loss: 0.1775205284357071
step: 530, loss: 0.04719975218176842
epoch 1: dev_f1=0.7108843537414966, f1=0.6907351022183559, best_f1=0.6907351022183559
step: 0, loss: 0.06608247011899948
step: 10, loss: 0.08643461018800735
step: 20, loss: 0.052598658949136734
step: 30, loss: 0.08513785898685455
step: 40, loss: 0.24829921126365662
step: 50, loss: 0.06916577368974686
step: 60, loss: 0.06019079312682152
step: 70, loss: 0.02161666378378868
step: 80, loss: 0.04494114965200424
step: 90, loss: 0.2105211615562439
step: 100, loss: 0.07644990086555481
step: 110, loss: 0.07055886834859848
step: 120, loss: 0.10091793537139893
step: 130, loss: 0.02559283934533596
step: 140, loss: 0.06962083280086517
step: 150, loss: 0.14014194905757904
step: 160, loss: 0.09393870830535889
step: 170, loss: 0.0087989941239357
step: 180, loss: 0.12130111455917358
step: 190, loss: 0.11666090041399002
step: 200, loss: 0.11321850121021271
step: 210, loss: 0.13040487468242645
step: 220, loss: 0.054044146090745926
step: 230, loss: 0.06723800301551819
step: 240, loss: 0.1111997738480568
step: 250, loss: 0.0015064254403114319
step: 260, loss: 0.03248826041817665
step: 270, loss: 0.21417231857776642
step: 280, loss: 0.36722809076309204
step: 290, loss: 0.04072605445981026
step: 300, loss: 0.005165558308362961
step: 310, loss: 0.04670608416199684
step: 320, loss: 0.10326872020959854
step: 330, loss: 0.20905821025371552
step: 340, loss: 0.06596246361732483
step: 350, loss: 0.16448049247264862
step: 360, loss: 0.023016145452857018
step: 370, loss: 0.06653119623661041
step: 380, loss: 0.0807771384716034
step: 390, loss: 0.12197983264923096
step: 400, loss: 0.16495490074157715
step: 410, loss: 0.2952740490436554
step: 420, loss: 0.01954081282019615
step: 430, loss: 0.05923355370759964
step: 440, loss: 0.1430967152118683
step: 450, loss: 0.0930139496922493
step: 460, loss: 0.0904880091547966
step: 470, loss: 0.20694662630558014
step: 480, loss: 0.11788426339626312
step: 490, loss: 0.021110747009515762
step: 500, loss: 0.1560804545879364
step: 510, loss: 0.09797580540180206
step: 520, loss: 0.06322748214006424
step: 530, loss: 0.07973230630159378
epoch 2: dev_f1=0.7949640287769786, f1=0.7752707581227436, best_f1=0.7752707581227436
step: 0, loss: 0.05724363401532173
step: 10, loss: 0.1137315109372139
step: 20, loss: 0.08226855099201202
step: 30, loss: 0.08523430675268173
step: 40, loss: 0.07525695115327835
step: 50, loss: 0.004870516713708639
step: 60, loss: 0.07786527276039124
step: 70, loss: 0.09841500222682953
step: 80, loss: 0.06624774634838104
step: 90, loss: 0.024385541677474976
step: 100, loss: 0.044021714478731155
step: 110, loss: 0.006631738971918821
step: 120, loss: 0.04562130570411682
step: 130, loss: 0.04454345628619194
step: 140, loss: 0.12673446536064148
step: 150, loss: 0.007771826349198818
step: 160, loss: 0.027303243055939674
step: 170, loss: 0.00770881213247776
step: 180, loss: 0.021441150456666946
step: 190, loss: 0.043248508125543594
step: 200, loss: 0.02696266584098339
step: 210, loss: 0.07311908900737762
step: 220, loss: 0.07139940559864044
step: 230, loss: 0.08565803617238998
step: 240, loss: 0.02957962453365326
step: 250, loss: 0.06515254825353622
step: 260, loss: 0.06973303109407425
step: 270, loss: 0.05893972888588905
step: 280, loss: 0.023270493373274803
step: 290, loss: 0.04254445061087608
step: 300, loss: 0.044855255633592606
step: 310, loss: 0.053305383771657944
step: 320, loss: 0.0700075775384903
step: 330, loss: 0.10567928850650787
step: 340, loss: 0.019597534090280533
step: 350, loss: 0.034103672951459885
step: 360, loss: 0.11357922106981277
step: 370, loss: 0.031928375363349915
step: 380, loss: 0.008717234246432781
step: 390, loss: 0.05002923682332039
step: 400, loss: 0.04557868465781212
step: 410, loss: 0.013463241048157215
step: 420, loss: 0.2092483937740326
step: 430, loss: 0.035800423473119736
step: 440, loss: 0.02410227060317993
step: 450, loss: 0.04052753001451492
step: 460, loss: 0.03939591348171234
step: 470, loss: 0.006820895709097385
step: 480, loss: 0.047938499599695206
step: 490, loss: 0.2258238047361374
step: 500, loss: 0.1902683824300766
step: 510, loss: 0.03768395259976387
step: 520, loss: 0.020635945722460747
step: 530, loss: 0.09405902773141861
epoch 3: dev_f1=0.8055427251732101, f1=0.7728337236533959, best_f1=0.7728337236533959
step: 0, loss: 0.020268352702260017
step: 10, loss: 0.02020847797393799
step: 20, loss: 0.06328590214252472
step: 30, loss: 0.03503373637795448
step: 40, loss: 0.006201125215739012
step: 50, loss: 0.04354766756296158
step: 60, loss: 0.05475149676203728
step: 70, loss: 0.012149611487984657
step: 80, loss: 0.033261340111494064
step: 90, loss: 0.00861863698810339
step: 100, loss: 0.028345005586743355
step: 110, loss: 0.033886004239320755
step: 120, loss: 0.015608374960720539
step: 130, loss: 0.03890514373779297
step: 140, loss: 0.08935308456420898
step: 150, loss: 0.13853512704372406
step: 160, loss: 0.12128166109323502
step: 170, loss: 0.0381639301776886
step: 180, loss: 0.10076301544904709
step: 190, loss: 0.04821430891752243
step: 200, loss: 0.13731598854064941
step: 210, loss: 0.1067262589931488
step: 220, loss: 0.048722926527261734
step: 230, loss: 0.017281129956245422
step: 240, loss: 0.13389188051223755
step: 250, loss: 0.059481486678123474
step: 260, loss: 0.05454624816775322
step: 270, loss: 0.07272734493017197
step: 280, loss: 0.034936077892780304
step: 290, loss: 0.047637227922677994
step: 300, loss: 0.051251742988824844
step: 310, loss: 0.112569160759449
step: 320, loss: 0.1450600028038025
step: 330, loss: 0.060032278299331665
step: 340, loss: 0.19415788352489471
step: 350, loss: 0.003006366081535816
step: 360, loss: 0.05926411971449852
step: 370, loss: 0.015180888585746288
step: 380, loss: 0.0056653693318367004
step: 390, loss: 0.04962996393442154
step: 400, loss: 0.07958173751831055
step: 410, loss: 0.02177567034959793
step: 420, loss: 0.08294976502656937
step: 430, loss: 0.0636315867304802
step: 440, loss: 0.07536512613296509
step: 450, loss: 0.08281178772449493
step: 460, loss: 0.027767792344093323
step: 470, loss: 0.07470829784870148
step: 480, loss: 0.023520277813076973
step: 490, loss: 0.07432328909635544
step: 500, loss: 0.04690797999501228
step: 510, loss: 0.09520068764686584
step: 520, loss: 0.012902132235467434
step: 530, loss: 0.11376737058162689
epoch 4: dev_f1=0.7770050996754753, f1=0.7432624113475178, best_f1=0.7728337236533959
step: 0, loss: 0.07630554586648941
step: 10, loss: 0.009725003503262997
step: 20, loss: 0.056650515645742416
step: 30, loss: 0.10052786767482758
step: 40, loss: 0.17412368953227997
step: 50, loss: 0.02258395403623581
step: 60, loss: 0.013072595000267029
step: 70, loss: 0.03536082059144974
step: 80, loss: 0.00372900883667171
step: 90, loss: 0.0015098161529749632
step: 100, loss: 0.021368421614170074
step: 110, loss: 0.07874732464551926
step: 120, loss: 0.061305973678827286
step: 130, loss: 0.07406606525182724
step: 140, loss: 0.0034110299311578274
step: 150, loss: 0.00880209356546402
step: 160, loss: 0.04752849414944649
step: 170, loss: 0.15859660506248474
step: 180, loss: 0.006525514181703329
step: 190, loss: 0.11948811262845993
step: 200, loss: 0.1125279888510704
step: 210, loss: 0.002525195013731718
step: 220, loss: 0.04830792546272278
step: 230, loss: 0.010865346528589725
step: 240, loss: 0.0017393783200532198
step: 250, loss: 0.005926597397774458
step: 260, loss: 0.0015458567067980766
step: 270, loss: 0.004716562572866678
step: 280, loss: 0.004372084978967905
step: 290, loss: 0.04606761038303375
step: 300, loss: 0.057460129261016846
step: 310, loss: 0.11456849426031113
step: 320, loss: 0.029902679845690727
step: 330, loss: 0.024562159553170204
step: 340, loss: 0.16386008262634277
step: 350, loss: 0.006817812565714121
step: 360, loss: 0.10565659403800964
step: 370, loss: 0.0667668879032135
step: 380, loss: 0.1383168250322342
step: 390, loss: 0.002729896456003189
step: 400, loss: 0.0614577941596508
step: 410, loss: 0.002371228998526931
step: 420, loss: 0.13202232122421265
step: 430, loss: 0.09162517637014389
step: 440, loss: 0.001134074991568923
step: 450, loss: 0.02021964266896248
step: 460, loss: 0.004694635979831219
step: 470, loss: 0.025025557726621628
step: 480, loss: 0.04375707730650902
step: 490, loss: 0.008900835178792477
step: 500, loss: 0.008066228590905666
step: 510, loss: 0.13416536152362823
step: 520, loss: 0.0007090658182278275
step: 530, loss: 0.06348395347595215
epoch 5: dev_f1=0.769434628975265, f1=0.7213842058562556, best_f1=0.7728337236533959
step: 0, loss: 0.01422024518251419
step: 10, loss: 0.06253617256879807
step: 20, loss: 0.06618116050958633
step: 30, loss: 0.12405037134885788
step: 40, loss: 0.004692853894084692
step: 50, loss: 0.01665208302438259
step: 60, loss: 0.036145955324172974
step: 70, loss: 0.004307526163756847
step: 80, loss: 0.011071705259382725
step: 90, loss: 0.03196759521961212
step: 100, loss: 0.007480624131858349
step: 110, loss: 0.024350052699446678
step: 120, loss: 0.053894054144620895
step: 130, loss: 0.04187984764575958
step: 140, loss: 0.051150914281606674
step: 150, loss: 0.0015463934978470206
step: 160, loss: 0.004309419542551041
step: 170, loss: 0.0037979355547577143
step: 180, loss: 0.0817003920674324
step: 190, loss: 0.05068105459213257
step: 200, loss: 0.020210323855280876
step: 210, loss: 0.01780576817691326
step: 220, loss: 0.02590142749249935
step: 230, loss: 0.0090485829859972
step: 240, loss: 0.0014211487723514438
step: 250, loss: 0.00817611999809742
step: 260, loss: 0.006867618765681982
step: 270, loss: 0.009917022660374641
step: 280, loss: 0.007474239449948072
step: 290, loss: 0.19673120975494385
step: 300, loss: 0.064860038459301
step: 310, loss: 0.017891094088554382
step: 320, loss: 0.021973535418510437
step: 330, loss: 0.006245979107916355
step: 340, loss: 0.00430938508361578
step: 350, loss: 0.05149625614285469
step: 360, loss: 0.03433248773217201
step: 370, loss: 0.015173046849668026
step: 380, loss: 0.016086719930171967
step: 390, loss: 0.017997009679675102
step: 400, loss: 0.044817786663770676
step: 410, loss: 0.0006259753135964274
step: 420, loss: 0.006853282917290926
step: 430, loss: 0.0006640055798925459
step: 440, loss: 0.0007757548009976745
step: 450, loss: 0.014308174140751362
step: 460, loss: 0.03741786628961563
step: 470, loss: 0.007209367584437132
step: 480, loss: 0.1369793713092804
step: 490, loss: 0.0612679123878479
step: 500, loss: 0.004205463454127312
step: 510, loss: 0.0050727748312056065
step: 520, loss: 0.008256538771092892
step: 530, loss: 0.045561641454696655
epoch 6: dev_f1=0.8121546961325966, f1=0.7865375749193176, best_f1=0.7865375749193176
step: 0, loss: 0.0052186609245836735
step: 10, loss: 0.021393373608589172
step: 20, loss: 0.0004632338532246649
step: 30, loss: 0.03099232353270054
step: 40, loss: 0.0007464699447154999
step: 50, loss: 0.09411754459142685
step: 60, loss: 0.02804313786327839
step: 70, loss: 0.02259582281112671
step: 80, loss: 0.018776461482048035
step: 90, loss: 0.025073878467082977
step: 100, loss: 0.008552728220820427
step: 110, loss: 0.00954439491033554
step: 120, loss: 0.04055375978350639
step: 130, loss: 0.021301312372088432
step: 140, loss: 0.002166516613215208
step: 150, loss: 0.000509638455696404
step: 160, loss: 0.004666544497013092
step: 170, loss: 0.05169684812426567
step: 180, loss: 0.0036506974138319492
step: 190, loss: 0.0022395087871700525
step: 200, loss: 0.0024212561547756195
step: 210, loss: 0.012895438820123672
step: 220, loss: 0.005926381330937147
step: 230, loss: 0.10838888585567474
step: 240, loss: 0.0007400619797408581
step: 250, loss: 0.017080968245863914
step: 260, loss: 0.005115082021802664
step: 270, loss: 0.0008391882875002921
step: 280, loss: 0.06977470964193344
step: 290, loss: 0.03057199716567993
step: 300, loss: 0.0007232606294564903
step: 310, loss: 0.0757962092757225
step: 320, loss: 0.003528868779540062
step: 330, loss: 0.00872064009308815
step: 340, loss: 0.0006962500046938658
step: 350, loss: 0.025587258860468864
step: 360, loss: 0.030564695596694946
step: 370, loss: 0.012820682488381863
step: 380, loss: 0.011320961639285088
step: 390, loss: 0.0010993926553055644
step: 400, loss: 0.016670627519488335
step: 410, loss: 0.003780580824241042
step: 420, loss: 0.01816234365105629
step: 430, loss: 0.011128866113722324
step: 440, loss: 0.00039838807424530387
step: 450, loss: 0.018447328358888626
step: 460, loss: 0.14011096954345703
step: 470, loss: 0.07388715445995331
step: 480, loss: 0.00040119074401445687
step: 490, loss: 0.011287551373243332
step: 500, loss: 0.0008475224603898823
step: 510, loss: 0.027569595724344254
step: 520, loss: 0.0002432313049212098
step: 530, loss: 0.01925269514322281
epoch 7: dev_f1=0.803347280334728, f1=0.7596466759646676, best_f1=0.7865375749193176
step: 0, loss: 0.0023716215509921312
step: 10, loss: 0.005331105086952448
step: 20, loss: 0.007935653440654278
step: 30, loss: 0.017912231385707855
step: 40, loss: 0.0004877258907072246
step: 50, loss: 0.002316346624866128
step: 60, loss: 0.0003255168267060071
step: 70, loss: 0.007012967020273209
step: 80, loss: 0.008518618531525135
step: 90, loss: 0.00241670198738575
step: 100, loss: 0.001562307821586728
step: 110, loss: 0.10293912887573242
step: 120, loss: 0.0005345089011825621
step: 130, loss: 0.006697963923215866
step: 140, loss: 0.0005722789210267365
step: 150, loss: 0.0005085661541670561
step: 160, loss: 0.005444584880024195
step: 170, loss: 0.0006252777529880404
step: 180, loss: 0.025142474099993706
step: 190, loss: 0.007423642091453075
step: 200, loss: 0.002913451986387372
step: 210, loss: 0.001133705023676157
step: 220, loss: 0.0033756126649677753
step: 230, loss: 0.02116125077009201
step: 240, loss: 0.001024127472192049
step: 250, loss: 0.007584104314446449
step: 260, loss: 0.04987811669707298
step: 270, loss: 0.014741482213139534
step: 280, loss: 0.015252945944666862
step: 290, loss: 0.0324353389441967
step: 300, loss: 0.007428301032632589
step: 310, loss: 0.006009237840771675
step: 320, loss: 0.034739185124635696
step: 330, loss: 0.0021406810265034437
step: 340, loss: 0.027372367680072784
step: 350, loss: 0.00016439026512671262
step: 360, loss: 0.01801193878054619
step: 370, loss: 0.03197873383760452
step: 380, loss: 0.08575381338596344
step: 390, loss: 0.0033740056678652763
step: 400, loss: 0.0033111334778368473
step: 410, loss: 0.1085016131401062
step: 420, loss: 0.09467256814241409
step: 430, loss: 0.00038237785338424146
step: 440, loss: 0.043235693126916885
step: 450, loss: 0.014735560864210129
step: 460, loss: 0.06225590407848358
step: 470, loss: 0.0003670387959573418
step: 480, loss: 0.038221511989831924
step: 490, loss: 0.07761908322572708
step: 500, loss: 0.0001918415946420282
step: 510, loss: 0.022196300327777863
step: 520, loss: 0.19684214890003204
step: 530, loss: 0.0005191059899516404
epoch 8: dev_f1=0.8242990654205608, f1=0.7828139754485363, best_f1=0.7828139754485363
step: 0, loss: 0.039583753794431686
step: 10, loss: 0.003918174654245377
step: 20, loss: 0.004364179912954569
step: 30, loss: 0.03628818690776825
step: 40, loss: 0.0037342191208153963
step: 50, loss: 0.003116779262199998
step: 60, loss: 0.01123923808336258
step: 70, loss: 0.060857199132442474
step: 80, loss: 0.04602661356329918
step: 90, loss: 0.0031798435375094414
step: 100, loss: 0.002921764040365815
step: 110, loss: 0.0027332052122801542
step: 120, loss: 0.12976746261119843
step: 130, loss: 0.006584275513887405
step: 140, loss: 0.06873498857021332
step: 150, loss: 0.12780334055423737
step: 160, loss: 0.0003542260092217475
step: 170, loss: 0.0022103667724877596
step: 180, loss: 0.0023696774151176214
step: 190, loss: 0.00030177057487890124
step: 200, loss: 0.017608696594834328
step: 210, loss: 0.003119377652183175
step: 220, loss: 0.025951262563467026
step: 230, loss: 0.018992139026522636
step: 240, loss: 0.0012404954759404063
step: 250, loss: 0.010588585399091244
step: 260, loss: 0.0005073875654488802
step: 270, loss: 0.03586849570274353
step: 280, loss: 0.0010224634315818548
step: 290, loss: 0.0001677677355473861
step: 300, loss: 0.005551797337830067
step: 310, loss: 0.04800444841384888
step: 320, loss: 0.0010806561913341284
step: 330, loss: 0.0009442734299227595
step: 340, loss: 0.00026201840955764055
step: 350, loss: 0.0005114716477692127
step: 360, loss: 0.0007463017827831209
step: 370, loss: 0.0005366918630897999
step: 380, loss: 0.0002028091694228351
step: 390, loss: 0.00018374704814050347
step: 400, loss: 0.05129672959446907
step: 410, loss: 0.016910888254642487
step: 420, loss: 0.02545558661222458
step: 430, loss: 0.006300314795225859
step: 440, loss: 0.011503715068101883
step: 450, loss: 0.20111492276191711
step: 460, loss: 0.0010354302357882261
step: 470, loss: 0.0003644036769401282
step: 480, loss: 0.09625797718763351
step: 490, loss: 0.00164132216013968
step: 500, loss: 0.005517455283552408
step: 510, loss: 0.10979447513818741
step: 520, loss: 0.11751611530780792
step: 530, loss: 8.046090079005808e-05
epoch 9: dev_f1=0.7999999999999999, f1=0.7657957244655581, best_f1=0.7828139754485363
step: 0, loss: 0.002201775787398219
step: 10, loss: 0.0273571889847517
step: 20, loss: 0.000645292631816119
step: 30, loss: 0.03516700118780136
step: 40, loss: 0.06784217059612274
step: 50, loss: 0.0011878840159624815
step: 60, loss: 0.0011586659820750356
step: 70, loss: 0.001644727773964405
step: 80, loss: 0.07574356347322464
step: 90, loss: 0.003947876859456301
step: 100, loss: 0.005569789558649063
step: 110, loss: 0.01588599383831024
step: 120, loss: 0.0004037727485410869
step: 130, loss: 0.015265418216586113
step: 140, loss: 0.0014284350909292698
step: 150, loss: 0.03566389158368111
step: 160, loss: 0.008662918582558632
step: 170, loss: 0.01219159085303545
step: 180, loss: 0.00041468546260148287
step: 190, loss: 0.006990121211856604
step: 200, loss: 0.02108858898282051
step: 210, loss: 0.00641018059104681
step: 220, loss: 0.007459112908691168
step: 230, loss: 0.005958414636552334
step: 240, loss: 5.874485577805899e-05
step: 250, loss: 0.00040086140506900847
step: 260, loss: 0.02348962426185608
step: 270, loss: 0.0014322830829769373
step: 280, loss: 0.1654825508594513
step: 290, loss: 0.20188620686531067
step: 300, loss: 0.00037775826058350503
step: 310, loss: 0.015773644670844078
step: 320, loss: 0.06869442760944366
step: 330, loss: 0.008798526600003242
step: 340, loss: 0.0025447921361774206
step: 350, loss: 0.0010922732762992382
step: 360, loss: 0.0037734119687229395
step: 370, loss: 0.0011937522795051336
step: 380, loss: 0.006877976004034281
step: 390, loss: 0.015752211213111877
step: 400, loss: 0.0007078767521306872
step: 410, loss: 0.037481002509593964
step: 420, loss: 0.011157356202602386
step: 430, loss: 0.046553414314985275
step: 440, loss: 0.008310964331030846
step: 450, loss: 0.00040132857975549996
step: 460, loss: 0.019748643040657043
step: 470, loss: 0.12136861681938171
step: 480, loss: 0.0008802375523373485
step: 490, loss: 0.04528534784913063
step: 500, loss: 0.05766453593969345
step: 510, loss: 0.0001304762699874118
step: 520, loss: 0.02189878188073635
step: 530, loss: 0.0007067108526825905
epoch 10: dev_f1=0.7944945420028476, f1=0.7716763005780346, best_f1=0.7828139754485363
step: 0, loss: 0.025131262838840485
step: 10, loss: 0.00011871205788338557
step: 20, loss: 7.088846177794039e-05
step: 30, loss: 0.0006312905461527407
step: 40, loss: 0.0002855387283489108
step: 50, loss: 0.0006298549706116319
step: 60, loss: 0.0016952359583228827
step: 70, loss: 9.163408685708418e-05
step: 80, loss: 0.09440699964761734
step: 90, loss: 0.00023352158314082772
step: 100, loss: 0.013893986120820045
step: 110, loss: 7.687191828154027e-05
step: 120, loss: 0.005959736183285713
step: 130, loss: 0.00020625063916668296
step: 140, loss: 0.000978349125944078
step: 150, loss: 0.0010006658267229795
step: 160, loss: 0.0015070108929648995
step: 170, loss: 0.006285904906690121
step: 180, loss: 0.0010605857241898775
step: 190, loss: 5.94173397985287e-05
step: 200, loss: 0.001513655879534781
step: 210, loss: 0.0014499378157779574
step: 220, loss: 0.0014956080121919513
step: 230, loss: 0.0008807312697172165
step: 240, loss: 0.016247551888227463
step: 250, loss: 0.006533974315971136
step: 260, loss: 0.0024126002099364996
step: 270, loss: 0.07911328226327896
step: 280, loss: 0.00043136559543199837
step: 290, loss: 0.00015428889309987426
step: 300, loss: 0.0014660233864560723
step: 310, loss: 0.004078269470483065
step: 320, loss: 0.0025909855030477047
step: 330, loss: 0.012026029638946056
step: 340, loss: 0.0007342834724113345
step: 350, loss: 0.00042598205618560314
step: 360, loss: 3.446901973802596e-05
step: 370, loss: 0.01717447116971016
step: 380, loss: 0.0011655252892524004
step: 390, loss: 0.0003007437917403877
step: 400, loss: 0.0019199908711016178
step: 410, loss: 0.00036843170528300107
step: 420, loss: 0.00022996841289568692
step: 430, loss: 0.005722980014979839
step: 440, loss: 0.029592469334602356
step: 450, loss: 8.912473276723176e-05
step: 460, loss: 0.0006521022296510637
step: 470, loss: 0.0024954748805612326
step: 480, loss: 0.07851686328649521
step: 490, loss: 0.01958616077899933
step: 500, loss: 0.0026361262425780296
step: 510, loss: 0.0007240371778607368
step: 520, loss: 0.0012390438932925463
step: 530, loss: 0.0001194454962387681
epoch 11: dev_f1=0.8112941176470587, f1=0.783485357657225, best_f1=0.7828139754485363
step: 0, loss: 0.003726130584254861
step: 10, loss: 0.00028243294218555093
step: 20, loss: 0.00042690688860602677
step: 30, loss: 0.0007981921662576497
step: 40, loss: 0.000354737916495651
step: 50, loss: 0.00021669789566658437
step: 60, loss: 0.00018635405285749584
step: 70, loss: 0.0035515367053449154
step: 80, loss: 0.004335363395512104
step: 90, loss: 0.00045428951852954924
step: 100, loss: 0.0003402769798412919
step: 110, loss: 0.0006179144838824868
step: 120, loss: 0.00040205958066508174
step: 130, loss: 0.00044154704664833844
step: 140, loss: 0.00952355656772852
step: 150, loss: 0.010131796821951866
step: 160, loss: 0.0024128921795636415
step: 170, loss: 0.003255719318985939
step: 180, loss: 0.0014657271094620228
step: 190, loss: 0.0003712354227900505
step: 200, loss: 0.0007000346668064594
step: 210, loss: 2.844902155629825e-05
step: 220, loss: 0.00019509285630192608
step: 230, loss: 0.00010260897397529334
step: 240, loss: 0.0023196188267320395
step: 250, loss: 0.008888554759323597
step: 260, loss: 0.12446430325508118
step: 270, loss: 0.00014624182949773967
step: 280, loss: 8.003637049114332e-05
step: 290, loss: 0.0019032495329156518
step: 300, loss: 6.069701339583844e-05
step: 310, loss: 0.0010008361423388124
step: 320, loss: 0.0056684305891394615
step: 330, loss: 2.5405719497939572e-05
step: 340, loss: 0.00934890192002058
step: 350, loss: 0.006516472436487675
step: 360, loss: 0.000133686771732755
step: 370, loss: 0.00559385446831584
step: 380, loss: 0.030938483774662018
step: 390, loss: 9.612678695702925e-05
step: 400, loss: 0.00132247363217175
step: 410, loss: 7.008694228716195e-05
step: 420, loss: 0.0011215488193556666
step: 430, loss: 0.00041087999125011265
step: 440, loss: 0.0017452671891078353
step: 450, loss: 0.0076743001118302345
step: 460, loss: 0.0014725145883858204
step: 470, loss: 0.0003642384835984558
step: 480, loss: 0.00024030092754401267
step: 490, loss: 0.0004470203712116927
step: 500, loss: 0.00019899413746315986
step: 510, loss: 0.00019420291937422007
step: 520, loss: 0.0006610063719563186
step: 530, loss: 0.14104416966438293
epoch 12: dev_f1=0.8264775413711583, f1=0.7889207258834767, best_f1=0.7889207258834767
step: 0, loss: 0.0754728615283966
step: 10, loss: 0.035692475736141205
step: 20, loss: 1.8510219888412394e-05
step: 30, loss: 0.01612599566578865
step: 40, loss: 3.956049476983026e-05
step: 50, loss: 0.0002868477604351938
step: 60, loss: 0.0018139021703973413
step: 70, loss: 0.0014841185184195638
step: 80, loss: 0.07774785161018372
step: 90, loss: 3.758367893169634e-05
step: 100, loss: 0.002212302526459098
step: 110, loss: 0.00027553882682695985
step: 120, loss: 1.9013639757758938e-05
step: 130, loss: 8.294427243527025e-05
step: 140, loss: 0.00022152588644530624
step: 150, loss: 0.0001320527953794226
step: 160, loss: 0.008276334963738918
step: 170, loss: 0.00013402145123109221
step: 180, loss: 0.00642490666359663
step: 190, loss: 0.006332179065793753
step: 200, loss: 0.00023940826940815896
step: 210, loss: 0.053566351532936096
step: 220, loss: 0.0025209225714206696
step: 230, loss: 0.031563062220811844
step: 240, loss: 2.8009771995129995e-05
step: 250, loss: 6.72114038025029e-05
step: 260, loss: 0.0005044860299676657
step: 270, loss: 0.004781857132911682
step: 280, loss: 0.0007429555407725275
step: 290, loss: 0.0004647138703148812
step: 300, loss: 0.0007771558011882007
step: 310, loss: 0.009731411002576351
step: 320, loss: 0.005293581634759903
step: 330, loss: 0.0003506390785332769
step: 340, loss: 0.015496390871703625
step: 350, loss: 3.6720626667374745e-05
step: 360, loss: 0.006960985250771046
step: 370, loss: 6.814044172642753e-05
step: 380, loss: 0.0009068096405826509
step: 390, loss: 0.0013251856435090303
step: 400, loss: 9.17275101528503e-05
step: 410, loss: 0.001463629538193345
step: 420, loss: 0.0001640711270738393
step: 430, loss: 0.0006358379032462835
step: 440, loss: 0.005569668486714363
step: 450, loss: 0.0014095044462010264
step: 460, loss: 0.01164829172194004
step: 470, loss: 0.0030152038671076298
step: 480, loss: 1.919237183756195e-05
step: 490, loss: 0.0019909178372472525
step: 500, loss: 0.00039345768163912
step: 510, loss: 0.0009891955414786935
step: 520, loss: 0.0394648052752018
step: 530, loss: 0.000577546888962388
epoch 13: dev_f1=0.8092263334935127, f1=0.782820888238165, best_f1=0.7889207258834767
step: 0, loss: 0.0003517993027344346
step: 10, loss: 8.535916276741773e-05
step: 20, loss: 0.0028665822464972734
step: 30, loss: 5.852279355167411e-05
step: 40, loss: 0.07324523478746414
step: 50, loss: 0.0037233708426356316
step: 60, loss: 0.000271187920589
step: 70, loss: 3.31496776198037e-05
step: 80, loss: 0.005944147240370512
step: 90, loss: 4.155931674176827e-05
step: 100, loss: 4.875257218373008e-05
step: 110, loss: 0.0025578506756573915
step: 120, loss: 0.0004250992205925286
step: 130, loss: 0.00029464723775163293
step: 140, loss: 0.0016000998439267278
step: 150, loss: 3.4102402423741296e-05
step: 160, loss: 0.002384228864684701
step: 170, loss: 0.002036299090832472
step: 180, loss: 0.00013447178935166448
step: 190, loss: 4.554965198622085e-05
step: 200, loss: 0.0034462506882846355
step: 210, loss: 6.825056334491819e-05
step: 220, loss: 0.0001591035834280774
step: 230, loss: 0.008086816407740116
step: 240, loss: 0.0016456766752526164
step: 250, loss: 0.0022969646379351616
step: 260, loss: 0.004779300186783075
step: 270, loss: 0.10797014832496643
step: 280, loss: 0.0026556127704679966
step: 290, loss: 5.858987424289808e-05
step: 300, loss: 0.0005650767125189304
step: 310, loss: 9.693380707176402e-05
step: 320, loss: 0.00015694495232310146
step: 330, loss: 0.00014155733515508473
step: 340, loss: 0.00017500243848189712
step: 350, loss: 0.16531862318515778
step: 360, loss: 0.00016578976646997035
step: 370, loss: 0.0012193170841783285
step: 380, loss: 0.0002496453817002475
step: 390, loss: 0.001022003940306604
step: 400, loss: 0.02984888106584549
step: 410, loss: 5.8972465922124684e-05
step: 420, loss: 0.003085186704993248
step: 430, loss: 0.001968525815755129
step: 440, loss: 0.0012199378106743097
step: 450, loss: 0.00022259603429120034
step: 460, loss: 0.0029318679589778185
step: 470, loss: 0.007460028398782015
step: 480, loss: 0.00957137905061245
step: 490, loss: 0.002818796318024397
step: 500, loss: 0.0014207613421604037
step: 510, loss: 3.281044337200001e-05
step: 520, loss: 0.00016545546532142907
step: 530, loss: 0.0001415984152117744
epoch 14: dev_f1=0.8175182481751825, f1=0.7889564810481984, best_f1=0.7889207258834767
step: 0, loss: 0.0026536660734564066
step: 10, loss: 0.0010436009615659714
step: 20, loss: 0.041306477040052414
step: 30, loss: 0.0020925116259604692
step: 40, loss: 0.000137946437462233
step: 50, loss: 0.000680172408465296
step: 60, loss: 0.0029801027849316597
step: 70, loss: 0.00019549053104128689
step: 80, loss: 0.0001831673871492967
step: 90, loss: 0.011503303423523903
step: 100, loss: 6.819647387601435e-05
step: 110, loss: 0.0009677073685452342
step: 120, loss: 7.720851135673001e-05
step: 130, loss: 0.007000182289630175
step: 140, loss: 0.03720656409859657
step: 150, loss: 0.04418062046170235
step: 160, loss: 0.0002533487568143755
step: 170, loss: 6.69256696710363e-05
step: 180, loss: 0.0022648382000625134
step: 190, loss: 0.0005416820058599114
step: 200, loss: 0.0001523086684755981
step: 210, loss: 0.003094240091741085
step: 220, loss: 7.049195119179785e-05
step: 230, loss: 0.0004742695018649101
step: 240, loss: 0.0005487593589350581
step: 250, loss: 4.387840090203099e-05
step: 260, loss: 3.0561113817384467e-05
step: 270, loss: 7.709972851444036e-05
step: 280, loss: 0.0013026947854086757
step: 290, loss: 4.8701855121180415e-05
step: 300, loss: 0.0001112671016016975
step: 310, loss: 0.0017406682018190622
step: 320, loss: 0.16365009546279907
step: 330, loss: 0.0008172125671990216
step: 340, loss: 0.003238840028643608
step: 350, loss: 0.002519408706575632
step: 360, loss: 7.790610106894746e-05
step: 370, loss: 0.0002134653477696702
step: 380, loss: 0.0005477509112097323
step: 390, loss: 0.00016473887080792338
step: 400, loss: 6.0296355513855815e-05
step: 410, loss: 0.0016906955279409885
step: 420, loss: 0.0002992223890032619
step: 430, loss: 6.067153299227357e-05
step: 440, loss: 0.00011399971117498353
step: 450, loss: 0.0003032610984519124
step: 460, loss: 0.008358050137758255
step: 470, loss: 4.129323860979639e-05
step: 480, loss: 5.467538721859455e-05
step: 490, loss: 2.0756582671310753e-05
step: 500, loss: 0.00022483426437247545
step: 510, loss: 3.5621473216451705e-05
step: 520, loss: 3.615147215896286e-05
step: 530, loss: 0.001752384938299656
epoch 15: dev_f1=0.8102803738317756, f1=0.7702510658455708, best_f1=0.7889207258834767
step: 0, loss: 3.781739724217914e-05
step: 10, loss: 0.0003873280656989664
step: 20, loss: 0.00036795318010263145
step: 30, loss: 0.016567755490541458
step: 40, loss: 0.0013940827921032906
step: 50, loss: 0.00019010230607818812
step: 60, loss: 0.0006899563013575971
step: 70, loss: 3.145365189993754e-05
step: 80, loss: 3.100793037447147e-05
step: 90, loss: 0.0008680833270773292
step: 100, loss: 9.795990627026185e-05
step: 110, loss: 6.0333957662805915e-05
step: 120, loss: 9.011044312501326e-05
step: 130, loss: 2.409064836683683e-05
step: 140, loss: 9.218007471645251e-05
step: 150, loss: 0.0008088828762993217
step: 160, loss: 7.397177978418767e-05
step: 170, loss: 2.4901968572521582e-05
step: 180, loss: 0.00018745924171525985
step: 190, loss: 5.907879312871955e-05
step: 200, loss: 1.4349630873766728e-05
step: 210, loss: 0.0011213603429496288
step: 220, loss: 2.8210000891704112e-05
step: 230, loss: 5.7610170188127086e-05
step: 240, loss: 3.1704777939012274e-05
step: 250, loss: 0.002430408028885722
step: 260, loss: 0.00012685950787272304
step: 270, loss: 0.0008744028164073825
step: 280, loss: 0.0007125306874513626
step: 290, loss: 4.584850466926582e-05
step: 300, loss: 5.173928730073385e-05
step: 310, loss: 0.00010129249130841345
step: 320, loss: 0.00015168162644840777
step: 330, loss: 6.996219599386677e-05
step: 340, loss: 0.00026880810037255287
step: 350, loss: 4.0944818465504795e-05
step: 360, loss: 0.000778759946115315
step: 370, loss: 0.0010963426902890205
step: 380, loss: 0.003999154549092054
step: 390, loss: 0.00016548116400372237
step: 400, loss: 0.0004457932082004845
step: 410, loss: 0.0002459071693010628
step: 420, loss: 1.943808456417173e-05
step: 430, loss: 0.0006139194592833519
step: 440, loss: 5.2463990869000554e-05
step: 450, loss: 2.9535018256865442e-05
step: 460, loss: 0.0012060260633006692
step: 470, loss: 0.0007368896622210741
step: 480, loss: 0.00021328292496036738
step: 490, loss: 5.542175495065749e-05
step: 500, loss: 5.115297972224653e-05
step: 510, loss: 7.05377824488096e-05
step: 520, loss: 8.849178266245872e-05
step: 530, loss: 7.893047586549073e-05
epoch 16: dev_f1=0.80765639589169, f1=0.7713603818615752, best_f1=0.7889207258834767
step: 0, loss: 2.4183782443287782e-05
step: 10, loss: 0.0012683147797361016
step: 20, loss: 2.9290329621289857e-05
step: 30, loss: 0.11783386766910553
step: 40, loss: 0.001014653709717095
step: 50, loss: 0.0004976924974471331
step: 60, loss: 0.0026818206533789635
step: 70, loss: 0.00020314592984504998
step: 80, loss: 0.0007590614259243011
step: 90, loss: 0.0002650337992236018
step: 100, loss: 0.00012093148689018562
step: 110, loss: 0.00044211509521119297
step: 120, loss: 0.0006802140269428492
step: 130, loss: 0.00011339096090523526
step: 140, loss: 4.223764335620217e-05
step: 150, loss: 7.19948802725412e-05
step: 160, loss: 4.260575587977655e-05
step: 170, loss: 0.0001358087465632707
step: 180, loss: 9.159631008515134e-05
step: 190, loss: 0.0001511668524472043
step: 200, loss: 3.0018965844647028e-05
step: 210, loss: 0.0003076731227338314
step: 220, loss: 5.664310447173193e-05
step: 230, loss: 0.00028935508453287184
step: 240, loss: 8.468540909234434e-05
step: 250, loss: 0.0007468718686141074
step: 260, loss: 2.6961266485159285e-05
step: 270, loss: 2.858992047549691e-05
step: 280, loss: 3.955222200602293e-05
step: 290, loss: 5.4042702686274424e-05
step: 300, loss: 3.3749212889233604e-05
step: 310, loss: 5.492815398611128e-05
step: 320, loss: 3.478871440165676e-05
step: 330, loss: 0.00039740552892908454
step: 340, loss: 0.01810428500175476
step: 350, loss: 0.0012298356741666794
step: 360, loss: 2.725345257204026e-05
step: 370, loss: 2.5334973543067463e-05
step: 380, loss: 0.0083860969170928
step: 390, loss: 0.00026287371292710304
step: 400, loss: 4.5023392885923386e-05
step: 410, loss: 0.009929688647389412
step: 420, loss: 3.96451614506077e-05
step: 430, loss: 1.9058272300753742e-05
step: 440, loss: 0.00040831987280398607
step: 450, loss: 0.00015679556236136705
step: 460, loss: 0.00030741628143005073
step: 470, loss: 0.0021892464719712734
step: 480, loss: 4.809267556993291e-05
step: 490, loss: 0.0005582633893936872
step: 500, loss: 1.1537138561834581e-05
step: 510, loss: 0.00016163843974936754
step: 520, loss: 3.919752998626791e-05
step: 530, loss: 0.0010126600973308086
epoch 17: dev_f1=0.8126474752241624, f1=0.7783109404990403, best_f1=0.7889207258834767
step: 0, loss: 0.011091469787061214
step: 10, loss: 3.7142854125704616e-05
step: 20, loss: 0.000651794602163136
step: 30, loss: 8.72308446560055e-05
step: 40, loss: 3.477275095065124e-05
step: 50, loss: 0.00022592888853978366
step: 60, loss: 1.983283982553985e-05
step: 70, loss: 0.00014423551328945905
step: 80, loss: 7.54384309402667e-05
step: 90, loss: 0.00038961716927587986
step: 100, loss: 2.3170381609816104e-05
step: 110, loss: 3.576347808120772e-05
step: 120, loss: 6.806356395827606e-05
step: 130, loss: 3.107092925347388e-05
step: 140, loss: 2.0179551938781515e-05
step: 150, loss: 4.046744652441703e-05
step: 160, loss: 9.066415077541023e-05
step: 170, loss: 0.0022939087357372046
step: 180, loss: 9.632266301196069e-05
step: 190, loss: 0.00014640475274063647
step: 200, loss: 0.00022067292593419552
step: 210, loss: 6.462802411988378e-05
step: 220, loss: 2.1721585653722286e-05
step: 230, loss: 3.222829400328919e-05
step: 240, loss: 0.003471618052572012
step: 250, loss: 1.5023784726508893e-05
step: 260, loss: 0.00010455783194629475
step: 270, loss: 0.00030505022732540965
step: 280, loss: 0.00012148023233748972
step: 290, loss: 0.00011107172031188384
step: 300, loss: 0.07539500296115875
step: 310, loss: 9.218113700626418e-05
step: 320, loss: 0.0002356050827074796
step: 330, loss: 0.00011011385504389182
step: 340, loss: 0.00012235299800522625
step: 350, loss: 0.00019476847955957055
step: 360, loss: 3.1634725019102916e-05
step: 370, loss: 5.286220766720362e-05
step: 380, loss: 5.03107366967015e-05
step: 390, loss: 2.2708145479555242e-05
step: 400, loss: 5.65608570468612e-05
step: 410, loss: 0.00013930840941611677
step: 420, loss: 7.064588135108352e-05
step: 430, loss: 5.695961954188533e-05
step: 440, loss: 0.1948336809873581
step: 450, loss: 4.222997449687682e-05
step: 460, loss: 8.348676783498377e-05
step: 470, loss: 3.856902549159713e-05
step: 480, loss: 0.00013298859994392842
step: 490, loss: 9.467564086662605e-05
step: 500, loss: 4.126087878830731e-05
step: 510, loss: 1.464757133362582e-05
step: 520, loss: 0.0003125187358818948
step: 530, loss: 0.00033492298098281026
epoch 18: dev_f1=0.8335745296671491, f1=0.7970731707317074, best_f1=0.7970731707317074
step: 0, loss: 3.422929148655385e-05
step: 10, loss: 4.850621917285025e-05
step: 20, loss: 0.00021062939777038991
step: 30, loss: 4.8044483264675364e-05
step: 40, loss: 6.223523814696819e-05
step: 50, loss: 3.4370932553429157e-05
step: 60, loss: 2.379242141614668e-05
step: 70, loss: 1.565309321449604e-05
step: 80, loss: 0.008084425702691078
step: 90, loss: 1.7456353816669434e-05
step: 100, loss: 2.9306915166671388e-05
step: 110, loss: 9.451804362470284e-05
step: 120, loss: 5.1390754379099235e-05
step: 130, loss: 0.00031697607482783496
step: 140, loss: 2.59892094618408e-05
step: 150, loss: 6.168091204017401e-05
step: 160, loss: 1.833172791521065e-05
step: 170, loss: 1.7143476725323126e-05
step: 180, loss: 0.00012587071978487074
step: 190, loss: 0.00016672504716552794
step: 200, loss: 0.00016883219359442592
step: 210, loss: 7.975838525453582e-05
step: 220, loss: 0.00015289857401512563
step: 230, loss: 2.1754836780019104e-05
step: 240, loss: 3.171710704918951e-05
step: 250, loss: 0.00013810963719151914
step: 260, loss: 2.242093250970356e-05
step: 270, loss: 3.4879787563113496e-05
step: 280, loss: 3.630262290243991e-05
step: 290, loss: 0.023545119911432266
step: 300, loss: 0.00015065711340866983
step: 310, loss: 0.0006029950454831123
step: 320, loss: 2.1423409634735435e-05
step: 330, loss: 0.00035908963764086366
step: 340, loss: 6.371326162479818e-05
step: 350, loss: 0.00019477339810691774
step: 360, loss: 0.001221225829795003
step: 370, loss: 2.303619658050593e-05
step: 380, loss: 0.0004614689387381077
step: 390, loss: 0.00044084544060751796
step: 400, loss: 0.0005227010697126389
step: 410, loss: 9.519513696432114e-05
step: 420, loss: 9.789777686819434e-05
step: 430, loss: 5.635073102894239e-05
step: 440, loss: 3.207433837815188e-05
step: 450, loss: 5.445738497655839e-05
step: 460, loss: 0.00035489266156218946
step: 470, loss: 1.6417057850048877e-05
step: 480, loss: 1.6070536730694585e-05
step: 490, loss: 0.0007085367105901241
step: 500, loss: 0.003066804027184844
step: 510, loss: 2.3348693503066897e-05
step: 520, loss: 1.973508005903568e-05
step: 530, loss: 0.00015669039567001164
epoch 19: dev_f1=0.826318335752298, f1=0.7925817471937531, best_f1=0.7970731707317074
step: 0, loss: 2.4231532734120265e-05
step: 10, loss: 6.221543299034238e-05
step: 20, loss: 7.459925109287724e-05
step: 30, loss: 2.755068453552667e-05
step: 40, loss: 3.1835119443712756e-05
step: 50, loss: 1.8681783330976032e-05
step: 60, loss: 5.383402094594203e-05
step: 70, loss: 0.00023361272178590298
step: 80, loss: 4.458451076061465e-05
step: 90, loss: 3.97779731429182e-05
step: 100, loss: 3.195221506757662e-05
step: 110, loss: 0.0005858098156750202
step: 120, loss: 0.0003891536907758564
step: 130, loss: 2.258178938063793e-05
step: 140, loss: 0.011970793828368187
step: 150, loss: 8.488887397106737e-05
step: 160, loss: 3.0301391234388575e-05
step: 170, loss: 6.905386544531211e-05
step: 180, loss: 0.00043094251304864883
step: 190, loss: 0.001731378142721951
step: 200, loss: 3.606139944167808e-05
step: 210, loss: 3.366857345099561e-05
step: 220, loss: 5.949580736341886e-05
step: 230, loss: 0.0001922599331010133
step: 240, loss: 3.078699592151679e-05
step: 250, loss: 0.00012821261771023273
step: 260, loss: 0.0008809685241430998
step: 270, loss: 4.2990654037566856e-05
step: 280, loss: 2.3207487174659036e-05
step: 290, loss: 0.0008477026131004095
step: 300, loss: 0.015099901705980301
step: 310, loss: 4.7227244067471474e-05
step: 320, loss: 3.854388342006132e-05
step: 330, loss: 0.0007314449176192284
step: 340, loss: 0.0004078923666384071
step: 350, loss: 0.00042748876148834825
step: 360, loss: 6.334861245704815e-05
step: 370, loss: 0.0011203172616660595
step: 380, loss: 2.4532488168915734e-05
step: 390, loss: 2.9683136745006777e-05
step: 400, loss: 2.5151335648843087e-05
step: 410, loss: 1.2211370631121099e-05
step: 420, loss: 8.676295692566782e-05
step: 430, loss: 1.805950523703359e-05
step: 440, loss: 8.491904736729339e-05
step: 450, loss: 0.05078974738717079
step: 460, loss: 1.8718908904702403e-05
step: 470, loss: 7.740866567473859e-05
step: 480, loss: 0.00016325723845511675
step: 490, loss: 0.00011304279178148136
step: 500, loss: 0.00013889271940570325
step: 510, loss: 9.216921898769215e-05
step: 520, loss: 0.0004242728464305401
step: 530, loss: 2.959603807539679e-05
epoch 20: dev_f1=0.8245017015070492, f1=0.7870461236506379, best_f1=0.7970731707317074
