cuda
Device: cuda
step: 0, loss: 0.642475426197052
step: 10, loss: 0.4697205722332001
step: 20, loss: 0.2949409782886505
step: 30, loss: 0.47930827736854553
step: 40, loss: 0.45697686076164246
step: 50, loss: 0.4629407525062561
step: 60, loss: 0.6395310163497925
step: 70, loss: 0.17964109778404236
step: 80, loss: 0.33874183893203735
step: 90, loss: 0.10585258156061172
step: 100, loss: 0.3802109360694885
step: 110, loss: 0.28194522857666016
step: 120, loss: 0.3324832618236542
step: 130, loss: 0.16378627717494965
step: 140, loss: 0.23226100206375122
step: 150, loss: 0.17530280351638794
step: 160, loss: 0.17492148280143738
step: 170, loss: 0.3140099346637726
step: 180, loss: 0.25449103116989136
step: 190, loss: 0.2889769971370697
step: 200, loss: 0.1845533698797226
step: 210, loss: 0.27751433849334717
step: 220, loss: 0.09032878279685974
step: 230, loss: 0.2107590287923813
step: 240, loss: 0.2287158966064453
step: 250, loss: 0.04808054119348526
step: 260, loss: 0.15837475657463074
step: 270, loss: 0.16114497184753418
step: 280, loss: 0.17097888886928558
step: 290, loss: 0.02343425713479519
step: 300, loss: 0.027644654735922813
step: 310, loss: 0.14530406892299652
step: 320, loss: 0.34770601987838745
step: 330, loss: 0.06560304015874863
step: 340, loss: 0.20821727812290192
step: 350, loss: 0.1093224361538887
step: 360, loss: 0.020874524489045143
step: 370, loss: 0.11222250759601593
step: 380, loss: 0.05488035827875137
step: 390, loss: 0.13796789944171906
step: 400, loss: 0.2799281179904938
step: 410, loss: 0.1292569786310196
step: 420, loss: 0.045501116663217545
step: 430, loss: 0.09733867645263672
step: 440, loss: 0.11796422302722931
step: 450, loss: 0.09707613289356232
step: 460, loss: 0.11782704293727875
step: 470, loss: 0.054581157863140106
step: 480, loss: 0.10457692295312881
step: 490, loss: 0.234111949801445
step: 500, loss: 0.21066723763942719
step: 510, loss: 0.10970001667737961
step: 520, loss: 0.06276815384626389
step: 530, loss: 0.0427214652299881
epoch 1: dev_f1=0.7182587666263603, f1=0.6980902072328322, best_f1=0.6980902072328322
step: 0, loss: 0.06620942801237106
step: 10, loss: 0.12548604607582092
step: 20, loss: 0.2893759608268738
step: 30, loss: 0.23080256581306458
step: 40, loss: 0.0413355715572834
step: 50, loss: 0.16901490092277527
step: 60, loss: 0.03909022733569145
step: 70, loss: 0.15206705033779144
step: 80, loss: 0.08932603895664215
step: 90, loss: 0.0232834592461586
step: 100, loss: 0.14977918565273285
step: 110, loss: 0.0044624824076890945
step: 120, loss: 0.04015081748366356
step: 130, loss: 0.009030517190694809
step: 140, loss: 0.07646764814853668
step: 150, loss: 0.06312154233455658
step: 160, loss: 0.010683317668735981
step: 170, loss: 0.04110122099518776
step: 180, loss: 0.10790597647428513
step: 190, loss: 0.014348181895911694
step: 200, loss: 0.06763125956058502
step: 210, loss: 0.11553703993558884
step: 220, loss: 0.08080143481492996
step: 230, loss: 0.12679535150527954
step: 240, loss: 0.1643182337284088
step: 250, loss: 0.08632130175828934
step: 260, loss: 0.11537696421146393
step: 270, loss: 0.055257685482501984
step: 280, loss: 0.10852795839309692
step: 290, loss: 0.03388302028179169
step: 300, loss: 0.0477178618311882
step: 310, loss: 0.007876651361584663
step: 320, loss: 0.011201413348317146
step: 330, loss: 0.14301112294197083
step: 340, loss: 0.09701160341501236
step: 350, loss: 0.06298822909593582
step: 360, loss: 0.14216099679470062
step: 370, loss: 0.2347867786884308
step: 380, loss: 0.09934397041797638
step: 390, loss: 0.005843103863298893
step: 400, loss: 0.2300710827112198
step: 410, loss: 0.29222428798675537
step: 420, loss: 0.1348176896572113
step: 430, loss: 0.06003731116652489
step: 440, loss: 0.08633667230606079
step: 450, loss: 0.07184725999832153
step: 460, loss: 0.07357827574014664
step: 470, loss: 0.14203336834907532
step: 480, loss: 0.15626296401023865
step: 490, loss: 0.004519160836935043
step: 500, loss: 0.038276899605989456
step: 510, loss: 0.0429682619869709
step: 520, loss: 0.040751922875642776
step: 530, loss: 0.11322160810232162
epoch 2: dev_f1=0.7563667232597623, f1=0.7381974248927038, best_f1=0.7381974248927038
step: 0, loss: 0.036947011947631836
step: 10, loss: 0.1385738104581833
step: 20, loss: 0.05262568220496178
step: 30, loss: 0.11708258092403412
step: 40, loss: 0.12681272625923157
step: 50, loss: 0.10733702033758163
step: 60, loss: 0.06920883059501648
step: 70, loss: 0.036302365362644196
step: 80, loss: 0.05878021568059921
step: 90, loss: 0.13814756274223328
step: 100, loss: 0.008697899989783764
step: 110, loss: 0.09249503165483475
step: 120, loss: 0.052018798887729645
step: 130, loss: 0.06290685385465622
step: 140, loss: 0.038306836038827896
step: 150, loss: 0.05121869966387749
step: 160, loss: 0.08336726576089859
step: 170, loss: 0.1066431850194931
step: 180, loss: 0.043108005076646805
step: 190, loss: 0.05597897246479988
step: 200, loss: 0.03503083437681198
step: 210, loss: 0.14431968331336975
step: 220, loss: 0.04426496848464012
step: 230, loss: 0.05479608103632927
step: 240, loss: 0.036206766963005066
step: 250, loss: 0.006979061756283045
step: 260, loss: 0.12775073945522308
step: 270, loss: 0.01271307934075594
step: 280, loss: 0.23649007081985474
step: 290, loss: 0.03343576565384865
step: 300, loss: 0.02058248780667782
step: 310, loss: 0.01761568710207939
step: 320, loss: 0.1773679256439209
step: 330, loss: 0.23504666984081268
step: 340, loss: 0.08390400558710098
step: 350, loss: 0.015980413183569908
step: 360, loss: 0.00788932852447033
step: 370, loss: 0.08127803355455399
step: 380, loss: 0.10641651600599289
step: 390, loss: 0.1590421348810196
step: 400, loss: 0.055614206939935684
step: 410, loss: 0.11445565521717072
step: 420, loss: 0.004140921868383884
step: 430, loss: 0.14368943870067596
step: 440, loss: 0.1543467938899994
step: 450, loss: 0.1307327002286911
step: 460, loss: 0.028672955930233
step: 470, loss: 0.06469189375638962
step: 480, loss: 0.021185651421546936
step: 490, loss: 0.027014661580324173
step: 500, loss: 0.00747691560536623
step: 510, loss: 0.03271902725100517
step: 520, loss: 0.018859054893255234
step: 530, loss: 0.0928499773144722
epoch 3: dev_f1=0.7795992714025501, f1=0.7512784751278476, best_f1=0.7512784751278476
step: 0, loss: 0.06448247283697128
step: 10, loss: 0.007488085888326168
step: 20, loss: 0.04810144752264023
step: 30, loss: 0.16397663950920105
step: 40, loss: 0.003873848356306553
step: 50, loss: 0.1074196994304657
step: 60, loss: 0.013066715560853481
step: 70, loss: 0.006799036171287298
step: 80, loss: 0.019267918542027473
step: 90, loss: 0.01397961936891079
step: 100, loss: 0.05255294591188431
step: 110, loss: 0.01299240905791521
step: 120, loss: 0.1548316776752472
step: 130, loss: 0.09293296188116074
step: 140, loss: 0.02086293324828148
step: 150, loss: 0.0505065843462944
step: 160, loss: 0.024637993425130844
step: 170, loss: 0.011134596541523933
step: 180, loss: 0.005575683433562517
step: 190, loss: 0.08520834892988205
step: 200, loss: 0.0929880291223526
step: 210, loss: 0.045106321573257446
step: 220, loss: 0.049133069813251495
step: 230, loss: 0.013654262758791447
step: 240, loss: 0.07509714365005493
step: 250, loss: 0.16736087203025818
step: 260, loss: 0.06615916639566422
step: 270, loss: 0.1037897989153862
step: 280, loss: 0.025484543293714523
step: 290, loss: 0.07406733185052872
step: 300, loss: 0.055244434624910355
step: 310, loss: 0.08177721500396729
step: 320, loss: 0.08843398094177246
step: 330, loss: 0.09182890504598618
step: 340, loss: 0.02965620346367359
step: 350, loss: 0.02913729101419449
step: 360, loss: 0.1252388060092926
step: 370, loss: 0.1414118856191635
step: 380, loss: 0.11346857249736786
step: 390, loss: 0.04635700210928917
step: 400, loss: 0.038808662444353104
step: 410, loss: 0.02239745855331421
step: 420, loss: 0.12989073991775513
step: 430, loss: 0.0215923972427845
step: 440, loss: 0.0743117555975914
step: 450, loss: 0.033018551766872406
step: 460, loss: 0.04820925369858742
step: 470, loss: 0.08049732446670532
step: 480, loss: 0.049295924603939056
step: 490, loss: 0.010713142342865467
step: 500, loss: 0.015322024933993816
step: 510, loss: 0.052027538418769836
step: 520, loss: 0.022264305502176285
step: 530, loss: 0.02413165755569935
epoch 4: dev_f1=0.7840501792114696, f1=0.7431645002241146, best_f1=0.7431645002241146
step: 0, loss: 0.002210370497778058
step: 10, loss: 0.0501902811229229
step: 20, loss: 0.09332648664712906
step: 30, loss: 0.0669487789273262
step: 40, loss: 0.0724017322063446
step: 50, loss: 0.07597465813159943
step: 60, loss: 0.1149439662694931
step: 70, loss: 0.006345405243337154
step: 80, loss: 0.01167018711566925
step: 90, loss: 0.015069420449435711
step: 100, loss: 0.08625765889883041
step: 110, loss: 0.0037063867785036564
step: 120, loss: 0.003294875845313072
step: 130, loss: 0.004346082918345928
step: 140, loss: 0.026666363701224327
step: 150, loss: 0.01909080520272255
step: 160, loss: 0.21382848918437958
step: 170, loss: 0.007333798799663782
step: 180, loss: 0.024454843252897263
step: 190, loss: 0.0920824334025383
step: 200, loss: 0.04211661219596863
step: 210, loss: 0.12243407964706421
step: 220, loss: 0.0659182071685791
step: 230, loss: 0.00813430454581976
step: 240, loss: 0.04971667379140854
step: 250, loss: 0.060580771416425705
step: 260, loss: 0.04946165531873703
step: 270, loss: 0.0361601822078228
step: 280, loss: 0.03511344641447067
step: 290, loss: 0.08387038111686707
step: 300, loss: 0.0009323767735622823
step: 310, loss: 0.05326381325721741
step: 320, loss: 0.013073737733066082
step: 330, loss: 0.0003407335898373276
step: 340, loss: 0.016727264970541
step: 350, loss: 0.016126388683915138
step: 360, loss: 0.12256473302841187
step: 370, loss: 0.008040784858167171
step: 380, loss: 0.018659930676221848
step: 390, loss: 0.00048259535105898976
step: 400, loss: 0.17710065841674805
step: 410, loss: 0.03882821276783943
step: 420, loss: 0.04867526516318321
step: 430, loss: 0.0005794611060991883
step: 440, loss: 0.02623777836561203
step: 450, loss: 0.07085950672626495
step: 460, loss: 0.081560418009758
step: 470, loss: 0.035446036607027054
step: 480, loss: 0.04471525549888611
step: 490, loss: 0.03335533291101456
step: 500, loss: 0.019702821969985962
step: 510, loss: 0.006489782128483057
step: 520, loss: 0.042141806334257126
step: 530, loss: 0.23549339175224304
epoch 5: dev_f1=0.774987690792713, f1=0.7253626813406704, best_f1=0.7431645002241146
step: 0, loss: 0.0014872020110487938
step: 10, loss: 0.01712838187813759
step: 20, loss: 0.09705541282892227
step: 30, loss: 0.18008315563201904
step: 40, loss: 0.03548811748623848
step: 50, loss: 0.02458205632865429
step: 60, loss: 0.003030348801985383
step: 70, loss: 0.00933365523815155
step: 80, loss: 0.002480599796399474
step: 90, loss: 0.029767081141471863
step: 100, loss: 0.004389379173517227
step: 110, loss: 0.006092406343668699
step: 120, loss: 0.0030483442824333906
step: 130, loss: 0.0016174956690520048
step: 140, loss: 0.04181712865829468
step: 150, loss: 0.07045970857143402
step: 160, loss: 0.06609970331192017
step: 170, loss: 0.04686548560857773
step: 180, loss: 0.004112422466278076
step: 190, loss: 0.015580205246806145
step: 200, loss: 0.055242907255887985
step: 210, loss: 0.049323175102472305
step: 220, loss: 0.04897771403193474
step: 230, loss: 0.012232733890414238
step: 240, loss: 0.015984438359737396
step: 250, loss: 0.004531324375420809
step: 260, loss: 0.01139957644045353
step: 270, loss: 0.002179946517571807
step: 280, loss: 0.0006411228096112609
step: 290, loss: 0.026270752772688866
step: 300, loss: 0.020770180970430374
step: 310, loss: 0.022964095696806908
step: 320, loss: 0.008937924169003963
step: 330, loss: 0.02811628393828869
step: 340, loss: 0.023498978465795517
step: 350, loss: 0.025438277050852776
step: 360, loss: 0.02431594580411911
step: 370, loss: 0.13047190010547638
step: 380, loss: 0.03537196293473244
step: 390, loss: 0.025616291910409927
step: 400, loss: 0.0015845663147047162
step: 410, loss: 0.011146020144224167
step: 420, loss: 0.022313162684440613
step: 430, loss: 0.001278887502849102
step: 440, loss: 0.009381375275552273
step: 450, loss: 0.00340964924544096
step: 460, loss: 0.13321533799171448
step: 470, loss: 0.007793901953846216
step: 480, loss: 0.017321642488241196
step: 490, loss: 0.06249568983912468
step: 500, loss: 0.09155116230249405
step: 510, loss: 0.12378724664449692
step: 520, loss: 0.0010136335622519255
step: 530, loss: 0.057911474257707596
epoch 6: dev_f1=0.797534376481745, f1=0.759825327510917, best_f1=0.759825327510917
step: 0, loss: 0.03193154186010361
step: 10, loss: 0.023823799565434456
step: 20, loss: 0.04601549729704857
step: 30, loss: 0.0023527301382273436
step: 40, loss: 0.0015001075807958841
step: 50, loss: 0.007613839581608772
step: 60, loss: 0.008331711404025555
step: 70, loss: 0.00037827243795618415
step: 80, loss: 0.0043192156590521336
step: 90, loss: 0.0014642199967056513
step: 100, loss: 0.015081335790455341
step: 110, loss: 0.00047189483302645385
step: 120, loss: 0.0021391790360212326
step: 130, loss: 0.0027979256119579077
step: 140, loss: 0.0004475536698009819
step: 150, loss: 0.1353735327720642
step: 160, loss: 0.03047696128487587
step: 170, loss: 0.015883129090070724
step: 180, loss: 0.0010937119368463755
step: 190, loss: 0.012293697334825993
step: 200, loss: 0.004836465232074261
step: 210, loss: 0.018652450293302536
step: 220, loss: 0.005249486304819584
step: 230, loss: 0.015707924962043762
step: 240, loss: 0.05283487215638161
step: 250, loss: 0.023349272087216377
step: 260, loss: 0.008731498382985592
step: 270, loss: 0.12219095975160599
step: 280, loss: 0.09527933597564697
step: 290, loss: 0.013451127335429192
step: 300, loss: 0.07598480582237244
step: 310, loss: 0.004388908855617046
step: 320, loss: 0.2789236903190613
step: 330, loss: 0.07250267267227173
step: 340, loss: 0.010150052607059479
step: 350, loss: 0.03685988485813141
step: 360, loss: 0.0010809509549289942
step: 370, loss: 0.010027226060628891
step: 380, loss: 0.028164619579911232
step: 390, loss: 0.0048797884956002235
step: 400, loss: 0.0022742673754692078
step: 410, loss: 0.00048135477118194103
step: 420, loss: 0.11475441604852676
step: 430, loss: 0.08812122046947479
step: 440, loss: 0.009050032123923302
step: 450, loss: 0.047261595726013184
step: 460, loss: 0.004516866523772478
step: 470, loss: 0.022170962765812874
step: 480, loss: 0.002849680371582508
step: 490, loss: 0.052694108337163925
step: 500, loss: 0.006072544492781162
step: 510, loss: 0.0009152189013548195
step: 520, loss: 0.1286449432373047
step: 530, loss: 0.01032271794974804
epoch 7: dev_f1=0.7998228520814881, f1=0.7714922048997772, best_f1=0.7714922048997772
step: 0, loss: 0.05450684204697609
step: 10, loss: 0.061611201614141464
step: 20, loss: 0.008406810462474823
step: 30, loss: 0.006569072604179382
step: 40, loss: 0.00188443623483181
step: 50, loss: 0.03694801405072212
step: 60, loss: 0.07268168032169342
step: 70, loss: 0.05021296441555023
step: 80, loss: 0.011667922139167786
step: 90, loss: 0.06344591081142426
step: 100, loss: 0.007788119371980429
step: 110, loss: 0.08798255026340485
step: 120, loss: 0.0002850275195669383
step: 130, loss: 0.01900990679860115
step: 140, loss: 0.011936181224882603
step: 150, loss: 0.0024215304292738438
step: 160, loss: 0.0013227787567302585
step: 170, loss: 0.05971801280975342
step: 180, loss: 0.011876633390784264
step: 190, loss: 0.11008499562740326
step: 200, loss: 0.0009153533610515296
step: 210, loss: 0.01998555101454258
step: 220, loss: 0.012629464268684387
step: 230, loss: 0.012605380266904831
step: 240, loss: 0.004846482537686825
step: 250, loss: 0.09216148406267166
step: 260, loss: 0.08063074946403503
step: 270, loss: 0.01923201233148575
step: 280, loss: 0.031561821699142456
step: 290, loss: 0.001385778421536088
step: 300, loss: 0.027132730931043625
step: 310, loss: 0.005797566846013069
step: 320, loss: 0.018456418067216873
step: 330, loss: 0.0021874257363379
step: 340, loss: 0.013692607171833515
step: 350, loss: 0.019717151299118996
step: 360, loss: 0.0036661033518612385
step: 370, loss: 0.006011152174323797
step: 380, loss: 0.001139802043326199
step: 390, loss: 0.06825724244117737
step: 400, loss: 0.0019910973496735096
step: 410, loss: 0.006292317062616348
step: 420, loss: 0.07354404777288437
step: 430, loss: 0.0024602925404906273
step: 440, loss: 0.015566444955766201
step: 450, loss: 0.004475174937397242
step: 460, loss: 0.0004878193140029907
step: 470, loss: 0.033596113324165344
step: 480, loss: 0.009819967672228813
step: 490, loss: 0.2912183105945587
step: 500, loss: 0.0004822799237444997
step: 510, loss: 0.09022624790668488
step: 520, loss: 0.0018740043742582202
step: 530, loss: 0.0025264660362154245
epoch 8: dev_f1=0.7963604852686309, f1=0.7709401709401709, best_f1=0.7714922048997772
step: 0, loss: 0.003093927400186658
step: 10, loss: 0.018812548369169235
step: 20, loss: 0.046400997787714005
step: 30, loss: 0.005125388503074646
step: 40, loss: 0.06150154769420624
step: 50, loss: 0.0011106051970273256
step: 60, loss: 0.02085588313639164
step: 70, loss: 0.033877238631248474
step: 80, loss: 0.0017184867756441236
step: 90, loss: 0.0011745705269277096
step: 100, loss: 0.00044948761933483183
step: 110, loss: 0.0087064728140831
step: 120, loss: 0.016293637454509735
step: 130, loss: 0.003897391026839614
step: 140, loss: 0.027097651734948158
step: 150, loss: 0.009960507042706013
step: 160, loss: 0.004918399266898632
step: 170, loss: 0.021833252161741257
step: 180, loss: 0.0007843828061595559
step: 190, loss: 0.012175324372947216
step: 200, loss: 0.0023875064216554165
step: 210, loss: 0.04802229627966881
step: 220, loss: 0.05265085771679878
step: 230, loss: 0.01107050571590662
step: 240, loss: 0.0092928446829319
step: 250, loss: 0.0006068798829801381
step: 260, loss: 0.01842116378247738
step: 270, loss: 0.0002665134961716831
step: 280, loss: 0.00026277254801243544
step: 290, loss: 0.008541938848793507
step: 300, loss: 0.0001296012633247301
step: 310, loss: 0.003407978918403387
step: 320, loss: 0.058919087052345276
step: 330, loss: 0.0001316447160206735
step: 340, loss: 0.0005225483328104019
step: 350, loss: 0.002755015855655074
step: 360, loss: 0.03212658315896988
step: 370, loss: 0.02546181157231331
step: 380, loss: 0.008233646862208843
step: 390, loss: 0.017552580684423447
step: 400, loss: 0.002609306713566184
step: 410, loss: 0.0009092498221434653
step: 420, loss: 0.008392278105020523
step: 430, loss: 0.08488264679908752
step: 440, loss: 0.0011017657816410065
step: 450, loss: 0.0013966435799375176
step: 460, loss: 0.0002157174312742427
step: 470, loss: 0.041796039789915085
step: 480, loss: 0.001524995663203299
step: 490, loss: 0.0023806612007319927
step: 500, loss: 0.020563378930091858
step: 510, loss: 0.0023045840207487345
step: 520, loss: 0.0072978222742676735
step: 530, loss: 0.05126460641622543
epoch 9: dev_f1=0.8056662239929172, f1=0.7782169521299956, best_f1=0.7782169521299956
step: 0, loss: 0.056518252938985825
step: 10, loss: 0.035932764410972595
step: 20, loss: 0.0024070492945611477
step: 30, loss: 0.0004749222716782242
step: 40, loss: 0.05256085470318794
step: 50, loss: 0.0002462018746882677
step: 60, loss: 0.00036337238270789385
step: 70, loss: 0.00595167325809598
step: 80, loss: 0.00195282232016325
step: 90, loss: 0.002882686210796237
step: 100, loss: 0.0026404105592519045
step: 110, loss: 0.24958354234695435
step: 120, loss: 0.0024810577742755413
step: 130, loss: 0.08068355917930603
step: 140, loss: 0.00027529126964509487
step: 150, loss: 0.007940594106912613
step: 160, loss: 0.003319736570119858
step: 170, loss: 0.020993325859308243
step: 180, loss: 0.006270647514611483
step: 190, loss: 0.00010167907748837024
step: 200, loss: 0.033366408199071884
step: 210, loss: 0.0011153928935527802
step: 220, loss: 4.732474553748034e-05
step: 230, loss: 0.0005908043822273612
step: 240, loss: 0.004874385427683592
step: 250, loss: 0.0013817241415381432
step: 260, loss: 0.00015064480248838663
step: 270, loss: 0.00013130019942764193
step: 280, loss: 0.0013714170781895518
step: 290, loss: 0.009140468202531338
step: 300, loss: 7.32497574063018e-05
step: 310, loss: 0.008672920055687428
step: 320, loss: 0.001692736754193902
step: 330, loss: 0.00044224000885151327
step: 340, loss: 0.03943192586302757
step: 350, loss: 0.20620502531528473
step: 360, loss: 0.00021192702115513384
step: 370, loss: 0.0009747903677634895
step: 380, loss: 0.001020636409521103
step: 390, loss: 0.00033608402009122074
step: 400, loss: 0.004868824500590563
step: 410, loss: 0.004431307781487703
step: 420, loss: 0.0003394050872884691
step: 430, loss: 0.007331394124776125
step: 440, loss: 0.0008686951478011906
step: 450, loss: 0.002685441402718425
step: 460, loss: 0.01470127608627081
step: 470, loss: 0.04346580058336258
step: 480, loss: 0.020248981192708015
step: 490, loss: 0.0008126932661980391
step: 500, loss: 0.016260288655757904
step: 510, loss: 0.00844990648329258
step: 520, loss: 0.00010261758870910853
step: 530, loss: 0.0373808890581131
epoch 10: dev_f1=0.8044901777362021, f1=0.7808090310442145, best_f1=0.7782169521299956
step: 0, loss: 0.0003262021637056023
step: 10, loss: 0.0016687944298610091
step: 20, loss: 0.003791903844103217
step: 30, loss: 0.001822431804612279
step: 40, loss: 0.003137374296784401
step: 50, loss: 0.00010534508328419179
step: 60, loss: 0.006220943294465542
step: 70, loss: 6.709497392876074e-05
step: 80, loss: 0.0025839959271252155
step: 90, loss: 0.010496131144464016
step: 100, loss: 0.027176206931471825
step: 110, loss: 0.0001571301108924672
step: 120, loss: 4.713100133812986e-05
step: 130, loss: 0.007980688475072384
step: 140, loss: 0.011504286900162697
step: 150, loss: 0.0012284198310226202
step: 160, loss: 0.002388948807492852
step: 170, loss: 0.10166002064943314
step: 180, loss: 0.00025232104235328734
step: 190, loss: 0.02185612916946411
step: 200, loss: 0.024835698306560516
step: 210, loss: 0.0007891140412539244
step: 220, loss: 0.0018565431237220764
step: 230, loss: 0.0005581806180998683
step: 240, loss: 0.0009227500995621085
step: 250, loss: 0.009650549851357937
step: 260, loss: 0.0013039011973887682
step: 270, loss: 0.1375567615032196
step: 280, loss: 0.0007351184613071382
step: 290, loss: 0.0053505441173911095
step: 300, loss: 0.04423573240637779
step: 310, loss: 0.06424682587385178
step: 320, loss: 0.028037054464221
step: 330, loss: 0.00021856531384401023
step: 340, loss: 0.0061431750655174255
step: 350, loss: 0.0002578393032308668
step: 360, loss: 0.002872523618862033
step: 370, loss: 0.05503980070352554
step: 380, loss: 0.001212578034028411
step: 390, loss: 0.0014182472368702292
step: 400, loss: 0.005370759870857
step: 410, loss: 0.08032604306936264
step: 420, loss: 0.013614117167890072
step: 430, loss: 0.00029756486765109
step: 440, loss: 0.001071921200491488
step: 450, loss: 0.0017196256667375565
step: 460, loss: 0.0016039102338254452
step: 470, loss: 0.00017544538422953337
step: 480, loss: 0.00025032914709299803
step: 490, loss: 0.000726383354049176
step: 500, loss: 0.0016473053256049752
step: 510, loss: 0.00014031125465407968
step: 520, loss: 0.0002234834828414023
step: 530, loss: 0.0002071059716399759
epoch 11: dev_f1=0.8105216228265716, f1=0.7816497573886193, best_f1=0.7816497573886193
step: 0, loss: 0.0007529290742240846
step: 10, loss: 0.00023077087826095521
step: 20, loss: 0.00025175840710289776
step: 30, loss: 0.0013021843042224646
step: 40, loss: 0.008238228037953377
step: 50, loss: 0.00453814584761858
step: 60, loss: 0.006394116673618555
step: 70, loss: 0.0028346222825348377
step: 80, loss: 0.00025216315407305956
step: 90, loss: 0.0008435773779638112
step: 100, loss: 0.018039211630821228
step: 110, loss: 0.00021516077686101198
step: 120, loss: 6.013822348904796e-05
step: 130, loss: 0.0018610990373417735
step: 140, loss: 0.0003742456901818514
step: 150, loss: 0.00248607131652534
step: 160, loss: 0.0018748402362689376
step: 170, loss: 0.025351213291287422
step: 180, loss: 9.484292240813375e-05
step: 190, loss: 0.006763794459402561
step: 200, loss: 0.01412312500178814
step: 210, loss: 0.0024736421182751656
step: 220, loss: 0.0007611231994815171
step: 230, loss: 0.00031801185104995966
step: 240, loss: 0.0014089554315432906
step: 250, loss: 0.0012812966015189886
step: 260, loss: 0.01923958770930767
step: 270, loss: 0.016122909262776375
step: 280, loss: 0.0004181743715889752
step: 290, loss: 0.00015985507343430072
step: 300, loss: 0.0008195479167625308
step: 310, loss: 0.07854685932397842
step: 320, loss: 0.0035284790210425854
step: 330, loss: 0.0006388681358657777
step: 340, loss: 0.10259947180747986
step: 350, loss: 0.002732941647991538
step: 360, loss: 0.00013763959577772766
step: 370, loss: 0.00013348509673960507
step: 380, loss: 0.00046752466005273163
step: 390, loss: 8.121930295601487e-05
step: 400, loss: 0.018728816881775856
step: 410, loss: 0.005072841886430979
step: 420, loss: 0.007331974804401398
step: 430, loss: 3.423810994718224e-05
step: 440, loss: 0.0007526134140789509
step: 450, loss: 0.009526405483484268
step: 460, loss: 9.098862938117236e-05
step: 470, loss: 0.0010215522488579154
step: 480, loss: 0.010433070361614227
step: 490, loss: 0.0013787056086584926
step: 500, loss: 0.0004909769049845636
step: 510, loss: 0.00032300021848641336
step: 520, loss: 0.0016194818308576941
step: 530, loss: 8.173022069968283e-05
epoch 12: dev_f1=0.806639748766263, f1=0.7828442437923251, best_f1=0.7816497573886193
step: 0, loss: 0.000196833600057289
step: 10, loss: 0.0010081909131258726
step: 20, loss: 0.0003083444316871464
step: 30, loss: 0.0011959574185311794
step: 40, loss: 0.0005202995962463319
step: 50, loss: 0.12838114798069
step: 60, loss: 0.0019236310617998242
step: 70, loss: 0.016100384294986725
step: 80, loss: 0.0022477388847619295
step: 90, loss: 0.0009651879081502557
step: 100, loss: 0.0003309133171569556
step: 110, loss: 0.00048806951963342726
step: 120, loss: 0.0008867505821399391
step: 130, loss: 0.0001395681465510279
step: 140, loss: 0.00013001136539969593
step: 150, loss: 0.00028973291045986116
step: 160, loss: 0.0019498227629810572
step: 170, loss: 8.38926644064486e-05
step: 180, loss: 0.00015786479343660176
step: 190, loss: 0.0004822678747586906
step: 200, loss: 0.0006274338811635971
step: 210, loss: 9.514659905107692e-05
step: 220, loss: 0.0003332578926347196
step: 230, loss: 0.01786583475768566
step: 240, loss: 0.0001263509038835764
step: 250, loss: 0.0005754733574576676
step: 260, loss: 0.00020121280977036804
step: 270, loss: 0.002172232838347554
step: 280, loss: 0.0004080658545717597
step: 290, loss: 0.0013112288434058428
step: 300, loss: 0.00138973374851048
step: 310, loss: 0.003416141029447317
step: 320, loss: 0.0026381402276456356
step: 330, loss: 0.002182227559387684
step: 340, loss: 0.004859765060245991
step: 350, loss: 0.003008214756846428
step: 360, loss: 0.00349655793979764
step: 370, loss: 0.07270271331071854
step: 380, loss: 0.0002918441023211926
step: 390, loss: 0.1595669686794281
step: 400, loss: 0.0011532003991305828
step: 410, loss: 0.05556140094995499
step: 420, loss: 0.009142771363258362
step: 430, loss: 6.902575114509091e-05
step: 440, loss: 0.00021642548381350935
step: 450, loss: 0.0009675175533629954
step: 460, loss: 0.00012346875155344605
step: 470, loss: 6.767558807041496e-05
step: 480, loss: 0.0007830420508980751
step: 490, loss: 0.028682395815849304
step: 500, loss: 0.00023507379228249192
step: 510, loss: 8.475877257296816e-05
step: 520, loss: 0.00018222159997094423
step: 530, loss: 0.000277341139735654
epoch 13: dev_f1=0.8099773242630387, f1=0.7857142857142856, best_f1=0.7816497573886193
step: 0, loss: 0.03591887652873993
step: 10, loss: 0.0010763048194348812
step: 20, loss: 4.125967461732216e-05
step: 30, loss: 0.013600466772913933
step: 40, loss: 0.00016190003952942789
step: 50, loss: 3.389931589481421e-05
step: 60, loss: 0.002936886390671134
step: 70, loss: 0.0002791777369566262
step: 80, loss: 3.042623029614333e-05
step: 90, loss: 4.406990046845749e-05
step: 100, loss: 0.015219608321785927
step: 110, loss: 0.030760077759623528
step: 120, loss: 9.968637459678575e-05
step: 130, loss: 0.002853607991710305
step: 140, loss: 0.000347284076269716
step: 150, loss: 0.00020171771757304668
step: 160, loss: 2.4660952476551756e-05
step: 170, loss: 0.0001432562858099118
step: 180, loss: 0.00010354915866628289
step: 190, loss: 0.00014291791012510657
step: 200, loss: 0.0002334631426492706
step: 210, loss: 0.0003098317247349769
step: 220, loss: 0.002432872075587511
step: 230, loss: 9.43498162087053e-05
step: 240, loss: 5.812724702991545e-05
step: 250, loss: 0.00047476866166107357
step: 260, loss: 0.00027301660156808794
step: 270, loss: 2.94960609608097e-05
step: 280, loss: 6.925062916707247e-05
step: 290, loss: 0.015286391600966454
step: 300, loss: 0.00016931902791839093
step: 310, loss: 7.049230043776333e-05
step: 320, loss: 6.563930219272152e-05
step: 330, loss: 6.63133614580147e-05
step: 340, loss: 0.03507973998785019
step: 350, loss: 0.0007063833181746304
step: 360, loss: 6.978135934332386e-05
step: 370, loss: 0.002182518830522895
step: 380, loss: 6.44253013888374e-05
step: 390, loss: 4.549030927591957e-05
step: 400, loss: 0.0005567269399762154
step: 410, loss: 6.021152876201086e-05
step: 420, loss: 0.0005758659681305289
step: 430, loss: 0.0008089069742709398
step: 440, loss: 0.07348278909921646
step: 450, loss: 9.510429663350806e-05
step: 460, loss: 7.992093014763668e-05
step: 470, loss: 0.0001594434870639816
step: 480, loss: 0.01117025502026081
step: 490, loss: 0.0014405770925804973
step: 500, loss: 0.0012576421722769737
step: 510, loss: 0.01589243859052658
step: 520, loss: 0.0015372141497209668
step: 530, loss: 0.00011296598677290604
epoch 14: dev_f1=0.8105011933174224, f1=0.781190019193858, best_f1=0.7816497573886193
step: 0, loss: 3.5499018849805e-05
step: 10, loss: 0.00010282922448823228
step: 20, loss: 2.763339944067411e-05
step: 30, loss: 6.258604844333604e-05
step: 40, loss: 0.0003620765055529773
step: 50, loss: 4.8286667151842266e-05
step: 60, loss: 0.0002763296652119607
step: 70, loss: 0.0005273769493214786
step: 80, loss: 0.0002947263128589839
step: 90, loss: 0.0024482188746333122
step: 100, loss: 0.0002768167178146541
step: 110, loss: 6.562995258718729e-05
step: 120, loss: 0.0002606795751489699
step: 130, loss: 5.374344618758187e-05
step: 140, loss: 7.98663604655303e-05
step: 150, loss: 5.66249291296117e-05
step: 160, loss: 3.848765845759772e-05
step: 170, loss: 0.00281890039332211
step: 180, loss: 6.741970719303936e-05
step: 190, loss: 0.0002542747533880174
step: 200, loss: 0.010848217643797398
step: 210, loss: 0.000676448573358357
step: 220, loss: 4.5885451982030645e-05
step: 230, loss: 0.035580407828092575
step: 240, loss: 6.02375075686723e-05
step: 250, loss: 0.003620824310928583
step: 260, loss: 5.864299964741804e-05
step: 270, loss: 0.0006946364301256835
step: 280, loss: 0.00021164322970435023
step: 290, loss: 0.005002832505851984
step: 300, loss: 0.00011645418271655217
step: 310, loss: 0.0034980177879333496
step: 320, loss: 0.0034307772293686867
step: 330, loss: 0.10968440771102905
step: 340, loss: 0.0008752218564040959
step: 350, loss: 6.741197285009548e-05
step: 360, loss: 0.0011723489733412862
step: 370, loss: 0.000260693283053115
step: 380, loss: 0.0002314176526851952
step: 390, loss: 0.00013931425928603858
step: 400, loss: 3.336275040055625e-05
step: 410, loss: 0.0014601738657802343
step: 420, loss: 0.2441484034061432
step: 430, loss: 0.0022884223144501448
step: 440, loss: 0.0065559386275708675
step: 450, loss: 0.0010801787720993161
step: 460, loss: 0.00015459785936400294
step: 470, loss: 0.00010931586439255625
step: 480, loss: 0.004233913961797953
step: 490, loss: 4.71937091788277e-05
step: 500, loss: 0.002050598617643118
step: 510, loss: 0.00023497286019846797
step: 520, loss: 0.0696585550904274
step: 530, loss: 8.767700637690723e-05
epoch 15: dev_f1=0.7870791628753413, f1=0.7590971902349147, best_f1=0.7816497573886193
step: 0, loss: 0.0001554068294353783
step: 10, loss: 0.0008727152599021792
step: 20, loss: 0.0005431523313745856
step: 30, loss: 0.0009602036443538964
step: 40, loss: 0.0004181290278211236
step: 50, loss: 0.0002964924497064203
step: 60, loss: 8.441343379672617e-05
step: 70, loss: 0.0009018555865623057
step: 80, loss: 0.0008222499745897949
step: 90, loss: 5.533317380468361e-05
step: 100, loss: 7.305458711925894e-05
step: 110, loss: 0.0003447774797677994
step: 120, loss: 0.0002388416905887425
step: 130, loss: 3.9378628571284935e-05
step: 140, loss: 0.00012831561616621912
step: 150, loss: 9.262395178666338e-05
step: 160, loss: 4.229736441629939e-05
step: 170, loss: 0.00018783820269163698
step: 180, loss: 5.085289740236476e-05
step: 190, loss: 0.00022822478786110878
step: 200, loss: 0.00018827649182640016
step: 210, loss: 0.0002365006657782942
step: 220, loss: 3.983682836405933e-05
step: 230, loss: 0.00012657413026317954
step: 240, loss: 0.00015189388068392873
step: 250, loss: 9.680993389338255e-05
step: 260, loss: 0.00011836773774120957
step: 270, loss: 0.0001657446991885081
step: 280, loss: 4.412717680679634e-05
step: 290, loss: 3.99624441342894e-05
step: 300, loss: 0.0008315020240843296
step: 310, loss: 2.4105951524688862e-05
step: 320, loss: 0.00015295959019567817
step: 330, loss: 2.011257311096415e-05
step: 340, loss: 0.00012383567809592932
step: 350, loss: 0.021968849003314972
step: 360, loss: 0.00016591082385275513
step: 370, loss: 3.0087991035543382e-05
step: 380, loss: 0.00021094366093166173
step: 390, loss: 3.146284871036187e-05
step: 400, loss: 0.009929651394486427
step: 410, loss: 0.0024553958792239428
step: 420, loss: 2.0261588360881433e-05
step: 430, loss: 8.868530130712315e-05
step: 440, loss: 3.977307278546505e-05
step: 450, loss: 0.0007413191488012671
step: 460, loss: 4.912200529361144e-05
step: 470, loss: 6.244419637368992e-05
step: 480, loss: 0.0013061701320111752
step: 490, loss: 0.03983855992555618
step: 500, loss: 0.00012349056487437338
step: 510, loss: 0.0009608175605535507
step: 520, loss: 0.002664315514266491
step: 530, loss: 0.00027050977223552763
epoch 16: dev_f1=0.8144424131627056, f1=0.7873220027560864, best_f1=0.7873220027560864
step: 0, loss: 0.00030125517514534295
step: 10, loss: 4.563096081255935e-05
step: 20, loss: 0.00029367933166213334
step: 30, loss: 0.0007869285764172673
step: 40, loss: 0.0002420467499177903
step: 50, loss: 0.00012571856495924294
step: 60, loss: 4.990332672605291e-05
step: 70, loss: 6.160217890283093e-05
step: 80, loss: 0.0008870217716321349
step: 90, loss: 8.686307410243899e-05
step: 100, loss: 9.741202666191384e-05
step: 110, loss: 0.00022490086848847568
step: 120, loss: 0.0001399180036969483
step: 130, loss: 0.0001124625705415383
step: 140, loss: 6.858989945612848e-05
step: 150, loss: 0.00016710475028958172
step: 160, loss: 0.00023869324650149792
step: 170, loss: 2.4105711418087594e-05
step: 180, loss: 0.000655984622426331
step: 190, loss: 2.661655526026152e-05
step: 200, loss: 0.00011340170749463141
step: 210, loss: 0.00018605994409881532
step: 220, loss: 6.780115654692054e-05
step: 230, loss: 0.0007131975726224482
step: 240, loss: 5.9668029280146584e-05
step: 250, loss: 0.0014258871087804437
step: 260, loss: 0.0004376306605990976
step: 270, loss: 0.00016300719289574772
step: 280, loss: 0.021999651566147804
step: 290, loss: 0.00044869224075227976
step: 300, loss: 8.18040207377635e-05
step: 310, loss: 0.0002945931628346443
step: 320, loss: 0.0009470486547797918
step: 330, loss: 5.34655264345929e-05
step: 340, loss: 5.7747456594370306e-05
step: 350, loss: 5.0032514991471544e-05
step: 360, loss: 3.5656797990668565e-05
step: 370, loss: 0.0013454011641442776
step: 380, loss: 3.736618236871436e-05
step: 390, loss: 0.01129624992609024
step: 400, loss: 3.4785058232955635e-05
step: 410, loss: 0.00034915778087452054
step: 420, loss: 3.528866363922134e-05
step: 430, loss: 4.089728099643253e-05
step: 440, loss: 8.858043293002993e-05
step: 450, loss: 0.00017723810742609203
step: 460, loss: 0.00015046363114379346
step: 470, loss: 0.000944910163525492
step: 480, loss: 0.027485879138112068
step: 490, loss: 2.2757380065741017e-05
step: 500, loss: 4.673301009461284e-05
step: 510, loss: 0.00017077098891604692
step: 520, loss: 2.4828334062476642e-05
step: 530, loss: 7.525808905484155e-05
epoch 17: dev_f1=0.8166058394160584, f1=0.797427652733119, best_f1=0.797427652733119
step: 0, loss: 8.233028347603977e-05
step: 10, loss: 0.00037210085429251194
step: 20, loss: 7.434913277393207e-05
step: 30, loss: 0.004930477123707533
step: 40, loss: 5.290611443342641e-05
step: 50, loss: 0.00044348411029204726
step: 60, loss: 0.00010283212759532034
step: 70, loss: 0.00058830960188061
step: 80, loss: 0.0001414975122315809
step: 90, loss: 0.00018618270405568182
step: 100, loss: 0.00011065534636145458
step: 110, loss: 6.941038009244949e-05
step: 120, loss: 0.00046836139517836273
step: 130, loss: 0.00021012857905589044
step: 140, loss: 0.00041966556455008686
step: 150, loss: 4.0805007301969454e-05
step: 160, loss: 6.008890341036022e-05
step: 170, loss: 3.874808317050338e-05
step: 180, loss: 0.0013186982832849026
step: 190, loss: 0.0090385926887393
step: 200, loss: 0.0001512407325208187
step: 210, loss: 0.00012726863496936858
step: 220, loss: 0.00018502422608435154
step: 230, loss: 0.0074226330034434795
step: 240, loss: 4.2233048588968813e-05
step: 250, loss: 0.00042306233081035316
step: 260, loss: 0.00010945041867671534
step: 270, loss: 7.302628364413977e-05
step: 280, loss: 0.00015635263116564602
step: 290, loss: 9.352281631436199e-05
step: 300, loss: 0.00020015350310131907
step: 310, loss: 2.3908420189400204e-05
step: 320, loss: 0.0005331934080459177
step: 330, loss: 0.0001051565632224083
step: 340, loss: 0.0002477576199453324
step: 350, loss: 6.535110878758132e-05
step: 360, loss: 5.970940037514083e-05
step: 370, loss: 6.270759331528097e-05
step: 380, loss: 6.87962383381091e-05
step: 390, loss: 5.415230771177448e-05
step: 400, loss: 0.00028509055846370757
step: 410, loss: 8.043411071412265e-05
step: 420, loss: 0.0004448132822290063
step: 430, loss: 2.5461657060077414e-05
step: 440, loss: 0.00018477927369531244
step: 450, loss: 5.15705396537669e-05
step: 460, loss: 0.0031889472156763077
step: 470, loss: 4.4877990148961544e-05
step: 480, loss: 8.878934022504836e-05
step: 490, loss: 0.0005658960435539484
step: 500, loss: 7.079321221681312e-05
step: 510, loss: 0.0002617531572468579
step: 520, loss: 2.0216381017235108e-05
step: 530, loss: 3.158890103804879e-05
epoch 18: dev_f1=0.7979704797047971, f1=0.7751865671641791, best_f1=0.797427652733119
step: 0, loss: 0.004834427963942289
step: 10, loss: 6.966181535972282e-05
step: 20, loss: 4.832400009036064e-05
step: 30, loss: 3.220374128432013e-05
step: 40, loss: 0.002063681371510029
step: 50, loss: 0.0018211329588666558
step: 60, loss: 0.022643472999334335
step: 70, loss: 2.4351116735488176e-05
step: 80, loss: 3.1101353670237586e-05
step: 90, loss: 0.00018524093320593238
step: 100, loss: 1.8227598047815263e-05
step: 110, loss: 1.9691622583195567e-05
step: 120, loss: 0.0002609513176139444
step: 130, loss: 7.482278306270018e-05
step: 140, loss: 2.2202209947863594e-05
step: 150, loss: 0.0005040137330070138
step: 160, loss: 0.00031693780329078436
step: 170, loss: 0.00011443643597885966
step: 180, loss: 8.139502460835502e-05
step: 190, loss: 2.3762819182593375e-05
step: 200, loss: 0.002887584501877427
step: 210, loss: 3.4545999369584024e-05
step: 220, loss: 6.648893031524494e-05
step: 230, loss: 0.00011171069490956143
step: 240, loss: 4.903488661511801e-05
step: 250, loss: 4.649599577533081e-05
step: 260, loss: 0.0060472083278000355
step: 270, loss: 0.0002355952892685309
step: 280, loss: 0.0006281720707193017
step: 290, loss: 0.00010158250370295718
step: 300, loss: 0.0014142469735816121
step: 310, loss: 7.99241170170717e-05
step: 320, loss: 0.0012893046950921416
step: 330, loss: 0.0005641216412186623
step: 340, loss: 0.00023281951143871993
step: 350, loss: 3.348872633068822e-05
step: 360, loss: 2.2004698621458374e-05
step: 370, loss: 0.00028410012600943446
step: 380, loss: 6.310649041552097e-05
step: 390, loss: 4.525528856902383e-05
step: 400, loss: 4.281703513697721e-05
step: 410, loss: 2.7398735255701467e-05
step: 420, loss: 8.565763710066676e-05
step: 430, loss: 0.0008754497393965721
step: 440, loss: 4.557084685075097e-05
step: 450, loss: 0.0005954983062110841
step: 460, loss: 0.00024068370112217963
step: 470, loss: 7.721975998720154e-05
step: 480, loss: 3.4713917557382956e-05
step: 490, loss: 0.00011044971324736252
step: 500, loss: 7.339723379118368e-05
step: 510, loss: 1.949412762769498e-05
step: 520, loss: 3.801500497502275e-05
step: 530, loss: 0.0004469287523534149
epoch 19: dev_f1=0.8005644402634055, f1=0.7731811697574894, best_f1=0.797427652733119
step: 0, loss: 4.7871308197500184e-05
step: 10, loss: 0.000991611392237246
step: 20, loss: 2.5591403755242936e-05
step: 30, loss: 0.00011226320930290967
step: 40, loss: 0.00014649491640739143
step: 50, loss: 2.5684725187602453e-05
step: 60, loss: 3.412271325942129e-05
step: 70, loss: 0.0005480985273607075
step: 80, loss: 0.00013274210505187511
step: 90, loss: 1.4755734810023569e-05
step: 100, loss: 7.941083458717912e-05
step: 110, loss: 0.0010974815813824534
step: 120, loss: 0.00557866133749485
step: 130, loss: 3.169542469549924e-05
step: 140, loss: 2.756210778898094e-05
step: 150, loss: 0.00015358082600869238
step: 160, loss: 0.0006484476616606116
step: 170, loss: 0.0003029340005014092
step: 180, loss: 4.9366433813702315e-05
step: 190, loss: 0.00034627161221578717
step: 200, loss: 2.813210267049726e-05
step: 210, loss: 3.773520074901171e-05
step: 220, loss: 2.6832201911020093e-05
step: 230, loss: 0.00010428592941025272
step: 240, loss: 1.8890710634877905e-05
step: 250, loss: 0.0002748786937445402
step: 260, loss: 4.469078703550622e-05
step: 270, loss: 2.502567986084614e-05
step: 280, loss: 3.962678601965308e-05
step: 290, loss: 2.605762711027637e-05
step: 300, loss: 5.3399187891045585e-05
step: 310, loss: 0.0001642910938244313
step: 320, loss: 6.490206578746438e-05
step: 330, loss: 3.2981635740725324e-05
step: 340, loss: 0.0001275912654818967
step: 350, loss: 0.004388652741909027
step: 360, loss: 0.00021818175446242094
step: 370, loss: 0.00027513582608662546
step: 380, loss: 4.551810343400575e-05
step: 390, loss: 0.00038908797432668507
step: 400, loss: 0.00013708946062251925
step: 410, loss: 0.00019532055011950433
step: 420, loss: 2.7130487069371156e-05
step: 430, loss: 6.869446951895952e-05
step: 440, loss: 3.329072569613345e-05
step: 450, loss: 0.0007241324055939913
step: 460, loss: 0.0006136659067124128
step: 470, loss: 0.000494757667183876
step: 480, loss: 0.05741880461573601
step: 490, loss: 5.196457641432062e-05
step: 500, loss: 5.608393985312432e-05
step: 510, loss: 0.0011075531365349889
step: 520, loss: 5.365684410207905e-05
step: 530, loss: 8.358125342056155e-05
epoch 20: dev_f1=0.8014842300556586, f1=0.7744360902255639, best_f1=0.797427652733119
