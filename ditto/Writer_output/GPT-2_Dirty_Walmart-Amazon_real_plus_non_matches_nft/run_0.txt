cuda
Device: cuda
step: 0, loss: 0.7212626338005066
step: 10, loss: 0.3267384469509125
step: 20, loss: 0.14961698651313782
step: 30, loss: 0.1374102532863617
step: 40, loss: 0.32621681690216064
step: 50, loss: 0.13668228685855865
step: 60, loss: 0.42992785573005676
step: 70, loss: 0.5735298991203308
step: 80, loss: 0.5579820275306702
step: 90, loss: 0.3004058003425598
step: 100, loss: 0.13808411359786987
step: 110, loss: 0.21592946350574493
step: 120, loss: 0.16489002108573914
step: 130, loss: 0.20694600045681
step: 140, loss: 0.040520135313272476
step: 150, loss: 0.21759355068206787
step: 160, loss: 0.23977035284042358
step: 170, loss: 0.2167322337627411
step: 180, loss: 0.3023507595062256
step: 190, loss: 0.26215654611587524
step: 200, loss: 0.15713487565517426
step: 210, loss: 0.06177453324198723
step: 220, loss: 0.11333204805850983
step: 230, loss: 0.028182918205857277
step: 240, loss: 0.1314254105091095
step: 250, loss: 0.09417895972728729
step: 260, loss: 0.2764694094657898
step: 270, loss: 0.2508311867713928
step: 280, loss: 0.30852746963500977
step: 290, loss: 0.0520072877407074
step: 300, loss: 0.07802943140268326
step: 310, loss: 0.1196150854229927
step: 320, loss: 0.12460767477750778
step: 330, loss: 0.14418330788612366
step: 340, loss: 0.30120259523391724
step: 350, loss: 0.19785326719284058
step: 360, loss: 0.1298540085554123
epoch 1: dev_f1=0.5065274151436031, f1=0.5191256830601094, best_f1=0.5191256830601094
step: 0, loss: 0.02264677733182907
step: 10, loss: 0.1532018631696701
step: 20, loss: 0.16881033778190613
step: 30, loss: 0.07257343828678131
step: 40, loss: 0.06353016942739487
step: 50, loss: 0.07029087096452713
step: 60, loss: 0.06036017835140228
step: 70, loss: 0.21098078787326813
step: 80, loss: 0.24002093076705933
step: 90, loss: 0.1256677657365799
step: 100, loss: 0.20125773549079895
step: 110, loss: 0.20389388501644135
step: 120, loss: 0.1665494740009308
step: 130, loss: 0.2608928084373474
step: 140, loss: 0.1785324662923813
step: 150, loss: 0.05661279335618019
step: 160, loss: 0.05038886144757271
step: 170, loss: 0.023934409022331238
step: 180, loss: 0.054963137954473495
step: 190, loss: 0.2338709980249405
step: 200, loss: 0.08570348471403122
step: 210, loss: 0.14001138508319855
step: 220, loss: 0.06933069229125977
step: 230, loss: 0.050372205674648285
step: 240, loss: 0.08358125388622284
step: 250, loss: 0.20468361675739288
step: 260, loss: 0.17277111113071442
step: 270, loss: 0.04582810401916504
step: 280, loss: 0.03549843281507492
step: 290, loss: 0.006446605548262596
step: 300, loss: 0.10610724240541458
step: 310, loss: 0.008928305469453335
step: 320, loss: 0.24150420725345612
step: 330, loss: 0.08071766793727875
step: 340, loss: 0.39271020889282227
step: 350, loss: 0.14122731983661652
step: 360, loss: 0.01198965311050415
epoch 2: dev_f1=0.6761904761904761, f1=0.6732186732186732, best_f1=0.6732186732186732
step: 0, loss: 0.33348557353019714
step: 10, loss: 0.029792554676532745
step: 20, loss: 0.017155418172478676
step: 30, loss: 0.10454514622688293
step: 40, loss: 0.02105897292494774
step: 50, loss: 0.0016946694813668728
step: 60, loss: 0.0521087646484375
step: 70, loss: 0.12792420387268066
step: 80, loss: 0.2675365209579468
step: 90, loss: 0.10619039833545685
step: 100, loss: 0.29738375544548035
step: 110, loss: 0.017719322815537453
step: 120, loss: 0.06637190282344818
step: 130, loss: 0.13519009947776794
step: 140, loss: 0.05633607879281044
step: 150, loss: 0.038966163992881775
step: 160, loss: 0.020652957260608673
step: 170, loss: 0.002059520687907934
step: 180, loss: 0.0889006033539772
step: 190, loss: 0.024276327341794968
step: 200, loss: 0.07911178469657898
step: 210, loss: 0.07802291214466095
step: 220, loss: 0.2751031816005707
step: 230, loss: 0.041235361248254776
step: 240, loss: 0.004450417589396238
step: 250, loss: 0.2038118839263916
step: 260, loss: 0.0021345524583011866
step: 270, loss: 0.04873032867908478
step: 280, loss: 0.15427033603191376
step: 290, loss: 0.018890464678406715
step: 300, loss: 0.02606460638344288
step: 310, loss: 0.005383380223065615
step: 320, loss: 0.17640726268291473
step: 330, loss: 0.0864165648818016
step: 340, loss: 0.02058963105082512
step: 350, loss: 0.099628746509552
step: 360, loss: 0.10513342171907425
epoch 3: dev_f1=0.736, f1=0.7087912087912088, best_f1=0.7087912087912088
step: 0, loss: 0.04961231350898743
step: 10, loss: 0.011082719080150127
step: 20, loss: 0.273788183927536
step: 30, loss: 0.013919857330620289
step: 40, loss: 0.011178645305335522
step: 50, loss: 0.0018907955382019281
step: 60, loss: 0.043980956077575684
step: 70, loss: 0.008888647891581059
step: 80, loss: 0.011645019985735416
step: 90, loss: 0.0028501928318291903
step: 100, loss: 0.00097629614174366
step: 110, loss: 0.010959437116980553
step: 120, loss: 0.06445422023534775
step: 130, loss: 0.02461095340549946
step: 140, loss: 0.012217286042869091
step: 150, loss: 0.0029530073516070843
step: 160, loss: 0.03950197994709015
step: 170, loss: 0.03716550022363663
step: 180, loss: 0.0036138962022960186
step: 190, loss: 0.00043620678479783237
step: 200, loss: 0.03791768476366997
step: 210, loss: 0.029651453718543053
step: 220, loss: 0.08893810212612152
step: 230, loss: 0.021593935787677765
step: 240, loss: 0.004844388924539089
step: 250, loss: 0.10492374002933502
step: 260, loss: 0.018070435151457787
step: 270, loss: 0.018863791599869728
step: 280, loss: 0.0028298511169850826
step: 290, loss: 0.03274040296673775
step: 300, loss: 0.08293835073709488
step: 310, loss: 0.0059777479618787766
step: 320, loss: 0.022870708256959915
step: 330, loss: 0.08582065254449844
step: 340, loss: 0.02423311583697796
step: 350, loss: 0.005475710146129131
step: 360, loss: 0.014147886075079441
epoch 4: dev_f1=0.7052631578947368, f1=0.6833333333333333, best_f1=0.7087912087912088
step: 0, loss: 0.045952945947647095
step: 10, loss: 0.00403210986405611
step: 20, loss: 0.06283757835626602
step: 30, loss: 0.2924361228942871
step: 40, loss: 0.16712671518325806
step: 50, loss: 0.0417594313621521
step: 60, loss: 0.0023540614638477564
step: 70, loss: 0.00435363594442606
step: 80, loss: 0.001849890686571598
step: 90, loss: 0.01119416393339634
step: 100, loss: 0.005525469779968262
step: 110, loss: 0.0020269646774977446
step: 120, loss: 0.00259574968367815
step: 130, loss: 0.001765000750310719
step: 140, loss: 0.16303661465644836
step: 150, loss: 0.06968227028846741
step: 160, loss: 0.0013744073221459985
step: 170, loss: 0.0039408546872437
step: 180, loss: 0.015753600746393204
step: 190, loss: 0.01982560008764267
step: 200, loss: 0.01822982355952263
step: 210, loss: 0.005219985265284777
step: 220, loss: 0.0025452773552387953
step: 230, loss: 0.02060188166797161
step: 240, loss: 0.020630571991205215
step: 250, loss: 0.13410410284996033
step: 260, loss: 0.002491612220183015
step: 270, loss: 0.06208234280347824
step: 280, loss: 0.08974316716194153
step: 290, loss: 0.004880413878709078
step: 300, loss: 0.04226113483309746
step: 310, loss: 0.028976574540138245
step: 320, loss: 0.019691215828061104
step: 330, loss: 0.008099393919110298
step: 340, loss: 0.0008283215574920177
step: 350, loss: 0.00867103785276413
step: 360, loss: 0.017186667770147324
epoch 5: dev_f1=0.7379134860050889, f1=0.7135416666666666, best_f1=0.7135416666666666
step: 0, loss: 0.03957340866327286
step: 10, loss: 0.11647535115480423
step: 20, loss: 0.04062744230031967
step: 30, loss: 0.00787070207297802
step: 40, loss: 0.01966751553118229
step: 50, loss: 0.005246366374194622
step: 60, loss: 0.0669424757361412
step: 70, loss: 0.006556803360581398
step: 80, loss: 0.00323523860424757
step: 90, loss: 0.0005573295056819916
step: 100, loss: 0.024478226900100708
step: 110, loss: 0.010016389191150665
step: 120, loss: 0.001342201721854508
step: 130, loss: 0.0022503272630274296
step: 140, loss: 0.03502244874835014
step: 150, loss: 0.0014021588722243905
step: 160, loss: 0.00011651241948129609
step: 170, loss: 0.0005962293362244964
step: 180, loss: 0.0004633539938367903
step: 190, loss: 0.0007472982397302985
step: 200, loss: 0.00012519813026301563
step: 210, loss: 0.0073770275339484215
step: 220, loss: 0.0028816014528274536
step: 230, loss: 0.07408109307289124
step: 240, loss: 0.002324506174772978
step: 250, loss: 0.003230156609788537
step: 260, loss: 0.0028113825246691704
step: 270, loss: 0.00048364445683546364
step: 280, loss: 0.0007093586027622223
step: 290, loss: 0.14197301864624023
step: 300, loss: 0.009070584550499916
step: 310, loss: 0.0016768689965829253
step: 320, loss: 0.006233447231352329
step: 330, loss: 0.0783282220363617
step: 340, loss: 0.0028657931834459305
step: 350, loss: 0.0003401284047868103
step: 360, loss: 0.020704109221696854
epoch 6: dev_f1=0.6818181818181818, f1=0.6919191919191918, best_f1=0.7135416666666666
step: 0, loss: 0.12129345536231995
step: 10, loss: 0.02230830118060112
step: 20, loss: 0.03468051925301552
step: 30, loss: 0.0012407461181282997
step: 40, loss: 0.000841895118355751
step: 50, loss: 0.0007694041705690324
step: 60, loss: 0.0006424981402233243
step: 70, loss: 0.0019713295623660088
step: 80, loss: 0.1198078840970993
step: 90, loss: 0.0005580871365964413
step: 100, loss: 0.012550605461001396
step: 110, loss: 0.0018526508938521147
step: 120, loss: 0.0009102515177801251
step: 130, loss: 0.0016452017007395625
step: 140, loss: 0.002031147014349699
step: 150, loss: 0.0011618118733167648
step: 160, loss: 0.002491894643753767
step: 170, loss: 0.0030049241613596678
step: 180, loss: 0.0020061975810676813
step: 190, loss: 0.0005070449551567435
step: 200, loss: 0.0011082408018410206
step: 210, loss: 0.004584452137351036
step: 220, loss: 0.002119258278980851
step: 230, loss: 0.02866809442639351
step: 240, loss: 0.0003053274704143405
step: 250, loss: 0.0059092664159834385
step: 260, loss: 0.007778047118335962
step: 270, loss: 0.0016248448519036174
step: 280, loss: 0.0005438510561361909
step: 290, loss: 0.03635668382048607
step: 300, loss: 0.0005935884546488523
step: 310, loss: 0.00034071874688379467
step: 320, loss: 0.01026899740099907
step: 330, loss: 0.08974399417638779
step: 340, loss: 0.033731214702129364
step: 350, loss: 0.0018990447279065847
step: 360, loss: 0.01414234284311533
epoch 7: dev_f1=0.7182044887780549, f1=0.7231920199501246, best_f1=0.7135416666666666
step: 0, loss: 0.005434448830783367
step: 10, loss: 0.0015415857778862119
step: 20, loss: 0.00023469451116397977
step: 30, loss: 0.0009862593142315745
step: 40, loss: 0.0009135000291280448
step: 50, loss: 0.0005717570893466473
step: 60, loss: 0.000357287673978135
step: 70, loss: 0.0006761201657354832
step: 80, loss: 0.0006163220969028771
step: 90, loss: 0.005180390551686287
step: 100, loss: 0.011586971580982208
step: 110, loss: 0.004583868198096752
step: 120, loss: 0.003107893979176879
step: 130, loss: 0.0009973087580874562
step: 140, loss: 0.0017376028699800372
step: 150, loss: 0.0015804556896910071
step: 160, loss: 0.000439431139966473
step: 170, loss: 0.0030311238951981068
step: 180, loss: 0.000732522108592093
step: 190, loss: 0.011326724663376808
step: 200, loss: 0.0017031233292073011
step: 210, loss: 0.000322557520121336
step: 220, loss: 0.00055482960306108
step: 230, loss: 0.0009433762170374393
step: 240, loss: 0.04359543323516846
step: 250, loss: 0.00024121333262883127
step: 260, loss: 0.001432587974704802
step: 270, loss: 0.00031819241121411324
step: 280, loss: 0.0010679748374968767
step: 290, loss: 0.0004990978632122278
step: 300, loss: 0.0030358503572642803
step: 310, loss: 0.00019835920829791576
step: 320, loss: 0.006827887147665024
step: 330, loss: 0.01126788929104805
step: 340, loss: 0.14660096168518066
step: 350, loss: 0.0030881373677402735
step: 360, loss: 0.0008982365834526718
epoch 8: dev_f1=0.7557603686635944, f1=0.7146171693735499, best_f1=0.7146171693735499
step: 0, loss: 0.0006259764777496457
step: 10, loss: 0.0017658415017649531
step: 20, loss: 0.10190519690513611
step: 30, loss: 0.0005100657581351697
step: 40, loss: 0.017931543290615082
step: 50, loss: 0.000345594686223194
step: 60, loss: 0.0006291967583820224
step: 70, loss: 0.009297054260969162
step: 80, loss: 0.04792018234729767
step: 90, loss: 0.06783799082040787
step: 100, loss: 0.00806134007871151
step: 110, loss: 0.00041163060814142227
step: 120, loss: 0.0006155872251838446
step: 130, loss: 0.00693946098908782
step: 140, loss: 0.0017465458950027823
step: 150, loss: 0.000938490207772702
step: 160, loss: 0.0016123929526656866
step: 170, loss: 0.021439241245388985
step: 180, loss: 0.004151101689785719
step: 190, loss: 0.00586289307102561
step: 200, loss: 0.000366037042113021
step: 210, loss: 0.0007841617334634066
step: 220, loss: 0.00015948295185808092
step: 230, loss: 0.012530356645584106
step: 240, loss: 9.180740016745403e-05
step: 250, loss: 0.000954186252783984
step: 260, loss: 0.0009177160100080073
step: 270, loss: 0.0012377557577565312
step: 280, loss: 0.023451853543519974
step: 290, loss: 0.0003956398577429354
step: 300, loss: 0.0004223902360536158
step: 310, loss: 7.477877079509199e-05
step: 320, loss: 0.0003233430616091937
step: 330, loss: 0.0003776605299208313
step: 340, loss: 0.00027883975417353213
step: 350, loss: 0.002595750382170081
step: 360, loss: 0.0030146560166031122
epoch 9: dev_f1=0.751842751842752, f1=0.6849999999999999, best_f1=0.7146171693735499
step: 0, loss: 0.0023297122679650784
step: 10, loss: 0.00010430435213493183
step: 20, loss: 0.0030366715509444475
step: 30, loss: 0.0012268555583432317
step: 40, loss: 0.00011623940372373909
step: 50, loss: 0.00018580324831418693
step: 60, loss: 0.0008703509229235351
step: 70, loss: 0.00017747419769875705
step: 80, loss: 0.051864467561244965
step: 90, loss: 0.00011921356053790078
step: 100, loss: 5.093574509373866e-05
step: 110, loss: 0.0006323487614281476
step: 120, loss: 0.00033309473656117916
step: 130, loss: 0.00305915460921824
step: 140, loss: 0.0005866893916390836
step: 150, loss: 0.0004503054078668356
step: 160, loss: 0.0003911574021913111
step: 170, loss: 0.0003374701482243836
step: 180, loss: 0.007299617864191532
step: 190, loss: 0.00018209943664260209
step: 200, loss: 0.0010763737373054028
step: 210, loss: 0.0013740212889388204
step: 220, loss: 0.0004443399957381189
step: 230, loss: 7.746979099465534e-05
step: 240, loss: 7.450382690876722e-05
step: 250, loss: 0.000561075983569026
step: 260, loss: 0.0002419505181023851
step: 270, loss: 0.00027521539595909417
step: 280, loss: 0.0002092886861646548
step: 290, loss: 0.00013630952162202448
step: 300, loss: 0.00010052646393887699
step: 310, loss: 0.00019937011529691517
step: 320, loss: 0.0001941994996741414
step: 330, loss: 0.00012506829807534814
step: 340, loss: 0.021757880225777626
step: 350, loss: 5.004974445910193e-05
step: 360, loss: 0.00012911025260109454
epoch 10: dev_f1=0.6954177897574124, f1=0.6775956284153005, best_f1=0.7146171693735499
step: 0, loss: 0.007620126008987427
step: 10, loss: 0.0033452596981078386
step: 20, loss: 0.005444090347737074
step: 30, loss: 6.34048628853634e-05
step: 40, loss: 0.0003794568183366209
step: 50, loss: 0.00012617185711860657
step: 60, loss: 0.0015232614241540432
step: 70, loss: 0.0010844985954463482
step: 80, loss: 0.0013281850842759013
step: 90, loss: 0.0001496539480285719
step: 100, loss: 0.0003396495885681361
step: 110, loss: 0.0002848601434379816
step: 120, loss: 0.0010397018631920218
step: 130, loss: 0.0003577864554245025
step: 140, loss: 0.00020573909569066018
step: 150, loss: 0.02211933024227619
step: 160, loss: 0.00013199813838582486
step: 170, loss: 0.029231466352939606
step: 180, loss: 0.0650993064045906
step: 190, loss: 0.11549977213144302
step: 200, loss: 0.04861616715788841
step: 210, loss: 0.005419887602329254
step: 220, loss: 0.0007161255925893784
step: 230, loss: 0.0008994474774226546
step: 240, loss: 0.0006242700037546456
step: 250, loss: 0.0016314232489094138
step: 260, loss: 0.0002028069575317204
step: 270, loss: 0.00026836019242182374
step: 280, loss: 0.00019370997324585915
step: 290, loss: 0.0008771260618232191
step: 300, loss: 0.00014592157094739377
step: 310, loss: 0.0006678546778857708
step: 320, loss: 0.00015086350322235376
step: 330, loss: 8.2776190538425e-05
step: 340, loss: 0.0016642336267977953
step: 350, loss: 0.03982750326395035
step: 360, loss: 0.00112019176594913
epoch 11: dev_f1=0.743142144638404, f1=0.7411167512690356, best_f1=0.7146171693735499
step: 0, loss: 0.002398119308054447
step: 10, loss: 0.001348244957625866
step: 20, loss: 0.0002321689680684358
step: 30, loss: 0.0005392928142100573
step: 40, loss: 6.100544851506129e-05
step: 50, loss: 0.0003183602821081877
step: 60, loss: 0.029457097873091698
step: 70, loss: 0.0006162042263895273
step: 80, loss: 4.380388782010414e-05
step: 90, loss: 0.003913436084985733
step: 100, loss: 5.463440538733266e-05
step: 110, loss: 0.0003382156428415328
step: 120, loss: 8.076718950178474e-05
step: 130, loss: 4.075667311553843e-05
step: 140, loss: 0.00036499404814094305
step: 150, loss: 0.004680579993873835
step: 160, loss: 0.002905258210375905
step: 170, loss: 0.001122378627769649
step: 180, loss: 0.0041675264947116375
step: 190, loss: 0.00012139741738792509
step: 200, loss: 0.0009646576945669949
step: 210, loss: 0.0008996344404295087
step: 220, loss: 0.0002333023294340819
step: 230, loss: 0.0013086445396766067
step: 240, loss: 0.00011306947999401018
step: 250, loss: 0.0009439175482839346
step: 260, loss: 0.00012856411922257394
step: 270, loss: 0.007893120869994164
step: 280, loss: 0.0023528740275651217
step: 290, loss: 0.0001919906644616276
step: 300, loss: 0.001804101630114019
step: 310, loss: 0.0008995860698632896
step: 320, loss: 0.00047350319800898433
step: 330, loss: 0.00024277997727040201
step: 340, loss: 0.0003742668777704239
step: 350, loss: 4.2973428207915276e-05
step: 360, loss: 0.00012649908603634685
epoch 12: dev_f1=0.7336956521739131, f1=0.7032967032967032, best_f1=0.7146171693735499
step: 0, loss: 0.002200705697759986
step: 10, loss: 9.438009146833792e-05
step: 20, loss: 0.00035770251997746527
step: 30, loss: 0.004740236327052116
step: 40, loss: 4.599708699970506e-05
step: 50, loss: 7.751418161205947e-05
step: 60, loss: 4.802452531293966e-05
step: 70, loss: 0.0003255745396018028
step: 80, loss: 3.726558497874066e-05
step: 90, loss: 0.00014864014519844204
step: 100, loss: 0.000650323461741209
step: 110, loss: 7.925028330646455e-05
step: 120, loss: 0.00011369135609129444
step: 130, loss: 0.00011445668496889994
step: 140, loss: 0.0008827496785670519
step: 150, loss: 0.09761770069599152
step: 160, loss: 0.00012725158012472093
step: 170, loss: 0.00025553518207743764
step: 180, loss: 0.06623119115829468
step: 190, loss: 0.002285345923155546
step: 200, loss: 0.0014197416603565216
step: 210, loss: 0.0002267023955937475
step: 220, loss: 0.00024317952920682728
step: 230, loss: 0.0008292262791655958
step: 240, loss: 0.0004288277996238321
step: 250, loss: 8.758101466810331e-05
step: 260, loss: 0.0153459208086133
step: 270, loss: 0.001245435792952776
step: 280, loss: 0.001370651414617896
step: 290, loss: 0.00016419556050095707
step: 300, loss: 8.83504471858032e-05
step: 310, loss: 0.00014341017231345177
step: 320, loss: 0.0003401301510166377
step: 330, loss: 0.13528622686862946
step: 340, loss: 0.003364481730386615
step: 350, loss: 0.002080728067085147
step: 360, loss: 0.0007227748865261674
epoch 13: dev_f1=0.7229551451187335, f1=0.7268041237113403, best_f1=0.7146171693735499
step: 0, loss: 0.00047707927296869457
step: 10, loss: 0.003183304565027356
step: 20, loss: 0.0005953811923973262
step: 30, loss: 0.0001930231519509107
step: 40, loss: 4.316552804084495e-05
step: 50, loss: 0.0003324182762298733
step: 60, loss: 0.00017036359349731356
step: 70, loss: 0.0005012667970731854
step: 80, loss: 3.243456012569368e-05
step: 90, loss: 3.924965494661592e-05
step: 100, loss: 0.0010186947183683515
step: 110, loss: 0.00013148298603482544
step: 120, loss: 0.00041887914994731545
step: 130, loss: 0.006827829871326685
step: 140, loss: 0.0012902396265417337
step: 150, loss: 0.0005879346281290054
step: 160, loss: 0.0015588323585689068
step: 170, loss: 0.002929642563685775
step: 180, loss: 4.859093314735219e-05
step: 190, loss: 0.026075387373566628
step: 200, loss: 0.005367964971810579
step: 210, loss: 0.00013142070383764803
step: 220, loss: 0.002059816149994731
step: 230, loss: 0.00013442744966596365
step: 240, loss: 1.942712151503656e-05
step: 250, loss: 0.00032862540683709085
step: 260, loss: 8.932875061873347e-05
step: 270, loss: 0.012181395664811134
step: 280, loss: 0.002222278853878379
step: 290, loss: 0.0001650667400099337
step: 300, loss: 0.00016126326227094978
step: 310, loss: 0.00011294542491668835
step: 320, loss: 0.00020834429597016424
step: 330, loss: 0.00016514996241312474
step: 340, loss: 0.0012042101006954908
step: 350, loss: 0.0004284423775970936
step: 360, loss: 0.0024773050099611282
epoch 14: dev_f1=0.7216494845360825, f1=0.6979166666666666, best_f1=0.7146171693735499
step: 0, loss: 0.0004035752499476075
step: 10, loss: 0.0043746489100158215
step: 20, loss: 7.19398885848932e-05
step: 30, loss: 0.002242734655737877
step: 40, loss: 0.001535764429718256
step: 50, loss: 0.0006039499421603978
step: 60, loss: 0.003984502051025629
step: 70, loss: 0.0027983728796243668
step: 80, loss: 0.00030430161859840155
step: 90, loss: 0.00028811959782615304
step: 100, loss: 0.00023731321562081575
step: 110, loss: 0.0010228415485471487
step: 120, loss: 0.0006734417984262109
step: 130, loss: 0.0006687709246762097
step: 140, loss: 0.00046955840662121773
step: 150, loss: 7.665168959647417e-05
step: 160, loss: 0.00032263726461678743
step: 170, loss: 0.0001181021289085038
step: 180, loss: 0.00015452125808224082
step: 190, loss: 0.0002649726811796427
step: 200, loss: 0.0003647916892077774
step: 210, loss: 0.004897942766547203
step: 220, loss: 9.69840693869628e-05
step: 230, loss: 0.0001571342145325616
step: 240, loss: 2.7015265004592948e-05
step: 250, loss: 0.000340876606060192
step: 260, loss: 0.00014682207256555557
step: 270, loss: 0.0006528868689201772
step: 280, loss: 0.0007162940455600619
step: 290, loss: 0.000457483169157058
step: 300, loss: 0.0002470472827553749
step: 310, loss: 0.00025158957578241825
step: 320, loss: 0.00024833326460793614
step: 330, loss: 0.0005577885895036161
step: 340, loss: 0.0018073510145768523
step: 350, loss: 0.005420109257102013
step: 360, loss: 9.143185889115557e-05
epoch 15: dev_f1=0.7106598984771575, f1=0.7116883116883116, best_f1=0.7146171693735499
step: 0, loss: 0.0001524109538877383
step: 10, loss: 0.00018663046648725867
step: 20, loss: 8.406895358348265e-05
step: 30, loss: 0.00012905661424156278
step: 40, loss: 0.0003719679662026465
step: 50, loss: 0.00016764549945946783
step: 60, loss: 8.897302905097604e-05
step: 70, loss: 0.004125854466110468
step: 80, loss: 0.0003324337303638458
step: 90, loss: 2.7376087018637918e-05
step: 100, loss: 4.9167538236361e-05
step: 110, loss: 0.0006952647236175835
step: 120, loss: 0.0001340271846856922
step: 130, loss: 0.00042596031562425196
step: 140, loss: 0.0001203263527713716
step: 150, loss: 0.00042077514808624983
step: 160, loss: 0.00033293062006123364
step: 170, loss: 0.0007266551838256419
step: 180, loss: 7.347371138166636e-05
step: 190, loss: 0.0005637510330416262
step: 200, loss: 0.0045969728380441666
step: 210, loss: 5.9337038692319766e-05
step: 220, loss: 0.00011030079622287303
step: 230, loss: 6.142193888081238e-05
step: 240, loss: 0.00031226230203174055
step: 250, loss: 0.0008313176222145557
step: 260, loss: 0.00012569755199365318
step: 270, loss: 9.612662688596174e-05
step: 280, loss: 0.00018552316760178655
step: 290, loss: 0.000101756006188225
step: 300, loss: 4.515265754889697e-05
step: 310, loss: 0.0006173621513880789
step: 320, loss: 0.0024105904158204794
step: 330, loss: 2.5409064619452693e-05
step: 340, loss: 0.00016257469542324543
step: 350, loss: 0.0002702666388358921
step: 360, loss: 0.0002856150676961988
epoch 16: dev_f1=0.7258883248730965, f1=0.711340206185567, best_f1=0.7146171693735499
step: 0, loss: 6.729300366714597e-05
step: 10, loss: 0.00012442479783203453
step: 20, loss: 2.6061541575472802e-05
step: 30, loss: 0.00020145237795077264
step: 40, loss: 0.00011727269884431735
step: 50, loss: 0.00012280946248210967
step: 60, loss: 9.922832396114245e-05
step: 70, loss: 0.0025800608564168215
step: 80, loss: 0.0005825763801112771
step: 90, loss: 0.0002042565611191094
step: 100, loss: 7.060041389195248e-05
step: 110, loss: 0.0004459042102098465
step: 120, loss: 3.645293691079132e-05
step: 130, loss: 0.00010462938371347263
step: 140, loss: 5.539434641832486e-05
step: 150, loss: 0.00013720589049626142
step: 160, loss: 0.0003714619087986648
step: 170, loss: 0.0015780744142830372
step: 180, loss: 3.7812162190675735e-05
step: 190, loss: 0.0004254535015206784
step: 200, loss: 7.781478052493185e-05
step: 210, loss: 4.442484714672901e-05
step: 220, loss: 0.0006717915530316532
step: 230, loss: 0.00041119856177829206
step: 240, loss: 0.00015344450366683304
step: 250, loss: 7.094645116012543e-05
step: 260, loss: 9.253106691176072e-05
step: 270, loss: 3.084423951804638e-05
step: 280, loss: 6.546649092342705e-05
step: 290, loss: 4.754774636239745e-05
step: 300, loss: 4.927435293211602e-05
step: 310, loss: 1.8428725525154732e-05
step: 320, loss: 0.0010508578270673752
step: 330, loss: 8.9889312221203e-05
step: 340, loss: 0.00022684472787659615
step: 350, loss: 7.966404518811032e-05
step: 360, loss: 0.00013788945216219872
epoch 17: dev_f1=0.7376237623762376, f1=0.7135678391959798, best_f1=0.7146171693735499
step: 0, loss: 3.136540181003511e-05
step: 10, loss: 0.0011387381237000227
step: 20, loss: 0.00011498892854433507
step: 30, loss: 0.0001331596140516922
step: 40, loss: 0.00017900197417475283
step: 50, loss: 2.3718390366411768e-05
step: 60, loss: 7.601793913636357e-05
step: 70, loss: 0.00010169688175665215
step: 80, loss: 9.967812366085127e-05
step: 90, loss: 3.1976611353456974e-05
step: 100, loss: 7.83773502917029e-05
step: 110, loss: 4.78643923997879e-05
step: 120, loss: 6.224289245437831e-05
step: 130, loss: 9.895782568491995e-05
step: 140, loss: 3.776453377213329e-05
step: 150, loss: 2.3450162188964896e-05
step: 160, loss: 4.216310480842367e-05
step: 170, loss: 8.28263582661748e-05
step: 180, loss: 0.00012044828326907009
step: 190, loss: 9.335455251857638e-05
step: 200, loss: 0.00021776033099740744
step: 210, loss: 5.97029211348854e-05
step: 220, loss: 0.0010390806710347533
step: 230, loss: 1.7992957509704866e-05
step: 240, loss: 0.0007228364120237529
step: 250, loss: 4.975092815584503e-05
step: 260, loss: 4.2087041947524995e-05
step: 270, loss: 3.260582889197394e-05
step: 280, loss: 6.0869970184285194e-05
step: 290, loss: 0.00012612297723535448
step: 300, loss: 2.4362683689105324e-05
step: 310, loss: 3.901904710801318e-05
step: 320, loss: 3.5354754800209776e-05
step: 330, loss: 0.00020948928431607783
step: 340, loss: 0.00025049070245586336
step: 350, loss: 3.763960557989776e-05
step: 360, loss: 9.721075184643269e-05
epoch 18: dev_f1=0.7272727272727273, f1=0.7119565217391304, best_f1=0.7146171693735499
step: 0, loss: 7.831338734831661e-05
step: 10, loss: 0.00010494565503904596
step: 20, loss: 3.821231803158298e-05
step: 30, loss: 2.490234692231752e-05
step: 40, loss: 0.00027895046514458954
step: 50, loss: 2.758325354079716e-05
step: 60, loss: 0.002598169259727001
step: 70, loss: 0.0002283184148836881
step: 80, loss: 0.0001125969210988842
step: 90, loss: 0.0004312981618568301
step: 100, loss: 8.445570711046457e-05
step: 110, loss: 2.6693907784647308e-05
step: 120, loss: 0.00011093205830547959
step: 130, loss: 6.225964170880616e-05
step: 140, loss: 0.00046787853352725506
step: 150, loss: 4.472619912121445e-05
step: 160, loss: 2.0745832443935797e-05
step: 170, loss: 0.00014378562627825886
step: 180, loss: 4.592373807099648e-05
step: 190, loss: 0.00017383016529493034
step: 200, loss: 9.98580944724381e-05
step: 210, loss: 9.089748346013948e-05
step: 220, loss: 9.540329483570531e-05
step: 230, loss: 0.00010511172149563208
step: 240, loss: 6.466093327617273e-05
step: 250, loss: 0.00012350617907941341
step: 260, loss: 0.0006211118306964636
step: 270, loss: 0.0001589334715390578
step: 280, loss: 0.0014358378248289227
step: 290, loss: 0.0003655896580312401
step: 300, loss: 5.716237137676217e-05
step: 310, loss: 0.00044120693928562105
step: 320, loss: 0.00011631393863353878
step: 330, loss: 8.23755472083576e-05
step: 340, loss: 2.8688613383565098e-05
step: 350, loss: 0.00034411231172271073
step: 360, loss: 0.00015700732183177024
epoch 19: dev_f1=0.7351351351351353, f1=0.7197802197802198, best_f1=0.7146171693735499
step: 0, loss: 0.00015829061158001423
step: 10, loss: 0.00012352275371085852
step: 20, loss: 0.00011897936201421544
step: 30, loss: 2.304389090568293e-05
step: 40, loss: 0.0018258645432069898
step: 50, loss: 3.119326720479876e-05
step: 60, loss: 7.271463255165145e-05
step: 70, loss: 0.00012586470984388143
step: 80, loss: 0.0001804628991521895
step: 90, loss: 0.0005825773696415126
step: 100, loss: 0.0009266437264159322
step: 110, loss: 6.875696999486536e-05
step: 120, loss: 4.223159339744598e-05
step: 130, loss: 0.00010894789738813415
step: 140, loss: 6.728416337864473e-05
step: 150, loss: 0.00020449195289984345
step: 160, loss: 8.548167534172535e-05
step: 170, loss: 0.0007622884004376829
step: 180, loss: 5.493023490998894e-05
step: 190, loss: 9.836050594458356e-05
step: 200, loss: 0.00017108555766753852
step: 210, loss: 2.9853234082111157e-05
step: 220, loss: 0.00010075711907120422
step: 230, loss: 0.00011837943020509556
step: 240, loss: 7.322225428652018e-05
step: 250, loss: 0.001265231054276228
step: 260, loss: 4.656450983020477e-05
step: 270, loss: 0.00010573745385045186
step: 280, loss: 6.185536767588928e-05
step: 290, loss: 8.279130270238966e-05
step: 300, loss: 2.707063868001569e-05
step: 310, loss: 5.5092834372771904e-05
step: 320, loss: 2.7558669899008237e-05
step: 330, loss: 0.00022842836915515363
step: 340, loss: 5.526769018615596e-05
step: 350, loss: 3.4426262573106214e-05
step: 360, loss: 0.0004353472322691232
epoch 20: dev_f1=0.7526315789473683, f1=0.7184986595174263, best_f1=0.7146171693735499
