cuda
Device: cuda
step: 0, loss: 0.6799758076667786
step: 10, loss: 0.4289931654930115
step: 20, loss: 0.3913181722164154
step: 30, loss: 0.4056232273578644
step: 40, loss: 0.13958457112312317
step: 50, loss: 0.21680782735347748
step: 60, loss: 0.29630550742149353
step: 70, loss: 0.17353463172912598
step: 80, loss: 0.06314649432897568
step: 90, loss: 0.26635754108428955
step: 100, loss: 0.0622456818819046
step: 110, loss: 0.048985082656145096
step: 120, loss: 0.24090512096881866
step: 130, loss: 0.2418675273656845
step: 140, loss: 0.2732146382331848
step: 150, loss: 0.06632426381111145
step: 160, loss: 0.13795645534992218
step: 170, loss: 0.16772453486919403
step: 180, loss: 0.11165148764848709
step: 190, loss: 0.056219447404146194
step: 200, loss: 0.10103098303079605
step: 210, loss: 0.15011389553546906
step: 220, loss: 0.13707560300827026
step: 230, loss: 0.2933185398578644
step: 240, loss: 0.19026502966880798
step: 250, loss: 0.09334591031074524
step: 260, loss: 0.25797775387763977
step: 270, loss: 0.0348765067756176
step: 280, loss: 0.09064017981290817
step: 290, loss: 0.07160256803035736
step: 300, loss: 0.018326709046959877
step: 310, loss: 0.021610720083117485
step: 320, loss: 0.08693403005599976
step: 330, loss: 0.016883622854948044
step: 340, loss: 0.018737565726041794
step: 350, loss: 0.029056232422590256
step: 360, loss: 0.0887230858206749
step: 370, loss: 0.045455362647771835
step: 380, loss: 0.039712075144052505
step: 390, loss: 0.059595510363578796
step: 400, loss: 0.025742555037140846
step: 410, loss: 0.02523149363696575
step: 420, loss: 0.07512491196393967
step: 430, loss: 0.21820227801799774
step: 440, loss: 0.03493215888738632
step: 450, loss: 0.10840018838644028
step: 460, loss: 0.07836772501468658
epoch 1: dev_f1=0.990990990990991, f1=0.9864253393665158, best_f1=0.9864253393665158
step: 0, loss: 0.02278081886470318
step: 10, loss: 0.01382917445152998
step: 20, loss: 0.02248719148337841
step: 30, loss: 0.03193264082074165
step: 40, loss: 0.076370008289814
step: 50, loss: 0.1487448662519455
step: 60, loss: 0.07404700666666031
step: 70, loss: 0.0713406354188919
step: 80, loss: 0.17404446005821228
step: 90, loss: 0.04445856437087059
step: 100, loss: 0.06879082322120667
step: 110, loss: 0.07907069474458694
step: 120, loss: 0.01341400109231472
step: 130, loss: 0.25451958179473877
step: 140, loss: 0.16421538591384888
step: 150, loss: 0.06502703577280045
step: 160, loss: 0.04052957519888878
step: 170, loss: 0.04007936269044876
step: 180, loss: 0.018474584445357323
step: 190, loss: 0.17173311114311218
step: 200, loss: 0.053620174527168274
step: 210, loss: 0.0590558759868145
step: 220, loss: 0.0921272337436676
step: 230, loss: 0.0608261302113533
step: 240, loss: 0.009298324584960938
step: 250, loss: 0.03120465949177742
step: 260, loss: 0.075382761657238
step: 270, loss: 0.09866590797901154
step: 280, loss: 0.06015930697321892
step: 290, loss: 0.07335617393255234
step: 300, loss: 0.06907015293836594
step: 310, loss: 0.009989127516746521
step: 320, loss: 0.029651258140802383
step: 330, loss: 0.08462674170732498
step: 340, loss: 0.07716311514377594
step: 350, loss: 0.015163993462920189
step: 360, loss: 0.08969121426343918
step: 370, loss: 0.016638966277241707
step: 380, loss: 0.01796828769147396
step: 390, loss: 0.054773975163698196
step: 400, loss: 0.06967293471097946
step: 410, loss: 0.0735594779253006
step: 420, loss: 0.0127419987693429
step: 430, loss: 0.08474284410476685
step: 440, loss: 0.07089368999004364
step: 450, loss: 0.07342422753572464
step: 460, loss: 0.08070295304059982
epoch 2: dev_f1=0.9887892376681614, f1=0.9876543209876544, best_f1=0.9864253393665158
step: 0, loss: 0.0003126804658677429
step: 10, loss: 0.024040380492806435
step: 20, loss: 0.03214047849178314
step: 30, loss: 0.021586230024695396
step: 40, loss: 0.03022201918065548
step: 50, loss: 0.00870649702847004
step: 60, loss: 0.1570509970188141
step: 70, loss: 0.060553524643182755
step: 80, loss: 0.15362150967121124
step: 90, loss: 0.09602690488100052
step: 100, loss: 0.06751362979412079
step: 110, loss: 0.030283931642770767
step: 120, loss: 0.09532883763313293
step: 130, loss: 0.07292267680168152
step: 140, loss: 0.014387461356818676
step: 150, loss: 0.01578635722398758
step: 160, loss: 0.05571949481964111
step: 170, loss: 0.07316820323467255
step: 180, loss: 0.01874883472919464
step: 190, loss: 0.010869842953979969
step: 200, loss: 0.07956651598215103
step: 210, loss: 0.08737695962190628
step: 220, loss: 0.055936455726623535
step: 230, loss: 0.10554248839616776
step: 240, loss: 0.07778483629226685
step: 250, loss: 0.05772252753376961
step: 260, loss: 0.02186504751443863
step: 270, loss: 0.02324007824063301
step: 280, loss: 0.026936659589409828
step: 290, loss: 0.07788608223199844
step: 300, loss: 0.00459783710539341
step: 310, loss: 0.047834280878305435
step: 320, loss: 0.08854856342077255
step: 330, loss: 0.048442739993333817
step: 340, loss: 0.027899133041501045
step: 350, loss: 0.08043751120567322
step: 360, loss: 0.06490659713745117
step: 370, loss: 0.1473395675420761
step: 380, loss: 0.0991099551320076
step: 390, loss: 0.028128698468208313
step: 400, loss: 0.052387550473213196
step: 410, loss: 0.04056341573596001
step: 420, loss: 0.014961905777454376
step: 430, loss: 0.12941007316112518
step: 440, loss: 0.08321764320135117
step: 450, loss: 0.1683916300535202
step: 460, loss: 0.03291952610015869
epoch 3: dev_f1=0.9932584269662922, f1=0.9887640449438202, best_f1=0.9887640449438202
step: 0, loss: 0.021163158118724823
step: 10, loss: 0.019775379449129105
step: 20, loss: 0.035924166440963745
step: 30, loss: 0.3378922641277313
step: 40, loss: 0.11812467873096466
step: 50, loss: 0.04014743119478226
step: 60, loss: 0.02929837442934513
step: 70, loss: 0.061053868383169174
step: 80, loss: 0.0959220677614212
step: 90, loss: 0.12914304435253143
step: 100, loss: 0.0005582838202826679
step: 110, loss: 0.006017576903104782
step: 120, loss: 0.06200774013996124
step: 130, loss: 0.05939043313264847
step: 140, loss: 0.05864768475294113
step: 150, loss: 0.014897453598678112
step: 160, loss: 0.020075811073184013
step: 170, loss: 0.08062156289815903
step: 180, loss: 0.013827958144247532
step: 190, loss: 0.02651360258460045
step: 200, loss: 0.05802937224507332
step: 210, loss: 0.04106337949633598
step: 220, loss: 0.03702673688530922
step: 230, loss: 0.01739371009171009
step: 240, loss: 0.028041627258062363
step: 250, loss: 0.008669419214129448
step: 260, loss: 0.03344403952360153
step: 270, loss: 0.020155806094408035
step: 280, loss: 0.09415584057569504
step: 290, loss: 0.13440518081188202
step: 300, loss: 0.015435478650033474
step: 310, loss: 0.03543781116604805
step: 320, loss: 0.1523957997560501
step: 330, loss: 0.04281968995928764
step: 340, loss: 0.014078466221690178
step: 350, loss: 0.19009938836097717
step: 360, loss: 0.016160013154149055
step: 370, loss: 0.02789728157222271
step: 380, loss: 0.07296736538410187
step: 390, loss: 0.0670880451798439
step: 400, loss: 0.07452171295881271
step: 410, loss: 0.08828937262296677
step: 420, loss: 0.06171422451734543
step: 430, loss: 0.005520581267774105
step: 440, loss: 0.011162460781633854
step: 450, loss: 0.0037191505543887615
step: 460, loss: 0.04453752934932709
epoch 4: dev_f1=0.9943757030371203, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.016606517136096954
step: 10, loss: 0.06505783647298813
step: 20, loss: 0.02163035236299038
step: 30, loss: 0.031748492270708084
step: 40, loss: 0.07571079581975937
step: 50, loss: 0.05214540287852287
step: 60, loss: 0.0042246556840837
step: 70, loss: 0.0725216343998909
step: 80, loss: 0.010701825842261314
step: 90, loss: 0.014957747422158718
step: 100, loss: 0.008003626950085163
step: 110, loss: 0.024582020938396454
step: 120, loss: 0.012475280091166496
step: 130, loss: 0.08104581385850906
step: 140, loss: 0.0654660314321518
step: 150, loss: 0.030827701091766357
step: 160, loss: 0.07893181592226028
step: 170, loss: 0.004425681196153164
step: 180, loss: 0.052845969796180725
step: 190, loss: 0.087986521422863
step: 200, loss: 0.006449417676776648
step: 210, loss: 0.0941113531589508
step: 220, loss: 0.0028663305565714836
step: 230, loss: 0.018613575026392937
step: 240, loss: 0.0048679206520318985
step: 250, loss: 0.012173178605735302
step: 260, loss: 0.00015306314162444323
step: 270, loss: 0.12861782312393188
step: 280, loss: 0.057448603212833405
step: 290, loss: 0.011199106462299824
step: 300, loss: 0.03088700771331787
step: 310, loss: 0.021141355857253075
step: 320, loss: 0.15192443132400513
step: 330, loss: 0.005138276144862175
step: 340, loss: 0.06472023576498032
step: 350, loss: 0.022509681060910225
step: 360, loss: 0.04858950525522232
step: 370, loss: 0.012207992374897003
step: 380, loss: 0.03848576918244362
step: 390, loss: 0.07073875516653061
step: 400, loss: 0.06521566212177277
step: 410, loss: 0.036106839776039124
step: 420, loss: 0.015807026997208595
step: 430, loss: 0.023631710559129715
step: 440, loss: 0.10417905449867249
step: 450, loss: 0.07089105993509293
step: 460, loss: 0.07030300796031952
epoch 5: dev_f1=0.9898762654668166, f1=0.9797752808988766, best_f1=0.9854423292273236
step: 0, loss: 0.031072955578565598
step: 10, loss: 0.007928307168185711
step: 20, loss: 0.0050135282799601555
step: 30, loss: 0.021450236439704895
step: 40, loss: 0.005545358639210463
step: 50, loss: 0.10758863389492035
step: 60, loss: 0.0357615165412426
step: 70, loss: 0.04847089946269989
step: 80, loss: 0.12205741554498672
step: 90, loss: 0.06276840716600418
step: 100, loss: 0.03257550671696663
step: 110, loss: 0.0041052051819860935
step: 120, loss: 0.014172122813761234
step: 130, loss: 0.05131123587489128
step: 140, loss: 0.025587130337953568
step: 150, loss: 0.029525574296712875
step: 160, loss: 0.17312036454677582
step: 170, loss: 0.0077143036760389805
step: 180, loss: 0.027027754113078117
step: 190, loss: 0.14157621562480927
step: 200, loss: 0.018163196742534637
step: 210, loss: 0.02289130911231041
step: 220, loss: 0.05756636708974838
step: 230, loss: 0.04033772647380829
step: 240, loss: 0.005786916706711054
step: 250, loss: 0.058915410190820694
step: 260, loss: 0.006565156392753124
step: 270, loss: 0.11748509109020233
step: 280, loss: 0.004142765421420336
step: 290, loss: 0.06768439710140228
step: 300, loss: 0.011338808573782444
step: 310, loss: 0.03829964995384216
step: 320, loss: 0.014969659969210625
step: 330, loss: 0.04436745494604111
step: 340, loss: 0.0715646967291832
step: 350, loss: 0.01608022302389145
step: 360, loss: 0.08265126496553421
step: 370, loss: 0.011653885245323181
step: 380, loss: 0.0700254812836647
step: 390, loss: 0.05917072668671608
step: 400, loss: 0.024743473157286644
step: 410, loss: 0.020342249423265457
step: 420, loss: 0.07031433284282684
step: 430, loss: 0.03152871131896973
step: 440, loss: 0.03802553564310074
step: 450, loss: 0.016041863709688187
step: 460, loss: 0.012310083024203777
epoch 6: dev_f1=0.9910112359550561, f1=0.9798206278026906, best_f1=0.9854423292273236
step: 0, loss: 0.048852622509002686
step: 10, loss: 0.13430866599082947
step: 20, loss: 0.012750942260026932
step: 30, loss: 0.04019593447446823
step: 40, loss: 0.0040695094503462315
step: 50, loss: 0.007875065319240093
step: 60, loss: 0.0145037230104208
step: 70, loss: 0.0114523284137249
step: 80, loss: 0.08437813818454742
step: 90, loss: 0.01090236660093069
step: 100, loss: 0.008840220980346203
step: 110, loss: 0.010142470709979534
step: 120, loss: 0.03438340872526169
step: 130, loss: 0.12095136195421219
step: 140, loss: 0.03999762609601021
step: 150, loss: 0.07621099799871445
step: 160, loss: 0.056173745542764664
step: 170, loss: 0.02650696411728859
step: 180, loss: 0.12803803384304047
step: 190, loss: 0.034592632204294205
step: 200, loss: 0.05125702545046806
step: 210, loss: 0.003142454195767641
step: 220, loss: 0.07547534257173538
step: 230, loss: 0.046869389712810516
step: 240, loss: 0.06362253427505493
step: 250, loss: 0.10960832983255386
step: 260, loss: 0.3358530104160309
step: 270, loss: 0.03415011987090111
step: 280, loss: 0.11723018437623978
step: 290, loss: 0.0035223367158323526
step: 300, loss: 0.05863885581493378
step: 310, loss: 0.040143366903066635
step: 320, loss: 0.021660709753632545
step: 330, loss: 0.0018239227356389165
step: 340, loss: 0.00031097434111870825
step: 350, loss: 0.001756463199853897
step: 360, loss: 0.0027527003549039364
step: 370, loss: 0.06410035490989685
step: 380, loss: 0.0019267668249085546
step: 390, loss: 0.01858605444431305
step: 400, loss: 0.11167848855257034
step: 410, loss: 0.0591144822537899
step: 420, loss: 0.00278932461515069
step: 430, loss: 0.007954240776598454
step: 440, loss: 0.04128337651491165
step: 450, loss: 0.07189164310693741
step: 460, loss: 0.02378861792385578
epoch 7: dev_f1=0.9954954954954955, f1=0.9865470852017937, best_f1=0.9865470852017937
step: 0, loss: 0.008871341124176979
step: 10, loss: 0.010882660746574402
step: 20, loss: 0.04474399983882904
step: 30, loss: 0.04581654071807861
step: 40, loss: 0.10581771284341812
step: 50, loss: 0.0020588275510817766
step: 60, loss: 0.00017990935884881765
step: 70, loss: 0.016854597255587578
step: 80, loss: 0.010806942358613014
step: 90, loss: 0.028846487402915955
step: 100, loss: 0.014159169048070908
step: 110, loss: 0.033606112003326416
step: 120, loss: 0.07213059812784195
step: 130, loss: 0.0856831893324852
step: 140, loss: 0.006086340174078941
step: 150, loss: 0.03505835309624672
step: 160, loss: 0.11541515588760376
step: 170, loss: 0.023196212947368622
step: 180, loss: 0.013228771276772022
step: 190, loss: 0.08651126176118851
step: 200, loss: 0.05235469341278076
step: 210, loss: 0.049104463309049606
step: 220, loss: 0.03195939213037491
step: 230, loss: 0.03033004142343998
step: 240, loss: 0.0024770975578576326
step: 250, loss: 0.04751470685005188
step: 260, loss: 0.12334688007831573
step: 270, loss: 0.023724287748336792
step: 280, loss: 0.022997617721557617
step: 290, loss: 0.0021410323679447174
step: 300, loss: 0.06997872143983841
step: 310, loss: 0.04058186709880829
step: 320, loss: 0.014952598139643669
step: 330, loss: 0.1499846875667572
step: 340, loss: 0.007204368244856596
step: 350, loss: 0.008865748532116413
step: 360, loss: 0.03421742469072342
step: 370, loss: 0.02278745360672474
step: 380, loss: 0.04685467109084129
step: 390, loss: 0.012641943991184235
step: 400, loss: 0.009267730638384819
step: 410, loss: 0.022409582510590553
step: 420, loss: 0.08695903420448303
step: 430, loss: 0.001381782698445022
step: 440, loss: 0.05073089525103569
step: 450, loss: 0.0014311919221654534
step: 460, loss: 0.025449182838201523
epoch 8: dev_f1=0.9921259842519685, f1=0.9820627802690582, best_f1=0.9865470852017937
step: 0, loss: 0.00032733893021941185
step: 10, loss: 0.0025570308789610863
step: 20, loss: 0.05284545198082924
step: 30, loss: 0.03678705915808678
step: 40, loss: 0.04424525424838066
step: 50, loss: 0.033371683210134506
step: 60, loss: 0.08578594774007797
step: 70, loss: 0.04136872664093971
step: 80, loss: 0.01915600150823593
step: 90, loss: 0.039111725986003876
step: 100, loss: 0.07245924323797226
step: 110, loss: 0.005664665251970291
step: 120, loss: 0.011328576132655144
step: 130, loss: 0.0352378711104393
step: 140, loss: 0.01556829921901226
step: 150, loss: 0.02397748827934265
step: 160, loss: 5.118202534504235e-05
step: 170, loss: 0.02182758040726185
step: 180, loss: 0.1588630974292755
step: 190, loss: 0.03505156189203262
step: 200, loss: 0.053722914308309555
step: 210, loss: 0.03727184608578682
step: 220, loss: 0.0009141032351180911
step: 230, loss: 0.058139923959970474
step: 240, loss: 0.08896907418966293
step: 250, loss: 0.015364699997007847
step: 260, loss: 0.0022668729070574045
step: 270, loss: 0.03273560851812363
step: 280, loss: 0.09086630493402481
step: 290, loss: 0.05243803560733795
step: 300, loss: 0.06143497675657272
step: 310, loss: 0.11155858635902405
step: 320, loss: 4.245971649652347e-05
step: 330, loss: 0.07025141268968582
step: 340, loss: 0.022102385759353638
step: 350, loss: 0.011622965335845947
step: 360, loss: 6.236700573936105e-05
step: 370, loss: 0.2252195179462433
step: 380, loss: 0.13317692279815674
step: 390, loss: 4.497740519582294e-05
step: 400, loss: 0.033830948173999786
step: 410, loss: 0.08440512418746948
step: 420, loss: 0.007429541554301977
step: 430, loss: 0.11316736787557602
step: 440, loss: 0.05708809942007065
step: 450, loss: 0.039624426513910294
step: 460, loss: 0.03104090504348278
epoch 9: dev_f1=0.9943883277216611, f1=0.9832402234636871, best_f1=0.9865470852017937
step: 0, loss: 0.00503403227776289
step: 10, loss: 6.407335604308173e-05
step: 20, loss: 0.0696130096912384
step: 30, loss: 0.036401573568582535
step: 40, loss: 0.023233041167259216
step: 50, loss: 0.0008821214432828128
step: 60, loss: 0.08177440613508224
step: 70, loss: 0.07505727559328079
step: 80, loss: 0.05261840671300888
step: 90, loss: 0.051708467304706573
step: 100, loss: 0.023328395560383797
step: 110, loss: 0.0005307065439410508
step: 120, loss: 0.0009337785886600614
step: 130, loss: 0.03574139624834061
step: 140, loss: 0.020364534109830856
step: 150, loss: 0.06590762734413147
step: 160, loss: 0.0023894186597317457
step: 170, loss: 0.018234556540846825
step: 180, loss: 0.004319568630307913
step: 190, loss: 0.03947458788752556
step: 200, loss: 0.030786780640482903
step: 210, loss: 0.019014567136764526
step: 220, loss: 0.021931301802396774
step: 230, loss: 0.00311454338952899
step: 240, loss: 0.010050483047962189
step: 250, loss: 0.13674962520599365
step: 260, loss: 0.03147254139184952
step: 270, loss: 0.07657154649496078
step: 280, loss: 0.08643443882465363
step: 290, loss: 0.0016002978663891554
step: 300, loss: 9.046021295944229e-05
step: 310, loss: 0.01945624127984047
step: 320, loss: 0.017777077853679657
step: 330, loss: 0.06452887505292892
step: 340, loss: 0.012473618611693382
step: 350, loss: 0.02068456821143627
step: 360, loss: 0.07409727573394775
step: 370, loss: 0.019834717735648155
step: 380, loss: 0.05017080530524254
step: 390, loss: 0.030364597216248512
step: 400, loss: 0.020517446100711823
step: 410, loss: 0.05828164890408516
step: 420, loss: 0.010578363202512264
step: 430, loss: 0.08063656091690063
step: 440, loss: 0.046785857528448105
step: 450, loss: 0.03421124815940857
step: 460, loss: 0.014562695287168026
epoch 10: dev_f1=0.9887640449438202, f1=0.9808342728297633, best_f1=0.9865470852017937
step: 0, loss: 0.004388299770653248
step: 10, loss: 0.01786644384264946
step: 20, loss: 0.04774993285536766
step: 30, loss: 0.07539557665586472
step: 40, loss: 0.09654474258422852
step: 50, loss: 0.0243319571018219
step: 60, loss: 0.0013417761074379086
step: 70, loss: 0.013636547140777111
step: 80, loss: 0.042758919298648834
step: 90, loss: 0.041490714997053146
step: 100, loss: 0.07392983138561249
step: 110, loss: 0.0009389071492478251
step: 120, loss: 0.1134832501411438
step: 130, loss: 0.03043588250875473
step: 140, loss: 0.013554044999182224
step: 150, loss: 0.07653859257698059
step: 160, loss: 0.011686581186950207
step: 170, loss: 0.014364898204803467
step: 180, loss: 8.661408355692402e-05
step: 190, loss: 0.010158604942262173
step: 200, loss: 0.01357107050716877
step: 210, loss: 0.019607387483119965
step: 220, loss: 0.03527262806892395
step: 230, loss: 0.06097938492894173
step: 240, loss: 0.00012998474994674325
step: 250, loss: 0.05727069079875946
step: 260, loss: 0.03651168942451477
step: 270, loss: 0.024787528440356255
step: 280, loss: 0.04434467479586601
step: 290, loss: 0.0228959321975708
step: 300, loss: 0.017928970977663994
step: 310, loss: 0.008457313291728497
step: 320, loss: 0.017887048423290253
step: 330, loss: 0.012524357065558434
step: 340, loss: 5.0992155593121424e-05
step: 350, loss: 0.04547036439180374
step: 360, loss: 0.016907211393117905
step: 370, loss: 0.05820164456963539
step: 380, loss: 0.12780670821666718
step: 390, loss: 0.0008682911284267902
step: 400, loss: 0.0038338967133313417
step: 410, loss: 0.0033844723366200924
step: 420, loss: 0.075199194252491
step: 430, loss: 0.061719831079244614
step: 440, loss: 0.043531544506549835
step: 450, loss: 0.029523318633437157
step: 460, loss: 0.00014310071128420532
epoch 11: dev_f1=0.9932279909706545, f1=0.9831271091113611, best_f1=0.9865470852017937
step: 0, loss: 0.057970527559518814
step: 10, loss: 0.021466871723532677
step: 20, loss: 0.038586121052503586
step: 30, loss: 0.0032992928754538298
step: 40, loss: 0.019025055691599846
step: 50, loss: 0.024148372933268547
step: 60, loss: 0.04131210595369339
step: 70, loss: 0.03617158159613609
step: 80, loss: 0.0006031512748450041
step: 90, loss: 0.0015777169028297067
step: 100, loss: 0.003728073090314865
step: 110, loss: 0.00011235668353037909
step: 120, loss: 0.00038308952935039997
step: 130, loss: 0.03448234125971794
step: 140, loss: 0.043886952102184296
step: 150, loss: 0.10223988443613052
step: 160, loss: 0.017171427607536316
step: 170, loss: 0.032131128013134
step: 180, loss: 0.01667611300945282
step: 190, loss: 0.18618585169315338
step: 200, loss: 0.011335051618516445
step: 210, loss: 0.040084466338157654
step: 220, loss: 0.01856900379061699
step: 230, loss: 0.026687974110245705
step: 240, loss: 4.580606400850229e-05
step: 250, loss: 0.05178322643041611
step: 260, loss: 0.0006135457078926265
step: 270, loss: 0.020569559186697006
step: 280, loss: 0.0077821193262934685
step: 290, loss: 0.027916360646486282
step: 300, loss: 0.03144500404596329
step: 310, loss: 0.03643300011754036
step: 320, loss: 0.028281057253479958
step: 330, loss: 0.001715609454549849
step: 340, loss: 0.05159803479909897
step: 350, loss: 0.016041046008467674
step: 360, loss: 0.10322151333093643
step: 370, loss: 0.06329654157161713
step: 380, loss: 0.02860904671251774
step: 390, loss: 0.02441534586250782
step: 400, loss: 0.014232096262276173
step: 410, loss: 2.4616039809188806e-05
step: 420, loss: 0.024916544556617737
step: 430, loss: 0.12010152637958527
step: 440, loss: 0.05256136506795883
step: 450, loss: 0.01989453099668026
step: 460, loss: 0.037334442138671875
epoch 12: dev_f1=0.992108229988726, f1=0.9852774631936579, best_f1=0.9865470852017937
step: 0, loss: 0.05055227875709534
step: 10, loss: 0.09627929329872131
step: 20, loss: 0.00996336992830038
step: 30, loss: 4.9668389692669734e-05
step: 40, loss: 7.461909262929112e-05
step: 50, loss: 0.03351140022277832
step: 60, loss: 0.001811986556276679
step: 70, loss: 0.05553775280714035
step: 80, loss: 0.03156561404466629
step: 90, loss: 0.023025594651699066
step: 100, loss: 0.05237642303109169
step: 110, loss: 0.0293270256370306
step: 120, loss: 0.016790667548775673
step: 130, loss: 0.03505568951368332
step: 140, loss: 0.00538987061008811
step: 150, loss: 7.903252844698727e-05
step: 160, loss: 0.04655635729432106
step: 170, loss: 0.022620240226387978
step: 180, loss: 0.0003016773553099483
step: 190, loss: 2.705965016502887e-05
step: 200, loss: 0.00046133625437505543
step: 210, loss: 0.017443379387259483
step: 220, loss: 0.019718647003173828
step: 230, loss: 0.04219958186149597
step: 240, loss: 0.05922612175345421
step: 250, loss: 0.031196873635053635
step: 260, loss: 0.037692319601774216
step: 270, loss: 0.0003960692847613245
step: 280, loss: 0.019585583359003067
step: 290, loss: 0.06448464840650558
step: 300, loss: 0.0571296364068985
step: 310, loss: 0.06998413056135178
step: 320, loss: 0.03238067403435707
step: 330, loss: 0.025076350197196007
step: 340, loss: 0.01645975559949875
step: 350, loss: 0.05890120193362236
step: 360, loss: 0.0005893997731618583
step: 370, loss: 0.025392398238182068
step: 380, loss: 0.02707151137292385
step: 390, loss: 0.03010324202477932
step: 400, loss: 0.07315994054079056
step: 410, loss: 9.012380905915052e-05
step: 420, loss: 0.018039675429463387
step: 430, loss: 0.22380049526691437
step: 440, loss: 0.048526134341955185
step: 450, loss: 0.00018762584659270942
step: 460, loss: 0.011109896004199982
epoch 13: dev_f1=0.9943883277216611, f1=0.984304932735426, best_f1=0.9865470852017937
step: 0, loss: 0.0018783877603709698
step: 10, loss: 0.06894040107727051
step: 20, loss: 0.04272269457578659
step: 30, loss: 0.012171002104878426
step: 40, loss: 0.10024957358837128
step: 50, loss: 0.04030526801943779
step: 60, loss: 0.022868920117616653
step: 70, loss: 0.000552854617126286
step: 80, loss: 0.006586055736988783
step: 90, loss: 0.00019864554633386433
step: 100, loss: 0.028191417455673218
step: 110, loss: 0.044007834047079086
step: 120, loss: 0.060201216489076614
step: 130, loss: 0.03006952442228794
step: 140, loss: 0.017435450106859207
step: 150, loss: 0.007226248737424612
step: 160, loss: 0.020847998559474945
step: 170, loss: 0.0461687408387661
step: 180, loss: 0.025721818208694458
step: 190, loss: 0.11519890278577805
step: 200, loss: 0.024758677929639816
step: 210, loss: 7.749945507384837e-05
step: 220, loss: 0.022892838343977928
step: 230, loss: 0.057603076100349426
step: 240, loss: 0.023809989914298058
step: 250, loss: 0.04066706821322441
step: 260, loss: 0.04204674810171127
step: 270, loss: 0.019838154315948486
step: 280, loss: 0.03412861004471779
step: 290, loss: 1.5817417079233564e-05
step: 300, loss: 0.00028226463473401964
step: 310, loss: 0.027882961556315422
step: 320, loss: 0.0033556590788066387
step: 330, loss: 0.00010363532783230767
step: 340, loss: 0.05584482103586197
step: 350, loss: 0.023112501949071884
step: 360, loss: 0.027389077469706535
step: 370, loss: 4.85727287014015e-05
step: 380, loss: 0.02526504546403885
step: 390, loss: 0.0014755330048501492
step: 400, loss: 0.00024887718609534204
step: 410, loss: 0.028305426239967346
step: 420, loss: 0.0012491153320297599
step: 430, loss: 9.489057993050665e-05
step: 440, loss: 0.029008150100708008
step: 450, loss: 0.016633931547403336
step: 460, loss: 0.09046823531389236
epoch 14: dev_f1=0.9943883277216611, f1=0.984304932735426, best_f1=0.9865470852017937
step: 0, loss: 0.0006748406449332833
step: 10, loss: 0.0004055496829096228
step: 20, loss: 0.023551005870103836
step: 30, loss: 0.02100546285510063
step: 40, loss: 5.6235105148516595e-05
step: 50, loss: 0.0003268824948463589
step: 60, loss: 0.062071673572063446
step: 70, loss: 0.05427463725209236
step: 80, loss: 0.021644065156579018
step: 90, loss: 0.01611373759806156
step: 100, loss: 0.012331749312579632
step: 110, loss: 0.03333040326833725
step: 120, loss: 0.02607887051999569
step: 130, loss: 0.18940715491771698
step: 140, loss: 0.02459079585969448
step: 150, loss: 0.04534073919057846
step: 160, loss: 0.0248859953135252
step: 170, loss: 0.04582952708005905
step: 180, loss: 0.12072281539440155
step: 190, loss: 0.02029697224497795
step: 200, loss: 0.016350245103240013
step: 210, loss: 0.0001482506631873548
step: 220, loss: 0.052970822900533676
step: 230, loss: 0.00013585438136942685
step: 240, loss: 0.015429265797138214
step: 250, loss: 0.004518912173807621
step: 260, loss: 0.0617612786591053
step: 270, loss: 0.02118046209216118
step: 280, loss: 0.051055703312158585
step: 290, loss: 0.05620693787932396
step: 300, loss: 0.016461476683616638
step: 310, loss: 0.003142602276057005
step: 320, loss: 0.0002837370557244867
step: 330, loss: 9.920537559082732e-05
step: 340, loss: 6.313683115877211e-05
step: 350, loss: 0.0008829230791889131
step: 360, loss: 9.810780466068536e-05
step: 370, loss: 0.022995488718152046
step: 380, loss: 0.01375123206526041
step: 390, loss: 0.01577843725681305
step: 400, loss: 0.04473518207669258
step: 410, loss: 5.148827767698094e-05
step: 420, loss: 6.822203431511298e-05
step: 430, loss: 0.05057437717914581
step: 440, loss: 0.009090911597013474
step: 450, loss: 4.2470604967093095e-05
step: 460, loss: 0.014170026406645775
epoch 15: dev_f1=0.9932735426008968, f1=0.9854096520763187, best_f1=0.9865470852017937
step: 0, loss: 0.019668899476528168
step: 10, loss: 0.02625480480492115
step: 20, loss: 0.036437731236219406
step: 30, loss: 0.00036636347067542374
step: 40, loss: 0.016196833923459053
step: 50, loss: 0.029109029099345207
step: 60, loss: 0.09456908702850342
step: 70, loss: 0.04599203169345856
step: 80, loss: 0.0003820136480499059
step: 90, loss: 0.027366112917661667
step: 100, loss: 0.019100971519947052
step: 110, loss: 0.02582293376326561
step: 120, loss: 2.3728711312287487e-05
step: 130, loss: 0.014660830609500408
step: 140, loss: 0.0016191797330975533
step: 150, loss: 0.005240987986326218
step: 160, loss: 0.019092964008450508
step: 170, loss: 0.012452345341444016
step: 180, loss: 0.01654544100165367
step: 190, loss: 0.024236606433987617
step: 200, loss: 0.02326129749417305
step: 210, loss: 0.044019121676683426
step: 220, loss: 0.0163833349943161
step: 230, loss: 0.026656651869416237
step: 240, loss: 0.11761200428009033
step: 250, loss: 0.02814771793782711
step: 260, loss: 0.014005894772708416
step: 270, loss: 0.057081568986177444
step: 280, loss: 0.022849153727293015
step: 290, loss: 7.036403985694051e-05
step: 300, loss: 8.992374205263332e-05
step: 310, loss: 0.002216518856585026
step: 320, loss: 9.914566180668771e-05
step: 330, loss: 0.016757499426603317
step: 340, loss: 0.11282747983932495
step: 350, loss: 9.877781849354506e-05
step: 360, loss: 1.3522689187084325e-05
step: 370, loss: 4.997728319722228e-05
step: 380, loss: 0.019868526607751846
step: 390, loss: 0.00013671076158061624
step: 400, loss: 0.028250811621546745
step: 410, loss: 0.09544367343187332
step: 420, loss: 0.021881232038140297
step: 430, loss: 0.03568648546934128
step: 440, loss: 0.04918231815099716
step: 450, loss: 0.019424008205533028
step: 460, loss: 0.04992000013589859
epoch 16: dev_f1=0.9932735426008968, f1=0.984304932735426, best_f1=0.9865470852017937
step: 0, loss: 0.04513925686478615
step: 10, loss: 0.044344112277030945
step: 20, loss: 0.00010845823999261484
step: 30, loss: 0.01679835468530655
step: 40, loss: 0.024434395134449005
step: 50, loss: 0.023591918870806694
step: 60, loss: 4.444654769031331e-05
step: 70, loss: 0.00041405894444324076
step: 80, loss: 0.03803067281842232
step: 90, loss: 0.021680714562535286
step: 100, loss: 0.028215520083904266
step: 110, loss: 0.07993845641613007
step: 120, loss: 0.020078565925359726
step: 130, loss: 0.021660519763827324
step: 140, loss: 0.00011293972784187645
step: 150, loss: 2.5140428988379426e-05
step: 160, loss: 0.03612072765827179
step: 170, loss: 0.055239252746105194
step: 180, loss: 0.00024250750720966607
step: 190, loss: 0.07204829156398773
step: 200, loss: 0.022392120212316513
step: 210, loss: 0.028112253174185753
step: 220, loss: 3.4644406696315855e-05
step: 230, loss: 2.0152783690718934e-05
step: 240, loss: 0.06128190830349922
step: 250, loss: 0.020495105534791946
step: 260, loss: 0.07591557502746582
step: 270, loss: 0.03183853626251221
step: 280, loss: 3.712215766427107e-05
step: 290, loss: 0.048263125121593475
step: 300, loss: 0.013674138113856316
step: 310, loss: 0.000823250797111541
step: 320, loss: 0.02573452517390251
step: 330, loss: 0.03590924292802811
step: 340, loss: 0.00027618365129455924
step: 350, loss: 0.0009128375095315278
step: 360, loss: 0.04461314156651497
step: 370, loss: 2.883401066355873e-05
step: 380, loss: 3.0081389922997914e-05
step: 390, loss: 0.06686527281999588
step: 400, loss: 0.048437826335430145
step: 410, loss: 2.773714004433714e-05
step: 420, loss: 3.504340202198364e-05
step: 430, loss: 0.0032488724682480097
step: 440, loss: 0.047585681080818176
step: 450, loss: 0.03186783939599991
step: 460, loss: 0.012138575315475464
epoch 17: dev_f1=0.9921436588103255, f1=0.984304932735426, best_f1=0.9865470852017937
step: 0, loss: 0.04792625829577446
step: 10, loss: 8.266985241789371e-05
step: 20, loss: 0.013144437223672867
step: 30, loss: 0.02039722539484501
step: 40, loss: 0.0400804728269577
step: 50, loss: 0.025851283222436905
step: 60, loss: 0.01696489006280899
step: 70, loss: 0.061251308768987656
step: 80, loss: 0.04479209706187248
step: 90, loss: 0.00019267626339569688
step: 100, loss: 0.04685952141880989
step: 110, loss: 0.048534095287323
step: 120, loss: 0.018116839230060577
step: 130, loss: 0.0016777657438069582
step: 140, loss: 0.028249140828847885
step: 150, loss: 0.07971815019845963
step: 160, loss: 0.0462239533662796
step: 170, loss: 0.046352777630090714
step: 180, loss: 0.01629902422428131
step: 190, loss: 0.00033803601399995387
step: 200, loss: 0.05228899046778679
step: 210, loss: 0.02555505372583866
step: 220, loss: 0.030525656417012215
step: 230, loss: 0.028537770733237267
step: 240, loss: 0.0005426757270470262
step: 250, loss: 0.019151341170072556
step: 260, loss: 0.04886944219470024
step: 270, loss: 0.036899175494909286
step: 280, loss: 0.014194723218679428
step: 290, loss: 0.05687515810132027
step: 300, loss: 0.018767332658171654
step: 310, loss: 3.6401983379619196e-05
step: 320, loss: 0.01634884811937809
step: 330, loss: 0.03746318444609642
step: 340, loss: 4.67406862298958e-05
step: 350, loss: 0.025768281891942024
step: 360, loss: 0.00010768372885650024
step: 370, loss: 7.431073026964441e-05
step: 380, loss: 0.042181506752967834
step: 390, loss: 0.0007217209204100072
step: 400, loss: 0.026813313364982605
step: 410, loss: 1.4081407243793365e-05
step: 420, loss: 0.04872201755642891
step: 430, loss: 0.057298965752124786
step: 440, loss: 0.0723777487874031
step: 450, loss: 0.06136193498969078
step: 460, loss: 0.014536223374307156
epoch 18: dev_f1=0.9921436588103255, f1=0.984304932735426, best_f1=0.9865470852017937
step: 0, loss: 0.00424692127853632
step: 10, loss: 0.0215911827981472
step: 20, loss: 0.018640128895640373
step: 30, loss: 3.4752047213260084e-05
step: 40, loss: 0.012886503711342812
step: 50, loss: 0.00028317776741459966
step: 60, loss: 0.018966108560562134
step: 70, loss: 0.02520872838795185
step: 80, loss: 0.018816346302628517
step: 90, loss: 0.041979096829891205
step: 100, loss: 3.139325781376101e-05
step: 110, loss: 0.03507441654801369
step: 120, loss: 0.02195616066455841
step: 130, loss: 0.033099375665187836
step: 140, loss: 0.05542127415537834
step: 150, loss: 0.00011683152115438133
step: 160, loss: 0.025404933840036392
step: 170, loss: 4.4998363591730595e-05
step: 180, loss: 0.03169690817594528
step: 190, loss: 0.02390284091234207
step: 200, loss: 3.149275289615616e-05
step: 210, loss: 0.025947997346520424
step: 220, loss: 0.027778035029768944
step: 230, loss: 0.020364411175251007
step: 240, loss: 0.016224713996052742
step: 250, loss: 0.02032496966421604
step: 260, loss: 0.011833200231194496
step: 270, loss: 0.05783543363213539
step: 280, loss: 0.03596042841672897
step: 290, loss: 4.3783988076029345e-05
step: 300, loss: 0.00021084278705529869
step: 310, loss: 1.7564083464094438e-05
step: 320, loss: 0.02330567128956318
step: 330, loss: 0.019831249490380287
step: 340, loss: 0.0025599526707082987
step: 350, loss: 0.012971161864697933
step: 360, loss: 0.006771776359528303
step: 370, loss: 7.428099343087524e-05
step: 380, loss: 0.014265032485127449
step: 390, loss: 2.1345029381336644e-05
step: 400, loss: 0.034712474793195724
step: 410, loss: 0.05010753124952316
step: 420, loss: 0.0003143093781545758
step: 430, loss: 0.00039392043254338205
step: 440, loss: 6.030346412444487e-05
step: 450, loss: 0.022434929385781288
step: 460, loss: 5.9143148973817006e-05
epoch 19: dev_f1=0.9932584269662922, f1=0.9854096520763187, best_f1=0.9865470852017937
step: 0, loss: 0.012493503279983997
step: 10, loss: 0.017544224858283997
step: 20, loss: 0.00016379973385483027
step: 30, loss: 0.02854040078818798
step: 40, loss: 0.00013211106124799699
step: 50, loss: 3.553377973730676e-05
step: 60, loss: 0.03780264034867287
step: 70, loss: 6.930615927558392e-05
step: 80, loss: 0.02793387696146965
step: 90, loss: 0.04877729341387749
step: 100, loss: 0.0012087997747585177
step: 110, loss: 0.02540513500571251
step: 120, loss: 0.024983340874314308
step: 130, loss: 0.015393860638141632
step: 140, loss: 0.028962312266230583
step: 150, loss: 0.03007626160979271
step: 160, loss: 0.06201624870300293
step: 170, loss: 8.933398930821568e-05
step: 180, loss: 7.337242277571931e-05
step: 190, loss: 0.016717810183763504
step: 200, loss: 0.032285384833812714
step: 210, loss: 0.03964700549840927
step: 220, loss: 0.05808890238404274
step: 230, loss: 0.04387185722589493
step: 240, loss: 7.688119512749836e-05
step: 250, loss: 0.0035847255494445562
step: 260, loss: 0.027030665427446365
step: 270, loss: 0.0459672249853611
step: 280, loss: 1.1410442311898805e-05
step: 290, loss: 0.037138454616069794
step: 300, loss: 1.4446229215536732e-05
step: 310, loss: 3.754199860850349e-05
step: 320, loss: 7.587608706671745e-05
step: 330, loss: 8.62282031448558e-05
step: 340, loss: 0.020139465108513832
step: 350, loss: 0.021699054166674614
step: 360, loss: 0.08186474442481995
step: 370, loss: 0.0414431206882
step: 380, loss: 0.012575829401612282
step: 390, loss: 6.02756226726342e-05
step: 400, loss: 0.01541582029312849
step: 410, loss: 0.03044157661497593
step: 420, loss: 0.0016315517714247108
step: 430, loss: 0.014327919110655785
step: 440, loss: 4.519505091593601e-05
step: 450, loss: 0.02455577626824379
step: 460, loss: 0.01826799474656582
epoch 20: dev_f1=0.9932432432432432, f1=0.9854096520763187, best_f1=0.9865470852017937
