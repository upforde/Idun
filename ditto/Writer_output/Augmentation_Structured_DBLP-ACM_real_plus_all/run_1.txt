cuda
Device: cuda
step: 0, loss: 0.6317601799964905
step: 10, loss: 0.4717584252357483
step: 20, loss: 0.4833713173866272
step: 30, loss: 0.24971763789653778
step: 40, loss: 0.2151777446269989
step: 50, loss: 0.2540886104106903
step: 60, loss: 0.15230631828308105
step: 70, loss: 0.32017946243286133
step: 80, loss: 0.14743103086948395
step: 90, loss: 0.3364100456237793
step: 100, loss: 0.07778555154800415
step: 110, loss: 0.19337795674800873
step: 120, loss: 0.11650393903255463
step: 130, loss: 0.1307043880224228
step: 140, loss: 0.1468079835176468
step: 150, loss: 0.18689268827438354
step: 160, loss: 0.1118529811501503
step: 170, loss: 0.08196645975112915
step: 180, loss: 0.2761332094669342
step: 190, loss: 0.15696541965007782
step: 200, loss: 0.144607275724411
step: 210, loss: 0.23884278535842896
step: 220, loss: 0.1086193397641182
step: 230, loss: 0.14636853337287903
step: 240, loss: 0.039011094719171524
step: 250, loss: 0.09208700805902481
step: 260, loss: 0.14538352191448212
step: 270, loss: 0.023470090702176094
step: 280, loss: 0.026323538273572922
step: 290, loss: 0.0011311328271403909
step: 300, loss: 0.07573588192462921
step: 310, loss: 0.1059940978884697
step: 320, loss: 0.24992774426937103
step: 330, loss: 0.08286536484956741
step: 340, loss: 0.03360002860426903
step: 350, loss: 0.024375244975090027
step: 360, loss: 0.04153553023934364
step: 370, loss: 0.014826984144747257
step: 380, loss: 0.018497098237276077
step: 390, loss: 0.025170374661684036
step: 400, loss: 0.16026374697685242
step: 410, loss: 0.0707445815205574
step: 420, loss: 0.06976024806499481
step: 430, loss: 0.01145801693201065
step: 440, loss: 0.09485158324241638
step: 450, loss: 0.07069040089845657
step: 460, loss: 0.015484857372939587
epoch 1: dev_f1=0.9799107142857142, f1=0.9774774774774775, best_f1=0.9774774774774775
step: 0, loss: 0.07754839956760406
step: 10, loss: 0.011982913129031658
step: 20, loss: 0.008216599933803082
step: 30, loss: 0.0435851514339447
step: 40, loss: 0.019588680937886238
step: 50, loss: 0.04790098965167999
step: 60, loss: 0.08785835653543472
step: 70, loss: 0.13180530071258545
step: 80, loss: 0.026572182774543762
step: 90, loss: 0.034220848232507706
step: 100, loss: 0.08592908829450607
step: 110, loss: 0.008946266025304794
step: 120, loss: 0.07571347057819366
step: 130, loss: 0.02117401733994484
step: 140, loss: 0.2066463977098465
step: 150, loss: 0.027894005179405212
step: 160, loss: 0.052263468503952026
step: 170, loss: 0.014388687908649445
step: 180, loss: 0.057663995772600174
step: 190, loss: 0.06971165537834167
step: 200, loss: 0.008417587727308273
step: 210, loss: 0.10820817947387695
step: 220, loss: 0.08567935228347778
step: 230, loss: 0.08513472229242325
step: 240, loss: 0.19501720368862152
step: 250, loss: 0.024705074727535248
step: 260, loss: 0.087086983025074
step: 270, loss: 0.00976345781236887
step: 280, loss: 0.008395294658839703
step: 290, loss: 0.08269563317298889
step: 300, loss: 0.12074925750494003
step: 310, loss: 0.017126066610217094
step: 320, loss: 0.07304742187261581
step: 330, loss: 0.04008254036307335
step: 340, loss: 0.040385618805885315
step: 350, loss: 0.1407736837863922
step: 360, loss: 0.08407636731863022
step: 370, loss: 0.03149532899260521
step: 380, loss: 0.01867481879889965
step: 390, loss: 0.09950097650289536
step: 400, loss: 0.25712284445762634
step: 410, loss: 0.149727001786232
step: 420, loss: 0.01579027995467186
step: 430, loss: 0.059603720903396606
step: 440, loss: 0.0642925575375557
step: 450, loss: 0.031755730509757996
step: 460, loss: 0.00754899624735117
epoch 2: dev_f1=0.9887387387387387, f1=0.9808773903262092, best_f1=0.9808773903262092
step: 0, loss: 0.01397781353443861
step: 10, loss: 0.022416764870285988
step: 20, loss: 0.14776462316513062
step: 30, loss: 0.006320167798548937
step: 40, loss: 0.0037469302769750357
step: 50, loss: 0.017143843695521355
step: 60, loss: 0.025883818045258522
step: 70, loss: 0.05590780824422836
step: 80, loss: 0.012024639174342155
step: 90, loss: 0.03577291965484619
step: 100, loss: 0.16846616566181183
step: 110, loss: 0.06751329451799393
step: 120, loss: 0.07816100865602493
step: 130, loss: 0.012257229536771774
step: 140, loss: 0.03512479364871979
step: 150, loss: 0.18113982677459717
step: 160, loss: 0.04384005069732666
step: 170, loss: 0.06602414697408676
step: 180, loss: 0.1297890692949295
step: 190, loss: 0.04512198641896248
step: 200, loss: 0.049324315041303635
step: 210, loss: 0.028279973194003105
step: 220, loss: 0.0208878293633461
step: 230, loss: 0.012608116492629051
step: 240, loss: 0.12886668741703033
step: 250, loss: 0.027588533237576485
step: 260, loss: 0.010516868904232979
step: 270, loss: 0.012021767906844616
step: 280, loss: 0.1357172429561615
step: 290, loss: 0.11987525969743729
step: 300, loss: 0.08729849755764008
step: 310, loss: 0.07537626475095749
step: 320, loss: 0.007746366783976555
step: 330, loss: 0.055624719709157944
step: 340, loss: 0.1648474484682083
step: 350, loss: 0.05746876448392868
step: 360, loss: 0.08204346895217896
step: 370, loss: 0.019857630133628845
step: 380, loss: 0.0415811724960804
step: 390, loss: 0.012425793334841728
step: 400, loss: 0.19826482236385345
step: 410, loss: 0.013757769949734211
step: 420, loss: 0.04184005782008171
step: 430, loss: 0.08657418936491013
step: 440, loss: 0.0420619361102581
step: 450, loss: 0.014287794008851051
step: 460, loss: 0.13348956406116486
epoch 3: dev_f1=0.9921436588103255, f1=0.9810901001112348, best_f1=0.9810901001112348
step: 0, loss: 0.0045188129879534245
step: 10, loss: 0.01809532195329666
step: 20, loss: 0.1844361573457718
step: 30, loss: 0.09813231974840164
step: 40, loss: 0.004170685075223446
step: 50, loss: 0.010067803785204887
step: 60, loss: 0.05952393263578415
step: 70, loss: 0.020890967920422554
step: 80, loss: 0.010257204994559288
step: 90, loss: 0.0795922800898552
step: 100, loss: 0.07877444475889206
step: 110, loss: 0.01236385852098465
step: 120, loss: 0.11201922595500946
step: 130, loss: 0.07996485382318497
step: 140, loss: 0.13498933613300323
step: 150, loss: 0.06726394593715668
step: 160, loss: 0.06775354593992233
step: 170, loss: 0.05800158157944679
step: 180, loss: 0.0392439067363739
step: 190, loss: 0.004913974087685347
step: 200, loss: 0.10475384443998337
step: 210, loss: 0.09977895021438599
step: 220, loss: 0.06975547224283218
step: 230, loss: 0.11809521913528442
step: 240, loss: 0.024261970072984695
step: 250, loss: 0.007539353333413601
step: 260, loss: 0.01856202445924282
step: 270, loss: 0.008273162879049778
step: 280, loss: 0.09335815906524658
step: 290, loss: 0.038357168436050415
step: 300, loss: 0.10582579672336578
step: 310, loss: 0.04782372713088989
step: 320, loss: 0.02129504457116127
step: 330, loss: 0.07512515783309937
step: 340, loss: 0.005576927214860916
step: 350, loss: 0.008739856071770191
step: 360, loss: 0.02618560381233692
step: 370, loss: 0.07763130962848663
step: 380, loss: 0.06510446220636368
step: 390, loss: 0.03720003738999367
step: 400, loss: 0.09156869351863861
step: 410, loss: 0.3045421242713928
step: 420, loss: 0.16915586590766907
step: 430, loss: 0.07819847762584686
step: 440, loss: 0.0820656418800354
step: 450, loss: 0.02432352490723133
step: 460, loss: 0.04418278485536575
epoch 4: dev_f1=0.9921612541993281, f1=0.9833147942157954, best_f1=0.9833147942157954
step: 0, loss: 0.060722049325704575
step: 10, loss: 0.18481825292110443
step: 20, loss: 0.05634201318025589
step: 30, loss: 0.06558247655630112
step: 40, loss: 0.09241803735494614
step: 50, loss: 0.022610731422901154
step: 60, loss: 0.02003766968846321
step: 70, loss: 0.1830512285232544
step: 80, loss: 0.02878820337355137
step: 90, loss: 0.07746287435293198
step: 100, loss: 0.017235305160284042
step: 110, loss: 0.02111481875181198
step: 120, loss: 0.08333064615726471
step: 130, loss: 0.035694099962711334
step: 140, loss: 0.055678509175777435
step: 150, loss: 0.17479953169822693
step: 160, loss: 0.03355025500059128
step: 170, loss: 0.06774407625198364
step: 180, loss: 0.005456654820591211
step: 190, loss: 0.080715112388134
step: 200, loss: 0.011701496317982674
step: 210, loss: 0.06571102142333984
step: 220, loss: 0.006504714954644442
step: 230, loss: 0.02139122597873211
step: 240, loss: 0.013182367198169231
step: 250, loss: 0.03280896320939064
step: 260, loss: 0.02017921209335327
step: 270, loss: 0.06794602423906326
step: 280, loss: 0.08257994055747986
step: 290, loss: 0.013636681251227856
step: 300, loss: 0.12317629903554916
step: 310, loss: 0.01489103864878416
step: 320, loss: 0.07234112173318863
step: 330, loss: 0.07706329226493835
step: 340, loss: 0.08023161441087723
step: 350, loss: 0.17239302396774292
step: 360, loss: 0.0077552469447255135
step: 370, loss: 0.15224678814411163
step: 380, loss: 0.003116459585726261
step: 390, loss: 0.022743288427591324
step: 400, loss: 0.012341495603322983
step: 410, loss: 0.15541473031044006
step: 420, loss: 0.04940168559551239
step: 430, loss: 0.1089465320110321
step: 440, loss: 0.007955173961818218
step: 450, loss: 0.011322351172566414
step: 460, loss: 0.029421726241707802
epoch 5: dev_f1=0.9921259842519685, f1=0.9843400447427293, best_f1=0.9833147942157954
step: 0, loss: 0.0159014705568552
step: 10, loss: 0.0055443886667490005
step: 20, loss: 0.06521829217672348
step: 30, loss: 0.03020866960287094
step: 40, loss: 0.04901210218667984
step: 50, loss: 0.014730461873114109
step: 60, loss: 0.0038444395177066326
step: 70, loss: 0.09217002987861633
step: 80, loss: 0.0527229830622673
step: 90, loss: 0.04896708205342293
step: 100, loss: 0.019043274223804474
step: 110, loss: 0.031238196417689323
step: 120, loss: 0.06634011119604111
step: 130, loss: 0.016615180298686028
step: 140, loss: 0.003492032177746296
step: 150, loss: 0.09881824254989624
step: 160, loss: 0.050185829401016235
step: 170, loss: 0.009263730607926846
step: 180, loss: 0.04234599694609642
step: 190, loss: 0.01407923549413681
step: 200, loss: 0.017762355506420135
step: 210, loss: 0.0900479108095169
step: 220, loss: 0.010003400966525078
step: 230, loss: 0.01147824339568615
step: 240, loss: 0.02407599426805973
step: 250, loss: 0.0005943665164522827
step: 260, loss: 0.025096163153648376
step: 270, loss: 0.025433499366044998
step: 280, loss: 0.03965195640921593
step: 290, loss: 0.002157172653824091
step: 300, loss: 0.01567216031253338
step: 310, loss: 0.016263583675026894
step: 320, loss: 0.03508377447724342
step: 330, loss: 0.07044373452663422
step: 340, loss: 0.05794769898056984
step: 350, loss: 0.05096351355314255
step: 360, loss: 0.1579473614692688
step: 370, loss: 0.15605869889259338
step: 380, loss: 0.040731336921453476
step: 390, loss: 0.02822376787662506
step: 400, loss: 0.039470065385103226
step: 410, loss: 0.07024302333593369
step: 420, loss: 0.016853703185915947
step: 430, loss: 0.08807478100061417
step: 440, loss: 0.07995326817035675
step: 450, loss: 0.03938998281955719
step: 460, loss: 0.011611921712756157
epoch 6: dev_f1=0.9910112359550561, f1=0.9854096520763187, best_f1=0.9833147942157954
step: 0, loss: 0.024039888754487038
step: 10, loss: 0.06136466562747955
step: 20, loss: 0.01873694360256195
step: 30, loss: 0.12035266309976578
step: 40, loss: 0.02303309366106987
step: 50, loss: 0.030097721144557
step: 60, loss: 0.0002873141202144325
step: 70, loss: 0.05310293287038803
step: 80, loss: 0.2174261063337326
step: 90, loss: 0.028658999130129814
step: 100, loss: 0.02845168299973011
step: 110, loss: 0.009831332601606846
step: 120, loss: 0.01997206173837185
step: 130, loss: 0.016761768609285355
step: 140, loss: 0.10542397201061249
step: 150, loss: 0.3380492329597473
step: 160, loss: 0.08616192638874054
step: 170, loss: 0.006371203809976578
step: 180, loss: 0.18653646111488342
step: 190, loss: 0.057200804352760315
step: 200, loss: 0.031106257811188698
step: 210, loss: 0.17871896922588348
step: 220, loss: 0.03130628913640976
step: 230, loss: 0.012538405135273933
step: 240, loss: 0.08065744489431381
step: 250, loss: 0.07639198005199432
step: 260, loss: 0.012192785739898682
step: 270, loss: 0.09618821740150452
step: 280, loss: 0.05318823456764221
step: 290, loss: 0.08020707219839096
step: 300, loss: 0.15156403183937073
step: 310, loss: 0.018826600164175034
step: 320, loss: 0.10402907431125641
step: 330, loss: 0.006270247511565685
step: 340, loss: 0.0456969253718853
step: 350, loss: 0.06705242395401001
step: 360, loss: 0.005354053340852261
step: 370, loss: 0.032732006162405014
step: 380, loss: 0.12111277878284454
step: 390, loss: 0.020371899008750916
step: 400, loss: 0.058247167617082596
step: 410, loss: 0.009228182956576347
step: 420, loss: 0.08081480115652084
step: 430, loss: 0.0758863240480423
step: 440, loss: 0.03489458188414574
step: 450, loss: 0.0807085931301117
step: 460, loss: 0.1369892954826355
epoch 7: dev_f1=0.9875706214689265, f1=0.9796839729119639, best_f1=0.9833147942157954
step: 0, loss: 0.01882530190050602
step: 10, loss: 0.07210826128721237
step: 20, loss: 0.029747892171144485
step: 30, loss: 0.07859358191490173
step: 40, loss: 0.004583469592034817
step: 50, loss: 0.05376874655485153
step: 60, loss: 0.08837926387786865
step: 70, loss: 0.005118409637361765
step: 80, loss: 0.10112382471561432
step: 90, loss: 0.20867499709129333
step: 100, loss: 0.03413205221295357
step: 110, loss: 0.03080771118402481
step: 120, loss: 0.036933161318302155
step: 130, loss: 0.0711514949798584
step: 140, loss: 0.010849655605852604
step: 150, loss: 0.04307635501027107
step: 160, loss: 0.057226382195949554
step: 170, loss: 0.012667076662182808
step: 180, loss: 0.11746341735124588
step: 190, loss: 0.05244774743914604
step: 200, loss: 0.009951881133019924
step: 210, loss: 0.04539336636662483
step: 220, loss: 0.011608259752392769
step: 230, loss: 0.07549339532852173
step: 240, loss: 0.046827223151922226
step: 250, loss: 0.030975673347711563
step: 260, loss: 0.10738806426525116
step: 270, loss: 0.05081608146429062
step: 280, loss: 0.005258285440504551
step: 290, loss: 0.01880849152803421
step: 300, loss: 0.007032338064163923
step: 310, loss: 0.08632463961839676
step: 320, loss: 0.1029401645064354
step: 330, loss: 0.014337596483528614
step: 340, loss: 0.05311943218111992
step: 350, loss: 0.009688666090369225
step: 360, loss: 0.0036792755126953125
step: 370, loss: 0.11799990385770798
step: 380, loss: 0.024948077276349068
step: 390, loss: 0.11412189155817032
step: 400, loss: 0.12134207040071487
step: 410, loss: 0.0736016184091568
step: 420, loss: 0.057302530854940414
step: 430, loss: 0.03550819680094719
step: 440, loss: 0.051403410732746124
step: 450, loss: 0.012923995964229107
step: 460, loss: 0.022115372121334076
epoch 8: dev_f1=0.9932432432432432, f1=0.9820627802690582, best_f1=0.9820627802690582
step: 0, loss: 0.03886352479457855
step: 10, loss: 0.07543527334928513
step: 20, loss: 0.06515610218048096
step: 30, loss: 0.10252898931503296
step: 40, loss: 0.012773494236171246
step: 50, loss: 0.014292259700596333
step: 60, loss: 0.0008081287960521877
step: 70, loss: 0.06266326457262039
step: 80, loss: 0.0972694531083107
step: 90, loss: 0.020147621631622314
step: 100, loss: 0.06376713514328003
step: 110, loss: 0.04078007489442825
step: 120, loss: 0.026388121768832207
step: 130, loss: 0.009177605621516705
step: 140, loss: 0.04462585970759392
step: 150, loss: 0.09238670021295547
step: 160, loss: 0.005949243437498808
step: 170, loss: 0.11446431279182434
step: 180, loss: 0.015231962315738201
step: 190, loss: 0.01716894656419754
step: 200, loss: 0.0878780335187912
step: 210, loss: 0.0016843321500346065
step: 220, loss: 0.04295193776488304
step: 230, loss: 0.0782761424779892
step: 240, loss: 0.11385459452867508
step: 250, loss: 0.0015136755537241697
step: 260, loss: 0.09317727386951447
step: 270, loss: 0.013252594508230686
step: 280, loss: 0.11291234195232391
step: 290, loss: 0.05998147279024124
step: 300, loss: 0.030591757968068123
step: 310, loss: 0.010258345864713192
step: 320, loss: 0.1276630014181137
step: 330, loss: 0.01532017719000578
step: 340, loss: 0.12897919118404388
step: 350, loss: 0.04941456764936447
step: 360, loss: 0.025426702573895454
step: 370, loss: 0.0029060926754027605
step: 380, loss: 0.1394926756620407
step: 390, loss: 0.04126191884279251
step: 400, loss: 0.05635066702961922
step: 410, loss: 0.03986790403723717
step: 420, loss: 0.08625616133213043
step: 430, loss: 0.1053524762392044
step: 440, loss: 0.0346299409866333
step: 450, loss: 0.06150674447417259
step: 460, loss: 0.024607116356492043
epoch 9: dev_f1=0.9932584269662922, f1=0.9821029082774049, best_f1=0.9821029082774049
step: 0, loss: 0.05545669049024582
step: 10, loss: 0.0798897072672844
step: 20, loss: 0.027796613052487373
step: 30, loss: 0.03868794068694115
step: 40, loss: 0.0023915611673146486
step: 50, loss: 0.02323683351278305
step: 60, loss: 0.024811839684844017
step: 70, loss: 0.12656132876873016
step: 80, loss: 0.07890617102384567
step: 90, loss: 0.06637166440486908
step: 100, loss: 0.008991280570626259
step: 110, loss: 0.1459735929965973
step: 120, loss: 0.004374319687485695
step: 130, loss: 0.021937239915132523
step: 140, loss: 0.09673495590686798
step: 150, loss: 0.1251825988292694
step: 160, loss: 0.04982890188694
step: 170, loss: 0.05295375734567642
step: 180, loss: 0.05262540653347969
step: 190, loss: 0.02193261682987213
step: 200, loss: 0.004139363765716553
step: 210, loss: 0.04683513939380646
step: 220, loss: 0.0099556315690279
step: 230, loss: 0.07752342522144318
step: 240, loss: 0.00985383428633213
step: 250, loss: 0.005797217600047588
step: 260, loss: 0.034231770783662796
step: 270, loss: 0.04806039482355118
step: 280, loss: 0.09521228075027466
step: 290, loss: 0.03530332073569298
step: 300, loss: 0.015384659171104431
step: 310, loss: 0.1406521499156952
step: 320, loss: 0.02122514881193638
step: 330, loss: 0.03954619541764259
step: 340, loss: 0.03284936770796776
step: 350, loss: 0.033752404153347015
step: 360, loss: 0.06380809098482132
step: 370, loss: 0.007334019523113966
step: 380, loss: 0.07293788343667984
step: 390, loss: 0.02717587724328041
step: 400, loss: 0.00824136845767498
step: 410, loss: 0.050754014402627945
step: 420, loss: 0.09102225303649902
step: 430, loss: 0.09454769641160965
step: 440, loss: 0.03605708107352257
step: 450, loss: 0.021073991432785988
step: 460, loss: 0.05834389477968216
epoch 10: dev_f1=0.9921259842519685, f1=0.9787709497206705, best_f1=0.9821029082774049
step: 0, loss: 0.08640207350254059
step: 10, loss: 0.03215688839554787
step: 20, loss: 0.06920628249645233
step: 30, loss: 0.060125164687633514
step: 40, loss: 0.03837549686431885
step: 50, loss: 0.014428943395614624
step: 60, loss: 0.037191156297922134
step: 70, loss: 0.029657194390892982
step: 80, loss: 0.04251338914036751
step: 90, loss: 0.043954070657491684
step: 100, loss: 0.1328117549419403
step: 110, loss: 0.017492573708295822
step: 120, loss: 0.05205582082271576
step: 130, loss: 0.012553839012980461
step: 140, loss: 0.011949856765568256
step: 150, loss: 0.03107609786093235
step: 160, loss: 0.02091684751212597
step: 170, loss: 0.04856270179152489
step: 180, loss: 0.021319657564163208
step: 190, loss: 0.06670592725276947
step: 200, loss: 0.07364144176244736
step: 210, loss: 0.04105491563677788
step: 220, loss: 0.012444800697267056
step: 230, loss: 0.08051297068595886
step: 240, loss: 0.013033629395067692
step: 250, loss: 0.039820458739995956
step: 260, loss: 0.0031486423686146736
step: 270, loss: 0.07164611667394638
step: 280, loss: 0.04169280454516411
step: 290, loss: 0.055852532386779785
step: 300, loss: 0.0027115598786622286
step: 310, loss: 0.006358870770782232
step: 320, loss: 0.007330254651606083
step: 330, loss: 0.021746216341853142
step: 340, loss: 0.011179076507687569
step: 350, loss: 0.020438237115740776
step: 360, loss: 0.1411622017621994
step: 370, loss: 0.0012147383531555533
step: 380, loss: 0.036231379956007004
step: 390, loss: 0.005480826832354069
step: 400, loss: 0.02729612961411476
step: 410, loss: 0.05163564160466194
step: 420, loss: 0.15265701711177826
step: 430, loss: 0.0008793232846073806
step: 440, loss: 0.00401849951595068
step: 450, loss: 0.00031796935945749283
step: 460, loss: 0.08875563740730286
epoch 11: dev_f1=0.9921436588103255, f1=0.9833147942157954, best_f1=0.9821029082774049
step: 0, loss: 0.03485383838415146
step: 10, loss: 0.07409346103668213
step: 20, loss: 0.004690355155616999
step: 30, loss: 5.784436143585481e-05
step: 40, loss: 0.0012080399319529533
step: 50, loss: 0.029535463079810143
step: 60, loss: 0.005180323496460915
step: 70, loss: 0.06475477665662766
step: 80, loss: 0.02341482602059841
step: 90, loss: 0.03104490414261818
step: 100, loss: 0.017164576798677444
step: 110, loss: 0.037228409200906754
step: 120, loss: 0.0037786986213177443
step: 130, loss: 0.13168127834796906
step: 140, loss: 0.0009732029284350574
step: 150, loss: 0.025825146585702896
step: 160, loss: 0.05214860290288925
step: 170, loss: 0.06541289389133453
step: 180, loss: 3.576786912162788e-05
step: 190, loss: 0.04033556208014488
step: 200, loss: 0.0727885514497757
step: 210, loss: 0.08752895146608353
step: 220, loss: 0.009755967184901237
step: 230, loss: 0.057737596333026886
step: 240, loss: 0.03928911313414574
step: 250, loss: 0.02297438681125641
step: 260, loss: 0.013858522288501263
step: 270, loss: 0.0519849956035614
step: 280, loss: 0.019334569573402405
step: 290, loss: 0.006833258550614119
step: 300, loss: 0.04198002070188522
step: 310, loss: 0.03149237111210823
step: 320, loss: 0.04004606604576111
step: 330, loss: 0.15154027938842773
step: 340, loss: 0.0582459457218647
step: 350, loss: 0.05730587616562843
step: 360, loss: 0.025043468922376633
step: 370, loss: 0.06756135821342468
step: 380, loss: 0.05092897266149521
step: 390, loss: 0.015366527251899242
step: 400, loss: 0.09554170817136765
step: 410, loss: 2.3681197490077466e-05
step: 420, loss: 0.022034941241145134
step: 430, loss: 0.025827467441558838
step: 440, loss: 0.03309019282460213
step: 450, loss: 0.10546816140413284
step: 460, loss: 0.03540826961398125
epoch 12: dev_f1=0.9932432432432432, f1=0.9810055865921787, best_f1=0.9821029082774049
step: 0, loss: 0.023569244891405106
step: 10, loss: 0.004244511481374502
step: 20, loss: 0.0021084097679704428
step: 30, loss: 0.005132226273417473
step: 40, loss: 0.06164245307445526
step: 50, loss: 0.032228998839855194
step: 60, loss: 0.08576907217502594
step: 70, loss: 0.05708764120936394
step: 80, loss: 0.01393692847341299
step: 90, loss: 0.017811566591262817
step: 100, loss: 0.1817317008972168
step: 110, loss: 0.006754908245056868
step: 120, loss: 0.01953223906457424
step: 130, loss: 0.015400592237710953
step: 140, loss: 0.0004868684627581388
step: 150, loss: 0.10345446318387985
step: 160, loss: 0.03932507336139679
step: 170, loss: 0.054872963577508926
step: 180, loss: 0.11225518584251404
step: 190, loss: 0.06998465210199356
step: 200, loss: 0.001203469350002706
step: 210, loss: 0.03169591724872589
step: 220, loss: 0.0074760327115654945
step: 230, loss: 0.022134507074952126
step: 240, loss: 0.014407457783818245
step: 250, loss: 0.02903701364994049
step: 260, loss: 0.011046916246414185
step: 270, loss: 0.04582647606730461
step: 280, loss: 0.03148671239614487
step: 290, loss: 0.015416793525218964
step: 300, loss: 0.00017774588195607066
step: 310, loss: 0.05511650815606117
step: 320, loss: 0.03262781351804733
step: 330, loss: 0.08667310327291489
step: 340, loss: 0.020612284541130066
step: 350, loss: 0.035451747477054596
step: 360, loss: 0.08665686845779419
step: 370, loss: 0.041995346546173096
step: 380, loss: 0.0007756827981211245
step: 390, loss: 0.06072021275758743
step: 400, loss: 0.024564066901803017
step: 410, loss: 0.035303376615047455
step: 420, loss: 0.020048022270202637
step: 430, loss: 0.04051700979471207
step: 440, loss: 0.0002911653427872807
step: 450, loss: 0.009795071557164192
step: 460, loss: 0.0002212465915363282
epoch 13: dev_f1=0.9898989898989898, f1=0.9831649831649831, best_f1=0.9821029082774049
step: 0, loss: 0.07862383872270584
step: 10, loss: 0.04513250291347504
step: 20, loss: 0.03428439050912857
step: 30, loss: 0.054352447390556335
step: 40, loss: 0.06374583393335342
step: 50, loss: 0.004280186258256435
step: 60, loss: 0.03132341429591179
step: 70, loss: 0.008123471401631832
step: 80, loss: 0.029680587351322174
step: 90, loss: 0.062176767736673355
step: 100, loss: 0.029886361211538315
step: 110, loss: 0.0029447367414832115
step: 120, loss: 0.038782235234975815
step: 130, loss: 0.033830687403678894
step: 140, loss: 0.0005049634492024779
step: 150, loss: 0.00018309528240934014
step: 160, loss: 0.06782904267311096
step: 170, loss: 0.01631293073296547
step: 180, loss: 0.05449685454368591
step: 190, loss: 0.02105640433728695
step: 200, loss: 0.06400500982999802
step: 210, loss: 0.0004084911779500544
step: 220, loss: 0.00044240779243409634
step: 230, loss: 0.0011517787352204323
step: 240, loss: 2.884747118514497e-05
step: 250, loss: 0.053655460476875305
step: 260, loss: 0.027758734300732613
step: 270, loss: 0.05643247812986374
step: 280, loss: 0.09016560018062592
step: 290, loss: 0.07462292909622192
step: 300, loss: 0.00015771268226671964
step: 310, loss: 0.032208967953920364
step: 320, loss: 0.004037291742861271
step: 330, loss: 0.02614589035511017
step: 340, loss: 0.04231874644756317
step: 350, loss: 0.04083346948027611
step: 360, loss: 0.025263112038373947
step: 370, loss: 0.02488134428858757
step: 380, loss: 0.04383488744497299
step: 390, loss: 0.06876737624406815
step: 400, loss: 0.003310810076072812
step: 410, loss: 0.019553760066628456
step: 420, loss: 0.005366925615817308
step: 430, loss: 8.045836875680834e-05
step: 440, loss: 0.05424020066857338
step: 450, loss: 0.05872093886137009
step: 460, loss: 0.028836866840720177
epoch 14: dev_f1=0.9932432432432432, f1=0.9832026875699889, best_f1=0.9821029082774049
step: 0, loss: 0.026122435927391052
step: 10, loss: 0.018006976693868637
step: 20, loss: 0.07148218154907227
step: 30, loss: 0.0002688146196305752
step: 40, loss: 0.05754045024514198
step: 50, loss: 0.0723695307970047
step: 60, loss: 0.03032776340842247
step: 70, loss: 0.034046970307826996
step: 80, loss: 0.043837107717990875
step: 90, loss: 0.019988365471363068
step: 100, loss: 0.020712170749902725
step: 110, loss: 8.508737664669752e-05
step: 120, loss: 0.07846324890851974
step: 130, loss: 0.04505570977926254
step: 140, loss: 3.324629142298363e-05
step: 150, loss: 0.07905328273773193
step: 160, loss: 0.0035619984846562147
step: 170, loss: 0.10285884141921997
step: 180, loss: 0.06475480645895004
step: 190, loss: 0.037008143961429596
step: 200, loss: 0.05007624253630638
step: 210, loss: 0.019963910803198814
step: 220, loss: 0.04993872717022896
step: 230, loss: 0.015284715220332146
step: 240, loss: 0.039662916213274
step: 250, loss: 0.02239462360739708
step: 260, loss: 3.270197339588776e-05
step: 270, loss: 0.00017665521590970457
step: 280, loss: 0.1515488624572754
step: 290, loss: 0.06938303261995316
step: 300, loss: 0.06318444013595581
step: 310, loss: 0.032441142946481705
step: 320, loss: 0.0636751726269722
step: 330, loss: 0.00016632609185762703
step: 340, loss: 0.025852933526039124
step: 350, loss: 0.0008897037478163838
step: 360, loss: 0.12043776363134384
step: 370, loss: 0.0309690423309803
step: 380, loss: 0.019872531294822693
step: 390, loss: 0.03156905993819237
step: 400, loss: 0.0012982187326997519
step: 410, loss: 0.019894946366548538
step: 420, loss: 0.03894417732954025
step: 430, loss: 4.500187060330063e-05
step: 440, loss: 0.05800079554319382
step: 450, loss: 0.08215559273958206
step: 460, loss: 0.019701244309544563
epoch 15: dev_f1=0.9932432432432432, f1=0.984304932735426, best_f1=0.9821029082774049
step: 0, loss: 0.029287122189998627
step: 10, loss: 6.277323700487614e-05
step: 20, loss: 0.04452528432011604
step: 30, loss: 0.03735645115375519
step: 40, loss: 0.050485990941524506
step: 50, loss: 0.0241656806319952
step: 60, loss: 0.0742892324924469
step: 70, loss: 0.00022281728161033243
step: 80, loss: 0.04114536941051483
step: 90, loss: 0.02074735052883625
step: 100, loss: 0.023740515112876892
step: 110, loss: 0.019202126190066338
step: 120, loss: 0.019773142412304878
step: 130, loss: 0.028762398287653923
step: 140, loss: 0.00035235652467235923
step: 150, loss: 0.03831261023879051
step: 160, loss: 2.9051758247078396e-05
step: 170, loss: 0.1218264251947403
step: 180, loss: 0.01678507588803768
step: 190, loss: 0.022941390052437782
step: 200, loss: 0.040681418031454086
step: 210, loss: 0.08529079705476761
step: 220, loss: 0.021257931366562843
step: 230, loss: 0.021408958360552788
step: 240, loss: 3.522414408507757e-05
step: 250, loss: 0.10292451083660126
step: 260, loss: 0.0006487502832897007
step: 270, loss: 2.7570124075282365e-05
step: 280, loss: 0.004997672513127327
step: 290, loss: 0.024365724995732307
step: 300, loss: 0.013350650668144226
step: 310, loss: 0.12352558970451355
step: 320, loss: 0.032521165907382965
step: 330, loss: 0.06843295693397522
step: 340, loss: 0.023601656779646873
step: 350, loss: 0.05723275616765022
step: 360, loss: 0.004469709470868111
step: 370, loss: 0.02811744622886181
step: 380, loss: 4.866904782829806e-05
step: 390, loss: 0.020788591355085373
step: 400, loss: 4.546194395516068e-05
step: 410, loss: 0.07540592551231384
step: 420, loss: 3.688177093863487e-05
step: 430, loss: 0.06042240932583809
step: 440, loss: 0.014221692457795143
step: 450, loss: 0.01583315245807171
step: 460, loss: 0.03254200890660286
epoch 16: dev_f1=0.9921259842519685, f1=0.9832026875699889, best_f1=0.9821029082774049
step: 0, loss: 2.348001544305589e-05
step: 10, loss: 0.02327185682952404
step: 20, loss: 0.001059195026755333
step: 30, loss: 3.209598799003288e-05
step: 40, loss: 0.017107943072915077
step: 50, loss: 0.052233241498470306
step: 60, loss: 2.3897011487861164e-05
step: 70, loss: 0.0019168017897754908
step: 80, loss: 0.0020693643018603325
step: 90, loss: 0.01932663284242153
step: 100, loss: 0.07854560762643814
step: 110, loss: 0.01853727363049984
step: 120, loss: 0.06747832894325256
step: 130, loss: 0.024026019498705864
step: 140, loss: 0.02552071586251259
step: 150, loss: 0.01754232868552208
step: 160, loss: 0.020593009889125824
step: 170, loss: 0.02390681393444538
step: 180, loss: 0.06041036173701286
step: 190, loss: 2.7170739485882223e-05
step: 200, loss: 0.05104922503232956
step: 210, loss: 0.05005445331335068
step: 220, loss: 0.008761596865952015
step: 230, loss: 0.05662749335169792
step: 240, loss: 0.020226694643497467
step: 250, loss: 0.01975562423467636
step: 260, loss: 0.00010012702841777354
step: 270, loss: 0.02451484091579914
step: 280, loss: 0.00014130766794551164
step: 290, loss: 0.04303143173456192
step: 300, loss: 0.021865027025341988
step: 310, loss: 0.026894623413681984
step: 320, loss: 0.024588385596871376
step: 330, loss: 0.0004749778308905661
step: 340, loss: 0.02295750379562378
step: 350, loss: 0.09885311126708984
step: 360, loss: 0.037529125809669495
step: 370, loss: 0.0964149460196495
step: 380, loss: 0.02199709787964821
step: 390, loss: 0.0516405813395977
step: 400, loss: 3.15181641781237e-05
step: 410, loss: 7.295608520507812e-05
step: 420, loss: 3.0810497264610603e-05
step: 430, loss: 2.326742105651647e-05
step: 440, loss: 0.024606779217720032
step: 450, loss: 0.02110295556485653
step: 460, loss: 0.0013558377977460623
epoch 17: dev_f1=0.9932126696832579, f1=0.983050847457627, best_f1=0.9821029082774049
step: 0, loss: 0.0001997387153096497
step: 10, loss: 0.011811185628175735
step: 20, loss: 0.06035234034061432
step: 30, loss: 7.843349885661155e-05
step: 40, loss: 0.06293600797653198
step: 50, loss: 0.04882051423192024
step: 60, loss: 0.041542716324329376
step: 70, loss: 0.05182131379842758
step: 80, loss: 0.016151554882526398
step: 90, loss: 0.0001758047001203522
step: 100, loss: 0.06527570635080338
step: 110, loss: 0.019611256197094917
step: 120, loss: 0.0007665196899324656
step: 130, loss: 0.021871410310268402
step: 140, loss: 1.7720965843182057e-05
step: 150, loss: 0.042499884963035583
step: 160, loss: 0.02083992399275303
step: 170, loss: 0.07422297447919846
step: 180, loss: 0.020416032522916794
step: 190, loss: 0.05644448474049568
step: 200, loss: 0.013125229626893997
step: 210, loss: 0.03922457993030548
step: 220, loss: 0.10669367015361786
step: 230, loss: 0.023398272693157196
step: 240, loss: 0.06904467195272446
step: 250, loss: 4.189688479527831e-05
step: 260, loss: 0.025646690279245377
step: 270, loss: 0.03559448570013046
step: 280, loss: 3.43670035363175e-05
step: 290, loss: 0.08804067969322205
step: 300, loss: 0.025334548205137253
step: 310, loss: 0.08724530041217804
step: 320, loss: 4.001266279374249e-05
step: 330, loss: 2.356177537876647e-05
step: 340, loss: 2.9983108106534928e-05
step: 350, loss: 0.0834105834364891
step: 360, loss: 5.904813588131219e-05
step: 370, loss: 0.06342454254627228
step: 380, loss: 0.045261822640895844
step: 390, loss: 3.8278674765024334e-05
step: 400, loss: 0.047452181577682495
step: 410, loss: 0.022772785276174545
step: 420, loss: 0.01827894151210785
step: 430, loss: 3.385635500308126e-05
step: 440, loss: 0.040313929319381714
step: 450, loss: 0.02083462104201317
step: 460, loss: 3.527623266563751e-05
epoch 18: dev_f1=0.9910112359550561, f1=0.9821029082774049, best_f1=0.9821029082774049
step: 0, loss: 0.0008669689414091408
step: 10, loss: 0.020588137209415436
step: 20, loss: 0.04683784022927284
step: 30, loss: 0.04387008398771286
step: 40, loss: 0.02185617759823799
step: 50, loss: 4.535962580121122e-05
step: 60, loss: 0.033055685460567474
step: 70, loss: 9.367975872009993e-05
step: 80, loss: 0.06281276792287827
step: 90, loss: 2.4962298994068988e-05
step: 100, loss: 0.025419028475880623
step: 110, loss: 0.06531408429145813
step: 120, loss: 2.2049563995096833e-05
step: 130, loss: 7.208525494206697e-05
step: 140, loss: 0.01909039355814457
step: 150, loss: 0.0519804023206234
step: 160, loss: 0.06395652145147324
step: 170, loss: 0.023431986570358276
step: 180, loss: 0.02256949245929718
step: 190, loss: 0.02125994861125946
step: 200, loss: 0.044369444251060486
step: 210, loss: 0.020626889541745186
step: 220, loss: 0.03834480419754982
step: 230, loss: 0.09310954064130783
step: 240, loss: 0.018953898921608925
step: 250, loss: 4.4265983888180926e-05
step: 260, loss: 0.02968606911599636
step: 270, loss: 0.0006551012047566473
step: 280, loss: 0.004719390533864498
step: 290, loss: 2.3699654775555246e-05
step: 300, loss: 0.02925407886505127
step: 310, loss: 0.019938375800848007
step: 320, loss: 0.04147889465093613
step: 330, loss: 0.02723648212850094
step: 340, loss: 0.05005215108394623
step: 350, loss: 0.00042037584353238344
step: 360, loss: 9.206126560457051e-05
step: 370, loss: 0.03731304779648781
step: 380, loss: 0.007745330221951008
step: 390, loss: 0.00014826311962679029
step: 400, loss: 8.142545993905514e-05
step: 410, loss: 0.038426101207733154
step: 420, loss: 0.014792880043387413
step: 430, loss: 0.037561289966106415
step: 440, loss: 5.113158476888202e-05
step: 450, loss: 0.035642702132463455
step: 460, loss: 5.154483005753718e-05
epoch 19: dev_f1=0.9910112359550561, f1=0.9832402234636871, best_f1=0.9821029082774049
step: 0, loss: 0.017097115516662598
step: 10, loss: 0.02268943004310131
step: 20, loss: 0.017474086955189705
step: 30, loss: 0.023420337587594986
step: 40, loss: 8.174614049494267e-05
step: 50, loss: 0.005455790553241968
step: 60, loss: 3.2404870580649e-05
step: 70, loss: 0.020442049950361252
step: 80, loss: 0.017477991059422493
step: 90, loss: 0.05515344440937042
step: 100, loss: 0.023830482736229897
step: 110, loss: 0.0207876767963171
step: 120, loss: 3.603658842621371e-05
step: 130, loss: 0.02326766774058342
step: 140, loss: 0.036303918808698654
step: 150, loss: 4.606624861480668e-05
step: 160, loss: 0.04180052876472473
step: 170, loss: 0.04184819757938385
step: 180, loss: 0.04447850212454796
step: 190, loss: 0.002226800424978137
step: 200, loss: 2.5513623768347315e-05
step: 210, loss: 0.024053841829299927
step: 220, loss: 0.02082335762679577
step: 230, loss: 0.024017881602048874
step: 240, loss: 0.021717797964811325
step: 250, loss: 0.00037385994801297784
step: 260, loss: 0.031760722398757935
step: 270, loss: 5.4780008213128895e-05
step: 280, loss: 0.023136382922530174
step: 290, loss: 0.026924870908260345
step: 300, loss: 0.04068848490715027
step: 310, loss: 0.015275080688297749
step: 320, loss: 0.02068059891462326
step: 330, loss: 6.23827290837653e-05
step: 340, loss: 0.02074570767581463
step: 350, loss: 0.04130306839942932
step: 360, loss: 3.937418296118267e-05
step: 370, loss: 0.00015718569920863956
step: 380, loss: 0.044581204652786255
step: 390, loss: 0.041974615305662155
step: 400, loss: 0.022050797939300537
step: 410, loss: 0.04836227744817734
step: 420, loss: 0.020096978172659874
step: 430, loss: 0.03232879936695099
step: 440, loss: 0.016335951164364815
step: 450, loss: 0.021457133814692497
step: 460, loss: 0.022896485403180122
epoch 20: dev_f1=0.9910112359550561, f1=0.9821029082774049, best_f1=0.9821029082774049
