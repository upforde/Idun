cuda
Device: cuda
step: 0, loss: 0.7122476100921631
step: 10, loss: 0.4985866844654083
step: 20, loss: 0.476748526096344
step: 30, loss: 0.3966067433357239
step: 40, loss: 0.3046436607837677
step: 50, loss: 0.27807044982910156
step: 60, loss: 0.16873712837696075
step: 70, loss: 0.2337697148323059
step: 80, loss: 0.08503501117229462
step: 90, loss: 0.12032796442508698
step: 100, loss: 0.023179171606898308
step: 110, loss: 0.030774662271142006
step: 120, loss: 0.037305574864149094
step: 130, loss: 0.08274321258068085
step: 140, loss: 0.10046672821044922
step: 150, loss: 0.04315241798758507
step: 160, loss: 0.06388545036315918
step: 170, loss: 0.11512628197669983
step: 180, loss: 0.1021762564778328
step: 190, loss: 0.09028981626033783
step: 200, loss: 0.15112704038619995
step: 210, loss: 0.03187349811196327
step: 220, loss: 0.13750718533992767
step: 230, loss: 0.2153339684009552
step: 240, loss: 0.07951483130455017
step: 250, loss: 0.023434050381183624
step: 260, loss: 0.07246734201908112
step: 270, loss: 0.12750382721424103
step: 280, loss: 0.07239489257335663
step: 290, loss: 0.06063337251543999
step: 300, loss: 0.07276815921068192
step: 310, loss: 0.3568323850631714
step: 320, loss: 0.009942195378243923
step: 330, loss: 0.10229156166315079
step: 340, loss: 0.022953074425458908
step: 350, loss: 0.2212096005678177
step: 360, loss: 0.029608631506562233
step: 370, loss: 0.18437956273555756
step: 380, loss: 0.06905662268400192
step: 390, loss: 0.05670634284615517
step: 400, loss: 0.006370576098561287
step: 410, loss: 0.10441935062408447
step: 420, loss: 0.038465794175863266
step: 430, loss: 0.04854041337966919
step: 440, loss: 0.038798388093709946
step: 450, loss: 0.11710241436958313
step: 460, loss: 0.019047517329454422
epoch 1: dev_f1=0.9898305084745763, f1=0.9852440408626559, best_f1=0.9852440408626559
step: 0, loss: 0.02940312959253788
step: 10, loss: 0.04147958382964134
step: 20, loss: 0.00389573210850358
step: 30, loss: 0.005165723618119955
step: 40, loss: 0.010015509091317654
step: 50, loss: 0.000725580204743892
step: 60, loss: 0.03324852138757706
step: 70, loss: 0.07700051367282867
step: 80, loss: 0.004205835051834583
step: 90, loss: 0.09076900780200958
step: 100, loss: 0.29039663076400757
step: 110, loss: 0.009819208644330502
step: 120, loss: 0.006610066629946232
step: 130, loss: 0.04140491783618927
step: 140, loss: 0.21776182949543
step: 150, loss: 0.05586479231715202
step: 160, loss: 0.01978669874370098
step: 170, loss: 0.07246952503919601
step: 180, loss: 0.018839828670024872
step: 190, loss: 0.1920326054096222
step: 200, loss: 0.016428224742412567
step: 210, loss: 0.008915774524211884
step: 220, loss: 0.2274397313594818
step: 230, loss: 0.07716074585914612
step: 240, loss: 0.006240777671337128
step: 250, loss: 0.04930394887924194
step: 260, loss: 0.00921179261058569
step: 270, loss: 0.059652600437402725
step: 280, loss: 0.01736399158835411
step: 290, loss: 0.13575570285320282
step: 300, loss: 0.0714389905333519
step: 310, loss: 0.01738331839442253
step: 320, loss: 0.1297423243522644
step: 330, loss: 0.005398557521402836
step: 340, loss: 0.03599635139107704
step: 350, loss: 0.07832664996385574
step: 360, loss: 0.009058844298124313
step: 370, loss: 0.25121259689331055
step: 380, loss: 0.03915192559361458
step: 390, loss: 0.07084919512271881
step: 400, loss: 0.1485474705696106
step: 410, loss: 0.057633232325315475
step: 420, loss: 0.07953400909900665
step: 430, loss: 0.05742870271205902
step: 440, loss: 0.014350870624184608
step: 450, loss: 0.1254883110523224
step: 460, loss: 0.049977369606494904
epoch 2: dev_f1=0.9853438556933484, f1=0.9887133182844244, best_f1=0.9852440408626559
step: 0, loss: 0.04638945311307907
step: 10, loss: 0.1440274864435196
step: 20, loss: 0.03927271068096161
step: 30, loss: 0.05025617033243179
step: 40, loss: 0.01953434944152832
step: 50, loss: 0.022192982956767082
step: 60, loss: 0.019550152122974396
step: 70, loss: 0.024764614179730415
step: 80, loss: 0.0117145711556077
step: 90, loss: 0.14441947638988495
step: 100, loss: 0.11310071498155594
step: 110, loss: 0.0477200523018837
step: 120, loss: 0.0006096805445849895
step: 130, loss: 0.13399015367031097
step: 140, loss: 0.07015470415353775
step: 150, loss: 0.0068257153034210205
step: 160, loss: 0.12419053912162781
step: 170, loss: 0.07014649361371994
step: 180, loss: 0.07288375496864319
step: 190, loss: 0.11625848710536957
step: 200, loss: 0.018697481602430344
step: 210, loss: 0.005761880427598953
step: 220, loss: 0.08372712880373001
step: 230, loss: 0.027304481714963913
step: 240, loss: 0.06317904591560364
step: 250, loss: 0.04228781908750534
step: 260, loss: 0.05733707919716835
step: 270, loss: 0.08637556433677673
step: 280, loss: 0.015963496640324593
step: 290, loss: 0.00021425398881547153
step: 300, loss: 0.09180354326963425
step: 310, loss: 0.017560172826051712
step: 320, loss: 0.014958420768380165
step: 330, loss: 0.15571431815624237
step: 340, loss: 0.09729268401861191
step: 350, loss: 0.23606543242931366
step: 360, loss: 0.05332525074481964
step: 370, loss: 0.08292818814516068
step: 380, loss: 0.06460022926330566
step: 390, loss: 0.03687301650643349
step: 400, loss: 0.1386704444885254
step: 410, loss: 0.06922554224729538
step: 420, loss: 0.10854769498109818
step: 430, loss: 0.02233562432229519
step: 440, loss: 0.14171120524406433
step: 450, loss: 0.01413767784833908
step: 460, loss: 0.13678470253944397
epoch 3: dev_f1=0.9920903954802259, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.024166252464056015
step: 10, loss: 0.06686427444219589
step: 20, loss: 0.01831897348165512
step: 30, loss: 0.08716585487127304
step: 40, loss: 0.07730534672737122
step: 50, loss: 0.04259203374385834
step: 60, loss: 0.0033104494214057922
step: 70, loss: 0.0706595927476883
step: 80, loss: 0.03637918829917908
step: 90, loss: 0.017957929521799088
step: 100, loss: 0.020336007699370384
step: 110, loss: 0.000362193415639922
step: 120, loss: 0.0662698894739151
step: 130, loss: 7.353976252488792e-05
step: 140, loss: 0.14801271259784698
step: 150, loss: 0.08755334466695786
step: 160, loss: 0.023296445608139038
step: 170, loss: 0.019594792276620865
step: 180, loss: 0.05521134287118912
step: 190, loss: 0.0207078717648983
step: 200, loss: 0.0034733025822788477
step: 210, loss: 0.08697636425495148
step: 220, loss: 0.0706438422203064
step: 230, loss: 0.05717350170016289
step: 240, loss: 0.03606583923101425
step: 250, loss: 0.13344953954219818
step: 260, loss: 0.020758824422955513
step: 270, loss: 0.05787878856062889
step: 280, loss: 0.01523606851696968
step: 290, loss: 0.007382238749414682
step: 300, loss: 0.02873375453054905
step: 310, loss: 9.762567060533911e-05
step: 320, loss: 0.0644540935754776
step: 330, loss: 0.14234495162963867
step: 340, loss: 0.018268221989274025
step: 350, loss: 0.0007892970461398363
step: 360, loss: 0.10217573493719101
step: 370, loss: 0.014279773458838463
step: 380, loss: 0.060110364109277725
step: 390, loss: 0.08475235849618912
step: 400, loss: 0.04318422079086304
step: 410, loss: 0.00994894839823246
step: 420, loss: 0.014117368496954441
step: 430, loss: 0.14927087724208832
step: 440, loss: 0.0038665044121444225
step: 450, loss: 0.0038591893389821053
step: 460, loss: 0.07138955593109131
epoch 4: dev_f1=0.9943883277216611, f1=0.9844444444444443, best_f1=0.9844444444444443
step: 0, loss: 0.0807337686419487
step: 10, loss: 0.010043264366686344
step: 20, loss: 0.013631024397909641
step: 30, loss: 0.08355077356100082
step: 40, loss: 0.056563425809144974
step: 50, loss: 0.027824057266116142
step: 60, loss: 0.00029869601712562144
step: 70, loss: 0.13727591931819916
step: 80, loss: 0.13313813507556915
step: 90, loss: 0.18605759739875793
step: 100, loss: 0.09490813314914703
step: 110, loss: 0.07171307504177094
step: 120, loss: 0.015637462958693504
step: 130, loss: 0.02276618406176567
step: 140, loss: 0.07016530632972717
step: 150, loss: 0.02257572114467621
step: 160, loss: 0.1367618590593338
step: 170, loss: 0.12319856137037277
step: 180, loss: 0.003902812721207738
step: 190, loss: 0.13509725034236908
step: 200, loss: 0.12836900353431702
step: 210, loss: 0.012298454530537128
step: 220, loss: 0.0677414983510971
step: 230, loss: 0.07425913214683533
step: 240, loss: 0.0743044838309288
step: 250, loss: 0.026839574798941612
step: 260, loss: 0.10728243738412857
step: 270, loss: 0.014410276897251606
step: 280, loss: 0.07002286612987518
step: 290, loss: 0.14147719740867615
step: 300, loss: 0.01145489513874054
step: 310, loss: 0.011689035221934319
step: 320, loss: 0.0012522604083642364
step: 330, loss: 0.021939128637313843
step: 340, loss: 0.03405637666583061
step: 350, loss: 0.08957815915346146
step: 360, loss: 0.08883090317249298
step: 370, loss: 0.0063539776019752026
step: 380, loss: 0.07528285682201385
step: 390, loss: 0.011459248140454292
step: 400, loss: 0.006616127677261829
step: 410, loss: 0.024670381098985672
step: 420, loss: 0.012804103083908558
step: 430, loss: 0.1924578696489334
step: 440, loss: 0.05123116821050644
step: 450, loss: 0.34223559498786926
step: 460, loss: 0.06456019729375839
epoch 5: dev_f1=0.9932584269662922, f1=0.9888392857142857, best_f1=0.9844444444444443
step: 0, loss: 0.03942176327109337
step: 10, loss: 0.011109085753560066
step: 20, loss: 0.07892924547195435
step: 30, loss: 0.012776599265635014
step: 40, loss: 0.004855351056903601
step: 50, loss: 0.07896225899457932
step: 60, loss: 0.008379202336072922
step: 70, loss: 0.09764103591442108
step: 80, loss: 0.019775038585066795
step: 90, loss: 0.07633557915687561
step: 100, loss: 0.07894854992628098
step: 110, loss: 0.06757107377052307
step: 120, loss: 0.007605037651956081
step: 130, loss: 0.06309255212545395
step: 140, loss: 0.02299201302230358
step: 150, loss: 0.07804974168539047
step: 160, loss: 0.07281225919723511
step: 170, loss: 0.018848666921257973
step: 180, loss: 0.10565979778766632
step: 190, loss: 0.0062306541949510574
step: 200, loss: 0.00024833896895870566
step: 210, loss: 0.02008107863366604
step: 220, loss: 0.14373359084129333
step: 230, loss: 0.0005815897602587938
step: 240, loss: 0.07798796892166138
step: 250, loss: 4.3100146285723895e-05
step: 260, loss: 0.008607803843915462
step: 270, loss: 0.021247293800115585
step: 280, loss: 0.09356306493282318
step: 290, loss: 0.017796333879232407
step: 300, loss: 0.0823633000254631
step: 310, loss: 0.06971000880002975
step: 320, loss: 0.09517748653888702
step: 330, loss: 0.03737160190939903
step: 340, loss: 0.04264861345291138
step: 350, loss: 0.027341321110725403
step: 360, loss: 0.028335116803646088
step: 370, loss: 0.12489429116249084
step: 380, loss: 0.020505407825112343
step: 390, loss: 0.08608914166688919
step: 400, loss: 0.20827652513980865
step: 410, loss: 0.05561140179634094
step: 420, loss: 0.01864025555551052
step: 430, loss: 0.011290622875094414
step: 440, loss: 0.061771098524332047
step: 450, loss: 0.036102045327425
step: 460, loss: 0.0057128435000777245
epoch 6: dev_f1=0.9932735426008968, f1=0.9866071428571428, best_f1=0.9844444444444443
step: 0, loss: 0.049271490424871445
step: 10, loss: 0.051052678376436234
step: 20, loss: 0.01733335293829441
step: 30, loss: 0.0124863525852561
step: 40, loss: 0.007063216995447874
step: 50, loss: 0.040606800466775894
step: 60, loss: 0.00782172754406929
step: 70, loss: 0.013852403499186039
step: 80, loss: 0.024084733799099922
step: 90, loss: 0.030206339433789253
step: 100, loss: 0.1241576224565506
step: 110, loss: 0.10675014555454254
step: 120, loss: 0.08865976333618164
step: 130, loss: 0.01015060767531395
step: 140, loss: 0.076064333319664
step: 150, loss: 0.0011296268785372376
step: 160, loss: 0.051748957484960556
step: 170, loss: 0.005329200066626072
step: 180, loss: 0.36300185322761536
step: 190, loss: 0.09478645771741867
step: 200, loss: 0.08920497447252274
step: 210, loss: 0.023117342963814735
step: 220, loss: 0.009620717726647854
step: 230, loss: 0.018874427303671837
step: 240, loss: 0.0674140453338623
step: 250, loss: 0.011223609559237957
step: 260, loss: 0.15278954803943634
step: 270, loss: 0.10731753706932068
step: 280, loss: 0.1337806135416031
step: 290, loss: 0.03269197791814804
step: 300, loss: 0.009395134635269642
step: 310, loss: 0.14778926968574524
step: 320, loss: 0.02197377011179924
step: 330, loss: 0.09801035374403
step: 340, loss: 0.014897748827934265
step: 350, loss: 0.06259782612323761
step: 360, loss: 0.10177506506443024
step: 370, loss: 0.06806716322898865
step: 380, loss: 0.032960064709186554
step: 390, loss: 0.032351020723581314
step: 400, loss: 0.012270587496459484
step: 410, loss: 0.008185917511582375
step: 420, loss: 0.09414167702198029
step: 430, loss: 0.13061781227588654
step: 440, loss: 0.03692290186882019
step: 450, loss: 0.0829482451081276
step: 460, loss: 0.12222465127706528
epoch 7: dev_f1=0.9943883277216611, f1=0.9866369710467707, best_f1=0.9844444444444443
step: 0, loss: 0.14820453524589539
step: 10, loss: 0.021035276353359222
step: 20, loss: 0.12481261789798737
step: 30, loss: 0.0692499428987503
step: 40, loss: 0.0042633796110749245
step: 50, loss: 0.027123186737298965
step: 60, loss: 0.03915007784962654
step: 70, loss: 0.00010634755744831637
step: 80, loss: 0.07730918377637863
step: 90, loss: 0.09985040128231049
step: 100, loss: 0.022831421345472336
step: 110, loss: 0.004362097941339016
step: 120, loss: 0.004429356660693884
step: 130, loss: 0.05306819826364517
step: 140, loss: 0.010042794048786163
step: 150, loss: 0.03894598409533501
step: 160, loss: 0.004124799743294716
step: 170, loss: 0.08839372545480728
step: 180, loss: 0.002864077454432845
step: 190, loss: 0.04014085605740547
step: 200, loss: 0.007806546986103058
step: 210, loss: 0.0016021474730223417
step: 220, loss: 0.08777426183223724
step: 230, loss: 0.058503828942775726
step: 240, loss: 0.02262587659060955
step: 250, loss: 0.08865151554346085
step: 260, loss: 0.02304425835609436
step: 270, loss: 0.04761720076203346
step: 280, loss: 0.06916390359401703
step: 290, loss: 0.09374770522117615
step: 300, loss: 0.0834069699048996
step: 310, loss: 0.003719500731676817
step: 320, loss: 0.00831545703113079
step: 330, loss: 0.012379391118884087
step: 340, loss: 3.285167258582078e-05
step: 350, loss: 0.14326635003089905
step: 360, loss: 0.021780788898468018
step: 370, loss: 0.0682472437620163
step: 380, loss: 0.0033606227952986956
step: 390, loss: 0.011044036597013474
step: 400, loss: 0.24345284700393677
step: 410, loss: 0.018413998186588287
step: 420, loss: 0.013507531024515629
step: 430, loss: 0.09915149956941605
step: 440, loss: 6.65744228172116e-05
step: 450, loss: 0.08244968950748444
step: 460, loss: 0.003034645691514015
epoch 8: dev_f1=0.9932735426008968, f1=0.9854423292273236, best_f1=0.9844444444444443
step: 0, loss: 0.03716321289539337
step: 10, loss: 0.05456291884183884
step: 20, loss: 0.05622582137584686
step: 30, loss: 0.024703659117221832
step: 40, loss: 0.00846861582249403
step: 50, loss: 0.15245641767978668
step: 60, loss: 0.09918692708015442
step: 70, loss: 0.038104429841041565
step: 80, loss: 0.051715463399887085
step: 90, loss: 0.007150785531848669
step: 100, loss: 0.02610943466424942
step: 110, loss: 0.039727240800857544
step: 120, loss: 0.031220782548189163
step: 130, loss: 0.051623113453388214
step: 140, loss: 0.0510915145277977
step: 150, loss: 0.04040604084730148
step: 160, loss: 0.00038092120666988194
step: 170, loss: 0.03733338415622711
step: 180, loss: 0.011207938194274902
step: 190, loss: 0.0701117217540741
step: 200, loss: 0.026541292667388916
step: 210, loss: 0.043153710663318634
step: 220, loss: 0.12103373557329178
step: 230, loss: 0.002562690293416381
step: 240, loss: 0.021586086601018906
step: 250, loss: 0.09026909619569778
step: 260, loss: 0.055208463221788406
step: 270, loss: 0.03754786029458046
step: 280, loss: 0.021021217107772827
step: 290, loss: 0.02583799883723259
step: 300, loss: 0.014249280095100403
step: 310, loss: 0.09069139510393143
step: 320, loss: 0.011207135394215584
step: 330, loss: 0.04887847974896431
step: 340, loss: 0.1072598323225975
step: 350, loss: 0.07560515403747559
step: 360, loss: 0.016394078731536865
step: 370, loss: 0.1559794843196869
step: 380, loss: 0.004695905838161707
step: 390, loss: 0.07255715876817703
step: 400, loss: 0.066095732152462
step: 410, loss: 0.00206184946000576
step: 420, loss: 0.02090057171881199
step: 430, loss: 0.15277282893657684
step: 440, loss: 0.07901457697153091
step: 450, loss: 0.06768914312124252
step: 460, loss: 0.06472083181142807
epoch 9: dev_f1=0.9909706546275394, f1=0.9864864864864865, best_f1=0.9844444444444443
step: 0, loss: 0.025764821097254753
step: 10, loss: 0.003086396958678961
step: 20, loss: 0.018179960548877716
step: 30, loss: 0.03121757134795189
step: 40, loss: 0.04955345019698143
step: 50, loss: 0.007688026875257492
step: 60, loss: 0.03744106367230415
step: 70, loss: 0.09829502552747726
step: 80, loss: 0.01819608360528946
step: 90, loss: 0.0382072739303112
step: 100, loss: 0.002393650356680155
step: 110, loss: 0.06394579261541367
step: 120, loss: 0.0009252980817109346
step: 130, loss: 0.19688774645328522
step: 140, loss: 0.008434002287685871
step: 150, loss: 0.0028731070924550295
step: 160, loss: 0.046285100281238556
step: 170, loss: 0.026821734383702278
step: 180, loss: 0.08342871814966202
step: 190, loss: 0.005888514220714569
step: 200, loss: 0.025654055178165436
step: 210, loss: 0.04457847401499748
step: 220, loss: 0.05165090411901474
step: 230, loss: 0.011720645241439342
step: 240, loss: 8.678718586452305e-05
step: 250, loss: 0.10210952907800674
step: 260, loss: 0.047689881175756454
step: 270, loss: 0.043950553983449936
step: 280, loss: 0.008873364888131618
step: 290, loss: 0.0028642001561820507
step: 300, loss: 0.003206211142241955
step: 310, loss: 0.07005167752504349
step: 320, loss: 0.02897091582417488
step: 330, loss: 0.024935226887464523
step: 340, loss: 0.1255260407924652
step: 350, loss: 0.01974523812532425
step: 360, loss: 0.027430199086666107
step: 370, loss: 0.009046105667948723
step: 380, loss: 0.0034402331802994013
step: 390, loss: 0.0010641022818163037
step: 400, loss: 0.07814326882362366
step: 410, loss: 0.08480487018823624
step: 420, loss: 0.05996454507112503
step: 430, loss: 0.008156416937708855
step: 440, loss: 0.007325348444283009
step: 450, loss: 0.00041196306119672954
step: 460, loss: 0.07109702378511429
epoch 10: dev_f1=0.9888392857142857, f1=0.9811320754716982, best_f1=0.9844444444444443
step: 0, loss: 0.03968055918812752
step: 10, loss: 0.000552898389287293
step: 20, loss: 0.011692110449075699
step: 30, loss: 0.03821759298443794
step: 40, loss: 0.042594555765390396
step: 50, loss: 0.00021266173280309886
step: 60, loss: 0.0017531064804643393
step: 70, loss: 0.0017690864624455571
step: 80, loss: 0.00010574131010798737
step: 90, loss: 0.01405490655452013
step: 100, loss: 0.02720632590353489
step: 110, loss: 0.02620730549097061
step: 120, loss: 0.05324246361851692
step: 130, loss: 0.03152426332235336
step: 140, loss: 0.020386794582009315
step: 150, loss: 0.00010832903353730217
step: 160, loss: 0.07112469524145126
step: 170, loss: 3.328003367641941e-05
step: 180, loss: 0.09164424985647202
step: 190, loss: 0.025130076333880424
step: 200, loss: 0.038012389093637466
step: 210, loss: 0.01563858799636364
step: 220, loss: 0.05571924149990082
step: 230, loss: 0.042675066739320755
step: 240, loss: 0.008840624243021011
step: 250, loss: 0.009394019842147827
step: 260, loss: 5.371946099330671e-05
step: 270, loss: 0.005882491823285818
step: 280, loss: 0.07968655973672867
step: 290, loss: 0.02340737357735634
step: 300, loss: 8.355722820851952e-05
step: 310, loss: 0.08883023262023926
step: 320, loss: 0.012740719132125378
step: 330, loss: 0.012566976249217987
step: 340, loss: 0.018688026815652847
step: 350, loss: 0.00874368753284216
step: 360, loss: 0.09301047772169113
step: 370, loss: 0.03159216791391373
step: 380, loss: 0.0003093983686994761
step: 390, loss: 0.002258195774629712
step: 400, loss: 0.04187861084938049
step: 410, loss: 0.03234526142477989
step: 420, loss: 0.003971044439822435
step: 430, loss: 0.03806540369987488
step: 440, loss: 3.96489049308002e-05
step: 450, loss: 0.029608706012368202
step: 460, loss: 0.01141718216240406
epoch 11: dev_f1=0.9932735426008968, f1=0.9843400447427293, best_f1=0.9844444444444443
step: 0, loss: 0.004808618221431971
step: 10, loss: 0.017825037240982056
step: 20, loss: 0.1214180663228035
step: 30, loss: 0.00021500210277736187
step: 40, loss: 0.028793754056096077
step: 50, loss: 0.03912082687020302
step: 60, loss: 0.025001201778650284
step: 70, loss: 0.07761821895837784
step: 80, loss: 0.025357728824019432
step: 90, loss: 0.03691622614860535
step: 100, loss: 0.018507318571209908
step: 110, loss: 0.11901894956827164
step: 120, loss: 0.040316179394721985
step: 130, loss: 0.0013468132819980383
step: 140, loss: 0.06344129145145416
step: 150, loss: 7.919684139778838e-05
step: 160, loss: 0.00018994796846527606
step: 170, loss: 3.6597950384020805e-05
step: 180, loss: 0.018861137330532074
step: 190, loss: 0.10590109974145889
step: 200, loss: 0.036765873432159424
step: 210, loss: 0.07746640592813492
step: 220, loss: 0.0027075940743088722
step: 230, loss: 0.04113598167896271
step: 240, loss: 0.0011650256346911192
step: 250, loss: 0.07202383130788803
step: 260, loss: 0.033155955374240875
step: 270, loss: 0.027054479345679283
step: 280, loss: 0.02057521604001522
step: 290, loss: 0.10996383428573608
step: 300, loss: 0.0810399278998375
step: 310, loss: 0.0198227409273386
step: 320, loss: 0.04273092746734619
step: 330, loss: 0.01037837378680706
step: 340, loss: 0.0678490400314331
step: 350, loss: 0.0533740371465683
step: 360, loss: 0.05113410949707031
step: 370, loss: 0.025163792073726654
step: 380, loss: 0.0001972762547666207
step: 390, loss: 0.00010359814041294158
step: 400, loss: 0.018440498039126396
step: 410, loss: 0.10900251567363739
step: 420, loss: 0.0020787743851542473
step: 430, loss: 0.000328343128785491
step: 440, loss: 0.03423287719488144
step: 450, loss: 0.03379662707448006
step: 460, loss: 0.024260714650154114
epoch 12: dev_f1=0.9921612541993281, f1=0.98, best_f1=0.9844444444444443
step: 0, loss: 0.05148264393210411
step: 10, loss: 0.03287598863244057
step: 20, loss: 0.0019678394310176373
step: 30, loss: 0.012460008263587952
step: 40, loss: 0.026112230494618416
step: 50, loss: 0.021545536816120148
step: 60, loss: 0.061580706387758255
step: 70, loss: 0.007080898154526949
step: 80, loss: 0.002887107664719224
step: 90, loss: 0.01898784004151821
step: 100, loss: 0.09139611572027206
step: 110, loss: 0.016705099493265152
step: 120, loss: 0.041758324950933456
step: 130, loss: 0.03811272233724594
step: 140, loss: 0.05297820642590523
step: 150, loss: 0.022908354178071022
step: 160, loss: 0.054064132273197174
step: 170, loss: 0.021899040788412094
step: 180, loss: 0.0002853375335689634
step: 190, loss: 0.026019886136054993
step: 200, loss: 0.03953341394662857
step: 210, loss: 0.043138619512319565
step: 220, loss: 0.007374592125415802
step: 230, loss: 0.0009744605631567538
step: 240, loss: 0.020178865641355515
step: 250, loss: 0.0001899532217066735
step: 260, loss: 0.0010343972826376557
step: 270, loss: 0.01683221571147442
step: 280, loss: 7.418243330903351e-05
step: 290, loss: 0.08021838217973709
step: 300, loss: 0.019921524450182915
step: 310, loss: 0.011559694074094296
step: 320, loss: 0.06541547924280167
step: 330, loss: 0.009423627518117428
step: 340, loss: 0.02856958657503128
step: 350, loss: 0.02118215523660183
step: 360, loss: 0.0016138196224346757
step: 370, loss: 0.023106344044208527
step: 380, loss: 0.024547316133975983
step: 390, loss: 0.025575632229447365
step: 400, loss: 0.018014926463365555
step: 410, loss: 0.022478586062788963
step: 420, loss: 0.016514813527464867
step: 430, loss: 0.037597641348838806
step: 440, loss: 0.03136119619011879
step: 450, loss: 0.024979669600725174
step: 460, loss: 0.1371481865644455
epoch 13: dev_f1=0.9921612541993281, f1=0.9855072463768116, best_f1=0.9844444444444443
step: 0, loss: 0.040597811341285706
step: 10, loss: 0.04099586606025696
step: 20, loss: 0.027218736708164215
step: 30, loss: 0.06603773683309555
step: 40, loss: 0.00740842754021287
step: 50, loss: 0.00015537251601926982
step: 60, loss: 0.06776490807533264
step: 70, loss: 6.649915303569287e-05
step: 80, loss: 0.0509444884955883
step: 90, loss: 0.02237405814230442
step: 100, loss: 0.04543298855423927
step: 110, loss: 0.05326935276389122
step: 120, loss: 0.00035431646392680705
step: 130, loss: 0.029962986707687378
step: 140, loss: 0.0003524731146171689
step: 150, loss: 0.04481014236807823
step: 160, loss: 0.028091169893741608
step: 170, loss: 0.021543823182582855
step: 180, loss: 0.023861847817897797
step: 190, loss: 0.046150948852300644
step: 200, loss: 0.020090891048312187
step: 210, loss: 0.03234335035085678
step: 220, loss: 0.041018687188625336
step: 230, loss: 0.04394374415278435
step: 240, loss: 0.01937565580010414
step: 250, loss: 0.019503982737660408
step: 260, loss: 0.04679432883858681
step: 270, loss: 0.031934451311826706
step: 280, loss: 0.035101719200611115
step: 290, loss: 0.00015086129133123904
step: 300, loss: 3.61332313332241e-05
step: 310, loss: 2.797544038912747e-05
step: 320, loss: 0.023837197571992874
step: 330, loss: 0.04905598610639572
step: 340, loss: 0.017623741179704666
step: 350, loss: 0.00023936742218211293
step: 360, loss: 0.002242923714220524
step: 370, loss: 0.033378902822732925
step: 380, loss: 0.02867656946182251
step: 390, loss: 0.021119367331266403
step: 400, loss: 0.025458915159106255
step: 410, loss: 0.018257254734635353
step: 420, loss: 0.00018473177624400705
step: 430, loss: 0.02998911403119564
step: 440, loss: 0.0047203656286001205
step: 450, loss: 0.021165188401937485
step: 460, loss: 0.06496893614530563
epoch 14: dev_f1=0.9932735426008968, f1=0.9865771812080537, best_f1=0.9844444444444443
step: 0, loss: 0.002438213909044862
step: 10, loss: 0.06704150885343552
step: 20, loss: 0.06961984187364578
step: 30, loss: 0.06300198286771774
step: 40, loss: 0.040299586951732635
step: 50, loss: 4.368953523226082e-05
step: 60, loss: 0.03345610946416855
step: 70, loss: 0.04764588549733162
step: 80, loss: 0.00010972077870974317
step: 90, loss: 0.0310268085449934
step: 100, loss: 0.02207239530980587
step: 110, loss: 0.029869385063648224
step: 120, loss: 0.021599847823381424
step: 130, loss: 0.0004741409211419523
step: 140, loss: 0.00021640952036250383
step: 150, loss: 0.03923990577459335
step: 160, loss: 0.045775655657052994
step: 170, loss: 0.019086463376879692
step: 180, loss: 0.07515998929738998
step: 190, loss: 0.021306009963154793
step: 200, loss: 0.00033680087653920054
step: 210, loss: 0.02066214196383953
step: 220, loss: 0.046610988676548004
step: 230, loss: 0.02088361606001854
step: 240, loss: 0.047665975987911224
step: 250, loss: 0.04244746267795563
step: 260, loss: 0.022396931424736977
step: 270, loss: 0.027351820841431618
step: 280, loss: 0.013665813952684402
step: 290, loss: 0.0007219241233542562
step: 300, loss: 0.020319702103734016
step: 310, loss: 0.02113945223391056
step: 320, loss: 0.02228524722158909
step: 330, loss: 0.02006145939230919
step: 340, loss: 0.03718087449669838
step: 350, loss: 0.0003013036912307143
step: 360, loss: 0.00032806521630845964
step: 370, loss: 0.05632563307881355
step: 380, loss: 0.020153405144810677
step: 390, loss: 8.782689110375941e-05
step: 400, loss: 0.00763978436589241
step: 410, loss: 0.08334089815616608
step: 420, loss: 0.025311987847089767
step: 430, loss: 0.10176972299814224
step: 440, loss: 0.01896909438073635
step: 450, loss: 4.8193527618423104e-05
step: 460, loss: 0.021947801113128662
epoch 15: dev_f1=0.9943757030371203, f1=0.9842696629213483, best_f1=0.9844444444444443
step: 0, loss: 0.08972103148698807
step: 10, loss: 0.04298573359847069
step: 20, loss: 1.692378646112047e-05
step: 30, loss: 0.0307912677526474
step: 40, loss: 7.766616909066215e-05
step: 50, loss: 0.08649638295173645
step: 60, loss: 0.032149262726306915
step: 70, loss: 0.021911488845944405
step: 80, loss: 7.550038571935147e-05
step: 90, loss: 0.0002151370281353593
step: 100, loss: 0.01931121200323105
step: 110, loss: 0.0038976790383458138
step: 120, loss: 0.028284257277846336
step: 130, loss: 0.02475092001259327
step: 140, loss: 0.018537161871790886
step: 150, loss: 0.0006092257681302726
step: 160, loss: 0.021945349872112274
step: 170, loss: 0.05897502601146698
step: 180, loss: 0.018678713589906693
step: 190, loss: 0.024381792172789574
step: 200, loss: 0.020905308425426483
step: 210, loss: 0.06406431645154953
step: 220, loss: 0.03279653191566467
step: 230, loss: 2.5842931790975854e-05
step: 240, loss: 0.00019678482203744352
step: 250, loss: 0.07291701436042786
step: 260, loss: 6.090883834986016e-05
step: 270, loss: 0.07044526189565659
step: 280, loss: 0.0016961632063612342
step: 290, loss: 0.017321724444627762
step: 300, loss: 0.025180423632264137
step: 310, loss: 0.02782750315964222
step: 320, loss: 0.00024143019982147962
step: 330, loss: 0.04282589256763458
step: 340, loss: 0.0002610600786283612
step: 350, loss: 0.021854141727089882
step: 360, loss: 0.021762412041425705
step: 370, loss: 0.00011289784015389159
step: 380, loss: 0.04391716793179512
step: 390, loss: 0.0003263839171268046
step: 400, loss: 0.044612735509872437
step: 410, loss: 0.19712191820144653
step: 420, loss: 0.020261460915207863
step: 430, loss: 0.0031118926126509905
step: 440, loss: 0.00021325412672013044
step: 450, loss: 0.00013359234435483813
step: 460, loss: 0.04079361632466316
epoch 16: dev_f1=0.9932735426008968, f1=0.9866071428571428, best_f1=0.9844444444444443
step: 0, loss: 0.024503417313098907
step: 10, loss: 0.00032610102789476514
step: 20, loss: 1.651770799071528e-05
step: 30, loss: 5.46949559065979e-05
step: 40, loss: 0.024882525205612183
step: 50, loss: 0.0001597442023921758
step: 60, loss: 0.048975467681884766
step: 70, loss: 0.03171946108341217
step: 80, loss: 0.04531806707382202
step: 90, loss: 4.011898272437975e-05
step: 100, loss: 0.00018560590979177505
step: 110, loss: 0.0009842942235991359
step: 120, loss: 6.075297642382793e-05
step: 130, loss: 0.02220206893980503
step: 140, loss: 0.0004068249836564064
step: 150, loss: 2.7837329980684444e-05
step: 160, loss: 0.019295888021588326
step: 170, loss: 0.060378823429346085
step: 180, loss: 0.0028597768396139145
step: 190, loss: 0.01948094367980957
step: 200, loss: 0.019780481234192848
step: 210, loss: 0.00010763449972728267
step: 220, loss: 0.02351268194615841
step: 230, loss: 0.047724585980176926
step: 240, loss: 0.10589557886123657
step: 250, loss: 0.028162751346826553
step: 260, loss: 0.0230557918548584
step: 270, loss: 0.024584602564573288
step: 280, loss: 0.040490906685590744
step: 290, loss: 0.0003461703017819673
step: 300, loss: 0.04807327687740326
step: 310, loss: 0.04724255949258804
step: 320, loss: 0.024133747443556786
step: 330, loss: 1.6160094673978165e-05
step: 340, loss: 0.00020522896375041455
step: 350, loss: 7.351450767600909e-05
step: 360, loss: 0.14136655628681183
step: 370, loss: 5.8831763453781605e-05
step: 380, loss: 0.021190619096159935
step: 390, loss: 0.02525540627539158
step: 400, loss: 0.01911167986690998
step: 410, loss: 0.00012885495380032808
step: 420, loss: 0.022591181099414825
step: 430, loss: 0.020922143012285233
step: 440, loss: 0.00020514205971267074
step: 450, loss: 1.345933742413763e-05
step: 460, loss: 0.00020607135957106948
epoch 17: dev_f1=0.9943883277216611, f1=0.9865771812080537, best_f1=0.9844444444444443
step: 0, loss: 1.430868542229291e-05
step: 10, loss: 0.021938594058156013
step: 20, loss: 0.021401111036539078
step: 30, loss: 0.043993305414915085
step: 40, loss: 1.2598824469023384e-05
step: 50, loss: 0.04447747394442558
step: 60, loss: 2.1604237190331332e-05
step: 70, loss: 0.0208765659481287
step: 80, loss: 0.022831184789538383
step: 90, loss: 8.79607250681147e-05
step: 100, loss: 0.000705677317455411
step: 110, loss: 0.020616523921489716
step: 120, loss: 0.021157274022698402
step: 130, loss: 0.05162183567881584
step: 140, loss: 1.1678706869133748e-05
step: 150, loss: 0.02421937696635723
step: 160, loss: 0.022924834862351418
step: 170, loss: 0.02384248375892639
step: 180, loss: 0.00010274255328113213
step: 190, loss: 6.212134030647576e-05
step: 200, loss: 0.04413812234997749
step: 210, loss: 0.020876280963420868
step: 220, loss: 0.023020228371024132
step: 230, loss: 0.01909760572016239
step: 240, loss: 0.018086569383740425
step: 250, loss: 0.03606325387954712
step: 260, loss: 0.01921660825610161
step: 270, loss: 0.02376066893339157
step: 280, loss: 0.03497689962387085
step: 290, loss: 2.0719044186989777e-05
step: 300, loss: 0.06329763680696487
step: 310, loss: 0.00029632283258251846
step: 320, loss: 0.034305255860090256
step: 330, loss: 0.023952895775437355
step: 340, loss: 0.00017181364819407463
step: 350, loss: 7.609956810483709e-05
step: 360, loss: 0.02112053520977497
step: 370, loss: 5.1062415877822787e-05
step: 380, loss: 0.05626353248953819
step: 390, loss: 2.4380095055676065e-05
step: 400, loss: 0.017830263823270798
step: 410, loss: 0.021803613752126694
step: 420, loss: 0.00020089751342311502
step: 430, loss: 0.01932792365550995
step: 440, loss: 3.7124755181139335e-05
step: 450, loss: 0.09543133527040482
step: 460, loss: 8.263386553153396e-05
epoch 18: dev_f1=0.9932735426008968, f1=0.987709497206704, best_f1=0.9844444444444443
step: 0, loss: 0.00012761203106492758
step: 10, loss: 0.04677706956863403
step: 20, loss: 1.178668208012823e-05
step: 30, loss: 0.06277182698249817
step: 40, loss: 0.02027343213558197
step: 50, loss: 1.5552888726233505e-05
step: 60, loss: 0.041865549981594086
step: 70, loss: 0.021453114226460457
step: 80, loss: 0.00012679897190537304
step: 90, loss: 6.216367182787508e-05
step: 100, loss: 9.615249291528016e-05
step: 110, loss: 0.12182881683111191
step: 120, loss: 0.07091175019741058
step: 130, loss: 0.020163757726550102
step: 140, loss: 0.001182321459054947
step: 150, loss: 3.705391281982884e-05
step: 160, loss: 1.8249626009492204e-05
step: 170, loss: 0.003569487016648054
step: 180, loss: 0.022166550159454346
step: 190, loss: 0.023242224007844925
step: 200, loss: 0.043568700551986694
step: 210, loss: 0.07776238769292831
step: 220, loss: 0.020777519792318344
step: 230, loss: 7.610284228576347e-05
step: 240, loss: 0.02019231766462326
step: 250, loss: 0.023876111954450607
step: 260, loss: 0.02260414883494377
step: 270, loss: 0.019371312111616135
step: 280, loss: 0.02140544168651104
step: 290, loss: 0.020379796624183655
step: 300, loss: 0.017875630408525467
step: 310, loss: 0.04292106255888939
step: 320, loss: 0.023791395127773285
step: 330, loss: 5.601905650109984e-05
step: 340, loss: 7.095829641912133e-05
step: 350, loss: 0.01834474317729473
step: 360, loss: 0.00013902306091040373
step: 370, loss: 0.00010593864135444164
step: 380, loss: 7.927729893708602e-05
step: 390, loss: 0.00047607524902559817
step: 400, loss: 2.8263644708204083e-05
step: 410, loss: 0.04468187689781189
step: 420, loss: 0.029178112745285034
step: 430, loss: 0.049054104834795
step: 440, loss: 0.00010737129196058959
step: 450, loss: 0.04939020797610283
step: 460, loss: 0.00017222769383806735
epoch 19: dev_f1=0.9932735426008968, f1=0.9855072463768116, best_f1=0.9844444444444443
step: 0, loss: 0.036755334585905075
step: 10, loss: 2.4071339794318192e-05
step: 20, loss: 4.2693827708717436e-05
step: 30, loss: 0.023226721212267876
step: 40, loss: 0.00025647744769230485
step: 50, loss: 0.00019077994511462748
step: 60, loss: 0.03649893030524254
step: 70, loss: 3.9268474210985005e-05
step: 80, loss: 3.340490729897283e-05
step: 90, loss: 0.00011214448750251904
step: 100, loss: 0.04157475382089615
step: 110, loss: 0.021707797423005104
step: 120, loss: 0.05722786858677864
step: 130, loss: 0.02542506903409958
step: 140, loss: 0.0011183532187715173
step: 150, loss: 0.018868455663323402
step: 160, loss: 0.0466165728867054
step: 170, loss: 0.00053627067245543
step: 180, loss: 0.09225644916296005
step: 190, loss: 0.020454619079828262
step: 200, loss: 1.1935740076296497e-05
step: 210, loss: 0.04472091421484947
step: 220, loss: 0.02535269968211651
step: 230, loss: 0.00014517940871883184
step: 240, loss: 6.0712318372679874e-05
step: 250, loss: 0.04746632277965546
step: 260, loss: 0.021387090906500816
step: 270, loss: 1.1399299182812683e-05
step: 280, loss: 0.04916002228856087
step: 290, loss: 0.04471300169825554
step: 300, loss: 0.023116936907172203
step: 310, loss: 0.02113337814807892
step: 320, loss: 3.568401007214561e-05
step: 330, loss: 0.022197073325514793
step: 340, loss: 0.01920570805668831
step: 350, loss: 0.0006845206953585148
step: 360, loss: 0.026636222377419472
step: 370, loss: 2.026421316259075e-05
step: 380, loss: 1.3895183656131849e-05
step: 390, loss: 0.015234274789690971
step: 400, loss: 4.8179565055761486e-05
step: 410, loss: 0.022333232685923576
step: 420, loss: 0.040258653461933136
step: 430, loss: 5.385454642237164e-05
step: 440, loss: 0.02615421637892723
step: 450, loss: 2.076338932965882e-05
step: 460, loss: 0.050185929983854294
epoch 20: dev_f1=0.9932735426008968, f1=0.987709497206704, best_f1=0.9844444444444443
