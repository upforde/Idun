cuda
Device: cuda
step: 0, loss: 0.7228996157646179
step: 10, loss: 0.5397157073020935
step: 20, loss: 0.70624840259552
step: 30, loss: 0.3356391191482544
step: 40, loss: 0.4410342574119568
step: 50, loss: 0.4845810830593109
step: 60, loss: 0.35078662633895874
step: 70, loss: 0.20136313140392303
step: 80, loss: 0.04383358359336853
step: 90, loss: 0.3946635127067566
step: 100, loss: 0.11664199084043503
step: 110, loss: 0.12948308885097504
step: 120, loss: 0.22704331576824188
step: 130, loss: 0.19138546288013458
step: 140, loss: 0.24055154621601105
step: 150, loss: 0.2503083348274231
step: 160, loss: 0.14859220385551453
step: 170, loss: 0.196427583694458
step: 180, loss: 0.13084222376346588
step: 190, loss: 0.122389055788517
step: 200, loss: 0.25211310386657715
step: 210, loss: 0.1604311168193817
step: 220, loss: 0.11931348592042923
step: 230, loss: 0.1614871472120285
step: 240, loss: 0.23210647702217102
step: 250, loss: 0.1097656786441803
step: 260, loss: 0.1891687661409378
step: 270, loss: 0.15367427468299866
step: 280, loss: 0.08571363985538483
step: 290, loss: 0.06790392100811005
step: 300, loss: 0.10479666292667389
step: 310, loss: 0.0836627259850502
step: 320, loss: 0.25015175342559814
step: 330, loss: 0.10152948647737503
step: 340, loss: 0.13931380212306976
step: 350, loss: 0.06795009225606918
step: 360, loss: 0.21541371941566467
step: 370, loss: 0.18881197273731232
step: 380, loss: 0.07916087657213211
step: 390, loss: 0.07063014805316925
step: 400, loss: 0.1012907326221466
step: 410, loss: 0.12685923278331757
step: 420, loss: 0.024962911382317543
step: 430, loss: 0.15143848955631256
step: 440, loss: 0.09190545231103897
step: 450, loss: 0.010345990769565105
step: 460, loss: 0.05015302449464798
epoch 1: dev_f1=0.9798657718120806, f1=0.9775280898876404, best_f1=0.9775280898876404
step: 0, loss: 0.08345150202512741
step: 10, loss: 0.11960738152265549
step: 20, loss: 0.08484139293432236
step: 30, loss: 0.021892840042710304
step: 40, loss: 0.12175537645816803
step: 50, loss: 0.1876796931028366
step: 60, loss: 0.0686422660946846
step: 70, loss: 0.028359392657876015
step: 80, loss: 0.1296738088130951
step: 90, loss: 0.08925028890371323
step: 100, loss: 0.08457634598016739
step: 110, loss: 0.06906336545944214
step: 120, loss: 0.014344921335577965
step: 130, loss: 0.05451761931180954
step: 140, loss: 0.15073858201503754
step: 150, loss: 0.03188643604516983
step: 160, loss: 0.01356930285692215
step: 170, loss: 0.07472957670688629
step: 180, loss: 0.025796396657824516
step: 190, loss: 0.032537318766117096
step: 200, loss: 0.04258543998003006
step: 210, loss: 0.0066331299021840096
step: 220, loss: 0.26014402508735657
step: 230, loss: 0.03433843329548836
step: 240, loss: 0.10503200441598892
step: 250, loss: 0.06389463692903519
step: 260, loss: 0.04345476254820824
step: 270, loss: 0.005100136622786522
step: 280, loss: 0.2019781917333603
step: 290, loss: 0.04184351861476898
step: 300, loss: 0.05973754823207855
step: 310, loss: 0.005488918162882328
step: 320, loss: 0.07203532755374908
step: 330, loss: 0.05915975198149681
step: 340, loss: 0.10281071066856384
step: 350, loss: 0.016136059537529945
step: 360, loss: 0.06401462852954865
step: 370, loss: 0.01731986366212368
step: 380, loss: 0.040753889828920364
step: 390, loss: 0.02370540425181389
step: 400, loss: 0.08952242136001587
step: 410, loss: 0.037230804562568665
step: 420, loss: 0.015177292749285698
step: 430, loss: 0.08892040699720383
step: 440, loss: 0.15925614535808563
step: 450, loss: 0.05828350782394409
step: 460, loss: 0.01183794904500246
epoch 2: dev_f1=0.9910112359550561, f1=0.9808773903262092, best_f1=0.9808773903262092
step: 0, loss: 0.013883993960916996
step: 10, loss: 0.012204514816403389
step: 20, loss: 0.03544589504599571
step: 30, loss: 0.043932583183050156
step: 40, loss: 0.05816807970404625
step: 50, loss: 0.007457016035914421
step: 60, loss: 0.009120051749050617
step: 70, loss: 0.05541177839040756
step: 80, loss: 0.019548678770661354
step: 90, loss: 0.050394248217344284
step: 100, loss: 0.06228477135300636
step: 110, loss: 0.06558080017566681
step: 120, loss: 0.027322158217430115
step: 130, loss: 0.03324286267161369
step: 140, loss: 0.07315806299448013
step: 150, loss: 0.08081908524036407
step: 160, loss: 0.04355340823531151
step: 170, loss: 0.016528524458408356
step: 180, loss: 0.012150698341429234
step: 190, loss: 0.058901745826005936
step: 200, loss: 0.08828853070735931
step: 210, loss: 0.12123388797044754
step: 220, loss: 0.039579473435878754
step: 230, loss: 0.06461978703737259
step: 240, loss: 0.031739335507154465
step: 250, loss: 0.0741288885474205
step: 260, loss: 0.02700835093855858
step: 270, loss: 0.026499753817915916
step: 280, loss: 0.1654638797044754
step: 290, loss: 0.029399914667010307
step: 300, loss: 0.07106530666351318
step: 310, loss: 0.06065581366419792
step: 320, loss: 0.015772651880979538
step: 330, loss: 0.1828193962574005
step: 340, loss: 0.05707116425037384
step: 350, loss: 0.007877523079514503
step: 360, loss: 0.0054427506402134895
step: 370, loss: 0.02821158617734909
step: 380, loss: 0.2954599857330322
step: 390, loss: 0.017273396253585815
step: 400, loss: 0.22884294390678406
step: 410, loss: 0.0668015256524086
step: 420, loss: 0.06415832042694092
step: 430, loss: 0.07932180166244507
step: 440, loss: 0.05168403685092926
step: 450, loss: 0.01215381920337677
step: 460, loss: 0.030886275693774223
epoch 3: dev_f1=0.987598647125141, f1=0.9795454545454545, best_f1=0.9808773903262092
step: 0, loss: 0.019344711676239967
step: 10, loss: 0.033041853457689285
step: 20, loss: 0.012648691423237324
step: 30, loss: 0.006081100553274155
step: 40, loss: 0.011723186820745468
step: 50, loss: 0.12426183372735977
step: 60, loss: 0.023871155455708504
step: 70, loss: 0.009892337955534458
step: 80, loss: 0.021291185170412064
step: 90, loss: 0.1982925832271576
step: 100, loss: 0.021768974140286446
step: 110, loss: 0.06603032350540161
step: 120, loss: 0.012859556823968887
step: 130, loss: 0.011388699524104595
step: 140, loss: 0.14340443909168243
step: 150, loss: 0.030340010300278664
step: 160, loss: 0.015408271923661232
step: 170, loss: 0.02787615917623043
step: 180, loss: 0.12975692749023438
step: 190, loss: 0.17499208450317383
step: 200, loss: 0.02773263305425644
step: 210, loss: 0.10694977641105652
step: 220, loss: 0.02296840399503708
step: 230, loss: 0.1298786997795105
step: 240, loss: 0.012095939368009567
step: 250, loss: 0.07433546334505081
step: 260, loss: 0.05181517079472542
step: 270, loss: 0.03717398643493652
step: 280, loss: 0.0013238716637715697
step: 290, loss: 0.01852571964263916
step: 300, loss: 0.025249138474464417
step: 310, loss: 0.006484262179583311
step: 320, loss: 0.02191436104476452
step: 330, loss: 0.024465033784508705
step: 340, loss: 0.09024282544851303
step: 350, loss: 0.13255150616168976
step: 360, loss: 0.12986475229263306
step: 370, loss: 0.027112707495689392
step: 380, loss: 0.036531008780002594
step: 390, loss: 0.03562957048416138
step: 400, loss: 0.06259980797767639
step: 410, loss: 0.035564810037612915
step: 420, loss: 0.035804882645606995
step: 430, loss: 0.006478397641330957
step: 440, loss: 0.024923916906118393
step: 450, loss: 0.13749383389949799
step: 460, loss: 0.07627765834331512
epoch 4: dev_f1=0.9932432432432432, f1=0.9807474518686297, best_f1=0.9807474518686297
step: 0, loss: 0.017746681347489357
step: 10, loss: 0.00670600775629282
step: 20, loss: 0.00695672444999218
step: 30, loss: 0.009145285002887249
step: 40, loss: 0.1127973347902298
step: 50, loss: 0.02129744552075863
step: 60, loss: 0.04282655566930771
step: 70, loss: 0.07402127236127853
step: 80, loss: 0.07485876977443695
step: 90, loss: 0.009919950738549232
step: 100, loss: 0.07620786130428314
step: 110, loss: 0.042530253529548645
step: 120, loss: 0.011133994907140732
step: 130, loss: 0.0800136998295784
step: 140, loss: 0.0001124777554650791
step: 150, loss: 0.1174798235297203
step: 160, loss: 0.0786273181438446
step: 170, loss: 0.01002029050141573
step: 180, loss: 0.027056599035859108
step: 190, loss: 0.15895132720470428
step: 200, loss: 0.2282029092311859
step: 210, loss: 0.0063839866779744625
step: 220, loss: 0.12040878087282181
step: 230, loss: 0.07329722493886948
step: 240, loss: 0.05028613284230232
step: 250, loss: 0.06397402286529541
step: 260, loss: 0.10445838421583176
step: 270, loss: 0.05630993843078613
step: 280, loss: 0.08740805834531784
step: 290, loss: 0.14185914397239685
step: 300, loss: 0.0650557428598404
step: 310, loss: 0.020458724349737167
step: 320, loss: 0.006696875672787428
step: 330, loss: 0.06676626950502396
step: 340, loss: 0.035405222326517105
step: 350, loss: 0.04348073899745941
step: 360, loss: 0.06249736249446869
step: 370, loss: 0.03870279714465141
step: 380, loss: 0.13172481954097748
step: 390, loss: 0.005922967102378607
step: 400, loss: 0.009324081242084503
step: 410, loss: 0.025536425411701202
step: 420, loss: 0.02241493947803974
step: 430, loss: 0.01141765434294939
step: 440, loss: 0.14856357872486115
step: 450, loss: 0.01313729863613844
step: 460, loss: 0.05942158028483391
epoch 5: dev_f1=0.9899441340782122, f1=0.9843749999999999, best_f1=0.9807474518686297
step: 0, loss: 0.10373956710100174
step: 10, loss: 0.050269726663827896
step: 20, loss: 0.05945282056927681
step: 30, loss: 0.00636557349935174
step: 40, loss: 0.019214406609535217
step: 50, loss: 0.13600406050682068
step: 60, loss: 0.057207077741622925
step: 70, loss: 0.0018653394654393196
step: 80, loss: 0.14813069999217987
step: 90, loss: 0.13597147166728973
step: 100, loss: 0.018306734040379524
step: 110, loss: 0.01277877762913704
step: 120, loss: 0.07773197442293167
step: 130, loss: 0.012009317986667156
step: 140, loss: 0.006884453352540731
step: 150, loss: 0.0789269283413887
step: 160, loss: 0.011358107440173626
step: 170, loss: 0.010800491087138653
step: 180, loss: 0.12745694816112518
step: 190, loss: 0.08107298612594604
step: 200, loss: 0.025756046175956726
step: 210, loss: 0.03887748718261719
step: 220, loss: 0.1486220359802246
step: 230, loss: 0.00037239392986521125
step: 240, loss: 0.12760572135448456
step: 250, loss: 0.07262361794710159
step: 260, loss: 0.01177268661558628
step: 270, loss: 0.07138222455978394
step: 280, loss: 0.013768628239631653
step: 290, loss: 0.0318169929087162
step: 300, loss: 0.12543612718582153
step: 310, loss: 0.021103844046592712
step: 320, loss: 0.0905836671590805
step: 330, loss: 0.0005958050605840981
step: 340, loss: 0.00666454853489995
step: 350, loss: 0.014122076332569122
step: 360, loss: 0.010288913734257221
step: 370, loss: 0.005751198157668114
step: 380, loss: 0.030454499647021294
step: 390, loss: 0.08585315942764282
step: 400, loss: 0.005868986714631319
step: 410, loss: 0.008061930537223816
step: 420, loss: 0.1097688302397728
step: 430, loss: 0.00835446547716856
step: 440, loss: 0.26570650935173035
step: 450, loss: 0.06767047941684723
step: 460, loss: 0.026281457394361496
epoch 6: dev_f1=0.992108229988726, f1=0.9807037457434733, best_f1=0.9807474518686297
step: 0, loss: 0.0790625661611557
step: 10, loss: 0.02175149694085121
step: 20, loss: 0.0880160704255104
step: 30, loss: 0.14993321895599365
step: 40, loss: 0.027381617575883865
step: 50, loss: 0.05787203833460808
step: 60, loss: 0.09641943871974945
step: 70, loss: 0.006917583756148815
step: 80, loss: 0.04572873190045357
step: 90, loss: 0.06165776029229164
step: 100, loss: 0.06417758762836456
step: 110, loss: 0.019369900226593018
step: 120, loss: 0.008531556464731693
step: 130, loss: 3.3939035347430035e-05
step: 140, loss: 0.09733844548463821
step: 150, loss: 0.1515624076128006
step: 160, loss: 0.060958266258239746
step: 170, loss: 0.009485088288784027
step: 180, loss: 0.0537378191947937
step: 190, loss: 0.03876078501343727
step: 200, loss: 0.013587991707026958
step: 210, loss: 0.10351324826478958
step: 220, loss: 0.007922305725514889
step: 230, loss: 0.06391573697328568
step: 240, loss: 0.008329623378813267
step: 250, loss: 0.01768399402499199
step: 260, loss: 0.06795432418584824
step: 270, loss: 0.012679096311330795
step: 280, loss: 0.15100640058517456
step: 290, loss: 0.10268726199865341
step: 300, loss: 0.10073862224817276
step: 310, loss: 0.11149876564741135
step: 320, loss: 0.00013324714382179081
step: 330, loss: 0.010650986805558205
step: 340, loss: 0.08075883239507675
step: 350, loss: 0.00527427950873971
step: 360, loss: 0.032137181609869
step: 370, loss: 0.06444701552391052
step: 380, loss: 0.007958860136568546
step: 390, loss: 0.40352609753608704
step: 400, loss: 0.015970204025506973
step: 410, loss: 0.11228885501623154
step: 420, loss: 0.07266229391098022
step: 430, loss: 0.03399350121617317
step: 440, loss: 0.08367584645748138
step: 450, loss: 0.0825926885008812
step: 460, loss: 0.054599322378635406
epoch 7: dev_f1=0.9943630214205187, f1=0.9864559819413092, best_f1=0.9864559819413092
step: 0, loss: 0.060541652143001556
step: 10, loss: 0.06251361221075058
step: 20, loss: 0.07938869297504425
step: 30, loss: 0.0038401505444198847
step: 40, loss: 0.025056984275579453
step: 50, loss: 0.01288443710654974
step: 60, loss: 0.046271223574876785
step: 70, loss: 0.01870666816830635
step: 80, loss: 0.13417434692382812
step: 90, loss: 0.008068565279245377
step: 100, loss: 0.14294733107089996
step: 110, loss: 0.11777888238430023
step: 120, loss: 0.11780163645744324
step: 130, loss: 0.09476613998413086
step: 140, loss: 0.08152171224355698
step: 150, loss: 0.0412735752761364
step: 160, loss: 0.006977291312068701
step: 170, loss: 0.005556774791330099
step: 180, loss: 0.027670927345752716
step: 190, loss: 0.015371640212833881
step: 200, loss: 0.05249040946364403
step: 210, loss: 0.039108674973249435
step: 220, loss: 0.10218305140733719
step: 230, loss: 0.1837998330593109
step: 240, loss: 0.01647508330643177
step: 250, loss: 0.00010020052286563441
step: 260, loss: 0.11043205857276917
step: 270, loss: 0.08844549208879471
step: 280, loss: 0.010109136812388897
step: 290, loss: 0.060454487800598145
step: 300, loss: 0.16375431418418884
step: 310, loss: 0.012427338398993015
step: 320, loss: 0.21956458687782288
step: 330, loss: 0.12460681051015854
step: 340, loss: 0.006767251994460821
step: 350, loss: 0.044045593589544296
step: 360, loss: 0.018376262858510017
step: 370, loss: 0.013182135298848152
step: 380, loss: 0.0717838853597641
step: 390, loss: 0.07328926771879196
step: 400, loss: 0.007257189601659775
step: 410, loss: 0.014745828695595264
step: 420, loss: 0.11943669617176056
step: 430, loss: 0.024666810408234596
step: 440, loss: 7.518201891798526e-05
step: 450, loss: 0.055884018540382385
step: 460, loss: 0.025713076815009117
epoch 8: dev_f1=0.9954853273137697, f1=0.9841628959276018, best_f1=0.9841628959276018
step: 0, loss: 0.02419368177652359
step: 10, loss: 0.015875525772571564
step: 20, loss: 0.10360030829906464
step: 30, loss: 0.07096099853515625
step: 40, loss: 0.011630658060312271
step: 50, loss: 0.00956830196082592
step: 60, loss: 0.015615185722708702
step: 70, loss: 0.009929919615387917
step: 80, loss: 0.09241995215415955
step: 90, loss: 0.07359869033098221
step: 100, loss: 0.008710845373570919
step: 110, loss: 0.0382215790450573
step: 120, loss: 0.09900885075330734
step: 130, loss: 0.046409863978624344
step: 140, loss: 0.04107504338026047
step: 150, loss: 0.023019619286060333
step: 160, loss: 0.0003273743495810777
step: 170, loss: 0.08171262592077255
step: 180, loss: 0.024367619305849075
step: 190, loss: 0.02430017478764057
step: 200, loss: 0.0006694244220852852
step: 210, loss: 0.03431445732712746
step: 220, loss: 0.09431476145982742
step: 230, loss: 0.018352758139371872
step: 240, loss: 0.017950715497136116
step: 250, loss: 0.014309708960354328
step: 260, loss: 0.012897024862468243
step: 270, loss: 0.05494258180260658
step: 280, loss: 0.03082168847322464
step: 290, loss: 0.01001262478530407
step: 300, loss: 0.020072393119335175
step: 310, loss: 0.08186958730220795
step: 320, loss: 0.003956317901611328
step: 330, loss: 0.002199915936216712
step: 340, loss: 0.08675295859575272
step: 350, loss: 0.13596074283123016
step: 360, loss: 0.012694689445197582
step: 370, loss: 0.01902986876666546
step: 380, loss: 0.023001326248049736
step: 390, loss: 0.05296621099114418
step: 400, loss: 0.041578762233257294
step: 410, loss: 0.07906007021665573
step: 420, loss: 0.008473029360175133
step: 430, loss: 0.0027538728900253773
step: 440, loss: 0.021635418757796288
step: 450, loss: 0.0847117230296135
step: 460, loss: 0.04119938984513283
epoch 9: dev_f1=0.9943630214205187, f1=0.9809203142536477, best_f1=0.9841628959276018
step: 0, loss: 0.016114581376314163
step: 10, loss: 0.03704448044300079
step: 20, loss: 0.019061770290136337
step: 30, loss: 0.005705407354980707
step: 40, loss: 0.017604917287826538
step: 50, loss: 0.0459098182618618
step: 60, loss: 0.009719997644424438
step: 70, loss: 0.03935703635215759
step: 80, loss: 0.011261445470154285
step: 90, loss: 0.007407776545733213
step: 100, loss: 0.028788719326257706
step: 110, loss: 0.13538555800914764
step: 120, loss: 0.009820816107094288
step: 130, loss: 0.0060903108678758144
step: 140, loss: 0.006244336720556021
step: 150, loss: 0.004063159693032503
step: 160, loss: 0.039809707552194595
step: 170, loss: 0.04236770048737526
step: 180, loss: 0.04525928944349289
step: 190, loss: 0.02664032019674778
step: 200, loss: 0.016514349728822708
step: 210, loss: 0.0542534664273262
step: 220, loss: 0.04062114283442497
step: 230, loss: 0.007566113490611315
step: 240, loss: 0.0003095952561125159
step: 250, loss: 0.1252320259809494
step: 260, loss: 0.047248002141714096
step: 270, loss: 0.0022342007141560316
step: 280, loss: 0.0026471400633454323
step: 290, loss: 0.07358069717884064
step: 300, loss: 0.00974944792687893
step: 310, loss: 0.005514965858310461
step: 320, loss: 0.060615770518779755
step: 330, loss: 0.1467047780752182
step: 340, loss: 0.04826226830482483
step: 350, loss: 0.07407670468091965
step: 360, loss: 0.057420164346694946
step: 370, loss: 0.04352779686450958
step: 380, loss: 0.005547710694372654
step: 390, loss: 0.011116587556898594
step: 400, loss: 0.00803138967603445
step: 410, loss: 0.052594274282455444
step: 420, loss: 0.014937165193259716
step: 430, loss: 0.01046872790902853
step: 440, loss: 0.022157015278935432
step: 450, loss: 0.013305431231856346
step: 460, loss: 0.0059981015510857105
epoch 10: dev_f1=0.9932432432432432, f1=0.9775280898876404, best_f1=0.9841628959276018
step: 0, loss: 0.04443087801337242
step: 10, loss: 0.06330626457929611
step: 20, loss: 0.03205908462405205
step: 30, loss: 0.034876104444265366
step: 40, loss: 0.07038690894842148
step: 50, loss: 0.1044042631983757
step: 60, loss: 0.06641991436481476
step: 70, loss: 0.0068904934450984
step: 80, loss: 0.016659200191497803
step: 90, loss: 0.026329953223466873
step: 100, loss: 0.02326633781194687
step: 110, loss: 0.047872599214315414
step: 120, loss: 0.04614121839404106
step: 130, loss: 0.024192674085497856
step: 140, loss: 0.014145126566290855
step: 150, loss: 0.0005739370244555175
step: 160, loss: 0.06673308461904526
step: 170, loss: 0.020041396841406822
step: 180, loss: 0.04858682304620743
step: 190, loss: 0.010211315006017685
step: 200, loss: 0.059881679713726044
step: 210, loss: 0.0304277241230011
step: 220, loss: 0.0012208075495436788
step: 230, loss: 0.022419990971684456
step: 240, loss: 0.005369794089347124
step: 250, loss: 0.027723446488380432
step: 260, loss: 0.035043902695178986
step: 270, loss: 0.012183199636638165
step: 280, loss: 0.006390197668224573
step: 290, loss: 0.13305729627609253
step: 300, loss: 0.0014645842602476478
step: 310, loss: 0.006900581531226635
step: 320, loss: 0.02433484047651291
step: 330, loss: 0.08039331436157227
step: 340, loss: 0.03969314321875572
step: 350, loss: 0.015756627544760704
step: 360, loss: 0.002176634967327118
step: 370, loss: 0.05823338404297829
step: 380, loss: 0.012090514414012432
step: 390, loss: 0.045628245919942856
step: 400, loss: 0.019139019772410393
step: 410, loss: 0.06465038657188416
step: 420, loss: 0.0029199286364018917
step: 430, loss: 0.06272707134485245
step: 440, loss: 0.10731354355812073
step: 450, loss: 0.033656906336545944
step: 460, loss: 0.0194723978638649
epoch 11: dev_f1=0.9909706546275394, f1=0.9830124575311437, best_f1=0.9841628959276018
step: 0, loss: 0.0003602129581850022
step: 10, loss: 0.0723208487033844
step: 20, loss: 0.03955695405602455
step: 30, loss: 0.08039422333240509
step: 40, loss: 0.013932495377957821
step: 50, loss: 0.050022684037685394
step: 60, loss: 0.01270294189453125
step: 70, loss: 0.008889560587704182
step: 80, loss: 0.029306896030902863
step: 90, loss: 0.008090382441878319
step: 100, loss: 0.02584780380129814
step: 110, loss: 0.022878531366586685
step: 120, loss: 0.0001381906622555107
step: 130, loss: 0.0005753301084041595
step: 140, loss: 0.07539301365613937
step: 150, loss: 0.04451670125126839
step: 160, loss: 0.03748897463083267
step: 170, loss: 0.017898978665471077
step: 180, loss: 0.16928313672542572
step: 190, loss: 0.0004031965509057045
step: 200, loss: 0.15114203095436096
step: 210, loss: 0.003551098983734846
step: 220, loss: 0.029131928458809853
step: 230, loss: 0.05626218765974045
step: 240, loss: 0.04086236283183098
step: 250, loss: 0.10029875487089157
step: 260, loss: 0.022472558543086052
step: 270, loss: 0.009325727820396423
step: 280, loss: 0.028148988261818886
step: 290, loss: 0.05758261680603027
step: 300, loss: 0.0013653866481035948
step: 310, loss: 0.011600480414927006
step: 320, loss: 0.002921057166531682
step: 330, loss: 0.03350646421313286
step: 340, loss: 0.05604881793260574
step: 350, loss: 0.061573587357997894
step: 360, loss: 0.07256853580474854
step: 370, loss: 0.04908865690231323
step: 380, loss: 0.00017761884373612702
step: 390, loss: 0.06498514115810394
step: 400, loss: 0.012630615383386612
step: 410, loss: 0.0736384466290474
step: 420, loss: 0.00408210139721632
step: 430, loss: 0.052743203938007355
step: 440, loss: 0.05106401816010475
step: 450, loss: 0.05856581777334213
step: 460, loss: 0.005539926700294018
epoch 12: dev_f1=0.9920903954802259, f1=0.9841986455981941, best_f1=0.9841628959276018
step: 0, loss: 0.10804640501737595
step: 10, loss: 0.0029099630191922188
step: 20, loss: 0.042618829756975174
step: 30, loss: 0.04423733800649643
step: 40, loss: 0.008325734175741673
step: 50, loss: 0.05941443145275116
step: 60, loss: 4.47728561994154e-05
step: 70, loss: 0.003544681938365102
step: 80, loss: 0.000478054687846452
step: 90, loss: 0.009787040762603283
step: 100, loss: 0.04516591504216194
step: 110, loss: 0.07439594715833664
step: 120, loss: 0.026694854721426964
step: 130, loss: 0.03803820535540581
step: 140, loss: 0.010983404703438282
step: 150, loss: 0.00011076610098825768
step: 160, loss: 0.11239302158355713
step: 170, loss: 0.0007647951715625823
step: 180, loss: 0.00012104634515708312
step: 190, loss: 0.01750795915722847
step: 200, loss: 0.0002924065920524299
step: 210, loss: 0.010810058563947678
step: 220, loss: 0.0018074777908623219
step: 230, loss: 0.07908449321985245
step: 240, loss: 0.029670748859643936
step: 250, loss: 0.0012661418877542019
step: 260, loss: 0.009957973845303059
step: 270, loss: 0.0004005607042927295
step: 280, loss: 0.0334085114300251
step: 290, loss: 0.01652400568127632
step: 300, loss: 0.034872982650995255
step: 310, loss: 0.06790734082460403
step: 320, loss: 0.028042303398251534
step: 330, loss: 0.023738130927085876
step: 340, loss: 0.036102451384067535
step: 350, loss: 0.0001023960139718838
step: 360, loss: 0.03787356987595558
step: 370, loss: 0.005205726251006126
step: 380, loss: 0.024783682078123093
step: 390, loss: 3.4865151974372566e-05
step: 400, loss: 0.0006067674257792532
step: 410, loss: 0.04103625565767288
step: 420, loss: 0.0024998271837830544
step: 430, loss: 0.028305407613515854
step: 440, loss: 0.03669143095612526
step: 450, loss: 0.1018921285867691
step: 460, loss: 0.04197688773274422
epoch 13: dev_f1=0.9932432432432432, f1=0.980963045912654, best_f1=0.9841628959276018
step: 0, loss: 0.06659366935491562
step: 10, loss: 0.11046307533979416
step: 20, loss: 0.1353672295808792
step: 30, loss: 0.002049710601568222
step: 40, loss: 0.046641506254673004
step: 50, loss: 0.04301371052861214
step: 60, loss: 0.013314313255250454
step: 70, loss: 0.00042631139513105154
step: 80, loss: 0.034173812717199326
step: 90, loss: 0.012600904330611229
step: 100, loss: 0.025232840329408646
step: 110, loss: 0.001347917946986854
step: 120, loss: 0.029359769076108932
step: 130, loss: 0.06706196814775467
step: 140, loss: 0.004810065031051636
step: 150, loss: 7.01878234394826e-05
step: 160, loss: 0.0194130539894104
step: 170, loss: 0.023479733616113663
step: 180, loss: 0.03317847475409508
step: 190, loss: 0.030178673565387726
step: 200, loss: 0.01697000488638878
step: 210, loss: 0.019430598244071007
step: 220, loss: 0.002882437314838171
step: 230, loss: 0.11371179670095444
step: 240, loss: 0.0002185011253459379
step: 250, loss: 0.03056333214044571
step: 260, loss: 0.0011733522405847907
step: 270, loss: 0.011484280228614807
step: 280, loss: 0.004734564572572708
step: 290, loss: 0.05122201517224312
step: 300, loss: 0.00045468000462278724
step: 310, loss: 0.07171869277954102
step: 320, loss: 0.009349309839308262
step: 330, loss: 0.037026602774858475
step: 340, loss: 0.011834630742669106
step: 350, loss: 0.1980583667755127
step: 360, loss: 0.03138769790530205
step: 370, loss: 0.032909560948610306
step: 380, loss: 0.022933045402169228
step: 390, loss: 0.009143420495092869
step: 400, loss: 0.017200656235218048
step: 410, loss: 0.002044555963948369
step: 420, loss: 0.04563174769282341
step: 430, loss: 0.020960869267582893
step: 440, loss: 0.07111415266990662
step: 450, loss: 0.021532058715820312
step: 460, loss: 0.023207535967230797
epoch 14: dev_f1=0.9943630214205187, f1=0.9821029082774049, best_f1=0.9841628959276018
step: 0, loss: 0.0035949251614511013
step: 10, loss: 0.04430684819817543
step: 20, loss: 0.003911405801773071
step: 30, loss: 0.08801624178886414
step: 40, loss: 0.009480314329266548
step: 50, loss: 0.028305256739258766
step: 60, loss: 0.0016372953541576862
step: 70, loss: 0.035071056336164474
step: 80, loss: 0.05753686651587486
step: 90, loss: 0.06540871411561966
step: 100, loss: 0.04392307251691818
step: 110, loss: 0.0458589643239975
step: 120, loss: 0.02637520059943199
step: 130, loss: 0.08460906893014908
step: 140, loss: 0.06773504614830017
step: 150, loss: 0.05723069608211517
step: 160, loss: 0.009350328706204891
step: 170, loss: 0.0005124977906234562
step: 180, loss: 0.0003848194901365787
step: 190, loss: 0.0007243865984492004
step: 200, loss: 0.04292651638388634
step: 210, loss: 0.03781440481543541
step: 220, loss: 0.0001258409902220592
step: 230, loss: 0.018824869766831398
step: 240, loss: 0.040305979549884796
step: 250, loss: 0.0023925628047436476
step: 260, loss: 7.33159831725061e-05
step: 270, loss: 0.03325768560171127
step: 280, loss: 0.0010710243368521333
step: 290, loss: 0.0203787162899971
step: 300, loss: 0.025220323354005814
step: 310, loss: 0.0005863108672201633
step: 320, loss: 7.446105155395344e-05
step: 330, loss: 0.017069103196263313
step: 340, loss: 0.08924680203199387
step: 350, loss: 0.023634666576981544
step: 360, loss: 0.005144448485225439
step: 370, loss: 0.0015807548770681024
step: 380, loss: 0.0886499360203743
step: 390, loss: 0.05668546259403229
step: 400, loss: 0.027852648869156837
step: 410, loss: 0.005699864123016596
step: 420, loss: 0.06318984180688858
step: 430, loss: 0.04149411991238594
step: 440, loss: 7.507253758376464e-05
step: 450, loss: 0.05093732476234436
step: 460, loss: 0.0003189287963323295
epoch 15: dev_f1=0.9943630214205187, f1=0.9809203142536477, best_f1=0.9841628959276018
step: 0, loss: 0.03827038034796715
step: 10, loss: 0.06841471791267395
step: 20, loss: 0.012871377170085907
step: 30, loss: 0.05873047187924385
step: 40, loss: 0.03397199884057045
step: 50, loss: 0.03298022598028183
step: 60, loss: 0.07629726082086563
step: 70, loss: 0.0256645567715168
step: 80, loss: 0.04655367508530617
step: 90, loss: 0.11084252595901489
step: 100, loss: 0.03410881385207176
step: 110, loss: 0.0006643202505074441
step: 120, loss: 0.04555446654558182
step: 130, loss: 0.00021976447897031903
step: 140, loss: 0.03554270416498184
step: 150, loss: 0.004842010326683521
step: 160, loss: 0.001166449161246419
step: 170, loss: 0.00013548298738896847
step: 180, loss: 0.024855943396687508
step: 190, loss: 0.03162545710802078
step: 200, loss: 0.00042680432670749724
step: 210, loss: 0.03708832710981369
step: 220, loss: 0.03633924573659897
step: 230, loss: 0.006382023449987173
step: 240, loss: 0.04759775847196579
step: 250, loss: 0.020092055201530457
step: 260, loss: 0.02080862782895565
step: 270, loss: 0.029549792408943176
step: 280, loss: 0.021536393091082573
step: 290, loss: 0.04555543512105942
step: 300, loss: 0.03144792839884758
step: 310, loss: 0.01304175890982151
step: 320, loss: 0.0365220382809639
step: 330, loss: 0.03422652184963226
step: 340, loss: 0.034186843782663345
step: 350, loss: 0.06003666669130325
step: 360, loss: 0.03594879060983658
step: 370, loss: 0.0006466195918619633
step: 380, loss: 0.08738905191421509
step: 390, loss: 0.03663458675146103
step: 400, loss: 0.00024636389571242034
step: 410, loss: 0.03537154570221901
step: 420, loss: 0.15542960166931152
step: 430, loss: 0.00012991303810849786
step: 440, loss: 0.03026742860674858
step: 450, loss: 0.007225903682410717
step: 460, loss: 0.0689627155661583
epoch 16: dev_f1=0.9943630214205187, f1=0.9832026875699889, best_f1=0.9841628959276018
step: 0, loss: 5.39254724571947e-05
step: 10, loss: 0.000430209533078596
step: 20, loss: 0.00015777844237163663
step: 30, loss: 0.07846065610647202
step: 40, loss: 0.0007283121813088655
step: 50, loss: 0.003492891788482666
step: 60, loss: 0.020783783867955208
step: 70, loss: 0.06637285649776459
step: 80, loss: 0.017375720664858818
step: 90, loss: 0.016360443085432053
step: 100, loss: 0.022064054384827614
step: 110, loss: 0.08565697073936462
step: 120, loss: 3.4244629205204546e-05
step: 130, loss: 0.04184852913022041
step: 140, loss: 0.06033681705594063
step: 150, loss: 0.0020747450180351734
step: 160, loss: 0.021674541756510735
step: 170, loss: 0.00939098745584488
step: 180, loss: 0.03221346437931061
step: 190, loss: 0.008118705824017525
step: 200, loss: 0.04575781524181366
step: 210, loss: 0.013238316401839256
step: 220, loss: 0.02370220422744751
step: 230, loss: 6.60069563309662e-05
step: 240, loss: 0.0463801771402359
step: 250, loss: 0.08069527894258499
step: 260, loss: 3.9949052734300494e-05
step: 270, loss: 0.09487973153591156
step: 280, loss: 0.04426110163331032
step: 290, loss: 0.0444222055375576
step: 300, loss: 9.75799048319459e-05
step: 310, loss: 0.015421590767800808
step: 320, loss: 3.1133364245761186e-05
step: 330, loss: 0.0012562839547172189
step: 340, loss: 0.019113389775156975
step: 350, loss: 0.027159377932548523
step: 360, loss: 0.002336192410439253
step: 370, loss: 0.00045083611621521413
step: 380, loss: 0.03854796662926674
step: 390, loss: 0.014052103273570538
step: 400, loss: 2.596431841084268e-05
step: 410, loss: 0.033339083194732666
step: 420, loss: 0.029861614108085632
step: 430, loss: 0.11904466897249222
step: 440, loss: 0.05749424919486046
step: 450, loss: 0.01694159209728241
step: 460, loss: 0.06866704672574997
epoch 17: dev_f1=0.9943630214205187, f1=0.9832026875699889, best_f1=0.9841628959276018
step: 0, loss: 0.0120090302079916
step: 10, loss: 0.06256045401096344
step: 20, loss: 0.03177748993039131
step: 30, loss: 0.04010036587715149
step: 40, loss: 3.99689597543329e-05
step: 50, loss: 0.015495287254452705
step: 60, loss: 0.04011215269565582
step: 70, loss: 0.02869138866662979
step: 80, loss: 4.194720895611681e-05
step: 90, loss: 8.386762056034058e-05
step: 100, loss: 0.020853476598858833
step: 110, loss: 0.01852102391421795
step: 120, loss: 0.02436966262757778
step: 130, loss: 0.03437613323330879
step: 140, loss: 0.02443586476147175
step: 150, loss: 0.01313591655343771
step: 160, loss: 0.0036216448061168194
step: 170, loss: 0.020849835127592087
step: 180, loss: 0.030377399176359177
step: 190, loss: 0.02812364138662815
step: 200, loss: 0.00021638571342919022
step: 210, loss: 0.02696748822927475
step: 220, loss: 0.01793687231838703
step: 230, loss: 2.2551144866156392e-05
step: 240, loss: 0.035839058458805084
step: 250, loss: 0.020633473992347717
step: 260, loss: 4.4348857045406476e-05
step: 270, loss: 0.07384451478719711
step: 280, loss: 0.0017358431359753013
step: 290, loss: 0.05528115853667259
step: 300, loss: 0.0015757668297737837
step: 310, loss: 0.0002363682142458856
step: 320, loss: 5.9481357311597094e-05
step: 330, loss: 0.04030761122703552
step: 340, loss: 0.0292806439101696
step: 350, loss: 9.91272900137119e-05
step: 360, loss: 0.0008014392224140465
step: 370, loss: 0.012634511105716228
step: 380, loss: 0.02509317733347416
step: 390, loss: 0.011015917174518108
step: 400, loss: 0.049167267978191376
step: 410, loss: 0.021172476932406425
step: 420, loss: 0.061609525233507156
step: 430, loss: 0.06457189470529556
step: 440, loss: 0.022777611389756203
step: 450, loss: 5.8908743085339665e-05
step: 460, loss: 0.02245139144361019
epoch 18: dev_f1=0.9943630214205187, f1=0.9832026875699889, best_f1=0.9841628959276018
step: 0, loss: 0.05354313179850578
step: 10, loss: 3.6419834941625595e-05
step: 20, loss: 0.03997126966714859
step: 30, loss: 3.4281169064342976e-05
step: 40, loss: 0.041937511414289474
step: 50, loss: 0.00043106795055791736
step: 60, loss: 0.13019198179244995
step: 70, loss: 0.029519300907850266
step: 80, loss: 0.041508179157972336
step: 90, loss: 0.027055850252509117
step: 100, loss: 0.017537284642457962
step: 110, loss: 0.0044074710458517075
step: 120, loss: 1.5854573575779796e-05
step: 130, loss: 0.02976043149828911
step: 140, loss: 0.05212942510843277
step: 150, loss: 0.0007663884316571057
step: 160, loss: 2.6533818527241237e-05
step: 170, loss: 0.017924237996339798
step: 180, loss: 0.001597140566445887
step: 190, loss: 2.5799585273489356e-05
step: 200, loss: 0.012699812650680542
step: 210, loss: 0.007463063113391399
step: 220, loss: 5.2254465117584914e-05
step: 230, loss: 0.02532757632434368
step: 240, loss: 0.047865502536296844
step: 250, loss: 9.255563782062382e-05
step: 260, loss: 9.34633135329932e-05
step: 270, loss: 0.0194125734269619
step: 280, loss: 8.830695878714323e-05
step: 290, loss: 3.910764280590229e-05
step: 300, loss: 0.05442630499601364
step: 310, loss: 0.0011659972369670868
step: 320, loss: 0.01226565521210432
step: 330, loss: 3.8118145312182605e-05
step: 340, loss: 0.06430113315582275
step: 350, loss: 0.012054222635924816
step: 360, loss: 3.722396650118753e-05
step: 370, loss: 0.03910135105252266
step: 380, loss: 0.017708536237478256
step: 390, loss: 0.021250510588288307
step: 400, loss: 0.00016744082677178085
step: 410, loss: 0.02288568951189518
step: 420, loss: 0.022675354033708572
step: 430, loss: 0.022893210873007774
step: 440, loss: 4.230705962982029e-05
step: 450, loss: 1.69422182807466e-05
step: 460, loss: 0.0263197124004364
epoch 19: dev_f1=0.9943630214205187, f1=0.9832026875699889, best_f1=0.9841628959276018
step: 0, loss: 3.0359124139067717e-05
step: 10, loss: 2.3338005121331662e-05
step: 20, loss: 0.043616656213998795
step: 30, loss: 0.012208140455186367
step: 40, loss: 9.581667836755514e-05
step: 50, loss: 0.011093661189079285
step: 60, loss: 2.8161672162241302e-05
step: 70, loss: 0.00019458302995190024
step: 80, loss: 0.0006163415382616222
step: 90, loss: 0.016743669286370277
step: 100, loss: 0.015026772394776344
step: 110, loss: 0.04748428240418434
step: 120, loss: 0.022427277639508247
step: 130, loss: 0.04369336739182472
step: 140, loss: 0.00011489590542623773
step: 150, loss: 0.02254534885287285
step: 160, loss: 3.3234489819733426e-05
step: 170, loss: 0.024895381182432175
step: 180, loss: 0.04474470019340515
step: 190, loss: 0.031003033742308617
step: 200, loss: 0.042348023504018784
step: 210, loss: 2.2730970158590935e-05
step: 220, loss: 0.024455837905406952
step: 230, loss: 0.0179681908339262
step: 240, loss: 0.012547601945698261
step: 250, loss: 1.5422425349242985e-05
step: 260, loss: 5.7337161706527695e-05
step: 270, loss: 0.02568136341869831
step: 280, loss: 0.0001025051242322661
step: 290, loss: 5.3083284001331776e-05
step: 300, loss: 0.032512418925762177
step: 310, loss: 0.028284048661589622
step: 320, loss: 0.01273768488317728
step: 330, loss: 9.534813580103219e-05
step: 340, loss: 4.656349483411759e-05
step: 350, loss: 4.53578686574474e-05
step: 360, loss: 3.3248943509534e-05
step: 370, loss: 6.462078454205766e-05
step: 380, loss: 0.02684216946363449
step: 390, loss: 8.398236241191626e-05
step: 400, loss: 0.020630069077014923
step: 410, loss: 4.720078140962869e-05
step: 420, loss: 0.04127638041973114
step: 430, loss: 0.019737757742404938
step: 440, loss: 3.454974284977652e-05
step: 450, loss: 0.034878700971603394
step: 460, loss: 0.005794065538793802
epoch 20: dev_f1=0.9943630214205187, f1=0.9832026875699889, best_f1=0.9841628959276018
