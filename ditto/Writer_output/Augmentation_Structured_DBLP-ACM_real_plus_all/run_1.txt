cuda
Device: cuda
step: 0, loss: 0.7293429374694824
step: 10, loss: 0.6537886261940002
step: 20, loss: 0.4754377007484436
step: 30, loss: 0.29311633110046387
step: 40, loss: 0.364992618560791
step: 50, loss: 0.2330009639263153
step: 60, loss: 0.09912464767694473
step: 70, loss: 0.13917365670204163
step: 80, loss: 0.16910238564014435
step: 90, loss: 0.1845797300338745
step: 100, loss: 0.20724299550056458
step: 110, loss: 0.27854397892951965
step: 120, loss: 0.10834861546754837
step: 130, loss: 0.10962186753749847
step: 140, loss: 0.05394391342997551
step: 150, loss: 0.09825969487428665
step: 160, loss: 0.12417175620794296
step: 170, loss: 0.10572649538516998
step: 180, loss: 0.10452289134263992
step: 190, loss: 0.1206260696053505
step: 200, loss: 0.1123853400349617
step: 210, loss: 0.11853276193141937
step: 220, loss: 0.029026903212070465
step: 230, loss: 0.11366093903779984
step: 240, loss: 0.20634083449840546
step: 250, loss: 0.2531910538673401
step: 260, loss: 0.2366294115781784
step: 270, loss: 0.09237215667963028
step: 280, loss: 0.25990065932273865
step: 290, loss: 0.11337718367576599
step: 300, loss: 0.09646869450807571
step: 310, loss: 0.0677822157740593
step: 320, loss: 0.12634015083312988
step: 330, loss: 0.22222226858139038
step: 340, loss: 0.03824842348694801
step: 350, loss: 0.05631299689412117
step: 360, loss: 0.05335365980863571
step: 370, loss: 0.06154869496822357
step: 380, loss: 0.052498795092105865
step: 390, loss: 0.10199796408414841
step: 400, loss: 0.07362581044435501
step: 410, loss: 0.04619235545396805
step: 420, loss: 0.10257583111524582
step: 430, loss: 0.1963910460472107
step: 440, loss: 0.03755415976047516
step: 450, loss: 0.12601454555988312
step: 460, loss: 0.030419372022151947
epoch 1: dev_f1=0.9876543209876544, f1=0.9853107344632768, best_f1=0.9853107344632768
step: 0, loss: 0.01532807108014822
step: 10, loss: 0.09982989728450775
step: 20, loss: 0.10522481054067612
step: 30, loss: 0.14533057808876038
step: 40, loss: 0.11532286554574966
step: 50, loss: 0.049732599407434464
step: 60, loss: 0.09933851659297943
step: 70, loss: 0.04714592173695564
step: 80, loss: 0.24563421308994293
step: 90, loss: 0.07890567928552628
step: 100, loss: 0.009074277244508266
step: 110, loss: 0.0005445820279419422
step: 120, loss: 0.13992461562156677
step: 130, loss: 0.033121660351753235
step: 140, loss: 0.02620587684214115
step: 150, loss: 0.03826026991009712
step: 160, loss: 0.021677132695913315
step: 170, loss: 0.11721694469451904
step: 180, loss: 0.15237370133399963
step: 190, loss: 0.07796360552310944
step: 200, loss: 0.029760099947452545
step: 210, loss: 0.017366841435432434
step: 220, loss: 0.13191530108451843
step: 230, loss: 0.038870032876729965
step: 240, loss: 0.11376304924488068
step: 250, loss: 0.06893792748451233
step: 260, loss: 0.05361451581120491
step: 270, loss: 0.03758156672120094
step: 280, loss: 0.03406590595841408
step: 290, loss: 0.11342146247625351
step: 300, loss: 0.12257350236177444
step: 310, loss: 0.12281111627817154
step: 320, loss: 0.01782691292464733
step: 330, loss: 0.07218174636363983
step: 340, loss: 0.012303467839956284
step: 350, loss: 0.14694063365459442
step: 360, loss: 0.03803674131631851
step: 370, loss: 0.06632813066244125
step: 380, loss: 0.08445622026920319
step: 390, loss: 0.07026542723178864
step: 400, loss: 0.037884727120399475
step: 410, loss: 0.12432737648487091
step: 420, loss: 0.01964002475142479
step: 430, loss: 0.0699981302022934
step: 440, loss: 0.08482617884874344
step: 450, loss: 0.044206276535987854
step: 460, loss: 0.02651025541126728
epoch 2: dev_f1=0.9898989898989898, f1=0.9810055865921787, best_f1=0.9810055865921787
step: 0, loss: 0.0282367505133152
step: 10, loss: 0.009981677867472172
step: 20, loss: 0.13890649378299713
step: 30, loss: 0.000929325120523572
step: 40, loss: 0.013493509963154793
step: 50, loss: 0.007127877790480852
step: 60, loss: 0.030367527157068253
step: 70, loss: 0.0627242848277092
step: 80, loss: 0.08121366798877716
step: 90, loss: 0.04530707374215126
step: 100, loss: 0.10492142289876938
step: 110, loss: 0.012648622505366802
step: 120, loss: 0.07531630247831345
step: 130, loss: 0.046128157526254654
step: 140, loss: 0.014383009634912014
step: 150, loss: 0.00099446892272681
step: 160, loss: 0.17695380747318268
step: 170, loss: 0.02542860619723797
step: 180, loss: 0.019834361970424652
step: 190, loss: 0.008588249795138836
step: 200, loss: 0.05112159252166748
step: 210, loss: 0.07436449080705643
step: 220, loss: 0.02009289711713791
step: 230, loss: 0.22477997839450836
step: 240, loss: 0.0268469899892807
step: 250, loss: 0.12590856850147247
step: 260, loss: 0.08170910179615021
step: 270, loss: 0.03130420669913292
step: 280, loss: 0.031448058784008026
step: 290, loss: 0.013646169565618038
step: 300, loss: 0.0929112359881401
step: 310, loss: 0.13534899055957794
step: 320, loss: 0.02257986180484295
step: 330, loss: 0.04487929493188858
step: 340, loss: 0.018875716254115105
step: 350, loss: 0.1308882087469101
step: 360, loss: 0.015923192724585533
step: 370, loss: 0.021546557545661926
step: 380, loss: 0.011148606427013874
step: 390, loss: 0.06621123105287552
step: 400, loss: 0.060294948518276215
step: 410, loss: 0.07294987887144089
step: 420, loss: 0.14787191152572632
step: 430, loss: 0.027362270280718803
step: 440, loss: 0.06108244135975838
step: 450, loss: 0.08140338957309723
step: 460, loss: 0.0230952687561512
epoch 3: dev_f1=0.9898989898989898, f1=0.9798206278026906, best_f1=0.9810055865921787
step: 0, loss: 0.07279712706804276
step: 10, loss: 0.11470401287078857
step: 20, loss: 0.021239394322037697
step: 30, loss: 0.02221369743347168
step: 40, loss: 0.009318477474153042
step: 50, loss: 0.023221125826239586
step: 60, loss: 0.1891171783208847
step: 70, loss: 0.12466862797737122
step: 80, loss: 0.0514831617474556
step: 90, loss: 0.030066922307014465
step: 100, loss: 0.03613247722387314
step: 110, loss: 0.04277261346578598
step: 120, loss: 0.06100207567214966
step: 130, loss: 0.080750472843647
step: 140, loss: 0.035928841680288315
step: 150, loss: 0.05710563436150551
step: 160, loss: 0.03836826607584953
step: 170, loss: 0.15615949034690857
step: 180, loss: 0.09242599457502365
step: 190, loss: 0.16672615706920624
step: 200, loss: 0.022504448890686035
step: 210, loss: 0.2712002992630005
step: 220, loss: 0.14077112078666687
step: 230, loss: 0.030335724353790283
step: 240, loss: 0.0007178412051871419
step: 250, loss: 0.009778468869626522
step: 260, loss: 0.09281058609485626
step: 270, loss: 0.06623204797506332
step: 280, loss: 0.0243978314101696
step: 290, loss: 0.02286241017282009
step: 300, loss: 0.12340202182531357
step: 310, loss: 0.037988729774951935
step: 320, loss: 0.027905995026230812
step: 330, loss: 0.05441487580537796
step: 340, loss: 0.05979221314191818
step: 350, loss: 0.10551126301288605
step: 360, loss: 0.011775157414376736
step: 370, loss: 0.07014540582895279
step: 380, loss: 0.028137817978858948
step: 390, loss: 0.09060350060462952
step: 400, loss: 0.07120027393102646
step: 410, loss: 0.02886955626308918
step: 420, loss: 0.056124042719602585
step: 430, loss: 0.07286886870861053
step: 440, loss: 0.033473704010248184
step: 450, loss: 0.06882178038358688
step: 460, loss: 0.04165913537144661
epoch 4: dev_f1=0.9876819708846584, f1=0.9754464285714286, best_f1=0.9810055865921787
step: 0, loss: 0.07892011851072311
step: 10, loss: 0.05567547306418419
step: 20, loss: 0.00551825575530529
step: 30, loss: 0.11310314387083054
step: 40, loss: 0.06348869204521179
step: 50, loss: 0.017639879137277603
step: 60, loss: 0.07475630939006805
step: 70, loss: 0.01687632128596306
step: 80, loss: 0.10064176470041275
step: 90, loss: 0.0030048240441828966
step: 100, loss: 0.22561506927013397
step: 110, loss: 0.06235051155090332
step: 120, loss: 0.14883334934711456
step: 130, loss: 0.09545502066612244
step: 140, loss: 0.11722452193498611
step: 150, loss: 0.030902370810508728
step: 160, loss: 0.01983438804745674
step: 170, loss: 0.010786015540361404
step: 180, loss: 0.07348243147134781
step: 190, loss: 0.04546934738755226
step: 200, loss: 0.04413307085633278
step: 210, loss: 0.062455035746097565
step: 220, loss: 0.0761716365814209
step: 230, loss: 0.08121407777070999
step: 240, loss: 0.2189694046974182
step: 250, loss: 0.0715070366859436
step: 260, loss: 0.014878330752253532
step: 270, loss: 0.08622068911790848
step: 280, loss: 0.006003404036164284
step: 290, loss: 0.007007341831922531
step: 300, loss: 0.004540510941296816
step: 310, loss: 0.028718557208776474
step: 320, loss: 0.019301865249872208
step: 330, loss: 0.0002383336832281202
step: 340, loss: 0.02381162717938423
step: 350, loss: 0.044109854847192764
step: 360, loss: 0.016129182651638985
step: 370, loss: 0.05803718417882919
step: 380, loss: 0.017286065965890884
step: 390, loss: 0.0549372062087059
step: 400, loss: 0.01022876612842083
step: 410, loss: 0.01762358471751213
step: 420, loss: 0.020027173683047295
step: 430, loss: 0.09828832000494003
step: 440, loss: 0.05891614779829979
step: 450, loss: 0.021889638155698776
step: 460, loss: 0.022947190329432487
epoch 5: dev_f1=0.9910112359550561, f1=0.9843400447427293, best_f1=0.9843400447427293
step: 0, loss: 0.027166971936821938
step: 10, loss: 0.026001213118433952
step: 20, loss: 0.016393903642892838
step: 30, loss: 0.06651332229375839
step: 40, loss: 0.03346969559788704
step: 50, loss: 0.021493006497621536
step: 60, loss: 0.06304898113012314
step: 70, loss: 0.033282894641160965
step: 80, loss: 0.07645417004823685
step: 90, loss: 0.014345790259540081
step: 100, loss: 0.06854287534952164
step: 110, loss: 0.032452575862407684
step: 120, loss: 0.012093950062990189
step: 130, loss: 0.08151523768901825
step: 140, loss: 0.06137743219733238
step: 150, loss: 0.00744735449552536
step: 160, loss: 0.07049841433763504
step: 170, loss: 0.020264724269509315
step: 180, loss: 0.07006661593914032
step: 190, loss: 0.024842791259288788
step: 200, loss: 0.025825273245573044
step: 210, loss: 0.014655834063887596
step: 220, loss: 0.0451836995780468
step: 230, loss: 0.009882642887532711
step: 240, loss: 0.010487236082553864
step: 250, loss: 0.02417239360511303
step: 260, loss: 0.06772425770759583
step: 270, loss: 0.057151518762111664
step: 280, loss: 0.02269098535180092
step: 290, loss: 0.08403991907835007
step: 300, loss: 0.0559195913374424
step: 310, loss: 0.014337700791656971
step: 320, loss: 0.004002909641712904
step: 330, loss: 0.021270113065838814
step: 340, loss: 0.01448854897171259
step: 350, loss: 0.0759609267115593
step: 360, loss: 0.058433517813682556
step: 370, loss: 0.023584675043821335
step: 380, loss: 0.08513866364955902
step: 390, loss: 0.0043775890953838825
step: 400, loss: 0.060004111379384995
step: 410, loss: 0.024545997381210327
step: 420, loss: 0.08215846866369247
step: 430, loss: 0.007167462725192308
step: 440, loss: 0.031089309602975845
step: 450, loss: 0.017760301008820534
step: 460, loss: 0.012968676164746284
epoch 6: dev_f1=0.9932584269662922, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.04200006648898125
step: 10, loss: 0.07539752870798111
step: 20, loss: 0.007654818706214428
step: 30, loss: 0.023629942908883095
step: 40, loss: 0.009004229679703712
step: 50, loss: 0.012880446389317513
step: 60, loss: 0.12954659759998322
step: 70, loss: 0.3198348581790924
step: 80, loss: 0.11213262379169464
step: 90, loss: 0.03873523324728012
step: 100, loss: 0.05052173137664795
step: 110, loss: 0.003678472014144063
step: 120, loss: 0.01857440359890461
step: 130, loss: 0.05538145825266838
step: 140, loss: 0.12059134244918823
step: 150, loss: 0.06312128901481628
step: 160, loss: 0.06175656616687775
step: 170, loss: 0.12452805787324905
step: 180, loss: 0.16770312190055847
step: 190, loss: 0.07294262200593948
step: 200, loss: 0.014873092994093895
step: 210, loss: 0.1316763013601303
step: 220, loss: 0.015721293166279793
step: 230, loss: 0.02765272557735443
step: 240, loss: 0.07215609401464462
step: 250, loss: 0.023917928338050842
step: 260, loss: 0.006999455392360687
step: 270, loss: 0.06700016558170319
step: 280, loss: 0.023481469601392746
step: 290, loss: 0.006185046397149563
step: 300, loss: 0.005665897391736507
step: 310, loss: 0.014676345512270927
step: 320, loss: 0.018492544069886208
step: 330, loss: 0.015530191361904144
step: 340, loss: 0.007944340817630291
step: 350, loss: 0.13674038648605347
step: 360, loss: 0.09483793377876282
step: 370, loss: 0.04695349559187889
step: 380, loss: 0.10066905617713928
step: 390, loss: 0.01763714663684368
step: 400, loss: 0.02703522890806198
step: 410, loss: 0.01626923680305481
step: 420, loss: 0.06181381642818451
step: 430, loss: 0.05181822553277016
step: 440, loss: 0.016573816537857056
step: 450, loss: 0.11324596405029297
step: 460, loss: 0.011079246178269386
epoch 7: dev_f1=0.9921436588103255, f1=0.9810479375696767, best_f1=0.9788182831661093
step: 0, loss: 0.05036443844437599
step: 10, loss: 0.06184380501508713
step: 20, loss: 6.885255425004289e-05
step: 30, loss: 0.016041625291109085
step: 40, loss: 0.04977588355541229
step: 50, loss: 0.02043222263455391
step: 60, loss: 0.002855104161426425
step: 70, loss: 0.03924725204706192
step: 80, loss: 0.01763152703642845
step: 90, loss: 0.06655340641736984
step: 100, loss: 0.031192217022180557
step: 110, loss: 0.13960738480091095
step: 120, loss: 0.09812698513269424
step: 130, loss: 0.07684388756752014
step: 140, loss: 0.021055882796645164
step: 150, loss: 0.019079970195889473
step: 160, loss: 0.04679487645626068
step: 170, loss: 0.008488541468977928
step: 180, loss: 0.020750030875205994
step: 190, loss: 0.07310875505208969
step: 200, loss: 0.07792869955301285
step: 210, loss: 0.1104915663599968
step: 220, loss: 0.02444407343864441
step: 230, loss: 0.026612577959895134
step: 240, loss: 0.07568643987178802
step: 250, loss: 0.15754787623882294
step: 260, loss: 0.03859935328364372
step: 270, loss: 0.05481288954615593
step: 280, loss: 0.09359230846166611
step: 290, loss: 0.05303606763482094
step: 300, loss: 0.080985888838768
step: 310, loss: 0.06645877659320831
step: 320, loss: 0.061379335820674896
step: 330, loss: 0.09349325299263
step: 340, loss: 0.006905224174261093
step: 350, loss: 0.041483405977487564
step: 360, loss: 0.0001078665372915566
step: 370, loss: 0.019578849896788597
step: 380, loss: 0.04542181268334389
step: 390, loss: 0.042776040732860565
step: 400, loss: 0.09128492325544357
step: 410, loss: 0.009006905369460583
step: 420, loss: 0.05786121264100075
step: 430, loss: 0.04599697142839432
step: 440, loss: 0.18082088232040405
step: 450, loss: 0.19273024797439575
step: 460, loss: 0.012672253884375095
epoch 8: dev_f1=0.9921436588103255, f1=0.9821428571428571, best_f1=0.9788182831661093
step: 0, loss: 0.009680677205324173
step: 10, loss: 0.020921405404806137
step: 20, loss: 0.05706249922513962
step: 30, loss: 0.01972196064889431
step: 40, loss: 0.10291390120983124
step: 50, loss: 0.008380509912967682
step: 60, loss: 0.012241635471582413
step: 70, loss: 0.012676850892603397
step: 80, loss: 0.03671907261013985
step: 90, loss: 0.04920731484889984
step: 100, loss: 0.0007414569263346493
step: 110, loss: 0.016182828694581985
step: 120, loss: 0.041954413056373596
step: 130, loss: 0.03306318074464798
step: 140, loss: 0.08525613695383072
step: 150, loss: 0.043084245175123215
step: 160, loss: 0.0010982982348650694
step: 170, loss: 0.05676903575658798
step: 180, loss: 0.014214548282325268
step: 190, loss: 0.03936553746461868
step: 200, loss: 0.08482936024665833
step: 210, loss: 0.022851034998893738
step: 220, loss: 0.030671730637550354
step: 230, loss: 0.03684137016534805
step: 240, loss: 0.16495755314826965
step: 250, loss: 0.02653753012418747
step: 260, loss: 0.036579348146915436
step: 270, loss: 0.02028239518404007
step: 280, loss: 0.14534679055213928
step: 290, loss: 0.05811648070812225
step: 300, loss: 0.07076897472143173
step: 310, loss: 0.016291867941617966
step: 320, loss: 0.04114329069852829
step: 330, loss: 0.013674695044755936
step: 340, loss: 0.1464654952287674
step: 350, loss: 0.017146650701761246
step: 360, loss: 0.016734611243009567
step: 370, loss: 0.1283463090658188
step: 380, loss: 0.0731295496225357
step: 390, loss: 0.008550075814127922
step: 400, loss: 0.1707066297531128
step: 410, loss: 0.03399745374917984
step: 420, loss: 0.10336515307426453
step: 430, loss: 0.052080728113651276
step: 440, loss: 0.10611893236637115
step: 450, loss: 0.004818749148398638
step: 460, loss: 0.03872659429907799
epoch 9: dev_f1=0.9921259842519685, f1=0.9821428571428571, best_f1=0.9788182831661093
step: 0, loss: 0.10630209743976593
step: 10, loss: 5.7585839385865256e-05
step: 20, loss: 0.0012544413330033422
step: 30, loss: 0.059207137674093246
step: 40, loss: 0.10347871482372284
step: 50, loss: 0.1172555536031723
step: 60, loss: 0.05265159159898758
step: 70, loss: 0.01019136980175972
step: 80, loss: 0.05446528270840645
step: 90, loss: 0.042834699153900146
step: 100, loss: 0.0441979318857193
step: 110, loss: 0.09122183918952942
step: 120, loss: 0.0015492137754336
step: 130, loss: 0.019067110493779182
step: 140, loss: 0.10894790291786194
step: 150, loss: 0.03945297747850418
step: 160, loss: 0.02278296649456024
step: 170, loss: 0.00015302807150874287
step: 180, loss: 0.0036921037826687098
step: 190, loss: 0.01279608067125082
step: 200, loss: 0.05511416494846344
step: 210, loss: 0.05846148356795311
step: 220, loss: 0.006375640630722046
step: 230, loss: 0.0559263750910759
step: 240, loss: 0.006996286101639271
step: 250, loss: 0.138346329331398
step: 260, loss: 0.07078831642866135
step: 270, loss: 0.013912796974182129
step: 280, loss: 0.01085389219224453
step: 290, loss: 0.17213021218776703
step: 300, loss: 0.010462887585163116
step: 310, loss: 0.06746798753738403
step: 320, loss: 0.019664710387587547
step: 330, loss: 0.017284465953707695
step: 340, loss: 0.07802069187164307
step: 350, loss: 0.012349177151918411
step: 360, loss: 0.04736959934234619
step: 370, loss: 0.00925974827259779
step: 380, loss: 0.04995754361152649
step: 390, loss: 3.352235580678098e-05
step: 400, loss: 0.14137502014636993
step: 410, loss: 0.019183658063411713
step: 420, loss: 0.0003828995977528393
step: 430, loss: 0.05544743686914444
step: 440, loss: 0.12958990037441254
step: 450, loss: 0.015837304294109344
step: 460, loss: 0.10988481342792511
epoch 10: dev_f1=0.9932279909706545, f1=0.9865168539325843, best_f1=0.9788182831661093
step: 0, loss: 0.005704168695956469
step: 10, loss: 0.09037709981203079
step: 20, loss: 0.038670849055051804
step: 30, loss: 0.000465247081592679
step: 40, loss: 0.0800006091594696
step: 50, loss: 0.00852162204682827
step: 60, loss: 0.0032271735835820436
step: 70, loss: 0.009545459412038326
step: 80, loss: 0.03622644394636154
step: 90, loss: 0.03900255262851715
step: 100, loss: 0.031720347702503204
step: 110, loss: 0.07805871218442917
step: 120, loss: 0.010009287856519222
step: 130, loss: 0.0023852672893553972
step: 140, loss: 0.14289993047714233
step: 150, loss: 0.16881266236305237
step: 160, loss: 0.07319936901330948
step: 170, loss: 0.0014472870388999581
step: 180, loss: 0.00297090457752347
step: 190, loss: 0.04618438705801964
step: 200, loss: 0.0006604914669878781
step: 210, loss: 0.051204487681388855
step: 220, loss: 0.0233828816562891
step: 230, loss: 0.028454983606934547
step: 240, loss: 0.023805320262908936
step: 250, loss: 0.03152322769165039
step: 260, loss: 0.061344146728515625
step: 270, loss: 0.0022264576982706785
step: 280, loss: 0.05154234915971756
step: 290, loss: 0.160373717546463
step: 300, loss: 0.004405996762216091
step: 310, loss: 0.0036586734931916
step: 320, loss: 0.021519076079130173
step: 330, loss: 0.0826280489563942
step: 340, loss: 0.10342956334352493
step: 350, loss: 0.01747215911746025
step: 360, loss: 0.041534822434186935
step: 370, loss: 0.024733364582061768
step: 380, loss: 0.04220934584736824
step: 390, loss: 0.09160271286964417
step: 400, loss: 0.08897124230861664
step: 410, loss: 0.03435070440173149
step: 420, loss: 0.034030817449092865
step: 430, loss: 0.021777261048555374
step: 440, loss: 0.04529307410120964
step: 450, loss: 0.17038798332214355
step: 460, loss: 0.022853415459394455
epoch 11: dev_f1=0.9909706546275394, f1=0.980963045912654, best_f1=0.9788182831661093
step: 0, loss: 0.030059246346354485
step: 10, loss: 0.029273509979248047
step: 20, loss: 0.01893511973321438
step: 30, loss: 0.020383883267641068
step: 40, loss: 0.019468992948532104
step: 50, loss: 0.031046882271766663
step: 60, loss: 5.6791956012602895e-05
step: 70, loss: 0.0027694781310856342
step: 80, loss: 0.010906706564128399
step: 90, loss: 0.022380854934453964
step: 100, loss: 0.006808696314692497
step: 110, loss: 0.000739055045414716
step: 120, loss: 0.026463178917765617
step: 130, loss: 0.0006374631193466485
step: 140, loss: 0.09584999084472656
step: 150, loss: 0.018775029107928276
step: 160, loss: 0.044057633727788925
step: 170, loss: 0.05471940338611603
step: 180, loss: 0.042818620800971985
step: 190, loss: 0.013736828230321407
step: 200, loss: 0.043895166367292404
step: 210, loss: 0.04674887657165527
step: 220, loss: 0.07008273154497147
step: 230, loss: 0.0007717725820839405
step: 240, loss: 0.0011939789401367307
step: 250, loss: 0.04491168260574341
step: 260, loss: 0.001314722467213869
step: 270, loss: 0.0680498480796814
step: 280, loss: 0.025988483801484108
step: 290, loss: 8.246147626778111e-05
step: 300, loss: 0.03681120276451111
step: 310, loss: 0.08548641949892044
step: 320, loss: 0.054856278002262115
step: 330, loss: 0.00016632927872706205
step: 340, loss: 0.026853440329432487
step: 350, loss: 0.00033816907671280205
step: 360, loss: 0.024042995646595955
step: 370, loss: 0.06655614078044891
step: 380, loss: 4.781862662639469e-05
step: 390, loss: 0.005439676810055971
step: 400, loss: 0.11258500814437866
step: 410, loss: 0.0001055693210219033
step: 420, loss: 0.0650131031870842
step: 430, loss: 0.04963839426636696
step: 440, loss: 0.019166404381394386
step: 450, loss: 0.020217755809426308
step: 460, loss: 0.017191998660564423
epoch 12: dev_f1=0.990990990990991, f1=0.9787709497206705, best_f1=0.9788182831661093
step: 0, loss: 0.04083188995718956
step: 10, loss: 0.03514347970485687
step: 20, loss: 0.048526324331760406
step: 30, loss: 0.040931977331638336
step: 40, loss: 0.0012478908756747842
step: 50, loss: 0.11783105880022049
step: 60, loss: 0.06053914129734039
step: 70, loss: 0.07399102300405502
step: 80, loss: 0.0003243488899897784
step: 90, loss: 0.03723183274269104
step: 100, loss: 0.04841778427362442
step: 110, loss: 0.02085212618112564
step: 120, loss: 0.23262101411819458
step: 130, loss: 0.04869520291686058
step: 140, loss: 0.02564990147948265
step: 150, loss: 0.011538187973201275
step: 160, loss: 0.004956379067152739
step: 170, loss: 0.060585472732782364
step: 180, loss: 0.0025537319015711546
step: 190, loss: 0.022454913705587387
step: 200, loss: 0.037651628255844116
step: 210, loss: 0.000994294648990035
step: 220, loss: 0.05663983151316643
step: 230, loss: 0.029881609603762627
step: 240, loss: 0.02939782291650772
step: 250, loss: 0.03001304343342781
step: 260, loss: 0.0016074002487584949
step: 270, loss: 0.0003572130808606744
step: 280, loss: 0.03990552946925163
step: 290, loss: 0.00038716758717782795
step: 300, loss: 0.00010406426008557901
step: 310, loss: 0.043983712792396545
step: 320, loss: 0.062117800116539
step: 330, loss: 0.03982936590909958
step: 340, loss: 0.008200912736356258
step: 350, loss: 0.02976493537425995
step: 360, loss: 0.03005802445113659
step: 370, loss: 0.03897229582071304
step: 380, loss: 0.04055873304605484
step: 390, loss: 0.04726814478635788
step: 400, loss: 0.0008302513160742819
step: 410, loss: 0.040188249200582504
step: 420, loss: 0.038918036967515945
step: 430, loss: 0.000537877029273659
step: 440, loss: 0.0480024591088295
step: 450, loss: 0.043241582810878754
step: 460, loss: 0.042109448462724686
epoch 13: dev_f1=0.9932432432432432, f1=0.9832402234636871, best_f1=0.9788182831661093
step: 0, loss: 0.030490264296531677
step: 10, loss: 0.04906114563345909
step: 20, loss: 0.04498795419931412
step: 30, loss: 0.023119162768125534
step: 40, loss: 0.10069027543067932
step: 50, loss: 0.029205605387687683
step: 60, loss: 0.12512977421283722
step: 70, loss: 0.004776363261044025
step: 80, loss: 0.04246249422430992
step: 90, loss: 0.04338889196515083
step: 100, loss: 0.039249107241630554
step: 110, loss: 0.020030036568641663
step: 120, loss: 0.006792289670556784
step: 130, loss: 0.00019015782163478434
step: 140, loss: 8.842335228109732e-05
step: 150, loss: 0.08462677896022797
step: 160, loss: 0.028580322861671448
step: 170, loss: 0.00015117626753635705
step: 180, loss: 0.0006832759827375412
step: 190, loss: 0.007683283183723688
step: 200, loss: 0.0003742191765923053
step: 210, loss: 6.911253876751289e-05
step: 220, loss: 0.0031979393679648638
step: 230, loss: 0.0194285549223423
step: 240, loss: 0.0001163183624157682
step: 250, loss: 0.02917042188346386
step: 260, loss: 0.08503822237253189
step: 270, loss: 0.07331696897745132
step: 280, loss: 0.006548871751874685
step: 290, loss: 0.03786381706595421
step: 300, loss: 0.08197134733200073
step: 310, loss: 0.046629078686237335
step: 320, loss: 0.03856712207198143
step: 330, loss: 0.04289550334215164
step: 340, loss: 0.02122863568365574
step: 350, loss: 0.04051835089921951
step: 360, loss: 0.04042055457830429
step: 370, loss: 0.05459970608353615
step: 380, loss: 7.12078035576269e-05
step: 390, loss: 0.005427558906376362
step: 400, loss: 0.05360248312354088
step: 410, loss: 0.09354769438505173
step: 420, loss: 3.7863486795686185e-05
step: 430, loss: 0.06889266520738602
step: 440, loss: 0.003086838638409972
step: 450, loss: 0.08334828168153763
step: 460, loss: 0.0016586326528340578
epoch 14: dev_f1=0.990990990990991, f1=0.9799107142857142, best_f1=0.9788182831661093
step: 0, loss: 0.00037383282324299216
step: 10, loss: 0.000646541768219322
step: 20, loss: 0.00011684738274198025
step: 30, loss: 8.273626735899597e-05
step: 40, loss: 0.00012384809087961912
step: 50, loss: 0.04653391242027283
step: 60, loss: 8.069814793998376e-05
step: 70, loss: 0.0013075871393084526
step: 80, loss: 6.476397538790479e-05
step: 90, loss: 0.02595406584441662
step: 100, loss: 6.796851812396199e-05
step: 110, loss: 0.040870651602745056
step: 120, loss: 0.00013685048907063901
step: 130, loss: 0.04095115140080452
step: 140, loss: 0.0013903342187404633
step: 150, loss: 9.691147715784609e-05
step: 160, loss: 0.023899134248495102
step: 170, loss: 0.0791424810886383
step: 180, loss: 0.04579908773303032
step: 190, loss: 0.024974513798952103
step: 200, loss: 0.04329884797334671
step: 210, loss: 0.020900215953588486
step: 220, loss: 0.0347876213490963
step: 230, loss: 0.0034652119502425194
step: 240, loss: 0.00011285978689556941
step: 250, loss: 0.0863908976316452
step: 260, loss: 0.024185411632061005
step: 270, loss: 3.812180148088373e-05
step: 280, loss: 0.020683472976088524
step: 290, loss: 0.012489872984588146
step: 300, loss: 1.9922230421798304e-05
step: 310, loss: 0.02131064608693123
step: 320, loss: 0.04105636104941368
step: 330, loss: 0.03099512867629528
step: 340, loss: 0.0752953514456749
step: 350, loss: 0.042347509413957596
step: 360, loss: 0.08103182911872864
step: 370, loss: 1.801128382794559e-05
step: 380, loss: 0.02958609350025654
step: 390, loss: 0.004694357048720121
step: 400, loss: 0.15884122252464294
step: 410, loss: 0.06242421641945839
step: 420, loss: 0.07205969840288162
step: 430, loss: 1.5440979041159153e-05
step: 440, loss: 0.06987158209085464
step: 450, loss: 0.026865383610129356
step: 460, loss: 6.612620200030506e-05
epoch 15: dev_f1=0.992108229988726, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.0001109277582145296
step: 10, loss: 0.022436469793319702
step: 20, loss: 0.015814363956451416
step: 30, loss: 0.006516763474792242
step: 40, loss: 0.07457615435123444
step: 50, loss: 0.03246980533003807
step: 60, loss: 0.06337461620569229
step: 70, loss: 0.020818008109927177
step: 80, loss: 0.019632283598184586
step: 90, loss: 0.039748191833496094
step: 100, loss: 0.018885282799601555
step: 110, loss: 0.019971920177340508
step: 120, loss: 0.020147206261754036
step: 130, loss: 0.00010324668255634606
step: 140, loss: 0.021544668823480606
step: 150, loss: 0.020853662863373756
step: 160, loss: 0.024794895201921463
step: 170, loss: 3.582406498026103e-05
step: 180, loss: 0.00010262416617479175
step: 190, loss: 0.057855889201164246
step: 200, loss: 0.06791972368955612
step: 210, loss: 6.346352165564895e-05
step: 220, loss: 8.009208249859512e-05
step: 230, loss: 0.0208725705742836
step: 240, loss: 0.08809195458889008
step: 250, loss: 0.046819254755973816
step: 260, loss: 0.032322660088539124
step: 270, loss: 3.097545413766056e-05
step: 280, loss: 0.015621340833604336
step: 290, loss: 0.03870135918259621
step: 300, loss: 0.0010370903182774782
step: 310, loss: 0.02043255604803562
step: 320, loss: 0.051731619983911514
step: 330, loss: 0.024237046018242836
step: 340, loss: 0.020344166085124016
step: 350, loss: 0.019414708018302917
step: 360, loss: 3.455149271758273e-05
step: 370, loss: 0.019511796534061432
step: 380, loss: 1.6178526493604295e-05
step: 390, loss: 0.019348962232470512
step: 400, loss: 1.926618642755784e-05
step: 410, loss: 4.1854749724734575e-05
step: 420, loss: 0.030633116140961647
step: 430, loss: 0.01891195774078369
step: 440, loss: 0.022667791694402695
step: 450, loss: 0.03906959295272827
step: 460, loss: 3.9585676859132946e-05
epoch 16: dev_f1=0.992108229988726, f1=0.9810055865921787, best_f1=0.9788182831661093
step: 0, loss: 0.02675083465874195
step: 10, loss: 0.04388149827718735
step: 20, loss: 0.062138792127370834
step: 30, loss: 5.446813520393334e-05
step: 40, loss: 0.017404338344931602
step: 50, loss: 0.0945238247513771
step: 60, loss: 0.05665990710258484
step: 70, loss: 3.555850707925856e-05
step: 80, loss: 3.8791069528087974e-05
step: 90, loss: 3.4207980206701905e-05
step: 100, loss: 9.483477333560586e-05
step: 110, loss: 0.07755107432603836
step: 120, loss: 0.0225418321788311
step: 130, loss: 0.10140018165111542
step: 140, loss: 0.0438196137547493
step: 150, loss: 0.04165790602564812
step: 160, loss: 0.01839340478181839
step: 170, loss: 8.667353540658951e-05
step: 180, loss: 0.03771355748176575
step: 190, loss: 0.01866072788834572
step: 200, loss: 4.7359288146253675e-05
step: 210, loss: 5.29732606082689e-05
step: 220, loss: 0.014519444666802883
step: 230, loss: 0.06681010872125626
step: 240, loss: 4.8440702812513337e-05
step: 250, loss: 0.02405625581741333
step: 260, loss: 0.06443899124860764
step: 270, loss: 0.04714955762028694
step: 280, loss: 0.028099240735173225
step: 290, loss: 2.9264147087815218e-05
step: 300, loss: 0.05779079347848892
step: 310, loss: 0.021024491637945175
step: 320, loss: 0.04176543280482292
step: 330, loss: 0.024319306015968323
step: 340, loss: 0.08329923450946808
step: 350, loss: 0.04614338278770447
step: 360, loss: 0.00012412460637278855
step: 370, loss: 0.020797034725546837
step: 380, loss: 0.00010387604561401531
step: 390, loss: 0.03500868007540703
step: 400, loss: 0.04635586962103844
step: 410, loss: 0.00023136139498092234
step: 420, loss: 6.738318188581616e-05
step: 430, loss: 0.049510106444358826
step: 440, loss: 0.05210842564702034
step: 450, loss: 2.562132794992067e-05
step: 460, loss: 1.899854942166712e-05
epoch 17: dev_f1=0.9932432432432432, f1=0.9810901001112348, best_f1=0.9788182831661093
step: 0, loss: 2.1170275431359187e-05
step: 10, loss: 7.867359090596437e-05
step: 20, loss: 0.0006796115776523948
step: 30, loss: 6.619946361752227e-05
step: 40, loss: 0.020522920414805412
step: 50, loss: 0.022163638845086098
step: 60, loss: 2.4794102500891313e-05
step: 70, loss: 0.01549248956143856
step: 80, loss: 0.040851835161447525
step: 90, loss: 0.06841474026441574
step: 100, loss: 5.734373553423211e-05
step: 110, loss: 0.10795633494853973
step: 120, loss: 0.010151570662856102
step: 130, loss: 0.0431257002055645
step: 140, loss: 0.0016079503111541271
step: 150, loss: 5.931065243203193e-05
step: 160, loss: 0.03887033835053444
step: 170, loss: 0.06296039372682571
step: 180, loss: 0.010799674317240715
step: 190, loss: 0.07222798466682434
step: 200, loss: 2.35793359024683e-05
step: 210, loss: 1.569417327118572e-05
step: 220, loss: 0.016376782208681107
step: 230, loss: 0.08594199270009995
step: 240, loss: 0.026747796684503555
step: 250, loss: 0.019665688276290894
step: 260, loss: 0.1063423603773117
step: 270, loss: 0.00014814567111898214
step: 280, loss: 0.02274899184703827
step: 290, loss: 0.00027448576292954385
step: 300, loss: 1.5690535292378627e-05
step: 310, loss: 0.021587040275335312
step: 320, loss: 0.019140763208270073
step: 330, loss: 0.024688877165317535
step: 340, loss: 0.0006349507020786405
step: 350, loss: 0.04769410938024521
step: 360, loss: 0.0700412392616272
step: 370, loss: 0.02814660593867302
step: 380, loss: 0.020806889981031418
step: 390, loss: 0.043756790459156036
step: 400, loss: 0.07013267278671265
step: 410, loss: 0.0009542088955640793
step: 420, loss: 0.026074610650539398
step: 430, loss: 0.04006233066320419
step: 440, loss: 0.0196091216057539
step: 450, loss: 0.0009388778707943857
step: 460, loss: 0.01965724118053913
epoch 18: dev_f1=0.9909706546275394, f1=0.980963045912654, best_f1=0.9788182831661093
step: 0, loss: 0.0015995786525309086
step: 10, loss: 0.022450599819421768
step: 20, loss: 2.9250608349684626e-05
step: 30, loss: 0.0025149225257337093
step: 40, loss: 0.00022946616809349507
step: 50, loss: 1.0199672942690086e-05
step: 60, loss: 0.062186457216739655
step: 70, loss: 0.06812650710344315
step: 80, loss: 0.00015582820924464613
step: 90, loss: 0.06364680826663971
step: 100, loss: 0.0238605048507452
step: 110, loss: 0.02081216871738434
step: 120, loss: 0.00010229886538581923
step: 130, loss: 0.041890546679496765
step: 140, loss: 0.021772384643554688
step: 150, loss: 0.07309052348136902
step: 160, loss: 0.028260648250579834
step: 170, loss: 0.025811554864048958
step: 180, loss: 0.04491947963833809
step: 190, loss: 0.031131839379668236
step: 200, loss: 0.015529320575296879
step: 210, loss: 0.05105987936258316
step: 220, loss: 0.03896711766719818
step: 230, loss: 0.06329166889190674
step: 240, loss: 0.0451301634311676
step: 250, loss: 1.6096621038741432e-05
step: 260, loss: 0.020461587235331535
step: 270, loss: 0.0006123590865172446
step: 280, loss: 0.037482406944036484
step: 290, loss: 2.6734564016805962e-05
step: 300, loss: 0.024326877668499947
step: 310, loss: 7.041176286293194e-05
step: 320, loss: 0.023160701617598534
step: 330, loss: 0.037148039788007736
step: 340, loss: 0.0180178452283144
step: 350, loss: 0.0642254427075386
step: 360, loss: 2.900844265241176e-05
step: 370, loss: 0.023341309279203415
step: 380, loss: 0.04176628589630127
step: 390, loss: 0.023403961211442947
step: 400, loss: 0.02638581395149231
step: 410, loss: 5.9993388276780024e-05
step: 420, loss: 0.05065109208226204
step: 430, loss: 0.023656850680708885
step: 440, loss: 0.022383172065019608
step: 450, loss: 0.020075203850865364
step: 460, loss: 0.021679408848285675
epoch 19: dev_f1=0.9909706546275394, f1=0.9821029082774049, best_f1=0.9788182831661093
step: 0, loss: 0.04859194904565811
step: 10, loss: 0.00015075443661771715
step: 20, loss: 0.04265465587377548
step: 30, loss: 0.024343006312847137
step: 40, loss: 0.05378946661949158
step: 50, loss: 0.0395350344479084
step: 60, loss: 0.022364065051078796
step: 70, loss: 4.049558992846869e-05
step: 80, loss: 0.02305719628930092
step: 90, loss: 0.05692471191287041
step: 100, loss: 0.08273457735776901
step: 110, loss: 0.022235387936234474
step: 120, loss: 0.00018091547826770693
step: 130, loss: 0.048487432301044464
step: 140, loss: 0.04663589596748352
step: 150, loss: 0.01890191063284874
step: 160, loss: 3.47564164258074e-05
step: 170, loss: 0.021487371996045113
step: 180, loss: 0.07671178877353668
step: 190, loss: 0.022510768845677376
step: 200, loss: 0.020651033148169518
step: 210, loss: 0.02434256300330162
step: 220, loss: 3.699668377521448e-05
step: 230, loss: 4.623618588084355e-05
step: 240, loss: 0.0715397447347641
step: 250, loss: 0.02379647269845009
step: 260, loss: 0.00012382793647702783
step: 270, loss: 0.09552004933357239
step: 280, loss: 0.00011911527690244839
step: 290, loss: 0.03428729623556137
step: 300, loss: 0.029288917779922485
step: 310, loss: 0.015684109181165695
step: 320, loss: 0.04483424872159958
step: 330, loss: 0.021522339433431625
step: 340, loss: 4.4662294385489076e-05
step: 350, loss: 0.000878329505212605
step: 360, loss: 0.0010779176373034716
step: 370, loss: 3.230665606679395e-05
step: 380, loss: 3.350583210703917e-05
step: 390, loss: 3.379683766979724e-05
step: 400, loss: 3.355166700202972e-05
step: 410, loss: 2.81311986327637e-05
step: 420, loss: 3.201309300493449e-05
step: 430, loss: 0.02250007539987564
step: 440, loss: 0.043258652091026306
step: 450, loss: 0.04481431841850281
step: 460, loss: 0.021770142018795013
epoch 20: dev_f1=0.9909706546275394, f1=0.9821029082774049, best_f1=0.9788182831661093
