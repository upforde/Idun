cuda
Device: cuda
step: 0, loss: 0.6670567989349365
step: 10, loss: 0.4745835065841675
step: 20, loss: 0.46210160851478577
step: 30, loss: 0.2584615647792816
step: 40, loss: 0.28833913803100586
step: 50, loss: 0.2171221673488617
step: 60, loss: 0.28354835510253906
step: 70, loss: 0.20533910393714905
step: 80, loss: 0.14145395159721375
step: 90, loss: 0.15153789520263672
step: 100, loss: 0.16988277435302734
step: 110, loss: 0.18375955522060394
step: 120, loss: 0.1535564363002777
step: 130, loss: 0.1720496267080307
step: 140, loss: 0.10022730380296707
step: 150, loss: 0.07995457947254181
step: 160, loss: 0.02426261641085148
step: 170, loss: 0.1381939798593521
step: 180, loss: 0.15282922983169556
step: 190, loss: 0.16059282422065735
step: 200, loss: 0.12102494388818741
step: 210, loss: 0.08797600120306015
step: 220, loss: 0.19912686944007874
step: 230, loss: 0.09848389774560928
step: 240, loss: 0.07208392769098282
step: 250, loss: 0.16564008593559265
step: 260, loss: 0.0532657764852047
step: 270, loss: 0.031371939927339554
step: 280, loss: 0.1660504788160324
step: 290, loss: 0.11109450459480286
step: 300, loss: 0.0791291892528534
step: 310, loss: 0.3914468288421631
step: 320, loss: 0.046839192509651184
step: 330, loss: 0.008911985903978348
step: 340, loss: 0.11742193251848221
step: 350, loss: 0.024680746719241142
step: 360, loss: 0.08448536694049835
step: 370, loss: 0.2647554278373718
step: 380, loss: 0.054741598665714264
step: 390, loss: 0.007881542667746544
step: 400, loss: 0.02264411188662052
step: 410, loss: 0.09210411459207535
step: 420, loss: 0.011252522468566895
step: 430, loss: 0.1491519957780838
step: 440, loss: 0.048400238156318665
step: 450, loss: 0.09716758131980896
step: 460, loss: 0.13419587910175323
epoch 1: dev_f1=0.9843749999999999, f1=0.9739524348810873, best_f1=0.9739524348810873
step: 0, loss: 0.020901169627904892
step: 10, loss: 0.04517805948853493
step: 20, loss: 0.07469743490219116
step: 30, loss: 0.03227150812745094
step: 40, loss: 0.19976195693016052
step: 50, loss: 0.012642014771699905
step: 60, loss: 0.045782774686813354
step: 70, loss: 0.08567582070827484
step: 80, loss: 0.028864216059446335
step: 90, loss: 0.08134253323078156
step: 100, loss: 0.014270282350480556
step: 110, loss: 0.14759355783462524
step: 120, loss: 0.12525184452533722
step: 130, loss: 0.04650057107210159
step: 140, loss: 0.19211789965629578
step: 150, loss: 0.05712653324007988
step: 160, loss: 0.13893495500087738
step: 170, loss: 0.08170629292726517
step: 180, loss: 0.12869545817375183
step: 190, loss: 0.0262918621301651
step: 200, loss: 0.014850002713501453
step: 210, loss: 0.03688665106892586
step: 220, loss: 0.09363392740488052
step: 230, loss: 0.05803332105278969
step: 240, loss: 0.11427381634712219
step: 250, loss: 0.1034148633480072
step: 260, loss: 0.0326823852956295
step: 270, loss: 0.06804389506578445
step: 280, loss: 0.00765456585213542
step: 290, loss: 0.020755451172590256
step: 300, loss: 0.07145817577838898
step: 310, loss: 0.02628532610833645
step: 320, loss: 0.02203059382736683
step: 330, loss: 0.06849254667758942
step: 340, loss: 0.007263530511409044
step: 350, loss: 0.016389012336730957
step: 360, loss: 0.10838839411735535
step: 370, loss: 0.0191997978836298
step: 380, loss: 0.006088790018111467
step: 390, loss: 0.012437349185347557
step: 400, loss: 0.048448000103235245
step: 410, loss: 0.02579498663544655
step: 420, loss: 0.06508847326040268
step: 430, loss: 0.008485047146677971
step: 440, loss: 0.025783536955714226
step: 450, loss: 0.14030180871486664
step: 460, loss: 0.0914367213845253
epoch 2: dev_f1=0.992108229988726, f1=0.9796380090497738, best_f1=0.9796380090497738
step: 0, loss: 0.014207313768565655
step: 10, loss: 0.005319362506270409
step: 20, loss: 0.07188604027032852
step: 30, loss: 0.03389868512749672
step: 40, loss: 0.08173162490129471
step: 50, loss: 0.056021373718976974
step: 60, loss: 0.005647010635584593
step: 70, loss: 0.07562844455242157
step: 80, loss: 0.05776171758770943
step: 90, loss: 0.07491935789585114
step: 100, loss: 0.020801354199647903
step: 110, loss: 0.0717068612575531
step: 120, loss: 0.007137401029467583
step: 130, loss: 0.025631364434957504
step: 140, loss: 0.018999619409441948
step: 150, loss: 0.006934951990842819
step: 160, loss: 0.014970186166465282
step: 170, loss: 0.004625226370990276
step: 180, loss: 0.08162611722946167
step: 190, loss: 0.04925886169075966
step: 200, loss: 0.08097405731678009
step: 210, loss: 0.07410069555044174
step: 220, loss: 0.08983679860830307
step: 230, loss: 0.15319350361824036
step: 240, loss: 0.06557011604309082
step: 250, loss: 0.08664029091596603
step: 260, loss: 0.08361423760652542
step: 270, loss: 0.06960521638393402
step: 280, loss: 0.020800592377781868
step: 290, loss: 0.18487629294395447
step: 300, loss: 0.06376057118177414
step: 310, loss: 0.04190877452492714
step: 320, loss: 0.11114303767681122
step: 330, loss: 0.02035508304834366
step: 340, loss: 0.10406185686588287
step: 350, loss: 0.08184006065130234
step: 360, loss: 0.023815244436264038
step: 370, loss: 0.1134323924779892
step: 380, loss: 0.12468116730451584
step: 390, loss: 0.03965669497847557
step: 400, loss: 0.01547813881188631
step: 410, loss: 0.1291048526763916
step: 420, loss: 0.14145836234092712
step: 430, loss: 0.04713159054517746
step: 440, loss: 0.07220935821533203
step: 450, loss: 0.09486540406942368
step: 460, loss: 0.06978362798690796
epoch 3: dev_f1=0.976324689966178, f1=0.9740112994350283, best_f1=0.9796380090497738
step: 0, loss: 0.008912676945328712
step: 10, loss: 0.09550590068101883
step: 20, loss: 0.011908570304512978
step: 30, loss: 0.08175317943096161
step: 40, loss: 0.07739704102277756
step: 50, loss: 0.03001541458070278
step: 60, loss: 0.10531128942966461
step: 70, loss: 0.0017732193227857351
step: 80, loss: 0.1515476554632187
step: 90, loss: 0.0931142121553421
step: 100, loss: 0.21349506080150604
step: 110, loss: 0.1112792119383812
step: 120, loss: 0.05261416360735893
step: 130, loss: 0.2223086655139923
step: 140, loss: 0.1074705496430397
step: 150, loss: 0.08512771129608154
step: 160, loss: 0.06131262332201004
step: 170, loss: 0.07743552327156067
step: 180, loss: 0.01646062545478344
step: 190, loss: 0.02064579166471958
step: 200, loss: 0.09203531593084335
step: 210, loss: 0.06946395337581635
step: 220, loss: 0.015542353503406048
step: 230, loss: 0.05541028827428818
step: 240, loss: 0.07530287653207779
step: 250, loss: 0.07690116763114929
step: 260, loss: 0.023864399641752243
step: 270, loss: 0.027310911566019058
step: 280, loss: 0.0665321871638298
step: 290, loss: 0.010686634108424187
step: 300, loss: 0.00016699761908967048
step: 310, loss: 0.006855398882180452
step: 320, loss: 0.13039885461330414
step: 330, loss: 0.06534241139888763
step: 340, loss: 0.05659729987382889
step: 350, loss: 0.05954877287149429
step: 360, loss: 0.012313645333051682
step: 370, loss: 0.028090663254261017
step: 380, loss: 0.005266239866614342
step: 390, loss: 0.05966227129101753
step: 400, loss: 0.07516460865736008
step: 410, loss: 0.06489058583974838
step: 420, loss: 0.0964110717177391
step: 430, loss: 0.10081774741411209
step: 440, loss: 0.018035929650068283
step: 450, loss: 0.19319239258766174
step: 460, loss: 0.051140397787094116
epoch 4: dev_f1=0.990990990990991, f1=0.990990990990991, best_f1=0.9796380090497738
step: 0, loss: 0.08635683357715607
step: 10, loss: 0.06962917000055313
step: 20, loss: 0.0954703688621521
step: 30, loss: 0.012608010321855545
step: 40, loss: 0.08014002442359924
step: 50, loss: 0.0037926991935819387
step: 60, loss: 0.006563790142536163
step: 70, loss: 0.06716368347406387
step: 80, loss: 0.12584593892097473
step: 90, loss: 0.00846210028976202
step: 100, loss: 0.008448542095720768
step: 110, loss: 0.06905657052993774
step: 120, loss: 0.07928836345672607
step: 130, loss: 0.002687897300347686
step: 140, loss: 0.0049767144955694675
step: 150, loss: 0.009553704410791397
step: 160, loss: 0.009771348908543587
step: 170, loss: 0.0065826899372041225
step: 180, loss: 0.061669278889894485
step: 190, loss: 0.037698663771152496
step: 200, loss: 0.010322464630007744
step: 210, loss: 0.06434902548789978
step: 220, loss: 0.021488456055521965
step: 230, loss: 0.057144876569509506
step: 240, loss: 0.021123066544532776
step: 250, loss: 0.023210600018501282
step: 260, loss: 0.06102278456091881
step: 270, loss: 0.028494909405708313
step: 280, loss: 0.020670786499977112
step: 290, loss: 0.011653524823486805
step: 300, loss: 0.01235899981111288
step: 310, loss: 0.018422387540340424
step: 320, loss: 0.06278081238269806
step: 330, loss: 0.13569693267345428
step: 340, loss: 0.0888252705335617
step: 350, loss: 0.07427508383989334
step: 360, loss: 0.01842137798666954
step: 370, loss: 0.09627717733383179
step: 380, loss: 0.018330775201320648
step: 390, loss: 0.06057716906070709
step: 400, loss: 0.013555336743593216
step: 410, loss: 0.011254480108618736
step: 420, loss: 0.10835646092891693
step: 430, loss: 0.03320937231183052
step: 440, loss: 0.012027004733681679
step: 450, loss: 0.05278512462973595
step: 460, loss: 0.09151580184698105
epoch 5: dev_f1=0.9888392857142857, f1=0.985539488320356, best_f1=0.9796380090497738
step: 0, loss: 0.03529927134513855
step: 10, loss: 0.10635340213775635
step: 20, loss: 0.0859169289469719
step: 30, loss: 0.013590001501142979
step: 40, loss: 0.056932199746370316
step: 50, loss: 0.00016030594997573644
step: 60, loss: 0.021578222513198853
step: 70, loss: 0.08493627607822418
step: 80, loss: 0.09410646557807922
step: 90, loss: 0.08754219859838486
step: 100, loss: 0.00702562415972352
step: 110, loss: 0.0069254664704203606
step: 120, loss: 0.12583597004413605
step: 130, loss: 0.007640443742275238
step: 140, loss: 0.10770144313573837
step: 150, loss: 0.029796533286571503
step: 160, loss: 0.03034324198961258
step: 170, loss: 0.0032069552689790726
step: 180, loss: 0.04000108689069748
step: 190, loss: 0.08788994699716568
step: 200, loss: 0.06331241130828857
step: 210, loss: 0.02602623961865902
step: 220, loss: 0.07537276297807693
step: 230, loss: 0.05418287217617035
step: 240, loss: 0.12582539021968842
step: 250, loss: 0.008598756045103073
step: 260, loss: 0.1392221599817276
step: 270, loss: 0.06990835070610046
step: 280, loss: 0.16018053889274597
step: 290, loss: 0.02440708689391613
step: 300, loss: 8.493842324241996e-05
step: 310, loss: 0.014356853440403938
step: 320, loss: 0.06996669620275497
step: 330, loss: 0.0759277492761612
step: 340, loss: 0.014563214965164661
step: 350, loss: 0.04598409682512283
step: 360, loss: 0.11531388759613037
step: 370, loss: 0.02495208941400051
step: 380, loss: 0.017344530671834946
step: 390, loss: 0.06348968297243118
step: 400, loss: 0.01576313190162182
step: 410, loss: 4.9708756705513224e-05
step: 420, loss: 0.005274808965623379
step: 430, loss: 0.010471334680914879
step: 440, loss: 0.038392260670661926
step: 450, loss: 0.00940290093421936
step: 460, loss: 0.08295079320669174
epoch 6: dev_f1=0.9943757030371203, f1=0.9843749999999999, best_f1=0.9843749999999999
step: 0, loss: 0.05510108917951584
step: 10, loss: 0.007547689601778984
step: 20, loss: 0.05190970003604889
step: 30, loss: 0.06817468255758286
step: 40, loss: 0.07457420229911804
step: 50, loss: 0.02724023535847664
step: 60, loss: 0.035673804581165314
step: 70, loss: 0.14955899119377136
step: 80, loss: 0.007696027401834726
step: 90, loss: 0.018842361867427826
step: 100, loss: 0.025007933378219604
step: 110, loss: 0.004772220738232136
step: 120, loss: 0.004746878519654274
step: 130, loss: 0.018184911459684372
step: 140, loss: 0.021386072039604187
step: 150, loss: 0.09806762635707855
step: 160, loss: 0.012260143645107746
step: 170, loss: 0.044024884700775146
step: 180, loss: 0.011622346937656403
step: 190, loss: 0.17530101537704468
step: 200, loss: 0.048608310520648956
step: 210, loss: 0.08435830473899841
step: 220, loss: 0.04068498685956001
step: 230, loss: 0.07362382113933563
step: 240, loss: 0.030620180070400238
step: 250, loss: 0.1633264273405075
step: 260, loss: 0.017953749746084213
step: 270, loss: 0.07777814567089081
step: 280, loss: 0.010217909701168537
step: 290, loss: 0.023566987365484238
step: 300, loss: 0.0967307835817337
step: 310, loss: 0.01008075475692749
step: 320, loss: 0.013393767178058624
step: 330, loss: 0.011307865381240845
step: 340, loss: 0.008309748023748398
step: 350, loss: 0.02379685267806053
step: 360, loss: 0.030934887006878853
step: 370, loss: 0.011768519878387451
step: 380, loss: 0.05966953933238983
step: 390, loss: 0.04000125452876091
step: 400, loss: 0.06341525912284851
step: 410, loss: 0.0076437173411250114
step: 420, loss: 0.10469895601272583
step: 430, loss: 0.053782522678375244
step: 440, loss: 0.10246850550174713
step: 450, loss: 0.05868903920054436
step: 460, loss: 0.06692862510681152
epoch 7: dev_f1=0.9943757030371203, f1=0.9865470852017937, best_f1=0.9843749999999999
step: 0, loss: 0.00773890595883131
step: 10, loss: 0.060519300401210785
step: 20, loss: 0.14963297545909882
step: 30, loss: 0.010393442586064339
step: 40, loss: 0.04377985745668411
step: 50, loss: 0.06461457163095474
step: 60, loss: 0.01787823811173439
step: 70, loss: 0.18583303689956665
step: 80, loss: 0.04470612481236458
step: 90, loss: 0.030145136639475822
step: 100, loss: 0.05025582015514374
step: 110, loss: 0.023032037541270256
step: 120, loss: 0.0013823352055624127
step: 130, loss: 0.012717675417661667
step: 140, loss: 0.005548740737140179
step: 150, loss: 0.007451937068253756
step: 160, loss: 0.00011022303078789264
step: 170, loss: 0.08737830817699432
step: 180, loss: 0.0401914045214653
step: 190, loss: 0.0019739691633731127
step: 200, loss: 0.002869522664695978
step: 210, loss: 0.01234725397080183
step: 220, loss: 0.009134834632277489
step: 230, loss: 0.056269653141498566
step: 240, loss: 0.008916051127016544
step: 250, loss: 0.02646973915398121
step: 260, loss: 0.008069891482591629
step: 270, loss: 0.0703013688325882
step: 280, loss: 0.008774553425610065
step: 290, loss: 0.016691267490386963
step: 300, loss: 0.0025638164952397346
step: 310, loss: 0.04208889603614807
step: 320, loss: 0.011790447868406773
step: 330, loss: 0.09266979247331619
step: 340, loss: 0.04192975535988808
step: 350, loss: 0.009075142443180084
step: 360, loss: 0.015074748545885086
step: 370, loss: 0.006540656555444002
step: 380, loss: 0.012374023906886578
step: 390, loss: 0.04564768448472023
step: 400, loss: 0.005226791370660067
step: 410, loss: 0.01698857918381691
step: 420, loss: 0.07894722372293472
step: 430, loss: 0.06037472188472748
step: 440, loss: 0.07084251940250397
step: 450, loss: 0.06707263737916946
step: 460, loss: 0.08262789994478226
epoch 8: dev_f1=0.990990990990991, f1=0.9864253393665158, best_f1=0.9843749999999999
step: 0, loss: 0.03252219408750534
step: 10, loss: 0.03353331610560417
step: 20, loss: 0.08399087935686111
step: 30, loss: 0.004248179029673338
step: 40, loss: 0.016585441306233406
step: 50, loss: 0.017121633514761925
step: 60, loss: 0.021778827533125877
step: 70, loss: 0.023247456178069115
step: 80, loss: 0.1282597929239273
step: 90, loss: 0.008458281867206097
step: 100, loss: 0.009408720768988132
step: 110, loss: 0.04965030401945114
step: 120, loss: 0.09094268083572388
step: 130, loss: 0.011531869880855083
step: 140, loss: 0.05656296759843826
step: 150, loss: 0.03488856554031372
step: 160, loss: 0.12131232768297195
step: 170, loss: 0.0263303704559803
step: 180, loss: 0.016025032848119736
step: 190, loss: 0.0019893767312169075
step: 200, loss: 0.02125360816717148
step: 210, loss: 0.012627888470888138
step: 220, loss: 0.1732673943042755
step: 230, loss: 0.004348325077444315
step: 240, loss: 0.00013739702990278602
step: 250, loss: 0.049958713352680206
step: 260, loss: 0.030677398666739464
step: 270, loss: 0.06595206260681152
step: 280, loss: 0.004436488263309002
step: 290, loss: 0.011853266507387161
step: 300, loss: 0.0003722070250660181
step: 310, loss: 0.07405009865760803
step: 320, loss: 0.05901036411523819
step: 330, loss: 0.06430985033512115
step: 340, loss: 0.01818152703344822
step: 350, loss: 0.09687556326389313
step: 360, loss: 0.0015837687533348799
step: 370, loss: 0.0588051937520504
step: 380, loss: 0.0008397214696742594
step: 390, loss: 0.010543842799961567
step: 400, loss: 0.054012481123209
step: 410, loss: 0.08556382358074188
step: 420, loss: 0.04910016432404518
step: 430, loss: 0.09389269351959229
step: 440, loss: 0.0007029681000858545
step: 450, loss: 0.017123479396104813
step: 460, loss: 0.06600562483072281
epoch 9: dev_f1=0.9943757030371203, f1=0.987709497206704, best_f1=0.9843749999999999
step: 0, loss: 3.8874815800227225e-05
step: 10, loss: 0.0040964181534945965
step: 20, loss: 0.055414583534002304
step: 30, loss: 0.0031920326873660088
step: 40, loss: 0.0034407267812639475
step: 50, loss: 0.0022144815884530544
step: 60, loss: 0.010098055005073547
step: 70, loss: 0.07312402129173279
step: 80, loss: 0.04419665411114693
step: 90, loss: 0.07066800445318222
step: 100, loss: 0.000812573591247201
step: 110, loss: 0.06720612198114395
step: 120, loss: 0.04091796651482582
step: 130, loss: 0.048348601907491684
step: 140, loss: 0.02974594570696354
step: 150, loss: 0.004294777754694223
step: 160, loss: 0.004256872925907373
step: 170, loss: 0.08403626084327698
step: 180, loss: 0.009107884019613266
step: 190, loss: 0.04684781655669212
step: 200, loss: 0.056656792759895325
step: 210, loss: 0.008103415369987488
step: 220, loss: 0.029804812744259834
step: 230, loss: 0.05521633103489876
step: 240, loss: 0.06738586723804474
step: 250, loss: 0.03557712584733963
step: 260, loss: 0.035953231155872345
step: 270, loss: 0.062394727021455765
step: 280, loss: 0.02452772483229637
step: 290, loss: 0.0004525924741756171
step: 300, loss: 0.0377955362200737
step: 310, loss: 0.055311910808086395
step: 320, loss: 0.03731882944703102
step: 330, loss: 0.17774249613285065
step: 340, loss: 0.0636402815580368
step: 350, loss: 0.056135423481464386
step: 360, loss: 0.0012407400645315647
step: 370, loss: 0.22976356744766235
step: 380, loss: 0.08603072166442871
step: 390, loss: 0.024712294340133667
step: 400, loss: 0.018653754144906998
step: 410, loss: 0.0021094640251249075
step: 420, loss: 0.03913702443242073
step: 430, loss: 0.022752245888113976
step: 440, loss: 0.06663297116756439
step: 450, loss: 0.061072174459695816
step: 460, loss: 0.08137763291597366
epoch 10: dev_f1=0.9932432432432432, f1=0.9831271091113611, best_f1=0.9843749999999999
step: 0, loss: 0.012811325490474701
step: 10, loss: 0.016082560643553734
step: 20, loss: 0.003159799613058567
step: 30, loss: 0.0011455384083092213
step: 40, loss: 0.04220889136195183
step: 50, loss: 0.039628129452466965
step: 60, loss: 0.11920754611492157
step: 70, loss: 0.062381211668252945
step: 80, loss: 0.0007470194832421839
step: 90, loss: 0.06966479122638702
step: 100, loss: 0.02740379422903061
step: 110, loss: 0.0066289398819208145
step: 120, loss: 0.020429303869605064
step: 130, loss: 0.27084651589393616
step: 140, loss: 0.008964911103248596
step: 150, loss: 0.07379909604787827
step: 160, loss: 0.1397794783115387
step: 170, loss: 0.024158013984560966
step: 180, loss: 0.0014889496378600597
step: 190, loss: 0.04017391800880432
step: 200, loss: 0.020110294222831726
step: 210, loss: 0.0020281963516026735
step: 220, loss: 0.0001039574999595061
step: 230, loss: 0.006100934464484453
step: 240, loss: 0.009433957748115063
step: 250, loss: 0.0020646394696086645
step: 260, loss: 0.0006716011557728052
step: 270, loss: 0.07100055366754532
step: 280, loss: 0.011624915525317192
step: 290, loss: 0.0017176574328914285
step: 300, loss: 0.04134178161621094
step: 310, loss: 0.05563142150640488
step: 320, loss: 0.009502405300736427
step: 330, loss: 0.002681239042431116
step: 340, loss: 0.05896672233939171
step: 350, loss: 0.08763403445482254
step: 360, loss: 0.0023793354630470276
step: 370, loss: 0.09210487455129623
step: 380, loss: 0.015657367184758186
step: 390, loss: 0.022014152258634567
step: 400, loss: 0.04723526909947395
step: 410, loss: 0.07779683917760849
step: 420, loss: 0.021983204409480095
step: 430, loss: 0.04055047035217285
step: 440, loss: 0.05019401013851166
step: 450, loss: 0.03884347155690193
step: 460, loss: 0.00040377091499976814
epoch 11: dev_f1=0.9921436588103255, f1=0.9843400447427293, best_f1=0.9843749999999999
step: 0, loss: 0.04218871146440506
step: 10, loss: 0.09911574423313141
step: 20, loss: 0.056742921471595764
step: 30, loss: 0.021542565897107124
step: 40, loss: 0.015516893938183784
step: 50, loss: 0.04852786287665367
step: 60, loss: 0.00019067701941821724
step: 70, loss: 0.04253308102488518
step: 80, loss: 0.030424874275922775
step: 90, loss: 0.0035467061679810286
step: 100, loss: 0.018817029893398285
step: 110, loss: 0.02915623039007187
step: 120, loss: 0.00023192375374492258
step: 130, loss: 0.18127483129501343
step: 140, loss: 6.303287227638066e-05
step: 150, loss: 0.06543421000242233
step: 160, loss: 0.06336025148630142
step: 170, loss: 0.018415365368127823
step: 180, loss: 0.08066911995410919
step: 190, loss: 0.06553473323583603
step: 200, loss: 0.06081376224756241
step: 210, loss: 0.015083225443959236
step: 220, loss: 0.0004443553916644305
step: 230, loss: 0.08764132857322693
step: 240, loss: 0.0026281168684363365
step: 250, loss: 0.040730126202106476
step: 260, loss: 0.00035940096131525934
step: 270, loss: 0.00047932262532413006
step: 280, loss: 0.13220056891441345
step: 290, loss: 0.05833589658141136
step: 300, loss: 0.02885635383427143
step: 310, loss: 0.0033000577241182327
step: 320, loss: 0.0005193362012505531
step: 330, loss: 0.0642276257276535
step: 340, loss: 0.04706916585564613
step: 350, loss: 0.030194822698831558
step: 360, loss: 0.015343434177339077
step: 370, loss: 0.031902581453323364
step: 380, loss: 7.374816777883098e-05
step: 390, loss: 0.0012044061440974474
step: 400, loss: 0.021029895171523094
step: 410, loss: 0.0006278300425037742
step: 420, loss: 0.07778750360012054
step: 430, loss: 0.017760973423719406
step: 440, loss: 2.9313099730643444e-05
step: 450, loss: 0.05682380869984627
step: 460, loss: 0.02422109991312027
epoch 12: dev_f1=0.9943630214205187, f1=0.9809203142536477, best_f1=0.9843749999999999
step: 0, loss: 0.034221041947603226
step: 10, loss: 0.028939930722117424
step: 20, loss: 0.007439287845045328
step: 30, loss: 0.03636830672621727
step: 40, loss: 0.0010012234561145306
step: 50, loss: 0.02286013774573803
step: 60, loss: 0.10612604767084122
step: 70, loss: 0.0541720911860466
step: 80, loss: 0.06701655685901642
step: 90, loss: 0.08402924239635468
step: 100, loss: 0.05412615090608597
step: 110, loss: 0.040724948048591614
step: 120, loss: 0.03668539971113205
step: 130, loss: 0.01739812269806862
step: 140, loss: 0.020662663504481316
step: 150, loss: 0.00020966277224943042
step: 160, loss: 0.058246929198503494
step: 170, loss: 0.020847856998443604
step: 180, loss: 0.037076886743307114
step: 190, loss: 0.0006493038963526487
step: 200, loss: 0.0002099315170198679
step: 210, loss: 0.02539667673408985
step: 220, loss: 0.0005898542585782707
step: 230, loss: 0.009800709784030914
step: 240, loss: 0.06186109036207199
step: 250, loss: 0.00024815453798510134
step: 260, loss: 0.025145890191197395
step: 270, loss: 0.00010011242557084188
step: 280, loss: 0.04468195140361786
step: 290, loss: 0.08165383338928223
step: 300, loss: 0.019648266956210136
step: 310, loss: 0.05588018521666527
step: 320, loss: 0.019317595288157463
step: 330, loss: 0.026173720136284828
step: 340, loss: 8.306655217893422e-05
step: 350, loss: 0.00033822140539996326
step: 360, loss: 0.029066815972328186
step: 370, loss: 0.3250965178012848
step: 380, loss: 0.042477428913116455
step: 390, loss: 0.0198541097342968
step: 400, loss: 0.019489867612719536
step: 410, loss: 0.03358238935470581
step: 420, loss: 0.02811441570520401
step: 430, loss: 0.0011931512271985412
step: 440, loss: 0.07739223539829254
step: 450, loss: 0.02250029146671295
step: 460, loss: 0.00013401311298366636
epoch 13: dev_f1=0.9932584269662922, f1=0.980963045912654, best_f1=0.9843749999999999
step: 0, loss: 0.01842806115746498
step: 10, loss: 0.000554223486687988
step: 20, loss: 0.028648411855101585
step: 30, loss: 0.004188315477222204
step: 40, loss: 0.0017944981809705496
step: 50, loss: 0.07928182184696198
step: 60, loss: 9.952279651770368e-05
step: 70, loss: 0.022046446800231934
step: 80, loss: 0.0005032661720179021
step: 90, loss: 0.055343400686979294
step: 100, loss: 4.207469828543253e-05
step: 110, loss: 0.02622513473033905
step: 120, loss: 0.039297010749578476
step: 130, loss: 0.07753591239452362
step: 140, loss: 0.0347457230091095
step: 150, loss: 0.05476875603199005
step: 160, loss: 0.016627317294478416
step: 170, loss: 0.015215134248137474
step: 180, loss: 0.014760088175535202
step: 190, loss: 0.022611355409026146
step: 200, loss: 0.06147771328687668
step: 210, loss: 4.598188024829142e-05
step: 220, loss: 0.06772420555353165
step: 230, loss: 0.05013866722583771
step: 240, loss: 0.046254098415374756
step: 250, loss: 0.026434989646077156
step: 260, loss: 0.0001309128274442628
step: 270, loss: 0.0003750970063265413
step: 280, loss: 0.0281514935195446
step: 290, loss: 0.005170920863747597
step: 300, loss: 0.03505454584956169
step: 310, loss: 0.06795379519462585
step: 320, loss: 0.10613178461790085
step: 330, loss: 0.034570153802633286
step: 340, loss: 0.052530352026224136
step: 350, loss: 0.00017306003428529948
step: 360, loss: 0.02357831969857216
step: 370, loss: 0.032313354313373566
step: 380, loss: 0.05983513221144676
step: 390, loss: 0.014781143516302109
step: 400, loss: 0.0010604204144328833
step: 410, loss: 0.05555965006351471
step: 420, loss: 0.0016024223295971751
step: 430, loss: 0.016567489132285118
step: 440, loss: 0.023680415004491806
step: 450, loss: 0.0009238588972948492
step: 460, loss: 0.0397706963121891
epoch 14: dev_f1=0.9932432432432432, f1=0.9819819819819819, best_f1=0.9843749999999999
step: 0, loss: 0.03454635664820671
step: 10, loss: 0.0344252735376358
step: 20, loss: 2.235129250038881e-05
step: 30, loss: 0.00025044556241482496
step: 40, loss: 0.0013221564004197717
step: 50, loss: 0.04932813346385956
step: 60, loss: 0.0018540541641414165
step: 70, loss: 0.08154109120368958
step: 80, loss: 0.01812603697180748
step: 90, loss: 0.014432964846491814
step: 100, loss: 0.03767649456858635
step: 110, loss: 0.028792420402169228
step: 120, loss: 0.022602073848247528
step: 130, loss: 0.04423489794135094
step: 140, loss: 0.04073354974389076
step: 150, loss: 0.01852240599691868
step: 160, loss: 0.07682708650827408
step: 170, loss: 0.04681621491909027
step: 180, loss: 0.021225841715931892
step: 190, loss: 0.016675323247909546
step: 200, loss: 0.05191454663872719
step: 210, loss: 0.05505716800689697
step: 220, loss: 0.002419182797893882
step: 230, loss: 0.00019685315783135593
step: 240, loss: 0.0011273372219875455
step: 250, loss: 0.07498960942029953
step: 260, loss: 0.0020182281732559204
step: 270, loss: 1.4010675840836484e-05
step: 280, loss: 0.03342080116271973
step: 290, loss: 0.00046151841524988413
step: 300, loss: 0.041628625243902206
step: 310, loss: 0.03978797793388367
step: 320, loss: 0.021083876490592957
step: 330, loss: 0.0864487886428833
step: 340, loss: 0.052830588072538376
step: 350, loss: 2.5956760509870946e-05
step: 360, loss: 0.031049057841300964
step: 370, loss: 0.030255531892180443
step: 380, loss: 6.803108408348635e-05
step: 390, loss: 0.02729802392423153
step: 400, loss: 0.10842230916023254
step: 410, loss: 0.04054811969399452
step: 420, loss: 0.0014871071325615048
step: 430, loss: 0.010717089287936687
step: 440, loss: 0.00024790639872662723
step: 450, loss: 0.0014094733633100986
step: 460, loss: 0.06227684020996094
epoch 15: dev_f1=0.9932432432432432, f1=0.9842696629213483, best_f1=0.9843749999999999
step: 0, loss: 0.00017340372141916305
step: 10, loss: 0.0466172955930233
step: 20, loss: 0.021121850237250328
step: 30, loss: 5.40100627404172e-05
step: 40, loss: 0.015765715390443802
step: 50, loss: 4.09330205002334e-05
step: 60, loss: 0.09498941898345947
step: 70, loss: 5.762785076512955e-05
step: 80, loss: 0.021693062037229538
step: 90, loss: 4.601370164891705e-05
step: 100, loss: 0.00020531438349280506
step: 110, loss: 0.0016208557644858956
step: 120, loss: 0.011761502362787724
step: 130, loss: 0.019476253539323807
step: 140, loss: 0.07414887100458145
step: 150, loss: 0.052446868270635605
step: 160, loss: 0.022239847108721733
step: 170, loss: 0.031248383224010468
step: 180, loss: 0.06810575723648071
step: 190, loss: 2.0403113012434915e-05
step: 200, loss: 0.0260142982006073
step: 210, loss: 0.03383098542690277
step: 220, loss: 0.00201591569930315
step: 230, loss: 0.0032110949978232384
step: 240, loss: 0.027598733082413673
step: 250, loss: 0.025753028690814972
step: 260, loss: 0.04205326363444328
step: 270, loss: 0.03495708107948303
step: 280, loss: 0.005414607468992472
step: 290, loss: 0.008640031330287457
step: 300, loss: 0.049078598618507385
step: 310, loss: 0.03930826485157013
step: 320, loss: 0.00041357020381838083
step: 330, loss: 0.06321289390325546
step: 340, loss: 0.051321931183338165
step: 350, loss: 0.021109864115715027
step: 360, loss: 0.020803725346922874
step: 370, loss: 0.09341283142566681
step: 380, loss: 0.0005178300198167562
step: 390, loss: 0.0042677815072238445
step: 400, loss: 1.5426277968799695e-05
step: 410, loss: 0.00032615900272503495
step: 420, loss: 0.04525750130414963
step: 430, loss: 9.885389590635896e-05
step: 440, loss: 0.0005141599685885012
step: 450, loss: 0.034956395626068115
step: 460, loss: 0.0824429914355278
epoch 16: dev_f1=0.9921259842519685, f1=0.9854096520763187, best_f1=0.9843749999999999
step: 0, loss: 0.027254700660705566
step: 10, loss: 0.06811580806970596
step: 20, loss: 0.04256391525268555
step: 30, loss: 0.045366205275058746
step: 40, loss: 5.7157431001542136e-05
step: 50, loss: 1.6089215932879597e-05
step: 60, loss: 0.017773235216736794
step: 70, loss: 0.00024812493938952684
step: 80, loss: 2.0317334929131903e-05
step: 90, loss: 0.02407909370958805
step: 100, loss: 0.04130464047193527
step: 110, loss: 0.00023943556880112737
step: 120, loss: 0.04055742919445038
step: 130, loss: 0.06368304044008255
step: 140, loss: 0.00016673776553943753
step: 150, loss: 0.03481321409344673
step: 160, loss: 0.024461952969431877
step: 170, loss: 0.07919709384441376
step: 180, loss: 0.005874503869563341
step: 190, loss: 0.0485127791762352
step: 200, loss: 0.03601016476750374
step: 210, loss: 0.03870638087391853
step: 220, loss: 0.000526953546795994
step: 230, loss: 0.028604228049516678
step: 240, loss: 0.0003258874057792127
step: 250, loss: 0.00012937665451318026
step: 260, loss: 0.04467439651489258
step: 270, loss: 0.02306051179766655
step: 280, loss: 0.03589976951479912
step: 290, loss: 0.014606582932174206
step: 300, loss: 0.001121660927310586
step: 310, loss: 0.00021642059436999261
step: 320, loss: 0.03469974920153618
step: 330, loss: 0.00013212044723331928
step: 340, loss: 0.08034560084342957
step: 350, loss: 0.02041802927851677
step: 360, loss: 0.0012629968114197254
step: 370, loss: 0.03321826830506325
step: 380, loss: 0.006846528500318527
step: 390, loss: 0.036631714552640915
step: 400, loss: 7.755701517453417e-05
step: 410, loss: 0.027663784101605415
step: 420, loss: 0.02875014953315258
step: 430, loss: 0.03911568969488144
step: 440, loss: 0.0001242720172740519
step: 450, loss: 0.00023546205193269998
step: 460, loss: 0.00206180801615119
epoch 17: dev_f1=0.9932432432432432, f1=0.9842696629213483, best_f1=0.9843749999999999
step: 0, loss: 3.590744745451957e-05
step: 10, loss: 0.017206447198987007
step: 20, loss: 0.027270367369055748
step: 30, loss: 0.00037374786916188896
step: 40, loss: 0.03321197256445885
step: 50, loss: 0.04456217214465141
step: 60, loss: 0.025981510058045387
step: 70, loss: 0.020853623747825623
step: 80, loss: 0.04064936190843582
step: 90, loss: 0.001222156803123653
step: 100, loss: 0.01804763451218605
step: 110, loss: 0.00010224906145595014
step: 120, loss: 0.00010571040911599994
step: 130, loss: 0.0002014660567510873
step: 140, loss: 0.01845436729490757
step: 150, loss: 0.0563042014837265
step: 160, loss: 0.020649095997214317
step: 170, loss: 0.04025080427527428
step: 180, loss: 0.029758771881461143
step: 190, loss: 0.007152723614126444
step: 200, loss: 0.07907648384571075
step: 210, loss: 0.025810640305280685
step: 220, loss: 0.03819751366972923
step: 230, loss: 0.028610650449991226
step: 240, loss: 0.04509158432483673
step: 250, loss: 0.060909561812877655
step: 260, loss: 0.0002622035681270063
step: 270, loss: 0.042758651077747345
step: 280, loss: 0.08213004469871521
step: 290, loss: 0.00012677231279667467
step: 300, loss: 0.025613075122237206
step: 310, loss: 0.045142535120248795
step: 320, loss: 0.04339573532342911
step: 330, loss: 0.00012733966286759824
step: 340, loss: 0.02093682624399662
step: 350, loss: 0.018221674486994743
step: 360, loss: 0.05649866908788681
step: 370, loss: 0.07356854528188705
step: 380, loss: 0.025408267974853516
step: 390, loss: 0.04340910166501999
step: 400, loss: 0.01728030852973461
step: 410, loss: 0.015598200261592865
step: 420, loss: 0.01931079663336277
step: 430, loss: 0.03043453022837639
step: 440, loss: 0.02064145915210247
step: 450, loss: 0.00029480652301572263
step: 460, loss: 0.024149777367711067
epoch 18: dev_f1=0.9943502824858756, f1=0.9852774631936579, best_f1=0.9843749999999999
step: 0, loss: 0.00025178020587190986
step: 10, loss: 0.08784020692110062
step: 20, loss: 0.0004735174879897386
step: 30, loss: 0.03752153366804123
step: 40, loss: 0.00011772437574109063
step: 50, loss: 0.04779885709285736
step: 60, loss: 0.011576689779758453
step: 70, loss: 0.02491508238017559
step: 80, loss: 0.017363740131258965
step: 90, loss: 0.020052822306752205
step: 100, loss: 0.0531969889998436
step: 110, loss: 0.040972255170345306
step: 120, loss: 0.03351786360144615
step: 130, loss: 0.0001441929052816704
step: 140, loss: 5.184885594644584e-05
step: 150, loss: 1.2561567928059958e-05
step: 160, loss: 8.155004616128281e-05
step: 170, loss: 0.03616143763065338
step: 180, loss: 0.024635426700115204
step: 190, loss: 0.018929945304989815
step: 200, loss: 0.00024893038789741695
step: 210, loss: 0.016462119296193123
step: 220, loss: 9.781435801414773e-05
step: 230, loss: 0.02160797454416752
step: 240, loss: 0.005730956792831421
step: 250, loss: 0.0001368032826576382
step: 260, loss: 3.29987051372882e-05
step: 270, loss: 0.000495858199428767
step: 280, loss: 0.020899929106235504
step: 290, loss: 0.08712853491306305
step: 300, loss: 0.000577882572542876
step: 310, loss: 0.013762233778834343
step: 320, loss: 0.00017975566152017564
step: 330, loss: 0.016179949045181274
step: 340, loss: 3.9810001908335835e-05
step: 350, loss: 0.025744568556547165
step: 360, loss: 0.00046216094051487744
step: 370, loss: 0.021522771567106247
step: 380, loss: 6.623551598750055e-05
step: 390, loss: 0.0444413423538208
step: 400, loss: 0.01851137913763523
step: 410, loss: 0.05797426775097847
step: 420, loss: 0.020313827320933342
step: 430, loss: 0.02222401835024357
step: 440, loss: 0.0222247876226902
step: 450, loss: 0.024530712515115738
step: 460, loss: 0.027838382869958878
epoch 19: dev_f1=0.9943630214205187, f1=0.9831271091113611, best_f1=0.9843749999999999
step: 0, loss: 0.06713494658470154
step: 10, loss: 0.01647147722542286
step: 20, loss: 0.02458285167813301
step: 30, loss: 0.055512573570013046
step: 40, loss: 0.023928383365273476
step: 50, loss: 0.033440399914979935
step: 60, loss: 0.037986110895872116
step: 70, loss: 0.02532445266842842
step: 80, loss: 0.07619541883468628
step: 90, loss: 0.00010908111289609224
step: 100, loss: 0.06236967816948891
step: 110, loss: 6.017660052748397e-05
step: 120, loss: 0.02490953356027603
step: 130, loss: 0.012661812826991081
step: 140, loss: 0.018465664237737656
step: 150, loss: 0.026704072952270508
step: 160, loss: 0.04217850789427757
step: 170, loss: 0.021469900384545326
step: 180, loss: 0.00014638592256233096
step: 190, loss: 0.03848100081086159
step: 200, loss: 0.04669705405831337
step: 210, loss: 0.02421162836253643
step: 220, loss: 6.483888137154281e-05
step: 230, loss: 0.00010956142068607733
step: 240, loss: 0.024591943249106407
step: 250, loss: 0.09297437965869904
step: 260, loss: 0.027908004820346832
step: 270, loss: 0.023249361664056778
step: 280, loss: 0.04707500711083412
step: 290, loss: 0.014964103698730469
step: 300, loss: 0.024789251387119293
step: 310, loss: 0.000975529314018786
step: 320, loss: 0.03414169326424599
step: 330, loss: 0.009023742750287056
step: 340, loss: 0.02715211734175682
step: 350, loss: 0.011418110691010952
step: 360, loss: 0.027857784181833267
step: 370, loss: 0.07049643248319626
step: 380, loss: 0.017314918339252472
step: 390, loss: 0.026288388296961784
step: 400, loss: 0.0018665124662220478
step: 410, loss: 0.06292152404785156
step: 420, loss: 4.81386850879062e-05
step: 430, loss: 0.01598154939711094
step: 440, loss: 0.04126910865306854
step: 450, loss: 0.03912271931767464
step: 460, loss: 4.84017982671503e-05
epoch 20: dev_f1=0.9943630214205187, f1=0.9831271091113611, best_f1=0.9843749999999999
