cuda
Device: cuda
step: 0, loss: 0.8020076155662537
step: 10, loss: 0.32162636518478394
step: 20, loss: 0.5859920978546143
step: 30, loss: 0.3807579576969147
step: 40, loss: 0.4087485373020172
step: 50, loss: 0.5259527564048767
step: 60, loss: 0.31830254197120667
step: 70, loss: 0.3068031966686249
step: 80, loss: 0.20937441289424896
step: 90, loss: 0.3136783838272095
step: 100, loss: 0.2185673713684082
step: 110, loss: 0.169070303440094
step: 120, loss: 0.08581854403018951
step: 130, loss: 0.06936632096767426
step: 140, loss: 0.15992797911167145
step: 150, loss: 0.09851844608783722
step: 160, loss: 0.18684764206409454
step: 170, loss: 0.13427910208702087
step: 180, loss: 0.08136030286550522
step: 190, loss: 0.028432080522179604
step: 200, loss: 0.09336043149232864
step: 210, loss: 0.02431311644613743
step: 220, loss: 0.08395938575267792
step: 230, loss: 0.04151475057005882
step: 240, loss: 0.06869492679834366
step: 250, loss: 0.051788780838251114
step: 260, loss: 0.04151690751314163
step: 270, loss: 0.05306130275130272
step: 280, loss: 0.234613299369812
step: 290, loss: 0.09341899305582047
step: 300, loss: 0.18777652084827423
step: 310, loss: 0.14319159090518951
step: 320, loss: 0.12961770594120026
step: 330, loss: 0.12770313024520874
step: 340, loss: 0.0743347629904747
step: 350, loss: 0.08247560262680054
step: 360, loss: 0.13341081142425537
step: 370, loss: 0.02934866026043892
step: 380, loss: 0.09389300644397736
step: 390, loss: 0.059994302690029144
step: 400, loss: 0.10482962429523468
step: 410, loss: 0.06816061586141586
step: 420, loss: 0.0759323313832283
step: 430, loss: 0.05961991474032402
step: 440, loss: 0.16407684981822968
step: 450, loss: 0.02990146167576313
step: 460, loss: 0.21480600535869598
epoch 1: dev_f1=0.9876265466816648, f1=0.9774774774774775, best_f1=0.9774774774774775
step: 0, loss: 0.09462692588567734
step: 10, loss: 0.07298029214143753
step: 20, loss: 0.05350148305296898
step: 30, loss: 0.046744950115680695
step: 40, loss: 0.05614188686013222
step: 50, loss: 0.019507160410284996
step: 60, loss: 0.13943526148796082
step: 70, loss: 0.06811608374118805
step: 80, loss: 0.05811484158039093
step: 90, loss: 0.18603411316871643
step: 100, loss: 0.05038031190633774
step: 110, loss: 0.0010701739229261875
step: 120, loss: 0.02126646600663662
step: 130, loss: 0.020693859085440636
step: 140, loss: 0.16959960758686066
step: 150, loss: 0.1150459423661232
step: 160, loss: 0.034326452761888504
step: 170, loss: 0.03795647993683815
step: 180, loss: 0.09942156076431274
step: 190, loss: 0.1527160406112671
step: 200, loss: 0.07678864896297455
step: 210, loss: 0.0269380621612072
step: 220, loss: 0.1681608408689499
step: 230, loss: 0.07421838492155075
step: 240, loss: 0.12296630442142487
step: 250, loss: 0.0061884294264018536
step: 260, loss: 0.07436425238847733
step: 270, loss: 0.020055819302797318
step: 280, loss: 0.09399840980768204
step: 290, loss: 0.08972932398319244
step: 300, loss: 0.06331553310155869
step: 310, loss: 0.06948654353618622
step: 320, loss: 0.03909534960985184
step: 330, loss: 0.03876730054616928
step: 340, loss: 0.059422027319669724
step: 350, loss: 0.05309566110372543
step: 360, loss: 0.08413171768188477
step: 370, loss: 0.1226467490196228
step: 380, loss: 0.041643429547548294
step: 390, loss: 0.05747552961111069
step: 400, loss: 0.04634581506252289
step: 410, loss: 0.08391427993774414
step: 420, loss: 0.02458929270505905
step: 430, loss: 0.058590471744537354
step: 440, loss: 0.027150264009833336
step: 450, loss: 0.16519320011138916
step: 460, loss: 0.08192609250545502
epoch 2: dev_f1=0.9865168539325843, f1=0.9819819819819819, best_f1=0.9774774774774775
step: 0, loss: 0.037933021783828735
step: 10, loss: 0.07463418692350388
step: 20, loss: 0.0316961370408535
step: 30, loss: 0.0638771653175354
step: 40, loss: 0.014926265925168991
step: 50, loss: 0.1332973837852478
step: 60, loss: 0.033759668469429016
step: 70, loss: 0.022753385826945305
step: 80, loss: 0.09281092137098312
step: 90, loss: 0.12102988362312317
step: 100, loss: 0.013206446543335915
step: 110, loss: 0.011208049021661282
step: 120, loss: 0.09153979271650314
step: 130, loss: 0.050927478820085526
step: 140, loss: 0.0771763026714325
step: 150, loss: 0.03323577344417572
step: 160, loss: 0.016710564494132996
step: 170, loss: 0.031080981716513634
step: 180, loss: 0.13902157545089722
step: 190, loss: 0.013864400796592236
step: 200, loss: 0.051493920385837555
step: 210, loss: 0.08903487771749496
step: 220, loss: 0.010952308773994446
step: 230, loss: 0.024552742019295692
step: 240, loss: 0.10097479075193405
step: 250, loss: 0.025091255083680153
step: 260, loss: 0.05878094211220741
step: 270, loss: 0.1444932520389557
step: 280, loss: 0.07928981631994247
step: 290, loss: 0.07811443507671356
step: 300, loss: 0.06464219838380814
step: 310, loss: 0.008290674537420273
step: 320, loss: 0.2625206410884857
step: 330, loss: 0.05245622992515564
step: 340, loss: 0.026570260524749756
step: 350, loss: 0.03498219698667526
step: 360, loss: 0.16570106148719788
step: 370, loss: 0.059256769716739655
step: 380, loss: 0.04057754948735237
step: 390, loss: 0.06520549207925797
step: 400, loss: 0.026194054633378983
step: 410, loss: 0.15888133645057678
step: 420, loss: 0.09346941858530045
step: 430, loss: 0.021821359172463417
step: 440, loss: 0.08108406513929367
step: 450, loss: 0.029898570850491524
step: 460, loss: 0.015600757673382759
epoch 3: dev_f1=0.9909706546275394, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.00933642778545618
step: 10, loss: 0.011592946946620941
step: 20, loss: 0.0061436984688043594
step: 30, loss: 0.12806151807308197
step: 40, loss: 0.07912701368331909
step: 50, loss: 0.0067710187286138535
step: 60, loss: 0.08682185411453247
step: 70, loss: 0.04840656369924545
step: 80, loss: 0.015853144228458405
step: 90, loss: 0.07229459285736084
step: 100, loss: 0.06645559519529343
step: 110, loss: 0.178311288356781
step: 120, loss: 0.041130997240543365
step: 130, loss: 0.060644663870334625
step: 140, loss: 0.0073294672183692455
step: 150, loss: 0.011783500202000141
step: 160, loss: 0.06609228253364563
step: 170, loss: 0.01862763985991478
step: 180, loss: 0.012765130959451199
step: 190, loss: 0.05395277962088585
step: 200, loss: 0.010699210688471794
step: 210, loss: 0.01822785846889019
step: 220, loss: 0.04453318193554878
step: 230, loss: 0.046592723578214645
step: 240, loss: 0.06966841220855713
step: 250, loss: 0.055849574506282806
step: 260, loss: 0.065358966588974
step: 270, loss: 0.05315393581986427
step: 280, loss: 0.1567460000514984
step: 290, loss: 0.05893293395638466
step: 300, loss: 0.09238509088754654
step: 310, loss: 0.02265201322734356
step: 320, loss: 0.07865159213542938
step: 330, loss: 0.03667872026562691
step: 340, loss: 0.03340409696102142
step: 350, loss: 0.08158071339130402
step: 360, loss: 0.02951003983616829
step: 370, loss: 0.012317090295255184
step: 380, loss: 0.14393725991249084
step: 390, loss: 0.056237779557704926
step: 400, loss: 0.007239396218210459
step: 410, loss: 0.1152157112956047
step: 420, loss: 0.11217258125543594
step: 430, loss: 0.012950917705893517
step: 440, loss: 0.007748914882540703
step: 450, loss: 0.09373866766691208
step: 460, loss: 0.048715174198150635
epoch 4: dev_f1=0.9876543209876544, f1=0.9841269841269841, best_f1=0.9809203142536477
step: 0, loss: 0.007586610969156027
step: 10, loss: 0.038585323840379715
step: 20, loss: 0.03930201008915901
step: 30, loss: 0.0007797597791068256
step: 40, loss: 0.16438643634319305
step: 50, loss: 0.046256668865680695
step: 60, loss: 0.00920941587537527
step: 70, loss: 0.0831916406750679
step: 80, loss: 0.014155130833387375
step: 90, loss: 0.00446375971660018
step: 100, loss: 0.014420483261346817
step: 110, loss: 0.023914722725749016
step: 120, loss: 0.008799396455287933
step: 130, loss: 0.016880957409739494
step: 140, loss: 0.007522578816860914
step: 150, loss: 0.06048052757978439
step: 160, loss: 0.08189080655574799
step: 170, loss: 0.039739660918712616
step: 180, loss: 0.009528364054858685
step: 190, loss: 0.008101249113678932
step: 200, loss: 0.012427113018929958
step: 210, loss: 0.03475375846028328
step: 220, loss: 0.07287802547216415
step: 230, loss: 0.07057923078536987
step: 240, loss: 0.02139170654118061
step: 250, loss: 0.012218369171023369
step: 260, loss: 0.00011844546679640189
step: 270, loss: 0.0176247451454401
step: 280, loss: 0.07315300405025482
step: 290, loss: 0.006511029787361622
step: 300, loss: 0.016327323392033577
step: 310, loss: 0.14896751940250397
step: 320, loss: 0.012142360210418701
step: 330, loss: 0.007342163007706404
step: 340, loss: 0.05096738785505295
step: 350, loss: 0.11625577509403229
step: 360, loss: 0.131704181432724
step: 370, loss: 0.0069356742314994335
step: 380, loss: 0.04757619649171829
step: 390, loss: 0.009648697450757027
step: 400, loss: 0.056492600589990616
step: 410, loss: 0.03066488727927208
step: 420, loss: 0.03673788160085678
step: 430, loss: 0.07921375334262848
step: 440, loss: 0.05533730238676071
step: 450, loss: 0.07474758476018906
step: 460, loss: 0.016668207943439484
epoch 5: dev_f1=0.9932126696832579, f1=0.9841628959276018, best_f1=0.9841628959276018
step: 0, loss: 0.015563206747174263
step: 10, loss: 0.06117599084973335
step: 20, loss: 0.06309530138969421
step: 30, loss: 0.014901148155331612
step: 40, loss: 0.028641143813729286
step: 50, loss: 0.09109926968812943
step: 60, loss: 0.05610558018088341
step: 70, loss: 0.01755915954709053
step: 80, loss: 0.07913856208324432
step: 90, loss: 0.050986066460609436
step: 100, loss: 0.15066510438919067
step: 110, loss: 0.00763813266530633
step: 120, loss: 0.07624682039022446
step: 130, loss: 0.018732596188783646
step: 140, loss: 0.0158999003469944
step: 150, loss: 0.08852681517601013
step: 160, loss: 9.600383054930717e-05
step: 170, loss: 6.558492168551311e-05
step: 180, loss: 0.009151043370366096
step: 190, loss: 0.07309722155332565
step: 200, loss: 0.03360713645815849
step: 210, loss: 0.005120052490383387
step: 220, loss: 0.25653013586997986
step: 230, loss: 0.013507626950740814
step: 240, loss: 0.0881347507238388
step: 250, loss: 0.08777914196252823
step: 260, loss: 0.015195277519524097
step: 270, loss: 0.07051216065883636
step: 280, loss: 0.05551281198859215
step: 290, loss: 0.035564444959163666
step: 300, loss: 0.01495432574301958
step: 310, loss: 0.11085399985313416
step: 320, loss: 0.08322485536336899
step: 330, loss: 0.030204400420188904
step: 340, loss: 0.003647587727755308
step: 350, loss: 0.01596113294363022
step: 360, loss: 0.05900280550122261
step: 370, loss: 0.007830015383660793
step: 380, loss: 0.022481752559542656
step: 390, loss: 0.12071922421455383
step: 400, loss: 0.051502835005521774
step: 410, loss: 0.10988189280033112
step: 420, loss: 0.022841159254312515
step: 430, loss: 0.14358104765415192
step: 440, loss: 0.02155095525085926
step: 450, loss: 0.17212316393852234
step: 460, loss: 0.0338464230298996
epoch 6: dev_f1=0.9943502824858756, f1=0.9841628959276018, best_f1=0.9841628959276018
step: 0, loss: 0.03621713072061539
step: 10, loss: 0.004977417178452015
step: 20, loss: 0.015201359055936337
step: 30, loss: 0.01469071488827467
step: 40, loss: 0.16316598653793335
step: 50, loss: 0.022478561848402023
step: 60, loss: 0.009747742675244808
step: 70, loss: 0.17261312901973724
step: 80, loss: 0.040494732558727264
step: 90, loss: 0.08965875953435898
step: 100, loss: 0.03257275000214577
step: 110, loss: 0.03810394927859306
step: 120, loss: 0.04854697361588478
step: 130, loss: 0.017493439838290215
step: 140, loss: 0.12038033455610275
step: 150, loss: 0.04319123923778534
step: 160, loss: 0.036213621497154236
step: 170, loss: 0.022555191069841385
step: 180, loss: 0.014758381992578506
step: 190, loss: 0.057597801089286804
step: 200, loss: 0.010563923045992851
step: 210, loss: 0.005910631734877825
step: 220, loss: 0.03518196940422058
step: 230, loss: 0.006858225911855698
step: 240, loss: 0.009391598403453827
step: 250, loss: 0.00936590600758791
step: 260, loss: 0.04941829666495323
step: 270, loss: 0.021630803123116493
step: 280, loss: 0.053581368178129196
step: 290, loss: 0.03765388950705528
step: 300, loss: 0.019212307408452034
step: 310, loss: 0.008263406343758106
step: 320, loss: 0.07388578355312347
step: 330, loss: 0.11033248156309128
step: 340, loss: 0.0573180690407753
step: 350, loss: 0.021198660135269165
step: 360, loss: 0.05798611044883728
step: 370, loss: 0.007952171377837658
step: 380, loss: 0.019999971613287926
step: 390, loss: 0.1054467260837555
step: 400, loss: 0.012487845495343208
step: 410, loss: 0.08169783651828766
step: 420, loss: 0.07381954789161682
step: 430, loss: 0.09226968884468079
step: 440, loss: 0.08264986425638199
step: 450, loss: 0.06537824124097824
step: 460, loss: 0.11629742383956909
epoch 7: dev_f1=0.9932126696832579, f1=0.9864253393665158, best_f1=0.9841628959276018
step: 0, loss: 0.00801822543144226
step: 10, loss: 0.009206649847328663
step: 20, loss: 0.014238573610782623
step: 30, loss: 0.0669245794415474
step: 40, loss: 0.007043836638331413
step: 50, loss: 0.014742626808583736
step: 60, loss: 0.006938963197171688
step: 70, loss: 0.008101307787001133
step: 80, loss: 0.17627489566802979
step: 90, loss: 0.006023780442774296
step: 100, loss: 0.008725604973733425
step: 110, loss: 0.031673941761255264
step: 120, loss: 0.18710561096668243
step: 130, loss: 0.03375634923577309
step: 140, loss: 0.022157719358801842
step: 150, loss: 0.29670000076293945
step: 160, loss: 0.009109239093959332
step: 170, loss: 0.0598529614508152
step: 180, loss: 0.02020786516368389
step: 190, loss: 0.011370161548256874
step: 200, loss: 0.03284025192260742
step: 210, loss: 0.11652924865484238
step: 220, loss: 0.014190343208611012
step: 230, loss: 0.06332021206617355
step: 240, loss: 0.0358150377869606
step: 250, loss: 0.04917338490486145
step: 260, loss: 0.051859695464372635
step: 270, loss: 0.04695502668619156
step: 280, loss: 0.012107476592063904
step: 290, loss: 0.07152146100997925
step: 300, loss: 0.08709924668073654
step: 310, loss: 0.109965980052948
step: 320, loss: 0.07411635667085648
step: 330, loss: 0.03325450047850609
step: 340, loss: 0.030983557924628258
step: 350, loss: 0.0186309851706028
step: 360, loss: 0.06884689629077911
step: 370, loss: 0.10973633825778961
step: 380, loss: 0.016520187258720398
step: 390, loss: 0.021633565425872803
step: 400, loss: 0.009057433344423771
step: 410, loss: 0.005933744367212057
step: 420, loss: 0.017191193997859955
step: 430, loss: 0.01334424875676632
step: 440, loss: 0.04924019053578377
step: 450, loss: 0.017393026500940323
step: 460, loss: 0.06267515569925308
epoch 8: dev_f1=0.9943502824858756, f1=0.983050847457627, best_f1=0.9841628959276018
step: 0, loss: 0.0013345179613679647
step: 10, loss: 0.0657106339931488
step: 20, loss: 0.018313689157366753
step: 30, loss: 0.08184569329023361
step: 40, loss: 0.021313991397619247
step: 50, loss: 0.020481541752815247
step: 60, loss: 0.04527541249990463
step: 70, loss: 0.07293245196342468
step: 80, loss: 0.044061969965696335
step: 90, loss: 0.017813604325056076
step: 100, loss: 0.01619107276201248
step: 110, loss: 0.00014979061961639673
step: 120, loss: 0.028648851439356804
step: 130, loss: 0.019777657464146614
step: 140, loss: 0.058914221823215485
step: 150, loss: 0.03975905478000641
step: 160, loss: 0.016389677301049232
step: 170, loss: 0.08023730665445328
step: 180, loss: 0.012306341901421547
step: 190, loss: 0.045560095459222794
step: 200, loss: 0.012099369429051876
step: 210, loss: 0.006759533658623695
step: 220, loss: 0.18874506652355194
step: 230, loss: 0.017906133085489273
step: 240, loss: 0.10808894783258438
step: 250, loss: 0.018837157636880875
step: 260, loss: 0.0005525663727894425
step: 270, loss: 0.024225862696766853
step: 280, loss: 0.00715138204395771
step: 290, loss: 0.007413453422486782
step: 300, loss: 0.019270414486527443
step: 310, loss: 0.040253907442092896
step: 320, loss: 0.06249010190367699
step: 330, loss: 0.009431755170226097
step: 340, loss: 0.09112163633108139
step: 350, loss: 0.04584689065814018
step: 360, loss: 0.09134655445814133
step: 370, loss: 0.1150335967540741
step: 380, loss: 0.03268195316195488
step: 390, loss: 0.0004328723007347435
step: 400, loss: 0.07448884844779968
step: 410, loss: 0.005608696490526199
step: 420, loss: 0.015041099861264229
step: 430, loss: 0.01191114541143179
step: 440, loss: 0.047509800642728806
step: 450, loss: 0.03066197969019413
step: 460, loss: 0.14056679606437683
epoch 9: dev_f1=0.9920903954802259, f1=0.9875706214689265, best_f1=0.9841628959276018
step: 0, loss: 0.03459145873785019
step: 10, loss: 0.021228179335594177
step: 20, loss: 0.04206612706184387
step: 30, loss: 0.006430641748011112
step: 40, loss: 0.0035055677872151136
step: 50, loss: 0.05635645240545273
step: 60, loss: 0.10210365802049637
step: 70, loss: 0.012813026085495949
step: 80, loss: 0.017114922404289246
step: 90, loss: 0.004662053659558296
step: 100, loss: 0.005108815152198076
step: 110, loss: 0.0017763902433216572
step: 120, loss: 0.0013422865886241198
step: 130, loss: 0.09401927143335342
step: 140, loss: 0.03034522756934166
step: 150, loss: 0.017515908926725388
step: 160, loss: 0.013951679691672325
step: 170, loss: 0.0180109404027462
step: 180, loss: 0.08023109287023544
step: 190, loss: 0.04254204034805298
step: 200, loss: 0.004313154146075249
step: 210, loss: 0.020718708634376526
step: 220, loss: 0.11032257974147797
step: 230, loss: 0.015694379806518555
step: 240, loss: 0.018678855150938034
step: 250, loss: 0.08371059596538544
step: 260, loss: 0.004457866307348013
step: 270, loss: 0.04097885265946388
step: 280, loss: 0.17279119789600372
step: 290, loss: 0.060174908488988876
step: 300, loss: 0.07387904822826385
step: 310, loss: 0.024805430322885513
step: 320, loss: 0.0017124718287959695
step: 330, loss: 0.005329460836946964
step: 340, loss: 0.011018061079084873
step: 350, loss: 0.1064443439245224
step: 360, loss: 0.0480874702334404
step: 370, loss: 0.024281440302729607
step: 380, loss: 0.00021858944091945887
step: 390, loss: 0.019449885934591293
step: 400, loss: 0.012014945968985558
step: 410, loss: 0.006491717416793108
step: 420, loss: 0.0011771066347137094
step: 430, loss: 0.002032484859228134
step: 440, loss: 0.03379121795296669
step: 450, loss: 0.006436238065361977
step: 460, loss: 0.020731886848807335
epoch 10: dev_f1=0.9876265466816648, f1=0.9841986455981941, best_f1=0.9841628959276018
step: 0, loss: 0.03599492460489273
step: 10, loss: 0.02277691289782524
step: 20, loss: 0.04291627183556557
step: 30, loss: 0.04354982450604439
step: 40, loss: 0.04335745796561241
step: 50, loss: 0.0944368913769722
step: 60, loss: 0.03890782594680786
step: 70, loss: 0.0014090128242969513
step: 80, loss: 0.012379080057144165
step: 90, loss: 0.04630620405077934
step: 100, loss: 0.05534137412905693
step: 110, loss: 0.13956549763679504
step: 120, loss: 0.03588929399847984
step: 130, loss: 0.05297451466321945
step: 140, loss: 0.02374054118990898
step: 150, loss: 0.08839066326618195
step: 160, loss: 0.10033899545669556
step: 170, loss: 0.01710677333176136
step: 180, loss: 0.03039584495127201
step: 190, loss: 0.0019489303231239319
step: 200, loss: 0.03184245154261589
step: 210, loss: 0.05755548179149628
step: 220, loss: 0.09357675164937973
step: 230, loss: 0.02796294167637825
step: 240, loss: 0.023054882884025574
step: 250, loss: 0.03598841279745102
step: 260, loss: 5.6941502407426015e-05
step: 270, loss: 0.02729206159710884
step: 280, loss: 0.025811543688178062
step: 290, loss: 0.024696826934814453
step: 300, loss: 0.09580295532941818
step: 310, loss: 0.06651860475540161
step: 320, loss: 0.0003697903302963823
step: 330, loss: 0.05009710416197777
step: 340, loss: 0.08776447176933289
step: 350, loss: 0.0014324449002742767
step: 360, loss: 0.04392583668231964
step: 370, loss: 0.0379658080637455
step: 380, loss: 0.04474896937608719
step: 390, loss: 0.07677433639764786
step: 400, loss: 0.016497576609253883
step: 410, loss: 0.006037114653736353
step: 420, loss: 0.0006633171578869224
step: 430, loss: 0.009198462590575218
step: 440, loss: 0.10775215178728104
step: 450, loss: 0.07479684799909592
step: 460, loss: 0.11623473465442657
epoch 11: dev_f1=0.9909502262443439, f1=0.9785310734463276, best_f1=0.9841628959276018
step: 0, loss: 0.003693251870572567
step: 10, loss: 0.01220807246863842
step: 20, loss: 0.0005626301863230765
step: 30, loss: 0.00018009738414548337
step: 40, loss: 0.030159441754221916
step: 50, loss: 0.00016898287867661566
step: 60, loss: 0.013700537383556366
step: 70, loss: 0.0005167375784367323
step: 80, loss: 0.056820690631866455
step: 90, loss: 0.02449762262403965
step: 100, loss: 0.0317518450319767
step: 110, loss: 0.0028672092594206333
step: 120, loss: 0.025914892554283142
step: 130, loss: 0.001091875834390521
step: 140, loss: 0.03588016703724861
step: 150, loss: 0.05037706717848778
step: 160, loss: 0.04055827856063843
step: 170, loss: 0.04566860571503639
step: 180, loss: 0.08084164559841156
step: 190, loss: 0.01992817223072052
step: 200, loss: 0.002050065901130438
step: 210, loss: 0.035259827971458435
step: 220, loss: 0.023476378992199898
step: 230, loss: 0.040097229182720184
step: 240, loss: 0.017835207283496857
step: 250, loss: 0.06465870141983032
step: 260, loss: 0.04174700006842613
step: 270, loss: 0.032292403280735016
step: 280, loss: 0.0010795819107443094
step: 290, loss: 0.023754097521305084
step: 300, loss: 0.0806674137711525
step: 310, loss: 0.036214713007211685
step: 320, loss: 0.07833613455295563
step: 330, loss: 2.6646366677596234e-05
step: 340, loss: 0.019041474908590317
step: 350, loss: 0.04506559297442436
step: 360, loss: 0.03854650631546974
step: 370, loss: 0.04026041924953461
step: 380, loss: 0.040960174053907394
step: 390, loss: 0.0019667940214276314
step: 400, loss: 0.014703408814966679
step: 410, loss: 0.04170852154493332
step: 420, loss: 0.0001072478698915802
step: 430, loss: 2.6146577511099167e-05
step: 440, loss: 0.004995637573301792
step: 450, loss: 0.045875146985054016
step: 460, loss: 0.10676534473896027
epoch 12: dev_f1=0.9943502824858756, f1=0.987598647125141, best_f1=0.9841628959276018
step: 0, loss: 0.012786328792572021
step: 10, loss: 0.04586836323142052
step: 20, loss: 0.0775492936372757
step: 30, loss: 0.08490004390478134
step: 40, loss: 0.0012892729137092829
step: 50, loss: 0.0020484747365117073
step: 60, loss: 0.01233627274632454
step: 70, loss: 0.07131457328796387
step: 80, loss: 0.0008387555135414004
step: 90, loss: 0.029523832723498344
step: 100, loss: 0.000523355498444289
step: 110, loss: 0.012745261192321777
step: 120, loss: 0.0002322743384866044
step: 130, loss: 0.028573257848620415
step: 140, loss: 0.00025325382011942565
step: 150, loss: 0.029397396370768547
step: 160, loss: 0.0719171017408371
step: 170, loss: 0.041042618453502655
step: 180, loss: 0.02287091501057148
step: 190, loss: 0.007063369732350111
step: 200, loss: 0.03484615683555603
step: 210, loss: 0.049728721380233765
step: 220, loss: 0.012529118917882442
step: 230, loss: 0.13153418898582458
step: 240, loss: 0.003974833060055971
step: 250, loss: 0.04177192226052284
step: 260, loss: 0.00021122919861227274
step: 270, loss: 0.00024260270583909005
step: 280, loss: 0.05998310074210167
step: 290, loss: 0.03097025863826275
step: 300, loss: 0.0262522604316473
step: 310, loss: 0.04754944518208504
step: 320, loss: 0.01986251026391983
step: 330, loss: 0.04767484590411186
step: 340, loss: 0.025267915800213814
step: 350, loss: 0.2171241044998169
step: 360, loss: 0.006368635222315788
step: 370, loss: 0.05084360018372536
step: 380, loss: 0.005451036151498556
step: 390, loss: 0.019731180742383003
step: 400, loss: 0.04113844409584999
step: 410, loss: 0.024636203423142433
step: 420, loss: 0.003486551344394684
step: 430, loss: 0.04416414722800255
step: 440, loss: 0.013183553703129292
step: 450, loss: 0.05652391165494919
step: 460, loss: 0.08453681319952011
epoch 13: dev_f1=0.9932279909706545, f1=0.9820627802690582, best_f1=0.9841628959276018
step: 0, loss: 0.09376569837331772
step: 10, loss: 0.08486003428697586
step: 20, loss: 0.025009365752339363
step: 30, loss: 0.0002034871868090704
step: 40, loss: 0.08215031772851944
step: 50, loss: 0.0021308816503733397
step: 60, loss: 0.034874655306339264
step: 70, loss: 0.014848196879029274
step: 80, loss: 0.05230753868818283
step: 90, loss: 0.0012137116864323616
step: 100, loss: 0.027296004816889763
step: 110, loss: 0.026816831901669502
step: 120, loss: 0.023324716836214066
step: 130, loss: 0.0031705829314887524
step: 140, loss: 0.046524204313755035
step: 150, loss: 0.07129871845245361
step: 160, loss: 0.03581588342785835
step: 170, loss: 0.05268814042210579
step: 180, loss: 0.07271011173725128
step: 190, loss: 0.002527930773794651
step: 200, loss: 0.00014621867740061134
step: 210, loss: 0.05510726198554039
step: 220, loss: 0.07631754130125046
step: 230, loss: 0.00014268350787460804
step: 240, loss: 0.09521780163049698
step: 250, loss: 0.07335268706083298
step: 260, loss: 0.05987359583377838
step: 270, loss: 0.004074809607118368
step: 280, loss: 0.05453765019774437
step: 290, loss: 0.06356114149093628
step: 300, loss: 0.10754011571407318
step: 310, loss: 0.02530422993004322
step: 320, loss: 0.026215465739369392
step: 330, loss: 0.06307891756296158
step: 340, loss: 0.04412057250738144
step: 350, loss: 0.00430290587246418
step: 360, loss: 0.0010680019622668624
step: 370, loss: 0.002719888463616371
step: 380, loss: 0.0007602982805110514
step: 390, loss: 0.0012064877664670348
step: 400, loss: 0.06608545780181885
step: 410, loss: 0.025144638493657112
step: 420, loss: 0.001177005236968398
step: 430, loss: 0.023492779582738876
step: 440, loss: 0.051873546093702316
step: 450, loss: 0.020216433331370354
step: 460, loss: 0.0007913543959148228
epoch 14: dev_f1=0.9932279909706545, f1=0.9831649831649831, best_f1=0.9841628959276018
step: 0, loss: 0.057036157697439194
step: 10, loss: 0.002324615139514208
step: 20, loss: 9.302223770646378e-05
step: 30, loss: 7.341058517340571e-05
step: 40, loss: 0.00010333626414649189
step: 50, loss: 0.06312058866024017
step: 60, loss: 0.011663906276226044
step: 70, loss: 0.06751269102096558
step: 80, loss: 0.025585470721125603
step: 90, loss: 0.0667264312505722
step: 100, loss: 0.04449012130498886
step: 110, loss: 0.0750330314040184
step: 120, loss: 4.5613629481522366e-05
step: 130, loss: 0.04051472246646881
step: 140, loss: 0.03753083944320679
step: 150, loss: 0.00021797799854539335
step: 160, loss: 0.02505476586520672
step: 170, loss: 0.0001234421506524086
step: 180, loss: 0.0031498530879616737
step: 190, loss: 0.004746599588543177
step: 200, loss: 0.00014231615932658315
step: 210, loss: 0.030308328568935394
step: 220, loss: 0.00010208868479821831
step: 230, loss: 0.03517187386751175
step: 240, loss: 0.000108291809738148
step: 250, loss: 0.0005457970546558499
step: 260, loss: 0.04951821267604828
step: 270, loss: 0.07645963132381439
step: 280, loss: 0.01863138936460018
step: 290, loss: 0.045043256133794785
step: 300, loss: 0.0014940169639885426
step: 310, loss: 0.02158173732459545
step: 320, loss: 0.07170134037733078
step: 330, loss: 0.01456493977457285
step: 340, loss: 0.06507871299982071
step: 350, loss: 0.048989392817020416
step: 360, loss: 5.396831693360582e-05
step: 370, loss: 0.01785741001367569
step: 380, loss: 0.07436352968215942
step: 390, loss: 0.025875484570860863
step: 400, loss: 0.05239851400256157
step: 410, loss: 0.018933838233351707
step: 420, loss: 0.01960471086204052
step: 430, loss: 0.0649830624461174
step: 440, loss: 0.025213779881596565
step: 450, loss: 0.020583610981702805
step: 460, loss: 0.0012791119515895844
epoch 15: dev_f1=0.992108229988726, f1=0.9821029082774049, best_f1=0.9841628959276018
step: 0, loss: 0.018543904647231102
step: 10, loss: 0.0005997912958264351
step: 20, loss: 0.020860668271780014
step: 30, loss: 0.06282515078783035
step: 40, loss: 0.024836048483848572
step: 50, loss: 0.008131291717290878
step: 60, loss: 0.13715162873268127
step: 70, loss: 0.00879716221243143
step: 80, loss: 0.024619320407509804
step: 90, loss: 0.0024160733446478844
step: 100, loss: 0.040938738733530045
step: 110, loss: 0.08946159482002258
step: 120, loss: 0.038179121911525726
step: 130, loss: 0.05972549691796303
step: 140, loss: 0.039460133761167526
step: 150, loss: 0.04363707825541496
step: 160, loss: 0.042954497039318085
step: 170, loss: 0.018780294805765152
step: 180, loss: 0.019863637164235115
step: 190, loss: 0.021957574412226677
step: 200, loss: 0.0009606878156773746
step: 210, loss: 0.027426015585660934
step: 220, loss: 0.025070562958717346
step: 230, loss: 0.05194995924830437
step: 240, loss: 0.03309827670454979
step: 250, loss: 4.9942187615670264e-05
step: 260, loss: 0.030194755643606186
step: 270, loss: 0.019503556191921234
step: 280, loss: 7.513198943343014e-05
step: 290, loss: 0.021282639354467392
step: 300, loss: 0.021248286589980125
step: 310, loss: 0.048338115215301514
step: 320, loss: 0.11975205689668655
step: 330, loss: 0.04913588985800743
step: 340, loss: 0.03708392009139061
step: 350, loss: 0.05090069770812988
step: 360, loss: 0.05218077450990677
step: 370, loss: 0.02602083422243595
step: 380, loss: 0.03974774852395058
step: 390, loss: 0.07302121818065643
step: 400, loss: 0.018299052491784096
step: 410, loss: 0.06736233830451965
step: 420, loss: 0.021978575736284256
step: 430, loss: 0.001247265376150608
step: 440, loss: 0.026600776240229607
step: 450, loss: 0.04815966263413429
step: 460, loss: 0.0014525731094181538
epoch 16: dev_f1=0.9920903954802259, f1=0.9797752808988766, best_f1=0.9841628959276018
step: 0, loss: 0.04824894294142723
step: 10, loss: 0.04795778542757034
step: 20, loss: 0.0412137545645237
step: 30, loss: 7.711959187872708e-05
step: 40, loss: 0.015527855604887009
step: 50, loss: 0.022936122491955757
step: 60, loss: 0.026849349960684776
step: 70, loss: 2.251024852739647e-05
step: 80, loss: 0.010542357340455055
step: 90, loss: 0.00014959581312723458
step: 100, loss: 0.016667131334543228
step: 110, loss: 6.775340443709865e-05
step: 120, loss: 0.03899211063981056
step: 130, loss: 0.04769003391265869
step: 140, loss: 8.178070129361004e-05
step: 150, loss: 3.557230229489505e-05
step: 160, loss: 0.00010179913806496188
step: 170, loss: 5.865310231456533e-05
step: 180, loss: 0.06000981107354164
step: 190, loss: 0.09574010968208313
step: 200, loss: 0.04371079057455063
step: 210, loss: 0.0007785913767293096
step: 220, loss: 0.025690587237477303
step: 230, loss: 0.0006041357410140336
step: 240, loss: 0.025228226557374
step: 250, loss: 0.024032387882471085
step: 260, loss: 0.029050804674625397
step: 270, loss: 0.03785044699907303
step: 280, loss: 0.0014017511857673526
step: 290, loss: 0.04027840867638588
step: 300, loss: 0.00045714981388300657
step: 310, loss: 3.5590826882980764e-05
step: 320, loss: 0.01652090810239315
step: 330, loss: 3.82409525627736e-05
step: 340, loss: 0.042305655777454376
step: 350, loss: 4.0123890357790515e-05
step: 360, loss: 0.03118249960243702
step: 370, loss: 3.469104558462277e-05
step: 380, loss: 0.02470642887055874
step: 390, loss: 0.0013670262414962053
step: 400, loss: 0.024870669469237328
step: 410, loss: 0.016698718070983887
step: 420, loss: 8.672587136970833e-05
step: 430, loss: 9.691554441815242e-05
step: 440, loss: 0.00012693095777649432
step: 450, loss: 0.05709883198142052
step: 460, loss: 0.009869524277746677
epoch 17: dev_f1=0.9932279909706545, f1=0.9832026875699889, best_f1=0.9841628959276018
step: 0, loss: 0.022594477981328964
step: 10, loss: 0.000238043227000162
step: 20, loss: 3.1217812647810206e-05
step: 30, loss: 0.0001144610796472989
step: 40, loss: 0.05125907436013222
step: 50, loss: 2.4663691874593496e-05
step: 60, loss: 0.12701977789402008
step: 70, loss: 0.07631173729896545
step: 80, loss: 0.00042324705282226205
step: 90, loss: 9.303531260229647e-05
step: 100, loss: 0.021243562921881676
step: 110, loss: 0.00027448852779343724
step: 120, loss: 0.021781399846076965
step: 130, loss: 0.06715413182973862
step: 140, loss: 0.023994674906134605
step: 150, loss: 1.1820228792203125e-05
step: 160, loss: 0.017536906525492668
step: 170, loss: 8.63551686052233e-05
step: 180, loss: 0.03605249896645546
step: 190, loss: 0.021490398794412613
step: 200, loss: 0.01365942507982254
step: 210, loss: 0.040526460856199265
step: 220, loss: 0.07144606858491898
step: 230, loss: 0.015193196944892406
step: 240, loss: 0.003893492044880986
step: 250, loss: 0.07000267505645752
step: 260, loss: 0.08351745456457138
step: 270, loss: 0.021593276411294937
step: 280, loss: 9.353599307360128e-05
step: 290, loss: 0.07501127570867538
step: 300, loss: 0.037837494164705276
step: 310, loss: 0.0008344503003172576
step: 320, loss: 0.004189533181488514
step: 330, loss: 0.00012893317034468055
step: 340, loss: 0.07757842540740967
step: 350, loss: 0.02114945277571678
step: 360, loss: 0.04372159391641617
step: 370, loss: 0.018821248784661293
step: 380, loss: 0.00921736378222704
step: 390, loss: 0.019998256117105484
step: 400, loss: 0.023695360869169235
step: 410, loss: 0.00015174999134615064
step: 420, loss: 0.00013277874677442014
step: 430, loss: 0.050460703670978546
step: 440, loss: 3.129507604171522e-05
step: 450, loss: 0.0001452537690056488
step: 460, loss: 0.022812791168689728
epoch 18: dev_f1=0.9920903954802259, f1=0.9797297297297298, best_f1=0.9841628959276018
step: 0, loss: 0.026605410501360893
step: 10, loss: 0.03891030699014664
step: 20, loss: 7.801502215443179e-05
step: 30, loss: 0.04353543370962143
step: 40, loss: 0.04488178715109825
step: 50, loss: 0.020181970670819283
step: 60, loss: 0.04265868291258812
step: 70, loss: 0.01906956359744072
step: 80, loss: 0.02795368991792202
step: 90, loss: 0.02183808945119381
step: 100, loss: 3.7050351238576695e-05
step: 110, loss: 0.05271713063120842
step: 120, loss: 0.024126648902893066
step: 130, loss: 3.315131107228808e-05
step: 140, loss: 8.660844468977302e-05
step: 150, loss: 0.09448372572660446
step: 160, loss: 0.0629119873046875
step: 170, loss: 0.018500544130802155
step: 180, loss: 0.04736976698040962
step: 190, loss: 0.000721464108210057
step: 200, loss: 0.026485126465559006
step: 210, loss: 0.021171240136027336
step: 220, loss: 0.000116779949166812
step: 230, loss: 0.0008755185408517718
step: 240, loss: 0.041421953588724136
step: 250, loss: 0.02367878332734108
step: 260, loss: 7.81427079346031e-05
step: 270, loss: 0.003535961266607046
step: 280, loss: 5.595632319455035e-05
step: 290, loss: 3.7636036722688004e-05
step: 300, loss: 0.024349646642804146
step: 310, loss: 0.021463165059685707
step: 320, loss: 0.022248096764087677
step: 330, loss: 0.0767398253083229
step: 340, loss: 9.722141112433746e-05
step: 350, loss: 5.120564310345799e-05
step: 360, loss: 0.02596130035817623
step: 370, loss: 0.0001784623455023393
step: 380, loss: 0.0742323100566864
step: 390, loss: 2.6335319489589892e-05
step: 400, loss: 0.005301248282194138
step: 410, loss: 0.004772220738232136
step: 420, loss: 0.07547245174646378
step: 430, loss: 0.05265626311302185
step: 440, loss: 0.017371581867337227
step: 450, loss: 7.6931799412705e-05
step: 460, loss: 0.023529140278697014
epoch 19: dev_f1=0.9920903954802259, f1=0.9832026875699889, best_f1=0.9841628959276018
step: 0, loss: 0.0251045860350132
step: 10, loss: 0.01557250041514635
step: 20, loss: 8.696967415744439e-05
step: 30, loss: 0.07937920093536377
step: 40, loss: 0.042860470712184906
step: 50, loss: 0.0005038335802964866
step: 60, loss: 0.038323670625686646
step: 70, loss: 0.0001220849371748045
step: 80, loss: 0.001661872025579214
step: 90, loss: 0.045238617807626724
step: 100, loss: 0.00011597725097090006
step: 110, loss: 0.021118367090821266
step: 120, loss: 0.00020876119378954172
step: 130, loss: 0.07124786078929901
step: 140, loss: 0.02777669206261635
step: 150, loss: 5.23262242495548e-05
step: 160, loss: 0.00011607341002672911
step: 170, loss: 0.024019822478294373
step: 180, loss: 0.00017634726827964187
step: 190, loss: 4.292489029467106e-05
step: 200, loss: 0.06671805679798126
step: 210, loss: 0.02100139856338501
step: 220, loss: 1.1689749044307973e-05
step: 230, loss: 0.03123379498720169
step: 240, loss: 0.04343673959374428
step: 250, loss: 2.705012957449071e-05
step: 260, loss: 0.026484860107302666
step: 270, loss: 0.05443471297621727
step: 280, loss: 0.024983860552310944
step: 290, loss: 5.442675683298148e-05
step: 300, loss: 2.5178051146212965e-05
step: 310, loss: 0.047372329980134964
step: 320, loss: 0.09241120517253876
step: 330, loss: 0.020286496728658676
step: 340, loss: 6.098238372942433e-05
step: 350, loss: 7.007832027738914e-05
step: 360, loss: 0.0002007587463594973
step: 370, loss: 0.0012570660328492522
step: 380, loss: 0.07045473158359528
step: 390, loss: 0.02546919323503971
step: 400, loss: 0.00030792533652856946
step: 410, loss: 0.045433249324560165
step: 420, loss: 0.035409726202487946
step: 430, loss: 0.030022509396076202
step: 440, loss: 0.00014640262816101313
step: 450, loss: 0.023738183081150055
step: 460, loss: 5.3877571190241724e-05
epoch 20: dev_f1=0.9920903954802259, f1=0.9820627802690582, best_f1=0.9841628959276018
