cuda
Device: cuda
step: 0, loss: 0.5869293808937073
step: 10, loss: 0.2993119955062866
step: 20, loss: 0.45559683442115784
step: 30, loss: 0.5250393748283386
step: 40, loss: 0.13706374168395996
step: 50, loss: 0.11624527722597122
step: 60, loss: 0.17981496453285217
step: 70, loss: 0.07580488920211792
step: 80, loss: 0.21214941143989563
step: 90, loss: 0.03247753158211708
step: 100, loss: 0.0984032154083252
step: 110, loss: 0.05999094247817993
step: 120, loss: 0.13719411194324493
step: 130, loss: 0.08779557794332504
step: 140, loss: 0.14418071508407593
step: 150, loss: 0.0370066799223423
step: 160, loss: 0.0837731808423996
step: 170, loss: 0.09878995269536972
step: 180, loss: 0.04263560101389885
step: 190, loss: 0.257192462682724
step: 200, loss: 0.3052407503128052
step: 210, loss: 0.04703451320528984
step: 220, loss: 0.1394721418619156
step: 230, loss: 0.024793708696961403
step: 240, loss: 0.061227113008499146
step: 250, loss: 0.04791571944952011
step: 260, loss: 0.21087002754211426
step: 270, loss: 0.1275944709777832
step: 280, loss: 0.0328068882226944
step: 290, loss: 0.14098727703094482
step: 300, loss: 0.04271894320845604
step: 310, loss: 0.11990668624639511
step: 320, loss: 0.14278283715248108
step: 330, loss: 0.08370403200387955
step: 340, loss: 0.01789342612028122
step: 350, loss: 0.04050152748823166
step: 360, loss: 0.039360977709293365
step: 370, loss: 0.024672625586390495
step: 380, loss: 0.06826814264059067
step: 390, loss: 0.02661605179309845
step: 400, loss: 0.027227312326431274
step: 410, loss: 0.005822969600558281
step: 420, loss: 0.022206991910934448
step: 430, loss: 0.005323878023773432
step: 440, loss: 0.008653336204588413
step: 450, loss: 0.00771672185510397
step: 460, loss: 0.023933270946145058
epoch 1: dev_f1=0.990990990990991, f1=0.9796380090497738, best_f1=0.9796380090497738
step: 0, loss: 0.015411941334605217
step: 10, loss: 0.13280893862247467
step: 20, loss: 0.11464262753725052
step: 30, loss: 0.04744657129049301
step: 40, loss: 0.09676016867160797
step: 50, loss: 0.05264956131577492
step: 60, loss: 0.05708857625722885
step: 70, loss: 0.03931499272584915
step: 80, loss: 0.026106057688593864
step: 90, loss: 0.08483442664146423
step: 100, loss: 0.017911141738295555
step: 110, loss: 0.08444308489561081
step: 120, loss: 0.1617523729801178
step: 130, loss: 0.053975168615579605
step: 140, loss: 0.023448167368769646
step: 150, loss: 0.1413019448518753
step: 160, loss: 0.02881016582250595
step: 170, loss: 0.04764460399746895
step: 180, loss: 0.08378582447767258
step: 190, loss: 0.14986564218997955
step: 200, loss: 0.17530593276023865
step: 210, loss: 0.024154501035809517
step: 220, loss: 0.07621859014034271
step: 230, loss: 0.05943024903535843
step: 240, loss: 0.19131557643413544
step: 250, loss: 0.10096403956413269
step: 260, loss: 0.04643367975950241
step: 270, loss: 0.022069882601499557
step: 280, loss: 0.08822919428348541
step: 290, loss: 0.08285629004240036
step: 300, loss: 0.012180542573332787
step: 310, loss: 0.02860131300985813
step: 320, loss: 0.10936693847179413
step: 330, loss: 0.16389040648937225
step: 340, loss: 0.026958536356687546
step: 350, loss: 0.060099001973867416
step: 360, loss: 0.036726634949445724
step: 370, loss: 0.04280192032456398
step: 380, loss: 0.014864780008792877
step: 390, loss: 0.015513208694756031
step: 400, loss: 0.1804903894662857
step: 410, loss: 0.05763242393732071
step: 420, loss: 0.021554341539740562
step: 430, loss: 0.007308162283152342
step: 440, loss: 0.049193304032087326
step: 450, loss: 0.049034617841243744
step: 460, loss: 0.041145309805870056
epoch 2: dev_f1=0.9943757030371203, f1=0.9842342342342343, best_f1=0.9842342342342343
step: 0, loss: 0.0017931750044226646
step: 10, loss: 0.012953097000718117
step: 20, loss: 0.013202711008489132
step: 30, loss: 0.046509094536304474
step: 40, loss: 0.14665459096431732
step: 50, loss: 0.04351033270359039
step: 60, loss: 0.11441965401172638
step: 70, loss: 0.02272988297045231
step: 80, loss: 0.02725013718008995
step: 90, loss: 0.10275232046842575
step: 100, loss: 0.18186821043491364
step: 110, loss: 0.12822391092777252
step: 120, loss: 0.03271319717168808
step: 130, loss: 0.017497748136520386
step: 140, loss: 0.04116437956690788
step: 150, loss: 0.0071096597239375114
step: 160, loss: 0.012421541847288609
step: 170, loss: 0.003233832772821188
step: 180, loss: 0.10788357257843018
step: 190, loss: 0.0005055619985796511
step: 200, loss: 0.03850205987691879
step: 210, loss: 0.04065975546836853
step: 220, loss: 0.026600588113069534
step: 230, loss: 0.05486414581537247
step: 240, loss: 0.07735572010278702
step: 250, loss: 0.047704968601465225
step: 260, loss: 0.01733291894197464
step: 270, loss: 0.07407782971858978
step: 280, loss: 0.17444546520709991
step: 290, loss: 0.00017640423902776092
step: 300, loss: 0.0893775001168251
step: 310, loss: 0.001821373007260263
step: 320, loss: 0.015872100368142128
step: 330, loss: 0.07205399870872498
step: 340, loss: 0.08241201937198639
step: 350, loss: 0.08078522235155106
step: 360, loss: 0.07123015820980072
step: 370, loss: 0.02352515421807766
step: 380, loss: 0.0796687975525856
step: 390, loss: 0.026967063546180725
step: 400, loss: 0.030124017968773842
step: 410, loss: 0.02164764143526554
step: 420, loss: 0.07699819654226303
step: 430, loss: 0.08727072924375534
step: 440, loss: 0.14789652824401855
step: 450, loss: 0.03414537385106087
step: 460, loss: 0.01946287788450718
epoch 3: dev_f1=0.9921436588103255, f1=0.9865771812080537, best_f1=0.9842342342342343
step: 0, loss: 0.008361339569091797
step: 10, loss: 0.011963386088609695
step: 20, loss: 0.03648455813527107
step: 30, loss: 0.2628622353076935
step: 40, loss: 0.00021240462956484407
step: 50, loss: 0.03351805731654167
step: 60, loss: 0.010287109762430191
step: 70, loss: 0.11064623296260834
step: 80, loss: 0.1830868124961853
step: 90, loss: 0.03420798107981682
step: 100, loss: 0.018520191311836243
step: 110, loss: 0.026442639529705048
step: 120, loss: 0.106570765376091
step: 130, loss: 0.09423771500587463
step: 140, loss: 0.04669428989291191
step: 150, loss: 0.01605026051402092
step: 160, loss: 0.048213087022304535
step: 170, loss: 0.07906566560268402
step: 180, loss: 0.06845858693122864
step: 190, loss: 0.0069151404313743114
step: 200, loss: 0.056234005838632584
step: 210, loss: 0.050628624856472015
step: 220, loss: 0.019185775890946388
step: 230, loss: 0.012677427381277084
step: 240, loss: 0.07517609000205994
step: 250, loss: 0.09366032481193542
step: 260, loss: 0.06126144528388977
step: 270, loss: 0.0249409731477499
step: 280, loss: 0.0004944461979903281
step: 290, loss: 0.03932459279894829
step: 300, loss: 0.13439896702766418
step: 310, loss: 0.07720448076725006
step: 320, loss: 0.011930292472243309
step: 330, loss: 0.088637575507164
step: 340, loss: 0.026131661608815193
step: 350, loss: 0.007951918058097363
step: 360, loss: 0.05647747218608856
step: 370, loss: 0.09118448942899704
step: 380, loss: 0.07035002112388611
step: 390, loss: 0.09394882619380951
step: 400, loss: 0.060452159494161606
step: 410, loss: 0.058757320046424866
step: 420, loss: 0.044189147651195526
step: 430, loss: 0.006005972158163786
step: 440, loss: 0.013973742723464966
step: 450, loss: 0.06673718988895416
step: 460, loss: 0.020543185994029045
epoch 4: dev_f1=0.9921436588103255, f1=0.9854748603351955, best_f1=0.9842342342342343
step: 0, loss: 0.12225078791379929
step: 10, loss: 0.044919777661561966
step: 20, loss: 0.014591789804399014
step: 30, loss: 0.01751026138663292
step: 40, loss: 0.07500754296779633
step: 50, loss: 0.022702118381857872
step: 60, loss: 0.01332434918731451
step: 70, loss: 0.009553227573633194
step: 80, loss: 0.08067228645086288
step: 90, loss: 0.0076986877247691154
step: 100, loss: 0.08231117576360703
step: 110, loss: 0.09324143826961517
step: 120, loss: 0.1394079029560089
step: 130, loss: 0.1083722934126854
step: 140, loss: 0.14814692735671997
step: 150, loss: 0.009032376110553741
step: 160, loss: 0.026635728776454926
step: 170, loss: 0.005370688624680042
step: 180, loss: 0.05185415968298912
step: 190, loss: 0.08698622137308121
step: 200, loss: 0.024183174595236778
step: 210, loss: 0.06656457483768463
step: 220, loss: 0.0667898878455162
step: 230, loss: 0.08054642379283905
step: 240, loss: 0.0738121047616005
step: 250, loss: 0.014229226857423782
step: 260, loss: 0.013658788055181503
step: 270, loss: 0.0549023300409317
step: 280, loss: 0.05651294067502022
step: 290, loss: 0.0698569267988205
step: 300, loss: 0.060522183775901794
step: 310, loss: 0.0005489243776537478
step: 320, loss: 0.07809106260538101
step: 330, loss: 0.010984877124428749
step: 340, loss: 0.06851651519536972
step: 350, loss: 0.044813044369220734
step: 360, loss: 0.011984611861407757
step: 370, loss: 0.07397297024726868
step: 380, loss: 0.09396419674158096
step: 390, loss: 0.0033466219902038574
step: 400, loss: 0.029571684077382088
step: 410, loss: 0.09404803067445755
step: 420, loss: 0.08930769562721252
step: 430, loss: 0.03082556277513504
step: 440, loss: 0.007066764403134584
step: 450, loss: 0.11837603896856308
step: 460, loss: 0.061869047582149506
epoch 5: dev_f1=0.990990990990991, f1=0.9797297297297298, best_f1=0.9842342342342343
step: 0, loss: 0.06002333387732506
step: 10, loss: 0.11707834899425507
step: 20, loss: 0.009728636592626572
step: 30, loss: 0.07627908885478973
step: 40, loss: 0.028683796525001526
step: 50, loss: 0.005455963313579559
step: 60, loss: 0.20626160502433777
step: 70, loss: 0.02472558058798313
step: 80, loss: 0.002781474497169256
step: 90, loss: 0.05095522850751877
step: 100, loss: 0.018877556547522545
step: 110, loss: 0.050337113440036774
step: 120, loss: 0.0472111739218235
step: 130, loss: 0.07969069480895996
step: 140, loss: 0.00010832793486770242
step: 150, loss: 0.09366852045059204
step: 160, loss: 0.0240141861140728
step: 170, loss: 0.0992281585931778
step: 180, loss: 0.09032681584358215
step: 190, loss: 0.010339939966797829
step: 200, loss: 0.009909764863550663
step: 210, loss: 0.0162520632147789
step: 220, loss: 0.03182769566774368
step: 230, loss: 0.09435289353132248
step: 240, loss: 0.021216247230768204
step: 250, loss: 0.06421303749084473
step: 260, loss: 0.007786551024764776
step: 270, loss: 0.13942556083202362
step: 280, loss: 0.011612851172685623
step: 290, loss: 0.08887242525815964
step: 300, loss: 0.023412996903061867
step: 310, loss: 0.21441587805747986
step: 320, loss: 0.075301893055439
step: 330, loss: 0.025337431579828262
step: 340, loss: 0.005236487835645676
step: 350, loss: 0.013306571170687675
step: 360, loss: 0.011400607414543629
step: 370, loss: 0.015867792069911957
step: 380, loss: 0.0030625713989138603
step: 390, loss: 0.013547386974096298
step: 400, loss: 0.024800898507237434
step: 410, loss: 0.04427991807460785
step: 420, loss: 0.00824028067290783
step: 430, loss: 0.12060654908418655
step: 440, loss: 0.01117419172078371
step: 450, loss: 0.0612349659204483
step: 460, loss: 0.057105690240859985
epoch 6: dev_f1=0.9932885906040269, f1=0.9758241758241758, best_f1=0.9842342342342343
step: 0, loss: 0.02389434725046158
step: 10, loss: 0.025065381079912186
step: 20, loss: 0.011838008649647236
step: 30, loss: 0.021200105547904968
step: 40, loss: 0.10476222634315491
step: 50, loss: 0.007098423782736063
step: 60, loss: 0.1488138884305954
step: 70, loss: 0.023383963853120804
step: 80, loss: 0.012814239598810673
step: 90, loss: 0.05204489827156067
step: 100, loss: 0.08127735555171967
step: 110, loss: 8.230861567426473e-05
step: 120, loss: 0.030274447053670883
step: 130, loss: 0.07300248742103577
step: 140, loss: 0.040622226893901825
step: 150, loss: 0.007665691897273064
step: 160, loss: 0.0077910153195261955
step: 170, loss: 0.06366975605487823
step: 180, loss: 0.02203897200524807
step: 190, loss: 0.06392788141965866
step: 200, loss: 0.08085822314023972
step: 210, loss: 0.014350451529026031
step: 220, loss: 0.06438526511192322
step: 230, loss: 0.04357479140162468
step: 240, loss: 0.08324889838695526
step: 250, loss: 0.024140823632478714
step: 260, loss: 0.00912196934223175
step: 270, loss: 0.00996142253279686
step: 280, loss: 0.031090959906578064
step: 290, loss: 0.06665724515914917
step: 300, loss: 0.12514623999595642
step: 310, loss: 0.057318802922964096
step: 320, loss: 0.06939074397087097
step: 330, loss: 0.0553247444331646
step: 340, loss: 0.009536897763609886
step: 350, loss: 0.05857478827238083
step: 360, loss: 0.023825792595744133
step: 370, loss: 0.07852695882320404
step: 380, loss: 0.08234954625368118
step: 390, loss: 0.11681121587753296
step: 400, loss: 0.07309462130069733
step: 410, loss: 0.03885237127542496
step: 420, loss: 0.14118582010269165
step: 430, loss: 0.07352664321660995
step: 440, loss: 0.01980207860469818
step: 450, loss: 0.0034838111605495214
step: 460, loss: 0.007161556277424097
epoch 7: dev_f1=0.9932432432432432, f1=0.9820627802690582, best_f1=0.9842342342342343
step: 0, loss: 0.005126746371388435
step: 10, loss: 0.0070900931023061275
step: 20, loss: 0.06050005927681923
step: 30, loss: 0.0669880360364914
step: 40, loss: 0.06609094887971878
step: 50, loss: 0.055031679570674896
step: 60, loss: 0.017660409212112427
step: 70, loss: 0.012999494560062885
step: 80, loss: 0.04308716952800751
step: 90, loss: 0.048105962574481964
step: 100, loss: 0.09886851161718369
step: 110, loss: 0.06395631283521652
step: 120, loss: 0.03440025448799133
step: 130, loss: 0.0715327262878418
step: 140, loss: 0.0038420511409640312
step: 150, loss: 0.05298162251710892
step: 160, loss: 0.00029001454822719097
step: 170, loss: 0.007598118390887976
step: 180, loss: 0.04140857234597206
step: 190, loss: 0.007017127238214016
step: 200, loss: 0.14714503288269043
step: 210, loss: 0.02869725227355957
step: 220, loss: 0.0768308937549591
step: 230, loss: 0.022395387291908264
step: 240, loss: 0.025601409375667572
step: 250, loss: 0.012616959400475025
step: 260, loss: 0.08505667746067047
step: 270, loss: 0.049964550882577896
step: 280, loss: 0.02191726118326187
step: 290, loss: 0.012388983741402626
step: 300, loss: 0.031411152333021164
step: 310, loss: 0.0015792831545695662
step: 320, loss: 0.016709445044398308
step: 330, loss: 0.16417142748832703
step: 340, loss: 0.11834212392568588
step: 350, loss: 0.020245494320988655
step: 360, loss: 0.008804528042674065
step: 370, loss: 0.03833210840821266
step: 380, loss: 0.03966426104307175
step: 390, loss: 0.006358054466545582
step: 400, loss: 0.017799021676182747
step: 410, loss: 0.03659265115857124
step: 420, loss: 0.047930389642715454
step: 430, loss: 0.008041251450777054
step: 440, loss: 0.03639429807662964
step: 450, loss: 0.0029533086344599724
step: 460, loss: 0.11454575508832932
epoch 8: dev_f1=0.9921436588103255, f1=0.9843749999999999, best_f1=0.9842342342342343
step: 0, loss: 5.3933825256535783e-05
step: 10, loss: 0.0032946965657174587
step: 20, loss: 0.005884228739887476
step: 30, loss: 0.022835589945316315
step: 40, loss: 0.013022634200751781
step: 50, loss: 0.011257445439696312
step: 60, loss: 0.06390663236379623
step: 70, loss: 0.023305743932724
step: 80, loss: 0.011644928716123104
step: 90, loss: 0.09584256261587143
step: 100, loss: 0.0002487207530066371
step: 110, loss: 0.012677484191954136
step: 120, loss: 0.12823374569416046
step: 130, loss: 0.037409283220767975
step: 140, loss: 0.06324407458305359
step: 150, loss: 0.03131896257400513
step: 160, loss: 0.005078842397779226
step: 170, loss: 0.10301622748374939
step: 180, loss: 0.08346272259950638
step: 190, loss: 0.04477524384856224
step: 200, loss: 0.07475923746824265
step: 210, loss: 0.004215633496642113
step: 220, loss: 0.004360739607363939
step: 230, loss: 0.005624326877295971
step: 240, loss: 0.05849337577819824
step: 250, loss: 0.12946657836437225
step: 260, loss: 0.02337970957159996
step: 270, loss: 0.03784112259745598
step: 280, loss: 0.03887777775526047
step: 290, loss: 0.03511328250169754
step: 300, loss: 0.0026914237532764673
step: 310, loss: 0.03108777105808258
step: 320, loss: 0.02005641907453537
step: 330, loss: 0.02400023117661476
step: 340, loss: 0.043732915073633194
step: 350, loss: 0.06319472938776016
step: 360, loss: 0.058333784341812134
step: 370, loss: 0.10002173483371735
step: 380, loss: 0.006639798637479544
step: 390, loss: 0.11101222783327103
step: 400, loss: 0.12925375998020172
step: 410, loss: 0.006618354469537735
step: 420, loss: 0.07602949440479279
step: 430, loss: 0.006117335520684719
step: 440, loss: 0.07625359296798706
step: 450, loss: 0.027011090889573097
step: 460, loss: 0.018479637801647186
epoch 9: dev_f1=0.9921259842519685, f1=0.9854096520763187, best_f1=0.9842342342342343
step: 0, loss: 0.03904565051198006
step: 10, loss: 0.08090220391750336
step: 20, loss: 0.03383132815361023
step: 30, loss: 0.06806282699108124
step: 40, loss: 0.06837014108896255
step: 50, loss: 0.054388515651226044
step: 60, loss: 0.03009028546512127
step: 70, loss: 0.007956774905323982
step: 80, loss: 0.023242030292749405
step: 90, loss: 0.02919311635196209
step: 100, loss: 0.045219920575618744
step: 110, loss: 0.031072169542312622
step: 120, loss: 0.001960017252713442
step: 130, loss: 0.02254951186478138
step: 140, loss: 0.06661997735500336
step: 150, loss: 0.02167777717113495
step: 160, loss: 0.11197489500045776
step: 170, loss: 0.008796010166406631
step: 180, loss: 0.03373158723115921
step: 190, loss: 0.04443500563502312
step: 200, loss: 0.008713009767234325
step: 210, loss: 0.10663962364196777
step: 220, loss: 0.025029046460986137
step: 230, loss: 0.02559196762740612
step: 240, loss: 0.0018408987671136856
step: 250, loss: 0.0011253745760768652
step: 260, loss: 0.04567291587591171
step: 270, loss: 0.084615059196949
step: 280, loss: 0.014785340055823326
step: 290, loss: 0.05624798312783241
step: 300, loss: 0.05063565447926521
step: 310, loss: 0.02995201200246811
step: 320, loss: 0.08893763273954391
step: 330, loss: 0.03079042211174965
step: 340, loss: 0.028938475996255875
step: 350, loss: 0.11002898961305618
step: 360, loss: 0.027230586856603622
step: 370, loss: 0.007018614560365677
step: 380, loss: 0.003604599041864276
step: 390, loss: 0.01989518664777279
step: 400, loss: 0.00811620894819498
step: 410, loss: 0.09411800652742386
step: 420, loss: 0.00015223631635308266
step: 430, loss: 0.022440105676651
step: 440, loss: 0.08587899804115295
step: 450, loss: 0.02948777750134468
step: 460, loss: 0.008494197390973568
epoch 10: dev_f1=0.9943883277216611, f1=0.9843400447427293, best_f1=0.9843400447427293
step: 0, loss: 0.008180106058716774
step: 10, loss: 0.03493598476052284
step: 20, loss: 0.07069995254278183
step: 30, loss: 0.0010085379472002387
step: 40, loss: 0.0300710778683424
step: 50, loss: 2.2042151613277383e-05
step: 60, loss: 0.07131972908973694
step: 70, loss: 0.07500260323286057
step: 80, loss: 0.020376082509756088
step: 90, loss: 0.028656259179115295
step: 100, loss: 6.489470251835883e-05
step: 110, loss: 4.260658533894457e-05
step: 120, loss: 0.0894559770822525
step: 130, loss: 0.08516280353069305
step: 140, loss: 0.00276257935911417
step: 150, loss: 0.07069844007492065
step: 160, loss: 0.0010158342774957418
step: 170, loss: 0.00018943945178762078
step: 180, loss: 0.02654375322163105
step: 190, loss: 0.0002733914880082011
step: 200, loss: 0.06591898202896118
step: 210, loss: 0.04017600044608116
step: 220, loss: 0.018972482532262802
step: 230, loss: 0.0007545067346654832
step: 240, loss: 0.07610973715782166
step: 250, loss: 0.0029160368721932173
step: 260, loss: 0.05705385282635689
step: 270, loss: 0.06386321783065796
step: 280, loss: 0.0547972172498703
step: 290, loss: 0.0002725587401073426
step: 300, loss: 0.00014225393533706665
step: 310, loss: 0.034458208829164505
step: 320, loss: 0.02123015932738781
step: 330, loss: 0.003281014272943139
step: 340, loss: 0.05410746484994888
step: 350, loss: 0.010339748114347458
step: 360, loss: 0.033189188688993454
step: 370, loss: 0.0002505772572476417
step: 380, loss: 0.0011017108336091042
step: 390, loss: 0.03624950349330902
step: 400, loss: 0.001724699162878096
step: 410, loss: 0.07674626260995865
step: 420, loss: 0.04613110050559044
step: 430, loss: 0.07731377333402634
step: 440, loss: 4.619851097231731e-05
step: 450, loss: 0.11494673788547516
step: 460, loss: 0.010175476782023907
epoch 11: dev_f1=0.9943883277216611, f1=0.9854748603351955, best_f1=0.9843400447427293
step: 0, loss: 0.004712019115686417
step: 10, loss: 0.043602410703897476
step: 20, loss: 0.0005486317677423358
step: 30, loss: 0.023286350071430206
step: 40, loss: 0.028149230405688286
step: 50, loss: 0.07183396071195602
step: 60, loss: 0.05183350294828415
step: 70, loss: 0.04261027276515961
step: 80, loss: 0.06899072974920273
step: 90, loss: 0.0016337924171239138
step: 100, loss: 0.02920738235116005
step: 110, loss: 0.05506844446063042
step: 120, loss: 0.042264170944690704
step: 130, loss: 0.016204968094825745
step: 140, loss: 0.0009666936821304262
step: 150, loss: 0.0007221601554192603
step: 160, loss: 0.0040771691128611565
step: 170, loss: 0.02271423116326332
step: 180, loss: 0.03730387985706329
step: 190, loss: 0.02508995682001114
step: 200, loss: 0.030951526015996933
step: 210, loss: 0.044709108769893646
step: 220, loss: 0.0003636176697909832
step: 230, loss: 0.10557122528553009
step: 240, loss: 0.03051880933344364
step: 250, loss: 0.008893533609807491
step: 260, loss: 0.0510859377682209
step: 270, loss: 0.018788453191518784
step: 280, loss: 0.05794632434844971
step: 290, loss: 0.006887131370604038
step: 300, loss: 0.04067106172442436
step: 310, loss: 0.04078609123826027
step: 320, loss: 3.682398164528422e-05
step: 330, loss: 0.034412533044815063
step: 340, loss: 0.044890858232975006
step: 350, loss: 0.008511901833117008
step: 360, loss: 0.14420372247695923
step: 370, loss: 0.04235612973570824
step: 380, loss: 0.048906002193689346
step: 390, loss: 0.027805427089333534
step: 400, loss: 0.004395726602524519
step: 410, loss: 0.003518845420330763
step: 420, loss: 0.006136615294963121
step: 430, loss: 0.029603000730276108
step: 440, loss: 0.039017945528030396
step: 450, loss: 0.023778438568115234
step: 460, loss: 0.0006495997658930719
epoch 12: dev_f1=0.9943883277216611, f1=0.9888392857142857, best_f1=0.9843400447427293
step: 0, loss: 0.0016087769763544202
step: 10, loss: 0.02112540788948536
step: 20, loss: 0.03402075543999672
step: 30, loss: 0.05931227654218674
step: 40, loss: 0.0388481430709362
step: 50, loss: 0.02674926072359085
step: 60, loss: 0.0013245362788438797
step: 70, loss: 0.07370984554290771
step: 80, loss: 0.0002320924832019955
step: 90, loss: 0.011197350919246674
step: 100, loss: 0.00012452797091100365
step: 110, loss: 0.019009362906217575
step: 120, loss: 0.03811248764395714
step: 130, loss: 0.001551986439153552
step: 140, loss: 0.03894862160086632
step: 150, loss: 0.11224551498889923
step: 160, loss: 0.042566608637571335
step: 170, loss: 0.12660807371139526
step: 180, loss: 0.05029818415641785
step: 190, loss: 0.016379833221435547
step: 200, loss: 0.051347631961107254
step: 210, loss: 0.026862602680921555
step: 220, loss: 0.30733320116996765
step: 230, loss: 0.026324070990085602
step: 240, loss: 0.07285227626562119
step: 250, loss: 0.031168602406978607
step: 260, loss: 0.01832263544201851
step: 270, loss: 0.008653962053358555
step: 280, loss: 0.0008101169369183481
step: 290, loss: 0.010940267704427242
step: 300, loss: 0.023162871599197388
step: 310, loss: 8.784036617726088e-05
step: 320, loss: 0.0009587681852281094
step: 330, loss: 0.0024609307292848825
step: 340, loss: 0.02870890125632286
step: 350, loss: 0.010446964763104916
step: 360, loss: 0.04210600629448891
step: 370, loss: 0.019345877692103386
step: 380, loss: 0.028513850644230843
step: 390, loss: 0.026421964168548584
step: 400, loss: 0.038494620472192764
step: 410, loss: 0.18149475753307343
step: 420, loss: 0.02224593237042427
step: 430, loss: 0.03731353208422661
step: 440, loss: 0.04067964479327202
step: 450, loss: 0.017661888152360916
step: 460, loss: 0.0007863265345804393
epoch 13: dev_f1=0.9921436588103255, f1=0.9865470852017937, best_f1=0.9843400447427293
step: 0, loss: 0.00017653412942308933
step: 10, loss: 0.02405206672847271
step: 20, loss: 0.015273231081664562
step: 30, loss: 0.026514921337366104
step: 40, loss: 0.016823789104819298
step: 50, loss: 0.020010678097605705
step: 60, loss: 0.0019035122822970152
step: 70, loss: 0.001053225132636726
step: 80, loss: 0.01830812729895115
step: 90, loss: 0.02546648308634758
step: 100, loss: 0.09301657974720001
step: 110, loss: 0.0003336682275403291
step: 120, loss: 0.013207491487264633
step: 130, loss: 0.001168476534076035
step: 140, loss: 0.03881257027387619
step: 150, loss: 0.0001311972737312317
step: 160, loss: 0.022413285449147224
step: 170, loss: 0.008444131352007389
step: 180, loss: 0.001061365008354187
step: 190, loss: 0.0007014332804828882
step: 200, loss: 0.020367927849292755
step: 210, loss: 0.0005201156600378454
step: 220, loss: 0.020691601559519768
step: 230, loss: 0.06248529255390167
step: 240, loss: 0.02566172182559967
step: 250, loss: 2.5211997126461938e-05
step: 260, loss: 0.049026936292648315
step: 270, loss: 0.020095491781830788
step: 280, loss: 0.0013169669546186924
step: 290, loss: 0.018956445157527924
step: 300, loss: 0.03835781663656235
step: 310, loss: 0.040749091655015945
step: 320, loss: 0.015156498178839684
step: 330, loss: 0.002210112288594246
step: 340, loss: 0.0010990978917106986
step: 350, loss: 0.09139080345630646
step: 360, loss: 0.0432598851621151
step: 370, loss: 0.016499275341629982
step: 380, loss: 0.026475440710783005
step: 390, loss: 0.041197534650564194
step: 400, loss: 0.07225735485553741
step: 410, loss: 0.021008068695664406
step: 420, loss: 0.024104639887809753
step: 430, loss: 0.000521348905749619
step: 440, loss: 0.022264324128627777
step: 450, loss: 0.001977556850761175
step: 460, loss: 0.0003275452181696892
epoch 14: dev_f1=0.9910112359550561, f1=0.9819819819819819, best_f1=0.9843400447427293
step: 0, loss: 4.1390976548427716e-05
step: 10, loss: 0.00038503381074406207
step: 20, loss: 0.028063403442502022
step: 30, loss: 0.01804155297577381
step: 40, loss: 0.014405793510377407
step: 50, loss: 0.0002642290201038122
step: 60, loss: 0.00025915791047737
step: 70, loss: 0.06341337412595749
step: 80, loss: 0.0019258641405031085
step: 90, loss: 0.0005227663205005229
step: 100, loss: 0.019185397773981094
step: 110, loss: 0.0008316993480548263
step: 120, loss: 0.02357306145131588
step: 130, loss: 0.020669568330049515
step: 140, loss: 0.060523469001054764
step: 150, loss: 0.01437920518219471
step: 160, loss: 0.00017703302728477865
step: 170, loss: 0.024988453835248947
step: 180, loss: 0.0001396523875882849
step: 190, loss: 4.230264312354848e-05
step: 200, loss: 0.021074168384075165
step: 210, loss: 5.656874054693617e-05
step: 220, loss: 0.04792981967329979
step: 230, loss: 0.05565217137336731
step: 240, loss: 0.02108549326658249
step: 250, loss: 0.030083775520324707
step: 260, loss: 0.03482262045145035
step: 270, loss: 0.02025279588997364
step: 280, loss: 0.00021148989617358893
step: 290, loss: 0.04350121691823006
step: 300, loss: 0.020526902750134468
step: 310, loss: 0.018782678991556168
step: 320, loss: 0.034151509404182434
step: 330, loss: 0.0001274879032280296
step: 340, loss: 0.02213747613132
step: 350, loss: 0.0477307066321373
step: 360, loss: 0.06429541856050491
step: 370, loss: 0.01562485285103321
step: 380, loss: 0.036997370421886444
step: 390, loss: 0.01844104193150997
step: 400, loss: 0.028790047392249107
step: 410, loss: 0.04462127014994621
step: 420, loss: 0.028131447732448578
step: 430, loss: 0.0005560658173635602
step: 440, loss: 0.04350630193948746
step: 450, loss: 9.022965241456404e-05
step: 460, loss: 0.0005266762454994023
epoch 15: dev_f1=0.9921612541993281, f1=0.9832402234636871, best_f1=0.9843400447427293
step: 0, loss: 4.039401392219588e-05
step: 10, loss: 8.456986688543111e-05
step: 20, loss: 0.0001520822406746447
step: 30, loss: 0.04556954652070999
step: 40, loss: 5.670472819474526e-05
step: 50, loss: 5.7923320127883926e-05
step: 60, loss: 0.02250685542821884
step: 70, loss: 0.018981466069817543
step: 80, loss: 0.025481296703219414
step: 90, loss: 0.05046791955828667
step: 100, loss: 7.049214764265344e-05
step: 110, loss: 0.020854363217949867
step: 120, loss: 0.023952675983309746
step: 130, loss: 9.708686411613598e-05
step: 140, loss: 0.017535103484988213
step: 150, loss: 0.0422896109521389
step: 160, loss: 0.016572432592511177
step: 170, loss: 0.023484714329242706
step: 180, loss: 9.285184933105484e-05
step: 190, loss: 0.0008139103883877397
step: 200, loss: 3.788318645092659e-05
step: 210, loss: 0.020386381074786186
step: 220, loss: 0.020228823646903038
step: 230, loss: 0.03417973965406418
step: 240, loss: 0.0001588708400959149
step: 250, loss: 0.018042849376797676
step: 260, loss: 0.06381025910377502
step: 270, loss: 5.181969027034938e-05
step: 280, loss: 0.04560673236846924
step: 290, loss: 0.05786038935184479
step: 300, loss: 7.636930968146771e-05
step: 310, loss: 0.05271731689572334
step: 320, loss: 0.023937387391924858
step: 330, loss: 0.06118267774581909
step: 340, loss: 0.00014825929247308522
step: 350, loss: 0.02345253713428974
step: 360, loss: 0.000252601777901873
step: 370, loss: 0.089817114174366
step: 380, loss: 0.01909659057855606
step: 390, loss: 0.04618477076292038
step: 400, loss: 0.022364947944879532
step: 410, loss: 0.07316901534795761
step: 420, loss: 0.001405160641297698
step: 430, loss: 0.025368062779307365
step: 440, loss: 0.03442775085568428
step: 450, loss: 0.04528559371829033
step: 460, loss: 0.0837991014122963
epoch 16: dev_f1=0.9921612541993281, f1=0.9854423292273236, best_f1=0.9843400447427293
step: 0, loss: 0.019623450934886932
step: 10, loss: 0.01938231848180294
step: 20, loss: 0.05996457114815712
step: 30, loss: 0.017219411209225655
step: 40, loss: 0.00045303982915356755
step: 50, loss: 0.047092653810977936
step: 60, loss: 0.01778988167643547
step: 70, loss: 5.925376171944663e-05
step: 80, loss: 0.000118188516353257
step: 90, loss: 8.981735300039873e-05
step: 100, loss: 0.022654252126812935
step: 110, loss: 0.03532492741942406
step: 120, loss: 0.02137000299990177
step: 130, loss: 0.03153637796640396
step: 140, loss: 0.04791494458913803
step: 150, loss: 0.03996698185801506
step: 160, loss: 0.049462493509054184
step: 170, loss: 0.04866665601730347
step: 180, loss: 3.068023215746507e-05
step: 190, loss: 1.5739051377750002e-05
step: 200, loss: 0.011820193380117416
step: 210, loss: 0.00023323566711042076
step: 220, loss: 0.04297519847750664
step: 230, loss: 0.00031651207245886326
step: 240, loss: 0.021878141909837723
step: 250, loss: 0.013500731438398361
step: 260, loss: 9.327846055384725e-05
step: 270, loss: 0.04799257591366768
step: 280, loss: 0.02238822728395462
step: 290, loss: 0.025514811277389526
step: 300, loss: 8.437029464403167e-05
step: 310, loss: 0.02590135671198368
step: 320, loss: 0.07555539906024933
step: 330, loss: 0.02132873237133026
step: 340, loss: 0.02123340032994747
step: 350, loss: 0.00012630326091311872
step: 360, loss: 0.04954058676958084
step: 370, loss: 0.02145720273256302
step: 380, loss: 0.049963220953941345
step: 390, loss: 0.024499893188476562
step: 400, loss: 0.023145828396081924
step: 410, loss: 0.04974794015288353
step: 420, loss: 9.496472921455279e-05
step: 430, loss: 0.000646181171759963
step: 440, loss: 0.019379302859306335
step: 450, loss: 0.018367823213338852
step: 460, loss: 0.03992309793829918
epoch 17: dev_f1=0.9932735426008968, f1=0.9854423292273236, best_f1=0.9843400447427293
step: 0, loss: 0.09581320732831955
step: 10, loss: 0.0011019001249223948
step: 20, loss: 0.02043531835079193
step: 30, loss: 0.07222270965576172
step: 40, loss: 0.01960783824324608
step: 50, loss: 0.001443375600501895
step: 60, loss: 0.08460642397403717
step: 70, loss: 0.029035940766334534
step: 80, loss: 0.0022474448196589947
step: 90, loss: 1.8126780560123734e-05
step: 100, loss: 0.06906606256961823
step: 110, loss: 0.018284503370523453
step: 120, loss: 0.02332107163965702
step: 130, loss: 0.0003868018975481391
step: 140, loss: 0.01758411154150963
step: 150, loss: 0.01952897571027279
step: 160, loss: 0.020282858982682228
step: 170, loss: 0.0005572251975536346
step: 180, loss: 0.07452675700187683
step: 190, loss: 0.020674819126725197
step: 200, loss: 4.152425754000433e-05
step: 210, loss: 0.03192121535539627
step: 220, loss: 0.06338360905647278
step: 230, loss: 0.018542196601629257
step: 240, loss: 0.023605281487107277
step: 250, loss: 0.02182767726480961
step: 260, loss: 0.025356370955705643
step: 270, loss: 0.00021621011546812952
step: 280, loss: 0.0004138547519687563
step: 290, loss: 4.040850035380572e-05
step: 300, loss: 4.940768485539593e-05
step: 310, loss: 0.0220931489020586
step: 320, loss: 4.056056059198454e-05
step: 330, loss: 4.11847468058113e-05
step: 340, loss: 0.028439095243811607
step: 350, loss: 0.07175805419683456
step: 360, loss: 0.04669070988893509
step: 370, loss: 0.021382803097367287
step: 380, loss: 0.00023564518778584898
step: 390, loss: 0.027051812037825584
step: 400, loss: 0.02104436419904232
step: 410, loss: 0.019785147160291672
step: 420, loss: 0.05042830854654312
step: 430, loss: 0.00045958097325637937
step: 440, loss: 0.019759921357035637
step: 450, loss: 0.04350731149315834
step: 460, loss: 0.04441986605525017
epoch 18: dev_f1=0.9932584269662922, f1=0.9831271091113611, best_f1=0.9843400447427293
step: 0, loss: 0.03987490385770798
step: 10, loss: 2.060413135041017e-05
step: 20, loss: 4.977378193871118e-05
step: 30, loss: 0.01897038146853447
step: 40, loss: 0.00040795220411382616
step: 50, loss: 6.499059963971376e-05
step: 60, loss: 0.02107616327702999
step: 70, loss: 4.5908269385108724e-05
step: 80, loss: 0.032718390226364136
step: 90, loss: 0.021556781604886055
step: 100, loss: 0.050143975764513016
step: 110, loss: 0.019613947719335556
step: 120, loss: 0.02587362751364708
step: 130, loss: 0.050845757126808167
step: 140, loss: 0.023409906774759293
step: 150, loss: 0.044279009103775024
step: 160, loss: 0.0001282600569538772
step: 170, loss: 0.08990266174077988
step: 180, loss: 0.03186652809381485
step: 190, loss: 0.0201252531260252
step: 200, loss: 0.023898009210824966
step: 210, loss: 0.041403960436582565
step: 220, loss: 0.04934908449649811
step: 230, loss: 0.07155391573905945
step: 240, loss: 5.8517700381344184e-05
step: 250, loss: 0.09769689291715622
step: 260, loss: 0.09564589709043503
step: 270, loss: 0.00018867873586714268
step: 280, loss: 0.017742011696100235
step: 290, loss: 0.02250511758029461
step: 300, loss: 3.0775769118918106e-05
step: 310, loss: 0.039231736212968826
step: 320, loss: 0.022341039031744003
step: 330, loss: 3.905237826984376e-05
step: 340, loss: 0.00024901903816498816
step: 350, loss: 0.018373901024460793
step: 360, loss: 0.06475377082824707
step: 370, loss: 0.06401147693395615
step: 380, loss: 0.003304677316918969
step: 390, loss: 5.111241989652626e-05
step: 400, loss: 0.024401867762207985
step: 410, loss: 0.03639658913016319
step: 420, loss: 0.00012692317250184715
step: 430, loss: 0.022590529173612595
step: 440, loss: 0.01954685151576996
step: 450, loss: 3.937652218155563e-05
step: 460, loss: 7.33795459382236e-05
epoch 19: dev_f1=0.9932584269662922, f1=0.9854423292273236, best_f1=0.9843400447427293
step: 0, loss: 1.8539562006480992e-05
step: 10, loss: 0.051543693989515305
step: 20, loss: 0.025574730709195137
step: 30, loss: 0.00022380592417903244
step: 40, loss: 0.019496969878673553
step: 50, loss: 0.06299040466547012
step: 60, loss: 8.80276711541228e-05
step: 70, loss: 0.03443542867898941
step: 80, loss: 4.3938700400758535e-05
step: 90, loss: 0.019910983741283417
step: 100, loss: 0.025718331336975098
step: 110, loss: 0.0309587512165308
step: 120, loss: 0.040923770517110825
step: 130, loss: 0.023069629445672035
step: 140, loss: 0.055975291877985
step: 150, loss: 0.02125903032720089
step: 160, loss: 0.018505139276385307
step: 170, loss: 0.02362511307001114
step: 180, loss: 0.042839035391807556
step: 190, loss: 2.7193173082196154e-05
step: 200, loss: 0.0003089045640081167
step: 210, loss: 3.6972422094549984e-05
step: 220, loss: 4.698744305642322e-05
step: 230, loss: 0.05715549364686012
step: 240, loss: 5.461931141326204e-05
step: 250, loss: 0.028998177498579025
step: 260, loss: 0.021089037880301476
step: 270, loss: 0.023453734815120697
step: 280, loss: 1.440547111997148e-05
step: 290, loss: 0.022550109773874283
step: 300, loss: 5.14671191922389e-05
step: 310, loss: 0.1292276233434677
step: 320, loss: 0.038309160619974136
step: 330, loss: 0.06750738620758057
step: 340, loss: 0.06457321345806122
step: 350, loss: 1.2837224858230911e-05
step: 360, loss: 0.018668660894036293
step: 370, loss: 2.6987463570549153e-05
step: 380, loss: 0.027155272662639618
step: 390, loss: 0.020377224311232567
step: 400, loss: 0.02527393400669098
step: 410, loss: 0.05307215824723244
step: 420, loss: 0.02115914225578308
step: 430, loss: 7.503335655201226e-05
step: 440, loss: 0.020691879093647003
step: 450, loss: 0.06280349940061569
step: 460, loss: 0.06005010008811951
epoch 20: dev_f1=0.9932584269662922, f1=0.9842696629213483, best_f1=0.9843400447427293
