cuda
Device: cuda
step: 0, loss: 0.6668365597724915
step: 10, loss: 0.30830439925193787
step: 20, loss: 0.46261459589004517
step: 30, loss: 0.40834084153175354
step: 40, loss: 0.31420469284057617
step: 50, loss: 0.17845122516155243
step: 60, loss: 0.19825071096420288
step: 70, loss: 0.2656773328781128
step: 80, loss: 0.2689269483089447
step: 90, loss: 0.22223111987113953
step: 100, loss: 0.1755874752998352
step: 110, loss: 0.2965216636657715
step: 120, loss: 0.13709767162799835
step: 130, loss: 0.1067732647061348
step: 140, loss: 0.07174298167228699
step: 150, loss: 0.1999823898077011
step: 160, loss: 0.0353730246424675
step: 170, loss: 0.09206312894821167
step: 180, loss: 0.15112526714801788
step: 190, loss: 0.10142669826745987
step: 200, loss: 0.08263150602579117
step: 210, loss: 0.12139347940683365
step: 220, loss: 0.14072179794311523
step: 230, loss: 0.13629920780658722
step: 240, loss: 0.07757341116666794
step: 250, loss: 0.10999493300914764
step: 260, loss: 0.2562052607536316
step: 270, loss: 0.1475818008184433
step: 280, loss: 0.10962353646755219
step: 290, loss: 0.05200938135385513
step: 300, loss: 0.07585029304027557
step: 310, loss: 0.05840521678328514
step: 320, loss: 0.03578514978289604
step: 330, loss: 0.01787422224879265
step: 340, loss: 0.1943826973438263
step: 350, loss: 0.07833711057901382
step: 360, loss: 0.0600542314350605
step: 370, loss: 0.0686723068356514
step: 380, loss: 0.011496315710246563
step: 390, loss: 0.18069645762443542
step: 400, loss: 0.1261293739080429
step: 410, loss: 0.05507441610097885
step: 420, loss: 0.051415108144283295
step: 430, loss: 0.023019153624773026
step: 440, loss: 0.15769723057746887
step: 450, loss: 0.06255560368299484
step: 460, loss: 0.037546537816524506
epoch 1: dev_f1=0.9876543209876544, f1=0.9841628959276018, best_f1=0.9841628959276018
step: 0, loss: 0.10233905166387558
step: 10, loss: 0.08267749845981598
step: 20, loss: 0.013058424927294254
step: 30, loss: 0.045175034552812576
step: 40, loss: 0.05689356476068497
step: 50, loss: 0.08135097473859787
step: 60, loss: 0.009360900148749352
step: 70, loss: 0.05728365480899811
step: 80, loss: 0.04521642252802849
step: 90, loss: 0.04934658482670784
step: 100, loss: 0.011317756026983261
step: 110, loss: 0.01685107871890068
step: 120, loss: 0.09559947997331619
step: 130, loss: 0.07543140649795532
step: 140, loss: 0.06870228052139282
step: 150, loss: 0.08848294615745544
step: 160, loss: 0.06279534101486206
step: 170, loss: 0.013912100344896317
step: 180, loss: 0.07591081410646439
step: 190, loss: 0.04519559070467949
step: 200, loss: 0.04877699911594391
step: 210, loss: 0.028646986931562424
step: 220, loss: 0.04125552624464035
step: 230, loss: 0.0700325146317482
step: 240, loss: 0.04344116151332855
step: 250, loss: 0.08524579554796219
step: 260, loss: 0.05826757848262787
step: 270, loss: 0.0558677576482296
step: 280, loss: 0.18596018850803375
step: 290, loss: 0.05172405391931534
step: 300, loss: 0.10817922651767731
step: 310, loss: 0.08126108348369598
step: 320, loss: 0.042937204241752625
step: 330, loss: 0.027529697865247726
step: 340, loss: 0.04273797944188118
step: 350, loss: 0.1495790183544159
step: 360, loss: 0.006584617309272289
step: 370, loss: 0.1568644642829895
step: 380, loss: 0.19390477240085602
step: 390, loss: 0.024227602407336235
step: 400, loss: 0.12315276265144348
step: 410, loss: 0.0727638229727745
step: 420, loss: 0.011223815381526947
step: 430, loss: 0.15972059965133667
step: 440, loss: 0.060150761157274246
step: 450, loss: 0.14806941151618958
step: 460, loss: 0.030284753069281578
epoch 2: dev_f1=0.9842342342342343, f1=0.9819819819819819, best_f1=0.9841628959276018
step: 0, loss: 0.06633060425519943
step: 10, loss: 0.04401995614171028
step: 20, loss: 0.027264563366770744
step: 30, loss: 0.009927977807819843
step: 40, loss: 0.14919155836105347
step: 50, loss: 0.06247735396027565
step: 60, loss: 0.017565026879310608
step: 70, loss: 0.08140610158443451
step: 80, loss: 0.05521596595644951
step: 90, loss: 0.059002719819545746
step: 100, loss: 0.14529354870319366
step: 110, loss: 0.016987811774015427
step: 120, loss: 0.09145820140838623
step: 130, loss: 0.040003664791584015
step: 140, loss: 0.03528725355863571
step: 150, loss: 0.0074176606722176075
step: 160, loss: 0.010907039046287537
step: 170, loss: 0.003577286144718528
step: 180, loss: 0.02852780930697918
step: 190, loss: 0.0762915387749672
step: 200, loss: 0.0036216950975358486
step: 210, loss: 0.11300919950008392
step: 220, loss: 0.008509156294167042
step: 230, loss: 0.11443839967250824
step: 240, loss: 0.06777336448431015
step: 250, loss: 0.0666891410946846
step: 260, loss: 0.1277577131986618
step: 270, loss: 0.05608596280217171
step: 280, loss: 0.11499233543872833
step: 290, loss: 0.1449582427740097
step: 300, loss: 0.010173797607421875
step: 310, loss: 0.07163602113723755
step: 320, loss: 0.03145414590835571
step: 330, loss: 0.017110608518123627
step: 340, loss: 0.1607442945241928
step: 350, loss: 0.005383478943258524
step: 360, loss: 0.1312321275472641
step: 370, loss: 0.02870923839509487
step: 380, loss: 0.13390947878360748
step: 390, loss: 0.02506525069475174
step: 400, loss: 0.035455912351608276
step: 410, loss: 0.11381316184997559
step: 420, loss: 0.08291810005903244
step: 430, loss: 0.03832261636853218
step: 440, loss: 0.021335937082767487
step: 450, loss: 0.11064606159925461
step: 460, loss: 0.0556887611746788
epoch 3: dev_f1=0.9932279909706545, f1=0.9875424688561721, best_f1=0.9875424688561721
step: 0, loss: 0.13142317533493042
step: 10, loss: 0.015183361247181892
step: 20, loss: 0.01750800386071205
step: 30, loss: 0.01792026497423649
step: 40, loss: 0.021700739860534668
step: 50, loss: 0.0038337400183081627
step: 60, loss: 0.0332760214805603
step: 70, loss: 0.0262406375259161
step: 80, loss: 0.16141745448112488
step: 90, loss: 0.031264159828424454
step: 100, loss: 0.03049541264772415
step: 110, loss: 0.13182440400123596
step: 120, loss: 0.029002655297517776
step: 130, loss: 0.03583543747663498
step: 140, loss: 0.03964827209711075
step: 150, loss: 0.02272317372262478
step: 160, loss: 0.00947912223637104
step: 170, loss: 0.012253127060830593
step: 180, loss: 0.15485036373138428
step: 190, loss: 0.062059059739112854
step: 200, loss: 0.13904070854187012
step: 210, loss: 0.01156441681087017
step: 220, loss: 0.09876778721809387
step: 230, loss: 0.07448380440473557
step: 240, loss: 0.0790984258055687
step: 250, loss: 0.02215343900024891
step: 260, loss: 0.03653428331017494
step: 270, loss: 0.1251596212387085
step: 280, loss: 0.03263430297374725
step: 290, loss: 0.03666660189628601
step: 300, loss: 0.016899891197681427
step: 310, loss: 0.06171490624547005
step: 320, loss: 0.07106941193342209
step: 330, loss: 0.09563247859477997
step: 340, loss: 0.061464011669158936
step: 350, loss: 0.02987702563405037
step: 360, loss: 0.04015772417187691
step: 370, loss: 0.08717074990272522
step: 380, loss: 0.08122526854276657
step: 390, loss: 0.0019867108203470707
step: 400, loss: 0.06171724572777748
step: 410, loss: 0.015341907739639282
step: 420, loss: 0.08565706014633179
step: 430, loss: 0.14554379880428314
step: 440, loss: 0.00017465782002545893
step: 450, loss: 0.2301163673400879
step: 460, loss: 0.06496934592723846
epoch 4: dev_f1=0.9864559819413092, f1=0.9853438556933484, best_f1=0.9875424688561721
step: 0, loss: 0.023137617856264114
step: 10, loss: 0.041786227375268936
step: 20, loss: 0.011616346426308155
step: 30, loss: 0.019184116274118423
step: 40, loss: 0.09833835065364838
step: 50, loss: 0.03721864894032478
step: 60, loss: 0.005597107112407684
step: 70, loss: 0.0632762536406517
step: 80, loss: 0.054308827966451645
step: 90, loss: 0.06773234903812408
step: 100, loss: 0.16780142486095428
step: 110, loss: 0.04514090716838837
step: 120, loss: 0.008092298172414303
step: 130, loss: 0.023369569331407547
step: 140, loss: 0.02316744439303875
step: 150, loss: 0.07554509490728378
step: 160, loss: 0.02042359672486782
step: 170, loss: 0.17735859751701355
step: 180, loss: 0.010269775055348873
step: 190, loss: 0.0060707153752446175
step: 200, loss: 0.006193751003593206
step: 210, loss: 0.02008303999900818
step: 220, loss: 0.03086966462433338
step: 230, loss: 0.011432158760726452
step: 240, loss: 0.08290589600801468
step: 250, loss: 0.02395990490913391
step: 260, loss: 0.08062740415334702
step: 270, loss: 0.010678539983928204
step: 280, loss: 0.019464541226625443
step: 290, loss: 0.01459253765642643
step: 300, loss: 0.018979884684085846
step: 310, loss: 0.08203266561031342
step: 320, loss: 0.005151900462806225
step: 330, loss: 0.0333685465157032
step: 340, loss: 0.05651794746518135
step: 350, loss: 0.0029566993471235037
step: 360, loss: 0.023679574951529503
step: 370, loss: 0.09403151273727417
step: 380, loss: 0.008313162252306938
step: 390, loss: 0.07982217520475388
step: 400, loss: 0.02267339825630188
step: 410, loss: 0.007126468699425459
step: 420, loss: 0.017773054540157318
step: 430, loss: 0.017317328602075577
step: 440, loss: 0.07913079112768173
step: 450, loss: 0.09333542734384537
step: 460, loss: 0.03187328577041626
epoch 5: dev_f1=0.9898762654668166, f1=0.9864559819413092, best_f1=0.9875424688561721
step: 0, loss: 0.01999310404062271
step: 10, loss: 0.014629023149609566
step: 20, loss: 0.08045246452093124
step: 30, loss: 0.01235416904091835
step: 40, loss: 0.2888290584087372
step: 50, loss: 0.09793645143508911
step: 60, loss: 0.060060352087020874
step: 70, loss: 0.03358662873506546
step: 80, loss: 0.07496882230043411
step: 90, loss: 0.008131133392453194
step: 100, loss: 0.0539625883102417
step: 110, loss: 0.0470273531973362
step: 120, loss: 0.03622090816497803
step: 130, loss: 0.056476496160030365
step: 140, loss: 0.01410019863396883
step: 150, loss: 0.0531802624464035
step: 160, loss: 0.014400233514606953
step: 170, loss: 0.010788386687636375
step: 180, loss: 0.006438160315155983
step: 190, loss: 0.0037658032961189747
step: 200, loss: 0.007962200790643692
step: 210, loss: 0.022859973832964897
step: 220, loss: 0.0812593474984169
step: 230, loss: 0.015102730132639408
step: 240, loss: 0.03473617136478424
step: 250, loss: 0.13027140498161316
step: 260, loss: 0.08147406578063965
step: 270, loss: 0.10284116119146347
step: 280, loss: 0.029152754694223404
step: 290, loss: 0.2368360012769699
step: 300, loss: 0.09232344478368759
step: 310, loss: 0.027348307892680168
step: 320, loss: 0.007818754762411118
step: 330, loss: 0.06728155165910721
step: 340, loss: 0.018768727779388428
step: 350, loss: 0.17144730687141418
step: 360, loss: 0.011048349551856518
step: 370, loss: 0.051309119910001755
step: 380, loss: 0.029834643006324768
step: 390, loss: 0.026023607701063156
step: 400, loss: 0.009710497222840786
step: 410, loss: 0.0073381457477808
step: 420, loss: 0.02754294127225876
step: 430, loss: 0.052471037954092026
step: 440, loss: 0.09497922658920288
step: 450, loss: 0.07927775382995605
step: 460, loss: 0.026131784543395042
epoch 6: dev_f1=0.9899216125419933, f1=0.9797297297297298, best_f1=0.9875424688561721
step: 0, loss: 0.05862954631447792
step: 10, loss: 0.026555676013231277
step: 20, loss: 0.06791225075721741
step: 30, loss: 0.020445654168725014
step: 40, loss: 0.11213058233261108
step: 50, loss: 0.011420832946896553
step: 60, loss: 0.07099904119968414
step: 70, loss: 0.07887297868728638
step: 80, loss: 0.13796713948249817
step: 90, loss: 0.07558891177177429
step: 100, loss: 0.08610570430755615
step: 110, loss: 0.008700593374669552
step: 120, loss: 0.009034579619765282
step: 130, loss: 0.01348473597317934
step: 140, loss: 0.08258626610040665
step: 150, loss: 0.0783238559961319
step: 160, loss: 0.040869638323783875
step: 170, loss: 0.11531668156385422
step: 180, loss: 0.0065728058107197285
step: 190, loss: 0.030666548758745193
step: 200, loss: 0.014730225317180157
step: 210, loss: 0.04386705532670021
step: 220, loss: 0.005248922389000654
step: 230, loss: 0.2915497422218323
step: 240, loss: 0.01682158000767231
step: 250, loss: 0.07852862775325775
step: 260, loss: 0.06097738444805145
step: 270, loss: 0.05706339329481125
step: 280, loss: 0.013877139426767826
step: 290, loss: 0.10994423180818558
step: 300, loss: 0.05374934896826744
step: 310, loss: 0.1607968956232071
step: 320, loss: 0.13133496046066284
step: 330, loss: 0.020055903121829033
step: 340, loss: 0.02897634170949459
step: 350, loss: 0.06924408674240112
step: 360, loss: 0.08544579148292542
step: 370, loss: 0.12604965269565582
step: 380, loss: 0.06315586715936661
step: 390, loss: 0.09363017976284027
step: 400, loss: 0.07733674347400665
step: 410, loss: 0.1036016196012497
step: 420, loss: 0.017573991790413857
step: 430, loss: 0.07624917477369308
step: 440, loss: 0.12574021518230438
step: 450, loss: 0.04789678379893303
step: 460, loss: 0.005991585552692413
epoch 7: dev_f1=0.9853768278965129, f1=0.9864253393665158, best_f1=0.9875424688561721
step: 0, loss: 0.07104159146547318
step: 10, loss: 0.009225025773048401
step: 20, loss: 0.05716714635491371
step: 30, loss: 0.07065828144550323
step: 40, loss: 0.0331154465675354
step: 50, loss: 0.07294873148202896
step: 60, loss: 0.11503718793392181
step: 70, loss: 0.07144547253847122
step: 80, loss: 0.07120227068662643
step: 90, loss: 0.016296550631523132
step: 100, loss: 0.015264647081494331
step: 110, loss: 0.05454365536570549
step: 120, loss: 0.009805121459066868
step: 130, loss: 0.013325412757694721
step: 140, loss: 0.0514797568321228
step: 150, loss: 0.03838861361145973
step: 160, loss: 0.05953352898359299
step: 170, loss: 0.15728917717933655
step: 180, loss: 0.028515726327896118
step: 190, loss: 0.03231412544846535
step: 200, loss: 0.062141939997673035
step: 210, loss: 0.03195783495903015
step: 220, loss: 0.020271917805075645
step: 230, loss: 0.0027880845591425896
step: 240, loss: 0.09765040129423141
step: 250, loss: 0.008423040620982647
step: 260, loss: 0.044198133051395416
step: 270, loss: 0.10531394928693771
step: 280, loss: 0.0009893466485664248
step: 290, loss: 0.019814694300293922
step: 300, loss: 0.003947402350604534
step: 310, loss: 0.010871232487261295
step: 320, loss: 0.06790115684270859
step: 330, loss: 4.09430249419529e-05
step: 340, loss: 0.0036203323397785425
step: 350, loss: 0.0029454363975673914
step: 360, loss: 0.07041055709123611
step: 370, loss: 0.004914617165923119
step: 380, loss: 0.06201159954071045
step: 390, loss: 0.041952162981033325
step: 400, loss: 0.004214351065456867
step: 410, loss: 0.013166330754756927
step: 420, loss: 0.07391460239887238
step: 430, loss: 0.00043910404201596975
step: 440, loss: 0.08151769638061523
step: 450, loss: 0.008481551893055439
step: 460, loss: 0.056686483323574066
epoch 8: dev_f1=0.9887892376681614, f1=0.9854748603351955, best_f1=0.9875424688561721
step: 0, loss: 0.0030390422325581312
step: 10, loss: 0.09978500753641129
step: 20, loss: 0.052207887172698975
step: 30, loss: 0.06449371576309204
step: 40, loss: 0.02864212915301323
step: 50, loss: 0.02249138243496418
step: 60, loss: 0.043984219431877136
step: 70, loss: 0.017139963805675507
step: 80, loss: 0.15851761400699615
step: 90, loss: 0.0653439462184906
step: 100, loss: 0.0358080193400383
step: 110, loss: 0.08116874098777771
step: 120, loss: 0.01560991257429123
step: 130, loss: 0.07548867166042328
step: 140, loss: 0.110162153840065
step: 150, loss: 0.005115014035254717
step: 160, loss: 0.11132591217756271
step: 170, loss: 0.030451640486717224
step: 180, loss: 0.06500218063592911
step: 190, loss: 0.0007433153223246336
step: 200, loss: 0.014554742723703384
step: 210, loss: 0.03851063922047615
step: 220, loss: 0.05075165629386902
step: 230, loss: 0.02510731853544712
step: 240, loss: 0.032884884625673294
step: 250, loss: 0.0002382796083111316
step: 260, loss: 0.003109648125246167
step: 270, loss: 0.0350634939968586
step: 280, loss: 0.023162053897976875
step: 290, loss: 0.09658809751272202
step: 300, loss: 0.02697259932756424
step: 310, loss: 0.0764884501695633
step: 320, loss: 0.021785272285342216
step: 330, loss: 0.013611968606710434
step: 340, loss: 0.007618390489369631
step: 350, loss: 4.221309063723311e-05
step: 360, loss: 0.090140700340271
step: 370, loss: 0.029239844530820847
step: 380, loss: 0.10883944481611252
step: 390, loss: 0.08249269425868988
step: 400, loss: 0.07712068408727646
step: 410, loss: 0.033257730305194855
step: 420, loss: 0.12723012268543243
step: 430, loss: 0.09054768830537796
step: 440, loss: 0.09619013965129852
step: 450, loss: 0.022294145077466965
step: 460, loss: 0.015151547268033028
epoch 9: dev_f1=0.9876265466816648, f1=0.9852774631936579, best_f1=0.9875424688561721
step: 0, loss: 0.09986386448144913
step: 10, loss: 0.05831248313188553
step: 20, loss: 0.092372827231884
step: 30, loss: 0.01660960167646408
step: 40, loss: 0.011947628110647202
step: 50, loss: 0.0017313207499682903
step: 60, loss: 0.005229013506323099
step: 70, loss: 0.08805087208747864
step: 80, loss: 0.040563635528087616
step: 90, loss: 0.015318161807954311
step: 100, loss: 0.008839178830385208
step: 110, loss: 0.05182299017906189
step: 120, loss: 0.07174240052700043
step: 130, loss: 0.016003450378775597
step: 140, loss: 0.038777224719524384
step: 150, loss: 0.05608471855521202
step: 160, loss: 0.002853508573025465
step: 170, loss: 0.013395387679338455
step: 180, loss: 0.05533232539892197
step: 190, loss: 0.018145261332392693
step: 200, loss: 0.000662477221339941
step: 210, loss: 0.00030655841692350805
step: 220, loss: 0.0754024013876915
step: 230, loss: 0.07139501720666885
step: 240, loss: 0.007504352368414402
step: 250, loss: 0.02277231402695179
step: 260, loss: 0.08434756100177765
step: 270, loss: 0.01952945627272129
step: 280, loss: 0.07494242489337921
step: 290, loss: 0.038561612367630005
step: 300, loss: 0.033339567482471466
step: 310, loss: 0.014735035598278046
step: 320, loss: 0.004563288763165474
step: 330, loss: 0.037902794778347015
step: 340, loss: 0.03472481667995453
step: 350, loss: 0.060609422624111176
step: 360, loss: 0.12018318474292755
step: 370, loss: 0.043369174003601074
step: 380, loss: 0.006921963766217232
step: 390, loss: 0.012396583333611488
step: 400, loss: 0.05998527631163597
step: 410, loss: 0.010299891233444214
step: 420, loss: 0.016925645992159843
step: 430, loss: 0.04262690618634224
step: 440, loss: 0.09193606674671173
step: 450, loss: 0.022228477522730827
step: 460, loss: 0.0627460777759552
epoch 10: dev_f1=0.9898989898989898, f1=0.9832026875699889, best_f1=0.9875424688561721
step: 0, loss: 0.05345487222075462
step: 10, loss: 0.05545182153582573
step: 20, loss: 0.055408574640750885
step: 30, loss: 0.004744254052639008
step: 40, loss: 0.011086790822446346
step: 50, loss: 0.08232316374778748
step: 60, loss: 0.0002819023502524942
step: 70, loss: 0.0056035215966403484
step: 80, loss: 0.02327078953385353
step: 90, loss: 0.03561832383275032
step: 100, loss: 0.038561493158340454
step: 110, loss: 0.07162213325500488
step: 120, loss: 0.09510480612516403
step: 130, loss: 0.10239340364933014
step: 140, loss: 0.04490790516138077
step: 150, loss: 0.03532465174794197
step: 160, loss: 0.04143310710787773
step: 170, loss: 0.07293196022510529
step: 180, loss: 0.024753209203481674
step: 190, loss: 0.005787169560790062
step: 200, loss: 3.413375816307962e-05
step: 210, loss: 0.04008945822715759
step: 220, loss: 0.1527690887451172
step: 230, loss: 0.04963105171918869
step: 240, loss: 0.00027051614597439766
step: 250, loss: 0.023639196529984474
step: 260, loss: 0.03266528248786926
step: 270, loss: 0.02262425795197487
step: 280, loss: 0.01801517978310585
step: 290, loss: 0.0008865809650160372
step: 300, loss: 0.18558160960674286
step: 310, loss: 0.03294192999601364
step: 320, loss: 0.04261958971619606
step: 330, loss: 0.009189274162054062
step: 340, loss: 0.011574534699320793
step: 350, loss: 0.06968500465154648
step: 360, loss: 0.04410405084490776
step: 370, loss: 0.015703566372394562
step: 380, loss: 0.029890917241573334
step: 390, loss: 2.301437416463159e-05
step: 400, loss: 0.002501345006749034
step: 410, loss: 0.056695833802223206
step: 420, loss: 0.015137221664190292
step: 430, loss: 0.05599778890609741
step: 440, loss: 0.09628702700138092
step: 450, loss: 0.0382005013525486
step: 460, loss: 0.03795211762189865
epoch 11: dev_f1=0.9887133182844244, f1=0.9762174405436014, best_f1=0.9875424688561721
step: 0, loss: 0.054060474038124084
step: 10, loss: 0.10353730618953705
step: 20, loss: 0.00013831343676429242
step: 30, loss: 4.031242860946804e-05
step: 40, loss: 0.01729016751050949
step: 50, loss: 0.04480836167931557
step: 60, loss: 0.03234013170003891
step: 70, loss: 0.0001826101215556264
step: 80, loss: 0.023487897589802742
step: 90, loss: 0.03551996871829033
step: 100, loss: 0.022261248901486397
step: 110, loss: 0.017500123009085655
step: 120, loss: 0.017874082550406456
step: 130, loss: 0.00022229041496757418
step: 140, loss: 0.029801862314343452
step: 150, loss: 0.0024867551401257515
step: 160, loss: 0.024179989472031593
step: 170, loss: 0.007859035395085812
step: 180, loss: 0.0005038885865360498
step: 190, loss: 0.028014585375785828
step: 200, loss: 0.15053732693195343
step: 210, loss: 0.06163555011153221
step: 220, loss: 0.026960251852869987
step: 230, loss: 0.03725895285606384
step: 240, loss: 0.06417582184076309
step: 250, loss: 0.045479800552129745
step: 260, loss: 0.04075004905462265
step: 270, loss: 0.06210743635892868
step: 280, loss: 0.07658366858959198
step: 290, loss: 0.02414732798933983
step: 300, loss: 0.027341393753886223
step: 310, loss: 0.08619055896997452
step: 320, loss: 0.033298902213573456
step: 330, loss: 0.01128802727907896
step: 340, loss: 0.1125580370426178
step: 350, loss: 0.023563873022794724
step: 360, loss: 0.030986031517386436
step: 370, loss: 0.033225949853658676
step: 380, loss: 0.10439325869083405
step: 390, loss: 0.03885629028081894
step: 400, loss: 0.0011817070189863443
step: 410, loss: 0.07192466408014297
step: 420, loss: 0.06716423481702805
step: 430, loss: 0.0632348507642746
step: 440, loss: 0.059930864721536636
step: 450, loss: 0.0019279344705864787
step: 460, loss: 0.004384107422083616
epoch 12: dev_f1=0.9887387387387387, f1=0.9785310734463276, best_f1=0.9875424688561721
step: 0, loss: 0.02227916568517685
step: 10, loss: 0.012245891615748405
step: 20, loss: 0.050501301884651184
step: 30, loss: 6.946998473722488e-05
step: 40, loss: 0.0007547390414401889
step: 50, loss: 0.029020972549915314
step: 60, loss: 0.05648837611079216
step: 70, loss: 0.043247856199741364
step: 80, loss: 0.015597944147884846
step: 90, loss: 8.864991104928777e-05
step: 100, loss: 0.00024153315462172031
step: 110, loss: 0.03607824444770813
step: 120, loss: 0.06881698220968246
step: 130, loss: 0.04098498448729515
step: 140, loss: 0.06349834054708481
step: 150, loss: 0.010103796608746052
step: 160, loss: 0.043028153479099274
step: 170, loss: 0.004102040082216263
step: 180, loss: 0.03513038530945778
step: 190, loss: 0.0024241767823696136
step: 200, loss: 0.033931829035282135
step: 210, loss: 0.0455939956009388
step: 220, loss: 0.017196251079440117
step: 230, loss: 0.0398612916469574
step: 240, loss: 0.057459525763988495
step: 250, loss: 0.023060103878378868
step: 260, loss: 0.04934476688504219
step: 270, loss: 0.035324569791555405
step: 280, loss: 0.033302608877420425
step: 290, loss: 0.008342035114765167
step: 300, loss: 0.03787541016936302
step: 310, loss: 0.027144944295287132
step: 320, loss: 0.021669156849384308
step: 330, loss: 0.014727001078426838
step: 340, loss: 0.054016321897506714
step: 350, loss: 0.016756359487771988
step: 360, loss: 0.0005166966002434492
step: 370, loss: 0.029767442494630814
step: 380, loss: 0.03685329109430313
step: 390, loss: 0.06787337362766266
step: 400, loss: 0.0978698804974556
step: 410, loss: 0.01555401086807251
step: 420, loss: 0.00030942505691200495
step: 430, loss: 0.004935489967465401
step: 440, loss: 0.05574334040284157
step: 450, loss: 0.017850086092948914
step: 460, loss: 0.01850374974310398
epoch 13: dev_f1=0.9876265466816648, f1=0.9797297297297298, best_f1=0.9875424688561721
step: 0, loss: 0.024587256833910942
step: 10, loss: 0.052806269377470016
step: 20, loss: 0.02670440636575222
step: 30, loss: 0.05213277041912079
step: 40, loss: 0.06991167366504669
step: 50, loss: 0.013503392226994038
step: 60, loss: 0.024881727993488312
step: 70, loss: 0.039418142288923264
step: 80, loss: 0.02767815627157688
step: 90, loss: 0.0009990362450480461
step: 100, loss: 0.05580729618668556
step: 110, loss: 0.11703784763813019
step: 120, loss: 0.032614126801490784
step: 130, loss: 0.039513103663921356
step: 140, loss: 0.11876194924116135
step: 150, loss: 0.04291854798793793
step: 160, loss: 0.026621578261256218
step: 170, loss: 6.826788012403995e-05
step: 180, loss: 0.021579090505838394
step: 190, loss: 0.008030224591493607
step: 200, loss: 0.0003604634548537433
step: 210, loss: 0.056866638362407684
step: 220, loss: 0.042148347944021225
step: 230, loss: 4.49412691523321e-05
step: 240, loss: 0.05796413496136665
step: 250, loss: 0.07455819845199585
step: 260, loss: 0.0006782087730243802
step: 270, loss: 5.984043309581466e-05
step: 280, loss: 0.025571413338184357
step: 290, loss: 0.06570221483707428
step: 300, loss: 0.17337338626384735
step: 310, loss: 0.031498707830905914
step: 320, loss: 0.07695600390434265
step: 330, loss: 2.9394208468147554e-05
step: 340, loss: 0.022939061746001244
step: 350, loss: 0.0305347740650177
step: 360, loss: 0.11064721643924713
step: 370, loss: 0.016927776858210564
step: 380, loss: 0.016110427677631378
step: 390, loss: 0.00022141668887343258
step: 400, loss: 0.1049196720123291
step: 410, loss: 0.0022297140676528215
step: 420, loss: 0.024446403607726097
step: 430, loss: 0.01766565814614296
step: 440, loss: 0.10395882278680801
step: 450, loss: 0.047208428382873535
step: 460, loss: 0.018139272928237915
epoch 14: dev_f1=0.9887640449438202, f1=0.984304932735426, best_f1=0.9875424688561721
step: 0, loss: 0.0012504238402470946
step: 10, loss: 0.028603941202163696
step: 20, loss: 0.0003475081757642329
step: 30, loss: 0.028261130675673485
step: 40, loss: 0.0021076430566608906
step: 50, loss: 0.037681736052036285
step: 60, loss: 0.0315299928188324
step: 70, loss: 0.0020190919749438763
step: 80, loss: 0.07351525127887726
step: 90, loss: 0.035940829664468765
step: 100, loss: 0.019292118027806282
step: 110, loss: 5.690131365554407e-05
step: 120, loss: 5.418711225502193e-05
step: 130, loss: 0.00011593485396588221
step: 140, loss: 0.015397777780890465
step: 150, loss: 0.04106021672487259
step: 160, loss: 0.019013050943613052
step: 170, loss: 0.048144374042749405
step: 180, loss: 0.009988553822040558
step: 190, loss: 0.029460852965712547
step: 200, loss: 0.11296089738607407
step: 210, loss: 0.03377656638622284
step: 220, loss: 0.04603094235062599
step: 230, loss: 0.024610279127955437
step: 240, loss: 0.06148175895214081
step: 250, loss: 0.0377238504588604
step: 260, loss: 0.06172129884362221
step: 270, loss: 0.018486276268959045
step: 280, loss: 0.022336691617965698
step: 290, loss: 0.034948624670505524
step: 300, loss: 0.05121903866529465
step: 310, loss: 0.020723775029182434
step: 320, loss: 0.019718104973435402
step: 330, loss: 0.0006944559863768518
step: 340, loss: 0.0008873478509485722
step: 350, loss: 0.08736595511436462
step: 360, loss: 0.014354989863932133
step: 370, loss: 0.05672610178589821
step: 380, loss: 0.03506360203027725
step: 390, loss: 0.0005938517861068249
step: 400, loss: 0.032311029732227325
step: 410, loss: 0.10607756674289703
step: 420, loss: 5.961440547253005e-05
step: 430, loss: 0.02157112956047058
step: 440, loss: 0.027025479823350906
step: 450, loss: 0.04376380890607834
step: 460, loss: 0.046987950801849365
epoch 15: dev_f1=0.9875706214689265, f1=0.9830124575311437, best_f1=0.9875424688561721
step: 0, loss: 0.04031212627887726
step: 10, loss: 0.02489613927900791
step: 20, loss: 0.09995229542255402
step: 30, loss: 0.01634703390300274
step: 40, loss: 0.02224372699856758
step: 50, loss: 0.025253910571336746
step: 60, loss: 0.028422994539141655
step: 70, loss: 0.021412841975688934
step: 80, loss: 0.0001861841301433742
step: 90, loss: 0.001921535818837583
step: 100, loss: 0.021409649401903152
step: 110, loss: 7.374144479399547e-05
step: 120, loss: 0.0030547224450856447
step: 130, loss: 0.06293975561857224
step: 140, loss: 0.05044291540980339
step: 150, loss: 0.021884223446249962
step: 160, loss: 0.03596982732415199
step: 170, loss: 0.06566383689641953
step: 180, loss: 0.02155955694615841
step: 190, loss: 0.013213204219937325
step: 200, loss: 5.4637930588796735e-05
step: 210, loss: 0.01616453193128109
step: 220, loss: 0.020942911505699158
step: 230, loss: 0.02161685936152935
step: 240, loss: 0.017467036843299866
step: 250, loss: 0.03928813338279724
step: 260, loss: 0.02901047095656395
step: 270, loss: 0.059398602694272995
step: 280, loss: 0.048884596675634384
step: 290, loss: 0.02766386792063713
step: 300, loss: 0.01643342152237892
step: 310, loss: 0.020998187363147736
step: 320, loss: 0.0327451266348362
step: 330, loss: 0.0005282306228764355
step: 340, loss: 0.0008484587888233364
step: 350, loss: 0.04152418673038483
step: 360, loss: 0.054471056908369064
step: 370, loss: 0.029467452317476273
step: 380, loss: 7.249854388646781e-05
step: 390, loss: 0.051379356533288956
step: 400, loss: 0.0028660071548074484
step: 410, loss: 0.05050053820014
step: 420, loss: 0.056745726615190506
step: 430, loss: 0.036954615265131
step: 440, loss: 0.029016010463237762
step: 450, loss: 0.00010569553705863655
step: 460, loss: 0.01743292808532715
epoch 16: dev_f1=0.9875706214689265, f1=0.987598647125141, best_f1=0.9875424688561721
step: 0, loss: 0.0022866278886795044
step: 10, loss: 0.013860942795872688
step: 20, loss: 1.433096440450754e-05
step: 30, loss: 0.047684937715530396
step: 40, loss: 0.015771953389048576
step: 50, loss: 0.10436797887086868
step: 60, loss: 0.02296418696641922
step: 70, loss: 0.055952176451683044
step: 80, loss: 0.01641804724931717
step: 90, loss: 0.013602945022284985
step: 100, loss: 0.012051554396748543
step: 110, loss: 0.02264922484755516
step: 120, loss: 0.019713645800948143
step: 130, loss: 0.04920945689082146
step: 140, loss: 5.653582775266841e-05
step: 150, loss: 2.8891683541587554e-05
step: 160, loss: 0.060002993792295456
step: 170, loss: 6.439634307753295e-05
step: 180, loss: 0.030835894867777824
step: 190, loss: 6.134188879514113e-05
step: 200, loss: 0.08289855718612671
step: 210, loss: 4.211824125377461e-05
step: 220, loss: 0.0649857446551323
step: 230, loss: 0.047075022011995316
step: 240, loss: 4.978801734978333e-05
step: 250, loss: 0.018200060352683067
step: 260, loss: 0.04789268225431442
step: 270, loss: 0.023471781983971596
step: 280, loss: 0.044637057930231094
step: 290, loss: 0.02578483335673809
step: 300, loss: 0.019929667934775352
step: 310, loss: 0.022954681888222694
step: 320, loss: 0.023873232305049896
step: 330, loss: 0.01269511692225933
step: 340, loss: 0.00031624376424588263
step: 350, loss: 4.0192851884057745e-05
step: 360, loss: 2.2987715055933222e-05
step: 370, loss: 0.07087063789367676
step: 380, loss: 2.2354128304868937e-05
step: 390, loss: 0.006867222487926483
step: 400, loss: 0.030666768550872803
step: 410, loss: 0.02442237176001072
step: 420, loss: 0.016738489270210266
step: 430, loss: 0.01914696767926216
step: 440, loss: 0.03980574011802673
step: 450, loss: 0.0016074745217338204
step: 460, loss: 0.039039142429828644
epoch 17: dev_f1=0.9876543209876544, f1=0.9843400447427293, best_f1=0.9875424688561721
step: 0, loss: 0.00010576847125776112
step: 10, loss: 0.02047858200967312
step: 20, loss: 0.08028548955917358
step: 30, loss: 0.04182073473930359
step: 40, loss: 6.0391463193809614e-05
step: 50, loss: 0.008146039210259914
step: 60, loss: 0.0017080880934372544
step: 70, loss: 0.04170636087656021
step: 80, loss: 0.03978395462036133
step: 90, loss: 7.809716043993831e-05
step: 100, loss: 4.3918058509007096e-05
step: 110, loss: 0.11083197593688965
step: 120, loss: 0.036946896463632584
step: 130, loss: 0.03043479472398758
step: 140, loss: 0.02371559850871563
step: 150, loss: 0.019655179232358932
step: 160, loss: 0.01298179104924202
step: 170, loss: 0.0007233678479678929
step: 180, loss: 0.021452980116009712
step: 190, loss: 0.02444174885749817
step: 200, loss: 0.042087748646736145
step: 210, loss: 0.018493475392460823
step: 220, loss: 0.018902285024523735
step: 230, loss: 0.04554526135325432
step: 240, loss: 0.009082507342100143
step: 250, loss: 0.03466236963868141
step: 260, loss: 0.02643674798309803
step: 270, loss: 0.04559813439846039
step: 280, loss: 6.06315879849717e-05
step: 290, loss: 0.022083433344960213
step: 300, loss: 0.07127594202756882
step: 310, loss: 0.022722411900758743
step: 320, loss: 0.07015364617109299
step: 330, loss: 0.0003281386161688715
step: 340, loss: 0.000718757277354598
step: 350, loss: 0.00181244604755193
step: 360, loss: 4.266485484549776e-05
step: 370, loss: 0.02754189819097519
step: 380, loss: 0.052543897181749344
step: 390, loss: 0.02384413406252861
step: 400, loss: 0.000359421013854444
step: 410, loss: 0.04038996249437332
step: 420, loss: 0.024860797449946404
step: 430, loss: 2.1892266886425205e-05
step: 440, loss: 0.0003043592441827059
step: 450, loss: 0.04578031599521637
step: 460, loss: 0.054786212742328644
epoch 18: dev_f1=0.9876265466816648, f1=0.984304932735426, best_f1=0.9875424688561721
step: 0, loss: 0.02430463396012783
step: 10, loss: 0.0891098901629448
step: 20, loss: 3.3520645956741646e-05
step: 30, loss: 0.0579628050327301
step: 40, loss: 9.49693494476378e-05
step: 50, loss: 0.021522101014852524
step: 60, loss: 0.020125871524214745
step: 70, loss: 0.021524719893932343
step: 80, loss: 0.016225475817918777
step: 90, loss: 0.06970882415771484
step: 100, loss: 0.022258330136537552
step: 110, loss: 0.01779123954474926
step: 120, loss: 9.755756764207035e-05
step: 130, loss: 3.960755202569999e-05
step: 140, loss: 0.025919973850250244
step: 150, loss: 0.01181501243263483
step: 160, loss: 0.01788160763680935
step: 170, loss: 3.068688965868205e-05
step: 180, loss: 4.9014754040399566e-05
step: 190, loss: 0.03440587967634201
step: 200, loss: 0.05985505133867264
step: 210, loss: 0.01946750283241272
step: 220, loss: 0.019285105168819427
step: 230, loss: 0.02370256744325161
step: 240, loss: 0.01958276517689228
step: 250, loss: 0.04025014862418175
step: 260, loss: 0.02405938133597374
step: 270, loss: 3.073187326663174e-05
step: 280, loss: 0.0386882983148098
step: 290, loss: 2.3479458832298405e-05
step: 300, loss: 0.023180773481726646
step: 310, loss: 4.820403773919679e-05
step: 320, loss: 0.030412890017032623
step: 330, loss: 0.00012323548435233533
step: 340, loss: 0.00014124329027254134
step: 350, loss: 0.0441642664372921
step: 360, loss: 0.021952146664261818
step: 370, loss: 0.043301112949848175
step: 380, loss: 0.024232041090726852
step: 390, loss: 0.0010774786351248622
step: 400, loss: 0.027420803904533386
step: 410, loss: 5.4227246437221766e-05
step: 420, loss: 3.5381825000513345e-05
step: 430, loss: 0.062219735234975815
step: 440, loss: 0.02057844027876854
step: 450, loss: 0.0024538065772503614
step: 460, loss: 0.01949990540742874
epoch 19: dev_f1=0.9875706214689265, f1=0.9853107344632768, best_f1=0.9875424688561721
step: 0, loss: 6.48528293822892e-05
step: 10, loss: 0.0817718654870987
step: 20, loss: 0.02207101136445999
step: 30, loss: 0.02013421431183815
step: 40, loss: 0.04539192467927933
step: 50, loss: 0.04888079687952995
step: 60, loss: 0.01953478343784809
step: 70, loss: 0.02436656318604946
step: 80, loss: 0.051691070199012756
step: 90, loss: 3.761623884201981e-05
step: 100, loss: 0.039910607039928436
step: 110, loss: 0.020208848640322685
step: 120, loss: 0.035045258700847626
step: 130, loss: 0.0001685119786998257
step: 140, loss: 1.8774620912154205e-05
step: 150, loss: 0.05049003288149834
step: 160, loss: 0.014028421603143215
step: 170, loss: 4.6103057684376836e-05
step: 180, loss: 0.019258545711636543
step: 190, loss: 0.019370192661881447
step: 200, loss: 0.0004274352977517992
step: 210, loss: 0.036384064704179764
step: 220, loss: 0.017840908840298653
step: 230, loss: 0.06805529445409775
step: 240, loss: 0.020631534978747368
step: 250, loss: 0.017366522923111916
step: 260, loss: 0.00010275370004819706
step: 270, loss: 2.738293733273167e-05
step: 280, loss: 0.021700358018279076
step: 290, loss: 0.035044219344854355
step: 300, loss: 0.021882189437747
step: 310, loss: 2.094658339046873e-05
step: 320, loss: 0.017379948869347572
step: 330, loss: 0.009493977762758732
step: 340, loss: 3.867978011840023e-05
step: 350, loss: 0.036655668169260025
step: 360, loss: 0.036344218999147415
step: 370, loss: 0.02176620252430439
step: 380, loss: 1.7347769244224764e-05
step: 390, loss: 0.04196508601307869
step: 400, loss: 0.07095427811145782
step: 410, loss: 0.03901679068803787
step: 420, loss: 4.111039743293077e-05
step: 430, loss: 0.018823137506842613
step: 440, loss: 0.025571579113602638
step: 450, loss: 0.055041275918483734
step: 460, loss: 0.00015768216690048575
epoch 20: dev_f1=0.9875706214689265, f1=0.9841628959276018, best_f1=0.9875424688561721
