cuda
Device: cuda
step: 0, loss: 0.82449871301651
step: 10, loss: 0.513423502445221
step: 20, loss: 0.449619859457016
step: 30, loss: 0.410381942987442
step: 40, loss: 0.3171014189720154
step: 50, loss: 0.5346271991729736
step: 60, loss: 0.21446841955184937
step: 70, loss: 0.18816456198692322
step: 80, loss: 0.27959930896759033
step: 90, loss: 0.1694183200597763
step: 100, loss: 0.17457841336727142
step: 110, loss: 0.4234391450881958
step: 120, loss: 0.09325875341892242
step: 130, loss: 0.11802633851766586
step: 140, loss: 0.17623214423656464
step: 150, loss: 0.08426128327846527
step: 160, loss: 0.16839274764060974
step: 170, loss: 0.09935503453016281
step: 180, loss: 0.18330074846744537
step: 190, loss: 0.10092031955718994
step: 200, loss: 0.08568473905324936
step: 210, loss: 0.07030455768108368
step: 220, loss: 0.09943424165248871
step: 230, loss: 0.14499713480472565
step: 240, loss: 0.1703481674194336
step: 250, loss: 0.09837397187948227
step: 260, loss: 0.198287233710289
step: 270, loss: 0.13070204854011536
step: 280, loss: 0.09043893963098526
step: 290, loss: 0.23281757533550262
step: 300, loss: 0.13826794922351837
step: 310, loss: 0.23440365493297577
step: 320, loss: 0.05207633972167969
step: 330, loss: 0.1520269364118576
step: 340, loss: 0.230283722281456
step: 350, loss: 0.17015165090560913
step: 360, loss: 0.3139576315879822
step: 370, loss: 0.15743307769298553
step: 380, loss: 0.019343843683600426
step: 390, loss: 0.08070223033428192
step: 400, loss: 0.09448766708374023
step: 410, loss: 0.12818357348442078
step: 420, loss: 0.07317394763231277
step: 430, loss: 0.22195424139499664
step: 440, loss: 0.03743307292461395
step: 450, loss: 0.11818234622478485
step: 460, loss: 0.15013688802719116
epoch 1: dev_f1=0.9887640449438202, f1=0.9841269841269841, best_f1=0.9841269841269841
step: 0, loss: 0.027341328561306
step: 10, loss: 0.04593712463974953
step: 20, loss: 0.07785921543836594
step: 30, loss: 0.15307608246803284
step: 40, loss: 0.009465541690587997
step: 50, loss: 0.11909911036491394
step: 60, loss: 0.035394445061683655
step: 70, loss: 0.028289446607232094
step: 80, loss: 0.1842191517353058
step: 90, loss: 0.05982225015759468
step: 100, loss: 0.20907621085643768
step: 110, loss: 0.0652703046798706
step: 120, loss: 0.06831563264131546
step: 130, loss: 0.09218286722898483
step: 140, loss: 0.06666268408298492
step: 150, loss: 0.10085529834032059
step: 160, loss: 0.08914178609848022
step: 170, loss: 0.08258330076932907
step: 180, loss: 0.012158443219959736
step: 190, loss: 0.21975137293338776
step: 200, loss: 0.039947353303432465
step: 210, loss: 0.08419173210859299
step: 220, loss: 0.13210368156433105
step: 230, loss: 0.03143421933054924
step: 240, loss: 0.0820322260260582
step: 250, loss: 0.016933267936110497
step: 260, loss: 0.07940088957548141
step: 270, loss: 0.056096114218235016
step: 280, loss: 0.01349653024226427
step: 290, loss: 0.11373449862003326
step: 300, loss: 0.08084136992692947
step: 310, loss: 0.04624360054731369
step: 320, loss: 0.04023294895887375
step: 330, loss: 0.020731022581458092
step: 340, loss: 0.16177386045455933
step: 350, loss: 0.017195619642734528
step: 360, loss: 0.06799585372209549
step: 370, loss: 0.0715252086520195
step: 380, loss: 0.13441850244998932
step: 390, loss: 0.01877141371369362
step: 400, loss: 0.2405732423067093
step: 410, loss: 0.04601156339049339
step: 420, loss: 0.08170385658740997
step: 430, loss: 0.05213412642478943
step: 440, loss: 0.043411944061517715
step: 450, loss: 0.030227510258555412
step: 460, loss: 0.04110318049788475
epoch 2: dev_f1=0.9898074745186863, f1=0.9806157354618015, best_f1=0.9806157354618015
step: 0, loss: 0.07486238330602646
step: 10, loss: 0.034465476870536804
step: 20, loss: 0.18818463385105133
step: 30, loss: 0.05832637473940849
step: 40, loss: 0.13907238841056824
step: 50, loss: 0.05886342376470566
step: 60, loss: 0.016344472765922546
step: 70, loss: 0.0035741266328841448
step: 80, loss: 0.07967977970838547
step: 90, loss: 0.1480921059846878
step: 100, loss: 0.01769810914993286
step: 110, loss: 0.026788953691720963
step: 120, loss: 0.012644792906939983
step: 130, loss: 0.07032895088195801
step: 140, loss: 0.10878030210733414
step: 150, loss: 0.0234244205057621
step: 160, loss: 0.008703048340976238
step: 170, loss: 0.08485840260982513
step: 180, loss: 0.024424508213996887
step: 190, loss: 0.06156108155846596
step: 200, loss: 0.07892973721027374
step: 210, loss: 0.1187344416975975
step: 220, loss: 0.09974344074726105
step: 230, loss: 0.08950081467628479
step: 240, loss: 0.10293660312891006
step: 250, loss: 0.012338539585471153
step: 260, loss: 0.08337610960006714
step: 270, loss: 0.07362479716539383
step: 280, loss: 0.06692159920930862
step: 290, loss: 0.09054102003574371
step: 300, loss: 0.09656618535518646
step: 310, loss: 0.000330623792251572
step: 320, loss: 0.01923968456685543
step: 330, loss: 0.07130616158246994
step: 340, loss: 0.007879722863435745
step: 350, loss: 0.07374431192874908
step: 360, loss: 0.06229443848133087
step: 370, loss: 0.03814543038606644
step: 380, loss: 0.031701672822237015
step: 390, loss: 0.1196603924036026
step: 400, loss: 0.022167576476931572
step: 410, loss: 0.18080443143844604
step: 420, loss: 0.19762581586837769
step: 430, loss: 0.04186288267374039
step: 440, loss: 0.25041040778160095
step: 450, loss: 0.005415832158178091
step: 460, loss: 0.09340628236532211
epoch 3: dev_f1=0.9831271091113611, f1=0.9807037457434733, best_f1=0.9806157354618015
step: 0, loss: 0.06785145401954651
step: 10, loss: 0.043723028153181076
step: 20, loss: 0.02157907374203205
step: 30, loss: 0.01222439855337143
step: 40, loss: 0.0598747655749321
step: 50, loss: 0.06561931222677231
step: 60, loss: 0.021983813494443893
step: 70, loss: 0.11447816342115402
step: 80, loss: 0.14668889343738556
step: 90, loss: 0.030102049931883812
step: 100, loss: 0.015124399214982986
step: 110, loss: 0.004544239025563002
step: 120, loss: 0.10645030438899994
step: 130, loss: 0.02607816271483898
step: 140, loss: 0.06884579360485077
step: 150, loss: 0.05764171481132507
step: 160, loss: 0.032923758029937744
step: 170, loss: 0.12955036759376526
step: 180, loss: 0.07100095599889755
step: 190, loss: 0.012061834335327148
step: 200, loss: 0.010528923943638802
step: 210, loss: 0.07895474135875702
step: 220, loss: 0.07581077516078949
step: 230, loss: 0.059438202530145645
step: 240, loss: 0.0771113932132721
step: 250, loss: 0.07542503625154495
step: 260, loss: 0.03554927185177803
step: 270, loss: 0.12144859880208969
step: 280, loss: 0.06935916841030121
step: 290, loss: 0.04757482558488846
step: 300, loss: 0.011623205617070198
step: 310, loss: 0.08385973423719406
step: 320, loss: 0.010894169099628925
step: 330, loss: 0.08657785505056381
step: 340, loss: 0.08311362564563751
step: 350, loss: 0.040758032351732254
step: 360, loss: 0.010799268260598183
step: 370, loss: 0.09699679166078568
step: 380, loss: 0.12083707004785538
step: 390, loss: 0.09053164720535278
step: 400, loss: 0.09578998386859894
step: 410, loss: 0.08530694991350174
step: 420, loss: 0.03190557658672333
step: 430, loss: 0.06205568462610245
step: 440, loss: 0.02775183878839016
step: 450, loss: 0.01858668401837349
step: 460, loss: 0.006843394134193659
epoch 4: dev_f1=0.9910112359550561, f1=0.9898762654668166, best_f1=0.9898762654668166
step: 0, loss: 0.061898406594991684
step: 10, loss: 0.10192619264125824
step: 20, loss: 0.009212061762809753
step: 30, loss: 0.1397438645362854
step: 40, loss: 0.025815147906541824
step: 50, loss: 0.05788328871130943
step: 60, loss: 0.01709192991256714
step: 70, loss: 0.023978684097528458
step: 80, loss: 0.0033779083751142025
step: 90, loss: 0.021069113165140152
step: 100, loss: 0.07588111609220505
step: 110, loss: 0.006159491837024689
step: 120, loss: 0.019173316657543182
step: 130, loss: 0.06978587806224823
step: 140, loss: 0.0754452496767044
step: 150, loss: 0.02535884641110897
step: 160, loss: 0.056413304060697556
step: 170, loss: 0.08653774857521057
step: 180, loss: 0.006477657705545425
step: 190, loss: 0.07782525569200516
step: 200, loss: 0.087720587849617
step: 210, loss: 0.006610854994505644
step: 220, loss: 0.06324822455644608
step: 230, loss: 0.06508135795593262
step: 240, loss: 0.008053289726376534
step: 250, loss: 0.045548632740974426
step: 260, loss: 0.06144534423947334
step: 270, loss: 0.071792371571064
step: 280, loss: 0.10530614107847214
step: 290, loss: 0.00019548849377315491
step: 300, loss: 0.024625692516565323
step: 310, loss: 0.0040756212547421455
step: 320, loss: 0.004044211935251951
step: 330, loss: 0.010236706584692001
step: 340, loss: 0.04871523380279541
step: 350, loss: 0.10743515193462372
step: 360, loss: 0.12684796750545502
step: 370, loss: 0.051828283816576004
step: 380, loss: 0.03369792178273201
step: 390, loss: 0.031033659353852272
step: 400, loss: 0.0174639243632555
step: 410, loss: 0.07673545181751251
step: 420, loss: 0.09814579784870148
step: 430, loss: 0.019663704559206963
step: 440, loss: 0.056792836636304855
step: 450, loss: 0.032625630497932434
step: 460, loss: 0.014085076749324799
epoch 5: dev_f1=0.9898534385569334, f1=0.9864253393665158, best_f1=0.9898762654668166
step: 0, loss: 0.011757689528167248
step: 10, loss: 0.07871737331151962
step: 20, loss: 0.09455059468746185
step: 30, loss: 0.01741505041718483
step: 40, loss: 0.1445474624633789
step: 50, loss: 0.018591683357954025
step: 60, loss: 0.00450398912653327
step: 70, loss: 0.0058210911229252815
step: 80, loss: 0.0899621993303299
step: 90, loss: 0.07799267768859863
step: 100, loss: 0.16200333833694458
step: 110, loss: 0.03163623437285423
step: 120, loss: 0.012040944769978523
step: 130, loss: 0.005670659709721804
step: 140, loss: 0.006992658134549856
step: 150, loss: 0.04178258031606674
step: 160, loss: 0.025781409814953804
step: 170, loss: 0.03603731095790863
step: 180, loss: 0.0219708401709795
step: 190, loss: 0.01306849904358387
step: 200, loss: 0.13743920624256134
step: 210, loss: 0.07785782963037491
step: 220, loss: 0.018214810639619827
step: 230, loss: 0.09978179633617401
step: 240, loss: 0.1429857462644577
step: 250, loss: 0.010662566870450974
step: 260, loss: 0.1433182954788208
step: 270, loss: 0.03630834445357323
step: 280, loss: 0.006679524667561054
step: 290, loss: 0.08797984570264816
step: 300, loss: 0.03769608587026596
step: 310, loss: 0.34301280975341797
step: 320, loss: 0.039565104991197586
step: 330, loss: 0.024798575788736343
step: 340, loss: 0.011177335865795612
step: 350, loss: 0.014504551887512207
step: 360, loss: 0.019015399739146233
step: 370, loss: 0.008992488496005535
step: 380, loss: 0.002952727023512125
step: 390, loss: 0.18329472839832306
step: 400, loss: 0.008350209333002567
step: 410, loss: 0.017076201736927032
step: 420, loss: 0.01589478924870491
step: 430, loss: 0.008497452363371849
step: 440, loss: 0.011824356392025948
step: 450, loss: 0.12417653203010559
step: 460, loss: 0.01531305257230997
epoch 6: dev_f1=0.9921436588103255, f1=0.9910313901345291, best_f1=0.9910313901345291
step: 0, loss: 0.075545534491539
step: 10, loss: 0.007925014942884445
step: 20, loss: 0.12749354541301727
step: 30, loss: 0.05725054815411568
step: 40, loss: 0.018945973366498947
step: 50, loss: 0.000122490047942847
step: 60, loss: 0.09882520884275436
step: 70, loss: 0.01723899319767952
step: 80, loss: 0.02147645317018032
step: 90, loss: 0.15606091916561127
step: 100, loss: 0.036580223590135574
step: 110, loss: 0.13745710253715515
step: 120, loss: 0.010454664006829262
step: 130, loss: 0.009043809026479721
step: 140, loss: 0.07775238156318665
step: 150, loss: 0.0518539696931839
step: 160, loss: 0.015512854792177677
step: 170, loss: 0.06262847036123276
step: 180, loss: 4.279732456780039e-05
step: 190, loss: 0.06566502898931503
step: 200, loss: 0.0005413541803136468
step: 210, loss: 0.08929368853569031
step: 220, loss: 0.15271389484405518
step: 230, loss: 0.03262113034725189
step: 240, loss: 0.1803818643093109
step: 250, loss: 0.005919392686337233
step: 260, loss: 0.008433599956333637
step: 270, loss: 0.05039840191602707
step: 280, loss: 0.0007941194344311953
step: 290, loss: 0.07623051106929779
step: 300, loss: 0.00044167012674733996
step: 310, loss: 0.02025138959288597
step: 320, loss: 0.12465300410985947
step: 330, loss: 0.01749216578900814
step: 340, loss: 0.012939161621034145
step: 350, loss: 0.018811998888850212
step: 360, loss: 0.01662866398692131
step: 370, loss: 0.03642398864030838
step: 380, loss: 0.06296910345554352
step: 390, loss: 0.024611087515950203
step: 400, loss: 0.026337232440710068
step: 410, loss: 0.010376039892435074
step: 420, loss: 0.03232188895344734
step: 430, loss: 0.014036997221410275
step: 440, loss: 0.19425168633460999
step: 450, loss: 0.06917653232812881
step: 460, loss: 0.019235769286751747
epoch 7: dev_f1=0.9943757030371203, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.07024580240249634
step: 10, loss: 0.08461453765630722
step: 20, loss: 0.02205299586057663
step: 30, loss: 0.006105258595198393
step: 40, loss: 0.013925263658165932
step: 50, loss: 0.024194631725549698
step: 60, loss: 0.022683141753077507
step: 70, loss: 0.08351963013410568
step: 80, loss: 0.007904229685664177
step: 90, loss: 0.0036134591791778803
step: 100, loss: 0.005871702916920185
step: 110, loss: 0.16738727688789368
step: 120, loss: 0.062080662697553635
step: 130, loss: 0.06123920530080795
step: 140, loss: 0.07838365435600281
step: 150, loss: 0.016929030418395996
step: 160, loss: 0.018124468624591827
step: 170, loss: 0.08080864697694778
step: 180, loss: 0.02280515991151333
step: 190, loss: 0.09488791227340698
step: 200, loss: 0.19076035916805267
step: 210, loss: 0.06501776725053787
step: 220, loss: 0.07690633833408356
step: 230, loss: 0.12151215970516205
step: 240, loss: 0.027264855802059174
step: 250, loss: 0.04850200191140175
step: 260, loss: 0.009269529953598976
step: 270, loss: 0.07720208913087845
step: 280, loss: 0.03147314488887787
step: 290, loss: 0.013116752728819847
step: 300, loss: 0.044977009296417236
step: 310, loss: 0.005979988723993301
step: 320, loss: 0.010345611721277237
step: 330, loss: 0.0033941082656383514
step: 340, loss: 0.018512243404984474
step: 350, loss: 0.08196155726909637
step: 360, loss: 0.16568875312805176
step: 370, loss: 0.010892108082771301
step: 380, loss: 0.040791697800159454
step: 390, loss: 0.010827322490513325
step: 400, loss: 0.008146615698933601
step: 410, loss: 0.05710717663168907
step: 420, loss: 0.07729338854551315
step: 430, loss: 0.076253242790699
step: 440, loss: 0.010400950908660889
step: 450, loss: 0.0844680443406105
step: 460, loss: 0.03216850385069847
epoch 8: dev_f1=0.9910313901345291, f1=0.9832026875699889, best_f1=0.9854096520763187
step: 0, loss: 0.10131313651800156
step: 10, loss: 0.07767657935619354
step: 20, loss: 0.06779178977012634
step: 30, loss: 0.11782243102788925
step: 40, loss: 0.016583416610956192
step: 50, loss: 0.010502484627068043
step: 60, loss: 0.018249567598104477
step: 70, loss: 0.025541653856635094
step: 80, loss: 0.05576716735959053
step: 90, loss: 0.011135625652968884
step: 100, loss: 0.11685580015182495
step: 110, loss: 0.17600753903388977
step: 120, loss: 0.03440368175506592
step: 130, loss: 0.06264004856348038
step: 140, loss: 0.04164229705929756
step: 150, loss: 0.059342361986637115
step: 160, loss: 0.16501502692699432
step: 170, loss: 0.00211290898732841
step: 180, loss: 0.09851477295160294
step: 190, loss: 0.06382883340120316
step: 200, loss: 0.02829720266163349
step: 210, loss: 0.00535264378413558
step: 220, loss: 0.08968134224414825
step: 230, loss: 0.012533142231404781
step: 240, loss: 0.056331172585487366
step: 250, loss: 0.0034705502912402153
step: 260, loss: 0.08297780901193619
step: 270, loss: 0.05586564540863037
step: 280, loss: 0.07852493226528168
step: 290, loss: 0.04741278290748596
step: 300, loss: 0.006288151256740093
step: 310, loss: 0.04568290337920189
step: 320, loss: 0.030936436727643013
step: 330, loss: 0.11728598922491074
step: 340, loss: 0.12774695456027985
step: 350, loss: 0.00647337269037962
step: 360, loss: 0.023337965831160545
step: 370, loss: 0.009559126570820808
step: 380, loss: 0.0088999904692173
step: 390, loss: 0.0006493236287496984
step: 400, loss: 0.012546852231025696
step: 410, loss: 0.04234446585178375
step: 420, loss: 0.01590578630566597
step: 430, loss: 0.010181020013988018
step: 440, loss: 0.004158583469688892
step: 450, loss: 0.0118008553981781
step: 460, loss: 0.020198361948132515
epoch 9: dev_f1=0.9898305084745763, f1=0.9796380090497738, best_f1=0.9854096520763187
step: 0, loss: 0.04090535640716553
step: 10, loss: 0.06240084022283554
step: 20, loss: 0.07132039964199066
step: 30, loss: 0.016092535108327866
step: 40, loss: 0.05494481325149536
step: 50, loss: 0.05388540029525757
step: 60, loss: 0.02309117279946804
step: 70, loss: 0.022266030311584473
step: 80, loss: 0.002447995124384761
step: 90, loss: 0.03775455802679062
step: 100, loss: 0.01832224614918232
step: 110, loss: 0.03167763352394104
step: 120, loss: 0.059267058968544006
step: 130, loss: 0.01955345645546913
step: 140, loss: 0.13967590034008026
step: 150, loss: 0.040120337158441544
step: 160, loss: 0.10730461776256561
step: 170, loss: 0.016404304653406143
step: 180, loss: 0.015963470563292503
step: 190, loss: 0.009769964031875134
step: 200, loss: 0.06703048944473267
step: 210, loss: 0.010300354100763798
step: 220, loss: 0.05862154811620712
step: 230, loss: 0.07461461424827576
step: 240, loss: 0.025485899299383163
step: 250, loss: 0.13987544178962708
step: 260, loss: 0.038287486881017685
step: 270, loss: 0.052554771304130554
step: 280, loss: 0.03750726953148842
step: 290, loss: 0.006795246619731188
step: 300, loss: 0.035370949655771255
step: 310, loss: 0.0782005563378334
step: 320, loss: 0.17513784766197205
step: 330, loss: 0.04436265304684639
step: 340, loss: 0.01679600402712822
step: 350, loss: 0.03571144491434097
step: 360, loss: 0.002252522623166442
step: 370, loss: 0.005804631393402815
step: 380, loss: 0.0710703656077385
step: 390, loss: 0.04857886955142021
step: 400, loss: 0.1546158343553543
step: 410, loss: 0.02364535629749298
step: 420, loss: 0.014823457226157188
step: 430, loss: 0.08808620274066925
step: 440, loss: 0.07684789597988129
step: 450, loss: 0.012704845517873764
step: 460, loss: 0.0012857880210503936
epoch 10: dev_f1=0.9910112359550561, f1=0.9854423292273236, best_f1=0.9854096520763187
step: 0, loss: 0.004453020170331001
step: 10, loss: 0.10495660454034805
step: 20, loss: 0.006935307290405035
step: 30, loss: 0.0976821631193161
step: 40, loss: 0.02129470556974411
step: 50, loss: 5.7167253544321284e-05
step: 60, loss: 0.0058359066024422646
step: 70, loss: 0.0467895045876503
step: 80, loss: 0.00027558766305446625
step: 90, loss: 0.008854085579514503
step: 100, loss: 0.002060424070805311
step: 110, loss: 0.008185414597392082
step: 120, loss: 0.04510623589158058
step: 130, loss: 0.009808365255594254
step: 140, loss: 0.08523916453123093
step: 150, loss: 0.06490771472454071
step: 160, loss: 0.017338762059807777
step: 170, loss: 0.019437402486801147
step: 180, loss: 0.06415268778800964
step: 190, loss: 0.02869296632707119
step: 200, loss: 0.0023126881569623947
step: 210, loss: 0.06710381805896759
step: 220, loss: 0.21225178241729736
step: 230, loss: 0.03996286168694496
step: 240, loss: 0.07146313041448593
step: 250, loss: 0.016050618141889572
step: 260, loss: 0.00632820138707757
step: 270, loss: 0.015232847072184086
step: 280, loss: 0.09152640402317047
step: 290, loss: 0.010973821394145489
step: 300, loss: 0.04980394244194031
step: 310, loss: 0.017716074362397194
step: 320, loss: 0.05528533086180687
step: 330, loss: 0.0021033824887126684
step: 340, loss: 0.08719437569379807
step: 350, loss: 0.024558262899518013
step: 360, loss: 0.10889562964439392
step: 370, loss: 0.009390812367200851
step: 380, loss: 0.03896307572722435
step: 390, loss: 0.016136400401592255
step: 400, loss: 0.08884912729263306
step: 410, loss: 0.11558617651462555
step: 420, loss: 0.1695011705160141
step: 430, loss: 0.03363886848092079
step: 440, loss: 0.02163950353860855
step: 450, loss: 0.10689156502485275
step: 460, loss: 0.030109040439128876
epoch 11: dev_f1=0.9932279909706545, f1=0.9797752808988766, best_f1=0.9854096520763187
step: 0, loss: 0.07674971967935562
step: 10, loss: 0.016767706722021103
step: 20, loss: 0.04333188012242317
step: 30, loss: 0.01888166554272175
step: 40, loss: 0.04388682171702385
step: 50, loss: 0.028849003836512566
step: 60, loss: 0.035882119089365005
step: 70, loss: 0.03808550164103508
step: 80, loss: 0.04237296059727669
step: 90, loss: 0.006147232837975025
step: 100, loss: 0.0038374587893486023
step: 110, loss: 0.025786587968468666
step: 120, loss: 0.0007521551451645792
step: 130, loss: 0.1622120887041092
step: 140, loss: 0.0028969189152121544
step: 150, loss: 0.006886541843414307
step: 160, loss: 0.03484277427196503
step: 170, loss: 0.0547972209751606
step: 180, loss: 4.711724250228144e-05
step: 190, loss: 0.04273442178964615
step: 200, loss: 0.0918327271938324
step: 210, loss: 0.11609459668397903
step: 220, loss: 0.046614985913038254
step: 230, loss: 0.05274896323680878
step: 240, loss: 0.0003936460125260055
step: 250, loss: 0.02939043566584587
step: 260, loss: 0.059258248656988144
step: 270, loss: 0.04946579411625862
step: 280, loss: 0.019087418913841248
step: 290, loss: 0.042531322687864304
step: 300, loss: 0.027420062571763992
step: 310, loss: 0.039377063512802124
step: 320, loss: 0.0006641121581196785
step: 330, loss: 0.06891121715307236
step: 340, loss: 0.04145342484116554
step: 350, loss: 0.0037708389572799206
step: 360, loss: 0.043273694813251495
step: 370, loss: 0.00957696046680212
step: 380, loss: 0.003291715867817402
step: 390, loss: 0.023991659283638
step: 400, loss: 0.03349749743938446
step: 410, loss: 0.046598225831985474
step: 420, loss: 0.003302252385765314
step: 430, loss: 0.11340989917516708
step: 440, loss: 0.005990526173263788
step: 450, loss: 0.043841518461704254
step: 460, loss: 0.10060063749551773
epoch 12: dev_f1=0.9932584269662922, f1=0.9843400447427293, best_f1=0.9854096520763187
step: 0, loss: 0.005029414314776659
step: 10, loss: 0.11180239170789719
step: 20, loss: 0.01296757161617279
step: 30, loss: 0.007153498940169811
step: 40, loss: 0.05744548887014389
step: 50, loss: 0.1507144719362259
step: 60, loss: 0.049820803105831146
step: 70, loss: 0.010556080378592014
step: 80, loss: 0.0002011973992921412
step: 90, loss: 0.051095038652420044
step: 100, loss: 0.04579773172736168
step: 110, loss: 0.020325370132923126
step: 120, loss: 0.021378930658102036
step: 130, loss: 0.056011591106653214
step: 140, loss: 0.029967134818434715
step: 150, loss: 0.06207995116710663
step: 160, loss: 4.3314637878211215e-05
step: 170, loss: 0.0015104181366041303
step: 180, loss: 0.02441610023379326
step: 190, loss: 0.025976985692977905
step: 200, loss: 5.249891910352744e-05
step: 210, loss: 0.05152386054396629
step: 220, loss: 0.05559887737035751
step: 230, loss: 0.024234984070062637
step: 240, loss: 0.012603660114109516
step: 250, loss: 0.1543787568807602
step: 260, loss: 0.010425089858472347
step: 270, loss: 0.03667595982551575
step: 280, loss: 0.0007484271773137152
step: 290, loss: 0.026986729353666306
step: 300, loss: 0.11607223749160767
step: 310, loss: 0.04897959902882576
step: 320, loss: 0.07957714796066284
step: 330, loss: 0.09941945225000381
step: 340, loss: 0.061425358057022095
step: 350, loss: 0.04485641419887543
step: 360, loss: 0.02076616883277893
step: 370, loss: 0.013349782675504684
step: 380, loss: 0.0016272834036499262
step: 390, loss: 0.0800958126783371
step: 400, loss: 0.03561769053339958
step: 410, loss: 0.022573083639144897
step: 420, loss: 0.018521331250667572
step: 430, loss: 0.008912044577300549
step: 440, loss: 0.013628870248794556
step: 450, loss: 0.03015909716486931
step: 460, loss: 0.07387427985668182
epoch 13: dev_f1=0.992108229988726, f1=0.9832026875699889, best_f1=0.9854096520763187
step: 0, loss: 0.04223208501935005
step: 10, loss: 0.027024637907743454
step: 20, loss: 0.0058984351344406605
step: 30, loss: 0.02251717448234558
step: 40, loss: 0.0019070289563387632
step: 50, loss: 0.01890549249947071
step: 60, loss: 0.02326052635908127
step: 70, loss: 0.0036958870477974415
step: 80, loss: 0.0006655052420683205
step: 90, loss: 0.061530567705631256
step: 100, loss: 0.020373240113258362
step: 110, loss: 0.02688833512365818
step: 120, loss: 0.04887622222304344
step: 130, loss: 0.017654690891504288
step: 140, loss: 0.046327266842126846
step: 150, loss: 0.043248251080513
step: 160, loss: 0.005858742166310549
step: 170, loss: 0.024616284295916557
step: 180, loss: 0.019104991108179092
step: 190, loss: 0.02371590957045555
step: 200, loss: 0.04180748015642166
step: 210, loss: 0.0898684486746788
step: 220, loss: 0.0306748915463686
step: 230, loss: 0.09793470054864883
step: 240, loss: 0.07673247903585434
step: 250, loss: 0.0375184565782547
step: 260, loss: 0.0009669571882113814
step: 270, loss: 0.0005526767927221954
step: 280, loss: 0.08025247603654861
step: 290, loss: 0.029408369213342667
step: 300, loss: 0.061507269740104675
step: 310, loss: 0.03797431290149689
step: 320, loss: 0.03498585522174835
step: 330, loss: 0.09573644399642944
step: 340, loss: 0.0073601556941866875
step: 350, loss: 0.001744044478982687
step: 360, loss: 0.011779431253671646
step: 370, loss: 0.036639075726270676
step: 380, loss: 0.05330290272831917
step: 390, loss: 0.001526291947811842
step: 400, loss: 0.07403460890054703
step: 410, loss: 0.045267991721630096
step: 420, loss: 0.017644692212343216
step: 430, loss: 2.7342832254362293e-05
step: 440, loss: 0.028935499489307404
step: 450, loss: 0.028991278260946274
step: 460, loss: 0.034099020063877106
epoch 14: dev_f1=0.9932584269662922, f1=0.9854748603351955, best_f1=0.9854096520763187
step: 0, loss: 0.002051399089396
step: 10, loss: 0.05726509913802147
step: 20, loss: 0.0003254948533140123
step: 30, loss: 0.00016934586165007204
step: 40, loss: 0.00016392642282880843
step: 50, loss: 0.00015736099157948047
step: 60, loss: 0.10425019264221191
step: 70, loss: 8.566659380448982e-05
step: 80, loss: 0.00034942905767820776
step: 90, loss: 0.020535636693239212
step: 100, loss: 0.0008537676185369492
step: 110, loss: 0.015387443825602531
step: 120, loss: 0.03433540090918541
step: 130, loss: 0.028646769002079964
step: 140, loss: 0.01749151572585106
step: 150, loss: 0.040087297558784485
step: 160, loss: 0.05172673985362053
step: 170, loss: 0.057764776051044464
step: 180, loss: 0.0005174442194402218
step: 190, loss: 0.07129006087779999
step: 200, loss: 0.03318219259381294
step: 210, loss: 0.00044550985330715775
step: 220, loss: 0.05914461240172386
step: 230, loss: 0.02718217298388481
step: 240, loss: 0.04600925371050835
step: 250, loss: 0.02233203873038292
step: 260, loss: 0.020267847925424576
step: 270, loss: 0.046801432967185974
step: 280, loss: 0.00034002255415543914
step: 290, loss: 0.010946064256131649
step: 300, loss: 0.016734661534428596
step: 310, loss: 0.024216262623667717
step: 320, loss: 0.0003221107181161642
step: 330, loss: 0.042490847408771515
step: 340, loss: 0.01915440522134304
step: 350, loss: 0.04002120718359947
step: 360, loss: 0.026377134025096893
step: 370, loss: 0.0009388080216012895
step: 380, loss: 0.024150405079126358
step: 390, loss: 0.06559748202562332
step: 400, loss: 0.060925811529159546
step: 410, loss: 0.0004243783187121153
step: 420, loss: 0.015797371044754982
step: 430, loss: 0.024485787376761436
step: 440, loss: 0.010174757800996304
step: 450, loss: 0.016842439770698547
step: 460, loss: 0.042514968663454056
epoch 15: dev_f1=0.9932432432432432, f1=0.9831271091113611, best_f1=0.9854096520763187
step: 0, loss: 0.000724152778275311
step: 10, loss: 0.06269186735153198
step: 20, loss: 0.032034050673246384
step: 30, loss: 0.0002657092409208417
step: 40, loss: 0.02434024028480053
step: 50, loss: 0.026393979787826538
step: 60, loss: 0.0205442626029253
step: 70, loss: 0.023349400609731674
step: 80, loss: 0.028028637170791626
step: 90, loss: 0.035156503319740295
step: 100, loss: 0.09947091341018677
step: 110, loss: 0.11705780774354935
step: 120, loss: 0.00014678413572255522
step: 130, loss: 0.0008994779782369733
step: 140, loss: 0.17652668058872223
step: 150, loss: 0.0486447736620903
step: 160, loss: 0.024357561022043228
step: 170, loss: 0.019991369917988777
step: 180, loss: 0.044654589146375656
step: 190, loss: 0.018680913373827934
step: 200, loss: 0.0159610603004694
step: 210, loss: 0.025650111958384514
step: 220, loss: 0.1264432668685913
step: 230, loss: 0.03326002508401871
step: 240, loss: 0.048695627599954605
step: 250, loss: 0.016985362395644188
step: 260, loss: 0.03082055039703846
step: 270, loss: 0.038680557161569595
step: 280, loss: 0.03248975798487663
step: 290, loss: 0.0001604857825441286
step: 300, loss: 0.0013088396517559886
step: 310, loss: 0.024993445724248886
step: 320, loss: 0.02633638307452202
step: 330, loss: 0.0745605081319809
step: 340, loss: 0.09252070635557175
step: 350, loss: 0.06816818565130234
step: 360, loss: 0.016712697222828865
step: 370, loss: 0.023150963708758354
step: 380, loss: 0.07973235845565796
step: 390, loss: 0.04324023425579071
step: 400, loss: 0.01257568784058094
step: 410, loss: 6.136995943961665e-05
step: 420, loss: 0.01895863376557827
step: 430, loss: 0.03868788480758667
step: 440, loss: 0.06744484603404999
step: 450, loss: 0.00355575792491436
step: 460, loss: 0.06089112162590027
epoch 16: dev_f1=0.9932432432432432, f1=0.9842696629213483, best_f1=0.9854096520763187
step: 0, loss: 0.000665311876218766
step: 10, loss: 0.06136249378323555
step: 20, loss: 0.007350530009716749
step: 30, loss: 0.0434131994843483
step: 40, loss: 0.021583721041679382
step: 50, loss: 0.0012990683317184448
step: 60, loss: 0.023494292050600052
step: 70, loss: 0.00034883435000665486
step: 80, loss: 0.05485183000564575
step: 90, loss: 0.0263049453496933
step: 100, loss: 0.05542021244764328
step: 110, loss: 0.022823438048362732
step: 120, loss: 0.019886039197444916
step: 130, loss: 7.387290679616854e-05
step: 140, loss: 9.928872168529779e-05
step: 150, loss: 0.059792499989271164
step: 160, loss: 0.014000636525452137
step: 170, loss: 0.054807595908641815
step: 180, loss: 0.021577097475528717
step: 190, loss: 0.08524160832166672
step: 200, loss: 0.02073359489440918
step: 210, loss: 0.02120935171842575
step: 220, loss: 0.021038146689534187
step: 230, loss: 0.023209847509860992
step: 240, loss: 0.028699751943349838
step: 250, loss: 0.03449113294482231
step: 260, loss: 0.07751359045505524
step: 270, loss: 0.019461840391159058
step: 280, loss: 0.03380538150668144
step: 290, loss: 0.01703319326043129
step: 300, loss: 0.18608759343624115
step: 310, loss: 0.04521776735782623
step: 320, loss: 0.06379882246255875
step: 330, loss: 0.0006699205259792507
step: 340, loss: 0.0003161992644891143
step: 350, loss: 0.06471932679414749
step: 360, loss: 0.027047300711274147
step: 370, loss: 0.04379565641283989
step: 380, loss: 0.04759925603866577
step: 390, loss: 0.0002603491593617946
step: 400, loss: 0.3533722758293152
step: 410, loss: 0.019271409139037132
step: 420, loss: 0.07064460217952728
step: 430, loss: 5.2923456678399816e-05
step: 440, loss: 0.05680369213223457
step: 450, loss: 0.020865527912974358
step: 460, loss: 0.00016891892300918698
epoch 17: dev_f1=0.9943630214205187, f1=0.9819819819819819, best_f1=0.9854096520763187
step: 0, loss: 0.03361016884446144
step: 10, loss: 0.0004603046691045165
step: 20, loss: 0.015233123674988747
step: 30, loss: 0.00042340366053394973
step: 40, loss: 0.04042315483093262
step: 50, loss: 0.02979080006480217
step: 60, loss: 0.00010511969594517723
step: 70, loss: 0.07520385831594467
step: 80, loss: 0.0028839269652962685
step: 90, loss: 0.00011328599066473544
step: 100, loss: 0.01923430897295475
step: 110, loss: 0.039552364498376846
step: 120, loss: 0.021916463971138
step: 130, loss: 6.903053872520104e-05
step: 140, loss: 0.1139129102230072
step: 150, loss: 0.012844075448811054
step: 160, loss: 0.05581831932067871
step: 170, loss: 0.051792699843645096
step: 180, loss: 0.00017081854457501322
step: 190, loss: 0.041055213660001755
step: 200, loss: 0.019749648869037628
step: 210, loss: 5.8792058553081006e-05
step: 220, loss: 0.018023831769824028
step: 230, loss: 0.04571197181940079
step: 240, loss: 0.00013117253547534347
step: 250, loss: 0.01831524632871151
step: 260, loss: 5.895107824471779e-05
step: 270, loss: 0.018512846902012825
step: 280, loss: 0.0745195671916008
step: 290, loss: 0.0909278392791748
step: 300, loss: 0.0512111522257328
step: 310, loss: 0.01160199660807848
step: 320, loss: 0.04298102483153343
step: 330, loss: 0.017882823944091797
step: 340, loss: 0.023579394444823265
step: 350, loss: 0.0019663870334625244
step: 360, loss: 0.01960058882832527
step: 370, loss: 0.03098818100988865
step: 380, loss: 0.02994374744594097
step: 390, loss: 0.012914732098579407
step: 400, loss: 0.019623087719082832
step: 410, loss: 5.64367655897513e-05
step: 420, loss: 0.011743076145648956
step: 430, loss: 0.025890523567795753
step: 440, loss: 0.06452473998069763
step: 450, loss: 0.02692471817135811
step: 460, loss: 0.0011346074752509594
epoch 18: dev_f1=0.9943630214205187, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 2.663123086676933e-05
step: 10, loss: 0.0003919042646884918
step: 20, loss: 0.042441368103027344
step: 30, loss: 0.0397329144179821
step: 40, loss: 0.019048040732741356
step: 50, loss: 6.912639219081029e-05
step: 60, loss: 6.627692346228287e-05
step: 70, loss: 6.995426520006731e-05
step: 80, loss: 0.0221833735704422
step: 90, loss: 0.043659910559654236
step: 100, loss: 0.00014178651326801628
step: 110, loss: 2.371835034864489e-05
step: 120, loss: 0.03307754546403885
step: 130, loss: 0.03494938462972641
step: 140, loss: 0.04412880167365074
step: 150, loss: 2.419489828753285e-05
step: 160, loss: 2.3066122594173066e-05
step: 170, loss: 8.070896001299843e-05
step: 180, loss: 0.04978886619210243
step: 190, loss: 0.01675448939204216
step: 200, loss: 0.04981201887130737
step: 210, loss: 0.02176075428724289
step: 220, loss: 0.025663146749138832
step: 230, loss: 7.255662785610184e-05
step: 240, loss: 3.6993984394939616e-05
step: 250, loss: 0.02640695497393608
step: 260, loss: 0.04706183820962906
step: 270, loss: 0.01573149301111698
step: 280, loss: 0.040436916053295135
step: 290, loss: 0.05410465598106384
step: 300, loss: 0.05701656639575958
step: 310, loss: 0.024021916091442108
step: 320, loss: 4.26359947596211e-05
step: 330, loss: 3.786906017921865e-05
step: 340, loss: 3.134644794045016e-05
step: 350, loss: 0.02128482051193714
step: 360, loss: 2.929041329480242e-05
step: 370, loss: 0.024058809503912926
step: 380, loss: 0.01820513792335987
step: 390, loss: 0.048107828944921494
step: 400, loss: 0.025410696864128113
step: 410, loss: 0.03831953927874565
step: 420, loss: 0.017331890761852264
step: 430, loss: 0.01662689633667469
step: 440, loss: 0.03179130330681801
step: 450, loss: 0.021865015849471092
step: 460, loss: 4.726103725261055e-05
epoch 19: dev_f1=0.9943630214205187, f1=0.9842696629213483, best_f1=0.9854096520763187
step: 0, loss: 0.020439021289348602
step: 10, loss: 0.05971546471118927
step: 20, loss: 0.11913371831178665
step: 30, loss: 0.01908949948847294
step: 40, loss: 0.02551177144050598
step: 50, loss: 0.022695954889059067
step: 60, loss: 0.019578153267502785
step: 70, loss: 5.64338915864937e-05
step: 80, loss: 0.016758114099502563
step: 90, loss: 0.03619823232293129
step: 100, loss: 5.898217932553962e-05
step: 110, loss: 0.06917832046747208
step: 120, loss: 0.04652095586061478
step: 130, loss: 0.01984112150967121
step: 140, loss: 0.00014621390437241644
step: 150, loss: 0.05685114860534668
step: 160, loss: 4.916288162348792e-05
step: 170, loss: 0.03697770833969116
step: 180, loss: 0.025316543877124786
step: 190, loss: 0.0409652441740036
step: 200, loss: 0.021933725103735924
step: 210, loss: 0.023430153727531433
step: 220, loss: 0.020346034318208694
step: 230, loss: 0.062502920627594
step: 240, loss: 4.559773515211418e-05
step: 250, loss: 0.05978866294026375
step: 260, loss: 0.03493465483188629
step: 270, loss: 0.00016566968406550586
step: 280, loss: 0.019196541979908943
step: 290, loss: 0.06658125668764114
step: 300, loss: 2.7260570277576335e-05
step: 310, loss: 0.10305149108171463
step: 320, loss: 0.019724689424037933
step: 330, loss: 8.05764357210137e-05
step: 340, loss: 0.020940694957971573
step: 350, loss: 0.0003437630948610604
step: 360, loss: 0.07617355138063431
step: 370, loss: 0.020986612886190414
step: 380, loss: 0.019535163417458534
step: 390, loss: 0.00018148285744246095
step: 400, loss: 0.00012147489178460091
step: 410, loss: 0.04433005675673485
step: 420, loss: 0.04876122996211052
step: 430, loss: 0.04772266745567322
step: 440, loss: 4.629017348634079e-05
step: 450, loss: 0.02291475050151348
step: 460, loss: 0.0512925460934639
epoch 20: dev_f1=0.9943630214205187, f1=0.9842696629213483, best_f1=0.9854096520763187
