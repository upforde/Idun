cuda
Device: cuda
step: 0, loss: 0.6529732346534729
step: 10, loss: 0.37712833285331726
step: 20, loss: 0.4911675751209259
step: 30, loss: 0.34616324305534363
step: 40, loss: 0.21616016328334808
step: 50, loss: 0.26476380228996277
step: 60, loss: 0.2195969969034195
step: 70, loss: 0.055333446711301804
step: 80, loss: 0.2950604259967804
step: 90, loss: 0.07333728671073914
step: 100, loss: 0.1654241979122162
step: 110, loss: 0.12800230085849762
step: 120, loss: 0.2152228057384491
step: 130, loss: 0.059365153312683105
step: 140, loss: 0.10177169740200043
step: 150, loss: 0.33443498611450195
step: 160, loss: 0.19162572920322418
step: 170, loss: 0.0196981243789196
step: 180, loss: 0.13620837032794952
step: 190, loss: 0.1578749269247055
step: 200, loss: 0.1590976119041443
step: 210, loss: 0.16193118691444397
step: 220, loss: 0.1512387990951538
step: 230, loss: 0.21509180963039398
step: 240, loss: 0.09400232136249542
step: 250, loss: 0.15424935519695282
step: 260, loss: 0.08426827937364578
step: 270, loss: 0.04239232838153839
step: 280, loss: 0.14544987678527832
step: 290, loss: 0.0768243670463562
step: 300, loss: 0.14135119318962097
step: 310, loss: 0.01369512639939785
step: 320, loss: 0.009012144058942795
step: 330, loss: 0.11982529610395432
step: 340, loss: 0.058540910482406616
step: 350, loss: 0.09382379800081253
step: 360, loss: 0.08290452510118484
step: 370, loss: 0.04173196107149124
step: 380, loss: 0.26543164253234863
step: 390, loss: 0.025083210319280624
step: 400, loss: 0.0691930279135704
step: 410, loss: 0.07178425788879395
step: 420, loss: 0.13656412065029144
step: 430, loss: 0.08346249908208847
step: 440, loss: 0.07499416917562485
step: 450, loss: 0.06335719674825668
step: 460, loss: 0.05474097654223442
epoch 1: dev_f1=0.9821428571428571, f1=0.9787234042553192, best_f1=0.9787234042553192
step: 0, loss: 0.0249997079372406
step: 10, loss: 0.0753512904047966
step: 20, loss: 0.018084492534399033
step: 30, loss: 0.08404991775751114
step: 40, loss: 0.14208956062793732
step: 50, loss: 0.13461941480636597
step: 60, loss: 0.07655361294746399
step: 70, loss: 0.018078286200761795
step: 80, loss: 0.023107949644327164
step: 90, loss: 0.09229853749275208
step: 100, loss: 0.0075475606136024
step: 110, loss: 0.013949410058557987
step: 120, loss: 0.058309752494096756
step: 130, loss: 0.1279548555612564
step: 140, loss: 0.03796409070491791
step: 150, loss: 0.044128336012363434
step: 160, loss: 0.08994545787572861
step: 170, loss: 0.07014166563749313
step: 180, loss: 0.061123479157686234
step: 190, loss: 0.07811003923416138
step: 200, loss: 0.03233855217695236
step: 210, loss: 0.021146435290575027
step: 220, loss: 0.14004071056842804
step: 230, loss: 0.07390477508306503
step: 240, loss: 0.07985436171293259
step: 250, loss: 0.10591291636228561
step: 260, loss: 0.15781955420970917
step: 270, loss: 0.08413437753915787
step: 280, loss: 0.14201517403125763
step: 290, loss: 0.026878824457526207
step: 300, loss: 0.013187471777200699
step: 310, loss: 0.022760402411222458
step: 320, loss: 0.14096957445144653
step: 330, loss: 0.22835640609264374
step: 340, loss: 0.04470844566822052
step: 350, loss: 0.16609272360801697
step: 360, loss: 0.11576531082391739
step: 370, loss: 0.1205216497182846
step: 380, loss: 0.02780025452375412
step: 390, loss: 0.021698856726288795
step: 400, loss: 0.04942420497536659
step: 410, loss: 0.12472574412822723
step: 420, loss: 0.012155486270785332
step: 430, loss: 0.04189109802246094
step: 440, loss: 0.10572333633899689
step: 450, loss: 0.1215076670050621
step: 460, loss: 0.04097419232130051
epoch 2: dev_f1=0.9898989898989898, f1=0.9875706214689265, best_f1=0.9875706214689265
step: 0, loss: 0.11435504257678986
step: 10, loss: 0.015807390213012695
step: 20, loss: 0.008874289691448212
step: 30, loss: 0.04390322044491768
step: 40, loss: 0.08064142614603043
step: 50, loss: 0.024293653666973114
step: 60, loss: 0.003900607582181692
step: 70, loss: 0.05842132866382599
step: 80, loss: 0.00010514487803447992
step: 90, loss: 0.16503076255321503
step: 100, loss: 0.000712358858436346
step: 110, loss: 0.08316729962825775
step: 120, loss: 0.08174824714660645
step: 130, loss: 0.1407201588153839
step: 140, loss: 0.06517978757619858
step: 150, loss: 0.0767643004655838
step: 160, loss: 0.07361195981502533
step: 170, loss: 0.10859192907810211
step: 180, loss: 0.07028769701719284
step: 190, loss: 0.012194344773888588
step: 200, loss: 0.06361105293035507
step: 210, loss: 0.007728234399110079
step: 220, loss: 0.029823461547493935
step: 230, loss: 0.05555855482816696
step: 240, loss: 0.08074731379747391
step: 250, loss: 0.010781246237456799
step: 260, loss: 0.07193517684936523
step: 270, loss: 0.07185906171798706
step: 280, loss: 0.021596388891339302
step: 290, loss: 0.019234618172049522
step: 300, loss: 0.006869301665574312
step: 310, loss: 0.09197790175676346
step: 320, loss: 0.08903180807828903
step: 330, loss: 0.015978824347257614
step: 340, loss: 0.08428908884525299
step: 350, loss: 0.01719171181321144
step: 360, loss: 0.03553008288145065
step: 370, loss: 0.06441004574298859
step: 380, loss: 0.018951330333948135
step: 390, loss: 0.014318064786493778
step: 400, loss: 0.02045908197760582
step: 410, loss: 0.02723950892686844
step: 420, loss: 0.0652383342385292
step: 430, loss: 0.019514093175530434
step: 440, loss: 0.022020818665623665
step: 450, loss: 0.0681006982922554
step: 460, loss: 0.005356273148208857
epoch 3: dev_f1=0.9854096520763187, f1=0.9773755656108598, best_f1=0.9875706214689265
step: 0, loss: 0.015933336690068245
step: 10, loss: 0.02590721845626831
step: 20, loss: 0.010788531973958015
step: 30, loss: 0.029252005741000175
step: 40, loss: 0.028178203850984573
step: 50, loss: 0.12186665087938309
step: 60, loss: 0.026056211441755295
step: 70, loss: 0.0712316632270813
step: 80, loss: 0.0077541302889585495
step: 90, loss: 0.016752103343605995
step: 100, loss: 0.0029880155343562365
step: 110, loss: 0.03710760548710823
step: 120, loss: 0.1161571815609932
step: 130, loss: 0.026444680988788605
step: 140, loss: 0.016988927498459816
step: 150, loss: 0.02041609026491642
step: 160, loss: 0.018279792740941048
step: 170, loss: 0.08328323811292648
step: 180, loss: 0.10778909921646118
step: 190, loss: 0.026182476431131363
step: 200, loss: 0.0722455158829689
step: 210, loss: 0.03244117274880409
step: 220, loss: 0.11825169622898102
step: 230, loss: 0.015297377482056618
step: 240, loss: 0.13193070888519287
step: 250, loss: 0.03970509395003319
step: 260, loss: 0.009746170602738857
step: 270, loss: 0.0675174817442894
step: 280, loss: 0.017670517787337303
step: 290, loss: 0.006020319648087025
step: 300, loss: 0.07362531870603561
step: 310, loss: 0.08050210773944855
step: 320, loss: 0.09521806240081787
step: 330, loss: 0.0185678843408823
step: 340, loss: 0.07493529468774796
step: 350, loss: 0.07697359472513199
step: 360, loss: 0.012337351217865944
step: 370, loss: 0.10129643231630325
step: 380, loss: 0.016561567783355713
step: 390, loss: 0.12969258427619934
step: 400, loss: 0.05057275667786598
step: 410, loss: 0.16395898163318634
step: 420, loss: 0.09683778882026672
step: 430, loss: 0.01667662337422371
step: 440, loss: 0.07444991916418076
step: 450, loss: 0.019160909578204155
step: 460, loss: 0.003605782287195325
epoch 4: dev_f1=0.990990990990991, f1=0.9864253393665158, best_f1=0.9864253393665158
step: 0, loss: 0.0031550677958875895
step: 10, loss: 0.017674509435892105
step: 20, loss: 0.0831395611166954
step: 30, loss: 0.010043196380138397
step: 40, loss: 0.04006272554397583
step: 50, loss: 0.01342535950243473
step: 60, loss: 0.24968332052230835
step: 70, loss: 0.01191567350178957
step: 80, loss: 0.07465917617082596
step: 90, loss: 0.003860658733174205
step: 100, loss: 0.007394519634544849
step: 110, loss: 0.0582030788064003
step: 120, loss: 0.02568255178630352
step: 130, loss: 0.08323020488023758
step: 140, loss: 0.002729374449700117
step: 150, loss: 0.14381730556488037
step: 160, loss: 0.06753621995449066
step: 170, loss: 0.021833263337612152
step: 180, loss: 0.02239040657877922
step: 190, loss: 0.20553162693977356
step: 200, loss: 0.08641577512025833
step: 210, loss: 0.1342986822128296
step: 220, loss: 0.10628213733434677
step: 230, loss: 0.03570621460676193
step: 240, loss: 0.07230918854475021
step: 250, loss: 0.12474599480628967
step: 260, loss: 0.06701920926570892
step: 270, loss: 0.1758524626493454
step: 280, loss: 0.13461773097515106
step: 290, loss: 0.07962501794099808
step: 300, loss: 0.08424514532089233
step: 310, loss: 0.06899359077215195
step: 320, loss: 0.015114936046302319
step: 330, loss: 0.07101644575595856
step: 340, loss: 0.005547565873712301
step: 350, loss: 0.022606657817959785
step: 360, loss: 0.005433814134448767
step: 370, loss: 0.030337681993842125
step: 380, loss: 0.15550152957439423
step: 390, loss: 0.023615440353751183
step: 400, loss: 0.027390379458665848
step: 410, loss: 0.08183515816926956
step: 420, loss: 0.013073911890387535
step: 430, loss: 0.00044258739217184484
step: 440, loss: 0.07080793380737305
step: 450, loss: 0.014246542938053608
step: 460, loss: 0.17715828120708466
epoch 5: dev_f1=0.9943630214205187, f1=0.979591836734694, best_f1=0.979591836734694
step: 0, loss: 0.10821320116519928
step: 10, loss: 0.03245941549539566
step: 20, loss: 0.011210683733224869
step: 30, loss: 0.029759544879198074
step: 40, loss: 0.05270697921514511
step: 50, loss: 0.06612494587898254
step: 60, loss: 0.039442334324121475
step: 70, loss: 0.020877370610833168
step: 80, loss: 0.0071495091542601585
step: 90, loss: 0.0069516804069280624
step: 100, loss: 0.009226365014910698
step: 110, loss: 0.11470308154821396
step: 120, loss: 0.008534987457096577
step: 130, loss: 0.03753359243273735
step: 140, loss: 0.020767943933606148
step: 150, loss: 0.028235813602805138
step: 160, loss: 0.04070676490664482
step: 170, loss: 0.0020601372234523296
step: 180, loss: 0.06370454281568527
step: 190, loss: 0.01959153637290001
step: 200, loss: 0.125117689371109
step: 210, loss: 0.013342097401618958
step: 220, loss: 0.12296334654092789
step: 230, loss: 0.034017372876405716
step: 240, loss: 0.016098812222480774
step: 250, loss: 0.022280670702457428
step: 260, loss: 0.012324517592787743
step: 270, loss: 0.10273978859186172
step: 280, loss: 0.009524906054139137
step: 290, loss: 0.061216842383146286
step: 300, loss: 0.104648157954216
step: 310, loss: 0.06172739714384079
step: 320, loss: 0.03736936300992966
step: 330, loss: 0.02521950751543045
step: 340, loss: 0.13412228226661682
step: 350, loss: 0.006658507511019707
step: 360, loss: 0.008125360123813152
step: 370, loss: 0.04087406024336815
step: 380, loss: 0.0053815217688679695
step: 390, loss: 0.026458414271473885
step: 400, loss: 0.035427745431661606
step: 410, loss: 0.07235617190599442
step: 420, loss: 0.010018093511462212
step: 430, loss: 0.005700067151337862
step: 440, loss: 0.008599534630775452
step: 450, loss: 0.07372251898050308
step: 460, loss: 0.0061130584217607975
epoch 6: dev_f1=0.9932584269662922, f1=0.9842696629213483, best_f1=0.979591836734694
step: 0, loss: 0.054801665246486664
step: 10, loss: 0.008333569392561913
step: 20, loss: 0.08855369687080383
step: 30, loss: 0.10219080746173859
step: 40, loss: 0.1266976147890091
step: 50, loss: 0.08243122696876526
step: 60, loss: 0.010754560120403767
step: 70, loss: 0.06509179621934891
step: 80, loss: 0.0195677038282156
step: 90, loss: 0.08784320205450058
step: 100, loss: 0.020056724548339844
step: 110, loss: 0.03818837180733681
step: 120, loss: 0.014143767766654491
step: 130, loss: 0.02268698625266552
step: 140, loss: 0.08497058600187302
step: 150, loss: 0.11273939162492752
step: 160, loss: 0.13690367341041565
step: 170, loss: 0.022258160635828972
step: 180, loss: 0.06752171367406845
step: 190, loss: 0.06287962198257446
step: 200, loss: 0.016686098650097847
step: 210, loss: 0.06206566467881203
step: 220, loss: 0.10287553817033768
step: 230, loss: 0.019301360473036766
step: 240, loss: 0.03833668306469917
step: 250, loss: 0.137351855635643
step: 260, loss: 0.009798510000109673
step: 270, loss: 0.0038344443310052156
step: 280, loss: 0.06897047907114029
step: 290, loss: 0.02777010202407837
step: 300, loss: 0.004683862440288067
step: 310, loss: 0.07522987574338913
step: 320, loss: 0.0008275543805211782
step: 330, loss: 0.017696363851428032
step: 340, loss: 0.03137585520744324
step: 350, loss: 0.021765103563666344
step: 360, loss: 0.02295679785311222
step: 370, loss: 0.057809729129076004
step: 380, loss: 0.08110050112009048
step: 390, loss: 0.09110481292009354
step: 400, loss: 0.005107424687594175
step: 410, loss: 0.009580765850841999
step: 420, loss: 0.002364066196605563
step: 430, loss: 0.006157438270747662
step: 440, loss: 0.04023405537009239
step: 450, loss: 0.03397354856133461
step: 460, loss: 0.014985966496169567
epoch 7: dev_f1=0.9932584269662922, f1=0.9854423292273236, best_f1=0.979591836734694
step: 0, loss: 0.010016357526183128
step: 10, loss: 0.002633309457451105
step: 20, loss: 0.013516904786229134
step: 30, loss: 0.07724547386169434
step: 40, loss: 0.01585010252892971
step: 50, loss: 0.1890900582075119
step: 60, loss: 0.09149608761072159
step: 70, loss: 0.013276876881718636
step: 80, loss: 0.005343496799468994
step: 90, loss: 0.012522183358669281
step: 100, loss: 0.07308147847652435
step: 110, loss: 0.01962663233280182
step: 120, loss: 0.02291855961084366
step: 130, loss: 0.03231581300497055
step: 140, loss: 0.04589328169822693
step: 150, loss: 0.04167994484305382
step: 160, loss: 0.05563732609152794
step: 170, loss: 0.00932465773075819
step: 180, loss: 0.012375565245747566
step: 190, loss: 0.07758695632219315
step: 200, loss: 0.009119894355535507
step: 210, loss: 0.0010030223056674004
step: 220, loss: 0.007762379944324493
step: 230, loss: 0.003643000964075327
step: 240, loss: 0.018438130617141724
step: 250, loss: 0.05994436517357826
step: 260, loss: 0.10574322938919067
step: 270, loss: 0.028761958703398705
step: 280, loss: 0.02879766933619976
step: 290, loss: 0.09690988063812256
step: 300, loss: 0.0013626995496451855
step: 310, loss: 0.05405902490019798
step: 320, loss: 0.05369272083044052
step: 330, loss: 0.20006702840328217
step: 340, loss: 0.019639529287815094
step: 350, loss: 0.03258011117577553
step: 360, loss: 0.0042644101195037365
step: 370, loss: 0.042230866849422455
step: 380, loss: 0.0634479895234108
step: 390, loss: 0.012030004523694515
step: 400, loss: 0.0123664028942585
step: 410, loss: 0.020222699269652367
step: 420, loss: 0.23114709556102753
step: 430, loss: 0.04390905052423477
step: 440, loss: 0.036987073719501495
step: 450, loss: 0.03417246416211128
step: 460, loss: 0.04576406255364418
epoch 8: dev_f1=0.9921436588103255, f1=0.9831271091113611, best_f1=0.979591836734694
step: 0, loss: 0.010715952143073082
step: 10, loss: 0.021322501823306084
step: 20, loss: 0.0056851692497730255
step: 30, loss: 0.001648779259994626
step: 40, loss: 0.013901631347835064
step: 50, loss: 0.012160319834947586
step: 60, loss: 0.002442719181999564
step: 70, loss: 0.015621587634086609
step: 80, loss: 0.16828039288520813
step: 90, loss: 0.016090601682662964
step: 100, loss: 0.07050010561943054
step: 110, loss: 0.04246421158313751
step: 120, loss: 0.02933599427342415
step: 130, loss: 0.085598424077034
step: 140, loss: 0.08969692885875702
step: 150, loss: 0.017449500039219856
step: 160, loss: 0.036693185567855835
step: 170, loss: 0.012921711429953575
step: 180, loss: 0.06330730766057968
step: 190, loss: 0.03322272375226021
step: 200, loss: 0.01702069118618965
step: 210, loss: 0.009640798904001713
step: 220, loss: 0.004181186202913523
step: 230, loss: 0.006787578575313091
step: 240, loss: 0.036122843623161316
step: 250, loss: 0.12879008054733276
step: 260, loss: 0.007242877036333084
step: 270, loss: 0.04516081511974335
step: 280, loss: 0.03301834315061569
step: 290, loss: 0.024278033524751663
step: 300, loss: 0.09696930646896362
step: 310, loss: 0.045795295387506485
step: 320, loss: 0.017191141843795776
step: 330, loss: 0.12418531626462936
step: 340, loss: 0.15614615380764008
step: 350, loss: 0.06975281238555908
step: 360, loss: 0.09665852040052414
step: 370, loss: 0.03882542997598648
step: 380, loss: 0.03331824019551277
step: 390, loss: 0.015311701223254204
step: 400, loss: 0.004673183895647526
step: 410, loss: 0.08288831263780594
step: 420, loss: 0.01039888709783554
step: 430, loss: 0.006408682558685541
step: 440, loss: 0.024228766560554504
step: 450, loss: 0.01577727310359478
step: 460, loss: 0.007571435067802668
epoch 9: dev_f1=0.9943630214205187, f1=0.9853107344632768, best_f1=0.979591836734694
step: 0, loss: 0.003628180595114827
step: 10, loss: 0.04217764362692833
step: 20, loss: 0.016857927665114403
step: 30, loss: 0.05681870877742767
step: 40, loss: 0.011598474346101284
step: 50, loss: 0.05136943608522415
step: 60, loss: 0.02432621270418167
step: 70, loss: 0.019882772117853165
step: 80, loss: 0.013664986938238144
step: 90, loss: 0.018940307199954987
step: 100, loss: 0.020242419093847275
step: 110, loss: 0.00013686474994756281
step: 120, loss: 0.12930797040462494
step: 130, loss: 0.008960220962762833
step: 140, loss: 0.031109165400266647
step: 150, loss: 0.039354562759399414
step: 160, loss: 0.000284102454315871
step: 170, loss: 0.009769890457391739
step: 180, loss: 0.019747665151953697
step: 190, loss: 0.08602051436901093
step: 200, loss: 0.00014110059419181198
step: 210, loss: 0.227772057056427
step: 220, loss: 0.03658643737435341
step: 230, loss: 0.03576689586043358
step: 240, loss: 0.07271616160869598
step: 250, loss: 0.08365469425916672
step: 260, loss: 0.012948977760970592
step: 270, loss: 0.01769036427140236
step: 280, loss: 0.08097576349973679
step: 290, loss: 0.032480478286743164
step: 300, loss: 0.19170236587524414
step: 310, loss: 0.041819557547569275
step: 320, loss: 0.07297239452600479
step: 330, loss: 0.013987204059958458
step: 340, loss: 0.06071702018380165
step: 350, loss: 0.021029600873589516
step: 360, loss: 0.0444292277097702
step: 370, loss: 0.028234325349330902
step: 380, loss: 0.07317206263542175
step: 390, loss: 0.0637781172990799
step: 400, loss: 0.0395125150680542
step: 410, loss: 0.0626029372215271
step: 420, loss: 0.0017432243330404162
step: 430, loss: 0.058500610291957855
step: 440, loss: 0.07001607865095139
step: 450, loss: 0.0031235183123499155
step: 460, loss: 0.029590874910354614
epoch 10: dev_f1=0.9943757030371203, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.01766674779355526
step: 10, loss: 0.021424373611807823
step: 20, loss: 0.0030609096866101027
step: 30, loss: 0.000944568426348269
step: 40, loss: 0.040315721184015274
step: 50, loss: 3.263249163865112e-05
step: 60, loss: 0.062259968370199203
step: 70, loss: 0.010356887243688107
step: 80, loss: 0.02237934060394764
step: 90, loss: 0.06224622204899788
step: 100, loss: 0.019661081954836845
step: 110, loss: 0.03370077162981033
step: 120, loss: 0.10398073494434357
step: 130, loss: 0.02941228821873665
step: 140, loss: 0.00013728562043979764
step: 150, loss: 0.0007991362363100052
step: 160, loss: 0.03873290494084358
step: 170, loss: 0.054747793823480606
step: 180, loss: 0.016213437542319298
step: 190, loss: 0.0024332667235285044
step: 200, loss: 0.023319700732827187
step: 210, loss: 0.00866784155368805
step: 220, loss: 0.11872520297765732
step: 230, loss: 0.0010717482073232532
step: 240, loss: 0.06761317700147629
step: 250, loss: 0.08441895991563797
step: 260, loss: 0.001714549376629293
step: 270, loss: 0.021211575716733932
step: 280, loss: 0.05836945027112961
step: 290, loss: 0.05379169061779976
step: 300, loss: 0.0415315181016922
step: 310, loss: 0.03877345845103264
step: 320, loss: 3.1581937946612015e-05
step: 330, loss: 0.05403341352939606
step: 340, loss: 0.02973155863583088
step: 350, loss: 0.007919210940599442
step: 360, loss: 0.006357535254210234
step: 370, loss: 0.020205164328217506
step: 380, loss: 0.01607295125722885
step: 390, loss: 0.016445057466626167
step: 400, loss: 0.02841039001941681
step: 410, loss: 0.029412852600216866
step: 420, loss: 0.09800887852907181
step: 430, loss: 0.011477512307465076
step: 440, loss: 0.0747227892279625
step: 450, loss: 0.022650906816124916
step: 460, loss: 0.003670554840937257
epoch 11: dev_f1=0.9932279909706545, f1=0.9864559819413092, best_f1=0.9831271091113611
step: 0, loss: 0.025760529562830925
step: 10, loss: 0.016528749838471413
step: 20, loss: 0.02451319806277752
step: 30, loss: 0.058839209377765656
step: 40, loss: 0.04705613851547241
step: 50, loss: 0.020504215732216835
step: 60, loss: 0.002066979417577386
step: 70, loss: 0.0078660249710083
step: 80, loss: 0.000310512725263834
step: 90, loss: 0.0038594696670770645
step: 100, loss: 0.07927829027175903
step: 110, loss: 0.00409556832164526
step: 120, loss: 0.03311983868479729
step: 130, loss: 0.03541398420929909
step: 140, loss: 0.02349395863711834
step: 150, loss: 0.0272722989320755
step: 160, loss: 0.0015958877047523856
step: 170, loss: 0.0843365266919136
step: 180, loss: 0.0006575683946721256
step: 190, loss: 0.02548796311020851
step: 200, loss: 0.04270518571138382
step: 210, loss: 0.011077294126152992
step: 220, loss: 0.0007259050034917891
step: 230, loss: 0.06797396391630173
step: 240, loss: 0.05208459123969078
step: 250, loss: 0.00019115312898065895
step: 260, loss: 0.0006397562101483345
step: 270, loss: 0.040277399122714996
step: 280, loss: 0.00418331241235137
step: 290, loss: 0.1377212256193161
step: 300, loss: 0.07565951347351074
step: 310, loss: 0.025718528777360916
step: 320, loss: 0.003340974450111389
step: 330, loss: 0.14763540029525757
step: 340, loss: 3.766376175917685e-05
step: 350, loss: 0.004974855575710535
step: 360, loss: 0.020454857498407364
step: 370, loss: 0.02626177668571472
step: 380, loss: 0.02617393434047699
step: 390, loss: 0.0038419573102146387
step: 400, loss: 0.07218599319458008
step: 410, loss: 0.082601398229599
step: 420, loss: 0.08409562706947327
step: 430, loss: 2.3721055185887963e-05
step: 440, loss: 0.050193727016448975
step: 450, loss: 0.03902886062860489
step: 460, loss: 0.07840980589389801
epoch 12: dev_f1=0.9921436588103255, f1=0.9820627802690582, best_f1=0.9831271091113611
step: 0, loss: 0.024482998996973038
step: 10, loss: 0.00060088443569839
step: 20, loss: 0.0017592051299288869
step: 30, loss: 0.012336074374616146
step: 40, loss: 0.12405838817358017
step: 50, loss: 9.013602539198473e-05
step: 60, loss: 0.004693102557212114
step: 70, loss: 0.022015202790498734
step: 80, loss: 0.016427477821707726
step: 90, loss: 0.03852606564760208
step: 100, loss: 0.016147572547197342
step: 110, loss: 0.0005497555830515921
step: 120, loss: 0.03093927912414074
step: 130, loss: 0.03723401576280594
step: 140, loss: 0.10873435437679291
step: 150, loss: 0.003076524008065462
step: 160, loss: 0.017194334417581558
step: 170, loss: 0.03784747049212456
step: 180, loss: 0.04417111724615097
step: 190, loss: 0.01704130694270134
step: 200, loss: 0.009282336570322514
step: 210, loss: 0.026591315865516663
step: 220, loss: 0.04440520703792572
step: 230, loss: 0.03229000046849251
step: 240, loss: 0.06932038068771362
step: 250, loss: 0.030977608636021614
step: 260, loss: 0.017173731699585915
step: 270, loss: 0.024426132440567017
step: 280, loss: 0.022419145330786705
step: 290, loss: 0.03479207307100296
step: 300, loss: 0.0426797941327095
step: 310, loss: 0.04323061928153038
step: 320, loss: 0.026640499010682106
step: 330, loss: 0.0001817833399400115
step: 340, loss: 0.036143284291028976
step: 350, loss: 0.0006320964312180877
step: 360, loss: 0.01785389706492424
step: 370, loss: 0.022082878276705742
step: 380, loss: 0.04061396047472954
step: 390, loss: 0.0006300834938883781
step: 400, loss: 0.0007460165652446449
step: 410, loss: 0.07398094236850739
step: 420, loss: 0.021402452141046524
step: 430, loss: 0.0035483194515109062
step: 440, loss: 0.04878722503781319
step: 450, loss: 0.0012820225674659014
step: 460, loss: 0.022940903902053833
epoch 13: dev_f1=0.9921259842519685, f1=0.9819819819819819, best_f1=0.9831271091113611
step: 0, loss: 0.020336881279945374
step: 10, loss: 0.023982150480151176
step: 20, loss: 0.04726077616214752
step: 30, loss: 0.07597878575325012
step: 40, loss: 0.006087359972298145
step: 50, loss: 0.00100126420147717
step: 60, loss: 0.0014285682700574398
step: 70, loss: 0.0029349466785788536
step: 80, loss: 0.0018486258340999484
step: 90, loss: 0.024166377261281013
step: 100, loss: 0.03408731520175934
step: 110, loss: 0.055044032633304596
step: 120, loss: 0.022982317954301834
step: 130, loss: 0.02172957919538021
step: 140, loss: 0.050281114876270294
step: 150, loss: 0.0012188893742859364
step: 160, loss: 0.16064409911632538
step: 170, loss: 0.05996401235461235
step: 180, loss: 0.00219164346344769
step: 190, loss: 0.00017945434956345707
step: 200, loss: 0.0389290489256382
step: 210, loss: 0.022698068991303444
step: 220, loss: 0.016731295734643936
step: 230, loss: 0.02265906147658825
step: 240, loss: 0.06436222791671753
step: 250, loss: 0.00017654856492299587
step: 260, loss: 0.03973410651087761
step: 270, loss: 0.02809424139559269
step: 280, loss: 0.00024402917188126594
step: 290, loss: 0.002315550809726119
step: 300, loss: 0.0004580049717333168
step: 310, loss: 0.0033455826342105865
step: 320, loss: 0.02249632589519024
step: 330, loss: 0.00036713393637910485
step: 340, loss: 0.0008889276068657637
step: 350, loss: 0.0006529122474603355
step: 360, loss: 0.00031697185477241874
step: 370, loss: 0.026978176087141037
step: 380, loss: 0.04174458608031273
step: 390, loss: 0.0020760842598974705
step: 400, loss: 0.03561357408761978
step: 410, loss: 0.07051930576562881
step: 420, loss: 0.02443160116672516
step: 430, loss: 0.03964109346270561
step: 440, loss: 0.002574986545369029
step: 450, loss: 0.02363462559878826
step: 460, loss: 0.0015919373836368322
epoch 14: dev_f1=0.9932735426008968, f1=0.9833147942157954, best_f1=0.9831271091113611
step: 0, loss: 0.021869434043765068
step: 10, loss: 3.600132913561538e-05
step: 20, loss: 0.06179172173142433
step: 30, loss: 0.02335929125547409
step: 40, loss: 0.013948267325758934
step: 50, loss: 0.0001442389766452834
step: 60, loss: 0.05071301385760307
step: 70, loss: 0.02571655996143818
step: 80, loss: 0.020855946466326714
step: 90, loss: 1.6309099009959027e-05
step: 100, loss: 4.319539948482998e-05
step: 110, loss: 0.020198136568069458
step: 120, loss: 0.08311811089515686
step: 130, loss: 0.03224092349410057
step: 140, loss: 0.02281568944454193
step: 150, loss: 0.05205729231238365
step: 160, loss: 9.618625881557819e-06
step: 170, loss: 0.08829715847969055
step: 180, loss: 0.04744173586368561
step: 190, loss: 0.00018953792459797114
step: 200, loss: 0.019448433071374893
step: 210, loss: 0.04407584294676781
step: 220, loss: 1.0624438800732605e-05
step: 230, loss: 0.0004217127279844135
step: 240, loss: 0.03526056185364723
step: 250, loss: 0.01434729341417551
step: 260, loss: 0.10126412659883499
step: 270, loss: 0.04674100875854492
step: 280, loss: 0.05255585163831711
step: 290, loss: 0.013139449059963226
step: 300, loss: 0.05819740146398544
step: 310, loss: 0.018819252029061317
step: 320, loss: 0.0013368848012760282
step: 330, loss: 0.0017123731086030602
step: 340, loss: 0.031172052025794983
step: 350, loss: 0.018028821796178818
step: 360, loss: 0.011887099593877792
step: 370, loss: 0.02989862486720085
step: 380, loss: 0.05894928053021431
step: 390, loss: 0.023189928382635117
step: 400, loss: 0.0004753259418066591
step: 410, loss: 0.05742759257555008
step: 420, loss: 0.021621350198984146
step: 430, loss: 0.04535119980573654
step: 440, loss: 0.1168137714266777
step: 450, loss: 0.01842130906879902
step: 460, loss: 0.025998009368777275
epoch 15: dev_f1=0.9921436588103255, f1=0.9843749999999999, best_f1=0.9831271091113611
step: 0, loss: 0.03524378687143326
step: 10, loss: 0.015284474939107895
step: 20, loss: 0.00012405059533193707
step: 30, loss: 0.02142096683382988
step: 40, loss: 0.010425486601889133
step: 50, loss: 0.020925961434841156
step: 60, loss: 0.0005456266226246953
step: 70, loss: 0.01816197670996189
step: 80, loss: 0.016196424141526222
step: 90, loss: 0.00031876610592007637
step: 100, loss: 0.06463804095983505
step: 110, loss: 0.05156512185931206
step: 120, loss: 0.00021276930056046695
step: 130, loss: 6.343997665680945e-05
step: 140, loss: 0.002383278449997306
step: 150, loss: 4.6335037040989846e-05
step: 160, loss: 0.005133315920829773
step: 170, loss: 0.026018088683485985
step: 180, loss: 0.01874503493309021
step: 190, loss: 0.017958253622055054
step: 200, loss: 0.16442619264125824
step: 210, loss: 0.0011615637922659516
step: 220, loss: 0.017002789303660393
step: 230, loss: 0.0015755625208839774
step: 240, loss: 0.04845865070819855
step: 250, loss: 0.0041867829859256744
step: 260, loss: 0.00014245655620470643
step: 270, loss: 0.00042320432839915156
step: 280, loss: 0.04089570790529251
step: 290, loss: 0.049694158136844635
step: 300, loss: 0.02402682416141033
step: 310, loss: 0.0001460853818571195
step: 320, loss: 0.0764976441860199
step: 330, loss: 0.08487532287836075
step: 340, loss: 0.002205968601629138
step: 350, loss: 0.00296579347923398
step: 360, loss: 3.6298984923632815e-05
step: 370, loss: 0.018991874530911446
step: 380, loss: 0.02764885127544403
step: 390, loss: 0.06132621690630913
step: 400, loss: 0.017252784222364426
step: 410, loss: 0.025017471984028816
step: 420, loss: 0.017350226640701294
step: 430, loss: 0.0641825869679451
step: 440, loss: 0.04685487225651741
step: 450, loss: 0.025922570377588272
step: 460, loss: 0.02620956301689148
epoch 16: dev_f1=0.9932735426008968, f1=0.9822222222222222, best_f1=0.9831271091113611
step: 0, loss: 0.020174426957964897
step: 10, loss: 0.017329204827547073
step: 20, loss: 0.02212686650454998
step: 30, loss: 0.02042548358440399
step: 40, loss: 0.0498027503490448
step: 50, loss: 0.001800770522095263
step: 60, loss: 0.061123788356781006
step: 70, loss: 0.00011110042396467179
step: 80, loss: 3.0133962354739197e-05
step: 90, loss: 1.847299608925823e-05
step: 100, loss: 3.643937816377729e-05
step: 110, loss: 0.0012038398999720812
step: 120, loss: 0.024349959567189217
step: 130, loss: 0.0012294152984395623
step: 140, loss: 0.0001456480531487614
step: 150, loss: 0.0024269113782793283
step: 160, loss: 0.023331858217716217
step: 170, loss: 0.0163158867508173
step: 180, loss: 0.048516370356082916
step: 190, loss: 4.3857580749318004e-05
step: 200, loss: 0.08884409070014954
step: 210, loss: 0.04236430674791336
step: 220, loss: 0.020087024196982384
step: 230, loss: 0.05240581929683685
step: 240, loss: 0.04694671556353569
step: 250, loss: 0.029379861429333687
step: 260, loss: 0.02218051441013813
step: 270, loss: 6.41478254692629e-05
step: 280, loss: 0.021583158522844315
step: 290, loss: 0.00030024023726582527
step: 300, loss: 0.0001953438186319545
step: 310, loss: 4.756523048854433e-05
step: 320, loss: 0.017470452934503555
step: 330, loss: 0.00017700044554658234
step: 340, loss: 0.023862536996603012
step: 350, loss: 0.022467929869890213
step: 360, loss: 0.050403397530317307
step: 370, loss: 0.019990963861346245
step: 380, loss: 5.199155566515401e-05
step: 390, loss: 0.02330160140991211
step: 400, loss: 0.04588286951184273
step: 410, loss: 0.023240355774760246
step: 420, loss: 0.00018490143702365458
step: 430, loss: 0.12573347985744476
step: 440, loss: 0.05088333785533905
step: 450, loss: 0.02196558192372322
step: 460, loss: 0.03926144167780876
epoch 17: dev_f1=0.9932584269662922, f1=0.9842696629213483, best_f1=0.9831271091113611
step: 0, loss: 0.00011407230340410024
step: 10, loss: 0.05993515998125076
step: 20, loss: 0.015538427047431469
step: 30, loss: 0.020602494478225708
step: 40, loss: 0.05565060302615166
step: 50, loss: 0.0007358036236837506
step: 60, loss: 0.00042908862815238535
step: 70, loss: 0.00021936447592452168
step: 80, loss: 2.388727807556279e-05
step: 90, loss: 0.00016295671230182052
step: 100, loss: 4.948877904098481e-05
step: 110, loss: 0.02537873573601246
step: 120, loss: 0.03132031112909317
step: 130, loss: 6.213186861714348e-05
step: 140, loss: 9.957014844985679e-05
step: 150, loss: 0.02197270095348358
step: 160, loss: 0.028250565752387047
step: 170, loss: 9.909188520396128e-06
step: 180, loss: 0.016340656206011772
step: 190, loss: 0.016986360773444176
step: 200, loss: 0.026530835777521133
step: 210, loss: 0.05645985156297684
step: 220, loss: 0.00013681936252396554
step: 230, loss: 0.00010989995644195005
step: 240, loss: 7.170242315623909e-05
step: 250, loss: 0.0007108353893272579
step: 260, loss: 0.0002517222601454705
step: 270, loss: 0.01593211106956005
step: 280, loss: 0.025105733424425125
step: 290, loss: 5.1190923841204494e-05
step: 300, loss: 0.02205103635787964
step: 310, loss: 4.953541429131292e-05
step: 320, loss: 0.029493317008018494
step: 330, loss: 0.026831788942217827
step: 340, loss: 4.409736720845103e-05
step: 350, loss: 0.025028713047504425
step: 360, loss: 0.01978936232626438
step: 370, loss: 0.00023713722475804389
step: 380, loss: 0.00044343131594359875
step: 390, loss: 0.00023842173686716706
step: 400, loss: 0.00031852125539444387
step: 410, loss: 0.00022383520263247192
step: 420, loss: 6.77590214763768e-05
step: 430, loss: 0.025796743109822273
step: 440, loss: 0.019049253314733505
step: 450, loss: 0.02411598712205887
step: 460, loss: 0.048273757100105286
epoch 18: dev_f1=0.9932584269662922, f1=0.9854096520763187, best_f1=0.9831271091113611
step: 0, loss: 0.050428278744220734
step: 10, loss: 0.03965519368648529
step: 20, loss: 0.002058122307062149
step: 30, loss: 0.043640799820423126
step: 40, loss: 0.02486010640859604
step: 50, loss: 0.025522546842694283
step: 60, loss: 0.00013955651957076043
step: 70, loss: 0.041886091232299805
step: 80, loss: 0.021602259948849678
step: 90, loss: 0.0346800722181797
step: 100, loss: 0.0004099891521036625
step: 110, loss: 0.0003889220242854208
step: 120, loss: 0.02228182554244995
step: 130, loss: 0.0187876857817173
step: 140, loss: 0.0013501161010935903
step: 150, loss: 0.00015605204680468887
step: 160, loss: 0.029540199786424637
step: 170, loss: 0.0001047961923177354
step: 180, loss: 0.04466047137975693
step: 190, loss: 0.013809863477945328
step: 200, loss: 0.0642932578921318
step: 210, loss: 0.0358143225312233
step: 220, loss: 0.10221340507268906
step: 230, loss: 0.07476557046175003
step: 240, loss: 0.017640287056565285
step: 250, loss: 0.0227374117821455
step: 260, loss: 0.06261312961578369
step: 270, loss: 0.018017934635281563
step: 280, loss: 0.021407650783658028
step: 290, loss: 1.5727966456324793e-05
step: 300, loss: 0.03707469627261162
step: 310, loss: 0.020659858360886574
step: 320, loss: 0.0001543248217785731
step: 330, loss: 0.02358924224972725
step: 340, loss: 0.013493127189576626
step: 350, loss: 0.0586908720433712
step: 360, loss: 0.03639375790953636
step: 370, loss: 3.324260251247324e-05
step: 380, loss: 0.016967887058854103
step: 390, loss: 0.01743565872311592
step: 400, loss: 0.07221031934022903
step: 410, loss: 0.0028391352389007807
step: 420, loss: 0.01841939426958561
step: 430, loss: 9.359796968055889e-05
step: 440, loss: 0.01793220080435276
step: 450, loss: 2.8188022042741068e-05
step: 460, loss: 0.0016931411810219288
epoch 19: dev_f1=0.9932584269662922, f1=0.9854096520763187, best_f1=0.9831271091113611
step: 0, loss: 9.247333946404979e-05
step: 10, loss: 0.024774478748440742
step: 20, loss: 0.026410475373268127
step: 30, loss: 0.02159414067864418
step: 40, loss: 0.06463643908500671
step: 50, loss: 0.026035336777567863
step: 60, loss: 0.0003715466591529548
step: 70, loss: 0.042106471955776215
step: 80, loss: 0.046739522367715836
step: 90, loss: 0.05721953511238098
step: 100, loss: 0.00015143593191169202
step: 110, loss: 0.019317081198096275
step: 120, loss: 0.0003289173182565719
step: 130, loss: 0.019457422196865082
step: 140, loss: 0.012411149218678474
step: 150, loss: 0.11542803049087524
step: 160, loss: 0.023229893296957016
step: 170, loss: 0.01161773968487978
step: 180, loss: 9.88985484582372e-05
step: 190, loss: 0.04909113794565201
step: 200, loss: 0.02203420363366604
step: 210, loss: 0.053595397621393204
step: 220, loss: 0.22585071623325348
step: 230, loss: 0.01707996428012848
step: 240, loss: 0.020924687385559082
step: 250, loss: 3.4541993954917416e-05
step: 260, loss: 0.0001438753679394722
step: 270, loss: 0.048303715884685516
step: 280, loss: 3.0509912903653458e-05
step: 290, loss: 9.355587098980322e-05
step: 300, loss: 0.02244243212044239
step: 310, loss: 9.655942267272621e-05
step: 320, loss: 0.016553755849599838
step: 330, loss: 0.044962115585803986
step: 340, loss: 0.05918393284082413
step: 350, loss: 0.038164172321558
step: 360, loss: 0.043970152735710144
step: 370, loss: 0.00013695510278921574
step: 380, loss: 0.00014006963465362787
step: 390, loss: 0.024113168939948082
step: 400, loss: 3.9054695662343875e-05
step: 410, loss: 0.016693316400051117
step: 420, loss: 0.05578497424721718
step: 430, loss: 0.02336220256984234
step: 440, loss: 0.020332936197519302
step: 450, loss: 0.02114887908101082
step: 460, loss: 0.04852056875824928
epoch 20: dev_f1=0.9932584269662922, f1=0.9854096520763187, best_f1=0.9831271091113611
