cuda
Device: cuda
step: 0, loss: 0.6516228914260864
step: 10, loss: 0.3775438070297241
step: 20, loss: 0.507855236530304
step: 30, loss: 0.27843961119651794
step: 40, loss: 0.17144788801670074
step: 50, loss: 0.12480882555246353
step: 60, loss: 0.16816765069961548
step: 70, loss: 0.13307234644889832
step: 80, loss: 0.021472027525305748
step: 90, loss: 0.16855446994304657
step: 100, loss: 0.09745653718709946
step: 110, loss: 0.14412985742092133
step: 120, loss: 0.037496645003557205
step: 130, loss: 0.1169959157705307
step: 140, loss: 0.05432581901550293
step: 150, loss: 0.15026846528053284
step: 160, loss: 0.2018328607082367
step: 170, loss: 0.08692929893732071
step: 180, loss: 0.15864893794059753
step: 190, loss: 0.07174449414014816
step: 200, loss: 0.07791053503751755
step: 210, loss: 0.12993499636650085
step: 220, loss: 0.06416021287441254
step: 230, loss: 0.09682097285985947
step: 240, loss: 0.1069997251033783
step: 250, loss: 0.0727735087275505
step: 260, loss: 0.14945124089717865
step: 270, loss: 0.06377577781677246
step: 280, loss: 0.10889174044132233
step: 290, loss: 0.023565247654914856
step: 300, loss: 0.009053611196577549
step: 310, loss: 0.07635204493999481
step: 320, loss: 0.07396019250154495
step: 330, loss: 0.00869071763008833
step: 340, loss: 0.005249621346592903
step: 350, loss: 0.12904904782772064
step: 360, loss: 0.03143453225493431
step: 370, loss: 0.011050817556679249
step: 380, loss: 0.04143733158707619
step: 390, loss: 0.04348594695329666
step: 400, loss: 0.07078463584184647
step: 410, loss: 0.0130027299746871
step: 420, loss: 0.023007888346910477
step: 430, loss: 0.06638014316558838
step: 440, loss: 0.02683156728744507
step: 450, loss: 0.16174079477787018
step: 460, loss: 0.02483971416950226
epoch 1: dev_f1=0.9831649831649831, f1=0.9796380090497738, best_f1=0.9796380090497738
step: 0, loss: 0.11530748754739761
step: 10, loss: 0.07001695036888123
step: 20, loss: 0.00882789772003889
step: 30, loss: 0.11214333772659302
step: 40, loss: 0.05990587919950485
step: 50, loss: 0.04418608918786049
step: 60, loss: 0.015888195484876633
step: 70, loss: 0.009886998683214188
step: 80, loss: 0.08648375421762466
step: 90, loss: 0.11073728650808334
step: 100, loss: 0.40272828936576843
step: 110, loss: 0.06663228571414948
step: 120, loss: 0.029143372550606728
step: 130, loss: 0.023411670699715614
step: 140, loss: 0.07401766628026962
step: 150, loss: 0.06025422364473343
step: 160, loss: 0.08104676008224487
step: 170, loss: 0.09893231093883514
step: 180, loss: 0.09480158984661102
step: 190, loss: 0.07525952905416489
step: 200, loss: 0.061281848698854446
step: 210, loss: 0.015428885817527771
step: 220, loss: 0.025927094742655754
step: 230, loss: 0.0665651336312294
step: 240, loss: 0.034489795565605164
step: 250, loss: 0.02420143224298954
step: 260, loss: 0.0077249533496797085
step: 270, loss: 0.07404664158821106
step: 280, loss: 0.022408470511436462
step: 290, loss: 0.08654817193746567
step: 300, loss: 0.05155114457011223
step: 310, loss: 0.13024361431598663
step: 320, loss: 0.007941946387290955
step: 330, loss: 0.023419490084052086
step: 340, loss: 0.052421532571315765
step: 350, loss: 0.07546014338731766
step: 360, loss: 0.01387677900493145
step: 370, loss: 0.08987297862768173
step: 380, loss: 0.039109643548727036
step: 390, loss: 0.050114020705223083
step: 400, loss: 0.19124600291252136
step: 410, loss: 0.0191193874925375
step: 420, loss: 0.08125732839107513
step: 430, loss: 0.04580121859908104
step: 440, loss: 0.016304021701216698
step: 450, loss: 0.07143256068229675
step: 460, loss: 0.059963785111904144
epoch 2: dev_f1=0.990990990990991, f1=0.9864559819413092, best_f1=0.9864559819413092
step: 0, loss: 0.07834149152040482
step: 10, loss: 0.06286884844303131
step: 20, loss: 0.01590465009212494
step: 30, loss: 0.032510221004486084
step: 40, loss: 0.052711132913827896
step: 50, loss: 0.1524563580751419
step: 60, loss: 0.004096996039152145
step: 70, loss: 0.003824210027232766
step: 80, loss: 0.017043892294168472
step: 90, loss: 0.018840691074728966
step: 100, loss: 0.012413527816534042
step: 110, loss: 0.011722499504685402
step: 120, loss: 0.10830671340227127
step: 130, loss: 0.07560892403125763
step: 140, loss: 0.0222826786339283
step: 150, loss: 0.01708303391933441
step: 160, loss: 0.057511214166879654
step: 170, loss: 0.04529324173927307
step: 180, loss: 0.0421435721218586
step: 190, loss: 0.06323905289173126
step: 200, loss: 0.1144346371293068
step: 210, loss: 0.06296283006668091
step: 220, loss: 0.09365598857402802
step: 230, loss: 0.02687653712928295
step: 240, loss: 0.12227457016706467
step: 250, loss: 0.0737912654876709
step: 260, loss: 0.0823642835021019
step: 270, loss: 0.01807146891951561
step: 280, loss: 0.12453360855579376
step: 290, loss: 0.07107242941856384
step: 300, loss: 0.020946206524968147
step: 310, loss: 0.008971350267529488
step: 320, loss: 0.10158752650022507
step: 330, loss: 0.014236539602279663
step: 340, loss: 0.030548933893442154
step: 350, loss: 0.002674939576536417
step: 360, loss: 0.01558274868875742
step: 370, loss: 0.00752519303932786
step: 380, loss: 0.02165183424949646
step: 390, loss: 0.013842081651091576
step: 400, loss: 0.09075707197189331
step: 410, loss: 0.10550285130739212
step: 420, loss: 0.05891739949584007
step: 430, loss: 0.1296992003917694
step: 440, loss: 0.06346404552459717
step: 450, loss: 0.09944194555282593
step: 460, loss: 0.042475759983062744
epoch 3: dev_f1=0.9943883277216611, f1=0.9844444444444443, best_f1=0.9844444444444443
step: 0, loss: 0.01202744897454977
step: 10, loss: 0.1089053824543953
step: 20, loss: 0.03096923418343067
step: 30, loss: 0.0005074793007224798
step: 40, loss: 0.11259517818689346
step: 50, loss: 0.1192486584186554
step: 60, loss: 0.07689134031534195
step: 70, loss: 0.02559894323348999
step: 80, loss: 0.04631217569112778
step: 90, loss: 0.21657493710517883
step: 100, loss: 0.0506935678422451
step: 110, loss: 0.0008991495706140995
step: 120, loss: 0.16411609947681427
step: 130, loss: 0.008606852032244205
step: 140, loss: 0.11371206492185593
step: 150, loss: 0.01937766745686531
step: 160, loss: 0.007798962760716677
step: 170, loss: 0.03145039454102516
step: 180, loss: 0.03143318369984627
step: 190, loss: 0.11804132908582687
step: 200, loss: 0.025815147906541824
step: 210, loss: 0.021618690341711044
step: 220, loss: 0.03642383590340614
step: 230, loss: 0.024406876415014267
step: 240, loss: 0.05233331769704819
step: 250, loss: 0.032053038477897644
step: 260, loss: 0.12398179620504379
step: 270, loss: 0.01818658784031868
step: 280, loss: 0.0596042163670063
step: 290, loss: 0.06309071183204651
step: 300, loss: 0.03386581316590309
step: 310, loss: 0.011264581233263016
step: 320, loss: 0.2075282484292984
step: 330, loss: 0.0008766847313381732
step: 340, loss: 0.08952338248491287
step: 350, loss: 0.006927436217665672
step: 360, loss: 0.09874872863292694
step: 370, loss: 0.02238341048359871
step: 380, loss: 0.07878449559211731
step: 390, loss: 0.06452150642871857
step: 400, loss: 0.020413560792803764
step: 410, loss: 0.07933808118104935
step: 420, loss: 0.09069265425205231
step: 430, loss: 0.08927462995052338
step: 440, loss: 0.08321118354797363
step: 450, loss: 0.11256879568099976
step: 460, loss: 0.02330346591770649
epoch 4: dev_f1=0.9954954954954955, f1=0.9842342342342343, best_f1=0.9842342342342343
step: 0, loss: 0.07165878266096115
step: 10, loss: 0.016717292368412018
step: 20, loss: 0.0037653958424925804
step: 30, loss: 0.012387997470796108
step: 40, loss: 0.07508417218923569
step: 50, loss: 0.010651906952261925
step: 60, loss: 0.005563440732657909
step: 70, loss: 0.023121308535337448
step: 80, loss: 0.025404861196875572
step: 90, loss: 0.005786197260022163
step: 100, loss: 0.007316566072404385
step: 110, loss: 0.12004788219928741
step: 120, loss: 0.004083514213562012
step: 130, loss: 0.032703742384910583
step: 140, loss: 0.02457301691174507
step: 150, loss: 0.007200759835541248
step: 160, loss: 0.14119042456150055
step: 170, loss: 0.0089920898899436
step: 180, loss: 0.18392591178417206
step: 190, loss: 0.013631723821163177
step: 200, loss: 0.03216276690363884
step: 210, loss: 0.007659240625798702
step: 220, loss: 0.08433842658996582
step: 230, loss: 0.007063142489641905
step: 240, loss: 0.028660669922828674
step: 250, loss: 0.062216367572546005
step: 260, loss: 0.009606463834643364
step: 270, loss: 0.06968610733747482
step: 280, loss: 0.04133087396621704
step: 290, loss: 0.1580916792154312
step: 300, loss: 0.0279201902449131
step: 310, loss: 0.06400639563798904
step: 320, loss: 0.01559677254408598
step: 330, loss: 0.0588458776473999
step: 340, loss: 0.08509772270917892
step: 350, loss: 0.06026124581694603
step: 360, loss: 0.012690895237028599
step: 370, loss: 0.014551222324371338
step: 380, loss: 0.011378434486687183
step: 390, loss: 0.11500553041696548
step: 400, loss: 0.03832994028925896
step: 410, loss: 0.013050596229732037
step: 420, loss: 0.07010772824287415
step: 430, loss: 0.029746368527412415
step: 440, loss: 0.031275514513254166
step: 450, loss: 0.06356550753116608
step: 460, loss: 0.029066910967230797
epoch 5: dev_f1=0.9932584269662922, f1=0.9842696629213483, best_f1=0.9842342342342343
step: 0, loss: 0.006082557607442141
step: 10, loss: 0.019082020968198776
step: 20, loss: 0.07315348088741302
step: 30, loss: 0.008105585351586342
step: 40, loss: 0.06266368925571442
step: 50, loss: 0.006618569605052471
step: 60, loss: 0.02400488778948784
step: 70, loss: 0.24963754415512085
step: 80, loss: 0.004577650222927332
step: 90, loss: 0.0734410434961319
step: 100, loss: 0.037784673273563385
step: 110, loss: 0.0112120620906353
step: 120, loss: 0.13731344044208527
step: 130, loss: 0.024848774075508118
step: 140, loss: 0.04203924909234047
step: 150, loss: 0.07796597480773926
step: 160, loss: 0.0032103064004331827
step: 170, loss: 0.03536633402109146
step: 180, loss: 0.17760920524597168
step: 190, loss: 0.009127681143581867
step: 200, loss: 0.04786726459860802
step: 210, loss: 0.02285102754831314
step: 220, loss: 0.019944461062550545
step: 230, loss: 0.023087365552783012
step: 240, loss: 0.028547344729304314
step: 250, loss: 0.11789059638977051
step: 260, loss: 0.0347127802670002
step: 270, loss: 0.07626527547836304
step: 280, loss: 0.00010996465425705537
step: 290, loss: 0.01235406193882227
step: 300, loss: 0.0629371926188469
step: 310, loss: 0.017221957445144653
step: 320, loss: 0.09987539052963257
step: 330, loss: 0.07706987112760544
step: 340, loss: 0.009102641604840755
step: 350, loss: 0.025546928867697716
step: 360, loss: 0.10764461755752563
step: 370, loss: 0.05087832733988762
step: 380, loss: 0.006615781225264072
step: 390, loss: 0.024258118122816086
step: 400, loss: 0.013047287240624428
step: 410, loss: 0.01889161951839924
step: 420, loss: 0.019274156540632248
step: 430, loss: 0.0029381343629211187
step: 440, loss: 0.005675272084772587
step: 450, loss: 0.13641294836997986
step: 460, loss: 0.012525028549134731
epoch 6: dev_f1=0.9887892376681614, f1=0.9853768278965129, best_f1=0.9842342342342343
step: 0, loss: 0.04918947443366051
step: 10, loss: 0.08512048423290253
step: 20, loss: 0.07996656745672226
step: 30, loss: 0.03948363661766052
step: 40, loss: 0.09236592799425125
step: 50, loss: 0.06046350300312042
step: 60, loss: 0.08675188571214676
step: 70, loss: 0.008947798050940037
step: 80, loss: 0.11618874967098236
step: 90, loss: 0.0005055682850070298
step: 100, loss: 0.03258117288351059
step: 110, loss: 0.04485270008444786
step: 120, loss: 0.0145712373778224
step: 130, loss: 0.006365188863128424
step: 140, loss: 0.011039197444915771
step: 150, loss: 0.011825302615761757
step: 160, loss: 0.0760268047451973
step: 170, loss: 0.051702309399843216
step: 180, loss: 0.00022860731405671686
step: 190, loss: 0.00540158711373806
step: 200, loss: 0.0020062262192368507
step: 210, loss: 0.07980471104383469
step: 220, loss: 0.06882067024707794
step: 230, loss: 0.003084928262978792
step: 240, loss: 0.024544600397348404
step: 250, loss: 0.025618650019168854
step: 260, loss: 0.01175810769200325
step: 270, loss: 0.00503562344238162
step: 280, loss: 0.0652778223156929
step: 290, loss: 0.05548559129238129
step: 300, loss: 0.01679082214832306
step: 310, loss: 0.04689444601535797
step: 320, loss: 0.04659651592373848
step: 330, loss: 0.08772849291563034
step: 340, loss: 0.052441880106925964
step: 350, loss: 0.01791529916226864
step: 360, loss: 0.14079448580741882
step: 370, loss: 0.19655992090702057
step: 380, loss: 0.03826071694493294
step: 390, loss: 0.016408972442150116
step: 400, loss: 0.06875204294919968
step: 410, loss: 0.004006148315966129
step: 420, loss: 0.008605102077126503
step: 430, loss: 0.06600074470043182
step: 440, loss: 0.006155617535114288
step: 450, loss: 0.14670221507549286
step: 460, loss: 0.011734427884221077
epoch 7: dev_f1=0.9954853273137697, f1=0.9886877828054299, best_f1=0.9842342342342343
step: 0, loss: 0.009196480736136436
step: 10, loss: 0.013995562680065632
step: 20, loss: 0.03961900994181633
step: 30, loss: 0.010446660220623016
step: 40, loss: 0.07687488943338394
step: 50, loss: 0.05355231463909149
step: 60, loss: 0.03661948814988136
step: 70, loss: 0.023031514137983322
step: 80, loss: 0.0017739578615874052
step: 90, loss: 0.08683095872402191
step: 100, loss: 0.0039014003705233335
step: 110, loss: 0.008761667646467686
step: 120, loss: 0.10946208238601685
step: 130, loss: 0.06713203340768814
step: 140, loss: 0.010315727442502975
step: 150, loss: 0.01612645760178566
step: 160, loss: 0.06978119909763336
step: 170, loss: 0.08263888210058212
step: 180, loss: 0.010781507939100266
step: 190, loss: 0.005424934905022383
step: 200, loss: 0.019301239401102066
step: 210, loss: 0.0232795812189579
step: 220, loss: 0.05862068384885788
step: 230, loss: 0.0307316854596138
step: 240, loss: 0.09524881094694138
step: 250, loss: 0.07158719003200531
step: 260, loss: 0.09660256654024124
step: 270, loss: 0.11340983957052231
step: 280, loss: 0.05289183184504509
step: 290, loss: 0.10428319871425629
step: 300, loss: 0.05720067769289017
step: 310, loss: 0.047009412199258804
step: 320, loss: 0.027659714221954346
step: 330, loss: 0.017594650387763977
step: 340, loss: 0.043978091329336166
step: 350, loss: 0.005905644968152046
step: 360, loss: 0.030258076265454292
step: 370, loss: 0.047359295189380646
step: 380, loss: 0.026860836893320084
step: 390, loss: 0.010270138271152973
step: 400, loss: 0.011194635182619095
step: 410, loss: 0.005425704643130302
step: 420, loss: 0.0037992517463862896
step: 430, loss: 0.004524163901805878
step: 440, loss: 0.03237997740507126
step: 450, loss: 0.03532993048429489
step: 460, loss: 0.04219484329223633
epoch 8: dev_f1=0.9887640449438202, f1=0.9775280898876404, best_f1=0.9842342342342343
step: 0, loss: 0.02422710694372654
step: 10, loss: 0.012227491475641727
step: 20, loss: 0.003602219745516777
step: 30, loss: 0.00560907693579793
step: 40, loss: 0.05900967866182327
step: 50, loss: 0.01686709374189377
step: 60, loss: 0.04483397305011749
step: 70, loss: 0.00971016101539135
step: 80, loss: 0.003316387301310897
step: 90, loss: 0.010441064834594727
step: 100, loss: 0.009890957735478878
step: 110, loss: 0.009660870768129826
step: 120, loss: 0.11934468895196915
step: 130, loss: 0.03511667251586914
step: 140, loss: 0.06952938437461853
step: 150, loss: 3.9261933125089854e-05
step: 160, loss: 0.00010183616541326046
step: 170, loss: 0.00759071996435523
step: 180, loss: 0.002712578745558858
step: 190, loss: 0.003444402012974024
step: 200, loss: 0.14908160269260406
step: 210, loss: 0.004860979504883289
step: 220, loss: 0.058038052171468735
step: 230, loss: 0.019473278895020485
step: 240, loss: 0.0441952720284462
step: 250, loss: 0.002118943026289344
step: 260, loss: 0.08220845460891724
step: 270, loss: 0.00013222437701188028
step: 280, loss: 0.003922443371266127
step: 290, loss: 0.01464872993528843
step: 300, loss: 0.06973790377378464
step: 310, loss: 0.057007480412721634
step: 320, loss: 0.003452021861448884
step: 330, loss: 0.020479073747992516
step: 340, loss: 0.029318982735276222
step: 350, loss: 0.03440757840871811
step: 360, loss: 0.03843732923269272
step: 370, loss: 0.09721296280622482
step: 380, loss: 0.03038135915994644
step: 390, loss: 0.0052969371899962425
step: 400, loss: 0.02466358058154583
step: 410, loss: 0.017441434785723686
step: 420, loss: 0.05063376948237419
step: 430, loss: 0.01620519906282425
step: 440, loss: 0.0009151285048574209
step: 450, loss: 0.0050407228991389275
step: 460, loss: 0.02447311021387577
epoch 9: dev_f1=0.9910112359550561, f1=0.9820627802690582, best_f1=0.9842342342342343
step: 0, loss: 0.0280402060598135
step: 10, loss: 0.017783045768737793
step: 20, loss: 0.05254969373345375
step: 30, loss: 0.052910320460796356
step: 40, loss: 0.03514976426959038
step: 50, loss: 0.08022812008857727
step: 60, loss: 0.039207860827445984
step: 70, loss: 0.03614242747426033
step: 80, loss: 0.0023852435406297445
step: 90, loss: 0.032943498343229294
step: 100, loss: 0.08963119238615036
step: 110, loss: 0.04110969230532646
step: 120, loss: 0.0005013080663047731
step: 130, loss: 0.15558212995529175
step: 140, loss: 0.00028743702569045126
step: 150, loss: 0.038635868579149246
step: 160, loss: 0.056434690952301025
step: 170, loss: 0.07569944113492966
step: 180, loss: 0.021961752325296402
step: 190, loss: 0.0021069494541734457
step: 200, loss: 0.11501924693584442
step: 210, loss: 0.02530818246304989
step: 220, loss: 0.016044599935412407
step: 230, loss: 0.1548622101545334
step: 240, loss: 0.0032284024637192488
step: 250, loss: 0.037627942860126495
step: 260, loss: 0.02568667382001877
step: 270, loss: 0.04729165881872177
step: 280, loss: 0.013840962201356888
step: 290, loss: 0.1242300495505333
step: 300, loss: 0.02706955373287201
step: 310, loss: 0.062209125608205795
step: 320, loss: 0.011654991656541824
step: 330, loss: 0.01415533572435379
step: 340, loss: 0.06536255776882172
step: 350, loss: 0.0031186838168650866
step: 360, loss: 0.1646624654531479
step: 370, loss: 0.046025350689888
step: 380, loss: 0.05798689275979996
step: 390, loss: 0.029707105830311775
step: 400, loss: 0.06022661551833153
step: 410, loss: 9.14266420295462e-05
step: 420, loss: 0.06208561360836029
step: 430, loss: 0.019361989572644234
step: 440, loss: 0.005306258797645569
step: 450, loss: 0.015104428865015507
step: 460, loss: 0.228644460439682
epoch 10: dev_f1=0.9932279909706545, f1=0.9875706214689265, best_f1=0.9842342342342343
step: 0, loss: 0.003965023905038834
step: 10, loss: 0.018505407497286797
step: 20, loss: 0.0029925506096333265
step: 30, loss: 0.014783837832510471
step: 40, loss: 0.00876342598348856
step: 50, loss: 0.03862745314836502
step: 60, loss: 0.046111058443784714
step: 70, loss: 0.04551546648144722
step: 80, loss: 0.0012612113496288657
step: 90, loss: 0.07839147746562958
step: 100, loss: 0.0471077524125576
step: 110, loss: 0.03923264145851135
step: 120, loss: 0.0215240977704525
step: 130, loss: 0.058874208480119705
step: 140, loss: 0.028957845643162727
step: 150, loss: 0.03963048383593559
step: 160, loss: 0.01923641748726368
step: 170, loss: 0.05225672572851181
step: 180, loss: 0.04235243797302246
step: 190, loss: 0.00033224388607777655
step: 200, loss: 0.023900358006358147
step: 210, loss: 0.0006114504067227244
step: 220, loss: 0.026547111570835114
step: 230, loss: 0.017186978831887245
step: 240, loss: 0.03327532857656479
step: 250, loss: 0.01690206490457058
step: 260, loss: 0.07109833508729935
step: 270, loss: 0.00464440556243062
step: 280, loss: 0.03366558626294136
step: 290, loss: 0.006350673735141754
step: 300, loss: 0.0006633466109633446
step: 310, loss: 4.56130837847013e-05
step: 320, loss: 0.010450114496052265
step: 330, loss: 0.01768215373158455
step: 340, loss: 0.003581405384466052
step: 350, loss: 0.06867843866348267
step: 360, loss: 0.00286138360388577
step: 370, loss: 0.06473547965288162
step: 380, loss: 0.0009636040194891393
step: 390, loss: 0.015486124902963638
step: 400, loss: 0.017767783254384995
step: 410, loss: 0.035414259880781174
step: 420, loss: 0.04027707502245903
step: 430, loss: 0.042633455246686935
step: 440, loss: 0.009992672130465508
step: 450, loss: 0.0052694762125611305
step: 460, loss: 0.03701575845479965
epoch 11: dev_f1=0.9943757030371203, f1=0.9843749999999999, best_f1=0.9842342342342343
step: 0, loss: 0.039774809032678604
step: 10, loss: 0.025768473744392395
step: 20, loss: 0.09179990738630295
step: 30, loss: 0.018042966723442078
step: 40, loss: 0.05604129284620285
step: 50, loss: 0.020941654220223427
step: 60, loss: 0.028033358976244926
step: 70, loss: 0.029112467542290688
step: 80, loss: 0.0739135593175888
step: 90, loss: 0.026560161262750626
step: 100, loss: 0.08819719403982162
step: 110, loss: 0.04056788235902786
step: 120, loss: 0.029000403359532356
step: 130, loss: 0.11470231413841248
step: 140, loss: 0.002834599232301116
step: 150, loss: 0.0005958995316177607
step: 160, loss: 0.053782083094120026
step: 170, loss: 0.014524789527058601
step: 180, loss: 0.00024988403310999274
step: 190, loss: 0.010242023505270481
step: 200, loss: 0.02429688163101673
step: 210, loss: 0.0293820109218359
step: 220, loss: 0.01673775538802147
step: 230, loss: 0.08793268352746964
step: 240, loss: 0.003158801468089223
step: 250, loss: 0.0006185758975334466
step: 260, loss: 0.00011355892638675869
step: 270, loss: 0.06049933657050133
step: 280, loss: 0.0011517101665958762
step: 290, loss: 0.014533333480358124
step: 300, loss: 0.0001469570997869596
step: 310, loss: 0.08184590190649033
step: 320, loss: 0.05289456620812416
step: 330, loss: 0.0527682825922966
step: 340, loss: 0.003908629063516855
step: 350, loss: 0.028276728466153145
step: 360, loss: 0.02378731593489647
step: 370, loss: 0.0009890770306810737
step: 380, loss: 0.037813667207956314
step: 390, loss: 0.044855471700429916
step: 400, loss: 0.021929552778601646
step: 410, loss: 0.039783280342817307
step: 420, loss: 0.01676967553794384
step: 430, loss: 0.0010821027681231499
step: 440, loss: 0.01761912927031517
step: 450, loss: 0.053227510303258896
step: 460, loss: 0.045972321182489395
epoch 12: dev_f1=0.9921436588103255, f1=0.983277591973244, best_f1=0.9842342342342343
step: 0, loss: 0.02306775562465191
step: 10, loss: 0.004675818141549826
step: 20, loss: 1.7735799701767974e-05
step: 30, loss: 0.0001820433681132272
step: 40, loss: 0.020671004429459572
step: 50, loss: 0.03181544691324234
step: 60, loss: 0.026098378002643585
step: 70, loss: 0.00013749981008004397
step: 80, loss: 0.04492684453725815
step: 90, loss: 0.040221065282821655
step: 100, loss: 6.354977085720748e-05
step: 110, loss: 0.02415052428841591
step: 120, loss: 0.02529010735452175
step: 130, loss: 0.044578660279512405
step: 140, loss: 0.03565213829278946
step: 150, loss: 0.02511599101126194
step: 160, loss: 0.05573287978768349
step: 170, loss: 0.07228048145771027
step: 180, loss: 0.08378054946660995
step: 190, loss: 0.04788515716791153
step: 200, loss: 0.0637359544634819
step: 210, loss: 0.0011458599474281073
step: 220, loss: 0.030064664781093597
step: 230, loss: 0.0016827190993353724
step: 240, loss: 0.03300589323043823
step: 250, loss: 0.024452924728393555
step: 260, loss: 0.0012356835650280118
step: 270, loss: 0.04217366501688957
step: 280, loss: 0.039251234382390976
step: 290, loss: 0.047970086336135864
step: 300, loss: 0.0630788579583168
step: 310, loss: 0.03140683099627495
step: 320, loss: 0.09532538056373596
step: 330, loss: 0.02631247229874134
step: 340, loss: 0.007132912985980511
step: 350, loss: 0.0004922825610265136
step: 360, loss: 0.0004908537957817316
step: 370, loss: 8.643963519716635e-05
step: 380, loss: 0.06787574291229248
step: 390, loss: 0.00047424400690943
step: 400, loss: 0.021889066323637962
step: 410, loss: 0.0011571713257580996
step: 420, loss: 0.021314872428774834
step: 430, loss: 5.660110036842525e-05
step: 440, loss: 0.00021625933004543185
step: 450, loss: 0.07471585273742676
step: 460, loss: 0.00017809310520533472
epoch 13: dev_f1=0.9932279909706545, f1=0.9831271091113611, best_f1=0.9842342342342343
step: 0, loss: 0.003298502881079912
step: 10, loss: 0.05275781452655792
step: 20, loss: 0.04673952981829643
step: 30, loss: 0.0441160649061203
step: 40, loss: 0.0015179337933659554
step: 50, loss: 0.0029309734236449003
step: 60, loss: 0.00048604357289150357
step: 70, loss: 0.02190972864627838
step: 80, loss: 0.04709606245160103
step: 90, loss: 0.045023348182439804
step: 100, loss: 7.138690853025764e-05
step: 110, loss: 0.00011320628254907206
step: 120, loss: 0.022259578108787537
step: 130, loss: 0.0039885928854346275
step: 140, loss: 0.044664062559604645
step: 150, loss: 0.027920639142394066
step: 160, loss: 0.033240363001823425
step: 170, loss: 0.00012405852612573653
step: 180, loss: 0.00038286097696982324
step: 190, loss: 0.00019873131532222033
step: 200, loss: 9.069057705346495e-05
step: 210, loss: 2.34162562264828e-05
step: 220, loss: 0.022649459540843964
step: 230, loss: 0.0013893941650167108
step: 240, loss: 0.014468243345618248
step: 250, loss: 8.951523341238499e-05
step: 260, loss: 0.039955995976924896
step: 270, loss: 0.03992476314306259
step: 280, loss: 0.047670017927885056
step: 290, loss: 0.04386157914996147
step: 300, loss: 0.041254978626966476
step: 310, loss: 0.04334691911935806
step: 320, loss: 0.0015007015317678452
step: 330, loss: 0.03440752252936363
step: 340, loss: 0.0001126775678130798
step: 350, loss: 0.020435096696019173
step: 360, loss: 0.04137785732746124
step: 370, loss: 0.016905348747968674
step: 380, loss: 0.001247295062057674
step: 390, loss: 0.019178414717316628
step: 400, loss: 0.0004488325212150812
step: 410, loss: 0.00013560621300712228
step: 420, loss: 0.01798066310584545
step: 430, loss: 0.015609709545969963
step: 440, loss: 0.04890144243836403
step: 450, loss: 0.0527050606906414
step: 460, loss: 0.0604790635406971
epoch 14: dev_f1=0.9943630214205187, f1=0.9842696629213483, best_f1=0.9842342342342343
step: 0, loss: 0.25044187903404236
step: 10, loss: 0.021541813388466835
step: 20, loss: 0.0005145599134266376
step: 30, loss: 0.03766120225191116
step: 40, loss: 0.014669068157672882
step: 50, loss: 0.01999235525727272
step: 60, loss: 0.03697962686419487
step: 70, loss: 0.0213084127753973
step: 80, loss: 0.0001248065964318812
step: 90, loss: 0.022271132096648216
step: 100, loss: 0.00013618750381283462
step: 110, loss: 0.05068328604102135
step: 120, loss: 0.0019154750043526292
step: 130, loss: 0.023570913821458817
step: 140, loss: 0.0003864310565404594
step: 150, loss: 0.04398689046502113
step: 160, loss: 0.00023556129599455744
step: 170, loss: 0.038261089473962784
step: 180, loss: 0.06768564879894257
step: 190, loss: 0.0161699540913105
step: 200, loss: 0.0003307972801849246
step: 210, loss: 0.044045694172382355
step: 220, loss: 6.575070437975228e-05
step: 230, loss: 0.0001207174063893035
step: 240, loss: 0.0393453948199749
step: 250, loss: 0.07984701544046402
step: 260, loss: 8.078037353698164e-05
step: 270, loss: 0.05863399803638458
step: 280, loss: 0.02213367260992527
step: 290, loss: 0.0004153363988734782
step: 300, loss: 4.2169089283561334e-05
step: 310, loss: 0.21132349967956543
step: 320, loss: 0.023157086223363876
step: 330, loss: 0.04822489246726036
step: 340, loss: 0.0056468467228114605
step: 350, loss: 0.06478492170572281
step: 360, loss: 0.021804096177220345
step: 370, loss: 0.021383436396718025
step: 380, loss: 0.023590384051203728
step: 390, loss: 0.0422678105533123
step: 400, loss: 0.024817101657390594
step: 410, loss: 0.005697276908904314
step: 420, loss: 0.024974774569272995
step: 430, loss: 0.0176029484719038
step: 440, loss: 0.024373408406972885
step: 450, loss: 0.05282330885529518
step: 460, loss: 2.21798472921364e-05
epoch 15: dev_f1=0.9932432432432432, f1=0.984304932735426, best_f1=0.9842342342342343
step: 0, loss: 0.011694769375026226
step: 10, loss: 9.90637854556553e-05
step: 20, loss: 8.53602759889327e-05
step: 30, loss: 2.2659967726212926e-05
step: 40, loss: 0.05731312558054924
step: 50, loss: 0.02350563183426857
step: 60, loss: 0.00024953033425845206
step: 70, loss: 0.045315660536289215
step: 80, loss: 2.2227715817280114e-05
step: 90, loss: 0.014692917466163635
step: 100, loss: 5.194565164856613e-05
step: 110, loss: 0.007927995175123215
step: 120, loss: 0.00019338639685884118
step: 130, loss: 0.012981250882148743
step: 140, loss: 0.027725882828235626
step: 150, loss: 0.00014215832925401628
step: 160, loss: 0.0976923257112503
step: 170, loss: 0.02458002418279648
step: 180, loss: 0.017048027366399765
step: 190, loss: 0.002670172369107604
step: 200, loss: 2.7900274290004745e-05
step: 210, loss: 1.7042853869497776e-05
step: 220, loss: 0.018627893179655075
step: 230, loss: 0.019603615626692772
step: 240, loss: 0.05711113661527634
step: 250, loss: 0.0001809116656659171
step: 260, loss: 0.022693393751978874
step: 270, loss: 7.04597623553127e-05
step: 280, loss: 0.044416122138500214
step: 290, loss: 0.05547192692756653
step: 300, loss: 9.421950380783528e-05
step: 310, loss: 0.0002223370102001354
step: 320, loss: 9.26131397136487e-05
step: 330, loss: 0.03451665863394737
step: 340, loss: 0.023072626441717148
step: 350, loss: 0.006220495793968439
step: 360, loss: 0.047706589102745056
step: 370, loss: 0.0002256674924865365
step: 380, loss: 0.020617926493287086
step: 390, loss: 0.022613665089011192
step: 400, loss: 0.02250601537525654
step: 410, loss: 0.05026204138994217
step: 420, loss: 0.00023393664741888642
step: 430, loss: 0.024922462180256844
step: 440, loss: 0.00013463576033245772
step: 450, loss: 7.909406849648803e-05
step: 460, loss: 0.013379596173763275
epoch 16: dev_f1=0.9943630214205187, f1=0.984304932735426, best_f1=0.9842342342342343
step: 0, loss: 0.030683863908052444
step: 10, loss: 0.018444517627358437
step: 20, loss: 0.0008321597124449909
step: 30, loss: 0.026982326060533524
step: 40, loss: 0.0003286335850134492
step: 50, loss: 0.01728195883333683
step: 60, loss: 0.028369642794132233
step: 70, loss: 0.027678247541189194
step: 80, loss: 0.027610789984464645
step: 90, loss: 0.01908128149807453
step: 100, loss: 0.043227456510066986
step: 110, loss: 0.0511779859662056
step: 120, loss: 0.06016081944108009
step: 130, loss: 9.736687934491783e-05
step: 140, loss: 0.0808611735701561
step: 150, loss: 0.0001107285643229261
step: 160, loss: 0.0001760297891451046
step: 170, loss: 0.04321514815092087
step: 180, loss: 0.05052681639790535
step: 190, loss: 0.037580084055662155
step: 200, loss: 0.001184237189590931
step: 210, loss: 0.04330713301897049
step: 220, loss: 0.0030759088695049286
step: 230, loss: 0.028911788016557693
step: 240, loss: 8.371962030651048e-05
step: 250, loss: 0.04465292766690254
step: 260, loss: 5.4564752645092085e-05
step: 270, loss: 0.0003092469705734402
step: 280, loss: 7.178977102739736e-05
step: 290, loss: 0.021296456456184387
step: 300, loss: 0.01797836646437645
step: 310, loss: 0.01706465147435665
step: 320, loss: 0.043552324175834656
step: 330, loss: 0.017867449671030045
step: 340, loss: 0.00011626789637375623
step: 350, loss: 0.022069748491048813
step: 360, loss: 0.042020346969366074
step: 370, loss: 0.019186092540621758
step: 380, loss: 0.03512807562947273
step: 390, loss: 3.69239533029031e-05
step: 400, loss: 0.00013173768820706755
step: 410, loss: 0.03206007182598114
step: 420, loss: 0.01558668166399002
step: 430, loss: 5.093302024761215e-05
step: 440, loss: 0.01932522840797901
step: 450, loss: 0.022019706666469574
step: 460, loss: 0.04253546893596649
epoch 17: dev_f1=0.9932279909706545, f1=0.984304932735426, best_f1=0.9842342342342343
step: 0, loss: 0.0008690105751156807
step: 10, loss: 0.027145445346832275
step: 20, loss: 0.037005968391895294
step: 30, loss: 0.022246597334742546
step: 40, loss: 0.021495716646313667
step: 50, loss: 0.038429874926805496
step: 60, loss: 0.02023322694003582
step: 70, loss: 0.020353177562355995
step: 80, loss: 0.00022306936443783343
step: 90, loss: 0.020065564662218094
step: 100, loss: 0.047492559999227524
step: 110, loss: 0.08645472675561905
step: 120, loss: 0.0035205944441258907
step: 130, loss: 0.00011632542737061158
step: 140, loss: 0.024922417476773262
step: 150, loss: 0.012154816649854183
step: 160, loss: 0.04107005521655083
step: 170, loss: 0.012948512099683285
step: 180, loss: 0.000776936300098896
step: 190, loss: 0.05918683856725693
step: 200, loss: 5.7732147979550064e-05
step: 210, loss: 0.0393388494849205
step: 220, loss: 0.0206929799169302
step: 230, loss: 0.0972699373960495
step: 240, loss: 0.024473488330841064
step: 250, loss: 0.04086657613515854
step: 260, loss: 0.02354106493294239
step: 270, loss: 0.0001814280985854566
step: 280, loss: 0.042742881923913956
step: 290, loss: 0.0392131581902504
step: 300, loss: 7.420389738399535e-05
step: 310, loss: 6.882853631395847e-05
step: 320, loss: 6.545591895701364e-05
step: 330, loss: 0.0409967377781868
step: 340, loss: 0.049455758184194565
step: 350, loss: 0.027802787721157074
step: 360, loss: 0.017598124220967293
step: 370, loss: 0.02995842695236206
step: 380, loss: 0.06474516540765762
step: 390, loss: 5.472885095514357e-05
step: 400, loss: 0.11500076204538345
step: 410, loss: 0.02484913356602192
step: 420, loss: 4.651068229577504e-05
step: 430, loss: 0.021461907774209976
step: 440, loss: 1.8532684407546185e-05
step: 450, loss: 0.04838830605149269
step: 460, loss: 0.03375750407576561
epoch 18: dev_f1=0.9932279909706545, f1=0.9842696629213483, best_f1=0.9842342342342343
step: 0, loss: 0.01869477517902851
step: 10, loss: 0.062126290053129196
step: 20, loss: 0.08524318039417267
step: 30, loss: 0.07629355788230896
step: 40, loss: 0.019836410880088806
step: 50, loss: 0.0177972000092268
step: 60, loss: 0.03541434556245804
step: 70, loss: 0.016816219314932823
step: 80, loss: 0.013723633252084255
step: 90, loss: 0.03178439661860466
step: 100, loss: 0.0669255182147026
step: 110, loss: 9.440627763979137e-05
step: 120, loss: 0.009367820806801319
step: 130, loss: 0.022086190059781075
step: 140, loss: 0.053745340555906296
step: 150, loss: 0.037388622760772705
step: 160, loss: 0.019604895263910294
step: 170, loss: 7.622851262567565e-05
step: 180, loss: 0.0037583746016025543
step: 190, loss: 0.02295222505927086
step: 200, loss: 0.0727209746837616
step: 210, loss: 2.6577723474474624e-05
step: 220, loss: 2.4023360310820863e-05
step: 230, loss: 0.026065068319439888
step: 240, loss: 0.0196915864944458
step: 250, loss: 0.00013782588939648122
step: 260, loss: 0.14048627018928528
step: 270, loss: 0.024720115587115288
step: 280, loss: 0.05140458419919014
step: 290, loss: 1.387276643072255e-05
step: 300, loss: 0.02445034310221672
step: 310, loss: 0.038368143141269684
step: 320, loss: 0.00018165953224524856
step: 330, loss: 0.06811141222715378
step: 340, loss: 0.017856542021036148
step: 350, loss: 0.023385290056467056
step: 360, loss: 0.02444905787706375
step: 370, loss: 2.0230998416082002e-05
step: 380, loss: 0.07965081185102463
step: 390, loss: 0.021453039720654488
step: 400, loss: 0.0005903758574277163
step: 410, loss: 4.339714359957725e-05
step: 420, loss: 0.055985528975725174
step: 430, loss: 0.04311947524547577
step: 440, loss: 4.3090502003906295e-05
step: 450, loss: 7.361837197095156e-05
step: 460, loss: 0.01655326783657074
epoch 19: dev_f1=0.9932279909706545, f1=0.984304932735426, best_f1=0.9842342342342343
step: 0, loss: 0.020430948585271835
step: 10, loss: 5.713611972169019e-05
step: 20, loss: 0.02276359125971794
step: 30, loss: 0.02103710174560547
step: 40, loss: 0.023605506867170334
step: 50, loss: 0.016840921714901924
step: 60, loss: 4.1167280869558454e-05
step: 70, loss: 0.03468373790383339
step: 80, loss: 0.038562145084142685
step: 90, loss: 0.022423285990953445
step: 100, loss: 5.795867400593124e-05
step: 110, loss: 7.136786007322371e-05
step: 120, loss: 0.05742163956165314
step: 130, loss: 0.02388855069875717
step: 140, loss: 0.00012252178566996008
step: 150, loss: 5.117172622703947e-05
step: 160, loss: 0.024738779291510582
step: 170, loss: 3.586944148992188e-05
step: 180, loss: 0.04045435041189194
step: 190, loss: 0.053278837352991104
step: 200, loss: 0.022809987887740135
step: 210, loss: 0.0030085796024650335
step: 220, loss: 0.16225095093250275
step: 230, loss: 6.94790796842426e-05
step: 240, loss: 0.021460535004734993
step: 250, loss: 1.0389744602434803e-05
step: 260, loss: 9.516578575130552e-05
step: 270, loss: 3.898086288245395e-05
step: 280, loss: 0.03288372606039047
step: 290, loss: 0.00043831299990415573
step: 300, loss: 0.04618753492832184
step: 310, loss: 0.047442320734262466
step: 320, loss: 0.04010896012187004
step: 330, loss: 3.239864599891007e-05
step: 340, loss: 0.016584163531661034
step: 350, loss: 2.758798837021459e-05
step: 360, loss: 0.09345684200525284
step: 370, loss: 0.05557498708367348
step: 380, loss: 0.012744108214974403
step: 390, loss: 0.041032806038856506
step: 400, loss: 3.2031148293754086e-05
step: 410, loss: 0.02348305657505989
step: 420, loss: 0.04210420325398445
step: 430, loss: 0.0002679924655240029
step: 440, loss: 5.746158058173023e-05
step: 450, loss: 0.01925073377788067
step: 460, loss: 0.02158873714506626
epoch 20: dev_f1=0.9932279909706545, f1=0.984304932735426, best_f1=0.9842342342342343
