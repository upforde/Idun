cuda
Device: cuda
step: 0, loss: 0.9272146224975586
step: 10, loss: 0.3952377736568451
step: 20, loss: 0.37202781438827515
step: 30, loss: 0.6080877184867859
step: 40, loss: 0.5210965275764465
step: 50, loss: 0.27035295963287354
step: 60, loss: 0.2949008047580719
step: 70, loss: 0.10830894857645035
step: 80, loss: 0.14305970072746277
step: 90, loss: 0.060706328600645065
step: 100, loss: 0.17623287439346313
step: 110, loss: 0.1532939374446869
step: 120, loss: 0.1981784552335739
step: 130, loss: 0.1213281899690628
step: 140, loss: 0.06759672611951828
step: 150, loss: 0.06671874225139618
step: 160, loss: 0.23364140093326569
step: 170, loss: 0.029832402244210243
step: 180, loss: 0.04550427943468094
step: 190, loss: 0.2058478742837906
step: 200, loss: 0.025133319199085236
step: 210, loss: 0.09300150722265244
step: 220, loss: 0.05507823824882507
step: 230, loss: 0.03730665519833565
step: 240, loss: 0.10160475969314575
step: 250, loss: 0.03194066137075424
step: 260, loss: 0.04397042840719223
step: 270, loss: 0.015515973791480064
step: 280, loss: 0.04318132624030113
step: 290, loss: 0.036006707698106766
step: 300, loss: 0.07043691724538803
step: 310, loss: 0.02156287431716919
step: 320, loss: 0.1544482707977295
step: 330, loss: 0.12364237755537033
step: 340, loss: 0.11088800430297852
step: 350, loss: 0.10052987188100815
step: 360, loss: 0.049343567341566086
step: 370, loss: 0.06251857429742813
step: 380, loss: 0.01509161852300167
step: 390, loss: 0.018022578209638596
step: 400, loss: 0.041310764849185944
step: 410, loss: 0.1202428787946701
step: 420, loss: 0.06889176368713379
step: 430, loss: 0.0782361775636673
step: 440, loss: 0.06921928375959396
step: 450, loss: 0.0702749714255333
step: 460, loss: 0.06939013302326202
epoch 1: dev_f1=0.9898534385569334, f1=0.9853107344632768, best_f1=0.9853107344632768
step: 0, loss: 0.19520597159862518
step: 10, loss: 0.0633992925286293
step: 20, loss: 0.10022073239088058
step: 30, loss: 0.04948548227548599
step: 40, loss: 0.12664121389389038
step: 50, loss: 0.18755897879600525
step: 60, loss: 0.010723473504185677
step: 70, loss: 0.09512025117874146
step: 80, loss: 0.0903334692120552
step: 90, loss: 0.2905237376689911
step: 100, loss: 0.032353609800338745
step: 110, loss: 0.03663640469312668
step: 120, loss: 0.06190233677625656
step: 130, loss: 0.02496691793203354
step: 140, loss: 0.27356335520744324
step: 150, loss: 0.12644514441490173
step: 160, loss: 0.11877832561731339
step: 170, loss: 0.04600251466035843
step: 180, loss: 0.03307660296559334
step: 190, loss: 0.058906711637973785
step: 200, loss: 0.08946200460195541
step: 210, loss: 0.027842357754707336
step: 220, loss: 0.124346524477005
step: 230, loss: 0.08978921175003052
step: 240, loss: 0.05870507284998894
step: 250, loss: 0.009434073232114315
step: 260, loss: 0.014491249807178974
step: 270, loss: 0.09175469726324081
step: 280, loss: 0.046844109892845154
step: 290, loss: 0.10087159276008606
step: 300, loss: 0.02692563645541668
step: 310, loss: 0.28989437222480774
step: 320, loss: 0.05723869428038597
step: 330, loss: 0.12468404322862625
step: 340, loss: 0.13577070832252502
step: 350, loss: 0.09599767625331879
step: 360, loss: 0.054647814482450485
step: 370, loss: 0.10746221989393234
step: 380, loss: 0.0059518530033528805
step: 390, loss: 0.013260466046631336
step: 400, loss: 0.1102406233549118
step: 410, loss: 0.056785400956869125
step: 420, loss: 0.06674513965845108
step: 430, loss: 0.13026291131973267
step: 440, loss: 0.10646626353263855
step: 450, loss: 0.08062583208084106
step: 460, loss: 0.07049386203289032
epoch 2: dev_f1=0.988814317673378, f1=0.9821428571428571, best_f1=0.9853107344632768
step: 0, loss: 0.014099357649683952
step: 10, loss: 0.11744203418493271
step: 20, loss: 0.07063179463148117
step: 30, loss: 0.019608158618211746
step: 40, loss: 0.0040187472477555275
step: 50, loss: 0.13989831507205963
step: 60, loss: 0.028950370848178864
step: 70, loss: 0.03054027073085308
step: 80, loss: 0.07582711428403854
step: 90, loss: 0.036475107073783875
step: 100, loss: 0.017420951277017593
step: 110, loss: 0.022953443229198456
step: 120, loss: 0.16881214082241058
step: 130, loss: 0.07140845060348511
step: 140, loss: 0.014973968267440796
step: 150, loss: 0.005473974626511335
step: 160, loss: 0.016262907534837723
step: 170, loss: 0.03360509127378464
step: 180, loss: 0.015452812425792217
step: 190, loss: 0.11410072445869446
step: 200, loss: 0.024624673649668694
step: 210, loss: 0.0643845722079277
step: 220, loss: 0.03670769929885864
step: 230, loss: 0.1370779126882553
step: 240, loss: 0.05869339779019356
step: 250, loss: 0.029889272525906563
step: 260, loss: 0.016137925907969475
step: 270, loss: 0.11411678791046143
step: 280, loss: 0.02109159529209137
step: 290, loss: 0.08959291875362396
step: 300, loss: 0.28377285599708557
step: 310, loss: 0.025944968685507774
step: 320, loss: 0.07832811027765274
step: 330, loss: 0.0253529604524374
step: 340, loss: 0.020157882943749428
step: 350, loss: 0.046279825270175934
step: 360, loss: 0.017950359731912613
step: 370, loss: 0.018749579787254333
step: 380, loss: 0.06426095217466354
step: 390, loss: 0.02225825935602188
step: 400, loss: 0.05691809207201004
step: 410, loss: 0.013513166457414627
step: 420, loss: 0.02471751719713211
step: 430, loss: 0.06407677382230759
step: 440, loss: 0.011249400675296783
step: 450, loss: 0.06982061266899109
step: 460, loss: 0.08212320506572723
epoch 3: dev_f1=0.9843400447427293, f1=0.9810055865921787, best_f1=0.9853107344632768
step: 0, loss: 0.016902144998311996
step: 10, loss: 0.006302823778241873
step: 20, loss: 0.021039575338363647
step: 30, loss: 0.08937101066112518
step: 40, loss: 0.13265493512153625
step: 50, loss: 0.013811798766255379
step: 60, loss: 0.0830102190375328
step: 70, loss: 0.21862149238586426
step: 80, loss: 0.07525218278169632
step: 90, loss: 0.02200438268482685
step: 100, loss: 0.11726409196853638
step: 110, loss: 0.02924693562090397
step: 120, loss: 0.0323864109814167
step: 130, loss: 0.07138628512620926
step: 140, loss: 0.0066801197826862335
step: 150, loss: 0.034961968660354614
step: 160, loss: 0.007064090110361576
step: 170, loss: 0.027981773018836975
step: 180, loss: 0.021819954738020897
step: 190, loss: 0.08091619610786438
step: 200, loss: 0.013229848816990852
step: 210, loss: 0.005023682489991188
step: 220, loss: 0.021840786561369896
step: 230, loss: 0.02874140627682209
step: 240, loss: 0.024427007883787155
step: 250, loss: 0.04011290520429611
step: 260, loss: 0.008165157400071621
step: 270, loss: 0.014033160172402859
step: 280, loss: 0.008407782763242722
step: 290, loss: 0.060717903077602386
step: 300, loss: 0.02125871740281582
step: 310, loss: 0.019829096272587776
step: 320, loss: 0.05017949268221855
step: 330, loss: 0.14455269277095795
step: 340, loss: 0.053136032074689865
step: 350, loss: 0.08299286663532257
step: 360, loss: 0.009837636724114418
step: 370, loss: 0.18872405588626862
step: 380, loss: 0.031067458912730217
step: 390, loss: 0.008479347452521324
step: 400, loss: 0.12117941677570343
step: 410, loss: 0.21589870750904083
step: 420, loss: 0.014095067046582699
step: 430, loss: 0.041571009904146194
step: 440, loss: 0.0001696881663519889
step: 450, loss: 0.01104740984737873
step: 460, loss: 0.04503219947218895
epoch 4: dev_f1=0.990990990990991, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.09167258441448212
step: 10, loss: 0.047269612550735474
step: 20, loss: 0.010947925969958305
step: 30, loss: 0.08289293199777603
step: 40, loss: 0.1583712249994278
step: 50, loss: 0.01141363475471735
step: 60, loss: 0.04791523888707161
step: 70, loss: 0.05511791631579399
step: 80, loss: 0.015461467206478119
step: 90, loss: 0.030917901545763016
step: 100, loss: 0.006378956604748964
step: 110, loss: 0.10357183963060379
step: 120, loss: 0.011123819276690483
step: 130, loss: 0.07963450253009796
step: 140, loss: 0.027677010744810104
step: 150, loss: 0.02353348582983017
step: 160, loss: 0.026783088222146034
step: 170, loss: 0.010944821871817112
step: 180, loss: 0.055826906114816666
step: 190, loss: 0.007197885774075985
step: 200, loss: 0.00796207319945097
step: 210, loss: 0.06893450021743774
step: 220, loss: 0.019566824659705162
step: 230, loss: 0.007544561289250851
step: 240, loss: 0.1211608350276947
step: 250, loss: 0.05281960591673851
step: 260, loss: 0.015953324735164642
step: 270, loss: 0.03712093085050583
step: 280, loss: 0.06346264481544495
step: 290, loss: 0.007837692275643349
step: 300, loss: 0.12791316211223602
step: 310, loss: 0.008139208890497684
step: 320, loss: 0.006748410407453775
step: 330, loss: 0.06919022649526596
step: 340, loss: 0.06732835620641708
step: 350, loss: 0.17866376042366028
step: 360, loss: 0.08639741688966751
step: 370, loss: 0.04553164541721344
step: 380, loss: 0.028516244143247604
step: 390, loss: 0.0033493200317025185
step: 400, loss: 0.012714363634586334
step: 410, loss: 0.00784572958946228
step: 420, loss: 0.07295253127813339
step: 430, loss: 0.00972827896475792
step: 440, loss: 0.068707175552845
step: 450, loss: 0.022359298542141914
step: 460, loss: 0.04082312807440758
epoch 5: dev_f1=0.9920903954802259, f1=0.9808342728297633, best_f1=0.9808342728297633
step: 0, loss: 0.02851911447942257
step: 10, loss: 0.09365320950746536
step: 20, loss: 0.012719604186713696
step: 30, loss: 0.013943896628916264
step: 40, loss: 0.06534452736377716
step: 50, loss: 0.023176398128271103
step: 60, loss: 0.020541587844491005
step: 70, loss: 0.014656505547463894
step: 80, loss: 0.09497611224651337
step: 90, loss: 0.002001785207539797
step: 100, loss: 0.0005764949019066989
step: 110, loss: 0.035967472940683365
step: 120, loss: 0.02491912432014942
step: 130, loss: 0.11389362066984177
step: 140, loss: 0.015095188282430172
step: 150, loss: 0.01469549722969532
step: 160, loss: 0.005694013554602861
step: 170, loss: 0.09180671721696854
step: 180, loss: 0.08181704580783844
step: 190, loss: 0.006309269927442074
step: 200, loss: 0.010056393221020699
step: 210, loss: 0.00937877967953682
step: 220, loss: 0.1434391885995865
step: 230, loss: 0.07119837403297424
step: 240, loss: 0.02255324274301529
step: 250, loss: 0.046562518924474716
step: 260, loss: 0.0703013613820076
step: 270, loss: 0.023799560964107513
step: 280, loss: 0.08554137498140335
step: 290, loss: 0.013277467340230942
step: 300, loss: 0.004136198665946722
step: 310, loss: 0.012957770377397537
step: 320, loss: 0.15837283432483673
step: 330, loss: 0.083983413875103
step: 340, loss: 0.0059105451218783855
step: 350, loss: 0.07703348249197006
step: 360, loss: 0.04631059616804123
step: 370, loss: 0.08907485008239746
step: 380, loss: 0.13017921149730682
step: 390, loss: 0.00392282847315073
step: 400, loss: 0.03191136568784714
step: 410, loss: 0.03514205291867256
step: 420, loss: 0.1124810054898262
step: 430, loss: 0.0864861011505127
step: 440, loss: 0.04543188586831093
step: 450, loss: 0.1345917135477066
step: 460, loss: 0.005811943672597408
epoch 6: dev_f1=0.9726651480637813, f1=0.9751131221719457, best_f1=0.9808342728297633
step: 0, loss: 0.004574071150273085
step: 10, loss: 0.016069479286670685
step: 20, loss: 0.01484924927353859
step: 30, loss: 0.05454900115728378
step: 40, loss: 0.01689746417105198
step: 50, loss: 0.011407488957047462
step: 60, loss: 0.010589615441858768
step: 70, loss: 0.168153315782547
step: 80, loss: 0.0822911188006401
step: 90, loss: 0.027247773483395576
step: 100, loss: 0.005120936315506697
step: 110, loss: 0.1618087887763977
step: 120, loss: 0.017671536654233932
step: 130, loss: 0.010115893557667732
step: 140, loss: 0.08495032787322998
step: 150, loss: 0.02773229219019413
step: 160, loss: 0.12351337820291519
step: 170, loss: 0.02416400983929634
step: 180, loss: 0.013799590989947319
step: 190, loss: 0.012723725289106369
step: 200, loss: 0.008938472718000412
step: 210, loss: 0.01023824978619814
step: 220, loss: 0.1690938025712967
step: 230, loss: 0.00273172021843493
step: 240, loss: 0.05653749406337738
step: 250, loss: 0.017519740387797356
step: 260, loss: 0.006166367791593075
step: 270, loss: 0.03218194097280502
step: 280, loss: 0.004773602820932865
step: 290, loss: 5.2056908316444606e-05
step: 300, loss: 0.00468860100954771
step: 310, loss: 0.04720984771847725
step: 320, loss: 0.05571632459759712
step: 330, loss: 0.02289065718650818
step: 340, loss: 0.004229402635246515
step: 350, loss: 0.06258412450551987
step: 360, loss: 0.0029472752939909697
step: 370, loss: 0.005681624170392752
step: 380, loss: 0.0892627164721489
step: 390, loss: 0.07185421139001846
step: 400, loss: 0.040833860635757446
step: 410, loss: 0.11679422110319138
step: 420, loss: 0.024612577632069588
step: 430, loss: 0.009043509140610695
step: 440, loss: 0.038990575820207596
step: 450, loss: 0.038416486233472824
step: 460, loss: 0.14002305269241333
epoch 7: dev_f1=0.995505617977528, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.06238348037004471
step: 10, loss: 0.14493419229984283
step: 20, loss: 0.07160824537277222
step: 30, loss: 0.07480326294898987
step: 40, loss: 0.014506105333566666
step: 50, loss: 0.01883443258702755
step: 60, loss: 0.0025858008302748203
step: 70, loss: 0.003830866888165474
step: 80, loss: 0.05561307445168495
step: 90, loss: 0.05408918485045433
step: 100, loss: 0.010096904821693897
step: 110, loss: 0.10589715093374252
step: 120, loss: 0.007005030754953623
step: 130, loss: 0.014072122983634472
step: 140, loss: 0.22535577416419983
step: 150, loss: 0.03599492460489273
step: 160, loss: 0.10114382952451706
step: 170, loss: 0.05529278144240379
step: 180, loss: 0.05931030213832855
step: 190, loss: 0.0345764122903347
step: 200, loss: 0.018014725297689438
step: 210, loss: 0.04038728401064873
step: 220, loss: 0.0049420250579714775
step: 230, loss: 0.011072706431150436
step: 240, loss: 0.0579928494989872
step: 250, loss: 0.02819834090769291
step: 260, loss: 0.019240468740463257
step: 270, loss: 0.01893317885696888
step: 280, loss: 0.03878152742981911
step: 290, loss: 0.1349296271800995
step: 300, loss: 0.07435853779315948
step: 310, loss: 0.08338745683431625
step: 320, loss: 0.0208226777613163
step: 330, loss: 0.0011546022724360228
step: 340, loss: 0.007659510709345341
step: 350, loss: 0.08944534510374069
step: 360, loss: 0.008274570107460022
step: 370, loss: 0.010140039958059788
step: 380, loss: 0.06864418089389801
step: 390, loss: 0.05696076154708862
step: 400, loss: 0.08211833983659744
step: 410, loss: 0.08358655124902725
step: 420, loss: 0.04052949324250221
step: 430, loss: 0.10487174987792969
step: 440, loss: 0.008679776452481747
step: 450, loss: 0.009464123286306858
step: 460, loss: 0.12027950584888458
epoch 8: dev_f1=0.995505617977528, f1=0.9832026875699889, best_f1=0.984304932735426
step: 0, loss: 0.028992604464292526
step: 10, loss: 0.04406890645623207
step: 20, loss: 0.1292935013771057
step: 30, loss: 0.033156007528305054
step: 40, loss: 0.005229421891272068
step: 50, loss: 0.013271236792206764
step: 60, loss: 0.009278986603021622
step: 70, loss: 0.1351483166217804
step: 80, loss: 0.008426561951637268
step: 90, loss: 0.03626522049307823
step: 100, loss: 0.02229508012533188
step: 110, loss: 0.0016827668296173215
step: 120, loss: 0.010271357372403145
step: 130, loss: 0.07703593373298645
step: 140, loss: 0.04351068288087845
step: 150, loss: 0.021490827202796936
step: 160, loss: 0.08245576918125153
step: 170, loss: 0.03577648848295212
step: 180, loss: 0.012425005435943604
step: 190, loss: 0.03908541053533554
step: 200, loss: 0.014403835870325565
step: 210, loss: 0.02789621241390705
step: 220, loss: 0.020242691040039062
step: 230, loss: 0.014749942347407341
step: 240, loss: 0.08146126568317413
step: 250, loss: 0.019285239279270172
step: 260, loss: 0.029737871140241623
step: 270, loss: 0.018394991755485535
step: 280, loss: 0.043042298406362534
step: 290, loss: 0.010379414074122906
step: 300, loss: 0.019098207354545593
step: 310, loss: 0.022150183096528053
step: 320, loss: 0.000852737866807729
step: 330, loss: 0.1433020681142807
step: 340, loss: 0.09965050220489502
step: 350, loss: 0.10538758337497711
step: 360, loss: 0.020865675061941147
step: 370, loss: 0.046514660120010376
step: 380, loss: 0.021793818101286888
step: 390, loss: 0.002230506855994463
step: 400, loss: 0.05118829756975174
step: 410, loss: 0.02222559228539467
step: 420, loss: 0.015082292258739471
step: 430, loss: 0.03822237625718117
step: 440, loss: 0.0370798222720623
step: 450, loss: 0.06917766481637955
step: 460, loss: 0.01614437997341156
epoch 9: dev_f1=0.9954954954954955, f1=0.9854096520763187, best_f1=0.984304932735426
step: 0, loss: 0.015810249373316765
step: 10, loss: 0.0010329531505703926
step: 20, loss: 0.12022417038679123
step: 30, loss: 0.04587989300489426
step: 40, loss: 0.049883320927619934
step: 50, loss: 0.01080274023115635
step: 60, loss: 0.09025205671787262
step: 70, loss: 0.0305867288261652
step: 80, loss: 0.029343392699956894
step: 90, loss: 0.10745855420827866
step: 100, loss: 0.10250773280858994
step: 110, loss: 0.040271367877721786
step: 120, loss: 0.06414993107318878
step: 130, loss: 0.0012408551992848516
step: 140, loss: 0.03603464365005493
step: 150, loss: 0.03360941633582115
step: 160, loss: 0.06627343595027924
step: 170, loss: 0.018408464267849922
step: 180, loss: 0.03977036848664284
step: 190, loss: 0.17779991030693054
step: 200, loss: 0.0005486748996190727
step: 210, loss: 0.006821720395237207
step: 220, loss: 0.05820300057530403
step: 230, loss: 0.010560999624431133
step: 240, loss: 0.04835043102502823
step: 250, loss: 0.043047092854976654
step: 260, loss: 0.0038664103485643864
step: 270, loss: 0.022990651428699493
step: 280, loss: 0.12173588573932648
step: 290, loss: 0.04560474678874016
step: 300, loss: 0.06817073374986649
step: 310, loss: 0.05590920150279999
step: 320, loss: 0.014820781536400318
step: 330, loss: 0.04436511918902397
step: 340, loss: 0.01212473213672638
step: 350, loss: 0.03530178591609001
step: 360, loss: 0.019370220601558685
step: 370, loss: 0.2768752872943878
step: 380, loss: 0.0007446043309755623
step: 390, loss: 0.015758275985717773
step: 400, loss: 0.009574157185852528
step: 410, loss: 0.030054517090320587
step: 420, loss: 0.0533587746322155
step: 430, loss: 0.046317171305418015
step: 440, loss: 0.01739552803337574
step: 450, loss: 0.07337336242198944
step: 460, loss: 0.02589636668562889
epoch 10: dev_f1=0.9898989898989898, f1=0.980963045912654, best_f1=0.984304932735426
step: 0, loss: 0.04199543967843056
step: 10, loss: 0.10104978084564209
step: 20, loss: 0.040752243250608444
step: 30, loss: 0.0017563763540238142
step: 40, loss: 0.09719041734933853
step: 50, loss: 0.025240007787942886
step: 60, loss: 0.011713453568518162
step: 70, loss: 0.0025543272495269775
step: 80, loss: 0.1394963264465332
step: 90, loss: 0.03110494278371334
step: 100, loss: 0.04728587716817856
step: 110, loss: 0.05266590788960457
step: 120, loss: 0.08185505867004395
step: 130, loss: 0.04240597411990166
step: 140, loss: 0.19780313968658447
step: 150, loss: 0.1048135980963707
step: 160, loss: 0.018268510699272156
step: 170, loss: 0.03038671426475048
step: 180, loss: 0.021468698978424072
step: 190, loss: 0.026785004884004593
step: 200, loss: 0.04158356413245201
step: 210, loss: 0.0011856588535010815
step: 220, loss: 0.05904916301369667
step: 230, loss: 0.0214302409440279
step: 240, loss: 0.02307834103703499
step: 250, loss: 0.045905422419309616
step: 260, loss: 0.02885139361023903
step: 270, loss: 0.04749888926744461
step: 280, loss: 0.05058839172124863
step: 290, loss: 0.002402041107416153
step: 300, loss: 0.009988997131586075
step: 310, loss: 0.014680198393762112
step: 320, loss: 0.05627553537487984
step: 330, loss: 0.034125857055187225
step: 340, loss: 0.023216931149363518
step: 350, loss: 0.037987884134054184
step: 360, loss: 0.07719027251005173
step: 370, loss: 0.000542293069884181
step: 380, loss: 0.07663395255804062
step: 390, loss: 0.0006398268742486835
step: 400, loss: 0.0571751669049263
step: 410, loss: 0.0007646709564141929
step: 420, loss: 0.0403454452753067
step: 430, loss: 0.14932012557983398
step: 440, loss: 0.03358041122555733
step: 450, loss: 0.006716769654303789
step: 460, loss: 0.09671631455421448
epoch 11: dev_f1=0.9920903954802259, f1=0.9831271091113611, best_f1=0.984304932735426
step: 0, loss: 0.0647246465086937
step: 10, loss: 0.044224370270967484
step: 20, loss: 0.016217650845646858
step: 30, loss: 0.2432347685098648
step: 40, loss: 0.015109452418982983
step: 50, loss: 0.04135170578956604
step: 60, loss: 0.041809286922216415
step: 70, loss: 0.059282880276441574
step: 80, loss: 0.013299820013344288
step: 90, loss: 0.007533762603998184
step: 100, loss: 0.06278470903635025
step: 110, loss: 0.04669153317809105
step: 120, loss: 0.028368351981043816
step: 130, loss: 0.02124784141778946
step: 140, loss: 0.029254790395498276
step: 150, loss: 0.06267758458852768
step: 160, loss: 0.014936677180230618
step: 170, loss: 0.015589391812682152
step: 180, loss: 4.4245607568882406e-05
step: 190, loss: 0.13034659624099731
step: 200, loss: 0.0001251614885404706
step: 210, loss: 0.0005052545457147062
step: 220, loss: 0.035958558320999146
step: 230, loss: 0.07523272186517715
step: 240, loss: 0.019399382174015045
step: 250, loss: 0.14930418133735657
step: 260, loss: 0.004262097179889679
step: 270, loss: 0.07482214272022247
step: 280, loss: 0.00022644034470431507
step: 290, loss: 0.03189779445528984
step: 300, loss: 0.057050321251153946
step: 310, loss: 0.00391878467053175
step: 320, loss: 0.024178994819521904
step: 330, loss: 0.017559785395860672
step: 340, loss: 0.0220666341483593
step: 350, loss: 0.05904264748096466
step: 360, loss: 0.0002684645587578416
step: 370, loss: 0.009741692803800106
step: 380, loss: 0.0009789778850972652
step: 390, loss: 0.04117729887366295
step: 400, loss: 0.10095786303281784
step: 410, loss: 0.012482210993766785
step: 420, loss: 0.0033073122613132
step: 430, loss: 0.028968818485736847
step: 440, loss: 0.00017429504077881575
step: 450, loss: 0.011413881555199623
step: 460, loss: 0.003123070113360882
epoch 12: dev_f1=0.9943757030371203, f1=0.9831649831649831, best_f1=0.984304932735426
step: 0, loss: 0.03566427901387215
step: 10, loss: 0.08645718544721603
step: 20, loss: 0.0007586136925965548
step: 30, loss: 0.027805741876363754
step: 40, loss: 0.0012677260674536228
step: 50, loss: 0.02450001984834671
step: 60, loss: 0.004274788312613964
step: 70, loss: 0.05657954514026642
step: 80, loss: 0.04791304096579552
step: 90, loss: 0.041849687695503235
step: 100, loss: 0.04731244221329689
step: 110, loss: 0.00016965853865258396
step: 120, loss: 0.22723270952701569
step: 130, loss: 0.00027406879235059023
step: 140, loss: 0.025874361395835876
step: 150, loss: 0.02316083014011383
step: 160, loss: 0.00020165336900390685
step: 170, loss: 0.0007249281043186784
step: 180, loss: 0.001560552162118256
step: 190, loss: 0.04238993301987648
step: 200, loss: 0.07085298001766205
step: 210, loss: 0.020131129771471024
step: 220, loss: 0.025049971416592598
step: 230, loss: 0.008572956547141075
step: 240, loss: 0.00011450189049355686
step: 250, loss: 0.008869984187185764
step: 260, loss: 0.08842405676841736
step: 270, loss: 0.003190422197803855
step: 280, loss: 0.08452361077070236
step: 290, loss: 0.004132519476115704
step: 300, loss: 0.021397195756435394
step: 310, loss: 0.02525554597377777
step: 320, loss: 0.0001550705055706203
step: 330, loss: 0.01015067845582962
step: 340, loss: 0.036646768450737
step: 350, loss: 0.016079969704151154
step: 360, loss: 0.026942504569888115
step: 370, loss: 0.0002679237222764641
step: 380, loss: 0.04294022545218468
step: 390, loss: 4.358909427537583e-05
step: 400, loss: 0.024879593402147293
step: 410, loss: 0.05499626323580742
step: 420, loss: 0.12907660007476807
step: 430, loss: 0.000652849324978888
step: 440, loss: 0.027265440672636032
step: 450, loss: 0.03952296823263168
step: 460, loss: 0.00021223898511379957
epoch 13: dev_f1=0.9932432432432432, f1=0.9820627802690582, best_f1=0.984304932735426
step: 0, loss: 0.06575071066617966
step: 10, loss: 0.036203283816576004
step: 20, loss: 0.04732184857130051
step: 30, loss: 0.05707059055566788
step: 40, loss: 0.09863721579313278
step: 50, loss: 0.02405574731528759
step: 60, loss: 0.01985972560942173
step: 70, loss: 0.0002388738066656515
step: 80, loss: 0.044457800686359406
step: 90, loss: 0.06533458083868027
step: 100, loss: 0.001956431893631816
step: 110, loss: 0.020815152674913406
step: 120, loss: 0.000542232533916831
step: 130, loss: 0.025661267340183258
step: 140, loss: 0.0006519544404000044
step: 150, loss: 0.00010412057599751279
step: 160, loss: 0.0013758600689470768
step: 170, loss: 0.031582627445459366
step: 180, loss: 0.004455939866602421
step: 190, loss: 0.026339616626501083
step: 200, loss: 0.002233837964013219
step: 210, loss: 0.054505348205566406
step: 220, loss: 0.011245225556194782
step: 230, loss: 0.0003388500481378287
step: 240, loss: 0.08745406568050385
step: 250, loss: 0.000141248558065854
step: 260, loss: 0.00022709622862748802
step: 270, loss: 0.0418093241751194
step: 280, loss: 0.0002694759168662131
step: 290, loss: 0.0001040010029100813
step: 300, loss: 0.043088313192129135
step: 310, loss: 0.00955031905323267
step: 320, loss: 0.01108404528349638
step: 330, loss: 0.058344367891550064
step: 340, loss: 0.04353908449411392
step: 350, loss: 0.019070984795689583
step: 360, loss: 0.021233921870589256
step: 370, loss: 0.0003381230344530195
step: 380, loss: 0.005962015129625797
step: 390, loss: 0.001761879539117217
step: 400, loss: 0.0008371415897272527
step: 410, loss: 0.0005265860236249864
step: 420, loss: 0.053588852286338806
step: 430, loss: 0.02841276116669178
step: 440, loss: 0.038328614085912704
step: 450, loss: 0.034236352890729904
step: 460, loss: 0.05147692188620567
epoch 14: dev_f1=0.9932584269662922, f1=0.9798657718120806, best_f1=0.984304932735426
step: 0, loss: 0.03820560500025749
step: 10, loss: 0.019698824733495712
step: 20, loss: 0.013392183929681778
step: 30, loss: 0.05267111584544182
step: 40, loss: 0.021206073462963104
step: 50, loss: 0.05480499193072319
step: 60, loss: 0.10144249349832535
step: 70, loss: 0.02466314658522606
step: 80, loss: 0.0011201652232557535
step: 90, loss: 0.06773586571216583
step: 100, loss: 0.049260787665843964
step: 110, loss: 0.00011120975250378251
step: 120, loss: 0.03930553421378136
step: 130, loss: 0.031193017959594727
step: 140, loss: 0.1449017971754074
step: 150, loss: 0.04328446090221405
step: 160, loss: 0.0522681400179863
step: 170, loss: 0.040916670113801956
step: 180, loss: 0.020859379321336746
step: 190, loss: 0.00015462067676708102
step: 200, loss: 0.008168185129761696
step: 210, loss: 0.002762703923508525
step: 220, loss: 0.043958134949207306
step: 230, loss: 0.0008632914396002889
step: 240, loss: 7.915998867247254e-05
step: 250, loss: 5.4186966735869646e-05
step: 260, loss: 0.015442085452377796
step: 270, loss: 0.040487173944711685
step: 280, loss: 4.497581903706305e-05
step: 290, loss: 1.8782582628773525e-05
step: 300, loss: 0.03444558009505272
step: 310, loss: 0.001023499178700149
step: 320, loss: 0.06697200238704681
step: 330, loss: 0.00039279143675230443
step: 340, loss: 8.691492257639766e-05
step: 350, loss: 0.029513603076338768
step: 360, loss: 7.688887126278132e-05
step: 370, loss: 5.1192862883908674e-05
step: 380, loss: 0.03183066099882126
step: 390, loss: 0.039931606501340866
step: 400, loss: 0.04271218180656433
step: 410, loss: 0.0004556370840873569
step: 420, loss: 0.0023864905815571547
step: 430, loss: 0.02636403776705265
step: 440, loss: 5.9286379837431014e-05
step: 450, loss: 0.029832538217306137
step: 460, loss: 4.47064740001224e-05
epoch 15: dev_f1=0.9943630214205187, f1=0.9831649831649831, best_f1=0.984304932735426
step: 0, loss: 0.00014767705579288304
step: 10, loss: 0.01703084073960781
step: 20, loss: 0.019667575135827065
step: 30, loss: 0.008836639113724232
step: 40, loss: 0.042385272681713104
step: 50, loss: 3.734858546522446e-05
step: 60, loss: 2.4437089450657368e-05
step: 70, loss: 0.02288137376308441
step: 80, loss: 0.06539677083492279
step: 90, loss: 0.018098315224051476
step: 100, loss: 0.021538035944104195
step: 110, loss: 0.061332084238529205
step: 120, loss: 0.028487615287303925
step: 130, loss: 0.12699469923973083
step: 140, loss: 0.0002959619159810245
step: 150, loss: 0.0001918951456900686
step: 160, loss: 0.00011959174298681319
step: 170, loss: 0.02044459618628025
step: 180, loss: 4.201227784506045e-05
step: 190, loss: 0.04080656170845032
step: 200, loss: 0.04791627079248428
step: 210, loss: 0.00014941146946512163
step: 220, loss: 0.00018800438556354493
step: 230, loss: 0.021691910922527313
step: 240, loss: 0.01841723918914795
step: 250, loss: 0.026775505393743515
step: 260, loss: 0.0014005927368998528
step: 270, loss: 0.014153141528367996
step: 280, loss: 0.0036143376491963863
step: 290, loss: 0.07712210714817047
step: 300, loss: 0.043370455503463745
step: 310, loss: 0.0620281808078289
step: 320, loss: 6.241996015887707e-05
step: 330, loss: 0.0005886523867957294
step: 340, loss: 0.0253189355134964
step: 350, loss: 6.397537072189152e-05
step: 360, loss: 0.054359983652830124
step: 370, loss: 0.05467650666832924
step: 380, loss: 0.019639581441879272
step: 390, loss: 0.03257090598344803
step: 400, loss: 0.039873793721199036
step: 410, loss: 0.00014554023800883442
step: 420, loss: 0.06432781368494034
step: 430, loss: 5.521648927242495e-05
step: 440, loss: 1.1507308954605833e-05
step: 450, loss: 0.0221919734030962
step: 460, loss: 0.048289377242326736
epoch 16: dev_f1=0.9932279909706545, f1=0.9808773903262092, best_f1=0.984304932735426
step: 0, loss: 0.04260602220892906
step: 10, loss: 1.9370709196664393e-05
step: 20, loss: 0.03086007386445999
step: 30, loss: 3.165789530612528e-05
step: 40, loss: 0.045305266976356506
step: 50, loss: 0.02180302143096924
step: 60, loss: 0.021754974499344826
step: 70, loss: 0.08741005510091782
step: 80, loss: 0.029534978792071342
step: 90, loss: 0.003574324306100607
step: 100, loss: 0.04724360257387161
step: 110, loss: 0.00399950984865427
step: 120, loss: 0.0001500338694313541
step: 130, loss: 0.0001031111751217395
step: 140, loss: 0.02120302990078926
step: 150, loss: 8.116831304505467e-05
step: 160, loss: 3.4287575545022264e-05
step: 170, loss: 0.02275475300848484
step: 180, loss: 0.0003099966561421752
step: 190, loss: 0.07571271806955338
step: 200, loss: 0.008494681678712368
step: 210, loss: 0.04747384041547775
step: 220, loss: 5.172809323994443e-05
step: 230, loss: 0.00017722031043376774
step: 240, loss: 0.014257695525884628
step: 250, loss: 0.02630285732448101
step: 260, loss: 3.086161450482905e-05
step: 270, loss: 0.05092817172408104
step: 280, loss: 0.025081992149353027
step: 290, loss: 0.02203604392707348
step: 300, loss: 0.02196909300982952
step: 310, loss: 0.05940677598118782
step: 320, loss: 3.1539420888293535e-05
step: 330, loss: 0.019979804754257202
step: 340, loss: 0.026982292532920837
step: 350, loss: 0.06906942278146744
step: 360, loss: 0.02673397958278656
step: 370, loss: 2.442575350869447e-05
step: 380, loss: 0.023298291489481926
step: 390, loss: 0.020892050117254257
step: 400, loss: 2.15014679270098e-05
step: 410, loss: 0.03758475184440613
step: 420, loss: 0.02101237326860428
step: 430, loss: 3.283811020082794e-05
step: 440, loss: 5.616832277155481e-05
step: 450, loss: 9.81492266873829e-05
step: 460, loss: 0.022254500538110733
epoch 17: dev_f1=0.9932279909706545, f1=0.9808773903262092, best_f1=0.984304932735426
step: 0, loss: 0.009805957786738873
step: 10, loss: 0.024155929684638977
step: 20, loss: 0.00014025501150172204
step: 30, loss: 0.0002038173406617716
step: 40, loss: 0.022745784372091293
step: 50, loss: 0.022115301340818405
step: 60, loss: 0.03213901072740555
step: 70, loss: 0.03858127444982529
step: 80, loss: 0.00010666504385881126
step: 90, loss: 0.018719667568802834
step: 100, loss: 0.05802591145038605
step: 110, loss: 0.019634267315268517
step: 120, loss: 4.600619649863802e-05
step: 130, loss: 0.00011251873365836218
step: 140, loss: 0.02207895927131176
step: 150, loss: 0.04032904654741287
step: 160, loss: 0.023742852732539177
step: 170, loss: 0.02041209489107132
step: 180, loss: 0.02727447636425495
step: 190, loss: 0.04644862934947014
step: 200, loss: 0.02024225704371929
step: 210, loss: 0.025012938305735588
step: 220, loss: 0.00010330366785638034
step: 230, loss: 0.02176683396100998
step: 240, loss: 1.921735383803025e-05
step: 250, loss: 0.01969805732369423
step: 260, loss: 0.048280019313097
step: 270, loss: 7.331153756240383e-05
step: 280, loss: 0.037393972277641296
step: 290, loss: 0.005929355509579182
step: 300, loss: 9.566055086907e-05
step: 310, loss: 0.06477313488721848
step: 320, loss: 0.052808135747909546
step: 330, loss: 9.000313730211928e-05
step: 340, loss: 0.020880622789263725
step: 350, loss: 0.05793022736907005
step: 360, loss: 0.04680771753191948
step: 370, loss: 0.004897073842585087
step: 380, loss: 0.05966053530573845
step: 390, loss: 0.02925633266568184
step: 400, loss: 0.04901742935180664
step: 410, loss: 2.4704708266654052e-05
step: 420, loss: 0.0215954277664423
step: 430, loss: 0.029383812099695206
step: 440, loss: 0.020548205822706223
step: 450, loss: 0.04307715222239494
step: 460, loss: 0.044988151639699936
epoch 18: dev_f1=0.9932279909706545, f1=0.9820224719101124, best_f1=0.984304932735426
step: 0, loss: 0.042706720530986786
step: 10, loss: 2.343842243135441e-05
step: 20, loss: 0.04708399996161461
step: 30, loss: 0.015682732686400414
step: 40, loss: 0.06443627923727036
step: 50, loss: 6.820410635555163e-05
step: 60, loss: 0.04195311293005943
step: 70, loss: 0.022154251113533974
step: 80, loss: 0.023353923112154007
step: 90, loss: 0.020284859463572502
step: 100, loss: 0.022703366354107857
step: 110, loss: 0.020930128172039986
step: 120, loss: 0.03052804432809353
step: 130, loss: 0.022358283400535583
step: 140, loss: 2.0551709894789383e-05
step: 150, loss: 0.00010545185068622231
step: 160, loss: 0.02186695858836174
step: 170, loss: 0.014797516167163849
step: 180, loss: 0.019640281796455383
step: 190, loss: 0.04608491063117981
step: 200, loss: 0.02252763696014881
step: 210, loss: 0.04177648201584816
step: 220, loss: 0.04261394217610359
step: 230, loss: 0.021627351641654968
step: 240, loss: 0.0007978789508342743
step: 250, loss: 0.061589889228343964
step: 260, loss: 0.1173662394285202
step: 270, loss: 0.020759304985404015
step: 280, loss: 0.0005775333847850561
step: 290, loss: 4.938437632517889e-05
step: 300, loss: 2.7151267204317264e-05
step: 310, loss: 0.046942587941884995
step: 320, loss: 0.02141503617167473
step: 330, loss: 0.022027522325515747
step: 340, loss: 0.06849802285432816
step: 350, loss: 0.0005536729586310685
step: 360, loss: 0.022345250472426414
step: 370, loss: 1.564973354106769e-05
step: 380, loss: 2.8503385692602023e-05
step: 390, loss: 0.00011155763058923185
step: 400, loss: 0.05972936376929283
step: 410, loss: 6.021022272761911e-05
step: 420, loss: 0.00018109861412085593
step: 430, loss: 0.029767587780952454
step: 440, loss: 0.02069775201380253
step: 450, loss: 0.02163839340209961
step: 460, loss: 2.999371827172581e-05
epoch 19: dev_f1=0.9943630214205187, f1=0.9820627802690582, best_f1=0.984304932735426
step: 0, loss: 0.06122509017586708
step: 10, loss: 0.04298963397741318
step: 20, loss: 0.023470908403396606
step: 30, loss: 0.04094228520989418
step: 40, loss: 0.06295129656791687
step: 50, loss: 0.04870428517460823
step: 60, loss: 0.02228992059826851
step: 70, loss: 0.021540852263569832
step: 80, loss: 8.210921077989042e-05
step: 90, loss: 0.022919388487935066
step: 100, loss: 0.055372752249240875
step: 110, loss: 0.0002089790505124256
step: 120, loss: 0.021544739603996277
step: 130, loss: 4.631571937352419e-05
step: 140, loss: 0.07997886836528778
step: 150, loss: 5.057164889876731e-05
step: 160, loss: 0.04261258617043495
step: 170, loss: 0.021187754347920418
step: 180, loss: 0.008915293961763382
step: 190, loss: 3.2690986699890345e-05
step: 200, loss: 0.021796878427267075
step: 210, loss: 0.0233499426394701
step: 220, loss: 1.1861193343065679e-05
step: 230, loss: 0.00010099240898853168
step: 240, loss: 0.04555895924568176
step: 250, loss: 0.044223371893167496
step: 260, loss: 0.021360963582992554
step: 270, loss: 0.041088320314884186
step: 280, loss: 0.0652550533413887
step: 290, loss: 0.04778984561562538
step: 300, loss: 0.015471305698156357
step: 310, loss: 6.775591464247555e-05
step: 320, loss: 0.010455991141498089
step: 330, loss: 0.053879983723163605
step: 340, loss: 0.04855674132704735
step: 350, loss: 2.526161006244365e-05
step: 360, loss: 0.023828480392694473
step: 370, loss: 3.177943654009141e-05
step: 380, loss: 0.016054213047027588
step: 390, loss: 0.10492395609617233
step: 400, loss: 6.223903619684279e-05
step: 410, loss: 2.6781504857353866e-05
step: 420, loss: 0.014597260393202305
step: 430, loss: 5.317686009220779e-05
step: 440, loss: 0.05723658576607704
step: 450, loss: 0.025680603459477425
step: 460, loss: 2.84289380942937e-05
epoch 20: dev_f1=0.9943630214205187, f1=0.9831649831649831, best_f1=0.984304932735426
