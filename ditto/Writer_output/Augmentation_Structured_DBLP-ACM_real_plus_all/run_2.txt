cuda
Device: cuda
step: 0, loss: 0.9250515699386597
step: 10, loss: 0.3928227722644806
step: 20, loss: 0.3813715875148773
step: 30, loss: 0.6194724440574646
step: 40, loss: 0.5316977500915527
step: 50, loss: 0.32152000069618225
step: 60, loss: 0.4527851343154907
step: 70, loss: 0.19949518144130707
step: 80, loss: 0.20517121255397797
step: 90, loss: 0.05147920176386833
step: 100, loss: 0.1589672863483429
step: 110, loss: 0.11262891441583633
step: 120, loss: 0.19754883646965027
step: 130, loss: 0.106618732213974
step: 140, loss: 0.08653511106967926
step: 150, loss: 0.1119365319609642
step: 160, loss: 0.022076303139328957
step: 170, loss: 0.040022436529397964
step: 180, loss: 0.07649414241313934
step: 190, loss: 0.16679790616035461
step: 200, loss: 0.021824365481734276
step: 210, loss: 0.11048250645399094
step: 220, loss: 0.08149819821119308
step: 230, loss: 0.04877414181828499
step: 240, loss: 0.11418288946151733
step: 250, loss: 0.1012972742319107
step: 260, loss: 0.13314075767993927
step: 270, loss: 0.07364456355571747
step: 280, loss: 0.03128523379564285
step: 290, loss: 0.03242408484220505
step: 300, loss: 0.05878514423966408
step: 310, loss: 0.01254979893565178
step: 320, loss: 0.045310620218515396
step: 330, loss: 0.1441756784915924
step: 340, loss: 0.1315360814332962
step: 350, loss: 0.11601470410823822
step: 360, loss: 0.1262502372264862
step: 370, loss: 0.11949976533651352
step: 380, loss: 0.019884424284100533
step: 390, loss: 0.021701453253626823
step: 400, loss: 0.038747645914554596
step: 410, loss: 0.110179603099823
step: 420, loss: 0.07337246090173721
step: 430, loss: 0.027957143262028694
step: 440, loss: 0.05950627848505974
step: 450, loss: 0.05916866660118103
step: 460, loss: 0.09321250021457672
epoch 1: dev_f1=0.9865470852017937, f1=0.9830890642615557, best_f1=0.9830890642615557
step: 0, loss: 0.20627233386039734
step: 10, loss: 0.055571362376213074
step: 20, loss: 0.08177119493484497
step: 30, loss: 0.05811123549938202
step: 40, loss: 0.1191578283905983
step: 50, loss: 0.06812425702810287
step: 60, loss: 0.01058423426002264
step: 70, loss: 0.08626049757003784
step: 80, loss: 0.10501105338335037
step: 90, loss: 0.1753830462694168
step: 100, loss: 0.029684782028198242
step: 110, loss: 0.040116842836141586
step: 120, loss: 0.05978104844689369
step: 130, loss: 0.025335581973195076
step: 140, loss: 0.2777789235115051
step: 150, loss: 0.11292710900306702
step: 160, loss: 0.111866794526577
step: 170, loss: 0.056435707956552505
step: 180, loss: 0.010289589874446392
step: 190, loss: 0.062265828251838684
step: 200, loss: 0.08648262917995453
step: 210, loss: 0.06009257584810257
step: 220, loss: 0.16017499566078186
step: 230, loss: 0.060531411319971085
step: 240, loss: 0.07792695611715317
step: 250, loss: 0.010656876489520073
step: 260, loss: 0.0200046394020319
step: 270, loss: 0.07722488045692444
step: 280, loss: 0.06416154652833939
step: 290, loss: 0.10043615847826004
step: 300, loss: 0.027946902438998222
step: 310, loss: 0.17583045363426208
step: 320, loss: 0.05690876767039299
step: 330, loss: 0.09854741394519806
step: 340, loss: 0.1505500078201294
step: 350, loss: 0.016878485679626465
step: 360, loss: 0.02536115236580372
step: 370, loss: 0.07353083789348602
step: 380, loss: 0.010663270018994808
step: 390, loss: 0.007429775781929493
step: 400, loss: 0.012225977145135403
step: 410, loss: 0.017587263137102127
step: 420, loss: 0.05667136609554291
step: 430, loss: 0.09204957634210587
step: 440, loss: 0.18033847212791443
step: 450, loss: 0.08384693413972855
step: 460, loss: 0.025870637968182564
epoch 2: dev_f1=0.9943502824858756, f1=0.9852774631936579, best_f1=0.9852774631936579
step: 0, loss: 0.028092145919799805
step: 10, loss: 0.06257665902376175
step: 20, loss: 0.0696941465139389
step: 30, loss: 0.01957409642636776
step: 40, loss: 0.04340967908501625
step: 50, loss: 0.14114172756671906
step: 60, loss: 0.014924246817827225
step: 70, loss: 0.03176182880997658
step: 80, loss: 0.07328464090824127
step: 90, loss: 0.04461095482110977
step: 100, loss: 0.028308434411883354
step: 110, loss: 0.07222653180360794
step: 120, loss: 0.11767009645700455
step: 130, loss: 0.08923054486513138
step: 140, loss: 0.06795245409011841
step: 150, loss: 0.00791962817311287
step: 160, loss: 0.01571999303996563
step: 170, loss: 0.03417089208960533
step: 180, loss: 0.09450539201498032
step: 190, loss: 0.06787189096212387
step: 200, loss: 0.01863355003297329
step: 210, loss: 0.06689465045928955
step: 220, loss: 0.018688853830099106
step: 230, loss: 0.12980906665325165
step: 240, loss: 0.03529844805598259
step: 250, loss: 0.015114545822143555
step: 260, loss: 0.012811383232474327
step: 270, loss: 0.11938676983118057
step: 280, loss: 0.021909983828663826
step: 290, loss: 0.07694936543703079
step: 300, loss: 0.11725866049528122
step: 310, loss: 0.02338896319270134
step: 320, loss: 0.07744182646274567
step: 330, loss: 0.02043849043548107
step: 340, loss: 0.017113694921135902
step: 350, loss: 0.067853644490242
step: 360, loss: 0.16267570853233337
step: 370, loss: 0.06807570159435272
step: 380, loss: 0.08194120973348618
step: 390, loss: 0.026895737275481224
step: 400, loss: 0.056451961398124695
step: 410, loss: 0.014703402295708656
step: 420, loss: 0.03202679753303528
step: 430, loss: 0.06441216915845871
step: 440, loss: 0.039502933621406555
step: 450, loss: 0.07767899334430695
step: 460, loss: 0.08846074342727661
epoch 3: dev_f1=0.9920903954802259, f1=0.9852440408626559, best_f1=0.9852774631936579
step: 0, loss: 0.014433405362069607
step: 10, loss: 0.005912805907428265
step: 20, loss: 0.012212827801704407
step: 30, loss: 0.07062970846891403
step: 40, loss: 0.10071875154972076
step: 50, loss: 0.012182527221739292
step: 60, loss: 0.08506207913160324
step: 70, loss: 0.21217390894889832
step: 80, loss: 0.07217215746641159
step: 90, loss: 0.021342555060982704
step: 100, loss: 0.118415467441082
step: 110, loss: 0.022621670737862587
step: 120, loss: 0.02667594701051712
step: 130, loss: 0.07013490051031113
step: 140, loss: 0.00683612423017621
step: 150, loss: 0.028589367866516113
step: 160, loss: 0.006636816542595625
step: 170, loss: 0.03489866107702255
step: 180, loss: 0.02682996541261673
step: 190, loss: 0.07257112115621567
step: 200, loss: 0.015266714617609978
step: 210, loss: 0.005522278603166342
step: 220, loss: 0.007129769306629896
step: 230, loss: 0.03146985545754433
step: 240, loss: 0.01673722453415394
step: 250, loss: 0.04999884217977524
step: 260, loss: 0.009801525622606277
step: 270, loss: 0.011977048590779305
step: 280, loss: 0.021362191066145897
step: 290, loss: 0.05884088948369026
step: 300, loss: 0.012597381137311459
step: 310, loss: 0.014036953449249268
step: 320, loss: 0.06293809413909912
step: 330, loss: 0.1470632255077362
step: 340, loss: 0.08348890393972397
step: 350, loss: 0.07824336737394333
step: 360, loss: 0.009825444780290127
step: 370, loss: 0.17919771373271942
step: 380, loss: 0.02601885423064232
step: 390, loss: 0.0063563198782503605
step: 400, loss: 0.08242355287075043
step: 410, loss: 0.19247011840343475
step: 420, loss: 0.012509461492300034
step: 430, loss: 0.04102396219968796
step: 440, loss: 5.58464162168093e-05
step: 450, loss: 0.008458067663013935
step: 460, loss: 0.05223452299833298
epoch 4: dev_f1=0.9909706546275394, f1=0.9863945578231292, best_f1=0.9852774631936579
step: 0, loss: 0.080347940325737
step: 10, loss: 0.05255051329731941
step: 20, loss: 0.007848129607737064
step: 30, loss: 0.03756742179393768
step: 40, loss: 0.042525310069322586
step: 50, loss: 0.00613511074334383
step: 60, loss: 0.060838036239147186
step: 70, loss: 0.02945036254823208
step: 80, loss: 0.02128029428422451
step: 90, loss: 0.022230910137295723
step: 100, loss: 0.008480829186737537
step: 110, loss: 0.10674240440130234
step: 120, loss: 0.015765361487865448
step: 130, loss: 0.15104758739471436
step: 140, loss: 0.028643708676099777
step: 150, loss: 0.03316740691661835
step: 160, loss: 0.02391343005001545
step: 170, loss: 0.012111344374716282
step: 180, loss: 0.014839292503893375
step: 190, loss: 0.00617402046918869
step: 200, loss: 0.005312188994139433
step: 210, loss: 0.06358607113361359
step: 220, loss: 0.02308807708323002
step: 230, loss: 0.005101302172988653
step: 240, loss: 0.10983698070049286
step: 250, loss: 0.053409334272146225
step: 260, loss: 0.020641352981328964
step: 270, loss: 0.06852316111326218
step: 280, loss: 0.12801504135131836
step: 290, loss: 0.007862286642193794
step: 300, loss: 0.1373656541109085
step: 310, loss: 0.0043961540795862675
step: 320, loss: 0.0061479914002120495
step: 330, loss: 0.0671573355793953
step: 340, loss: 0.04540314897894859
step: 350, loss: 0.024846293032169342
step: 360, loss: 0.09073595702648163
step: 370, loss: 0.046957388520240784
step: 380, loss: 0.0394790843129158
step: 390, loss: 0.004665422718971968
step: 400, loss: 0.015426728874444962
step: 410, loss: 0.008512924425303936
step: 420, loss: 0.06970485299825668
step: 430, loss: 0.003141005989164114
step: 440, loss: 0.06443001329898834
step: 450, loss: 0.01809702254831791
step: 460, loss: 0.05258502438664436
epoch 5: dev_f1=0.9920903954802259, f1=0.9808342728297633, best_f1=0.9852774631936579
step: 0, loss: 0.019411960616707802
step: 10, loss: 0.08871573954820633
step: 20, loss: 0.010611922480165958
step: 30, loss: 0.01629975065588951
step: 40, loss: 0.08334893733263016
step: 50, loss: 0.018950525671243668
step: 60, loss: 0.026141665875911713
step: 70, loss: 0.015147709287703037
step: 80, loss: 0.13061191141605377
step: 90, loss: 0.0032153907231986523
step: 100, loss: 0.005308174528181553
step: 110, loss: 0.07884828001260757
step: 120, loss: 0.03642348572611809
step: 130, loss: 0.1142306923866272
step: 140, loss: 0.02058333158493042
step: 150, loss: 0.014990275725722313
step: 160, loss: 0.0035513220354914665
step: 170, loss: 0.08275345712900162
step: 180, loss: 0.07550027966499329
step: 190, loss: 0.011721350252628326
step: 200, loss: 0.008944698609411716
step: 210, loss: 0.01341644674539566
step: 220, loss: 0.07196270674467087
step: 230, loss: 0.06387346237897873
step: 240, loss: 0.02227715216577053
step: 250, loss: 0.050808314234018326
step: 260, loss: 0.07339650392532349
step: 270, loss: 0.021133193746209145
step: 280, loss: 0.1670100837945938
step: 290, loss: 0.01373984944075346
step: 300, loss: 0.006034973077476025
step: 310, loss: 0.01855732500553131
step: 320, loss: 0.1621304154396057
step: 330, loss: 0.06922521442174911
step: 340, loss: 0.004746970254927874
step: 350, loss: 0.07551337778568268
step: 360, loss: 0.04001455754041672
step: 370, loss: 0.08814522624015808
step: 380, loss: 0.10530632734298706
step: 390, loss: 0.005821458529680967
step: 400, loss: 0.039679303765296936
step: 410, loss: 0.030751733109354973
step: 420, loss: 0.1119343638420105
step: 430, loss: 0.0690881758928299
step: 440, loss: 0.04644075408577919
step: 450, loss: 0.1293228566646576
step: 460, loss: 0.0204179510474205
epoch 6: dev_f1=0.9898762654668166, f1=0.9819413092550789, best_f1=0.9852774631936579
step: 0, loss: 0.0039771306328475475
step: 10, loss: 0.016530649736523628
step: 20, loss: 0.016161300241947174
step: 30, loss: 0.059876326471567154
step: 40, loss: 0.027639949694275856
step: 50, loss: 0.018188420683145523
step: 60, loss: 0.0075351521372795105
step: 70, loss: 0.06966068595647812
step: 80, loss: 0.07468010485172272
step: 90, loss: 0.046444423496723175
step: 100, loss: 0.005062670912593603
step: 110, loss: 0.09507162123918533
step: 120, loss: 0.022185057401657104
step: 130, loss: 0.04603452980518341
step: 140, loss: 0.07227672636508942
step: 150, loss: 0.014450712129473686
step: 160, loss: 0.07700648903846741
step: 170, loss: 0.029261454939842224
step: 180, loss: 0.0158399511128664
step: 190, loss: 0.014848008751869202
step: 200, loss: 0.008499985560774803
step: 210, loss: 0.04062225669622421
step: 220, loss: 0.21105118095874786
step: 230, loss: 0.04970122128725052
step: 240, loss: 0.06395234167575836
step: 250, loss: 0.023249147459864616
step: 260, loss: 0.027743296697735786
step: 270, loss: 0.017432130873203278
step: 280, loss: 0.0059323739260435104
step: 290, loss: 8.811245061224326e-05
step: 300, loss: 0.00588961923494935
step: 310, loss: 0.024927319958806038
step: 320, loss: 0.05745028704404831
step: 330, loss: 0.02104073017835617
step: 340, loss: 0.03241454064846039
step: 350, loss: 0.08309422433376312
step: 360, loss: 0.00427237106487155
step: 370, loss: 0.005522661376744509
step: 380, loss: 0.07507255673408508
step: 390, loss: 0.07688562572002411
step: 400, loss: 0.043775759637355804
step: 410, loss: 0.12218653410673141
step: 420, loss: 0.01793954148888588
step: 430, loss: 0.00553872948512435
step: 440, loss: 0.05495035648345947
step: 450, loss: 0.03251023218035698
step: 460, loss: 0.12870532274246216
epoch 7: dev_f1=0.992108229988726, f1=0.9875706214689265, best_f1=0.9852774631936579
step: 0, loss: 0.0743681788444519
step: 10, loss: 0.14096297323703766
step: 20, loss: 0.07683809846639633
step: 30, loss: 0.09089049696922302
step: 40, loss: 0.013159381225705147
step: 50, loss: 0.02262699045240879
step: 60, loss: 0.00831373780965805
step: 70, loss: 0.005488205701112747
step: 80, loss: 0.0783369243144989
step: 90, loss: 0.03844083100557327
step: 100, loss: 0.02839650958776474
step: 110, loss: 0.059420786798000336
step: 120, loss: 0.004796805325895548
step: 130, loss: 0.012218577787280083
step: 140, loss: 0.2556556761264801
step: 150, loss: 0.06665878742933273
step: 160, loss: 0.10968279093503952
step: 170, loss: 0.05909332260489464
step: 180, loss: 0.059928376227617264
step: 190, loss: 0.04217253997921944
step: 200, loss: 0.027914242818951607
step: 210, loss: 0.042940229177474976
step: 220, loss: 0.014019286260008812
step: 230, loss: 0.0063413274474442005
step: 240, loss: 0.10908608138561249
step: 250, loss: 0.030426492914557457
step: 260, loss: 0.019046980887651443
step: 270, loss: 0.02497219480574131
step: 280, loss: 0.04700447991490364
step: 290, loss: 0.13455082476139069
step: 300, loss: 0.05996543541550636
step: 310, loss: 0.07037457823753357
step: 320, loss: 0.01369795948266983
step: 330, loss: 0.004047712776809931
step: 340, loss: 0.0095857884734869
step: 350, loss: 0.12634235620498657
step: 360, loss: 0.0036195337306708097
step: 370, loss: 0.018756741657853127
step: 380, loss: 0.05438486486673355
step: 390, loss: 0.06323376297950745
step: 400, loss: 0.07585632801055908
step: 410, loss: 0.09160561859607697
step: 420, loss: 0.020821571350097656
step: 430, loss: 0.09153604507446289
step: 440, loss: 0.01631397381424904
step: 450, loss: 0.00785195641219616
step: 460, loss: 0.13815459609031677
epoch 8: dev_f1=0.9898534385569334, f1=0.9841628959276018, best_f1=0.9852774631936579
step: 0, loss: 0.029082709923386574
step: 10, loss: 0.05464422330260277
step: 20, loss: 0.11484368145465851
step: 30, loss: 0.031521689146757126
step: 40, loss: 0.006315708160400391
step: 50, loss: 0.031050926074385643
step: 60, loss: 0.008229855448007584
step: 70, loss: 0.19324375689029694
step: 80, loss: 0.0028717913664877415
step: 90, loss: 0.024894390255212784
step: 100, loss: 0.018632667139172554
step: 110, loss: 0.007648761849850416
step: 120, loss: 0.01515881810337305
step: 130, loss: 0.09595136344432831
step: 140, loss: 0.04846205562353134
step: 150, loss: 0.027418632060289383
step: 160, loss: 0.09776325523853302
step: 170, loss: 0.043226636946201324
step: 180, loss: 0.018375974148511887
step: 190, loss: 0.06565452367067337
step: 200, loss: 0.009285299107432365
step: 210, loss: 0.029278015717864037
step: 220, loss: 0.049930647015571594
step: 230, loss: 0.024190302938222885
step: 240, loss: 0.07240382581949234
step: 250, loss: 0.009177235886454582
step: 260, loss: 0.03117329068481922
step: 270, loss: 0.00846882350742817
step: 280, loss: 0.05712975561618805
step: 290, loss: 0.047541242092847824
step: 300, loss: 0.009067812003195286
step: 310, loss: 0.045615725219249725
step: 320, loss: 0.00607823533937335
step: 330, loss: 0.12585656344890594
step: 340, loss: 0.04309492185711861
step: 350, loss: 0.08892906457185745
step: 360, loss: 0.020760856568813324
step: 370, loss: 0.0640304908156395
step: 380, loss: 0.028519636020064354
step: 390, loss: 0.0002325160166947171
step: 400, loss: 0.06393076479434967
step: 410, loss: 0.010754688642919064
step: 420, loss: 0.01088833436369896
step: 430, loss: 0.03019365668296814
step: 440, loss: 0.03265221789479256
step: 450, loss: 0.05974653363227844
step: 460, loss: 0.012141597457230091
epoch 9: dev_f1=0.9921259842519685, f1=0.9809203142536477, best_f1=0.9852774631936579
step: 0, loss: 0.012507487088441849
step: 10, loss: 0.007526232395321131
step: 20, loss: 0.12163165956735611
step: 30, loss: 0.07689880579710007
step: 40, loss: 0.055308129638433456
step: 50, loss: 0.01672392711043358
step: 60, loss: 0.061155952513217926
step: 70, loss: 0.014684570953249931
step: 80, loss: 0.025318510830402374
step: 90, loss: 0.10229074954986572
step: 100, loss: 0.09045369178056717
step: 110, loss: 0.04508156329393387
step: 120, loss: 0.03718098998069763
step: 130, loss: 0.004688714165240526
step: 140, loss: 0.02377038449048996
step: 150, loss: 0.02497076988220215
step: 160, loss: 0.08031708747148514
step: 170, loss: 0.01542688813060522
step: 180, loss: 0.025016628205776215
step: 190, loss: 0.038098566234111786
step: 200, loss: 5.806296394439414e-05
step: 210, loss: 0.003032818902283907
step: 220, loss: 0.06302846968173981
step: 230, loss: 0.01104168314486742
step: 240, loss: 0.07477071136236191
step: 250, loss: 0.04479637369513512
step: 260, loss: 0.004775321576744318
step: 270, loss: 0.043280474841594696
step: 280, loss: 0.15776550769805908
step: 290, loss: 0.10469724982976913
step: 300, loss: 0.09264518320560455
step: 310, loss: 0.03520846366882324
step: 320, loss: 0.008526829071342945
step: 330, loss: 0.06986862421035767
step: 340, loss: 0.015417841263115406
step: 350, loss: 0.035983141511678696
step: 360, loss: 0.017036497592926025
step: 370, loss: 0.0654863715171814
step: 380, loss: 0.003984373528510332
step: 390, loss: 0.020280078053474426
step: 400, loss: 0.014116717502474785
step: 410, loss: 0.04020562022924423
step: 420, loss: 0.0543966107070446
step: 430, loss: 0.05146221071481705
step: 440, loss: 0.019094601273536682
step: 450, loss: 0.0668911412358284
step: 460, loss: 0.020371023565530777
epoch 10: dev_f1=0.9943883277216611, f1=0.9865771812080537, best_f1=0.9865771812080537
step: 0, loss: 0.047972314059734344
step: 10, loss: 0.04127863422036171
step: 20, loss: 0.05202754586935043
step: 30, loss: 0.00011579682904994115
step: 40, loss: 0.0995134711265564
step: 50, loss: 0.018653443083167076
step: 60, loss: 0.005083548370748758
step: 70, loss: 0.005754419136792421
step: 80, loss: 0.09334679692983627
step: 90, loss: 0.013885005377233028
step: 100, loss: 0.0548325851559639
step: 110, loss: 0.05137714371085167
step: 120, loss: 0.12159456312656403
step: 130, loss: 0.04905971139669418
step: 140, loss: 0.05265664681792259
step: 150, loss: 0.1127205640077591
step: 160, loss: 0.030696699395775795
step: 170, loss: 0.02479557879269123
step: 180, loss: 0.026470839977264404
step: 190, loss: 0.03466770052909851
step: 200, loss: 0.05263267084956169
step: 210, loss: 0.001428562798537314
step: 220, loss: 0.07501186430454254
step: 230, loss: 0.005432257894426584
step: 240, loss: 0.017891395837068558
step: 250, loss: 0.07462947070598602
step: 260, loss: 0.035208482295274734
step: 270, loss: 0.14962881803512573
step: 280, loss: 0.08015792071819305
step: 290, loss: 0.003452158998697996
step: 300, loss: 0.026776475831866264
step: 310, loss: 0.0011971767526119947
step: 320, loss: 0.08398015797138214
step: 330, loss: 0.035901106894016266
step: 340, loss: 0.02152247168123722
step: 350, loss: 0.04184498265385628
step: 360, loss: 0.08597841113805771
step: 370, loss: 0.00018008275947067887
step: 380, loss: 0.09387721866369247
step: 390, loss: 0.004118683282285929
step: 400, loss: 0.03427779674530029
step: 410, loss: 8.437781798420474e-05
step: 420, loss: 0.03521207720041275
step: 430, loss: 0.11117502301931381
step: 440, loss: 0.03210759535431862
step: 450, loss: 0.006925989408046007
step: 460, loss: 0.0800078734755516
epoch 11: dev_f1=0.990990990990991, f1=0.9831271091113611, best_f1=0.9865771812080537
step: 0, loss: 0.08950571715831757
step: 10, loss: 0.014384320005774498
step: 20, loss: 0.016136154532432556
step: 30, loss: 0.11151429265737534
step: 40, loss: 0.021119432523846626
step: 50, loss: 0.04339580237865448
step: 60, loss: 0.04051363840699196
step: 70, loss: 0.061092838644981384
step: 80, loss: 0.009306377731263638
step: 90, loss: 0.0065056136809289455
step: 100, loss: 0.03603687882423401
step: 110, loss: 0.051929328590631485
step: 120, loss: 0.03410295769572258
step: 130, loss: 0.02848714590072632
step: 140, loss: 0.03034699335694313
step: 150, loss: 0.05328371375799179
step: 160, loss: 0.010943413712084293
step: 170, loss: 0.009271183051168919
step: 180, loss: 0.00020598256378434598
step: 190, loss: 0.0784180760383606
step: 200, loss: 0.00023332760611083359
step: 210, loss: 0.01504181232303381
step: 220, loss: 0.04342943802475929
step: 230, loss: 0.075419582426548
step: 240, loss: 0.019840678200125694
step: 250, loss: 0.10191846638917923
step: 260, loss: 0.007310100365430117
step: 270, loss: 0.10047296434640884
step: 280, loss: 0.009505745023488998
step: 290, loss: 0.04456578567624092
step: 300, loss: 0.08231370151042938
step: 310, loss: 0.0037004156038165092
step: 320, loss: 0.03780133277177811
step: 330, loss: 0.01756463758647442
step: 340, loss: 0.016629789024591446
step: 350, loss: 0.04087181016802788
step: 360, loss: 0.001559102674946189
step: 370, loss: 0.03255202993750572
step: 380, loss: 0.0035259013529866934
step: 390, loss: 0.06176967918872833
step: 400, loss: 0.10985067486763
step: 410, loss: 0.017897168174386024
step: 420, loss: 0.00792400911450386
step: 430, loss: 0.04187575355172157
step: 440, loss: 0.0026837033219635487
step: 450, loss: 0.02311480976641178
step: 460, loss: 0.00020938270608894527
epoch 12: dev_f1=0.9921436588103255, f1=0.9865771812080537, best_f1=0.9865771812080537
step: 0, loss: 0.04963775724172592
step: 10, loss: 0.1005227193236351
step: 20, loss: 0.0004899068735539913
step: 30, loss: 0.007263025268912315
step: 40, loss: 0.003650470869615674
step: 50, loss: 0.046497270464897156
step: 60, loss: 0.007365248631685972
step: 70, loss: 0.05931124463677406
step: 80, loss: 0.047248851507902145
step: 90, loss: 0.054867107421159744
step: 100, loss: 0.07522530108690262
step: 110, loss: 0.0014203081373125315
step: 120, loss: 0.11540274322032928
step: 130, loss: 7.343321340158582e-05
step: 140, loss: 0.016726763918995857
step: 150, loss: 0.01644069515168667
step: 160, loss: 0.01500720251351595
step: 170, loss: 0.030057396739721298
step: 180, loss: 0.01622684672474861
step: 190, loss: 0.025857675820589066
step: 200, loss: 0.08189722150564194
step: 210, loss: 0.01604413613677025
step: 220, loss: 0.03638492897152901
step: 230, loss: 0.008751374669373035
step: 240, loss: 0.0003475288685876876
step: 250, loss: 0.02134864218533039
step: 260, loss: 0.11101580411195755
step: 270, loss: 0.001473897835239768
step: 280, loss: 0.21016447246074677
step: 290, loss: 0.03977029770612717
step: 300, loss: 0.034686747938394547
step: 310, loss: 0.03936076536774635
step: 320, loss: 0.003916400019079447
step: 330, loss: 0.007944698445498943
step: 340, loss: 0.041122183203697205
step: 350, loss: 0.010728747583925724
step: 360, loss: 0.04787861928343773
step: 370, loss: 0.0008438381482847035
step: 380, loss: 0.023203913122415543
step: 390, loss: 0.00010045250382972881
step: 400, loss: 0.014628268778324127
step: 410, loss: 0.04725771024823189
step: 420, loss: 0.17658080160617828
step: 430, loss: 0.001748181413859129
step: 440, loss: 0.03902745619416237
step: 450, loss: 0.04329897463321686
step: 460, loss: 0.0012087526265531778
epoch 13: dev_f1=0.990990990990991, f1=0.9809203142536477, best_f1=0.9865771812080537
step: 0, loss: 0.06318923085927963
step: 10, loss: 0.03325469046831131
step: 20, loss: 0.05338894948363304
step: 30, loss: 0.030525311827659607
step: 40, loss: 0.10653119534254074
step: 50, loss: 0.029568498954176903
step: 60, loss: 0.026364624500274658
step: 70, loss: 0.005056667607277632
step: 80, loss: 0.04205325245857239
step: 90, loss: 0.08097611367702484
step: 100, loss: 0.0016376411076635122
step: 110, loss: 0.018513236194849014
step: 120, loss: 0.00014030195598024875
step: 130, loss: 0.03006105124950409
step: 140, loss: 0.00642574904486537
step: 150, loss: 0.0010165345156565309
step: 160, loss: 0.0029284791089594364
step: 170, loss: 0.06279109418392181
step: 180, loss: 0.0017877839272841811
step: 190, loss: 0.03960971534252167
step: 200, loss: 0.02174292504787445
step: 210, loss: 0.060057416558265686
step: 220, loss: 0.0037044421769678593
step: 230, loss: 0.0002142448938684538
step: 240, loss: 0.08856135606765747
step: 250, loss: 0.0442424900829792
step: 260, loss: 0.0022946004755795
step: 270, loss: 0.0480683408677578
step: 280, loss: 0.011783836409449577
step: 290, loss: 8.015485946089029e-05
step: 300, loss: 0.06441576778888702
step: 310, loss: 0.0174576323479414
step: 320, loss: 0.001292423577979207
step: 330, loss: 0.06309109926223755
step: 340, loss: 0.04811469092965126
step: 350, loss: 0.019379181787371635
step: 360, loss: 0.021428873762488365
step: 370, loss: 0.0003235162585042417
step: 380, loss: 0.00030957566923461854
step: 390, loss: 0.000640244223177433
step: 400, loss: 0.00019746861653402448
step: 410, loss: 0.00302283838391304
step: 420, loss: 0.033429887145757675
step: 430, loss: 0.03313548117876053
step: 440, loss: 0.03434550017118454
step: 450, loss: 0.159615620970726
step: 460, loss: 0.0716952234506607
epoch 14: dev_f1=0.9932584269662922, f1=0.9854423292273236, best_f1=0.9865771812080537
step: 0, loss: 0.02802226133644581
step: 10, loss: 0.03382357209920883
step: 20, loss: 0.017556577920913696
step: 30, loss: 0.03682389855384827
step: 40, loss: 0.018175968900322914
step: 50, loss: 0.05545209348201752
step: 60, loss: 0.031138045713305473
step: 70, loss: 0.05214948207139969
step: 80, loss: 0.005172306671738625
step: 90, loss: 0.053418662399053574
step: 100, loss: 0.04053804650902748
step: 110, loss: 0.0003623667871579528
step: 120, loss: 0.04132901132106781
step: 130, loss: 0.03972912207245827
step: 140, loss: 0.13000264763832092
step: 150, loss: 0.049935292452573776
step: 160, loss: 0.05038243532180786
step: 170, loss: 0.03975015878677368
step: 180, loss: 0.01965019479393959
step: 190, loss: 0.00028290340560488403
step: 200, loss: 0.012560115195810795
step: 210, loss: 0.016272930428385735
step: 220, loss: 0.04976418986916542
step: 230, loss: 0.0003795655502472073
step: 240, loss: 0.0002109002962242812
step: 250, loss: 0.0001270194916287437
step: 260, loss: 0.026760851964354515
step: 270, loss: 0.040085285902023315
step: 280, loss: 3.6974473914597183e-05
step: 290, loss: 0.00011020902456948534
step: 300, loss: 0.03892221674323082
step: 310, loss: 0.0017157875699922442
step: 320, loss: 0.03003419190645218
step: 330, loss: 0.0003035883419215679
step: 340, loss: 0.0003072084509767592
step: 350, loss: 0.01598493382334709
step: 360, loss: 0.0012308919103816152
step: 370, loss: 0.00011553262447705492
step: 380, loss: 0.03613084927201271
step: 390, loss: 0.061842549592256546
step: 400, loss: 0.04325167089700699
step: 410, loss: 0.01262049749493599
step: 420, loss: 0.0008782033692114055
step: 430, loss: 0.01844160631299019
step: 440, loss: 0.0001191917690448463
step: 450, loss: 0.029780473560094833
step: 460, loss: 0.00011270105460425839
epoch 15: dev_f1=0.9932584269662922, f1=0.9865771812080537, best_f1=0.9865771812080537
step: 0, loss: 0.023276343941688538
step: 10, loss: 0.023410111665725708
step: 20, loss: 0.00925492774695158
step: 30, loss: 0.01352436188608408
step: 40, loss: 0.04537603631615639
step: 50, loss: 0.00642289686948061
step: 60, loss: 0.00015768324374221265
step: 70, loss: 0.03853796049952507
step: 80, loss: 0.06562786549329758
step: 90, loss: 0.013744987547397614
step: 100, loss: 0.02587570622563362
step: 110, loss: 0.056535862386226654
step: 120, loss: 0.022301791235804558
step: 130, loss: 0.11978836357593536
step: 140, loss: 0.0034523052163422108
step: 150, loss: 0.00357184000313282
step: 160, loss: 0.0004123861144762486
step: 170, loss: 0.02574983425438404
step: 180, loss: 7.024972728686407e-05
step: 190, loss: 0.04307764768600464
step: 200, loss: 0.04823907092213631
step: 210, loss: 0.00011793345038313419
step: 220, loss: 0.0014350138371810317
step: 230, loss: 0.015119144693017006
step: 240, loss: 0.012961514294147491
step: 250, loss: 0.022156648337841034
step: 260, loss: 0.0003239610814489424
step: 270, loss: 0.014474195428192616
step: 280, loss: 0.0003336255613248795
step: 290, loss: 0.10157109051942825
step: 300, loss: 0.03767366707324982
step: 310, loss: 0.06614632904529572
step: 320, loss: 0.00010853951243916526
step: 330, loss: 0.0024783597327768803
step: 340, loss: 0.02384101413190365
step: 350, loss: 0.0001684696035226807
step: 360, loss: 0.07505671679973602
step: 370, loss: 0.044858772307634354
step: 380, loss: 0.023296736180782318
step: 390, loss: 0.03875599801540375
step: 400, loss: 0.05225373059511185
step: 410, loss: 0.0008159938734024763
step: 420, loss: 0.06297077983617783
step: 430, loss: 6.567649688804522e-05
step: 440, loss: 0.0001447725953767076
step: 450, loss: 0.03269270062446594
step: 460, loss: 0.042701490223407745
epoch 16: dev_f1=0.9921612541993281, f1=0.987709497206704, best_f1=0.9865771812080537
step: 0, loss: 0.03965097293257713
step: 10, loss: 5.218716250965372e-05
step: 20, loss: 0.042576003819704056
step: 30, loss: 5.821507511427626e-05
step: 40, loss: 0.05946283042430878
step: 50, loss: 0.017126811668276787
step: 60, loss: 0.02302718721330166
step: 70, loss: 0.09877116978168488
step: 80, loss: 0.01891397498548031
step: 90, loss: 0.004270448815077543
step: 100, loss: 0.050834208726882935
step: 110, loss: 0.000537982617970556
step: 120, loss: 0.0008951697964221239
step: 130, loss: 0.0004531847080215812
step: 140, loss: 0.020517462864518166
step: 150, loss: 0.0006746798753738403
step: 160, loss: 3.473985270829871e-05
step: 170, loss: 0.027285588905215263
step: 180, loss: 3.2457017368869856e-05
step: 190, loss: 0.06707010418176651
step: 200, loss: 0.015222865156829357
step: 210, loss: 0.048944585025310516
step: 220, loss: 0.0002872795448638499
step: 230, loss: 0.00030005761072970927
step: 240, loss: 0.017903853207826614
step: 250, loss: 0.03229939565062523
step: 260, loss: 6.920265150256455e-05
step: 270, loss: 0.23324765264987946
step: 280, loss: 0.023528123274445534
step: 290, loss: 0.045454222708940506
step: 300, loss: 0.02652193233370781
step: 310, loss: 0.058100298047065735
step: 320, loss: 4.203677599434741e-05
step: 330, loss: 0.020846907049417496
step: 340, loss: 0.018456466495990753
step: 350, loss: 0.10656298696994781
step: 360, loss: 0.025365304201841354
step: 370, loss: 3.554841168806888e-05
step: 380, loss: 0.025033175945281982
step: 390, loss: 0.015005039982497692
step: 400, loss: 2.967064210679382e-05
step: 410, loss: 0.04201328009366989
step: 420, loss: 0.022430671378970146
step: 430, loss: 0.0011008579749614
step: 440, loss: 7.937486952869222e-05
step: 450, loss: 0.00045880101970396936
step: 460, loss: 0.027579793706536293
epoch 17: dev_f1=0.9943757030371203, f1=0.9854096520763187, best_f1=0.9865771812080537
step: 0, loss: 0.0002858066582120955
step: 10, loss: 0.020919008180499077
step: 20, loss: 0.0040236725471913815
step: 30, loss: 0.002619826467707753
step: 40, loss: 0.025897519662976265
step: 50, loss: 0.01608322188258171
step: 60, loss: 0.03299105912446976
step: 70, loss: 0.04247872158885002
step: 80, loss: 0.0001953283353941515
step: 90, loss: 0.0019202824914827943
step: 100, loss: 0.06093336641788483
step: 110, loss: 0.026311349123716354
step: 120, loss: 4.8636444262228906e-05
step: 130, loss: 4.4922409870196134e-05
step: 140, loss: 0.021483764052391052
step: 150, loss: 0.0427878201007843
step: 160, loss: 0.019180787727236748
step: 170, loss: 0.02215668000280857
step: 180, loss: 0.0447373203933239
step: 190, loss: 0.05999787151813507
step: 200, loss: 0.021618545055389404
step: 210, loss: 0.03290553390979767
step: 220, loss: 0.00014960076077841222
step: 230, loss: 0.020788544788956642
step: 240, loss: 2.713211506488733e-05
step: 250, loss: 0.028564974665641785
step: 260, loss: 0.029378313571214676
step: 270, loss: 5.1082894060527906e-05
step: 280, loss: 0.028869174420833588
step: 290, loss: 0.0005946547607891262
step: 300, loss: 0.0002677124575711787
step: 310, loss: 0.040381912142038345
step: 320, loss: 0.045175518840551376
step: 330, loss: 0.0012273101601749659
step: 340, loss: 0.02516365610063076
step: 350, loss: 0.05010717362165451
step: 360, loss: 0.04615234211087227
step: 370, loss: 0.023944269865751266
step: 380, loss: 0.08064400404691696
step: 390, loss: 0.02683241292834282
step: 400, loss: 0.04417138919234276
step: 410, loss: 3.430043580010533e-05
step: 420, loss: 0.020930830389261246
step: 430, loss: 0.02080206386744976
step: 440, loss: 0.0214774701744318
step: 450, loss: 0.042089179158210754
step: 460, loss: 0.03444341570138931
epoch 18: dev_f1=0.9943757030371203, f1=0.9842696629213483, best_f1=0.9865771812080537
step: 0, loss: 0.0518980510532856
step: 10, loss: 0.00011109515617135912
step: 20, loss: 0.025380980223417282
step: 30, loss: 0.01961928978562355
step: 40, loss: 0.06921820342540741
step: 50, loss: 0.0002722912176977843
step: 60, loss: 0.04373088851571083
step: 70, loss: 0.0050828405655920506
step: 80, loss: 0.02438262850046158
step: 90, loss: 0.025885598734021187
step: 100, loss: 0.09461122751235962
step: 110, loss: 0.02085195481777191
step: 120, loss: 0.019849766045808792
step: 130, loss: 0.0176952313631773
step: 140, loss: 2.559526365075726e-05
step: 150, loss: 4.560291927191429e-05
step: 160, loss: 0.022068960592150688
step: 170, loss: 0.011287965811789036
step: 180, loss: 0.019455667585134506
step: 190, loss: 0.04314105957746506
step: 200, loss: 0.018156608566641808
step: 210, loss: 0.026833057403564453
step: 220, loss: 0.05425211042165756
step: 230, loss: 0.02052132599055767
step: 240, loss: 0.0004887504619546235
step: 250, loss: 0.05924025550484657
step: 260, loss: 0.021496165543794632
step: 270, loss: 0.020356906577944756
step: 280, loss: 0.00017386226681992412
step: 290, loss: 0.000124066966236569
step: 300, loss: 4.108530265511945e-05
step: 310, loss: 0.03967804089188576
step: 320, loss: 0.019233444705605507
step: 330, loss: 0.02312198095023632
step: 340, loss: 0.06302639096975327
step: 350, loss: 0.009572132490575314
step: 360, loss: 0.030313625931739807
step: 370, loss: 2.0064033378730528e-05
step: 380, loss: 3.188445407431573e-05
step: 390, loss: 7.954431202961132e-05
step: 400, loss: 0.09837184846401215
step: 410, loss: 5.156874976819381e-05
step: 420, loss: 0.011698249727487564
step: 430, loss: 0.02480001002550125
step: 440, loss: 0.03461887687444687
step: 450, loss: 0.02040707878768444
step: 460, loss: 0.0024081317242234945
epoch 19: dev_f1=0.9943630214205187, f1=0.9842696629213483, best_f1=0.9865771812080537
step: 0, loss: 0.06612885743379593
step: 10, loss: 0.032792966812849045
step: 20, loss: 0.0001516793272458017
step: 30, loss: 0.05592742934823036
step: 40, loss: 0.0746578499674797
step: 50, loss: 0.04195985570549965
step: 60, loss: 0.010781054385006428
step: 70, loss: 0.024088408797979355
step: 80, loss: 3.3404965506633744e-05
step: 90, loss: 0.02204084023833275
step: 100, loss: 0.07015859335660934
step: 110, loss: 6.319840031210333e-05
step: 120, loss: 0.00985021609812975
step: 130, loss: 8.414299372816458e-05
step: 140, loss: 0.009480154141783714
step: 150, loss: 0.0007178230443969369
step: 160, loss: 0.045432791113853455
step: 170, loss: 0.02012723870575428
step: 180, loss: 0.018495066091418266
step: 190, loss: 0.00012899241119157523
step: 200, loss: 0.019993141293525696
step: 210, loss: 0.02146245166659355
step: 220, loss: 3.516533979563974e-05
step: 230, loss: 8.324012014782056e-05
step: 240, loss: 0.06981246918439865
step: 250, loss: 0.03707415610551834
step: 260, loss: 0.01771879568696022
step: 270, loss: 0.03119342029094696
step: 280, loss: 0.059161342680454254
step: 290, loss: 0.04582056775689125
step: 300, loss: 0.030352577567100525
step: 310, loss: 0.00021729384025093168
step: 320, loss: 0.009791734628379345
step: 330, loss: 0.058394141495227814
step: 340, loss: 0.03437066823244095
step: 350, loss: 2.5780691430554725e-05
step: 360, loss: 0.0162400770932436
step: 370, loss: 6.629940617131069e-05
step: 380, loss: 0.013253236189484596
step: 390, loss: 0.09049482643604279
step: 400, loss: 0.00010230852058157325
step: 410, loss: 2.4600516553618945e-05
step: 420, loss: 0.022045321762561798
step: 430, loss: 4.7592606279067695e-05
step: 440, loss: 0.061678215861320496
step: 450, loss: 0.021795276552438736
step: 460, loss: 4.15067006542813e-05
epoch 20: dev_f1=0.9932432432432432, f1=0.9842696629213483, best_f1=0.9865771812080537
