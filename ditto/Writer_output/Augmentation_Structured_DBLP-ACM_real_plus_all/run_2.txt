cuda
Device: cuda
step: 0, loss: 0.8662431240081787
step: 10, loss: 0.4963240623474121
step: 20, loss: 0.5589222311973572
step: 30, loss: 0.35110482573509216
step: 40, loss: 0.041327811777591705
step: 50, loss: 0.2785702347755432
step: 60, loss: 0.1962020844221115
step: 70, loss: 0.3363361656665802
step: 80, loss: 0.15214106440544128
step: 90, loss: 0.15163417160511017
step: 100, loss: 0.16940109431743622
step: 110, loss: 0.16668234765529633
step: 120, loss: 0.13410376012325287
step: 130, loss: 0.2652432918548584
step: 140, loss: 0.2183956801891327
step: 150, loss: 0.12336578965187073
step: 160, loss: 0.03077130950987339
step: 170, loss: 0.138566255569458
step: 180, loss: 0.016596047207713127
step: 190, loss: 0.1171066015958786
step: 200, loss: 0.21231116354465485
step: 210, loss: 0.06166638806462288
step: 220, loss: 0.1642804890871048
step: 230, loss: 0.08049400895833969
step: 240, loss: 0.1295800805091858
step: 250, loss: 0.05380161106586456
step: 260, loss: 0.11553359031677246
step: 270, loss: 0.319947212934494
step: 280, loss: 0.11529127508401871
step: 290, loss: 0.071417436003685
step: 300, loss: 0.024988045915961266
step: 310, loss: 0.14635300636291504
step: 320, loss: 0.025802526623010635
step: 330, loss: 0.07709938287734985
step: 340, loss: 0.11609526723623276
step: 350, loss: 0.15189549326896667
step: 360, loss: 0.01938820257782936
step: 370, loss: 0.07372493296861649
step: 380, loss: 0.04747805371880531
step: 390, loss: 0.08696553856134415
step: 400, loss: 0.06096727028489113
step: 410, loss: 0.06568974256515503
step: 420, loss: 0.06530550867319107
step: 430, loss: 0.06699904054403305
step: 440, loss: 0.10273284465074539
step: 450, loss: 0.04309463128447533
step: 460, loss: 0.18306006491184235
epoch 1: dev_f1=0.9864559819413092, f1=0.984090909090909, best_f1=0.984090909090909
step: 0, loss: 0.006269362755119801
step: 10, loss: 0.15986879169940948
step: 20, loss: 0.08439931273460388
step: 30, loss: 0.031470153480768204
step: 40, loss: 0.14772851765155792
step: 50, loss: 0.04285861551761627
step: 60, loss: 0.03513603284955025
step: 70, loss: 0.013198094442486763
step: 80, loss: 0.09603982418775558
step: 90, loss: 0.0063568907789886
step: 100, loss: 0.05492985248565674
step: 110, loss: 0.032224949449300766
step: 120, loss: 0.11632997542619705
step: 130, loss: 0.06164895370602608
step: 140, loss: 0.14746028184890747
step: 150, loss: 0.06389175355434418
step: 160, loss: 0.027234988287091255
step: 170, loss: 0.11519820988178253
step: 180, loss: 0.06287133693695068
step: 190, loss: 0.08985331654548645
step: 200, loss: 0.01342193316668272
step: 210, loss: 0.027985330671072006
step: 220, loss: 0.14935903251171112
step: 230, loss: 0.09172402322292328
step: 240, loss: 0.05973362177610397
step: 250, loss: 0.032117389142513275
step: 260, loss: 0.03700851649045944
step: 270, loss: 0.06102333590388298
step: 280, loss: 0.07500242441892624
step: 290, loss: 0.06741214543581009
step: 300, loss: 0.004155500326305628
step: 310, loss: 0.012559239752590656
step: 320, loss: 0.23310931026935577
step: 330, loss: 0.014899635687470436
step: 340, loss: 0.09937059134244919
step: 350, loss: 0.11323771625757217
step: 360, loss: 0.13192343711853027
step: 370, loss: 0.06450594216585159
step: 380, loss: 0.03844471275806427
step: 390, loss: 0.10159415751695633
step: 400, loss: 0.08530913293361664
step: 410, loss: 0.08893151581287384
step: 420, loss: 0.021068869158625603
step: 430, loss: 0.02086770161986351
step: 440, loss: 0.3212970197200775
step: 450, loss: 0.17440682649612427
step: 460, loss: 0.023490888997912407
epoch 2: dev_f1=0.9876543209876544, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.02768978849053383
step: 10, loss: 0.02404838800430298
step: 20, loss: 0.12412167340517044
step: 30, loss: 0.08001921325922012
step: 40, loss: 0.024072375148534775
step: 50, loss: 0.08350477367639542
step: 60, loss: 0.06491170078516006
step: 70, loss: 0.07612033188343048
step: 80, loss: 0.07599940896034241
step: 90, loss: 0.007976791821420193
step: 100, loss: 0.07068698108196259
step: 110, loss: 0.12930621206760406
step: 120, loss: 0.07975415140390396
step: 130, loss: 0.20439758896827698
step: 140, loss: 0.09186156839132309
step: 150, loss: 0.03096579574048519
step: 160, loss: 0.06548304110765457
step: 170, loss: 0.007785077206790447
step: 180, loss: 0.01609327830374241
step: 190, loss: 0.111857570707798
step: 200, loss: 0.015487764030694962
step: 210, loss: 0.0977245569229126
step: 220, loss: 0.06276893615722656
step: 230, loss: 0.16940465569496155
step: 240, loss: 0.010527589358389378
step: 250, loss: 0.053775906562805176
step: 260, loss: 0.06023784726858139
step: 270, loss: 0.07465804368257523
step: 280, loss: 0.014899829402565956
step: 290, loss: 0.3313317894935608
step: 300, loss: 0.07415718585252762
step: 310, loss: 0.08145251125097275
step: 320, loss: 0.07166686654090881
step: 330, loss: 0.029366081580519676
step: 340, loss: 0.03713895007967949
step: 350, loss: 0.016655785962939262
step: 360, loss: 0.1071806401014328
step: 370, loss: 0.05494352802634239
step: 380, loss: 0.020548228174448013
step: 390, loss: 0.112948477268219
step: 400, loss: 0.19083325564861298
step: 410, loss: 0.01281853299587965
step: 420, loss: 0.027750656008720398
step: 430, loss: 0.06877152621746063
step: 440, loss: 0.07560323178768158
step: 450, loss: 0.021323775872588158
step: 460, loss: 0.07066022604703903
epoch 3: dev_f1=0.9920903954802259, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.1393517702817917
step: 10, loss: 0.01265589240938425
step: 20, loss: 0.014618352055549622
step: 30, loss: 0.006113600451499224
step: 40, loss: 0.09231820702552795
step: 50, loss: 0.06436444818973541
step: 60, loss: 0.01379249058663845
step: 70, loss: 0.006808269768953323
step: 80, loss: 0.018455980345606804
step: 90, loss: 0.1335679143667221
step: 100, loss: 0.07605858892202377
step: 110, loss: 0.061863552778959274
step: 120, loss: 0.0765913873910904
step: 130, loss: 0.02917289361357689
step: 140, loss: 0.06309843808412552
step: 150, loss: 0.1867106705904007
step: 160, loss: 0.08841413259506226
step: 170, loss: 0.015036605298519135
step: 180, loss: 0.07431420683860779
step: 190, loss: 0.026605356484651566
step: 200, loss: 0.06891825050115585
step: 210, loss: 0.04773402959108353
step: 220, loss: 0.11725812405347824
step: 230, loss: 0.14347881078720093
step: 240, loss: 0.011752036400139332
step: 250, loss: 0.025850430130958557
step: 260, loss: 0.12482817471027374
step: 270, loss: 0.0074386270716786385
step: 280, loss: 0.0673379972577095
step: 290, loss: 0.06745187938213348
step: 300, loss: 0.06690556555986404
step: 310, loss: 0.1380523443222046
step: 320, loss: 0.037245456129312515
step: 330, loss: 0.016973134130239487
step: 340, loss: 0.1728149652481079
step: 350, loss: 0.00728942546993494
step: 360, loss: 0.0039031654596328735
step: 370, loss: 0.02637346088886261
step: 380, loss: 0.00011000906670233235
step: 390, loss: 0.06250807642936707
step: 400, loss: 0.011256187222898006
step: 410, loss: 0.0439758338034153
step: 420, loss: 0.12821181118488312
step: 430, loss: 0.025114767253398895
step: 440, loss: 0.09787652641534805
step: 450, loss: 0.07312820851802826
step: 460, loss: 0.07831648737192154
epoch 4: dev_f1=0.9899665551839464, f1=0.9854748603351955, best_f1=0.9819819819819819
step: 0, loss: 0.1730262041091919
step: 10, loss: 0.026377474889159203
step: 20, loss: 0.035803429782390594
step: 30, loss: 0.14556415379047394
step: 40, loss: 0.015098254196345806
step: 50, loss: 0.04795520380139351
step: 60, loss: 0.008003954775631428
step: 70, loss: 0.006095151416957378
step: 80, loss: 0.13240055739879608
step: 90, loss: 0.07335735857486725
step: 100, loss: 0.038653962314128876
step: 110, loss: 0.056757356971502304
step: 120, loss: 0.10707100480794907
step: 130, loss: 0.0677570104598999
step: 140, loss: 0.043016377836465836
step: 150, loss: 0.05486782267689705
step: 160, loss: 0.03245328739285469
step: 170, loss: 0.07756712287664413
step: 180, loss: 0.12044749408960342
step: 190, loss: 0.09466774761676788
step: 200, loss: 0.007976931519806385
step: 210, loss: 0.13384443521499634
step: 220, loss: 0.08658614009618759
step: 230, loss: 0.062452252954244614
step: 240, loss: 0.026103109121322632
step: 250, loss: 0.016748463734984398
step: 260, loss: 0.07651638239622116
step: 270, loss: 0.03414569050073624
step: 280, loss: 0.07960562407970428
step: 290, loss: 0.06712611764669418
step: 300, loss: 0.02804546058177948
step: 310, loss: 0.019468052312731743
step: 320, loss: 0.015177435241639614
step: 330, loss: 0.13744215667247772
step: 340, loss: 0.021854711696505547
step: 350, loss: 0.0612335167825222
step: 360, loss: 0.13429123163223267
step: 370, loss: 0.0612889863550663
step: 380, loss: 0.020532121881842613
step: 390, loss: 0.02620200626552105
step: 400, loss: 0.02994312345981598
step: 410, loss: 0.06185255944728851
step: 420, loss: 0.008479036390781403
step: 430, loss: 7.45733777876012e-05
step: 440, loss: 0.0172794908285141
step: 450, loss: 0.047359220683574677
step: 460, loss: 0.10222326964139938
epoch 5: dev_f1=0.9909706546275394, f1=0.9852774631936579, best_f1=0.9819819819819819
step: 0, loss: 0.05868346244096756
step: 10, loss: 0.11452952772378922
step: 20, loss: 0.06808532774448395
step: 30, loss: 0.05092495307326317
step: 40, loss: 0.06691887229681015
step: 50, loss: 0.019579313695430756
step: 60, loss: 0.10390089452266693
step: 70, loss: 0.04417986795306206
step: 80, loss: 0.006480132695287466
step: 90, loss: 0.01656477339565754
step: 100, loss: 0.04919199272990227
step: 110, loss: 0.0711657777428627
step: 120, loss: 0.1743514984846115
step: 130, loss: 0.06811642646789551
step: 140, loss: 0.05856688693165779
step: 150, loss: 0.19024090468883514
step: 160, loss: 0.023012680932879448
step: 170, loss: 0.07966628670692444
step: 180, loss: 0.029956117272377014
step: 190, loss: 0.031149012967944145
step: 200, loss: 0.05509287118911743
step: 210, loss: 0.09918687492609024
step: 220, loss: 0.014710678718984127
step: 230, loss: 0.018309276551008224
step: 240, loss: 0.0437287762761116
step: 250, loss: 0.015075205825269222
step: 260, loss: 0.0052079083397984505
step: 270, loss: 0.0175583865493536
step: 280, loss: 0.0096812192350626
step: 290, loss: 0.019153587520122528
step: 300, loss: 0.058591295033693314
step: 310, loss: 0.013646825216710567
step: 320, loss: 0.06547959893941879
step: 330, loss: 0.009516878053545952
step: 340, loss: 0.01771358959376812
step: 350, loss: 0.061156630516052246
step: 360, loss: 0.07538142800331116
step: 370, loss: 0.04644869640469551
step: 380, loss: 0.07542157173156738
step: 390, loss: 0.06923001259565353
step: 400, loss: 0.06825844198465347
step: 410, loss: 0.12555405497550964
step: 420, loss: 0.0283129271119833
step: 430, loss: 0.014369431883096695
step: 440, loss: 7.03286932548508e-05
step: 450, loss: 0.043895475566387177
step: 460, loss: 0.01858784630894661
epoch 6: dev_f1=0.9909502262443439, f1=0.9864559819413092, best_f1=0.9819819819819819
step: 0, loss: 0.054956503212451935
step: 10, loss: 0.11658112704753876
step: 20, loss: 0.07569396495819092
step: 30, loss: 0.061177149415016174
step: 40, loss: 0.0945625975728035
step: 50, loss: 0.01938573271036148
step: 60, loss: 0.06626211106777191
step: 70, loss: 0.00011543423170223832
step: 80, loss: 0.025898121297359467
step: 90, loss: 0.03943774849176407
step: 100, loss: 0.00011102147254860029
step: 110, loss: 0.024312365800142288
step: 120, loss: 0.016186678782105446
step: 130, loss: 0.06509681046009064
step: 140, loss: 0.012720059603452682
step: 150, loss: 0.03185871243476868
step: 160, loss: 0.06954022496938705
step: 170, loss: 0.007544500287622213
step: 180, loss: 0.022658701986074448
step: 190, loss: 0.011713775806128979
step: 200, loss: 0.06056099385023117
step: 210, loss: 0.005699769593775272
step: 220, loss: 0.026223205029964447
step: 230, loss: 0.08401205390691757
step: 240, loss: 0.09021817892789841
step: 250, loss: 0.014731811359524727
step: 260, loss: 0.03209160640835762
step: 270, loss: 0.039583414793014526
step: 280, loss: 0.08079864829778671
step: 290, loss: 0.014503980055451393
step: 300, loss: 0.13597790896892548
step: 310, loss: 0.13397881388664246
step: 320, loss: 0.1070689707994461
step: 330, loss: 0.10022741556167603
step: 340, loss: 0.07970117777585983
step: 350, loss: 0.12240734696388245
step: 360, loss: 0.09568110853433609
step: 370, loss: 0.20111313462257385
step: 380, loss: 0.13642540574073792
step: 390, loss: 0.026599394157528877
step: 400, loss: 0.04747854173183441
step: 410, loss: 0.03228455409407616
step: 420, loss: 0.016418473795056343
step: 430, loss: 0.06977852433919907
step: 440, loss: 0.009512756019830704
step: 450, loss: 0.0869184359908104
step: 460, loss: 0.05852631479501724
epoch 7: dev_f1=0.995505617977528, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.02796648070216179
step: 10, loss: 0.12177003175020218
step: 20, loss: 0.05892793461680412
step: 30, loss: 0.07575912028551102
step: 40, loss: 0.09204660356044769
step: 50, loss: 0.01028486154973507
step: 60, loss: 0.07409583777189255
step: 70, loss: 0.1419035643339157
step: 80, loss: 0.07372195273637772
step: 90, loss: 0.015543375164270401
step: 100, loss: 0.0027522060554474592
step: 110, loss: 0.06209849938750267
step: 120, loss: 0.0947258397936821
step: 130, loss: 0.061859458684921265
step: 140, loss: 0.09080096334218979
step: 150, loss: 0.12009325623512268
step: 160, loss: 0.15503917634487152
step: 170, loss: 0.10533925145864487
step: 180, loss: 0.009958331473171711
step: 190, loss: 0.14296188950538635
step: 200, loss: 0.026718441396951675
step: 210, loss: 0.07944885641336441
step: 220, loss: 0.10615739226341248
step: 230, loss: 0.05712197721004486
step: 240, loss: 0.016166407614946365
step: 250, loss: 0.003955187276005745
step: 260, loss: 0.07076627016067505
step: 270, loss: 0.14962446689605713
step: 280, loss: 0.024174610152840614
step: 290, loss: 0.06202998757362366
step: 300, loss: 0.05048571154475212
step: 310, loss: 0.11073292046785355
step: 320, loss: 0.0035464689135551453
step: 330, loss: 0.0001685770694166422
step: 340, loss: 0.050920434296131134
step: 350, loss: 0.06447314471006393
step: 360, loss: 0.01015473436564207
step: 370, loss: 0.006840251851826906
step: 380, loss: 0.07957063615322113
step: 390, loss: 0.14270740747451782
step: 400, loss: 0.050620611757040024
step: 410, loss: 0.030059143900871277
step: 420, loss: 0.09881594777107239
step: 430, loss: 0.05365817993879318
step: 440, loss: 0.011144575662910938
step: 450, loss: 0.015327741391956806
step: 460, loss: 0.06555984169244766
epoch 8: dev_f1=0.9921612541993281, f1=0.9855072463768116, best_f1=0.9820224719101124
step: 0, loss: 0.0158416498452425
step: 10, loss: 0.1292179822921753
step: 20, loss: 0.03007722832262516
step: 30, loss: 0.008846442215144634
step: 40, loss: 0.0821019858121872
step: 50, loss: 0.035461653023958206
step: 60, loss: 0.03357217460870743
step: 70, loss: 0.0637938529253006
step: 80, loss: 4.698581324191764e-05
step: 90, loss: 0.02705003321170807
step: 100, loss: 0.022976994514465332
step: 110, loss: 0.0987463966012001
step: 120, loss: 0.1105792373418808
step: 130, loss: 0.05105290561914444
step: 140, loss: 0.06481002271175385
step: 150, loss: 0.020543765276670456
step: 160, loss: 0.00044404057553038
step: 170, loss: 0.0099594471976161
step: 180, loss: 0.003806631313636899
step: 190, loss: 0.010821535252034664
step: 200, loss: 0.04611832648515701
step: 210, loss: 0.0209499504417181
step: 220, loss: 0.1055028960108757
step: 230, loss: 0.018068186938762665
step: 240, loss: 0.041929878294467926
step: 250, loss: 0.005713382735848427
step: 260, loss: 0.03940742835402489
step: 270, loss: 0.08569765836000443
step: 280, loss: 0.05591331422328949
step: 290, loss: 0.0872432067990303
step: 300, loss: 0.022752821445465088
step: 310, loss: 0.008319715037941933
step: 320, loss: 0.07286187261343002
step: 330, loss: 0.01507172454148531
step: 340, loss: 0.04186054691672325
step: 350, loss: 0.024141810834407806
step: 360, loss: 0.011206031776964664
step: 370, loss: 0.13565674424171448
step: 380, loss: 0.0791611522436142
step: 390, loss: 0.0651678591966629
step: 400, loss: 0.0959613248705864
step: 410, loss: 0.02535816840827465
step: 420, loss: 0.007915962487459183
step: 430, loss: 0.014895554631948471
step: 440, loss: 0.010886428877711296
step: 450, loss: 0.034504905343055725
step: 460, loss: 0.0875510573387146
epoch 9: dev_f1=0.9932432432432432, f1=0.9898762654668166, best_f1=0.9820224719101124
step: 0, loss: 0.08951960504055023
step: 10, loss: 0.010952124372124672
step: 20, loss: 0.04982823133468628
step: 30, loss: 0.034878261387348175
step: 40, loss: 0.06541015207767487
step: 50, loss: 0.17516958713531494
step: 60, loss: 0.015387747436761856
step: 70, loss: 0.06160454824566841
step: 80, loss: 0.01553498487919569
step: 90, loss: 0.07644639909267426
step: 100, loss: 0.016690194606781006
step: 110, loss: 0.017141299322247505
step: 120, loss: 0.19760853052139282
step: 130, loss: 0.015644308179616928
step: 140, loss: 0.07339530438184738
step: 150, loss: 0.04531063511967659
step: 160, loss: 0.05545475706458092
step: 170, loss: 0.13307331502437592
step: 180, loss: 0.023051481693983078
step: 190, loss: 0.17618268728256226
step: 200, loss: 0.1511639952659607
step: 210, loss: 0.003189151408150792
step: 220, loss: 0.03383781015872955
step: 230, loss: 0.09095662087202072
step: 240, loss: 0.06625420600175858
step: 250, loss: 0.03012298420071602
step: 260, loss: 0.010560542345046997
step: 270, loss: 0.0579637847840786
step: 280, loss: 0.0527433417737484
step: 290, loss: 0.04904191568493843
step: 300, loss: 0.005493194796144962
step: 310, loss: 0.09100320190191269
step: 320, loss: 0.0016899076290428638
step: 330, loss: 0.11511055380105972
step: 340, loss: 0.07641109824180603
step: 350, loss: 0.0033942298032343388
step: 360, loss: 0.03367205709218979
step: 370, loss: 0.06561655551195145
step: 380, loss: 0.015250436961650848
step: 390, loss: 0.04536929354071617
step: 400, loss: 0.015284947119653225
step: 410, loss: 0.034784723073244095
step: 420, loss: 0.04629099741578102
step: 430, loss: 0.0018235092284157872
step: 440, loss: 0.010799940675497055
step: 450, loss: 0.020013537257909775
step: 460, loss: 0.016576556488871574
epoch 10: dev_f1=0.9932885906040269, f1=0.9843749999999999, best_f1=0.9820224719101124
step: 0, loss: 0.02145209349691868
step: 10, loss: 0.020918376743793488
step: 20, loss: 0.1650739163160324
step: 30, loss: 0.01124430913478136
step: 40, loss: 0.019903063774108887
step: 50, loss: 0.04044521972537041
step: 60, loss: 0.0017707300139591098
step: 70, loss: 0.03478923439979553
step: 80, loss: 0.016909519210457802
step: 90, loss: 0.011823946610093117
step: 100, loss: 0.004397774115204811
step: 110, loss: 0.059023596346378326
step: 120, loss: 0.049146078526973724
step: 130, loss: 0.004415991250425577
step: 140, loss: 0.013337794691324234
step: 150, loss: 0.06003571301698685
step: 160, loss: 0.06176162138581276
step: 170, loss: 0.024311255663633347
step: 180, loss: 0.02198069728910923
step: 190, loss: 0.04042308032512665
step: 200, loss: 0.008229261264204979
step: 210, loss: 0.015477738343179226
step: 220, loss: 0.0010580660309642553
step: 230, loss: 0.06459967792034149
step: 240, loss: 0.024261509999632835
step: 250, loss: 0.04910702258348465
step: 260, loss: 0.04934677481651306
step: 270, loss: 0.022147413343191147
step: 280, loss: 0.009437236934900284
step: 290, loss: 0.015891149640083313
step: 300, loss: 0.0006313568446785212
step: 310, loss: 0.06167734041810036
step: 320, loss: 0.001890099374577403
step: 330, loss: 0.03459775820374489
step: 340, loss: 0.0021179767791181803
step: 350, loss: 0.0006282253307290375
step: 360, loss: 0.01535109430551529
step: 370, loss: 0.0770244374871254
step: 380, loss: 0.022453632205724716
step: 390, loss: 0.055420536547899246
step: 400, loss: 0.0007627214072272182
step: 410, loss: 0.02286926843225956
step: 420, loss: 0.04700663313269615
step: 430, loss: 0.0003416914842091501
step: 440, loss: 0.05404651165008545
step: 450, loss: 0.026429656893014908
step: 460, loss: 0.029616737738251686
epoch 11: dev_f1=0.9943883277216611, f1=0.984304932735426, best_f1=0.9820224719101124
step: 0, loss: 0.005119249690324068
step: 10, loss: 0.0932283103466034
step: 20, loss: 0.04960911348462105
step: 30, loss: 0.0027896827086806297
step: 40, loss: 0.04266059771180153
step: 50, loss: 0.030492711812257767
step: 60, loss: 0.009679185226559639
step: 70, loss: 0.04022559896111488
step: 80, loss: 0.002162400633096695
step: 90, loss: 0.002305863192304969
step: 100, loss: 0.003000318305566907
step: 110, loss: 0.0001485884713474661
step: 120, loss: 0.11795568466186523
step: 130, loss: 0.009597509168088436
step: 140, loss: 0.0001061259608832188
step: 150, loss: 0.025535430759191513
step: 160, loss: 0.019119873642921448
step: 170, loss: 0.05698414891958237
step: 180, loss: 0.02421305701136589
step: 190, loss: 0.0018775828648358583
step: 200, loss: 0.10495901107788086
step: 210, loss: 0.08268576860427856
step: 220, loss: 0.038489919155836105
step: 230, loss: 0.008897979743778706
step: 240, loss: 0.07492333650588989
step: 250, loss: 0.012214967049658298
step: 260, loss: 0.0252284724265337
step: 270, loss: 0.06995916366577148
step: 280, loss: 0.01857474446296692
step: 290, loss: 0.12652958929538727
step: 300, loss: 0.0484142042696476
step: 310, loss: 0.0238193329423666
step: 320, loss: 0.0023076932411640882
step: 330, loss: 0.0528046116232872
step: 340, loss: 0.1305132806301117
step: 350, loss: 0.048042941838502884
step: 360, loss: 0.011764985509216785
step: 370, loss: 0.00019550829892978072
step: 380, loss: 0.011225039139389992
step: 390, loss: 0.000981733901426196
step: 400, loss: 0.005799064878374338
step: 410, loss: 0.04244856536388397
step: 420, loss: 0.01774284616112709
step: 430, loss: 0.0388847216963768
step: 440, loss: 0.024669192731380463
step: 450, loss: 0.038479480892419815
step: 460, loss: 0.0786035805940628
epoch 12: dev_f1=0.995505617977528, f1=0.9910313901345291, best_f1=0.9820224719101124
step: 0, loss: 0.000283866684185341
step: 10, loss: 0.06944675743579865
step: 20, loss: 0.017500437796115875
step: 30, loss: 0.03791947290301323
step: 40, loss: 0.00012404921289999038
step: 50, loss: 0.0023569753393530846
step: 60, loss: 0.00012001269351458177
step: 70, loss: 0.000753431289922446
step: 80, loss: 0.040496088564395905
step: 90, loss: 4.142299439990893e-05
step: 100, loss: 0.013221204280853271
step: 110, loss: 0.026976827532052994
step: 120, loss: 0.0033030060585588217
step: 130, loss: 0.05853269621729851
step: 140, loss: 0.03208227455615997
step: 150, loss: 0.03854404762387276
step: 160, loss: 0.023393474519252777
step: 170, loss: 0.09369970858097076
step: 180, loss: 0.004956452175974846
step: 190, loss: 0.0012294813059270382
step: 200, loss: 0.02691265381872654
step: 210, loss: 0.05448003113269806
step: 220, loss: 0.07885909080505371
step: 230, loss: 0.00030040432466194034
step: 240, loss: 0.015110544860363007
step: 250, loss: 0.027727186679840088
step: 260, loss: 0.026558175683021545
step: 270, loss: 0.19287577271461487
step: 280, loss: 0.001075754058547318
step: 290, loss: 0.023811832070350647
step: 300, loss: 0.046671830117702484
step: 310, loss: 0.04227517172694206
step: 320, loss: 0.07673861086368561
step: 330, loss: 0.03442595899105072
step: 340, loss: 0.041371699422597885
step: 350, loss: 0.023631546646356583
step: 360, loss: 0.03712697699666023
step: 370, loss: 0.02372214011847973
step: 380, loss: 0.025941982865333557
step: 390, loss: 0.02240467071533203
step: 400, loss: 0.06838331371545792
step: 410, loss: 0.0005952651845291257
step: 420, loss: 0.062022361904382706
step: 430, loss: 0.01739472895860672
step: 440, loss: 0.027109971269965172
step: 450, loss: 0.017371607944369316
step: 460, loss: 0.03249911963939667
epoch 13: dev_f1=0.9921787709497207, f1=0.9844097995545658, best_f1=0.9820224719101124
step: 0, loss: 0.0813807025551796
step: 10, loss: 0.000819603621494025
step: 20, loss: 0.018928270787000656
step: 30, loss: 0.029078200459480286
step: 40, loss: 0.07334737479686737
step: 50, loss: 0.03579568862915039
step: 60, loss: 0.0018918331479653716
step: 70, loss: 0.003950724843889475
step: 80, loss: 0.01440997514873743
step: 90, loss: 0.050321485847234726
step: 100, loss: 0.0004058092017658055
step: 110, loss: 0.007619552779942751
step: 120, loss: 0.013459574431180954
step: 130, loss: 0.02459380030632019
step: 140, loss: 0.02145635336637497
step: 150, loss: 0.030282985419034958
step: 160, loss: 0.0023514823988080025
step: 170, loss: 0.027076203376054764
step: 180, loss: 0.0009240775252692401
step: 190, loss: 0.025539567694067955
step: 200, loss: 0.05495765805244446
step: 210, loss: 0.02133447863161564
step: 220, loss: 0.03280174359679222
step: 230, loss: 0.01721884123980999
step: 240, loss: 0.000465426710434258
step: 250, loss: 0.07191625982522964
step: 260, loss: 0.05941430851817131
step: 270, loss: 0.04115226864814758
step: 280, loss: 0.09161227941513062
step: 290, loss: 0.02678370289504528
step: 300, loss: 0.06883212178945541
step: 310, loss: 0.0008446612628176808
step: 320, loss: 0.183137446641922
step: 330, loss: 9.483932080911472e-05
step: 340, loss: 0.023763732984662056
step: 350, loss: 0.000312826014123857
step: 360, loss: 0.029840411618351936
step: 370, loss: 0.0281656626611948
step: 380, loss: 0.00014193373499438167
step: 390, loss: 0.0268891379237175
step: 400, loss: 0.03623846545815468
step: 410, loss: 0.02121027372777462
step: 420, loss: 0.04979643598198891
step: 430, loss: 0.02605287916958332
step: 440, loss: 0.003019655356183648
step: 450, loss: 9.022257290780544e-05
step: 460, loss: 0.040019359439611435
epoch 14: dev_f1=0.9921436588103255, f1=0.983277591973244, best_f1=0.9820224719101124
step: 0, loss: 0.0003008369239978492
step: 10, loss: 0.03666592016816139
step: 20, loss: 0.0003924326738342643
step: 30, loss: 0.030008595436811447
step: 40, loss: 0.10358906537294388
step: 50, loss: 0.04431089758872986
step: 60, loss: 0.04918467998504639
step: 70, loss: 0.0020434833131730556
step: 80, loss: 6.532859697472304e-05
step: 90, loss: 0.01698957569897175
step: 100, loss: 0.0012401865096762776
step: 110, loss: 0.01858280412852764
step: 120, loss: 0.021309765055775642
step: 130, loss: 0.01689687930047512
step: 140, loss: 5.057868838775903e-05
step: 150, loss: 0.055023789405822754
step: 160, loss: 0.03938017785549164
step: 170, loss: 0.002090526046231389
step: 180, loss: 0.002684037433937192
step: 190, loss: 0.04243926331400871
step: 200, loss: 0.01565258577466011
step: 210, loss: 0.06400701403617859
step: 220, loss: 0.019049637019634247
step: 230, loss: 0.052126847207546234
step: 240, loss: 0.0144078079611063
step: 250, loss: 0.0002199233858846128
step: 260, loss: 7.718094275332987e-05
step: 270, loss: 0.01428978145122528
step: 280, loss: 0.055596206337213516
step: 290, loss: 0.0352841354906559
step: 300, loss: 0.07390895485877991
step: 310, loss: 2.1567879230133258e-05
step: 320, loss: 0.02108616568148136
step: 330, loss: 0.021143997088074684
step: 340, loss: 0.022330284118652344
step: 350, loss: 0.04273202270269394
step: 360, loss: 6.414917152142152e-05
step: 370, loss: 0.015912415459752083
step: 380, loss: 0.020699137821793556
step: 390, loss: 0.015138526447117329
step: 400, loss: 0.0009286928689107299
step: 410, loss: 0.00010890336125157773
step: 420, loss: 0.08291194587945938
step: 430, loss: 0.03426726907491684
step: 440, loss: 0.0491417720913887
step: 450, loss: 3.042263415409252e-05
step: 460, loss: 0.05385582894086838
epoch 15: dev_f1=0.9921259842519685, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.050364699214696884
step: 10, loss: 0.027145689353346825
step: 20, loss: 0.015914585441350937
step: 30, loss: 0.02318580448627472
step: 40, loss: 0.02095343917608261
step: 50, loss: 0.01629757694900036
step: 60, loss: 2.6515424906392582e-05
step: 70, loss: 0.07092629373073578
step: 80, loss: 0.029181236401200294
step: 90, loss: 0.034436289221048355
step: 100, loss: 0.02788309007883072
step: 110, loss: 0.04314199462532997
step: 120, loss: 0.03930197283625603
step: 130, loss: 0.06070318818092346
step: 140, loss: 0.0008896029903553426
step: 150, loss: 0.0002516266831662506
step: 160, loss: 0.000301664462313056
step: 170, loss: 0.044280264526605606
step: 180, loss: 0.04111088812351227
step: 190, loss: 0.00015003039152361453
step: 200, loss: 0.02402244508266449
step: 210, loss: 0.0940389633178711
step: 220, loss: 0.05217356234788895
step: 230, loss: 0.0022169833537191153
step: 240, loss: 0.022397859022021294
step: 250, loss: 0.02062123827636242
step: 260, loss: 0.022431714460253716
step: 270, loss: 0.021705569699406624
step: 280, loss: 5.178914580028504e-05
step: 290, loss: 0.051021501421928406
step: 300, loss: 0.00021941126033198088
step: 310, loss: 0.02502981573343277
step: 320, loss: 0.016216875985264778
step: 330, loss: 0.016873568296432495
step: 340, loss: 0.02247423678636551
step: 350, loss: 2.5906290829880163e-05
step: 360, loss: 0.02536604180932045
step: 370, loss: 0.08168318122625351
step: 380, loss: 0.02402295358479023
step: 390, loss: 0.042966146022081375
step: 400, loss: 0.020714180544018745
step: 410, loss: 6.655299512203783e-05
step: 420, loss: 0.02498677559196949
step: 430, loss: 0.07612103223800659
step: 440, loss: 0.02399407885968685
step: 450, loss: 0.03666258230805397
step: 460, loss: 0.009430298581719398
epoch 16: dev_f1=0.9921259842519685, f1=0.9876819708846584, best_f1=0.9820224719101124
step: 0, loss: 0.022168103605508804
step: 10, loss: 0.0001889258564915508
step: 20, loss: 0.045881353318691254
step: 30, loss: 1.9780507500399835e-05
step: 40, loss: 0.06445375084877014
step: 50, loss: 0.024961894378066063
step: 60, loss: 0.04290473833680153
step: 70, loss: 0.013602670282125473
step: 80, loss: 0.062315721064805984
step: 90, loss: 0.061677463352680206
step: 100, loss: 0.02591545134782791
step: 110, loss: 1.5239952517731581e-05
step: 120, loss: 0.06751099973917007
step: 130, loss: 0.0021308925934135914
step: 140, loss: 0.02277779020369053
step: 150, loss: 0.01644987240433693
step: 160, loss: 0.008662508800625801
step: 170, loss: 0.04861937463283539
step: 180, loss: 0.05700403451919556
step: 190, loss: 0.02981550619006157
step: 200, loss: 0.025389326736330986
step: 210, loss: 0.02339348755776882
step: 220, loss: 0.025314005091786385
step: 230, loss: 0.03291640803217888
step: 240, loss: 0.0578109435737133
step: 250, loss: 0.010843009687960148
step: 260, loss: 0.05182531476020813
step: 270, loss: 0.018364878371357918
step: 280, loss: 0.026598956435918808
step: 290, loss: 0.02325185388326645
step: 300, loss: 2.0913164917146787e-05
step: 310, loss: 0.04942534491419792
step: 320, loss: 0.017874523997306824
step: 330, loss: 0.02129456028342247
step: 340, loss: 0.037809256464242935
step: 350, loss: 0.021363351494073868
step: 360, loss: 4.692480433732271e-05
step: 370, loss: 0.023050062358379364
step: 380, loss: 0.026067839935421944
step: 390, loss: 0.019305184483528137
step: 400, loss: 0.02725059539079666
step: 410, loss: 0.019841108471155167
step: 420, loss: 7.014915900072083e-05
step: 430, loss: 0.02186521142721176
step: 440, loss: 0.00165787513833493
step: 450, loss: 0.00017638082499615848
step: 460, loss: 0.0001063625022652559
epoch 17: dev_f1=0.9921259842519685, f1=0.9865470852017937, best_f1=0.9820224719101124
step: 0, loss: 4.190432446193881e-05
step: 10, loss: 0.08422208577394485
step: 20, loss: 0.0002231007965747267
step: 30, loss: 0.03327912092208862
step: 40, loss: 7.162983820308e-05
step: 50, loss: 0.07457345724105835
step: 60, loss: 0.038958266377449036
step: 70, loss: 0.0028998986817896366
step: 80, loss: 0.01142117753624916
step: 90, loss: 0.020572930574417114
step: 100, loss: 0.017012236639857292
step: 110, loss: 0.0007481099455617368
step: 120, loss: 4.40879121015314e-05
step: 130, loss: 0.0001306808553636074
step: 140, loss: 0.037645868957042694
step: 150, loss: 0.049223873764276505
step: 160, loss: 9.330185275757685e-05
step: 170, loss: 0.06662098318338394
step: 180, loss: 0.024124182760715485
step: 190, loss: 0.04473986104130745
step: 200, loss: 0.025745388120412827
step: 210, loss: 0.022337688133120537
step: 220, loss: 0.00011333145084790885
step: 230, loss: 0.0001343868498224765
step: 240, loss: 0.011942623183131218
step: 250, loss: 0.06045200675725937
step: 260, loss: 0.02197251468896866
step: 270, loss: 0.00013518794730771333
step: 280, loss: 0.035818539559841156
step: 290, loss: 0.06379308551549911
step: 300, loss: 3.7164896639296785e-05
step: 310, loss: 0.026032859459519386
step: 320, loss: 0.0001516368065495044
step: 330, loss: 0.09570299834012985
step: 340, loss: 0.02368962951004505
step: 350, loss: 4.897893450106494e-05
step: 360, loss: 0.019926361739635468
step: 370, loss: 0.023661192506551743
step: 380, loss: 0.023051336407661438
step: 390, loss: 0.017252394929528236
step: 400, loss: 0.06761835515499115
step: 410, loss: 0.00016086746472865343
step: 420, loss: 0.018248355016112328
step: 430, loss: 0.024488890543580055
step: 440, loss: 0.03373529389500618
step: 450, loss: 0.000263885100139305
step: 460, loss: 0.023928167298436165
epoch 18: dev_f1=0.9921259842519685, f1=0.9876819708846584, best_f1=0.9820224719101124
step: 0, loss: 0.03238849341869354
step: 10, loss: 0.022212238982319832
step: 20, loss: 0.01794116012752056
step: 30, loss: 0.08730849623680115
step: 40, loss: 0.021987486630678177
step: 50, loss: 0.0726713314652443
step: 60, loss: 0.0173466969281435
step: 70, loss: 0.04288816452026367
step: 80, loss: 0.06137871742248535
step: 90, loss: 9.681875235401094e-05
step: 100, loss: 0.00010334180115023628
step: 110, loss: 0.05187592655420303
step: 120, loss: 0.05332043021917343
step: 130, loss: 0.076893649995327
step: 140, loss: 0.056771084666252136
step: 150, loss: 0.02151075191795826
step: 160, loss: 9.242957457900047e-05
step: 170, loss: 2.9457536584232002e-05
step: 180, loss: 0.0002888333983719349
step: 190, loss: 0.0411105640232563
step: 200, loss: 0.0007313673850148916
step: 210, loss: 0.020998336374759674
step: 220, loss: 0.02246147207915783
step: 230, loss: 0.02874758094549179
step: 240, loss: 0.046185512095689774
step: 250, loss: 0.022892318665981293
step: 260, loss: 0.02566869556903839
step: 270, loss: 0.055119212716817856
step: 280, loss: 0.018613656982779503
step: 290, loss: 0.04877803847193718
step: 300, loss: 9.133986168308184e-05
step: 310, loss: 0.00019849029195029289
step: 320, loss: 0.0008497085655108094
step: 330, loss: 0.02290458418428898
step: 340, loss: 0.0962395966053009
step: 350, loss: 0.03633120656013489
step: 360, loss: 0.022174693644046783
step: 370, loss: 0.048514969646930695
step: 380, loss: 2.512944229238201e-05
step: 390, loss: 0.026875967159867287
step: 400, loss: 0.030532708391547203
step: 410, loss: 0.04952635616064072
step: 420, loss: 0.04181424528360367
step: 430, loss: 0.04312989115715027
step: 440, loss: 0.02181742712855339
step: 450, loss: 0.02302541397511959
step: 460, loss: 0.0007521908264607191
epoch 19: dev_f1=0.9921259842519685, f1=0.9876819708846584, best_f1=0.9820224719101124
step: 0, loss: 5.5496449931524694e-05
step: 10, loss: 0.018727663904428482
step: 20, loss: 4.20521610067226e-05
step: 30, loss: 0.039938196539878845
step: 40, loss: 0.02451060339808464
step: 50, loss: 4.239950067130849e-05
step: 60, loss: 0.00023964485444594175
step: 70, loss: 6.633513839915395e-05
step: 80, loss: 0.04491540044546127
step: 90, loss: 0.00014361598005052656
step: 100, loss: 6.879179272800684e-05
step: 110, loss: 0.03411354869604111
step: 120, loss: 0.01765412651002407
step: 130, loss: 0.02862558700144291
step: 140, loss: 0.046990200877189636
step: 150, loss: 0.018602024763822556
step: 160, loss: 0.023165928199887276
step: 170, loss: 7.937191548990086e-05
step: 180, loss: 0.0006209107814356685
step: 190, loss: 5.402470924309455e-05
step: 200, loss: 0.022777101024985313
step: 210, loss: 0.0002998119161929935
step: 220, loss: 0.0006234612665139139
step: 230, loss: 0.025600656867027283
step: 240, loss: 0.03693922981619835
step: 250, loss: 0.06682758778333664
step: 260, loss: 0.023246318101882935
step: 270, loss: 0.0006530603277496994
step: 280, loss: 0.035583022981882095
step: 290, loss: 0.027013225480914116
step: 300, loss: 0.0605279766023159
step: 310, loss: 0.05985633656382561
step: 320, loss: 4.608762537827715e-05
step: 330, loss: 0.019412603229284286
step: 340, loss: 0.020702125504612923
step: 350, loss: 0.01953486166894436
step: 360, loss: 0.012969914823770523
step: 370, loss: 0.018921365961432457
step: 380, loss: 2.7832395062432624e-05
step: 390, loss: 0.0001549110747873783
step: 400, loss: 4.367083602119237e-05
step: 410, loss: 0.057140182703733444
step: 420, loss: 0.04620609059929848
step: 430, loss: 0.026826269924640656
step: 440, loss: 3.030343577847816e-05
step: 450, loss: 0.022667331621050835
step: 460, loss: 6.36335025774315e-05
epoch 20: dev_f1=0.9921259842519685, f1=0.9876819708846584, best_f1=0.9820224719101124
