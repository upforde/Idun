cuda
Device: cuda
step: 0, loss: 0.6812636852264404
step: 10, loss: 0.23305323719978333
step: 20, loss: 0.0349554605782032
step: 30, loss: 0.09298785775899887
step: 40, loss: 0.22075273096561432
step: 50, loss: 0.3483564853668213
step: 60, loss: 0.21372149884700775
step: 70, loss: 0.36150869727134705
step: 80, loss: 0.1501208394765854
step: 90, loss: 0.26681098341941833
step: 100, loss: 0.37785181403160095
step: 110, loss: 0.22910363972187042
step: 120, loss: 0.1173022985458374
step: 130, loss: 0.18186037242412567
step: 140, loss: 0.3341972827911377
step: 150, loss: 0.3190953731536865
step: 160, loss: 0.23876357078552246
step: 170, loss: 0.40951111912727356
step: 180, loss: 0.40712904930114746
step: 190, loss: 0.23278135061264038
step: 200, loss: 0.135410875082016
step: 210, loss: 0.19076155126094818
step: 220, loss: 0.09960135817527771
step: 230, loss: 0.19803503155708313
step: 240, loss: 0.13730815052986145
step: 250, loss: 0.17389197647571564
step: 260, loss: 0.045777611434459686
step: 270, loss: 0.10255864262580872
step: 280, loss: 0.08181644976139069
step: 290, loss: 0.09131412208080292
step: 300, loss: 0.07914646714925766
step: 310, loss: 0.10904988646507263
step: 320, loss: 0.09900408983230591
step: 330, loss: 0.18474358320236206
epoch 1: dev_f1=0.5714285714285715, f1=0.5304347826086956, best_f1=0.5304347826086956
step: 0, loss: 0.027263538911938667
step: 10, loss: 0.2421795278787613
step: 20, loss: 0.1457943618297577
step: 30, loss: 0.3570743799209595
step: 40, loss: 0.1431596875190735
step: 50, loss: 0.1193849965929985
step: 60, loss: 0.11531107872724533
step: 70, loss: 0.1403343826532364
step: 80, loss: 0.30103757977485657
step: 90, loss: 0.10971218347549438
step: 100, loss: 0.21994581818580627
step: 110, loss: 0.22861331701278687
step: 120, loss: 0.21273694932460785
step: 130, loss: 0.04183391481637955
step: 140, loss: 0.21460729837417603
step: 150, loss: 0.012679429724812508
step: 160, loss: 0.23768101632595062
step: 170, loss: 0.04852241650223732
step: 180, loss: 0.15107277035713196
step: 190, loss: 0.15740494430065155
step: 200, loss: 0.09797443449497223
step: 210, loss: 0.1160779595375061
step: 220, loss: 0.09880421310663223
step: 230, loss: 0.06380849331617355
step: 240, loss: 0.2559056282043457
step: 250, loss: 0.13416613638401031
step: 260, loss: 0.12776514887809753
step: 270, loss: 0.03180487081408501
step: 280, loss: 0.042744867503643036
step: 290, loss: 0.00741858733817935
step: 300, loss: 0.09292581677436829
step: 310, loss: 0.11377020925283432
step: 320, loss: 0.04576605185866356
step: 330, loss: 0.015136247500777245
epoch 2: dev_f1=0.7230046948356808, f1=0.6774193548387097, best_f1=0.6774193548387097
step: 0, loss: 0.02402734011411667
step: 10, loss: 0.03226468712091446
step: 20, loss: 0.019356098026037216
step: 30, loss: 0.17213696241378784
step: 40, loss: 0.0069157821126282215
step: 50, loss: 0.03262286260724068
step: 60, loss: 0.01731988787651062
step: 70, loss: 0.07551780343055725
step: 80, loss: 0.021592887118458748
step: 90, loss: 0.04680057615041733
step: 100, loss: 0.0447453148663044
step: 110, loss: 0.2508586049079895
step: 120, loss: 0.13798049092292786
step: 130, loss: 0.03871564567089081
step: 140, loss: 0.06817853450775146
step: 150, loss: 0.021252349019050598
step: 160, loss: 0.017390158027410507
step: 170, loss: 0.02840578183531761
step: 180, loss: 0.07895465195178986
step: 190, loss: 0.10285613685846329
step: 200, loss: 0.07135912775993347
step: 210, loss: 0.10422059893608093
step: 220, loss: 0.10686933249235153
step: 230, loss: 0.20371855795383453
step: 240, loss: 0.0023736711591482162
step: 250, loss: 0.12642568349838257
step: 260, loss: 0.2282550185918808
step: 270, loss: 0.009950719773769379
step: 280, loss: 0.14150896668434143
step: 290, loss: 0.010246356017887592
step: 300, loss: 0.04310225695371628
step: 310, loss: 0.06974601745605469
step: 320, loss: 0.11521913856267929
step: 330, loss: 0.12325108796358109
epoch 3: dev_f1=0.7808564231738037, f1=0.7577937649880095, best_f1=0.7577937649880095
step: 0, loss: 0.1626584231853485
step: 10, loss: 0.0307038314640522
step: 20, loss: 0.00974321085959673
step: 30, loss: 0.0016546493861824274
step: 40, loss: 0.004191551357507706
step: 50, loss: 0.03167221322655678
step: 60, loss: 0.09270468354225159
step: 70, loss: 0.09150509536266327
step: 80, loss: 0.000548408308532089
step: 90, loss: 0.009908364154398441
step: 100, loss: 0.058534398674964905
step: 110, loss: 0.0037163731176406145
step: 120, loss: 0.023107361048460007
step: 130, loss: 0.037803128361701965
step: 140, loss: 0.11336106061935425
step: 150, loss: 0.05788883566856384
step: 160, loss: 0.023105384781956673
step: 170, loss: 0.023792123422026634
step: 180, loss: 0.007945946417748928
step: 190, loss: 0.009796969592571259
step: 200, loss: 0.07510983198881149
step: 210, loss: 0.027506845071911812
step: 220, loss: 0.05278778448700905
step: 230, loss: 0.03700731322169304
step: 240, loss: 0.0033240204211324453
step: 250, loss: 0.02723955363035202
step: 260, loss: 0.0054044877178967
step: 270, loss: 0.03470559045672417
step: 280, loss: 0.008991483598947525
step: 290, loss: 0.09892538189888
step: 300, loss: 0.011632660403847694
step: 310, loss: 0.038065966218709946
step: 320, loss: 0.08010392636060715
step: 330, loss: 0.09598639607429504
epoch 4: dev_f1=0.7888631090487238, f1=0.7837837837837838, best_f1=0.7837837837837838
step: 0, loss: 0.007492727134376764
step: 10, loss: 0.009643493220210075
step: 20, loss: 0.04387073218822479
step: 30, loss: 0.03325069695711136
step: 40, loss: 0.04759545996785164
step: 50, loss: 0.00294196093454957
step: 60, loss: 0.0031461415346711874
step: 70, loss: 0.007717175874859095
step: 80, loss: 0.0013342860620468855
step: 90, loss: 0.007046223618090153
step: 100, loss: 0.0024779713712632656
step: 110, loss: 0.03569919988512993
step: 120, loss: 0.000700627570040524
step: 130, loss: 0.005222294479608536
step: 140, loss: 0.012296431697905064
step: 150, loss: 0.07817386835813522
step: 160, loss: 0.029054800048470497
step: 170, loss: 0.13424746692180634
step: 180, loss: 0.02152397111058235
step: 190, loss: 0.1234687939286232
step: 200, loss: 0.15846450626850128
step: 210, loss: 0.05821293219923973
step: 220, loss: 0.0066659701988101006
step: 230, loss: 0.0020717016886919737
step: 240, loss: 0.0007184452842921019
step: 250, loss: 0.0018909265054389834
step: 260, loss: 0.02906009927392006
step: 270, loss: 0.012878160923719406
step: 280, loss: 0.012398920953273773
step: 290, loss: 0.006747377570718527
step: 300, loss: 0.022766882553696632
step: 310, loss: 0.05876569449901581
step: 320, loss: 0.006520359311252832
step: 330, loss: 0.1142226979136467
epoch 5: dev_f1=0.8065268065268064, f1=0.7645687645687645, best_f1=0.7645687645687645
step: 0, loss: 0.006482409778982401
step: 10, loss: 0.022878292948007584
step: 20, loss: 0.15962329506874084
step: 30, loss: 0.022621361538767815
step: 40, loss: 0.018346596509218216
step: 50, loss: 0.01706438884139061
step: 60, loss: 0.0063995616510510445
step: 70, loss: 0.18222756683826447
step: 80, loss: 0.03296816349029541
step: 90, loss: 0.008425967767834663
step: 100, loss: 0.009939148090779781
step: 110, loss: 0.0011770876590162516
step: 120, loss: 0.017511267215013504
step: 130, loss: 0.20566822588443756
step: 140, loss: 0.05798264965415001
step: 150, loss: 0.05175253748893738
step: 160, loss: 0.06680849939584732
step: 170, loss: 0.019166981801390648
step: 180, loss: 0.02240792103111744
step: 190, loss: 0.026692992076277733
step: 200, loss: 0.00013832766853738576
step: 210, loss: 0.021171800792217255
step: 220, loss: 0.030868535861372948
step: 230, loss: 0.019630175083875656
step: 240, loss: 0.02254893071949482
step: 250, loss: 0.004631909541785717
step: 260, loss: 0.046955086290836334
step: 270, loss: 0.005755862221121788
step: 280, loss: 0.01390641275793314
step: 290, loss: 0.02695479430258274
step: 300, loss: 0.025600727647542953
step: 310, loss: 0.045129209756851196
step: 320, loss: 0.0018216781318187714
step: 330, loss: 0.0026171677745878696
epoch 6: dev_f1=0.7703349282296651, f1=0.7627906976744185, best_f1=0.7645687645687645
step: 0, loss: 0.14486080408096313
step: 10, loss: 0.05493480712175369
step: 20, loss: 0.0025710328482091427
step: 30, loss: 0.0028437140863388777
step: 40, loss: 0.010317491367459297
step: 50, loss: 0.03754492104053497
step: 60, loss: 0.013129155151546001
step: 70, loss: 0.003884062869474292
step: 80, loss: 0.017750943079590797
step: 90, loss: 0.001184459775686264
step: 100, loss: 0.00018433814693707973
step: 110, loss: 0.007519819773733616
step: 120, loss: 0.11566618084907532
step: 130, loss: 0.05744615197181702
step: 140, loss: 0.025977879762649536
step: 150, loss: 0.021422067657113075
step: 160, loss: 0.007985755801200867
step: 170, loss: 0.0005835884367115796
step: 180, loss: 0.020518193021416664
step: 190, loss: 0.0013629301683977246
step: 200, loss: 0.14704681932926178
step: 210, loss: 0.005144760012626648
step: 220, loss: 0.00017304409993812442
step: 230, loss: 0.0025031089317053556
step: 240, loss: 0.0021502915769815445
step: 250, loss: 0.03625655919313431
step: 260, loss: 0.003185585141181946
step: 270, loss: 0.03911304101347923
step: 280, loss: 0.06830144673585892
step: 290, loss: 0.02369542419910431
step: 300, loss: 0.00043005202314816415
step: 310, loss: 4.97385481139645e-05
step: 320, loss: 0.0022315916139632463
step: 330, loss: 0.012012925930321217
epoch 7: dev_f1=0.7526315789473685, f1=0.7450980392156863, best_f1=0.7645687645687645
step: 0, loss: 0.0004417957679834217
step: 10, loss: 0.0019342736341059208
step: 20, loss: 0.000970744586084038
step: 30, loss: 9.496799611952156e-05
step: 40, loss: 0.00037567332037724555
step: 50, loss: 0.0004396143776830286
step: 60, loss: 0.0007205344154499471
step: 70, loss: 7.755540718790144e-05
step: 80, loss: 0.0038266261108219624
step: 90, loss: 0.001577094430103898
step: 100, loss: 0.002327326685190201
step: 110, loss: 0.04971396178007126
step: 120, loss: 0.014453593641519547
step: 130, loss: 0.015085822902619839
step: 140, loss: 0.0016751387156546116
step: 150, loss: 0.009738190099596977
step: 160, loss: 0.0043767280876636505
step: 170, loss: 0.00382423447445035
step: 180, loss: 0.007990961894392967
step: 190, loss: 0.00014980402193032205
step: 200, loss: 0.006973120849579573
step: 210, loss: 0.00022568802523892373
step: 220, loss: 0.07834278792142868
step: 230, loss: 0.002487880177795887
step: 240, loss: 0.015807829797267914
step: 250, loss: 0.00045952360960654914
step: 260, loss: 0.0016127603594213724
step: 270, loss: 0.007731953170150518
step: 280, loss: 0.04732487350702286
step: 290, loss: 0.013224191032350063
step: 300, loss: 0.0019254162907600403
step: 310, loss: 0.00020297041919548064
step: 320, loss: 0.0009731458849273622
step: 330, loss: 0.09118591248989105
epoch 8: dev_f1=0.7990762124711317, f1=0.7454545454545455, best_f1=0.7645687645687645
step: 0, loss: 0.0027508309576660395
step: 10, loss: 0.0008806389523670077
step: 20, loss: 0.005969011224806309
step: 30, loss: 0.004236666485667229
step: 40, loss: 0.18142978847026825
step: 50, loss: 0.0021069650538265705
step: 60, loss: 0.01832551881670952
step: 70, loss: 0.0005951908533461392
step: 80, loss: 0.06808045506477356
step: 90, loss: 0.03053974360227585
step: 100, loss: 0.0001489878777647391
step: 110, loss: 0.0033045874442905188
step: 120, loss: 0.04349212348461151
step: 130, loss: 0.020447148010134697
step: 140, loss: 0.02961811237037182
step: 150, loss: 0.011533334851264954
step: 160, loss: 0.00018402893329039216
step: 170, loss: 0.009412056766450405
step: 180, loss: 0.00012208425323478878
step: 190, loss: 0.00010621360706863925
step: 200, loss: 0.0005019028903916478
step: 210, loss: 0.0019526004325598478
step: 220, loss: 0.0005824558320455253
step: 230, loss: 0.003379635978490114
step: 240, loss: 0.0036398388911038637
step: 250, loss: 0.0007491063443012536
step: 260, loss: 0.0013356787385419011
step: 270, loss: 0.007457115687429905
step: 280, loss: 6.80019220453687e-05
step: 290, loss: 0.0017456932691857219
step: 300, loss: 0.028336573392152786
step: 310, loss: 0.0008336094324477017
step: 320, loss: 0.0003532158734742552
step: 330, loss: 0.0005900379037484527
epoch 9: dev_f1=0.7980997624703088, f1=0.76056338028169, best_f1=0.7645687645687645
step: 0, loss: 4.706297841039486e-05
step: 10, loss: 0.05415131896734238
step: 20, loss: 0.0001795402349671349
step: 30, loss: 0.0009663018281571567
step: 40, loss: 8.635611447971314e-05
step: 50, loss: 0.008564775809645653
step: 60, loss: 0.00022919832554180175
step: 70, loss: 0.27075886726379395
step: 80, loss: 0.006871447898447514
step: 90, loss: 0.0023306210059672594
step: 100, loss: 0.0066912551410496235
step: 110, loss: 0.0010613423073664308
step: 120, loss: 0.02948172390460968
step: 130, loss: 0.007196909282356501
step: 140, loss: 0.0017950106412172318
step: 150, loss: 0.0024362646508961916
step: 160, loss: 0.0016809911467134953
step: 170, loss: 0.0011665878118947148
step: 180, loss: 0.00039637452573515475
step: 190, loss: 0.002160924021154642
step: 200, loss: 0.018644819036126137
step: 210, loss: 0.03390144556760788
step: 220, loss: 0.002739022485911846
step: 230, loss: 0.031122764572501183
step: 240, loss: 0.00022847966465633363
step: 250, loss: 0.0028767804615199566
step: 260, loss: 0.00012718104699160904
step: 270, loss: 0.013411004096269608
step: 280, loss: 0.001619750983081758
step: 290, loss: 0.06535176187753677
step: 300, loss: 5.3753530664835125e-05
step: 310, loss: 0.004949941765516996
step: 320, loss: 0.00043303004349581897
step: 330, loss: 0.0017732081469148397
epoch 10: dev_f1=0.7738693467336684, f1=0.7630331753554502, best_f1=0.7645687645687645
step: 0, loss: 0.002518267137929797
step: 10, loss: 0.00021455191017594188
step: 20, loss: 0.02345493994653225
step: 30, loss: 0.0781598836183548
step: 40, loss: 6.485515041276813e-05
step: 50, loss: 0.00012937418068759143
step: 60, loss: 9.6869160188362e-05
step: 70, loss: 0.008630538359284401
step: 80, loss: 0.0070889731869101524
step: 90, loss: 0.0010075659956783056
step: 100, loss: 0.0006274400511756539
step: 110, loss: 4.8696987505536526e-05
step: 120, loss: 0.0345270000398159
step: 130, loss: 0.004724860657006502
step: 140, loss: 0.0004948511486873031
step: 150, loss: 0.012032557278871536
step: 160, loss: 8.27153999125585e-05
step: 170, loss: 0.0015581430634483695
step: 180, loss: 0.007735983934253454
step: 190, loss: 0.00010362413740949705
step: 200, loss: 9.841088467510417e-05
step: 210, loss: 0.0021700174547731876
step: 220, loss: 0.0005402314709499478
step: 230, loss: 0.0006000642315484583
step: 240, loss: 0.004449442028999329
step: 250, loss: 0.000922732288017869
step: 260, loss: 0.005983010865747929
step: 270, loss: 0.018203340470790863
step: 280, loss: 0.018735449761152267
step: 290, loss: 0.00333399698138237
step: 300, loss: 0.003947806544601917
step: 310, loss: 0.002588587813079357
step: 320, loss: 0.041360799223184586
step: 330, loss: 3.609638588386588e-05
epoch 11: dev_f1=0.7707808564231737, f1=0.7923627684964201, best_f1=0.7645687645687645
step: 0, loss: 0.00011638430441962555
step: 10, loss: 0.0005034034256823361
step: 20, loss: 0.002679769415408373
step: 30, loss: 0.09563210606575012
step: 40, loss: 0.0009943178156390786
step: 50, loss: 0.0006869857897982001
step: 60, loss: 0.0016523400554433465
step: 70, loss: 0.000603487016633153
step: 80, loss: 0.0007970414008013904
step: 90, loss: 0.0026732180267572403
step: 100, loss: 0.0003143354842904955
step: 110, loss: 0.0013361542951315641
step: 120, loss: 0.00028799401479773223
step: 130, loss: 0.016038496047258377
step: 140, loss: 0.00017753386055119336
step: 150, loss: 0.0002752172586042434
step: 160, loss: 0.0011019797530025244
step: 170, loss: 0.00018047764024231583
step: 180, loss: 0.004784704186022282
step: 190, loss: 0.03085138648748398
step: 200, loss: 0.004519033245742321
step: 210, loss: 0.00037591191357932985
step: 220, loss: 0.0008882476831786335
step: 230, loss: 0.0003979487519245595
step: 240, loss: 0.01611390896141529
step: 250, loss: 0.005076141096651554
step: 260, loss: 0.00015086654457263649
step: 270, loss: 0.010305745527148247
step: 280, loss: 0.00035182313877157867
step: 290, loss: 0.010320501402020454
step: 300, loss: 0.0199746023863554
step: 310, loss: 0.00031062294146977365
step: 320, loss: 0.0002543128503020853
step: 330, loss: 0.0027440295089036226
epoch 12: dev_f1=0.7653061224489796, f1=0.7524752475247525, best_f1=0.7645687645687645
step: 0, loss: 0.00013562444655690342
step: 10, loss: 0.002437469782307744
step: 20, loss: 0.06513034552335739
step: 30, loss: 7.62496201787144e-05
step: 40, loss: 0.002815535059198737
step: 50, loss: 0.015964681282639503
step: 60, loss: 0.0007725356263108552
step: 70, loss: 5.158708881936036e-05
step: 80, loss: 0.00022583930694963783
step: 90, loss: 5.081461858935654e-05
step: 100, loss: 3.710264718392864e-05
step: 110, loss: 0.19599367678165436
step: 120, loss: 2.764455166470725e-05
step: 130, loss: 0.00021635442681144923
step: 140, loss: 0.003050116589292884
step: 150, loss: 0.00039268264663405716
step: 160, loss: 0.00015110967797227204
step: 170, loss: 0.00012079376028850675
step: 180, loss: 0.0016670487821102142
step: 190, loss: 0.002271316247060895
step: 200, loss: 0.06488803774118423
step: 210, loss: 0.04218001291155815
step: 220, loss: 0.001505686086602509
step: 230, loss: 0.0013469865079969168
step: 240, loss: 0.01520038302987814
step: 250, loss: 0.0009472679812461138
step: 260, loss: 0.0036089445929974318
step: 270, loss: 0.023157095536589622
step: 280, loss: 0.0034874023403972387
step: 290, loss: 0.00618370296433568
step: 300, loss: 5.2893974498147145e-05
step: 310, loss: 0.01623968966305256
step: 320, loss: 5.361014700611122e-05
step: 330, loss: 0.00022150762379169464
epoch 13: dev_f1=0.7838479809976248, f1=0.7934272300469484, best_f1=0.7645687645687645
step: 0, loss: 0.0002711688575800508
step: 10, loss: 0.00012907010386697948
step: 20, loss: 0.0020145648159086704
step: 30, loss: 0.003309702966362238
step: 40, loss: 0.0004415913426782936
step: 50, loss: 0.005731400102376938
step: 60, loss: 0.00027814420172944665
step: 70, loss: 0.0002590661169961095
step: 80, loss: 0.0005618936265818775
step: 90, loss: 0.0014017096254974604
step: 100, loss: 4.13376692449674e-05
step: 110, loss: 0.0003756794903893024
step: 120, loss: 0.0002632214454934001
step: 130, loss: 0.0001400714390911162
step: 140, loss: 0.00015804724534973502
step: 150, loss: 0.00014135308447293937
step: 160, loss: 5.094366133562289e-05
step: 170, loss: 0.0002618298167362809
step: 180, loss: 0.0002530335623305291
step: 190, loss: 0.0018828004831448197
step: 200, loss: 0.0009415628155693412
step: 210, loss: 4.5382264943327755e-05
step: 220, loss: 2.781600778689608e-05
step: 230, loss: 8.578912093071267e-05
step: 240, loss: 9.423347364645451e-05
step: 250, loss: 0.06941546499729156
step: 260, loss: 5.1470724429236725e-05
step: 270, loss: 0.000708277802914381
step: 280, loss: 5.424298069556244e-05
step: 290, loss: 0.0005194986006245017
step: 300, loss: 0.00012228493869770318
step: 310, loss: 0.0006695165648125112
step: 320, loss: 0.00033803272526711226
step: 330, loss: 0.00015615555457770824
epoch 14: dev_f1=0.7546174142480211, f1=0.7680798004987531, best_f1=0.7645687645687645
step: 0, loss: 0.0003246513078920543
step: 10, loss: 0.0005873885238543153
step: 20, loss: 0.000396587944123894
step: 30, loss: 0.040192145854234695
step: 40, loss: 0.0004562902031466365
step: 50, loss: 0.10142796486616135
step: 60, loss: 2.960684651043266e-05
step: 70, loss: 0.03692743927240372
step: 80, loss: 0.0004710840294137597
step: 90, loss: 4.7687448386568576e-05
step: 100, loss: 0.0013886605156585574
step: 110, loss: 3.4806798794306815e-05
step: 120, loss: 3.277318683103658e-05
step: 130, loss: 2.028374728979543e-05
step: 140, loss: 2.1136949726496823e-05
step: 150, loss: 0.00017354745068587363
step: 160, loss: 0.00029082148103043437
step: 170, loss: 8.08463737484999e-05
step: 180, loss: 0.0007910286076366901
step: 190, loss: 0.00464562838897109
step: 200, loss: 0.00043352972716093063
step: 210, loss: 0.0002076589735224843
step: 220, loss: 4.4489082938525826e-05
step: 230, loss: 0.10075220465660095
step: 240, loss: 0.006322114262729883
step: 250, loss: 0.004783650394529104
step: 260, loss: 0.001100557274185121
step: 270, loss: 0.0004725125036202371
step: 280, loss: 0.000394254777347669
step: 290, loss: 2.200104972871486e-05
step: 300, loss: 0.00015048369823489338
step: 310, loss: 6.395381933543831e-05
step: 320, loss: 9.668844722909853e-05
step: 330, loss: 0.048895638436079025
epoch 15: dev_f1=0.7419354838709677, f1=0.752577319587629, best_f1=0.7645687645687645
step: 0, loss: 0.00015119748422876
step: 10, loss: 0.01567871868610382
step: 20, loss: 0.0006543901981785893
step: 30, loss: 0.000976473733317107
step: 40, loss: 0.023523341864347458
step: 50, loss: 0.006963458843529224
step: 60, loss: 0.00036146631464362144
step: 70, loss: 4.547726712189615e-05
step: 80, loss: 0.02122935652732849
step: 90, loss: 0.00017238387954421341
step: 100, loss: 0.0001101615052903071
step: 110, loss: 9.910650260280818e-05
step: 120, loss: 0.009769018739461899
step: 130, loss: 0.04888969659805298
step: 140, loss: 7.302137964870781e-05
step: 150, loss: 0.003451460273936391
step: 160, loss: 6.22353472863324e-05
step: 170, loss: 7.839477621018887e-05
step: 180, loss: 0.002767974976450205
step: 190, loss: 0.0001753550604917109
step: 200, loss: 7.129627192625776e-05
step: 210, loss: 0.0008749093394726515
step: 220, loss: 0.0006360801053233445
step: 230, loss: 9.088944352697581e-05
step: 240, loss: 6.886684423079714e-05
step: 250, loss: 5.2077699365327135e-05
step: 260, loss: 5.572794907493517e-05
step: 270, loss: 6.168478284962475e-05
step: 280, loss: 6.273930193856359e-05
step: 290, loss: 0.0005872759502381086
step: 300, loss: 0.00010368932998972014
step: 310, loss: 0.0003282116667833179
step: 320, loss: 0.0011569150956347585
step: 330, loss: 8.025296847335994e-05
epoch 16: dev_f1=0.7567567567567567, f1=0.7645569620253165, best_f1=0.7645687645687645
step: 0, loss: 0.00011475244536995888
step: 10, loss: 7.67144447308965e-05
step: 20, loss: 7.302549784071743e-05
step: 30, loss: 0.006234923843294382
step: 40, loss: 4.500747672864236e-05
step: 50, loss: 0.00012401600542943925
step: 60, loss: 8.553185762139037e-05
step: 70, loss: 0.002655825112015009
step: 80, loss: 0.00018845414160750806
step: 90, loss: 9.312920883530751e-05
step: 100, loss: 0.00017532562196720392
step: 110, loss: 0.008131241425871849
step: 120, loss: 0.000856716011185199
step: 130, loss: 1.5180426998995245e-05
step: 140, loss: 0.0001844904327299446
step: 150, loss: 2.306262649653945e-05
step: 160, loss: 4.497476402320899e-05
step: 170, loss: 0.0019231875194236636
step: 180, loss: 0.0017945580184459686
step: 190, loss: 0.01046472042798996
step: 200, loss: 4.3679287045961246e-05
step: 210, loss: 0.006943369749933481
step: 220, loss: 0.00012456916738301516
step: 230, loss: 0.00028037073207087815
step: 240, loss: 4.731273293145932e-05
step: 250, loss: 8.111005445243791e-05
step: 260, loss: 2.4832090275594965e-05
step: 270, loss: 0.0001359331072308123
step: 280, loss: 0.0016323138261213899
step: 290, loss: 0.010696152225136757
step: 300, loss: 6.032942474121228e-05
step: 310, loss: 3.16884252242744e-05
step: 320, loss: 0.0005076144589111209
step: 330, loss: 0.00010993180330842733
epoch 17: dev_f1=0.763157894736842, f1=0.7575757575757577, best_f1=0.7645687645687645
step: 0, loss: 0.0015072018140926957
step: 10, loss: 2.0358118490548804e-05
step: 20, loss: 0.0007188878953456879
step: 30, loss: 0.0012742760591208935
step: 40, loss: 0.003723142435774207
step: 50, loss: 6.926657806616277e-05
step: 60, loss: 6.475876580225304e-05
step: 70, loss: 5.108627010486089e-05
step: 80, loss: 7.883045327616856e-05
step: 90, loss: 0.011303260922431946
step: 100, loss: 0.0016629062592983246
step: 110, loss: 0.011701306328177452
step: 120, loss: 4.900752901448868e-05
step: 130, loss: 6.719024531776085e-05
step: 140, loss: 0.015575099736452103
step: 150, loss: 0.0025069343391805887
step: 160, loss: 0.00011014332994818687
step: 170, loss: 3.8001562643330544e-05
step: 180, loss: 4.928009366267361e-05
step: 190, loss: 0.09322500973939896
step: 200, loss: 0.0008208607905544341
step: 210, loss: 0.00012410531053319573
step: 220, loss: 1.793317642295733e-05
step: 230, loss: 3.774892684305087e-05
step: 240, loss: 2.2213434931472875e-05
step: 250, loss: 0.010851297527551651
step: 260, loss: 0.0002334843302378431
step: 270, loss: 2.7595615392783657e-05
step: 280, loss: 0.0010286589385941625
step: 290, loss: 4.718824493465945e-05
step: 300, loss: 8.974939555628225e-05
step: 310, loss: 0.005155185703188181
step: 320, loss: 0.027844881638884544
step: 330, loss: 4.0583494410384446e-05
epoch 18: dev_f1=0.7586206896551725, f1=0.7589743589743588, best_f1=0.7645687645687645
step: 0, loss: 7.325044134631753e-05
step: 10, loss: 3.1445852073375136e-05
step: 20, loss: 3.1141258659772575e-05
step: 30, loss: 2.835538543877192e-05
step: 40, loss: 0.0004902630462311208
step: 50, loss: 0.00607419153675437
step: 60, loss: 0.002712951973080635
step: 70, loss: 4.470913336263038e-05
step: 80, loss: 4.595930295181461e-05
step: 90, loss: 3.749270035768859e-05
step: 100, loss: 1.4450276466959622e-05
step: 110, loss: 0.006441766861826181
step: 120, loss: 3.962386108469218e-05
step: 130, loss: 0.0001394952996633947
step: 140, loss: 4.7695240937173367e-05
step: 150, loss: 5.9458150644786656e-05
step: 160, loss: 0.018181409686803818
step: 170, loss: 6.547811790369451e-05
step: 180, loss: 6.213658343767747e-05
step: 190, loss: 3.057462890865281e-05
step: 200, loss: 2.0730800315504894e-05
step: 210, loss: 9.50271132751368e-05
step: 220, loss: 0.00047702703159302473
step: 230, loss: 0.0005159024149179459
step: 240, loss: 1.9378641809453256e-05
step: 250, loss: 1.9158567738486454e-05
step: 260, loss: 2.173625944124069e-05
step: 270, loss: 0.00021425004524644464
step: 280, loss: 3.088768062298186e-05
step: 290, loss: 6.996747833909467e-05
step: 300, loss: 3.166268652421422e-05
step: 310, loss: 4.1941522795241326e-05
step: 320, loss: 1.6297910406137817e-05
step: 330, loss: 0.0001914823951665312
epoch 19: dev_f1=0.7573333333333334, f1=0.7570332480818416, best_f1=0.7645687645687645
step: 0, loss: 0.00015037866251077503
step: 10, loss: 8.045753202168271e-05
step: 20, loss: 4.9974860303336754e-05
step: 30, loss: 0.0009448782075196505
step: 40, loss: 2.141207551176194e-05
step: 50, loss: 0.00014459865633398294
step: 60, loss: 3.5579556424636394e-05
step: 70, loss: 2.6076257199747488e-05
step: 80, loss: 0.006636373698711395
step: 90, loss: 0.004073584917932749
step: 100, loss: 1.7448832295485772e-05
step: 110, loss: 1.8536695279181004e-05
step: 120, loss: 3.556681258487515e-05
step: 130, loss: 4.302173329051584e-05
step: 140, loss: 0.0010489304549992085
step: 150, loss: 3.850746725220233e-05
step: 160, loss: 6.738131924066693e-05
step: 170, loss: 2.0875879272352904e-05
step: 180, loss: 2.0339450202300213e-05
step: 190, loss: 1.838395655795466e-05
step: 200, loss: 1.702786175883375e-05
step: 210, loss: 0.016917064785957336
step: 220, loss: 4.168281520833261e-05
step: 230, loss: 0.01683432050049305
step: 240, loss: 0.00013790665252599865
step: 250, loss: 7.963257667142898e-05
step: 260, loss: 3.856542753055692e-05
step: 270, loss: 1.4044222552911378e-05
step: 280, loss: 6.862667942186818e-05
step: 290, loss: 0.012532738968729973
step: 300, loss: 1.3142721400072332e-05
step: 310, loss: 0.0029450240544974804
step: 320, loss: 0.00048771887668408453
step: 330, loss: 0.00010264344018651173
epoch 20: dev_f1=0.7553191489361702, f1=0.7570332480818416, best_f1=0.7645687645687645
