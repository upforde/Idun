cuda
Device: cuda
step: 0, loss: 0.5598331689834595
step: 10, loss: 0.2371656447649002
step: 20, loss: 0.28851887583732605
step: 30, loss: 0.3245219588279724
step: 40, loss: 0.25205251574516296
step: 50, loss: 0.23997293412685394
step: 60, loss: 0.4047911465167999
step: 70, loss: 0.14742986857891083
step: 80, loss: 0.13139866292476654
step: 90, loss: 0.2101859748363495
step: 100, loss: 0.4995045065879822
step: 110, loss: 0.13323232531547546
step: 120, loss: 0.13263483345508575
step: 130, loss: 0.20953048765659332
step: 140, loss: 0.28975987434387207
step: 150, loss: 0.154011070728302
step: 160, loss: 0.23022010922431946
step: 170, loss: 0.5830150842666626
step: 180, loss: 0.08711586147546768
step: 190, loss: 0.27461856603622437
step: 200, loss: 0.17455849051475525
step: 210, loss: 0.39238598942756653
step: 220, loss: 0.2475261390209198
step: 230, loss: 0.05786921828985214
step: 240, loss: 0.2274303138256073
step: 250, loss: 0.16811861097812653
step: 260, loss: 0.10883364081382751
step: 270, loss: 0.18364816904067993
step: 280, loss: 0.12213310599327087
step: 290, loss: 0.2637326717376709
step: 300, loss: 0.1325267255306244
step: 310, loss: 0.14047837257385254
step: 320, loss: 0.138576939702034
step: 330, loss: 0.38438770174980164
epoch 1: dev_f1=0.5741176470588235, f1=0.5474613686534215, best_f1=0.5474613686534215
step: 0, loss: 0.05668843537569046
step: 10, loss: 0.16229449212551117
step: 20, loss: 0.06272990256547928
step: 30, loss: 0.2585970461368561
step: 40, loss: 0.43671664595603943
step: 50, loss: 0.15713797509670258
step: 60, loss: 0.30865079164505005
step: 70, loss: 0.3301040828227997
step: 80, loss: 0.11927402019500732
step: 90, loss: 0.09353527426719666
step: 100, loss: 0.08202458918094635
step: 110, loss: 0.08853504061698914
step: 120, loss: 0.012950226664543152
step: 130, loss: 0.11394069343805313
step: 140, loss: 0.06339986622333527
step: 150, loss: 0.07403987646102905
step: 160, loss: 0.2044280618429184
step: 170, loss: 0.08697935193777084
step: 180, loss: 0.05830833688378334
step: 190, loss: 0.04331574589014053
step: 200, loss: 0.09212572127580643
step: 210, loss: 0.11482606083154678
step: 220, loss: 0.06796097010374069
step: 230, loss: 0.043068695813417435
step: 240, loss: 0.18115098774433136
step: 250, loss: 0.084384024143219
step: 260, loss: 0.12216788530349731
step: 270, loss: 0.032666243612766266
step: 280, loss: 0.1181197538971901
step: 290, loss: 0.025457359850406647
step: 300, loss: 0.16743195056915283
step: 310, loss: 0.08991094678640366
step: 320, loss: 0.1312147080898285
step: 330, loss: 0.09949272871017456
epoch 2: dev_f1=0.7590909090909091, f1=0.7488789237668162, best_f1=0.7488789237668162
step: 0, loss: 0.07004682719707489
step: 10, loss: 0.06361072510480881
step: 20, loss: 0.01655811443924904
step: 30, loss: 0.022002490237355232
step: 40, loss: 0.026156369596719742
step: 50, loss: 0.0729905366897583
step: 60, loss: 0.2035840004682541
step: 70, loss: 0.05471162870526314
step: 80, loss: 0.07530667632818222
step: 90, loss: 0.22911256551742554
step: 100, loss: 0.05995338782668114
step: 110, loss: 0.07639997452497482
step: 120, loss: 0.08693566918373108
step: 130, loss: 0.031229261308908463
step: 140, loss: 0.1629931628704071
step: 150, loss: 0.043746545910835266
step: 160, loss: 0.02335146814584732
step: 170, loss: 0.24597622454166412
step: 180, loss: 0.042131416499614716
step: 190, loss: 0.020347746089100838
step: 200, loss: 0.03208957612514496
step: 210, loss: 0.040322475135326385
step: 220, loss: 0.13819557428359985
step: 230, loss: 0.06449765712022781
step: 240, loss: 0.09091462194919586
step: 250, loss: 0.025675011798739433
step: 260, loss: 0.13932253420352936
step: 270, loss: 0.015508033335208893
step: 280, loss: 0.07075925916433334
step: 290, loss: 0.06261556595563889
step: 300, loss: 0.10054337233304977
step: 310, loss: 0.24473993480205536
step: 320, loss: 0.117897629737854
step: 330, loss: 0.09017252922058105
epoch 3: dev_f1=0.8009708737864077, f1=0.78743961352657, best_f1=0.78743961352657
step: 0, loss: 0.028718218207359314
step: 10, loss: 0.025331325829029083
step: 20, loss: 0.03606605902314186
step: 30, loss: 0.08645572513341904
step: 40, loss: 0.05757695063948631
step: 50, loss: 0.007820559665560722
step: 60, loss: 0.07627455145120621
step: 70, loss: 0.04880661517381668
step: 80, loss: 0.04009772837162018
step: 90, loss: 0.04611276090145111
step: 100, loss: 0.039222292602062225
step: 110, loss: 0.1327918916940689
step: 120, loss: 0.013059055432677269
step: 130, loss: 0.05764038488268852
step: 140, loss: 0.005840289406478405
step: 150, loss: 0.01604805514216423
step: 160, loss: 0.025316542014479637
step: 170, loss: 0.07144512981176376
step: 180, loss: 0.051479119807481766
step: 190, loss: 0.007264460902661085
step: 200, loss: 0.003982174210250378
step: 210, loss: 0.0033491530921310186
step: 220, loss: 0.06884361058473587
step: 230, loss: 0.04468963295221329
step: 240, loss: 0.0742686539888382
step: 250, loss: 0.02167217619717121
step: 260, loss: 0.11676877737045288
step: 270, loss: 0.02662401646375656
step: 280, loss: 0.03778165578842163
step: 290, loss: 0.1968396008014679
step: 300, loss: 0.0758759155869484
step: 310, loss: 0.037420790642499924
step: 320, loss: 0.11854074150323868
step: 330, loss: 0.007887271232903004
epoch 4: dev_f1=0.7862407862407862, f1=0.7793427230046948, best_f1=0.78743961352657
step: 0, loss: 0.02838803455233574
step: 10, loss: 0.10913287848234177
step: 20, loss: 0.007934129796922207
step: 30, loss: 0.03390660509467125
step: 40, loss: 0.0009678469505161047
step: 50, loss: 0.014182017184793949
step: 60, loss: 0.008066036738455296
step: 70, loss: 0.000918757461477071
step: 80, loss: 0.031387001276016235
step: 90, loss: 0.022888360545039177
step: 100, loss: 0.012979094870388508
step: 110, loss: 0.035887014120817184
step: 120, loss: 0.014599010348320007
step: 130, loss: 0.003802364692091942
step: 140, loss: 0.008556663058698177
step: 150, loss: 0.031217403709888458
step: 160, loss: 0.01026131957769394
step: 170, loss: 0.10022444278001785
step: 180, loss: 0.00914672575891018
step: 190, loss: 0.004220376722514629
step: 200, loss: 0.1202411875128746
step: 210, loss: 0.018092554062604904
step: 220, loss: 0.046241674572229385
step: 230, loss: 0.007076113019138575
step: 240, loss: 0.009449607692658901
step: 250, loss: 0.002268442651256919
step: 260, loss: 0.011618373915553093
step: 270, loss: 0.015664974227547646
step: 280, loss: 0.00046814672532491386
step: 290, loss: 0.005861253943294287
step: 300, loss: 0.040560148656368256
step: 310, loss: 0.003509307047352195
step: 320, loss: 0.042905837297439575
step: 330, loss: 0.00496189808472991
epoch 5: dev_f1=0.817258883248731, f1=0.7719298245614035, best_f1=0.7719298245614035
step: 0, loss: 0.015338374301791191
step: 10, loss: 0.019290553405880928
step: 20, loss: 0.0022473346907645464
step: 30, loss: 0.0003372323408257216
step: 40, loss: 0.02595873735845089
step: 50, loss: 0.2809072434902191
step: 60, loss: 0.0022031895350664854
step: 70, loss: 0.029539555311203003
step: 80, loss: 0.01383174303919077
step: 90, loss: 0.020378265529870987
step: 100, loss: 0.006036240141838789
step: 110, loss: 0.010561495088040829
step: 120, loss: 0.00029540268587879837
step: 130, loss: 0.022430485114455223
step: 140, loss: 0.04832720011472702
step: 150, loss: 0.008916415274143219
step: 160, loss: 0.0035257337149232626
step: 170, loss: 0.0009197352919727564
step: 180, loss: 0.01023175474256277
step: 190, loss: 0.002420215168967843
step: 200, loss: 0.110874243080616
step: 210, loss: 0.0006031690281815827
step: 220, loss: 0.0016027915989980102
step: 230, loss: 0.00399766443297267
step: 240, loss: 0.003916972316801548
step: 250, loss: 0.0008967345929704607
step: 260, loss: 0.0019646266009658575
step: 270, loss: 0.08827564865350723
step: 280, loss: 0.005418419372290373
step: 290, loss: 0.005378400906920433
step: 300, loss: 0.000805384072009474
step: 310, loss: 0.012570646591484547
step: 320, loss: 0.03277330845594406
step: 330, loss: 0.04738089069724083
epoch 6: dev_f1=0.8223350253807107, f1=0.7883211678832117, best_f1=0.7883211678832117
step: 0, loss: 0.004842519760131836
step: 10, loss: 0.006656059995293617
step: 20, loss: 0.0016423455672338605
step: 30, loss: 0.0015780575340613723
step: 40, loss: 0.11088931560516357
step: 50, loss: 0.004877259023487568
step: 60, loss: 0.005388195626437664
step: 70, loss: 0.0017676511779427528
step: 80, loss: 0.10425465553998947
step: 90, loss: 0.0011626856867223978
step: 100, loss: 0.060544468462467194
step: 110, loss: 0.0007243154104799032
step: 120, loss: 0.007168993353843689
step: 130, loss: 0.007621455937623978
step: 140, loss: 0.01850435696542263
step: 150, loss: 0.010859436355531216
step: 160, loss: 0.003612291067838669
step: 170, loss: 0.0010288944467902184
step: 180, loss: 0.03557552024722099
step: 190, loss: 0.032599665224552155
step: 200, loss: 0.0015165942022576928
step: 210, loss: 0.00010537819616729394
step: 220, loss: 0.0369139239192009
step: 230, loss: 0.0367717482149601
step: 240, loss: 0.0106688616797328
step: 250, loss: 0.0014865678967908025
step: 260, loss: 7.428758544847369e-05
step: 270, loss: 0.0019885641522705555
step: 280, loss: 0.003289907705038786
step: 290, loss: 0.0012925532646477222
step: 300, loss: 0.026283428072929382
step: 310, loss: 0.0014506906736642122
step: 320, loss: 0.029224943369627
step: 330, loss: 0.0020084751304239035
epoch 7: dev_f1=0.8010752688172044, f1=0.8020833333333334, best_f1=0.7883211678832117
step: 0, loss: 0.01003576535731554
step: 10, loss: 0.0021433543879538774
step: 20, loss: 0.0408984050154686
step: 30, loss: 0.021848740056157112
step: 40, loss: 0.006166533567011356
step: 50, loss: 0.0004994716146029532
step: 60, loss: 0.0004198807873763144
step: 70, loss: 0.000794523861259222
step: 80, loss: 0.004786809906363487
step: 90, loss: 0.0010003629140555859
step: 100, loss: 0.0062129986472427845
step: 110, loss: 0.004963167477399111
step: 120, loss: 0.0009102769545279443
step: 130, loss: 0.01703452877700329
step: 140, loss: 0.03563261032104492
step: 150, loss: 0.0002813611354213208
step: 160, loss: 0.000337355537340045
step: 170, loss: 0.0016138908686116338
step: 180, loss: 0.07690175622701645
step: 190, loss: 0.003947401884943247
step: 200, loss: 0.002527120290324092
step: 210, loss: 0.0025865763891488314
step: 220, loss: 0.0007430100813508034
step: 230, loss: 0.006571868434548378
step: 240, loss: 0.007023978047072887
step: 250, loss: 0.02710467018187046
step: 260, loss: 0.0006467501516453922
step: 270, loss: 0.03668959438800812
step: 280, loss: 0.001362721319310367
step: 290, loss: 0.0005912076449021697
step: 300, loss: 0.0016158854123204947
step: 310, loss: 0.009383540600538254
step: 320, loss: 0.010924607515335083
step: 330, loss: 6.998021126491949e-05
epoch 8: dev_f1=0.8159203980099503, f1=0.8047058823529412, best_f1=0.7883211678832117
step: 0, loss: 0.0009534915443509817
step: 10, loss: 0.039584044367074966
step: 20, loss: 0.009971532970666885
step: 30, loss: 4.228960460750386e-05
step: 40, loss: 0.0057909367606043816
step: 50, loss: 0.05584714189171791
step: 60, loss: 7.991112943273038e-05
step: 70, loss: 0.016652988269925117
step: 80, loss: 0.048670444637537
step: 90, loss: 0.033391766250133514
step: 100, loss: 0.0024368353188037872
step: 110, loss: 0.000445707468315959
step: 120, loss: 0.010308284312486649
step: 130, loss: 0.0062948232516646385
step: 140, loss: 0.0005717367166653275
step: 150, loss: 0.01630333997309208
step: 160, loss: 0.001434137113392353
step: 170, loss: 0.002071050927042961
step: 180, loss: 0.01798626407980919
step: 190, loss: 0.0008914752979762852
step: 200, loss: 0.0023833075538277626
step: 210, loss: 0.0003034773108083755
step: 220, loss: 0.027401145547628403
step: 230, loss: 0.01952330581843853
step: 240, loss: 7.925579120637849e-05
step: 250, loss: 0.004035888705402613
step: 260, loss: 0.0017096593510359526
step: 270, loss: 0.0035485904663801193
step: 280, loss: 0.012476368807256222
step: 290, loss: 0.0008313526632264256
step: 300, loss: 0.014940138906240463
step: 310, loss: 0.0008647263166494668
step: 320, loss: 0.0021245391108095646
step: 330, loss: 0.0033696256577968597
epoch 9: dev_f1=0.7629427792915532, f1=0.7338501291989664, best_f1=0.7883211678832117
step: 0, loss: 0.0002898668753914535
step: 10, loss: 0.0013060972560197115
step: 20, loss: 0.19416601955890656
step: 30, loss: 0.00037736669764854014
step: 40, loss: 0.019084179773926735
step: 50, loss: 0.0010823080083355308
step: 60, loss: 0.0038604959845542908
step: 70, loss: 0.00030257063917815685
step: 80, loss: 0.019785309210419655
step: 90, loss: 0.0002391272719250992
step: 100, loss: 3.5947919968748465e-05
step: 110, loss: 0.0027106255292892456
step: 120, loss: 0.00011840716615552083
step: 130, loss: 0.00011574687960091978
step: 140, loss: 6.089836824685335e-05
step: 150, loss: 8.617837011115626e-05
step: 160, loss: 0.0005517547251656651
step: 170, loss: 0.002372624119743705
step: 180, loss: 0.08847562223672867
step: 190, loss: 0.0008214185945689678
step: 200, loss: 0.003092151368036866
step: 210, loss: 0.17272748053073883
step: 220, loss: 0.0004524532414507121
step: 230, loss: 0.027292069047689438
step: 240, loss: 0.00012237623741384596
step: 250, loss: 0.0007826388464309275
step: 260, loss: 0.00035492447204887867
step: 270, loss: 0.0002532195649109781
step: 280, loss: 0.01740318536758423
step: 290, loss: 0.00240515754558146
step: 300, loss: 0.0158536396920681
step: 310, loss: 0.005351316649466753
step: 320, loss: 6.264699186431244e-05
step: 330, loss: 0.008330273441970348
epoch 10: dev_f1=0.8009478672985781, f1=0.767816091954023, best_f1=0.7883211678832117
step: 0, loss: 0.00011639806325547397
step: 10, loss: 0.009030244313180447
step: 20, loss: 0.0005141885485500097
step: 30, loss: 0.005507247988134623
step: 40, loss: 0.00012929941294714808
step: 50, loss: 0.0012939072912558913
step: 60, loss: 0.003563170088455081
step: 70, loss: 0.00014113029465079308
step: 80, loss: 0.012643571011722088
step: 90, loss: 0.011517409235239029
step: 100, loss: 4.04807178711053e-05
step: 110, loss: 2.4053857487160712e-05
step: 120, loss: 5.400905502028763e-05
step: 130, loss: 0.002970617264509201
step: 140, loss: 0.0002263182686874643
step: 150, loss: 0.192682147026062
step: 160, loss: 0.00013804987247567624
step: 170, loss: 0.0010275059612467885
step: 180, loss: 1.9289338524686173e-05
step: 190, loss: 0.0005039909738115966
step: 200, loss: 0.00011859888036269695
step: 210, loss: 0.00022714948863722384
step: 220, loss: 0.010988693684339523
step: 230, loss: 0.00015850929776206613
step: 240, loss: 0.001836329814977944
step: 250, loss: 2.5223531338269822e-05
step: 260, loss: 0.011414172127842903
step: 270, loss: 0.0035796898882836103
step: 280, loss: 0.00043901149183511734
step: 290, loss: 0.0028109701815992594
step: 300, loss: 0.01488610077649355
step: 310, loss: 0.016940893605351448
step: 320, loss: 0.000302577594993636
step: 330, loss: 0.012913335114717484
epoch 11: dev_f1=0.7772020725388602, f1=0.7609756097560975, best_f1=0.7883211678832117
step: 0, loss: 0.0003545005456544459
step: 10, loss: 0.0003818948462139815
step: 20, loss: 0.0007039576885290444
step: 30, loss: 8.531105413567275e-05
step: 40, loss: 0.016586970537900925
step: 50, loss: 0.0011296668089926243
step: 60, loss: 0.0057242251932621
step: 70, loss: 0.000515351421199739
step: 80, loss: 0.000241780566284433
step: 90, loss: 0.0002738044422585517
step: 100, loss: 0.004726278595626354
step: 110, loss: 8.09260382084176e-05
step: 120, loss: 0.0018496172269806266
step: 130, loss: 0.0017266353825107217
step: 140, loss: 0.0121687650680542
step: 150, loss: 0.0004919830826111138
step: 160, loss: 9.751129982760176e-05
step: 170, loss: 0.00023464903642889112
step: 180, loss: 8.769021223997697e-05
step: 190, loss: 0.004103136248886585
step: 200, loss: 0.0002911486371885985
step: 210, loss: 0.013784210197627544
step: 220, loss: 0.0004921547952108085
step: 230, loss: 4.966921915183775e-05
step: 240, loss: 0.00349075417034328
step: 250, loss: 0.00043048633961007
step: 260, loss: 0.00014217209536582232
step: 270, loss: 0.00042941159335896373
step: 280, loss: 0.05475129559636116
step: 290, loss: 8.460137905785814e-05
step: 300, loss: 0.0002293699944857508
step: 310, loss: 0.00329401483759284
step: 320, loss: 2.2924794393475167e-05
step: 330, loss: 0.0026468434371054173
epoch 12: dev_f1=0.8262910798122066, f1=0.8117913832199547, best_f1=0.8117913832199547
step: 0, loss: 0.0010043536312878132
step: 10, loss: 0.002510456833988428
step: 20, loss: 0.00032217547413893044
step: 30, loss: 0.0004907585680484772
step: 40, loss: 0.00014520202239509672
step: 50, loss: 0.001110008335672319
step: 60, loss: 0.01306140422821045
step: 70, loss: 0.00042130533256568015
step: 80, loss: 0.0007153947371989489
step: 90, loss: 0.000701075594406575
step: 100, loss: 0.0013136843917891383
step: 110, loss: 0.012051385827362537
step: 120, loss: 0.0003613416920416057
step: 130, loss: 0.029729507863521576
step: 140, loss: 0.00029886141419410706
step: 150, loss: 0.017918551340699196
step: 160, loss: 0.07534332573413849
step: 170, loss: 5.4498628742294386e-05
step: 180, loss: 0.0007109030266292393
step: 190, loss: 0.00014732065028510988
step: 200, loss: 8.449085726169869e-05
step: 210, loss: 0.00017233475227840245
step: 220, loss: 0.00034835105179809034
step: 230, loss: 0.0014949811156839132
step: 240, loss: 0.0020669542718678713
step: 250, loss: 3.18861857522279e-05
step: 260, loss: 0.12217040359973907
step: 270, loss: 0.060218434780836105
step: 280, loss: 0.024053219705820084
step: 290, loss: 0.0018592214910313487
step: 300, loss: 0.012996789999306202
step: 310, loss: 0.0003327850135974586
step: 320, loss: 0.0006407079054042697
step: 330, loss: 0.00010544367978582159
epoch 13: dev_f1=0.8126520681265207, f1=0.7884615384615384, best_f1=0.8117913832199547
step: 0, loss: 0.0021938313730061054
step: 10, loss: 5.564593448070809e-05
step: 20, loss: 0.00016441363550256938
step: 30, loss: 0.00010441362974233925
step: 40, loss: 0.000221046429942362
step: 50, loss: 0.00028860915335826576
step: 60, loss: 0.0001245082967216149
step: 70, loss: 0.01986168697476387
step: 80, loss: 0.06393042951822281
step: 90, loss: 0.005408382508903742
step: 100, loss: 0.00016166840214282274
step: 110, loss: 0.00217682053335011
step: 120, loss: 0.05040079727768898
step: 130, loss: 0.0012426021276041865
step: 140, loss: 0.0008862854447215796
step: 150, loss: 0.001693198224529624
step: 160, loss: 0.012943255715072155
step: 170, loss: 0.0006482170429080725
step: 180, loss: 0.0005878914962522686
step: 190, loss: 0.00040021739550866187
step: 200, loss: 0.006530568469315767
step: 210, loss: 0.00011782169895013794
step: 220, loss: 0.0003951136604882777
step: 230, loss: 0.0015723428223282099
step: 240, loss: 0.01308622770011425
step: 250, loss: 0.007385841105133295
step: 260, loss: 0.00010643702989909798
step: 270, loss: 0.00011893174087163061
step: 280, loss: 0.005470942705869675
step: 290, loss: 0.00038438758929260075
step: 300, loss: 0.0006498991861008108
step: 310, loss: 0.00017798354383558035
step: 320, loss: 0.0030341173987835646
step: 330, loss: 2.7256895918981172e-05
epoch 14: dev_f1=0.8010471204188482, f1=0.7641025641025642, best_f1=0.8117913832199547
step: 0, loss: 0.015994559973478317
step: 10, loss: 9.380387200508267e-05
step: 20, loss: 0.00043785592424683273
step: 30, loss: 1.81300456461031e-05
step: 40, loss: 0.00018867527251131833
step: 50, loss: 0.00038946321001276374
step: 60, loss: 3.93182817788329e-05
step: 70, loss: 0.00020437651255633682
step: 80, loss: 4.348165384726599e-05
step: 90, loss: 0.002033294178545475
step: 100, loss: 0.00014814038877375424
step: 110, loss: 0.00026928502484224737
step: 120, loss: 0.0017801787471398711
step: 130, loss: 0.018923470750451088
step: 140, loss: 0.00041873627924360335
step: 150, loss: 7.562498649349436e-05
step: 160, loss: 0.0004221190756652504
step: 170, loss: 0.00016207036969717592
step: 180, loss: 0.017602723091840744
step: 190, loss: 0.0004330950614530593
step: 200, loss: 3.713461774168536e-05
step: 210, loss: 0.0007193551282398403
step: 220, loss: 0.00012263478129170835
step: 230, loss: 0.00013112276792526245
step: 240, loss: 0.0011739755282178521
step: 250, loss: 4.784620614373125e-05
step: 260, loss: 0.015221855603158474
step: 270, loss: 9.362730634165928e-05
step: 280, loss: 0.0001961212110472843
step: 290, loss: 0.00022837001597508788
step: 300, loss: 0.0008216737769544125
step: 310, loss: 0.004432433284819126
step: 320, loss: 0.00014457956422120333
step: 330, loss: 3.47317909472622e-05
epoch 15: dev_f1=0.7598944591029023, f1=0.7424242424242425, best_f1=0.8117913832199547
step: 0, loss: 8.367210102733225e-05
step: 10, loss: 2.708710599108599e-05
step: 20, loss: 0.0004409058892633766
step: 30, loss: 0.0005663541960529983
step: 40, loss: 0.04503611847758293
step: 50, loss: 0.0007328437641263008
step: 60, loss: 0.0001331872772425413
step: 70, loss: 0.0001192761046695523
step: 80, loss: 0.00452950457111001
step: 90, loss: 0.011714059859514236
step: 100, loss: 0.00038802321068942547
step: 110, loss: 0.0012428534682840109
step: 120, loss: 0.00035812874557450414
step: 130, loss: 0.00017116159142460674
step: 140, loss: 0.03352482244372368
step: 150, loss: 0.00012958000297658145
step: 160, loss: 0.04261243715882301
step: 170, loss: 5.041276745032519e-05
step: 180, loss: 0.00020359313930384815
step: 190, loss: 4.4316708226688206e-05
step: 200, loss: 5.106408934807405e-05
step: 210, loss: 4.751270898850635e-05
step: 220, loss: 3.027629827556666e-05
step: 230, loss: 0.0003195369499735534
step: 240, loss: 9.265982225770131e-05
step: 250, loss: 7.25647623767145e-05
step: 260, loss: 0.07073797285556793
step: 270, loss: 5.351442814571783e-05
step: 280, loss: 0.00816588755697012
step: 290, loss: 0.00015500863082706928
step: 300, loss: 0.0156349278986454
step: 310, loss: 0.0004523784446064383
step: 320, loss: 0.000366826105164364
step: 330, loss: 5.0912258302560076e-05
epoch 16: dev_f1=0.8078817733990147, f1=0.8018867924528301, best_f1=0.8117913832199547
step: 0, loss: 0.00010496061440790072
step: 10, loss: 0.00036398987867869437
step: 20, loss: 2.1698997443309054e-05
step: 30, loss: 0.0029428089037537575
step: 40, loss: 4.5741449866909534e-05
step: 50, loss: 0.0016128785209730268
step: 60, loss: 2.1601435946649872e-05
step: 70, loss: 0.0003041523159481585
step: 80, loss: 9.935220441548154e-05
step: 90, loss: 1.2185278137621935e-05
step: 100, loss: 3.2314714189851657e-05
step: 110, loss: 9.909690561471507e-05
step: 120, loss: 0.0024514244869351387
step: 130, loss: 0.0005719836917705834
step: 140, loss: 2.292052704433445e-05
step: 150, loss: 0.00016732577932998538
step: 160, loss: 9.187801333609968e-05
step: 170, loss: 6.669378490187228e-05
step: 180, loss: 6.522546027554199e-05
step: 190, loss: 1.3351257621252444e-05
step: 200, loss: 0.001710748067125678
step: 210, loss: 0.00012123889609938487
step: 220, loss: 0.13800325989723206
step: 230, loss: 0.0002469283062964678
step: 240, loss: 9.983161726268008e-05
step: 250, loss: 0.0063703907653689384
step: 260, loss: 0.0002825112023856491
step: 270, loss: 0.0015455246903002262
step: 280, loss: 0.005609830841422081
step: 290, loss: 0.0001775747659849003
step: 300, loss: 3.8701738958479837e-05
step: 310, loss: 0.00025382815510965884
step: 320, loss: 0.00011727058154065162
step: 330, loss: 0.0015736034838482738
epoch 17: dev_f1=0.8049382716049382, f1=0.7794117647058824, best_f1=0.8117913832199547
step: 0, loss: 0.00017132317589130253
step: 10, loss: 2.244746428914368e-05
step: 20, loss: 5.33139354956802e-05
step: 30, loss: 4.022556095151231e-05
step: 40, loss: 4.966832420905121e-05
step: 50, loss: 0.00010659718827810138
step: 60, loss: 8.942245040088892e-05
step: 70, loss: 3.7670735764550045e-05
step: 80, loss: 0.021710408851504326
step: 90, loss: 0.0004696763935498893
step: 100, loss: 0.005757907405495644
step: 110, loss: 5.597732524620369e-05
step: 120, loss: 0.00010067296534543857
step: 130, loss: 7.576598727609962e-05
step: 140, loss: 0.0001966618001461029
step: 150, loss: 3.159513289574534e-05
step: 160, loss: 0.00016461210907436907
step: 170, loss: 0.00037685278221033514
step: 180, loss: 5.760265776189044e-05
step: 190, loss: 4.696903488365933e-05
step: 200, loss: 0.00021278187341522425
step: 210, loss: 3.337372618261725e-05
step: 220, loss: 5.501653140527196e-05
step: 230, loss: 5.267870437819511e-05
step: 240, loss: 7.596538489451632e-05
step: 250, loss: 6.251530430745333e-05
step: 260, loss: 5.723855792894028e-05
step: 270, loss: 1.609279388503637e-05
step: 280, loss: 2.8729831683449447e-05
step: 290, loss: 5.007101208320819e-05
step: 300, loss: 4.492004154599272e-05
step: 310, loss: 5.579808203037828e-05
step: 320, loss: 0.0004546302661765367
step: 330, loss: 7.110155274858698e-05
epoch 18: dev_f1=0.8, f1=0.7654320987654322, best_f1=0.8117913832199547
step: 0, loss: 4.183884084341116e-05
step: 10, loss: 2.502467032172717e-05
step: 20, loss: 5.899285679333843e-05
step: 30, loss: 3.1538667826680467e-05
step: 40, loss: 0.0007280324352905154
step: 50, loss: 0.00013886007945984602
step: 60, loss: 0.00018184128566645086
step: 70, loss: 0.0007800675230100751
step: 80, loss: 3.834840754279867e-05
step: 90, loss: 1.2002750736428425e-05
step: 100, loss: 6.392173963831738e-05
step: 110, loss: 0.0004054749442730099
step: 120, loss: 0.0001200272745336406
step: 130, loss: 3.5730099625652656e-05
step: 140, loss: 0.0008612051606178284
step: 150, loss: 3.5269418731331825e-05
step: 160, loss: 4.877637911704369e-05
step: 170, loss: 0.0002850698074325919
step: 180, loss: 3.0344041078933515e-05
step: 190, loss: 0.00013146843411959708
step: 200, loss: 3.6445730074774474e-05
step: 210, loss: 0.00018784600251819938
step: 220, loss: 0.0002355483447900042
step: 230, loss: 1.627151868888177e-05
step: 240, loss: 0.006368932779878378
step: 250, loss: 0.022097768262028694
step: 260, loss: 0.00011163733870489523
step: 270, loss: 0.021742315962910652
step: 280, loss: 2.883049273805227e-05
step: 290, loss: 7.431940321112052e-05
step: 300, loss: 4.7934652684489265e-05
step: 310, loss: 7.239477417897433e-05
step: 320, loss: 2.1855019440408796e-05
step: 330, loss: 5.059566319687292e-05
epoch 19: dev_f1=0.8058968058968059, f1=0.8009478672985781, best_f1=0.8117913832199547
step: 0, loss: 0.0061807781457901
step: 10, loss: 2.153859895770438e-05
step: 20, loss: 5.3344225307228044e-05
step: 30, loss: 5.541592327062972e-05
step: 40, loss: 2.5026427465490997e-05
step: 50, loss: 0.00027530823717825115
step: 60, loss: 0.00040999604971148074
step: 70, loss: 0.0001573383342474699
step: 80, loss: 4.933891614200547e-05
step: 90, loss: 0.0001480712671764195
step: 100, loss: 0.0003055035194847733
step: 110, loss: 0.013205835595726967
step: 120, loss: 0.0005205032648518682
step: 130, loss: 6.907563511049375e-05
step: 140, loss: 8.663578773848712e-05
step: 150, loss: 0.01067932229489088
step: 160, loss: 1.437559421901824e-05
step: 170, loss: 2.156829032173846e-05
step: 180, loss: 2.9456738047883846e-05
step: 190, loss: 0.0208544060587883
step: 200, loss: 0.008576891385018826
step: 210, loss: 4.347828871686943e-05
step: 220, loss: 0.03189428523182869
step: 230, loss: 3.255568299209699e-05
step: 240, loss: 6.153787398943678e-05
step: 250, loss: 2.362475061090663e-05
step: 260, loss: 2.26551837840816e-05
step: 270, loss: 0.0002954583615064621
step: 280, loss: 2.8973356165806763e-05
step: 290, loss: 1.5049589819682296e-05
step: 300, loss: 0.0008331462740898132
step: 310, loss: 0.03230641782283783
step: 320, loss: 3.788623507716693e-05
step: 330, loss: 3.742487751878798e-05
epoch 20: dev_f1=0.8029925187032417, f1=0.7902439024390243, best_f1=0.8117913832199547
