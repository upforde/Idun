cuda
Device: cuda
step: 0, loss: 0.8510773181915283
step: 10, loss: 0.14891654253005981
step: 20, loss: 0.24718789756298065
step: 30, loss: 0.07351629436016083
step: 40, loss: 0.12559272348880768
step: 50, loss: 0.13594107329845428
step: 60, loss: 0.23872001469135284
step: 70, loss: 0.21530991792678833
step: 80, loss: 0.16785834729671478
step: 90, loss: 0.12366154044866562
step: 100, loss: 0.12810567021369934
step: 110, loss: 0.29143786430358887
step: 120, loss: 0.3661680221557617
step: 130, loss: 0.2719922959804535
step: 140, loss: 0.14694514870643616
step: 150, loss: 0.12982624769210815
step: 160, loss: 0.19970454275608063
step: 170, loss: 0.14192624390125275
step: 180, loss: 0.2603938579559326
step: 190, loss: 0.1872938573360443
step: 200, loss: 0.18076905608177185
step: 210, loss: 0.1851986050605774
step: 220, loss: 0.30581337213516235
step: 230, loss: 0.1434178501367569
step: 240, loss: 0.2788577079772949
step: 250, loss: 0.17708873748779297
step: 260, loss: 0.2332518845796585
step: 270, loss: 0.24861744046211243
step: 280, loss: 0.2747378945350647
step: 290, loss: 0.3214140236377716
step: 300, loss: 0.32261013984680176
step: 310, loss: 0.059826646000146866
step: 320, loss: 0.22812190651893616
step: 330, loss: 0.20774580538272858
epoch 1: dev_f1=0.6110056925996205, f1=0.651685393258427, best_f1=0.651685393258427
step: 0, loss: 0.18438220024108887
step: 10, loss: 0.166563481092453
step: 20, loss: 0.21320810914039612
step: 30, loss: 0.3218691051006317
step: 40, loss: 0.09477885067462921
step: 50, loss: 0.3455184996128082
step: 60, loss: 0.2525617182254791
step: 70, loss: 0.03912279009819031
step: 80, loss: 0.08502902835607529
step: 90, loss: 0.06841658800840378
step: 100, loss: 0.03655428811907768
step: 110, loss: 0.1254851520061493
step: 120, loss: 0.08171990513801575
step: 130, loss: 0.12898334860801697
step: 140, loss: 0.03904501721262932
step: 150, loss: 0.07332229614257812
step: 160, loss: 0.11040307581424713
step: 170, loss: 0.024588964879512787
step: 180, loss: 0.05518164485692978
step: 190, loss: 0.060484450310468674
step: 200, loss: 0.07975836098194122
step: 210, loss: 0.013355814851820469
step: 220, loss: 0.24364185333251953
step: 230, loss: 0.06066164746880531
step: 240, loss: 0.1738480031490326
step: 250, loss: 0.09757952392101288
step: 260, loss: 0.05159870535135269
step: 270, loss: 0.15270157158374786
step: 280, loss: 0.05810840055346489
step: 290, loss: 0.15246479213237762
step: 300, loss: 0.02826743572950363
step: 310, loss: 0.07651350647211075
step: 320, loss: 0.09310916811227798
step: 330, loss: 0.011524491012096405
epoch 2: dev_f1=0.7547169811320755, f1=0.7235955056179775, best_f1=0.7235955056179775
step: 0, loss: 0.022499149665236473
step: 10, loss: 0.07479862868785858
step: 20, loss: 0.04224169999361038
step: 30, loss: 0.0725274533033371
step: 40, loss: 0.08763323724269867
step: 50, loss: 0.10911046713590622
step: 60, loss: 0.18218019604682922
step: 70, loss: 0.012941391207277775
step: 80, loss: 0.025216294452548027
step: 90, loss: 0.07752162218093872
step: 100, loss: 0.13295352458953857
step: 110, loss: 0.022564709186553955
step: 120, loss: 0.06183422729372978
step: 130, loss: 0.01979685015976429
step: 140, loss: 0.028964459896087646
step: 150, loss: 0.10970448702573776
step: 160, loss: 0.17671404778957367
step: 170, loss: 0.05358971282839775
step: 180, loss: 0.026823192834854126
step: 190, loss: 0.035198964178562164
step: 200, loss: 0.09024181962013245
step: 210, loss: 0.0025503879878669977
step: 220, loss: 0.11621204018592834
step: 230, loss: 0.16736675798892975
step: 240, loss: 0.21901792287826538
step: 250, loss: 0.04809076339006424
step: 260, loss: 0.015913788229227066
step: 270, loss: 0.08648090064525604
step: 280, loss: 0.015416931360960007
step: 290, loss: 0.192751944065094
step: 300, loss: 0.0008685196517035365
step: 310, loss: 0.12313316762447357
step: 320, loss: 0.11499898135662079
step: 330, loss: 0.012347958981990814
epoch 3: dev_f1=0.7934272300469484, f1=0.7882882882882883, best_f1=0.7882882882882883
step: 0, loss: 0.016373906284570694
step: 10, loss: 0.009555560536682606
step: 20, loss: 0.0819525346159935
step: 30, loss: 0.06343082338571548
step: 40, loss: 0.05221855640411377
step: 50, loss: 0.00795027520507574
step: 60, loss: 0.13002368807792664
step: 70, loss: 0.045426104217767715
step: 80, loss: 0.027939610183238983
step: 90, loss: 0.05216711759567261
step: 100, loss: 0.019645320251584053
step: 110, loss: 0.07913542538881302
step: 120, loss: 0.06638497859239578
step: 130, loss: 0.021415401250123978
step: 140, loss: 0.00769365718588233
step: 150, loss: 0.008567361161112785
step: 160, loss: 0.025829443708062172
step: 170, loss: 0.00911737885326147
step: 180, loss: 0.007072645705193281
step: 190, loss: 0.1221994012594223
step: 200, loss: 0.047895900905132294
step: 210, loss: 0.02315342426300049
step: 220, loss: 0.004359550774097443
step: 230, loss: 0.028239957988262177
step: 240, loss: 0.07693934440612793
step: 250, loss: 0.07377206534147263
step: 260, loss: 0.02885100618004799
step: 270, loss: 0.009759762324392796
step: 280, loss: 0.013321243226528168
step: 290, loss: 0.12050216645002365
step: 300, loss: 0.23067119717597961
step: 310, loss: 0.005010440479964018
step: 320, loss: 0.017214670777320862
step: 330, loss: 0.08717428147792816
epoch 4: dev_f1=0.7760532150776053, f1=0.7647058823529412, best_f1=0.7882882882882883
step: 0, loss: 0.05620467662811279
step: 10, loss: 0.11584785580635071
step: 20, loss: 0.0029658402781933546
step: 30, loss: 0.004420398268848658
step: 40, loss: 0.0010013105347752571
step: 50, loss: 0.006354996934533119
step: 60, loss: 0.015469684265553951
step: 70, loss: 0.03689378872513771
step: 80, loss: 0.00882006622850895
step: 90, loss: 0.006151570472866297
step: 100, loss: 0.0019588496070355177
step: 110, loss: 0.0422838069498539
step: 120, loss: 0.012251325882971287
step: 130, loss: 0.07690083235502243
step: 140, loss: 0.0066946400329470634
step: 150, loss: 0.008211870677769184
step: 160, loss: 0.05157599225640297
step: 170, loss: 0.025975780561566353
step: 180, loss: 0.005463727284222841
step: 190, loss: 0.026779213920235634
step: 200, loss: 0.0224346574395895
step: 210, loss: 0.011960050091147423
step: 220, loss: 0.14272454380989075
step: 230, loss: 0.028539352118968964
step: 240, loss: 0.004410620778799057
step: 250, loss: 0.05190232768654823
step: 260, loss: 0.00035669247154146433
step: 270, loss: 0.014237926341593266
step: 280, loss: 0.11517822742462158
step: 290, loss: 0.017795007675886154
step: 300, loss: 0.01259117852896452
step: 310, loss: 0.0054196384735405445
step: 320, loss: 0.005283699370920658
step: 330, loss: 0.012019696645438671
epoch 5: dev_f1=0.7865707434052758, f1=0.7581395348837208, best_f1=0.7882882882882883
step: 0, loss: 0.009948577731847763
step: 10, loss: 0.007406491786241531
step: 20, loss: 0.013424516655504704
step: 30, loss: 0.011919627897441387
step: 40, loss: 0.01893557980656624
step: 50, loss: 0.003854343667626381
step: 60, loss: 0.0024121387396007776
step: 70, loss: 0.005002297926694155
step: 80, loss: 0.0026541987899690866
step: 90, loss: 0.10137657821178436
step: 100, loss: 0.004963808227330446
step: 110, loss: 0.004550526384264231
step: 120, loss: 0.0008170625078491867
step: 130, loss: 0.0007701372960582376
step: 140, loss: 0.0017879495862871408
step: 150, loss: 0.013220242224633694
step: 160, loss: 0.004718263633549213
step: 170, loss: 0.0036315268371254206
step: 180, loss: 0.0005268629756756127
step: 190, loss: 0.010335246101021767
step: 200, loss: 0.002779889851808548
step: 210, loss: 0.02342895418405533
step: 220, loss: 0.01666421629488468
step: 230, loss: 0.025864997878670692
step: 240, loss: 0.021365376189351082
step: 250, loss: 0.017587851732969284
step: 260, loss: 0.16294260323047638
step: 270, loss: 0.007616708055138588
step: 280, loss: 0.03874532878398895
step: 290, loss: 0.0038835210725665092
step: 300, loss: 0.019191036000847816
step: 310, loss: 0.0018920302391052246
step: 320, loss: 0.04062521830201149
step: 330, loss: 6.952157855266705e-05
epoch 6: dev_f1=0.7960687960687961, f1=0.7688679245283018, best_f1=0.7688679245283018
step: 0, loss: 0.010701418854296207
step: 10, loss: 0.13990797102451324
step: 20, loss: 0.08902078121900558
step: 30, loss: 0.0022698049433529377
step: 40, loss: 0.001886749523691833
step: 50, loss: 0.0054536000825464725
step: 60, loss: 6.0670012317132205e-05
step: 70, loss: 0.00999397225677967
step: 80, loss: 0.004240650683641434
step: 90, loss: 0.004370355978608131
step: 100, loss: 0.00035368328099139035
step: 110, loss: 0.0011238735169172287
step: 120, loss: 0.012986406683921814
step: 130, loss: 0.0017294049030169845
step: 140, loss: 0.0009887643391266465
step: 150, loss: 0.0145546430721879
step: 160, loss: 0.025653677061200142
step: 170, loss: 4.583852205541916e-05
step: 180, loss: 0.026499710977077484
step: 190, loss: 0.0012403419241309166
step: 200, loss: 0.020360339432954788
step: 210, loss: 0.005460930988192558
step: 220, loss: 0.023217635229229927
step: 230, loss: 0.03610031306743622
step: 240, loss: 0.03694908693432808
step: 250, loss: 0.029225345700979233
step: 260, loss: 0.004661392420530319
step: 270, loss: 0.0004982709651812911
step: 280, loss: 0.00014156523684505373
step: 290, loss: 0.0005886006401851773
step: 300, loss: 0.003863306948915124
step: 310, loss: 0.00022983827511779964
step: 320, loss: 6.122931517893448e-05
step: 330, loss: 4.2249910620739684e-05
epoch 7: dev_f1=0.7513513513513513, f1=0.7587939698492463, best_f1=0.7688679245283018
step: 0, loss: 0.00018757399811875075
step: 10, loss: 0.0005002059624530375
step: 20, loss: 0.000853185832966119
step: 30, loss: 3.265883424319327e-05
step: 40, loss: 4.287252886570059e-05
step: 50, loss: 0.0013247642200440168
step: 60, loss: 0.000244693539571017
step: 70, loss: 7.904523226898164e-05
step: 80, loss: 0.0004937266930937767
step: 90, loss: 0.0033444338478147984
step: 100, loss: 0.0059412335976958275
step: 110, loss: 0.0009982505580410361
step: 120, loss: 0.014623026363551617
step: 130, loss: 0.010069691576063633
step: 140, loss: 0.020555125549435616
step: 150, loss: 2.328278606000822e-05
step: 160, loss: 0.02517266571521759
step: 170, loss: 0.00030067426268942654
step: 180, loss: 0.0013660113327205181
step: 190, loss: 0.0002638678124640137
step: 200, loss: 0.0002985135652124882
step: 210, loss: 0.04331832006573677
step: 220, loss: 0.21686381101608276
step: 230, loss: 0.0025286029558628798
step: 240, loss: 0.012735503725707531
step: 250, loss: 0.005050930660218
step: 260, loss: 0.003299569245427847
step: 270, loss: 0.07535194605588913
step: 280, loss: 0.005597579758614302
step: 290, loss: 0.05418547987937927
step: 300, loss: 0.0940934270620346
step: 310, loss: 0.0026132636703550816
step: 320, loss: 0.013554318808019161
step: 330, loss: 0.012436832301318645
epoch 8: dev_f1=0.7990074441687345, f1=0.7614457831325301, best_f1=0.7614457831325301
step: 0, loss: 0.0029809416737407446
step: 10, loss: 0.00031786892213858664
step: 20, loss: 0.0856841504573822
step: 30, loss: 0.07256938517093658
step: 40, loss: 0.0006266396376304328
step: 50, loss: 0.002034969162195921
step: 60, loss: 0.007690140977501869
step: 70, loss: 0.001439299201592803
step: 80, loss: 0.01519766729325056
step: 90, loss: 0.0016858059680089355
step: 100, loss: 0.0007435653824359179
step: 110, loss: 0.01727950945496559
step: 120, loss: 0.0013090776046738029
step: 130, loss: 0.03527242690324783
step: 140, loss: 0.001949804020114243
step: 150, loss: 0.0014343525981530547
step: 160, loss: 0.02378227189183235
step: 170, loss: 0.015455481596291065
step: 180, loss: 0.0016112207667902112
step: 190, loss: 0.0005656753783114254
step: 200, loss: 0.0004943687235936522
step: 210, loss: 0.00012769800378009677
step: 220, loss: 0.0026125474832952023
step: 230, loss: 0.005901196040213108
step: 240, loss: 0.007973691448569298
step: 250, loss: 0.00032326809014193714
step: 260, loss: 1.980713386728894e-05
step: 270, loss: 0.08327388018369675
step: 280, loss: 0.015561624430119991
step: 290, loss: 0.0005130119388923049
step: 300, loss: 0.00012843753211200237
step: 310, loss: 0.0005687805823981762
step: 320, loss: 2.2563668608199805e-05
step: 330, loss: 0.0004440022457856685
epoch 9: dev_f1=0.7971014492753623, f1=0.7517730496453902, best_f1=0.7614457831325301
step: 0, loss: 0.0014364770613610744
step: 10, loss: 0.00015028234338387847
step: 20, loss: 0.0002413072215858847
step: 30, loss: 0.0006171264685690403
step: 40, loss: 0.0024462416768074036
step: 50, loss: 0.00035319855669513345
step: 60, loss: 0.0005231543909758329
step: 70, loss: 0.00201585004106164
step: 80, loss: 0.0006345047149807215
step: 90, loss: 0.01787716895341873
step: 100, loss: 0.03792760521173477
step: 110, loss: 0.06338878720998764
step: 120, loss: 2.2232055925996974e-05
step: 130, loss: 0.0010962587548419833
step: 140, loss: 0.016763607040047646
step: 150, loss: 0.00039758795173838735
step: 160, loss: 0.003669995814561844
step: 170, loss: 0.00014166103210300207
step: 180, loss: 0.0014833413297310472
step: 190, loss: 0.14078933000564575
step: 200, loss: 0.13870206475257874
step: 210, loss: 0.00339562282897532
step: 220, loss: 0.008373390883207321
step: 230, loss: 0.0038056650664657354
step: 240, loss: 0.004469213541597128
step: 250, loss: 0.018978238105773926
step: 260, loss: 0.005647428333759308
step: 270, loss: 0.06668362766504288
step: 280, loss: 0.09213637560606003
step: 290, loss: 0.0038408611435443163
step: 300, loss: 0.013604389503598213
step: 310, loss: 0.0010202949633821845
step: 320, loss: 0.0006335346261039376
step: 330, loss: 0.09473829716444016
epoch 10: dev_f1=0.7912621359223301, f1=0.7889908256880733, best_f1=0.7614457831325301
step: 0, loss: 0.010418840683996677
step: 10, loss: 0.00010544345423113555
step: 20, loss: 0.0013255131198093295
step: 30, loss: 0.01622280664741993
step: 40, loss: 0.004941904451698065
step: 50, loss: 0.010717225261032581
step: 60, loss: 0.0018541637109592557
step: 70, loss: 0.0014102384448051453
step: 80, loss: 0.00023756160226184875
step: 90, loss: 0.0015257992781698704
step: 100, loss: 2.11629976547556e-05
step: 110, loss: 0.00023161937133409083
step: 120, loss: 0.0001033538646879606
step: 130, loss: 0.1182234138250351
step: 140, loss: 0.00021342388936318457
step: 150, loss: 0.0027298147324472666
step: 160, loss: 0.0012341092806309462
step: 170, loss: 0.005428728647530079
step: 180, loss: 0.014255653135478497
step: 190, loss: 0.004038452636450529
step: 200, loss: 0.04257261008024216
step: 210, loss: 0.00031762587605044246
step: 220, loss: 0.00014069599274080247
step: 230, loss: 0.0006293076439760625
step: 240, loss: 0.0014659101143479347
step: 250, loss: 0.00027355848578736186
step: 260, loss: 0.004534932319074869
step: 270, loss: 0.003477283287793398
step: 280, loss: 0.047248661518096924
step: 290, loss: 0.00011917625670321286
step: 300, loss: 0.0016808788059279323
step: 310, loss: 0.00867983978241682
step: 320, loss: 0.0018586402293294668
step: 330, loss: 0.11805179715156555
epoch 11: dev_f1=0.779746835443038, f1=0.7637231503579952, best_f1=0.7614457831325301
step: 0, loss: 0.005426248535513878
step: 10, loss: 4.588409137795679e-05
step: 20, loss: 0.00024986869539134204
step: 30, loss: 0.0021489672362804413
step: 40, loss: 0.000989847001619637
step: 50, loss: 0.006263950373977423
step: 60, loss: 0.00019514441373758018
step: 70, loss: 0.003173752222210169
step: 80, loss: 0.030568771064281464
step: 90, loss: 0.002025446156039834
step: 100, loss: 1.3135273547959514e-05
step: 110, loss: 0.003904304699972272
step: 120, loss: 0.00028666164143942297
step: 130, loss: 0.0010973036987707019
step: 140, loss: 0.000862824555952102
step: 150, loss: 0.014217057265341282
step: 160, loss: 0.09449386596679688
step: 170, loss: 0.00032335479045286775
step: 180, loss: 0.005372868850827217
step: 190, loss: 0.00014843366807326674
step: 200, loss: 0.0008397442870773375
step: 210, loss: 0.0007976199849508703
step: 220, loss: 0.00011599104618653655
step: 230, loss: 1.4781751815462485e-05
step: 240, loss: 0.005350262392312288
step: 250, loss: 0.0021122535690665245
step: 260, loss: 0.0004042436194140464
step: 270, loss: 0.025180349126458168
step: 280, loss: 0.11458487808704376
step: 290, loss: 0.00011936669034184888
step: 300, loss: 0.007102706003934145
step: 310, loss: 0.007111123763024807
step: 320, loss: 0.003071279963478446
step: 330, loss: 0.009142279624938965
epoch 12: dev_f1=0.7761194029850746, f1=0.7803738317757009, best_f1=0.7614457831325301
step: 0, loss: 0.0005954676889814436
step: 10, loss: 0.0002655564749147743
step: 20, loss: 0.0002418035001028329
step: 30, loss: 0.0037789936177432537
step: 40, loss: 0.0007858701283112168
step: 50, loss: 2.0982894056942314e-05
step: 60, loss: 0.001283452264033258
step: 70, loss: 0.0007620883407071233
step: 80, loss: 0.0002985503524541855
step: 90, loss: 0.0015832687495276332
step: 100, loss: 0.003071859711781144
step: 110, loss: 0.001018904964439571
step: 120, loss: 0.04193416237831116
step: 130, loss: 0.0014110045740380883
step: 140, loss: 0.013769101351499557
step: 150, loss: 4.61807576357387e-05
step: 160, loss: 0.014169792644679546
step: 170, loss: 0.00010150128218811005
step: 180, loss: 2.2732869183528237e-05
step: 190, loss: 0.00010794035188155249
step: 200, loss: 0.00022695321240462363
step: 210, loss: 8.137764234561473e-05
step: 220, loss: 2.577868872322142e-05
step: 230, loss: 2.6836154574993998e-05
step: 240, loss: 8.601118315709755e-05
step: 250, loss: 8.385775436181575e-05
step: 260, loss: 0.010822136886417866
step: 270, loss: 0.00038604059955105186
step: 280, loss: 1.122794310504105e-05
step: 290, loss: 4.048319533467293e-05
step: 300, loss: 0.13829012215137482
step: 310, loss: 0.0027551106177270412
step: 320, loss: 6.653051968896762e-05
step: 330, loss: 5.915196379646659e-05
epoch 13: dev_f1=0.7783251231527093, f1=0.776470588235294, best_f1=0.7614457831325301
step: 0, loss: 8.545142918592319e-05
step: 10, loss: 0.0002494110376574099
step: 20, loss: 0.000143458106322214
step: 30, loss: 1.0050780474557541e-05
step: 40, loss: 0.002293672878295183
step: 50, loss: 0.0015643984079360962
step: 60, loss: 0.002391321584582329
step: 70, loss: 0.0033455435186624527
step: 80, loss: 0.001977653242647648
step: 90, loss: 0.0010548667050898075
step: 100, loss: 0.0007100966176949441
step: 110, loss: 0.004370957612991333
step: 120, loss: 0.00036236477899365127
step: 130, loss: 0.0008661447209306061
step: 140, loss: 0.001184541848488152
step: 150, loss: 0.00036608875961974263
step: 160, loss: 0.0003849068016279489
step: 170, loss: 0.001409729360602796
step: 180, loss: 0.0013374636182561517
step: 190, loss: 3.050200939469505e-05
step: 200, loss: 0.0001132828911067918
step: 210, loss: 0.015036889351904392
step: 220, loss: 0.0009342269622720778
step: 230, loss: 0.00012843545118812472
step: 240, loss: 0.04317307844758034
step: 250, loss: 5.084988151793368e-05
step: 260, loss: 3.148149335174821e-05
step: 270, loss: 8.140951831592247e-05
step: 280, loss: 0.00010189919703407213
step: 290, loss: 0.005417919717729092
step: 300, loss: 0.0005018925294280052
step: 310, loss: 0.021345721557736397
step: 320, loss: 6.333558849291876e-05
step: 330, loss: 0.030458666384220123
epoch 14: dev_f1=0.7621483375959078, f1=0.7598039215686274, best_f1=0.7614457831325301
step: 0, loss: 0.001442330190911889
step: 10, loss: 0.006604371592402458
step: 20, loss: 9.824034350458533e-05
step: 30, loss: 1.7318605387117714e-05
step: 40, loss: 0.00033847810118459165
step: 50, loss: 5.886286817258224e-05
step: 60, loss: 3.1965748348739e-05
step: 70, loss: 0.0008079654653556645
step: 80, loss: 0.0014756667660549283
step: 90, loss: 0.00026561267441138625
step: 100, loss: 0.0007262117578648031
step: 110, loss: 0.032428134232759476
step: 120, loss: 0.00872216559946537
step: 130, loss: 0.0030206795781850815
step: 140, loss: 0.004199446178972721
step: 150, loss: 0.00013422973279375583
step: 160, loss: 9.17279176064767e-05
step: 170, loss: 0.0008281801710836589
step: 180, loss: 0.024582868441939354
step: 190, loss: 0.0003721684333868325
step: 200, loss: 0.06352347880601883
step: 210, loss: 0.0001609401369933039
step: 220, loss: 0.00047991692554205656
step: 230, loss: 0.0003098658053204417
step: 240, loss: 0.016614962369203568
step: 250, loss: 0.002045275876298547
step: 260, loss: 5.059031173004769e-05
step: 270, loss: 4.7427562094526365e-05
step: 280, loss: 6.300196400843561e-05
step: 290, loss: 0.00017446176207158715
step: 300, loss: 7.924948295112699e-05
step: 310, loss: 4.329289004090242e-05
step: 320, loss: 8.917956438381225e-05
step: 330, loss: 2.9375147278187796e-05
epoch 15: dev_f1=0.7547169811320755, f1=0.7397959183673468, best_f1=0.7614457831325301
step: 0, loss: 9.680064977146685e-05
step: 10, loss: 0.012140444479882717
step: 20, loss: 1.483761388954008e-05
step: 30, loss: 7.423512579407543e-05
step: 40, loss: 3.086419019382447e-05
step: 50, loss: 1.1529692528711166e-05
step: 60, loss: 1.2557847185235005e-05
step: 70, loss: 0.0002215828135376796
step: 80, loss: 0.0002574692771304399
step: 90, loss: 6.903640314703807e-05
step: 100, loss: 1.1172072845511138e-05
step: 110, loss: 2.096059688483365e-05
step: 120, loss: 9.743590635480359e-05
step: 130, loss: 0.00014596676919609308
step: 140, loss: 0.0008158558048307896
step: 150, loss: 0.00012034342216793448
step: 160, loss: 2.9754432034678757e-05
step: 170, loss: 4.283049565856345e-05
step: 180, loss: 0.00013842980843037367
step: 190, loss: 0.0003122997295577079
step: 200, loss: 1.3708935512113385e-05
step: 210, loss: 0.027689022943377495
step: 220, loss: 0.0002645781496539712
step: 230, loss: 0.00090682168956846
step: 240, loss: 0.004792932886630297
step: 250, loss: 0.0006761478143744171
step: 260, loss: 0.0003472858516033739
step: 270, loss: 0.003773464122787118
step: 280, loss: 0.010389992035925388
step: 290, loss: 3.242531238356605e-05
step: 300, loss: 0.015878872945904732
step: 310, loss: 0.0022117237094789743
step: 320, loss: 4.320376683608629e-05
step: 330, loss: 0.012071176432073116
epoch 16: dev_f1=0.7901907356948228, f1=0.7660668380462724, best_f1=0.7614457831325301
step: 0, loss: 0.003366423537954688
step: 10, loss: 0.0015608620597049594
step: 20, loss: 0.0004833574639633298
step: 30, loss: 9.59616809268482e-05
step: 40, loss: 0.00010363468754803762
step: 50, loss: 9.541006875224411e-05
step: 60, loss: 1.3302698789630085e-05
step: 70, loss: 0.00047827951493673027
step: 80, loss: 0.0009539112215861678
step: 90, loss: 3.4844313631765544e-05
step: 100, loss: 0.00020661158487200737
step: 110, loss: 0.00134739326313138
step: 120, loss: 0.00022565321705769747
step: 130, loss: 7.697829278185964e-05
step: 140, loss: 0.00029079028172418475
step: 150, loss: 2.811590275086928e-05
step: 160, loss: 3.6781508242711425e-05
step: 170, loss: 0.00016677695384714752
step: 180, loss: 0.00011907582666026428
step: 190, loss: 0.011755540035665035
step: 200, loss: 0.0003694532497320324
step: 210, loss: 6.731860776199028e-05
step: 220, loss: 8.227532816817984e-05
step: 230, loss: 0.00014988132170401514
step: 240, loss: 0.00010023594222730026
step: 250, loss: 0.0010667173191905022
step: 260, loss: 4.346672722022049e-05
step: 270, loss: 0.0007314619142562151
step: 280, loss: 0.0004072793817613274
step: 290, loss: 0.001176908379420638
step: 300, loss: 0.00044718061690218747
step: 310, loss: 6.229838618310168e-05
step: 320, loss: 9.73959467955865e-05
step: 330, loss: 1.1488667041703593e-05
epoch 17: dev_f1=0.7999999999999999, f1=0.7769784172661871, best_f1=0.7769784172661871
step: 0, loss: 4.9823487643152475e-05
step: 10, loss: 0.0009397334069944918
step: 20, loss: 8.229042578022927e-05
step: 30, loss: 0.001208636094816029
step: 40, loss: 0.001191332470625639
step: 50, loss: 2.4511440642527305e-05
step: 60, loss: 0.030769266188144684
step: 70, loss: 0.0042758723720908165
step: 80, loss: 1.0605782335915137e-05
step: 90, loss: 6.372181087499484e-05
step: 100, loss: 6.640113133471459e-05
step: 110, loss: 0.00012482714373618364
step: 120, loss: 0.00014343834482133389
step: 130, loss: 3.7406458432087675e-05
step: 140, loss: 0.00020194720127619803
step: 150, loss: 0.0038489720318466425
step: 160, loss: 2.5954968805308454e-05
step: 170, loss: 4.345511115388945e-05
step: 180, loss: 8.508523933414835e-06
step: 190, loss: 0.00034841400338336825
step: 200, loss: 4.8267756938003004e-05
step: 210, loss: 7.53942658775486e-05
step: 220, loss: 2.602313361421693e-05
step: 230, loss: 1.911218168970663e-05
step: 240, loss: 0.030234863981604576
step: 250, loss: 9.796625090530142e-05
step: 260, loss: 0.0016711056232452393
step: 270, loss: 0.0001816719159251079
step: 280, loss: 1.2114423043385614e-05
step: 290, loss: 2.256824700452853e-05
step: 300, loss: 0.022948896512389183
step: 310, loss: 1.917920781124849e-05
step: 320, loss: 0.0002746786631178111
step: 330, loss: 5.388354111346416e-05
epoch 18: dev_f1=0.7846153846153846, f1=0.7647058823529412, best_f1=0.7769784172661871
step: 0, loss: 7.802151958458126e-05
step: 10, loss: 1.2598741705005523e-05
step: 20, loss: 4.815344072994776e-05
step: 30, loss: 1.1619027645792812e-05
step: 40, loss: 0.0006682028761133552
step: 50, loss: 8.705956133781001e-06
step: 60, loss: 7.678779365960509e-05
step: 70, loss: 2.233019404229708e-05
step: 80, loss: 0.00023874854377936572
step: 90, loss: 5.8107842050958425e-05
step: 100, loss: 5.4437321523437276e-05
step: 110, loss: 4.293821257306263e-05
step: 120, loss: 2.054994911304675e-05
step: 130, loss: 8.629114017821848e-05
step: 140, loss: 7.938560884213075e-06
step: 150, loss: 2.7698417397914454e-05
step: 160, loss: 7.352657848969102e-05
step: 170, loss: 6.910775846336037e-05
step: 180, loss: 2.216720167780295e-05
step: 190, loss: 8.304051880259067e-05
step: 200, loss: 5.7646582718007267e-05
step: 210, loss: 0.027081161737442017
step: 220, loss: 0.0027671223506331444
step: 230, loss: 5.658274676534347e-05
step: 240, loss: 0.0005212835967540741
step: 250, loss: 1.6907597455428913e-05
step: 260, loss: 2.9343917049118318e-05
step: 270, loss: 7.169707532739267e-05
step: 280, loss: 2.3290442186407745e-05
step: 290, loss: 3.47723689628765e-05
step: 300, loss: 5.1400762458797544e-05
step: 310, loss: 8.530871127732098e-06
step: 320, loss: 9.406301614944823e-06
step: 330, loss: 5.7101267884718254e-05
epoch 19: dev_f1=0.7830687830687831, f1=0.7568922305764412, best_f1=0.7769784172661871
step: 0, loss: 1.9663684724946506e-05
step: 10, loss: 4.946929038851522e-05
step: 20, loss: 0.00031456415308639407
step: 30, loss: 0.011793617159128189
step: 40, loss: 0.004734427202492952
step: 50, loss: 1.8002705473918468e-05
step: 60, loss: 3.906591882696375e-05
step: 70, loss: 0.0011928934836760163
step: 80, loss: 8.519689799868502e-06
step: 90, loss: 0.00031483452767133713
step: 100, loss: 6.512770778499544e-05
step: 110, loss: 6.476319686044008e-05
step: 120, loss: 0.00024165533250197768
step: 130, loss: 2.66719980572816e-05
step: 140, loss: 0.030056681483983994
step: 150, loss: 0.00011908423766726628
step: 160, loss: 0.0007184818387031555
step: 170, loss: 8.045418508118019e-05
step: 180, loss: 0.0003058768925257027
step: 190, loss: 0.0006534839048981667
step: 200, loss: 1.8985689166584052e-05
step: 210, loss: 8.093877841020003e-05
step: 220, loss: 7.07573999534361e-05
step: 230, loss: 4.3548869143705815e-05
step: 240, loss: 4.9346708692610264e-05
step: 250, loss: 0.00014003991964273155
step: 260, loss: 0.00011800375068560243
step: 270, loss: 3.731915057869628e-05
step: 280, loss: 0.0033016393426805735
step: 290, loss: 3.582527278922498e-05
step: 300, loss: 0.0009334793430753052
step: 310, loss: 4.217278547002934e-05
step: 320, loss: 8.009338671399746e-06
step: 330, loss: 8.867667929735035e-05
epoch 20: dev_f1=0.7819148936170214, f1=0.7587939698492463, best_f1=0.7769784172661871
