cuda
Device: cuda
step: 0, loss: 0.5739012360572815
step: 10, loss: 0.14323557913303375
step: 20, loss: 0.14745080471038818
step: 30, loss: 0.22443290054798126
step: 40, loss: 0.3377845883369446
step: 50, loss: 0.23142610490322113
step: 60, loss: 0.14037486910820007
step: 70, loss: 0.311095267534256
step: 80, loss: 0.22752727568149567
step: 90, loss: 0.07067931443452835
step: 100, loss: 0.13714368641376495
step: 110, loss: 0.7029598355293274
step: 120, loss: 0.30325841903686523
step: 130, loss: 0.24087923765182495
step: 140, loss: 0.04501112923026085
step: 150, loss: 0.12045721709728241
step: 160, loss: 0.07140566408634186
step: 170, loss: 0.41424307227134705
step: 180, loss: 0.21083420515060425
step: 190, loss: 0.14452090859413147
step: 200, loss: 0.03341969475150108
step: 210, loss: 0.2503679692745209
step: 220, loss: 0.4595029354095459
step: 230, loss: 0.3556362986564636
step: 240, loss: 0.1263316571712494
step: 250, loss: 0.20028971135616302
step: 260, loss: 0.384968101978302
step: 270, loss: 0.4165079891681671
step: 280, loss: 0.23314133286476135
step: 290, loss: 0.28971290588378906
step: 300, loss: 0.28119081258773804
step: 310, loss: 0.2844880521297455
step: 320, loss: 0.02199610322713852
step: 330, loss: 0.22808733582496643
epoch 1: dev_f1=0.43290043290043295, f1=0.3991228070175439, best_f1=0.3991228070175439
step: 0, loss: 0.11180116981267929
step: 10, loss: 0.2980227470397949
step: 20, loss: 0.34983986616134644
step: 30, loss: 0.09804089367389679
step: 40, loss: 0.2171802520751953
step: 50, loss: 0.20481804013252258
step: 60, loss: 0.14854666590690613
step: 70, loss: 0.21243305504322052
step: 80, loss: 0.29689541459083557
step: 90, loss: 0.05852239206433296
step: 100, loss: 0.12083873152732849
step: 110, loss: 0.10015437752008438
step: 120, loss: 0.2618328034877777
step: 130, loss: 0.08987435698509216
step: 140, loss: 0.11360901594161987
step: 150, loss: 0.09900587052106857
step: 160, loss: 0.07551851868629456
step: 170, loss: 0.05179639533162117
step: 180, loss: 0.22073589265346527
step: 190, loss: 0.12612776458263397
step: 200, loss: 0.07651802152395248
step: 210, loss: 0.07153992354869843
step: 220, loss: 0.11391596496105194
step: 230, loss: 0.34783735871315
step: 240, loss: 0.07488608360290527
step: 250, loss: 0.31715676188468933
step: 260, loss: 0.07492496073246002
step: 270, loss: 0.10652634501457214
step: 280, loss: 0.3567441403865814
step: 290, loss: 0.14791658520698547
step: 300, loss: 0.13751548528671265
step: 310, loss: 0.29157891869544983
step: 320, loss: 0.19964392483234406
step: 330, loss: 0.13725821673870087
epoch 2: dev_f1=0.7391304347826086, f1=0.7129455909943715, best_f1=0.7129455909943715
step: 0, loss: 0.04757918789982796
step: 10, loss: 0.0011738924076780677
step: 20, loss: 0.037768688052892685
step: 30, loss: 0.08398381620645523
step: 40, loss: 0.052855681627988815
step: 50, loss: 0.14243844151496887
step: 60, loss: 0.057330429553985596
step: 70, loss: 0.019813191145658493
step: 80, loss: 0.04142341762781143
step: 90, loss: 0.01703478954732418
step: 100, loss: 0.08963526785373688
step: 110, loss: 0.06760141998529434
step: 120, loss: 0.04832858592271805
step: 130, loss: 0.061028677970170975
step: 140, loss: 0.06823015958070755
step: 150, loss: 0.10548090934753418
step: 160, loss: 0.03968555107712746
step: 170, loss: 0.05124009773135185
step: 180, loss: 0.05530405044555664
step: 190, loss: 0.06983129680156708
step: 200, loss: 0.08249713480472565
step: 210, loss: 0.0922020822763443
step: 220, loss: 0.00756438635289669
step: 230, loss: 0.014423503540456295
step: 240, loss: 0.022729849442839622
step: 250, loss: 0.04873473942279816
step: 260, loss: 0.03519440442323685
step: 270, loss: 0.14741401374340057
step: 280, loss: 0.02419206313788891
step: 290, loss: 0.020238680765032768
step: 300, loss: 0.14743119478225708
step: 310, loss: 0.042678799480199814
step: 320, loss: 0.13317212462425232
step: 330, loss: 0.05584230273962021
epoch 3: dev_f1=0.7961165048543688, f1=0.7635467980295567, best_f1=0.7635467980295567
step: 0, loss: 0.06320646405220032
step: 10, loss: 0.08819876611232758
step: 20, loss: 0.005743999965488911
step: 30, loss: 0.013173487968742847
step: 40, loss: 0.00527957221493125
step: 50, loss: 0.0062719061970710754
step: 60, loss: 0.04699130356311798
step: 70, loss: 0.0859110876917839
step: 80, loss: 0.005479264073073864
step: 90, loss: 0.037969812750816345
step: 100, loss: 0.02257443219423294
step: 110, loss: 0.07238481193780899
step: 120, loss: 0.008575605228543282
step: 130, loss: 0.06645941734313965
step: 140, loss: 0.028154445812106133
step: 150, loss: 0.02390933781862259
step: 160, loss: 0.013266521506011486
step: 170, loss: 0.08446738868951797
step: 180, loss: 0.003923967946320772
step: 190, loss: 0.012965268455445766
step: 200, loss: 0.011862434446811676
step: 210, loss: 0.038471221923828125
step: 220, loss: 0.2165001481771469
step: 230, loss: 0.012947609648108482
step: 240, loss: 0.042510583996772766
step: 250, loss: 0.0758901983499527
step: 260, loss: 0.10503475368022919
step: 270, loss: 0.16990293562412262
step: 280, loss: 0.032465193420648575
step: 290, loss: 0.19904422760009766
step: 300, loss: 0.019573671743273735
step: 310, loss: 0.04141925275325775
step: 320, loss: 0.0020125359296798706
step: 330, loss: 0.07498599588871002
epoch 4: dev_f1=0.7637231503579952, f1=0.7435294117647059, best_f1=0.7635467980295567
step: 0, loss: 0.035605207085609436
step: 10, loss: 0.21052533388137817
step: 20, loss: 0.03829886391758919
step: 30, loss: 0.030920395627617836
step: 40, loss: 0.0005138058913871646
step: 50, loss: 0.0027229294646531343
step: 60, loss: 0.014991959556937218
step: 70, loss: 0.004737597890198231
step: 80, loss: 0.018554087728261948
step: 90, loss: 0.01302993856370449
step: 100, loss: 0.005004025995731354
step: 110, loss: 0.026849085465073586
step: 120, loss: 0.004360323306173086
step: 130, loss: 0.057882171124219894
step: 140, loss: 0.004485413432121277
step: 150, loss: 0.09709998220205307
step: 160, loss: 0.0007582339458167553
step: 170, loss: 0.033787716180086136
step: 180, loss: 0.0037029858212918043
step: 190, loss: 0.018792985007166862
step: 200, loss: 0.006160578224807978
step: 210, loss: 0.006538949441164732
step: 220, loss: 0.0952535942196846
step: 230, loss: 0.004031551536172628
step: 240, loss: 0.0015153835993260145
step: 250, loss: 0.04484838992357254
step: 260, loss: 0.05800056457519531
step: 270, loss: 0.0032042081002146006
step: 280, loss: 0.0034523068461567163
step: 290, loss: 0.015741923823952675
step: 300, loss: 0.14271841943264008
step: 310, loss: 0.053114406764507294
step: 320, loss: 0.07512973248958588
step: 330, loss: 0.049758076667785645
epoch 5: dev_f1=0.8009259259259259, f1=0.7935779816513762, best_f1=0.7935779816513762
step: 0, loss: 0.010056118480861187
step: 10, loss: 0.006607078947126865
step: 20, loss: 0.022264933213591576
step: 30, loss: 0.0031651353929191828
step: 40, loss: 0.031253233551979065
step: 50, loss: 0.0007045303354971111
step: 60, loss: 0.0015036489348858595
step: 70, loss: 0.001994929974898696
step: 80, loss: 0.00988773349672556
step: 90, loss: 0.0007380720344372094
step: 100, loss: 0.002418779768049717
step: 110, loss: 0.004940043669193983
step: 120, loss: 0.023068934679031372
step: 130, loss: 0.03308328613638878
step: 140, loss: 8.229060767916963e-05
step: 150, loss: 0.0003446867340244353
step: 160, loss: 0.010861708782613277
step: 170, loss: 0.0019307713955640793
step: 180, loss: 0.006729261018335819
step: 190, loss: 0.002160093979910016
step: 200, loss: 0.02721886709332466
step: 210, loss: 0.004787152633070946
step: 220, loss: 0.08448480814695358
step: 230, loss: 0.14455775916576385
step: 240, loss: 0.02890407294034958
step: 250, loss: 0.0015220495406538248
step: 260, loss: 0.03083973191678524
step: 270, loss: 0.12777268886566162
step: 280, loss: 0.129251629114151
step: 290, loss: 0.03830079361796379
step: 300, loss: 0.0032107667066156864
step: 310, loss: 0.000896853394806385
step: 320, loss: 0.009916098788380623
step: 330, loss: 0.00965232402086258
epoch 6: dev_f1=0.7952380952380952, f1=0.7953488372093023, best_f1=0.7935779816513762
step: 0, loss: 0.0008961858693510294
step: 10, loss: 0.00034308014437556267
step: 20, loss: 0.0005221606697887182
step: 30, loss: 0.0002140064025297761
step: 40, loss: 0.18819338083267212
step: 50, loss: 0.03683255612850189
step: 60, loss: 0.004981143865734339
step: 70, loss: 0.005308846477419138
step: 80, loss: 0.036369580775499344
step: 90, loss: 0.0003404440067242831
step: 100, loss: 0.0007890004781074822
step: 110, loss: 0.09233155846595764
step: 120, loss: 0.0007045961101539433
step: 130, loss: 0.1860000342130661
step: 140, loss: 0.010601946152746677
step: 150, loss: 0.0008872185717336833
step: 160, loss: 0.007729446981102228
step: 170, loss: 0.1421317458152771
step: 180, loss: 0.0037452809046953917
step: 190, loss: 0.04119319096207619
step: 200, loss: 0.04155443608760834
step: 210, loss: 0.0005820153164677322
step: 220, loss: 0.0061344909481704235
step: 230, loss: 0.0006334595382213593
step: 240, loss: 0.030267788097262383
step: 250, loss: 0.004345486871898174
step: 260, loss: 0.028545020148158073
step: 270, loss: 0.059400320053100586
step: 280, loss: 0.0003260830126237124
step: 290, loss: 0.1441890448331833
step: 300, loss: 0.0005272654816508293
step: 310, loss: 0.00047137629007920623
step: 320, loss: 0.017603764310479164
step: 330, loss: 0.024066844955086708
epoch 7: dev_f1=0.7702407002188184, f1=0.7432150313152401, best_f1=0.7935779816513762
step: 0, loss: 0.0032515455968677998
step: 10, loss: 0.012638273648917675
step: 20, loss: 0.0012315064668655396
step: 30, loss: 0.003458020044490695
step: 40, loss: 0.016107702627778053
step: 50, loss: 0.00672818161547184
step: 60, loss: 0.022679513320326805
step: 70, loss: 0.0017124672885984182
step: 80, loss: 0.0010720993159338832
step: 90, loss: 0.009880319237709045
step: 100, loss: 0.00901191309094429
step: 110, loss: 0.0001673696970101446
step: 120, loss: 5.9143938415218145e-05
step: 130, loss: 0.00013402212061919272
step: 140, loss: 0.00011400924995541573
step: 150, loss: 0.00285590928979218
step: 160, loss: 0.00044389907270669937
step: 170, loss: 0.005331791006028652
step: 180, loss: 0.0004924059612676501
step: 190, loss: 0.00023081706603989005
step: 200, loss: 0.00031464212224818766
step: 210, loss: 0.005431601777672768
step: 220, loss: 0.014284029603004456
step: 230, loss: 0.04019390419125557
step: 240, loss: 0.0005610943771898746
step: 250, loss: 0.0005654941196553409
step: 260, loss: 0.00428432784974575
step: 270, loss: 0.00102975033223629
step: 280, loss: 0.0001376209402224049
step: 290, loss: 0.0008152747759595513
step: 300, loss: 0.07929430902004242
step: 310, loss: 0.0011238685110583901
step: 320, loss: 0.003060069866478443
step: 330, loss: 0.001533747068606317
epoch 8: dev_f1=0.8, f1=0.7972350230414745, best_f1=0.7935779816513762
step: 0, loss: 0.0008387047564610839
step: 10, loss: 0.0224500373005867
step: 20, loss: 0.030998006463050842
step: 30, loss: 0.04895016923546791
step: 40, loss: 0.10220947116613388
step: 50, loss: 0.001998041057959199
step: 60, loss: 0.0019814122933894396
step: 70, loss: 0.002588570350781083
step: 80, loss: 0.00020623422460630536
step: 90, loss: 0.1808118224143982
step: 100, loss: 0.00014372328587342054
step: 110, loss: 7.974531763466075e-05
step: 120, loss: 8.490948675898835e-05
step: 130, loss: 0.0007500234642066061
step: 140, loss: 0.0021746973507106304
step: 150, loss: 0.0018901076400652528
step: 160, loss: 0.0082264244556427
step: 170, loss: 0.0014835064066573977
step: 180, loss: 0.00019398104632273316
step: 190, loss: 0.0003059465961996466
step: 200, loss: 0.00016168913862202317
step: 210, loss: 0.000845800619572401
step: 220, loss: 0.020638592541217804
step: 230, loss: 0.000447519269073382
step: 240, loss: 0.004639666527509689
step: 250, loss: 0.0035609451588243246
step: 260, loss: 0.0002935929223895073
step: 270, loss: 0.00019897177116945386
step: 280, loss: 0.011558711528778076
step: 290, loss: 0.0003221403749193996
step: 300, loss: 0.0005006905412301421
step: 310, loss: 0.0013553238241001964
step: 320, loss: 0.0011263623600825667
step: 330, loss: 0.01424479577690363
epoch 9: dev_f1=0.7990543735224587, f1=0.765375854214123, best_f1=0.7935779816513762
step: 0, loss: 0.025902122259140015
step: 10, loss: 0.001332522020675242
step: 20, loss: 0.0034988215193152428
step: 30, loss: 0.010017634369432926
step: 40, loss: 0.015847504138946533
step: 50, loss: 0.0023567955940961838
step: 60, loss: 0.007562640588730574
step: 70, loss: 0.00039355276385322213
step: 80, loss: 0.00016002636402845383
step: 90, loss: 0.00045025793951936066
step: 100, loss: 0.0011694941204041243
step: 110, loss: 0.00113619863986969
step: 120, loss: 4.520307629718445e-05
step: 130, loss: 0.0006759260431863368
step: 140, loss: 0.00011426564014982432
step: 150, loss: 0.08663666248321533
step: 160, loss: 0.0025694253854453564
step: 170, loss: 0.0006551400292664766
step: 180, loss: 0.0001033454027492553
step: 190, loss: 0.00010283636947860941
step: 200, loss: 0.0038895041216164827
step: 210, loss: 0.00016287797188851982
step: 220, loss: 0.026926910504698753
step: 230, loss: 0.0006169879343360662
step: 240, loss: 0.010726967826485634
step: 250, loss: 0.001184110646136105
step: 260, loss: 0.0015777471708133817
step: 270, loss: 5.542299913940951e-05
step: 280, loss: 0.0018878604751080275
step: 290, loss: 0.009315610863268375
step: 300, loss: 0.011855725198984146
step: 310, loss: 0.0041219694539904594
step: 320, loss: 0.012555752880871296
step: 330, loss: 0.0011617684504017234
epoch 10: dev_f1=0.8220551378446115, f1=0.8038740920096852, best_f1=0.8038740920096852
step: 0, loss: 0.00044920152868144214
step: 10, loss: 0.0027688289992511272
step: 20, loss: 9.709118603495881e-05
step: 30, loss: 0.15943504869937897
step: 40, loss: 0.001050882856361568
step: 50, loss: 0.0005793361342512071
step: 60, loss: 0.00013831647811457515
step: 70, loss: 0.00013115494220983237
step: 80, loss: 4.71728817501571e-05
step: 90, loss: 0.0009830129565671086
step: 100, loss: 0.000650819216389209
step: 110, loss: 5.704107752535492e-05
step: 120, loss: 0.00028963640215806663
step: 130, loss: 3.9377438952215016e-05
step: 140, loss: 0.0002143973542843014
step: 150, loss: 0.0001264844904653728
step: 160, loss: 0.0010836576111614704
step: 170, loss: 0.0015431493520736694
step: 180, loss: 0.0016853727865964174
step: 190, loss: 0.00011371962318662554
step: 200, loss: 0.00011605103645706549
step: 210, loss: 0.0004215144435875118
step: 220, loss: 0.0024926457554101944
step: 230, loss: 0.002824244322255254
step: 240, loss: 0.00040730927139520645
step: 250, loss: 0.00017296840087510645
step: 260, loss: 0.00011209714284632355
step: 270, loss: 0.00010104179091285914
step: 280, loss: 4.833841376239434e-05
step: 290, loss: 0.0007530430448241532
step: 300, loss: 0.0005514971562661231
step: 310, loss: 0.004896343220025301
step: 320, loss: 0.01220724731683731
step: 330, loss: 0.004097711760550737
epoch 11: dev_f1=0.8244680851063829, f1=0.7740259740259741, best_f1=0.7740259740259741
step: 0, loss: 0.0011525602312758565
step: 10, loss: 0.011222459375858307
step: 20, loss: 0.0011906822910532355
step: 30, loss: 0.00012138215970480815
step: 40, loss: 4.7270037612179294e-05
step: 50, loss: 3.614285378716886e-05
step: 60, loss: 5.8905417972709984e-05
step: 70, loss: 5.383720781537704e-05
step: 80, loss: 0.00020855704497080296
step: 90, loss: 0.06481333076953888
step: 100, loss: 5.3385429055197164e-05
step: 110, loss: 0.00014301692135632038
step: 120, loss: 9.890113142319024e-05
step: 130, loss: 5.358978523872793e-05
step: 140, loss: 0.013776756823062897
step: 150, loss: 0.0001311113592237234
step: 160, loss: 0.022816810756921768
step: 170, loss: 0.0009014258976094425
step: 180, loss: 5.858603253727779e-05
step: 190, loss: 0.00039191683754324913
step: 200, loss: 3.558201569830999e-05
step: 210, loss: 0.000367853237548843
step: 220, loss: 0.025096891447901726
step: 230, loss: 0.0006442484445869923
step: 240, loss: 0.00020907263387925923
step: 250, loss: 0.0356941744685173
step: 260, loss: 0.0006350059993565083
step: 270, loss: 0.0015433651860803366
step: 280, loss: 0.00017930078320205212
step: 290, loss: 0.0002708368992898613
step: 300, loss: 0.00044107815483585
step: 310, loss: 0.0003185308596584946
step: 320, loss: 0.0002588359930086881
step: 330, loss: 0.0023717153817415237
epoch 12: dev_f1=0.8133971291866029, f1=0.7990762124711317, best_f1=0.7740259740259741
step: 0, loss: 4.368408917798661e-05
step: 10, loss: 0.009300429373979568
step: 20, loss: 0.00017167792248073965
step: 30, loss: 0.0008406726410612464
step: 40, loss: 0.003456639824435115
step: 50, loss: 2.7946069167228416e-05
step: 60, loss: 5.6246601161547005e-05
step: 70, loss: 0.00018992730474565178
step: 80, loss: 5.132992737344466e-05
step: 90, loss: 3.056452260352671e-05
step: 100, loss: 0.03515811637043953
step: 110, loss: 0.005327114835381508
step: 120, loss: 0.0015832188073545694
step: 130, loss: 0.00033171894028782845
step: 140, loss: 0.00020660959125962108
step: 150, loss: 0.007002625614404678
step: 160, loss: 0.0134360883384943
step: 170, loss: 5.795697870780714e-05
step: 180, loss: 0.006319309119135141
step: 190, loss: 0.0013742847368121147
step: 200, loss: 4.032695505884476e-05
step: 210, loss: 5.207845970289782e-05
step: 220, loss: 0.004321695771068335
step: 230, loss: 0.045930344611406326
step: 240, loss: 0.00022722284484189004
step: 250, loss: 0.0010312527883797884
step: 260, loss: 0.0017517192754894495
step: 270, loss: 0.00010179239325225353
step: 280, loss: 0.0013861411716789007
step: 290, loss: 7.685004675295204e-05
step: 300, loss: 7.612059562234208e-05
step: 310, loss: 0.00043779084808193147
step: 320, loss: 0.22992688417434692
step: 330, loss: 0.005544306710362434
epoch 13: dev_f1=0.8054919908466818, f1=0.7662337662337663, best_f1=0.7740259740259741
step: 0, loss: 0.00018749198352452368
step: 10, loss: 0.0010993954492732882
step: 20, loss: 0.0019938501063734293
step: 30, loss: 0.004573246464133263
step: 40, loss: 0.04292898252606392
step: 50, loss: 0.0008519658003933728
step: 60, loss: 0.00741578871384263
step: 70, loss: 4.1127663280349225e-05
step: 80, loss: 2.515971391403582e-05
step: 90, loss: 4.419337346917018e-05
step: 100, loss: 0.0007795824203640223
step: 110, loss: 8.946711750468239e-05
step: 120, loss: 4.73716136184521e-05
step: 130, loss: 0.00012672343291342258
step: 140, loss: 2.3554488507215865e-05
step: 150, loss: 0.02025851048529148
step: 160, loss: 0.0005088221514597535
step: 170, loss: 3.6110875953454524e-05
step: 180, loss: 0.00011519191320985556
step: 190, loss: 0.0002433722111163661
step: 200, loss: 0.0001572557957842946
step: 210, loss: 0.011560991406440735
step: 220, loss: 0.00035516751813702285
step: 230, loss: 0.0006801291019655764
step: 240, loss: 0.010895656421780586
step: 250, loss: 0.00015189198893494904
step: 260, loss: 0.041429534554481506
step: 270, loss: 5.690427860827185e-05
step: 280, loss: 0.0001341400929959491
step: 290, loss: 0.0002229100646218285
step: 300, loss: 8.076726226136088e-05
step: 310, loss: 6.361956184264272e-05
step: 320, loss: 0.0001761719904607162
step: 330, loss: 0.0015428276965394616
epoch 14: dev_f1=0.7826086956521738, f1=0.7566137566137566, best_f1=0.7740259740259741
step: 0, loss: 0.0009205251699313521
step: 10, loss: 0.001657433807849884
step: 20, loss: 0.00035770697286352515
step: 30, loss: 7.159595406847075e-05
step: 40, loss: 0.00030577954021282494
step: 50, loss: 0.0010731425136327744
step: 60, loss: 0.00012278843496460468
step: 70, loss: 5.209085065871477e-05
step: 80, loss: 0.00012949590745847672
step: 90, loss: 8.563818846596405e-05
step: 100, loss: 5.5340398830594495e-05
step: 110, loss: 3.488963557174429e-05
step: 120, loss: 0.002251255325973034
step: 130, loss: 0.0006734527996741235
step: 140, loss: 0.0001986037677852437
step: 150, loss: 5.377722845878452e-05
step: 160, loss: 3.456927152001299e-05
step: 170, loss: 0.013067729771137238
step: 180, loss: 0.002133767819032073
step: 190, loss: 3.9660382753936574e-05
step: 200, loss: 3.3842326956801116e-05
step: 210, loss: 0.001042902353219688
step: 220, loss: 0.08681843429803848
step: 230, loss: 3.964593634009361e-05
step: 240, loss: 0.0002337394980713725
step: 250, loss: 4.802021794603206e-05
step: 260, loss: 0.00013608856534119695
step: 270, loss: 5.973553197691217e-05
step: 280, loss: 0.00010904342343565077
step: 290, loss: 0.01224901620298624
step: 300, loss: 0.03030143864452839
step: 310, loss: 0.00010439591278554872
step: 320, loss: 0.0008019014494493604
step: 330, loss: 4.0737333620199934e-05
epoch 15: dev_f1=0.7835616438356166, f1=0.7379679144385027, best_f1=0.7740259740259741
step: 0, loss: 6.30111462669447e-05
step: 10, loss: 0.0018460260471329093
step: 20, loss: 3.427886258577928e-05
step: 30, loss: 2.55177201324841e-05
step: 40, loss: 0.00019537274783942848
step: 50, loss: 0.00014182575978338718
step: 60, loss: 0.008800436742603779
step: 70, loss: 2.5565845135133713e-05
step: 80, loss: 5.5236025218619034e-05
step: 90, loss: 0.0002983764570672065
step: 100, loss: 9.621064964449033e-05
step: 110, loss: 0.00036236565210856497
step: 120, loss: 8.499609248246998e-05
step: 130, loss: 2.339789534744341e-05
step: 140, loss: 0.05701719596982002
step: 150, loss: 0.0013814293779432774
step: 160, loss: 0.006416304502636194
step: 170, loss: 5.643392069032416e-05
step: 180, loss: 3.18533020617906e-05
step: 190, loss: 0.00021212943829596043
step: 200, loss: 0.001557674608193338
step: 210, loss: 2.884731293306686e-05
step: 220, loss: 0.00032974264468066394
step: 230, loss: 8.457600051769987e-05
step: 240, loss: 0.000553964520804584
step: 250, loss: 4.8996618716046214e-05
step: 260, loss: 0.0002271896810270846
step: 270, loss: 7.641498814336956e-05
step: 280, loss: 0.008967677131295204
step: 290, loss: 0.00012073649850208312
step: 300, loss: 4.877868195762858e-05
step: 310, loss: 3.852728332276456e-05
step: 320, loss: 2.3077673176885583e-05
step: 330, loss: 3.631774598034099e-05
epoch 16: dev_f1=0.7751937984496124, f1=0.7635467980295567, best_f1=0.7740259740259741
step: 0, loss: 0.009250422939658165
step: 10, loss: 4.761054879054427e-05
step: 20, loss: 0.0001706677139736712
step: 30, loss: 3.4776552638504654e-05
step: 40, loss: 0.00014734217256773263
step: 50, loss: 3.5906949051423e-05
step: 60, loss: 5.13000413775444e-05
step: 70, loss: 6.494775880128145e-05
step: 80, loss: 6.1892977100797e-05
step: 90, loss: 0.00020225330081302673
step: 100, loss: 2.7297859560349025e-05
step: 110, loss: 0.00012353071360848844
step: 120, loss: 0.0009140109759755433
step: 130, loss: 3.698453292599879e-05
step: 140, loss: 6.546899385284632e-05
step: 150, loss: 6.425759784178808e-05
step: 160, loss: 0.0010196127695962787
step: 170, loss: 4.9249476433033124e-05
step: 180, loss: 0.018706340342760086
step: 190, loss: 5.6324042816413566e-05
step: 200, loss: 0.00014911701146047562
step: 210, loss: 1.8004038793151267e-05
step: 220, loss: 2.7163741833646782e-05
step: 230, loss: 2.5591829398763366e-05
step: 240, loss: 1.9985811377409846e-05
step: 250, loss: 0.0005049278261139989
step: 260, loss: 0.01232084445655346
step: 270, loss: 2.4735078113735653e-05
step: 280, loss: 0.00017170609498862177
step: 290, loss: 2.4109282094286755e-05
step: 300, loss: 0.0007333658286370337
step: 310, loss: 3.088376979576424e-05
step: 320, loss: 9.409917402081192e-05
step: 330, loss: 0.00012755399802699685
epoch 17: dev_f1=0.7906976744186047, f1=0.7791563275434243, best_f1=0.7740259740259741
step: 0, loss: 4.544801413430832e-05
step: 10, loss: 3.3979376894421875e-05
step: 20, loss: 0.0005089493351988494
step: 30, loss: 3.344960350659676e-05
step: 40, loss: 3.59124896931462e-05
step: 50, loss: 3.156290767947212e-05
step: 60, loss: 5.2577535825548694e-05
step: 70, loss: 0.001371505786664784
step: 80, loss: 1.9694838556461036e-05
step: 90, loss: 0.031817689538002014
step: 100, loss: 0.025540221482515335
step: 110, loss: 1.921817602124065e-05
step: 120, loss: 2.2566904590348713e-05
step: 130, loss: 0.0001595726062078029
step: 140, loss: 2.1631960407830775e-05
step: 150, loss: 5.991235593683086e-05
step: 160, loss: 0.00012301841343287379
step: 170, loss: 2.0454581317608245e-05
step: 180, loss: 2.0890669475193135e-05
step: 190, loss: 2.1966936401440762e-05
step: 200, loss: 1.4155913049762603e-05
step: 210, loss: 6.722907710354775e-05
step: 220, loss: 2.3103517378331162e-05
step: 230, loss: 2.6381509087514132e-05
step: 240, loss: 1.9978127966169268e-05
step: 250, loss: 1.3727587429457344e-05
step: 260, loss: 2.4593335183453746e-05
step: 270, loss: 1.7206697521032766e-05
step: 280, loss: 3.0292712835944258e-05
step: 290, loss: 2.973769005620852e-05
step: 300, loss: 3.674995605251752e-05
step: 310, loss: 3.8997030060272664e-05
step: 320, loss: 5.5067728681024164e-05
step: 330, loss: 2.483554089849349e-05
epoch 18: dev_f1=0.7918781725888325, f1=0.7745098039215688, best_f1=0.7740259740259741
step: 0, loss: 0.0007789380033500493
step: 10, loss: 0.0010774934198707342
step: 20, loss: 2.375516851316206e-05
step: 30, loss: 3.7236335629131645e-05
step: 40, loss: 4.463945879251696e-05
step: 50, loss: 6.150395347503945e-05
step: 60, loss: 0.007365442346781492
step: 70, loss: 5.3403568017529324e-05
step: 80, loss: 0.00010568382276687771
step: 90, loss: 1.218907164002303e-05
step: 100, loss: 2.0004226826131344e-05
step: 110, loss: 4.792061008629389e-05
step: 120, loss: 0.0002450880128890276
step: 130, loss: 2.987915650010109e-05
step: 140, loss: 2.4749606382101774e-05
step: 150, loss: 3.18097481795121e-05
step: 160, loss: 0.002245122566819191
step: 170, loss: 5.129626879352145e-05
step: 180, loss: 6.537389708682895e-05
step: 190, loss: 3.827972977887839e-05
step: 200, loss: 2.933158611995168e-05
step: 210, loss: 0.003389325924217701
step: 220, loss: 0.00015098482253961265
step: 230, loss: 5.061377305537462e-05
step: 240, loss: 1.4453967196459416e-05
step: 250, loss: 0.0014320584014058113
step: 260, loss: 0.007980012334883213
step: 270, loss: 0.00628799619153142
step: 280, loss: 3.167309478158131e-05
step: 290, loss: 2.670074718480464e-05
step: 300, loss: 2.7662405045703053e-05
step: 310, loss: 0.010470299050211906
step: 320, loss: 0.005320241209119558
step: 330, loss: 0.00017335772281512618
epoch 19: dev_f1=0.7716535433070866, f1=0.7738693467336684, best_f1=0.7740259740259741
step: 0, loss: 0.00028913491405546665
step: 10, loss: 1.8901579096564092e-05
step: 20, loss: 0.0007825393695384264
step: 30, loss: 1.3198597116570454e-05
step: 40, loss: 1.7113610738306306e-05
step: 50, loss: 2.5882382033159956e-05
step: 60, loss: 1.1332266694807913e-05
step: 70, loss: 2.9541679396061227e-05
step: 80, loss: 2.7498936105985194e-05
step: 90, loss: 3.0112025342532434e-05
step: 100, loss: 6.428065535146743e-05
step: 110, loss: 3.828874105238356e-05
step: 120, loss: 1.772086034179665e-05
step: 130, loss: 2.3636079276911914e-05
step: 140, loss: 6.429104541894048e-05
step: 150, loss: 0.026509253308176994
step: 160, loss: 0.00972672738134861
step: 170, loss: 3.99025266233366e-05
step: 180, loss: 2.286875132995192e-05
step: 190, loss: 0.00027008246979676187
step: 200, loss: 2.5010529498104006e-05
step: 210, loss: 6.770376057829708e-05
step: 220, loss: 0.00031362203299067914
step: 230, loss: 1.6607020370429382e-05
step: 240, loss: 1.9709899788722396e-05
step: 250, loss: 0.036103617399930954
step: 260, loss: 1.558995973027777e-05
step: 270, loss: 2.4280345314764418e-05
step: 280, loss: 0.04510502889752388
step: 290, loss: 2.021653563133441e-05
step: 300, loss: 1.8432230717735365e-05
step: 310, loss: 4.060540231876075e-05
step: 320, loss: 2.225731259386521e-05
step: 330, loss: 2.275694532727357e-05
epoch 20: dev_f1=0.7792207792207791, f1=0.7810945273631842, best_f1=0.7740259740259741
