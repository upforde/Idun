cuda
Device: cuda
step: 0, loss: 0.7578981518745422
step: 10, loss: 0.0359872430562973
step: 20, loss: 0.14141666889190674
step: 30, loss: 0.43574538826942444
step: 40, loss: 0.3977997303009033
step: 50, loss: 0.151264488697052
step: 60, loss: 0.07220114767551422
step: 70, loss: 0.32103949785232544
step: 80, loss: 0.06873215734958649
step: 90, loss: 0.181729257106781
step: 100, loss: 0.3073446750640869
step: 110, loss: 0.25229474902153015
step: 120, loss: 0.34638503193855286
step: 130, loss: 0.4131453037261963
step: 140, loss: 0.30995893478393555
step: 150, loss: 0.1266726404428482
step: 160, loss: 0.30613741278648376
step: 170, loss: 0.06825088709592819
step: 180, loss: 0.38017845153808594
step: 190, loss: 0.26505038142204285
step: 200, loss: 0.3872791826725006
step: 210, loss: 0.20345743000507355
step: 220, loss: 0.12605224549770355
step: 230, loss: 0.3892430067062378
step: 240, loss: 0.030081074684858322
step: 250, loss: 0.13790006935596466
step: 260, loss: 0.033772215247154236
step: 270, loss: 0.10913308709859848
step: 280, loss: 0.17953412234783173
step: 290, loss: 0.1292298436164856
step: 300, loss: 0.18399938941001892
step: 310, loss: 0.4460008144378662
step: 320, loss: 0.3090827465057373
step: 330, loss: 0.1503075212240219
epoch 1: dev_f1=0.29292929292929293, f1=0.274442538593482, best_f1=0.274442538593482
step: 0, loss: 0.31616365909576416
step: 10, loss: 0.07216154038906097
step: 20, loss: 0.1172177866101265
step: 30, loss: 0.1813403218984604
step: 40, loss: 0.15074214339256287
step: 50, loss: 0.19242383539676666
step: 60, loss: 0.19292694330215454
step: 70, loss: 0.24072544276714325
step: 80, loss: 0.12190759927034378
step: 90, loss: 0.07704537361860275
step: 100, loss: 0.07393429428339005
step: 110, loss: 0.24808064103126526
step: 120, loss: 0.18459154665470123
step: 130, loss: 0.12187058478593826
step: 140, loss: 0.18767651915550232
step: 150, loss: 0.23842328786849976
step: 160, loss: 0.05485228821635246
step: 170, loss: 0.09890186786651611
step: 180, loss: 0.1024126186966896
step: 190, loss: 0.193623349070549
step: 200, loss: 0.294603556394577
step: 210, loss: 0.015211829915642738
step: 220, loss: 0.05717407912015915
step: 230, loss: 0.24910111725330353
step: 240, loss: 0.0908103957772255
step: 250, loss: 0.19107133150100708
step: 260, loss: 0.031759925186634064
step: 270, loss: 0.24544323980808258
step: 280, loss: 0.07996218651533127
step: 290, loss: 0.09111965447664261
step: 300, loss: 0.1385713815689087
step: 310, loss: 0.20918792486190796
step: 320, loss: 0.07985556125640869
step: 330, loss: 0.026556383818387985
epoch 2: dev_f1=0.701123595505618, f1=0.6945054945054946, best_f1=0.6945054945054946
step: 0, loss: 0.0355353020131588
step: 10, loss: 0.021470682695508003
step: 20, loss: 0.11219590157270432
step: 30, loss: 0.01971498131752014
step: 40, loss: 0.08375000953674316
step: 50, loss: 0.11230693012475967
step: 60, loss: 0.08755199611186981
step: 70, loss: 0.035526927560567856
step: 80, loss: 0.04826309531927109
step: 90, loss: 0.07482641190290451
step: 100, loss: 0.11785117536783218
step: 110, loss: 0.1379416435956955
step: 120, loss: 0.12439578771591187
step: 130, loss: 0.047732532024383545
step: 140, loss: 0.10521500557661057
step: 150, loss: 0.02652832306921482
step: 160, loss: 0.0414695106446743
step: 170, loss: 0.007122575305402279
step: 180, loss: 0.10033505409955978
step: 190, loss: 0.11495847254991531
step: 200, loss: 0.22710157930850983
step: 210, loss: 0.12340632826089859
step: 220, loss: 0.20552891492843628
step: 230, loss: 0.20197267830371857
step: 240, loss: 0.08666089177131653
step: 250, loss: 0.0808403342962265
step: 260, loss: 0.03605226054787636
step: 270, loss: 0.07200904935598373
step: 280, loss: 0.06464310735464096
step: 290, loss: 0.0765005499124527
step: 300, loss: 0.04396267980337143
step: 310, loss: 0.053571924567222595
step: 320, loss: 0.16639186441898346
step: 330, loss: 0.18858933448791504
epoch 3: dev_f1=0.7537688442211056, f1=0.7589498806682576, best_f1=0.7589498806682576
step: 0, loss: 0.007999302819371223
step: 10, loss: 0.03878965601325035
step: 20, loss: 0.033165495842695236
step: 30, loss: 0.0012009163619950414
step: 40, loss: 0.014445669017732143
step: 50, loss: 0.03059280477464199
step: 60, loss: 0.028666967526078224
step: 70, loss: 0.09811048954725266
step: 80, loss: 0.08236860483884811
step: 90, loss: 0.024274054914712906
step: 100, loss: 0.12502652406692505
step: 110, loss: 0.01814649999141693
step: 120, loss: 0.030387308448553085
step: 130, loss: 0.02643391117453575
step: 140, loss: 0.06585834175348282
step: 150, loss: 0.01946369558572769
step: 160, loss: 0.0007063913508318365
step: 170, loss: 0.24179235100746155
step: 180, loss: 0.0929342582821846
step: 190, loss: 0.06445912271738052
step: 200, loss: 0.05368049070239067
step: 210, loss: 0.03783595934510231
step: 220, loss: 0.07437791675329208
step: 230, loss: 0.06880952417850494
step: 240, loss: 0.033308856189250946
step: 250, loss: 0.046809542924165726
step: 260, loss: 0.018699156120419502
step: 270, loss: 0.11281686276197433
step: 280, loss: 0.009706065058708191
step: 290, loss: 0.12033480405807495
step: 300, loss: 0.0014276704750955105
step: 310, loss: 0.004191738087683916
step: 320, loss: 0.031247979030013084
step: 330, loss: 0.04930983483791351
epoch 4: dev_f1=0.7402298850574712, f1=0.7259953161592505, best_f1=0.7589498806682576
step: 0, loss: 0.01650267466902733
step: 10, loss: 0.007237957790493965
step: 20, loss: 0.0013734037056565285
step: 30, loss: 0.03152760863304138
step: 40, loss: 0.004051683004945517
step: 50, loss: 0.013396468944847584
step: 60, loss: 0.0016713220393285155
step: 70, loss: 0.025085626170039177
step: 80, loss: 0.12910668551921844
step: 90, loss: 0.18206657469272614
step: 100, loss: 0.009340831078588963
step: 110, loss: 0.0024850170593708754
step: 120, loss: 0.005140089895576239
step: 130, loss: 0.08780789375305176
step: 140, loss: 0.04402764514088631
step: 150, loss: 0.12062203884124756
step: 160, loss: 0.015689916908740997
step: 170, loss: 0.05970349535346031
step: 180, loss: 0.0859861820936203
step: 190, loss: 0.02404448576271534
step: 200, loss: 0.03975040838122368
step: 210, loss: 0.024685198441147804
step: 220, loss: 0.13147257268428802
step: 230, loss: 0.022451309487223625
step: 240, loss: 0.07707332819700241
step: 250, loss: 0.0020712618716061115
step: 260, loss: 0.004561273381114006
step: 270, loss: 0.006300739478319883
step: 280, loss: 0.05103771388530731
step: 290, loss: 0.04287244752049446
step: 300, loss: 0.0022590032313019037
step: 310, loss: 0.018781907856464386
step: 320, loss: 0.014908934012055397
step: 330, loss: 0.039498552680015564
epoch 5: dev_f1=0.763888888888889, f1=0.7595505617977529, best_f1=0.7595505617977529
step: 0, loss: 0.0008959663100540638
step: 10, loss: 0.009271642193198204
step: 20, loss: 0.0023163179866969585
step: 30, loss: 0.08092036098241806
step: 40, loss: 0.05603926628828049
step: 50, loss: 0.003466217312961817
step: 60, loss: 0.0053071328438818455
step: 70, loss: 0.11309392750263214
step: 80, loss: 0.0021064872853457928
step: 90, loss: 0.06861966103315353
step: 100, loss: 0.04490461200475693
step: 110, loss: 0.01442395057529211
step: 120, loss: 0.013445092365145683
step: 130, loss: 0.02821269817650318
step: 140, loss: 0.0851232185959816
step: 150, loss: 0.08244343847036362
step: 160, loss: 0.06268317997455597
step: 170, loss: 0.0005304508958943188
step: 180, loss: 0.04712025448679924
step: 190, loss: 0.04198378324508667
step: 200, loss: 0.017090389505028725
step: 210, loss: 0.0012675130274146795
step: 220, loss: 0.0016011653933674097
step: 230, loss: 0.050051603466272354
step: 240, loss: 0.0019758744165301323
step: 250, loss: 0.019608691334724426
step: 260, loss: 0.022101251408457756
step: 270, loss: 0.0036883121356368065
step: 280, loss: 0.001547556952573359
step: 290, loss: 0.06968792527914047
step: 300, loss: 0.00563158979639411
step: 310, loss: 0.002529460471123457
step: 320, loss: 0.0020752050913870335
step: 330, loss: 0.001099409768357873
epoch 6: dev_f1=0.7897196261682243, f1=0.7695852534562211, best_f1=0.7695852534562211
step: 0, loss: 0.00026815367164090276
step: 10, loss: 0.00012351979967206717
step: 20, loss: 0.0014806098770350218
step: 30, loss: 0.17984828352928162
step: 40, loss: 0.00012681944645009935
step: 50, loss: 0.004304524976760149
step: 60, loss: 0.019044239073991776
step: 70, loss: 0.0037360850255936384
step: 80, loss: 0.0021543530747294426
step: 90, loss: 0.0447436086833477
step: 100, loss: 0.0011412621242925525
step: 110, loss: 0.01784120872616768
step: 120, loss: 0.05736551806330681
step: 130, loss: 0.003524814499542117
step: 140, loss: 0.07832866907119751
step: 150, loss: 0.029219310730695724
step: 160, loss: 0.00451192120090127
step: 170, loss: 0.0018534846603870392
step: 180, loss: 0.0032050388399511576
step: 190, loss: 0.03664029762148857
step: 200, loss: 8.541510032955557e-05
step: 210, loss: 0.0051183560863137245
step: 220, loss: 0.005219294223934412
step: 230, loss: 0.0003601665375754237
step: 240, loss: 0.00039700971683487296
step: 250, loss: 0.02716965414583683
step: 260, loss: 0.00029956718208268285
step: 270, loss: 0.013212128542363644
step: 280, loss: 0.0054666646756231785
step: 290, loss: 0.0013508480042219162
step: 300, loss: 0.0023893993347883224
step: 310, loss: 0.06934529542922974
step: 320, loss: 0.026220357045531273
step: 330, loss: 0.023799696937203407
epoch 7: dev_f1=0.8059701492537313, f1=0.7922705314009661, best_f1=0.7922705314009661
step: 0, loss: 0.03814268112182617
step: 10, loss: 0.0025021100882440805
step: 20, loss: 0.03936205059289932
step: 30, loss: 0.05957363173365593
step: 40, loss: 0.0012664978858083487
step: 50, loss: 0.00029433605959638953
step: 60, loss: 0.0004885168746113777
step: 70, loss: 0.11908935755491257
step: 80, loss: 0.0017890076851472259
step: 90, loss: 0.00010031441343016922
step: 100, loss: 0.008533949963748455
step: 110, loss: 9.41901162150316e-05
step: 120, loss: 0.0003271409368608147
step: 130, loss: 0.010180707089602947
step: 140, loss: 0.000270818272838369
step: 150, loss: 0.00012512353714555502
step: 160, loss: 0.01012071967124939
step: 170, loss: 0.006743771489709616
step: 180, loss: 0.059182774275541306
step: 190, loss: 0.0012432353105396032
step: 200, loss: 0.004111626651138067
step: 210, loss: 0.0017664612969383597
step: 220, loss: 0.033043716102838516
step: 230, loss: 0.011617043055593967
step: 240, loss: 0.0029904264956712723
step: 250, loss: 0.0001641606941120699
step: 260, loss: 0.004265494178980589
step: 270, loss: 0.004398462828248739
step: 280, loss: 0.04109586775302887
step: 290, loss: 0.007418477442115545
step: 300, loss: 0.0012169105466455221
step: 310, loss: 9.517045691609383e-05
step: 320, loss: 0.0016819414449855685
step: 330, loss: 0.0001127802170231007
epoch 8: dev_f1=0.8, f1=0.7660550458715597, best_f1=0.7922705314009661
step: 0, loss: 0.0020850033033639193
step: 10, loss: 0.0012780193937942386
step: 20, loss: 0.007747359573841095
step: 30, loss: 0.04736102372407913
step: 40, loss: 0.00013572003808803856
step: 50, loss: 0.0001247723848791793
step: 60, loss: 0.00016379094449803233
step: 70, loss: 0.005902005359530449
step: 80, loss: 0.0011229407973587513
step: 90, loss: 0.03777524456381798
step: 100, loss: 0.023644763976335526
step: 110, loss: 0.00652881246060133
step: 120, loss: 0.008768620900809765
step: 130, loss: 0.02338067628443241
step: 140, loss: 0.00010236848174827173
step: 150, loss: 0.00014896539505571127
step: 160, loss: 0.00017754569125827402
step: 170, loss: 0.009126897901296616
step: 180, loss: 0.03191623091697693
step: 190, loss: 0.007069393992424011
step: 200, loss: 0.0899759829044342
step: 210, loss: 0.0027143668849021196
step: 220, loss: 0.030937431380152702
step: 230, loss: 0.05175371095538139
step: 240, loss: 0.0012365136062726378
step: 250, loss: 0.0019797992426902056
step: 260, loss: 0.007259885780513287
step: 270, loss: 0.0031263509299606085
step: 280, loss: 0.009819302707910538
step: 290, loss: 0.05215495824813843
step: 300, loss: 0.02806674689054489
step: 310, loss: 0.0018278993666172028
step: 320, loss: 0.001156326849013567
step: 330, loss: 0.02784227579832077
epoch 9: dev_f1=0.7722772277227724, f1=0.7639902676399027, best_f1=0.7922705314009661
step: 0, loss: 0.00018177332822233438
step: 10, loss: 0.00036537228152155876
step: 20, loss: 0.0006671589217148721
step: 30, loss: 0.010113845579326153
step: 40, loss: 0.02844531089067459
step: 50, loss: 0.0002128054911736399
step: 60, loss: 0.025762878358364105
step: 70, loss: 0.0026960414834320545
step: 80, loss: 0.00029409793205559254
step: 90, loss: 0.0007350585074163973
step: 100, loss: 0.003935149870812893
step: 110, loss: 0.0046934699639678
step: 120, loss: 0.0003580337797757238
step: 130, loss: 0.00034392072120681405
step: 140, loss: 0.0005717992316931486
step: 150, loss: 0.034204594790935516
step: 160, loss: 0.0058299945667386055
step: 170, loss: 0.0014827616978436708
step: 180, loss: 0.1764223873615265
step: 190, loss: 0.0017229747027158737
step: 200, loss: 0.00140001333784312
step: 210, loss: 0.0003184287343174219
step: 220, loss: 0.011393661610782146
step: 230, loss: 0.0010529829887673259
step: 240, loss: 0.026046091690659523
step: 250, loss: 0.0060384939424693584
step: 260, loss: 0.00024093457614071667
step: 270, loss: 0.0003659068897832185
step: 280, loss: 8.319821790792048e-05
step: 290, loss: 0.013193780556321144
step: 300, loss: 0.001822205143980682
step: 310, loss: 0.039727408438920975
step: 320, loss: 0.03223187103867531
step: 330, loss: 0.00045505896559916437
epoch 10: dev_f1=0.7474226804123711, f1=0.7711442786069652, best_f1=0.7922705314009661
step: 0, loss: 3.644413300207816e-05
step: 10, loss: 0.0005554853123612702
step: 20, loss: 0.004968421068042517
step: 30, loss: 0.00013153649342712015
step: 40, loss: 0.0019249891629442573
step: 50, loss: 0.00014815649774391204
step: 60, loss: 4.186031219433062e-05
step: 70, loss: 0.0070443847216665745
step: 80, loss: 0.0010326270712539554
step: 90, loss: 0.00029197600088082254
step: 100, loss: 0.001144869951531291
step: 110, loss: 0.0003198377962689847
step: 120, loss: 0.0015044764149934053
step: 130, loss: 0.02582300826907158
step: 140, loss: 0.001173730124719441
step: 150, loss: 0.10427110642194748
step: 160, loss: 0.10886379331350327
step: 170, loss: 7.74737709434703e-05
step: 180, loss: 0.018093153834342957
step: 190, loss: 0.003379249246791005
step: 200, loss: 0.013257772661745548
step: 210, loss: 0.0008542112773284316
step: 220, loss: 0.022103669121861458
step: 230, loss: 0.0003094066050834954
step: 240, loss: 0.018214302137494087
step: 250, loss: 0.00026489398442208767
step: 260, loss: 0.00028820717125199735
step: 270, loss: 0.0043264287523925304
step: 280, loss: 0.00021974659466650337
step: 290, loss: 0.002042116830125451
step: 300, loss: 0.0015303677646443248
step: 310, loss: 0.007347053848206997
step: 320, loss: 0.028345530852675438
step: 330, loss: 0.00010039192420663312
epoch 11: dev_f1=0.7512953367875648, f1=0.745679012345679, best_f1=0.7922705314009661
step: 0, loss: 0.0001028262049658224
step: 10, loss: 6.171406130306423e-05
step: 20, loss: 2.0876270355074666e-05
step: 30, loss: 0.00018342057592235506
step: 40, loss: 0.006638847291469574
step: 50, loss: 0.0011648981599137187
step: 60, loss: 8.966817404143512e-05
step: 70, loss: 0.007747534662485123
step: 80, loss: 0.01385495811700821
step: 90, loss: 0.0005523697473108768
step: 100, loss: 2.998634590767324e-05
step: 110, loss: 0.00017285544890910387
step: 120, loss: 0.00015616696327924728
step: 130, loss: 0.000858396990224719
step: 140, loss: 0.0003127229865640402
step: 150, loss: 0.011892130598425865
step: 160, loss: 0.0004918857594020665
step: 170, loss: 0.01899627596139908
step: 180, loss: 0.0011883411789312959
step: 190, loss: 0.00025501757045276463
step: 200, loss: 0.00011617452400969341
step: 210, loss: 0.0004615304933395237
step: 220, loss: 0.0006634040619246662
step: 230, loss: 0.006424030754715204
step: 240, loss: 0.0002346811961615458
step: 250, loss: 0.001619772519916296
step: 260, loss: 0.002054581418633461
step: 270, loss: 0.0008981261635199189
step: 280, loss: 0.0011627546045929193
step: 290, loss: 0.01201782375574112
step: 300, loss: 0.0015497945714741945
step: 310, loss: 0.008705521002411842
step: 320, loss: 0.00032544502755627036
step: 330, loss: 0.0011083314893767238
epoch 12: dev_f1=0.7487437185929648, f1=0.7584541062801932, best_f1=0.7922705314009661
step: 0, loss: 0.0012656210456043482
step: 10, loss: 0.0010813026456162333
step: 20, loss: 0.0007974662003107369
step: 30, loss: 0.005013624206185341
step: 40, loss: 0.0003351860505063087
step: 50, loss: 0.00014071675832383335
step: 60, loss: 0.0005903408746235073
step: 70, loss: 0.05533454939723015
step: 80, loss: 0.0006041929009370506
step: 90, loss: 0.0025536310859024525
step: 100, loss: 0.00112695072311908
step: 110, loss: 0.00025521969655528665
step: 120, loss: 0.000660691992379725
step: 130, loss: 0.010012008249759674
step: 140, loss: 0.0005917716189287603
step: 150, loss: 0.00012183390208519995
step: 160, loss: 5.7207882491638884e-05
step: 170, loss: 0.0016074544982984662
step: 180, loss: 0.0004508436832111329
step: 190, loss: 0.0001251195790246129
step: 200, loss: 0.002612498588860035
step: 210, loss: 5.516637975233607e-05
step: 220, loss: 0.0006534907151944935
step: 230, loss: 4.00168719352223e-05
step: 240, loss: 0.02274494804441929
step: 250, loss: 0.0005225679487921298
step: 260, loss: 0.006395071744918823
step: 270, loss: 3.359659967827611e-05
step: 280, loss: 0.006011659279465675
step: 290, loss: 3.329790342831984e-05
step: 300, loss: 1.5306941349990666e-05
step: 310, loss: 2.0015593690914102e-05
step: 320, loss: 0.004392649978399277
step: 330, loss: 2.8466773073887452e-05
epoch 13: dev_f1=0.7662650602409637, f1=0.7670588235294118, best_f1=0.7922705314009661
step: 0, loss: 0.0001545568957226351
step: 10, loss: 3.367690078448504e-05
step: 20, loss: 0.00012639234773814678
step: 30, loss: 2.7047382900491357e-05
step: 40, loss: 3.7262743717292324e-05
step: 50, loss: 0.005356594454497099
step: 60, loss: 0.000259150518104434
step: 70, loss: 3.9007285522529855e-05
step: 80, loss: 0.00022004838683642447
step: 90, loss: 0.01332505140453577
step: 100, loss: 3.4515313018346205e-05
step: 110, loss: 0.0001247773034265265
step: 120, loss: 0.00028617389034479856
step: 130, loss: 6.215205212356523e-05
step: 140, loss: 3.084895070060156e-05
step: 150, loss: 3.3921136491699144e-05
step: 160, loss: 7.992413884494454e-05
step: 170, loss: 3.6343553801998496e-05
step: 180, loss: 4.072991941939108e-05
step: 190, loss: 1.2382773093122523e-05
step: 200, loss: 0.0016313237138092518
step: 210, loss: 1.8081957023241557e-05
step: 220, loss: 0.00020970879995729774
step: 230, loss: 1.2960195817868225e-05
step: 240, loss: 2.1720774384448305e-05
step: 250, loss: 0.01009458303451538
step: 260, loss: 0.057764310389757156
step: 270, loss: 9.946557111106813e-05
step: 280, loss: 0.00010522046795813367
step: 290, loss: 0.00017423040117137134
step: 300, loss: 0.005517563782632351
step: 310, loss: 0.0005053075728937984
step: 320, loss: 0.03349500149488449
step: 330, loss: 0.0012548716040328145
epoch 14: dev_f1=0.756476683937824, f1=0.7722772277227724, best_f1=0.7922705314009661
step: 0, loss: 0.00022852403344586492
step: 10, loss: 0.0002165884943678975
step: 20, loss: 0.041961196810007095
step: 30, loss: 1.402184170729015e-05
step: 40, loss: 3.681062662508339e-05
step: 50, loss: 6.456312257796526e-05
step: 60, loss: 5.844539191457443e-05
step: 70, loss: 0.0016890306724235415
step: 80, loss: 6.366198795149103e-05
step: 90, loss: 0.007844184525310993
step: 100, loss: 0.0003060236922465265
step: 110, loss: 2.836288149410393e-05
step: 120, loss: 2.2469910618383437e-05
step: 130, loss: 7.194341014837846e-05
step: 140, loss: 4.4784457713831216e-05
step: 150, loss: 9.344969294033945e-05
step: 160, loss: 0.0001194302094518207
step: 170, loss: 0.00020449812291190028
step: 180, loss: 0.00019383526523597538
step: 190, loss: 1.7422707969672047e-05
step: 200, loss: 2.0868432329734787e-05
step: 210, loss: 0.0006314802449196577
step: 220, loss: 8.111899660434574e-05
step: 230, loss: 0.0012400245759636164
step: 240, loss: 0.0007345575140789151
step: 250, loss: 0.00016513405716978014
step: 260, loss: 2.0637378838728182e-05
step: 270, loss: 0.0002646294014994055
step: 280, loss: 7.393243140541017e-05
step: 290, loss: 6.0680944443447515e-05
step: 300, loss: 0.0005503427237272263
step: 310, loss: 0.0011996026150882244
step: 320, loss: 0.0042907362803816795
step: 330, loss: 0.0002191680541727692
epoch 15: dev_f1=0.760705289672544, f1=0.7718446601941746, best_f1=0.7922705314009661
step: 0, loss: 0.001608685008250177
step: 10, loss: 0.003389985067769885
step: 20, loss: 0.0004910798161290586
step: 30, loss: 0.0003022155724465847
step: 40, loss: 0.0014928774908185005
step: 50, loss: 0.008466800674796104
step: 60, loss: 0.0022022342309355736
step: 70, loss: 0.002572484314441681
step: 80, loss: 6.580720219062641e-05
step: 90, loss: 0.0038610841147601604
step: 100, loss: 3.22507657983806e-05
step: 110, loss: 8.938944665715098e-05
step: 120, loss: 0.0005894119385629892
step: 130, loss: 0.03884051740169525
step: 140, loss: 4.63876967842225e-05
step: 150, loss: 1.4308680874819402e-05
step: 160, loss: 2.8396336347213946e-05
step: 170, loss: 2.2361675291904248e-05
step: 180, loss: 0.00010238639515591785
step: 190, loss: 0.0001265702594537288
step: 200, loss: 1.2379002328088973e-05
step: 210, loss: 0.00012879740097559988
step: 220, loss: 3.190072311554104e-05
step: 230, loss: 1.699789754638914e-05
step: 240, loss: 0.0002893681521527469
step: 250, loss: 0.024246275424957275
step: 260, loss: 0.002706124447286129
step: 270, loss: 0.0006645983667112887
step: 280, loss: 9.711850725580007e-05
step: 290, loss: 1.780646744009573e-05
step: 300, loss: 0.0028121573850512505
step: 310, loss: 1.1850010196212679e-05
step: 320, loss: 0.00038350524846464396
step: 330, loss: 2.3646740373806097e-05
epoch 16: dev_f1=0.748051948051948, f1=0.7616707616707616, best_f1=0.7922705314009661
step: 0, loss: 6.273480539675802e-05
step: 10, loss: 0.00016372441314160824
step: 20, loss: 4.34614994446747e-05
step: 30, loss: 3.3828826417448e-05
step: 40, loss: 1.0587205906631425e-05
step: 50, loss: 0.002253622515127063
step: 60, loss: 0.00028054541326127946
step: 70, loss: 0.00018100666056852788
step: 80, loss: 0.002166164107620716
step: 90, loss: 0.00017736083827912807
step: 100, loss: 0.000248891010414809
step: 110, loss: 1.5701729353168048e-05
step: 120, loss: 0.00022623033146373928
step: 130, loss: 0.0003100877511315048
step: 140, loss: 6.0261816543061286e-05
step: 150, loss: 4.6150344132911414e-05
step: 160, loss: 3.476134952506982e-05
step: 170, loss: 5.068816972197965e-05
step: 180, loss: 2.2008249288774095e-05
step: 190, loss: 0.003810540307313204
step: 200, loss: 0.00017577408289071172
step: 210, loss: 0.0005352996522560716
step: 220, loss: 0.0008687617955729365
step: 230, loss: 9.455897816224024e-05
step: 240, loss: 1.99926107598003e-05
step: 250, loss: 0.08481649309396744
step: 260, loss: 0.0006701229722239077
step: 270, loss: 0.0014682766050100327
step: 280, loss: 0.0011777146719396114
step: 290, loss: 0.0016454580472782254
step: 300, loss: 0.0033874583896249533
step: 310, loss: 0.0001041596697177738
step: 320, loss: 0.00431212130934
step: 330, loss: 3.108899181825109e-05
epoch 17: dev_f1=0.7658536585365854, f1=0.7754137115839244, best_f1=0.7922705314009661
step: 0, loss: 8.791354048298672e-05
step: 10, loss: 7.730956713203341e-05
step: 20, loss: 3.6039673432242125e-05
step: 30, loss: 1.1332251233397983e-05
step: 40, loss: 5.5537628213642165e-05
step: 50, loss: 0.001636257627978921
step: 60, loss: 0.1026952862739563
step: 70, loss: 5.4770636779721826e-05
step: 80, loss: 9.701852832222357e-05
step: 90, loss: 5.4250402172328904e-05
step: 100, loss: 3.398213812033646e-05
step: 110, loss: 5.487436646944843e-05
step: 120, loss: 0.14367520809173584
step: 130, loss: 6.826121534686536e-05
step: 140, loss: 0.0008070561452768743
step: 150, loss: 0.020147431641817093
step: 160, loss: 4.02846526412759e-05
step: 170, loss: 0.00010595702042337507
step: 180, loss: 2.175486042688135e-05
step: 190, loss: 5.709911056328565e-05
step: 200, loss: 0.0002725297526922077
step: 210, loss: 0.0028781595174223185
step: 220, loss: 0.00033712180447764695
step: 230, loss: 1.9479006368783303e-05
step: 240, loss: 4.488671038416214e-05
step: 250, loss: 0.0006556805456057191
step: 260, loss: 0.00017467912402935326
step: 270, loss: 0.0007049007690511644
step: 280, loss: 4.787909711012617e-05
step: 290, loss: 3.682773240143433e-05
step: 300, loss: 0.0004294243990443647
step: 310, loss: 0.00025101707433350384
step: 320, loss: 0.005546217784285545
step: 330, loss: 0.00020789775589946657
epoch 18: dev_f1=0.775, f1=0.774818401937046, best_f1=0.7922705314009661
step: 0, loss: 0.0038725631311535835
step: 10, loss: 9.738397056935355e-05
step: 20, loss: 0.0001796124706743285
step: 30, loss: 0.00011469739547464997
step: 40, loss: 0.00020603662414941937
step: 50, loss: 0.000532155972905457
step: 60, loss: 0.00018937996355816722
step: 70, loss: 0.0001430016418453306
step: 80, loss: 0.00029441044898703694
step: 90, loss: 0.0047013647854328156
step: 100, loss: 0.00022115607862360775
step: 110, loss: 0.00014410704898182303
step: 120, loss: 0.0004712414229288697
step: 130, loss: 2.2093312509241514e-05
step: 140, loss: 2.774443601083476e-05
step: 150, loss: 0.040371641516685486
step: 160, loss: 0.00040919994353316724
step: 170, loss: 0.00013510386634152383
step: 180, loss: 0.0012296319473534822
step: 190, loss: 1.2118254744564183e-05
step: 200, loss: 5.784093445981853e-05
step: 210, loss: 0.013264073058962822
step: 220, loss: 4.041773718199693e-05
step: 230, loss: 0.00020900015078950673
step: 240, loss: 0.002348358044400811
step: 250, loss: 0.011769025586545467
step: 260, loss: 2.7255964596406557e-05
step: 270, loss: 7.186891161836684e-05
step: 280, loss: 0.0005203840555623174
step: 290, loss: 0.00031676882645115256
step: 300, loss: 0.0062628756277263165
step: 310, loss: 0.00013756919361185282
step: 320, loss: 0.0003561542835086584
step: 330, loss: 3.449696669122204e-05
epoch 19: dev_f1=0.7660668380462724, f1=0.7741935483870968, best_f1=0.7922705314009661
step: 0, loss: 0.0002007774164667353
step: 10, loss: 2.3389740817947313e-05
step: 20, loss: 0.0011123201111331582
step: 30, loss: 0.0030152532272040844
step: 40, loss: 0.0031186044216156006
step: 50, loss: 0.01448008231818676
step: 60, loss: 2.642491745064035e-05
step: 70, loss: 0.00018174873548559844
step: 80, loss: 0.0003645012329798192
step: 90, loss: 2.7479976779432036e-05
step: 100, loss: 1.3757319720753003e-05
step: 110, loss: 0.000997811439447105
step: 120, loss: 6.0176269471412525e-05
step: 130, loss: 0.011675279587507248
step: 140, loss: 0.0008564797462895513
step: 150, loss: 0.00016733980737626553
step: 160, loss: 0.001919797621667385
step: 170, loss: 0.0001368469966109842
step: 180, loss: 0.018084701150655746
step: 190, loss: 0.0013433441054075956
step: 200, loss: 2.4397771994699724e-05
step: 210, loss: 0.001442585838958621
step: 220, loss: 7.852436101529747e-05
step: 230, loss: 1.8718967112363316e-05
step: 240, loss: 9.593908180249855e-05
step: 250, loss: 1.6487665561726317e-05
step: 260, loss: 0.0002812635793816298
step: 270, loss: 0.0011996137909591198
step: 280, loss: 0.00010142489918507636
step: 290, loss: 0.0038841934874653816
step: 300, loss: 2.2219996026251465e-05
step: 310, loss: 0.00090615707449615
step: 320, loss: 6.729852611897513e-05
step: 330, loss: 0.0006288923905231059
epoch 20: dev_f1=0.7621483375959078, f1=0.7783251231527093, best_f1=0.7922705314009661
