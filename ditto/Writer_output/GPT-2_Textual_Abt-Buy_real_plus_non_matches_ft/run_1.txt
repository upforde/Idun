cuda
Device: cuda
step: 0, loss: 0.6930811405181885
step: 10, loss: 0.45729860663414
step: 20, loss: 0.137568861246109
step: 30, loss: 0.2978082597255707
step: 40, loss: 0.23632164299488068
step: 50, loss: 0.35128092765808105
step: 60, loss: 0.31367409229278564
step: 70, loss: 0.2190481424331665
step: 80, loss: 0.13799124956130981
step: 90, loss: 0.14202019572257996
step: 100, loss: 0.2185698002576828
step: 110, loss: 0.22766970098018646
step: 120, loss: 0.21825210750102997
step: 130, loss: 0.3035234808921814
step: 140, loss: 0.12141979485750198
step: 150, loss: 0.20708419382572174
step: 160, loss: 0.23688319325447083
step: 170, loss: 0.16134226322174072
step: 180, loss: 0.33365005254745483
step: 190, loss: 0.33418816328048706
step: 200, loss: 0.08102896809577942
step: 210, loss: 0.11003410816192627
step: 220, loss: 0.07799175381660461
step: 230, loss: 0.029155172407627106
step: 240, loss: 0.32807666063308716
step: 250, loss: 0.191085085272789
step: 260, loss: 0.27130207419395447
step: 270, loss: 0.17386707663536072
step: 280, loss: 0.1603400707244873
step: 290, loss: 0.059566862881183624
step: 300, loss: 0.07962474226951599
step: 310, loss: 0.5890089273452759
step: 320, loss: 0.23276397585868835
step: 330, loss: 0.14776326715946198
epoch 1: dev_f1=0.29467084639498436, f1=0.27145085803432134, best_f1=0.27145085803432134
step: 0, loss: 0.1898796707391739
step: 10, loss: 0.23698927462100983
step: 20, loss: 0.3110935688018799
step: 30, loss: 0.24109318852424622
step: 40, loss: 0.04027190059423447
step: 50, loss: 0.2710523307323456
step: 60, loss: 0.08684956282377243
step: 70, loss: 0.2153770625591278
step: 80, loss: 0.1767444610595703
step: 90, loss: 0.06431548297405243
step: 100, loss: 0.14430095255374908
step: 110, loss: 0.177488774061203
step: 120, loss: 0.24770484864711761
step: 130, loss: 0.0431704968214035
step: 140, loss: 0.14323806762695312
step: 150, loss: 0.26943525671958923
step: 160, loss: 0.2248600274324417
step: 170, loss: 0.05296582356095314
step: 180, loss: 0.21489456295967102
step: 190, loss: 0.0993926003575325
step: 200, loss: 0.0056046429090201855
step: 210, loss: 0.12433404475450516
step: 220, loss: 0.4807160794734955
step: 230, loss: 0.17503632605075836
step: 240, loss: 0.3312957286834717
step: 250, loss: 0.2549799680709839
step: 260, loss: 0.01007022149860859
step: 270, loss: 0.08085180819034576
step: 280, loss: 0.12638267874717712
step: 290, loss: 0.2041880190372467
step: 300, loss: 0.18485143780708313
step: 310, loss: 0.13124212622642517
step: 320, loss: 0.04702562466263771
step: 330, loss: 0.2519776225090027
epoch 2: dev_f1=0.7050691244239632, f1=0.7023554603854388, best_f1=0.7023554603854388
step: 0, loss: 0.06693625450134277
step: 10, loss: 0.03444153070449829
step: 20, loss: 0.06317182630300522
step: 30, loss: 0.11212791502475739
step: 40, loss: 0.07496751099824905
step: 50, loss: 0.0750875249505043
step: 60, loss: 0.13689355552196503
step: 70, loss: 0.050922468304634094
step: 80, loss: 0.04281797260046005
step: 90, loss: 0.06139194220304489
step: 100, loss: 0.03314328193664551
step: 110, loss: 0.07089900970458984
step: 120, loss: 0.02919231355190277
step: 130, loss: 0.005196778103709221
step: 140, loss: 0.0697535052895546
step: 150, loss: 0.0449739545583725
step: 160, loss: 0.006765846628695726
step: 170, loss: 0.031320761889219284
step: 180, loss: 0.06692173331975937
step: 190, loss: 0.33305683732032776
step: 200, loss: 0.03502051159739494
step: 210, loss: 0.008059734478592873
step: 220, loss: 0.15891033411026
step: 230, loss: 0.009254178032279015
step: 240, loss: 0.11669226735830307
step: 250, loss: 0.06261908262968063
step: 260, loss: 0.044538069516420364
step: 270, loss: 0.01604173704981804
step: 280, loss: 0.17854326963424683
step: 290, loss: 0.04147135093808174
step: 300, loss: 0.10721553862094879
step: 310, loss: 0.0943685844540596
step: 320, loss: 0.09535202383995056
step: 330, loss: 0.06991542130708694
epoch 3: dev_f1=0.8073394495412843, f1=0.7461368653421634, best_f1=0.7461368653421634
step: 0, loss: 0.03433011844754219
step: 10, loss: 0.04854947701096535
step: 20, loss: 0.06523577868938446
step: 30, loss: 0.08517846465110779
step: 40, loss: 0.06236801669001579
step: 50, loss: 0.050149232149124146
step: 60, loss: 0.09002447873353958
step: 70, loss: 0.031156577169895172
step: 80, loss: 0.05333750322461128
step: 90, loss: 0.00041432087891735137
step: 100, loss: 0.044205278158187866
step: 110, loss: 0.018657870590686798
step: 120, loss: 0.006485591642558575
step: 130, loss: 0.04810617119073868
step: 140, loss: 0.04755553975701332
step: 150, loss: 0.08782126009464264
step: 160, loss: 0.060120124369859695
step: 170, loss: 0.060772161930799484
step: 180, loss: 0.0341654010117054
step: 190, loss: 0.05526019632816315
step: 200, loss: 0.013923502527177334
step: 210, loss: 0.12812472879886627
step: 220, loss: 0.02349201962351799
step: 230, loss: 0.003560691373422742
step: 240, loss: 0.05408455431461334
step: 250, loss: 0.0006091229734010994
step: 260, loss: 0.008803493343293667
step: 270, loss: 0.08822391927242279
step: 280, loss: 0.017701536417007446
step: 290, loss: 0.07318834960460663
step: 300, loss: 0.17353585362434387
step: 310, loss: 0.10991368442773819
step: 320, loss: 0.012904845178127289
step: 330, loss: 0.011315474286675453
epoch 4: dev_f1=0.8048192771084338, f1=0.7517730496453902, best_f1=0.7461368653421634
step: 0, loss: 0.06073842570185661
step: 10, loss: 0.017859362065792084
step: 20, loss: 0.00011363707017153502
step: 30, loss: 0.037123143672943115
step: 40, loss: 0.040643878281116486
step: 50, loss: 0.013856103643774986
step: 60, loss: 0.13168106973171234
step: 70, loss: 0.00227929325774312
step: 80, loss: 0.001564259291626513
step: 90, loss: 0.00526194553822279
step: 100, loss: 0.0006513474509119987
step: 110, loss: 0.09701621532440186
step: 120, loss: 0.008822253905236721
step: 130, loss: 0.03951812535524368
step: 140, loss: 0.005544754676520824
step: 150, loss: 0.003985856659710407
step: 160, loss: 0.05783862993121147
step: 170, loss: 0.0069391196593642235
step: 180, loss: 0.014010814018547535
step: 190, loss: 0.0063238260336220264
step: 200, loss: 0.008172780275344849
step: 210, loss: 0.08803422003984451
step: 220, loss: 0.004797715228050947
step: 230, loss: 0.0017707191873341799
step: 240, loss: 0.09539239853620529
step: 250, loss: 0.018649978563189507
step: 260, loss: 0.006899785250425339
step: 270, loss: 0.005283943843096495
step: 280, loss: 0.017611240968108177
step: 290, loss: 0.10121707618236542
step: 300, loss: 0.07848429679870605
step: 310, loss: 0.04671764373779297
step: 320, loss: 0.04946252703666687
step: 330, loss: 0.01921192556619644
epoch 5: dev_f1=0.8040201005025125, f1=0.7759036144578313, best_f1=0.7461368653421634
step: 0, loss: 0.016291307285428047
step: 10, loss: 0.008462730795145035
step: 20, loss: 0.09928294271230698
step: 30, loss: 0.009076249785721302
step: 40, loss: 0.017284665256738663
step: 50, loss: 0.00611112779006362
step: 60, loss: 0.0034886079374700785
step: 70, loss: 0.00874651875346899
step: 80, loss: 0.09171491861343384
step: 90, loss: 0.007541016675531864
step: 100, loss: 0.044572584331035614
step: 110, loss: 0.04242440313100815
step: 120, loss: 0.0066295345313847065
step: 130, loss: 0.05662626400589943
step: 140, loss: 0.044196419417858124
step: 150, loss: 0.005472994409501553
step: 160, loss: 0.006301583722233772
step: 170, loss: 0.16997882723808289
step: 180, loss: 0.003808527020737529
step: 190, loss: 0.027627160772681236
step: 200, loss: 0.041140951216220856
step: 210, loss: 0.054503101855516434
step: 220, loss: 0.013787935487926006
step: 230, loss: 0.006516608409583569
step: 240, loss: 0.03499415144324303
step: 250, loss: 0.014377444982528687
step: 260, loss: 0.000649016525130719
step: 270, loss: 0.0060868337750434875
step: 280, loss: 0.00010858490713872015
step: 290, loss: 0.0018551656976342201
step: 300, loss: 0.1406104415655136
step: 310, loss: 0.0030863317660987377
step: 320, loss: 0.004229341167956591
step: 330, loss: 0.044685255736112595
epoch 6: dev_f1=0.7409326424870466, f1=0.7586206896551724, best_f1=0.7461368653421634
step: 0, loss: 0.009470869787037373
step: 10, loss: 0.0037502057384699583
step: 20, loss: 0.06112715229392052
step: 30, loss: 0.017506850883364677
step: 40, loss: 0.004954701289534569
step: 50, loss: 0.029205843806266785
step: 60, loss: 0.0016419625608250499
step: 70, loss: 0.04359576851129532
step: 80, loss: 0.0017778255278244615
step: 90, loss: 0.08312514424324036
step: 100, loss: 0.016430815681815147
step: 110, loss: 0.00401721615344286
step: 120, loss: 0.13026021420955658
step: 130, loss: 0.11551211774349213
step: 140, loss: 0.002295225625857711
step: 150, loss: 0.0037971038836985826
step: 160, loss: 0.0005196525598876178
step: 170, loss: 0.05902242287993431
step: 180, loss: 0.00570298545062542
step: 190, loss: 0.12082210183143616
step: 200, loss: 0.0006867655320093036
step: 210, loss: 0.008294373750686646
step: 220, loss: 8.886831346899271e-05
step: 230, loss: 0.00901616271585226
step: 240, loss: 0.00849920604377985
step: 250, loss: 0.01534780953079462
step: 260, loss: 0.00851917453110218
step: 270, loss: 0.04782252758741379
step: 280, loss: 0.0014130729250609875
step: 290, loss: 0.0009061415330506861
step: 300, loss: 0.00892808847129345
step: 310, loss: 0.006114582996815443
step: 320, loss: 0.013340042904019356
step: 330, loss: 0.06973022222518921
epoch 7: dev_f1=0.8069306930693069, f1=0.7931873479318734, best_f1=0.7461368653421634
step: 0, loss: 0.007945137098431587
step: 10, loss: 0.0008678285521455109
step: 20, loss: 0.0009000084828585386
step: 30, loss: 0.02509426884353161
step: 40, loss: 0.010779079049825668
step: 50, loss: 0.00016355009574908763
step: 60, loss: 0.00209927000105381
step: 70, loss: 0.0009614746086299419
step: 80, loss: 0.0037268276792019606
step: 90, loss: 0.002453865483403206
step: 100, loss: 0.0056400359608232975
step: 110, loss: 0.00443333201110363
step: 120, loss: 0.0005582369049079716
step: 130, loss: 0.0014663380570709705
step: 140, loss: 0.004130235873162746
step: 150, loss: 0.002423437312245369
step: 160, loss: 0.0005977887194603682
step: 170, loss: 0.02398066222667694
step: 180, loss: 0.03874501958489418
step: 190, loss: 0.010035146959125996
step: 200, loss: 0.004813666455447674
step: 210, loss: 0.027639247477054596
step: 220, loss: 0.00024004370789043605
step: 230, loss: 0.0009633820736780763
step: 240, loss: 0.0006971887778490782
step: 250, loss: 0.009297891519963741
step: 260, loss: 0.00033660087501630187
step: 270, loss: 0.002343233209103346
step: 280, loss: 0.01085254829376936
step: 290, loss: 0.025742415338754654
step: 300, loss: 0.08230399340391159
step: 310, loss: 0.012664358131587505
step: 320, loss: 0.01437355950474739
step: 330, loss: 0.000821599387563765
epoch 8: dev_f1=0.7830423940149626, f1=0.7772511848341233, best_f1=0.7461368653421634
step: 0, loss: 0.0003235089243389666
step: 10, loss: 0.00019286888709757477
step: 20, loss: 0.0006956740980967879
step: 30, loss: 0.00018278034985996783
step: 40, loss: 0.001572823035530746
step: 50, loss: 0.0009137216839008033
step: 60, loss: 0.016660558059811592
step: 70, loss: 0.0041198269464075565
step: 80, loss: 0.0062283617444336414
step: 90, loss: 0.0003279009833931923
step: 100, loss: 0.03126101940870285
step: 110, loss: 0.0031961353961378336
step: 120, loss: 0.02948787808418274
step: 130, loss: 0.0002850468154065311
step: 140, loss: 0.0013854691060259938
step: 150, loss: 0.0009596843738108873
step: 160, loss: 0.00614982470870018
step: 170, loss: 0.0002476464433129877
step: 180, loss: 0.00023875829356256872
step: 190, loss: 0.06394895911216736
step: 200, loss: 0.0017463641706854105
step: 210, loss: 0.00011335931048961356
step: 220, loss: 0.03304075822234154
step: 230, loss: 0.00020959280664101243
step: 240, loss: 0.09178370237350464
step: 250, loss: 0.0012389871990308166
step: 260, loss: 0.005313613917678595
step: 270, loss: 0.00035902162198908627
step: 280, loss: 0.001523106824606657
step: 290, loss: 0.005455339793115854
step: 300, loss: 0.0008290035766549408
step: 310, loss: 0.0010562582174316049
step: 320, loss: 0.06361284852027893
step: 330, loss: 0.030278539285063744
epoch 9: dev_f1=0.7581047381546135, f1=0.7735849056603774, best_f1=0.7461368653421634
step: 0, loss: 0.0005232939147390425
step: 10, loss: 0.0009437138214707375
step: 20, loss: 0.002484974917024374
step: 30, loss: 0.0001317317073699087
step: 40, loss: 0.012604787014424801
step: 50, loss: 0.0008843240793794394
step: 60, loss: 0.00012957533181179315
step: 70, loss: 0.0005755887250415981
step: 80, loss: 0.003599657444283366
step: 90, loss: 0.00048651162069290876
step: 100, loss: 0.0026158313266932964
step: 110, loss: 0.0011345000239089131
step: 120, loss: 0.0008869455778039992
step: 130, loss: 0.03898537531495094
step: 140, loss: 0.004618013743311167
step: 150, loss: 0.0003526729706209153
step: 160, loss: 0.0001234762603417039
step: 170, loss: 0.0015221638604998589
step: 180, loss: 0.016442883759737015
step: 190, loss: 0.0005188976065255702
step: 200, loss: 0.09660819917917252
step: 210, loss: 0.00019384395272936672
step: 220, loss: 0.0003509043890517205
step: 230, loss: 0.00028612956521101296
step: 240, loss: 0.09772438555955887
step: 250, loss: 0.0012490516528487206
step: 260, loss: 0.01236380822956562
step: 270, loss: 0.0008015485946089029
step: 280, loss: 0.0464937649667263
step: 290, loss: 0.0002779425121843815
step: 300, loss: 0.0003915217821486294
step: 310, loss: 0.018666420131921768
step: 320, loss: 0.0003416065592318773
step: 330, loss: 0.015778619796037674
epoch 10: dev_f1=0.7787610619469026, f1=0.7479338842975207, best_f1=0.7461368653421634
step: 0, loss: 0.017138712108135223
step: 10, loss: 0.00556441955268383
step: 20, loss: 0.0017676475690677762
step: 30, loss: 0.0004068090347573161
step: 40, loss: 0.004309781361371279
step: 50, loss: 0.0012751944595947862
step: 60, loss: 0.006049285642802715
step: 70, loss: 0.00039396825013682246
step: 80, loss: 0.0031600852962583303
step: 90, loss: 0.0004464734811335802
step: 100, loss: 0.0009645290556363761
step: 110, loss: 0.00029743742197752
step: 120, loss: 0.0001018075636238791
step: 130, loss: 0.0006405500462278724
step: 140, loss: 0.00014027867291588336
step: 150, loss: 0.00010029127588495612
step: 160, loss: 0.00043281278340145946
step: 170, loss: 0.00018951826496049762
step: 180, loss: 0.0028331067878752947
step: 190, loss: 0.018360627815127373
step: 200, loss: 6.924557237653062e-05
step: 210, loss: 0.031059052795171738
step: 220, loss: 0.00017460359958931804
step: 230, loss: 0.0012595001608133316
step: 240, loss: 0.001843501115217805
step: 250, loss: 0.00019858000450767577
step: 260, loss: 0.00012128653906984255
step: 270, loss: 0.000672192603815347
step: 280, loss: 0.0003208527050446719
step: 290, loss: 0.0037412294186651707
step: 300, loss: 0.0009180380147881806
step: 310, loss: 0.01988159492611885
step: 320, loss: 0.0013128994032740593
step: 330, loss: 0.013741951435804367
epoch 11: dev_f1=0.7714987714987714, f1=0.7677725118483412, best_f1=0.7461368653421634
step: 0, loss: 7.294840906979516e-05
step: 10, loss: 0.0003548626264091581
step: 20, loss: 0.0002825851261150092
step: 30, loss: 0.001388589502312243
step: 40, loss: 0.0010397534351795912
step: 50, loss: 0.00042413678602315485
step: 60, loss: 0.003942572511732578
step: 70, loss: 0.0008810078725218773
step: 80, loss: 0.0003118619497399777
step: 90, loss: 0.0007564147817902267
step: 100, loss: 0.0006343062850646675
step: 110, loss: 0.0013216040097177029
step: 120, loss: 0.00033757498022168875
step: 130, loss: 0.005852933507412672
step: 140, loss: 0.00013106442929711193
step: 150, loss: 0.0004893035511486232
step: 160, loss: 0.00017310562543570995
step: 170, loss: 0.0018536084098741412
step: 180, loss: 0.000117302784929052
step: 190, loss: 0.003001633333042264
step: 200, loss: 0.00011325685045449063
step: 210, loss: 4.7047775296960026e-05
step: 220, loss: 0.00032409641426056623
step: 230, loss: 0.0009863714221864939
step: 240, loss: 0.0012468126369640231
step: 250, loss: 0.00015367352170869708
step: 260, loss: 0.0035530461464077234
step: 270, loss: 0.0002177550341002643
step: 280, loss: 0.00015490580699406564
step: 290, loss: 0.0560954287648201
step: 300, loss: 0.16619230806827545
step: 310, loss: 5.823936589877121e-05
step: 320, loss: 0.0025534857995808125
step: 330, loss: 0.0005759402411058545
epoch 12: dev_f1=0.7707808564231737, f1=0.7754137115839244, best_f1=0.7461368653421634
step: 0, loss: 0.0005374237080104649
step: 10, loss: 0.0003837679687421769
step: 20, loss: 0.009565470740199089
step: 30, loss: 0.00013482959184329957
step: 40, loss: 7.943317905301228e-05
step: 50, loss: 2.8833230317104608e-05
step: 60, loss: 0.000300028536003083
step: 70, loss: 0.00021486276818905026
step: 80, loss: 0.008386331610381603
step: 90, loss: 0.007684293668717146
step: 100, loss: 0.006775451824069023
step: 110, loss: 0.00018730769807007164
step: 120, loss: 0.0005473630735650659
step: 130, loss: 0.002870770636945963
step: 140, loss: 0.0002992633089888841
step: 150, loss: 0.0001760159939294681
step: 160, loss: 0.0004625627479981631
step: 170, loss: 0.0001000111224129796
step: 180, loss: 0.00017232834943570197
step: 190, loss: 0.000272030767519027
step: 200, loss: 6.378913531079888e-05
step: 210, loss: 0.00012939056614413857
step: 220, loss: 0.00017315855075139552
step: 230, loss: 0.03230395168066025
step: 240, loss: 6.67571002850309e-05
step: 250, loss: 0.02404479682445526
step: 260, loss: 0.00014296006702352315
step: 270, loss: 0.00010109123104484752
step: 280, loss: 0.0057726758532226086
step: 290, loss: 0.0007211096817627549
step: 300, loss: 6.915071571711451e-05
step: 310, loss: 7.476696191588417e-05
step: 320, loss: 3.702948379213922e-05
step: 330, loss: 9.325874270871282e-05
epoch 13: dev_f1=0.8010335917312662, f1=0.7949999999999999, best_f1=0.7461368653421634
step: 0, loss: 7.749295036774129e-05
step: 10, loss: 0.037143267691135406
step: 20, loss: 0.006170410662889481
step: 30, loss: 0.0009835653472691774
step: 40, loss: 0.011759590357542038
step: 50, loss: 0.020092247053980827
step: 60, loss: 0.00010711080540204421
step: 70, loss: 0.0011938201496377587
step: 80, loss: 4.059667844558135e-05
step: 90, loss: 0.0004982391255907714
step: 100, loss: 0.0389384999871254
step: 110, loss: 0.015183869749307632
step: 120, loss: 7.468670082744211e-05
step: 130, loss: 0.00012960677850060165
step: 140, loss: 0.00034289166796952486
step: 150, loss: 5.367939957068302e-05
step: 160, loss: 6.353185744956136e-05
step: 170, loss: 6.825575837865472e-05
step: 180, loss: 0.0005971311475150287
step: 190, loss: 0.00015527383948210627
step: 200, loss: 6.295274215517566e-05
step: 210, loss: 0.011428472585976124
step: 220, loss: 6.232507439563051e-05
step: 230, loss: 0.00024235263117589056
step: 240, loss: 0.009481554850935936
step: 250, loss: 0.002623169217258692
step: 260, loss: 7.588989683426917e-05
step: 270, loss: 5.308860636432655e-05
step: 280, loss: 0.04249955341219902
step: 290, loss: 0.00030697378679178655
step: 300, loss: 0.00011435009946580976
step: 310, loss: 0.0009288333239965141
step: 320, loss: 0.00010053154255729169
step: 330, loss: 0.049624644219875336
epoch 14: dev_f1=0.8009708737864077, f1=0.7749419953596287, best_f1=0.7461368653421634
step: 0, loss: 3.1693733035353944e-05
step: 10, loss: 0.0035206431057304144
step: 20, loss: 3.634492532000877e-05
step: 30, loss: 9.320873505203053e-05
step: 40, loss: 0.00010395342542324215
step: 50, loss: 5.229358794167638e-05
step: 60, loss: 0.0003842927690129727
step: 70, loss: 0.0014592622173950076
step: 80, loss: 2.3044192857923917e-05
step: 90, loss: 3.743356865015812e-05
step: 100, loss: 8.21255671326071e-05
step: 110, loss: 3.61692946171388e-05
step: 120, loss: 0.0002331701252842322
step: 130, loss: 0.00010667638707673177
step: 140, loss: 6.628159462707117e-05
step: 150, loss: 8.545340824639425e-05
step: 160, loss: 4.5507116738008335e-05
step: 170, loss: 8.105373126454651e-05
step: 180, loss: 0.005499903112649918
step: 190, loss: 2.9164255465730093e-05
step: 200, loss: 0.00014923905837349594
step: 210, loss: 0.00015047937631607056
step: 220, loss: 0.0011477720690891147
step: 230, loss: 5.435741331893951e-05
step: 240, loss: 0.0001870663109002635
step: 250, loss: 0.0001376215077470988
step: 260, loss: 4.556706335279159e-05
step: 270, loss: 0.013607393018901348
step: 280, loss: 0.00012458556739147753
step: 290, loss: 3.0507921110256575e-05
step: 300, loss: 7.87588651292026e-05
step: 310, loss: 2.0496270735748112e-05
step: 320, loss: 0.0008243769407272339
step: 330, loss: 5.726665767724626e-05
epoch 15: dev_f1=0.7735368956743003, f1=0.7604938271604937, best_f1=0.7461368653421634
step: 0, loss: 0.036394476890563965
step: 10, loss: 0.000379502191208303
step: 20, loss: 4.933660602546297e-05
step: 30, loss: 0.026804205030202866
step: 40, loss: 4.972862370777875e-05
step: 50, loss: 9.990093531087041e-05
step: 60, loss: 0.001330892788246274
step: 70, loss: 2.0454977857298218e-05
step: 80, loss: 0.00017906748689711094
step: 90, loss: 0.008550078608095646
step: 100, loss: 0.00025543937226757407
step: 110, loss: 1.879384944913909e-05
step: 120, loss: 0.0002761498326435685
step: 130, loss: 3.3506785257486627e-05
step: 140, loss: 0.017276227474212646
step: 150, loss: 0.00022848215303383768
step: 160, loss: 0.00016330255311913788
step: 170, loss: 0.0009132392588071525
step: 180, loss: 3.250901136198081e-05
step: 190, loss: 0.0006758624804206192
step: 200, loss: 2.0026778656756505e-05
step: 210, loss: 0.00015412410721182823
step: 220, loss: 8.883545524440706e-05
step: 230, loss: 0.0016592122847214341
step: 240, loss: 1.992990291910246e-05
step: 250, loss: 5.5446085752919316e-05
step: 260, loss: 1.6387279174523428e-05
step: 270, loss: 0.008559596724808216
step: 280, loss: 3.1069444958120584e-05
step: 290, loss: 0.00036513994564302266
step: 300, loss: 0.010469069704413414
step: 310, loss: 0.012757101096212864
step: 320, loss: 0.00017258926527574658
step: 330, loss: 3.871472290484235e-05
epoch 16: dev_f1=0.7849999999999999, f1=0.7790973871733967, best_f1=0.7461368653421634
step: 0, loss: 0.00034652953036129475
step: 10, loss: 8.62312808749266e-05
step: 20, loss: 6.480847514467314e-05
step: 30, loss: 6.145476072560996e-05
step: 40, loss: 3.525233842083253e-05
step: 50, loss: 5.7871435274137184e-05
step: 60, loss: 3.8105437852209434e-05
step: 70, loss: 5.090402555651963e-05
step: 80, loss: 2.2149937649373896e-05
step: 90, loss: 0.0073874336667358875
step: 100, loss: 9.8933327535633e-05
step: 110, loss: 6.147590465843678e-05
step: 120, loss: 0.00010848834062926471
step: 130, loss: 2.8098484108340926e-05
step: 140, loss: 0.00010344132169848308
step: 150, loss: 0.00011960176925640553
step: 160, loss: 4.018304753117263e-05
step: 170, loss: 2.5843881303444505e-05
step: 180, loss: 2.7591555408434942e-05
step: 190, loss: 0.0010782041354104877
step: 200, loss: 5.9805326600326225e-05
step: 210, loss: 2.5435110728722066e-05
step: 220, loss: 8.89991206349805e-05
step: 230, loss: 4.831724436371587e-05
step: 240, loss: 6.2458602769766e-05
step: 250, loss: 0.025430744513869286
step: 260, loss: 4.9701888201525435e-05
step: 270, loss: 0.005535684060305357
step: 280, loss: 0.004954253323376179
step: 290, loss: 3.119029861409217e-05
step: 300, loss: 1.477059140597703e-05
step: 310, loss: 4.519641152000986e-05
step: 320, loss: 2.7560679882299155e-05
step: 330, loss: 0.03616202622652054
epoch 17: dev_f1=0.7814207650273223, f1=0.7671957671957672, best_f1=0.7461368653421634
step: 0, loss: 2.316258724022191e-05
step: 10, loss: 0.00012062252062605694
step: 20, loss: 3.119107714155689e-05
step: 30, loss: 9.179775952361524e-05
step: 40, loss: 2.5997494958573952e-05
step: 50, loss: 0.00021383858984336257
step: 60, loss: 6.068782749935053e-05
step: 70, loss: 2.001563916564919e-05
step: 80, loss: 6.769076571799815e-05
step: 90, loss: 0.0006466767517849803
step: 100, loss: 2.5796152840484865e-05
step: 110, loss: 0.00019604925182648003
step: 120, loss: 3.574442962417379e-05
step: 130, loss: 5.258446981315501e-05
step: 140, loss: 0.00113126658834517
step: 150, loss: 0.00015818839892745018
step: 160, loss: 5.501956547959708e-05
step: 170, loss: 2.845957897079643e-05
step: 180, loss: 0.008541679009795189
step: 190, loss: 0.0004613408527802676
step: 200, loss: 4.998379517928697e-05
step: 210, loss: 0.010022255592048168
step: 220, loss: 5.890499960514717e-05
step: 230, loss: 1.4383225789060816e-05
step: 240, loss: 3.145751907140948e-05
step: 250, loss: 7.755435217404738e-05
step: 260, loss: 0.04806067794561386
step: 270, loss: 0.0013222119305282831
step: 280, loss: 1.4401807675312739e-05
step: 290, loss: 0.00020662065071519464
step: 300, loss: 2.4212453354266472e-05
step: 310, loss: 2.5178096620948054e-05
step: 320, loss: 0.0001043920055963099
step: 330, loss: 0.0013546185800805688
epoch 18: dev_f1=0.7639257294429708, f1=0.7587939698492463, best_f1=0.7461368653421634
step: 0, loss: 3.7039295420981944e-05
step: 10, loss: 2.0551731722662225e-05
step: 20, loss: 0.00022920525225345045
step: 30, loss: 7.315017137443647e-05
step: 40, loss: 1.5627456377842464e-05
step: 50, loss: 4.408878885442391e-05
step: 60, loss: 0.00015973580593708903
step: 70, loss: 0.000605230568908155
step: 80, loss: 0.010715438984334469
step: 90, loss: 4.208004247630015e-05
step: 100, loss: 0.00022135372273623943
step: 110, loss: 3.3568056096555665e-05
step: 120, loss: 0.00022956740576773882
step: 130, loss: 2.1658072000718676e-05
step: 140, loss: 7.022672070888802e-05
step: 150, loss: 1.2494539078033995e-05
step: 160, loss: 0.0014900584938004613
step: 170, loss: 0.00036055463715456426
step: 180, loss: 0.0011907038278877735
step: 190, loss: 1.6268157196464017e-05
step: 200, loss: 0.0030786741990596056
step: 210, loss: 4.1543600673321635e-05
step: 220, loss: 2.803117604344152e-05
step: 230, loss: 0.02322521060705185
step: 240, loss: 7.036938040982932e-05
step: 250, loss: 3.992793062934652e-05
step: 260, loss: 5.2249910368118435e-05
step: 270, loss: 0.00014610843209084123
step: 280, loss: 6.978870806051418e-05
step: 290, loss: 9.587116801412776e-05
step: 300, loss: 8.380650251638144e-05
step: 310, loss: 0.00025125377578660846
step: 320, loss: 5.71052405575756e-05
step: 330, loss: 4.6973196731414646e-05
epoch 19: dev_f1=0.7734806629834254, f1=0.7688172043010754, best_f1=0.7461368653421634
step: 0, loss: 0.005872485693544149
step: 10, loss: 0.00012215200695209205
step: 20, loss: 2.2481199266621843e-05
step: 30, loss: 0.0019791065715253353
step: 40, loss: 4.084458851139061e-05
step: 50, loss: 0.00011864973930642009
step: 60, loss: 6.858753476990387e-05
step: 70, loss: 3.771940100705251e-05
step: 80, loss: 6.58546996419318e-05
step: 90, loss: 6.230406870599836e-05
step: 100, loss: 0.0002447364095132798
step: 110, loss: 2.1613330318359658e-05
step: 120, loss: 3.0857190722599626e-05
step: 130, loss: 0.0002155972324544564
step: 140, loss: 4.555300256470218e-05
step: 150, loss: 0.012272464111447334
step: 160, loss: 0.0013938597403466702
step: 170, loss: 2.3188797058537602e-05
step: 180, loss: 0.00020663997565861791
step: 190, loss: 2.141617915185634e-05
step: 200, loss: 7.237544195959345e-05
step: 210, loss: 0.00014452036703005433
step: 220, loss: 6.467776256613433e-05
step: 230, loss: 7.267570617841557e-05
step: 240, loss: 4.788899968843907e-05
step: 250, loss: 3.863148231175728e-05
step: 260, loss: 0.00011072559573221952
step: 270, loss: 0.0051620835438370705
step: 280, loss: 9.722731920192018e-05
step: 290, loss: 7.454150181729347e-05
step: 300, loss: 3.272019966971129e-05
step: 310, loss: 1.892388900159858e-05
step: 320, loss: 5.934744331170805e-05
step: 330, loss: 0.001687261974439025
epoch 20: dev_f1=0.775623268698061, f1=0.7642276422764228, best_f1=0.7461368653421634
