cuda
Device: cuda
step: 0, loss: 0.6482996940612793
step: 10, loss: 0.5651103258132935
step: 20, loss: 0.5311837792396545
step: 30, loss: 0.5313240885734558
step: 40, loss: 0.31208693981170654
step: 50, loss: 0.7120644450187683
step: 60, loss: 0.15232549607753754
step: 70, loss: 0.34368476271629333
step: 80, loss: 0.11508449912071228
step: 90, loss: 0.11657325178384781
step: 100, loss: 0.028808925300836563
step: 110, loss: 0.022554747760295868
step: 120, loss: 0.09657634049654007
step: 130, loss: 0.368694007396698
step: 140, loss: 0.16017206013202667
step: 150, loss: 0.046810559928417206
step: 160, loss: 0.16578622162342072
step: 170, loss: 0.1360228806734085
step: 180, loss: 0.05685705691576004
step: 190, loss: 0.06645654886960983
step: 200, loss: 0.021152116358280182
step: 210, loss: 0.09952181577682495
step: 220, loss: 0.20963142812252045
step: 230, loss: 0.053102634847164154
step: 240, loss: 0.2089800387620926
step: 250, loss: 0.06723003834486008
step: 260, loss: 0.010575161315500736
step: 270, loss: 0.01870935969054699
epoch 1: dev_f1=0.9623893805309734, f1=0.9484083424807903, best_f1=0.9484083424807903
step: 0, loss: 0.031095687299966812
step: 10, loss: 0.012140555307269096
step: 20, loss: 0.0035717205610126257
step: 30, loss: 0.11798963695764542
step: 40, loss: 0.0083021130412817
step: 50, loss: 0.03738013282418251
step: 60, loss: 0.1069997027516365
step: 70, loss: 0.21884037554264069
step: 80, loss: 0.07134918123483658
step: 90, loss: 0.11490163952112198
step: 100, loss: 0.0711391344666481
step: 110, loss: 0.10311654955148697
step: 120, loss: 0.060847360640764236
step: 130, loss: 0.008655744604766369
step: 140, loss: 0.11231661587953568
step: 150, loss: 0.07347188889980316
step: 160, loss: 0.050463929772377014
step: 170, loss: 0.20139378309249878
step: 180, loss: 0.04438966140151024
step: 190, loss: 0.30514517426490784
step: 200, loss: 0.060801487416028976
step: 210, loss: 0.011809059418737888
step: 220, loss: 0.2522425353527069
step: 230, loss: 0.08251412957906723
step: 240, loss: 0.07035727798938751
step: 250, loss: 0.05849491059780121
step: 260, loss: 0.002683954546228051
step: 270, loss: 0.016536777839064598
epoch 2: dev_f1=0.9810479375696767, f1=0.9645232815964524, best_f1=0.9645232815964524
step: 0, loss: 0.0059174648486077785
step: 10, loss: 0.11351495236158371
step: 20, loss: 0.00848669558763504
step: 30, loss: 0.0020351733546704054
step: 40, loss: 0.17271873354911804
step: 50, loss: 0.028262829408049583
step: 60, loss: 0.006050721276551485
step: 70, loss: 0.026402559131383896
step: 80, loss: 0.20535969734191895
step: 90, loss: 0.04294729605317116
step: 100, loss: 0.14055941998958588
step: 110, loss: 0.021465569734573364
step: 120, loss: 0.006953194737434387
step: 130, loss: 0.02812657691538334
step: 140, loss: 0.05761578306555748
step: 150, loss: 0.08098287880420685
step: 160, loss: 0.0916564017534256
step: 170, loss: 0.005269334185868502
step: 180, loss: 0.07557112723588943
step: 190, loss: 0.011507943272590637
step: 200, loss: 0.03184068575501442
step: 210, loss: 0.0014168514171615243
step: 220, loss: 0.010169272311031818
step: 230, loss: 0.011592433787882328
step: 240, loss: 0.0040480573661625385
step: 250, loss: 0.017145678400993347
step: 260, loss: 0.06484092772006989
step: 270, loss: 0.008822668343782425
epoch 3: dev_f1=0.978865406006674, f1=0.9700332963374029, best_f1=0.9645232815964524
step: 0, loss: 0.00426510302349925
step: 10, loss: 0.011120650917291641
step: 20, loss: 0.003086578566581011
step: 30, loss: 0.15043197572231293
step: 40, loss: 0.021748442202806473
step: 50, loss: 0.022360006347298622
step: 60, loss: 0.002276662504300475
step: 70, loss: 0.015056779608130455
step: 80, loss: 0.0041817002929747105
step: 90, loss: 0.057371851056814194
step: 100, loss: 0.05647093430161476
step: 110, loss: 0.004270065575838089
step: 120, loss: 0.1663128286600113
step: 130, loss: 0.01737407222390175
step: 140, loss: 0.023610513657331467
step: 150, loss: 0.0024700749199837446
step: 160, loss: 0.01030108891427517
step: 170, loss: 0.14270704984664917
step: 180, loss: 0.21259498596191406
step: 190, loss: 0.014211229048669338
step: 200, loss: 0.006009002216160297
step: 210, loss: 0.1492283195257187
step: 220, loss: 0.010833311825990677
step: 230, loss: 0.0023902407847344875
step: 240, loss: 0.005614142864942551
step: 250, loss: 0.0022101791109889746
step: 260, loss: 0.09874647855758667
step: 270, loss: 0.004807550925761461
epoch 4: dev_f1=0.9854423292273236, f1=0.9798206278026906, best_f1=0.9798206278026906
step: 0, loss: 0.007598696276545525
step: 10, loss: 0.008837927132844925
step: 20, loss: 0.0021643450018018484
step: 30, loss: 0.004993175622075796
step: 40, loss: 0.005544746294617653
step: 50, loss: 0.034689761698246
step: 60, loss: 0.0024348462466150522
step: 70, loss: 0.09633547812700272
step: 80, loss: 0.08861219882965088
step: 90, loss: 0.08852043747901917
step: 100, loss: 0.002227513352409005
step: 110, loss: 0.005253972951322794
step: 120, loss: 0.017917079851031303
step: 130, loss: 0.015056065283715725
step: 140, loss: 0.0016223859274759889
step: 150, loss: 0.03634776175022125
step: 160, loss: 0.0011432195315137506
step: 170, loss: 0.0019750583451241255
step: 180, loss: 0.0017979331314563751
step: 190, loss: 0.0009914900874719024
step: 200, loss: 0.003617670154199004
step: 210, loss: 0.009708204306662083
step: 220, loss: 0.030229991301894188
step: 230, loss: 0.0005473205237649381
step: 240, loss: 0.013548535294830799
step: 250, loss: 0.0032365545630455017
step: 260, loss: 0.006965842563658953
step: 270, loss: 0.0003909108054358512
epoch 5: dev_f1=0.9798657718120806, f1=0.9809203142536477, best_f1=0.9798206278026906
step: 0, loss: 0.0004962405073456466
step: 10, loss: 0.0009119294118136168
step: 20, loss: 0.00046178020420484245
step: 30, loss: 0.03417646139860153
step: 40, loss: 0.0030576542485505342
step: 50, loss: 0.000830921228043735
step: 60, loss: 0.026595506817102432
step: 70, loss: 0.00027817266527563334
step: 80, loss: 0.08315283060073853
step: 90, loss: 0.00019266715389676392
step: 100, loss: 0.0026665139012038708
step: 110, loss: 0.0024089240469038486
step: 120, loss: 0.011680645868182182
step: 130, loss: 0.027590570971369743
step: 140, loss: 0.0125085124745965
step: 150, loss: 0.03216669708490372
step: 160, loss: 0.02641003206372261
step: 170, loss: 0.01924402266740799
step: 180, loss: 0.001725845504552126
step: 190, loss: 0.007378846872597933
step: 200, loss: 0.02163759246468544
step: 210, loss: 0.003357004141435027
step: 220, loss: 0.0019642191473394632
step: 230, loss: 0.11332590132951736
step: 240, loss: 0.0012919638538733125
step: 250, loss: 0.013271018862724304
step: 260, loss: 0.06256930530071259
step: 270, loss: 0.011205433867871761
epoch 6: dev_f1=0.9798657718120806, f1=0.9753914988814317, best_f1=0.9798206278026906
step: 0, loss: 0.0038979738019406796
step: 10, loss: 0.0007867239182814956
step: 20, loss: 0.0012357289670035243
step: 30, loss: 0.0007202110136859119
step: 40, loss: 0.0007587609579786658
step: 50, loss: 0.001212035189382732
step: 60, loss: 0.0053220754489302635
step: 70, loss: 0.005172976292669773
step: 80, loss: 0.001997497398406267
step: 90, loss: 0.0008298692991957068
step: 100, loss: 0.0004972236347384751
step: 110, loss: 0.011906232684850693
step: 120, loss: 0.001465761219151318
step: 130, loss: 0.005568812135607004
step: 140, loss: 0.00041046401020139456
step: 150, loss: 0.0013086789986118674
step: 160, loss: 0.002200861694291234
step: 170, loss: 0.003331407904624939
step: 180, loss: 0.002724722493439913
step: 190, loss: 0.0006612838478758931
step: 200, loss: 0.004704699385911226
step: 210, loss: 0.015655865892767906
step: 220, loss: 0.0022663124836981297
step: 230, loss: 0.027815314009785652
step: 240, loss: 0.0013043970102444291
step: 250, loss: 0.014729829505085945
step: 260, loss: 0.00028418147121556103
step: 270, loss: 0.0010628006421029568
epoch 7: dev_f1=0.9810055865921787, f1=0.9787234042553192, best_f1=0.9798206278026906
step: 0, loss: 0.0004753219254780561
step: 10, loss: 0.017595892772078514
step: 20, loss: 0.0002901899570133537
step: 30, loss: 0.00042433993075974286
step: 40, loss: 0.0003818281111307442
step: 50, loss: 0.005667577031999826
step: 60, loss: 0.0005657855072058737
step: 70, loss: 0.0001977383653866127
step: 80, loss: 0.0002691934350878
step: 90, loss: 0.04747171327471733
step: 100, loss: 0.0017199141439050436
step: 110, loss: 0.00010422150808153674
step: 120, loss: 0.22514685988426208
step: 130, loss: 0.005778038874268532
step: 140, loss: 0.009946716018021107
step: 150, loss: 0.0017139473930001259
step: 160, loss: 0.00046301624388433993
step: 170, loss: 0.000330573006067425
step: 180, loss: 0.11607617139816284
step: 190, loss: 0.0005606302875094116
step: 200, loss: 0.08569063991308212
step: 210, loss: 0.0021722009405493736
step: 220, loss: 0.006518742069602013
step: 230, loss: 0.0002657925651874393
step: 240, loss: 0.029693342745304108
step: 250, loss: 0.0029263547621667385
step: 260, loss: 0.0002105060702888295
step: 270, loss: 0.00012300968228373677
epoch 8: dev_f1=0.9831649831649831, f1=0.9775784753363228, best_f1=0.9798206278026906
step: 0, loss: 0.003418530570343137
step: 10, loss: 0.002149599604308605
step: 20, loss: 0.000784867035690695
step: 30, loss: 0.009689612314105034
step: 40, loss: 0.005765011068433523
step: 50, loss: 0.07732264697551727
step: 60, loss: 0.00042296588071621954
step: 70, loss: 0.001269780215807259
step: 80, loss: 0.0003476038109511137
step: 90, loss: 0.0003983604838140309
step: 100, loss: 0.0006695796619169414
step: 110, loss: 0.05716949701309204
step: 120, loss: 0.11641954630613327
step: 130, loss: 0.0009806790621951222
step: 140, loss: 0.0029232921078801155
step: 150, loss: 0.002099151723086834
step: 160, loss: 0.0004733653913717717
step: 170, loss: 0.0005849784356541932
step: 180, loss: 0.0003690716694109142
step: 190, loss: 0.0004014785517938435
step: 200, loss: 0.00047048702253960073
step: 210, loss: 0.0013161710230633616
step: 220, loss: 0.0007384208729490638
step: 230, loss: 0.000337441946612671
step: 240, loss: 0.0010964252287521958
step: 250, loss: 0.0002589085779618472
step: 260, loss: 0.26961731910705566
step: 270, loss: 0.002892193151637912
epoch 9: dev_f1=0.9733333333333333, f1=0.9743589743589743, best_f1=0.9798206278026906
step: 0, loss: 0.00019165777484886348
step: 10, loss: 0.00034759409027174115
step: 20, loss: 0.0013329569483175874
step: 30, loss: 0.0002585042966529727
step: 40, loss: 0.0005260426551103592
step: 50, loss: 0.00021759675291832536
step: 60, loss: 0.013850790448486805
step: 70, loss: 0.016864782199263573
step: 80, loss: 0.00013890473928768188
step: 90, loss: 0.004321342799812555
step: 100, loss: 0.0003775204240810126
step: 110, loss: 0.0001703033340163529
step: 120, loss: 0.0429333858191967
step: 130, loss: 0.00013219454558566213
step: 140, loss: 0.00380160310305655
step: 150, loss: 0.001097130123525858
step: 160, loss: 0.00018491147784516215
step: 170, loss: 0.0001085924232029356
step: 180, loss: 0.00024512031814083457
step: 190, loss: 0.001386122195981443
step: 200, loss: 0.004126343410462141
step: 210, loss: 0.002700498793274164
step: 220, loss: 0.00019105251703877002
step: 230, loss: 0.0023109293542802334
step: 240, loss: 0.0004016732273157686
step: 250, loss: 0.000184360338607803
step: 260, loss: 0.0001300310977967456
step: 270, loss: 0.00020576103997882456
epoch 10: dev_f1=0.9741282339707535, f1=0.9617977528089887, best_f1=0.9798206278026906
step: 0, loss: 0.0012556120054796338
step: 10, loss: 0.0001878280017990619
step: 20, loss: 0.0053773801773786545
step: 30, loss: 0.0007345777121372521
step: 40, loss: 0.00017523212591186166
step: 50, loss: 0.0028059077449142933
step: 60, loss: 0.0009575210278853774
step: 70, loss: 0.00021364729036577046
step: 80, loss: 0.006660963408648968
step: 90, loss: 0.0004097941564396024
step: 100, loss: 0.0002123638114426285
step: 110, loss: 0.0002023655251832679
step: 120, loss: 0.0006445135222747922
step: 130, loss: 0.0033920533023774624
step: 140, loss: 0.004053701180964708
step: 150, loss: 0.007534623611718416
step: 160, loss: 0.00020873220637440681
step: 170, loss: 0.0009932221146300435
step: 180, loss: 0.015708375722169876
step: 190, loss: 0.0003759144456125796
step: 200, loss: 0.00014335250307340175
step: 210, loss: 0.0015105382772162557
step: 220, loss: 0.0064858198165893555
step: 230, loss: 0.020894665271043777
step: 240, loss: 0.020205702632665634
step: 250, loss: 0.008176688104867935
step: 260, loss: 0.0004979793448001146
step: 270, loss: 0.00048597322893328965
epoch 11: dev_f1=0.9765886287625419, f1=0.9741863075196409, best_f1=0.9798206278026906
step: 0, loss: 0.00028170409495942295
step: 10, loss: 0.032013505697250366
step: 20, loss: 0.0004997469950467348
step: 30, loss: 0.0001969711884157732
step: 40, loss: 0.0001556298229843378
step: 50, loss: 0.028139764443039894
step: 60, loss: 0.0006029510404914618
step: 70, loss: 0.00011972223728662357
step: 80, loss: 0.0002313398726982996
step: 90, loss: 0.00038240919820964336
step: 100, loss: 0.0001254285016329959
step: 110, loss: 0.00029263587202876806
step: 120, loss: 0.0002833213366102427
step: 130, loss: 0.0009708233992569149
step: 140, loss: 0.0003650004218798131
step: 150, loss: 0.00013764314644504339
step: 160, loss: 0.0001195911318063736
step: 170, loss: 0.002057749079540372
step: 180, loss: 7.003457722021267e-05
step: 190, loss: 0.0001525364350527525
step: 200, loss: 0.00011624117178143933
step: 210, loss: 0.00022131949663162231
step: 220, loss: 0.00035828171530738473
step: 230, loss: 0.00024018924159463495
step: 240, loss: 0.00014183887105900794
step: 250, loss: 0.0019004030618816614
step: 260, loss: 0.00038044602843001485
step: 270, loss: 0.00037902354961261153
epoch 12: dev_f1=0.9831649831649831, f1=0.9753914988814317, best_f1=0.9798206278026906
step: 0, loss: 0.02168199233710766
step: 10, loss: 0.0001927232078742236
step: 20, loss: 0.00023745768703520298
step: 30, loss: 0.00040908437222242355
step: 40, loss: 0.0012707760324701667
step: 50, loss: 0.029166799038648605
step: 60, loss: 9.152148413704708e-05
step: 70, loss: 0.00029513976187445223
step: 80, loss: 0.003942843060940504
step: 90, loss: 0.0001297963026445359
step: 100, loss: 9.320832032244653e-05
step: 110, loss: 0.0001234961673617363
step: 120, loss: 0.002437506802380085
step: 130, loss: 0.0004935199394822121
step: 140, loss: 8.98072321433574e-05
step: 150, loss: 7.704772724537179e-05
step: 160, loss: 0.00016626428987365216
step: 170, loss: 0.015142788179218769
step: 180, loss: 0.00011344954691594467
step: 190, loss: 8.578843699069694e-05
step: 200, loss: 0.001771709998138249
step: 210, loss: 0.00029654111131094396
step: 220, loss: 0.00016291069914586842
step: 230, loss: 0.0001614943757886067
step: 240, loss: 5.0673024816205725e-05
step: 250, loss: 0.14485222101211548
step: 260, loss: 0.0098726162686944
step: 270, loss: 5.97398575337138e-05
epoch 13: dev_f1=0.9799554565701558, f1=0.9744160177975528, best_f1=0.9798206278026906
step: 0, loss: 6.748351006535813e-05
step: 10, loss: 0.0007231485797092319
step: 20, loss: 0.00011518168321345001
step: 30, loss: 8.547095058020204e-05
step: 40, loss: 0.017944209277629852
step: 50, loss: 0.0001302435848629102
step: 60, loss: 6.109282549005002e-05
step: 70, loss: 0.00010189567547058687
step: 80, loss: 0.00010358435974922031
step: 90, loss: 0.05265800282359123
step: 100, loss: 5.082884308649227e-05
step: 110, loss: 7.09834712324664e-05
step: 120, loss: 0.02085355669260025
step: 130, loss: 0.00030680466443300247
step: 140, loss: 6.12094736425206e-05
step: 150, loss: 0.0497906468808651
step: 160, loss: 0.00011928856838494539
step: 170, loss: 5.061336560174823e-05
step: 180, loss: 0.0008850513258948922
step: 190, loss: 0.001017825212329626
step: 200, loss: 0.014761213213205338
step: 210, loss: 0.00809934176504612
step: 220, loss: 0.00015407399041578174
step: 230, loss: 0.0003607576945796609
step: 240, loss: 6.146157829789445e-05
step: 250, loss: 0.00012273216270841658
step: 260, loss: 0.00015214567247312516
step: 270, loss: 0.00011599534627748653
epoch 14: dev_f1=0.9820627802690582, f1=0.9743016759776536, best_f1=0.9798206278026906
step: 0, loss: 0.00018227564578410238
step: 10, loss: 0.00018015207024291158
step: 20, loss: 0.00017145562742371112
step: 30, loss: 0.0003987107484135777
step: 40, loss: 0.02771615982055664
step: 50, loss: 0.0007339635631069541
step: 60, loss: 0.0002677934826351702
step: 70, loss: 6.217032932909206e-05
step: 80, loss: 0.00017745261720847338
step: 90, loss: 0.00031489066896028817
step: 100, loss: 0.00012576569861266762
step: 110, loss: 3.436463521211408e-05
step: 120, loss: 8.289038669317961e-05
step: 130, loss: 0.003541977610439062
step: 140, loss: 0.0005500600673258305
step: 150, loss: 0.00037571389111690223
step: 160, loss: 4.980424273526296e-05
step: 170, loss: 0.00018406110757496208
step: 180, loss: 5.239080564933829e-05
step: 190, loss: 0.0004231910570524633
step: 200, loss: 4.64301738247741e-05
step: 210, loss: 7.778403232805431e-05
step: 220, loss: 0.00029809208353981376
step: 230, loss: 6.904438487254083e-05
step: 240, loss: 6.52777380309999e-05
step: 250, loss: 0.00010596672655083239
step: 260, loss: 0.001735215657390654
step: 270, loss: 0.00010325520270271227
epoch 15: dev_f1=0.9821029082774049, f1=0.9732142857142857, best_f1=0.9798206278026906
step: 0, loss: 0.00011026522406609729
step: 10, loss: 0.012529724277555943
step: 20, loss: 9.856441465672106e-05
step: 30, loss: 6.720151577610523e-05
step: 40, loss: 3.134365761070512e-05
step: 50, loss: 7.072185690049082e-05
step: 60, loss: 0.019841959699988365
step: 70, loss: 4.356796125648543e-05
step: 80, loss: 0.0006144113140180707
step: 90, loss: 4.846349111176096e-05
step: 100, loss: 8.340247586602345e-05
step: 110, loss: 2.6758003514260054e-05
step: 120, loss: 0.018040765076875687
step: 130, loss: 0.023311907425522804
step: 140, loss: 9.857367695076391e-05
step: 150, loss: 4.045855166623369e-05
step: 160, loss: 0.0019255136139690876
step: 170, loss: 0.016093820333480835
step: 180, loss: 0.03770262375473976
step: 190, loss: 0.0028650767635554075
step: 200, loss: 4.620171966962516e-05
step: 210, loss: 5.9838686865987256e-05
step: 220, loss: 3.9642443880438805e-05
step: 230, loss: 3.7441495805978775e-05
step: 240, loss: 4.777782305609435e-05
step: 250, loss: 3.209599162801169e-05
step: 260, loss: 0.0003379638656042516
step: 270, loss: 6.949813541723415e-05
epoch 16: dev_f1=0.9855072463768116, f1=0.9767955801104972, best_f1=0.9767955801104972
step: 0, loss: 0.00016789302753750235
step: 10, loss: 5.733591751777567e-05
step: 20, loss: 6.57284545013681e-05
step: 30, loss: 0.00016628624871373177
step: 40, loss: 4.39152390754316e-05
step: 50, loss: 6.479187140939757e-05
step: 60, loss: 3.1712534109828994e-05
step: 70, loss: 0.00011960682604694739
step: 80, loss: 0.0003071395040024072
step: 90, loss: 0.00028323830338194966
step: 100, loss: 9.775567741598934e-05
step: 110, loss: 0.00015676880138926208
step: 120, loss: 0.000720900425221771
step: 130, loss: 0.018368743360042572
step: 140, loss: 6.322284025372937e-05
step: 150, loss: 4.787458237842657e-05
step: 160, loss: 0.0005780457286164165
step: 170, loss: 4.6173623559297994e-05
step: 180, loss: 8.148886263370514e-05
step: 190, loss: 2.5558341803844087e-05
step: 200, loss: 6.740796379745007e-05
step: 210, loss: 0.0015810765326023102
step: 220, loss: 4.3405267206253484e-05
step: 230, loss: 0.00025878893211483955
step: 240, loss: 0.04199447110295296
step: 250, loss: 0.022732147946953773
step: 260, loss: 3.74896262655966e-05
step: 270, loss: 4.669859117711894e-05
epoch 17: dev_f1=0.9810055865921787, f1=0.9754464285714286, best_f1=0.9767955801104972
step: 0, loss: 6.794650835217908e-05
step: 10, loss: 0.0004176099319010973
step: 20, loss: 4.980363155482337e-05
step: 30, loss: 0.022344544529914856
step: 40, loss: 3.8297250284813344e-05
step: 50, loss: 6.683757965220138e-05
step: 60, loss: 8.372694719582796e-05
step: 70, loss: 0.00031998963095247746
step: 80, loss: 0.010660363361239433
step: 90, loss: 0.00010415407450636849
step: 100, loss: 6.505144847324118e-05
step: 110, loss: 4.872101635555737e-05
step: 120, loss: 0.00017083239799831063
step: 130, loss: 4.9520433094585314e-05
step: 140, loss: 0.00040994505980052054
step: 150, loss: 4.397773227537982e-05
step: 160, loss: 4.587877992889844e-05
step: 170, loss: 7.851002010283992e-05
step: 180, loss: 0.0007236182573251426
step: 190, loss: 4.348212678451091e-05
step: 200, loss: 6.439220305765048e-05
step: 210, loss: 5.2256917115300894e-05
step: 220, loss: 0.022933926433324814
step: 230, loss: 7.808047666912898e-05
step: 240, loss: 4.2973228119080886e-05
step: 250, loss: 3.423027737881057e-05
step: 260, loss: 4.823850395041518e-05
step: 270, loss: 3.681932503241114e-05
epoch 18: dev_f1=0.9854096520763187, f1=0.9787709497206705, best_f1=0.9767955801104972
step: 0, loss: 5.277058153296821e-05
step: 10, loss: 3.2543273846386e-05
step: 20, loss: 4.195604196866043e-05
step: 30, loss: 7.933032611617818e-05
step: 40, loss: 0.09222196787595749
step: 50, loss: 0.000911473820451647
step: 60, loss: 0.00012039512512274086
step: 70, loss: 8.221382449846715e-05
step: 80, loss: 0.00028425114578567445
step: 90, loss: 0.00018959064618684351
step: 100, loss: 3.899453076883219e-05
step: 110, loss: 3.828729677479714e-05
step: 120, loss: 0.02531566470861435
step: 130, loss: 0.000498579116538167
step: 140, loss: 4.573156184051186e-05
step: 150, loss: 6.817987014073879e-05
step: 160, loss: 8.140580757753924e-05
step: 170, loss: 0.0007570813759230077
step: 180, loss: 0.03591509163379669
step: 190, loss: 0.01569901965558529
step: 200, loss: 4.0167673432733864e-05
step: 210, loss: 5.679002424585633e-05
step: 220, loss: 0.016439277678728104
step: 230, loss: 5.0302358431508765e-05
step: 240, loss: 0.00013132284220773727
step: 250, loss: 4.764034747495316e-05
step: 260, loss: 3.46625383826904e-05
step: 270, loss: 2.611365562188439e-05
epoch 19: dev_f1=0.9832026875699889, f1=0.9765363128491621, best_f1=0.9767955801104972
step: 0, loss: 0.026888184249401093
step: 10, loss: 5.113842780701816e-05
step: 20, loss: 0.00019291124772280455
step: 30, loss: 2.8955812013009563e-05
step: 40, loss: 0.03209845349192619
step: 50, loss: 0.014318117871880531
step: 60, loss: 4.659962360165082e-05
step: 70, loss: 0.0019494572188705206
step: 80, loss: 3.091894541285001e-05
step: 90, loss: 0.00018614690634422004
step: 100, loss: 7.30752944946289e-05
step: 110, loss: 0.03955003619194031
step: 120, loss: 3.17684534820728e-05
step: 130, loss: 4.031306889373809e-05
step: 140, loss: 0.00024068087805062532
step: 150, loss: 5.3608862799592316e-05
step: 160, loss: 0.04777752235531807
step: 170, loss: 3.0490546123473905e-05
step: 180, loss: 0.003062235424295068
step: 190, loss: 3.4148812119383365e-05
step: 200, loss: 4.366863868199289e-05
step: 210, loss: 3.444305184530094e-05
step: 220, loss: 9.441348083782941e-05
step: 230, loss: 6.456316623371094e-05
step: 240, loss: 4.117666321690194e-05
step: 250, loss: 8.313763828482479e-05
step: 260, loss: 0.02842153236269951
step: 270, loss: 0.0006561859627254307
epoch 20: dev_f1=0.9832026875699889, f1=0.9765363128491621, best_f1=0.9767955801104972
