cuda
Device: cuda
step: 0, loss: 0.62604820728302
step: 10, loss: 0.43868157267570496
step: 20, loss: 0.39022988080978394
step: 30, loss: 0.12253762781620026
step: 40, loss: 0.4489327371120453
step: 50, loss: 0.2230270951986313
step: 60, loss: 0.19109657406806946
step: 70, loss: 0.23529043793678284
step: 80, loss: 0.20803608000278473
step: 90, loss: 0.24246814846992493
step: 100, loss: 0.2974230945110321
step: 110, loss: 0.12755264341831207
step: 120, loss: 0.14999030530452728
step: 130, loss: 0.23322997987270355
step: 140, loss: 0.10414877533912659
step: 150, loss: 0.24619458615779877
step: 160, loss: 0.2164168357849121
step: 170, loss: 0.1933608055114746
step: 180, loss: 0.14484231173992157
step: 190, loss: 0.23666149377822876
step: 200, loss: 0.07454913854598999
step: 210, loss: 0.16365864872932434
step: 220, loss: 0.19621703028678894
step: 230, loss: 0.3985746502876282
step: 240, loss: 0.12457737326622009
step: 250, loss: 0.08020640909671783
step: 260, loss: 0.23755651712417603
step: 270, loss: 0.07172073423862457
step: 280, loss: 0.05606343224644661
step: 290, loss: 0.13733577728271484
step: 300, loss: 0.12766094505786896
step: 310, loss: 0.13023968040943146
step: 320, loss: 0.13968802988529205
step: 330, loss: 0.1256103813648224
step: 340, loss: 0.3144030272960663
step: 350, loss: 0.245449498295784
step: 360, loss: 0.13213469088077545
step: 370, loss: 0.19025997817516327
step: 380, loss: 0.12416844815015793
step: 390, loss: 0.11601684242486954
step: 400, loss: 0.1299055516719818
step: 410, loss: 0.09000442177057266
step: 420, loss: 0.09961745887994766
step: 430, loss: 0.14790022373199463
step: 440, loss: 0.034306421875953674
step: 450, loss: 0.1368933916091919
step: 460, loss: 0.07622800022363663
step: 470, loss: 0.2129024714231491
step: 480, loss: 0.1413625329732895
step: 490, loss: 0.11414426565170288
step: 500, loss: 0.12165877968072891
step: 510, loss: 0.1821635514497757
step: 520, loss: 0.137391597032547
step: 530, loss: 0.07602439075708389
step: 540, loss: 0.07089009135961533
step: 550, loss: 0.1808428168296814
step: 560, loss: 0.19470930099487305
step: 570, loss: 0.11975081264972687
step: 580, loss: 0.1116548553109169
step: 590, loss: 0.17266449332237244
step: 600, loss: 0.030444767326116562
step: 610, loss: 0.12721215188503265
step: 620, loss: 0.12463667243719101
step: 630, loss: 0.10467340052127838
step: 640, loss: 0.18436568975448608
step: 650, loss: 0.1355651468038559
step: 660, loss: 0.07931765913963318
step: 670, loss: 0.09636353701353073
step: 680, loss: 0.08217795938253403
step: 690, loss: 0.19159772992134094
step: 700, loss: 0.07120298594236374
step: 710, loss: 0.09071392565965652
step: 720, loss: 0.10372938960790634
step: 730, loss: 0.164228618144989
step: 740, loss: 0.08989842981100082
step: 750, loss: 0.09717538952827454
step: 760, loss: 0.24893316626548767
step: 770, loss: 0.20294713973999023
step: 780, loss: 0.14956089854240417
step: 790, loss: 0.14114835858345032
step: 800, loss: 0.09773164987564087
step: 810, loss: 0.08791722357273102
step: 820, loss: 0.2400674819946289
step: 830, loss: 0.18576622009277344
step: 840, loss: 0.06525273621082306
step: 850, loss: 0.17172324657440186
step: 860, loss: 0.13815629482269287
step: 870, loss: 0.04469427093863487
step: 880, loss: 0.1326998770236969
step: 890, loss: 0.04904089868068695
step: 900, loss: 0.29310309886932373
step: 910, loss: 0.1645907312631607
step: 920, loss: 0.10912872105836868
step: 930, loss: 0.1931789666414261
step: 940, loss: 0.13640184700489044
step: 950, loss: 0.25781846046447754
step: 960, loss: 0.09107758849859238
step: 970, loss: 0.16747400164604187
step: 980, loss: 0.10907386243343353
step: 990, loss: 0.162864550948143
step: 1000, loss: 0.15176308155059814
step: 1010, loss: 0.1757836788892746
step: 1020, loss: 0.07051241397857666
step: 1030, loss: 0.08029645681381226
step: 1040, loss: 0.16824288666248322
step: 1050, loss: 0.07155944406986237
step: 1060, loss: 0.1689649075269699
step: 1070, loss: 0.15359705686569214
epoch 1: dev_f1=0.9225159525979945, f1=0.916439600363306, best_f1=0.916439600363306
step: 0, loss: 0.12920506298542023
step: 10, loss: 0.059540752321481705
step: 20, loss: 0.049970630556344986
step: 30, loss: 0.11423299461603165
step: 40, loss: 0.11377500742673874
step: 50, loss: 0.13010156154632568
step: 60, loss: 0.029218705371022224
step: 70, loss: 0.14592492580413818
step: 80, loss: 0.07195361703634262
step: 90, loss: 0.10741220414638519
step: 100, loss: 0.20275837182998657
step: 110, loss: 0.20806579291820526
step: 120, loss: 0.05551975592970848
step: 130, loss: 0.15275715291500092
step: 140, loss: 0.05823977664113045
step: 150, loss: 0.06224411725997925
step: 160, loss: 0.0811896100640297
step: 170, loss: 0.07116463780403137
step: 180, loss: 0.02225383371114731
step: 190, loss: 0.1650361716747284
step: 200, loss: 0.10160614550113678
step: 210, loss: 0.1247706189751625
step: 220, loss: 0.09254097938537598
step: 230, loss: 0.17476582527160645
step: 240, loss: 0.09661043435335159
step: 250, loss: 0.08565384894609451
step: 260, loss: 0.10468798130750656
step: 270, loss: 0.10998958349227905
step: 280, loss: 0.12133385241031647
step: 290, loss: 0.1234593540430069
step: 300, loss: 0.0660797730088234
step: 310, loss: 0.22129416465759277
step: 320, loss: 0.09733380377292633
step: 330, loss: 0.12707403302192688
step: 340, loss: 0.08810984343290329
step: 350, loss: 0.06902395933866501
step: 360, loss: 0.013202287256717682
step: 370, loss: 0.08313026279211044
step: 380, loss: 0.14187124371528625
step: 390, loss: 0.10169167071580887
step: 400, loss: 0.11865001916885376
step: 410, loss: 0.016548173502087593
step: 420, loss: 0.11025375127792358
step: 430, loss: 0.15816831588745117
step: 440, loss: 0.05548292398452759
step: 450, loss: 0.05826650932431221
step: 460, loss: 0.2464967668056488
step: 470, loss: 0.07904871553182602
step: 480, loss: 0.12145213037729263
step: 490, loss: 0.0932500809431076
step: 500, loss: 0.10024705529212952
step: 510, loss: 0.13592207431793213
step: 520, loss: 0.03718564659357071
step: 530, loss: 0.08208722621202469
step: 540, loss: 0.16834211349487305
step: 550, loss: 0.05706806108355522
step: 560, loss: 0.03402421250939369
step: 570, loss: 0.08569779247045517
step: 580, loss: 0.11061999201774597
step: 590, loss: 0.1526927500963211
step: 600, loss: 0.07691922038793564
step: 610, loss: 0.1310972422361374
step: 620, loss: 0.09330271184444427
step: 630, loss: 0.0754215344786644
step: 640, loss: 0.13217857480049133
step: 650, loss: 0.25653329491615295
step: 660, loss: 0.04134508967399597
step: 670, loss: 0.11728987842798233
step: 680, loss: 0.24818472564220428
step: 690, loss: 0.05425950884819031
step: 700, loss: 0.1303584724664688
step: 710, loss: 0.10809899121522903
step: 720, loss: 0.06536748260259628
step: 730, loss: 0.03888170048594475
step: 740, loss: 0.16440139710903168
step: 750, loss: 0.14231199026107788
step: 760, loss: 0.07703041285276413
step: 770, loss: 0.14710402488708496
step: 780, loss: 0.14553235471248627
step: 790, loss: 0.21095781028270721
step: 800, loss: 0.14898569881916046
step: 810, loss: 0.11077665537595749
step: 820, loss: 0.09321768581867218
step: 830, loss: 0.1622454822063446
step: 840, loss: 0.15135979652404785
step: 850, loss: 0.22007638216018677
step: 860, loss: 0.12708787620067596
step: 870, loss: 0.17478452622890472
step: 880, loss: 0.07976116240024567
step: 890, loss: 0.11109721660614014
step: 900, loss: 0.12560251355171204
step: 910, loss: 0.07042299211025238
step: 920, loss: 0.08361832797527313
step: 930, loss: 0.11904684454202652
step: 940, loss: 0.15911228954792023
step: 950, loss: 0.10436057299375534
step: 960, loss: 0.03760563209652901
step: 970, loss: 0.1291990578174591
step: 980, loss: 0.10893747210502625
step: 990, loss: 0.061704121530056
step: 1000, loss: 0.18523383140563965
step: 1010, loss: 0.13736720383167267
step: 1020, loss: 0.06307616084814072
step: 1030, loss: 0.20669250190258026
step: 1040, loss: 0.11260522902011871
step: 1050, loss: 0.10069123655557632
step: 1060, loss: 0.16262276470661163
step: 1070, loss: 0.25376206636428833
epoch 2: dev_f1=0.9298162976919454, f1=0.9242282507015902, best_f1=0.9242282507015902
step: 0, loss: 0.14454258978366852
step: 10, loss: 0.05095614492893219
step: 20, loss: 0.0471014678478241
step: 30, loss: 0.2219512015581131
step: 40, loss: 0.020583752542734146
step: 50, loss: 0.2542702853679657
step: 60, loss: 0.12224980443716049
step: 70, loss: 0.06494297087192535
step: 80, loss: 0.11648672819137573
step: 90, loss: 0.10922423005104065
step: 100, loss: 0.05220178887248039
step: 110, loss: 0.15381455421447754
step: 120, loss: 0.0015969002852216363
step: 130, loss: 0.09061158448457718
step: 140, loss: 0.10179605334997177
step: 150, loss: 0.04327131062746048
step: 160, loss: 0.1898074746131897
step: 170, loss: 0.02620631270110607
step: 180, loss: 0.02530335821211338
step: 190, loss: 0.18648095428943634
step: 200, loss: 0.022463351488113403
step: 210, loss: 0.06849557906389236
step: 220, loss: 0.11130345612764359
step: 230, loss: 0.07782302051782608
step: 240, loss: 0.07460197806358337
step: 250, loss: 0.06542228907346725
step: 260, loss: 0.09091955423355103
step: 270, loss: 0.08149091899394989
step: 280, loss: 0.05377945303916931
step: 290, loss: 0.11933380365371704
step: 300, loss: 0.06622076034545898
step: 310, loss: 0.12778308987617493
step: 320, loss: 0.06385081261396408
step: 330, loss: 0.06690207123756409
step: 340, loss: 0.135359987616539
step: 350, loss: 0.05189220979809761
step: 360, loss: 0.1334673911333084
step: 370, loss: 0.08043734729290009
step: 380, loss: 0.23007847368717194
step: 390, loss: 0.09375260770320892
step: 400, loss: 0.07881972938776016
step: 410, loss: 0.06120794266462326
step: 420, loss: 0.13116011023521423
step: 430, loss: 0.3290051817893982
step: 440, loss: 0.018208781257271767
step: 450, loss: 0.031032847240567207
step: 460, loss: 0.15977969765663147
step: 470, loss: 0.14121560752391815
step: 480, loss: 0.00798114761710167
step: 490, loss: 0.06615626811981201
step: 500, loss: 0.15735192596912384
step: 510, loss: 0.11623257398605347
step: 520, loss: 0.17162595689296722
step: 530, loss: 0.12198010832071304
step: 540, loss: 0.09129031747579575
step: 550, loss: 0.018476802855730057
step: 560, loss: 0.09055104106664658
step: 570, loss: 0.11220257729291916
step: 580, loss: 0.19905492663383484
step: 590, loss: 0.20625858008861542
step: 600, loss: 0.1133156269788742
step: 610, loss: 0.02419247105717659
step: 620, loss: 0.12406622618436813
step: 630, loss: 0.07670832425355911
step: 640, loss: 0.14760492742061615
step: 650, loss: 0.06181470304727554
step: 660, loss: 0.022968534380197525
step: 670, loss: 0.1294751763343811
step: 680, loss: 0.0989108681678772
step: 690, loss: 0.11519661545753479
step: 700, loss: 0.19119016826152802
step: 710, loss: 0.0863119512796402
step: 720, loss: 0.19251498579978943
step: 730, loss: 0.15118952095508575
step: 740, loss: 0.18613795936107635
step: 750, loss: 0.08992935717105865
step: 760, loss: 0.2597387731075287
step: 770, loss: 0.07010199874639511
step: 780, loss: 0.17997464537620544
step: 790, loss: 0.11250758171081543
step: 800, loss: 0.04297048971056938
step: 810, loss: 0.033786844462156296
step: 820, loss: 0.12416083365678787
step: 830, loss: 0.011113855987787247
step: 840, loss: 0.11053931713104248
step: 850, loss: 0.15984119474887848
step: 860, loss: 0.09520544856786728
step: 870, loss: 0.151154562830925
step: 880, loss: 0.037285804748535156
step: 890, loss: 0.10937073081731796
step: 900, loss: 0.06717512011528015
step: 910, loss: 0.14228135347366333
step: 920, loss: 0.09419113397598267
step: 930, loss: 0.08546070009469986
step: 940, loss: 0.15721797943115234
step: 950, loss: 0.10328064858913422
step: 960, loss: 0.07029563188552856
step: 970, loss: 0.06906532496213913
step: 980, loss: 0.23810824751853943
step: 990, loss: 0.04565072059631348
step: 1000, loss: 0.1342640221118927
step: 1010, loss: 0.08313413709402084
step: 1020, loss: 0.05172310769557953
step: 1030, loss: 0.11283548176288605
step: 1040, loss: 0.08269653469324112
step: 1050, loss: 0.20079590380191803
step: 1060, loss: 0.04420078918337822
step: 1070, loss: 0.09871871769428253
epoch 3: dev_f1=0.9316596931659693, f1=0.9287037037037037, best_f1=0.9287037037037037
step: 0, loss: 0.09721284359693527
step: 10, loss: 0.07600519061088562
step: 20, loss: 0.14111588895320892
step: 30, loss: 0.10018536448478699
step: 40, loss: 0.0002948698529507965
step: 50, loss: 0.07815171778202057
step: 60, loss: 0.05109979957342148
step: 70, loss: 0.12043046206235886
step: 80, loss: 0.045601289719343185
step: 90, loss: 0.11418043076992035
step: 100, loss: 0.013268332928419113
step: 110, loss: 0.2577323317527771
step: 120, loss: 0.18314510583877563
step: 130, loss: 0.0353691391646862
step: 140, loss: 0.1200154647231102
step: 150, loss: 0.08573830127716064
step: 160, loss: 0.043608732521533966
step: 170, loss: 0.12975728511810303
step: 180, loss: 0.13477389514446259
step: 190, loss: 0.08723624050617218
step: 200, loss: 0.13604992628097534
step: 210, loss: 0.1334039866924286
step: 220, loss: 0.25124287605285645
step: 230, loss: 0.05329481512308121
step: 240, loss: 0.1906103938817978
step: 250, loss: 0.02981128916144371
step: 260, loss: 0.06671910732984543
step: 270, loss: 0.09594237804412842
step: 280, loss: 0.0792168602347374
step: 290, loss: 0.24017949402332306
step: 300, loss: 0.07665687054395676
step: 310, loss: 0.10328292101621628
step: 320, loss: 0.0588369257748127
step: 330, loss: 0.026836682111024857
step: 340, loss: 0.09774407744407654
step: 350, loss: 0.029903817921876907
step: 360, loss: 0.05265950411558151
step: 370, loss: 0.04529305547475815
step: 380, loss: 0.25381556153297424
step: 390, loss: 0.19605115056037903
step: 400, loss: 0.03607553616166115
step: 410, loss: 0.049342501908540726
step: 420, loss: 0.06919147074222565
step: 430, loss: 0.042741890996694565
step: 440, loss: 0.04390498995780945
step: 450, loss: 0.05964700132608414
step: 460, loss: 0.12440910935401917
step: 470, loss: 0.06480346620082855
step: 480, loss: 0.06391746550798416
step: 490, loss: 0.12231630086898804
step: 500, loss: 0.09347043931484222
step: 510, loss: 0.08331944793462753
step: 520, loss: 0.06787051260471344
step: 530, loss: 0.23293419182300568
step: 540, loss: 0.20681148767471313
step: 550, loss: 0.03214580565690994
step: 560, loss: 0.059039514511823654
step: 570, loss: 0.11091140657663345
step: 580, loss: 0.050230372697114944
step: 590, loss: 0.20746071636676788
step: 600, loss: 0.08011316508054733
step: 610, loss: 0.1103706881403923
step: 620, loss: 0.08820901066064835
step: 630, loss: 0.10524386167526245
step: 640, loss: 0.006342257838696241
step: 650, loss: 0.1915471851825714
step: 660, loss: 0.03685397654771805
step: 670, loss: 0.21978433430194855
step: 680, loss: 0.034620944410562515
step: 690, loss: 0.16328448057174683
step: 700, loss: 0.09027121961116791
step: 710, loss: 0.09552643448114395
step: 720, loss: 0.13009338080883026
step: 730, loss: 0.1314784735441208
step: 740, loss: 0.04798753559589386
step: 750, loss: 0.14022645354270935
step: 760, loss: 0.042036645114421844
step: 770, loss: 0.06580714136362076
step: 780, loss: 0.07759789377450943
step: 790, loss: 0.04904313012957573
step: 800, loss: 0.0968351736664772
step: 810, loss: 0.024636728689074516
step: 820, loss: 0.017356568947434425
step: 830, loss: 0.10172293335199356
step: 840, loss: 0.0029001750517636538
step: 850, loss: 0.020621202886104584
step: 860, loss: 0.15643322467803955
step: 870, loss: 0.04588993266224861
step: 880, loss: 0.002512803766876459
step: 890, loss: 0.10515578836202621
step: 900, loss: 0.057614635676145554
step: 910, loss: 0.0903327614068985
step: 920, loss: 0.12396884709596634
step: 930, loss: 0.1060950979590416
step: 940, loss: 0.036550622433423996
step: 950, loss: 0.10932841897010803
step: 960, loss: 0.12524113059043884
step: 970, loss: 0.06577792763710022
step: 980, loss: 0.11114310473203659
step: 990, loss: 0.08250030130147934
step: 1000, loss: 0.09411902725696564
step: 1010, loss: 0.028943249955773354
step: 1020, loss: 0.08667230606079102
step: 1030, loss: 0.23807236552238464
step: 1040, loss: 0.01974540762603283
step: 1050, loss: 0.03427309915423393
step: 1060, loss: 0.1109767034649849
step: 1070, loss: 0.060929074883461
epoch 4: dev_f1=0.9230068337129841, f1=0.9135355364418288, best_f1=0.9287037037037037
step: 0, loss: 0.10079371184110641
step: 10, loss: 0.06287536770105362
step: 20, loss: 0.045030053704977036
step: 30, loss: 0.09079208225011826
step: 40, loss: 0.08003624528646469
step: 50, loss: 0.02042018622159958
step: 60, loss: 0.16284708678722382
step: 70, loss: 0.12512825429439545
step: 80, loss: 0.01907244138419628
step: 90, loss: 0.03442728891968727
step: 100, loss: 0.13817189633846283
step: 110, loss: 0.14805619418621063
step: 120, loss: 0.1361696422100067
step: 130, loss: 0.16358233988285065
step: 140, loss: 0.12198612093925476
step: 150, loss: 0.09299982339143753
step: 160, loss: 0.05871391296386719
step: 170, loss: 0.07419639825820923
step: 180, loss: 0.08764227479696274
step: 190, loss: 0.05736678093671799
step: 200, loss: 0.09883015602827072
step: 210, loss: 0.07166697084903717
step: 220, loss: 0.05541391298174858
step: 230, loss: 0.06602580100297928
step: 240, loss: 0.17443235218524933
step: 250, loss: 0.07822062075138092
step: 260, loss: 0.03625817596912384
step: 270, loss: 0.08634579926729202
step: 280, loss: 0.08979573100805283
step: 290, loss: 0.1604468673467636
step: 300, loss: 0.022522659972310066
step: 310, loss: 0.1558527946472168
step: 320, loss: 0.08018796890974045
step: 330, loss: 0.1688118278980255
step: 340, loss: 0.05159815400838852
step: 350, loss: 0.011900066398084164
step: 360, loss: 0.11183631420135498
step: 370, loss: 0.06153537705540657
step: 380, loss: 0.10234302282333374
step: 390, loss: 0.16110944747924805
step: 400, loss: 0.1125732883810997
step: 410, loss: 0.11476379632949829
step: 420, loss: 0.05255982279777527
step: 430, loss: 0.0681753009557724
step: 440, loss: 0.23758231103420258
step: 450, loss: 0.06472855061292648
step: 460, loss: 0.07409590482711792
step: 470, loss: 0.06393595039844513
step: 480, loss: 0.13776178658008575
step: 490, loss: 0.15707014501094818
step: 500, loss: 0.06632030755281448
step: 510, loss: 0.07883726805448532
step: 520, loss: 0.19958388805389404
step: 530, loss: 0.1533953994512558
step: 540, loss: 0.13938264548778534
step: 550, loss: 0.02108466997742653
step: 560, loss: 0.06537511944770813
step: 570, loss: 0.08992491662502289
step: 580, loss: 0.15058395266532898
step: 590, loss: 0.02462238259613514
step: 600, loss: 0.16365857422351837
step: 610, loss: 0.09359177201986313
step: 620, loss: 0.09027507156133652
step: 630, loss: 0.04960941523313522
step: 640, loss: 0.058967605233192444
step: 650, loss: 0.11557085812091827
step: 660, loss: 0.04218847304582596
step: 670, loss: 0.11965927481651306
step: 680, loss: 0.06729213148355484
step: 690, loss: 0.12180495262145996
step: 700, loss: 0.04563277214765549
step: 710, loss: 0.07611033320426941
step: 720, loss: 0.08951863646507263
step: 730, loss: 0.1131851077079773
step: 740, loss: 0.04912477731704712
step: 750, loss: 0.12414015829563141
step: 760, loss: 0.09388899803161621
step: 770, loss: 0.0758596882224083
step: 780, loss: 0.1650160551071167
step: 790, loss: 0.016819726675748825
step: 800, loss: 0.14763496816158295
step: 810, loss: 0.20696598291397095
step: 820, loss: 0.07492717355489731
step: 830, loss: 0.07951277494430542
step: 840, loss: 0.03628642112016678
step: 850, loss: 0.09331534802913666
step: 860, loss: 0.09874753654003143
step: 870, loss: 0.12425272166728973
step: 880, loss: 0.062471356242895126
step: 890, loss: 0.09890079498291016
step: 900, loss: 0.047977264970541
step: 910, loss: 0.10637890547513962
step: 920, loss: 0.04850863665342331
step: 930, loss: 0.07320182770490646
step: 940, loss: 0.08552169054746628
step: 950, loss: 0.14029601216316223
step: 960, loss: 0.06194140017032623
step: 970, loss: 0.14437678456306458
step: 980, loss: 0.08667773008346558
step: 990, loss: 0.07436788082122803
step: 1000, loss: 0.041800737380981445
step: 1010, loss: 0.03525681421160698
step: 1020, loss: 0.0641169399023056
step: 1030, loss: 0.03671686351299286
step: 1040, loss: 0.05193517729640007
step: 1050, loss: 0.18621255457401276
step: 1060, loss: 0.12737290561199188
step: 1070, loss: 0.03297245875000954
epoch 5: dev_f1=0.9262564584311883, f1=0.9281352747768906, best_f1=0.9287037037037037
step: 0, loss: 0.04542805626988411
step: 10, loss: 0.04965968802571297
step: 20, loss: 0.005946881137788296
step: 30, loss: 0.18029440939426422
step: 40, loss: 0.09749303758144379
step: 50, loss: 0.04650362953543663
step: 60, loss: 0.05939771607518196
step: 70, loss: 0.14573965966701508
step: 80, loss: 0.05830634385347366
step: 90, loss: 0.12411405146121979
step: 100, loss: 0.1143973171710968
step: 110, loss: 0.20589679479599
step: 120, loss: 0.17291449010372162
step: 130, loss: 0.07386244088411331
step: 140, loss: 0.05084235593676567
step: 150, loss: 0.07660693675279617
step: 160, loss: 0.04575326666235924
step: 170, loss: 0.03674517571926117
step: 180, loss: 0.0630687028169632
step: 190, loss: 0.061194922775030136
step: 200, loss: 0.09152207523584366
step: 210, loss: 0.1438213288784027
step: 220, loss: 0.14604277908802032
step: 230, loss: 0.19858992099761963
step: 240, loss: 0.03264516219496727
step: 250, loss: 0.04755692556500435
step: 260, loss: 0.24731041491031647
step: 270, loss: 0.029130632057785988
step: 280, loss: 0.06087120249867439
step: 290, loss: 0.10000892728567123
step: 300, loss: 0.08828737586736679
step: 310, loss: 0.051197659224271774
step: 320, loss: 0.1196577250957489
step: 330, loss: 0.1049349457025528
step: 340, loss: 0.2057122141122818
step: 350, loss: 0.045481111854314804
step: 360, loss: 0.11049780994653702
step: 370, loss: 0.07618638128042221
step: 380, loss: 0.08295515924692154
step: 390, loss: 0.16168323159217834
step: 400, loss: 0.02948208898305893
step: 410, loss: 0.002146214945241809
step: 420, loss: 0.056372106075286865
step: 430, loss: 0.10702323913574219
step: 440, loss: 0.04867205396294594
step: 450, loss: 0.041605349630117416
step: 460, loss: 0.059857212007045746
step: 470, loss: 0.0913919061422348
step: 480, loss: 0.1190943643450737
step: 490, loss: 0.02974148839712143
step: 500, loss: 0.0720805749297142
step: 510, loss: 0.055165987461805344
step: 520, loss: 0.03158209100365639
step: 530, loss: 0.07980823516845703
step: 540, loss: 0.06464451551437378
step: 550, loss: 0.015463984571397305
step: 560, loss: 0.055703964084386826
step: 570, loss: 0.08822924643754959
step: 580, loss: 0.02958298660814762
step: 590, loss: 0.09431912750005722
step: 600, loss: 0.09423869103193283
step: 610, loss: 0.24308547377586365
step: 620, loss: 0.014662636443972588
step: 630, loss: 0.09178964793682098
step: 640, loss: 0.15415243804454803
step: 650, loss: 0.03008389100432396
step: 660, loss: 0.06722874939441681
step: 670, loss: 0.05309044197201729
step: 680, loss: 0.15497615933418274
step: 690, loss: 0.13032421469688416
step: 700, loss: 0.08736339956521988
step: 710, loss: 0.055388662964105606
step: 720, loss: 0.047323647886514664
step: 730, loss: 0.09584452211856842
step: 740, loss: 0.0988084003329277
step: 750, loss: 0.00723779434338212
step: 760, loss: 0.11022090911865234
step: 770, loss: 0.14396093785762787
step: 780, loss: 0.20536842942237854
step: 790, loss: 0.051960717886686325
step: 800, loss: 0.09095466136932373
step: 810, loss: 0.17786967754364014
step: 820, loss: 0.11805978417396545
step: 830, loss: 0.2273487150669098
step: 840, loss: 0.10446377098560333
step: 850, loss: 0.09409008175134659
step: 860, loss: 0.043085016310214996
step: 870, loss: 0.11782877892255783
step: 880, loss: 0.02136996015906334
step: 890, loss: 0.006117717362940311
step: 900, loss: 0.008789625950157642
step: 910, loss: 0.14721986651420593
step: 920, loss: 0.08087685704231262
step: 930, loss: 0.06614066660404205
step: 940, loss: 0.05082772672176361
step: 950, loss: 0.05582667887210846
step: 960, loss: 0.12694589793682098
step: 970, loss: 0.05077975243330002
step: 980, loss: 0.03382325544953346
step: 990, loss: 0.25859060883522034
step: 1000, loss: 0.03438138589262962
step: 1010, loss: 0.058075159788131714
step: 1020, loss: 0.113907590508461
step: 1030, loss: 0.03872229903936386
step: 1040, loss: 0.03993995860219002
step: 1050, loss: 0.06354895234107971
step: 1060, loss: 0.04181594029068947
step: 1070, loss: 0.04283704608678818
epoch 6: dev_f1=0.9349112426035502, f1=0.9315068493150684, best_f1=0.9315068493150684
step: 0, loss: 0.07865077257156372
step: 10, loss: 0.08938683569431305
step: 20, loss: 0.14731240272521973
step: 30, loss: 0.04764196649193764
step: 40, loss: 0.02645697444677353
step: 50, loss: 0.11238521337509155
step: 60, loss: 0.058261990547180176
step: 70, loss: 0.01738409698009491
step: 80, loss: 0.13057678937911987
step: 90, loss: 0.08385026454925537
step: 100, loss: 0.05360030382871628
step: 110, loss: 0.10681413114070892
step: 120, loss: 0.026340512558817863
step: 130, loss: 0.015380633063614368
step: 140, loss: 0.012411853298544884
step: 150, loss: 0.06455793231725693
step: 160, loss: 0.0605112686753273
step: 170, loss: 0.03412904590368271
step: 180, loss: 0.1319134682416916
step: 190, loss: 0.04764299839735031
step: 200, loss: 0.05916725471615791
step: 210, loss: 0.08152361959218979
step: 220, loss: 0.10880715399980545
step: 230, loss: 0.0332263708114624
step: 240, loss: 0.014652417972683907
step: 250, loss: 0.023121215403079987
step: 260, loss: 0.07798474282026291
step: 270, loss: 0.02843617834150791
step: 280, loss: 0.11054817587137222
step: 290, loss: 0.17223364114761353
step: 300, loss: 0.11343737691640854
step: 310, loss: 0.12729951739311218
step: 320, loss: 0.04377422854304314
step: 330, loss: 0.11830829828977585
step: 340, loss: 0.051781270653009415
step: 350, loss: 0.09229837357997894
step: 360, loss: 0.07837966084480286
step: 370, loss: 0.09629158675670624
step: 380, loss: 0.008131698705255985
step: 390, loss: 0.11242014169692993
step: 400, loss: 0.0468287318944931
step: 410, loss: 0.08242306113243103
step: 420, loss: 0.026069728657603264
step: 430, loss: 0.061121609061956406
step: 440, loss: 0.01541585847735405
step: 450, loss: 0.0944809690117836
step: 460, loss: 0.11544397473335266
step: 470, loss: 0.13288964331150055
step: 480, loss: 0.08858950436115265
step: 490, loss: 0.08795057237148285
step: 500, loss: 0.10327363759279251
step: 510, loss: 0.10709275305271149
step: 520, loss: 0.06569577008485794
step: 530, loss: 0.21307654678821564
step: 540, loss: 0.0933263748884201
step: 550, loss: 0.03722144663333893
step: 560, loss: 0.028535598888993263
step: 570, loss: 0.10372014343738556
step: 580, loss: 0.00012102782056899741
step: 590, loss: 0.08061421662569046
step: 600, loss: 0.050738077610731125
step: 610, loss: 0.07641515135765076
step: 620, loss: 0.035697028040885925
step: 630, loss: 0.06554018706083298
step: 640, loss: 0.022913120687007904
step: 650, loss: 0.08808613568544388
step: 660, loss: 0.021934866905212402
step: 670, loss: 0.13938888907432556
step: 680, loss: 0.05620148032903671
step: 690, loss: 0.08189413696527481
step: 700, loss: 0.058349136263132095
step: 710, loss: 0.11064223945140839
step: 720, loss: 0.1979137659072876
step: 730, loss: 0.045758821070194244
step: 740, loss: 0.04538319632411003
step: 750, loss: 0.10857339203357697
step: 760, loss: 0.05554765835404396
step: 770, loss: 0.11633823812007904
step: 780, loss: 0.0833781361579895
step: 790, loss: 0.16312509775161743
step: 800, loss: 0.11369819939136505
step: 810, loss: 0.11394017934799194
step: 820, loss: 0.06441426277160645
step: 830, loss: 0.08840194344520569
step: 840, loss: 0.19257503747940063
step: 850, loss: 0.09379272162914276
step: 860, loss: 0.11531428247690201
step: 870, loss: 0.1300245076417923
step: 880, loss: 0.08504115045070648
step: 890, loss: 0.05690906196832657
step: 900, loss: 0.12077445536851883
step: 910, loss: 0.07296140491962433
step: 920, loss: 0.10819364339113235
step: 930, loss: 0.0951993465423584
step: 940, loss: 0.04638805612921715
step: 950, loss: 0.02200636826455593
step: 960, loss: 0.07883647829294205
step: 970, loss: 0.10267564654350281
step: 980, loss: 0.027535395696759224
step: 990, loss: 0.09993728250265121
step: 1000, loss: 0.11986641585826874
step: 1010, loss: 0.03917543590068817
step: 1020, loss: 0.05614724010229111
step: 1030, loss: 0.05415577068924904
step: 1040, loss: 0.21455417573451996
step: 1050, loss: 0.07091064751148224
step: 1060, loss: 0.11007370799779892
step: 1070, loss: 0.07814541459083557
epoch 7: dev_f1=0.9311141932501156, f1=0.9259088817303267, best_f1=0.9315068493150684
step: 0, loss: 0.020233072340488434
step: 10, loss: 0.04183114692568779
step: 20, loss: 0.11795691400766373
step: 30, loss: 0.1899716854095459
step: 40, loss: 0.05541060119867325
step: 50, loss: 0.05079963430762291
step: 60, loss: 0.09674351662397385
step: 70, loss: 0.06995583325624466
step: 80, loss: 0.09228885918855667
step: 90, loss: 0.0005137933767400682
step: 100, loss: 0.033986836671829224
step: 110, loss: 0.1044265627861023
step: 120, loss: 0.16105613112449646
step: 130, loss: 0.1754625141620636
step: 140, loss: 0.05458494648337364
step: 150, loss: 0.08597457408905029
step: 160, loss: 0.11078034341335297
step: 170, loss: 0.09086550772190094
step: 180, loss: 0.17402383685112
step: 190, loss: 0.08291122317314148
step: 200, loss: 0.1536283642053604
step: 210, loss: 0.09272687882184982
step: 220, loss: 0.10363461822271347
step: 230, loss: 0.03120752051472664
step: 240, loss: 0.010379872284829617
step: 250, loss: 0.19778455793857574
step: 260, loss: 0.0833977535367012
step: 270, loss: 0.02051260508596897
step: 280, loss: 0.03955916315317154
step: 290, loss: 0.03370556980371475
step: 300, loss: 0.09897176176309586
step: 310, loss: 0.05283132940530777
step: 320, loss: 0.011395974084734917
step: 330, loss: 0.08496703952550888
step: 340, loss: 0.051281124353408813
step: 350, loss: 0.06885498762130737
step: 360, loss: 0.1983521431684494
step: 370, loss: 0.03180481120944023
step: 380, loss: 0.008298143744468689
step: 390, loss: 0.06447300314903259
step: 400, loss: 0.07045070827007294
step: 410, loss: 0.0653073862195015
step: 420, loss: 0.09014210850000381
step: 430, loss: 0.04846257343888283
step: 440, loss: 0.07188674062490463
step: 450, loss: 0.006920843385159969
step: 460, loss: 0.07496296614408493
step: 470, loss: 0.06865642219781876
step: 480, loss: 0.02142532728612423
step: 490, loss: 0.3509621024131775
step: 500, loss: 0.14808064699172974
step: 510, loss: 0.07646673172712326
step: 520, loss: 0.030567610636353493
step: 530, loss: 0.005778689868748188
step: 540, loss: 0.09966466575860977
step: 550, loss: 0.09259697794914246
step: 560, loss: 0.13143642246723175
step: 570, loss: 0.07533532381057739
step: 580, loss: 0.04785224050283432
step: 590, loss: 0.07006076723337173
step: 600, loss: 0.18962781131267548
step: 610, loss: 0.04890879616141319
step: 620, loss: 0.057209573686122894
step: 630, loss: 0.028149064630270004
step: 640, loss: 0.010802606120705605
step: 650, loss: 0.13399861752986908
step: 660, loss: 0.09797147661447525
step: 670, loss: 0.09342627227306366
step: 680, loss: 0.05438537895679474
step: 690, loss: 0.04752981290221214
step: 700, loss: 0.09687323123216629
step: 710, loss: 0.0936884880065918
step: 720, loss: 0.11934515088796616
step: 730, loss: 0.009322249330580235
step: 740, loss: 0.027921825647354126
step: 750, loss: 0.13770660758018494
step: 760, loss: 0.09934013336896896
step: 770, loss: 0.0867234468460083
step: 780, loss: 0.07471776753664017
step: 790, loss: 0.056571114808321
step: 800, loss: 0.02027582749724388
step: 810, loss: 0.042453061789274216
step: 820, loss: 0.042985718697309494
step: 830, loss: 0.03642101213335991
step: 840, loss: 0.07339954376220703
step: 850, loss: 0.07274453341960907
step: 860, loss: 0.05070438235998154
step: 870, loss: 0.11541862040758133
step: 880, loss: 0.1369902342557907
step: 890, loss: 0.030818091705441475
step: 900, loss: 0.12758798897266388
step: 910, loss: 0.06790398061275482
step: 920, loss: 0.08062079548835754
step: 930, loss: 0.08715446293354034
step: 940, loss: 0.054542046040296555
step: 950, loss: 0.04290777072310448
step: 960, loss: 0.02959403023123741
step: 970, loss: 0.0716150775551796
step: 980, loss: 0.08062263578176498
step: 990, loss: 0.0778181403875351
step: 1000, loss: 0.09290415793657303
step: 1010, loss: 0.03639398515224457
step: 1020, loss: 0.07511817663908005
step: 1030, loss: 0.06052633374929428
step: 1040, loss: 0.032903533428907394
step: 1050, loss: 0.02351740002632141
step: 1060, loss: 0.1576537787914276
step: 1070, loss: 0.008011708967387676
epoch 8: dev_f1=0.9392014519056261, f1=0.9251141552511415, best_f1=0.9251141552511415
step: 0, loss: 0.10042428970336914
step: 10, loss: 0.1067490205168724
step: 20, loss: 0.08076383918523788
step: 30, loss: 0.07947756350040436
step: 40, loss: 0.09559234976768494
step: 50, loss: 0.02224143221974373
step: 60, loss: 0.06416983157396317
step: 70, loss: 0.14023321866989136
step: 80, loss: 0.0452398955821991
step: 90, loss: 0.04042680934071541
step: 100, loss: 0.09416687488555908
step: 110, loss: 0.0010767308995127678
step: 120, loss: 0.09613412618637085
step: 130, loss: 0.1250917762517929
step: 140, loss: 0.1142166405916214
step: 150, loss: 0.06458140909671783
step: 160, loss: 0.04000261053442955
step: 170, loss: 0.043930534273386
step: 180, loss: 0.02760067582130432
step: 190, loss: 0.05115298181772232
step: 200, loss: 0.15189801156520844
step: 210, loss: 0.2266010195016861
step: 220, loss: 0.04653085395693779
step: 230, loss: 0.1556374430656433
step: 240, loss: 0.10117717832326889
step: 250, loss: 0.06092057749629021
step: 260, loss: 0.06527791172266006
step: 270, loss: 0.07379788905382156
step: 280, loss: 0.10736279934644699
step: 290, loss: 0.0647224709391594
step: 300, loss: 0.06876502931118011
step: 310, loss: 0.004564715549349785
step: 320, loss: 0.04505452141165733
step: 330, loss: 0.0457950197160244
step: 340, loss: 0.032254185527563095
step: 350, loss: 0.10030940175056458
step: 360, loss: 0.08710063248872757
step: 370, loss: 0.04617994278669357
step: 380, loss: 0.09262935817241669
step: 390, loss: 0.1369117945432663
step: 400, loss: 0.06379277259111404
step: 410, loss: 0.050267964601516724
step: 420, loss: 0.11348561197519302
step: 430, loss: 0.0508636049926281
step: 440, loss: 0.02955339290201664
step: 450, loss: 0.04156996309757233
step: 460, loss: 0.02519976533949375
step: 470, loss: 0.05277238413691521
step: 480, loss: 0.06066606193780899
step: 490, loss: 0.1501612365245819
step: 500, loss: 0.058096688240766525
step: 510, loss: 0.171319380402565
step: 520, loss: 0.10382070392370224
step: 530, loss: 0.07134371995925903
step: 540, loss: 0.11592377722263336
step: 550, loss: 0.032527048140764236
step: 560, loss: 0.13614477217197418
step: 570, loss: 0.07441122084856033
step: 580, loss: 0.11447439342737198
step: 590, loss: 0.13859274983406067
step: 600, loss: 0.02614840306341648
step: 610, loss: 0.09109841287136078
step: 620, loss: 0.019239751622080803
step: 630, loss: 0.09991766512393951
step: 640, loss: 0.11274775117635727
step: 650, loss: 0.04353829845786095
step: 660, loss: 0.08299271017313004
step: 670, loss: 0.0333046093583107
step: 680, loss: 0.03805946558713913
step: 690, loss: 0.21308249235153198
step: 700, loss: 0.0776338279247284
step: 710, loss: 0.05808337777853012
step: 720, loss: 0.2278594821691513
step: 730, loss: 0.012483544647693634
step: 740, loss: 0.13724717497825623
step: 750, loss: 0.07321305572986603
step: 760, loss: 0.025407595559954643
step: 770, loss: 0.08188232779502869
step: 780, loss: 0.04300486296415329
step: 790, loss: 0.10757140070199966
step: 800, loss: 0.05843988060951233
step: 810, loss: 0.1765049695968628
step: 820, loss: 0.03492147475481033
step: 830, loss: 0.09217267483472824
step: 840, loss: 0.01537411380559206
step: 850, loss: 0.023541711270809174
step: 860, loss: 0.0855088084936142
step: 870, loss: 0.08859311044216156
step: 880, loss: 0.06474699079990387
step: 890, loss: 0.02012302353978157
step: 900, loss: 0.03863115236163139
step: 910, loss: 0.012305786833167076
step: 920, loss: 0.039751678705215454
step: 930, loss: 0.04208482429385185
step: 940, loss: 0.005090142600238323
step: 950, loss: 0.09062173962593079
step: 960, loss: 0.05511503294110298
step: 970, loss: 0.12151475995779037
step: 980, loss: 0.0060670338571071625
step: 990, loss: 0.09829355031251907
step: 1000, loss: 0.03134099394083023
step: 1010, loss: 0.1716686487197876
step: 1020, loss: 0.09679817408323288
step: 1030, loss: 0.10369253158569336
step: 1040, loss: 0.11136914789676666
step: 1050, loss: 0.05831489711999893
step: 1060, loss: 0.02920355089008808
step: 1070, loss: 0.078421950340271
epoch 9: dev_f1=0.937528921795465, f1=0.9295380307979467, best_f1=0.9251141552511415
step: 0, loss: 0.052713170647621155
step: 10, loss: 0.017373064532876015
step: 20, loss: 0.04288718104362488
step: 30, loss: 0.05457707867026329
step: 40, loss: 0.08726241439580917
step: 50, loss: 0.00016798937576822937
step: 60, loss: 0.09396866708993912
step: 70, loss: 0.059575535356998444
step: 80, loss: 0.06009947136044502
step: 90, loss: 0.02371901087462902
step: 100, loss: 0.07915736734867096
step: 110, loss: 0.08517039567232132
step: 120, loss: 0.04234597459435463
step: 130, loss: 0.17410197854042053
step: 140, loss: 0.08019605278968811
step: 150, loss: 0.036826495081186295
step: 160, loss: 0.007279533892869949
step: 170, loss: 0.026409532874822617
step: 180, loss: 0.02918979711830616
step: 190, loss: 0.019503794610500336
step: 200, loss: 0.07824905216693878
step: 210, loss: 0.042173001915216446
step: 220, loss: 0.023095769807696342
step: 230, loss: 0.09125629812479019
step: 240, loss: 0.03009798377752304
step: 250, loss: 0.06735213845968246
step: 260, loss: 0.030685946345329285
step: 270, loss: 0.0003452796663623303
step: 280, loss: 0.04514732211828232
step: 290, loss: 0.009039637632668018
step: 300, loss: 0.12299969792366028
step: 310, loss: 0.08155914396047592
step: 320, loss: 0.17044822871685028
step: 330, loss: 0.14064890146255493
step: 340, loss: 0.054633114486932755
step: 350, loss: 0.07120467722415924
step: 360, loss: 0.17510762810707092
step: 370, loss: 0.08546000719070435
step: 380, loss: 0.059220150113105774
step: 390, loss: 0.14943692088127136
step: 400, loss: 0.05480626970529556
step: 410, loss: 0.08695411682128906
step: 420, loss: 0.03694143518805504
step: 430, loss: 0.05853268504142761
step: 440, loss: 0.016075432300567627
step: 450, loss: 0.07434672862291336
step: 460, loss: 0.053425949066877365
step: 470, loss: 0.04313481226563454
step: 480, loss: 0.002466591540724039
step: 490, loss: 0.1356683373451233
step: 500, loss: 0.12584733963012695
step: 510, loss: 0.011218678206205368
step: 520, loss: 0.09866301715373993
step: 530, loss: 0.10376104712486267
step: 540, loss: 0.024938631802797318
step: 550, loss: 0.08417854458093643
step: 560, loss: 0.03204653412103653
step: 570, loss: 0.03466733545064926
step: 580, loss: 0.08713968843221664
step: 590, loss: 0.07367382198572159
step: 600, loss: 0.060128506273031235
step: 610, loss: 0.04906199872493744
step: 620, loss: 0.030311306938529015
step: 630, loss: 0.12206880003213882
step: 640, loss: 0.012645700946450233
step: 650, loss: 0.10393642634153366
step: 660, loss: 0.07579647749662399
step: 670, loss: 0.01933160424232483
step: 680, loss: 0.05654158815741539
step: 690, loss: 0.05310574173927307
step: 700, loss: 0.060413818806409836
step: 710, loss: 0.06577949970960617
step: 720, loss: 0.06445260345935822
step: 730, loss: 0.1054677814245224
step: 740, loss: 0.02517952397465706
step: 750, loss: 0.05787517875432968
step: 760, loss: 0.0531465969979763
step: 770, loss: 0.06510856002569199
step: 780, loss: 0.17139853537082672
step: 790, loss: 0.07487144321203232
step: 800, loss: 0.00023041268286760896
step: 810, loss: 0.013443165458738804
step: 820, loss: 0.09263700991868973
step: 830, loss: 0.0648745521903038
step: 840, loss: 0.06445727497339249
step: 850, loss: 0.2024073451757431
step: 860, loss: 0.06681042164564133
step: 870, loss: 0.008836261928081512
step: 880, loss: 0.07159110903739929
step: 890, loss: 0.029042063280940056
step: 900, loss: 0.08854508399963379
step: 910, loss: 0.022872529923915863
step: 920, loss: 0.030147429555654526
step: 930, loss: 0.03108351305127144
step: 940, loss: 0.07270524650812149
step: 950, loss: 0.10400306433439255
step: 960, loss: 0.15699763596057892
step: 970, loss: 0.044587455689907074
step: 980, loss: 0.057932861149311066
step: 990, loss: 0.14489561319351196
step: 1000, loss: 0.003600240917876363
step: 1010, loss: 0.0011781874345615506
step: 1020, loss: 0.19135682284832
step: 1030, loss: 0.14109912514686584
step: 1040, loss: 0.0710165873169899
step: 1050, loss: 0.038336511701345444
step: 1060, loss: 0.0958096832036972
step: 1070, loss: 0.00011445803829701617
epoch 10: dev_f1=0.9354545454545454, f1=0.9246823956442831, best_f1=0.9251141552511415
step: 0, loss: 0.07180789113044739
step: 10, loss: 0.09963083267211914
step: 20, loss: 0.12817758321762085
step: 30, loss: 0.11619086563587189
step: 40, loss: 0.16178815066814423
step: 50, loss: 0.05808423087000847
step: 60, loss: 0.07538255304098129
step: 70, loss: 0.045082688331604004
step: 80, loss: 0.04602951928973198
step: 90, loss: 0.03566446900367737
step: 100, loss: 0.027410350739955902
step: 110, loss: 0.005054888315498829
step: 120, loss: 0.013297836296260357
step: 130, loss: 0.11704055964946747
step: 140, loss: 0.09124758839607239
step: 150, loss: 0.10905811935663223
step: 160, loss: 0.031986866146326065
step: 170, loss: 0.04387035220861435
step: 180, loss: 0.03684113919734955
step: 190, loss: 0.02962261624634266
step: 200, loss: 0.0711413249373436
step: 210, loss: 0.015494287014007568
step: 220, loss: 0.1029067113995552
step: 230, loss: 0.04579123482108116
step: 240, loss: 0.06292072683572769
step: 250, loss: 0.058969445526599884
step: 260, loss: 0.09899898618459702
step: 270, loss: 0.05264284461736679
step: 280, loss: 0.040973957628011703
step: 290, loss: 0.19121791422367096
step: 300, loss: 0.04785328358411789
step: 310, loss: 0.03382747992873192
step: 320, loss: 0.007320523727685213
step: 330, loss: 0.086612269282341
step: 340, loss: 0.08234882354736328
step: 350, loss: 0.0327877439558506
step: 360, loss: 0.002993278903886676
step: 370, loss: 0.0009223041124641895
step: 380, loss: 0.057881902903318405
step: 390, loss: 0.04451706260442734
step: 400, loss: 0.03439956158399582
step: 410, loss: 0.04645151644945145
step: 420, loss: 0.000122277153423056
step: 430, loss: 0.15461064875125885
step: 440, loss: 0.04381799325346947
step: 450, loss: 0.024579022079706192
step: 460, loss: 0.08409424126148224
step: 470, loss: 0.05570732429623604
step: 480, loss: 0.0986989289522171
step: 490, loss: 0.06030943989753723
step: 500, loss: 0.058556150645017624
step: 510, loss: 0.005658817011862993
step: 520, loss: 0.13880780339241028
step: 530, loss: 0.04192662239074707
step: 540, loss: 0.09753373265266418
step: 550, loss: 0.0542844757437706
step: 560, loss: 0.1258142590522766
step: 570, loss: 0.14464472234249115
step: 580, loss: 0.011994566768407822
step: 590, loss: 0.05080569162964821
step: 600, loss: 0.03412223979830742
step: 610, loss: 0.008332495577633381
step: 620, loss: 0.13518010079860687
step: 630, loss: 0.07614478468894958
step: 640, loss: 0.0837881863117218
step: 650, loss: 0.13801243901252747
step: 660, loss: 0.1521332859992981
step: 670, loss: 0.04113373905420303
step: 680, loss: 0.16021090745925903
step: 690, loss: 0.12240996211767197
step: 700, loss: 0.10765340924263
step: 710, loss: 0.3584393262863159
step: 720, loss: 0.22135642170906067
step: 730, loss: 0.0316249318420887
step: 740, loss: 0.07630040496587753
step: 750, loss: 0.022218039259314537
step: 760, loss: 0.04178928956389427
step: 770, loss: 0.10232137888669968
step: 780, loss: 0.07027153670787811
step: 790, loss: 0.03045632876455784
step: 800, loss: 0.05305570736527443
step: 810, loss: 0.022031858563423157
step: 820, loss: 0.08451353013515472
step: 830, loss: 0.08535497635602951
step: 840, loss: 0.053689971566200256
step: 850, loss: 0.03376716375350952
step: 860, loss: 0.019801370799541473
step: 870, loss: 0.08878564089536667
step: 880, loss: 0.10074590146541595
step: 890, loss: 0.09326302260160446
step: 900, loss: 0.0017410529544577003
step: 910, loss: 0.0506204292178154
step: 920, loss: 0.0022671851329505444
step: 930, loss: 0.20152130722999573
step: 940, loss: 0.05808066204190254
step: 950, loss: 0.0891597718000412
step: 960, loss: 0.015478130429983139
step: 970, loss: 0.023293212056159973
step: 980, loss: 0.07417590171098709
step: 990, loss: 0.046171218156814575
step: 1000, loss: 0.12684956192970276
step: 1010, loss: 0.0038643600419163704
step: 1020, loss: 0.048492055386304855
step: 1030, loss: 6.42622253508307e-05
step: 1040, loss: 0.026647120714187622
step: 1050, loss: 0.052854061126708984
step: 1060, loss: 0.024259794503450394
step: 1070, loss: 0.051062025129795074
epoch 11: dev_f1=0.9327808471454879, f1=0.9238578680203047, best_f1=0.9251141552511415
step: 0, loss: 0.026709454134106636
step: 10, loss: 0.046475961804389954
step: 20, loss: 0.014323117211461067
step: 30, loss: 0.020409632474184036
step: 40, loss: 0.07700753211975098
step: 50, loss: 0.0878298431634903
step: 60, loss: 0.01363805215805769
step: 70, loss: 0.14789260923862457
step: 80, loss: 0.03876964747905731
step: 90, loss: 0.1945231705904007
step: 100, loss: 0.0625099390745163
step: 110, loss: 0.08149653673171997
step: 120, loss: 0.06121149659156799
step: 130, loss: 0.010336829349398613
step: 140, loss: 0.05190671607851982
step: 150, loss: 0.0796683058142662
step: 160, loss: 0.00972496997565031
step: 170, loss: 0.03130108490586281
step: 180, loss: 0.01694033108651638
step: 190, loss: 0.04640430957078934
step: 200, loss: 0.06910864263772964
step: 210, loss: 0.04958665743470192
step: 220, loss: 0.11865569651126862
step: 230, loss: 0.0014694847632199526
step: 240, loss: 0.18968039751052856
step: 250, loss: 0.013173189014196396
step: 260, loss: 0.020709071308374405
step: 270, loss: 0.06594768166542053
step: 280, loss: 0.04300343245267868
step: 290, loss: 2.110696368617937e-05
step: 300, loss: 0.07507923990488052
step: 310, loss: 0.035873088985681534
step: 320, loss: 0.0589851476252079
step: 330, loss: 0.1136060431599617
step: 340, loss: 0.13715608417987823
step: 350, loss: 0.027885179966688156
step: 360, loss: 0.11236325651407242
step: 370, loss: 0.038997095078229904
step: 380, loss: 0.077936552464962
step: 390, loss: 0.014629028737545013
step: 400, loss: 0.014000149443745613
step: 410, loss: 0.009653663262724876
step: 420, loss: 0.02270534820854664
step: 430, loss: 0.09134571999311447
step: 440, loss: 0.027591878548264503
step: 450, loss: 0.038008589297533035
step: 460, loss: 0.03775778412818909
step: 470, loss: 0.11681266874074936
step: 480, loss: 0.09411050379276276
step: 490, loss: 0.08968198299407959
step: 500, loss: 0.028065640479326248
step: 510, loss: 0.06479550898075104
step: 520, loss: 0.1949588507413864
step: 530, loss: 0.047957297414541245
step: 540, loss: 0.02261514961719513
step: 550, loss: 0.034321337938308716
step: 560, loss: 0.034468572586774826
step: 570, loss: 0.07156145572662354
step: 580, loss: 0.009493863210082054
step: 590, loss: 0.019271638244390488
step: 600, loss: 0.0654531717300415
step: 610, loss: 0.02586178109049797
step: 620, loss: 0.05583833158016205
step: 630, loss: 0.1352686733007431
step: 640, loss: 0.0639195591211319
step: 650, loss: 0.034872423857450485
step: 660, loss: 0.013267743401229382
step: 670, loss: 0.06505773216485977
step: 680, loss: 0.07858932763338089
step: 690, loss: 0.08951997756958008
step: 700, loss: 0.007092402316629887
step: 710, loss: 0.10485460609197617
step: 720, loss: 0.004588468931615353
step: 730, loss: 0.11713996529579163
step: 740, loss: 0.08383805304765701
step: 750, loss: 0.056717485189437866
step: 760, loss: 0.030476853251457214
step: 770, loss: 0.13698264956474304
step: 780, loss: 0.1452530026435852
step: 790, loss: 0.04663235321640968
step: 800, loss: 0.08908026665449142
step: 810, loss: 0.0589563213288784
step: 820, loss: 0.061395063996315
step: 830, loss: 0.06680585443973541
step: 840, loss: 0.008780473843216896
step: 850, loss: 0.14580591022968292
step: 860, loss: 0.08073621988296509
step: 870, loss: 0.07857067137956619
step: 880, loss: 0.03171398490667343
step: 890, loss: 0.06643964350223541
step: 900, loss: 0.0629325658082962
step: 910, loss: 0.05892503261566162
step: 920, loss: 0.1326182335615158
step: 930, loss: 0.23711659014225006
step: 940, loss: 0.01937018521130085
step: 950, loss: 0.16785281896591187
step: 960, loss: 0.023571603000164032
step: 970, loss: 0.07306834310293198
step: 980, loss: 0.09980084002017975
step: 990, loss: 0.055778853595256805
step: 1000, loss: 0.1099289283156395
step: 1010, loss: 0.10487543046474457
step: 1020, loss: 0.10186915099620819
step: 1030, loss: 0.09127254784107208
step: 1040, loss: 0.06713774055242538
step: 1050, loss: 0.01128963939845562
step: 1060, loss: 0.055551402270793915
step: 1070, loss: 0.05244362726807594
epoch 12: dev_f1=0.9366034243405831, f1=0.9271461716937355, best_f1=0.9251141552511415
step: 0, loss: 0.14268040657043457
step: 10, loss: 0.11001300811767578
step: 20, loss: 0.05940661206841469
step: 30, loss: 0.029526861384510994
step: 40, loss: 0.029081564396619797
step: 50, loss: 0.020287318155169487
step: 60, loss: 0.06280343979597092
step: 70, loss: 0.04357091709971428
step: 80, loss: 0.0662931278347969
step: 90, loss: 0.1012604609131813
step: 100, loss: 0.08005555719137192
step: 110, loss: 0.023248745128512383
step: 120, loss: 0.04154970869421959
step: 130, loss: 0.10791020840406418
step: 140, loss: 0.059457577764987946
step: 150, loss: 0.017894376069307327
step: 160, loss: 0.10243824869394302
step: 170, loss: 0.11019837856292725
step: 180, loss: 0.04727911204099655
step: 190, loss: 0.030213968828320503
step: 200, loss: 0.08133088052272797
step: 210, loss: 0.01375698484480381
step: 220, loss: 0.06693807989358902
step: 230, loss: 0.053748417645692825
step: 240, loss: 0.0060400948859751225
step: 250, loss: 0.016606124117970467
step: 260, loss: 0.050033699721097946
step: 270, loss: 0.0033875408116728067
step: 280, loss: 0.07158370316028595
step: 290, loss: 0.07548750936985016
step: 300, loss: 0.047625429928302765
step: 310, loss: 0.0316331721842289
step: 320, loss: 0.08007308840751648
step: 330, loss: 0.02665337547659874
step: 340, loss: 0.10574187338352203
step: 350, loss: 0.04078327864408493
step: 360, loss: 0.04934235289692879
step: 370, loss: 0.05361829325556755
step: 380, loss: 0.07219476997852325
step: 390, loss: 0.019889969378709793
step: 400, loss: 0.01691056229174137
step: 410, loss: 0.03422844037413597
step: 420, loss: 0.05748486518859863
step: 430, loss: 0.0404638908803463
step: 440, loss: 0.07053879648447037
step: 450, loss: 0.02699979394674301
step: 460, loss: 0.059438832104206085
step: 470, loss: 0.02189762331545353
step: 480, loss: 0.015175885520875454
step: 490, loss: 0.05386307090520859
step: 500, loss: 0.12033270299434662
step: 510, loss: 0.06622633337974548
step: 520, loss: 0.08282984048128128
step: 530, loss: 0.052280038595199585
step: 540, loss: 0.07197123765945435
step: 550, loss: 0.06227635592222214
step: 560, loss: 0.023413650691509247
step: 570, loss: 0.1439710110425949
step: 580, loss: 0.05086598917841911
step: 590, loss: 0.14240796864032745
step: 600, loss: 0.0642847940325737
step: 610, loss: 0.002490654354915023
step: 620, loss: 0.04111390560865402
step: 630, loss: 0.0353611558675766
step: 640, loss: 0.033241137862205505
step: 650, loss: 0.029422204941511154
step: 660, loss: 0.061086587607860565
step: 670, loss: 0.12188753485679626
step: 680, loss: 0.10215958207845688
step: 690, loss: 0.010557039640843868
step: 700, loss: 0.0020851714070886374
step: 710, loss: 0.03603542596101761
step: 720, loss: 0.03140842914581299
step: 730, loss: 0.11545171588659286
step: 740, loss: 0.020491916686296463
step: 750, loss: 0.036312900483608246
step: 760, loss: 0.0018463514279574156
step: 770, loss: 0.03244434669613838
step: 780, loss: 0.05232177674770355
step: 790, loss: 0.0968112200498581
step: 800, loss: 0.09602005779743195
step: 810, loss: 0.17385011911392212
step: 820, loss: 0.049536269158124924
step: 830, loss: 0.09822556376457214
step: 840, loss: 0.05362202972173691
step: 850, loss: 0.03194417059421539
step: 860, loss: 0.0006993999122641981
step: 870, loss: 0.07420643419027328
step: 880, loss: 0.04937655106186867
step: 890, loss: 0.028087645769119263
step: 900, loss: 0.10033534467220306
step: 910, loss: 0.0037686731666326523
step: 920, loss: 0.07793594151735306
step: 930, loss: 0.08150701224803925
step: 940, loss: 0.008874122053384781
step: 950, loss: 0.1268991231918335
step: 960, loss: 0.11017758399248123
step: 970, loss: 0.019893452525138855
step: 980, loss: 0.06406822800636292
step: 990, loss: 0.06692567467689514
step: 1000, loss: 0.06434886157512665
step: 1010, loss: 0.041444309055805206
step: 1020, loss: 0.07852333039045334
step: 1030, loss: 0.015948934480547905
step: 1040, loss: 0.04891087859869003
step: 1050, loss: 0.07158950716257095
step: 1060, loss: 0.027666309848427773
step: 1070, loss: 0.07724914699792862
epoch 13: dev_f1=0.9348729792147806, f1=0.9267840593141797, best_f1=0.9251141552511415
step: 0, loss: 0.03324368596076965
step: 10, loss: 0.052994754165410995
step: 20, loss: 0.0011268911184743047
step: 30, loss: 0.10756657272577286
step: 40, loss: 0.03650263696908951
step: 50, loss: 0.010842068120837212
step: 60, loss: 0.06613193452358246
step: 70, loss: 0.030836591497063637
step: 80, loss: 0.02276749163866043
step: 90, loss: 0.12457981705665588
step: 100, loss: 0.0279611237347126
step: 110, loss: 0.00013844350178260356
step: 120, loss: 0.056623008102178574
step: 130, loss: 0.045815762132406235
step: 140, loss: 0.04986683651804924
step: 150, loss: 0.020072447136044502
step: 160, loss: 0.079426109790802
step: 170, loss: 0.0061265453696250916
step: 180, loss: 0.00026155897649005055
step: 190, loss: 0.11812204867601395
step: 200, loss: 0.025780746713280678
step: 210, loss: 0.05485144630074501
step: 220, loss: 0.05412443354725838
step: 230, loss: 0.0749220997095108
step: 240, loss: 0.000663013372104615
step: 250, loss: 0.14556458592414856
step: 260, loss: 0.08876149356365204
step: 270, loss: 0.20277665555477142
step: 280, loss: 0.09407997131347656
step: 290, loss: 0.08734964579343796
step: 300, loss: 0.059103675186634064
step: 310, loss: 0.033241670578718185
step: 320, loss: 0.06980873644351959
step: 330, loss: 0.005524246487766504
step: 340, loss: 0.07387726753950119
step: 350, loss: 0.04684785380959511
step: 360, loss: 0.023489568382501602
step: 370, loss: 0.020578350871801376
step: 380, loss: 0.06613495945930481
step: 390, loss: 0.07964716851711273
step: 400, loss: 0.00819194782525301
step: 410, loss: 0.06465233117341995
step: 420, loss: 0.016364367678761482
step: 430, loss: 0.059294816106557846
step: 440, loss: 0.011720741167664528
step: 450, loss: 0.10331980139017105
step: 460, loss: 0.00028763970476575196
step: 470, loss: 0.03921481594443321
step: 480, loss: 0.01752641424536705
step: 490, loss: 0.05783683434128761
step: 500, loss: 0.06650926917791367
step: 510, loss: 0.027421582490205765
step: 520, loss: 0.059808261692523956
step: 530, loss: 0.03432341665029526
step: 540, loss: 0.0008867140859365463
step: 550, loss: 0.06415491551160812
step: 560, loss: 0.1171906366944313
step: 570, loss: 0.008567864075303078
step: 580, loss: 0.053210824728012085
step: 590, loss: 0.027342330664396286
step: 600, loss: 0.00023965920263435692
step: 610, loss: 0.06423114240169525
step: 620, loss: 0.03716854378581047
step: 630, loss: 0.0137043921276927
step: 640, loss: 0.07659539580345154
step: 650, loss: 0.028415581211447716
step: 660, loss: 0.09123928099870682
step: 670, loss: 0.038988806307315826
step: 680, loss: 0.10817214101552963
step: 690, loss: 0.011583950370550156
step: 700, loss: 0.07544513791799545
step: 710, loss: 0.022248748689889908
step: 720, loss: 0.06105149909853935
step: 730, loss: 0.10459382086992264
step: 740, loss: 0.0033282253425568342
step: 750, loss: 0.12813380360603333
step: 760, loss: 0.029522987082600594
step: 770, loss: 0.09329840540885925
step: 780, loss: 0.09739436954259872
step: 790, loss: 0.12735526263713837
step: 800, loss: 0.023728152737021446
step: 810, loss: 0.029927778989076614
step: 820, loss: 0.03701559081673622
step: 830, loss: 0.0830472856760025
step: 840, loss: 0.03395426273345947
step: 850, loss: 0.017003150656819344
step: 860, loss: 0.08446504920721054
step: 870, loss: 0.01699361950159073
step: 880, loss: 0.06907371431589127
step: 890, loss: 0.10288936644792557
step: 900, loss: 0.008407052606344223
step: 910, loss: 0.008377332240343094
step: 920, loss: 0.0281109306961298
step: 930, loss: 0.11561863124370575
step: 940, loss: 0.012361816130578518
step: 950, loss: 0.060278408229351044
step: 960, loss: 0.08440665155649185
step: 970, loss: 0.13020260632038116
step: 980, loss: 0.07815759629011154
step: 990, loss: 2.266781302751042e-05
step: 1000, loss: 0.06722050160169601
step: 1010, loss: 0.14386054873466492
step: 1020, loss: 0.12217825651168823
step: 1030, loss: 0.03686269372701645
step: 1040, loss: 0.029937947168946266
step: 1050, loss: 0.08543374389410019
step: 1060, loss: 0.03361603990197182
step: 1070, loss: 0.08644271641969681
epoch 14: dev_f1=0.9356779268857011, f1=0.9289363678588016, best_f1=0.9251141552511415
step: 0, loss: 0.06514466553926468
step: 10, loss: 0.05619021877646446
step: 20, loss: 0.0439445823431015
step: 30, loss: 0.013242540881037712
step: 40, loss: 0.06723172962665558
step: 50, loss: 0.04775892570614815
step: 60, loss: 0.03450095281004906
step: 70, loss: 0.02490399032831192
step: 80, loss: 8.357713522855192e-05
step: 90, loss: 0.044233303517103195
step: 100, loss: 0.039720065891742706
step: 110, loss: 0.0625096783041954
step: 120, loss: 0.01799166388809681
step: 130, loss: 0.013553767465054989
step: 140, loss: 0.15855370461940765
step: 150, loss: 0.02877523936331272
step: 160, loss: 0.008062692359089851
step: 170, loss: 0.064142145216465
step: 180, loss: 0.11435186117887497
step: 190, loss: 0.07144401222467422
step: 200, loss: 0.038974322378635406
step: 210, loss: 0.02151942066848278
step: 220, loss: 0.0328512117266655
step: 230, loss: 0.0346040278673172
step: 240, loss: 0.04003482684493065
step: 250, loss: 0.09536822140216827
step: 260, loss: 0.020721394568681717
step: 270, loss: 0.04246283695101738
step: 280, loss: 0.01950646936893463
step: 290, loss: 0.038725804537534714
step: 300, loss: 0.04240889474749565
step: 310, loss: 0.14828701317310333
step: 320, loss: 0.018736304715275764
step: 330, loss: 0.06875152885913849
step: 340, loss: 0.030667556449770927
step: 350, loss: 0.04787151515483856
step: 360, loss: 0.0018169513205066323
step: 370, loss: 0.03609412908554077
step: 380, loss: 0.017082322388887405
step: 390, loss: 0.06577027589082718
step: 400, loss: 0.037842538207769394
step: 410, loss: 0.14459890127182007
step: 420, loss: 0.00023165458696894348
step: 430, loss: 0.039884377270936966
step: 440, loss: 0.038475535809993744
step: 450, loss: 0.05599368363618851
step: 460, loss: 0.09944219142198563
step: 470, loss: 0.1222057193517685
step: 480, loss: 0.021837875247001648
step: 490, loss: 0.0357787162065506
step: 500, loss: 0.023845858871936798
step: 510, loss: 0.016564689576625824
step: 520, loss: 0.033120617270469666
step: 530, loss: 0.0324934720993042
step: 540, loss: 0.07391192018985748
step: 550, loss: 0.08747769147157669
step: 560, loss: 0.07259470224380493
step: 570, loss: 0.03213206306099892
step: 580, loss: 0.03156571462750435
step: 590, loss: 0.1081564649939537
step: 600, loss: 0.04869745299220085
step: 610, loss: 0.04667741805315018
step: 620, loss: 0.08108339458703995
step: 630, loss: 0.03761724755167961
step: 640, loss: 0.06277292221784592
step: 650, loss: 0.025551091879606247
step: 660, loss: 0.009608456864953041
step: 670, loss: 0.09112705290317535
step: 680, loss: 0.02413860708475113
step: 690, loss: 0.014150519855320454
step: 700, loss: 0.06434718519449234
step: 710, loss: 0.045716363936662674
step: 720, loss: 0.041032787412405014
step: 730, loss: 0.017577894032001495
step: 740, loss: 0.013318441808223724
step: 750, loss: 0.12271910905838013
step: 760, loss: 0.036756522953510284
step: 770, loss: 0.012812805362045765
step: 780, loss: 0.033448003232479095
step: 790, loss: 0.04536288231611252
step: 800, loss: 1.858519135566894e-05
step: 810, loss: 0.03217155858874321
step: 820, loss: 0.03125644102692604
step: 830, loss: 0.11802154779434204
step: 840, loss: 0.025276081636548042
step: 850, loss: 0.023725224658846855
step: 860, loss: 0.05083247646689415
step: 870, loss: 0.025809967890381813
step: 880, loss: 0.06223442032933235
step: 890, loss: 0.030286140739917755
step: 900, loss: 0.04372210428118706
step: 910, loss: 0.05468815192580223
step: 920, loss: 0.034607402980327606
step: 930, loss: 0.05340554192662239
step: 940, loss: 0.042643316090106964
step: 950, loss: 0.011081365868449211
step: 960, loss: 0.030673686414957047
step: 970, loss: 0.023963317275047302
step: 980, loss: 0.014679940417408943
step: 990, loss: 0.027780000120401382
step: 1000, loss: 0.04553017392754555
step: 1010, loss: 0.11071578413248062
step: 1020, loss: 0.14906099438667297
step: 1030, loss: 0.013250065967440605
step: 1040, loss: 0.0626237764954567
step: 1050, loss: 0.06908800452947617
step: 1060, loss: 0.08801882714033127
step: 1070, loss: 0.04858476668596268
epoch 15: dev_f1=0.9359742054352833, f1=0.9232192414431082, best_f1=0.9251141552511415
step: 0, loss: 0.07553332298994064
step: 10, loss: 0.05575210228562355
step: 20, loss: 0.047367461025714874
step: 30, loss: 0.03432059660553932
step: 40, loss: 0.010947061702609062
step: 50, loss: 0.06564795970916748
step: 60, loss: 0.008388882502913475
step: 70, loss: 0.029330335557460785
step: 80, loss: 0.07857025414705276
step: 90, loss: 0.03200205788016319
step: 100, loss: 0.03992294520139694
step: 110, loss: 0.018495621159672737
step: 120, loss: 0.03960026428103447
step: 130, loss: 0.00025806203484535217
step: 140, loss: 0.013823437504470348
step: 150, loss: 0.002284861169755459
step: 160, loss: 0.04639992490410805
step: 170, loss: 0.12499362975358963
step: 180, loss: 0.03980477154254913
step: 190, loss: 0.06917296350002289
step: 200, loss: 0.08533306419849396
step: 210, loss: 0.04667281731963158
step: 220, loss: 0.027868378907442093
step: 230, loss: 0.014800210483372211
step: 240, loss: 0.025826960802078247
step: 250, loss: 0.0428343191742897
step: 260, loss: 0.07703614979982376
step: 270, loss: 0.0047158473171293736
step: 280, loss: 0.058171313256025314
step: 290, loss: 0.002540556015446782
step: 300, loss: 0.04072222113609314
step: 310, loss: 0.13742230832576752
step: 320, loss: 0.08330255001783371
step: 330, loss: 0.016875935718417168
step: 340, loss: 0.005847414489835501
step: 350, loss: 0.06566955894231796
step: 360, loss: 0.03250010311603546
step: 370, loss: 0.042014431208372116
step: 380, loss: 0.06911025941371918
step: 390, loss: 0.08273562788963318
step: 400, loss: 0.06493058055639267
step: 410, loss: 0.004599146079272032
step: 420, loss: 0.01870381459593773
step: 430, loss: 0.09057155251502991
step: 440, loss: 0.06394094228744507
step: 450, loss: 0.031121177598834038
step: 460, loss: 0.004909178242087364
step: 470, loss: 0.05380270257592201
step: 480, loss: 0.07121720165014267
step: 490, loss: 0.021203268319368362
step: 500, loss: 1.3660463991982397e-05
step: 510, loss: 0.07229975610971451
step: 520, loss: 0.0252400990575552
step: 530, loss: 0.13751445710659027
step: 540, loss: 0.047578029334545135
step: 550, loss: 0.0375806987285614
step: 560, loss: 0.03537462279200554
step: 570, loss: 0.009115556254982948
step: 580, loss: 0.03457014635205269
step: 590, loss: 0.06726378202438354
step: 600, loss: 0.0413581021130085
step: 610, loss: 0.04827876389026642
step: 620, loss: 0.017968136817216873
step: 630, loss: 0.07539574801921844
step: 640, loss: 0.033861130475997925
step: 650, loss: 0.08982285112142563
step: 660, loss: 0.006501829717308283
step: 670, loss: 0.07817335426807404
step: 680, loss: 0.06971776485443115
step: 690, loss: 0.0568196177482605
step: 700, loss: 0.035296857357025146
step: 710, loss: 0.05857805907726288
step: 720, loss: 0.00010816071153385565
step: 730, loss: 0.09326455742120743
step: 740, loss: 0.026355858892202377
step: 750, loss: 0.12405422329902649
step: 760, loss: 0.055106937885284424
step: 770, loss: 0.0832296833395958
step: 780, loss: 0.09140723943710327
step: 790, loss: 0.12013636529445648
step: 800, loss: 0.046135395765304565
step: 810, loss: 0.062245018780231476
step: 820, loss: 0.05025377869606018
step: 830, loss: 0.05050065368413925
step: 840, loss: 0.12520700693130493
step: 850, loss: 0.08243035525083542
step: 860, loss: 0.10807827860116959
step: 870, loss: 0.10273636132478714
step: 880, loss: 5.070078987046145e-05
step: 890, loss: 0.0973474532365799
step: 900, loss: 0.027303515002131462
step: 910, loss: 0.049856048077344894
step: 920, loss: 0.10716806352138519
step: 930, loss: 0.055887285619974136
step: 940, loss: 0.0053850929252803326
step: 950, loss: 0.06322459876537323
step: 960, loss: 0.055485595017671585
step: 970, loss: 4.020543929073028e-05
step: 980, loss: 0.018836837261915207
step: 990, loss: 0.09029647707939148
step: 1000, loss: 0.002053951844573021
step: 1010, loss: 0.047588642686605453
step: 1020, loss: 0.18116715550422668
step: 1030, loss: 0.06138434261083603
step: 1040, loss: 0.041561875492334366
step: 1050, loss: 0.05944822356104851
step: 1060, loss: 0.027456184849143028
step: 1070, loss: 0.0602915994822979
epoch 16: dev_f1=0.9337626494940202, f1=0.922227335480902, best_f1=0.9251141552511415
step: 0, loss: 0.04611621052026749
step: 10, loss: 0.10623802244663239
step: 20, loss: 0.0384761206805706
step: 30, loss: 0.03212583810091019
step: 40, loss: 0.09463237226009369
step: 50, loss: 0.06918023526668549
step: 60, loss: 0.0884646400809288
step: 70, loss: 0.058895789086818695
step: 80, loss: 0.018457511439919472
step: 90, loss: 0.05126222223043442
step: 100, loss: 3.4121705539291725e-05
step: 110, loss: 0.02841767482459545
step: 120, loss: 0.015573147684335709
step: 130, loss: 0.06581651419401169
step: 140, loss: 0.05757075175642967
step: 150, loss: 0.000326947687426582
step: 160, loss: 4.1721414163475856e-05
step: 170, loss: 0.04784701019525528
step: 180, loss: 0.028787028044462204
step: 190, loss: 0.015844017267227173
step: 200, loss: 0.037504568696022034
step: 210, loss: 0.039605770260095596
step: 220, loss: 0.07752581685781479
step: 230, loss: 0.0837213546037674
step: 240, loss: 0.19694751501083374
step: 250, loss: 0.08008009195327759
step: 260, loss: 0.021156135946512222
step: 270, loss: 0.006103908643126488
step: 280, loss: 0.06643462181091309
step: 290, loss: 0.0457460843026638
step: 300, loss: 0.14190155267715454
step: 310, loss: 0.04798407107591629
step: 320, loss: 0.024643762037158012
step: 330, loss: 0.019241545349359512
step: 340, loss: 0.04472082480788231
step: 350, loss: 0.01572999730706215
step: 360, loss: 0.08228877931833267
step: 370, loss: 0.0006076784920878708
step: 380, loss: 0.1404077410697937
step: 390, loss: 0.020403405651450157
step: 400, loss: 0.07348256558179855
step: 410, loss: 0.052147723734378815
step: 420, loss: 0.04295825585722923
step: 430, loss: 0.037865687161684036
step: 440, loss: 0.013201042078435421
step: 450, loss: 0.020638907328248024
step: 460, loss: 0.05429501459002495
step: 470, loss: 0.03370939567685127
step: 480, loss: 0.05680720880627632
step: 490, loss: 0.004182429984211922
step: 500, loss: 0.018795110285282135
step: 510, loss: 0.050720587372779846
step: 520, loss: 0.006234179716557264
step: 530, loss: 0.11394114792346954
step: 540, loss: 0.029850702732801437
step: 550, loss: 0.03147223964333534
step: 560, loss: 0.06387076526880264
step: 570, loss: 0.023269712924957275
step: 580, loss: 0.02415945753455162
step: 590, loss: 0.053167469799518585
step: 600, loss: 0.05044221132993698
step: 610, loss: 0.09127923101186752
step: 620, loss: 0.02816161885857582
step: 630, loss: 8.217318827519193e-05
step: 640, loss: 0.0009723248076625168
step: 650, loss: 0.03469953313469887
step: 660, loss: 0.06959450989961624
step: 670, loss: 2.290930387971457e-05
step: 680, loss: 0.05034080520272255
step: 690, loss: 0.04758913069963455
step: 700, loss: 0.04819313436746597
step: 710, loss: 0.010621837340295315
step: 720, loss: 0.04385986924171448
step: 730, loss: 0.05470438674092293
step: 740, loss: 0.054042793810367584
step: 750, loss: 0.012268592603504658
step: 760, loss: 0.022514913231134415
step: 770, loss: 0.07594872266054153
step: 780, loss: 0.017605014145374298
step: 790, loss: 0.08472215384244919
step: 800, loss: 0.10549949109554291
step: 810, loss: 0.015470323152840137
step: 820, loss: 2.9694427212234586e-05
step: 830, loss: 0.007365981116890907
step: 840, loss: 0.038828253746032715
step: 850, loss: 0.05041064694523811
step: 860, loss: 0.08270411193370819
step: 870, loss: 1.556023744342383e-05
step: 880, loss: 0.027497489005327225
step: 890, loss: 0.05342625454068184
step: 900, loss: 0.023333944380283356
step: 910, loss: 0.031126152724027634
step: 920, loss: 0.0268806591629982
step: 930, loss: 0.05633418262004852
step: 940, loss: 0.06990237534046173
step: 950, loss: 0.020863739773631096
step: 960, loss: 0.10735630989074707
step: 970, loss: 0.07175672799348831
step: 980, loss: 0.035227514803409576
step: 990, loss: 0.0461539700627327
step: 1000, loss: 0.0776306688785553
step: 1010, loss: 0.04913722723722458
step: 1020, loss: 0.12008722126483917
step: 1030, loss: 0.017644044011831284
step: 1040, loss: 0.04424002394080162
step: 1050, loss: 0.07648160308599472
step: 1060, loss: 0.09370184689760208
step: 1070, loss: 0.03136582300066948
epoch 17: dev_f1=0.9342592592592593, f1=0.9219261337073399, best_f1=0.9251141552511415
step: 0, loss: 0.06537943333387375
step: 10, loss: 0.036433055996894836
step: 20, loss: 0.049187760800123215
step: 30, loss: 0.036881186068058014
step: 40, loss: 0.07506035268306732
step: 50, loss: 0.017666548490524292
step: 60, loss: 0.09375626593828201
step: 70, loss: 0.03132001683115959
step: 80, loss: 0.00010323216702090576
step: 90, loss: 0.05968276783823967
step: 100, loss: 0.01539336983114481
step: 110, loss: 0.08551888167858124
step: 120, loss: 0.040520504117012024
step: 130, loss: 0.027675677090883255
step: 140, loss: 0.035270363092422485
step: 150, loss: 0.015095074661076069
step: 160, loss: 8.430412708548829e-05
step: 170, loss: 0.04626156762242317
step: 180, loss: 0.06145300716161728
step: 190, loss: 0.058323126286268234
step: 200, loss: 0.018775179982185364
step: 210, loss: 0.014512856490910053
step: 220, loss: 0.13432210683822632
step: 230, loss: 0.01294287946075201
step: 240, loss: 0.03639616817235947
step: 250, loss: 0.0512508898973465
step: 260, loss: 0.03379184380173683
step: 270, loss: 0.029515409842133522
step: 280, loss: 0.0005342495860531926
step: 290, loss: 0.0493331104516983
step: 300, loss: 0.05006414279341698
step: 310, loss: 0.03301025554537773
step: 320, loss: 0.06128518283367157
step: 330, loss: 0.03095613420009613
step: 340, loss: 0.02444775402545929
step: 350, loss: 0.05998069792985916
step: 360, loss: 0.07256552577018738
step: 370, loss: 0.033368684351444244
step: 380, loss: 0.08170146495103836
step: 390, loss: 0.03770815208554268
step: 400, loss: 4.273556260159239e-05
step: 410, loss: 0.02470286935567856
step: 420, loss: 0.008236891590058804
step: 430, loss: 0.12400496006011963
step: 440, loss: 0.023383919149637222
step: 450, loss: 0.011646658182144165
step: 460, loss: 0.06233871355652809
step: 470, loss: 0.05524003133177757
step: 480, loss: 0.018969090655446053
step: 490, loss: 0.01489961426705122
step: 500, loss: 0.07825195044279099
step: 510, loss: 0.008850484155118465
step: 520, loss: 0.04561961069703102
step: 530, loss: 0.018821626901626587
step: 540, loss: 0.06282036751508713
step: 550, loss: 0.07915735989809036
step: 560, loss: 0.09314350038766861
step: 570, loss: 0.001635096501559019
step: 580, loss: 0.04099750891327858
step: 590, loss: 0.014856011606752872
step: 600, loss: 0.023586051538586617
step: 610, loss: 0.032708849757909775
step: 620, loss: 0.041143521666526794
step: 630, loss: 0.012288261204957962
step: 640, loss: 0.08104392886161804
step: 650, loss: 0.02802996151149273
step: 660, loss: 0.09279444813728333
step: 670, loss: 0.061614565551280975
step: 680, loss: 0.02660699002444744
step: 690, loss: 0.05941249802708626
step: 700, loss: 0.023209696635603905
step: 710, loss: 0.026499437168240547
step: 720, loss: 0.025811096653342247
step: 730, loss: 0.11747094243764877
step: 740, loss: 0.06707390397787094
step: 750, loss: 0.07580255717039108
step: 760, loss: 0.002855079248547554
step: 770, loss: 0.09277178347110748
step: 780, loss: 0.0657203271985054
step: 790, loss: 0.017778338864445686
step: 800, loss: 3.244883555453271e-05
step: 810, loss: 0.0520188994705677
step: 820, loss: 0.012184816412627697
step: 830, loss: 0.02697710134088993
step: 840, loss: 0.07127851247787476
step: 850, loss: 0.017514094710350037
step: 860, loss: 0.07989291101694107
step: 870, loss: 0.011241098865866661
step: 880, loss: 0.04333028197288513
step: 890, loss: 0.061056334525346756
step: 900, loss: 0.014937889762222767
step: 910, loss: 0.0483388788998127
step: 920, loss: 0.044920407235622406
step: 930, loss: 0.1727333962917328
step: 940, loss: 3.054186890949495e-05
step: 950, loss: 0.04206840693950653
step: 960, loss: 0.027602415531873703
step: 970, loss: 0.1096804291009903
step: 980, loss: 0.05444992706179619
step: 990, loss: 0.06357797980308533
step: 1000, loss: 0.10233034938573837
step: 1010, loss: 0.07272937893867493
step: 1020, loss: 0.029613398015499115
step: 1030, loss: 0.045422252267599106
step: 1040, loss: 0.027935024350881577
step: 1050, loss: 0.0004948092973791063
step: 1060, loss: 0.029261667281389236
step: 1070, loss: 1.5846953829168342e-05
epoch 18: dev_f1=0.9316712834718375, f1=0.9265799256505577, best_f1=0.9251141552511415
step: 0, loss: 0.038472745567560196
step: 10, loss: 0.017238598316907883
step: 20, loss: 0.12680859863758087
step: 30, loss: 0.007287032436579466
step: 40, loss: 9.852317452896386e-05
step: 50, loss: 0.029922975227236748
step: 60, loss: 0.030956033617258072
step: 70, loss: 0.04800562933087349
step: 80, loss: 0.021973755210638046
step: 90, loss: 0.00525264348834753
step: 100, loss: 0.012473399750888348
step: 110, loss: 0.0028224627021700144
step: 120, loss: 0.03885253891348839
step: 130, loss: 0.012390216812491417
step: 140, loss: 0.018653487786650658
step: 150, loss: 0.04643610119819641
step: 160, loss: 0.042929939925670624
step: 170, loss: 0.023081699386239052
step: 180, loss: 0.045801565051078796
step: 190, loss: 0.1076669842004776
step: 200, loss: 0.026660410687327385
step: 210, loss: 0.03069811686873436
step: 220, loss: 0.017665183171629906
step: 230, loss: 0.02725069224834442
step: 240, loss: 0.03018585406243801
step: 250, loss: 0.09936342388391495
step: 260, loss: 0.02742149867117405
step: 270, loss: 0.04313832148909569
step: 280, loss: 0.01854948326945305
step: 290, loss: 0.0005719249602407217
step: 300, loss: 0.05754387378692627
step: 310, loss: 0.007722507230937481
step: 320, loss: 0.04501659423112869
step: 330, loss: 0.044328317046165466
step: 340, loss: 0.035587944090366364
step: 350, loss: 0.026875246316194534
step: 360, loss: 0.06424202769994736
step: 370, loss: 0.01438590046018362
step: 380, loss: 0.0660109668970108
step: 390, loss: 0.05108208209276199
step: 400, loss: 0.041199713945388794
step: 410, loss: 0.11646799743175507
step: 420, loss: 0.036539264023303986
step: 430, loss: 0.030610598623752594
step: 440, loss: 0.0002066622255370021
step: 450, loss: 0.06873422116041183
step: 460, loss: 0.037676673382520676
step: 470, loss: 0.022829202935099602
step: 480, loss: 0.0108416136354208
step: 490, loss: 0.012008607387542725
step: 500, loss: 0.04948728159070015
step: 510, loss: 0.03257538750767708
step: 520, loss: 0.022807909175753593
step: 530, loss: 0.14326417446136475
step: 540, loss: 1.7109476175392047e-05
step: 550, loss: 0.059136491268873215
step: 560, loss: 0.1290057897567749
step: 570, loss: 0.061542216688394547
step: 580, loss: 0.0886862650513649
step: 590, loss: 0.060805678367614746
step: 600, loss: 0.09750455617904663
step: 610, loss: 0.05244480073451996
step: 620, loss: 0.01372449193149805
step: 630, loss: 0.03067798539996147
step: 640, loss: 0.13613717257976532
step: 650, loss: 0.030794262886047363
step: 660, loss: 0.05478960648179054
step: 670, loss: 0.018133053556084633
step: 680, loss: 0.025444142520427704
step: 690, loss: 0.0003425746108405292
step: 700, loss: 6.061210297048092e-05
step: 710, loss: 0.024917028844356537
step: 720, loss: 2.084230254695285e-05
step: 730, loss: 0.06343306601047516
step: 740, loss: 0.06655194610357285
step: 750, loss: 0.05540786311030388
step: 760, loss: 0.0339820496737957
step: 770, loss: 0.030017178505659103
step: 780, loss: 0.02885090373456478
step: 790, loss: 0.04165006801486015
step: 800, loss: 0.03363857790827751
step: 810, loss: 0.029330682009458542
step: 820, loss: 0.05340822786092758
step: 830, loss: 0.11312499642372131
step: 840, loss: 0.11195898801088333
step: 850, loss: 0.11270502954721451
step: 860, loss: 0.06284942477941513
step: 870, loss: 0.044324230402708054
step: 880, loss: 0.01134843472391367
step: 890, loss: 2.0484658307395875e-05
step: 900, loss: 0.04387157782912254
step: 910, loss: 0.0009173687431029975
step: 920, loss: 0.027387024834752083
step: 930, loss: 0.03328926861286163
step: 940, loss: 0.08927615731954575
step: 950, loss: 0.01711908169090748
step: 960, loss: 0.00873583648353815
step: 970, loss: 0.05974447354674339
step: 980, loss: 0.067429319024086
step: 990, loss: 8.492036431562155e-05
step: 1000, loss: 0.03219234198331833
step: 1010, loss: 0.05602516606450081
step: 1020, loss: 0.0351690910756588
step: 1030, loss: 0.03472943976521492
step: 1040, loss: 0.046732332557439804
step: 1050, loss: 0.05717654898762703
step: 1060, loss: 0.02040852978825569
step: 1070, loss: 0.0460866242647171
epoch 19: dev_f1=0.9317865429234339, f1=0.9251637043966324, best_f1=0.9251141552511415
step: 0, loss: 0.010465916246175766
step: 10, loss: 0.027817165479063988
step: 20, loss: 0.034554410725831985
step: 30, loss: 0.023812802508473396
step: 40, loss: 0.01884450949728489
step: 50, loss: 3.817668402916752e-05
step: 60, loss: 1.9631626855698414e-05
step: 70, loss: 0.00011477810039650649
step: 80, loss: 0.012007471174001694
step: 90, loss: 0.001914741238579154
step: 100, loss: 0.023366494104266167
step: 110, loss: 0.014967055991292
step: 120, loss: 0.032194703817367554
step: 130, loss: 0.04640423133969307
step: 140, loss: 0.04668579623103142
step: 150, loss: 0.005808964371681213
step: 160, loss: 0.061331771314144135
step: 170, loss: 0.05793282762169838
step: 180, loss: 0.001607624115422368
step: 190, loss: 0.06815194338560104
step: 200, loss: 0.03725543990731239
step: 210, loss: 0.0384245328605175
step: 220, loss: 0.005272839218378067
step: 230, loss: 0.14834566414356232
step: 240, loss: 0.06776732206344604
step: 250, loss: 0.08010533452033997
step: 260, loss: 0.020852185785770416
step: 270, loss: 0.06547259539365768
step: 280, loss: 0.02209986373782158
step: 290, loss: 0.00011982357682427391
step: 300, loss: 0.042297448962926865
step: 310, loss: 0.060004789382219315
step: 320, loss: 0.023467283695936203
step: 330, loss: 0.035626284778118134
step: 340, loss: 0.000566940288990736
step: 350, loss: 0.0005018397350795567
step: 360, loss: 0.01632796600461006
step: 370, loss: 0.027425164356827736
step: 380, loss: 0.0042159766890108585
step: 390, loss: 0.013930385001003742
step: 400, loss: 0.057467494159936905
step: 410, loss: 0.016158023849129677
step: 420, loss: 0.024470897391438484
step: 430, loss: 0.05871311575174332
step: 440, loss: 0.07720880210399628
step: 450, loss: 0.0453069843351841
step: 460, loss: 0.05607622489333153
step: 470, loss: 0.018368592485785484
step: 480, loss: 0.042875196784734726
step: 490, loss: 1.3984494216856547e-05
step: 500, loss: 0.04585373401641846
step: 510, loss: 0.05962888151407242
step: 520, loss: 0.025790812447667122
step: 530, loss: 0.02124885842204094
step: 540, loss: 0.06527506560087204
step: 550, loss: 0.054966893047094345
step: 560, loss: 0.029911838471889496
step: 570, loss: 0.03775767609477043
step: 580, loss: 0.09312247484922409
step: 590, loss: 3.3727847039699554e-05
step: 600, loss: 0.020343685522675514
step: 610, loss: 0.052762486040592194
step: 620, loss: 0.02219936065375805
step: 630, loss: 0.030467979609966278
step: 640, loss: 0.035421185195446014
step: 650, loss: 0.030152346938848495
step: 660, loss: 0.03436078131198883
step: 670, loss: 0.021414050832390785
step: 680, loss: 0.02755826711654663
step: 690, loss: 0.10076858103275299
step: 700, loss: 0.03393883630633354
step: 710, loss: 0.048308972269296646
step: 720, loss: 0.03750251978635788
step: 730, loss: 0.05960428714752197
step: 740, loss: 0.05661849305033684
step: 750, loss: 0.05183227360248566
step: 760, loss: 0.07370588928461075
step: 770, loss: 0.0016539066564291716
step: 780, loss: 0.0007981827948242426
step: 790, loss: 0.02881253883242607
step: 800, loss: 0.0015791860641911626
step: 810, loss: 0.011729507707059383
step: 820, loss: 0.0715525671839714
step: 830, loss: 0.05306586995720863
step: 840, loss: 0.05390915274620056
step: 850, loss: 0.05166982114315033
step: 860, loss: 0.06985237449407578
step: 870, loss: 0.04472548887133598
step: 880, loss: 0.016724955290555954
step: 890, loss: 0.08620680123567581
step: 900, loss: 0.03684331104159355
step: 910, loss: 0.057300079613924026
step: 920, loss: 0.009213611483573914
step: 930, loss: 0.028092283755540848
step: 940, loss: 0.020812461152672768
step: 950, loss: 0.03249123692512512
step: 960, loss: 0.05160444229841232
step: 970, loss: 0.026824116706848145
step: 980, loss: 0.034129295498132706
step: 990, loss: 0.015634143725037575
step: 1000, loss: 0.08244483172893524
step: 1010, loss: 0.028644099831581116
step: 1020, loss: 0.035012029111385345
step: 1030, loss: 0.07593192160129547
step: 1040, loss: 0.0069503504782915115
step: 1050, loss: 1.6517516996827908e-05
step: 1060, loss: 0.02968694269657135
step: 1070, loss: 0.010011376813054085
epoch 20: dev_f1=0.9318497913769124, f1=0.9256661991584852, best_f1=0.9251141552511415
