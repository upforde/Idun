cuda
Device: cuda
step: 0, loss: 0.8328955173492432
step: 10, loss: 0.46327438950538635
step: 20, loss: 0.5098494291305542
step: 30, loss: 0.5611071586608887
step: 40, loss: 0.42645135521888733
step: 50, loss: 0.33827120065689087
step: 60, loss: 0.2680838406085968
step: 70, loss: 0.35534366965293884
step: 80, loss: 0.21332992613315582
step: 90, loss: 0.1745939403772354
step: 100, loss: 0.2939527630805969
step: 110, loss: 0.10639870166778564
step: 120, loss: 0.12269463390111923
step: 130, loss: 0.2384481430053711
step: 140, loss: 0.07213524729013443
step: 150, loss: 0.12028538435697556
step: 160, loss: 0.18634824454784393
step: 170, loss: 0.09241262078285217
step: 180, loss: 0.1265982985496521
step: 190, loss: 0.16729089617729187
step: 200, loss: 0.08898935467004776
step: 210, loss: 0.11672292649745941
step: 220, loss: 0.03544144332408905
step: 230, loss: 0.022496404126286507
step: 240, loss: 0.03702685236930847
step: 250, loss: 0.10996521264314651
step: 260, loss: 0.03998759388923645
step: 270, loss: 0.07037562876939774
step: 280, loss: 0.0720924362540245
step: 290, loss: 0.0366804301738739
step: 300, loss: 0.17088612914085388
step: 310, loss: 0.061115141957998276
step: 320, loss: 0.03972876816987991
step: 330, loss: 0.031466737389564514
step: 340, loss: 0.017177611589431763
step: 350, loss: 0.03499400615692139
step: 360, loss: 0.06348469108343124
step: 370, loss: 0.17544224858283997
step: 380, loss: 0.06910192221403122
step: 390, loss: 0.10125230997800827
step: 400, loss: 0.16116750240325928
step: 410, loss: 0.03124050796031952
step: 420, loss: 0.006479411851614714
step: 430, loss: 0.2619898319244385
step: 440, loss: 0.08745677769184113
step: 450, loss: 0.19140616059303284
step: 460, loss: 0.09072995185852051
step: 470, loss: 0.1484576314687729
step: 480, loss: 0.08834432810544968
step: 490, loss: 0.037496168166399
step: 500, loss: 0.046773817390203476
step: 510, loss: 0.07183045893907547
step: 520, loss: 0.08637576550245285
step: 530, loss: 0.18845145404338837
epoch 1: dev_f1=0.8485125858123569, f1=0.8467153284671534, best_f1=0.8467153284671534
step: 0, loss: 0.03095669113099575
step: 10, loss: 0.024820024147629738
step: 20, loss: 0.07449743896722794
step: 30, loss: 0.09045924991369247
step: 40, loss: 0.07982639223337173
step: 50, loss: 0.024612098932266235
step: 60, loss: 0.015589970164000988
step: 70, loss: 0.054873161017894745
step: 80, loss: 0.03501396253705025
step: 90, loss: 0.01720120944082737
step: 100, loss: 0.058120518922805786
step: 110, loss: 0.014891468919813633
step: 120, loss: 0.020283866673707962
step: 130, loss: 0.08535266667604446
step: 140, loss: 0.023070594295859337
step: 150, loss: 0.0839538723230362
step: 160, loss: 0.023773735389113426
step: 170, loss: 0.015742456540465355
step: 180, loss: 0.03674209117889404
step: 190, loss: 0.03568822517991066
step: 200, loss: 0.012074288912117481
step: 210, loss: 0.008355490863323212
step: 220, loss: 0.1235087439417839
step: 230, loss: 0.007090185768902302
step: 240, loss: 0.21271821856498718
step: 250, loss: 0.01346948929131031
step: 260, loss: 0.017177598550915718
step: 270, loss: 0.08173175901174545
step: 280, loss: 0.028424052521586418
step: 290, loss: 0.06379832327365875
step: 300, loss: 0.15160630643367767
step: 310, loss: 0.025531457737088203
step: 320, loss: 0.08275381475687027
step: 330, loss: 0.02939840964972973
step: 340, loss: 0.043038804084062576
step: 350, loss: 0.09431933611631393
step: 360, loss: 0.0038233778905123472
step: 370, loss: 0.010107796639204025
step: 380, loss: 0.02787572517991066
step: 390, loss: 0.23454424738883972
step: 400, loss: 0.07133612036705017
step: 410, loss: 0.044226326048374176
step: 420, loss: 0.03231583908200264
step: 430, loss: 0.15931853652000427
step: 440, loss: 0.1084367036819458
step: 450, loss: 0.08294345438480377
step: 460, loss: 0.017382126301527023
step: 470, loss: 0.18376590311527252
step: 480, loss: 0.16801509261131287
step: 490, loss: 0.027252892032265663
step: 500, loss: 0.16399046778678894
step: 510, loss: 0.006702587939798832
step: 520, loss: 0.012477469630539417
step: 530, loss: 0.014018934220075607
epoch 2: dev_f1=0.8484848484848485, f1=0.8614008941877793, best_f1=0.8467153284671534
step: 0, loss: 0.1488896757364273
step: 10, loss: 0.06042234227061272
step: 20, loss: 0.05243449658155441
step: 30, loss: 0.02414380945265293
step: 40, loss: 0.022529052570462227
step: 50, loss: 0.1466844081878662
step: 60, loss: 0.12153398245573044
step: 70, loss: 0.05154205486178398
step: 80, loss: 0.1181444600224495
step: 90, loss: 0.011448155157268047
step: 100, loss: 0.04788246750831604
step: 110, loss: 0.07518737763166428
step: 120, loss: 0.027405396103858948
step: 130, loss: 0.07467015087604523
step: 140, loss: 0.06543870270252228
step: 150, loss: 0.2768748104572296
step: 160, loss: 0.013326263055205345
step: 170, loss: 0.0765456035733223
step: 180, loss: 0.10173201560974121
step: 190, loss: 0.12566415965557098
step: 200, loss: 0.13709820806980133
step: 210, loss: 0.04614103212952614
step: 220, loss: 0.05469171330332756
step: 230, loss: 0.013126767240464687
step: 240, loss: 0.03738710284233093
step: 250, loss: 0.007323583122342825
step: 260, loss: 0.06558399647474289
step: 270, loss: 0.029453648254275322
step: 280, loss: 0.05892988294363022
step: 290, loss: 0.10312420129776001
step: 300, loss: 0.05136529728770256
step: 310, loss: 0.011850882321596146
step: 320, loss: 0.01674465276300907
step: 330, loss: 0.05520861595869064
step: 340, loss: 0.11165277659893036
step: 350, loss: 0.03740520775318146
step: 360, loss: 0.0021996607538312674
step: 370, loss: 0.011605065315961838
step: 380, loss: 0.004943221807479858
step: 390, loss: 0.059719160199165344
step: 400, loss: 0.23774640262126923
step: 410, loss: 0.12804166972637177
step: 420, loss: 0.08176840841770172
step: 430, loss: 0.1023288443684578
step: 440, loss: 0.08196751028299332
step: 450, loss: 0.08879571408033371
step: 460, loss: 0.003697696141898632
step: 470, loss: 0.11679072678089142
step: 480, loss: 0.018125014379620552
step: 490, loss: 0.056506045162677765
step: 500, loss: 0.054485514760017395
step: 510, loss: 0.062117092311382294
step: 520, loss: 0.0018318836810067296
step: 530, loss: 0.028006812557578087
epoch 3: dev_f1=0.8740384615384614, f1=0.8761358201817313, best_f1=0.8761358201817313
step: 0, loss: 0.022219333797693253
step: 10, loss: 0.09821455925703049
step: 20, loss: 0.014064351096749306
step: 30, loss: 0.02187003567814827
step: 40, loss: 0.022921714931726456
step: 50, loss: 0.05979520082473755
step: 60, loss: 0.05900411307811737
step: 70, loss: 0.11302255094051361
step: 80, loss: 0.022314952686429024
step: 90, loss: 0.09469421952962875
step: 100, loss: 0.06671005487442017
step: 110, loss: 0.040136098861694336
step: 120, loss: 0.007512829266488552
step: 130, loss: 0.09518247097730637
step: 140, loss: 0.005851753521710634
step: 150, loss: 0.012227321043610573
step: 160, loss: 0.01646004244685173
step: 170, loss: 0.050856441259384155
step: 180, loss: 0.00937146320939064
step: 190, loss: 0.14505691826343536
step: 200, loss: 0.2338346391916275
step: 210, loss: 0.04744125157594681
step: 220, loss: 0.014975636266171932
step: 230, loss: 0.002494838321581483
step: 240, loss: 0.007609858177602291
step: 250, loss: 0.026039917021989822
step: 260, loss: 0.001268696621991694
step: 270, loss: 0.052554354071617126
step: 280, loss: 0.06992918998003006
step: 290, loss: 0.08762557804584503
step: 300, loss: 0.0037648070137947798
step: 310, loss: 0.1628868579864502
step: 320, loss: 0.008800935931503773
step: 330, loss: 0.06591777503490448
step: 340, loss: 0.11148490756750107
step: 350, loss: 0.03216211497783661
step: 360, loss: 0.15624240040779114
step: 370, loss: 0.051726385951042175
step: 380, loss: 0.06185751035809517
step: 390, loss: 0.14048555493354797
step: 400, loss: 0.23160377144813538
step: 410, loss: 0.008144955150783062
step: 420, loss: 0.052074696868658066
step: 430, loss: 0.09737566858530045
step: 440, loss: 0.05106144770979881
step: 450, loss: 0.05066615715622902
step: 460, loss: 0.007355400826781988
step: 470, loss: 0.17476169764995575
step: 480, loss: 0.10961417108774185
step: 490, loss: 0.047739800065755844
step: 500, loss: 0.12324880063533783
step: 510, loss: 0.0034544554073363543
step: 520, loss: 0.056088801473379135
step: 530, loss: 0.006673264317214489
epoch 4: dev_f1=0.8538461538461537, f1=0.8486304661220567, best_f1=0.8761358201817313
step: 0, loss: 0.06909502297639847
step: 10, loss: 0.039888378232717514
step: 20, loss: 0.07254400849342346
step: 30, loss: 0.058506812900304794
step: 40, loss: 0.0005696092848666012
step: 50, loss: 0.012814142741262913
step: 60, loss: 0.014001023024320602
step: 70, loss: 0.02579868584871292
step: 80, loss: 0.012424249202013016
step: 90, loss: 0.09320279210805893
step: 100, loss: 0.006384584587067366
step: 110, loss: 0.0401466079056263
step: 120, loss: 0.0068144467659294605
step: 130, loss: 0.1813465654850006
step: 140, loss: 0.057693373411893845
step: 150, loss: 0.04848729446530342
step: 160, loss: 0.046383053064346313
step: 170, loss: 0.005846819840371609
step: 180, loss: 0.0037628880236297846
step: 190, loss: 0.010246159508824348
step: 200, loss: 0.011336220428347588
step: 210, loss: 0.2228529155254364
step: 220, loss: 0.008026518858969212
step: 230, loss: 0.006323940586298704
step: 240, loss: 0.02231084555387497
step: 250, loss: 0.007215956691652536
step: 260, loss: 0.05352260544896126
step: 270, loss: 0.07240387797355652
step: 280, loss: 0.054518818855285645
step: 290, loss: 0.06755434721708298
step: 300, loss: 0.07488755136728287
step: 310, loss: 0.08196305483579636
step: 320, loss: 0.03634254261851311
step: 330, loss: 0.06739170104265213
step: 340, loss: 0.008527231402695179
step: 350, loss: 0.0025239158421754837
step: 360, loss: 0.0029799211770296097
step: 370, loss: 0.031113101169466972
step: 380, loss: 0.00503690866753459
step: 390, loss: 0.051962193101644516
step: 400, loss: 0.0005477954400703311
step: 410, loss: 0.021520908921957016
step: 420, loss: 0.04525900259613991
step: 430, loss: 0.004830405116081238
step: 440, loss: 0.08466891199350357
step: 450, loss: 0.04339441657066345
step: 460, loss: 0.0516008697450161
step: 470, loss: 0.048184834420681
step: 480, loss: 0.08257876336574554
step: 490, loss: 0.015900544822216034
step: 500, loss: 0.0008299779728986323
step: 510, loss: 0.029873903840780258
step: 520, loss: 0.09354066848754883
step: 530, loss: 0.04359377548098564
epoch 5: dev_f1=0.6469500924214417, f1=0.6308557151780138, best_f1=0.8761358201817313
step: 0, loss: 0.003570319851860404
step: 10, loss: 0.07161051034927368
step: 20, loss: 0.033733729273080826
step: 30, loss: 0.0026756511069834232
step: 40, loss: 0.07986829429864883
step: 50, loss: 0.0003440377186052501
step: 60, loss: 0.016037296503782272
step: 70, loss: 0.08210024982690811
step: 80, loss: 0.06025215610861778
step: 90, loss: 0.05661339685320854
step: 100, loss: 0.019408412277698517
step: 110, loss: 0.0347488708794117
step: 120, loss: 0.0003833697410300374
step: 130, loss: 0.12289681285619736
step: 140, loss: 0.003824704559519887
step: 150, loss: 0.02075556106865406
step: 160, loss: 0.00997814629226923
step: 170, loss: 0.006839129142463207
step: 180, loss: 0.012575032189488411
step: 190, loss: 0.20398759841918945
step: 200, loss: 0.004755211062729359
step: 210, loss: 0.005517646204680204
step: 220, loss: 0.13852262496948242
step: 230, loss: 0.03374111279845238
step: 240, loss: 0.00013078244228381664
step: 250, loss: 0.16930849850177765
step: 260, loss: 0.040695808827877045
step: 270, loss: 0.018190139904618263
step: 280, loss: 0.00040179057396017015
step: 290, loss: 0.11509839445352554
step: 300, loss: 0.040845829993486404
step: 310, loss: 0.00997093878686428
step: 320, loss: 0.0952192097902298
step: 330, loss: 0.03390444070100784
step: 340, loss: 0.01814986765384674
step: 350, loss: 0.016673900187015533
step: 360, loss: 0.10098971426486969
step: 370, loss: 0.002229528035968542
step: 380, loss: 0.0003144322254229337
step: 390, loss: 0.0513218529522419
step: 400, loss: 0.007373329252004623
step: 410, loss: 0.02073698677122593
step: 420, loss: 0.03437246382236481
step: 430, loss: 0.017291512340307236
step: 440, loss: 0.07860296964645386
step: 450, loss: 0.023309854790568352
step: 460, loss: 0.0023608363699167967
step: 470, loss: 0.02595735713839531
step: 480, loss: 0.05233106389641762
step: 490, loss: 0.004067337140440941
step: 500, loss: 0.0727076381444931
step: 510, loss: 0.051617953926324844
step: 520, loss: 0.029277406632900238
step: 530, loss: 0.0004698667617049068
epoch 6: dev_f1=0.8265867066466767, f1=0.8102153229844766, best_f1=0.8761358201817313
step: 0, loss: 0.03162628039717674
step: 10, loss: 0.057029686868190765
step: 20, loss: 0.06551305204629898
step: 30, loss: 0.002388828434050083
step: 40, loss: 0.004464760888367891
step: 50, loss: 0.0027118856087327003
step: 60, loss: 0.026781296357512474
step: 70, loss: 0.02769802324473858
step: 80, loss: 0.0048299371264874935
step: 90, loss: 0.028666263446211815
step: 100, loss: 0.07721623033285141
step: 110, loss: 0.016473757103085518
step: 120, loss: 0.05187050253152847
step: 130, loss: 0.09368205070495605
step: 140, loss: 0.00513369869440794
step: 150, loss: 0.0004003694048151374
step: 160, loss: 0.006398885045200586
step: 170, loss: 0.0032057217322289944
step: 180, loss: 0.026884732767939568
step: 190, loss: 0.04405558481812477
step: 200, loss: 0.00036680162884294987
step: 210, loss: 0.016804533079266548
step: 220, loss: 0.057550396770238876
step: 230, loss: 0.0011091603664681315
step: 240, loss: 0.0401504784822464
step: 250, loss: 0.006577635649591684
step: 260, loss: 0.022231554612517357
step: 270, loss: 0.0031172377057373524
step: 280, loss: 0.0020214798860251904
step: 290, loss: 0.03584171459078789
step: 300, loss: 0.008246643468737602
step: 310, loss: 0.033808689564466476
step: 320, loss: 0.0027186451479792595
step: 330, loss: 0.007460363674908876
step: 340, loss: 0.0002786804107017815
step: 350, loss: 0.043790850788354874
step: 360, loss: 0.0402207225561142
step: 370, loss: 0.004316666163504124
step: 380, loss: 0.0025121159851551056
step: 390, loss: 0.028508590534329414
step: 400, loss: 0.029020458459854126
step: 410, loss: 0.004937686957418919
step: 420, loss: 0.042814865708351135
step: 430, loss: 0.019462350755929947
step: 440, loss: 0.014587022364139557
step: 450, loss: 0.08050426840782166
step: 460, loss: 0.043805766850709915
step: 470, loss: 0.002955696079879999
step: 480, loss: 0.05355703830718994
step: 490, loss: 0.001730748568661511
step: 500, loss: 0.01451367512345314
step: 510, loss: 0.001317454967647791
step: 520, loss: 0.045446284115314484
step: 530, loss: 0.05041704326868057
epoch 7: dev_f1=0.8190875721027792, f1=0.7932131495227996, best_f1=0.8761358201817313
step: 0, loss: 0.03852935880422592
step: 10, loss: 0.0026805324014276266
step: 20, loss: 0.07225257158279419
step: 30, loss: 0.05078504607081413
step: 40, loss: 9.063308971235529e-05
step: 50, loss: 0.024899017065763474
step: 60, loss: 0.018211955204606056
step: 70, loss: 0.10331277549266815
step: 80, loss: 0.03379465267062187
step: 90, loss: 0.005208150949329138
step: 100, loss: 0.021619629114866257
step: 110, loss: 0.001805884880013764
step: 120, loss: 0.006054941564798355
step: 130, loss: 0.034403689205646515
step: 140, loss: 0.00014280586037784815
step: 150, loss: 0.004031159915030003
step: 160, loss: 0.03540315479040146
step: 170, loss: 0.0004990457673557103
step: 180, loss: 0.08703801780939102
step: 190, loss: 0.16171850264072418
step: 200, loss: 0.005942396819591522
step: 210, loss: 0.001071900362148881
step: 220, loss: 0.00040821536094881594
step: 230, loss: 0.002074394142255187
step: 240, loss: 0.0007659725961275399
step: 250, loss: 0.014045407064259052
step: 260, loss: 0.00010433074203319848
step: 270, loss: 0.0016229747561737895
step: 280, loss: 0.0008117190445773304
step: 290, loss: 0.0011700100731104612
step: 300, loss: 0.05365448817610741
step: 310, loss: 0.0033468257170170546
step: 320, loss: 0.002813221188262105
step: 330, loss: 0.020419953390955925
step: 340, loss: 0.03871718794107437
step: 350, loss: 0.07284961640834808
step: 360, loss: 0.005576389841735363
step: 370, loss: 0.04969833791255951
step: 380, loss: 0.0007594240014441311
step: 390, loss: 0.004871880169957876
step: 400, loss: 0.027784686535596848
step: 410, loss: 0.0034569697454571724
step: 420, loss: 0.05271950364112854
step: 430, loss: 0.03393740952014923
step: 440, loss: 0.00034787776530720294
step: 450, loss: 0.038476575165987015
step: 460, loss: 0.028163345530629158
step: 470, loss: 0.02337408997118473
step: 480, loss: 0.04742497205734253
step: 490, loss: 0.0032061466481536627
step: 500, loss: 0.044196583330631256
step: 510, loss: 0.00218466785736382
step: 520, loss: 0.02896672673523426
step: 530, loss: 0.051093690097332
epoch 8: dev_f1=0.7379077615298087, f1=0.7251131221719457, best_f1=0.8761358201817313
step: 0, loss: 0.016808100044727325
step: 10, loss: 0.0002158984716515988
step: 20, loss: 0.0014592672232538462
step: 30, loss: 0.0002625535416882485
step: 40, loss: 8.355603495147079e-05
step: 50, loss: 0.01036036480218172
step: 60, loss: 0.049327023327350616
step: 70, loss: 0.013325701467692852
step: 80, loss: 0.002918634098023176
step: 90, loss: 0.08646607398986816
step: 100, loss: 0.00047226325841620564
step: 110, loss: 0.00027064583264291286
step: 120, loss: 9.162718197330832e-05
step: 130, loss: 0.04898634925484657
step: 140, loss: 0.04790497198700905
step: 150, loss: 0.004677304998040199
step: 160, loss: 0.022408505901694298
step: 170, loss: 8.545802120352164e-05
step: 180, loss: 0.0002578754792921245
step: 190, loss: 0.003936540335416794
step: 200, loss: 0.01138982642441988
step: 210, loss: 0.05469590052962303
step: 220, loss: 0.00012502640311140567
step: 230, loss: 0.027791008353233337
step: 240, loss: 0.001936103100888431
step: 250, loss: 0.032312653958797455
step: 260, loss: 0.012346828356385231
step: 270, loss: 0.04081729054450989
step: 280, loss: 0.0002076929376926273
step: 290, loss: 6.379250407917425e-05
step: 300, loss: 5.780052379122935e-05
step: 310, loss: 0.009568313136696815
step: 320, loss: 6.17537516518496e-05
step: 330, loss: 0.005119417794048786
step: 340, loss: 0.03945571184158325
step: 350, loss: 0.015442839823663235
step: 360, loss: 0.05693812668323517
step: 370, loss: 0.00015240212087519467
step: 380, loss: 0.14714086055755615
step: 390, loss: 0.06117619201540947
step: 400, loss: 0.0013577883364632726
step: 410, loss: 0.008519058115780354
step: 420, loss: 0.024541305378079414
step: 430, loss: 0.027226561680436134
step: 440, loss: 0.003955235704779625
step: 450, loss: 0.00653081014752388
step: 460, loss: 0.009221562184393406
step: 470, loss: 0.0077675809152424335
step: 480, loss: 0.0006429711356759071
step: 490, loss: 0.000143396231578663
step: 500, loss: 0.029105115681886673
step: 510, loss: 0.0006944612832739949
step: 520, loss: 0.04016854241490364
step: 530, loss: 0.0001598889211891219
epoch 9: dev_f1=0.5680781758957655, f1=0.5408637873754152, best_f1=0.8761358201817313
step: 0, loss: 0.01617983728647232
step: 10, loss: 0.022943872958421707
step: 20, loss: 0.08731042593717575
step: 30, loss: 0.00040229203295893967
step: 40, loss: 0.00042085658060386777
step: 50, loss: 0.010394871234893799
step: 60, loss: 0.00016279103874694556
step: 70, loss: 0.007723050657659769
step: 80, loss: 0.04777874797582626
step: 90, loss: 0.005399865098297596
step: 100, loss: 0.03348991274833679
step: 110, loss: 0.012986511923372746
step: 120, loss: 0.0005249471287243068
step: 130, loss: 0.02592337131500244
step: 140, loss: 2.2958631234359927e-05
step: 150, loss: 0.021681100130081177
step: 160, loss: 0.017529359087347984
step: 170, loss: 7.569445733679458e-05
step: 180, loss: 0.0001990060554817319
step: 190, loss: 0.0006021737935952842
step: 200, loss: 0.0006342795095406473
step: 210, loss: 0.0021307223942130804
step: 220, loss: 0.03299180045723915
step: 230, loss: 0.017326416447758675
step: 240, loss: 0.01883336901664734
step: 250, loss: 0.030731484293937683
step: 260, loss: 0.0687275305390358
step: 270, loss: 0.0007923974189907312
step: 280, loss: 0.02279633656144142
step: 290, loss: 0.08772490173578262
step: 300, loss: 0.15318700671195984
step: 310, loss: 0.004965208470821381
step: 320, loss: 0.053105928003787994
step: 330, loss: 0.006720267701894045
step: 340, loss: 0.09521385282278061
step: 350, loss: 0.002011310774832964
step: 360, loss: 0.006167938467115164
step: 370, loss: 0.00012931985838804394
step: 380, loss: 0.003001721343025565
step: 390, loss: 0.025009043514728546
step: 400, loss: 0.041170548647642136
step: 410, loss: 0.01499167736619711
step: 420, loss: 0.008846812881529331
step: 430, loss: 0.011655967682600021
step: 440, loss: 0.027081547304987907
step: 450, loss: 0.02514749951660633
step: 460, loss: 0.001462829764932394
step: 470, loss: 0.00015124032506719232
step: 480, loss: 0.00028917682357132435
step: 490, loss: 0.0626450777053833
step: 500, loss: 0.028727231547236443
step: 510, loss: 0.037206441164016724
step: 520, loss: 0.00012815292575396597
step: 530, loss: 0.006115457974374294
epoch 10: dev_f1=0.636085626911315, f1=0.613664596273292, best_f1=0.8761358201817313
step: 0, loss: 0.0001686298637650907
step: 10, loss: 0.016062693670392036
step: 20, loss: 0.023253416642546654
step: 30, loss: 0.029581502079963684
step: 40, loss: 0.007137767970561981
step: 50, loss: 0.002530117053538561
step: 60, loss: 0.03198712319135666
step: 70, loss: 0.0016483402578160167
step: 80, loss: 8.906793664209545e-05
step: 90, loss: 0.0010791003005579114
step: 100, loss: 0.010715615004301071
step: 110, loss: 0.021626902744174004
step: 120, loss: 0.047702252864837646
step: 130, loss: 0.003394056810066104
step: 140, loss: 0.0016280957497656345
step: 150, loss: 3.977502274210565e-05
step: 160, loss: 0.001091563724912703
step: 170, loss: 0.00013154912448953837
step: 180, loss: 0.004426718223839998
step: 190, loss: 0.019772658124566078
step: 200, loss: 0.025979354977607727
step: 210, loss: 2.9682340027648024e-05
step: 220, loss: 0.00043041608296334743
step: 230, loss: 0.004699271637946367
step: 240, loss: 0.20748381316661835
step: 250, loss: 0.03611474484205246
step: 260, loss: 2.3561809939565137e-05
step: 270, loss: 0.012562497518956661
step: 280, loss: 0.00012943914043717086
step: 290, loss: 0.02724650129675865
step: 300, loss: 0.05664321407675743
step: 310, loss: 0.04098689556121826
step: 320, loss: 0.0009706710116006434
step: 330, loss: 0.0005353569285944104
step: 340, loss: 0.02506157197058201
step: 350, loss: 0.010122396051883698
step: 360, loss: 0.011139897629618645
step: 370, loss: 0.006600887980312109
step: 380, loss: 0.006992307025939226
step: 390, loss: 0.013266335241496563
step: 400, loss: 0.025181714445352554
step: 410, loss: 0.0002007358561968431
step: 420, loss: 3.815981108346023e-05
step: 430, loss: 0.0017184081953018904
step: 440, loss: 0.0003460018488112837
step: 450, loss: 0.019259441643953323
step: 460, loss: 0.006365739740431309
step: 470, loss: 0.030659915879368782
step: 480, loss: 5.4741092753829435e-05
step: 490, loss: 0.0003069768426939845
step: 500, loss: 0.0001945612020790577
step: 510, loss: 0.030459914356470108
step: 520, loss: 6.965600186958909e-05
step: 530, loss: 0.00027812388725578785
epoch 11: dev_f1=0.5958254269449715, f1=0.5732484076433121, best_f1=0.8761358201817313
step: 0, loss: 0.00010086067049996927
step: 10, loss: 0.0033454743679612875
step: 20, loss: 0.03152092546224594
step: 30, loss: 0.04994088411331177
step: 40, loss: 1.5999959941837005e-05
step: 50, loss: 0.014528595842421055
step: 60, loss: 0.01854284480214119
step: 70, loss: 2.965921157738194e-05
step: 80, loss: 0.013638029806315899
step: 90, loss: 0.022363530471920967
step: 100, loss: 0.06837461143732071
step: 110, loss: 0.02480345405638218
step: 120, loss: 0.003376092528924346
step: 130, loss: 2.023164961428847e-05
step: 140, loss: 0.00011643124889815226
step: 150, loss: 0.0013982760719954967
step: 160, loss: 0.0005012562032788992
step: 170, loss: 5.0465925596654415e-05
step: 180, loss: 0.03456752002239227
step: 190, loss: 0.019726544618606567
step: 200, loss: 0.004919236991554499
step: 210, loss: 0.01201902236789465
step: 220, loss: 0.000498215202242136
step: 230, loss: 0.06384377181529999
step: 240, loss: 0.0006987627130001783
step: 250, loss: 0.04150928184390068
step: 260, loss: 0.0009613796137273312
step: 270, loss: 0.03238097205758095
step: 280, loss: 0.01730244606733322
step: 290, loss: 0.16060052812099457
step: 300, loss: 0.024769119918346405
step: 310, loss: 0.016574352979660034
step: 320, loss: 0.0006856080144643784
step: 330, loss: 0.00044905763934366405
step: 340, loss: 0.012408429756760597
step: 350, loss: 0.035460785031318665
step: 360, loss: 0.00010645368456607684
step: 370, loss: 0.026899375021457672
step: 380, loss: 0.0008203022880479693
step: 390, loss: 2.4489278075634502e-05
step: 400, loss: 0.025160757824778557
step: 410, loss: 0.002118062460795045
step: 420, loss: 0.02181079052388668
step: 430, loss: 0.02187388762831688
step: 440, loss: 0.049027878791093826
step: 450, loss: 2.6649538995116018e-05
step: 460, loss: 0.008142790757119656
step: 470, loss: 0.022211657837033272
step: 480, loss: 0.05975327640771866
step: 490, loss: 0.03319597616791725
step: 500, loss: 0.004434949718415737
step: 510, loss: 0.0007845611544325948
step: 520, loss: 0.018761977553367615
step: 530, loss: 0.08540337532758713
epoch 12: dev_f1=0.654126213592233, f1=0.6359163591635917, best_f1=0.8761358201817313
step: 0, loss: 0.000599610386416316
step: 10, loss: 0.009916198439896107
step: 20, loss: 0.014073490165174007
step: 30, loss: 7.65868098824285e-05
step: 40, loss: 0.02089165523648262
step: 50, loss: 0.024014797061681747
step: 60, loss: 0.003711764933541417
step: 70, loss: 0.004289938136935234
step: 80, loss: 1.6003556083887815e-05
step: 90, loss: 0.01750054582953453
step: 100, loss: 0.0006004221504554152
step: 110, loss: 0.011019035242497921
step: 120, loss: 0.043095074594020844
step: 130, loss: 0.08517849445343018
step: 140, loss: 0.00010328334610676393
step: 150, loss: 4.548456126940437e-05
step: 160, loss: 0.0032414263114333153
step: 170, loss: 0.021404240280389786
step: 180, loss: 0.0004262508300598711
step: 190, loss: 0.04219357669353485
step: 200, loss: 0.00033958718995563686
step: 210, loss: 0.00024281737569253892
step: 220, loss: 4.153797635808587e-05
step: 230, loss: 8.383026579394937e-05
step: 240, loss: 0.043201345950365067
step: 250, loss: 0.015175849199295044
step: 260, loss: 0.00013183378905523568
step: 270, loss: 0.0002306214882992208
step: 280, loss: 0.04178940877318382
step: 290, loss: 0.040960974991321564
step: 300, loss: 0.023490717634558678
step: 310, loss: 0.0015268165152519941
step: 320, loss: 1.9374865587451495e-05
step: 330, loss: 0.006487095728516579
step: 340, loss: 0.008076692931354046
step: 350, loss: 0.0249281395226717
step: 360, loss: 7.42492193239741e-05
step: 370, loss: 0.2806336283683777
step: 380, loss: 0.09682594239711761
step: 390, loss: 0.0006407226901501417
step: 400, loss: 0.025146793574094772
step: 410, loss: 0.004111908841878176
step: 420, loss: 0.027551205828785896
step: 430, loss: 0.022107208147644997
step: 440, loss: 0.008925044909119606
step: 450, loss: 0.013415263965725899
step: 460, loss: 0.022985123097896576
step: 470, loss: 3.813899093074724e-05
step: 480, loss: 0.009088678285479546
step: 490, loss: 0.04493451863527298
step: 500, loss: 3.514647323754616e-05
step: 510, loss: 0.0032701182644814253
step: 520, loss: 0.0020538214594125748
step: 530, loss: 0.0005308272666297853
epoch 13: dev_f1=0.5438943894389439, f1=0.5251172136637643, best_f1=0.8761358201817313
step: 0, loss: 0.0017696763388812542
step: 10, loss: 0.00013553831377066672
step: 20, loss: 0.00037511688424274325
step: 30, loss: 1.5035071555757895e-05
step: 40, loss: 4.881400673184544e-05
step: 50, loss: 0.03644702211022377
step: 60, loss: 0.01566760241985321
step: 70, loss: 0.0001892527798190713
step: 80, loss: 0.0008410003501921892
step: 90, loss: 0.00011025888670701534
step: 100, loss: 0.021681733429431915
step: 110, loss: 2.261449299112428e-05
step: 120, loss: 0.015412991866469383
step: 130, loss: 0.057803925126791
step: 140, loss: 0.0680842325091362
step: 150, loss: 0.0007490248535759747
step: 160, loss: 0.0007242195424623787
step: 170, loss: 4.4463002268457785e-05
step: 180, loss: 2.342731022508815e-05
step: 190, loss: 0.0006613873410969973
step: 200, loss: 0.022526675835251808
step: 210, loss: 3.393124643480405e-05
step: 220, loss: 0.04953934624791145
step: 230, loss: 0.00015963523765094578
step: 240, loss: 0.017421720549464226
step: 250, loss: 8.466991857858375e-05
step: 260, loss: 0.0012853480875492096
step: 270, loss: 0.0011230437085032463
step: 280, loss: 0.025078875944018364
step: 290, loss: 0.05562528967857361
step: 300, loss: 0.007500722073018551
step: 310, loss: 0.000320473249303177
step: 320, loss: 3.473965989542194e-05
step: 330, loss: 0.014629676938056946
step: 340, loss: 0.004419622477144003
step: 350, loss: 4.005461232736707e-05
step: 360, loss: 7.253164221765473e-05
step: 370, loss: 0.023427536711096764
step: 380, loss: 8.570029604015872e-05
step: 390, loss: 0.008749965578317642
step: 400, loss: 0.0009763642447069287
step: 410, loss: 3.140460103168152e-05
step: 420, loss: 9.889034845400602e-05
step: 430, loss: 0.05842076987028122
step: 440, loss: 0.0023477859795093536
step: 450, loss: 3.947526420233771e-05
step: 460, loss: 0.02253664657473564
step: 470, loss: 0.00028775312239304185
step: 480, loss: 8.408736175624654e-05
step: 490, loss: 0.00014133835793472826
step: 500, loss: 0.0018187102396041155
step: 510, loss: 5.494808283401653e-05
step: 520, loss: 0.00011495364742586389
step: 530, loss: 0.00011060671386076137
epoch 14: dev_f1=0.3872875092387288, f1=0.3887240356083086, best_f1=0.8761358201817313
step: 0, loss: 0.005760536063462496
step: 10, loss: 0.02048802189528942
step: 20, loss: 1.7284952264162712e-05
step: 30, loss: 0.024969322606921196
step: 40, loss: 1.3649332686327398e-05
step: 50, loss: 0.04465985298156738
step: 60, loss: 0.00019748440536204726
step: 70, loss: 0.021901540458202362
step: 80, loss: 0.02772895246744156
step: 90, loss: 0.008166041225194931
step: 100, loss: 2.6301890102331527e-05
step: 110, loss: 0.002631635405123234
step: 120, loss: 5.188191425986588e-05
step: 130, loss: 6.308095180429518e-05
step: 140, loss: 0.06050317734479904
step: 150, loss: 1.1853792784677353e-05
step: 160, loss: 0.0748639702796936
step: 170, loss: 0.012188922613859177
step: 180, loss: 0.023308400064706802
step: 190, loss: 0.025051714852452278
step: 200, loss: 0.024607444182038307
step: 210, loss: 2.2179283405421302e-05
step: 220, loss: 2.0532534108497202e-05
step: 230, loss: 0.00016563604003749788
step: 240, loss: 0.02578650787472725
step: 250, loss: 0.036949608474969864
step: 260, loss: 0.000756406516302377
step: 270, loss: 2.5761848519323394e-05
step: 280, loss: 0.037128619849681854
step: 290, loss: 0.0213291198015213
step: 300, loss: 0.19407236576080322
step: 310, loss: 0.00020383847004268318
step: 320, loss: 0.019717561081051826
step: 330, loss: 0.01207187119871378
step: 340, loss: 0.016118692234158516
step: 350, loss: 0.11989473551511765
step: 360, loss: 0.05567051097750664
step: 370, loss: 7.864120561862364e-05
step: 380, loss: 0.003930017352104187
step: 390, loss: 0.029421374201774597
step: 400, loss: 0.0003539926547091454
step: 410, loss: 0.05621505528688431
step: 420, loss: 0.0006823071162216365
step: 430, loss: 0.00029815552989020944
step: 440, loss: 0.02714526280760765
step: 450, loss: 4.820050889975391e-05
step: 460, loss: 0.0003015935071744025
step: 470, loss: 0.006598418578505516
step: 480, loss: 0.0005763847148045897
step: 490, loss: 0.029374420642852783
step: 500, loss: 0.0002840633678715676
step: 510, loss: 0.014805921353399754
step: 520, loss: 9.382278949487954e-05
step: 530, loss: 2.0253721231711097e-05
epoch 15: dev_f1=0.4319654427645788, f1=0.4197530864197531, best_f1=0.8761358201817313
step: 0, loss: 5.7528297475073487e-05
step: 10, loss: 0.02647440694272518
step: 20, loss: 0.01570242829620838
step: 30, loss: 1.3783384929411113e-05
step: 40, loss: 0.01575580984354019
step: 50, loss: 1.5888095731497742e-05
step: 60, loss: 0.003258461132645607
step: 70, loss: 3.710322198458016e-05
step: 80, loss: 0.05500704050064087
step: 90, loss: 3.437390114413574e-05
step: 100, loss: 5.4214237025007606e-05
step: 110, loss: 1.5444780729012564e-05
step: 120, loss: 2.8980768547626212e-05
step: 130, loss: 3.058649235754274e-05
step: 140, loss: 4.284395618014969e-05
step: 150, loss: 0.02644604630768299
step: 160, loss: 1.6133833923959173e-05
step: 170, loss: 3.9002745324978605e-05
step: 180, loss: 0.05344090983271599
step: 190, loss: 0.010317645967006683
step: 200, loss: 0.0016491442220285535
step: 210, loss: 0.0034827603958547115
step: 220, loss: 0.015591736882925034
step: 230, loss: 0.023177968338131905
step: 240, loss: 0.023080263286828995
step: 250, loss: 0.011410372331738472
step: 260, loss: 0.012261813506484032
step: 270, loss: 3.7343488656915724e-05
step: 280, loss: 0.0004869069380220026
step: 290, loss: 6.572136044269428e-05
step: 300, loss: 0.020646411925554276
step: 310, loss: 0.0068996138870716095
step: 320, loss: 0.04407798871397972
step: 330, loss: 0.02187659591436386
step: 340, loss: 7.23352495697327e-05
step: 350, loss: 0.024010559543967247
step: 360, loss: 0.04602254927158356
step: 370, loss: 0.021111290901899338
step: 380, loss: 0.00012590888945851475
step: 390, loss: 0.03897205367684364
step: 400, loss: 2.0346997189335525e-05
step: 410, loss: 1.2922880159749184e-05
step: 420, loss: 0.001400818582624197
step: 430, loss: 7.551357703050599e-05
step: 440, loss: 0.025130495429039
step: 450, loss: 2.5798528440645896e-05
step: 460, loss: 3.350890983710997e-05
step: 470, loss: 2.5502040443825535e-05
step: 480, loss: 0.004400973208248615
step: 490, loss: 1.4800356439081952e-05
step: 500, loss: 2.9100050596753135e-05
step: 510, loss: 0.0006098984740674496
step: 520, loss: 0.0022984477691352367
step: 530, loss: 0.022462351247668266
epoch 16: dev_f1=0.4329749103942653, f1=0.418840579710145, best_f1=0.8761358201817313
step: 0, loss: 2.9766903026029468e-05
step: 10, loss: 0.027002114802598953
step: 20, loss: 0.0006913257529959083
step: 30, loss: 1.796290962374769e-05
step: 40, loss: 0.0327225960791111
step: 50, loss: 0.015178224071860313
step: 60, loss: 1.9590126612456515e-05
step: 70, loss: 0.00559764401987195
step: 80, loss: 0.021099155768752098
step: 90, loss: 0.03445956110954285
step: 100, loss: 0.001358264940790832
step: 110, loss: 9.176557796308771e-05
step: 120, loss: 2.2160736989462748e-05
step: 130, loss: 0.0011638078140094876
step: 140, loss: 0.02989993803203106
step: 150, loss: 1.674120176176075e-05
step: 160, loss: 0.03929046541452408
step: 170, loss: 0.01659013330936432
step: 180, loss: 2.475723158568144e-05
step: 190, loss: 1.1943177014472894e-05
step: 200, loss: 1.5441142750205472e-05
step: 210, loss: 0.000303391192574054
step: 220, loss: 0.04958973079919815
step: 230, loss: 3.11416806653142e-05
step: 240, loss: 0.008684179745614529
step: 250, loss: 5.306336242938414e-05
step: 260, loss: 0.00019713921938091516
step: 270, loss: 0.002694448223337531
step: 280, loss: 0.002067520748823881
step: 290, loss: 4.0599457861389965e-05
step: 300, loss: 1.7553124052938074e-05
step: 310, loss: 0.0007574223564006388
step: 320, loss: 6.75986084388569e-05
step: 330, loss: 0.0452512763440609
step: 340, loss: 0.001881400472484529
step: 350, loss: 4.810661994270049e-05
step: 360, loss: 0.0005249864188954234
step: 370, loss: 1.9973649614257738e-05
step: 380, loss: 0.02177789993584156
step: 390, loss: 0.016462333500385284
step: 400, loss: 0.0001106193958548829
step: 410, loss: 2.676286931091454e-05
step: 420, loss: 0.03149386867880821
step: 430, loss: 0.00010605614079395309
step: 440, loss: 9.57394513534382e-06
step: 450, loss: 0.0007527203415520489
step: 460, loss: 5.661866453010589e-05
step: 470, loss: 0.015475301072001457
step: 480, loss: 0.05705936998128891
step: 490, loss: 0.0005105410236865282
step: 500, loss: 0.0010053386213257909
step: 510, loss: 0.0003287242434453219
step: 520, loss: 3.951380494982004e-05
step: 530, loss: 0.00011010310845449567
epoch 17: dev_f1=0.4199855177407676, f1=0.40762463343108507, best_f1=0.8761358201817313
step: 0, loss: 0.02017221786081791
step: 10, loss: 0.00015045373584143817
step: 20, loss: 7.688099867664278e-05
step: 30, loss: 2.494622822268866e-05
step: 40, loss: 4.7663455916335806e-05
step: 50, loss: 1.87152145372238e-05
step: 60, loss: 0.021507320925593376
step: 70, loss: 0.02203977480530739
step: 80, loss: 7.367181387962773e-05
step: 90, loss: 4.5358196075540036e-05
step: 100, loss: 0.025973767042160034
step: 110, loss: 0.0253349207341671
step: 120, loss: 0.00012087936192983761
step: 130, loss: 0.02199120819568634
step: 140, loss: 0.02874220535159111
step: 150, loss: 1.4852574167889543e-05
step: 160, loss: 0.008540205657482147
step: 170, loss: 3.658320929389447e-05
step: 180, loss: 0.004442946519702673
step: 190, loss: 0.028884997591376305
step: 200, loss: 0.005558603908866644
step: 210, loss: 0.018267888575792313
step: 220, loss: 2.6529160095378757e-05
step: 230, loss: 0.0046472446992993355
step: 240, loss: 0.0003092016268055886
step: 250, loss: 0.04529663920402527
step: 260, loss: 1.6283018339890987e-05
step: 270, loss: 0.006833779625594616
step: 280, loss: 0.00016525080718565732
step: 290, loss: 0.038327328860759735
step: 300, loss: 0.024399390444159508
step: 310, loss: 5.8397101383889094e-05
step: 320, loss: 0.01663699373602867
step: 330, loss: 0.0001719342835713178
step: 340, loss: 3.379534246050753e-05
step: 350, loss: 3.59255209332332e-05
step: 360, loss: 5.4719101171940565e-05
step: 370, loss: 2.1888265109737404e-05
step: 380, loss: 0.004556882660835981
step: 390, loss: 0.05491030588746071
step: 400, loss: 0.012436702847480774
step: 410, loss: 0.00015459493442904204
step: 420, loss: 0.015040984377264977
step: 430, loss: 0.01422004122287035
step: 440, loss: 0.021837841719388962
step: 450, loss: 5.586053157458082e-05
step: 460, loss: 0.004245672840625048
step: 470, loss: 0.03273333981633186
step: 480, loss: 0.004855412524193525
step: 490, loss: 2.4282217054860666e-05
step: 500, loss: 3.06679867208004e-05
step: 510, loss: 0.024321231991052628
step: 520, loss: 0.00023250504455063492
step: 530, loss: 2.2874603018863127e-05
epoch 18: dev_f1=0.4035216434336023, f1=0.398822663723326, best_f1=0.8761358201817313
step: 0, loss: 1.3544953617383726e-05
step: 10, loss: 3.877724884659983e-05
step: 20, loss: 7.02578472555615e-05
step: 30, loss: 0.0110698277130723
step: 40, loss: 0.000841906585264951
step: 50, loss: 0.0006534320418722928
step: 60, loss: 0.0017592130461707711
step: 70, loss: 0.07404953241348267
step: 80, loss: 0.04362359270453453
step: 90, loss: 1.182763389806496e-05
step: 100, loss: 3.4445823985151947e-05
step: 110, loss: 0.00019259657710790634
step: 120, loss: 0.04209332913160324
step: 130, loss: 0.022359132766723633
step: 140, loss: 0.0001388130331179127
step: 150, loss: 3.0125102057354525e-05
step: 160, loss: 0.019005628302693367
step: 170, loss: 1.8897557310992852e-05
step: 180, loss: 0.025203656405210495
step: 190, loss: 0.017318839207291603
step: 200, loss: 1.819765384425409e-05
step: 210, loss: 0.02674524299800396
step: 220, loss: 1.1123634976684116e-05
step: 230, loss: 0.0006408644840121269
step: 240, loss: 0.00409417599439621
step: 250, loss: 0.00026286154752597213
step: 260, loss: 4.6253691834863275e-05
step: 270, loss: 5.5670938309049234e-05
step: 280, loss: 0.04552428051829338
step: 290, loss: 6.412506627384573e-05
step: 300, loss: 0.01732725091278553
step: 310, loss: 1.5627319953637198e-05
step: 320, loss: 0.0006181653589010239
step: 330, loss: 4.0871789678931236e-05
step: 340, loss: 0.008101657964289188
step: 350, loss: 3.571467095753178e-05
step: 360, loss: 2.4798171580187045e-05
step: 370, loss: 1.456194877391681e-05
step: 380, loss: 0.05993424728512764
step: 390, loss: 0.014619101770222187
step: 400, loss: 1.7378062693751417e-05
step: 410, loss: 2.878291707020253e-05
step: 420, loss: 2.350550494156778e-05
step: 430, loss: 5.740722917835228e-05
step: 440, loss: 4.128809814574197e-05
step: 450, loss: 1.9888368115061894e-05
step: 460, loss: 1.8696533516049385e-05
step: 470, loss: 1.4401824955712073e-05
step: 480, loss: 0.028112705796957016
step: 490, loss: 0.0544748529791832
step: 500, loss: 0.026257354766130447
step: 510, loss: 0.01778501458466053
step: 520, loss: 1.8800850739353336e-05
step: 530, loss: 1.5750345482956618e-05
epoch 19: dev_f1=0.38215613382899627, f1=0.3890126206384559, best_f1=0.8761358201817313
step: 0, loss: 2.2577944037038833e-05
step: 10, loss: 0.024374909698963165
step: 20, loss: 9.177520405501127e-05
step: 30, loss: 0.0247502401471138
step: 40, loss: 2.8902049962198362e-05
step: 50, loss: 3.308374289190397e-05
step: 60, loss: 0.00011525419540703297
step: 70, loss: 0.0002573828387539834
step: 80, loss: 1.9087443433818407e-05
step: 90, loss: 0.0006311442703008652
step: 100, loss: 0.04632929712533951
step: 110, loss: 0.017163360491394997
step: 120, loss: 5.056594454799779e-05
step: 130, loss: 1.7202886738232337e-05
step: 140, loss: 6.616958853555843e-05
step: 150, loss: 6.145946827018633e-05
step: 160, loss: 0.022100791335105896
step: 170, loss: 1.550439810671378e-05
step: 180, loss: 1.544480983284302e-05
step: 190, loss: 4.8224323109025136e-05
step: 200, loss: 0.0001059627320501022
step: 210, loss: 0.02258269488811493
step: 220, loss: 1.8692933736019768e-05
step: 230, loss: 0.0186673142015934
step: 240, loss: 0.03671356290578842
step: 250, loss: 1.7828730051405728e-05
step: 260, loss: 0.0018173784483224154
step: 270, loss: 0.026113471016287804
step: 280, loss: 1.6718662664061412e-05
step: 290, loss: 1.5057305972732138e-05
step: 300, loss: 2.0596089598257095e-05
step: 310, loss: 4.7095487389015034e-05
step: 320, loss: 1.3206029507273342e-05
step: 330, loss: 0.015600296668708324
step: 340, loss: 1.0386045687482692e-05
step: 350, loss: 1.4982903849158902e-05
step: 360, loss: 3.390856727492064e-05
step: 370, loss: 0.04816722869873047
step: 380, loss: 0.02660420350730419
step: 390, loss: 0.03934840112924576
step: 400, loss: 1.7202941307914443e-05
step: 410, loss: 0.018389403820037842
step: 420, loss: 1.686380710452795e-05
step: 430, loss: 2.976729410875123e-05
step: 440, loss: 0.00021959925652481616
step: 450, loss: 3.658655259641819e-05
step: 460, loss: 0.00011460953101050109
step: 470, loss: 8.71602533152327e-05
step: 480, loss: 0.002365941647440195
step: 490, loss: 1.801848156901542e-05
step: 500, loss: 0.02076975628733635
step: 510, loss: 0.0226605124771595
step: 520, loss: 0.024719929322600365
step: 530, loss: 1.2870755199401174e-05
epoch 20: dev_f1=0.35454545454545455, f1=0.3511450381679389, best_f1=0.8761358201817313
