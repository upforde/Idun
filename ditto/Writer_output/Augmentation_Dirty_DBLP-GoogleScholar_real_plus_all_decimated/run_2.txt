cuda
Device: cuda
step: 0, loss: 0.772806704044342
step: 10, loss: 0.4791371524333954
step: 20, loss: 0.5668737888336182
step: 30, loss: 0.49998587369918823
step: 40, loss: 0.3937308192253113
step: 50, loss: 0.5621525645256042
step: 60, loss: 0.20647288858890533
step: 70, loss: 0.30481281876564026
step: 80, loss: 0.3876628577709198
step: 90, loss: 0.17662790417671204
step: 100, loss: 0.1571696400642395
step: 110, loss: 0.15914343297481537
step: 120, loss: 0.1746673732995987
step: 130, loss: 0.2773124575614929
step: 140, loss: 0.13194391131401062
step: 150, loss: 0.14042244851589203
step: 160, loss: 0.07189791649580002
step: 170, loss: 0.13371542096138
step: 180, loss: 0.13782528042793274
step: 190, loss: 0.2806638777256012
step: 200, loss: 0.14510218799114227
step: 210, loss: 0.13995128870010376
step: 220, loss: 0.26490747928619385
step: 230, loss: 0.22540493309497833
step: 240, loss: 0.3536480963230133
step: 250, loss: 0.20366208255290985
step: 260, loss: 0.1707705408334732
step: 270, loss: 0.25922179222106934
step: 280, loss: 0.29382702708244324
step: 290, loss: 0.15424437820911407
step: 300, loss: 0.04347546026110649
step: 310, loss: 0.04066150635480881
step: 320, loss: 0.09579072892665863
step: 330, loss: 0.19762350618839264
step: 340, loss: 0.23592548072338104
step: 350, loss: 0.005754960235208273
step: 360, loss: 0.14623768627643585
step: 370, loss: 0.18748413026332855
step: 380, loss: 0.1583770364522934
step: 390, loss: 0.3123556077480316
step: 400, loss: 0.23845617473125458
step: 410, loss: 0.15975381433963776
step: 420, loss: 0.06453597545623779
step: 430, loss: 0.2493714541196823
step: 440, loss: 0.16932956874370575
step: 450, loss: 0.31746906042099
step: 460, loss: 0.3059048056602478
step: 470, loss: 0.10053428262472153
step: 480, loss: 0.11885392665863037
step: 490, loss: 0.10007733851671219
step: 500, loss: 0.04323078319430351
step: 510, loss: 0.17360135912895203
step: 520, loss: 0.20217463374137878
step: 530, loss: 0.04251951724290848
step: 540, loss: 0.2544974386692047
step: 550, loss: 0.1297360360622406
step: 560, loss: 0.14025481045246124
step: 570, loss: 0.11340007185935974
step: 580, loss: 0.06144578754901886
step: 590, loss: 0.08557289838790894
step: 600, loss: 0.06479012221097946
step: 610, loss: 0.25503167510032654
step: 620, loss: 0.10251262038946152
step: 630, loss: 0.09148483723402023
step: 640, loss: 0.10726763308048248
step: 650, loss: 0.08093477040529251
step: 660, loss: 0.043645650148391724
step: 670, loss: 0.10955443233251572
step: 680, loss: 0.15708336234092712
step: 690, loss: 0.08676273375749588
step: 700, loss: 0.06836969405412674
step: 710, loss: 0.1034582257270813
step: 720, loss: 0.1352894902229309
step: 730, loss: 0.03551365062594414
step: 740, loss: 0.12404375523328781
step: 750, loss: 0.07109593600034714
step: 760, loss: 0.11425093561410904
step: 770, loss: 0.040910281240940094
step: 780, loss: 0.26259154081344604
step: 790, loss: 0.06842298060655594
step: 800, loss: 0.11737149953842163
step: 810, loss: 0.0808466225862503
step: 820, loss: 0.07056862115859985
step: 830, loss: 0.11143586039543152
step: 840, loss: 0.1604902446269989
step: 850, loss: 0.12282351404428482
step: 860, loss: 0.052884720265865326
step: 870, loss: 0.17969128489494324
step: 880, loss: 0.15426379442214966
step: 890, loss: 0.16965161263942719
step: 900, loss: 0.09130440652370453
step: 910, loss: 0.13329482078552246
step: 920, loss: 0.17319922149181366
step: 930, loss: 0.20148850977420807
step: 940, loss: 0.18052002787590027
step: 950, loss: 0.11416192352771759
step: 960, loss: 0.14571774005889893
step: 970, loss: 0.14601968228816986
step: 980, loss: 0.12239275872707367
step: 990, loss: 0.20230159163475037
step: 1000, loss: 0.16608427464962006
step: 1010, loss: 0.0884491354227066
step: 1020, loss: 0.15016302466392517
step: 1030, loss: 0.1379804015159607
step: 1040, loss: 0.16233572363853455
step: 1050, loss: 0.31459739804267883
step: 1060, loss: 0.30293986201286316
step: 1070, loss: 0.09498841315507889
epoch 1: dev_f1=0.9182844243792324, f1=0.920196165849309, best_f1=0.920196165849309
step: 0, loss: 0.035383984446525574
step: 10, loss: 0.07643793523311615
step: 20, loss: 0.16553515195846558
step: 30, loss: 0.16634558141231537
step: 40, loss: 0.1294054388999939
step: 50, loss: 0.06267838180065155
step: 60, loss: 0.1017543375492096
step: 70, loss: 0.10253992676734924
step: 80, loss: 0.1965552419424057
step: 90, loss: 0.09363047033548355
step: 100, loss: 0.09620065242052078
step: 110, loss: 0.14892448484897614
step: 120, loss: 0.19956381618976593
step: 130, loss: 0.12981347739696503
step: 140, loss: 0.22484943270683289
step: 150, loss: 0.2856789529323578
step: 160, loss: 0.17141488194465637
step: 170, loss: 0.19558057188987732
step: 180, loss: 0.10186238586902618
step: 190, loss: 0.04495753347873688
step: 200, loss: 0.3431446850299835
step: 210, loss: 0.20849882066249847
step: 220, loss: 0.1688615083694458
step: 230, loss: 0.1104220300912857
step: 240, loss: 0.16610844433307648
step: 250, loss: 0.07177937775850296
step: 260, loss: 0.3068823218345642
step: 270, loss: 0.18667440116405487
step: 280, loss: 0.13672968745231628
step: 290, loss: 0.24274659156799316
step: 300, loss: 0.13860122859477997
step: 310, loss: 0.07668057084083557
step: 320, loss: 0.08647818118333817
step: 330, loss: 0.31424111127853394
step: 340, loss: 0.053214702755212784
step: 350, loss: 0.22322487831115723
step: 360, loss: 0.12555214762687683
step: 370, loss: 0.060563553124666214
step: 380, loss: 0.13051864504814148
step: 390, loss: 0.0868687704205513
step: 400, loss: 0.08538152277469635
step: 410, loss: 0.3050740957260132
step: 420, loss: 0.18579086661338806
step: 430, loss: 0.1130407527089119
step: 440, loss: 0.12479954957962036
step: 450, loss: 0.011181081645190716
step: 460, loss: 0.04462428390979767
step: 470, loss: 0.08213935047388077
step: 480, loss: 0.05239160358905792
step: 490, loss: 0.13005580008029938
step: 500, loss: 0.18548931181430817
step: 510, loss: 0.09939336031675339
step: 520, loss: 0.13386572897434235
step: 530, loss: 0.1983637660741806
step: 540, loss: 0.09869717806577682
step: 550, loss: 0.008974486030638218
step: 560, loss: 0.15458422899246216
step: 570, loss: 0.046959392726421356
step: 580, loss: 0.0977107360959053
step: 590, loss: 0.1568325161933899
step: 600, loss: 0.06544989347457886
step: 610, loss: 0.14261706173419952
step: 620, loss: 0.2300317883491516
step: 630, loss: 0.1037948876619339
step: 640, loss: 0.15698491036891937
step: 650, loss: 0.05252006649971008
step: 660, loss: 0.08688254654407501
step: 670, loss: 0.16166000068187714
step: 680, loss: 0.15364597737789154
step: 690, loss: 0.03633664920926094
step: 700, loss: 0.1874668449163437
step: 710, loss: 0.1314791440963745
step: 720, loss: 0.10614701360464096
step: 730, loss: 0.042234160006046295
step: 740, loss: 0.02376728504896164
step: 750, loss: 0.1607738435268402
step: 760, loss: 0.18644064664840698
step: 770, loss: 0.1119370236992836
step: 780, loss: 0.17408740520477295
step: 790, loss: 0.1782226413488388
step: 800, loss: 0.08999405801296234
step: 810, loss: 0.08377065509557724
step: 820, loss: 0.1581277698278427
step: 830, loss: 0.13055378198623657
step: 840, loss: 0.11393703520298004
step: 850, loss: 0.161392480134964
step: 860, loss: 0.22883696854114532
step: 870, loss: 0.09588247537612915
step: 880, loss: 0.24913389980793
step: 890, loss: 0.07579434663057327
step: 900, loss: 0.22316908836364746
step: 910, loss: 0.11128359287977219
step: 920, loss: 0.2248341292142868
step: 930, loss: 0.1114213615655899
step: 940, loss: 0.09383884072303772
step: 950, loss: 0.1738581657409668
step: 960, loss: 0.14208956062793732
step: 970, loss: 0.017048701643943787
step: 980, loss: 0.10488467663526535
step: 990, loss: 0.0887284055352211
step: 1000, loss: 0.1090427115559578
step: 1010, loss: 0.0872819721698761
step: 1020, loss: 0.0606863833963871
step: 1030, loss: 0.10625973343849182
step: 1040, loss: 0.0848391205072403
step: 1050, loss: 0.09541597962379456
step: 1060, loss: 0.06923860311508179
step: 1070, loss: 0.15952350199222565
epoch 2: dev_f1=0.9377593360995851, f1=0.9422548120989918, best_f1=0.9422548120989918
step: 0, loss: 0.04644838348031044
step: 10, loss: 0.11204248666763306
step: 20, loss: 0.0608031190931797
step: 30, loss: 0.17630034685134888
step: 40, loss: 0.14656411111354828
step: 50, loss: 0.10533127933740616
step: 60, loss: 0.10838590562343597
step: 70, loss: 0.10081275552511215
step: 80, loss: 0.11886969208717346
step: 90, loss: 0.1310097575187683
step: 100, loss: 0.1276659220457077
step: 110, loss: 0.12222907692193985
step: 120, loss: 0.09126174449920654
step: 130, loss: 0.09603720903396606
step: 140, loss: 0.054055288434028625
step: 150, loss: 0.1651196926832199
step: 160, loss: 0.1037459522485733
step: 170, loss: 0.07377029955387115
step: 180, loss: 0.10331312566995621
step: 190, loss: 0.0852588340640068
step: 200, loss: 0.02144668437540531
step: 210, loss: 0.14284253120422363
step: 220, loss: 0.09837302565574646
step: 230, loss: 0.10038647055625916
step: 240, loss: 0.06635849177837372
step: 250, loss: 0.11870607733726501
step: 260, loss: 0.1535349041223526
step: 270, loss: 0.2191975861787796
step: 280, loss: 0.06573938578367233
step: 290, loss: 0.13159014284610748
step: 300, loss: 0.05983513966202736
step: 310, loss: 0.1476914882659912
step: 320, loss: 0.12153647094964981
step: 330, loss: 0.038296185433864594
step: 340, loss: 0.11764947324991226
step: 350, loss: 0.11715173721313477
step: 360, loss: 0.17782710492610931
step: 370, loss: 0.07604874670505524
step: 380, loss: 0.0763532742857933
step: 390, loss: 0.13918110728263855
step: 400, loss: 0.10706039518117905
step: 410, loss: 0.1305990368127823
step: 420, loss: 0.11805742979049683
step: 430, loss: 0.13850407302379608
step: 440, loss: 0.13459119200706482
step: 450, loss: 0.17052598297595978
step: 460, loss: 0.06241358444094658
step: 470, loss: 0.17120829224586487
step: 480, loss: 0.16913023591041565
step: 490, loss: 0.07237830758094788
step: 500, loss: 0.09752164036035538
step: 510, loss: 0.16720667481422424
step: 520, loss: 0.10472636669874191
step: 530, loss: 0.03713282570242882
step: 540, loss: 0.08871785551309586
step: 550, loss: 0.07991931587457657
step: 560, loss: 0.1474711000919342
step: 570, loss: 0.09110472351312637
step: 580, loss: 0.07540939748287201
step: 590, loss: 0.04835999384522438
step: 600, loss: 0.05822008103132248
step: 610, loss: 0.0636267140507698
step: 620, loss: 0.17833498120307922
step: 630, loss: 0.11374329775571823
step: 640, loss: 0.12599973380565643
step: 650, loss: 0.09570933878421783
step: 660, loss: 0.049993790686130524
step: 670, loss: 0.06349905580282211
step: 680, loss: 0.1488315314054489
step: 690, loss: 0.149823397397995
step: 700, loss: 0.1505410224199295
step: 710, loss: 0.06262478977441788
step: 720, loss: 0.16642339527606964
step: 730, loss: 0.11403873562812805
step: 740, loss: 0.16607864201068878
step: 750, loss: 0.12847241759300232
step: 760, loss: 0.20364537835121155
step: 770, loss: 0.05705716088414192
step: 780, loss: 0.06559236347675323
step: 790, loss: 0.12902379035949707
step: 800, loss: 0.13569679856300354
step: 810, loss: 0.09947648644447327
step: 820, loss: 0.1375884711742401
step: 830, loss: 0.06326839327812195
step: 840, loss: 0.04012209549546242
step: 850, loss: 0.02079383283853531
step: 860, loss: 0.06509034335613251
step: 870, loss: 0.09555520117282867
step: 880, loss: 0.06358609348535538
step: 890, loss: 0.3090015649795532
step: 900, loss: 0.11723677814006805
step: 910, loss: 0.056410569697618484
step: 920, loss: 0.09827646613121033
step: 930, loss: 0.13497433066368103
step: 940, loss: 0.3706589937210083
step: 950, loss: 0.14232231676578522
step: 960, loss: 0.11106360703706741
step: 970, loss: 0.1900060623884201
step: 980, loss: 0.14822131395339966
step: 990, loss: 0.07362277060747147
step: 1000, loss: 0.09128469973802567
step: 1010, loss: 0.040579862892627716
step: 1020, loss: 0.10412602126598358
step: 1030, loss: 0.07548822462558746
step: 1040, loss: 0.06497588008642197
step: 1050, loss: 0.07066888362169266
step: 1060, loss: 0.11032639443874359
step: 1070, loss: 0.111233189702034
epoch 3: dev_f1=0.9348729792147806, f1=0.9232889297197979, best_f1=0.9422548120989918
step: 0, loss: 0.14260199666023254
step: 10, loss: 0.16016410291194916
step: 20, loss: 0.04837976023554802
step: 30, loss: 0.10671454668045044
step: 40, loss: 0.12101031839847565
step: 50, loss: 0.1414126604795456
step: 60, loss: 0.13098827004432678
step: 70, loss: 0.038361161947250366
step: 80, loss: 0.1736808866262436
step: 90, loss: 0.1088990718126297
step: 100, loss: 0.06483929604291916
step: 110, loss: 0.08209189027547836
step: 120, loss: 0.09509489685297012
step: 130, loss: 0.04088796675205231
step: 140, loss: 0.05666906386613846
step: 150, loss: 0.01805722340941429
step: 160, loss: 0.15731534361839294
step: 170, loss: 0.16167224943637848
step: 180, loss: 0.07638122141361237
step: 190, loss: 0.13392174243927002
step: 200, loss: 0.061227038502693176
step: 210, loss: 0.10535722225904465
step: 220, loss: 0.0681585967540741
step: 230, loss: 0.13639922440052032
step: 240, loss: 0.10029707849025726
step: 250, loss: 0.036040447652339935
step: 260, loss: 0.12482685595750809
step: 270, loss: 0.04365396872162819
step: 280, loss: 0.09725459665060043
step: 290, loss: 0.04791373759508133
step: 300, loss: 0.12903834879398346
step: 310, loss: 0.23255687952041626
step: 320, loss: 0.1115507036447525
step: 330, loss: 0.0969720110297203
step: 340, loss: 0.007631010841578245
step: 350, loss: 0.1476367712020874
step: 360, loss: 0.041340380907058716
step: 370, loss: 0.04386213421821594
step: 380, loss: 0.08262991160154343
step: 390, loss: 0.09952995926141739
step: 400, loss: 0.15294107794761658
step: 410, loss: 0.05419746786355972
step: 420, loss: 0.02502400614321232
step: 430, loss: 0.12487876415252686
step: 440, loss: 0.08071167767047882
step: 450, loss: 0.05365458130836487
step: 460, loss: 0.08702319860458374
step: 470, loss: 0.08158521354198456
step: 480, loss: 0.13233400881290436
step: 490, loss: 0.18126428127288818
step: 500, loss: 0.2661072611808777
step: 510, loss: 0.14667688310146332
step: 520, loss: 0.08935589343309402
step: 530, loss: 0.06084286421537399
step: 540, loss: 0.10339735448360443
step: 550, loss: 0.228106290102005
step: 560, loss: 0.28036627173423767
step: 570, loss: 0.07812085002660751
step: 580, loss: 0.1677355021238327
step: 590, loss: 0.14149485528469086
step: 600, loss: 0.10730660706758499
step: 610, loss: 0.13342615962028503
step: 620, loss: 0.09566845744848251
step: 630, loss: 0.1409301459789276
step: 640, loss: 0.05476174131035805
step: 650, loss: 0.07298294454813004
step: 660, loss: 0.0925242155790329
step: 670, loss: 0.12570929527282715
step: 680, loss: 0.20642541348934174
step: 690, loss: 0.07165272533893585
step: 700, loss: 0.09830283373594284
step: 710, loss: 0.09887637197971344
step: 720, loss: 0.06588827818632126
step: 730, loss: 0.04485457018017769
step: 740, loss: 0.11430920660495758
step: 750, loss: 0.04519210755825043
step: 760, loss: 0.11168401688337326
step: 770, loss: 0.08092775195837021
step: 780, loss: 0.049396321177482605
step: 790, loss: 0.23143891990184784
step: 800, loss: 0.17913858592510223
step: 810, loss: 0.17395415902137756
step: 820, loss: 0.08275798708200455
step: 830, loss: 0.03557608649134636
step: 840, loss: 0.179715096950531
step: 850, loss: 0.052992843091487885
step: 860, loss: 0.1045178696513176
step: 870, loss: 0.051640164107084274
step: 880, loss: 0.054851505905389786
step: 890, loss: 0.1201438158750534
step: 900, loss: 0.14173577725887299
step: 910, loss: 0.13452228903770447
step: 920, loss: 0.06070679426193237
step: 930, loss: 0.09408256411552429
step: 940, loss: 0.03040122799575329
step: 950, loss: 0.025012677535414696
step: 960, loss: 0.18498212099075317
step: 970, loss: 0.0946522057056427
step: 980, loss: 0.11947974562644958
step: 990, loss: 0.090242899954319
step: 1000, loss: 0.12932349741458893
step: 1010, loss: 0.04127540811896324
step: 1020, loss: 0.07372061163187027
step: 1030, loss: 0.1723388284444809
step: 1040, loss: 0.14247147738933563
step: 1050, loss: 0.06671209633350372
step: 1060, loss: 0.11620964854955673
step: 1070, loss: 0.03236966207623482
epoch 4: dev_f1=0.9225746268656716, f1=0.9219399538106235, best_f1=0.9422548120989918
step: 0, loss: 0.011759528890252113
step: 10, loss: 0.042290832847356796
step: 20, loss: 0.03083561733365059
step: 30, loss: 0.0739128589630127
step: 40, loss: 0.136949822306633
step: 50, loss: 0.20525217056274414
step: 60, loss: 0.0623786561191082
step: 70, loss: 0.18551333248615265
step: 80, loss: 0.08032646775245667
step: 90, loss: 0.04033053293824196
step: 100, loss: 0.016228709369897842
step: 110, loss: 0.035449810326099396
step: 120, loss: 0.11739441007375717
step: 130, loss: 0.04167308285832405
step: 140, loss: 0.017385104671120644
step: 150, loss: 0.08154252916574478
step: 160, loss: 0.10535399615764618
step: 170, loss: 0.0721365213394165
step: 180, loss: 0.12317120283842087
step: 190, loss: 0.09049117565155029
step: 200, loss: 0.07536089420318604
step: 210, loss: 0.09332548081874847
step: 220, loss: 0.12634076178073883
step: 230, loss: 0.15729285776615143
step: 240, loss: 0.21238455176353455
step: 250, loss: 0.10991684347391129
step: 260, loss: 0.08816789090633392
step: 270, loss: 0.3087558448314667
step: 280, loss: 0.03879263252019882
step: 290, loss: 0.03955475986003876
step: 300, loss: 0.12351551651954651
step: 310, loss: 0.19746547937393188
step: 320, loss: 0.10121353715658188
step: 330, loss: 0.042653393000364304
step: 340, loss: 0.18487434089183807
step: 350, loss: 0.15043847262859344
step: 360, loss: 0.14785175025463104
step: 370, loss: 0.10253676027059555
step: 380, loss: 0.03574812412261963
step: 390, loss: 0.049403078854084015
step: 400, loss: 0.09759902954101562
step: 410, loss: 0.13033612072467804
step: 420, loss: 0.05018452927470207
step: 430, loss: 0.05850555747747421
step: 440, loss: 0.12228725850582123
step: 450, loss: 0.04977409541606903
step: 460, loss: 0.08714433014392853
step: 470, loss: 0.08896389603614807
step: 480, loss: 0.051805052906274796
step: 490, loss: 0.08349359035491943
step: 500, loss: 0.03683628886938095
step: 510, loss: 0.029757317155599594
step: 520, loss: 0.017037034034729004
step: 530, loss: 0.03007003292441368
step: 540, loss: 0.0911923423409462
step: 550, loss: 0.10012049227952957
step: 560, loss: 0.08615629374980927
step: 570, loss: 0.05561131238937378
step: 580, loss: 0.14468999207019806
step: 590, loss: 0.2091478854417801
step: 600, loss: 0.04286075383424759
step: 610, loss: 0.08259262144565582
step: 620, loss: 0.08080904930830002
step: 630, loss: 0.02384065091609955
step: 640, loss: 0.08555437624454498
step: 650, loss: 0.06984976679086685
step: 660, loss: 0.19026435911655426
step: 670, loss: 0.09899222105741501
step: 680, loss: 0.025618741288781166
step: 690, loss: 0.06943797320127487
step: 700, loss: 0.0664830207824707
step: 710, loss: 0.06571926921606064
step: 720, loss: 0.03859350457787514
step: 730, loss: 0.03111155331134796
step: 740, loss: 0.1593029797077179
step: 750, loss: 0.12069295346736908
step: 760, loss: 0.06541883200407028
step: 770, loss: 0.10523699223995209
step: 780, loss: 0.03544359654188156
step: 790, loss: 0.08048956841230392
step: 800, loss: 0.05696731060743332
step: 810, loss: 0.03890996053814888
step: 820, loss: 0.14853867888450623
step: 830, loss: 0.029129832983016968
step: 840, loss: 0.0982019379734993
step: 850, loss: 0.11717874556779861
step: 860, loss: 0.09160875529050827
step: 870, loss: 0.04583677276968956
step: 880, loss: 0.05700895935297012
step: 890, loss: 0.036686770617961884
step: 900, loss: 0.032402925193309784
step: 910, loss: 0.04629158973693848
step: 920, loss: 0.18750202655792236
step: 930, loss: 0.035330984741449356
step: 940, loss: 0.08285964280366898
step: 950, loss: 0.04666149988770485
step: 960, loss: 0.15626196563243866
step: 970, loss: 0.1292012631893158
step: 980, loss: 0.03484043851494789
step: 990, loss: 0.11736062169075012
step: 1000, loss: 0.08199156075716019
step: 1010, loss: 0.002961769001558423
step: 1020, loss: 0.020753663033246994
step: 1030, loss: 0.1439843326807022
step: 1040, loss: 0.055622052401304245
step: 1050, loss: 0.0713224709033966
step: 1060, loss: 0.04381599277257919
step: 1070, loss: 0.05045600235462189
epoch 5: dev_f1=0.9264844486333647, f1=0.921274601686973, best_f1=0.9422548120989918
step: 0, loss: 0.24561947584152222
step: 10, loss: 0.001289720879867673
step: 20, loss: 0.15833646059036255
step: 30, loss: 0.10459025949239731
step: 40, loss: 0.04129229113459587
step: 50, loss: 0.0934998169541359
step: 60, loss: 0.032286904752254486
step: 70, loss: 0.07479315251111984
step: 80, loss: 0.12930718064308167
step: 90, loss: 0.0659746527671814
step: 100, loss: 0.1687292903661728
step: 110, loss: 0.1464756280183792
step: 120, loss: 0.1642279326915741
step: 130, loss: 0.07532519102096558
step: 140, loss: 0.1152171641588211
step: 150, loss: 0.24261482059955597
step: 160, loss: 0.17134922742843628
step: 170, loss: 0.1088806614279747
step: 180, loss: 0.03628605604171753
step: 190, loss: 0.02843022346496582
step: 200, loss: 0.11222168058156967
step: 210, loss: 0.11833487451076508
step: 220, loss: 0.06120845302939415
step: 230, loss: 0.10428284853696823
step: 240, loss: 0.07857412099838257
step: 250, loss: 0.13337461650371552
step: 260, loss: 0.044378120452165604
step: 270, loss: 0.16227620840072632
step: 280, loss: 0.2095595896244049
step: 290, loss: 0.1942145973443985
step: 300, loss: 0.03765493258833885
step: 310, loss: 0.12646779417991638
step: 320, loss: 0.08358940482139587
step: 330, loss: 0.07449217885732651
step: 340, loss: 0.0713500827550888
step: 350, loss: 0.1280357986688614
step: 360, loss: 0.17050857841968536
step: 370, loss: 0.00023616485123056918
step: 380, loss: 0.14001597464084625
step: 390, loss: 0.07098959386348724
step: 400, loss: 0.17103920876979828
step: 410, loss: 0.07726132869720459
step: 420, loss: 0.060917630791664124
step: 430, loss: 0.06709286570549011
step: 440, loss: 0.11635000258684158
step: 450, loss: 0.03673510253429413
step: 460, loss: 0.11725176870822906
step: 470, loss: 0.0461340956389904
step: 480, loss: 0.01535984966903925
step: 490, loss: 0.04740085080265999
step: 500, loss: 0.07445097714662552
step: 510, loss: 0.09322516620159149
step: 520, loss: 0.15108731389045715
step: 530, loss: 0.08098545670509338
step: 540, loss: 0.15171340107917786
step: 550, loss: 0.11289983242750168
step: 560, loss: 0.13457992672920227
step: 570, loss: 0.05857723951339722
step: 580, loss: 0.08484943956136703
step: 590, loss: 0.014717807061970234
step: 600, loss: 0.08453977108001709
step: 610, loss: 0.08858494460582733
step: 620, loss: 0.06596718728542328
step: 630, loss: 0.04106588289141655
step: 640, loss: 0.049782466143369675
step: 650, loss: 0.030833624303340912
step: 660, loss: 0.0764373317360878
step: 670, loss: 0.05320100858807564
step: 680, loss: 0.11353668570518494
step: 690, loss: 0.030930668115615845
step: 700, loss: 0.05354464426636696
step: 710, loss: 0.03546770289540291
step: 720, loss: 0.027043631300330162
step: 730, loss: 0.07527109980583191
step: 740, loss: 0.060999300330877304
step: 750, loss: 0.03694498911499977
step: 760, loss: 0.06163112446665764
step: 770, loss: 0.029823942109942436
step: 780, loss: 0.0034688313025981188
step: 790, loss: 0.14849279820919037
step: 800, loss: 0.023596880957484245
step: 810, loss: 0.15068455040454865
step: 820, loss: 0.1566905528306961
step: 830, loss: 0.09398666024208069
step: 840, loss: 0.08726099133491516
step: 850, loss: 0.05896599590778351
step: 860, loss: 0.1191459447145462
step: 870, loss: 0.013315869495272636
step: 880, loss: 0.04820108413696289
step: 890, loss: 0.048319943249225616
step: 900, loss: 0.09642522782087326
step: 910, loss: 0.0664442703127861
step: 920, loss: 0.07458663731813431
step: 930, loss: 0.10629541426897049
step: 940, loss: 0.08197104930877686
step: 950, loss: 0.11337146908044815
step: 960, loss: 0.02060922607779503
step: 970, loss: 0.07603414356708527
step: 980, loss: 0.051850952208042145
step: 990, loss: 0.1277557760477066
step: 1000, loss: 0.11624566465616226
step: 1010, loss: 0.09090985357761383
step: 1020, loss: 0.035419367253780365
step: 1030, loss: 0.19861982762813568
step: 1040, loss: 0.18694615364074707
step: 1050, loss: 0.12486600875854492
step: 1060, loss: 0.05980964004993439
step: 1070, loss: 0.03508661314845085
epoch 6: dev_f1=0.9326568265682658, f1=0.921803127874885, best_f1=0.9422548120989918
step: 0, loss: 0.09875864535570145
step: 10, loss: 0.10542508959770203
step: 20, loss: 0.14242979884147644
step: 30, loss: 0.08674698323011398
step: 40, loss: 0.08020278811454773
step: 50, loss: 0.07034219056367874
step: 60, loss: 0.07284516841173172
step: 70, loss: 0.03196076676249504
step: 80, loss: 0.06842836737632751
step: 90, loss: 0.1410568207502365
step: 100, loss: 0.035476602613925934
step: 110, loss: 0.07468965649604797
step: 120, loss: 0.03037937358021736
step: 130, loss: 0.10232001543045044
step: 140, loss: 0.07587845623493195
step: 150, loss: 0.1715770959854126
step: 160, loss: 0.05056145787239075
step: 170, loss: 0.02200920693576336
step: 180, loss: 0.02323249727487564
step: 190, loss: 0.09286756068468094
step: 200, loss: 0.026551024988293648
step: 210, loss: 0.05966142565011978
step: 220, loss: 0.040111444890499115
step: 230, loss: 0.10975049436092377
step: 240, loss: 0.05841268599033356
step: 250, loss: 0.06652890890836716
step: 260, loss: 0.1070244237780571
step: 270, loss: 0.0930369570851326
step: 280, loss: 0.07344865798950195
step: 290, loss: 0.061169303953647614
step: 300, loss: 0.03896990045905113
step: 310, loss: 0.04836449772119522
step: 320, loss: 0.04781397432088852
step: 330, loss: 0.03489000350236893
step: 340, loss: 5.683739800588228e-05
step: 350, loss: 0.0409487783908844
step: 360, loss: 0.02588374726474285
step: 370, loss: 0.09270491451025009
step: 380, loss: 0.13215631246566772
step: 390, loss: 0.1619974672794342
step: 400, loss: 0.07018481194972992
step: 410, loss: 0.07674058526754379
step: 420, loss: 0.10764919221401215
step: 430, loss: 0.07939159125089645
step: 440, loss: 0.03927558660507202
step: 450, loss: 0.19816173613071442
step: 460, loss: 0.11756893992424011
step: 470, loss: 0.06153031811118126
step: 480, loss: 0.11487460881471634
step: 490, loss: 0.04235277324914932
step: 500, loss: 0.09406910091638565
step: 510, loss: 0.16741740703582764
step: 520, loss: 0.057434551417827606
step: 530, loss: 0.001691647106781602
step: 540, loss: 0.02933434583246708
step: 550, loss: 0.04981878027319908
step: 560, loss: 0.05696665495634079
step: 570, loss: 0.02079392597079277
step: 580, loss: 0.0802716314792633
step: 590, loss: 0.09640251845121384
step: 600, loss: 0.08093968033790588
step: 610, loss: 0.0805523619055748
step: 620, loss: 0.1324402093887329
step: 630, loss: 0.07118604332208633
step: 640, loss: 0.1777469515800476
step: 650, loss: 0.04337479919195175
step: 660, loss: 0.15070711076259613
step: 670, loss: 0.09402848780155182
step: 680, loss: 0.06414657086133957
step: 690, loss: 0.060503069311380386
step: 700, loss: 0.15734094381332397
step: 710, loss: 0.06747899949550629
step: 720, loss: 0.008686728775501251
step: 730, loss: 0.09334889054298401
step: 740, loss: 0.11079780757427216
step: 750, loss: 0.07203072309494019
step: 760, loss: 0.04406140744686127
step: 770, loss: 0.03148801252245903
step: 780, loss: 0.08382811397314072
step: 790, loss: 0.0906321331858635
step: 800, loss: 0.12562155723571777
step: 810, loss: 0.08602273464202881
step: 820, loss: 0.17299751937389374
step: 830, loss: 0.03919369727373123
step: 840, loss: 0.1137252151966095
step: 850, loss: 0.24397912621498108
step: 860, loss: 0.03573351353406906
step: 870, loss: 0.19712452590465546
step: 880, loss: 0.03708590194582939
step: 890, loss: 0.025569550693035126
step: 900, loss: 0.12111787497997284
step: 910, loss: 0.12872110307216644
step: 920, loss: 0.16566915810108185
step: 930, loss: 0.18231382966041565
step: 940, loss: 0.10238585621118546
step: 950, loss: 0.0927354171872139
step: 960, loss: 0.07635734975337982
step: 970, loss: 0.10309602320194244
step: 980, loss: 0.05500086024403572
step: 990, loss: 0.09147834032773972
step: 1000, loss: 0.17614008486270905
step: 1010, loss: 0.07488961517810822
step: 1020, loss: 0.0782347247004509
step: 1030, loss: 0.10006660223007202
step: 1040, loss: 0.061148155480623245
step: 1050, loss: 0.1282879114151001
step: 1060, loss: 0.05466163903474808
step: 1070, loss: 0.09214933216571808
epoch 7: dev_f1=0.9327058823529412, f1=0.9318394024276377, best_f1=0.9422548120989918
step: 0, loss: 0.08100290596485138
step: 10, loss: 0.031234098598361015
step: 20, loss: 0.08626513928174973
step: 30, loss: 0.07076183706521988
step: 40, loss: 0.047047171741724014
step: 50, loss: 0.05916580930352211
step: 60, loss: 0.008929355069994926
step: 70, loss: 0.08947606384754181
step: 80, loss: 0.11557570844888687
step: 90, loss: 0.018573151901364326
step: 100, loss: 0.030523203313350677
step: 110, loss: 0.10904242098331451
step: 120, loss: 0.08641227334737778
step: 130, loss: 0.10593589395284653
step: 140, loss: 0.07652931660413742
step: 150, loss: 0.05913565680384636
step: 160, loss: 0.07283838838338852
step: 170, loss: 0.05023575946688652
step: 180, loss: 0.05483440309762955
step: 190, loss: 0.14980511367321014
step: 200, loss: 0.0807449221611023
step: 210, loss: 0.12503519654273987
step: 220, loss: 0.041327740997076035
step: 230, loss: 0.0973331406712532
step: 240, loss: 0.051496442407369614
step: 250, loss: 0.008164357393980026
step: 260, loss: 0.0678858831524849
step: 270, loss: 0.03749322146177292
step: 280, loss: 0.036514826118946075
step: 290, loss: 0.027971366420388222
step: 300, loss: 0.07128645479679108
step: 310, loss: 0.0025035638827830553
step: 320, loss: 0.044827286154031754
step: 330, loss: 0.05308874696493149
step: 340, loss: 0.13665986061096191
step: 350, loss: 0.06956667453050613
step: 360, loss: 0.0211179256439209
step: 370, loss: 0.07768253982067108
step: 380, loss: 0.08615803718566895
step: 390, loss: 0.05648134648799896
step: 400, loss: 0.0068021803162992
step: 410, loss: 0.08845630288124084
step: 420, loss: 0.13491806387901306
step: 430, loss: 0.013503128662705421
step: 440, loss: 0.059720229357481
step: 450, loss: 0.029574492946267128
step: 460, loss: 0.021328626200556755
step: 470, loss: 0.14114601910114288
step: 480, loss: 0.08108105510473251
step: 490, loss: 0.05342160165309906
step: 500, loss: 0.13114455342292786
step: 510, loss: 0.08035752922296524
step: 520, loss: 0.035705845803022385
step: 530, loss: 0.0853208377957344
step: 540, loss: 0.09966249018907547
step: 550, loss: 8.017836807994172e-05
step: 560, loss: 0.02270841971039772
step: 570, loss: 0.0527477003633976
step: 580, loss: 0.1293935626745224
step: 590, loss: 0.04170069471001625
step: 600, loss: 0.15120407938957214
step: 610, loss: 0.0928269624710083
step: 620, loss: 0.039857033640146255
step: 630, loss: 0.0484125129878521
step: 640, loss: 0.04803142696619034
step: 650, loss: 0.11894113570451736
step: 660, loss: 0.039822306483983994
step: 670, loss: 0.10315735638141632
step: 680, loss: 0.0487646758556366
step: 690, loss: 0.13056781888008118
step: 700, loss: 0.1501564085483551
step: 710, loss: 0.13377317786216736
step: 720, loss: 0.10472901165485382
step: 730, loss: 0.10189090669155121
step: 740, loss: 0.07698654383420944
step: 750, loss: 0.03499488905072212
step: 760, loss: 0.0575668141245842
step: 770, loss: 0.030470410361886024
step: 780, loss: 0.07265621423721313
step: 790, loss: 0.0410844124853611
step: 800, loss: 0.0829554870724678
step: 810, loss: 0.25800636410713196
step: 820, loss: 0.16587427258491516
step: 830, loss: 0.12949563562870026
step: 840, loss: 0.048789575695991516
step: 850, loss: 0.12139032781124115
step: 860, loss: 0.11129476875066757
step: 870, loss: 0.015854764729738235
step: 880, loss: 0.08171529322862625
step: 890, loss: 0.053288985043764114
step: 900, loss: 0.17822265625
step: 910, loss: 0.09168259054422379
step: 920, loss: 0.23259617388248444
step: 930, loss: 0.07205747812986374
step: 940, loss: 0.03301958739757538
step: 950, loss: 0.05376780405640602
step: 960, loss: 0.02507948875427246
step: 970, loss: 0.09459680318832397
step: 980, loss: 0.03675547614693642
step: 990, loss: 0.09015806019306183
step: 1000, loss: 0.08356843143701553
step: 1010, loss: 0.007675988133996725
step: 1020, loss: 0.1224391981959343
step: 1030, loss: 0.07707144320011139
step: 1040, loss: 0.05523732304573059
step: 1050, loss: 0.09883003681898117
step: 1060, loss: 0.09929673373699188
step: 1070, loss: 0.015245846472680569
epoch 8: dev_f1=0.9351851851851852, f1=0.9361702127659576, best_f1=0.9422548120989918
step: 0, loss: 0.1466643512248993
step: 10, loss: 0.11351317912340164
step: 20, loss: 0.08460531383752823
step: 30, loss: 0.14775820076465607
step: 40, loss: 0.05644102022051811
step: 50, loss: 0.09071160852909088
step: 60, loss: 0.0693507269024849
step: 70, loss: 0.02248765341937542
step: 80, loss: 0.1646975427865982
step: 90, loss: 0.06330026686191559
step: 100, loss: 0.08349153399467468
step: 110, loss: 0.027696412056684494
step: 120, loss: 0.1226930245757103
step: 130, loss: 0.013640846125781536
step: 140, loss: 0.09949596226215363
step: 150, loss: 0.07981734722852707
step: 160, loss: 0.040175750851631165
step: 170, loss: 0.04776749387383461
step: 180, loss: 0.07296233624219894
step: 190, loss: 0.0202383603900671
step: 200, loss: 0.012879159301519394
step: 210, loss: 0.012401273474097252
step: 220, loss: 0.029859527945518494
step: 230, loss: 0.15068911015987396
step: 240, loss: 0.12486276030540466
step: 250, loss: 0.11329653114080429
step: 260, loss: 0.03040352091193199
step: 270, loss: 0.0556967556476593
step: 280, loss: 0.06715717166662216
step: 290, loss: 0.09550123661756516
step: 300, loss: 0.10067513585090637
step: 310, loss: 0.06092193350195885
step: 320, loss: 0.10531958937644958
step: 330, loss: 0.030004404485225677
step: 340, loss: 0.06513667851686478
step: 350, loss: 0.10421504825353622
step: 360, loss: 0.09754118323326111
step: 370, loss: 0.007225971203297377
step: 380, loss: 0.056054241955280304
step: 390, loss: 0.06298922002315521
step: 400, loss: 0.1356377750635147
step: 410, loss: 0.07483696192502975
step: 420, loss: 0.02981281839311123
step: 430, loss: 0.1331101804971695
step: 440, loss: 0.03307301551103592
step: 450, loss: 0.05893979221582413
step: 460, loss: 0.08496896922588348
step: 470, loss: 0.06420619785785675
step: 480, loss: 0.011101048439741135
step: 490, loss: 0.14373750984668732
step: 500, loss: 0.09817397594451904
step: 510, loss: 0.15492191910743713
step: 520, loss: 0.03493592143058777
step: 530, loss: 0.03340195119380951
step: 540, loss: 0.04028508812189102
step: 550, loss: 0.037020064890384674
step: 560, loss: 0.013403678312897682
step: 570, loss: 0.05099373683333397
step: 580, loss: 0.07207700610160828
step: 590, loss: 0.04670780524611473
step: 600, loss: 0.12224835902452469
step: 610, loss: 0.05149023234844208
step: 620, loss: 0.1472301483154297
step: 630, loss: 0.06384347379207611
step: 640, loss: 0.034438516944646835
step: 650, loss: 0.13401544094085693
step: 660, loss: 0.0685640424489975
step: 670, loss: 0.039183977991342545
step: 680, loss: 0.1573312133550644
step: 690, loss: 0.005455389153212309
step: 700, loss: 0.1454479992389679
step: 710, loss: 0.16458025574684143
step: 720, loss: 0.10204136371612549
step: 730, loss: 0.02445439249277115
step: 740, loss: 0.061213418841362
step: 750, loss: 0.05630931630730629
step: 760, loss: 0.07670051604509354
step: 770, loss: 0.03147998824715614
step: 780, loss: 0.03760845214128494
step: 790, loss: 0.08615482598543167
step: 800, loss: 0.030441103503108025
step: 810, loss: 0.07154606282711029
step: 820, loss: 0.15606354176998138
step: 830, loss: 0.03767433390021324
step: 840, loss: 0.022691240534186363
step: 850, loss: 0.09568401426076889
step: 860, loss: 0.033275023102760315
step: 870, loss: 0.0667775571346283
step: 880, loss: 0.09727604687213898
step: 890, loss: 0.06334634870290756
step: 900, loss: 0.04464919865131378
step: 910, loss: 6.119404133642092e-05
step: 920, loss: 0.018241427838802338
step: 930, loss: 0.008443835191428661
step: 940, loss: 0.07598178088665009
step: 950, loss: 0.07570148259401321
step: 960, loss: 0.0526624396443367
step: 970, loss: 0.12499736249446869
step: 980, loss: 0.02816968411207199
step: 990, loss: 0.05007329210639
step: 1000, loss: 0.04895665869116783
step: 1010, loss: 0.12017647176980972
step: 1020, loss: 0.03807822987437248
step: 1030, loss: 0.09241050481796265
step: 1040, loss: 0.11639590561389923
step: 1050, loss: 0.06550608575344086
step: 1060, loss: 0.12800173461437225
step: 1070, loss: 0.11818161606788635
epoch 9: dev_f1=0.9304964539007093, f1=0.9247515380974918, best_f1=0.9422548120989918
step: 0, loss: 0.029142536222934723
step: 10, loss: 0.06529475003480911
step: 20, loss: 0.01873604580760002
step: 30, loss: 0.05911831185221672
step: 40, loss: 0.0075805531814694405
step: 50, loss: 0.08268380910158157
step: 60, loss: 0.04842846840620041
step: 70, loss: 0.06664019823074341
step: 80, loss: 0.0020770723931491375
step: 90, loss: 0.01976734772324562
step: 100, loss: 0.00790965836495161
step: 110, loss: 0.06804058700799942
step: 120, loss: 0.047749921679496765
step: 130, loss: 0.01597108133137226
step: 140, loss: 0.011471420526504517
step: 150, loss: 0.055940233170986176
step: 160, loss: 0.03936931863427162
step: 170, loss: 0.06913433223962784
step: 180, loss: 0.08701006323099136
step: 190, loss: 0.048172857612371445
step: 200, loss: 0.06296775490045547
step: 210, loss: 0.05070798844099045
step: 220, loss: 0.08280035853385925
step: 230, loss: 0.033927321434020996
step: 240, loss: 0.056332193315029144
step: 250, loss: 4.5112195948604494e-05
step: 260, loss: 0.10180069506168365
step: 270, loss: 0.031459178775548935
step: 280, loss: 0.06267417222261429
step: 290, loss: 0.06842906028032303
step: 300, loss: 0.01533875335007906
step: 310, loss: 0.06315015256404877
step: 320, loss: 0.11778268963098526
step: 330, loss: 0.09486439824104309
step: 340, loss: 0.055925607681274414
step: 350, loss: 0.02159145474433899
step: 360, loss: 0.05900344252586365
step: 370, loss: 0.03380732983350754
step: 380, loss: 0.05675816535949707
step: 390, loss: 0.020891137421131134
step: 400, loss: 0.05760647729039192
step: 410, loss: 0.01047243271023035
step: 420, loss: 0.14968712627887726
step: 430, loss: 0.048342447727918625
step: 440, loss: 0.007021965924650431
step: 450, loss: 0.03328368812799454
step: 460, loss: 0.015850229188799858
step: 470, loss: 0.0452226921916008
step: 480, loss: 0.047878045588731766
step: 490, loss: 0.10853724181652069
step: 500, loss: 0.09826117753982544
step: 510, loss: 0.019920913502573967
step: 520, loss: 0.05939009413123131
step: 530, loss: 0.015936819836497307
step: 540, loss: 0.03910389915108681
step: 550, loss: 0.10344821214675903
step: 560, loss: 0.07481513917446136
step: 570, loss: 0.0005331975407898426
step: 580, loss: 0.16319912672042847
step: 590, loss: 0.06583628803491592
step: 600, loss: 0.093897245824337
step: 610, loss: 0.14216791093349457
step: 620, loss: 0.0328516811132431
step: 630, loss: 0.030339684337377548
step: 640, loss: 0.13356664776802063
step: 650, loss: 0.0964239090681076
step: 660, loss: 0.04209964722394943
step: 670, loss: 0.08217255771160126
step: 680, loss: 0.007160019129514694
step: 690, loss: 0.14672516286373138
step: 700, loss: 0.14302633702754974
step: 710, loss: 0.07075753062963486
step: 720, loss: 0.04466687887907028
step: 730, loss: 0.030778052285313606
step: 740, loss: 0.2055804431438446
step: 750, loss: 0.00437914626672864
step: 760, loss: 0.04679599776864052
step: 770, loss: 0.07922884821891785
step: 780, loss: 0.011919836513698101
step: 790, loss: 0.019527146592736244
step: 800, loss: 0.06521482765674591
step: 810, loss: 0.017400585114955902
step: 820, loss: 0.033930711448192596
step: 830, loss: 0.13007855415344238
step: 840, loss: 0.033399730920791626
step: 850, loss: 0.06662480533123016
step: 860, loss: 0.10157038271427155
step: 870, loss: 0.08224461227655411
step: 880, loss: 0.07052501291036606
step: 890, loss: 0.06163376197218895
step: 900, loss: 0.04275636374950409
step: 910, loss: 0.15881390869617462
step: 920, loss: 0.15107059478759766
step: 930, loss: 0.053079068660736084
step: 940, loss: 0.19353146851062775
step: 950, loss: 0.018462641164660454
step: 960, loss: 0.01345624215900898
step: 970, loss: 0.1052560806274414
step: 980, loss: 0.06041599437594414
step: 990, loss: 0.2218906730413437
step: 1000, loss: 0.033921971917152405
step: 1010, loss: 0.05527617037296295
step: 1020, loss: 0.07485752552747726
step: 1030, loss: 0.01884051226079464
step: 1040, loss: 0.23691436648368835
step: 1050, loss: 0.006071601063013077
step: 1060, loss: 0.11005162447690964
step: 1070, loss: 0.03484751284122467
epoch 10: dev_f1=0.9210406207211318, f1=0.9222323879231473, best_f1=0.9422548120989918
step: 0, loss: 0.03914080187678337
step: 10, loss: 0.02663252502679825
step: 20, loss: 0.009057874791324139
step: 30, loss: 0.04589754715561867
step: 40, loss: 0.12341620028018951
step: 50, loss: 0.15503159165382385
step: 60, loss: 0.059497617185115814
step: 70, loss: 0.08565769344568253
step: 80, loss: 0.1309957504272461
step: 90, loss: 0.02982623316347599
step: 100, loss: 0.08897853642702103
step: 110, loss: 0.0898425504565239
step: 120, loss: 0.11475041508674622
step: 130, loss: 0.048768945038318634
step: 140, loss: 0.029504630714654922
step: 150, loss: 0.16766811907291412
step: 160, loss: 0.0521802119910717
step: 170, loss: 0.035935819149017334
step: 180, loss: 0.154672771692276
step: 190, loss: 0.05277474224567413
step: 200, loss: 0.02236015349626541
step: 210, loss: 0.06548967212438583
step: 220, loss: 0.040211908519268036
step: 230, loss: 0.005228149704635143
step: 240, loss: 0.0018325946293771267
step: 250, loss: 0.07260875403881073
step: 260, loss: 0.06500152498483658
step: 270, loss: 0.06110428273677826
step: 280, loss: 0.038258958607912064
step: 290, loss: 0.07966898381710052
step: 300, loss: 0.06866490840911865
step: 310, loss: 0.17900173366069794
step: 320, loss: 0.023800764232873917
step: 330, loss: 0.00021804016432724893
step: 340, loss: 0.051829054951667786
step: 350, loss: 0.030920013785362244
step: 360, loss: 0.024670416489243507
step: 370, loss: 0.002208494348451495
step: 380, loss: 0.12031228840351105
step: 390, loss: 0.03394947201013565
step: 400, loss: 0.07654133439064026
step: 410, loss: 0.12411811947822571
step: 420, loss: 0.056584134697914124
step: 430, loss: 0.16713839769363403
step: 440, loss: 0.1550469696521759
step: 450, loss: 0.13098832964897156
step: 460, loss: 0.025797167792916298
step: 470, loss: 0.06876247376203537
step: 480, loss: 0.1128149926662445
step: 490, loss: 0.054444074630737305
step: 500, loss: 0.016637876629829407
step: 510, loss: 0.03835684433579445
step: 520, loss: 0.06695529818534851
step: 530, loss: 0.0010556494817137718
step: 540, loss: 0.1237122192978859
step: 550, loss: 0.01738477684557438
step: 560, loss: 0.04690226912498474
step: 570, loss: 0.060806699097156525
step: 580, loss: 0.0883345976471901
step: 590, loss: 0.08198652416467667
step: 600, loss: 0.03789373114705086
step: 610, loss: 1.6696563761797734e-05
step: 620, loss: 0.04767795652151108
step: 630, loss: 0.10414750874042511
step: 640, loss: 0.12715944647789001
step: 650, loss: 0.019107628613710403
step: 660, loss: 0.09213711321353912
step: 670, loss: 0.07516379654407501
step: 680, loss: 0.049354128539562225
step: 690, loss: 3.899398507201113e-05
step: 700, loss: 0.13896623253822327
step: 710, loss: 0.06093469634652138
step: 720, loss: 0.08376120775938034
step: 730, loss: 0.045483339577913284
step: 740, loss: 0.019436072558164597
step: 750, loss: 0.04344270005822182
step: 760, loss: 0.07620316743850708
step: 770, loss: 0.045642297714948654
step: 780, loss: 0.0502387098968029
step: 790, loss: 0.065567746758461
step: 800, loss: 0.08403529226779938
step: 810, loss: 0.10882606357336044
step: 820, loss: 0.0006143567734397948
step: 830, loss: 0.06306920200586319
step: 840, loss: 0.028307829052209854
step: 850, loss: 0.004194973036646843
step: 860, loss: 0.04381554201245308
step: 870, loss: 0.06402162462472916
step: 880, loss: 0.06945984065532684
step: 890, loss: 0.08340291678905487
step: 900, loss: 0.10940109938383102
step: 910, loss: 0.07268702983856201
step: 920, loss: 0.047015782445669174
step: 930, loss: 0.08847016096115112
step: 940, loss: 0.009716255590319633
step: 950, loss: 0.03282658010721207
step: 960, loss: 0.03224754333496094
step: 970, loss: 0.06250366568565369
step: 980, loss: 0.0861155092716217
step: 990, loss: 0.11825218796730042
step: 1000, loss: 0.07625877112150192
step: 1010, loss: 0.02679043635725975
step: 1020, loss: 0.09141848236322403
step: 1030, loss: 0.03394874557852745
step: 1040, loss: 0.05035810172557831
step: 1050, loss: 0.11211289465427399
step: 1060, loss: 0.02276676706969738
step: 1070, loss: 0.0699622854590416
epoch 11: dev_f1=0.933454876937101, f1=0.9328460484239378, best_f1=0.9422548120989918
step: 0, loss: 0.07059744000434875
step: 10, loss: 0.04623289406299591
step: 20, loss: 0.0385664626955986
step: 30, loss: 0.020420130342245102
step: 40, loss: 0.0613999143242836
step: 50, loss: 0.04997757449746132
step: 60, loss: 0.06590186804533005
step: 70, loss: 0.06314985454082489
step: 80, loss: 0.052606742829084396
step: 90, loss: 0.06561901420354843
step: 100, loss: 0.061592090874910355
step: 110, loss: 0.11468822509050369
step: 120, loss: 0.019991308450698853
step: 130, loss: 0.05974242836236954
step: 140, loss: 0.14490841329097748
step: 150, loss: 0.0024260729551315308
step: 160, loss: 0.1008450984954834
step: 170, loss: 0.08841781318187714
step: 180, loss: 0.13416482508182526
step: 190, loss: 0.08705826848745346
step: 200, loss: 0.06576347351074219
step: 210, loss: 0.06416340917348862
step: 220, loss: 0.04846558719873428
step: 230, loss: 0.005350564140826464
step: 240, loss: 0.030650585889816284
step: 250, loss: 0.0329241082072258
step: 260, loss: 0.026285376399755478
step: 270, loss: 0.06516702473163605
step: 280, loss: 0.017419446259737015
step: 290, loss: 0.010076219215989113
step: 300, loss: 0.000557965599000454
step: 310, loss: 0.03875334933400154
step: 320, loss: 0.04282735660672188
step: 330, loss: 0.03498753160238266
step: 340, loss: 0.08607631921768188
step: 350, loss: 0.10635390877723694
step: 360, loss: 0.05181853473186493
step: 370, loss: 0.08282507210969925
step: 380, loss: 0.031343910843133926
step: 390, loss: 0.03066370263695717
step: 400, loss: 0.08337448537349701
step: 410, loss: 0.014955547638237476
step: 420, loss: 0.0951714888215065
step: 430, loss: 0.1208900734782219
step: 440, loss: 0.015746306627988815
step: 450, loss: 0.04523957520723343
step: 460, loss: 0.13220131397247314
step: 470, loss: 0.008214260451495647
step: 480, loss: 0.05236642435193062
step: 490, loss: 0.09606574475765228
step: 500, loss: 0.06667761504650116
step: 510, loss: 0.08894538879394531
step: 520, loss: 0.053515899926424026
step: 530, loss: 0.12073234468698502
step: 540, loss: 0.13147307932376862
step: 550, loss: 0.02328360639512539
step: 560, loss: 0.05149740353226662
step: 570, loss: 0.07093597203493118
step: 580, loss: 0.015246561728417873
step: 590, loss: 0.05183623358607292
step: 600, loss: 0.009550623595714569
step: 610, loss: 0.011048971675336361
step: 620, loss: 0.017644502222537994
step: 630, loss: 0.07091182470321655
step: 640, loss: 0.06374786794185638
step: 650, loss: 0.05624718219041824
step: 660, loss: 0.0980834811925888
step: 670, loss: 0.06212085112929344
step: 680, loss: 0.01980958878993988
step: 690, loss: 0.07627054303884506
step: 700, loss: 0.03928806260228157
step: 710, loss: 0.027768444269895554
step: 720, loss: 0.1265016347169876
step: 730, loss: 0.09913851320743561
step: 740, loss: 0.02223179116845131
step: 750, loss: 0.06956445425748825
step: 760, loss: 0.026400476694107056
step: 770, loss: 0.06503892689943314
step: 780, loss: 0.09599806368350983
step: 790, loss: 0.07033375650644302
step: 800, loss: 0.05161157622933388
step: 810, loss: 0.05525815486907959
step: 820, loss: 0.06672567129135132
step: 830, loss: 0.07538995891809464
step: 840, loss: 0.0005665414500981569
step: 850, loss: 0.03321241959929466
step: 860, loss: 0.07877200841903687
step: 870, loss: 0.023368636146187782
step: 880, loss: 0.0783584862947464
step: 890, loss: 0.021575527265667915
step: 900, loss: 0.034618593752384186
step: 910, loss: 0.06959367543458939
step: 920, loss: 0.14471270143985748
step: 930, loss: 6.394272350007668e-05
step: 940, loss: 0.03316406533122063
step: 950, loss: 0.05886773020029068
step: 960, loss: 0.08600262552499771
step: 970, loss: 0.04700932279229164
step: 980, loss: 0.003617732785642147
step: 990, loss: 0.10990362614393234
step: 1000, loss: 0.0719698891043663
step: 1010, loss: 0.09461887925863266
step: 1020, loss: 0.13925787806510925
step: 1030, loss: 0.028620297089219093
step: 1040, loss: 0.062410034239292145
step: 1050, loss: 0.04808366671204567
step: 1060, loss: 0.06344517320394516
step: 1070, loss: 0.09892327338457108
epoch 12: dev_f1=0.9324699352451433, f1=0.9300184162062616, best_f1=0.9422548120989918
step: 0, loss: 0.03523249924182892
step: 10, loss: 0.005409174598753452
step: 20, loss: 0.021192491054534912
step: 30, loss: 0.0313507579267025
step: 40, loss: 0.16196325421333313
step: 50, loss: 0.02093687281012535
step: 60, loss: 0.015117567963898182
step: 70, loss: 0.08172529190778732
step: 80, loss: 0.046795424073934555
step: 90, loss: 0.005473666358739138
step: 100, loss: 0.18454846739768982
step: 110, loss: 0.07029154896736145
step: 120, loss: 0.019341319799423218
step: 130, loss: 0.030699333176016808
step: 140, loss: 0.035710033029317856
step: 150, loss: 0.10325486958026886
step: 160, loss: 0.024820107966661453
step: 170, loss: 0.010410558432340622
step: 180, loss: 0.022723931819200516
step: 190, loss: 0.010740061290562153
step: 200, loss: 0.022275345399975777
step: 210, loss: 0.03620081767439842
step: 220, loss: 0.00023714589769952
step: 230, loss: 0.07937076687812805
step: 240, loss: 0.11994793266057968
step: 250, loss: 0.06810972094535828
step: 260, loss: 0.05651051551103592
step: 270, loss: 0.08850786834955215
step: 280, loss: 0.29982492327690125
step: 290, loss: 0.014541080221533775
step: 300, loss: 0.003220838960260153
step: 310, loss: 0.021937372162938118
step: 320, loss: 0.07595136016607285
step: 330, loss: 0.034813541918992996
step: 340, loss: 0.020508652552962303
step: 350, loss: 0.015349912457168102
step: 360, loss: 0.06157039850950241
step: 370, loss: 0.13488754630088806
step: 380, loss: 0.00816081091761589
step: 390, loss: 0.0003596116148401052
step: 400, loss: 0.0658818781375885
step: 410, loss: 0.12079516053199768
step: 420, loss: 0.05889340862631798
step: 430, loss: 0.03783141449093819
step: 440, loss: 0.06066226586699486
step: 450, loss: 0.06099114567041397
step: 460, loss: 5.2747331210412085e-05
step: 470, loss: 0.024343162775039673
step: 480, loss: 0.06181866303086281
step: 490, loss: 0.005420580040663481
step: 500, loss: 0.0008454487542621791
step: 510, loss: 0.027841923758387566
step: 520, loss: 0.04384418949484825
step: 530, loss: 0.015597607009112835
step: 540, loss: 0.04375169053673744
step: 550, loss: 0.03138458728790283
step: 560, loss: 0.021707534790039062
step: 570, loss: 0.13969320058822632
step: 580, loss: 0.0381658561527729
step: 590, loss: 0.05375157669186592
step: 600, loss: 0.11306576430797577
step: 610, loss: 0.11822538822889328
step: 620, loss: 0.06686555594205856
step: 630, loss: 0.06572450697422028
step: 640, loss: 0.0018703560344874859
step: 650, loss: 0.11930828541517258
step: 660, loss: 0.007755017373710871
step: 670, loss: 0.0594499334692955
step: 680, loss: 0.14304672181606293
step: 690, loss: 0.1354539543390274
step: 700, loss: 0.058471616357564926
step: 710, loss: 0.07119602710008621
step: 720, loss: 0.06982894241809845
step: 730, loss: 0.05209168419241905
step: 740, loss: 0.04990178346633911
step: 750, loss: 0.06620541960000992
step: 760, loss: 0.026033660396933556
step: 770, loss: 0.064516581594944
step: 780, loss: 5.993750528432429e-05
step: 790, loss: 0.08865761011838913
step: 800, loss: 0.02045438624918461
step: 810, loss: 0.23585335910320282
step: 820, loss: 0.04115663841366768
step: 830, loss: 0.09440620988607407
step: 840, loss: 0.051429443061351776
step: 850, loss: 0.05604115501046181
step: 860, loss: 0.08007293939590454
step: 870, loss: 0.1331930309534073
step: 880, loss: 0.00011990388884441927
step: 890, loss: 0.09188974648714066
step: 900, loss: 0.07897796481847763
step: 910, loss: 0.17885422706604004
step: 920, loss: 0.04077484458684921
step: 930, loss: 0.03377888351678848
step: 940, loss: 0.03731008991599083
step: 950, loss: 0.07377486675977707
step: 960, loss: 0.02920345589518547
step: 970, loss: 0.11660843342542648
step: 980, loss: 0.028938453644514084
step: 990, loss: 0.024339711293578148
step: 1000, loss: 0.07802474498748779
step: 1010, loss: 0.022919854149222374
step: 1020, loss: 0.10913083702325821
step: 1030, loss: 0.14436447620391846
step: 1040, loss: 0.022351641207933426
step: 1050, loss: 0.08359168469905853
step: 1060, loss: 0.06963594257831573
step: 1070, loss: 0.015123466961085796
epoch 13: dev_f1=0.9335776454420522, f1=0.9266943291839558, best_f1=0.9422548120989918
step: 0, loss: 0.040075186640024185
step: 10, loss: 0.10006894171237946
step: 20, loss: 0.015334254130721092
step: 30, loss: 0.08990127593278885
step: 40, loss: 0.1043148934841156
step: 50, loss: 0.03360239043831825
step: 60, loss: 0.023675214499235153
step: 70, loss: 0.041435349732637405
step: 80, loss: 0.1500120311975479
step: 90, loss: 0.014051693491637707
step: 100, loss: 0.1349146068096161
step: 110, loss: 0.08163172751665115
step: 120, loss: 0.09001261740922928
step: 130, loss: 0.046178754419088364
step: 140, loss: 0.07457205653190613
step: 150, loss: 0.08167988806962967
step: 160, loss: 0.03917867690324783
step: 170, loss: 0.05419708415865898
step: 180, loss: 0.015596525743603706
step: 190, loss: 0.0656125620007515
step: 200, loss: 0.002707874169573188
step: 210, loss: 0.10535507649183273
step: 220, loss: 0.041375402361154556
step: 230, loss: 0.03478435054421425
step: 240, loss: 0.034382328391075134
step: 250, loss: 0.023306511342525482
step: 260, loss: 0.0539897158741951
step: 270, loss: 0.038808126002550125
step: 280, loss: 0.05628031864762306
step: 290, loss: 0.06378449499607086
step: 300, loss: 0.012774054892361164
step: 310, loss: 0.0928153395652771
step: 320, loss: 0.10613113641738892
step: 330, loss: 0.05271602421998978
step: 340, loss: 0.16660970449447632
step: 350, loss: 0.04666539654135704
step: 360, loss: 0.021333744749426842
step: 370, loss: 0.11676888912916183
step: 380, loss: 0.041957758367061615
step: 390, loss: 0.046373169869184494
step: 400, loss: 0.03498231619596481
step: 410, loss: 0.09165799617767334
step: 420, loss: 0.054501548409461975
step: 430, loss: 0.0787849947810173
step: 440, loss: 0.06542129814624786
step: 450, loss: 0.027117280289530754
step: 460, loss: 0.04688803851604462
step: 470, loss: 0.04948405921459198
step: 480, loss: 0.06359557062387466
step: 490, loss: 0.03722554072737694
step: 500, loss: 0.03191234916448593
step: 510, loss: 0.1280570775270462
step: 520, loss: 0.07438448071479797
step: 530, loss: 0.03883688524365425
step: 540, loss: 0.043945807963609695
step: 550, loss: 0.04806753620505333
step: 560, loss: 0.055493734776973724
step: 570, loss: 0.03120448812842369
step: 580, loss: 0.051188621670007706
step: 590, loss: 0.12211588025093079
step: 600, loss: 0.0430479571223259
step: 610, loss: 0.04890511929988861
step: 620, loss: 0.06501713395118713
step: 630, loss: 0.014794622547924519
step: 640, loss: 0.13502565026283264
step: 650, loss: 0.04206831380724907
step: 660, loss: 0.05156223848462105
step: 670, loss: 0.02866417169570923
step: 680, loss: 0.05197549983859062
step: 690, loss: 0.060384999960660934
step: 700, loss: 0.07495744526386261
step: 710, loss: 0.0654224306344986
step: 720, loss: 0.043717969208955765
step: 730, loss: 0.04703424870967865
step: 740, loss: 0.04511814936995506
step: 750, loss: 0.018901433795690536
step: 760, loss: 0.0359916053712368
step: 770, loss: 0.038705602288246155
step: 780, loss: 0.02454594150185585
step: 790, loss: 0.03941647335886955
step: 800, loss: 0.0768432691693306
step: 810, loss: 0.05599358305335045
step: 820, loss: 0.050908494740724564
step: 830, loss: 0.029614759609103203
step: 840, loss: 0.12652206420898438
step: 850, loss: 0.04588749259710312
step: 860, loss: 0.0831708088517189
step: 870, loss: 0.03564945608377457
step: 880, loss: 0.06130610778927803
step: 890, loss: 0.07411886751651764
step: 900, loss: 0.03879030421376228
step: 910, loss: 0.03406115248799324
step: 920, loss: 0.07261137664318085
step: 930, loss: 0.05953487381339073
step: 940, loss: 0.12653188407421112
step: 950, loss: 9.451547521166503e-05
step: 960, loss: 0.13895802199840546
step: 970, loss: 0.1405356228351593
step: 980, loss: 0.13144783675670624
step: 990, loss: 0.0016991484444588423
step: 1000, loss: 0.08656315505504608
step: 1010, loss: 0.05009299889206886
step: 1020, loss: 0.020824162289500237
step: 1030, loss: 0.05496710538864136
step: 1040, loss: 0.10526075959205627
step: 1050, loss: 0.032189417630434036
step: 1060, loss: 0.08497918397188187
step: 1070, loss: 0.04277563467621803
epoch 14: dev_f1=0.9306466729147141, f1=0.923943661971831, best_f1=0.9422548120989918
step: 0, loss: 0.00012447728659026325
step: 10, loss: 0.054890070110559464
step: 20, loss: 0.04235858470201492
step: 30, loss: 0.023774782195687294
step: 40, loss: 0.03333164006471634
step: 50, loss: 0.03638005256652832
step: 60, loss: 0.019514335319399834
step: 70, loss: 0.040515393018722534
step: 80, loss: 0.000474028434837237
step: 90, loss: 0.028517624363303185
step: 100, loss: 0.0729336366057396
step: 110, loss: 0.029446251690387726
step: 120, loss: 0.034414924681186676
step: 130, loss: 0.05262187123298645
step: 140, loss: 0.014291340485215187
step: 150, loss: 0.10450571775436401
step: 160, loss: 0.03756042197346687
step: 170, loss: 0.060530055314302444
step: 180, loss: 0.025426998734474182
step: 190, loss: 0.12125995010137558
step: 200, loss: 0.08548397570848465
step: 210, loss: 4.9203317757928744e-05
step: 220, loss: 0.022097205743193626
step: 230, loss: 0.03138785809278488
step: 240, loss: 0.020251363515853882
step: 250, loss: 0.07343137264251709
step: 260, loss: 0.06409292668104172
step: 270, loss: 0.06770191341638565
step: 280, loss: 7.533141615567729e-05
step: 290, loss: 0.0363144688308239
step: 300, loss: 0.10476680099964142
step: 310, loss: 0.003432157449424267
step: 320, loss: 0.061826154589653015
step: 330, loss: 0.07890424132347107
step: 340, loss: 0.0446799173951149
step: 350, loss: 0.024655770510435104
step: 360, loss: 0.049847349524497986
step: 370, loss: 0.04922729358077049
step: 380, loss: 0.07548442482948303
step: 390, loss: 0.09930074214935303
step: 400, loss: 0.013985355384647846
step: 410, loss: 0.016156204044818878
step: 420, loss: 0.07302046567201614
step: 430, loss: 0.012876425869762897
step: 440, loss: 0.05823643133044243
step: 450, loss: 0.04983217641711235
step: 460, loss: 0.09118863940238953
step: 470, loss: 0.021559588611125946
step: 480, loss: 0.1511869579553604
step: 490, loss: 0.012729947455227375
step: 500, loss: 0.22562554478645325
step: 510, loss: 0.07049170136451721
step: 520, loss: 0.0741838812828064
step: 530, loss: 0.019688474014401436
step: 540, loss: 0.1048460528254509
step: 550, loss: 0.05935746431350708
step: 560, loss: 0.0657712072134018
step: 570, loss: 0.12023528665304184
step: 580, loss: 0.013156009837985039
step: 590, loss: 0.04428308829665184
step: 600, loss: 0.04899808019399643
step: 610, loss: 0.05864815413951874
step: 620, loss: 0.012413927353918552
step: 630, loss: 0.02914888598024845
step: 640, loss: 0.07553529739379883
step: 650, loss: 0.05824034661054611
step: 660, loss: 0.0697830468416214
step: 670, loss: 0.06909570842981339
step: 680, loss: 0.03228199854493141
step: 690, loss: 0.10429401695728302
step: 700, loss: 0.035756491124629974
step: 710, loss: 0.07696905732154846
step: 720, loss: 0.07112263888120651
step: 730, loss: 0.09421087801456451
step: 740, loss: 0.039478663355112076
step: 750, loss: 0.022500451654195786
step: 760, loss: 0.061851050704717636
step: 770, loss: 0.01966174691915512
step: 780, loss: 0.19200320541858673
step: 790, loss: 0.11997448652982712
step: 800, loss: 0.01980942115187645
step: 810, loss: 0.04101003706455231
step: 820, loss: 0.05342453718185425
step: 830, loss: 0.026047859340906143
step: 840, loss: 0.0955219715833664
step: 850, loss: 0.0714101493358612
step: 860, loss: 0.022640198469161987
step: 870, loss: 0.032390352338552475
step: 880, loss: 0.05493142083287239
step: 890, loss: 0.1122315302491188
step: 900, loss: 0.0746622383594513
step: 910, loss: 0.02060162089765072
step: 920, loss: 0.03277834877371788
step: 930, loss: 0.13500811159610748
step: 940, loss: 0.0807499960064888
step: 950, loss: 0.09374315291643143
step: 960, loss: 0.033863380551338196
step: 970, loss: 0.06479496508836746
step: 980, loss: 0.05837147682905197
step: 990, loss: 0.013250966556370258
step: 1000, loss: 0.08471040427684784
step: 1010, loss: 0.10600167512893677
step: 1020, loss: 0.017029475420713425
step: 1030, loss: 0.06766946613788605
step: 1040, loss: 0.029152560979127884
step: 1050, loss: 0.04242369160056114
step: 1060, loss: 0.05877089500427246
step: 1070, loss: 0.04007605463266373
epoch 15: dev_f1=0.9363678588016722, f1=0.9302973977695168, best_f1=0.9422548120989918
step: 0, loss: 0.12384766340255737
step: 10, loss: 0.02081466093659401
step: 20, loss: 0.04039919748902321
step: 30, loss: 0.050766658037900925
step: 40, loss: 7.617055234732106e-05
step: 50, loss: 0.10901693254709244
step: 60, loss: 0.06969023495912552
step: 70, loss: 0.014960721135139465
step: 80, loss: 0.006609915290027857
step: 90, loss: 0.05610793083906174
step: 100, loss: 0.0865732878446579
step: 110, loss: 0.08145271986722946
step: 120, loss: 0.02892152965068817
step: 130, loss: 0.056171681731939316
step: 140, loss: 0.05604681000113487
step: 150, loss: 0.022652486339211464
step: 160, loss: 0.012180404737591743
step: 170, loss: 0.0232707429677248
step: 180, loss: 0.03721482679247856
step: 190, loss: 0.1676533967256546
step: 200, loss: 0.04082086682319641
step: 210, loss: 3.986014053225517e-05
step: 220, loss: 0.028179382905364037
step: 230, loss: 0.04912202060222626
step: 240, loss: 0.03884904086589813
step: 250, loss: 0.01759606972336769
step: 260, loss: 1.5429555787704885e-05
step: 270, loss: 0.04710694029927254
step: 280, loss: 0.015467731282114983
step: 290, loss: 0.01634668931365013
step: 300, loss: 0.08056820929050446
step: 310, loss: 0.0333629809319973
step: 320, loss: 0.009238695725798607
step: 330, loss: 0.08912494033575058
step: 340, loss: 0.046465978026390076
step: 350, loss: 0.024529915302991867
step: 360, loss: 0.05512785166501999
step: 370, loss: 0.034667834639549255
step: 380, loss: 0.10359533876180649
step: 390, loss: 0.020708024501800537
step: 400, loss: 0.0025202054530382156
step: 410, loss: 0.01991506852209568
step: 420, loss: 0.04918263480067253
step: 430, loss: 0.0006266835262067616
step: 440, loss: 0.07923045754432678
step: 450, loss: 0.05326223373413086
step: 460, loss: 0.01865350268781185
step: 470, loss: 3.924487828044221e-05
step: 480, loss: 0.035970576107501984
step: 490, loss: 0.07110454887151718
step: 500, loss: 0.04853745549917221
step: 510, loss: 0.0011239777086302638
step: 520, loss: 0.09256315976381302
step: 530, loss: 0.06410154700279236
step: 540, loss: 0.08207998424768448
step: 550, loss: 0.03410394489765167
step: 560, loss: 0.004828073084354401
step: 570, loss: 0.05084561929106712
step: 580, loss: 0.05398373678326607
step: 590, loss: 0.04562387987971306
step: 600, loss: 0.005800498183816671
step: 610, loss: 0.01930849812924862
step: 620, loss: 0.013004004023969173
step: 630, loss: 0.08644958585500717
step: 640, loss: 0.08547157794237137
step: 650, loss: 0.07415778934955597
step: 660, loss: 0.01288582943379879
step: 670, loss: 0.10559238493442535
step: 680, loss: 0.1109180822968483
step: 690, loss: 0.03151953965425491
step: 700, loss: 0.04826092720031738
step: 710, loss: 0.028746729716658592
step: 720, loss: 0.13267403841018677
step: 730, loss: 0.10062301903963089
step: 740, loss: 0.13754092156887054
step: 750, loss: 0.03517279401421547
step: 760, loss: 0.022433489561080933
step: 770, loss: 0.062128279358148575
step: 780, loss: 0.04898082837462425
step: 790, loss: 0.006457735318690538
step: 800, loss: 0.0446256659924984
step: 810, loss: 0.10023438185453415
step: 820, loss: 0.04217391833662987
step: 830, loss: 0.03788108378648758
step: 840, loss: 0.0558091476559639
step: 850, loss: 0.14734351634979248
step: 860, loss: 0.06482820212841034
step: 870, loss: 0.06657799333333969
step: 880, loss: 0.00012198379408800974
step: 890, loss: 0.06241579353809357
step: 900, loss: 0.043632622808218
step: 910, loss: 0.039177849888801575
step: 920, loss: 0.051636070013046265
step: 930, loss: 0.030522091314196587
step: 940, loss: 0.02103458344936371
step: 950, loss: 0.0048985788598656654
step: 960, loss: 0.0627424493432045
step: 970, loss: 0.05917578935623169
step: 980, loss: 0.022759171202778816
step: 990, loss: 0.07820248603820801
step: 1000, loss: 0.04686249792575836
step: 1010, loss: 0.035134896636009216
step: 1020, loss: 0.08853623270988464
step: 1030, loss: 0.05357590317726135
step: 1040, loss: 0.01617780514061451
step: 1050, loss: 0.06319336593151093
step: 1060, loss: 0.059389617294073105
step: 1070, loss: 0.07767368108034134
epoch 16: dev_f1=0.9282739472466451, f1=0.9215777262180975, best_f1=0.9422548120989918
step: 0, loss: 0.01850568875670433
step: 10, loss: 0.00106962607242167
step: 20, loss: 0.00010409094102215022
step: 30, loss: 0.04180555045604706
step: 40, loss: 0.010989422909915447
step: 50, loss: 0.051256489008665085
step: 60, loss: 0.015929849818348885
step: 70, loss: 0.018464233726263046
step: 80, loss: 0.0767982229590416
step: 90, loss: 0.010954399593174458
step: 100, loss: 0.036132361739873886
step: 110, loss: 0.10059933364391327
step: 120, loss: 6.75684932502918e-05
step: 130, loss: 0.05448348820209503
step: 140, loss: 0.012399116531014442
step: 150, loss: 0.05861901491880417
step: 160, loss: 0.035633575171232224
step: 170, loss: 0.06578823924064636
step: 180, loss: 0.035068023949861526
step: 190, loss: 0.021105732768774033
step: 200, loss: 0.01697157323360443
step: 210, loss: 0.03610296919941902
step: 220, loss: 0.0016400981694459915
step: 230, loss: 0.08105770498514175
step: 240, loss: 0.11186639964580536
step: 250, loss: 0.0008546449244022369
step: 260, loss: 0.024596238508820534
step: 270, loss: 0.03863576427102089
step: 280, loss: 0.056999340653419495
step: 290, loss: 0.020023168995976448
step: 300, loss: 0.029482485726475716
step: 310, loss: 0.057322993874549866
step: 320, loss: 0.04086412489414215
step: 330, loss: 0.015559302642941475
step: 340, loss: 0.05145665630698204
step: 350, loss: 0.04891247674822807
step: 360, loss: 0.04494881629943848
step: 370, loss: 0.046947941184043884
step: 380, loss: 0.1989433318376541
step: 390, loss: 0.04888002946972847
step: 400, loss: 0.010036720894277096
step: 410, loss: 0.06402983516454697
step: 420, loss: 0.07617978751659393
step: 430, loss: 0.04128445312380791
step: 440, loss: 0.020281538367271423
step: 450, loss: 0.05080142617225647
step: 460, loss: 0.035642582923173904
step: 470, loss: 0.03559312969446182
step: 480, loss: 0.021275782957673073
step: 490, loss: 0.06341119855642319
step: 500, loss: 0.007612620946019888
step: 510, loss: 0.07817121595144272
step: 520, loss: 0.01606794446706772
step: 530, loss: 0.056746553629636765
step: 540, loss: 0.05161365121603012
step: 550, loss: 0.08924666792154312
step: 560, loss: 0.04450545459985733
step: 570, loss: 0.05443016067147255
step: 580, loss: 0.06714271754026413
step: 590, loss: 0.0777270644903183
step: 600, loss: 0.010063156485557556
step: 610, loss: 0.047665514051914215
step: 620, loss: 0.007800305262207985
step: 630, loss: 0.15643300116062164
step: 640, loss: 0.03842659667134285
step: 650, loss: 0.0489962212741375
step: 660, loss: 0.011773836798965931
step: 670, loss: 0.055691707879304886
step: 680, loss: 0.039539627730846405
step: 690, loss: 0.04948495328426361
step: 700, loss: 0.009802646934986115
step: 710, loss: 0.06006345897912979
step: 720, loss: 1.4711025869473815e-05
step: 730, loss: 0.04778219759464264
step: 740, loss: 0.035882242023944855
step: 750, loss: 0.09395693987607956
step: 760, loss: 0.05776510387659073
step: 770, loss: 0.019387230277061462
step: 780, loss: 0.04008812457323074
step: 790, loss: 0.04499511048197746
step: 800, loss: 0.0758805200457573
step: 810, loss: 0.022457195445895195
step: 820, loss: 0.05263948813080788
step: 830, loss: 0.07773946225643158
step: 840, loss: 0.04313415661454201
step: 850, loss: 0.07284151762723923
step: 860, loss: 0.0004412686685100198
step: 870, loss: 0.005957877729088068
step: 880, loss: 0.11727672815322876
step: 890, loss: 0.02024962194263935
step: 900, loss: 7.110201840987429e-05
step: 910, loss: 0.02837023325264454
step: 920, loss: 0.02568434178829193
step: 930, loss: 0.05040496960282326
step: 940, loss: 0.0883433073759079
step: 950, loss: 0.034325696527957916
step: 960, loss: 0.05195862054824829
step: 970, loss: 0.039688222110271454
step: 980, loss: 0.08096454292535782
step: 990, loss: 0.023467186838388443
step: 1000, loss: 0.04230431467294693
step: 1010, loss: 0.09527244418859482
step: 1020, loss: 0.03408569097518921
step: 1030, loss: 0.024820707738399506
step: 1040, loss: 0.01631447859108448
step: 1050, loss: 0.00017173691594507545
step: 1060, loss: 0.06217414140701294
step: 1070, loss: 0.04144086688756943
epoch 17: dev_f1=0.9310018903591682, f1=0.9272898961284232, best_f1=0.9422548120989918
step: 0, loss: 0.0008371697622351348
step: 10, loss: 0.03833157196640968
step: 20, loss: 0.06423310935497284
step: 30, loss: 0.04629531130194664
step: 40, loss: 5.946977034909651e-05
step: 50, loss: 0.05168968439102173
step: 60, loss: 0.08407755941152573
step: 70, loss: 0.02920178696513176
step: 80, loss: 0.11967753618955612
step: 90, loss: 0.04968302696943283
step: 100, loss: 0.041122399270534515
step: 110, loss: 0.016377445310354233
step: 120, loss: 0.037058841437101364
step: 130, loss: 0.09961587190628052
step: 140, loss: 0.051280539482831955
step: 150, loss: 0.04162829741835594
step: 160, loss: 0.030875716358423233
step: 170, loss: 0.019969424232840538
step: 180, loss: 0.08216439932584763
step: 190, loss: 0.04656475782394409
step: 200, loss: 0.05497689172625542
step: 210, loss: 0.00010768700303742662
step: 220, loss: 0.0707891657948494
step: 230, loss: 0.06925825774669647
step: 240, loss: 0.02473476342856884
step: 250, loss: 0.08880045264959335
step: 260, loss: 0.06395689398050308
step: 270, loss: 0.039294395595788956
step: 280, loss: 0.06218455359339714
step: 290, loss: 0.06308037787675858
step: 300, loss: 0.09815473854541779
step: 310, loss: 0.013470685109496117
step: 320, loss: 0.02557901106774807
step: 330, loss: 0.025348328053951263
step: 340, loss: 0.05815881863236427
step: 350, loss: 0.025974024087190628
step: 360, loss: 0.11074548214673996
step: 370, loss: 0.06748977303504944
step: 380, loss: 0.04710718244314194
step: 390, loss: 0.025555985048413277
step: 400, loss: 0.06683645397424698
step: 410, loss: 0.11367984116077423
step: 420, loss: 0.0032980837859213352
step: 430, loss: 0.07490462064743042
step: 440, loss: 0.00010595563071547076
step: 450, loss: 0.02721303515136242
step: 460, loss: 0.06652697175741196
step: 470, loss: 0.019677093252539635
step: 480, loss: 0.08800391107797623
step: 490, loss: 0.02378552407026291
step: 500, loss: 0.01525096409022808
step: 510, loss: 0.029462916776537895
step: 520, loss: 0.059449780732393265
step: 530, loss: 0.061250120401382446
step: 540, loss: 0.047822024673223495
step: 550, loss: 0.04251981899142265
step: 560, loss: 0.10004023462533951
step: 570, loss: 0.03167491778731346
step: 580, loss: 3.90577879443299e-05
step: 590, loss: 0.029832981526851654
step: 600, loss: 4.9136066081700847e-05
step: 610, loss: 0.0819534957408905
step: 620, loss: 3.5723496694117785e-05
step: 630, loss: 0.05646948516368866
step: 640, loss: 0.05433465540409088
step: 650, loss: 0.03564142808318138
step: 660, loss: 0.026071710512042046
step: 670, loss: 0.020473752170801163
step: 680, loss: 0.056567225605249405
step: 690, loss: 0.023311670869588852
step: 700, loss: 0.033326420933008194
step: 710, loss: 0.05526409670710564
step: 720, loss: 0.029850583523511887
step: 730, loss: 0.017255252227187157
step: 740, loss: 0.042921897023916245
step: 750, loss: 0.055727772414684296
step: 760, loss: 0.029959404841065407
step: 770, loss: 0.023557458072900772
step: 780, loss: 0.062122415751218796
step: 790, loss: 0.05286508426070213
step: 800, loss: 0.010880743153393269
step: 810, loss: 0.03584463521838188
step: 820, loss: 0.0988033339381218
step: 830, loss: 0.052662286907434464
step: 840, loss: 0.012204557657241821
step: 850, loss: 0.08183152973651886
step: 860, loss: 0.007993822917342186
step: 870, loss: 0.134990856051445
step: 880, loss: 0.05711968615651131
step: 890, loss: 0.08501514047384262
step: 900, loss: 0.10239171981811523
step: 910, loss: 0.028518499806523323
step: 920, loss: 0.013506187126040459
step: 930, loss: 0.05855262652039528
step: 940, loss: 0.06080932542681694
step: 950, loss: 0.014239608310163021
step: 960, loss: 0.0369550846517086
step: 970, loss: 0.031988468021154404
step: 980, loss: 0.06433555483818054
step: 990, loss: 0.023651080206036568
step: 1000, loss: 0.21943777799606323
step: 1010, loss: 0.030582081526517868
step: 1020, loss: 0.03553927689790726
step: 1030, loss: 0.03608645871281624
step: 1040, loss: 0.028526317328214645
step: 1050, loss: 0.019504491239786148
step: 1060, loss: 0.029625464230775833
step: 1070, loss: 0.02079530619084835
epoch 18: dev_f1=0.9318394024276377, f1=0.9254571026722925, best_f1=0.9422548120989918
step: 0, loss: 0.026980338618159294
step: 10, loss: 0.031722672283649445
step: 20, loss: 0.036808717995882034
step: 30, loss: 0.04187862575054169
step: 40, loss: 0.03702125325798988
step: 50, loss: 0.026617372408509254
step: 60, loss: 0.06548876315355301
step: 70, loss: 0.032933544367551804
step: 80, loss: 0.06631531566381454
step: 90, loss: 0.04492902755737305
step: 100, loss: 0.07786388695240021
step: 110, loss: 0.011750677600502968
step: 120, loss: 0.010882621631026268
step: 130, loss: 0.003943158779293299
step: 140, loss: 0.10589486360549927
step: 150, loss: 0.0969853550195694
step: 160, loss: 0.023470204323530197
step: 170, loss: 0.009957420639693737
step: 180, loss: 0.09709256142377853
step: 190, loss: 0.08016733825206757
step: 200, loss: 0.04404662549495697
step: 210, loss: 0.045131195336580276
step: 220, loss: 0.006608243100345135
step: 230, loss: 0.07338394969701767
step: 240, loss: 0.0018860561540350318
step: 250, loss: 0.0899994894862175
step: 260, loss: 0.04751323163509369
step: 270, loss: 8.564244490116835e-05
step: 280, loss: 0.019271068274974823
step: 290, loss: 0.052332207560539246
step: 300, loss: 0.0355856716632843
step: 310, loss: 0.025098221376538277
step: 320, loss: 8.54317331686616e-05
step: 330, loss: 0.07259338349103928
step: 340, loss: 0.021230638027191162
step: 350, loss: 0.13310955464839935
step: 360, loss: 1.5537898434558883e-05
step: 370, loss: 0.049912575632333755
step: 380, loss: 0.026755889877676964
step: 390, loss: 0.028444165363907814
step: 400, loss: 0.047765206545591354
step: 410, loss: 0.03200861066579819
step: 420, loss: 0.08442087471485138
step: 430, loss: 0.04501615837216377
step: 440, loss: 0.027822202071547508
step: 450, loss: 8.425255509791896e-05
step: 460, loss: 0.056437887251377106
step: 470, loss: 0.08871425688266754
step: 480, loss: 0.020528554916381836
step: 490, loss: 0.08828845620155334
step: 500, loss: 0.01907539926469326
step: 510, loss: 0.002670613583177328
step: 520, loss: 0.02267294004559517
step: 530, loss: 0.02820599265396595
step: 540, loss: 0.049047645181417465
step: 550, loss: 0.050127945840358734
step: 560, loss: 0.08832433819770813
step: 570, loss: 0.03229852020740509
step: 580, loss: 0.051529545336961746
step: 590, loss: 8.651861571706831e-05
step: 600, loss: 0.01251973770558834
step: 610, loss: 0.057508498430252075
step: 620, loss: 6.609415868297219e-05
step: 630, loss: 6.783139542676508e-05
step: 640, loss: 0.09012991189956665
step: 650, loss: 0.002420943696051836
step: 660, loss: 0.04910936579108238
step: 670, loss: 0.06055249273777008
step: 680, loss: 0.0882212445139885
step: 690, loss: 0.081588514149189
step: 700, loss: 0.00041716714622452855
step: 710, loss: 0.0246259905397892
step: 720, loss: 0.017241939902305603
step: 730, loss: 5.569912536884658e-05
step: 740, loss: 0.058060914278030396
step: 750, loss: 0.055049315094947815
step: 760, loss: 0.05101059004664421
step: 770, loss: 0.049585431814193726
step: 780, loss: 0.06293478608131409
step: 790, loss: 0.00041770649841055274
step: 800, loss: 0.05351385101675987
step: 810, loss: 0.055586762726306915
step: 820, loss: 0.03496245667338371
step: 830, loss: 0.025018339976668358
step: 840, loss: 0.03252550587058067
step: 850, loss: 0.062667615711689
step: 860, loss: 0.022622616961598396
step: 870, loss: 0.0302138514816761
step: 880, loss: 0.02089748904109001
step: 890, loss: 0.04907107353210449
step: 900, loss: 0.04880019277334213
step: 910, loss: 9.682335803518072e-05
step: 920, loss: 0.06799712032079697
step: 930, loss: 0.05148312449455261
step: 940, loss: 0.08128880709409714
step: 950, loss: 0.10617393255233765
step: 960, loss: 0.07866134494543076
step: 970, loss: 0.05036991834640503
step: 980, loss: 8.001601963769644e-05
step: 990, loss: 0.0007216454250738025
step: 1000, loss: 0.0180637426674366
step: 1010, loss: 0.027569791302084923
step: 1020, loss: 0.011144980788230896
step: 1030, loss: 0.09824593365192413
step: 1040, loss: 0.02395600825548172
step: 1050, loss: 0.0609080046415329
step: 1060, loss: 0.1437445431947708
step: 1070, loss: 4.25851067120675e-05
epoch 19: dev_f1=0.9320843091334895, f1=0.9271958666040395, best_f1=0.9422548120989918
step: 0, loss: 0.01645694486796856
step: 10, loss: 0.08890502154827118
step: 20, loss: 0.017647819593548775
step: 30, loss: 2.5387207642779686e-05
step: 40, loss: 0.06684517115354538
step: 50, loss: 0.03372345119714737
step: 60, loss: 0.07216186821460724
step: 70, loss: 0.09791326522827148
step: 80, loss: 0.05061248317360878
step: 90, loss: 0.012596980668604374
step: 100, loss: 0.048709459602832794
step: 110, loss: 0.011699681170284748
step: 120, loss: 0.039978452026844025
step: 130, loss: 0.03235229104757309
step: 140, loss: 0.018490903079509735
step: 150, loss: 7.613313209731132e-05
step: 160, loss: 0.0021599209867417812
step: 170, loss: 4.358700607554056e-05
step: 180, loss: 0.09204759448766708
step: 190, loss: 0.04673748090863228
step: 200, loss: 0.02517934888601303
step: 210, loss: 0.000306827190797776
step: 220, loss: 0.02773021161556244
step: 230, loss: 0.048981670290231705
step: 240, loss: 0.04570893943309784
step: 250, loss: 0.08916690945625305
step: 260, loss: 0.06077846512198448
step: 270, loss: 0.0773998349905014
step: 280, loss: 0.056512217968702316
step: 290, loss: 1.0412095434730873e-05
step: 300, loss: 0.035438619554042816
step: 310, loss: 0.0657549798488617
step: 320, loss: 0.031910620629787445
step: 330, loss: 0.025241294875741005
step: 340, loss: 0.016854574903845787
step: 350, loss: 0.0008702532504685223
step: 360, loss: 3.616627509472892e-05
step: 370, loss: 5.4667263611918315e-05
step: 380, loss: 0.025906018912792206
step: 390, loss: 0.02611837163567543
step: 400, loss: 0.05727975443005562
step: 410, loss: 0.021278169006109238
step: 420, loss: 0.008450828492641449
step: 430, loss: 0.03712509945034981
step: 440, loss: 0.11834294348955154
step: 450, loss: 0.050084393471479416
step: 460, loss: 0.02003404311835766
step: 470, loss: 0.03168834000825882
step: 480, loss: 8.438948134426028e-05
step: 490, loss: 0.057065948843955994
step: 500, loss: 0.07553129643201828
step: 510, loss: 0.06136322394013405
step: 520, loss: 0.08667004853487015
step: 530, loss: 0.000629546819254756
step: 540, loss: 0.09395314007997513
step: 550, loss: 0.08515316247940063
step: 560, loss: 0.0005018800729885697
step: 570, loss: 0.0006257050554268062
step: 580, loss: 0.020239103585481644
step: 590, loss: 0.11341328173875809
step: 600, loss: 0.08020763099193573
step: 610, loss: 0.07802658528089523
step: 620, loss: 2.338557351322379e-05
step: 630, loss: 0.02147776633501053
step: 640, loss: 0.0002646759385243058
step: 650, loss: 1.6006950318114832e-05
step: 660, loss: 0.03340594097971916
step: 670, loss: 0.06056030094623566
step: 680, loss: 0.016197239980101585
step: 690, loss: 0.0021398637909442186
step: 700, loss: 0.04771922156214714
step: 710, loss: 0.047293294221162796
step: 720, loss: 0.05297455936670303
step: 730, loss: 0.04460033029317856
step: 740, loss: 0.0004263240844011307
step: 750, loss: 0.07601878046989441
step: 760, loss: 0.0002991640940308571
step: 770, loss: 0.03418522700667381
step: 780, loss: 0.030396437272429466
step: 790, loss: 0.08220447599887848
step: 800, loss: 0.07382859289646149
step: 810, loss: 0.1429203748703003
step: 820, loss: 0.01853032223880291
step: 830, loss: 0.058495450764894485
step: 840, loss: 0.06591002643108368
step: 850, loss: 0.04416702687740326
step: 860, loss: 0.04515129700303078
step: 870, loss: 0.04854786768555641
step: 880, loss: 0.022555049508810043
step: 890, loss: 0.08396515250205994
step: 900, loss: 0.05292579159140587
step: 910, loss: 0.058196187019348145
step: 920, loss: 0.00198459904640913
step: 930, loss: 0.0825602114200592
step: 940, loss: 0.010106244124472141
step: 950, loss: 0.016780659556388855
step: 960, loss: 0.011899787001311779
step: 970, loss: 0.06368009001016617
step: 980, loss: 0.08961071819067001
step: 990, loss: 0.018650740385055542
step: 1000, loss: 0.06962724030017853
step: 1010, loss: 0.08263000100851059
step: 1020, loss: 0.04857037216424942
step: 1030, loss: 0.03383680060505867
step: 1040, loss: 0.04370317608118057
step: 1050, loss: 0.053296007215976715
step: 1060, loss: 0.022008106112480164
step: 1070, loss: 0.06824290752410889
epoch 20: dev_f1=0.930188679245283, f1=0.92590844738084, best_f1=0.9422548120989918
