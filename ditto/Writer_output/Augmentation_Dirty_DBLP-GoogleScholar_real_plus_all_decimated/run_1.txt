cuda
Device: cuda
step: 0, loss: 0.528052031993866
step: 10, loss: 0.6850741505622864
step: 20, loss: 0.3863489031791687
step: 30, loss: 0.3967371881008148
step: 40, loss: 0.19729995727539062
step: 50, loss: 0.3392663598060608
step: 60, loss: 0.25720325112342834
step: 70, loss: 0.22339420020580292
step: 80, loss: 0.17836563289165497
step: 90, loss: 0.18731139600276947
step: 100, loss: 0.15040452778339386
step: 110, loss: 0.17138013243675232
step: 120, loss: 0.23797543346881866
step: 130, loss: 0.21912524104118347
step: 140, loss: 0.2297779619693756
step: 150, loss: 0.22196315228939056
step: 160, loss: 0.16190755367279053
step: 170, loss: 0.11471739411354065
step: 180, loss: 0.14495043456554413
step: 190, loss: 0.21276283264160156
step: 200, loss: 0.17715243995189667
step: 210, loss: 0.3171330988407135
step: 220, loss: 0.3308775722980499
step: 230, loss: 0.2795073986053467
step: 240, loss: 0.2616843283176422
step: 250, loss: 0.10491647571325302
step: 260, loss: 0.18830274045467377
step: 270, loss: 0.19528135657310486
step: 280, loss: 0.06574605405330658
step: 290, loss: 0.32886064052581787
step: 300, loss: 0.15731973946094513
step: 310, loss: 0.11005672067403793
step: 320, loss: 0.24078941345214844
step: 330, loss: 0.12290577590465546
step: 340, loss: 0.10455309599637985
step: 350, loss: 0.32389721274375916
step: 360, loss: 0.17116980254650116
step: 370, loss: 0.17498186230659485
step: 380, loss: 0.15209263563156128
step: 390, loss: 0.11201370507478714
step: 400, loss: 0.1629095822572708
step: 410, loss: 0.1471381038427353
step: 420, loss: 0.09012705087661743
step: 430, loss: 0.2384183257818222
step: 440, loss: 0.1289004385471344
step: 450, loss: 0.18793310225009918
step: 460, loss: 0.07781890779733658
step: 470, loss: 0.11892640590667725
step: 480, loss: 0.07954800873994827
step: 490, loss: 0.13999198377132416
step: 500, loss: 0.07277070730924606
step: 510, loss: 0.08689600229263306
step: 520, loss: 0.15292420983314514
step: 530, loss: 0.08996683359146118
step: 540, loss: 0.05033847689628601
step: 550, loss: 0.12095653265714645
step: 560, loss: 0.20923228561878204
step: 570, loss: 0.1343807429075241
step: 580, loss: 0.11194203048944473
step: 590, loss: 0.032804034650325775
step: 600, loss: 0.1878373622894287
step: 610, loss: 0.23996569216251373
step: 620, loss: 0.1525951772928238
step: 630, loss: 0.0829920768737793
step: 640, loss: 0.21515005826950073
step: 650, loss: 0.20068855583667755
step: 660, loss: 0.07644124329090118
step: 670, loss: 0.1730017364025116
step: 680, loss: 0.10050741583108902
step: 690, loss: 0.31371185183525085
step: 700, loss: 0.09026539325714111
step: 710, loss: 0.130483940243721
step: 720, loss: 0.04193202406167984
step: 730, loss: 0.09184543043375015
step: 740, loss: 0.054062698036432266
step: 750, loss: 0.16060197353363037
step: 760, loss: 0.06477643549442291
step: 770, loss: 0.06788155436515808
step: 780, loss: 0.20570886135101318
step: 790, loss: 0.21194107830524445
step: 800, loss: 0.2101285755634308
step: 810, loss: 0.12773822247982025
step: 820, loss: 0.08540967106819153
step: 830, loss: 0.15385130047798157
step: 840, loss: 0.21113361418247223
step: 850, loss: 0.21433275938034058
step: 860, loss: 0.09675335884094238
step: 870, loss: 0.1591133177280426
step: 880, loss: 0.17373862862586975
step: 890, loss: 0.11843889951705933
step: 900, loss: 0.09057687968015671
step: 910, loss: 0.17236116528511047
step: 920, loss: 0.22020332515239716
step: 930, loss: 0.0416254997253418
step: 940, loss: 0.24330513179302216
step: 950, loss: 0.08757788687944412
step: 960, loss: 0.12435054779052734
step: 970, loss: 0.08434486389160156
step: 980, loss: 0.14611215889453888
step: 990, loss: 0.15786559879779816
step: 1000, loss: 0.17326392233371735
step: 1010, loss: 0.1868777573108673
step: 1020, loss: 0.107968769967556
step: 1030, loss: 0.059479761868715286
step: 1040, loss: 0.2698345184326172
step: 1050, loss: 0.22244371473789215
step: 1060, loss: 0.21558745205402374
step: 1070, loss: 0.09376349300146103
epoch 1: dev_f1=0.9009174311926605, f1=0.9012178619756428, best_f1=0.9012178619756428
step: 0, loss: 0.13417698442935944
step: 10, loss: 0.07413282990455627
step: 20, loss: 0.043690573424100876
step: 30, loss: 0.11083647608757019
step: 40, loss: 0.11893615126609802
step: 50, loss: 0.24036255478858948
step: 60, loss: 0.0789884701371193
step: 70, loss: 0.08355607837438583
step: 80, loss: 0.08395309746265411
step: 90, loss: 0.07632259279489517
step: 100, loss: 0.06268247216939926
step: 110, loss: 0.0950484350323677
step: 120, loss: 0.19632235169410706
step: 130, loss: 0.17115934193134308
step: 140, loss: 0.10581094026565552
step: 150, loss: 0.07752074301242828
step: 160, loss: 0.3048405349254608
step: 170, loss: 0.08761864900588989
step: 180, loss: 0.09701234102249146
step: 190, loss: 0.09216131269931793
step: 200, loss: 0.0941426232457161
step: 210, loss: 0.16211958229541779
step: 220, loss: 0.11412721872329712
step: 230, loss: 0.12137190252542496
step: 240, loss: 0.2022419571876526
step: 250, loss: 0.15044423937797546
step: 260, loss: 0.04213964566588402
step: 270, loss: 0.028014758601784706
step: 280, loss: 0.11269780993461609
step: 290, loss: 0.09391635656356812
step: 300, loss: 0.17245490849018097
step: 310, loss: 0.19414407014846802
step: 320, loss: 0.14521349966526031
step: 330, loss: 0.053323742002248764
step: 340, loss: 0.09811785072088242
step: 350, loss: 0.06158831715583801
step: 360, loss: 0.1351700723171234
step: 370, loss: 0.15791548788547516
step: 380, loss: 0.21980026364326477
step: 390, loss: 0.058793794363737106
step: 400, loss: 0.1818891316652298
step: 410, loss: 0.16416168212890625
step: 420, loss: 0.13508492708206177
step: 430, loss: 0.09706474095582962
step: 440, loss: 0.1862877458333969
step: 450, loss: 0.16743989288806915
step: 460, loss: 0.07045798748731613
step: 470, loss: 0.1611464023590088
step: 480, loss: 0.17678923904895782
step: 490, loss: 0.15335528552532196
step: 500, loss: 0.1120312288403511
step: 510, loss: 0.21003644168376923
step: 520, loss: 0.05941854789853096
step: 530, loss: 0.18747474253177643
step: 540, loss: 0.14832495152950287
step: 550, loss: 0.2104329615831375
step: 560, loss: 0.19773072004318237
step: 570, loss: 0.13392727077007294
step: 580, loss: 0.1208757534623146
step: 590, loss: 0.14145810902118683
step: 600, loss: 0.054005589336156845
step: 610, loss: 0.08460434526205063
step: 620, loss: 0.1806434988975525
step: 630, loss: 0.24161885678768158
step: 640, loss: 0.08340001106262207
step: 650, loss: 0.15931501984596252
step: 660, loss: 0.06329143047332764
step: 670, loss: 0.09722550213336945
step: 680, loss: 0.03173750266432762
step: 690, loss: 0.08371933549642563
step: 700, loss: 0.09139403700828552
step: 710, loss: 0.16749262809753418
step: 720, loss: 0.03450138121843338
step: 730, loss: 0.10301151126623154
step: 740, loss: 0.12592774629592896
step: 750, loss: 0.0663352683186531
step: 760, loss: 0.11043938994407654
step: 770, loss: 0.08295965194702148
step: 780, loss: 0.1910659223794937
step: 790, loss: 0.07876797020435333
step: 800, loss: 0.1431782841682434
step: 810, loss: 0.04793195798993111
step: 820, loss: 0.11684489995241165
step: 830, loss: 0.2660122811794281
step: 840, loss: 0.10247647762298584
step: 850, loss: 0.06668777018785477
step: 860, loss: 0.07513740658760071
step: 870, loss: 0.22648760676383972
step: 880, loss: 0.029755849391222
step: 890, loss: 0.10609365999698639
step: 900, loss: 0.13336573541164398
step: 910, loss: 0.04553687945008278
step: 920, loss: 0.05619784817099571
step: 930, loss: 0.09275063872337341
step: 940, loss: 0.09218104183673859
step: 950, loss: 0.20169387757778168
step: 960, loss: 0.10513833165168762
step: 970, loss: 0.044336266815662384
step: 980, loss: 0.13988688588142395
step: 990, loss: 0.15985023975372314
step: 1000, loss: 0.14006148278713226
step: 1010, loss: 0.18286985158920288
step: 1020, loss: 0.0795060470700264
step: 1030, loss: 0.1070684865117073
step: 1040, loss: 0.07672347873449326
step: 1050, loss: 0.1840430498123169
step: 1060, loss: 0.15035945177078247
step: 1070, loss: 0.13962368667125702
epoch 2: dev_f1=0.9289316827143513, f1=0.9284085727314182, best_f1=0.9284085727314182
step: 0, loss: 0.11106743663549423
step: 10, loss: 0.06805204600095749
step: 20, loss: 0.18186141550540924
step: 30, loss: 0.09045800566673279
step: 40, loss: 0.10546661913394928
step: 50, loss: 0.08560500293970108
step: 60, loss: 0.12619642913341522
step: 70, loss: 0.10119609534740448
step: 80, loss: 0.06809504330158234
step: 90, loss: 0.10848362743854523
step: 100, loss: 0.17862153053283691
step: 110, loss: 0.18974526226520538
step: 120, loss: 0.05644654855132103
step: 130, loss: 0.09745848178863525
step: 140, loss: 0.06772001832723618
step: 150, loss: 0.14684438705444336
step: 160, loss: 0.08709459006786346
step: 170, loss: 0.058235522359609604
step: 180, loss: 0.14342479407787323
step: 190, loss: 0.0826837569475174
step: 200, loss: 0.20613238215446472
step: 210, loss: 0.1271301507949829
step: 220, loss: 0.150427907705307
step: 230, loss: 0.11233513057231903
step: 240, loss: 0.09438417106866837
step: 250, loss: 0.0686570480465889
step: 260, loss: 0.2586027681827545
step: 270, loss: 0.18826812505722046
step: 280, loss: 0.0960073471069336
step: 290, loss: 0.11773595958948135
step: 300, loss: 0.09224046766757965
step: 310, loss: 0.10151728987693787
step: 320, loss: 0.31053635478019714
step: 330, loss: 0.11852041631937027
step: 340, loss: 0.1030840277671814
step: 350, loss: 0.18737302720546722
step: 360, loss: 0.13184089958667755
step: 370, loss: 0.05807003006339073
step: 380, loss: 0.09358974546194077
step: 390, loss: 0.09093223512172699
step: 400, loss: 0.16954028606414795
step: 410, loss: 0.11903905123472214
step: 420, loss: 0.0706532895565033
step: 430, loss: 0.1193813756108284
step: 440, loss: 0.08900236338376999
step: 450, loss: 0.16288180649280548
step: 460, loss: 0.18280914425849915
step: 470, loss: 0.294712096452713
step: 480, loss: 0.0949617549777031
step: 490, loss: 0.014419317245483398
step: 500, loss: 0.08847188204526901
step: 510, loss: 0.09774564951658249
step: 520, loss: 0.26461830735206604
step: 530, loss: 0.03601749241352081
step: 540, loss: 0.09711507707834244
step: 550, loss: 0.09520632028579712
step: 560, loss: 0.058352433145046234
step: 570, loss: 0.17366886138916016
step: 580, loss: 0.16881604492664337
step: 590, loss: 0.18054138123989105
step: 600, loss: 0.09791471809148788
step: 610, loss: 0.11359427124261856
step: 620, loss: 0.07338310033082962
step: 630, loss: 0.1412670612335205
step: 640, loss: 0.15861204266548157
step: 650, loss: 0.054069746285676956
step: 660, loss: 0.18083231151103973
step: 670, loss: 0.1315908133983612
step: 680, loss: 0.0731235221028328
step: 690, loss: 0.11646150052547455
step: 700, loss: 0.07980769127607346
step: 710, loss: 0.10656311362981796
step: 720, loss: 0.15769802033901215
step: 730, loss: 0.20285865664482117
step: 740, loss: 0.07624644786119461
step: 750, loss: 0.1711423248052597
step: 760, loss: 0.31155750155448914
step: 770, loss: 0.21561822295188904
step: 780, loss: 0.14431877434253693
step: 790, loss: 0.07609913498163223
step: 800, loss: 0.07819042354822159
step: 810, loss: 0.12087351828813553
step: 820, loss: 0.16545790433883667
step: 830, loss: 0.005753260105848312
step: 840, loss: 0.15155085921287537
step: 850, loss: 0.0439254529774189
step: 860, loss: 0.13790571689605713
step: 870, loss: 0.07448852807283401
step: 880, loss: 0.09806971251964569
step: 890, loss: 0.22274544835090637
step: 900, loss: 0.16257844865322113
step: 910, loss: 0.24354009330272675
step: 920, loss: 0.08402640372514725
step: 930, loss: 0.021182293072342873
step: 940, loss: 0.015963783487677574
step: 950, loss: 0.04251422733068466
step: 960, loss: 0.14991797506809235
step: 970, loss: 0.07063734531402588
step: 980, loss: 0.1621350347995758
step: 990, loss: 0.1832842379808426
step: 1000, loss: 0.05376357585191727
step: 1010, loss: 0.15270933508872986
step: 1020, loss: 0.1020873561501503
step: 1030, loss: 0.11639080941677094
step: 1040, loss: 0.10022628307342529
step: 1050, loss: 0.13389600813388824
step: 1060, loss: 0.06249326840043068
step: 1070, loss: 0.09181412309408188
epoch 3: dev_f1=0.9267382174521699, f1=0.9211385907606159, best_f1=0.9284085727314182
step: 0, loss: 0.2843303084373474
step: 10, loss: 0.08495794981718063
step: 20, loss: 0.12576986849308014
step: 30, loss: 0.1392412632703781
step: 40, loss: 0.05369742959737778
step: 50, loss: 0.10536497831344604
step: 60, loss: 0.11761987954378128
step: 70, loss: 0.0412985123693943
step: 80, loss: 0.05055295675992966
step: 90, loss: 0.10009661316871643
step: 100, loss: 0.1123766303062439
step: 110, loss: 0.09780818223953247
step: 120, loss: 0.09267079830169678
step: 130, loss: 0.16194267570972443
step: 140, loss: 0.11440323293209076
step: 150, loss: 0.11824239045381546
step: 160, loss: 0.11809289455413818
step: 170, loss: 0.11533627659082413
step: 180, loss: 0.02304796688258648
step: 190, loss: 0.0906769260764122
step: 200, loss: 0.0827048197388649
step: 210, loss: 0.14477840065956116
step: 220, loss: 0.08690096437931061
step: 230, loss: 0.05881097912788391
step: 240, loss: 0.01908174529671669
step: 250, loss: 0.10855503380298615
step: 260, loss: 0.10513126850128174
step: 270, loss: 0.07450693100690842
step: 280, loss: 0.07579009234905243
step: 290, loss: 0.12299953401088715
step: 300, loss: 0.06302995979785919
step: 310, loss: 0.05715907737612724
step: 320, loss: 0.05619559437036514
step: 330, loss: 0.09175185859203339
step: 340, loss: 0.09753668308258057
step: 350, loss: 0.1279696226119995
step: 360, loss: 0.060384295880794525
step: 370, loss: 0.13269296288490295
step: 380, loss: 0.02449738048017025
step: 390, loss: 0.07815008610486984
step: 400, loss: 0.020357953384518623
step: 410, loss: 0.12181876599788666
step: 420, loss: 0.015776820480823517
step: 430, loss: 0.058475904166698456
step: 440, loss: 0.1188310980796814
step: 450, loss: 0.11078477650880814
step: 460, loss: 0.26103824377059937
step: 470, loss: 0.045662593096494675
step: 480, loss: 0.17381826043128967
step: 490, loss: 0.023989539593458176
step: 500, loss: 0.10010580718517303
step: 510, loss: 0.14881645143032074
step: 520, loss: 0.05981649458408356
step: 530, loss: 0.25770747661590576
step: 540, loss: 0.05748698115348816
step: 550, loss: 0.1135106161236763
step: 560, loss: 0.10972429811954498
step: 570, loss: 0.08324146270751953
step: 580, loss: 0.15889963507652283
step: 590, loss: 0.04702842980623245
step: 600, loss: 0.10291504114866257
step: 610, loss: 0.1065627932548523
step: 620, loss: 0.14964087307453156
step: 630, loss: 0.14032836258411407
step: 640, loss: 0.1262502670288086
step: 650, loss: 0.09677968174219131
step: 660, loss: 0.02732190117239952
step: 670, loss: 0.17099669575691223
step: 680, loss: 0.05103956162929535
step: 690, loss: 0.059987619519233704
step: 700, loss: 0.151959627866745
step: 710, loss: 0.02548340894281864
step: 720, loss: 0.08063991367816925
step: 730, loss: 0.14855560660362244
step: 740, loss: 0.1251969039440155
step: 750, loss: 0.16589736938476562
step: 760, loss: 0.06887718290090561
step: 770, loss: 0.05338266119360924
step: 780, loss: 0.17976737022399902
step: 790, loss: 0.127125084400177
step: 800, loss: 0.06181907281279564
step: 810, loss: 0.07131637632846832
step: 820, loss: 0.2058834284543991
step: 830, loss: 0.03843769058585167
step: 840, loss: 0.041754793375730515
step: 850, loss: 0.05184345692396164
step: 860, loss: 0.06407079845666885
step: 870, loss: 0.27710121870040894
step: 880, loss: 0.18004880845546722
step: 890, loss: 0.15195617079734802
step: 900, loss: 0.0788310170173645
step: 910, loss: 0.08547487109899521
step: 920, loss: 0.08250727504491806
step: 930, loss: 0.07072187960147858
step: 940, loss: 0.06925790011882782
step: 950, loss: 0.10752470791339874
step: 960, loss: 0.07877770066261292
step: 970, loss: 0.11644894629716873
step: 980, loss: 0.05606340989470482
step: 990, loss: 0.09591218084096909
step: 1000, loss: 0.09606149792671204
step: 1010, loss: 0.08403075486421585
step: 1020, loss: 0.20585329830646515
step: 1030, loss: 0.09347925335168839
step: 1040, loss: 0.07405512034893036
step: 1050, loss: 0.0372212678194046
step: 1060, loss: 0.024241620674729347
step: 1070, loss: 0.09693525731563568
epoch 4: dev_f1=0.9213587715216379, f1=0.9167437557816837, best_f1=0.9284085727314182
step: 0, loss: 0.03590712323784828
step: 10, loss: 0.32233428955078125
step: 20, loss: 0.051573846489191055
step: 30, loss: 0.07873090356588364
step: 40, loss: 0.10744393616914749
step: 50, loss: 0.1386924386024475
step: 60, loss: 0.0202876515686512
step: 70, loss: 0.20346423983573914
step: 80, loss: 0.12909026443958282
step: 90, loss: 0.0924176350235939
step: 100, loss: 0.0785336121916771
step: 110, loss: 0.13314689695835114
step: 120, loss: 0.09186355769634247
step: 130, loss: 0.21468956768512726
step: 140, loss: 0.20446814596652985
step: 150, loss: 0.08790715783834457
step: 160, loss: 0.026914721354842186
step: 170, loss: 0.09431853890419006
step: 180, loss: 0.2595534026622772
step: 190, loss: 0.07913479954004288
step: 200, loss: 0.06638827919960022
step: 210, loss: 0.05990247055888176
step: 220, loss: 0.040874235332012177
step: 230, loss: 0.039432257413864136
step: 240, loss: 0.10309341549873352
step: 250, loss: 0.15790535509586334
step: 260, loss: 0.15280070900917053
step: 270, loss: 0.20770898461341858
step: 280, loss: 0.07872249186038971
step: 290, loss: 0.09717980772256851
step: 300, loss: 0.0724363848567009
step: 310, loss: 0.03923245146870613
step: 320, loss: 0.1330002248287201
step: 330, loss: 0.14070026576519012
step: 340, loss: 0.1258281022310257
step: 350, loss: 0.06643988192081451
step: 360, loss: 0.11604364216327667
step: 370, loss: 0.12211348861455917
step: 380, loss: 0.11747575551271439
step: 390, loss: 0.07161317020654678
step: 400, loss: 0.0795738622546196
step: 410, loss: 0.1358088105916977
step: 420, loss: 0.08196881413459778
step: 430, loss: 0.08581134676933289
step: 440, loss: 0.1523837298154831
step: 450, loss: 0.15082384645938873
step: 460, loss: 0.09932837635278702
step: 470, loss: 0.07936513423919678
step: 480, loss: 0.1040983647108078
step: 490, loss: 0.010261597111821175
step: 500, loss: 0.18943245708942413
step: 510, loss: 0.07864163815975189
step: 520, loss: 0.14766734838485718
step: 530, loss: 0.0688367486000061
step: 540, loss: 0.15556733310222626
step: 550, loss: 0.14123055338859558
step: 560, loss: 0.11014523357152939
step: 570, loss: 0.059881243854761124
step: 580, loss: 0.10171457380056381
step: 590, loss: 0.17502765357494354
step: 600, loss: 0.07423528283834457
step: 610, loss: 0.0850168839097023
step: 620, loss: 0.1388012319803238
step: 630, loss: 0.09022081643342972
step: 640, loss: 0.03669366613030434
step: 650, loss: 0.0647815614938736
step: 660, loss: 0.11952033638954163
step: 670, loss: 0.061275187879800797
step: 680, loss: 0.09419578313827515
step: 690, loss: 0.03365123271942139
step: 700, loss: 0.03245983272790909
step: 710, loss: 0.2801368832588196
step: 720, loss: 0.10700266808271408
step: 730, loss: 0.07393927127122879
step: 740, loss: 0.1804797202348709
step: 750, loss: 0.14087706804275513
step: 760, loss: 0.08490321785211563
step: 770, loss: 0.0993364155292511
step: 780, loss: 0.006895100232213736
step: 790, loss: 0.06973804533481598
step: 800, loss: 0.04607471823692322
step: 810, loss: 0.03769760951399803
step: 820, loss: 0.06757152080535889
step: 830, loss: 0.09216384589672089
step: 840, loss: 0.13403292000293732
step: 850, loss: 0.09881508350372314
step: 860, loss: 0.036802101880311966
step: 870, loss: 0.09713682532310486
step: 880, loss: 0.054149750620126724
step: 890, loss: 0.17185141146183014
step: 900, loss: 0.010701289400458336
step: 910, loss: 0.021946685388684273
step: 920, loss: 0.08724448829889297
step: 930, loss: 0.15108910202980042
step: 940, loss: 0.044218603521585464
step: 950, loss: 0.05907990410923958
step: 960, loss: 0.0596177875995636
step: 970, loss: 0.06884916126728058
step: 980, loss: 0.05782114714384079
step: 990, loss: 0.20369887351989746
step: 1000, loss: 0.07133860886096954
step: 1010, loss: 0.14054353535175323
step: 1020, loss: 0.04527556896209717
step: 1030, loss: 0.03166772425174713
step: 1040, loss: 0.14026276767253876
step: 1050, loss: 0.08891890943050385
step: 1060, loss: 0.06983622908592224
step: 1070, loss: 0.04235648736357689
epoch 5: dev_f1=0.9354691075514875, f1=0.9337016574585636, best_f1=0.9337016574585636
step: 0, loss: 0.09085217863321304
step: 10, loss: 0.12997528910636902
step: 20, loss: 0.054986968636512756
step: 30, loss: 0.003870629006996751
step: 40, loss: 0.05336432904005051
step: 50, loss: 0.08738033473491669
step: 60, loss: 0.09963713586330414
step: 70, loss: 0.021431677043437958
step: 80, loss: 0.08007951825857162
step: 90, loss: 0.016423098742961884
step: 100, loss: 0.05694575235247612
step: 110, loss: 0.06026983633637428
step: 120, loss: 0.1032916009426117
step: 130, loss: 0.11464710533618927
step: 140, loss: 0.10144585371017456
step: 150, loss: 0.1465521901845932
step: 160, loss: 0.06930436193943024
step: 170, loss: 0.06573959439992905
step: 180, loss: 0.09576036781072617
step: 190, loss: 0.204987570643425
step: 200, loss: 0.10663993656635284
step: 210, loss: 0.11048310995101929
step: 220, loss: 0.0352533683180809
step: 230, loss: 0.08033823221921921
step: 240, loss: 0.12986691296100616
step: 250, loss: 0.07726170122623444
step: 260, loss: 0.04273425415158272
step: 270, loss: 0.013857905752956867
step: 280, loss: 0.09060515463352203
step: 290, loss: 0.009195425547659397
step: 300, loss: 0.059455886483192444
step: 310, loss: 0.0950460433959961
step: 320, loss: 0.11593504995107651
step: 330, loss: 0.027622636407613754
step: 340, loss: 0.08627276867628098
step: 350, loss: 0.11532671004533768
step: 360, loss: 0.06523963063955307
step: 370, loss: 0.20563286542892456
step: 380, loss: 0.07586006075143814
step: 390, loss: 0.0147410798817873
step: 400, loss: 0.07702885568141937
step: 410, loss: 0.1486484855413437
step: 420, loss: 0.19663597643375397
step: 430, loss: 0.11651306599378586
step: 440, loss: 0.06257925927639008
step: 450, loss: 0.04792763292789459
step: 460, loss: 0.11032255738973618
step: 470, loss: 0.0558902844786644
step: 480, loss: 0.05116259679198265
step: 490, loss: 0.0683278739452362
step: 500, loss: 0.0969989150762558
step: 510, loss: 0.026179414242506027
step: 520, loss: 0.035546086728572845
step: 530, loss: 0.06021775305271149
step: 540, loss: 0.10691455006599426
step: 550, loss: 0.12655389308929443
step: 560, loss: 0.06826186180114746
step: 570, loss: 0.07494526356458664
step: 580, loss: 0.05266205593943596
step: 590, loss: 0.06963378190994263
step: 600, loss: 0.09920719265937805
step: 610, loss: 0.0512707382440567
step: 620, loss: 0.2124895304441452
step: 630, loss: 0.2192561775445938
step: 640, loss: 0.07839681953191757
step: 650, loss: 0.07628194987773895
step: 660, loss: 0.17029978334903717
step: 670, loss: 0.057600297033786774
step: 680, loss: 0.03892911970615387
step: 690, loss: 0.08291509002447128
step: 700, loss: 0.11624611169099808
step: 710, loss: 0.16603976488113403
step: 720, loss: 0.09316331893205643
step: 730, loss: 0.06580829620361328
step: 740, loss: 0.0209733247756958
step: 750, loss: 0.12667077779769897
step: 760, loss: 0.1930178999900818
step: 770, loss: 0.06519988179206848
step: 780, loss: 0.08527913689613342
step: 790, loss: 0.2026025950908661
step: 800, loss: 0.07576850056648254
step: 810, loss: 0.026902643963694572
step: 820, loss: 0.14896151423454285
step: 830, loss: 0.12557706236839294
step: 840, loss: 0.009603211656212807
step: 850, loss: 0.11039329320192337
step: 860, loss: 0.03741750493645668
step: 870, loss: 0.08857597410678864
step: 880, loss: 0.11209611594676971
step: 890, loss: 0.07157130539417267
step: 900, loss: 0.18707077205181122
step: 910, loss: 0.12490323185920715
step: 920, loss: 0.10059944540262222
step: 930, loss: 0.029769735410809517
step: 940, loss: 0.12289150059223175
step: 950, loss: 0.1052129939198494
step: 960, loss: 0.160744771361351
step: 970, loss: 0.014343888498842716
step: 980, loss: 0.16465002298355103
step: 990, loss: 0.09878332167863846
step: 1000, loss: 0.12958462536334991
step: 1010, loss: 0.09296612441539764
step: 1020, loss: 0.04018159955739975
step: 1030, loss: 0.1801500767469406
step: 1040, loss: 0.03453171253204346
step: 1050, loss: 0.07789112627506256
step: 1060, loss: 0.1177162230014801
step: 1070, loss: 0.06355483084917068
epoch 6: dev_f1=0.9358560221504384, f1=0.9289012003693443, best_f1=0.9289012003693443
step: 0, loss: 0.04911577329039574
step: 10, loss: 0.057953815907239914
step: 20, loss: 0.09887318313121796
step: 30, loss: 0.0961313471198082
step: 40, loss: 0.06794463098049164
step: 50, loss: 0.08137933909893036
step: 60, loss: 0.08062275499105453
step: 70, loss: 0.0035820503253489733
step: 80, loss: 0.024724295362830162
step: 90, loss: 0.0926201120018959
step: 100, loss: 0.0057205012999475
step: 110, loss: 0.0848567858338356
step: 120, loss: 0.08453459292650223
step: 130, loss: 0.07955846190452576
step: 140, loss: 0.09400849789381027
step: 150, loss: 0.008789490908384323
step: 160, loss: 0.13923382759094238
step: 170, loss: 0.07323360443115234
step: 180, loss: 0.05600319802761078
step: 190, loss: 0.12839066982269287
step: 200, loss: 0.01283823698759079
step: 210, loss: 0.11385554820299149
step: 220, loss: 0.07625328004360199
step: 230, loss: 0.12989476323127747
step: 240, loss: 0.025754624977707863
step: 250, loss: 0.007690428756177425
step: 260, loss: 0.13872744143009186
step: 270, loss: 0.027050452306866646
step: 280, loss: 0.12837429344654083
step: 290, loss: 0.1135062649846077
step: 300, loss: 0.04092232882976532
step: 310, loss: 0.09466070681810379
step: 320, loss: 0.15221509337425232
step: 330, loss: 0.056840647011995316
step: 340, loss: 0.05787193402647972
step: 350, loss: 0.14865460991859436
step: 360, loss: 0.12799417972564697
step: 370, loss: 0.03689176216721535
step: 380, loss: 0.045384738594293594
step: 390, loss: 0.0561542734503746
step: 400, loss: 0.1430208534002304
step: 410, loss: 0.12444034963846207
step: 420, loss: 0.03490651771426201
step: 430, loss: 0.12876953184604645
step: 440, loss: 0.08092634379863739
step: 450, loss: 0.044960808008909225
step: 460, loss: 0.09993603825569153
step: 470, loss: 0.1457207351922989
step: 480, loss: 0.03625434637069702
step: 490, loss: 0.07942205667495728
step: 500, loss: 0.01789350062608719
step: 510, loss: 0.2822963297367096
step: 520, loss: 0.006266854703426361
step: 530, loss: 0.027736030519008636
step: 540, loss: 0.09453806281089783
step: 550, loss: 0.11491992324590683
step: 560, loss: 0.14789175987243652
step: 570, loss: 0.04567418247461319
step: 580, loss: 0.06193792074918747
step: 590, loss: 0.13632002472877502
step: 600, loss: 0.07040292024612427
step: 610, loss: 0.13192908465862274
step: 620, loss: 0.028931178152561188
step: 630, loss: 0.05628351494669914
step: 640, loss: 0.13959328830242157
step: 650, loss: 0.04610700532793999
step: 660, loss: 0.07915977388620377
step: 670, loss: 0.12935680150985718
step: 680, loss: 0.10379642248153687
step: 690, loss: 0.024050312116742134
step: 700, loss: 0.049184586852788925
step: 710, loss: 0.06892001628875732
step: 720, loss: 0.08479280024766922
step: 730, loss: 0.06881813704967499
step: 740, loss: 0.027395403012633324
step: 750, loss: 0.033072568476200104
step: 760, loss: 0.15914319455623627
step: 770, loss: 0.08030316978693008
step: 780, loss: 0.198116272687912
step: 790, loss: 0.12101070582866669
step: 800, loss: 0.0959995910525322
step: 810, loss: 0.13871914148330688
step: 820, loss: 0.11526287347078323
step: 830, loss: 0.09174040704965591
step: 840, loss: 0.06327880173921585
step: 850, loss: 0.05939193442463875
step: 860, loss: 0.14677312970161438
step: 870, loss: 0.10296188294887543
step: 880, loss: 0.08236861228942871
step: 890, loss: 0.01737251691520214
step: 900, loss: 0.0850856602191925
step: 910, loss: 0.0752023458480835
step: 920, loss: 0.08526401221752167
step: 930, loss: 0.10539088398218155
step: 940, loss: 0.1645258069038391
step: 950, loss: 0.14154289662837982
step: 960, loss: 0.0890934020280838
step: 970, loss: 0.14028003811836243
step: 980, loss: 0.08651379495859146
step: 990, loss: 0.07592348009347916
step: 1000, loss: 0.02527092769742012
step: 1010, loss: 0.07928624004125595
step: 1020, loss: 0.11872658878564835
step: 1030, loss: 0.021017974242568016
step: 1040, loss: 0.21049004793167114
step: 1050, loss: 0.022650379687547684
step: 1060, loss: 0.17725735902786255
step: 1070, loss: 0.12503762543201447
epoch 7: dev_f1=0.9305108145421077, f1=0.9229349330872173, best_f1=0.9289012003693443
step: 0, loss: 0.04750761017203331
step: 10, loss: 0.14137889444828033
step: 20, loss: 0.11145686358213425
step: 30, loss: 0.007643784862011671
step: 40, loss: 0.11201764643192291
step: 50, loss: 0.08573303371667862
step: 60, loss: 0.016721246764063835
step: 70, loss: 0.11645521968603134
step: 80, loss: 0.0522553026676178
step: 90, loss: 0.055845245718955994
step: 100, loss: 0.07858949154615402
step: 110, loss: 0.0035979836247861385
step: 120, loss: 0.07650463283061981
step: 130, loss: 0.0831492692232132
step: 140, loss: 0.1163398027420044
step: 150, loss: 0.09699711203575134
step: 160, loss: 0.030298398807644844
step: 170, loss: 0.007658621296286583
step: 180, loss: 0.10504696518182755
step: 190, loss: 0.13899731636047363
step: 200, loss: 0.030161039903759956
step: 210, loss: 0.12164945900440216
step: 220, loss: 0.11881697177886963
step: 230, loss: 0.12914280593395233
step: 240, loss: 0.07772524654865265
step: 250, loss: 0.07430966198444366
step: 260, loss: 0.10174844413995743
step: 270, loss: 0.10640617460012436
step: 280, loss: 0.06599646806716919
step: 290, loss: 0.14690586924552917
step: 300, loss: 0.08346457034349442
step: 310, loss: 0.038517896085977554
step: 320, loss: 0.005192727781832218
step: 330, loss: 0.018155403435230255
step: 340, loss: 0.24846477806568146
step: 350, loss: 0.017056189477443695
step: 360, loss: 0.13357292115688324
step: 370, loss: 0.1263519525527954
step: 380, loss: 0.008761407807469368
step: 390, loss: 0.06340868026018143
step: 400, loss: 0.11366696655750275
step: 410, loss: 0.013806728646159172
step: 420, loss: 0.0596872977912426
step: 430, loss: 0.1133197695016861
step: 440, loss: 0.021867597475647926
step: 450, loss: 0.03986957669258118
step: 460, loss: 0.07068274170160294
step: 470, loss: 0.16982276737689972
step: 480, loss: 0.2288995087146759
step: 490, loss: 0.07418487221002579
step: 500, loss: 0.05643366649746895
step: 510, loss: 0.039354193955659866
step: 520, loss: 0.02064874768257141
step: 530, loss: 0.04071178659796715
step: 540, loss: 0.02507202886044979
step: 550, loss: 0.05417778715491295
step: 560, loss: 0.08723537623882294
step: 570, loss: 0.13764360547065735
step: 580, loss: 0.04420052096247673
step: 590, loss: 0.053768180310726166
step: 600, loss: 0.24808701872825623
step: 610, loss: 0.12823693454265594
step: 620, loss: 0.0586063377559185
step: 630, loss: 0.057606328278779984
step: 640, loss: 0.03899376839399338
step: 650, loss: 0.08918877691030502
step: 660, loss: 0.05828994885087013
step: 670, loss: 0.01343143917620182
step: 680, loss: 0.01519879698753357
step: 690, loss: 0.17413552105426788
step: 700, loss: 0.03112032637000084
step: 710, loss: 0.06856328994035721
step: 720, loss: 0.01836274564266205
step: 730, loss: 0.054489221423864365
step: 740, loss: 0.06897307932376862
step: 750, loss: 0.017658578231930733
step: 760, loss: 0.059308480471372604
step: 770, loss: 0.015743546187877655
step: 780, loss: 0.045976120978593826
step: 790, loss: 0.20970995724201202
step: 800, loss: 0.007968400605022907
step: 810, loss: 0.035405777394771576
step: 820, loss: 0.06416897475719452
step: 830, loss: 0.08034418523311615
step: 840, loss: 0.07567070424556732
step: 850, loss: 0.01017417199909687
step: 860, loss: 0.04287176579236984
step: 870, loss: 0.1222267895936966
step: 880, loss: 0.046348556876182556
step: 890, loss: 0.07137851417064667
step: 900, loss: 0.06894358992576599
step: 910, loss: 0.14811156690120697
step: 920, loss: 0.07838232815265656
step: 930, loss: 0.11359190940856934
step: 940, loss: 0.11130162328481674
step: 950, loss: 0.07862882316112518
step: 960, loss: 0.04262351989746094
step: 970, loss: 0.009660796262323856
step: 980, loss: 0.03839163854718208
step: 990, loss: 0.07486546039581299
step: 1000, loss: 0.10913952440023422
step: 1010, loss: 0.062079187482595444
step: 1020, loss: 0.07981161028146744
step: 1030, loss: 0.0312295313924551
step: 1040, loss: 0.047172434628009796
step: 1050, loss: 0.032057005912065506
step: 1060, loss: 0.0438518151640892
step: 1070, loss: 0.10582751780748367
epoch 8: dev_f1=0.9338374291115311, f1=0.9298162976919454, best_f1=0.9289012003693443
step: 0, loss: 0.07097400724887848
step: 10, loss: 0.183759406208992
step: 20, loss: 0.0892343670129776
step: 30, loss: 0.13748003542423248
step: 40, loss: 0.1366262137889862
step: 50, loss: 0.04929094389081001
step: 60, loss: 0.013623671606183052
step: 70, loss: 0.06690286844968796
step: 80, loss: 0.05241517722606659
step: 90, loss: 0.06729509681463242
step: 100, loss: 0.08564296364784241
step: 110, loss: 0.06349138915538788
step: 120, loss: 0.14992228150367737
step: 130, loss: 0.07965458184480667
step: 140, loss: 0.04557455703616142
step: 150, loss: 0.06263909488916397
step: 160, loss: 0.051576871424913406
step: 170, loss: 0.08856306970119476
step: 180, loss: 0.06709864735603333
step: 190, loss: 0.02182961441576481
step: 200, loss: 0.06845216453075409
step: 210, loss: 0.06324329227209091
step: 220, loss: 0.02732766792178154
step: 230, loss: 0.11839808523654938
step: 240, loss: 0.0887332558631897
step: 250, loss: 0.06859558075666428
step: 260, loss: 0.027768336236476898
step: 270, loss: 0.0375673845410347
step: 280, loss: 0.016339214518666267
step: 290, loss: 0.11803595721721649
step: 300, loss: 0.13681422173976898
step: 310, loss: 0.036335382610559464
step: 320, loss: 0.008758334442973137
step: 330, loss: 0.06844042241573334
step: 340, loss: 0.052154190838336945
step: 350, loss: 0.027944914996623993
step: 360, loss: 0.0703178197145462
step: 370, loss: 0.11430300772190094
step: 380, loss: 0.13507047295570374
step: 390, loss: 0.03167736530303955
step: 400, loss: 0.10740549117326736
step: 410, loss: 0.06880276650190353
step: 420, loss: 0.08774098753929138
step: 430, loss: 0.19601376354694366
step: 440, loss: 0.1550987809896469
step: 450, loss: 0.0696844533085823
step: 460, loss: 0.054483700543642044
step: 470, loss: 0.08502805233001709
step: 480, loss: 0.047545745968818665
step: 490, loss: 0.060765281319618225
step: 500, loss: 0.03389674425125122
step: 510, loss: 0.16575412452220917
step: 520, loss: 0.06770095229148865
step: 530, loss: 0.053940363228321075
step: 540, loss: 0.039373088628053665
step: 550, loss: 0.09177137166261673
step: 560, loss: 0.010358725674450397
step: 570, loss: 0.01422131434082985
step: 580, loss: 0.07834666222333908
step: 590, loss: 0.05964614450931549
step: 600, loss: 0.0812668576836586
step: 610, loss: 0.0021688505075871944
step: 620, loss: 0.011945409700274467
step: 630, loss: 0.014612937346100807
step: 640, loss: 0.05176939070224762
step: 650, loss: 0.1024254709482193
step: 660, loss: 0.03989478573203087
step: 670, loss: 0.13414514064788818
step: 680, loss: 0.1476525515317917
step: 690, loss: 0.125919371843338
step: 700, loss: 0.10548339039087296
step: 710, loss: 0.04072093591094017
step: 720, loss: 0.06642533838748932
step: 730, loss: 0.0899701863527298
step: 740, loss: 0.08615123480558395
step: 750, loss: 0.07480931282043457
step: 760, loss: 0.002571500837802887
step: 770, loss: 0.06929262727499008
step: 780, loss: 0.06437059491872787
step: 790, loss: 0.11824967712163925
step: 800, loss: 0.040908608585596085
step: 810, loss: 0.08219730854034424
step: 820, loss: 0.12738703191280365
step: 830, loss: 0.10540833324193954
step: 840, loss: 0.01795988343656063
step: 850, loss: 0.04413037747144699
step: 860, loss: 0.1459072381258011
step: 870, loss: 0.06560158729553223
step: 880, loss: 0.0485939122736454
step: 890, loss: 0.030045898631215096
step: 900, loss: 0.10182760655879974
step: 910, loss: 0.16785156726837158
step: 920, loss: 0.1116059347987175
step: 930, loss: 0.202616348862648
step: 940, loss: 0.09708619117736816
step: 950, loss: 0.1288720965385437
step: 960, loss: 0.0820658728480339
step: 970, loss: 0.026261597871780396
step: 980, loss: 0.020687362179160118
step: 990, loss: 0.13658583164215088
step: 1000, loss: 0.0791262537240982
step: 1010, loss: 0.061440106481313705
step: 1020, loss: 0.0989832878112793
step: 1030, loss: 0.03358174487948418
step: 1040, loss: 0.10986559092998505
step: 1050, loss: 0.07229654490947723
step: 1060, loss: 0.08111520856618881
step: 1070, loss: 0.13456600904464722
epoch 9: dev_f1=0.9276039234002802, f1=0.9286713286713286, best_f1=0.9289012003693443
step: 0, loss: 0.0403340607881546
step: 10, loss: 0.05318399891257286
step: 20, loss: 0.05701771005988121
step: 30, loss: 0.10899822413921356
step: 40, loss: 0.061316851526498795
step: 50, loss: 0.07003942131996155
step: 60, loss: 0.007545135449618101
step: 70, loss: 0.026274723932147026
step: 80, loss: 0.06247276812791824
step: 90, loss: 0.07456961274147034
step: 100, loss: 0.08544763177633286
step: 110, loss: 0.06036171317100525
step: 120, loss: 0.2084597498178482
step: 130, loss: 0.04906202852725983
step: 140, loss: 0.09409049153327942
step: 150, loss: 0.038566190749406815
step: 160, loss: 0.11669965088367462
step: 170, loss: 0.030153648927807808
step: 180, loss: 0.19908885657787323
step: 190, loss: 0.09383495897054672
step: 200, loss: 0.09751193970441818
step: 210, loss: 0.12266016006469727
step: 220, loss: 0.05015028268098831
step: 230, loss: 0.0974573940038681
step: 240, loss: 0.147091343998909
step: 250, loss: 0.06795012950897217
step: 260, loss: 0.10688868165016174
step: 270, loss: 0.10251174122095108
step: 280, loss: 0.08142878860235214
step: 290, loss: 0.060276828706264496
step: 300, loss: 0.05158282443881035
step: 310, loss: 0.038680724799633026
step: 320, loss: 0.025365624576807022
step: 330, loss: 0.12060929089784622
step: 340, loss: 0.09058668464422226
step: 350, loss: 0.02356468141078949
step: 360, loss: 0.03412169963121414
step: 370, loss: 0.003917774185538292
step: 380, loss: 0.162216454744339
step: 390, loss: 0.053366437554359436
step: 400, loss: 0.058736301958560944
step: 410, loss: 0.037175584584474564
step: 420, loss: 0.11647018045186996
step: 430, loss: 0.08697645366191864
step: 440, loss: 0.11665424704551697
step: 450, loss: 0.033631451427936554
step: 460, loss: 0.03112444281578064
step: 470, loss: 0.1994573175907135
step: 480, loss: 0.047584448009729385
step: 490, loss: 0.11349935084581375
step: 500, loss: 0.16378259658813477
step: 510, loss: 0.11255402117967606
step: 520, loss: 0.12374374270439148
step: 530, loss: 0.10772205144166946
step: 540, loss: 0.11248156428337097
step: 550, loss: 0.1042056679725647
step: 560, loss: 0.06406360864639282
step: 570, loss: 0.09577061980962753
step: 580, loss: 0.08869461715221405
step: 590, loss: 0.1846330463886261
step: 600, loss: 0.08677894622087479
step: 610, loss: 0.012027399614453316
step: 620, loss: 0.06630001962184906
step: 630, loss: 0.026013541966676712
step: 640, loss: 0.07117092609405518
step: 650, loss: 0.056440047919750214
step: 660, loss: 0.0919475257396698
step: 670, loss: 0.0546177476644516
step: 680, loss: 0.05629681423306465
step: 690, loss: 0.0959448367357254
step: 700, loss: 0.1069750189781189
step: 710, loss: 0.0486450232565403
step: 720, loss: 0.12202698737382889
step: 730, loss: 0.07053349167108536
step: 740, loss: 0.08244650065898895
step: 750, loss: 0.11727932840585709
step: 760, loss: 0.049274224787950516
step: 770, loss: 0.3295227885246277
step: 780, loss: 0.05640603229403496
step: 790, loss: 0.0317421481013298
step: 800, loss: 0.08417482674121857
step: 810, loss: 0.04596403241157532
step: 820, loss: 0.04066179692745209
step: 830, loss: 0.020179664716124535
step: 840, loss: 0.07296962291002274
step: 850, loss: 0.06257502734661102
step: 860, loss: 0.0374186746776104
step: 870, loss: 0.002948685083538294
step: 880, loss: 0.057805385440588
step: 890, loss: 0.07234876602888107
step: 900, loss: 0.05785611271858215
step: 910, loss: 0.047856565564870834
step: 920, loss: 0.10818318277597427
step: 930, loss: 0.0438714399933815
step: 940, loss: 0.06290201097726822
step: 950, loss: 0.0734548419713974
step: 960, loss: 0.09615568071603775
step: 970, loss: 0.05785546079277992
step: 980, loss: 0.039188891649246216
step: 990, loss: 0.12149146944284439
step: 1000, loss: 0.06502868235111237
step: 1010, loss: 0.019254442304372787
step: 1020, loss: 0.04780197516083717
step: 1030, loss: 0.07985319197177887
step: 1040, loss: 0.05888120085000992
step: 1050, loss: 0.02136978693306446
step: 1060, loss: 0.22739195823669434
step: 1070, loss: 0.0472799651324749
epoch 10: dev_f1=0.9309865678554886, f1=0.9279778393351801, best_f1=0.9289012003693443
step: 0, loss: 0.05531642585992813
step: 10, loss: 0.11055013537406921
step: 20, loss: 0.031848665326833725
step: 30, loss: 0.022089136764407158
step: 40, loss: 0.07697086781263351
step: 50, loss: 0.07158082723617554
step: 60, loss: 0.16043628752231598
step: 70, loss: 0.03345412388443947
step: 80, loss: 0.14088013768196106
step: 90, loss: 0.023781822994351387
step: 100, loss: 0.027505749836564064
step: 110, loss: 0.0870562270283699
step: 120, loss: 0.028818732127547264
step: 130, loss: 0.07444707304239273
step: 140, loss: 0.04039382562041283
step: 150, loss: 0.035460617393255234
step: 160, loss: 0.049530334770679474
step: 170, loss: 0.0006657931953668594
step: 180, loss: 0.043017320334911346
step: 190, loss: 0.0925845056772232
step: 200, loss: 0.08236200362443924
step: 210, loss: 0.07991506159305573
step: 220, loss: 0.027656400576233864
step: 230, loss: 0.05998529866337776
step: 240, loss: 0.13758578896522522
step: 250, loss: 0.04244563728570938
step: 260, loss: 0.07883895933628082
step: 270, loss: 0.14575321972370148
step: 280, loss: 0.015710925683379173
step: 290, loss: 0.06538019329309464
step: 300, loss: 0.14308084547519684
step: 310, loss: 0.0636746808886528
step: 320, loss: 0.0020693959668278694
step: 330, loss: 0.0634729266166687
step: 340, loss: 0.04881855100393295
step: 350, loss: 0.13030311465263367
step: 360, loss: 0.09678858518600464
step: 370, loss: 0.04201070964336395
step: 380, loss: 0.023911843076348305
step: 390, loss: 0.10680226236581802
step: 400, loss: 0.016192156821489334
step: 410, loss: 0.048598628491163254
step: 420, loss: 0.2506634593009949
step: 430, loss: 0.17660224437713623
step: 440, loss: 0.03809312731027603
step: 450, loss: 0.07287202030420303
step: 460, loss: 0.0024758463259786367
step: 470, loss: 0.08362757414579391
step: 480, loss: 0.10224156081676483
step: 490, loss: 0.1070089116692543
step: 500, loss: 0.16847121715545654
step: 510, loss: 0.11878334730863571
step: 520, loss: 0.08487056940793991
step: 530, loss: 0.03261759132146835
step: 540, loss: 0.08385735005140305
step: 550, loss: 0.12709447741508484
step: 560, loss: 0.0019271698547527194
step: 570, loss: 0.01607677899301052
step: 580, loss: 0.03802808001637459
step: 590, loss: 0.25496402382850647
step: 600, loss: 0.02453933283686638
step: 610, loss: 0.02655697986483574
step: 620, loss: 0.1680441051721573
step: 630, loss: 9.295737254433334e-05
step: 640, loss: 0.011687830090522766
step: 650, loss: 0.08839616924524307
step: 660, loss: 0.05083266273140907
step: 670, loss: 0.02195051871240139
step: 680, loss: 0.026541687548160553
step: 690, loss: 0.13847938179969788
step: 700, loss: 0.051034536212682724
step: 710, loss: 0.03630227968096733
step: 720, loss: 0.13539373874664307
step: 730, loss: 0.024450622498989105
step: 740, loss: 0.08987046778202057
step: 750, loss: 0.05797472968697548
step: 760, loss: 0.12448453903198242
step: 770, loss: 0.03418416157364845
step: 780, loss: 0.039322759956121445
step: 790, loss: 0.02856377325952053
step: 800, loss: 0.026592804118990898
step: 810, loss: 0.03809547424316406
step: 820, loss: 0.05514412000775337
step: 830, loss: 0.20239561796188354
step: 840, loss: 0.042636267840862274
step: 850, loss: 0.10538262873888016
step: 860, loss: 0.045413725078105927
step: 870, loss: 0.08805149793624878
step: 880, loss: 0.05676821619272232
step: 890, loss: 0.056755948811769485
step: 900, loss: 0.04447178170084953
step: 910, loss: 0.09635362029075623
step: 920, loss: 0.10571596026420593
step: 930, loss: 0.05315537005662918
step: 940, loss: 0.047280535101890564
step: 950, loss: 0.0675836056470871
step: 960, loss: 0.04873812943696976
step: 970, loss: 0.05999026820063591
step: 980, loss: 0.05334730073809624
step: 990, loss: 0.0473032109439373
step: 1000, loss: 0.06495976448059082
step: 1010, loss: 0.007539576850831509
step: 1020, loss: 0.18198998272418976
step: 1030, loss: 0.09344113618135452
step: 1040, loss: 0.07034220546483994
step: 1050, loss: 0.10809241235256195
step: 1060, loss: 0.00420093210414052
step: 1070, loss: 0.084632508456707
epoch 11: dev_f1=0.9369786839666358, f1=0.9306839186691312, best_f1=0.9306839186691312
step: 0, loss: 0.041906341910362244
step: 10, loss: 0.06214115768671036
step: 20, loss: 0.040677402168512344
step: 30, loss: 0.03941165283322334
step: 40, loss: 0.0640697255730629
step: 50, loss: 0.10295989364385605
step: 60, loss: 0.05061329901218414
step: 70, loss: 0.05899045616388321
step: 80, loss: 0.04888945817947388
step: 90, loss: 0.051557522267103195
step: 100, loss: 0.0009817398386076093
step: 110, loss: 0.2111077606678009
step: 120, loss: 0.0929817408323288
step: 130, loss: 0.06092692166566849
step: 140, loss: 0.06473027914762497
step: 150, loss: 0.030193235725164413
step: 160, loss: 0.02340000867843628
step: 170, loss: 0.0756140947341919
step: 180, loss: 0.043179046362638474
step: 190, loss: 0.026775242760777473
step: 200, loss: 0.042976729571819305
step: 210, loss: 0.0012645230162888765
step: 220, loss: 0.09600983560085297
step: 230, loss: 0.08251922577619553
step: 240, loss: 2.5029719836311415e-05
step: 250, loss: 0.030362701043486595
step: 260, loss: 0.09597821533679962
step: 270, loss: 0.07506656646728516
step: 280, loss: 0.01831016317009926
step: 290, loss: 0.05338911712169647
step: 300, loss: 0.15759257972240448
step: 310, loss: 0.04390651732683182
step: 320, loss: 0.01573292724788189
step: 330, loss: 0.05619186535477638
step: 340, loss: 0.014381973072886467
step: 350, loss: 0.04323144629597664
step: 360, loss: 0.07369352877140045
step: 370, loss: 0.06324495375156403
step: 380, loss: 0.012653835117816925
step: 390, loss: 0.06493261456489563
step: 400, loss: 0.03245111182332039
step: 410, loss: 0.08095695823431015
step: 420, loss: 0.05933309346437454
step: 430, loss: 0.044832486659288406
step: 440, loss: 0.05402074009180069
step: 450, loss: 0.07244764268398285
step: 460, loss: 0.029281750321388245
step: 470, loss: 0.08227062225341797
step: 480, loss: 0.06490883976221085
step: 490, loss: 0.058696527034044266
step: 500, loss: 0.01575523056089878
step: 510, loss: 0.10745016485452652
step: 520, loss: 0.050521135330200195
step: 530, loss: 0.00453192088752985
step: 540, loss: 0.05059503763914108
step: 550, loss: 0.01940912753343582
step: 560, loss: 0.05971868336200714
step: 570, loss: 0.03951640799641609
step: 580, loss: 0.03185013681650162
step: 590, loss: 0.02540436200797558
step: 600, loss: 0.07367745786905289
step: 610, loss: 0.10814793407917023
step: 620, loss: 0.025932341814041138
step: 630, loss: 0.08390212804079056
step: 640, loss: 0.0026563326828181744
step: 650, loss: 0.04561639949679375
step: 660, loss: 0.09797172993421555
step: 670, loss: 0.11670348793268204
step: 680, loss: 0.024878419935703278
step: 690, loss: 0.024096660315990448
step: 700, loss: 0.034299202263355255
step: 710, loss: 0.04561431333422661
step: 720, loss: 0.06307411193847656
step: 730, loss: 0.07771362364292145
step: 740, loss: 0.09642808884382248
step: 750, loss: 0.027000034227967262
step: 760, loss: 0.011550136841833591
step: 770, loss: 0.00010889958502957597
step: 780, loss: 0.01192797813564539
step: 790, loss: 0.02159201353788376
step: 800, loss: 0.06237602233886719
step: 810, loss: 0.08949396759271622
step: 820, loss: 0.07302770018577576
step: 830, loss: 0.023365851491689682
step: 840, loss: 0.112195685505867
step: 850, loss: 0.06317922472953796
step: 860, loss: 0.08320678770542145
step: 870, loss: 0.08163072168827057
step: 880, loss: 0.09435431659221649
step: 890, loss: 0.11648814380168915
step: 900, loss: 0.04533042013645172
step: 910, loss: 0.0876242145895958
step: 920, loss: 0.014578886330127716
step: 930, loss: 0.0746508315205574
step: 940, loss: 0.08840692043304443
step: 950, loss: 0.0582888126373291
step: 960, loss: 0.049765445291996
step: 970, loss: 0.06355781853199005
step: 980, loss: 0.034408800303936005
step: 990, loss: 0.1689503788948059
step: 1000, loss: 0.0817476212978363
step: 1010, loss: 0.15813928842544556
step: 1020, loss: 0.012859208509325981
step: 1030, loss: 0.0664602667093277
step: 1040, loss: 0.04422673583030701
step: 1050, loss: 0.04342852905392647
step: 1060, loss: 0.08663571625947952
step: 1070, loss: 0.032354872673749924
epoch 12: dev_f1=0.9342592592592593, f1=0.9319129226493746, best_f1=0.9306839186691312
step: 0, loss: 0.07889797538518906
step: 10, loss: 0.046844273805618286
step: 20, loss: 0.027112405747175217
step: 30, loss: 0.05608951672911644
step: 40, loss: 0.170352965593338
step: 50, loss: 0.02307424321770668
step: 60, loss: 0.029871758073568344
step: 70, loss: 0.0905928760766983
step: 80, loss: 0.0036298269405961037
step: 90, loss: 0.021625064313411713
step: 100, loss: 0.0478111132979393
step: 110, loss: 0.03572331741452217
step: 120, loss: 0.08914682269096375
step: 130, loss: 0.029219167307019234
step: 140, loss: 0.07269901037216187
step: 150, loss: 0.05083856359124184
step: 160, loss: 0.03487568721175194
step: 170, loss: 0.02268347702920437
step: 180, loss: 0.035159189254045486
step: 190, loss: 0.025700783357024193
step: 200, loss: 0.02403784729540348
step: 210, loss: 0.01469563040882349
step: 220, loss: 0.044413745403289795
step: 230, loss: 0.11802023649215698
step: 240, loss: 0.03838615119457245
step: 250, loss: 0.10151661187410355
step: 260, loss: 0.030210228636860847
step: 270, loss: 0.09898006916046143
step: 280, loss: 0.07576461881399155
step: 290, loss: 0.009744889102876186
step: 300, loss: 0.12231352925300598
step: 310, loss: 0.11924316734075546
step: 320, loss: 0.02548982948064804
step: 330, loss: 0.021279800683259964
step: 340, loss: 0.0005152355879545212
step: 350, loss: 0.013554133474826813
step: 360, loss: 0.060213685035705566
step: 370, loss: 0.09543146193027496
step: 380, loss: 0.048477012664079666
step: 390, loss: 0.02745593525469303
step: 400, loss: 0.005435905419290066
step: 410, loss: 0.049901679158210754
step: 420, loss: 0.02316921204328537
step: 430, loss: 0.06401479244232178
step: 440, loss: 0.0014806051040068269
step: 450, loss: 0.01097134966403246
step: 460, loss: 0.025337405502796173
step: 470, loss: 0.0006513891275972128
step: 480, loss: 0.03529217094182968
step: 490, loss: 0.01941448636353016
step: 500, loss: 0.08616279065608978
step: 510, loss: 0.0036901363637298346
step: 520, loss: 0.07140876352787018
step: 530, loss: 0.03286660835146904
step: 540, loss: 0.027562545612454414
step: 550, loss: 0.16259799897670746
step: 560, loss: 0.06866580247879028
step: 570, loss: 0.09786301106214523
step: 580, loss: 0.04116406291723251
step: 590, loss: 0.021620411425828934
step: 600, loss: 0.0423198901116848
step: 610, loss: 0.08135886490345001
step: 620, loss: 0.0041386946104466915
step: 630, loss: 1.941957452800125e-05
step: 640, loss: 0.0460180789232254
step: 650, loss: 0.012954198755323887
step: 660, loss: 0.04930224269628525
step: 670, loss: 0.03700677677989006
step: 680, loss: 0.05866372957825661
step: 690, loss: 0.06544382125139236
step: 700, loss: 0.06871511787176132
step: 710, loss: 0.033487845212221146
step: 720, loss: 0.16353827714920044
step: 730, loss: 0.06123916432261467
step: 740, loss: 0.02284328266978264
step: 750, loss: 0.10630173236131668
step: 760, loss: 0.04803350567817688
step: 770, loss: 0.05623107776045799
step: 780, loss: 0.04884494096040726
step: 790, loss: 0.013155607506632805
step: 800, loss: 0.02651263400912285
step: 810, loss: 0.07616366446018219
step: 820, loss: 0.0442979633808136
step: 830, loss: 0.0809415802359581
step: 840, loss: 0.08426159620285034
step: 850, loss: 0.012997865676879883
step: 860, loss: 0.06889650970697403
step: 870, loss: 0.031022807583212852
step: 880, loss: 0.08828205615282059
step: 890, loss: 0.13691532611846924
step: 900, loss: 0.0673927441239357
step: 910, loss: 0.10376608371734619
step: 920, loss: 0.04467189684510231
step: 930, loss: 0.07441481202840805
step: 940, loss: 0.08685128390789032
step: 950, loss: 0.041693560779094696
step: 960, loss: 0.14843358099460602
step: 970, loss: 0.052631791681051254
step: 980, loss: 0.012123093008995056
step: 990, loss: 0.06858367472887039
step: 1000, loss: 0.02809503674507141
step: 1010, loss: 0.04402162879705429
step: 1020, loss: 0.08935198932886124
step: 1030, loss: 0.06628444045782089
step: 1040, loss: 0.045015234500169754
step: 1050, loss: 0.10901733487844467
step: 1060, loss: 0.12270079553127289
step: 1070, loss: 0.08728864043951035
epoch 13: dev_f1=0.9197960129809921, f1=0.9229349330872173, best_f1=0.9306839186691312
step: 0, loss: 0.060077860951423645
step: 10, loss: 0.03687237575650215
step: 20, loss: 0.06415809690952301
step: 30, loss: 0.014780547469854355
step: 40, loss: 0.07404026389122009
step: 50, loss: 0.08207084238529205
step: 60, loss: 0.0013178631197661161
step: 70, loss: 0.04191775247454643
step: 80, loss: 0.08244211226701736
step: 90, loss: 0.042254943400621414
step: 100, loss: 2.3117738237488084e-05
step: 110, loss: 0.01790449395775795
step: 120, loss: 0.04343967139720917
step: 130, loss: 0.06606905907392502
step: 140, loss: 0.046028632670640945
step: 150, loss: 0.11266562342643738
step: 160, loss: 0.056876301765441895
step: 170, loss: 0.04787895828485489
step: 180, loss: 0.05603915825486183
step: 190, loss: 0.039633478969335556
step: 200, loss: 0.07423096895217896
step: 210, loss: 0.03353913128376007
step: 220, loss: 0.04708552360534668
step: 230, loss: 0.06559914350509644
step: 240, loss: 0.09426278620958328
step: 250, loss: 0.012754053808748722
step: 260, loss: 0.034111861139535904
step: 270, loss: 0.05332781374454498
step: 280, loss: 0.061419449746608734
step: 290, loss: 0.12117711454629898
step: 300, loss: 0.09088920056819916
step: 310, loss: 0.07728374749422073
step: 320, loss: 0.0029701492749154568
step: 330, loss: 0.07382981479167938
step: 340, loss: 0.018762540072202682
step: 350, loss: 0.11349464952945709
step: 360, loss: 0.040190331637859344
step: 370, loss: 0.004980196710675955
step: 380, loss: 0.04060324281454086
step: 390, loss: 0.0464390404522419
step: 400, loss: 0.0469001866877079
step: 410, loss: 0.04219752177596092
step: 420, loss: 0.10249876230955124
step: 430, loss: 0.0982218086719513
step: 440, loss: 0.07792125642299652
step: 450, loss: 0.04020699858665466
step: 460, loss: 0.03143763542175293
step: 470, loss: 0.00040953385177999735
step: 480, loss: 0.05192771553993225
step: 490, loss: 0.044582054018974304
step: 500, loss: 0.054842449724674225
step: 510, loss: 0.11035812646150589
step: 520, loss: 0.03442186117172241
step: 530, loss: 0.012289448641240597
step: 540, loss: 0.019082803279161453
step: 550, loss: 0.08335601538419724
step: 560, loss: 0.06672109663486481
step: 570, loss: 0.0592188723385334
step: 580, loss: 0.02275681309401989
step: 590, loss: 0.002117773750796914
step: 600, loss: 0.02287299558520317
step: 610, loss: 0.05961911007761955
step: 620, loss: 0.10243476182222366
step: 630, loss: 0.05476846545934677
step: 640, loss: 0.059758260846138
step: 650, loss: 0.010926533490419388
step: 660, loss: 0.052580077201128006
step: 670, loss: 0.039744772017002106
step: 680, loss: 0.0175813939422369
step: 690, loss: 0.022970467805862427
step: 700, loss: 0.1844913512468338
step: 710, loss: 0.05759295076131821
step: 720, loss: 0.059681352227926254
step: 730, loss: 0.03564790263772011
step: 740, loss: 0.014554622583091259
step: 750, loss: 0.12113279849290848
step: 760, loss: 0.025678301230072975
step: 770, loss: 0.03961176797747612
step: 780, loss: 0.0363277792930603
step: 790, loss: 0.013415820896625519
step: 800, loss: 0.01648014411330223
step: 810, loss: 0.019548436626791954
step: 820, loss: 0.09991984069347382
step: 830, loss: 0.10659605264663696
step: 840, loss: 0.02343733236193657
step: 850, loss: 0.0223915446549654
step: 860, loss: 0.13027769327163696
step: 870, loss: 0.09144135564565659
step: 880, loss: 0.04055124521255493
step: 890, loss: 0.0003994416620116681
step: 900, loss: 0.019220104441046715
step: 910, loss: 0.03867270052433014
step: 920, loss: 0.055310532450675964
step: 930, loss: 0.022962216287851334
step: 940, loss: 0.05366834998130798
step: 950, loss: 0.054974719882011414
step: 960, loss: 0.010228234343230724
step: 970, loss: 0.1343497484922409
step: 980, loss: 0.051020458340644836
step: 990, loss: 0.05503733083605766
step: 1000, loss: 0.09272965043783188
step: 1010, loss: 0.07264820486307144
step: 1020, loss: 0.040845345705747604
step: 1030, loss: 0.07893300801515579
step: 1040, loss: 0.0664365366101265
step: 1050, loss: 0.018196897581219673
step: 1060, loss: 0.04894743859767914
step: 1070, loss: 0.05379585176706314
epoch 14: dev_f1=0.936111111111111, f1=0.9296947271045328, best_f1=0.9306839186691312
step: 0, loss: 0.0843038409948349
step: 10, loss: 0.055703237652778625
step: 20, loss: 0.041975073516368866
step: 30, loss: 0.010849002748727798
step: 40, loss: 0.002869301475584507
step: 50, loss: 0.038306187838315964
step: 60, loss: 0.08401821553707123
step: 70, loss: 0.13337087631225586
step: 80, loss: 0.09447810053825378
step: 90, loss: 0.019263040274381638
step: 100, loss: 0.04129472374916077
step: 110, loss: 0.06050513684749603
step: 120, loss: 0.09901409596204758
step: 130, loss: 0.05901623144745827
step: 140, loss: 0.03634311258792877
step: 150, loss: 0.009881095960736275
step: 160, loss: 0.010188518092036247
step: 170, loss: 0.05819781497120857
step: 180, loss: 0.026836464181542397
step: 190, loss: 0.06936980038881302
step: 200, loss: 0.014221417717635632
step: 210, loss: 0.002705446444451809
step: 220, loss: 0.05206144601106644
step: 230, loss: 0.032066475600004196
step: 240, loss: 0.014215569943189621
step: 250, loss: 0.08475825190544128
step: 260, loss: 0.05964638665318489
step: 270, loss: 0.04365290701389313
step: 280, loss: 0.07076192647218704
step: 290, loss: 0.07654094696044922
step: 300, loss: 0.02037709206342697
step: 310, loss: 0.04295772686600685
step: 320, loss: 0.029078014194965363
step: 330, loss: 0.005918318405747414
step: 340, loss: 0.06938251107931137
step: 350, loss: 0.008475562557578087
step: 360, loss: 0.10422360897064209
step: 370, loss: 0.06440702080726624
step: 380, loss: 0.03934305161237717
step: 390, loss: 0.027818461880087852
step: 400, loss: 0.09517969191074371
step: 410, loss: 0.039561837911605835
step: 420, loss: 0.07288620620965958
step: 430, loss: 0.002835125895217061
step: 440, loss: 0.06555550545454025
step: 450, loss: 0.025558780878782272
step: 460, loss: 0.14431805908679962
step: 470, loss: 0.010485826060175896
step: 480, loss: 0.0708625540137291
step: 490, loss: 0.07206248492002487
step: 500, loss: 0.0433223620057106
step: 510, loss: 0.04830162972211838
step: 520, loss: 0.02859734185039997
step: 530, loss: 0.045724961906671524
step: 540, loss: 0.10646016150712967
step: 550, loss: 0.032654643058776855
step: 560, loss: 0.009708690457046032
step: 570, loss: 0.06671756505966187
step: 580, loss: 0.0031824964098632336
step: 590, loss: 0.01126279216259718
step: 600, loss: 0.000848161696922034
step: 610, loss: 0.08585183322429657
step: 620, loss: 0.044416166841983795
step: 630, loss: 0.10321030765771866
step: 640, loss: 0.013296476565301418
step: 650, loss: 8.96701094461605e-05
step: 660, loss: 0.11126970499753952
step: 670, loss: 0.006783924996852875
step: 680, loss: 0.04643428325653076
step: 690, loss: 0.09225722402334213
step: 700, loss: 0.02534554898738861
step: 710, loss: 0.0506204292178154
step: 720, loss: 0.03618840128183365
step: 730, loss: 0.0674135759472847
step: 740, loss: 0.01613244228065014
step: 750, loss: 0.0785316675901413
step: 760, loss: 0.04794393107295036
step: 770, loss: 0.033045507967472076
step: 780, loss: 0.03570287674665451
step: 790, loss: 0.01348683051764965
step: 800, loss: 0.14767643809318542
step: 810, loss: 0.0004163819830864668
step: 820, loss: 0.06593112647533417
step: 830, loss: 0.06832245737314224
step: 840, loss: 0.0641302764415741
step: 850, loss: 0.017524324357509613
step: 860, loss: 0.03999678045511246
step: 870, loss: 0.05428977683186531
step: 880, loss: 0.12212849408388138
step: 890, loss: 0.019616801291704178
step: 900, loss: 0.10880477726459503
step: 910, loss: 0.0962434783577919
step: 920, loss: 0.06265642493963242
step: 930, loss: 0.09803710877895355
step: 940, loss: 0.05897219106554985
step: 950, loss: 0.004301263485103846
step: 960, loss: 0.07150579988956451
step: 970, loss: 0.046802543103694916
step: 980, loss: 0.10906602442264557
step: 990, loss: 0.0473770946264267
step: 1000, loss: 0.051239434629678726
step: 1010, loss: 0.036379922181367874
step: 1020, loss: 0.06379076838493347
step: 1030, loss: 0.04289870709180832
step: 1040, loss: 0.026032239198684692
step: 1050, loss: 0.03317989036440849
step: 1060, loss: 0.11809395253658295
step: 1070, loss: 0.017003696411848068
epoch 15: dev_f1=0.9276595744680851, f1=0.9244486156733928, best_f1=0.9306839186691312
step: 0, loss: 0.03927448391914368
step: 10, loss: 0.055212751030921936
step: 20, loss: 0.02875322662293911
step: 30, loss: 0.06001024320721626
step: 40, loss: 0.04763653874397278
step: 50, loss: 0.03967458754777908
step: 60, loss: 1.578007868374698e-05
step: 70, loss: 0.021184738725423813
step: 80, loss: 0.08328671008348465
step: 90, loss: 0.03475329652428627
step: 100, loss: 0.05927341803908348
step: 110, loss: 0.00010078861669171602
step: 120, loss: 0.07393567264080048
step: 130, loss: 0.07941000908613205
step: 140, loss: 0.06068908050656319
step: 150, loss: 0.019698992371559143
step: 160, loss: 0.08076111972332001
step: 170, loss: 0.052601415663957596
step: 180, loss: 0.014426653273403645
step: 190, loss: 0.01847715489566326
step: 200, loss: 0.046955421566963196
step: 210, loss: 0.07406152039766312
step: 220, loss: 0.025059876963496208
step: 230, loss: 0.00011686691868817434
step: 240, loss: 0.08945772796869278
step: 250, loss: 0.00022137697669677436
step: 260, loss: 0.06059359386563301
step: 270, loss: 0.04121362790465355
step: 280, loss: 0.09193849563598633
step: 290, loss: 0.010868760757148266
step: 300, loss: 7.24520068615675e-05
step: 310, loss: 0.036881208419799805
step: 320, loss: 0.001055293483659625
step: 330, loss: 0.04175728186964989
step: 340, loss: 0.03247009962797165
step: 350, loss: 0.0005779204657301307
step: 360, loss: 0.12953582406044006
step: 370, loss: 0.04687473922967911
step: 380, loss: 0.05222631245851517
step: 390, loss: 0.07379721850156784
step: 400, loss: 0.04602189362049103
step: 410, loss: 0.01402165088802576
step: 420, loss: 0.04380951449275017
step: 430, loss: 0.061430055648088455
step: 440, loss: 0.09319213777780533
step: 450, loss: 0.06871010363101959
step: 460, loss: 0.03577570989727974
step: 470, loss: 0.0001191027695313096
step: 480, loss: 0.07180238515138626
step: 490, loss: 0.04026458412408829
step: 500, loss: 0.06885473430156708
step: 510, loss: 0.014399522915482521
step: 520, loss: 0.0645827203989029
step: 530, loss: 0.03471897542476654
step: 540, loss: 0.038583435118198395
step: 550, loss: 0.057666849344968796
step: 560, loss: 0.024278951808810234
step: 570, loss: 0.056456033140420914
step: 580, loss: 0.04407135397195816
step: 590, loss: 0.03938421979546547
step: 600, loss: 0.00881931371986866
step: 610, loss: 0.09705598652362823
step: 620, loss: 0.03766423463821411
step: 630, loss: 0.03249668329954147
step: 640, loss: 0.02616095542907715
step: 650, loss: 0.018415890634059906
step: 660, loss: 0.01678185909986496
step: 670, loss: 0.06479950249195099
step: 680, loss: 0.0662773847579956
step: 690, loss: 0.029177503660321236
step: 700, loss: 0.026822460815310478
step: 710, loss: 0.03489316999912262
step: 720, loss: 0.05268854275345802
step: 730, loss: 0.00017894097254611552
step: 740, loss: 0.03766871988773346
step: 750, loss: 0.02094253897666931
step: 760, loss: 0.06484301388263702
step: 770, loss: 0.02204969897866249
step: 780, loss: 0.019874801859259605
step: 790, loss: 0.02855413220822811
step: 800, loss: 1.6368541764677502e-05
step: 810, loss: 0.09604758769273758
step: 820, loss: 0.04760371148586273
step: 830, loss: 0.036700911819934845
step: 840, loss: 0.11419229209423065
step: 850, loss: 0.08417347073554993
step: 860, loss: 0.034370724111795425
step: 870, loss: 0.06153721362352371
step: 880, loss: 0.025629445910453796
step: 890, loss: 0.10185041278600693
step: 900, loss: 0.05428911745548248
step: 910, loss: 0.013379809446632862
step: 920, loss: 0.045546285808086395
step: 930, loss: 0.00024186815426219255
step: 940, loss: 0.11512349545955658
step: 950, loss: 0.07290422171354294
step: 960, loss: 4.84817246615421e-05
step: 970, loss: 0.035902515053749084
step: 980, loss: 0.00021900070714764297
step: 990, loss: 0.011210695840418339
step: 1000, loss: 0.07360871881246567
step: 1010, loss: 0.0030201864428818226
step: 1020, loss: 3.885068144882098e-05
step: 1030, loss: 0.16340510547161102
step: 1040, loss: 0.037402842193841934
step: 1050, loss: 0.06477575749158859
step: 1060, loss: 0.056858886033296585
step: 1070, loss: 0.23707830905914307
epoch 16: dev_f1=0.9307942405945193, f1=0.9299953639313862, best_f1=0.9306839186691312
step: 0, loss: 6.703053804812953e-05
step: 10, loss: 0.028484372422099113
step: 20, loss: 0.06554896384477615
step: 30, loss: 0.05301805958151817
step: 40, loss: 0.030097568407654762
step: 50, loss: 0.03862420842051506
step: 60, loss: 0.1286769062280655
step: 70, loss: 0.012551315128803253
step: 80, loss: 0.0648793950676918
step: 90, loss: 0.020878400653600693
step: 100, loss: 0.04855140671133995
step: 110, loss: 0.1357841044664383
step: 120, loss: 0.07816454768180847
step: 130, loss: 0.0012459942372515798
step: 140, loss: 0.02346818707883358
step: 150, loss: 0.0013222740963101387
step: 160, loss: 0.04302992671728134
step: 170, loss: 0.07159534096717834
step: 180, loss: 0.04427475109696388
step: 190, loss: 0.035215962678194046
step: 200, loss: 0.048926401883363724
step: 210, loss: 0.02526792138814926
step: 220, loss: 0.0741482600569725
step: 230, loss: 0.02240240015089512
step: 240, loss: 0.023576078936457634
step: 250, loss: 1.8983631889568642e-05
step: 260, loss: 4.206482117297128e-05
step: 270, loss: 0.06601452082395554
step: 280, loss: 0.006763503886759281
step: 290, loss: 0.0011488223681226373
step: 300, loss: 0.00045308287371881306
step: 310, loss: 0.04673181474208832
step: 320, loss: 0.0791132003068924
step: 330, loss: 0.04222443327307701
step: 340, loss: 0.04145355522632599
step: 350, loss: 0.07209809124469757
step: 360, loss: 0.03177262097597122
step: 370, loss: 0.048871416598558426
step: 380, loss: 0.014702164568006992
step: 390, loss: 0.03274399787187576
step: 400, loss: 0.03251424804329872
step: 410, loss: 0.01334391813725233
step: 420, loss: 0.07062040269374847
step: 430, loss: 0.03564542904496193
step: 440, loss: 0.020258985459804535
step: 450, loss: 0.07772955298423767
step: 460, loss: 0.012324217706918716
step: 470, loss: 0.044817689806222916
step: 480, loss: 0.047424059361219406
step: 490, loss: 0.0770764872431755
step: 500, loss: 0.016571123152971268
step: 510, loss: 0.05942719802260399
step: 520, loss: 0.07274658232927322
step: 530, loss: 0.03356924280524254
step: 540, loss: 0.055053092539310455
step: 550, loss: 0.010154551826417446
step: 560, loss: 0.06759901344776154
step: 570, loss: 0.008359449915587902
step: 580, loss: 0.06259888410568237
step: 590, loss: 0.0971304327249527
step: 600, loss: 5.1489201723597944e-05
step: 610, loss: 0.03205427527427673
step: 620, loss: 0.020981959998607635
step: 630, loss: 0.01916930451989174
step: 640, loss: 0.07208644598722458
step: 650, loss: 0.09844917804002762
step: 660, loss: 0.03953562304377556
step: 670, loss: 0.007288322318345308
step: 680, loss: 0.05749877169728279
step: 690, loss: 0.015450360253453255
step: 700, loss: 0.020638205111026764
step: 710, loss: 0.028712335973978043
step: 720, loss: 0.03552320599555969
step: 730, loss: 0.046274855732917786
step: 740, loss: 0.01837472803890705
step: 750, loss: 0.0564374215900898
step: 760, loss: 0.12128891050815582
step: 770, loss: 0.10266023129224777
step: 780, loss: 0.0830148309469223
step: 790, loss: 0.034096598625183105
step: 800, loss: 0.07624813169240952
step: 810, loss: 0.017430249601602554
step: 820, loss: 0.0380798876285553
step: 830, loss: 0.09095603227615356
step: 840, loss: 0.00041166506707668304
step: 850, loss: 0.07781358808279037
step: 860, loss: 0.0793938860297203
step: 870, loss: 0.015327968634665012
step: 880, loss: 0.05859497934579849
step: 890, loss: 0.024372443556785583
step: 900, loss: 0.0006210825522430241
step: 910, loss: 0.06097986921668053
step: 920, loss: 3.077353903790936e-05
step: 930, loss: 0.03040885552763939
step: 940, loss: 0.08928961306810379
step: 950, loss: 0.03148219361901283
step: 960, loss: 0.0690559521317482
step: 970, loss: 0.1743171066045761
step: 980, loss: 0.0386371947824955
step: 990, loss: 0.04577302932739258
step: 1000, loss: 0.017107050865888596
step: 1010, loss: 0.026315972208976746
step: 1020, loss: 0.020296530798077583
step: 1030, loss: 0.04813515022397041
step: 1040, loss: 0.07292891293764114
step: 1050, loss: 0.0004389419045764953
step: 1060, loss: 0.0464034378528595
step: 1070, loss: 0.1546538919210434
epoch 17: dev_f1=0.9300567107750473, f1=0.925891181988743, best_f1=0.9306839186691312
step: 0, loss: 0.04885455220937729
step: 10, loss: 0.033864255994558334
step: 20, loss: 0.017536258324980736
step: 30, loss: 0.04859470948576927
step: 40, loss: 0.018513847142457962
step: 50, loss: 0.05019079148769379
step: 60, loss: 0.05683201923966408
step: 70, loss: 0.0004724361060652882
step: 80, loss: 0.12400496006011963
step: 90, loss: 0.016790173947811127
step: 100, loss: 0.02445346862077713
step: 110, loss: 0.07947315275669098
step: 120, loss: 0.02741413377225399
step: 130, loss: 0.07424936443567276
step: 140, loss: 0.0681564137339592
step: 150, loss: 0.003330900799483061
step: 160, loss: 0.053716883063316345
step: 170, loss: 0.013595988973975182
step: 180, loss: 0.03948955982923508
step: 190, loss: 0.12187288701534271
step: 200, loss: 3.1909210520097986e-05
step: 210, loss: 0.05363092198967934
step: 220, loss: 0.08897864073514938
step: 230, loss: 0.03385315462946892
step: 240, loss: 0.0516221709549427
step: 250, loss: 0.05668020620942116
step: 260, loss: 0.09572196751832962
step: 270, loss: 0.04161000996828079
step: 280, loss: 0.073574498295784
step: 290, loss: 0.05371081456542015
step: 300, loss: 0.05441301316022873
step: 310, loss: 0.029787976294755936
step: 320, loss: 0.016804439947009087
step: 330, loss: 0.028353624045848846
step: 340, loss: 0.017842508852481842
step: 350, loss: 0.03362921252846718
step: 360, loss: 0.06120863929390907
step: 370, loss: 0.030572880059480667
step: 380, loss: 0.013477951288223267
step: 390, loss: 0.07700510323047638
step: 400, loss: 0.19357028603553772
step: 410, loss: 0.0535813644528389
step: 420, loss: 0.07089970260858536
step: 430, loss: 0.04979921877384186
step: 440, loss: 4.492830339586362e-05
step: 450, loss: 0.004577888175845146
step: 460, loss: 0.0796949490904808
step: 470, loss: 0.02756006270647049
step: 480, loss: 0.07205267250537872
step: 490, loss: 0.013045517727732658
step: 500, loss: 0.07075412571430206
step: 510, loss: 0.010105649940669537
step: 520, loss: 0.017866481095552444
step: 530, loss: 0.09868509322404861
step: 540, loss: 0.00020070439495611936
step: 550, loss: 0.04990198463201523
step: 560, loss: 0.05353336036205292
step: 570, loss: 0.0817568227648735
step: 580, loss: 0.29027554392814636
step: 590, loss: 1.9870167307090014e-05
step: 600, loss: 0.05287866294384003
step: 610, loss: 0.0845615342259407
step: 620, loss: 0.0393836535513401
step: 630, loss: 0.029818639159202576
step: 640, loss: 0.017532140016555786
step: 650, loss: 0.00028007294167764485
step: 660, loss: 0.07893313467502594
step: 670, loss: 0.008566068485379219
step: 680, loss: 0.06800046563148499
step: 690, loss: 0.04942934587597847
step: 700, loss: 0.01585148274898529
step: 710, loss: 0.022894026711583138
step: 720, loss: 0.05170125514268875
step: 730, loss: 0.07661394774913788
step: 740, loss: 0.12860533595085144
step: 750, loss: 0.07599443197250366
step: 760, loss: 0.03620947152376175
step: 770, loss: 0.028425244614481926
step: 780, loss: 0.05139235034584999
step: 790, loss: 0.026058852672576904
step: 800, loss: 0.08221995085477829
step: 810, loss: 0.018632125109434128
step: 820, loss: 0.03552594780921936
step: 830, loss: 0.006853794679045677
step: 840, loss: 0.04693768918514252
step: 850, loss: 0.06541630625724792
step: 860, loss: 0.07134020328521729
step: 870, loss: 0.034020427614450455
step: 880, loss: 0.030503395944833755
step: 890, loss: 0.03330421447753906
step: 900, loss: 0.020572084933519363
step: 910, loss: 0.0003659281355794519
step: 920, loss: 0.06066058948636055
step: 930, loss: 0.10676608234643936
step: 940, loss: 0.0622674785554409
step: 950, loss: 0.036387715488672256
step: 960, loss: 0.04331507161259651
step: 970, loss: 0.0444587841629982
step: 980, loss: 0.007624292746186256
step: 990, loss: 0.01857735402882099
step: 1000, loss: 0.01906219683587551
step: 1010, loss: 0.03919481486082077
step: 1020, loss: 0.02889547124505043
step: 1030, loss: 0.06129735708236694
step: 1040, loss: 0.027358638122677803
step: 1050, loss: 0.03343426436185837
step: 1060, loss: 0.011581026017665863
step: 1070, loss: 0.14758427441120148
epoch 18: dev_f1=0.9293504030346136, f1=0.923368022705771, best_f1=0.9306839186691312
step: 0, loss: 0.04348716139793396
step: 10, loss: 0.08396124094724655
step: 20, loss: 0.008938935585319996
step: 30, loss: 0.06668394804000854
step: 40, loss: 0.14204595983028412
step: 50, loss: 0.02121681720018387
step: 60, loss: 5.2905947086401284e-05
step: 70, loss: 0.15181875228881836
step: 80, loss: 0.02649676240980625
step: 90, loss: 0.06731822341680527
step: 100, loss: 0.05506137013435364
step: 110, loss: 0.09321010857820511
step: 120, loss: 0.09243053942918777
step: 130, loss: 0.10083048045635223
step: 140, loss: 0.016498833894729614
step: 150, loss: 0.017362579703330994
step: 160, loss: 0.021998202428221703
step: 170, loss: 0.08710046857595444
step: 180, loss: 0.033954739570617676
step: 190, loss: 3.022950295417104e-05
step: 200, loss: 0.04596033692359924
step: 210, loss: 0.023945888504385948
step: 220, loss: 0.05783144384622574
step: 230, loss: 0.0602380745112896
step: 240, loss: 0.09766503423452377
step: 250, loss: 0.07779098302125931
step: 260, loss: 0.05908684805035591
step: 270, loss: 0.13717199862003326
step: 280, loss: 0.1004457175731659
step: 290, loss: 0.04103882610797882
step: 300, loss: 0.038179121911525726
step: 310, loss: 0.03087233193218708
step: 320, loss: 0.0550743006169796
step: 330, loss: 0.02896851673722267
step: 340, loss: 0.034611836075782776
step: 350, loss: 0.06025082245469093
step: 360, loss: 0.02880723588168621
step: 370, loss: 0.013578120619058609
step: 380, loss: 0.037128206342458725
step: 390, loss: 0.0559174120426178
step: 400, loss: 0.03004281409084797
step: 410, loss: 0.030400997027754784
step: 420, loss: 0.052633121609687805
step: 430, loss: 0.05921391025185585
step: 440, loss: 0.0002342460211366415
step: 450, loss: 0.06932991743087769
step: 460, loss: 0.04001575708389282
step: 470, loss: 0.07360124588012695
step: 480, loss: 0.05093124508857727
step: 490, loss: 0.02562660165131092
step: 500, loss: 0.038707662373781204
step: 510, loss: 0.0011338787153363228
step: 520, loss: 0.027443023398518562
step: 530, loss: 0.0011740917107090354
step: 540, loss: 0.07277921587228775
step: 550, loss: 0.05575014278292656
step: 560, loss: 0.07291313260793686
step: 570, loss: 0.024787288159132004
step: 580, loss: 0.06423904746770859
step: 590, loss: 0.08605023473501205
step: 600, loss: 0.01471711229532957
step: 610, loss: 0.01961589604616165
step: 620, loss: 0.023766515776515007
step: 630, loss: 0.007897458970546722
step: 640, loss: 0.10370390117168427
step: 650, loss: 0.08613111078739166
step: 660, loss: 0.026977889239788055
step: 670, loss: 0.06336505711078644
step: 680, loss: 0.07772177457809448
step: 690, loss: 0.056081611663103104
step: 700, loss: 0.026198245584964752
step: 710, loss: 0.050865013152360916
step: 720, loss: 0.03127635642886162
step: 730, loss: 0.015848083421587944
step: 740, loss: 0.08524756133556366
step: 750, loss: 0.016320066526532173
step: 760, loss: 0.04419342428445816
step: 770, loss: 0.06426428258419037
step: 780, loss: 0.0013933893060311675
step: 790, loss: 2.472999221936334e-05
step: 800, loss: 0.0528118871152401
step: 810, loss: 0.02926451712846756
step: 820, loss: 2.8473607017076574e-05
step: 830, loss: 0.09416443854570389
step: 840, loss: 0.05070550739765167
step: 850, loss: 0.020554877817630768
step: 860, loss: 0.05459345132112503
step: 870, loss: 0.013856722041964531
step: 880, loss: 0.021409470587968826
step: 890, loss: 0.06696199625730515
step: 900, loss: 0.07353660464286804
step: 910, loss: 0.047262612730264664
step: 920, loss: 0.029560448601841927
step: 930, loss: 0.011839824728667736
step: 940, loss: 0.03356286138296127
step: 950, loss: 0.1365126520395279
step: 960, loss: 0.12156426906585693
step: 970, loss: 0.11300265789031982
step: 980, loss: 0.027381740510463715
step: 990, loss: 0.029973208904266357
step: 1000, loss: 0.0005981362774036825
step: 1010, loss: 0.046132978051900864
step: 1020, loss: 0.019058333709836006
step: 1030, loss: 0.01572328247129917
step: 1040, loss: 5.310949927661568e-05
step: 1050, loss: 0.07322851568460464
step: 1060, loss: 0.02435729280114174
step: 1070, loss: 0.018372798338532448
epoch 19: dev_f1=0.9297501178689297, f1=0.9289055191768008, best_f1=0.9306839186691312
step: 0, loss: 0.010120801627635956
step: 10, loss: 0.037182703614234924
step: 20, loss: 0.030216936022043228
step: 30, loss: 2.658947960298974e-05
step: 40, loss: 0.10857971012592316
step: 50, loss: 0.04758058860898018
step: 60, loss: 0.04749651625752449
step: 70, loss: 0.055741459131240845
step: 80, loss: 0.06074616685509682
step: 90, loss: 0.04041106253862381
step: 100, loss: 0.06934881955385208
step: 110, loss: 0.06799789518117905
step: 120, loss: 0.03999738395214081
step: 130, loss: 0.0003895311674568802
step: 140, loss: 0.022493114694952965
step: 150, loss: 0.01576242782175541
step: 160, loss: 0.008081761188805103
step: 170, loss: 0.031535804271698
step: 180, loss: 0.049157582223415375
step: 190, loss: 0.005799855105578899
step: 200, loss: 0.028897615149617195
step: 210, loss: 0.021935850381851196
step: 220, loss: 0.03657529875636101
step: 230, loss: 0.04647320881485939
step: 240, loss: 0.0007087767007760704
step: 250, loss: 0.02740429900586605
step: 260, loss: 0.001473601907491684
step: 270, loss: 0.028458179906010628
step: 280, loss: 6.680026126559824e-05
step: 290, loss: 0.0637756809592247
step: 300, loss: 0.05150957405567169
step: 310, loss: 0.02220691367983818
step: 320, loss: 0.04019445180892944
step: 330, loss: 0.05255170911550522
step: 340, loss: 0.04149311035871506
step: 350, loss: 0.03914905712008476
step: 360, loss: 0.0009022511658258736
step: 370, loss: 0.04225824773311615
step: 380, loss: 0.025091204792261124
step: 390, loss: 0.07861912995576859
step: 400, loss: 0.12512069940567017
step: 410, loss: 0.019398022443056107
step: 420, loss: 0.03164992108941078
step: 430, loss: 0.08430663496255875
step: 440, loss: 0.031022122129797935
step: 450, loss: 0.0769643560051918
step: 460, loss: 0.06029971316456795
step: 470, loss: 0.028869949281215668
step: 480, loss: 0.036607760936021805
step: 490, loss: 0.02786935493350029
step: 500, loss: 0.029980303719639778
step: 510, loss: 0.04335390776395798
step: 520, loss: 0.03447023406624794
step: 530, loss: 4.911514406558126e-05
step: 540, loss: 0.04764541983604431
step: 550, loss: 0.012273828499019146
step: 560, loss: 0.09289576858282089
step: 570, loss: 1.8670334611670114e-05
step: 580, loss: 0.00012523944315034896
step: 590, loss: 0.015412339940667152
step: 600, loss: 0.06256146728992462
step: 610, loss: 0.038341421633958817
step: 620, loss: 0.03504185378551483
step: 630, loss: 0.01178017444908619
step: 640, loss: 0.06888533383607864
step: 650, loss: 0.013585926964879036
step: 660, loss: 0.0697312206029892
step: 670, loss: 0.0591299831867218
step: 680, loss: 0.06238977611064911
step: 690, loss: 0.06318079680204391
step: 700, loss: 0.051338206976652145
step: 710, loss: 0.05076097697019577
step: 720, loss: 0.05611296370625496
step: 730, loss: 0.0313691645860672
step: 740, loss: 0.1893738955259323
step: 750, loss: 0.04164288192987442
step: 760, loss: 0.04448425769805908
step: 770, loss: 0.13840588927268982
step: 780, loss: 0.07371370494365692
step: 790, loss: 0.05876850709319115
step: 800, loss: 0.017083995044231415
step: 810, loss: 0.03148704022169113
step: 820, loss: 0.020467210561037064
step: 830, loss: 0.03510182723402977
step: 840, loss: 0.018470553681254387
step: 850, loss: 0.0357837900519371
step: 860, loss: 0.049882255494594574
step: 870, loss: 0.061053380370140076
step: 880, loss: 0.0374525748193264
step: 890, loss: 0.117238350212574
step: 900, loss: 0.014706135727465153
step: 910, loss: 0.03986961022019386
step: 920, loss: 0.01589912176132202
step: 930, loss: 0.018948597833514214
step: 940, loss: 0.029704095795750618
step: 950, loss: 0.0543331503868103
step: 960, loss: 0.0250869058072567
step: 970, loss: 0.02691991813480854
step: 980, loss: 0.022191246971488
step: 990, loss: 0.07401847094297409
step: 1000, loss: 0.03895476087927818
step: 1010, loss: 0.000945933919865638
step: 1020, loss: 0.017995348200201988
step: 1030, loss: 0.04632182419300079
step: 1040, loss: 0.0433209054172039
step: 1050, loss: 0.00016234534268733114
step: 1060, loss: 0.04494283348321915
step: 1070, loss: 1.1611622539930977e-05
epoch 20: dev_f1=0.928739971684757, f1=0.926463700234192, best_f1=0.9306839186691312
