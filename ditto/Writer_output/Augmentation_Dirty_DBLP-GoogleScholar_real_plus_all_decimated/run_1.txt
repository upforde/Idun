cuda
Device: cuda
step: 0, loss: 0.725042462348938
step: 10, loss: 0.3735370635986328
step: 20, loss: 0.5153965353965759
step: 30, loss: 0.4533851146697998
step: 40, loss: 0.5866271257400513
step: 50, loss: 0.1906667798757553
step: 60, loss: 0.2524659037590027
step: 70, loss: 0.13450948894023895
step: 80, loss: 0.13304783403873444
step: 90, loss: 0.24997825920581818
step: 100, loss: 0.09553859382867813
step: 110, loss: 0.40691685676574707
step: 120, loss: 0.0807151198387146
step: 130, loss: 0.1130523532629013
step: 140, loss: 0.1256425529718399
step: 150, loss: 0.1371861845254898
step: 160, loss: 0.014906644821166992
step: 170, loss: 0.05711580812931061
step: 180, loss: 0.022684091702103615
step: 190, loss: 0.12213566899299622
step: 200, loss: 0.01820470578968525
step: 210, loss: 0.014307186007499695
step: 220, loss: 0.007532053627073765
step: 230, loss: 0.013008194044232368
step: 240, loss: 0.0639304593205452
step: 250, loss: 0.10162001848220825
step: 260, loss: 0.18239179253578186
step: 270, loss: 0.06911413371562958
step: 280, loss: 0.028894471004605293
step: 290, loss: 0.004620702005922794
step: 300, loss: 0.14985977113246918
step: 310, loss: 0.16420374810695648
step: 320, loss: 0.20934830605983734
step: 330, loss: 0.02144148200750351
step: 340, loss: 0.016880657523870468
step: 350, loss: 0.006293323822319508
step: 360, loss: 0.09530080854892731
step: 370, loss: 0.018469110131263733
step: 380, loss: 0.07142571359872818
step: 390, loss: 0.022226423025131226
step: 400, loss: 0.2049795687198639
step: 410, loss: 0.09293204545974731
step: 420, loss: 0.0915091335773468
step: 430, loss: 0.024499060586094856
step: 440, loss: 0.020447416231036186
step: 450, loss: 0.1478925496339798
step: 460, loss: 0.026456618681550026
step: 470, loss: 0.017366118729114532
step: 480, loss: 0.244769886136055
step: 490, loss: 0.15173733234405518
step: 500, loss: 0.013197933323681355
step: 510, loss: 0.011440618894994259
step: 520, loss: 0.016075965017080307
step: 530, loss: 0.09643781185150146
epoch 1: dev_f1=0.8862328463922089, f1=0.8880139982502188, best_f1=0.8880139982502188
step: 0, loss: 0.027123117819428444
step: 10, loss: 0.026338135823607445
step: 20, loss: 0.07250263541936874
step: 30, loss: 0.03884856775403023
step: 40, loss: 0.03714107349514961
step: 50, loss: 0.01172158494591713
step: 60, loss: 0.014440882951021194
step: 70, loss: 0.021105002611875534
step: 80, loss: 0.07951915264129639
step: 90, loss: 0.08481177687644958
step: 100, loss: 0.17928250133991241
step: 110, loss: 0.17544758319854736
step: 120, loss: 0.08588632941246033
step: 130, loss: 0.005172215402126312
step: 140, loss: 0.022481007501482964
step: 150, loss: 0.011166481301188469
step: 160, loss: 0.09637632966041565
step: 170, loss: 0.032618358731269836
step: 180, loss: 0.03167242556810379
step: 190, loss: 0.002543935552239418
step: 200, loss: 0.19948044419288635
step: 210, loss: 0.07538725435733795
step: 220, loss: 0.0532255619764328
step: 230, loss: 0.18050789833068848
step: 240, loss: 0.08618813008069992
step: 250, loss: 0.12979282438755035
step: 260, loss: 0.0064550056122243404
step: 270, loss: 0.11957432329654694
step: 280, loss: 0.09045504778623581
step: 290, loss: 0.006989157292991877
step: 300, loss: 0.03458409756422043
step: 310, loss: 0.2776796817779541
step: 320, loss: 0.0881800651550293
step: 330, loss: 0.020171280950307846
step: 340, loss: 0.015269461087882519
step: 350, loss: 0.10323181003332138
step: 360, loss: 0.1541816145181656
step: 370, loss: 0.16151267290115356
step: 380, loss: 0.07692285627126694
step: 390, loss: 0.20267783105373383
step: 400, loss: 0.011703033931553364
step: 410, loss: 0.139314204454422
step: 420, loss: 0.0073202201165258884
step: 430, loss: 0.1187252625823021
step: 440, loss: 0.12650282680988312
step: 450, loss: 0.06214530020952225
step: 460, loss: 0.13231141865253448
step: 470, loss: 0.03858409449458122
step: 480, loss: 0.03790995106101036
step: 490, loss: 0.011704702861607075
step: 500, loss: 0.0027356420177966356
step: 510, loss: 0.017381181940436363
step: 520, loss: 0.06970144063234329
step: 530, loss: 0.13132070004940033
epoch 2: dev_f1=0.8796163069544364, f1=0.8836764001914792, best_f1=0.8880139982502188
step: 0, loss: 0.07270300388336182
step: 10, loss: 0.016161203384399414
step: 20, loss: 0.014367125928401947
step: 30, loss: 0.009692562744021416
step: 40, loss: 0.00252066389657557
step: 50, loss: 0.021078767254948616
step: 60, loss: 0.024587981402873993
step: 70, loss: 0.0044047096744179726
step: 80, loss: 0.05988835170865059
step: 90, loss: 0.1203465387225151
step: 100, loss: 0.08858970552682877
step: 110, loss: 0.033394794911146164
step: 120, loss: 0.09053076058626175
step: 130, loss: 0.06634341180324554
step: 140, loss: 0.0909259244799614
step: 150, loss: 0.016932472586631775
step: 160, loss: 0.09664614498615265
step: 170, loss: 0.01746000349521637
step: 180, loss: 0.022019054740667343
step: 190, loss: 0.031796250492334366
step: 200, loss: 0.2425350546836853
step: 210, loss: 0.05212371423840523
step: 220, loss: 0.08920735865831375
step: 230, loss: 0.018391722813248634
step: 240, loss: 0.06494436413049698
step: 250, loss: 0.023193571716547012
step: 260, loss: 0.1746547967195511
step: 270, loss: 0.06524913012981415
step: 280, loss: 0.06940102577209473
step: 290, loss: 0.019917655736207962
step: 300, loss: 0.012850165367126465
step: 310, loss: 0.07312461733818054
step: 320, loss: 0.08232053369283676
step: 330, loss: 0.018908565863966942
step: 340, loss: 0.08967707306146622
step: 350, loss: 0.013136991299688816
step: 360, loss: 0.10404258221387863
step: 370, loss: 0.05800578370690346
step: 380, loss: 0.045663345605134964
step: 390, loss: 0.02435280755162239
step: 400, loss: 0.028077969327569008
step: 410, loss: 0.05214669182896614
step: 420, loss: 0.06337160617113113
step: 430, loss: 0.018504086881875992
step: 440, loss: 0.004771395120769739
step: 450, loss: 0.07631218433380127
step: 460, loss: 0.01666838862001896
step: 470, loss: 0.04067973047494888
step: 480, loss: 0.0050413720309734344
step: 490, loss: 0.0034797745756804943
step: 500, loss: 0.008980320766568184
step: 510, loss: 0.07191584259271622
step: 520, loss: 0.06341332942247391
step: 530, loss: 0.10415250062942505
epoch 3: dev_f1=0.7821888412017167, f1=0.8025410269984119, best_f1=0.8880139982502188
step: 0, loss: 0.06491941213607788
step: 10, loss: 0.039473164826631546
step: 20, loss: 0.0737885907292366
step: 30, loss: 0.044381022453308105
step: 40, loss: 0.002532127546146512
step: 50, loss: 0.00472638476639986
step: 60, loss: 0.014344324357807636
step: 70, loss: 0.0211737472563982
step: 80, loss: 0.07013317197561264
step: 90, loss: 0.09081975370645523
step: 100, loss: 0.09202565252780914
step: 110, loss: 0.059077613055706024
step: 120, loss: 0.004849362187087536
step: 130, loss: 0.0482821986079216
step: 140, loss: 0.044191356748342514
step: 150, loss: 0.06589366495609283
step: 160, loss: 0.06611787527799606
step: 170, loss: 0.02370920404791832
step: 180, loss: 0.024233894422650337
step: 190, loss: 0.01621277630329132
step: 200, loss: 0.006046830676496029
step: 210, loss: 0.06251587718725204
step: 220, loss: 0.00994944665580988
step: 230, loss: 0.07314182072877884
step: 240, loss: 0.06353944540023804
step: 250, loss: 0.051133569329977036
step: 260, loss: 0.007914705201983452
step: 270, loss: 0.05402912572026253
step: 280, loss: 0.02912125736474991
step: 290, loss: 0.07576552033424377
step: 300, loss: 0.00356625416316092
step: 310, loss: 0.04876158386468887
step: 320, loss: 0.024264637380838394
step: 330, loss: 0.007749802432954311
step: 340, loss: 0.012504762038588524
step: 350, loss: 0.07322405278682709
step: 360, loss: 0.01628876104950905
step: 370, loss: 0.0034059034660458565
step: 380, loss: 0.06467677652835846
step: 390, loss: 0.011435355059802532
step: 400, loss: 0.006357679143548012
step: 410, loss: 0.11311853677034378
step: 420, loss: 0.031691767275333405
step: 430, loss: 0.0772501677274704
step: 440, loss: 0.003135945415124297
step: 450, loss: 0.017276782542467117
step: 460, loss: 0.0024595563299953938
step: 470, loss: 0.21297653019428253
step: 480, loss: 0.09918298572301865
step: 490, loss: 0.0434565469622612
step: 500, loss: 0.006613609381020069
step: 510, loss: 0.04922067001461983
step: 520, loss: 0.03200358524918556
step: 530, loss: 0.09031586349010468
epoch 4: dev_f1=0.876040703052729, f1=0.8782728525493799, best_f1=0.8880139982502188
step: 0, loss: 0.07041464745998383
step: 10, loss: 0.061634838581085205
step: 20, loss: 0.05663028359413147
step: 30, loss: 0.00017365525127388537
step: 40, loss: 0.0031907500233501196
step: 50, loss: 7.864068902563304e-05
step: 60, loss: 0.027973845601081848
step: 70, loss: 0.014579445123672485
step: 80, loss: 0.00017027449212037027
step: 90, loss: 0.05544992908835411
step: 100, loss: 0.04031004384160042
step: 110, loss: 0.07760529220104218
step: 120, loss: 0.02557358145713806
step: 130, loss: 0.0032858385238796473
step: 140, loss: 0.25888583064079285
step: 150, loss: 0.01975625939667225
step: 160, loss: 0.051456645131111145
step: 170, loss: 0.0880507156252861
step: 180, loss: 0.08919140696525574
step: 190, loss: 0.00193555629812181
step: 200, loss: 0.02459632232785225
step: 210, loss: 0.0483432412147522
step: 220, loss: 0.056151095777750015
step: 230, loss: 0.042117565870285034
step: 240, loss: 0.015703575685620308
step: 250, loss: 0.017987621948122978
step: 260, loss: 0.04217696189880371
step: 270, loss: 0.012500864453613758
step: 280, loss: 0.00013677289825864136
step: 290, loss: 0.054301947355270386
step: 300, loss: 0.09287100285291672
step: 310, loss: 0.05420898273587227
step: 320, loss: 0.015069549903273582
step: 330, loss: 0.0005613764515146613
step: 340, loss: 0.013821243308484554
step: 350, loss: 0.050492290407419205
step: 360, loss: 0.00019826675998046994
step: 370, loss: 0.023187274113297462
step: 380, loss: 0.09360118955373764
step: 390, loss: 0.20265233516693115
step: 400, loss: 0.035919055342674255
step: 410, loss: 0.011483687907457352
step: 420, loss: 0.0002873355697374791
step: 430, loss: 0.00026986957527697086
step: 440, loss: 0.02106505073606968
step: 450, loss: 0.005225894041359425
step: 460, loss: 0.07038620114326477
step: 470, loss: 0.009540858678519726
step: 480, loss: 0.09049630910158157
step: 490, loss: 0.12169746309518814
step: 500, loss: 0.007684466429054737
step: 510, loss: 0.009815671481192112
step: 520, loss: 0.04850544035434723
step: 530, loss: 0.0039254059083759785
epoch 5: dev_f1=0.7144508670520233, f1=0.7001733102253033, best_f1=0.8880139982502188
step: 0, loss: 0.0467386357486248
step: 10, loss: 0.006049477960914373
step: 20, loss: 0.07033270597457886
step: 30, loss: 0.00980968028306961
step: 40, loss: 0.05547722056508064
step: 50, loss: 0.0317305289208889
step: 60, loss: 0.07027862221002579
step: 70, loss: 0.0801188126206398
step: 80, loss: 0.004466173704713583
step: 90, loss: 0.016026625409722328
step: 100, loss: 0.09071953594684601
step: 110, loss: 0.00029474220355041325
step: 120, loss: 0.002040343126282096
step: 130, loss: 0.006405513733625412
step: 140, loss: 0.041102465242147446
step: 150, loss: 0.005887535400688648
step: 160, loss: 0.021987274289131165
step: 170, loss: 0.00038606271846219897
step: 180, loss: 0.09260299056768417
step: 190, loss: 0.007172571960836649
step: 200, loss: 0.06159232184290886
step: 210, loss: 0.11380975693464279
step: 220, loss: 0.003612457076087594
step: 230, loss: 0.07775518298149109
step: 240, loss: 0.0039925118908286095
step: 250, loss: 0.06565132737159729
step: 260, loss: 0.053826406598091125
step: 270, loss: 0.07284954190254211
step: 280, loss: 0.013520960696041584
step: 290, loss: 0.10340560227632523
step: 300, loss: 0.09202884137630463
step: 310, loss: 0.03193693608045578
step: 320, loss: 0.005975177977234125
step: 330, loss: 0.009565401822328568
step: 340, loss: 0.025970619171857834
step: 350, loss: 0.029705144464969635
step: 360, loss: 0.009493519552052021
step: 370, loss: 0.0072418563067913055
step: 380, loss: 0.0038973805494606495
step: 390, loss: 0.018095597624778748
step: 400, loss: 0.0002357991470489651
step: 410, loss: 0.043739162385463715
step: 420, loss: 0.013142159208655357
step: 430, loss: 0.0058558424934744835
step: 440, loss: 0.018772248178720474
step: 450, loss: 0.08287656307220459
step: 460, loss: 0.012431971728801727
step: 470, loss: 0.03560873121023178
step: 480, loss: 0.006875285413116217
step: 490, loss: 0.07198861986398697
step: 500, loss: 0.05626654252409935
step: 510, loss: 0.04350704699754715
step: 520, loss: 0.006017097271978855
step: 530, loss: 0.11996801942586899
epoch 6: dev_f1=0.7793880837359098, f1=0.7798810167658193, best_f1=0.8880139982502188
step: 0, loss: 0.015418139286339283
step: 10, loss: 0.028214817866683006
step: 20, loss: 0.014444048516452312
step: 30, loss: 0.0008833463652990758
step: 40, loss: 0.005961262155324221
step: 50, loss: 0.08995147794485092
step: 60, loss: 0.044379979372024536
step: 70, loss: 0.0007170374155975878
step: 80, loss: 0.0003731141914613545
step: 90, loss: 0.20062755048274994
step: 100, loss: 0.050344184041023254
step: 110, loss: 0.02089143730700016
step: 120, loss: 0.003351776394993067
step: 130, loss: 0.05368691310286522
step: 140, loss: 0.00018830705084837973
step: 150, loss: 0.003867522580549121
step: 160, loss: 0.0008264201460406184
step: 170, loss: 0.002095739124342799
step: 180, loss: 0.0024538161233067513
step: 190, loss: 0.023020755499601364
step: 200, loss: 0.01586495153605938
step: 210, loss: 0.005443908274173737
step: 220, loss: 0.03305653855204582
step: 230, loss: 0.0001713711826596409
step: 240, loss: 0.007001178804785013
step: 250, loss: 0.03188656270503998
step: 260, loss: 0.004798285663127899
step: 270, loss: 0.015388761647045612
step: 280, loss: 0.016715139150619507
step: 290, loss: 0.07475798577070236
step: 300, loss: 0.013233665376901627
step: 310, loss: 0.0006970015238039196
step: 320, loss: 0.004325299058109522
step: 330, loss: 0.035353053361177444
step: 340, loss: 0.0006341719417832792
step: 350, loss: 0.009180077351629734
step: 360, loss: 0.02520829066634178
step: 370, loss: 0.007288266904652119
step: 380, loss: 0.11288226395845413
step: 390, loss: 0.0003976953448727727
step: 400, loss: 0.0006259800866246223
step: 410, loss: 0.0810667872428894
step: 420, loss: 0.0327482670545578
step: 430, loss: 0.011589545756578445
step: 440, loss: 0.03704063594341278
step: 450, loss: 0.03440103679895401
step: 460, loss: 0.14138731360435486
step: 470, loss: 0.010216807015240192
step: 480, loss: 0.0037853270769119263
step: 490, loss: 0.035950250923633575
step: 500, loss: 0.01711183600127697
step: 510, loss: 0.07053407281637192
step: 520, loss: 0.0718095600605011
step: 530, loss: 0.013904554769396782
epoch 7: dev_f1=0.7424412094064949, f1=0.7462520821765686, best_f1=0.8880139982502188
step: 0, loss: 0.038482874631881714
step: 10, loss: 0.004148032050579786
step: 20, loss: 0.0018347417935729027
step: 30, loss: 0.01769230328500271
step: 40, loss: 0.059120409190654755
step: 50, loss: 0.004724537488073111
step: 60, loss: 0.025530677288770676
step: 70, loss: 0.0018206340027973056
step: 80, loss: 0.03240108862519264
step: 90, loss: 0.010941061191260815
step: 100, loss: 0.0388803668320179
step: 110, loss: 0.014125341549515724
step: 120, loss: 0.03939591720700264
step: 130, loss: 0.04633481800556183
step: 140, loss: 0.06326919049024582
step: 150, loss: 0.03433475270867348
step: 160, loss: 8.738142059883103e-05
step: 170, loss: 0.007796952500939369
step: 180, loss: 0.0018212988507002592
step: 190, loss: 0.015125115402042866
step: 200, loss: 0.18216344714164734
step: 210, loss: 0.015308946371078491
step: 220, loss: 0.0325593426823616
step: 230, loss: 0.0017682347679510713
step: 240, loss: 0.05640001222491264
step: 250, loss: 0.040376074612140656
step: 260, loss: 0.00020591299107763916
step: 270, loss: 0.032105524092912674
step: 280, loss: 0.024632658809423447
step: 290, loss: 5.6889013649197295e-05
step: 300, loss: 0.03575506433844566
step: 310, loss: 0.04414648190140724
step: 320, loss: 0.0005413309554569423
step: 330, loss: 0.00017966855375561863
step: 340, loss: 0.05365171656012535
step: 350, loss: 0.005148607771843672
step: 360, loss: 0.002241043606773019
step: 370, loss: 0.021310953423380852
step: 380, loss: 0.06095549464225769
step: 390, loss: 0.0333896279335022
step: 400, loss: 0.01319951843470335
step: 410, loss: 0.08443694561719894
step: 420, loss: 0.02974531054496765
step: 430, loss: 0.0004957971978001297
step: 440, loss: 0.015936603769659996
step: 450, loss: 0.0015230602584779263
step: 460, loss: 0.01623351126909256
step: 470, loss: 0.0004660438862629235
step: 480, loss: 0.00013508058327715844
step: 490, loss: 0.03224022313952446
step: 500, loss: 0.01126447506248951
step: 510, loss: 0.022042447701096535
step: 520, loss: 0.0008957893005572259
step: 530, loss: 0.010382895357906818
epoch 8: dev_f1=0.726027397260274, f1=0.717217787913341, best_f1=0.8880139982502188
step: 0, loss: 0.008472111076116562
step: 10, loss: 0.01879117637872696
step: 20, loss: 0.00013425183715298772
step: 30, loss: 0.05454994738101959
step: 40, loss: 0.020523419603705406
step: 50, loss: 0.05777745693922043
step: 60, loss: 0.02025890350341797
step: 70, loss: 0.010583866387605667
step: 80, loss: 4.5906177547294647e-05
step: 90, loss: 0.00025004669441841543
step: 100, loss: 9.311382018495351e-05
step: 110, loss: 0.011438362300395966
step: 120, loss: 9.56970761762932e-05
step: 130, loss: 0.00017179196584038436
step: 140, loss: 0.03048229031264782
step: 150, loss: 0.055545657873153687
step: 160, loss: 0.020511487498879433
step: 170, loss: 0.00207927986048162
step: 180, loss: 0.03132301941514015
step: 190, loss: 0.00017092376947402954
step: 200, loss: 0.004762895405292511
step: 210, loss: 0.0010539420181885362
step: 220, loss: 0.0004134243063163012
step: 230, loss: 0.11641848832368851
step: 240, loss: 0.0004991852911189198
step: 250, loss: 0.003713899524882436
step: 260, loss: 0.00016558432253077626
step: 270, loss: 0.00020536199735943228
step: 280, loss: 0.005714149679988623
step: 290, loss: 0.029240161180496216
step: 300, loss: 8.551112841814756e-05
step: 310, loss: 0.08136044442653656
step: 320, loss: 0.022273819893598557
step: 330, loss: 0.0023754616267979145
step: 340, loss: 0.0002531659265514463
step: 350, loss: 0.02571714296936989
step: 360, loss: 0.037609849125146866
step: 370, loss: 0.028873497620224953
step: 380, loss: 0.030847953632473946
step: 390, loss: 0.06054496765136719
step: 400, loss: 0.00827873032540083
step: 410, loss: 0.01517872791737318
step: 420, loss: 0.020253747701644897
step: 430, loss: 0.004328055772930384
step: 440, loss: 0.0003169934789184481
step: 450, loss: 0.00010738814307842404
step: 460, loss: 0.04148424416780472
step: 470, loss: 0.06579920649528503
step: 480, loss: 0.22307386994361877
step: 490, loss: 0.1791859120130539
step: 500, loss: 0.0763719230890274
step: 510, loss: 0.06658241897821426
step: 520, loss: 0.020280003547668457
step: 530, loss: 0.10608984529972076
epoch 9: dev_f1=0.6102756892230576, f1=0.6130841121495327, best_f1=0.8880139982502188
step: 0, loss: 0.022464018315076828
step: 10, loss: 0.03995237872004509
step: 20, loss: 0.00036703539080917835
step: 30, loss: 0.0004587276198435575
step: 40, loss: 0.02050832100212574
step: 50, loss: 0.004891915712505579
step: 60, loss: 0.05213187634944916
step: 70, loss: 0.0007648583268746734
step: 80, loss: 0.005516235716640949
step: 90, loss: 0.008960213512182236
step: 100, loss: 0.00031235674396157265
step: 110, loss: 0.0014838386559858918
step: 120, loss: 0.0038766043726354837
step: 130, loss: 0.0007120897644199431
step: 140, loss: 3.9486454625148326e-05
step: 150, loss: 0.012147125788033009
step: 160, loss: 0.011808600276708603
step: 170, loss: 0.0003131055855192244
step: 180, loss: 0.009883874095976353
step: 190, loss: 8.426440035691485e-05
step: 200, loss: 6.104602653067559e-05
step: 210, loss: 0.029501408338546753
step: 220, loss: 7.431428821291775e-05
step: 230, loss: 0.02873927913606167
step: 240, loss: 0.00546274334192276
step: 250, loss: 0.005136557854712009
step: 260, loss: 0.0022589240688830614
step: 270, loss: 9.881627920549363e-05
step: 280, loss: 3.4699871321208775e-05
step: 290, loss: 3.5627552279038355e-05
step: 300, loss: 0.02752254158258438
step: 310, loss: 0.0011335129383951426
step: 320, loss: 0.036126311868429184
step: 330, loss: 0.02427859418094158
step: 340, loss: 0.1896343231201172
step: 350, loss: 0.07015714049339294
step: 360, loss: 0.06789970397949219
step: 370, loss: 0.029019184410572052
step: 380, loss: 0.004987984895706177
step: 390, loss: 0.025333279743790627
step: 400, loss: 0.0004553394392132759
step: 410, loss: 0.07618183642625809
step: 420, loss: 0.01101318746805191
step: 430, loss: 0.02784530632197857
step: 440, loss: 0.00383164850063622
step: 450, loss: 0.006155785638839006
step: 460, loss: 0.02216629683971405
step: 470, loss: 0.030193783342838287
step: 480, loss: 0.006738670635968447
step: 490, loss: 0.05509406700730324
step: 500, loss: 0.03809087350964546
step: 510, loss: 0.044237278401851654
step: 520, loss: 0.13809597492218018
step: 530, loss: 0.038544975221157074
epoch 10: dev_f1=0.6742651469706058, f1=0.6726403823178017, best_f1=0.8880139982502188
step: 0, loss: 0.03657310828566551
step: 10, loss: 3.987388845416717e-05
step: 20, loss: 0.020771954208612442
step: 30, loss: 0.01191492099314928
step: 40, loss: 0.0015689983265474439
step: 50, loss: 0.0007073857123032212
step: 60, loss: 0.03718180954456329
step: 70, loss: 0.0006276560598053038
step: 80, loss: 0.0031541448552161455
step: 90, loss: 0.0004778089059982449
step: 100, loss: 0.007250831928104162
step: 110, loss: 4.297546183806844e-05
step: 120, loss: 0.0025084875524044037
step: 130, loss: 0.0006084911292418838
step: 140, loss: 0.007079558912664652
step: 150, loss: 0.005676629487425089
step: 160, loss: 0.0192241407930851
step: 170, loss: 0.007632919121533632
step: 180, loss: 0.0017338459147140384
step: 190, loss: 0.0091682318598032
step: 200, loss: 5.833365867147222e-05
step: 210, loss: 0.006890953052788973
step: 220, loss: 7.05398342688568e-05
step: 230, loss: 0.00951404683291912
step: 240, loss: 0.003246234031394124
step: 250, loss: 0.014559812843799591
step: 260, loss: 0.0015685256803408265
step: 270, loss: 0.00010222989658359438
step: 280, loss: 0.045456454157829285
step: 290, loss: 0.005011309403926134
step: 300, loss: 0.1310264617204666
step: 310, loss: 0.0141481077298522
step: 320, loss: 0.011699657887220383
step: 330, loss: 0.022537747398018837
step: 340, loss: 0.007858474738895893
step: 350, loss: 0.038788992911577225
step: 360, loss: 0.0001859785697888583
step: 370, loss: 0.0008968528127297759
step: 380, loss: 0.0009715897031128407
step: 390, loss: 0.001494495663791895
step: 400, loss: 0.00012785784201696515
step: 410, loss: 4.605303911375813e-05
step: 420, loss: 0.00018805447325576097
step: 430, loss: 4.865561277256347e-05
step: 440, loss: 7.311640365514904e-05
step: 450, loss: 0.034925345331430435
step: 460, loss: 0.0006506785866804421
step: 470, loss: 0.00011486996663734317
step: 480, loss: 0.029016319662332535
step: 490, loss: 0.08108843117952347
step: 500, loss: 0.016311239451169968
step: 510, loss: 7.837182056391612e-05
step: 520, loss: 0.03761998191475868
step: 530, loss: 9.375939407618716e-05
epoch 11: dev_f1=0.3546423135464231, f1=0.3651515151515151, best_f1=0.8880139982502188
step: 0, loss: 0.0015997571172192693
step: 10, loss: 0.02673444338142872
step: 20, loss: 0.012971713207662106
step: 30, loss: 0.005471905693411827
step: 40, loss: 0.00011923370766453445
step: 50, loss: 0.007613763213157654
step: 60, loss: 0.0024973999243229628
step: 70, loss: 0.018769139423966408
step: 80, loss: 0.030533162876963615
step: 90, loss: 0.00016198803496081382
step: 100, loss: 0.007010323461145163
step: 110, loss: 0.0001515522162662819
step: 120, loss: 2.729463631112594e-05
step: 130, loss: 0.00017930599278770387
step: 140, loss: 0.0018579148454591632
step: 150, loss: 8.530681225238368e-05
step: 160, loss: 0.0008154671522788703
step: 170, loss: 0.03491736575961113
step: 180, loss: 0.0003682539099827409
step: 190, loss: 0.00497204577550292
step: 200, loss: 4.668152178055607e-05
step: 210, loss: 0.04723603278398514
step: 220, loss: 0.025390008464455605
step: 230, loss: 0.00389239308424294
step: 240, loss: 0.0013401223113760352
step: 250, loss: 0.0025132426526397467
step: 260, loss: 0.0034752297215163708
step: 270, loss: 5.897913797525689e-05
step: 280, loss: 0.07336793839931488
step: 290, loss: 7.334833208005875e-05
step: 300, loss: 5.274458453641273e-05
step: 310, loss: 0.037675049155950546
step: 320, loss: 4.6207507693907246e-05
step: 330, loss: 0.014021642506122589
step: 340, loss: 2.9916991479694843e-05
step: 350, loss: 0.00047340200399048626
step: 360, loss: 0.028861405327916145
step: 370, loss: 0.005435807630419731
step: 380, loss: 0.0637086033821106
step: 390, loss: 4.2935214878525585e-05
step: 400, loss: 0.006093146279454231
step: 410, loss: 0.006068652495741844
step: 420, loss: 0.0015964023768901825
step: 430, loss: 4.079621430719271e-05
step: 440, loss: 0.0003553916758392006
step: 450, loss: 0.000302688917145133
step: 460, loss: 0.07657286524772644
step: 470, loss: 6.011395453242585e-05
step: 480, loss: 0.03854217007756233
step: 490, loss: 0.0005568573833443224
step: 500, loss: 2.1606387235806324e-05
step: 510, loss: 0.0005699894391000271
step: 520, loss: 0.023432815447449684
step: 530, loss: 0.0006107562221586704
epoch 12: dev_f1=0.567125081859856, f1=0.5509933774834437, best_f1=0.8880139982502188
step: 0, loss: 0.0015319264493882656
step: 10, loss: 9.544465865474194e-05
step: 20, loss: 0.0048761023208498955
step: 30, loss: 0.013564664870500565
step: 40, loss: 8.747799438424408e-05
step: 50, loss: 6.39974678051658e-05
step: 60, loss: 0.01827017217874527
step: 70, loss: 0.0013381368480622768
step: 80, loss: 2.745823258010205e-05
step: 90, loss: 0.00796739012002945
step: 100, loss: 0.02848389744758606
step: 110, loss: 3.995911538368091e-05
step: 120, loss: 0.008368613198399544
step: 130, loss: 0.06694017350673676
step: 140, loss: 3.4932112612295896e-05
step: 150, loss: 0.012924558483064175
step: 160, loss: 0.018630454316735268
step: 170, loss: 0.03893718123435974
step: 180, loss: 0.013230113312602043
step: 190, loss: 0.02321256697177887
step: 200, loss: 0.003243135055527091
step: 210, loss: 0.0648641437292099
step: 220, loss: 0.00043362227734178305
step: 230, loss: 0.030099041759967804
step: 240, loss: 0.024571187794208527
step: 250, loss: 8.268599776783958e-05
step: 260, loss: 0.004580703563988209
step: 270, loss: 0.0005869560409337282
step: 280, loss: 0.0017240791348740458
step: 290, loss: 0.026207923889160156
step: 300, loss: 0.003958499990403652
step: 310, loss: 4.285205068299547e-05
step: 320, loss: 0.024007566273212433
step: 330, loss: 0.02522016502916813
step: 340, loss: 0.0016440184554085135
step: 350, loss: 0.003320074873045087
step: 360, loss: 2.2328977138386108e-05
step: 370, loss: 9.718190995045006e-05
step: 380, loss: 0.00027809213497675955
step: 390, loss: 1.3965998732601292e-05
step: 400, loss: 0.00029088632436469197
step: 410, loss: 0.020446158945560455
step: 420, loss: 0.0007620487012900412
step: 430, loss: 0.0034395805560052395
step: 440, loss: 1.860374686657451e-05
step: 450, loss: 0.0014565924648195505
step: 460, loss: 0.0017927142325788736
step: 470, loss: 0.0038122511468827724
step: 480, loss: 0.011432641185820103
step: 490, loss: 0.04104253649711609
step: 500, loss: 0.02493700198829174
step: 510, loss: 0.0699995905160904
step: 520, loss: 0.022611383348703384
step: 530, loss: 7.803335756761953e-05
epoch 13: dev_f1=0.5017182130584192, f1=0.4879393521709166, best_f1=0.8880139982502188
step: 0, loss: 0.000939776306040585
step: 10, loss: 0.015253473073244095
step: 20, loss: 3.358765388838947e-05
step: 30, loss: 0.08201279491186142
step: 40, loss: 4.088130663149059e-05
step: 50, loss: 4.8594163672532886e-05
step: 60, loss: 7.116411143215373e-05
step: 70, loss: 1.5221403373288922e-05
step: 80, loss: 0.009502598084509373
step: 90, loss: 2.4496799596818164e-05
step: 100, loss: 5.402803799370304e-05
step: 110, loss: 1.760919258231297e-05
step: 120, loss: 8.605416951468214e-05
step: 130, loss: 0.0001134129342972301
step: 140, loss: 0.0016011613188311458
step: 150, loss: 8.78028295119293e-05
step: 160, loss: 1.7836408005678095e-05
step: 170, loss: 0.020224889740347862
step: 180, loss: 0.0384078212082386
step: 190, loss: 0.01874336414039135
step: 200, loss: 0.0014002704992890358
step: 210, loss: 3.1504594517173246e-05
step: 220, loss: 2.15950894926209e-05
step: 230, loss: 0.04243127629160881
step: 240, loss: 0.07625754922628403
step: 250, loss: 0.008798748254776001
step: 260, loss: 0.0001329425722360611
step: 270, loss: 0.042132697999477386
step: 280, loss: 0.10641089081764221
step: 290, loss: 0.007092670537531376
step: 300, loss: 0.0002860424283426255
step: 310, loss: 1.7191980077768676e-05
step: 320, loss: 0.00035273440880700946
step: 330, loss: 0.00916336104273796
step: 340, loss: 0.02505621686577797
step: 350, loss: 0.00015916115080472082
step: 360, loss: 6.51770387776196e-05
step: 370, loss: 0.009652026928961277
step: 380, loss: 1.9650598915177397e-05
step: 390, loss: 0.03874524310231209
step: 400, loss: 2.4906454200390726e-05
step: 410, loss: 5.514786244020797e-05
step: 420, loss: 0.0003405206080060452
step: 430, loss: 0.00010293703235220164
step: 440, loss: 3.072811887250282e-05
step: 450, loss: 0.0042021130211651325
step: 460, loss: 3.7479396269191056e-05
step: 470, loss: 0.03099202923476696
step: 480, loss: 0.0010621354449540377
step: 490, loss: 0.001520354999229312
step: 500, loss: 0.021459734067320824
step: 510, loss: 0.00039922547875903547
step: 520, loss: 0.040469106286764145
step: 530, loss: 1.1820265171991196e-05
epoch 14: dev_f1=0.4204379562043795, f1=0.4035346097201768, best_f1=0.8880139982502188
step: 0, loss: 8.599341526860371e-05
step: 10, loss: 0.0003247180429752916
step: 20, loss: 0.0013678171671926975
step: 30, loss: 0.012082171626389027
step: 40, loss: 2.2489106413559057e-05
step: 50, loss: 4.327758142608218e-05
step: 60, loss: 0.01789895072579384
step: 70, loss: 1.6599713489995338e-05
step: 80, loss: 0.005033728200942278
step: 90, loss: 2.4113049221341498e-05
step: 100, loss: 0.0005545845488086343
step: 110, loss: 2.04549687623512e-05
step: 120, loss: 0.0018635678570717573
step: 130, loss: 0.0026232132222503424
step: 140, loss: 1.4800399185332935e-05
step: 150, loss: 0.015740448608994484
step: 160, loss: 0.0007175739738158882
step: 170, loss: 0.00021100025332998484
step: 180, loss: 0.04027096927165985
step: 190, loss: 0.04531995207071304
step: 200, loss: 0.020185064524412155
step: 210, loss: 0.0026439898647367954
step: 220, loss: 0.05738925188779831
step: 230, loss: 0.00556799815967679
step: 240, loss: 1.509470439486904e-05
step: 250, loss: 2.706302075239364e-05
step: 260, loss: 0.0015713840257376432
step: 270, loss: 0.0033352351747453213
step: 280, loss: 0.00012302112008910626
step: 290, loss: 4.024076770292595e-05
step: 300, loss: 0.009607082232832909
step: 310, loss: 0.005620651412755251
step: 320, loss: 0.00024451204808428884
step: 330, loss: 0.0037813212256878614
step: 340, loss: 0.03171820938587189
step: 350, loss: 0.0051694647409021854
step: 360, loss: 1.231943224411225e-05
step: 370, loss: 0.017917931079864502
step: 380, loss: 1.6003601558622904e-05
step: 390, loss: 0.01630479097366333
step: 400, loss: 0.02386586181819439
step: 410, loss: 4.987888678442687e-05
step: 420, loss: 0.044277094304561615
step: 430, loss: 0.0005313486326485872
step: 440, loss: 4.183356577414088e-05
step: 450, loss: 0.018274053931236267
step: 460, loss: 0.021567748859524727
step: 470, loss: 0.07447344809770584
step: 480, loss: 0.03046729415655136
step: 490, loss: 0.0006429732893593609
step: 500, loss: 0.021090086549520493
step: 510, loss: 5.1175149565096945e-05
step: 520, loss: 6.514490814879537e-05
step: 530, loss: 3.8963753468124196e-05
epoch 15: dev_f1=0.5822622107969151, f1=0.5871794871794872, best_f1=0.8880139982502188
step: 0, loss: 0.009882942773401737
step: 10, loss: 0.00044315803097561
step: 20, loss: 0.00045958702685311437
step: 30, loss: 0.00040567805990576744
step: 40, loss: 0.00215937034226954
step: 50, loss: 2.078989564324729e-05
step: 60, loss: 1.443532710254658e-05
step: 70, loss: 0.025318272411823273
step: 80, loss: 1.894651177281048e-05
step: 90, loss: 0.000107031904917676
step: 100, loss: 0.039914820343256
step: 110, loss: 8.619946311227977e-05
step: 120, loss: 0.010212219320237637
step: 130, loss: 3.127568925265223e-05
step: 140, loss: 0.0001975275226868689
step: 150, loss: 3.87689215131104e-05
step: 160, loss: 0.0018585564102977514
step: 170, loss: 0.00017085435683839023
step: 180, loss: 0.016029944643378258
step: 190, loss: 0.0011877685319632292
step: 200, loss: 0.0007000621990300715
step: 210, loss: 0.02694009430706501
step: 220, loss: 2.680612487893086e-05
step: 230, loss: 0.01256466656923294
step: 240, loss: 2.4023418518481776e-05
step: 250, loss: 1.6432019037893042e-05
step: 260, loss: 3.7376386899268255e-05
step: 270, loss: 0.025382472202181816
step: 280, loss: 0.0003563743084669113
step: 290, loss: 0.03408972918987274
step: 300, loss: 1.6372421669075266e-05
step: 310, loss: 0.0047980318777263165
step: 320, loss: 3.5993929486721754e-05
step: 330, loss: 0.006609235890209675
step: 340, loss: 0.01599741540849209
step: 350, loss: 0.00015438775881193578
step: 360, loss: 1.9229426470701583e-05
step: 370, loss: 0.02644171193242073
step: 380, loss: 3.5714987461688e-05
step: 390, loss: 0.03101494535803795
step: 400, loss: 0.003318779170513153
step: 410, loss: 1.1913391972484533e-05
step: 420, loss: 0.03449419140815735
step: 430, loss: 0.018654054030776024
step: 440, loss: 0.0337320901453495
step: 450, loss: 1.9065471860812977e-05
step: 460, loss: 0.0008156605763360858
step: 470, loss: 1.3466757081914693e-05
step: 480, loss: 0.017910245805978775
step: 490, loss: 0.0055138166062533855
step: 500, loss: 0.0718921646475792
step: 510, loss: 1.6081827197922394e-05
step: 520, loss: 0.004558185115456581
step: 530, loss: 0.003011487191542983
epoch 16: dev_f1=0.3420245398773006, f1=0.33664881407804126, best_f1=0.8880139982502188
step: 0, loss: 0.034024469554424286
step: 10, loss: 0.014421246945858002
step: 20, loss: 0.026405293494462967
step: 30, loss: 0.004232325591146946
step: 40, loss: 0.0012710358714684844
step: 50, loss: 1.3552486961998511e-05
step: 60, loss: 0.0002661311882548034
step: 70, loss: 0.016506392508745193
step: 80, loss: 5.004102422390133e-05
step: 90, loss: 1.674482336966321e-05
step: 100, loss: 1.4159700185700785e-05
step: 110, loss: 1.3761105037701782e-05
step: 120, loss: 0.07110843807458878
step: 130, loss: 2.4533299438189715e-05
step: 140, loss: 0.0007876193267293274
step: 150, loss: 0.015108447521924973
step: 160, loss: 0.0008762309444136918
step: 170, loss: 1.5381574485218152e-05
step: 180, loss: 0.02456553466618061
step: 190, loss: 4.604769856086932e-05
step: 200, loss: 0.01871412806212902
step: 210, loss: 0.019278597086668015
step: 220, loss: 2.2763448214391246e-05
step: 230, loss: 6.134296563686803e-05
step: 240, loss: 0.0002763140946626663
step: 250, loss: 9.364338620798662e-05
step: 260, loss: 0.001277542905882001
step: 270, loss: 0.00014044568524695933
step: 280, loss: 6.77330099279061e-05
step: 290, loss: 2.314425728400238e-05
step: 300, loss: 0.0024753862526267767
step: 310, loss: 0.0004042636719532311
step: 320, loss: 0.0262199304997921
step: 330, loss: 1.2438592420949135e-05
step: 340, loss: 0.004311939235776663
step: 350, loss: 0.03336530551314354
step: 360, loss: 0.02765752002596855
step: 370, loss: 1.3500286513590254e-05
step: 380, loss: 0.01536119170486927
step: 390, loss: 0.0015392620116472244
step: 400, loss: 0.027099566534161568
step: 410, loss: 0.007347829174250364
step: 420, loss: 3.386252501513809e-05
step: 430, loss: 1.4487372027360834e-05
step: 440, loss: 0.0022108592092990875
step: 450, loss: 1.3947188563179225e-05
step: 460, loss: 1.3768548342341091e-05
step: 470, loss: 4.516475019045174e-05
step: 480, loss: 0.0017785952659323812
step: 490, loss: 0.008377105928957462
step: 500, loss: 0.025996411219239235
step: 510, loss: 0.031707148998975754
step: 520, loss: 0.018175220116972923
step: 530, loss: 1.7057695004041307e-05
epoch 17: dev_f1=0.4374100719424461, f1=0.41569767441860467, best_f1=0.8880139982502188
step: 0, loss: 0.019018083810806274
step: 10, loss: 0.001159080071374774
step: 20, loss: 0.02903650887310505
step: 30, loss: 7.745260518277064e-05
step: 40, loss: 0.0012574008433148265
step: 50, loss: 0.0025308604817837477
step: 60, loss: 1.6718613551347516e-05
step: 70, loss: 0.017011482268571854
step: 80, loss: 0.0012263584649190307
step: 90, loss: 6.012539233779535e-05
step: 100, loss: 0.00017094040231313556
step: 110, loss: 1.1525945410539862e-05
step: 120, loss: 0.01764795556664467
step: 130, loss: 0.00010885416122619063
step: 140, loss: 2.011945252888836e-05
step: 150, loss: 1.6007217709557153e-05
step: 160, loss: 0.058525703847408295
step: 170, loss: 0.00879374798387289
step: 180, loss: 0.014141958206892014
step: 190, loss: 0.03807750344276428
step: 200, loss: 0.011227414011955261
step: 210, loss: 1.74378164956579e-05
step: 220, loss: 0.0008067082380875945
step: 230, loss: 1.5474437532247975e-05
step: 240, loss: 0.00013483731891028583
step: 250, loss: 1.2297090506763197e-05
step: 260, loss: 0.00092874257825315
step: 270, loss: 0.0017223255708813667
step: 280, loss: 4.1407838580198586e-05
step: 290, loss: 0.000435237045167014
step: 300, loss: 1.2986204637854826e-05
step: 310, loss: 0.020579736679792404
step: 320, loss: 0.010221305303275585
step: 330, loss: 1.3504021808330435e-05
step: 340, loss: 9.706361015560105e-05
step: 350, loss: 1.3895202755520586e-05
step: 360, loss: 1.0434469913889188e-05
step: 370, loss: 1.6774538380559534e-05
step: 380, loss: 0.00040904537308961153
step: 390, loss: 2.029802999459207e-05
step: 400, loss: 2.8660448151640594e-05
step: 410, loss: 0.001359068206511438
step: 420, loss: 1.710987271508202e-05
step: 430, loss: 0.004164277110248804
step: 440, loss: 1.4789102351642214e-05
step: 450, loss: 1.79738399310736e-05
step: 460, loss: 0.03896508738398552
step: 470, loss: 0.019059961661696434
step: 480, loss: 1.7039184967870824e-05
step: 490, loss: 1.2375298865663353e-05
step: 500, loss: 0.00010819160524988547
step: 510, loss: 0.00045174642582423985
step: 520, loss: 0.00014125832240097225
step: 530, loss: 0.00622660294175148
epoch 18: dev_f1=0.41867250182348653, f1=0.4171511627906976, best_f1=0.8880139982502188
step: 0, loss: 0.0290956012904644
step: 10, loss: 1.285954931518063e-05
step: 20, loss: 1.2066107046848629e-05
step: 30, loss: 0.037183552980422974
step: 40, loss: 0.018157577142119408
step: 50, loss: 0.0015477180713787675
step: 60, loss: 1.1086390259151813e-05
step: 70, loss: 1.3291708455653861e-05
step: 80, loss: 1.0278005902364384e-05
step: 90, loss: 0.02088237926363945
step: 100, loss: 0.00012379598047118634
step: 110, loss: 0.03503316268324852
step: 120, loss: 0.0001079422581824474
step: 130, loss: 0.000727963401004672
step: 140, loss: 2.0788755136891268e-05
step: 150, loss: 1.2319441339059267e-05
step: 160, loss: 0.03768576309084892
step: 170, loss: 0.02744525671005249
step: 180, loss: 1.909137972688768e-05
step: 190, loss: 1.4267651749833021e-05
step: 200, loss: 0.01571768894791603
step: 210, loss: 0.00015968919615261257
step: 220, loss: 0.03238650783896446
step: 230, loss: 0.0045314677990973
step: 240, loss: 0.00371930911205709
step: 250, loss: 1.1347145118634216e-05
step: 260, loss: 0.00010275273962179199
step: 270, loss: 0.00903374794870615
step: 280, loss: 0.06324237585067749
step: 290, loss: 1.6305313693010248e-05
step: 300, loss: 1.1332245776429772e-05
step: 310, loss: 4.4142288970761e-05
step: 320, loss: 6.548514647874981e-05
step: 330, loss: 8.450615860056132e-05
step: 340, loss: 0.00011372334120096639
step: 350, loss: 2.0160618078080006e-05
step: 360, loss: 1.2941537534061354e-05
step: 370, loss: 9.52551363297971e-06
step: 380, loss: 6.62462116451934e-05
step: 390, loss: 4.792513573192991e-05
step: 400, loss: 1.0590932106424589e-05
step: 410, loss: 1.101933048630599e-05
step: 420, loss: 0.016790760681033134
step: 430, loss: 1.1283801541139837e-05
step: 440, loss: 9.763921298144851e-06
step: 450, loss: 1.2643512491194997e-05
step: 460, loss: 0.030326619744300842
step: 470, loss: 3.397813270566985e-05
step: 480, loss: 1.701623114058748e-05
step: 490, loss: 1.013269957184093e-05
step: 500, loss: 3.410806675674394e-05
step: 510, loss: 2.1832614947925322e-05
step: 520, loss: 7.833531708456576e-05
step: 530, loss: 4.499393980950117e-05
epoch 19: dev_f1=0.4058823529411764, f1=0.40789473684210525, best_f1=0.8880139982502188
step: 0, loss: 1.2315709682297893e-05
step: 10, loss: 1.118694490287453e-05
step: 20, loss: 4.708155756816268e-05
step: 30, loss: 1.5303221516660415e-05
step: 40, loss: 0.034148864448070526
step: 50, loss: 0.018718598410487175
step: 60, loss: 0.0002942453429568559
step: 70, loss: 9.357876479043625e-06
step: 80, loss: 1.7757767636794597e-05
step: 90, loss: 1.5630990674253553e-05
step: 100, loss: 1.5705549230915494e-05
step: 110, loss: 1.2054906619596295e-05
step: 120, loss: 1.2591359336511232e-05
step: 130, loss: 1.1023046681657434e-05
step: 140, loss: 0.05038140341639519
step: 150, loss: 1.1365754289727192e-05
step: 160, loss: 8.226383943110704e-05
step: 170, loss: 0.001088470802642405
step: 180, loss: 0.023800915107131004
step: 190, loss: 0.006189263425767422
step: 200, loss: 3.0967719794716686e-05
step: 210, loss: 0.007607612758874893
step: 220, loss: 6.033436511643231e-05
step: 230, loss: 0.00026644644094631076
step: 240, loss: 0.05547773838043213
step: 250, loss: 0.00032656636903993785
step: 260, loss: 0.025420550256967545
step: 270, loss: 0.002047685906291008
step: 280, loss: 0.014164187014102936
step: 290, loss: 1.160044575954089e-05
step: 300, loss: 1.2457271623134147e-05
step: 310, loss: 0.034782905131578445
step: 320, loss: 0.001158552011474967
step: 330, loss: 1.3153829968359787e-05
step: 340, loss: 1.394708851876203e-05
step: 350, loss: 3.316325819469057e-05
step: 360, loss: 0.018518390133976936
step: 370, loss: 0.00021295847545843571
step: 380, loss: 0.022984320297837257
step: 390, loss: 0.02038579061627388
step: 400, loss: 9.640992175263818e-06
step: 410, loss: 1.3116610716679133e-05
step: 420, loss: 6.028214920661412e-05
step: 430, loss: 1.5269297364284284e-05
step: 440, loss: 1.0721285434556194e-05
step: 450, loss: 3.413553349673748e-05
step: 460, loss: 1.1030509995180182e-05
step: 470, loss: 4.5125816541258246e-05
step: 480, loss: 1.490825798100559e-05
step: 490, loss: 0.00011531491327332333
step: 500, loss: 1.4111152268014848e-05
step: 510, loss: 2.0621175281121396e-05
step: 520, loss: 0.0183815136551857
step: 530, loss: 0.026574846357107162
epoch 20: dev_f1=0.39674315321983716, f1=0.40176600441501104, best_f1=0.8880139982502188
