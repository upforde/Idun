cuda
Device: cuda
step: 0, loss: 0.5811672210693359
step: 10, loss: 0.3778296411037445
step: 20, loss: 0.36489084362983704
step: 30, loss: 0.24593020975589752
step: 40, loss: 0.14135709404945374
step: 50, loss: 0.19329574704170227
step: 60, loss: 0.06300964206457138
step: 70, loss: 0.05997507646679878
step: 80, loss: 0.07640070468187332
step: 90, loss: 0.12986837327480316
step: 100, loss: 0.19167865812778473
step: 110, loss: 0.10462441295385361
step: 120, loss: 0.1738322377204895
step: 130, loss: 0.06864557415246964
step: 140, loss: 0.08574692904949188
step: 150, loss: 0.09754856675863266
step: 160, loss: 0.06350208818912506
step: 170, loss: 0.20694544911384583
step: 180, loss: 0.13458456099033356
step: 190, loss: 0.1802113652229309
step: 200, loss: 0.09922783076763153
step: 210, loss: 0.030809514224529266
step: 220, loss: 0.23934267461299896
step: 230, loss: 0.10112523287534714
step: 240, loss: 0.12009815871715546
step: 250, loss: 0.06776066869497299
step: 260, loss: 0.17029239237308502
step: 270, loss: 0.05990532413125038
step: 280, loss: 0.13648256659507751
step: 290, loss: 0.09855001419782639
step: 300, loss: 0.055313099175691605
step: 310, loss: 0.22244299948215485
step: 320, loss: 0.00913330726325512
step: 330, loss: 0.06004013493657112
step: 340, loss: 0.07393888384103775
step: 350, loss: 0.08035241067409515
step: 360, loss: 0.22856497764587402
step: 370, loss: 0.0846303254365921
step: 380, loss: 0.016677197068929672
step: 390, loss: 0.14467184245586395
step: 400, loss: 0.3083871006965637
step: 410, loss: 0.09491044282913208
step: 420, loss: 0.09910240024328232
epoch 1: dev_f1=0.9865168539325843, f1=0.979591836734694, best_f1=0.979591836734694
step: 0, loss: 0.04815320298075676
step: 10, loss: 0.0700591430068016
step: 20, loss: 0.19707030057907104
step: 30, loss: 0.053517334163188934
step: 40, loss: 0.12290504574775696
step: 50, loss: 0.0835903063416481
step: 60, loss: 0.014390773139894009
step: 70, loss: 0.04121439903974533
step: 80, loss: 0.04133864864706993
step: 90, loss: 0.18945097923278809
step: 100, loss: 0.058891765773296356
step: 110, loss: 0.054475679993629456
step: 120, loss: 0.09147262573242188
step: 130, loss: 0.15209975838661194
step: 140, loss: 0.04012239724397659
step: 150, loss: 0.14949829876422882
step: 160, loss: 0.046017471700906754
step: 170, loss: 0.1422397643327713
step: 180, loss: 0.07418664544820786
step: 190, loss: 0.07829362899065018
step: 200, loss: 0.2484370470046997
step: 210, loss: 0.06320829689502716
step: 220, loss: 0.056573741137981415
step: 230, loss: 0.15509885549545288
step: 240, loss: 0.03474742919206619
step: 250, loss: 0.13348129391670227
step: 260, loss: 0.10697091370820999
step: 270, loss: 0.06531941890716553
step: 280, loss: 0.09188105165958405
step: 290, loss: 0.15211434662342072
step: 300, loss: 0.11283399164676666
step: 310, loss: 0.06994669884443283
step: 320, loss: 0.12323635071516037
step: 330, loss: 0.09034164994955063
step: 340, loss: 0.19398225843906403
step: 350, loss: 0.08669567853212357
step: 360, loss: 0.18444226682186127
step: 370, loss: 0.037604738026857376
step: 380, loss: 0.014199454337358475
step: 390, loss: 0.10093841701745987
step: 400, loss: 0.0636596754193306
step: 410, loss: 0.012959553860127926
step: 420, loss: 0.1276751309633255
epoch 2: dev_f1=0.987598647125141, f1=0.9818181818181818, best_f1=0.9818181818181818
step: 0, loss: 0.04664904624223709
step: 10, loss: 0.012336027808487415
step: 20, loss: 0.06024136021733284
step: 30, loss: 0.07403552532196045
step: 40, loss: 0.07456725835800171
step: 50, loss: 0.09612700343132019
step: 60, loss: 0.008805128745734692
step: 70, loss: 0.04223522171378136
step: 80, loss: 0.060998961329460144
step: 90, loss: 0.19871726632118225
step: 100, loss: 0.07614975422620773
step: 110, loss: 0.07284525781869888
step: 120, loss: 0.08157781511545181
step: 130, loss: 0.08545704185962677
step: 140, loss: 0.13215366005897522
step: 150, loss: 0.04183647036552429
step: 160, loss: 0.05899549648165703
step: 170, loss: 0.0655914694070816
step: 180, loss: 0.03474213555455208
step: 190, loss: 0.1078161895275116
step: 200, loss: 0.12407670170068741
step: 210, loss: 0.028208183124661446
step: 220, loss: 0.085482157766819
step: 230, loss: 0.09998572617769241
step: 240, loss: 0.07916412502527237
step: 250, loss: 0.027803510427474976
step: 260, loss: 0.08574508130550385
step: 270, loss: 0.06279586255550385
step: 280, loss: 0.07442857325077057
step: 290, loss: 0.2824655771255493
step: 300, loss: 0.12916536629199982
step: 310, loss: 0.02682507410645485
step: 320, loss: 0.10518117994070053
step: 330, loss: 0.09138645976781845
step: 340, loss: 0.1685701161623001
step: 350, loss: 0.08408588171005249
step: 360, loss: 0.02590617537498474
step: 370, loss: 0.08357246220111847
step: 380, loss: 0.154001846909523
step: 390, loss: 0.2616138160228729
step: 400, loss: 0.035668618977069855
step: 410, loss: 0.04735489562153816
step: 420, loss: 0.05414765700697899
epoch 3: dev_f1=0.9865771812080537, f1=0.978675645342312, best_f1=0.9818181818181818
step: 0, loss: 0.08602800965309143
step: 10, loss: 0.023051617667078972
step: 20, loss: 0.010622883215546608
step: 30, loss: 0.015225001610815525
step: 40, loss: 0.07715839147567749
step: 50, loss: 0.005780274048447609
step: 60, loss: 0.04731568694114685
step: 70, loss: 0.16964900493621826
step: 80, loss: 0.04178207740187645
step: 90, loss: 0.07352298498153687
step: 100, loss: 0.030853362753987312
step: 110, loss: 0.03858308866620064
step: 120, loss: 0.055845651775598526
step: 130, loss: 0.0843789204955101
step: 140, loss: 0.06835030764341354
step: 150, loss: 0.09435976296663284
step: 160, loss: 0.09100478887557983
step: 170, loss: 0.08870625495910645
step: 180, loss: 0.1833927184343338
step: 190, loss: 0.07131312042474747
step: 200, loss: 0.15381091833114624
step: 210, loss: 0.12308985739946365
step: 220, loss: 0.06234810873866081
step: 230, loss: 0.08472678065299988
step: 240, loss: 0.11784407496452332
step: 250, loss: 0.05428440496325493
step: 260, loss: 0.10900810360908508
step: 270, loss: 0.19516581296920776
step: 280, loss: 0.13602888584136963
step: 290, loss: 0.024683494120836258
step: 300, loss: 0.19972461462020874
step: 310, loss: 0.10815215110778809
step: 320, loss: 0.00933395978063345
step: 330, loss: 0.07867385447025299
step: 340, loss: 0.06460043787956238
step: 350, loss: 0.0077118766494095325
step: 360, loss: 0.029335033148527145
step: 370, loss: 0.04695439338684082
step: 380, loss: 0.22059650719165802
step: 390, loss: 0.1622152328491211
step: 400, loss: 0.05065450817346573
step: 410, loss: 0.12870152294635773
step: 420, loss: 0.09582213312387466
epoch 4: dev_f1=0.9854096520763187, f1=0.9787234042553192, best_f1=0.9818181818181818
step: 0, loss: 0.03198809176683426
step: 10, loss: 0.07615001499652863
step: 20, loss: 0.046133849769830704
step: 30, loss: 0.029037432745099068
step: 40, loss: 0.21059943735599518
step: 50, loss: 0.05992133915424347
step: 60, loss: 0.0810641273856163
step: 70, loss: 0.07193280011415482
step: 80, loss: 0.0007672499632462859
step: 90, loss: 0.11330161243677139
step: 100, loss: 0.045635826885700226
step: 110, loss: 0.033646970987319946
step: 120, loss: 0.09216750413179398
step: 130, loss: 0.07557661831378937
step: 140, loss: 0.20686520636081696
step: 150, loss: 0.043759703636169434
step: 160, loss: 0.16296423971652985
step: 170, loss: 0.13514478504657745
step: 180, loss: 0.12364634871482849
step: 190, loss: 0.1407533884048462
step: 200, loss: 0.07750833034515381
step: 210, loss: 0.05212254077196121
step: 220, loss: 0.10870933532714844
step: 230, loss: 0.0938597172498703
step: 240, loss: 0.011592033319175243
step: 250, loss: 0.03467164188623428
step: 260, loss: 0.0699702575802803
step: 270, loss: 0.13910147547721863
step: 280, loss: 0.13783809542655945
step: 290, loss: 0.024505140259861946
step: 300, loss: 0.08823812752962112
step: 310, loss: 0.11435806751251221
step: 320, loss: 0.11583172529935837
step: 330, loss: 0.034701522439718246
step: 340, loss: 0.03182174637913704
step: 350, loss: 0.029111916199326515
step: 360, loss: 0.025936981663107872
step: 370, loss: 0.07408599555492401
step: 380, loss: 0.050195660442113876
step: 390, loss: 0.09492015838623047
step: 400, loss: 0.08384368568658829
step: 410, loss: 0.05152172967791557
step: 420, loss: 0.0536954328417778
epoch 5: dev_f1=0.992108229988726, f1=0.9785310734463276, best_f1=0.9785310734463276
step: 0, loss: 0.06460010260343552
step: 10, loss: 0.05916672572493553
step: 20, loss: 0.08952303230762482
step: 30, loss: 0.14229483902454376
step: 40, loss: 0.02576158568263054
step: 50, loss: 0.1316061168909073
step: 60, loss: 0.12129124999046326
step: 70, loss: 0.011948371306061745
step: 80, loss: 0.12235529720783234
step: 90, loss: 0.14188545942306519
step: 100, loss: 0.024429617449641228
step: 110, loss: 0.03872726112604141
step: 120, loss: 0.06638497859239578
step: 130, loss: 0.07091348618268967
step: 140, loss: 0.043074898421764374
step: 150, loss: 0.07074910402297974
step: 160, loss: 0.09314531832933426
step: 170, loss: 0.05212397500872612
step: 180, loss: 0.18252982199192047
step: 190, loss: 0.09589888900518417
step: 200, loss: 0.04828273877501488
step: 210, loss: 0.10835586488246918
step: 220, loss: 0.054911840707063675
step: 230, loss: 0.05276552587747574
step: 240, loss: 0.03976913169026375
step: 250, loss: 0.04868865758180618
step: 260, loss: 0.041578441858291626
step: 270, loss: 0.09610603749752045
step: 280, loss: 0.05176391452550888
step: 290, loss: 0.14722567796707153
step: 300, loss: 0.07605025917291641
step: 310, loss: 0.1064930334687233
step: 320, loss: 0.00014234862464945763
step: 330, loss: 0.028574125841259956
step: 340, loss: 0.16149741411209106
step: 350, loss: 0.020830996334552765
step: 360, loss: 0.07686226069927216
step: 370, loss: 0.017065025866031647
step: 380, loss: 0.07577444612979889
step: 390, loss: 0.008050716482102871
step: 400, loss: 0.10697194188833237
step: 410, loss: 0.005993261933326721
step: 420, loss: 0.07686416804790497
epoch 6: dev_f1=0.9909706546275394, f1=0.9852774631936579, best_f1=0.9785310734463276
step: 0, loss: 0.07091593742370605
step: 10, loss: 0.11580702662467957
step: 20, loss: 0.024824783205986023
step: 30, loss: 0.11312314122915268
step: 40, loss: 0.052847784012556076
step: 50, loss: 0.01998295448720455
step: 60, loss: 0.050202153623104095
step: 70, loss: 0.14711463451385498
step: 80, loss: 0.033048249781131744
step: 90, loss: 0.13303151726722717
step: 100, loss: 0.2403070628643036
step: 110, loss: 0.14137227833271027
step: 120, loss: 0.028939463198184967
step: 130, loss: 0.03158709034323692
step: 140, loss: 0.08864309638738632
step: 150, loss: 0.07198352366685867
step: 160, loss: 0.12524420022964478
step: 170, loss: 0.0518239364027977
step: 180, loss: 0.16660070419311523
step: 190, loss: 0.1121177077293396
step: 200, loss: 0.06396572291851044
step: 210, loss: 0.055453136563301086
step: 220, loss: 0.12563595175743103
step: 230, loss: 0.1880628764629364
step: 240, loss: 0.01310574822127819
step: 250, loss: 0.07228828221559525
step: 260, loss: 0.1478176712989807
step: 270, loss: 0.0725739374756813
step: 280, loss: 0.08123775571584702
step: 290, loss: 0.09959758073091507
step: 300, loss: 0.11271888017654419
step: 310, loss: 0.07325629144906998
step: 320, loss: 0.0967475101351738
step: 330, loss: 0.10562274605035782
step: 340, loss: 0.022904152050614357
step: 350, loss: 0.10223733633756638
step: 360, loss: 0.07918272167444229
step: 370, loss: 0.033713072538375854
step: 380, loss: 0.11735711991786957
step: 390, loss: 0.04630754888057709
step: 400, loss: 0.05095629021525383
step: 410, loss: 8.159291610354558e-05
step: 420, loss: 0.07071230560541153
epoch 7: dev_f1=0.9932584269662922, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.05443873256444931
step: 10, loss: 0.05488501861691475
step: 20, loss: 0.1329142302274704
step: 30, loss: 0.04391112178564072
step: 40, loss: 0.017002753913402557
step: 50, loss: 0.035661909729242325
step: 60, loss: 0.18472182750701904
step: 70, loss: 0.10278724879026413
step: 80, loss: 0.07752784341573715
step: 90, loss: 0.05325396731495857
step: 100, loss: 0.010693153366446495
step: 110, loss: 0.009964288212358952
step: 120, loss: 0.0720471739768982
step: 130, loss: 0.009928041137754917
step: 140, loss: 0.10584462434053421
step: 150, loss: 0.1172361895442009
step: 160, loss: 0.24902458488941193
step: 170, loss: 0.03656774386763573
step: 180, loss: 0.0676637664437294
step: 190, loss: 0.04074890539050102
step: 200, loss: 0.015606177039444447
step: 210, loss: 0.13137143850326538
step: 220, loss: 0.01740463636815548
step: 230, loss: 0.012602842412889004
step: 240, loss: 0.06386055052280426
step: 250, loss: 0.03257889673113823
step: 260, loss: 0.04447447881102562
step: 270, loss: 0.014633477665483952
step: 280, loss: 0.07315034419298172
step: 290, loss: 0.0731261819601059
step: 300, loss: 0.022464321926236153
step: 310, loss: 0.0639234185218811
step: 320, loss: 0.15310366451740265
step: 330, loss: 0.03213619068264961
step: 340, loss: 0.054603688418865204
step: 350, loss: 0.07324957102537155
step: 360, loss: 0.02032403275370598
step: 370, loss: 0.14469420909881592
step: 380, loss: 0.028978539630770683
step: 390, loss: 0.024714143946766853
step: 400, loss: 0.017438838258385658
step: 410, loss: 0.022897988557815552
step: 420, loss: 0.05749201774597168
epoch 8: dev_f1=0.9854096520763187, f1=0.9810479375696767, best_f1=0.984304932735426
step: 0, loss: 0.09915727376937866
step: 10, loss: 0.16392922401428223
step: 20, loss: 0.014279455877840519
step: 30, loss: 0.06142309680581093
step: 40, loss: 0.039235517382621765
step: 50, loss: 0.016530925408005714
step: 60, loss: 0.041089579463005066
step: 70, loss: 0.0581401027739048
step: 80, loss: 0.038220684975385666
step: 90, loss: 0.07710028439760208
step: 100, loss: 0.0747910588979721
step: 110, loss: 0.07319286465644836
step: 120, loss: 0.03461362421512604
step: 130, loss: 0.006941747386008501
step: 140, loss: 0.13770942389965057
step: 150, loss: 0.01571352407336235
step: 160, loss: 0.02354024164378643
step: 170, loss: 0.12058834731578827
step: 180, loss: 0.0055649238638579845
step: 190, loss: 0.02119889110326767
step: 200, loss: 0.006574258673936129
step: 210, loss: 0.09156332910060883
step: 220, loss: 0.06750153005123138
step: 230, loss: 0.01902305707335472
step: 240, loss: 0.007117437198758125
step: 250, loss: 0.07039579004049301
step: 260, loss: 0.018234670162200928
step: 270, loss: 0.16669180989265442
step: 280, loss: 0.052754923701286316
step: 290, loss: 0.002505928510800004
step: 300, loss: 0.014339365996420383
step: 310, loss: 0.01660788059234619
step: 320, loss: 0.10132905840873718
step: 330, loss: 0.11349643021821976
step: 340, loss: 0.0682482197880745
step: 350, loss: 0.1474599689245224
step: 360, loss: 0.10107342898845673
step: 370, loss: 0.06454523652791977
step: 380, loss: 0.0861111581325531
step: 390, loss: 0.012402769178152084
step: 400, loss: 0.09574193507432938
step: 410, loss: 0.055718328803777695
step: 420, loss: 0.16702860593795776
epoch 9: dev_f1=0.9898534385569334, f1=0.9832026875699889, best_f1=0.984304932735426
step: 0, loss: 0.10016424208879471
step: 10, loss: 0.06156785786151886
step: 20, loss: 0.013544689863920212
step: 30, loss: 0.05294734612107277
step: 40, loss: 0.008591686375439167
step: 50, loss: 0.07088389992713928
step: 60, loss: 0.021475734189152718
step: 70, loss: 0.01993115246295929
step: 80, loss: 0.0035699973814189434
step: 90, loss: 0.11141924560070038
step: 100, loss: 0.028004329651594162
step: 110, loss: 0.1621287614107132
step: 120, loss: 0.03833189979195595
step: 130, loss: 0.07044801115989685
step: 140, loss: 0.12532858550548553
step: 150, loss: 0.1777665913105011
step: 160, loss: 0.023120587691664696
step: 170, loss: 0.03618916496634483
step: 180, loss: 0.09317096322774887
step: 190, loss: 0.024505145847797394
step: 200, loss: 0.04571382701396942
step: 210, loss: 0.014853520318865776
step: 220, loss: 0.12582311034202576
step: 230, loss: 0.054795537143945694
step: 240, loss: 0.06269270181655884
step: 250, loss: 0.09709091484546661
step: 260, loss: 0.09811475872993469
step: 270, loss: 0.17049655318260193
step: 280, loss: 0.0729755163192749
step: 290, loss: 0.049482312053442
step: 300, loss: 0.08453132212162018
step: 310, loss: 0.10540346801280975
step: 320, loss: 0.03236433491110802
step: 330, loss: 0.006509972270578146
step: 340, loss: 0.07025156915187836
step: 350, loss: 0.0457816943526268
step: 360, loss: 0.030054839327931404
step: 370, loss: 0.034658052027225494
step: 380, loss: 0.03319643437862396
step: 390, loss: 0.0846041738986969
step: 400, loss: 0.02840298041701317
step: 410, loss: 0.09933231770992279
step: 420, loss: 0.02526899054646492
epoch 10: dev_f1=0.9888392857142857, f1=0.9810479375696767, best_f1=0.984304932735426
step: 0, loss: 0.0711253210902214
step: 10, loss: 0.03154916316270828
step: 20, loss: 0.038519322872161865
step: 30, loss: 0.024642497301101685
step: 40, loss: 0.009149495512247086
step: 50, loss: 0.058304689824581146
step: 60, loss: 0.002597709419205785
step: 70, loss: 0.09837627410888672
step: 80, loss: 0.08445645868778229
step: 90, loss: 0.04716942086815834
step: 100, loss: 0.06543076038360596
step: 110, loss: 0.021206481382250786
step: 120, loss: 0.08836638927459717
step: 130, loss: 0.014903119765222073
step: 140, loss: 0.04868799448013306
step: 150, loss: 0.021779740229249
step: 160, loss: 0.0045173089019954205
step: 170, loss: 0.11134960502386093
step: 180, loss: 0.07419468462467194
step: 190, loss: 0.02441261149942875
step: 200, loss: 0.08715475350618362
step: 210, loss: 0.10416706651449203
step: 220, loss: 0.04444998875260353
step: 230, loss: 0.08437807112932205
step: 240, loss: 0.10214655846357346
step: 250, loss: 0.029000215232372284
step: 260, loss: 0.15145991742610931
step: 270, loss: 0.05774913355708122
step: 280, loss: 0.09027967602014542
step: 290, loss: 0.06438632309436798
step: 300, loss: 0.017439136281609535
step: 310, loss: 0.2090778648853302
step: 320, loss: 0.04341619089245796
step: 330, loss: 0.17916610836982727
step: 340, loss: 0.15713924169540405
step: 350, loss: 0.05852581933140755
step: 360, loss: 0.22870706021785736
step: 370, loss: 0.08522983640432358
step: 380, loss: 0.04981203377246857
step: 390, loss: 0.09625069797039032
step: 400, loss: 0.024143174290657043
step: 410, loss: 0.08924943208694458
step: 420, loss: 0.09640488773584366
epoch 11: dev_f1=0.9887387387387387, f1=0.9798206278026906, best_f1=0.984304932735426
step: 0, loss: 0.03968457877635956
step: 10, loss: 0.08025600761175156
step: 20, loss: 0.04668411239981651
step: 30, loss: 0.11843042820692062
step: 40, loss: 0.017000488936901093
step: 50, loss: 0.028130393475294113
step: 60, loss: 0.035494424402713776
step: 70, loss: 0.014730746857821941
step: 80, loss: 0.06058329716324806
step: 90, loss: 0.12786279618740082
step: 100, loss: 0.08607285469770432
step: 110, loss: 0.05415236949920654
step: 120, loss: 0.03989734128117561
step: 130, loss: 0.0210993904620409
step: 140, loss: 0.09225036203861237
step: 150, loss: 0.046057891100645065
step: 160, loss: 0.09810879826545715
step: 170, loss: 0.0791240856051445
step: 180, loss: 0.027327969670295715
step: 190, loss: 0.03835581988096237
step: 200, loss: 0.08775332570075989
step: 210, loss: 0.007606793195009232
step: 220, loss: 0.04388270527124405
step: 230, loss: 0.0695938989520073
step: 240, loss: 0.010233643464744091
step: 250, loss: 0.02256484515964985
step: 260, loss: 0.03626157343387604
step: 270, loss: 0.009853746742010117
step: 280, loss: 0.07398555427789688
step: 290, loss: 0.08115370571613312
step: 300, loss: 0.06851468235254288
step: 310, loss: 0.0806429535150528
step: 320, loss: 0.007956534624099731
step: 330, loss: 0.03367625176906586
step: 340, loss: 0.062306806445121765
step: 350, loss: 0.07514546066522598
step: 360, loss: 0.009023626334965229
step: 370, loss: 0.11611955612897873
step: 380, loss: 0.024106798693537712
step: 390, loss: 0.12220728397369385
step: 400, loss: 0.05187607929110527
step: 410, loss: 0.03255145251750946
step: 420, loss: 0.06006232649087906
epoch 12: dev_f1=0.9865168539325843, f1=0.9798206278026906, best_f1=0.984304932735426
step: 0, loss: 0.056713514029979706
step: 10, loss: 0.050168778747320175
step: 20, loss: 0.08364791423082352
step: 30, loss: 0.08454817533493042
step: 40, loss: 0.04935162514448166
step: 50, loss: 0.07145494967699051
step: 60, loss: 0.08562461286783218
step: 70, loss: 0.05116216465830803
step: 80, loss: 0.06264245510101318
step: 90, loss: 0.10764709115028381
step: 100, loss: 1.5508217984461226e-05
step: 110, loss: 0.02868296578526497
step: 120, loss: 0.030288606882095337
step: 130, loss: 0.04116315394639969
step: 140, loss: 0.007076372392475605
step: 150, loss: 0.00498171616345644
step: 160, loss: 0.0019025381188839674
step: 170, loss: 0.08674570918083191
step: 180, loss: 0.011817479506134987
step: 190, loss: 0.13362382352352142
step: 200, loss: 0.06425709277391434
step: 210, loss: 0.017044968903064728
step: 220, loss: 0.10578686743974686
step: 230, loss: 0.08321180194616318
step: 240, loss: 0.028076905757188797
step: 250, loss: 0.006687816698104143
step: 260, loss: 0.010599620640277863
step: 270, loss: 0.017337888479232788
step: 280, loss: 0.05925730615854263
step: 290, loss: 0.004531462211161852
step: 300, loss: 0.08260947465896606
step: 310, loss: 0.07350901514291763
step: 320, loss: 0.03439860790967941
step: 330, loss: 0.10832496732473373
step: 340, loss: 0.06733374297618866
step: 350, loss: 0.016194650903344154
step: 360, loss: 0.10545051097869873
step: 370, loss: 0.00026648599305190146
step: 380, loss: 0.019450362771749496
step: 390, loss: 0.099124014377594
step: 400, loss: 0.0782230943441391
step: 410, loss: 0.021544557064771652
step: 420, loss: 0.06399082392454147
epoch 13: dev_f1=0.9898762654668166, f1=0.9798206278026906, best_f1=0.984304932735426
step: 0, loss: 0.09952457249164581
step: 10, loss: 0.027685005217790604
step: 20, loss: 0.13399213552474976
step: 30, loss: 0.035884760320186615
step: 40, loss: 0.06055902689695358
step: 50, loss: 0.1612299531698227
step: 60, loss: 0.005082198418676853
step: 70, loss: 0.054464709013700485
step: 80, loss: 0.00886243861168623
step: 90, loss: 0.00401846831664443
step: 100, loss: 0.03408775106072426
step: 110, loss: 0.07684172689914703
step: 120, loss: 0.044226229190826416
step: 130, loss: 0.07682862877845764
step: 140, loss: 0.022065419703722
step: 150, loss: 0.10487422347068787
step: 160, loss: 0.046553585678339005
step: 170, loss: 0.06697341799736023
step: 180, loss: 0.0721888542175293
step: 190, loss: 0.025856541469693184
step: 200, loss: 0.002593256300315261
step: 210, loss: 0.037314385175704956
step: 220, loss: 0.011378113180398941
step: 230, loss: 0.08219551295042038
step: 240, loss: 0.03552419692277908
step: 250, loss: 0.09254120290279388
step: 260, loss: 0.04218751937150955
step: 270, loss: 0.00047288075438700616
step: 280, loss: 0.09308814257383347
step: 290, loss: 0.03162684664130211
step: 300, loss: 0.03234843164682388
step: 310, loss: 0.019336838275194168
step: 320, loss: 0.05002828687429428
step: 330, loss: 0.012388918548822403
step: 340, loss: 0.07598436623811722
step: 350, loss: 0.024327188730239868
step: 360, loss: 0.12405728548765182
step: 370, loss: 0.002002422232180834
step: 380, loss: 0.06756685674190521
step: 390, loss: 0.042048849165439606
step: 400, loss: 0.0011052718618884683
step: 410, loss: 0.048585906624794006
step: 420, loss: 0.11503832042217255
epoch 14: dev_f1=0.9909706546275394, f1=0.9830890642615557, best_f1=0.984304932735426
step: 0, loss: 0.06003629416227341
step: 10, loss: 0.002069114940240979
step: 20, loss: 0.02246313914656639
step: 30, loss: 0.050364989787340164
step: 40, loss: 0.03710922971367836
step: 50, loss: 0.11188111454248428
step: 60, loss: 0.0011316456366330385
step: 70, loss: 0.06931491196155548
step: 80, loss: 0.014180987142026424
step: 90, loss: 0.04117979854345322
step: 100, loss: 0.01952379010617733
step: 110, loss: 0.05309172347187996
step: 120, loss: 0.028302432969212532
step: 130, loss: 0.000496947905048728
step: 140, loss: 0.006731568370014429
step: 150, loss: 0.06912744045257568
step: 160, loss: 0.09661109745502472
step: 170, loss: 0.04785007983446121
step: 180, loss: 0.008273955434560776
step: 190, loss: 0.016468940302729607
step: 200, loss: 0.00026055972557514906
step: 210, loss: 0.06249811500310898
step: 220, loss: 0.028747152537107468
step: 230, loss: 0.1470327377319336
step: 240, loss: 0.07860289514064789
step: 250, loss: 0.07152529060840607
step: 260, loss: 0.013955226168036461
step: 270, loss: 0.014722366817295551
step: 280, loss: 1.448372768209083e-05
step: 290, loss: 0.03194417059421539
step: 300, loss: 0.03779689222574234
step: 310, loss: 0.044299542903900146
step: 320, loss: 0.03824355825781822
step: 330, loss: 0.04924998804926872
step: 340, loss: 0.03240690007805824
step: 350, loss: 0.06002155318856239
step: 360, loss: 0.09926977008581161
step: 370, loss: 0.07858626544475555
step: 380, loss: 0.019435444846749306
step: 390, loss: 0.07538432627916336
step: 400, loss: 0.05968094989657402
step: 410, loss: 0.00044353623525239527
step: 420, loss: 0.0005788191920146346
epoch 15: dev_f1=0.9909706546275394, f1=0.9819819819819819, best_f1=0.984304932735426
step: 0, loss: 0.03709757328033447
step: 10, loss: 0.0003548792446963489
step: 20, loss: 0.017516007646918297
step: 30, loss: 0.04050276055932045
step: 40, loss: 0.02549433521926403
step: 50, loss: 0.19008967280387878
step: 60, loss: 0.017239024862647057
step: 70, loss: 0.0008310998091474175
step: 80, loss: 0.08956892788410187
step: 90, loss: 0.05800269916653633
step: 100, loss: 0.02113892324268818
step: 110, loss: 0.10060948878526688
step: 120, loss: 0.09954751282930374
step: 130, loss: 0.04686366766691208
step: 140, loss: 0.0001359928137389943
step: 150, loss: 0.002053655218333006
step: 160, loss: 0.0014455219497904181
step: 170, loss: 0.01753302663564682
step: 180, loss: 0.02642234042286873
step: 190, loss: 0.07163819670677185
step: 200, loss: 0.06135637313127518
step: 210, loss: 0.07206623256206512
step: 220, loss: 0.021060753613710403
step: 230, loss: 0.07635556906461716
step: 240, loss: 0.0004638081882148981
step: 250, loss: 0.07529077678918839
step: 260, loss: 0.10585398972034454
step: 270, loss: 0.090410016477108
step: 280, loss: 0.09113673865795135
step: 290, loss: 0.07648949325084686
step: 300, loss: 0.001228434732183814
step: 310, loss: 0.06620659679174423
step: 320, loss: 0.033021826297044754
step: 330, loss: 0.046035513281822205
step: 340, loss: 0.06576777994632721
step: 350, loss: 0.10402276366949081
step: 360, loss: 0.0002070288173854351
step: 370, loss: 0.048625826835632324
step: 380, loss: 0.055593736469745636
step: 390, loss: 0.03400309756398201
step: 400, loss: 0.0007015622104518116
step: 410, loss: 0.02076098695397377
step: 420, loss: 0.00211871019564569
epoch 16: dev_f1=0.992108229988726, f1=0.9831649831649831, best_f1=0.984304932735426
step: 0, loss: 0.04040981084108353
step: 10, loss: 0.04482439532876015
step: 20, loss: 0.02032705582678318
step: 30, loss: 0.06682691723108292
step: 40, loss: 0.0005514758522622287
step: 50, loss: 0.02238733507692814
step: 60, loss: 0.0765020027756691
step: 70, loss: 0.04883533716201782
step: 80, loss: 0.1048438772559166
step: 90, loss: 0.02698252722620964
step: 100, loss: 0.020275510847568512
step: 110, loss: 0.00729589257389307
step: 120, loss: 0.00044842821080237627
step: 130, loss: 0.10165167599916458
step: 140, loss: 0.046108637005090714
step: 150, loss: 0.01279489416629076
step: 160, loss: 0.02643578313291073
step: 170, loss: 0.0174449160695076
step: 180, loss: 0.04504813626408577
step: 190, loss: 0.037991151213645935
step: 200, loss: 0.016767088323831558
step: 210, loss: 0.03497191146016121
step: 220, loss: 0.0789063423871994
step: 230, loss: 0.026863370090723038
step: 240, loss: 0.11738252639770508
step: 250, loss: 0.06600134074687958
step: 260, loss: 0.0247338879853487
step: 270, loss: 0.08734666556119919
step: 280, loss: 0.05901196971535683
step: 290, loss: 0.04637274146080017
step: 300, loss: 0.09141877293586731
step: 310, loss: 0.0874803215265274
step: 320, loss: 0.0694538950920105
step: 330, loss: 0.0606716126203537
step: 340, loss: 0.07645317167043686
step: 350, loss: 0.07399184256792068
step: 360, loss: 0.1359209567308426
step: 370, loss: 0.062378544360399246
step: 380, loss: 0.03179177641868591
step: 390, loss: 0.11567826569080353
step: 400, loss: 0.04558933898806572
step: 410, loss: 0.04373238608241081
step: 420, loss: 0.03121817484498024
epoch 17: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.984304932735426
step: 0, loss: 0.04038500040769577
step: 10, loss: 0.01714319735765457
step: 20, loss: 0.09084746986627579
step: 30, loss: 0.04339417815208435
step: 40, loss: 0.0005749107804149389
step: 50, loss: 0.01630868762731552
step: 60, loss: 0.08932063728570938
step: 70, loss: 0.019896268844604492
step: 80, loss: 0.0005698919994756579
step: 90, loss: 0.05219263583421707
step: 100, loss: 0.044165708124637604
step: 110, loss: 0.0664840042591095
step: 120, loss: 0.025810182094573975
step: 130, loss: 0.07245220988988876
step: 140, loss: 0.045147646218538284
step: 150, loss: 0.038914065808057785
step: 160, loss: 0.0019496737513691187
step: 170, loss: 0.04463930055499077
step: 180, loss: 0.020275425165891647
step: 190, loss: 0.03382948040962219
step: 200, loss: 0.03738444671034813
step: 210, loss: 0.11022407561540604
step: 220, loss: 0.046590063720941544
step: 230, loss: 0.04367009177803993
step: 240, loss: 0.0189790241420269
step: 250, loss: 0.0278690904378891
step: 260, loss: 0.0451749712228775
step: 270, loss: 0.0451294481754303
step: 280, loss: 0.016616234555840492
step: 290, loss: 0.027885228395462036
step: 300, loss: 0.03306615352630615
step: 310, loss: 0.025676842778921127
step: 320, loss: 0.0702950581908226
step: 330, loss: 0.07376091182231903
step: 340, loss: 0.02024684101343155
step: 350, loss: 0.056236956268548965
step: 360, loss: 0.04405811056494713
step: 370, loss: 0.023769231513142586
step: 380, loss: 0.01685427501797676
step: 390, loss: 0.053204767405986786
step: 400, loss: 0.048679664731025696
step: 410, loss: 0.06991492211818695
step: 420, loss: 0.01933956891298294
epoch 18: dev_f1=0.9909706546275394, f1=0.9819819819819819, best_f1=0.984304932735426
step: 0, loss: 0.04452528432011604
step: 10, loss: 0.013154367916285992
step: 20, loss: 0.041771300137043
step: 30, loss: 0.021260308101773262
step: 40, loss: 0.046051912009716034
step: 50, loss: 0.021520910784602165
step: 60, loss: 0.03006526082754135
step: 70, loss: 0.028569500893354416
step: 80, loss: 0.04822301119565964
step: 90, loss: 0.043370913714170456
step: 100, loss: 0.043427158147096634
step: 110, loss: 0.05256291478872299
step: 120, loss: 0.061806462705135345
step: 130, loss: 0.0026017450727522373
step: 140, loss: 0.028058530762791634
step: 150, loss: 0.04856504127383232
step: 160, loss: 0.04211387783288956
step: 170, loss: 0.014304610900580883
step: 180, loss: 0.04914797469973564
step: 190, loss: 0.046927668154239655
step: 200, loss: 0.03522966429591179
step: 210, loss: 0.05689802020788193
step: 220, loss: 0.026133468374609947
step: 230, loss: 0.0024218254256993532
step: 240, loss: 0.04971536248922348
step: 250, loss: 0.08659952133893967
step: 260, loss: 0.02221064642071724
step: 270, loss: 0.025339163839817047
step: 280, loss: 0.03304347023367882
step: 290, loss: 0.07206305861473083
step: 300, loss: 0.12936830520629883
step: 310, loss: 0.021010911092162132
step: 320, loss: 0.09486198425292969
step: 330, loss: 0.05509813129901886
step: 340, loss: 8.203782635973766e-05
step: 350, loss: 0.07652514427900314
step: 360, loss: 0.04472576454281807
step: 370, loss: 0.020342063158750534
step: 380, loss: 0.010911840945482254
step: 390, loss: 0.06982941925525665
step: 400, loss: 0.0010611498728394508
step: 410, loss: 0.039785370230674744
step: 420, loss: 0.07652068138122559
epoch 19: dev_f1=0.9898305084745763, f1=0.9819819819819819, best_f1=0.984304932735426
step: 0, loss: 0.048373032361269
step: 10, loss: 6.789256440242752e-05
step: 20, loss: 0.04396456480026245
step: 30, loss: 0.019705655053257942
step: 40, loss: 0.024460988119244576
step: 50, loss: 0.06446130573749542
step: 60, loss: 0.053708918392658234
step: 70, loss: 0.02260110341012478
step: 80, loss: 0.021658051759004593
step: 90, loss: 0.08562802523374557
step: 100, loss: 0.024144338443875313
step: 110, loss: 0.046227313578128815
step: 120, loss: 2.4775610654614866e-05
step: 130, loss: 0.023624237626791
step: 140, loss: 0.047030042856931686
step: 150, loss: 0.0004586291906889528
step: 160, loss: 0.027397872880101204
step: 170, loss: 0.0006369005423039198
step: 180, loss: 0.03774454817175865
step: 190, loss: 0.030152499675750732
step: 200, loss: 0.012796825729310513
step: 210, loss: 0.006574523169547319
step: 220, loss: 0.000681009900290519
step: 230, loss: 0.06535092741250992
step: 240, loss: 0.12082778662443161
step: 250, loss: 0.01431361585855484
step: 260, loss: 0.06786324083805084
step: 270, loss: 0.0032442070078104734
step: 280, loss: 0.04947258159518242
step: 290, loss: 0.00023699244775343686
step: 300, loss: 0.05863258242607117
step: 310, loss: 0.025227311998605728
step: 320, loss: 0.000822578149382025
step: 330, loss: 0.02110322192311287
step: 340, loss: 0.023447005078196526
step: 350, loss: 0.049579963088035583
step: 360, loss: 0.020797407254576683
step: 370, loss: 0.05021066218614578
step: 380, loss: 0.01257825456559658
step: 390, loss: 0.02434770204126835
step: 400, loss: 0.0263756662607193
step: 410, loss: 0.08763834089040756
step: 420, loss: 0.049946099519729614
epoch 20: dev_f1=0.9886877828054299, f1=0.9808773903262092, best_f1=0.984304932735426
