cuda
Device: cuda
step: 0, loss: 0.3374982476234436
step: 10, loss: 0.14809377491474152
step: 20, loss: 0.3601595163345337
step: 30, loss: 0.3433041274547577
step: 40, loss: 0.3463462293148041
step: 50, loss: 0.1999068558216095
step: 60, loss: 0.18628405034542084
step: 70, loss: 0.09266093373298645
step: 80, loss: 0.060196224600076675
step: 90, loss: 0.11245207488536835
step: 100, loss: 0.10161175578832626
step: 110, loss: 0.16980589926242828
step: 120, loss: 0.16433429718017578
step: 130, loss: 0.11821561306715012
step: 140, loss: 0.17347338795661926
step: 150, loss: 0.17285217344760895
step: 160, loss: 0.18125736713409424
step: 170, loss: 0.16443991661071777
step: 180, loss: 0.14010025560855865
step: 190, loss: 0.025079626590013504
step: 200, loss: 0.20725210011005402
step: 210, loss: 0.11769949644804001
step: 220, loss: 0.098863884806633
step: 230, loss: 0.036843132227659225
step: 240, loss: 0.1908128261566162
step: 250, loss: 0.05113928020000458
step: 260, loss: 0.102937251329422
step: 270, loss: 0.16881805658340454
step: 280, loss: 0.15318135917186737
step: 290, loss: 0.09687440097332001
step: 300, loss: 0.15907500684261322
step: 310, loss: 0.07033602893352509
step: 320, loss: 0.08945484459400177
step: 330, loss: 0.0943135991692543
step: 340, loss: 0.05955403670668602
step: 350, loss: 0.10227242112159729
step: 360, loss: 0.0890769362449646
step: 370, loss: 0.03740214183926582
step: 380, loss: 0.0412982702255249
step: 390, loss: 0.11360069364309311
step: 400, loss: 0.13172531127929688
step: 410, loss: 0.13862577080726624
step: 420, loss: 0.12203070521354675
epoch 1: dev_f1=0.9708520179372198, f1=0.9646522234891676, best_f1=0.9646522234891676
step: 0, loss: 0.13669465482234955
step: 10, loss: 0.08268249034881592
step: 20, loss: 0.09812028706073761
step: 30, loss: 0.16287434101104736
step: 40, loss: 0.08145185559988022
step: 50, loss: 0.014239737764000893
step: 60, loss: 0.10369458794593811
step: 70, loss: 0.07159430533647537
step: 80, loss: 0.07536432147026062
step: 90, loss: 0.07774359732866287
step: 100, loss: 0.07389897853136063
step: 110, loss: 0.16550873219966888
step: 120, loss: 0.07180370390415192
step: 130, loss: 0.1428646445274353
step: 140, loss: 0.13204637169837952
step: 150, loss: 0.07892093062400818
step: 160, loss: 0.10974454879760742
step: 170, loss: 0.06768155843019485
step: 180, loss: 0.16110657155513763
step: 190, loss: 0.09671968966722488
step: 200, loss: 0.04537881538271904
step: 210, loss: 0.10219698399305344
step: 220, loss: 0.08266269415616989
step: 230, loss: 0.04397088661789894
step: 240, loss: 0.11934594064950943
step: 250, loss: 0.06770674139261246
step: 260, loss: 0.06801625341176987
step: 270, loss: 0.07242163270711899
step: 280, loss: 0.05718201398849487
step: 290, loss: 0.06511315703392029
step: 300, loss: 0.06578095257282257
step: 310, loss: 0.03361843153834343
step: 320, loss: 0.2117883712053299
step: 330, loss: 0.07076092809438705
step: 340, loss: 0.02302062138915062
step: 350, loss: 0.07211605459451675
step: 360, loss: 0.04887557774782181
step: 370, loss: 0.2024189829826355
step: 380, loss: 0.053169604390859604
step: 390, loss: 0.018296057358384132
step: 400, loss: 0.07171797007322311
step: 410, loss: 0.049052558839321136
step: 420, loss: 0.03389204293489456
epoch 2: dev_f1=0.9694915254237287, f1=0.9668571428571429, best_f1=0.9646522234891676
step: 0, loss: 0.0627145767211914
step: 10, loss: 0.12722499668598175
step: 20, loss: 0.12791995704174042
step: 30, loss: 0.09658409655094147
step: 40, loss: 0.021992549300193787
step: 50, loss: 0.06422078609466553
step: 60, loss: 0.1356026828289032
step: 70, loss: 0.06997965276241302
step: 80, loss: 0.2605278789997101
step: 90, loss: 0.029140174388885498
step: 100, loss: 0.06074140965938568
step: 110, loss: 0.2014346420764923
step: 120, loss: 0.03495526686310768
step: 130, loss: 0.038207173347473145
step: 140, loss: 0.053659480065107346
step: 150, loss: 0.06293068826198578
step: 160, loss: 0.04854385182261467
step: 170, loss: 0.053909264504909515
step: 180, loss: 0.04232136532664299
step: 190, loss: 0.03831220418214798
step: 200, loss: 0.04297354444861412
step: 210, loss: 0.104641854763031
step: 220, loss: 0.02318526804447174
step: 230, loss: 0.01737844944000244
step: 240, loss: 0.023976953700184822
step: 250, loss: 0.006033362355083227
step: 260, loss: 0.08483736962080002
step: 270, loss: 0.10904374718666077
step: 280, loss: 0.28636032342910767
step: 290, loss: 0.02807324193418026
step: 300, loss: 0.23278291523456573
step: 310, loss: 0.0851101502776146
step: 320, loss: 0.12411266565322876
step: 330, loss: 0.12474268674850464
step: 340, loss: 0.04709974676370621
step: 350, loss: 0.1683889925479889
step: 360, loss: 0.11315460503101349
step: 370, loss: 0.07141529768705368
step: 380, loss: 0.06372268497943878
step: 390, loss: 0.0981767326593399
step: 400, loss: 0.008658213540911674
step: 410, loss: 0.11393216997385025
step: 420, loss: 0.04796794056892395
epoch 3: dev_f1=0.9865771812080537, f1=0.9832026875699889, best_f1=0.9832026875699889
step: 0, loss: 0.06554390490055084
step: 10, loss: 0.11341635882854462
step: 20, loss: 0.03367066755890846
step: 30, loss: 0.023314284160733223
step: 40, loss: 0.1147049218416214
step: 50, loss: 0.02049095928668976
step: 60, loss: 0.1362219750881195
step: 70, loss: 0.012969494797289371
step: 80, loss: 0.16125242412090302
step: 90, loss: 0.0418144166469574
step: 100, loss: 0.0336611233651638
step: 110, loss: 0.1635095477104187
step: 120, loss: 0.0712457150220871
step: 130, loss: 0.047018278390169144
step: 140, loss: 0.06744459271430969
step: 150, loss: 0.010285232216119766
step: 160, loss: 0.020427267998456955
step: 170, loss: 0.02733325958251953
step: 180, loss: 0.023440418764948845
step: 190, loss: 0.0743972584605217
step: 200, loss: 0.1545598953962326
step: 210, loss: 0.01820898801088333
step: 220, loss: 0.07862059772014618
step: 230, loss: 0.030862176790833473
step: 240, loss: 0.03820022940635681
step: 250, loss: 0.17102670669555664
step: 260, loss: 0.045165784657001495
step: 270, loss: 0.15539012849330902
step: 280, loss: 0.04111631587147713
step: 290, loss: 0.12152571231126785
step: 300, loss: 0.0886182188987732
step: 310, loss: 0.034388959407806396
step: 320, loss: 0.08120820671319962
step: 330, loss: 0.027468185871839523
step: 340, loss: 0.09408324211835861
step: 350, loss: 0.06904307752847672
step: 360, loss: 0.05165475606918335
step: 370, loss: 0.13604836165905
step: 380, loss: 0.057908132672309875
step: 390, loss: 0.024863390251994133
step: 400, loss: 0.026621710509061813
step: 410, loss: 0.01177920214831829
step: 420, loss: 0.11767105758190155
epoch 4: dev_f1=0.9887892376681614, f1=0.9785794813979707, best_f1=0.9785794813979707
step: 0, loss: 0.12465529888868332
step: 10, loss: 0.055208947509527206
step: 20, loss: 0.10366008430719376
step: 30, loss: 0.10663598775863647
step: 40, loss: 0.11884934455156326
step: 50, loss: 0.11150673776865005
step: 60, loss: 0.02916964702308178
step: 70, loss: 0.051106952130794525
step: 80, loss: 0.02526482753455639
step: 90, loss: 0.05567598715424538
step: 100, loss: 0.12903468310832977
step: 110, loss: 0.05653616413474083
step: 120, loss: 0.011453306302428246
step: 130, loss: 0.11648862063884735
step: 140, loss: 0.04779595509171486
step: 150, loss: 0.12748509645462036
step: 160, loss: 0.04845280945301056
step: 170, loss: 0.048371296375989914
step: 180, loss: 0.07978639751672745
step: 190, loss: 0.04416579380631447
step: 200, loss: 0.06213053688406944
step: 210, loss: 0.09159623086452484
step: 220, loss: 0.01936376839876175
step: 230, loss: 0.013524915091693401
step: 240, loss: 0.09626862406730652
step: 250, loss: 0.07077179104089737
step: 260, loss: 0.04440394416451454
step: 270, loss: 0.02641788125038147
step: 280, loss: 0.09455045312643051
step: 290, loss: 0.08128266036510468
step: 300, loss: 0.02872118540108204
step: 310, loss: 0.14645175635814667
step: 320, loss: 0.038726042956113815
step: 330, loss: 0.03071410208940506
step: 340, loss: 0.04849081113934517
step: 350, loss: 0.1778833270072937
step: 360, loss: 0.03361455351114273
step: 370, loss: 0.08505651354789734
step: 380, loss: 0.0688605010509491
step: 390, loss: 0.03659805655479431
step: 400, loss: 0.09941097348928452
step: 410, loss: 0.03662121668457985
step: 420, loss: 0.05952707305550575
epoch 5: dev_f1=0.984304932735426, f1=0.9820224719101124, best_f1=0.9785794813979707
step: 0, loss: 0.11396309733390808
step: 10, loss: 0.11183332651853561
step: 20, loss: 0.013297207653522491
step: 30, loss: 0.3261035680770874
step: 40, loss: 0.07066667824983597
step: 50, loss: 0.09038885682821274
step: 60, loss: 0.1109825074672699
step: 70, loss: 0.14885738492012024
step: 80, loss: 0.08980388939380646
step: 90, loss: 0.07079894840717316
step: 100, loss: 0.13597145676612854
step: 110, loss: 0.0850125327706337
step: 120, loss: 0.10929079353809357
step: 130, loss: 0.02604968659579754
step: 140, loss: 0.040472518652677536
step: 150, loss: 0.09703865647315979
step: 160, loss: 0.030716747045516968
step: 170, loss: 0.06511987000703812
step: 180, loss: 0.08825813978910446
step: 190, loss: 0.15875500440597534
step: 200, loss: 0.00831147376447916
step: 210, loss: 0.23784089088439941
step: 220, loss: 0.15401805937290192
step: 230, loss: 0.055349916219711304
step: 240, loss: 0.1357470005750656
step: 250, loss: 0.10026559978723526
step: 260, loss: 0.009671353735029697
step: 270, loss: 0.05653314292430878
step: 280, loss: 0.02119281142950058
step: 290, loss: 0.04920579493045807
step: 300, loss: 0.4631885290145874
step: 310, loss: 0.22867083549499512
step: 320, loss: 0.07628695666790009
step: 330, loss: 0.05562002584338188
step: 340, loss: 0.04408464580774307
step: 350, loss: 0.19429102540016174
step: 360, loss: 0.0749843567609787
step: 370, loss: 0.14675819873809814
step: 380, loss: 0.08792511373758316
step: 390, loss: 0.07962089776992798
step: 400, loss: 0.05570407584309578
step: 410, loss: 0.04428396373987198
step: 420, loss: 0.015918869525194168
epoch 6: dev_f1=0.9865470852017937, f1=0.9774266365688488, best_f1=0.9785794813979707
step: 0, loss: 0.038836438208818436
step: 10, loss: 0.05382731556892395
step: 20, loss: 0.01700037159025669
step: 30, loss: 0.16266237199306488
step: 40, loss: 0.025677533820271492
step: 50, loss: 0.07731139659881592
step: 60, loss: 0.217002272605896
step: 70, loss: 0.045939091593027115
step: 80, loss: 0.0826278105378151
step: 90, loss: 0.14181169867515564
step: 100, loss: 0.0753137469291687
step: 110, loss: 0.014047793112695217
step: 120, loss: 0.14216502010822296
step: 130, loss: 0.06565553694963455
step: 140, loss: 0.06848093122243881
step: 150, loss: 0.07076586782932281
step: 160, loss: 0.07705296576023102
step: 170, loss: 0.09203865379095078
step: 180, loss: 0.029493777081370354
step: 190, loss: 0.08998914808034897
step: 200, loss: 0.06376219540834427
step: 210, loss: 0.0831710547208786
step: 220, loss: 0.0954088494181633
step: 230, loss: 0.11254264414310455
step: 240, loss: 0.18164557218551636
step: 250, loss: 0.017964260652661324
step: 260, loss: 0.01748286932706833
step: 270, loss: 0.04767705872654915
step: 280, loss: 0.0584283247590065
step: 290, loss: 0.10018784552812576
step: 300, loss: 0.09815935045480728
step: 310, loss: 0.16893212497234344
step: 320, loss: 0.1578969955444336
step: 330, loss: 0.10806719958782196
step: 340, loss: 0.14199450612068176
step: 350, loss: 0.0587119460105896
step: 360, loss: 0.06034203991293907
step: 370, loss: 0.07058456540107727
step: 380, loss: 0.118143230676651
step: 390, loss: 0.05733704939484596
step: 400, loss: 0.06915660202503204
step: 410, loss: 0.03238767012953758
step: 420, loss: 0.11727551370859146
epoch 7: dev_f1=0.9888641425389755, f1=0.9757174392935982, best_f1=0.9757174392935982
step: 0, loss: 0.017486849799752235
step: 10, loss: 0.10346630215644836
step: 20, loss: 0.01284435112029314
step: 30, loss: 0.17699044942855835
step: 40, loss: 0.03291711583733559
step: 50, loss: 0.03651096671819687
step: 60, loss: 0.016723306849598885
step: 70, loss: 0.0010623011039569974
step: 80, loss: 0.02577490545809269
step: 90, loss: 0.1618373841047287
step: 100, loss: 0.03798166662454605
step: 110, loss: 0.0886969193816185
step: 120, loss: 0.09910552203655243
step: 130, loss: 0.004968040622770786
step: 140, loss: 0.009015416726469994
step: 150, loss: 0.08188781142234802
step: 160, loss: 0.07371384650468826
step: 170, loss: 0.11291784793138504
step: 180, loss: 0.08118851482868195
step: 190, loss: 0.029080988839268684
step: 200, loss: 0.004450966604053974
step: 210, loss: 0.034929897636175156
step: 220, loss: 0.23757514357566833
step: 230, loss: 0.06732387840747833
step: 240, loss: 0.06557167321443558
step: 250, loss: 0.12672650814056396
step: 260, loss: 0.04509320110082626
step: 270, loss: 0.08815964311361313
step: 280, loss: 0.039913490414619446
step: 290, loss: 0.012434497475624084
step: 300, loss: 0.008445223793387413
step: 310, loss: 0.0411362461745739
step: 320, loss: 0.13876263797283173
step: 330, loss: 0.051823049783706665
step: 340, loss: 0.014908882789313793
step: 350, loss: 0.13645292818546295
step: 360, loss: 0.021494120359420776
step: 370, loss: 0.16019666194915771
step: 380, loss: 0.07278956472873688
step: 390, loss: 0.03950094059109688
step: 400, loss: 0.032918963581323624
step: 410, loss: 0.06647168099880219
step: 420, loss: 0.020986931398510933
epoch 8: dev_f1=0.9898762654668166, f1=0.9785310734463276, best_f1=0.9785310734463276
step: 0, loss: 0.04696212336421013
step: 10, loss: 0.02571006864309311
step: 20, loss: 0.10555300861597061
step: 30, loss: 0.063026063144207
step: 40, loss: 0.19721846282482147
step: 50, loss: 0.07095330208539963
step: 60, loss: 0.06716717034578323
step: 70, loss: 0.07540068030357361
step: 80, loss: 0.11808537691831589
step: 90, loss: 0.0636366531252861
step: 100, loss: 0.04845277965068817
step: 110, loss: 0.03886346146464348
step: 120, loss: 0.016909999772906303
step: 130, loss: 0.04112568125128746
step: 140, loss: 0.07663670182228088
step: 150, loss: 0.16013863682746887
step: 160, loss: 0.10131433606147766
step: 170, loss: 0.11453907191753387
step: 180, loss: 0.09232109785079956
step: 190, loss: 0.0868944376707077
step: 200, loss: 0.021329447627067566
step: 210, loss: 0.008724822662770748
step: 220, loss: 0.018170155584812164
step: 230, loss: 0.10136798024177551
step: 240, loss: 0.0041380953043699265
step: 250, loss: 0.06997533142566681
step: 260, loss: 0.05201314389705658
step: 270, loss: 0.11716965585947037
step: 280, loss: 0.03220125287771225
step: 290, loss: 0.0719899982213974
step: 300, loss: 0.027982743456959724
step: 310, loss: 0.07717350125312805
step: 320, loss: 0.03692192956805229
step: 330, loss: 0.08346736431121826
step: 340, loss: 0.08667659759521484
step: 350, loss: 0.06964082270860672
step: 360, loss: 0.04547230154275894
step: 370, loss: 0.02794283628463745
step: 380, loss: 0.0246171522885561
step: 390, loss: 0.053338270634412766
step: 400, loss: 0.1746857613325119
step: 410, loss: 0.019954826682806015
step: 420, loss: 0.07416992634534836
epoch 9: dev_f1=0.987598647125141, f1=0.9773755656108598, best_f1=0.9785310734463276
step: 0, loss: 0.0604504719376564
step: 10, loss: 0.07489719986915588
step: 20, loss: 0.023288041353225708
step: 30, loss: 0.0113761555403471
step: 40, loss: 0.08204645663499832
step: 50, loss: 0.06781181693077087
step: 60, loss: 0.07310448586940765
step: 70, loss: 0.0814700648188591
step: 80, loss: 0.06333920359611511
step: 90, loss: 0.030617322772741318
step: 100, loss: 0.0468357689678669
step: 110, loss: 0.15801577270030975
step: 120, loss: 0.015199752524495125
step: 130, loss: 0.015400071628391743
step: 140, loss: 0.14811410009860992
step: 150, loss: 0.10238577425479889
step: 160, loss: 0.09345609694719315
step: 170, loss: 0.01209122035652399
step: 180, loss: 0.017338547855615616
step: 190, loss: 0.010411674156785011
step: 200, loss: 0.05738349258899689
step: 210, loss: 0.04783688485622406
step: 220, loss: 0.1573234498500824
step: 230, loss: 0.05202774330973625
step: 240, loss: 0.018985584378242493
step: 250, loss: 0.1256761997938156
step: 260, loss: 0.09302448481321335
step: 270, loss: 0.11234087496995926
step: 280, loss: 0.11107245832681656
step: 290, loss: 0.09161513298749924
step: 300, loss: 0.06361104547977448
step: 310, loss: 0.030107373371720314
step: 320, loss: 0.21589583158493042
step: 330, loss: 0.014422120526432991
step: 340, loss: 0.13804402947425842
step: 350, loss: 0.07278002053499222
step: 360, loss: 0.10453291982412338
step: 370, loss: 0.12874145805835724
step: 380, loss: 0.12674309313297272
step: 390, loss: 0.0534784197807312
step: 400, loss: 0.14216238260269165
step: 410, loss: 0.01245516911149025
step: 420, loss: 0.18366238474845886
epoch 10: dev_f1=0.9863945578231292, f1=0.9772209567198178, best_f1=0.9785310734463276
step: 0, loss: 0.07928518950939178
step: 10, loss: 0.03591842204332352
step: 20, loss: 0.05406155064702034
step: 30, loss: 0.00771587947383523
step: 40, loss: 0.05375383049249649
step: 50, loss: 0.016609350219368935
step: 60, loss: 0.014806571416556835
step: 70, loss: 0.051905307918787
step: 80, loss: 0.050827138125896454
step: 90, loss: 0.07420722395181656
step: 100, loss: 0.0819290429353714
step: 110, loss: 0.05893302336335182
step: 120, loss: 0.0767841711640358
step: 130, loss: 0.1297023594379425
step: 140, loss: 0.012978331185877323
step: 150, loss: 0.0785878524184227
step: 160, loss: 0.21224555373191833
step: 170, loss: 0.06727248430252075
step: 180, loss: 0.03354931250214577
step: 190, loss: 0.1499156355857849
step: 200, loss: 0.02698376402258873
step: 210, loss: 0.009065186604857445
step: 220, loss: 0.0772845596075058
step: 230, loss: 0.03583427518606186
step: 240, loss: 0.1656043380498886
step: 250, loss: 0.07135321199893951
step: 260, loss: 0.08047838509082794
step: 270, loss: 0.01724039576947689
step: 280, loss: 0.009843609295785427
step: 290, loss: 0.02160068415105343
step: 300, loss: 0.08498292416334152
step: 310, loss: 0.04965759813785553
step: 320, loss: 0.009822897613048553
step: 330, loss: 0.06969138234853745
step: 340, loss: 0.03316466137766838
step: 350, loss: 0.012057574465870857
step: 360, loss: 0.07102752476930618
step: 370, loss: 0.14159905910491943
step: 380, loss: 0.010798431001603603
step: 390, loss: 0.07496098428964615
step: 400, loss: 0.11374424397945404
step: 410, loss: 0.0942387729883194
step: 420, loss: 0.016180720180273056
epoch 11: dev_f1=0.9898989898989898, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.04744071885943413
step: 10, loss: 0.061582013964653015
step: 20, loss: 0.0618661530315876
step: 30, loss: 0.04115135595202446
step: 40, loss: 0.016705483198165894
step: 50, loss: 0.08466694504022598
step: 60, loss: 0.017806727439165115
step: 70, loss: 0.12751415371894836
step: 80, loss: 0.13690023124217987
step: 90, loss: 0.03491068631410599
step: 100, loss: 0.039331041276454926
step: 110, loss: 0.09303303062915802
step: 120, loss: 0.11526475101709366
step: 130, loss: 0.050221025943756104
step: 140, loss: 0.15562401711940765
step: 150, loss: 0.1428646743297577
step: 160, loss: 0.03846241906285286
step: 170, loss: 0.021907804533839226
step: 180, loss: 0.06764281541109085
step: 190, loss: 0.10314851999282837
step: 200, loss: 0.014737004414200783
step: 210, loss: 0.05178499594330788
step: 220, loss: 0.08552322536706924
step: 230, loss: 0.05288461223244667
step: 240, loss: 0.04244019091129303
step: 250, loss: 0.08132871985435486
step: 260, loss: 0.07258457690477371
step: 270, loss: 0.118102066218853
step: 280, loss: 0.04815475642681122
step: 290, loss: 0.08921796828508377
step: 300, loss: 0.07346367835998535
step: 310, loss: 0.024931887164711952
step: 320, loss: 0.066835917532444
step: 330, loss: 0.08072109520435333
step: 340, loss: 0.02427402138710022
step: 350, loss: 0.010118672624230385
step: 360, loss: 0.025390367954969406
step: 370, loss: 0.08643046766519547
step: 380, loss: 0.026053819805383682
step: 390, loss: 0.039623506367206573
step: 400, loss: 0.032076045870780945
step: 410, loss: 0.035897862166166306
step: 420, loss: 0.050661440938711166
epoch 12: dev_f1=0.9898074745186863, f1=0.9818181818181818, best_f1=0.9819819819819819
step: 0, loss: 0.056475378572940826
step: 10, loss: 0.1718357503414154
step: 20, loss: 0.011429047212004662
step: 30, loss: 0.016564153134822845
step: 40, loss: 0.041603658348321915
step: 50, loss: 0.016468778252601624
step: 60, loss: 0.012794033624231815
step: 70, loss: 0.031479883939027786
step: 80, loss: 0.023519964888691902
step: 90, loss: 0.02361670695245266
step: 100, loss: 0.04403200373053551
step: 110, loss: 0.051490891724824905
step: 120, loss: 0.06550930440425873
step: 130, loss: 0.12088418751955032
step: 140, loss: 0.014879792928695679
step: 150, loss: 0.07906147092580795
step: 160, loss: 0.012816396541893482
step: 170, loss: 0.05781278386712074
step: 180, loss: 0.029848037287592888
step: 190, loss: 0.012629993259906769
step: 200, loss: 0.04357053339481354
step: 210, loss: 0.1294741928577423
step: 220, loss: 0.3403870165348053
step: 230, loss: 0.04594294726848602
step: 240, loss: 0.027699757367372513
step: 250, loss: 0.02149234712123871
step: 260, loss: 0.07110141217708588
step: 270, loss: 0.05522314831614494
step: 280, loss: 0.00024505695910193026
step: 290, loss: 0.01718868874013424
step: 300, loss: 0.018351541832089424
step: 310, loss: 0.05259820073843002
step: 320, loss: 0.04612884670495987
step: 330, loss: 0.08431827276945114
step: 340, loss: 0.13707531988620758
step: 350, loss: 0.030781928449869156
step: 360, loss: 0.031842511147260666
step: 370, loss: 0.08561985194683075
step: 380, loss: 0.022403093054890633
step: 390, loss: 0.06109832972288132
step: 400, loss: 0.06323355436325073
step: 410, loss: 0.042662639170885086
step: 420, loss: 0.03339822217822075
epoch 13: dev_f1=0.9921436588103255, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.018343567848205566
step: 10, loss: 0.04737519472837448
step: 20, loss: 0.07858622074127197
step: 30, loss: 0.02556230127811432
step: 40, loss: 0.016142621636390686
step: 50, loss: 0.05586034432053566
step: 60, loss: 0.02327246032655239
step: 70, loss: 0.02467070147395134
step: 80, loss: 0.00856452900916338
step: 90, loss: 0.1336846649646759
step: 100, loss: 0.06714177131652832
step: 110, loss: 0.02069193497300148
step: 120, loss: 0.13641774654388428
step: 130, loss: 0.0686839297413826
step: 140, loss: 0.021283399313688278
step: 150, loss: 0.04899274557828903
step: 160, loss: 0.05647503584623337
step: 170, loss: 0.0028914480935782194
step: 180, loss: 0.06324339658021927
step: 190, loss: 0.07500459253787994
step: 200, loss: 0.02615480124950409
step: 210, loss: 0.017654966562986374
step: 220, loss: 0.030228659510612488
step: 230, loss: 0.06010456383228302
step: 240, loss: 0.061354681849479675
step: 250, loss: 0.02361997775733471
step: 260, loss: 0.01532675325870514
step: 270, loss: 0.04337858781218529
step: 280, loss: 0.10189943760633469
step: 290, loss: 0.12556473910808563
step: 300, loss: 0.02658969536423683
step: 310, loss: 0.06639035791158676
step: 320, loss: 0.060201071202754974
step: 330, loss: 0.014424644410610199
step: 340, loss: 0.03460180014371872
step: 350, loss: 0.060294706374406815
step: 360, loss: 0.11989084631204605
step: 370, loss: 0.033297691494226456
step: 380, loss: 0.01555988285690546
step: 390, loss: 0.0993780791759491
step: 400, loss: 0.007748509291559458
step: 410, loss: 0.03214552253484726
step: 420, loss: 0.03070174902677536
epoch 14: dev_f1=0.9921436588103255, f1=0.9797297297297298, best_f1=0.9831271091113611
step: 0, loss: 0.151731938123703
step: 10, loss: 0.11924168467521667
step: 20, loss: 0.14569294452667236
step: 30, loss: 0.013198082335293293
step: 40, loss: 0.10006104409694672
step: 50, loss: 0.10000728070735931
step: 60, loss: 0.0995415523648262
step: 70, loss: 0.13127867877483368
step: 80, loss: 0.026073329150676727
step: 90, loss: 0.05010341852903366
step: 100, loss: 0.05650885030627251
step: 110, loss: 0.05787399783730507
step: 120, loss: 0.04633967578411102
step: 130, loss: 0.006827796343713999
step: 140, loss: 0.016367819160223007
step: 150, loss: 0.028712932020425797
step: 160, loss: 0.056730642914772034
step: 170, loss: 0.0116902906447649
step: 180, loss: 0.07791820168495178
step: 190, loss: 0.012613755650818348
step: 200, loss: 0.0008919847314245999
step: 210, loss: 0.04034009575843811
step: 220, loss: 0.015845514833927155
step: 230, loss: 0.15410582721233368
step: 240, loss: 0.08091375231742859
step: 250, loss: 0.0031963400542736053
step: 260, loss: 0.011857138015329838
step: 270, loss: 0.02270108088850975
step: 280, loss: 0.09804073721170425
step: 290, loss: 0.07338885962963104
step: 300, loss: 0.03859017789363861
step: 310, loss: 0.06359101831912994
step: 320, loss: 0.0580303855240345
step: 330, loss: 0.020803261548280716
step: 340, loss: 0.04266287386417389
step: 350, loss: 0.0009063708712346852
step: 360, loss: 0.008890906348824501
step: 370, loss: 0.091208316385746
step: 380, loss: 0.0347415916621685
step: 390, loss: 0.022370727732777596
step: 400, loss: 0.12039514631032944
step: 410, loss: 0.09210438281297684
step: 420, loss: 0.03765954077243805
epoch 15: dev_f1=0.9899441340782122, f1=0.9797752808988766, best_f1=0.9831271091113611
step: 0, loss: 0.005013963673263788
step: 10, loss: 0.03300609812140465
step: 20, loss: 0.07675516605377197
step: 30, loss: 0.08943403512239456
step: 40, loss: 0.02726096287369728
step: 50, loss: 0.010974520817399025
step: 60, loss: 0.007432412821799517
step: 70, loss: 0.014137656427919865
step: 80, loss: 0.012335186824202538
step: 90, loss: 0.027605343610048294
step: 100, loss: 0.17876772582530975
step: 110, loss: 0.0356946736574173
step: 120, loss: 0.04716145619750023
step: 130, loss: 0.14230865240097046
step: 140, loss: 0.0537092424929142
step: 150, loss: 0.09527112543582916
step: 160, loss: 0.007163155358284712
step: 170, loss: 0.13603875041007996
step: 180, loss: 0.01663658767938614
step: 190, loss: 0.009006827138364315
step: 200, loss: 0.04630860313773155
step: 210, loss: 0.012912759557366371
step: 220, loss: 0.009048575535416603
step: 230, loss: 0.094916433095932
step: 240, loss: 0.09268305450677872
step: 250, loss: 0.03925160691142082
step: 260, loss: 0.07756819576025009
step: 270, loss: 0.10077893733978271
step: 280, loss: 0.07519345730543137
step: 290, loss: 0.07885818928480148
step: 300, loss: 0.06838829815387726
step: 310, loss: 0.04992935061454773
step: 320, loss: 0.2613257169723511
step: 330, loss: 0.007160590961575508
step: 340, loss: 0.0198880173265934
step: 350, loss: 0.11300387233495712
step: 360, loss: 0.14430277049541473
step: 370, loss: 0.017164701595902443
step: 380, loss: 0.09142003208398819
step: 390, loss: 0.05679045617580414
step: 400, loss: 0.06878909468650818
step: 410, loss: 0.04878053441643715
step: 420, loss: 0.05737308785319328
epoch 16: dev_f1=0.9910313901345291, f1=0.9831649831649831, best_f1=0.9831271091113611
step: 0, loss: 0.04359322786331177
step: 10, loss: 0.04986192658543587
step: 20, loss: 0.06380773335695267
step: 30, loss: 0.0621715672314167
step: 40, loss: 0.02601022645831108
step: 50, loss: 0.005132692866027355
step: 60, loss: 0.028336623683571815
step: 70, loss: 0.0039496757090091705
step: 80, loss: 0.010233820416033268
step: 90, loss: 0.013049252331256866
step: 100, loss: 0.04085438326001167
step: 110, loss: 0.03709188848733902
step: 120, loss: 0.04623139277100563
step: 130, loss: 0.0214853398501873
step: 140, loss: 0.07021484524011612
step: 150, loss: 0.02455276809632778
step: 160, loss: 0.02093663066625595
step: 170, loss: 0.042641669511795044
step: 180, loss: 0.011768254451453686
step: 190, loss: 0.04212804138660431
step: 200, loss: 0.008496168069541454
step: 210, loss: 0.0012281762901693583
step: 220, loss: 0.03738076239824295
step: 230, loss: 0.038310036063194275
step: 240, loss: 0.027482207864522934
step: 250, loss: 0.03239249438047409
step: 260, loss: 0.047361668199300766
step: 270, loss: 0.0006039650179445744
step: 280, loss: 0.030563313513994217
step: 290, loss: 0.2421545386314392
step: 300, loss: 0.05384108051657677
step: 310, loss: 0.0774565115571022
step: 320, loss: 0.055563151836395264
step: 330, loss: 0.0015823252033442259
step: 340, loss: 0.007805613800883293
step: 350, loss: 0.1256054937839508
step: 360, loss: 0.04196714609861374
step: 370, loss: 0.13846531510353088
step: 380, loss: 0.016931792721152306
step: 390, loss: 0.035306140780448914
step: 400, loss: 0.056709665805101395
step: 410, loss: 1.5437182810273953e-05
step: 420, loss: 0.05696937441825867
epoch 17: dev_f1=0.9887892376681614, f1=0.9820224719101124, best_f1=0.9831271091113611
step: 0, loss: 0.08054284006357193
step: 10, loss: 0.06723529100418091
step: 20, loss: 0.012490658089518547
step: 30, loss: 0.1086529865860939
step: 40, loss: 0.04215940833091736
step: 50, loss: 0.04554861783981323
step: 60, loss: 0.008184242993593216
step: 70, loss: 0.06174146756529808
step: 80, loss: 0.03928253799676895
step: 90, loss: 0.03716600686311722
step: 100, loss: 0.011071953922510147
step: 110, loss: 0.028137747198343277
step: 120, loss: 0.04779535531997681
step: 130, loss: 3.0644150683656335e-05
step: 140, loss: 0.026812629774212837
step: 150, loss: 0.06927426159381866
step: 160, loss: 0.02968464605510235
step: 170, loss: 0.025175388902425766
step: 180, loss: 1.2837183930969331e-05
step: 190, loss: 0.01411401480436325
step: 200, loss: 0.07574638724327087
step: 210, loss: 0.04921570047736168
step: 220, loss: 0.05104450136423111
step: 230, loss: 0.007663872558623552
step: 240, loss: 0.0032213989179581404
step: 250, loss: 0.133737713098526
step: 260, loss: 0.02382226660847664
step: 270, loss: 0.06556985527276993
step: 280, loss: 0.02355707436800003
step: 290, loss: 0.16359810531139374
step: 300, loss: 0.0034115470480173826
step: 310, loss: 0.03445727750658989
step: 320, loss: 0.005081991199404001
step: 330, loss: 0.06397276371717453
step: 340, loss: 0.04299396649003029
step: 350, loss: 0.025121474638581276
step: 360, loss: 0.08071771264076233
step: 370, loss: 0.04153629019856453
step: 380, loss: 0.002458937931805849
step: 390, loss: 0.004391822963953018
step: 400, loss: 0.10935559868812561
step: 410, loss: 0.04017660766839981
step: 420, loss: 0.011951177380979061
epoch 18: dev_f1=0.9876265466816648, f1=0.9808773903262092, best_f1=0.9831271091113611
step: 0, loss: 0.00021722650853917003
step: 10, loss: 0.02588174305856228
step: 20, loss: 0.018806982785463333
step: 30, loss: 0.03490656241774559
step: 40, loss: 0.029607683420181274
step: 50, loss: 0.07134483754634857
step: 60, loss: 0.09086425602436066
step: 70, loss: 0.006512143183499575
step: 80, loss: 0.07905977219343185
step: 90, loss: 0.04400818049907684
step: 100, loss: 0.045753054320812225
step: 110, loss: 0.09291503578424454
step: 120, loss: 0.11855299025774002
step: 130, loss: 0.03783072531223297
step: 140, loss: 0.0295659638941288
step: 150, loss: 0.03241517394781113
step: 160, loss: 0.03452349454164505
step: 170, loss: 0.012793992646038532
step: 180, loss: 0.02450498938560486
step: 190, loss: 0.031076982617378235
step: 200, loss: 0.014030984602868557
step: 210, loss: 0.1902952641248703
step: 220, loss: 0.018787769600749016
step: 230, loss: 0.03882058337330818
step: 240, loss: 0.04186367988586426
step: 250, loss: 0.07911290228366852
step: 260, loss: 0.13655278086662292
step: 270, loss: 0.056407537311315536
step: 280, loss: 0.04638354107737541
step: 290, loss: 0.030958231538534164
step: 300, loss: 0.01720813661813736
step: 310, loss: 0.01871218904852867
step: 320, loss: 0.09400872141122818
step: 330, loss: 0.03601378947496414
step: 340, loss: 0.060800448060035706
step: 350, loss: 0.08974906802177429
step: 360, loss: 0.053044937551021576
step: 370, loss: 0.020760376006364822
step: 380, loss: 0.11562582105398178
step: 390, loss: 0.029045969247817993
step: 400, loss: 0.05245787277817726
step: 410, loss: 0.041930194944143295
step: 420, loss: 0.06562522053718567
epoch 19: dev_f1=0.9887640449438202, f1=0.9820224719101124, best_f1=0.9831271091113611
step: 0, loss: 0.14873071014881134
step: 10, loss: 0.05910727009177208
step: 20, loss: 0.08475947380065918
step: 30, loss: 0.028164394199848175
step: 40, loss: 0.010576365515589714
step: 50, loss: 0.02109195850789547
step: 60, loss: 0.044748950749635696
step: 70, loss: 0.015661034733057022
step: 80, loss: 0.006052115932106972
step: 90, loss: 0.02494264394044876
step: 100, loss: 0.07187164574861526
step: 110, loss: 0.054550375789403915
step: 120, loss: 0.05737822502851486
step: 130, loss: 0.019311200827360153
step: 140, loss: 0.02156132459640503
step: 150, loss: 0.047915857285261154
step: 160, loss: 0.054743390530347824
step: 170, loss: 0.04707732051610947
step: 180, loss: 0.05843130871653557
step: 190, loss: 0.01846742257475853
step: 200, loss: 0.015493136830627918
step: 210, loss: 0.0025327077601104975
step: 220, loss: 0.037658270448446274
step: 230, loss: 0.010512178763747215
step: 240, loss: 0.06503564119338989
step: 250, loss: 0.007851243019104004
step: 260, loss: 0.008499747142195702
step: 270, loss: 0.06670941412448883
step: 280, loss: 0.036356981843709946
step: 290, loss: 0.04970439150929451
step: 300, loss: 0.023922275751829147
step: 310, loss: 0.02863100916147232
step: 320, loss: 0.043649472296237946
step: 330, loss: 0.061291757971048355
step: 340, loss: 0.019978707656264305
step: 350, loss: 0.005112261977046728
step: 360, loss: 0.049506139010190964
step: 370, loss: 0.030930308625102043
step: 380, loss: 0.022356458008289337
step: 390, loss: 0.015975898131728172
step: 400, loss: 6.737493822583929e-05
step: 410, loss: 0.0785796046257019
step: 420, loss: 0.17850516736507416
epoch 20: dev_f1=0.9887640449438202, f1=0.9797297297297298, best_f1=0.9831271091113611
