cuda
Device: cuda
step: 0, loss: 0.8756407499313354
step: 10, loss: 0.19129648804664612
step: 20, loss: 0.3052380383014679
step: 30, loss: 0.22748234868049622
step: 40, loss: 0.426998108625412
step: 50, loss: 0.30007755756378174
step: 60, loss: 0.19566994905471802
step: 70, loss: 0.16974568367004395
step: 80, loss: 0.2133948653936386
step: 90, loss: 0.15704719722270966
step: 100, loss: 0.04380536079406738
step: 110, loss: 0.1855122447013855
step: 120, loss: 0.0715273842215538
step: 130, loss: 0.15946681797504425
step: 140, loss: 0.16811083257198334
step: 150, loss: 0.1884383112192154
step: 160, loss: 0.07861581444740295
step: 170, loss: 0.20373894274234772
step: 180, loss: 0.28021639585494995
step: 190, loss: 0.28206390142440796
step: 200, loss: 0.08001391589641571
step: 210, loss: 0.1985069066286087
step: 220, loss: 0.12445282191038132
step: 230, loss: 0.1380462348461151
step: 240, loss: 0.09204889088869095
step: 250, loss: 0.07334721088409424
step: 260, loss: 0.15988494455814362
step: 270, loss: 0.07935017347335815
step: 280, loss: 0.10374221205711365
step: 290, loss: 0.010974285192787647
step: 300, loss: 0.09559657424688339
step: 310, loss: 0.0809643492102623
step: 320, loss: 0.12662570178508759
step: 330, loss: 0.06989025324583054
step: 340, loss: 0.18303506076335907
step: 350, loss: 0.12775428593158722
step: 360, loss: 0.10562984645366669
step: 370, loss: 0.11455795168876648
step: 380, loss: 0.06212938576936722
step: 390, loss: 0.11801917850971222
step: 400, loss: 0.18133589625358582
step: 410, loss: 0.1028480976819992
step: 420, loss: 0.0826190710067749
epoch 1: dev_f1=0.9821428571428571, f1=0.9764837625979844, best_f1=0.9764837625979844
step: 0, loss: 0.21652251482009888
step: 10, loss: 0.07369508594274521
step: 20, loss: 0.10004065930843353
step: 30, loss: 0.10902576893568039
step: 40, loss: 0.08329995721578598
step: 50, loss: 0.022472810000181198
step: 60, loss: 0.16007976233959198
step: 70, loss: 0.09652191400527954
step: 80, loss: 0.14120618999004364
step: 90, loss: 0.109250508248806
step: 100, loss: 0.10747479647397995
step: 110, loss: 0.06853243708610535
step: 120, loss: 0.06338868290185928
step: 130, loss: 0.08234074711799622
step: 140, loss: 0.09536318480968475
step: 150, loss: 0.031193982809782028
step: 160, loss: 0.18550674617290497
step: 170, loss: 0.09076806157827377
step: 180, loss: 0.09697128087282181
step: 190, loss: 0.044740740209817886
step: 200, loss: 0.13305723667144775
step: 210, loss: 0.22706323862075806
step: 220, loss: 0.018282998353242874
step: 230, loss: 0.07879754900932312
step: 240, loss: 0.11464760452508926
step: 250, loss: 0.1774057000875473
step: 260, loss: 0.08433345705270767
step: 270, loss: 0.0746951624751091
step: 280, loss: 0.0427117720246315
step: 290, loss: 0.08456704020500183
step: 300, loss: 0.16289441287517548
step: 310, loss: 0.030440595000982285
step: 320, loss: 0.08906212449073792
step: 330, loss: 0.10989400744438171
step: 340, loss: 0.12078013271093369
step: 350, loss: 0.09121447801589966
step: 360, loss: 0.19668449461460114
step: 370, loss: 0.037345025688409805
step: 380, loss: 0.01164273265749216
step: 390, loss: 0.027086617425084114
step: 400, loss: 0.052023254334926605
step: 410, loss: 0.012615550309419632
step: 420, loss: 0.1501937359571457
epoch 2: dev_f1=0.9898534385569334, f1=0.9863945578231292, best_f1=0.9863945578231292
step: 0, loss: 0.18775439262390137
step: 10, loss: 0.04356938228011131
step: 20, loss: 0.0949089303612709
step: 30, loss: 0.17205671966075897
step: 40, loss: 0.1747957468032837
step: 50, loss: 0.1733015924692154
step: 60, loss: 0.10715030878782272
step: 70, loss: 0.12444332987070084
step: 80, loss: 0.28195077180862427
step: 90, loss: 0.10587707906961441
step: 100, loss: 0.07104075700044632
step: 110, loss: 0.10222170501947403
step: 120, loss: 0.1909083127975464
step: 130, loss: 0.07645947486162186
step: 140, loss: 0.08584151417016983
step: 150, loss: 0.13878031075000763
step: 160, loss: 0.12154816836118698
step: 170, loss: 0.1058432087302208
step: 180, loss: 0.15665613114833832
step: 190, loss: 0.055194951593875885
step: 200, loss: 0.024467624723911285
step: 210, loss: 0.07002796977758408
step: 220, loss: 0.05374673008918762
step: 230, loss: 0.08507206290960312
step: 240, loss: 0.04911719635128975
step: 250, loss: 0.04282696172595024
step: 260, loss: 0.11042479425668716
step: 270, loss: 0.18598200380802155
step: 280, loss: 0.04212510213255882
step: 290, loss: 0.10016757994890213
step: 300, loss: 0.03517891839146614
step: 310, loss: 0.14290550351142883
step: 320, loss: 0.06032400578260422
step: 330, loss: 0.05432993546128273
step: 340, loss: 0.18747225403785706
step: 350, loss: 0.04070679098367691
step: 360, loss: 0.10571123659610748
step: 370, loss: 0.014322089962661266
step: 380, loss: 0.051636289805173874
step: 390, loss: 0.07128477841615677
step: 400, loss: 0.14408846199512482
step: 410, loss: 0.2382175624370575
step: 420, loss: 0.026331868022680283
epoch 3: dev_f1=0.992108229988726, f1=0.9797752808988766, best_f1=0.9797752808988766
step: 0, loss: 0.07107970118522644
step: 10, loss: 0.08543971925973892
step: 20, loss: 0.04723190516233444
step: 30, loss: 0.07670043408870697
step: 40, loss: 0.008110042661428452
step: 50, loss: 0.09860283136367798
step: 60, loss: 0.027536841109395027
step: 70, loss: 0.06634394824504852
step: 80, loss: 0.009806683287024498
step: 90, loss: 0.06264492124319077
step: 100, loss: 0.05221604183316231
step: 110, loss: 0.044116437435150146
step: 120, loss: 0.10034894943237305
step: 130, loss: 0.015346763655543327
step: 140, loss: 0.059617895632982254
step: 150, loss: 0.13924099504947662
step: 160, loss: 0.02535092458128929
step: 170, loss: 0.16683600842952728
step: 180, loss: 0.09000355005264282
step: 190, loss: 0.031143855303525925
step: 200, loss: 0.09511490166187286
step: 210, loss: 0.02597983181476593
step: 220, loss: 0.0919300839304924
step: 230, loss: 0.1236243024468422
step: 240, loss: 0.16853274405002594
step: 250, loss: 0.0182657428085804
step: 260, loss: 0.0675458088517189
step: 270, loss: 0.09139852225780487
step: 280, loss: 0.1522304117679596
step: 290, loss: 0.1154300719499588
step: 300, loss: 0.02434093877673149
step: 310, loss: 0.025982577353715897
step: 320, loss: 0.17874084413051605
step: 330, loss: 0.11935193091630936
step: 340, loss: 0.12075356394052505
step: 350, loss: 0.10751865804195404
step: 360, loss: 0.05512965843081474
step: 370, loss: 0.11848612874746323
step: 380, loss: 0.05693422630429268
step: 390, loss: 0.0878746286034584
step: 400, loss: 0.11479001492261887
step: 410, loss: 0.0832938402891159
step: 420, loss: 0.11779741942882538
epoch 4: dev_f1=0.9854423292273236, f1=0.9830124575311437, best_f1=0.9797752808988766
step: 0, loss: 0.0475001260638237
step: 10, loss: 0.05532944202423096
step: 20, loss: 0.11183007806539536
step: 30, loss: 0.10506467521190643
step: 40, loss: 0.14282888174057007
step: 50, loss: 0.057989127933979034
step: 60, loss: 0.02517399750649929
step: 70, loss: 0.11029201000928879
step: 80, loss: 0.034911975264549255
step: 90, loss: 0.12762139737606049
step: 100, loss: 0.07713772356510162
step: 110, loss: 0.12758922576904297
step: 120, loss: 0.036168258637189865
step: 130, loss: 0.07359867542982101
step: 140, loss: 0.11421272158622742
step: 150, loss: 0.03783376142382622
step: 160, loss: 0.0479186475276947
step: 170, loss: 0.057655297219753265
step: 180, loss: 0.040386367589235306
step: 190, loss: 0.08195748925209045
step: 200, loss: 0.12582962214946747
step: 210, loss: 0.12128447741270065
step: 220, loss: 0.016670437529683113
step: 230, loss: 0.08336900174617767
step: 240, loss: 0.08792326599359512
step: 250, loss: 0.13277532160282135
step: 260, loss: 0.0339471735060215
step: 270, loss: 0.025230946019291878
step: 280, loss: 0.1962762027978897
step: 290, loss: 0.035772040486335754
step: 300, loss: 0.09476372599601746
step: 310, loss: 0.10860050469636917
step: 320, loss: 0.05638360604643822
step: 330, loss: 0.02389875054359436
step: 340, loss: 0.026034612208604813
step: 350, loss: 0.11549817025661469
step: 360, loss: 0.07765846699476242
step: 370, loss: 0.12281603366136551
step: 380, loss: 0.041596975177526474
step: 390, loss: 0.02889273315668106
step: 400, loss: 0.1507740318775177
step: 410, loss: 0.0686001405119896
step: 420, loss: 0.031114540994167328
epoch 5: dev_f1=0.9932432432432432, f1=0.9797297297297298, best_f1=0.9797297297297298
step: 0, loss: 0.16145959496498108
step: 10, loss: 0.1052078828215599
step: 20, loss: 0.01251622661948204
step: 30, loss: 0.14346586167812347
step: 40, loss: 0.07694736868143082
step: 50, loss: 0.018883394077420235
step: 60, loss: 0.03973961994051933
step: 70, loss: 0.12067912518978119
step: 80, loss: 0.1114640012383461
step: 90, loss: 0.13716313242912292
step: 100, loss: 0.16677652299404144
step: 110, loss: 0.061398401856422424
step: 120, loss: 0.049001697450876236
step: 130, loss: 0.02792521007359028
step: 140, loss: 0.1250368356704712
step: 150, loss: 0.050610221922397614
step: 160, loss: 0.05103328824043274
step: 170, loss: 0.07245676219463348
step: 180, loss: 0.06774429976940155
step: 190, loss: 0.06303185224533081
step: 200, loss: 0.13061141967773438
step: 210, loss: 0.2396627813577652
step: 220, loss: 0.25137194991111755
step: 230, loss: 0.15009963512420654
step: 240, loss: 0.10203561186790466
step: 250, loss: 0.1086248904466629
step: 260, loss: 0.008853093720972538
step: 270, loss: 0.1797911375761032
step: 280, loss: 0.08860784769058228
step: 290, loss: 0.014267206192016602
step: 300, loss: 0.0611674003303051
step: 310, loss: 0.006139988079667091
step: 320, loss: 0.0139445960521698
step: 330, loss: 0.1554582118988037
step: 340, loss: 0.026320630684494972
step: 350, loss: 0.06470169126987457
step: 360, loss: 0.01866890862584114
step: 370, loss: 0.018813952803611755
step: 380, loss: 0.01973416842520237
step: 390, loss: 0.089874267578125
step: 400, loss: 0.02737003192305565
step: 410, loss: 0.05893708020448685
step: 420, loss: 0.09043154120445251
epoch 6: dev_f1=0.9887892376681614, f1=0.9810055865921787, best_f1=0.9797297297297298
step: 0, loss: 0.05982992798089981
step: 10, loss: 0.0298320222645998
step: 20, loss: 0.034384895116090775
step: 30, loss: 0.09148792177438736
step: 40, loss: 0.21745565533638
step: 50, loss: 0.14770595729351044
step: 60, loss: 0.05199771374464035
step: 70, loss: 0.088710717856884
step: 80, loss: 0.012412149459123611
step: 90, loss: 0.05832017958164215
step: 100, loss: 0.08013454079627991
step: 110, loss: 0.05465227738022804
step: 120, loss: 0.04834083840250969
step: 130, loss: 0.051032546907663345
step: 140, loss: 0.018708448857069016
step: 150, loss: 0.00044854701263830066
step: 160, loss: 0.03201436623930931
step: 170, loss: 0.006136319600045681
step: 180, loss: 0.01781863160431385
step: 190, loss: 0.026323776692152023
step: 200, loss: 0.017641961574554443
step: 210, loss: 0.12854129076004028
step: 220, loss: 0.06582631170749664
step: 230, loss: 0.16696833074092865
step: 240, loss: 0.0001460741477785632
step: 250, loss: 0.011325483210384846
step: 260, loss: 0.026302963495254517
step: 270, loss: 0.11651334166526794
step: 280, loss: 0.08217498660087585
step: 290, loss: 0.0774434357881546
step: 300, loss: 0.14473919570446014
step: 310, loss: 0.13573509454727173
step: 320, loss: 0.10836509615182877
step: 330, loss: 0.154023215174675
step: 340, loss: 0.11052282154560089
step: 350, loss: 0.10988013446331024
step: 360, loss: 0.04769398272037506
step: 370, loss: 0.05717950314283371
step: 380, loss: 0.0242012832313776
step: 390, loss: 0.06768529862165451
step: 400, loss: 0.035326242446899414
step: 410, loss: 0.07306701689958572
step: 420, loss: 0.08606436103582382
epoch 7: dev_f1=0.9910313901345291, f1=0.9810055865921787, best_f1=0.9797297297297298
step: 0, loss: 0.09266097843647003
step: 10, loss: 0.10912322998046875
step: 20, loss: 0.030750742182135582
step: 30, loss: 0.05337154120206833
step: 40, loss: 0.06468401849269867
step: 50, loss: 0.1385488063097
step: 60, loss: 0.12031862139701843
step: 70, loss: 0.04203946515917778
step: 80, loss: 0.019138885661959648
step: 90, loss: 0.05779298022389412
step: 100, loss: 0.10442055016756058
step: 110, loss: 0.1295071393251419
step: 120, loss: 0.012639987282454967
step: 130, loss: 0.03131797909736633
step: 140, loss: 0.06793182343244553
step: 150, loss: 0.0327780544757843
step: 160, loss: 0.04463495686650276
step: 170, loss: 0.05606333166360855
step: 180, loss: 0.027540452778339386
step: 190, loss: 0.09957669675350189
step: 200, loss: 0.050742704421281815
step: 210, loss: 0.08233559131622314
step: 220, loss: 0.05330498516559601
step: 230, loss: 0.03984931483864784
step: 240, loss: 0.04470003768801689
step: 250, loss: 0.01122693344950676
step: 260, loss: 0.023929864168167114
step: 270, loss: 0.02193688601255417
step: 280, loss: 0.10851078480482101
step: 290, loss: 0.07498279213905334
step: 300, loss: 0.17526115477085114
step: 310, loss: 0.03277371823787689
step: 320, loss: 0.1040295660495758
step: 330, loss: 0.020861072465777397
step: 340, loss: 0.00931984931230545
step: 350, loss: 0.03537730127573013
step: 360, loss: 0.05637678876519203
step: 370, loss: 0.007946331053972244
step: 380, loss: 0.017405137419700623
step: 390, loss: 0.10088866949081421
step: 400, loss: 0.07588565349578857
step: 410, loss: 0.04497072100639343
step: 420, loss: 0.09072054922580719
epoch 8: dev_f1=0.9899216125419933, f1=0.9810055865921787, best_f1=0.9797297297297298
step: 0, loss: 0.05853087082505226
step: 10, loss: 0.11554761976003647
step: 20, loss: 0.03772847726941109
step: 30, loss: 0.04423648491501808
step: 40, loss: 0.018031317740678787
step: 50, loss: 0.010272747837007046
step: 60, loss: 0.10384169965982437
step: 70, loss: 0.02129020355641842
step: 80, loss: 0.01818346045911312
step: 90, loss: 0.07008610665798187
step: 100, loss: 0.014497088268399239
step: 110, loss: 0.06403306126594543
step: 120, loss: 0.01646231859922409
step: 130, loss: 0.17555826902389526
step: 140, loss: 0.06232703477144241
step: 150, loss: 0.06306937336921692
step: 160, loss: 0.02329094521701336
step: 170, loss: 0.06706952303647995
step: 180, loss: 0.08150867372751236
step: 190, loss: 0.005846825893968344
step: 200, loss: 0.007669846061617136
step: 210, loss: 0.048456303775310516
step: 220, loss: 0.017403438687324524
step: 230, loss: 0.09543471038341522
step: 240, loss: 0.18695904314517975
step: 250, loss: 0.045848287642002106
step: 260, loss: 0.025052102282643318
step: 270, loss: 0.10327459871768951
step: 280, loss: 0.09331177175045013
step: 290, loss: 0.05851789191365242
step: 300, loss: 0.00489448057487607
step: 310, loss: 0.007958739995956421
step: 320, loss: 0.41151347756385803
step: 330, loss: 0.01930345594882965
step: 340, loss: 0.028214331716299057
step: 350, loss: 0.014107683673501015
step: 360, loss: 0.10170958191156387
step: 370, loss: 0.0031077538151293993
step: 380, loss: 0.07749564945697784
step: 390, loss: 0.00014976848615333438
step: 400, loss: 0.129714235663414
step: 410, loss: 0.06645248085260391
step: 420, loss: 0.05337050184607506
epoch 9: dev_f1=0.9932432432432432, f1=0.9787234042553192, best_f1=0.9797297297297298
step: 0, loss: 0.05464340001344681
step: 10, loss: 0.024203700944781303
step: 20, loss: 0.08167429268360138
step: 30, loss: 0.18083080649375916
step: 40, loss: 0.004570066928863525
step: 50, loss: 0.089415542781353
step: 60, loss: 0.04060930013656616
step: 70, loss: 0.02545417658984661
step: 80, loss: 0.061568714678287506
step: 90, loss: 0.10925264656543732
step: 100, loss: 0.012144427746534348
step: 110, loss: 0.008312016725540161
step: 120, loss: 0.10536438971757889
step: 130, loss: 0.08311928808689117
step: 140, loss: 0.051200758665800095
step: 150, loss: 0.0151376249268651
step: 160, loss: 0.05674344673752785
step: 170, loss: 0.1696128398180008
step: 180, loss: 0.10397318005561829
step: 190, loss: 0.06485781073570251
step: 200, loss: 0.034844331443309784
step: 210, loss: 0.04401625692844391
step: 220, loss: 0.04700740799307823
step: 230, loss: 0.05257926508784294
step: 240, loss: 0.10919031500816345
step: 250, loss: 0.0727638304233551
step: 260, loss: 0.019069112837314606
step: 270, loss: 0.08563461154699326
step: 280, loss: 0.06620658934116364
step: 290, loss: 0.00022708484902977943
step: 300, loss: 0.09062958508729935
step: 310, loss: 0.1038053035736084
step: 320, loss: 0.0434735044836998
step: 330, loss: 0.02596447244286537
step: 340, loss: 0.09770072996616364
step: 350, loss: 0.045128051191568375
step: 360, loss: 0.059886492788791656
step: 370, loss: 0.1007029339671135
step: 380, loss: 0.009897619485855103
step: 390, loss: 0.03149193152785301
step: 400, loss: 0.07419031113386154
step: 410, loss: 0.03657505288720131
step: 420, loss: 0.11560778319835663
epoch 10: dev_f1=0.9886877828054299, f1=0.9842342342342343, best_f1=0.9797297297297298
step: 0, loss: 0.10893189907073975
step: 10, loss: 0.06737437099218369
step: 20, loss: 0.06228332966566086
step: 30, loss: 0.06973762065172195
step: 40, loss: 0.04153691604733467
step: 50, loss: 0.005424614064395428
step: 60, loss: 0.06689867377281189
step: 70, loss: 0.07060635089874268
step: 80, loss: 0.06447988748550415
step: 90, loss: 0.08376343548297882
step: 100, loss: 0.012331235222518444
step: 110, loss: 0.09217046201229095
step: 120, loss: 0.24736140668392181
step: 130, loss: 0.10750561952590942
step: 140, loss: 0.10619886964559555
step: 150, loss: 0.07353145629167557
step: 160, loss: 0.019060952588915825
step: 170, loss: 0.04132392629981041
step: 180, loss: 0.1569899469614029
step: 190, loss: 0.11360261589288712
step: 200, loss: 0.10398205369710922
step: 210, loss: 0.020792651921510696
step: 220, loss: 0.1386638879776001
step: 230, loss: 0.10238218307495117
step: 240, loss: 0.06452352553606033
step: 250, loss: 0.0700502097606659
step: 260, loss: 0.13876834511756897
step: 270, loss: 0.0019296657992526889
step: 280, loss: 0.003819009056314826
step: 290, loss: 0.034826699644327164
step: 300, loss: 0.023072555661201477
step: 310, loss: 0.010855558328330517
step: 320, loss: 0.014628143981099129
step: 330, loss: 0.015571323223412037
step: 340, loss: 0.05712052807211876
step: 350, loss: 0.019620222970843315
step: 360, loss: 0.022912753745913506
step: 370, loss: 0.0359608456492424
step: 380, loss: 0.03227178752422333
step: 390, loss: 0.03967026248574257
step: 400, loss: 0.06386799365282059
step: 410, loss: 0.0026706524658948183
step: 420, loss: 0.04288128763437271
epoch 11: dev_f1=0.9932279909706545, f1=0.9830124575311437, best_f1=0.9797297297297298
step: 0, loss: 0.05049297958612442
step: 10, loss: 0.08428257703781128
step: 20, loss: 0.052137505263090134
step: 30, loss: 0.011767532676458359
step: 40, loss: 0.04955742135643959
step: 50, loss: 0.06358052790164948
step: 60, loss: 0.047970693558454514
step: 70, loss: 0.08060033619403839
step: 80, loss: 0.0668983981013298
step: 90, loss: 0.03432844579219818
step: 100, loss: 0.06001390144228935
step: 110, loss: 0.10828769207000732
step: 120, loss: 0.107868492603302
step: 130, loss: 0.030301764607429504
step: 140, loss: 0.09319428354501724
step: 150, loss: 0.013872708193957806
step: 160, loss: 0.05313708260655403
step: 170, loss: 0.0038683454040437937
step: 180, loss: 0.056209929287433624
step: 190, loss: 0.03966176137328148
step: 200, loss: 0.054273221641778946
step: 210, loss: 0.05197712779045105
step: 220, loss: 0.0841301903128624
step: 230, loss: 0.08465322852134705
step: 240, loss: 0.0917944386601448
step: 250, loss: 0.07695537805557251
step: 260, loss: 0.0160405021160841
step: 270, loss: 0.06488694995641708
step: 280, loss: 0.02427450753748417
step: 290, loss: 0.0033139821607619524
step: 300, loss: 0.060640834271907806
step: 310, loss: 0.022833071649074554
step: 320, loss: 0.12917885184288025
step: 330, loss: 0.08759933710098267
step: 340, loss: 0.010584613308310509
step: 350, loss: 0.05397731810808182
step: 360, loss: 0.059544287621974945
step: 370, loss: 0.11898098886013031
step: 380, loss: 0.03449971228837967
step: 390, loss: 2.2440401153289713e-05
step: 400, loss: 0.10983072221279144
step: 410, loss: 0.06130295991897583
step: 420, loss: 0.04582331329584122
epoch 12: dev_f1=0.990990990990991, f1=0.9865168539325843, best_f1=0.9797297297297298
step: 0, loss: 0.042289622128009796
step: 10, loss: 0.041755832731723785
step: 20, loss: 0.08744388818740845
step: 30, loss: 0.14616797864437103
step: 40, loss: 0.11476437747478485
step: 50, loss: 0.03676186874508858
step: 60, loss: 0.028699683025479317
step: 70, loss: 0.07531113177537918
step: 80, loss: 0.06785029917955399
step: 90, loss: 0.009399265050888062
step: 100, loss: 0.13268467783927917
step: 110, loss: 0.11124573647975922
step: 120, loss: 0.03210743889212608
step: 130, loss: 0.05154559761285782
step: 140, loss: 0.029183421283960342
step: 150, loss: 0.01291909720748663
step: 160, loss: 0.13989487290382385
step: 170, loss: 0.09608512371778488
step: 180, loss: 0.05327316373586655
step: 190, loss: 0.05971027910709381
step: 200, loss: 0.04412573203444481
step: 210, loss: 0.07678744941949844
step: 220, loss: 0.009752394631505013
step: 230, loss: 0.04654518887400627
step: 240, loss: 0.038103412836790085
step: 250, loss: 0.05493788793683052
step: 260, loss: 0.005121244117617607
step: 270, loss: 0.00042325971298851073
step: 280, loss: 0.03811432048678398
step: 290, loss: 0.06438502669334412
step: 300, loss: 0.1280452311038971
step: 310, loss: 0.08458714187145233
step: 320, loss: 0.08210007846355438
step: 330, loss: 0.08221898227930069
step: 340, loss: 0.03851974010467529
step: 350, loss: 0.04754842445254326
step: 360, loss: 0.08064337074756622
step: 370, loss: 0.07071839272975922
step: 380, loss: 0.04310113564133644
step: 390, loss: 0.0354435034096241
step: 400, loss: 0.06494376808404922
step: 410, loss: 0.03828354924917221
step: 420, loss: 0.0378839485347271
epoch 13: dev_f1=0.992108229988726, f1=0.9830124575311437, best_f1=0.9797297297297298
step: 0, loss: 0.04785934090614319
step: 10, loss: 0.10056616365909576
step: 20, loss: 0.02617744170129299
step: 30, loss: 0.017049845308065414
step: 40, loss: 0.0663243904709816
step: 50, loss: 0.02199324034154415
step: 60, loss: 0.06683239340782166
step: 70, loss: 0.06016993522644043
step: 80, loss: 0.003145682392641902
step: 90, loss: 0.05468444898724556
step: 100, loss: 0.05956175923347473
step: 110, loss: 0.10184798389673233
step: 120, loss: 0.03904762491583824
step: 130, loss: 3.0858565878588706e-05
step: 140, loss: 0.0011610192013904452
step: 150, loss: 0.03273626044392586
step: 160, loss: 0.0010180029785260558
step: 170, loss: 0.01856529898941517
step: 180, loss: 0.041406333446502686
step: 190, loss: 0.01920332759618759
step: 200, loss: 0.07551189512014389
step: 210, loss: 0.01684834063053131
step: 220, loss: 0.009444169700145721
step: 230, loss: 0.032101359218358994
step: 240, loss: 0.0011898638913407922
step: 250, loss: 0.062053028494119644
step: 260, loss: 0.07961196452379227
step: 270, loss: 0.04094414412975311
step: 280, loss: 0.02024228870868683
step: 290, loss: 0.01979612000286579
step: 300, loss: 0.06497170031070709
step: 310, loss: 0.08833573758602142
step: 320, loss: 0.02026141807436943
step: 330, loss: 0.036080557852983475
step: 340, loss: 0.018100041896104813
step: 350, loss: 0.0037047883961349726
step: 360, loss: 0.02840884029865265
step: 370, loss: 0.18067148327827454
step: 380, loss: 0.04551956430077553
step: 390, loss: 0.11235585063695908
step: 400, loss: 0.09706708043813705
step: 410, loss: 0.1689554750919342
step: 420, loss: 0.044872455298900604
epoch 14: dev_f1=0.9932432432432432, f1=0.980963045912654, best_f1=0.9797297297297298
step: 0, loss: 0.03311944380402565
step: 10, loss: 0.05163247883319855
step: 20, loss: 0.09301023185253143
step: 30, loss: 0.08693473786115646
step: 40, loss: 0.06618569791316986
step: 50, loss: 0.058158110827207565
step: 60, loss: 0.07094553858041763
step: 70, loss: 1.6592237443546765e-05
step: 80, loss: 0.01730777882039547
step: 90, loss: 0.02356501668691635
step: 100, loss: 0.08072294294834137
step: 110, loss: 0.10197780281305313
step: 120, loss: 0.05652102082967758
step: 130, loss: 0.027815725654363632
step: 140, loss: 0.011621130630373955
step: 150, loss: 0.06637786328792572
step: 160, loss: 0.12252959609031677
step: 170, loss: 0.176997110247612
step: 180, loss: 0.011772031895816326
step: 190, loss: 0.0566859245300293
step: 200, loss: 0.05211900919675827
step: 210, loss: 0.03306898847222328
step: 220, loss: 0.02184566855430603
step: 230, loss: 0.03671526536345482
step: 240, loss: 0.0049671269953250885
step: 250, loss: 0.07877413928508759
step: 260, loss: 0.04186449572443962
step: 270, loss: 0.03624599799513817
step: 280, loss: 0.02119840681552887
step: 290, loss: 0.05828806012868881
step: 300, loss: 0.0746992826461792
step: 310, loss: 0.03215758129954338
step: 320, loss: 0.03675461187958717
step: 330, loss: 0.07835538685321808
step: 340, loss: 0.054452840238809586
step: 350, loss: 0.23285748064517975
step: 360, loss: 0.08084309846162796
step: 370, loss: 0.01978990249335766
step: 380, loss: 0.04191119596362114
step: 390, loss: 0.052346162497997284
step: 400, loss: 0.1127110943198204
step: 410, loss: 0.01519245095551014
step: 420, loss: 0.020473020151257515
epoch 15: dev_f1=0.9932432432432432, f1=0.984304932735426, best_f1=0.9797297297297298
step: 0, loss: 0.04395478218793869
step: 10, loss: 0.044170256704092026
step: 20, loss: 0.0007206671289168298
step: 30, loss: 0.02360885590314865
step: 40, loss: 0.029970403760671616
step: 50, loss: 0.031616177409887314
step: 60, loss: 0.06736350804567337
step: 70, loss: 0.021211614832282066
step: 80, loss: 0.24528808891773224
step: 90, loss: 0.035620465874671936
step: 100, loss: 0.0026460373774170876
step: 110, loss: 0.01913960836827755
step: 120, loss: 0.04656094312667847
step: 130, loss: 0.024365253746509552
step: 140, loss: 0.0354623980820179
step: 150, loss: 0.06823363155126572
step: 160, loss: 0.03880881145596504
step: 170, loss: 0.06918120384216309
step: 180, loss: 0.03647366166114807
step: 190, loss: 0.042018406093120575
step: 200, loss: 0.03817719221115112
step: 210, loss: 0.07224590331315994
step: 220, loss: 0.044739510864019394
step: 230, loss: 0.022786449640989304
step: 240, loss: 0.03716585412621498
step: 250, loss: 0.011147864162921906
step: 260, loss: 0.014890868216753006
step: 270, loss: 0.03851934149861336
step: 280, loss: 0.0742834135890007
step: 290, loss: 0.07838700711727142
step: 300, loss: 0.023861262947320938
step: 310, loss: 0.004989126231521368
step: 320, loss: 0.001752133946865797
step: 330, loss: 0.031633131206035614
step: 340, loss: 0.05603552982211113
step: 350, loss: 0.07004906982183456
step: 360, loss: 0.0433572418987751
step: 370, loss: 0.048464030027389526
step: 380, loss: 0.11344995349645615
step: 390, loss: 0.10563196986913681
step: 400, loss: 0.03878410905599594
step: 410, loss: 0.07486279308795929
step: 420, loss: 0.1371283382177353
epoch 16: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9797297297297298
step: 0, loss: 0.032630179077386856
step: 10, loss: 0.05159894749522209
step: 20, loss: 0.01589038595557213
step: 30, loss: 0.014948854222893715
step: 40, loss: 0.0002105937310261652
step: 50, loss: 0.08774052560329437
step: 60, loss: 0.0002605672343634069
step: 70, loss: 0.03837302327156067
step: 80, loss: 0.022252241149544716
step: 90, loss: 0.017236249521374702
step: 100, loss: 0.024499228224158287
step: 110, loss: 0.018819710239768028
step: 120, loss: 0.004604562651365995
step: 130, loss: 0.022095289081335068
step: 140, loss: 0.02670476585626602
step: 150, loss: 0.004262156318873167
step: 160, loss: 0.0013891352573409677
step: 170, loss: 0.09037923812866211
step: 180, loss: 0.05308069661259651
step: 190, loss: 0.022034384310245514
step: 200, loss: 0.05796794593334198
step: 210, loss: 0.027998117730021477
step: 220, loss: 0.10769348591566086
step: 230, loss: 0.0014651407254859805
step: 240, loss: 0.03657974675297737
step: 250, loss: 0.07279596477746964
step: 260, loss: 0.008520271629095078
step: 270, loss: 0.047086916863918304
step: 280, loss: 0.055981144309043884
step: 290, loss: 0.10980643332004547
step: 300, loss: 0.023039087653160095
step: 310, loss: 0.0254114530980587
step: 320, loss: 0.09464367479085922
step: 330, loss: 0.03134617954492569
step: 340, loss: 0.013124348595738411
step: 350, loss: 0.07319126278162003
step: 360, loss: 0.05384371057152748
step: 370, loss: 0.0021086635533720255
step: 380, loss: 0.03488542139530182
step: 390, loss: 0.02467595413327217
step: 400, loss: 0.0007178481901064515
step: 410, loss: 0.08936981856822968
step: 420, loss: 0.00012759743549395353
epoch 17: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9797297297297298
step: 0, loss: 0.062483061105012894
step: 10, loss: 0.02720654010772705
step: 20, loss: 0.05839782953262329
step: 30, loss: 0.052916765213012695
step: 40, loss: 0.012264005839824677
step: 50, loss: 0.0505283921957016
step: 60, loss: 0.0033655697479844093
step: 70, loss: 3.125535658909939e-05
step: 80, loss: 0.05699929967522621
step: 90, loss: 0.0885486751794815
step: 100, loss: 0.037129323929548264
step: 110, loss: 0.06001923978328705
step: 120, loss: 0.061074115335941315
step: 130, loss: 0.07577241957187653
step: 140, loss: 0.09349095076322556
step: 150, loss: 0.12181255221366882
step: 160, loss: 0.03517583757638931
step: 170, loss: 0.03943735361099243
step: 180, loss: 0.07947520166635513
step: 190, loss: 0.07333183288574219
step: 200, loss: 0.08044207841157913
step: 210, loss: 0.0736556351184845
step: 220, loss: 0.014318627305328846
step: 230, loss: 0.021912021562457085
step: 240, loss: 0.09360158443450928
step: 250, loss: 0.04890749603509903
step: 260, loss: 0.022005928680300713
step: 270, loss: 0.05176275968551636
step: 280, loss: 0.04216260462999344
step: 290, loss: 0.042990993708372116
step: 300, loss: 0.05266263335943222
step: 310, loss: 0.07852564007043839
step: 320, loss: 0.10417108982801437
step: 330, loss: 0.021544938907027245
step: 340, loss: 0.02542140521109104
step: 350, loss: 0.054140910506248474
step: 360, loss: 0.12968875467777252
step: 370, loss: 0.023555787280201912
step: 380, loss: 0.07947002351284027
step: 390, loss: 0.00017535568622406572
step: 400, loss: 0.02019795961678028
step: 410, loss: 0.05377199500799179
step: 420, loss: 0.017611335963010788
epoch 18: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9797297297297298
step: 0, loss: 0.06708727031946182
step: 10, loss: 0.04629699885845184
step: 20, loss: 0.031248414888978004
step: 30, loss: 0.059859130531549454
step: 40, loss: 0.0007749282522127032
step: 50, loss: 0.026155546307563782
step: 60, loss: 0.029025375843048096
step: 70, loss: 0.03159428760409355
step: 80, loss: 0.00022025217185728252
step: 90, loss: 0.049210287630558014
step: 100, loss: 0.09921939671039581
step: 110, loss: 0.0583193339407444
step: 120, loss: 0.021394135430455208
step: 130, loss: 0.03872666880488396
step: 140, loss: 0.03422365337610245
step: 150, loss: 0.0417884923517704
step: 160, loss: 0.046951089054346085
step: 170, loss: 0.12830302119255066
step: 180, loss: 0.0478496290743351
step: 190, loss: 0.026562534272670746
step: 200, loss: 0.010880481451749802
step: 210, loss: 0.04323428124189377
step: 220, loss: 0.04526129737496376
step: 230, loss: 0.05401606485247612
step: 240, loss: 0.017359592020511627
step: 250, loss: 0.030359581112861633
step: 260, loss: 0.0885595828294754
step: 270, loss: 0.050049372017383575
step: 280, loss: 0.07408079504966736
step: 290, loss: 0.061954088509082794
step: 300, loss: 0.02116229757666588
step: 310, loss: 0.04285507649183273
step: 320, loss: 0.00048113311640918255
step: 330, loss: 0.03391968458890915
step: 340, loss: 0.03735099732875824
step: 350, loss: 0.02291640266776085
step: 360, loss: 0.021778002381324768
step: 370, loss: 0.02085752785205841
step: 380, loss: 0.12437297403812408
step: 390, loss: 0.023530304431915283
step: 400, loss: 0.02255675382912159
step: 410, loss: 0.03362736850976944
step: 420, loss: 0.04307468980550766
epoch 19: dev_f1=0.9932432432432432, f1=0.9842696629213483, best_f1=0.9797297297297298
step: 0, loss: 0.02370053343474865
step: 10, loss: 0.02581496350467205
step: 20, loss: 0.03352142497897148
step: 30, loss: 6.691993621643633e-05
step: 40, loss: 0.04454806074500084
step: 50, loss: 0.04215886816382408
step: 60, loss: 0.024838346987962723
step: 70, loss: 0.07250137627124786
step: 80, loss: 0.03862195834517479
step: 90, loss: 0.04356900602579117
step: 100, loss: 0.017849160358309746
step: 110, loss: 6.065659545129165e-05
step: 120, loss: 0.06772695481777191
step: 130, loss: 0.025069009512662888
step: 140, loss: 0.002910776762291789
step: 150, loss: 0.06260441243648529
step: 160, loss: 0.0555541068315506
step: 170, loss: 0.02654297649860382
step: 180, loss: 0.05662713572382927
step: 190, loss: 0.000325802800944075
step: 200, loss: 0.04478399455547333
step: 210, loss: 0.05109462887048721
step: 220, loss: 0.046978771686553955
step: 230, loss: 0.08630216866731644
step: 240, loss: 0.024557331576943398
step: 250, loss: 3.6323002859717235e-05
step: 260, loss: 0.043271541595458984
step: 270, loss: 0.03223397582769394
step: 280, loss: 0.09783818572759628
step: 290, loss: 0.012270416133105755
step: 300, loss: 0.10093828290700912
step: 310, loss: 0.013958903960883617
step: 320, loss: 0.10685362666845322
step: 330, loss: 0.016566086560487747
step: 340, loss: 0.02276984229683876
step: 350, loss: 0.0982123613357544
step: 360, loss: 0.033882930874824524
step: 370, loss: 0.03269902616739273
step: 380, loss: 0.03710116446018219
step: 390, loss: 0.06838960945606232
step: 400, loss: 0.07905219495296478
step: 410, loss: 0.0357527881860733
step: 420, loss: 0.04219551384449005
epoch 20: dev_f1=0.9932432432432432, f1=0.9842696629213483, best_f1=0.9797297297297298
