cuda
Device: cuda
step: 0, loss: 0.7691466212272644
step: 10, loss: 0.47832566499710083
step: 20, loss: 0.4423776865005493
step: 30, loss: 0.4971540570259094
step: 40, loss: 0.5022322535514832
step: 50, loss: 0.32040682435035706
step: 60, loss: 0.49299994111061096
step: 70, loss: 0.08398891985416412
step: 80, loss: 0.19803740084171295
step: 90, loss: 0.2469877153635025
step: 100, loss: 0.2121230661869049
step: 110, loss: 0.20385020971298218
step: 120, loss: 0.3108401894569397
step: 130, loss: 0.18378010392189026
step: 140, loss: 0.2738712728023529
step: 150, loss: 0.17886503040790558
step: 160, loss: 0.3307724893093109
step: 170, loss: 0.3304203152656555
step: 180, loss: 0.30320319533348083
step: 190, loss: 0.588322639465332
step: 200, loss: 0.1031140610575676
step: 210, loss: 0.2425520122051239
step: 220, loss: 0.2626655101776123
step: 230, loss: 0.13158908486366272
step: 240, loss: 0.2797372341156006
step: 250, loss: 0.12755145132541656
step: 260, loss: 0.14421923458576202
step: 270, loss: 0.18785712122917175
step: 280, loss: 0.46996209025382996
step: 290, loss: 0.39248722791671753
step: 300, loss: 0.27158477902412415
step: 310, loss: 0.22579047083854675
step: 320, loss: 0.2504175305366516
step: 330, loss: 0.20954325795173645
step: 340, loss: 0.3715488612651825
step: 350, loss: 0.3142887055873871
step: 360, loss: 0.37293142080307007
step: 370, loss: 0.08142779022455215
step: 380, loss: 0.35194748640060425
step: 390, loss: 0.3893498182296753
step: 400, loss: 0.3371826708316803
step: 410, loss: 0.20054024457931519
step: 420, loss: 0.15766988694667816
step: 430, loss: 0.17149509489536285
step: 440, loss: 0.1570732742547989
step: 450, loss: 0.2726786434650421
step: 460, loss: 0.17583030462265015
step: 470, loss: 0.2797801196575165
step: 480, loss: 0.2535814642906189
step: 490, loss: 0.11917438358068466
step: 500, loss: 0.087574303150177
step: 510, loss: 0.17993685603141785
step: 520, loss: 0.24704132974147797
step: 530, loss: 0.3298337161540985
step: 540, loss: 0.12250899523496628
step: 550, loss: 0.3455359637737274
step: 560, loss: 0.16102592647075653
step: 570, loss: 0.3497038185596466
step: 580, loss: 0.16551634669303894
step: 590, loss: 0.23363539576530457
step: 600, loss: 0.14569969475269318
step: 610, loss: 0.24430949985980988
step: 620, loss: 0.1155356764793396
step: 630, loss: 0.2067197561264038
step: 640, loss: 0.18222886323928833
step: 650, loss: 0.20042464137077332
step: 660, loss: 0.07993815094232559
step: 670, loss: 0.26084160804748535
step: 680, loss: 0.3276633024215698
step: 690, loss: 0.1893700510263443
step: 700, loss: 0.1607189178466797
step: 710, loss: 0.10323300957679749
step: 720, loss: 0.13684523105621338
step: 730, loss: 0.07764703780412674
step: 740, loss: 0.2610137164592743
step: 750, loss: 0.18041369318962097
step: 760, loss: 0.15995272994041443
step: 770, loss: 0.3095116913318634
step: 780, loss: 0.32669514417648315
step: 790, loss: 0.1837655007839203
step: 800, loss: 0.2908197045326233
step: 810, loss: 0.22470307350158691
step: 820, loss: 0.4790039658546448
step: 830, loss: 0.11505701392889023
step: 840, loss: 0.2538071274757385
step: 850, loss: 0.18528898060321808
step: 860, loss: 0.1484021097421646
step: 870, loss: 0.06754814088344574
step: 880, loss: 0.3014378249645233
step: 890, loss: 0.13465459644794464
step: 900, loss: 0.1835220754146576
step: 910, loss: 0.2729633152484894
step: 920, loss: 0.26623985171318054
step: 930, loss: 0.269369512796402
step: 940, loss: 0.17250126600265503
epoch 1: dev_f1=0.943378568086102, f1=0.9332087809434843, best_f1=0.9332087809434843
step: 0, loss: 0.1456054002046585
step: 10, loss: 0.1982080638408661
step: 20, loss: 0.19933591783046722
step: 30, loss: 0.2217974215745926
step: 40, loss: 0.18214735388755798
step: 50, loss: 0.16220048069953918
step: 60, loss: 0.27750691771507263
step: 70, loss: 0.09457031637430191
step: 80, loss: 0.029294215142726898
step: 90, loss: 0.09785585105419159
step: 100, loss: 0.128489151597023
step: 110, loss: 0.16307663917541504
step: 120, loss: 0.13351942598819733
step: 130, loss: 0.09630724042654037
step: 140, loss: 0.031197933480143547
step: 150, loss: 0.10335103422403336
step: 160, loss: 0.2567784786224365
step: 170, loss: 0.18140669167041779
step: 180, loss: 0.3044109642505646
step: 190, loss: 0.10319411009550095
step: 200, loss: 0.11402776092290878
step: 210, loss: 0.08847050368785858
step: 220, loss: 0.1148190051317215
step: 230, loss: 0.12922602891921997
step: 240, loss: 0.11696931719779968
step: 250, loss: 0.2043706178665161
step: 260, loss: 0.18551278114318848
step: 270, loss: 0.26022717356681824
step: 280, loss: 0.16706550121307373
step: 290, loss: 0.12720637023448944
step: 300, loss: 0.14480862021446228
step: 310, loss: 0.20992539823055267
step: 320, loss: 0.12439683824777603
step: 330, loss: 0.18140514194965363
step: 340, loss: 0.18972240388393402
step: 350, loss: 0.1765032410621643
step: 360, loss: 0.120063915848732
step: 370, loss: 0.13327239453792572
step: 380, loss: 0.15485426783561707
step: 390, loss: 0.04624084755778313
step: 400, loss: 0.13673801720142365
step: 410, loss: 0.09641669690608978
step: 420, loss: 0.21860551834106445
step: 430, loss: 0.11810673028230667
step: 440, loss: 0.10355565696954727
step: 450, loss: 0.24891076982021332
step: 460, loss: 0.2473609894514084
step: 470, loss: 0.23237958550453186
step: 480, loss: 0.26649951934814453
step: 490, loss: 0.2632589042186737
step: 500, loss: 0.1787022054195404
step: 510, loss: 0.20539841055870056
step: 520, loss: 0.1106870099902153
step: 530, loss: 0.041412353515625
step: 540, loss: 0.13892197608947754
step: 550, loss: 0.12318576872348785
step: 560, loss: 0.11811461299657822
step: 570, loss: 0.20826874673366547
step: 580, loss: 0.08222827315330505
step: 590, loss: 0.34591570496559143
step: 600, loss: 0.2874034345149994
step: 610, loss: 0.08281444013118744
step: 620, loss: 0.25955599546432495
step: 630, loss: 0.09646385908126831
step: 640, loss: 0.15515226125717163
step: 650, loss: 0.3950800597667694
step: 660, loss: 0.2174135446548462
step: 670, loss: 0.02873031236231327
step: 680, loss: 0.16637007892131805
step: 690, loss: 0.3333367109298706
step: 700, loss: 0.26184019446372986
step: 710, loss: 0.28095903992652893
step: 720, loss: 0.20527485013008118
step: 730, loss: 0.1169421598315239
step: 740, loss: 0.173121839761734
step: 750, loss: 0.3543534576892853
step: 760, loss: 0.16730651259422302
step: 770, loss: 0.08981149643659592
step: 780, loss: 0.1216118261218071
step: 790, loss: 0.09657514840364456
step: 800, loss: 0.13768510520458221
step: 810, loss: 0.2622670531272888
step: 820, loss: 0.16360913217067719
step: 830, loss: 0.15159747004508972
step: 840, loss: 0.050483185797929764
step: 850, loss: 0.10839404910802841
step: 860, loss: 0.19433832168579102
step: 870, loss: 0.13441970944404602
step: 880, loss: 0.0686086043715477
step: 890, loss: 0.12916432321071625
step: 900, loss: 0.06535714864730835
step: 910, loss: 0.1778319627046585
step: 920, loss: 0.21790435910224915
step: 930, loss: 0.0983424037694931
step: 940, loss: 0.1489054560661316
epoch 2: dev_f1=0.950943396226415, f1=0.9286740067017711, best_f1=0.9286740067017711
step: 0, loss: 0.07491350919008255
step: 10, loss: 0.0921391099691391
step: 20, loss: 0.19645725190639496
step: 30, loss: 0.4149407744407654
step: 40, loss: 0.08362729102373123
step: 50, loss: 0.19599337875843048
step: 60, loss: 0.17583920061588287
step: 70, loss: 0.07932434976100922
step: 80, loss: 0.12257867306470871
step: 90, loss: 0.025817541405558586
step: 100, loss: 0.13377264142036438
step: 110, loss: 0.02110479399561882
step: 120, loss: 0.01596272550523281
step: 130, loss: 0.13825297355651855
step: 140, loss: 0.11993417888879776
step: 150, loss: 0.07601466774940491
step: 160, loss: 0.0707772895693779
step: 170, loss: 0.22685100138187408
step: 180, loss: 0.022250298410654068
step: 190, loss: 0.06432186812162399
step: 200, loss: 0.252555787563324
step: 210, loss: 0.21435722708702087
step: 220, loss: 0.12400064617395401
step: 230, loss: 0.17435704171657562
step: 240, loss: 0.08232218027114868
step: 250, loss: 0.043083321303129196
step: 260, loss: 0.104703888297081
step: 270, loss: 0.23845095932483673
step: 280, loss: 0.09591203927993774
step: 290, loss: 0.11141685396432877
step: 300, loss: 0.2647159993648529
step: 310, loss: 0.10602069646120071
step: 320, loss: 0.17878097295761108
step: 330, loss: 0.10910864919424057
step: 340, loss: 0.14272373914718628
step: 350, loss: 0.03356480970978737
step: 360, loss: 0.08864714205265045
step: 370, loss: 0.039419569075107574
step: 380, loss: 0.018857885152101517
step: 390, loss: 0.1366201490163803
step: 400, loss: 0.19605116546154022
step: 410, loss: 0.04222976043820381
step: 420, loss: 0.03762465715408325
step: 430, loss: 0.11566174775362015
step: 440, loss: 0.06033695861697197
step: 450, loss: 0.052015289664268494
step: 460, loss: 0.041533589363098145
step: 470, loss: 0.11083266139030457
step: 480, loss: 0.15732668340206146
step: 490, loss: 0.06183595582842827
step: 500, loss: 0.02820502407848835
step: 510, loss: 0.08288735151290894
step: 520, loss: 0.1276380866765976
step: 530, loss: 0.061010099947452545
step: 540, loss: 0.11836053431034088
step: 550, loss: 0.04393235966563225
step: 560, loss: 0.014623046852648258
step: 570, loss: 0.07399016618728638
step: 580, loss: 0.06052205711603165
step: 590, loss: 0.06043463945388794
step: 600, loss: 0.04381943121552467
step: 610, loss: 0.1155272051692009
step: 620, loss: 0.12038705497980118
step: 630, loss: 0.29713550209999084
step: 640, loss: 0.12476254999637604
step: 650, loss: 0.09539075195789337
step: 660, loss: 0.2380422055721283
step: 670, loss: 0.05400624871253967
step: 680, loss: 0.0662030577659607
step: 690, loss: 0.2141178548336029
step: 700, loss: 0.19201454520225525
step: 710, loss: 0.1290539801120758
step: 720, loss: 0.08854877203702927
step: 730, loss: 0.12935896217823029
step: 740, loss: 0.041265252977609634
step: 750, loss: 0.1755281537771225
step: 760, loss: 0.14555402100086212
step: 770, loss: 0.0759328305721283
step: 780, loss: 0.19406495988368988
step: 790, loss: 0.054632335901260376
step: 800, loss: 0.01563180610537529
step: 810, loss: 0.00636118371039629
step: 820, loss: 0.01922105811536312
step: 830, loss: 0.16618485748767853
step: 840, loss: 0.06590452790260315
step: 850, loss: 0.27489954233169556
step: 860, loss: 0.09780464321374893
step: 870, loss: 0.2654852569103241
step: 880, loss: 0.044863466173410416
step: 890, loss: 0.17367400228977203
step: 900, loss: 0.18260295689105988
step: 910, loss: 0.07347096502780914
step: 920, loss: 0.14968396723270416
step: 930, loss: 0.09596078842878342
step: 940, loss: 0.044296007603406906
epoch 3: dev_f1=0.949767441860465, f1=0.9308235294117647, best_f1=0.9286740067017711
step: 0, loss: 0.024530408903956413
step: 10, loss: 0.15379762649536133
step: 20, loss: 0.06484957784414291
step: 30, loss: 0.011421749368309975
step: 40, loss: 0.12495061010122299
step: 50, loss: 0.05445672944188118
step: 60, loss: 0.02352314442396164
step: 70, loss: 0.15706317126750946
step: 80, loss: 0.13520361483097076
step: 90, loss: 0.05131658911705017
step: 100, loss: 0.03449693322181702
step: 110, loss: 0.09338366985321045
step: 120, loss: 0.1797400265932083
step: 130, loss: 0.07126101106405258
step: 140, loss: 0.06759905070066452
step: 150, loss: 0.07023970037698746
step: 160, loss: 0.03215506300330162
step: 170, loss: 0.08779647201299667
step: 180, loss: 0.036088477820158005
step: 190, loss: 0.036403778940439224
step: 200, loss: 0.07867591083049774
step: 210, loss: 0.07894989848136902
step: 220, loss: 0.015992728993296623
step: 230, loss: 0.20665407180786133
step: 240, loss: 0.24584746360778809
step: 250, loss: 0.18461990356445312
step: 260, loss: 0.08148209005594254
step: 270, loss: 0.24008719623088837
step: 280, loss: 0.1133585050702095
step: 290, loss: 0.05208693817257881
step: 300, loss: 0.08106818795204163
step: 310, loss: 0.15312020480632782
step: 320, loss: 0.04739075154066086
step: 330, loss: 0.012826360762119293
step: 340, loss: 0.12014813721179962
step: 350, loss: 0.12604168057441711
step: 360, loss: 0.09080337733030319
step: 370, loss: 0.058684367686510086
step: 380, loss: 0.004621818661689758
step: 390, loss: 0.20562966167926788
step: 400, loss: 0.10031083971261978
step: 410, loss: 0.04473459720611572
step: 420, loss: 0.12316853553056717
step: 430, loss: 0.05804772675037384
step: 440, loss: 0.21865107119083405
step: 450, loss: 0.05350707098841667
step: 460, loss: 0.01379223633557558
step: 470, loss: 0.028290044516324997
step: 480, loss: 0.032695040106773376
step: 490, loss: 0.17047958076000214
step: 500, loss: 0.012296068482100964
step: 510, loss: 0.13473422825336456
step: 520, loss: 0.141404926776886
step: 530, loss: 0.11319853365421295
step: 540, loss: 0.22058236598968506
step: 550, loss: 0.041121549904346466
step: 560, loss: 0.039909642189741135
step: 570, loss: 0.08306550979614258
step: 580, loss: 0.03322848305106163
step: 590, loss: 0.12348318845033646
step: 600, loss: 0.07072898745536804
step: 610, loss: 0.26772016286849976
step: 620, loss: 0.09321728348731995
step: 630, loss: 0.06995508819818497
step: 640, loss: 0.03317100927233696
step: 650, loss: 0.2896135747432709
step: 660, loss: 0.03800768405199051
step: 670, loss: 0.006864999886602163
step: 680, loss: 0.060531891882419586
step: 690, loss: 0.05483279004693031
step: 700, loss: 0.053203947842121124
step: 710, loss: 0.017278747633099556
step: 720, loss: 0.06757132709026337
step: 730, loss: 0.1402493715286255
step: 740, loss: 0.19017253816127777
step: 750, loss: 0.05719315633177757
step: 760, loss: 0.07904820144176483
step: 770, loss: 0.11668211966753006
step: 780, loss: 0.0583934411406517
step: 790, loss: 0.061770617961883545
step: 800, loss: 0.18997879326343536
step: 810, loss: 0.32628193497657776
step: 820, loss: 0.039010342210531235
step: 830, loss: 0.05288276448845863
step: 840, loss: 0.028990620747208595
step: 850, loss: 0.16856540739536285
step: 860, loss: 0.0783359631896019
step: 870, loss: 0.11824794858694077
step: 880, loss: 0.02154705859720707
step: 890, loss: 0.02488354779779911
step: 900, loss: 0.05845664069056511
step: 910, loss: 0.03899029642343521
step: 920, loss: 0.02196565456688404
step: 930, loss: 0.02891751565039158
step: 940, loss: 0.04933767765760422
epoch 4: dev_f1=0.9462867818776274, f1=0.9245994344957589, best_f1=0.9286740067017711
step: 0, loss: 0.23251274228096008
step: 10, loss: 0.07715506106615067
step: 20, loss: 0.003701369510963559
step: 30, loss: 0.021928558126091957
step: 40, loss: 0.24316655099391937
step: 50, loss: 0.10177909582853317
step: 60, loss: 0.02129700966179371
step: 70, loss: 0.031847380101680756
step: 80, loss: 0.1641455590724945
step: 90, loss: 0.20505684614181519
step: 100, loss: 0.014423036947846413
step: 110, loss: 0.03363794833421707
step: 120, loss: 0.04321290925145149
step: 130, loss: 0.020887278020381927
step: 140, loss: 0.019843099638819695
step: 150, loss: 0.029988911002874374
step: 160, loss: 0.023668842390179634
step: 170, loss: 0.0012667394476011395
step: 180, loss: 0.15495380759239197
step: 190, loss: 0.028960295021533966
step: 200, loss: 0.02921794354915619
step: 210, loss: 0.25828737020492554
step: 220, loss: 0.13652271032333374
step: 230, loss: 0.1918376088142395
step: 240, loss: 0.04467054083943367
step: 250, loss: 0.07190106064081192
step: 260, loss: 0.027559977024793625
step: 270, loss: 0.05285210162401199
step: 280, loss: 0.02745688334107399
step: 290, loss: 0.026560960337519646
step: 300, loss: 0.03525787591934204
step: 310, loss: 0.13782967627048492
step: 320, loss: 0.018295900896191597
step: 330, loss: 0.029926422983407974
step: 340, loss: 0.06163686141371727
step: 350, loss: 0.058531519025564194
step: 360, loss: 0.033434413373470306
step: 370, loss: 0.05776040628552437
step: 380, loss: 0.04547983407974243
step: 390, loss: 0.07097676396369934
step: 400, loss: 0.0748002901673317
step: 410, loss: 0.047626253217458725
step: 420, loss: 0.038379620760679245
step: 430, loss: 0.020260710269212723
step: 440, loss: 0.054449137300252914
step: 450, loss: 0.030518369749188423
step: 460, loss: 0.0372435562312603
step: 470, loss: 0.1366931051015854
step: 480, loss: 0.12592175602912903
step: 490, loss: 0.10713563114404678
step: 500, loss: 0.016172660514712334
step: 510, loss: 0.01849733479321003
step: 520, loss: 0.162996307015419
step: 530, loss: 0.042451225221157074
step: 540, loss: 0.11149713397026062
step: 550, loss: 0.1358056664466858
step: 560, loss: 0.15147069096565247
step: 570, loss: 0.056355684995651245
step: 580, loss: 0.05057103559374809
step: 590, loss: 0.008254068903625011
step: 600, loss: 0.0055787218734622
step: 610, loss: 0.006481731776148081
step: 620, loss: 0.0175465177744627
step: 630, loss: 0.0990542322397232
step: 640, loss: 0.17030051350593567
step: 650, loss: 0.13772591948509216
step: 660, loss: 0.02671153098344803
step: 670, loss: 0.0653330534696579
step: 680, loss: 0.06837382167577744
step: 690, loss: 0.04709472134709358
step: 700, loss: 0.11273211985826492
step: 710, loss: 0.006846295669674873
step: 720, loss: 0.03956697881221771
step: 730, loss: 0.13842186331748962
step: 740, loss: 0.04460151121020317
step: 750, loss: 0.002423624275252223
step: 760, loss: 0.0630706176161766
step: 770, loss: 0.044572774320840836
step: 780, loss: 0.04109910503029823
step: 790, loss: 0.004292073659598827
step: 800, loss: 0.04819941520690918
step: 810, loss: 0.04571330547332764
step: 820, loss: 0.06674299389123917
step: 830, loss: 0.020381735637784004
step: 840, loss: 0.009176977910101414
step: 850, loss: 0.11814809590578079
step: 860, loss: 0.07732735574245453
step: 870, loss: 0.2177659124135971
step: 880, loss: 0.06550124287605286
step: 890, loss: 0.2802734971046448
step: 900, loss: 0.056489259004592896
step: 910, loss: 0.07483181357383728
step: 920, loss: 0.007416598033159971
step: 930, loss: 0.017347004264593124
step: 940, loss: 0.016564663499593735
epoch 5: dev_f1=0.9425287356321841, f1=0.9309225776541493, best_f1=0.9286740067017711
step: 0, loss: 0.004289915785193443
step: 10, loss: 0.0326547808945179
step: 20, loss: 0.013619637116789818
step: 30, loss: 0.009727648459374905
step: 40, loss: 0.017091594636440277
step: 50, loss: 0.005283965263515711
step: 60, loss: 0.025930283591151237
step: 70, loss: 0.09677059948444366
step: 80, loss: 0.03811260312795639
step: 90, loss: 0.053204216063022614
step: 100, loss: 0.013001881539821625
step: 110, loss: 0.006176954600960016
step: 120, loss: 0.00700945220887661
step: 130, loss: 0.05640694126486778
step: 140, loss: 0.10398105531930923
step: 150, loss: 0.03647448867559433
step: 160, loss: 0.015839697793126106
step: 170, loss: 0.012240469455718994
step: 180, loss: 0.07050823420286179
step: 190, loss: 0.010096807032823563
step: 200, loss: 0.137475848197937
step: 210, loss: 0.05950603634119034
step: 220, loss: 0.021180229261517525
step: 230, loss: 0.014293089509010315
step: 240, loss: 0.026309411972761154
step: 250, loss: 0.008583304472267628
step: 260, loss: 0.06268264353275299
step: 270, loss: 0.1316262185573578
step: 280, loss: 0.003586463863030076
step: 290, loss: 0.026495419442653656
step: 300, loss: 0.026484394446015358
step: 310, loss: 0.04697570204734802
step: 320, loss: 0.06955794245004654
step: 330, loss: 0.0020319761242717505
step: 340, loss: 0.0225323848426342
step: 350, loss: 0.028498800471425056
step: 360, loss: 0.15361866354942322
step: 370, loss: 0.052222855389118195
step: 380, loss: 0.030747387558221817
step: 390, loss: 0.015401839278638363
step: 400, loss: 0.04174662008881569
step: 410, loss: 0.22992397844791412
step: 420, loss: 0.046204447746276855
step: 430, loss: 0.21463191509246826
step: 440, loss: 0.10759373009204865
step: 450, loss: 0.003778942162171006
step: 460, loss: 0.014960091561079025
step: 470, loss: 0.08828099071979523
step: 480, loss: 0.08035897463560104
step: 490, loss: 0.06979116052389145
step: 500, loss: 0.0023613939993083477
step: 510, loss: 0.007546981796622276
step: 520, loss: 0.0031263474375009537
step: 530, loss: 0.06977590918540955
step: 540, loss: 0.009275966323912144
step: 550, loss: 0.055589284747838974
step: 560, loss: 0.07445467263460159
step: 570, loss: 0.003080648835748434
step: 580, loss: 0.003076520748436451
step: 590, loss: 0.0506262332201004
step: 600, loss: 0.15925347805023193
step: 610, loss: 0.0012624762021005154
step: 620, loss: 0.06779365241527557
step: 630, loss: 0.005519820377230644
step: 640, loss: 0.025185786187648773
step: 650, loss: 0.1848624050617218
step: 660, loss: 0.03520222380757332
step: 670, loss: 0.06311271339654922
step: 680, loss: 0.01725507527589798
step: 690, loss: 0.22424523532390594
step: 700, loss: 0.012110312469303608
step: 710, loss: 0.03439337760210037
step: 720, loss: 0.015659019351005554
step: 730, loss: 0.037121810019016266
step: 740, loss: 0.06935400515794754
step: 750, loss: 0.00621657632291317
step: 760, loss: 0.037359707057476044
step: 770, loss: 0.0121635552495718
step: 780, loss: 0.006784265860915184
step: 790, loss: 0.017015580087900162
step: 800, loss: 0.23047778010368347
step: 810, loss: 0.002658892422914505
step: 820, loss: 0.03329847753047943
step: 830, loss: 0.01733584888279438
step: 840, loss: 0.0024211034178733826
step: 850, loss: 0.02903367020189762
step: 860, loss: 0.018412873148918152
step: 870, loss: 0.1183801218867302
step: 880, loss: 0.029578587040305138
step: 890, loss: 0.04501591622829437
step: 900, loss: 0.015384696424007416
step: 910, loss: 0.03086158260703087
step: 920, loss: 0.058951303362846375
step: 930, loss: 0.0020644061733037233
step: 940, loss: 0.19045312702655792
epoch 6: dev_f1=0.9426691729323308, f1=0.9308056872037914, best_f1=0.9286740067017711
step: 0, loss: 0.01645739935338497
step: 10, loss: 0.0291136484593153
step: 20, loss: 0.01925468258559704
step: 30, loss: 0.020601889118552208
step: 40, loss: 0.00924135185778141
step: 50, loss: 0.03026973269879818
step: 60, loss: 0.005170925986021757
step: 70, loss: 0.0031620878726243973
step: 80, loss: 0.002205378608778119
step: 90, loss: 0.008565656840801239
step: 100, loss: 0.007313964888453484
step: 110, loss: 0.0037278253585100174
step: 120, loss: 0.018943198025226593
step: 130, loss: 0.0216523464769125
step: 140, loss: 0.1085197851061821
step: 150, loss: 0.001084151677787304
step: 160, loss: 0.014120320789515972
step: 170, loss: 0.000863252324052155
step: 180, loss: 0.00217820075340569
step: 190, loss: 0.005416278727352619
step: 200, loss: 0.09373973309993744
step: 210, loss: 0.05445257946848869
step: 220, loss: 0.03382701054215431
step: 230, loss: 0.012859662063419819
step: 240, loss: 0.005091399420052767
step: 250, loss: 0.0011630923254415393
step: 260, loss: 0.022556161507964134
step: 270, loss: 0.039172250777482986
step: 280, loss: 0.0276100505143404
step: 290, loss: 0.02861398458480835
step: 300, loss: 0.07570618391036987
step: 310, loss: 0.005249164067208767
step: 320, loss: 0.023256942629814148
step: 330, loss: 0.12581892311573029
step: 340, loss: 0.009251495823264122
step: 350, loss: 0.049467187374830246
step: 360, loss: 0.03535052761435509
step: 370, loss: 0.001461647916585207
step: 380, loss: 0.02252056635916233
step: 390, loss: 0.0032494892366230488
step: 400, loss: 0.08359452337026596
step: 410, loss: 0.09635273367166519
step: 420, loss: 0.0021597198210656643
step: 430, loss: 0.0018522562459111214
step: 440, loss: 0.05949746072292328
step: 450, loss: 0.04976026341319084
step: 460, loss: 0.01782909967005253
step: 470, loss: 0.0165605116635561
step: 480, loss: 0.003991244360804558
step: 490, loss: 0.04025322198867798
step: 500, loss: 0.03229113295674324
step: 510, loss: 0.004976359661668539
step: 520, loss: 0.0043464298360049725
step: 530, loss: 0.012926701456308365
step: 540, loss: 0.00828138180077076
step: 550, loss: 0.0018355799838900566
step: 560, loss: 0.006754678208380938
step: 570, loss: 0.003101628739386797
step: 580, loss: 0.07024798542261124
step: 590, loss: 0.05087272822856903
step: 600, loss: 0.03328169882297516
step: 610, loss: 0.024671275168657303
step: 620, loss: 0.03633106127381325
step: 630, loss: 0.013584773987531662
step: 640, loss: 0.10843160003423691
step: 650, loss: 0.014851600863039494
step: 660, loss: 0.0826878771185875
step: 670, loss: 0.00438785832375288
step: 680, loss: 0.028409313410520554
step: 690, loss: 0.09747117012739182
step: 700, loss: 0.07833556085824966
step: 710, loss: 0.01788904145359993
step: 720, loss: 0.05427411571145058
step: 730, loss: 0.15475140511989594
step: 740, loss: 0.001421458786353469
step: 750, loss: 0.00383097305893898
step: 760, loss: 0.08692288398742676
step: 770, loss: 0.009898005053400993
step: 780, loss: 0.01665652170777321
step: 790, loss: 0.14703603088855743
step: 800, loss: 0.019162744283676147
step: 810, loss: 0.015541410073637962
step: 820, loss: 0.0034028247464448214
step: 830, loss: 0.0020115196239203215
step: 840, loss: 0.003628774546086788
step: 850, loss: 0.012323267757892609
step: 860, loss: 0.015842551365494728
step: 870, loss: 0.1587158441543579
step: 880, loss: 0.0029353625141084194
step: 890, loss: 0.05128345265984535
step: 900, loss: 0.005900256801396608
step: 910, loss: 0.006650377530604601
step: 920, loss: 0.008265284821391106
step: 930, loss: 0.03839437663555145
step: 940, loss: 0.04114646464586258
epoch 7: dev_f1=0.9387755102040817, f1=0.9232914923291492, best_f1=0.9286740067017711
step: 0, loss: 0.06840232014656067
step: 10, loss: 0.044908199459314346
step: 20, loss: 0.01713305525481701
step: 30, loss: 0.1053789034485817
step: 40, loss: 0.0008807797566987574
step: 50, loss: 0.0002825229021254927
step: 60, loss: 0.004916663281619549
step: 70, loss: 0.007455694954842329
step: 80, loss: 0.027734236791729927
step: 90, loss: 0.011981687508523464
step: 100, loss: 0.00035583251155912876
step: 110, loss: 0.0008640579762868583
step: 120, loss: 0.003426582785323262
step: 130, loss: 0.06497864425182343
step: 140, loss: 0.001379872439429164
step: 150, loss: 0.0018362825503572822
step: 160, loss: 0.02854986861348152
step: 170, loss: 0.03270348533987999
step: 180, loss: 0.008710172027349472
step: 190, loss: 0.012362798675894737
step: 200, loss: 0.0642232745885849
step: 210, loss: 0.01927795261144638
step: 220, loss: 0.0331202931702137
step: 230, loss: 0.0017205968033522367
step: 240, loss: 0.029106369242072105
step: 250, loss: 0.04059555009007454
step: 260, loss: 0.0913928747177124
step: 270, loss: 0.027028152719140053
step: 280, loss: 0.0028162787202745676
step: 290, loss: 0.01372150145471096
step: 300, loss: 0.00640216376632452
step: 310, loss: 0.0010363494511693716
step: 320, loss: 0.0044355690479278564
step: 330, loss: 0.0014969840412959456
step: 340, loss: 0.026832912117242813
step: 350, loss: 0.00454541714861989
step: 360, loss: 0.0020196905825287104
step: 370, loss: 0.0009896514238789678
step: 380, loss: 0.06233498454093933
step: 390, loss: 0.01188219990581274
step: 400, loss: 0.007790135685354471
step: 410, loss: 0.00893002562224865
step: 420, loss: 0.04330337792634964
step: 430, loss: 0.017634745687246323
step: 440, loss: 0.0037385199684649706
step: 450, loss: 0.0007675342494621873
step: 460, loss: 0.010190672241151333
step: 470, loss: 0.05944085121154785
step: 480, loss: 0.0078011625446379185
step: 490, loss: 0.0017227353528141975
step: 500, loss: 0.01778046414256096
step: 510, loss: 0.001002354547381401
step: 520, loss: 0.012605343014001846
step: 530, loss: 0.00037830579094588757
step: 540, loss: 0.08611621707677841
step: 550, loss: 0.004832088015973568
step: 560, loss: 0.014675448648631573
step: 570, loss: 0.0025076756719499826
step: 580, loss: 0.005593887064605951
step: 590, loss: 0.002314216922968626
step: 600, loss: 0.002192274434491992
step: 610, loss: 0.04754946753382683
step: 620, loss: 0.06929187476634979
step: 630, loss: 0.05230293050408363
step: 640, loss: 0.0009058505529537797
step: 650, loss: 0.1319640576839447
step: 660, loss: 0.0010693168733268976
step: 670, loss: 0.003048910526558757
step: 680, loss: 0.03180549293756485
step: 690, loss: 0.02913709171116352
step: 700, loss: 0.08889126032590866
step: 710, loss: 0.007414674386382103
step: 720, loss: 0.003159394022077322
step: 730, loss: 0.009121719747781754
step: 740, loss: 0.004431933164596558
step: 750, loss: 0.006432842928916216
step: 760, loss: 0.040361445397138596
step: 770, loss: 0.010564661584794521
step: 780, loss: 0.0009162453934550285
step: 790, loss: 0.07388298958539963
step: 800, loss: 0.00256070657633245
step: 810, loss: 0.02850002981722355
step: 820, loss: 0.0020331924315541983
step: 830, loss: 0.00033291871659457684
step: 840, loss: 0.0006572623387910426
step: 850, loss: 0.0002456267538946122
step: 860, loss: 0.0007013398571871221
step: 870, loss: 0.01669686660170555
step: 880, loss: 0.1506258100271225
step: 890, loss: 0.024859510362148285
step: 900, loss: 0.028864853084087372
step: 910, loss: 0.03446583077311516
step: 920, loss: 0.09393171221017838
step: 930, loss: 0.007303273770958185
step: 940, loss: 0.014877970330417156
epoch 8: dev_f1=0.9360709286047598, f1=0.9158091674462113, best_f1=0.9286740067017711
step: 0, loss: 0.001675903215073049
step: 10, loss: 0.021279582753777504
step: 20, loss: 0.045507434755563736
step: 30, loss: 0.0029416410252451897
step: 40, loss: 0.0003181728534400463
step: 50, loss: 0.00034456499270163476
step: 60, loss: 0.0030509475618600845
step: 70, loss: 0.0003915009438060224
step: 80, loss: 0.00444891257211566
step: 90, loss: 0.0027355002239346504
step: 100, loss: 0.0010438018944114447
step: 110, loss: 0.0009221769869327545
step: 120, loss: 0.06535301357507706
step: 130, loss: 0.0015261732041835785
step: 140, loss: 0.030908938497304916
step: 150, loss: 0.0018204625230282545
step: 160, loss: 0.012143307365477085
step: 170, loss: 0.006597729865461588
step: 180, loss: 0.018236100673675537
step: 190, loss: 0.004745491314679384
step: 200, loss: 0.005994636565446854
step: 210, loss: 0.010439152829349041
step: 220, loss: 0.09254653006792068
step: 230, loss: 0.006834469269961119
step: 240, loss: 0.002351832576096058
step: 250, loss: 0.12699167430400848
step: 260, loss: 0.0010813635308295488
step: 270, loss: 0.1596149206161499
step: 280, loss: 0.02801019698381424
step: 290, loss: 0.004569061566144228
step: 300, loss: 0.00916711613535881
step: 310, loss: 0.023501820862293243
step: 320, loss: 0.001811067690141499
step: 330, loss: 0.0022877114824950695
step: 340, loss: 0.011496908031404018
step: 350, loss: 0.007579213939607143
step: 360, loss: 0.009602497331798077
step: 370, loss: 0.0212100837379694
step: 380, loss: 0.010419290512800217
step: 390, loss: 0.0016056656604632735
step: 400, loss: 0.0011537184473127127
step: 410, loss: 0.0053177326917648315
step: 420, loss: 0.06878302991390228
step: 430, loss: 0.19857430458068848
step: 440, loss: 7.8823599324096e-05
step: 450, loss: 0.07655160874128342
step: 460, loss: 0.000912656425498426
step: 470, loss: 0.008710670284926891
step: 480, loss: 0.019960995763540268
step: 490, loss: 0.0075441994704306126
step: 500, loss: 0.0002650355745572597
step: 510, loss: 0.0005765737150795758
step: 520, loss: 0.172884002327919
step: 530, loss: 0.03192523866891861
step: 540, loss: 0.06624439358711243
step: 550, loss: 0.004533195402473211
step: 560, loss: 0.072810098528862
step: 570, loss: 0.0015089872758835554
step: 580, loss: 0.00025089961127378047
step: 590, loss: 0.010414990596473217
step: 600, loss: 0.001959563000127673
step: 610, loss: 0.00602889247238636
step: 620, loss: 0.0033593573607504368
step: 630, loss: 0.007459851913154125
step: 640, loss: 0.049508314579725266
step: 650, loss: 0.0036081974394619465
step: 660, loss: 0.02018379047513008
step: 670, loss: 0.10315600037574768
step: 680, loss: 0.00561023224145174
step: 690, loss: 0.03358267992734909
step: 700, loss: 0.0013070335844531655
step: 710, loss: 0.0008117607212625444
step: 720, loss: 0.05141875892877579
step: 730, loss: 0.001757257035933435
step: 740, loss: 0.04732922464609146
step: 750, loss: 0.10184246301651001
step: 760, loss: 0.0006435852264985442
step: 770, loss: 0.003168220166116953
step: 780, loss: 0.03634034842252731
step: 790, loss: 0.0009959451854228973
step: 800, loss: 0.00215518637560308
step: 810, loss: 0.002228661673143506
step: 820, loss: 0.027062391862273216
step: 830, loss: 0.01705126091837883
step: 840, loss: 0.011218165047466755
step: 850, loss: 0.0005735757295042276
step: 860, loss: 0.0072400690987706184
step: 870, loss: 0.07305748760700226
step: 880, loss: 0.15121714770793915
step: 890, loss: 0.00027947823400609195
step: 900, loss: 0.004216990899294615
step: 910, loss: 0.0024634324945509434
step: 920, loss: 0.07830721139907837
step: 930, loss: 0.028391579166054726
step: 940, loss: 0.0018608694663271308
epoch 9: dev_f1=0.9403475810239549, f1=0.9227099236641221, best_f1=0.9286740067017711
step: 0, loss: 9.246785339200869e-05
step: 10, loss: 0.0002269168762722984
step: 20, loss: 0.00021121121244505048
step: 30, loss: 0.002316597383469343
step: 40, loss: 0.007197850849479437
step: 50, loss: 0.001768756192177534
step: 60, loss: 0.0015276039484888315
step: 70, loss: 0.0005864420672878623
step: 80, loss: 0.015328696928918362
step: 90, loss: 0.005188617389649153
step: 100, loss: 0.03134092316031456
step: 110, loss: 0.00024529563961550593
step: 120, loss: 0.07053066790103912
step: 130, loss: 0.028746483847498894
step: 140, loss: 0.001713645993731916
step: 150, loss: 0.0007053182926028967
step: 160, loss: 0.0083910608664155
step: 170, loss: 0.00048001075629144907
step: 180, loss: 0.0005425917915999889
step: 190, loss: 0.00023032340686768293
step: 200, loss: 0.0017394894966855645
step: 210, loss: 0.013505125418305397
step: 220, loss: 0.00033262642682529986
step: 230, loss: 0.015187624841928482
step: 240, loss: 0.003548185108229518
step: 250, loss: 0.00027204834623262286
step: 260, loss: 0.001183145446702838
step: 270, loss: 0.030774708837270737
step: 280, loss: 0.0012640818022191525
step: 290, loss: 0.00021199206821620464
step: 300, loss: 0.0005817468627355993
step: 310, loss: 0.054103706032037735
step: 320, loss: 9.708091238280758e-05
step: 330, loss: 0.00026705313939601183
step: 340, loss: 0.0010446126107126474
step: 350, loss: 0.0254758782684803
step: 360, loss: 0.0005205149063840508
step: 370, loss: 0.0028759976848959923
step: 380, loss: 0.001506879460066557
step: 390, loss: 0.004383685067296028
step: 400, loss: 0.00014970758638810366
step: 410, loss: 0.0010873893043026328
step: 420, loss: 0.0005799237405881286
step: 430, loss: 0.0016884756041690707
step: 440, loss: 0.0011825145920738578
step: 450, loss: 0.00030171891557984054
step: 460, loss: 0.02176828868687153
step: 470, loss: 0.00022177622304297984
step: 480, loss: 0.01208079420030117
step: 490, loss: 0.0013378543080762029
step: 500, loss: 0.005690202582627535
step: 510, loss: 0.08858582377433777
step: 520, loss: 0.021791797131299973
step: 530, loss: 0.011734569445252419
step: 540, loss: 0.01927849091589451
step: 550, loss: 0.00020096692605875432
step: 560, loss: 0.06719589233398438
step: 570, loss: 0.006256437860429287
step: 580, loss: 0.00828151497989893
step: 590, loss: 0.0004883728688582778
step: 600, loss: 0.22844238579273224
step: 610, loss: 0.004581175744533539
step: 620, loss: 0.0003225759428460151
step: 630, loss: 0.0002215703862020746
step: 640, loss: 0.0018106464995071292
step: 650, loss: 0.0002293968718731776
step: 660, loss: 0.0035977079533040524
step: 670, loss: 0.0003366371965967119
step: 680, loss: 0.3050587773323059
step: 690, loss: 0.0005280891200527549
step: 700, loss: 0.07180843502283096
step: 710, loss: 0.0013471526326611638
step: 720, loss: 0.004414317198097706
step: 730, loss: 0.015270430594682693
step: 740, loss: 0.025740232318639755
step: 750, loss: 0.0011559571139514446
step: 760, loss: 0.010449537076056004
step: 770, loss: 0.007537689059972763
step: 780, loss: 0.002152734436094761
step: 790, loss: 0.005019090138375759
step: 800, loss: 0.0012071853270754218
step: 810, loss: 0.0036657557357102633
step: 820, loss: 0.0012341198744252324
step: 830, loss: 0.06544491648674011
step: 840, loss: 0.04245747625827789
step: 850, loss: 0.006359096150845289
step: 860, loss: 0.0008257807930931449
step: 870, loss: 0.04676350578665733
step: 880, loss: 0.0005463384441100061
step: 890, loss: 0.0026018419302999973
step: 900, loss: 0.031046878546476364
step: 910, loss: 0.18094682693481445
step: 920, loss: 0.006085471250116825
step: 930, loss: 0.0004814942949451506
step: 940, loss: 0.0008114760858006775
epoch 10: dev_f1=0.944649446494465, f1=0.9271028037383178, best_f1=0.9286740067017711
step: 0, loss: 0.0006051089731045067
step: 10, loss: 0.0003496368881314993
step: 20, loss: 0.0034788933116942644
step: 30, loss: 0.0005335111636668444
step: 40, loss: 0.0005665778880938888
step: 50, loss: 0.0009632005239836872
step: 60, loss: 0.0013829341623932123
step: 70, loss: 0.001574976835399866
step: 80, loss: 0.00030404338031075895
step: 90, loss: 0.0006404752493835986
step: 100, loss: 0.0006013347301632166
step: 110, loss: 0.01574801281094551
step: 120, loss: 0.023176629096269608
step: 130, loss: 0.0035161736886948347
step: 140, loss: 0.03277407959103584
step: 150, loss: 0.028386546298861504
step: 160, loss: 0.0014888511504977942
step: 170, loss: 0.037360966205596924
step: 180, loss: 0.0002911678166128695
step: 190, loss: 0.0017089679604396224
step: 200, loss: 0.00282872817479074
step: 210, loss: 0.012697238475084305
step: 220, loss: 0.0002757385082077235
step: 230, loss: 0.005056669004261494
step: 240, loss: 0.05432189255952835
step: 250, loss: 0.0036463572178035975
step: 260, loss: 0.0004276793624740094
step: 270, loss: 0.0010520373471081257
step: 280, loss: 0.0002911584742832929
step: 290, loss: 0.007128883618861437
step: 300, loss: 0.004062075633555651
step: 310, loss: 0.007359125651419163
step: 320, loss: 0.0007250733324326575
step: 330, loss: 9.446367766940966e-05
step: 340, loss: 0.0022076221648603678
step: 350, loss: 0.0865287110209465
step: 360, loss: 0.01151792798191309
step: 370, loss: 0.0006220920477062464
step: 380, loss: 0.0036433334462344646
step: 390, loss: 0.0011055467184633017
step: 400, loss: 0.04476667940616608
step: 410, loss: 0.0005685091600753367
step: 420, loss: 0.00018613910651765764
step: 430, loss: 0.001701640896499157
step: 440, loss: 0.00029985123546794057
step: 450, loss: 0.01693023554980755
step: 460, loss: 0.0003597579197958112
step: 470, loss: 0.08687157928943634
step: 480, loss: 0.0011372651206329465
step: 490, loss: 0.09253858774900436
step: 500, loss: 0.010920889675617218
step: 510, loss: 0.00015659703058190644
step: 520, loss: 0.019669119268655777
step: 530, loss: 0.0033695281017571688
step: 540, loss: 0.0007471503922715783
step: 550, loss: 0.0014266164507716894
step: 560, loss: 0.020396264269948006
step: 570, loss: 0.012357314117252827
step: 580, loss: 0.0021365568973124027
step: 590, loss: 0.020837556570768356
step: 600, loss: 0.12508821487426758
step: 610, loss: 0.00013452238636091352
step: 620, loss: 0.07862798869609833
step: 630, loss: 0.0004116581694688648
step: 640, loss: 0.027336737141013145
step: 650, loss: 0.0006606857059523463
step: 660, loss: 0.0002919660182669759
step: 670, loss: 0.023759664967656136
step: 680, loss: 0.005649937316775322
step: 690, loss: 0.0014338346663862467
step: 700, loss: 0.007402035407721996
step: 710, loss: 0.004402985796332359
step: 720, loss: 0.00023488272563554347
step: 730, loss: 0.00027833273634314537
step: 740, loss: 0.10101944953203201
step: 750, loss: 0.0007069084094837308
step: 760, loss: 0.01162145845592022
step: 770, loss: 0.019137904047966003
step: 780, loss: 0.0013802037574350834
step: 790, loss: 0.0006208468112163246
step: 800, loss: 0.0019183109980076551
step: 810, loss: 0.004925622139126062
step: 820, loss: 0.11082509160041809
step: 830, loss: 0.011130579747259617
step: 840, loss: 8.966042514657602e-05
step: 850, loss: 0.01541085634380579
step: 860, loss: 0.019542627036571503
step: 870, loss: 0.00016576478083152324
step: 880, loss: 0.013055759482085705
step: 890, loss: 0.04267304390668869
step: 900, loss: 0.11245426535606384
step: 910, loss: 0.0004924598033539951
step: 920, loss: 0.06966064125299454
step: 930, loss: 0.0005010891472920775
step: 940, loss: 0.035192180424928665
epoch 11: dev_f1=0.9419414770088249, f1=0.9288702928870293, best_f1=0.9286740067017711
step: 0, loss: 0.0003705759299919009
step: 10, loss: 0.0006063575274311006
step: 20, loss: 0.0009568698587827384
step: 30, loss: 0.0007876419113017619
step: 40, loss: 0.0003581356140784919
step: 50, loss: 0.0005259561003185809
step: 60, loss: 0.00013294264499563724
step: 70, loss: 0.038405779749155045
step: 80, loss: 0.046412933617830276
step: 90, loss: 0.00013149795995559543
step: 100, loss: 0.00035993653000332415
step: 110, loss: 0.0005259323515929282
step: 120, loss: 0.00015362296835519373
step: 130, loss: 0.0006697589415125549
step: 140, loss: 0.0007490477873943746
step: 150, loss: 0.0004886072711087763
step: 160, loss: 0.0008037689840421081
step: 170, loss: 0.06484642624855042
step: 180, loss: 8.237684960477054e-05
step: 190, loss: 0.0025895782746374607
step: 200, loss: 0.00010127514542546123
step: 210, loss: 0.00012232919107191265
step: 220, loss: 0.0012603681534528732
step: 230, loss: 0.019618703052401543
step: 240, loss: 0.0008485852158628404
step: 250, loss: 0.0013593444600701332
step: 260, loss: 0.004929336253553629
step: 270, loss: 0.003195742378011346
step: 280, loss: 8.543574222130701e-05
step: 290, loss: 0.0014384317910298705
step: 300, loss: 0.0004047137626912445
step: 310, loss: 0.0028438076842576265
step: 320, loss: 0.0006316204089671373
step: 330, loss: 7.073870801832527e-05
step: 340, loss: 0.025581682100892067
step: 350, loss: 0.0004533668397925794
step: 360, loss: 0.00039499724516645074
step: 370, loss: 0.00019011000404134393
step: 380, loss: 0.00012422792497090995
step: 390, loss: 5.834234616486356e-05
step: 400, loss: 0.026646552607417107
step: 410, loss: 0.0034435298293828964
step: 420, loss: 0.009469138458371162
step: 430, loss: 0.002379579935222864
step: 440, loss: 6.196065078256652e-05
step: 450, loss: 0.015137259848415852
step: 460, loss: 0.00056688446784392
step: 470, loss: 0.000325836765114218
step: 480, loss: 0.00027211467386223376
step: 490, loss: 0.03534344583749771
step: 500, loss: 0.01215983834117651
step: 510, loss: 0.0026377697940915823
step: 520, loss: 0.0018160399049520493
step: 530, loss: 0.0001449038099963218
step: 540, loss: 0.0008766002138145268
step: 550, loss: 0.0024935719557106495
step: 560, loss: 0.004788254387676716
step: 570, loss: 0.0002074368530884385
step: 580, loss: 0.0053663006983697414
step: 590, loss: 0.0010506059043109417
step: 600, loss: 0.00014752255810890347
step: 610, loss: 4.0167182305594906e-05
step: 620, loss: 5.22679511050228e-05
step: 630, loss: 0.0024005949962884188
step: 640, loss: 0.0003536392468959093
step: 650, loss: 0.00028943788493052125
step: 660, loss: 9.053705434780568e-05
step: 670, loss: 0.014385838992893696
step: 680, loss: 7.182222179835662e-05
step: 690, loss: 0.0014888134319335222
step: 700, loss: 0.006311945151537657
step: 710, loss: 0.0037399069406092167
step: 720, loss: 0.0006948296213522553
step: 730, loss: 0.014950196258723736
step: 740, loss: 0.0004056750622112304
step: 750, loss: 0.0004439631593413651
step: 760, loss: 0.0002238979795947671
step: 770, loss: 5.056380177848041e-05
step: 780, loss: 0.0001266359759029001
step: 790, loss: 0.0007763697649352252
step: 800, loss: 0.0001989487645914778
step: 810, loss: 0.08061583340167999
step: 820, loss: 0.010380209423601627
step: 830, loss: 0.00015110707317944616
step: 840, loss: 0.10018766671419144
step: 850, loss: 0.04685576632618904
step: 860, loss: 0.000359630910679698
step: 870, loss: 0.0012525528436526656
step: 880, loss: 0.0027134683914482594
step: 890, loss: 0.0003983598144259304
step: 900, loss: 0.0009529936360195279
step: 910, loss: 0.00011838428326882422
step: 920, loss: 0.00027325740666128695
step: 930, loss: 0.0017132955836132169
step: 940, loss: 0.011509756557643414
epoch 12: dev_f1=0.9451360073766714, f1=0.9258741258741259, best_f1=0.9286740067017711
step: 0, loss: 0.00032469999860040843
step: 10, loss: 0.001899136696010828
step: 20, loss: 0.0004158194933552295
step: 30, loss: 0.012090791016817093
step: 40, loss: 0.0014503998681902885
step: 50, loss: 0.00012841318675782531
step: 60, loss: 0.000529283017385751
step: 70, loss: 0.044331446290016174
step: 80, loss: 7.451781129930168e-05
step: 90, loss: 0.03758252039551735
step: 100, loss: 0.00021697842748835683
step: 110, loss: 0.0007978932117111981
step: 120, loss: 0.00042255877633579075
step: 130, loss: 8.720264304429293e-05
step: 140, loss: 0.000743155600503087
step: 150, loss: 9.834540833253413e-05
step: 160, loss: 0.00021129529341123998
step: 170, loss: 8.586238254792988e-05
step: 180, loss: 0.010284601710736752
step: 190, loss: 0.0006910354131832719
step: 200, loss: 7.170259050326422e-05
step: 210, loss: 0.0017729861428961158
step: 220, loss: 0.0001314268447458744
step: 230, loss: 0.00040440683369524777
step: 240, loss: 0.001221249345690012
step: 250, loss: 0.00013376357674133033
step: 260, loss: 0.0002001307439059019
step: 270, loss: 0.008308254182338715
step: 280, loss: 0.00012508673535194248
step: 290, loss: 0.006118953227996826
step: 300, loss: 8.02872673375532e-05
step: 310, loss: 0.00013502201181836426
step: 320, loss: 7.357342110481113e-05
step: 330, loss: 0.0373140387237072
step: 340, loss: 0.00012156681623309851
step: 350, loss: 0.0007051293505355716
step: 360, loss: 0.0008304730290547013
step: 370, loss: 0.00013159637455828488
step: 380, loss: 0.00035414626472629607
step: 390, loss: 0.00013525714166462421
step: 400, loss: 0.038043346256017685
step: 410, loss: 0.0027535874396562576
step: 420, loss: 0.00041136040817946196
step: 430, loss: 0.00205444497987628
step: 440, loss: 0.01251943875104189
step: 450, loss: 0.014303429052233696
step: 460, loss: 0.004642687737941742
step: 470, loss: 0.009015706367790699
step: 480, loss: 0.0027874219231307507
step: 490, loss: 0.00116243667434901
step: 500, loss: 0.0026313208509236574
step: 510, loss: 0.001372913713566959
step: 520, loss: 0.00012470711953938007
step: 530, loss: 0.0005362767842598259
step: 540, loss: 8.045098365982994e-05
step: 550, loss: 0.0001335148117505014
step: 560, loss: 0.013281591236591339
step: 570, loss: 0.000313556898618117
step: 580, loss: 0.0002041800325969234
step: 590, loss: 0.0005645553465001285
step: 600, loss: 0.0009312874171882868
step: 610, loss: 0.0004684566520154476
step: 620, loss: 0.000677532225381583
step: 630, loss: 0.0011194205144420266
step: 640, loss: 0.012739292345941067
step: 650, loss: 0.00010162012040382251
step: 660, loss: 0.00047010034904815257
step: 670, loss: 0.0036032572388648987
step: 680, loss: 0.0005467537557706237
step: 690, loss: 0.002856784500181675
step: 700, loss: 0.00412067212164402
step: 710, loss: 0.0005027063307352364
step: 720, loss: 0.00015453260857611895
step: 730, loss: 0.042021576315164566
step: 740, loss: 0.000106454172055237
step: 750, loss: 0.00032386407838203013
step: 760, loss: 0.0005649210070259869
step: 770, loss: 8.91216259333305e-05
step: 780, loss: 0.00024103824398480356
step: 790, loss: 0.018640883266925812
step: 800, loss: 0.00011100897972937673
step: 810, loss: 0.05218561366200447
step: 820, loss: 0.00031791924266144633
step: 830, loss: 0.0028460267931222916
step: 840, loss: 0.0001832244306569919
step: 850, loss: 0.005944917444139719
step: 860, loss: 0.0007048732368275523
step: 870, loss: 0.0014157983241602778
step: 880, loss: 0.004969237372279167
step: 890, loss: 0.006358572747558355
step: 900, loss: 0.0003274782793596387
step: 910, loss: 0.03430578485131264
step: 920, loss: 3.852752342936583e-05
step: 930, loss: 0.00020266724459361285
step: 940, loss: 0.0002950463385786861
epoch 13: dev_f1=0.9481961147086033, f1=0.9227906976744187, best_f1=0.9286740067017711
step: 0, loss: 0.02504059299826622
step: 10, loss: 0.0001595522480783984
step: 20, loss: 0.00013154707266949117
step: 30, loss: 0.00010774694965220988
step: 40, loss: 0.0013235086807981133
step: 50, loss: 0.006113483104854822
step: 60, loss: 8.142037404468283e-05
step: 70, loss: 0.0005325475940480828
step: 80, loss: 0.00011948246537940577
step: 90, loss: 0.11092362552881241
step: 100, loss: 0.0014269825769588351
step: 110, loss: 0.0005172063829377294
step: 120, loss: 0.006725116167217493
step: 130, loss: 0.008656350895762444
step: 140, loss: 0.05542973428964615
step: 150, loss: 0.00022953386360313743
step: 160, loss: 0.0008690883405506611
step: 170, loss: 0.0007352010579779744
step: 180, loss: 0.00590879051014781
step: 190, loss: 0.00042191322427242994
step: 200, loss: 0.0016470475820824504
step: 210, loss: 0.00039356574416160583
step: 220, loss: 0.000538040476385504
step: 230, loss: 0.06953860819339752
step: 240, loss: 0.0004740444419439882
step: 250, loss: 7.838047167751938e-05
step: 260, loss: 5.889248859602958e-05
step: 270, loss: 0.0005253390409052372
step: 280, loss: 0.006225866731256247
step: 290, loss: 0.0059461952187120914
step: 300, loss: 0.00015162210911512375
step: 310, loss: 6.0287413361947984e-05
step: 320, loss: 0.004365227650851011
step: 330, loss: 0.0016482557402923703
step: 340, loss: 7.578534132335335e-05
step: 350, loss: 0.019562331959605217
step: 360, loss: 0.00016615085769444704
step: 370, loss: 0.0006029339856468141
step: 380, loss: 0.00036679228651337326
step: 390, loss: 0.002413177164271474
step: 400, loss: 0.0005288408719934523
step: 410, loss: 0.0014890549937263131
step: 420, loss: 0.0006314461352303624
step: 430, loss: 0.0002735431771725416
step: 440, loss: 0.0318407341837883
step: 450, loss: 0.00039952766383066773
step: 460, loss: 0.000982660218141973
step: 470, loss: 0.006951888091862202
step: 480, loss: 0.00020308178500272334
step: 490, loss: 0.0025033133570104837
step: 500, loss: 0.0003037595597561449
step: 510, loss: 0.0011080335825681686
step: 520, loss: 0.0001150917451013811
step: 530, loss: 8.571797661716118e-05
step: 540, loss: 0.0026777544990181923
step: 550, loss: 0.00012614275328814983
step: 560, loss: 0.004386255517601967
step: 570, loss: 0.010858398862183094
step: 580, loss: 0.023104144260287285
step: 590, loss: 0.0006828744080848992
step: 600, loss: 0.01956108585000038
step: 610, loss: 0.03314623981714249
step: 620, loss: 0.002726895036175847
step: 630, loss: 9.910951484926045e-05
step: 640, loss: 0.0010807150974869728
step: 650, loss: 0.010629307478666306
step: 660, loss: 0.0002867609146051109
step: 670, loss: 0.02550610713660717
step: 680, loss: 0.0013172873295843601
step: 690, loss: 0.02902073785662651
step: 700, loss: 0.001993295270949602
step: 710, loss: 0.00015143374912440777
step: 720, loss: 0.0008625934133306146
step: 730, loss: 0.0002136004768544808
step: 740, loss: 0.0002019822713918984
step: 750, loss: 0.06053291633725166
step: 760, loss: 0.0002917297533713281
step: 770, loss: 0.00011371364234946668
step: 780, loss: 0.0033552844543009996
step: 790, loss: 0.0012673125602304935
step: 800, loss: 0.0001909254351630807
step: 810, loss: 0.1321732997894287
step: 820, loss: 0.0003081057220697403
step: 830, loss: 4.905833338852972e-05
step: 840, loss: 0.0008572317310608923
step: 850, loss: 8.31563665997237e-05
step: 860, loss: 9.532985131954774e-05
step: 870, loss: 0.00013346446212381124
step: 880, loss: 8.612515375716612e-05
step: 890, loss: 0.00010161167301703244
step: 900, loss: 0.006208533421158791
step: 910, loss: 0.00028152746381238103
step: 920, loss: 6.35955439065583e-05
step: 930, loss: 0.0001961198722710833
step: 940, loss: 0.00011245142377447337
epoch 14: dev_f1=0.9482517482517483, f1=0.9273584905660377, best_f1=0.9286740067017711
step: 0, loss: 4.4248372432775795e-05
step: 10, loss: 0.001825155457481742
step: 20, loss: 0.00011540567356860265
step: 30, loss: 0.004210410639643669
step: 40, loss: 4.0934672142611817e-05
step: 50, loss: 0.0001709843782009557
step: 60, loss: 0.0001143403715104796
step: 70, loss: 0.00034850623342208564
step: 80, loss: 4.1890485590556636e-05
step: 90, loss: 5.279825927573256e-05
step: 100, loss: 6.57515847706236e-05
step: 110, loss: 0.00016867497470229864
step: 120, loss: 0.00015644806262571365
step: 130, loss: 0.010553721338510513
step: 140, loss: 0.00024372449843212962
step: 150, loss: 0.03666442632675171
step: 160, loss: 0.003196602687239647
step: 170, loss: 0.00012465502368286252
step: 180, loss: 8.37801126181148e-05
step: 190, loss: 0.00018020908464677632
step: 200, loss: 0.0001190539333038032
step: 210, loss: 0.0005934500368312001
step: 220, loss: 5.128237899043597e-05
step: 230, loss: 0.0001946820120792836
step: 240, loss: 0.0006190616404637694
step: 250, loss: 0.0001284107711398974
step: 260, loss: 0.0003717409272212535
step: 270, loss: 0.001048760605044663
step: 280, loss: 8.214323315769434e-05
step: 290, loss: 0.0005964991869404912
step: 300, loss: 0.00018864768208004534
step: 310, loss: 0.00026983709540218115
step: 320, loss: 0.00019160630472470075
step: 330, loss: 0.023553889244794846
step: 340, loss: 0.0005587124032899737
step: 350, loss: 0.001008654828183353
step: 360, loss: 0.0002813372702803463
step: 370, loss: 0.0007254172232933342
step: 380, loss: 0.00047629239270463586
step: 390, loss: 4.7308214561780915e-05
step: 400, loss: 6.621356442337856e-05
step: 410, loss: 0.000728323997464031
step: 420, loss: 0.000291656528133899
step: 430, loss: 0.010673757642507553
step: 440, loss: 0.0019823217298835516
step: 450, loss: 0.01880303956568241
step: 460, loss: 4.6425338950939476e-05
step: 470, loss: 6.007184856571257e-05
step: 480, loss: 0.00017117349489126354
step: 490, loss: 0.00028588075656443834
step: 500, loss: 0.00016468737157993019
step: 510, loss: 0.0007098847418092191
step: 520, loss: 0.00021791258768644184
step: 530, loss: 0.019582880660891533
step: 540, loss: 8.467007137369365e-05
step: 550, loss: 0.00019462729687802494
step: 560, loss: 8.97228455869481e-05
step: 570, loss: 9.833380318013951e-05
step: 580, loss: 0.0009509336086921394
step: 590, loss: 0.002166453981772065
step: 600, loss: 0.00010577812645351514
step: 610, loss: 0.00017607574409339577
step: 620, loss: 5.484323264681734e-05
step: 630, loss: 0.0009542705956846476
step: 640, loss: 0.004943143110722303
step: 650, loss: 0.00277782347984612
step: 660, loss: 0.0002766655816230923
step: 670, loss: 0.004919000435620546
step: 680, loss: 0.06585312634706497
step: 690, loss: 0.0007006236119195819
step: 700, loss: 0.0030382995028048754
step: 710, loss: 7.550157170044258e-05
step: 720, loss: 0.0017615470569580793
step: 730, loss: 0.0004832539416383952
step: 740, loss: 7.095329056028277e-05
step: 750, loss: 0.0012778978561982512
step: 760, loss: 7.079455099301413e-05
step: 770, loss: 0.021779466420412064
step: 780, loss: 0.0006450886721722782
step: 790, loss: 0.0001655665982980281
step: 800, loss: 0.0007176444632932544
step: 810, loss: 0.005583013407886028
step: 820, loss: 0.008689760230481625
step: 830, loss: 0.005960278678685427
step: 840, loss: 0.0001082283488358371
step: 850, loss: 0.00016343437891919166
step: 860, loss: 0.1057468056678772
step: 870, loss: 0.0014156667748466134
step: 880, loss: 0.0007369047380052507
step: 890, loss: 0.00027190716355107725
step: 900, loss: 0.00030899938428774476
step: 910, loss: 0.0006265083211474121
step: 920, loss: 0.00028327369363978505
step: 930, loss: 8.482580597046763e-05
step: 940, loss: 0.04443677142262459
epoch 15: dev_f1=0.9456572224802601, f1=0.928772258669166, best_f1=0.9286740067017711
step: 0, loss: 0.002288241172209382
step: 10, loss: 0.000987756415270269
step: 20, loss: 0.00020360233611427248
step: 30, loss: 0.0002177859569201246
step: 40, loss: 0.007472401484847069
step: 50, loss: 3.982086491305381e-05
step: 60, loss: 9.812181087909266e-05
step: 70, loss: 0.0006386407767422497
step: 80, loss: 0.00013849139213562012
step: 90, loss: 0.004834758583456278
step: 100, loss: 0.0016546902479603887
step: 110, loss: 2.5528679543640465e-05
step: 120, loss: 0.011025817133486271
step: 130, loss: 0.00046762696001678705
step: 140, loss: 0.0002247039956273511
step: 150, loss: 0.00011500575783429667
step: 160, loss: 0.0002389654255239293
step: 170, loss: 4.674800220527686e-05
step: 180, loss: 0.0001663139701122418
step: 190, loss: 0.004762491676956415
step: 200, loss: 0.0026956985238939524
step: 210, loss: 0.0001339828158961609
step: 220, loss: 2.295094782311935e-05
step: 230, loss: 4.166516737313941e-05
step: 240, loss: 0.0266608577221632
step: 250, loss: 0.000418800744228065
step: 260, loss: 0.0023323402274399996
step: 270, loss: 0.0033790525048971176
step: 280, loss: 2.767755722743459e-05
step: 290, loss: 0.00014299542817752808
step: 300, loss: 0.0011232469696551561
step: 310, loss: 0.00018290999287273735
step: 320, loss: 0.0015762608963996172
step: 330, loss: 0.023424042388796806
step: 340, loss: 2.4768634830252267e-05
step: 350, loss: 0.000344040832715109
step: 360, loss: 5.409764708019793e-05
step: 370, loss: 0.00040989453555084765
step: 380, loss: 0.00010188709711655974
step: 390, loss: 0.0004173696506768465
step: 400, loss: 0.0005107006873004138
step: 410, loss: 0.003646292258054018
step: 420, loss: 4.550380981527269e-05
step: 430, loss: 0.003398309228941798
step: 440, loss: 0.016525888815522194
step: 450, loss: 0.00022569313296116889
step: 460, loss: 0.0018198676407337189
step: 470, loss: 0.0021021037828177214
step: 480, loss: 3.8617792597506195e-05
step: 490, loss: 0.000310403062030673
step: 500, loss: 0.0020968122407794
step: 510, loss: 9.441802831133828e-05
step: 520, loss: 0.09751272946596146
step: 530, loss: 3.084396666963585e-05
step: 540, loss: 5.230042734183371e-05
step: 550, loss: 4.914400778943673e-05
step: 560, loss: 0.00023036036873236299
step: 570, loss: 9.864632738754153e-05
step: 580, loss: 0.0005919621326029301
step: 590, loss: 4.073263698955998e-05
step: 600, loss: 6.869896606076509e-05
step: 610, loss: 4.3440279114292935e-05
step: 620, loss: 8.1826132372953e-05
step: 630, loss: 5.415296254795976e-05
step: 640, loss: 0.00011018024088116363
step: 650, loss: 8.472635090583935e-05
step: 660, loss: 0.02525823749601841
step: 670, loss: 0.0026478255167603493
step: 680, loss: 0.00013375734852161258
step: 690, loss: 9.768805466592312e-05
step: 700, loss: 0.0003343973367009312
step: 710, loss: 4.941941369906999e-05
step: 720, loss: 0.000308226648485288
step: 730, loss: 4.2956780816894025e-05
step: 740, loss: 0.0014691129326820374
step: 750, loss: 2.0641262381104752e-05
step: 760, loss: 0.00010302641749149188
step: 770, loss: 5.9996476920787245e-05
step: 780, loss: 0.00044581620022654533
step: 790, loss: 7.014068978605792e-05
step: 800, loss: 5.738455001846887e-05
step: 810, loss: 0.003368649398908019
step: 820, loss: 7.692443614359945e-05
step: 830, loss: 3.1056020816322416e-05
step: 840, loss: 0.00022974390594754368
step: 850, loss: 0.011549471877515316
step: 860, loss: 7.493948214687407e-05
step: 870, loss: 2.434024827380199e-05
step: 880, loss: 0.0006421036669053137
step: 890, loss: 3.285886123194359e-05
step: 900, loss: 0.004562724847346544
step: 910, loss: 2.9342754714889452e-05
step: 920, loss: 0.0005834096227772534
step: 930, loss: 0.026956120505928993
step: 940, loss: 8.801090734777972e-05
epoch 16: dev_f1=0.9431500465983226, f1=0.9195621132793907, best_f1=0.9286740067017711
step: 0, loss: 0.0004013578000012785
step: 10, loss: 0.003024226753041148
step: 20, loss: 0.0008357504266314209
step: 30, loss: 0.0001284051249967888
step: 40, loss: 5.782693187939003e-05
step: 50, loss: 0.0018643088405951858
step: 60, loss: 3.703104448504746e-05
step: 70, loss: 0.00030155235435813665
step: 80, loss: 0.00013368642248678952
step: 90, loss: 0.0012639440828934312
step: 100, loss: 0.002356497570872307
step: 110, loss: 0.00014534081856254488
step: 120, loss: 0.00158524583093822
step: 130, loss: 0.0002307273680344224
step: 140, loss: 3.454636316746473e-05
step: 150, loss: 6.766674050595611e-05
step: 160, loss: 8.763253572396934e-05
step: 170, loss: 3.316070433356799e-05
step: 180, loss: 6.548456440214068e-05
step: 190, loss: 1.9702687495737337e-05
step: 200, loss: 4.156796057941392e-05
step: 210, loss: 3.25905202771537e-05
step: 220, loss: 0.00010110370203619823
step: 230, loss: 7.103081588866189e-05
step: 240, loss: 2.5733368602232076e-05
step: 250, loss: 6.433167436625808e-05
step: 260, loss: 0.00449268938973546
step: 270, loss: 1.9370801965123974e-05
step: 280, loss: 2.2023443307261914e-05
step: 290, loss: 0.002816916676238179
step: 300, loss: 5.7531189668225124e-05
step: 310, loss: 3.869499050779268e-05
step: 320, loss: 0.001156723708845675
step: 330, loss: 0.000189238679013215
step: 340, loss: 1.880070340121165e-05
step: 350, loss: 3.914869739674032e-05
step: 360, loss: 0.0015960922464728355
step: 370, loss: 0.0008473876514472067
step: 380, loss: 0.002265096874907613
step: 390, loss: 4.7155728680081666e-05
step: 400, loss: 0.00016034755390137434
step: 410, loss: 0.00011947787425015122
step: 420, loss: 0.005709801334887743
step: 430, loss: 0.0002007213479373604
step: 440, loss: 4.510826329351403e-05
step: 450, loss: 0.0010028935503214598
step: 460, loss: 0.00029898423235863447
step: 470, loss: 8.98508369573392e-05
step: 480, loss: 7.767694478388876e-05
step: 490, loss: 6.470606604125351e-05
step: 500, loss: 3.235547774238512e-05
step: 510, loss: 0.0018475607503205538
step: 520, loss: 0.028177374973893166
step: 530, loss: 0.0002622034808155149
step: 540, loss: 8.363433880731463e-05
step: 550, loss: 3.968048622482456e-05
step: 560, loss: 0.00014981560525484383
step: 570, loss: 0.00012814500951208174
step: 580, loss: 0.00015145723591558635
step: 590, loss: 0.0003126246156170964
step: 600, loss: 0.0017512546619400382
step: 610, loss: 0.007822210900485516
step: 620, loss: 0.001007979502901435
step: 630, loss: 0.007321867626160383
step: 640, loss: 0.00023468479048460722
step: 650, loss: 3.409037526580505e-05
step: 660, loss: 3.48989233316388e-05
step: 670, loss: 2.6790292395162396e-05
step: 680, loss: 4.497355985222384e-05
step: 690, loss: 3.122916314168833e-05
step: 700, loss: 0.049644097685813904
step: 710, loss: 1.746383532008622e-05
step: 720, loss: 4.5574226533062756e-05
step: 730, loss: 0.0016864037606865168
step: 740, loss: 7.915807509562e-05
step: 750, loss: 4.244011506671086e-05
step: 760, loss: 0.0001100680892704986
step: 770, loss: 5.243098712526262e-05
step: 780, loss: 0.00018870734493248165
step: 790, loss: 0.00019908884132746607
step: 800, loss: 0.10418182611465454
step: 810, loss: 4.834346327697858e-05
step: 820, loss: 0.001410720287822187
step: 830, loss: 0.00026854919269680977
step: 840, loss: 2.9502944016712718e-05
step: 850, loss: 2.8825117624364793e-05
step: 860, loss: 2.470136860210914e-05
step: 870, loss: 0.00011935479415114969
step: 880, loss: 0.0020337605383247137
step: 890, loss: 3.2116611691890284e-05
step: 900, loss: 2.0238889192114584e-05
step: 910, loss: 0.0021126987412571907
step: 920, loss: 6.226604455150664e-05
step: 930, loss: 2.382988532190211e-05
step: 940, loss: 0.00769843440502882
epoch 17: dev_f1=0.9466357308584686, f1=0.9300140911225928, best_f1=0.9286740067017711
step: 0, loss: 0.0008829048601910472
step: 10, loss: 1.718442581477575e-05
step: 20, loss: 2.521086389606353e-05
step: 30, loss: 3.9034330256981775e-05
step: 40, loss: 0.0003789022739510983
step: 50, loss: 6.821711576776579e-05
step: 60, loss: 4.755047120852396e-05
step: 70, loss: 5.213938493398018e-05
step: 80, loss: 0.00020762407802976668
step: 90, loss: 4.845973307965323e-05
step: 100, loss: 3.253514296375215e-05
step: 110, loss: 5.47483068658039e-05
step: 120, loss: 8.551777136744931e-05
step: 130, loss: 2.803091410896741e-05
step: 140, loss: 1.763498039508704e-05
step: 150, loss: 0.017446978017687798
step: 160, loss: 3.212715819245204e-05
step: 170, loss: 0.00013356156705413014
step: 180, loss: 4.7507419367320836e-05
step: 190, loss: 0.000305343623040244
step: 200, loss: 0.0005779463099315763
step: 210, loss: 0.0030308838468044996
step: 220, loss: 0.000370034045772627
step: 230, loss: 1.8465365428710356e-05
step: 240, loss: 4.039985651616007e-05
step: 250, loss: 0.00015916881966404617
step: 260, loss: 2.3069986127666198e-05
step: 270, loss: 0.0001329428341705352
step: 280, loss: 3.6474211810855195e-05
step: 290, loss: 0.00042227539233863354
step: 300, loss: 0.0001695397077128291
step: 310, loss: 0.00012930222146678716
step: 320, loss: 0.0003601874632295221
step: 330, loss: 1.7322303392575122e-05
step: 340, loss: 2.8707621822832152e-05
step: 350, loss: 0.0003773253702092916
step: 360, loss: 0.08554940670728683
step: 370, loss: 2.1930190996499732e-05
step: 380, loss: 0.002246567513793707
step: 390, loss: 2.4853949071257375e-05
step: 400, loss: 0.0033636658918112516
step: 410, loss: 0.06947730481624603
step: 420, loss: 0.00015742229879833758
step: 430, loss: 4.882127541350201e-05
step: 440, loss: 5.140126813785173e-05
step: 450, loss: 9.176485036732629e-05
step: 460, loss: 4.4024938688380644e-05
step: 470, loss: 2.988150663441047e-05
step: 480, loss: 0.00021704028767999262
step: 490, loss: 7.94312873040326e-05
step: 500, loss: 7.37302252673544e-05
step: 510, loss: 6.617298640776426e-05
step: 520, loss: 2.401248275418766e-05
step: 530, loss: 3.154703153995797e-05
step: 540, loss: 0.03368446230888367
step: 550, loss: 5.574628448812291e-05
step: 560, loss: 0.00028494757134467363
step: 570, loss: 7.446719246217981e-05
step: 580, loss: 3.265773557359353e-05
step: 590, loss: 0.00011620602890616283
step: 600, loss: 0.00010309380741091445
step: 610, loss: 0.00015763375267852098
step: 620, loss: 3.2462710805702955e-05
step: 630, loss: 0.0002240506000816822
step: 640, loss: 4.789305603480898e-05
step: 650, loss: 4.0805516619002447e-05
step: 660, loss: 0.0022669206373393536
step: 670, loss: 0.000378910219296813
step: 680, loss: 3.989636024925858e-05
step: 690, loss: 5.218157821218483e-05
step: 700, loss: 0.006623455788940191
step: 710, loss: 0.007390936370939016
step: 720, loss: 0.00018806170555762947
step: 730, loss: 9.48836313909851e-05
step: 740, loss: 1.4673726582259405e-05
step: 750, loss: 3.052584725082852e-05
step: 760, loss: 0.00012919609434902668
step: 770, loss: 0.001648054108954966
step: 780, loss: 0.00018375700165051967
step: 790, loss: 2.3743934434605762e-05
step: 800, loss: 0.0003421057481318712
step: 810, loss: 2.501783637853805e-05
step: 820, loss: 1.57799877342768e-05
step: 830, loss: 0.00036163226468488574
step: 840, loss: 0.0051336754113435745
step: 850, loss: 1.4703444321639836e-05
step: 860, loss: 2.112116817443166e-05
step: 870, loss: 2.8137979825260118e-05
step: 880, loss: 5.0710114010144025e-05
step: 890, loss: 0.00020069767197128385
step: 900, loss: 0.00018087997159454972
step: 910, loss: 2.8123713491368107e-05
step: 920, loss: 0.1306627243757248
step: 930, loss: 0.00012481540034059435
step: 940, loss: 8.780778443906456e-05
epoch 18: dev_f1=0.9465861588481189, f1=0.9267139479905439, best_f1=0.9286740067017711
step: 0, loss: 3.1869207305135205e-05
step: 10, loss: 0.00013077167386654764
step: 20, loss: 1.997051549551543e-05
step: 30, loss: 0.00011576005636015907
step: 40, loss: 0.0009100392344407737
step: 50, loss: 0.00010241808195132762
step: 60, loss: 0.00019003060879185796
step: 70, loss: 0.0015338819939643145
step: 80, loss: 7.104953692760319e-05
step: 90, loss: 7.467775867553428e-05
step: 100, loss: 0.000549174437765032
step: 110, loss: 4.98659755976405e-05
step: 120, loss: 2.4232338546426035e-05
step: 130, loss: 3.542452395777218e-05
step: 140, loss: 0.0005749920383095741
step: 150, loss: 0.00040029597585089505
step: 160, loss: 2.5542982257320546e-05
step: 170, loss: 0.004186257719993591
step: 180, loss: 4.003396679763682e-05
step: 190, loss: 3.604752419050783e-05
step: 200, loss: 0.0004900161293335259
step: 210, loss: 0.00017457288049627095
step: 220, loss: 0.0002101594436680898
step: 230, loss: 0.00010177959484281018
step: 240, loss: 1.4494863535219338e-05
step: 250, loss: 0.01738765835762024
step: 260, loss: 1.224857805937063e-05
step: 270, loss: 0.00014971250493545085
step: 280, loss: 4.582216206472367e-05
step: 290, loss: 0.00047464529052376747
step: 300, loss: 2.2260830519371666e-05
step: 310, loss: 0.019692324101924896
step: 320, loss: 6.950621900614351e-05
step: 330, loss: 1.7843718524090946e-05
step: 340, loss: 6.620067870244384e-05
step: 350, loss: 7.493183511542156e-05
step: 360, loss: 5.111005884828046e-05
step: 370, loss: 4.043976150569506e-05
step: 380, loss: 1.873013206932228e-05
step: 390, loss: 3.076235589105636e-05
step: 400, loss: 1.4390557225851808e-05
step: 410, loss: 8.815034379949793e-05
step: 420, loss: 1.1056530638597906e-05
step: 430, loss: 8.434638584731147e-05
step: 440, loss: 0.0017926163272932172
step: 450, loss: 0.00014755887968931347
step: 460, loss: 7.361733878497034e-05
step: 470, loss: 3.083184128627181e-05
step: 480, loss: 0.00047909998102113605
step: 490, loss: 2.7927118935622275e-05
step: 500, loss: 7.861080666771159e-05
step: 510, loss: 5.591303852270357e-05
step: 520, loss: 2.5941786589100957e-05
step: 530, loss: 1.533295289846137e-05
step: 540, loss: 0.0001575949281686917
step: 550, loss: 7.254783122334629e-05
step: 560, loss: 1.1209282092750072e-05
step: 570, loss: 0.0008685764623805881
step: 580, loss: 2.3613409211975522e-05
step: 590, loss: 0.00010738596029113978
step: 600, loss: 0.0006160605698823929
step: 610, loss: 3.5998880775878206e-05
step: 620, loss: 0.00016367888019885868
step: 630, loss: 0.0018370846519246697
step: 640, loss: 0.0018485990585759282
step: 650, loss: 3.214948083041236e-05
step: 660, loss: 5.062162017566152e-05
step: 670, loss: 2.173581196984742e-05
step: 680, loss: 0.00048831821186468
step: 690, loss: 8.135605457937345e-05
step: 700, loss: 1.4710964933328796e-05
step: 710, loss: 0.00010833813576027751
step: 720, loss: 5.849362787557766e-05
step: 730, loss: 0.00010711338109103963
step: 740, loss: 0.012566733174026012
step: 750, loss: 8.741386409383267e-05
step: 760, loss: 1.7936832591658458e-05
step: 770, loss: 0.046648912131786346
step: 780, loss: 1.7039104932337068e-05
step: 790, loss: 0.0021968595683574677
step: 800, loss: 7.710189674980938e-05
step: 810, loss: 1.729977702780161e-05
step: 820, loss: 1.0684023436624557e-05
step: 830, loss: 6.95437629474327e-05
step: 840, loss: 0.0013130061561241746
step: 850, loss: 0.0004932025913149118
step: 860, loss: 4.583417103276588e-05
step: 870, loss: 3.888938590534963e-05
step: 880, loss: 2.687626147235278e-05
step: 890, loss: 1.1782924957515206e-05
step: 900, loss: 3.2150484912563115e-05
step: 910, loss: 4.8314952437067404e-05
step: 920, loss: 1.6606602002866566e-05
step: 930, loss: 9.063556717592292e-06
step: 940, loss: 5.4547253967029974e-05
epoch 19: dev_f1=0.9481481481481482, f1=0.9318394024276377, best_f1=0.9286740067017711
step: 0, loss: 1.8506023479858413e-05
step: 10, loss: 6.547521479660645e-05
step: 20, loss: 0.00025727771571837366
step: 30, loss: 5.582613812293857e-05
step: 40, loss: 2.179126204282511e-05
step: 50, loss: 0.0008167448686435819
step: 60, loss: 0.0005203519249334931
step: 70, loss: 0.0004136255010962486
step: 80, loss: 1.827560663514305e-05
step: 90, loss: 7.021107012405992e-05
step: 100, loss: 0.000527098891325295
step: 110, loss: 1.3786910130875185e-05
step: 120, loss: 5.643311669700779e-05
step: 130, loss: 1.4841314623481594e-05
step: 140, loss: 0.00015370607434306294
step: 150, loss: 1.9463563148747198e-05
step: 160, loss: 0.0017843313980847597
step: 170, loss: 4.4048014387954026e-05
step: 180, loss: 4.6636854676762596e-05
step: 190, loss: 1.95423599507194e-05
step: 200, loss: 2.7930211217608303e-05
step: 210, loss: 2.3442085876013152e-05
step: 220, loss: 2.9608992917928845e-05
step: 230, loss: 0.00010977708734571934
step: 240, loss: 0.0014204378239810467
step: 250, loss: 0.0024869877379387617
step: 260, loss: 5.615254121948965e-05
step: 270, loss: 1.6535983377252705e-05
step: 280, loss: 0.00012035421241307631
step: 290, loss: 0.000552862009499222
step: 300, loss: 0.0004996014176867902
step: 310, loss: 0.0006467138882726431
step: 320, loss: 0.0006700956146232784
step: 330, loss: 0.00028001872124150395
step: 340, loss: 0.00047909034765325487
step: 350, loss: 0.00017485834541730583
step: 360, loss: 9.583546489011496e-05
step: 370, loss: 0.00014902319526299834
step: 380, loss: 2.215695167251397e-05
step: 390, loss: 0.04164567217230797
step: 400, loss: 2.810328260238748e-05
step: 410, loss: 2.0775371012859978e-05
step: 420, loss: 2.870198295568116e-05
step: 430, loss: 1.1261407053098083e-05
step: 440, loss: 3.411385841900483e-05
step: 450, loss: 0.00019637768855318427
step: 460, loss: 3.1651990866521373e-05
step: 470, loss: 3.822042344836518e-05
step: 480, loss: 0.00010947972623398528
step: 490, loss: 0.011003546416759491
step: 500, loss: 0.00013184742419980466
step: 510, loss: 3.7672638427466154e-05
step: 520, loss: 0.0014829215360805392
step: 530, loss: 1.9448982129688375e-05
step: 540, loss: 0.02402534708380699
step: 550, loss: 0.0010024051880463958
step: 560, loss: 0.0002659565070644021
step: 570, loss: 3.4061173209920526e-05
step: 580, loss: 6.975048017920926e-05
step: 590, loss: 5.4242009355220944e-05
step: 600, loss: 1.8782468032441102e-05
step: 610, loss: 0.00015880145656410605
step: 620, loss: 1.8837939933291636e-05
step: 630, loss: 0.0009763603447936475
step: 640, loss: 0.027289709076285362
step: 650, loss: 0.043322835117578506
step: 660, loss: 0.00010140037193195894
step: 670, loss: 0.0035199851263314486
step: 680, loss: 2.3151509594754316e-05
step: 690, loss: 0.01786107011139393
step: 700, loss: 1.544465521874372e-05
step: 710, loss: 3.4835131373256445e-05
step: 720, loss: 1.3805723028781358e-05
step: 730, loss: 1.9408274965826422e-05
step: 740, loss: 1.4617780834669247e-05
step: 750, loss: 5.3837604355067015e-05
step: 760, loss: 3.1461575417779386e-05
step: 770, loss: 2.033201963058673e-05
step: 780, loss: 1.883824006654322e-05
step: 790, loss: 2.2272686692303978e-05
step: 800, loss: 0.00012023264571325853
step: 810, loss: 2.569232674431987e-05
step: 820, loss: 1.3999449038237799e-05
step: 830, loss: 0.0001174620701931417
step: 840, loss: 0.0002439843228785321
step: 850, loss: 0.00010451981506776065
step: 860, loss: 2.057415622402914e-05
step: 870, loss: 2.049978866125457e-05
step: 880, loss: 2.4250779460999183e-05
step: 890, loss: 0.0289040207862854
step: 900, loss: 2.648578811204061e-05
step: 910, loss: 0.0007355076377280056
step: 920, loss: 2.1411780835478567e-05
step: 930, loss: 3.856752664432861e-05
step: 940, loss: 3.340162948006764e-05
epoch 20: dev_f1=0.9485396383866481, f1=0.9308885754583921, best_f1=0.9286740067017711
