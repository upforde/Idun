cuda
Device: cuda
step: 0, loss: 0.6283910870552063
step: 10, loss: 0.47809821367263794
step: 20, loss: 0.448103666305542
step: 30, loss: 0.5193940997123718
step: 40, loss: 0.493641197681427
step: 50, loss: 0.4259547293186188
step: 60, loss: 0.15296895802021027
step: 70, loss: 0.35094255208969116
step: 80, loss: 0.311167448759079
step: 90, loss: 0.3463576138019562
step: 100, loss: 0.22457891702651978
step: 110, loss: 0.26803308725357056
step: 120, loss: 0.5438537001609802
step: 130, loss: 0.2986871600151062
step: 140, loss: 0.2585522532463074
step: 150, loss: 0.20203490555286407
step: 160, loss: 0.12745492160320282
step: 170, loss: 0.3047301471233368
step: 180, loss: 0.3646409511566162
step: 190, loss: 0.10008398443460464
step: 200, loss: 0.2853153944015503
step: 210, loss: 0.21955841779708862
step: 220, loss: 0.3253520429134369
step: 230, loss: 0.35674506425857544
step: 240, loss: 0.29150643944740295
step: 250, loss: 0.20138806104660034
step: 260, loss: 0.42966681718826294
step: 270, loss: 0.13429045677185059
step: 280, loss: 0.16503994166851044
step: 290, loss: 0.22667503356933594
step: 300, loss: 0.23238272964954376
step: 310, loss: 0.24911749362945557
step: 320, loss: 0.30900344252586365
step: 330, loss: 0.2169797718524933
step: 340, loss: 0.1281604915857315
step: 350, loss: 0.5741004347801208
step: 360, loss: 0.32267770171165466
step: 370, loss: 0.17690661549568176
step: 380, loss: 0.283588707447052
step: 390, loss: 0.08722005039453506
step: 400, loss: 0.07087409496307373
step: 410, loss: 0.2679118514060974
step: 420, loss: 0.1754380613565445
step: 430, loss: 0.10912324488162994
step: 440, loss: 0.3311533033847809
step: 450, loss: 0.38734936714172363
step: 460, loss: 0.28635525703430176
step: 470, loss: 0.35720282793045044
step: 480, loss: 0.40249747037887573
step: 490, loss: 0.24226921796798706
step: 500, loss: 0.13915961980819702
step: 510, loss: 0.1400502771139145
step: 520, loss: 0.22271732985973358
step: 530, loss: 0.4328382909297943
step: 540, loss: 0.5936028361320496
step: 550, loss: 0.4464491903781891
step: 560, loss: 0.24740469455718994
step: 570, loss: 0.23223452270030975
step: 580, loss: 0.4990803599357605
step: 590, loss: 0.07794265449047089
step: 600, loss: 0.13539524376392365
step: 610, loss: 0.4597320556640625
step: 620, loss: 0.44709932804107666
step: 630, loss: 0.21356244385242462
step: 640, loss: 0.3032878339290619
step: 650, loss: 0.1605631709098816
step: 660, loss: 0.2833900451660156
step: 670, loss: 0.14725559949874878
step: 680, loss: 0.13115619122982025
step: 690, loss: 0.19028520584106445
step: 700, loss: 0.16857486963272095
step: 710, loss: 0.19747936725616455
step: 720, loss: 0.2611216604709625
step: 730, loss: 0.25121021270751953
step: 740, loss: 0.12159321457147598
step: 750, loss: 0.3533514440059662
step: 760, loss: 0.25417736172676086
step: 770, loss: 0.21835651993751526
step: 780, loss: 0.32456815242767334
step: 790, loss: 0.19153481721878052
step: 800, loss: 0.1982126533985138
step: 810, loss: 0.21434415876865387
step: 820, loss: 0.15943080186843872
step: 830, loss: 0.08718391507863998
step: 840, loss: 0.2042894810438156
step: 850, loss: 0.1539345234632492
step: 860, loss: 0.20388031005859375
step: 870, loss: 0.2173394411802292
step: 880, loss: 0.2379232496023178
step: 890, loss: 0.1318543553352356
step: 900, loss: 0.1748557835817337
step: 910, loss: 0.17008614540100098
step: 920, loss: 0.27960705757141113
step: 930, loss: 0.32668831944465637
step: 940, loss: 0.2231282740831375
step: 950, loss: 0.24616560339927673
step: 960, loss: 0.11059246212244034
step: 970, loss: 0.25928908586502075
step: 980, loss: 0.2168843150138855
step: 990, loss: 0.18621937930583954
step: 1000, loss: 0.04455593600869179
step: 1010, loss: 0.29842641949653625
step: 1020, loss: 0.20954585075378418
step: 1030, loss: 0.05781949684023857
epoch 1: dev_f1=0.9317865429234339, f1=0.9189695550351288, best_f1=0.9189695550351288
step: 0, loss: 0.10466503351926804
step: 10, loss: 0.16697481274604797
step: 20, loss: 0.3711487948894501
step: 30, loss: 0.18303655087947845
step: 40, loss: 0.10151314735412598
step: 50, loss: 0.24829131364822388
step: 60, loss: 0.13562551140785217
step: 70, loss: 0.2284490466117859
step: 80, loss: 0.28824740648269653
step: 90, loss: 0.25397980213165283
step: 100, loss: 0.1569569706916809
step: 110, loss: 0.16013213992118835
step: 120, loss: 0.15035291016101837
step: 130, loss: 0.3084121644496918
step: 140, loss: 0.13149625062942505
step: 150, loss: 0.08747991174459457
step: 160, loss: 0.238312229514122
step: 170, loss: 0.08521884679794312
step: 180, loss: 0.39474552869796753
step: 190, loss: 0.11516296863555908
step: 200, loss: 0.34652191400527954
step: 210, loss: 0.243250772356987
step: 220, loss: 0.15671288967132568
step: 230, loss: 0.6435267925262451
step: 240, loss: 0.11344598233699799
step: 250, loss: 0.10653166472911835
step: 260, loss: 0.21419453620910645
step: 270, loss: 0.3705832362174988
step: 280, loss: 0.055360160768032074
step: 290, loss: 0.22979213297367096
step: 300, loss: 0.33241695165634155
step: 310, loss: 0.24475474655628204
step: 320, loss: 0.2622219920158386
step: 330, loss: 0.28486940264701843
step: 340, loss: 0.17854730784893036
step: 350, loss: 0.10727687180042267
step: 360, loss: 0.15031684935092926
step: 370, loss: 0.17170941829681396
step: 380, loss: 0.1140766516327858
step: 390, loss: 0.2227790504693985
step: 400, loss: 0.07267610728740692
step: 410, loss: 0.1932939738035202
step: 420, loss: 0.08065776526927948
step: 430, loss: 0.11617965251207352
step: 440, loss: 0.1577480584383011
step: 450, loss: 0.040586479008197784
step: 460, loss: 0.10590200126171112
step: 470, loss: 0.3444811999797821
step: 480, loss: 0.17480477690696716
step: 490, loss: 0.07640506327152252
step: 500, loss: 0.07910498976707458
step: 510, loss: 0.15842115879058838
step: 520, loss: 0.12559567391872406
step: 530, loss: 0.2638659179210663
step: 540, loss: 0.0749155730009079
step: 550, loss: 0.3101986348628998
step: 560, loss: 0.1902495175600052
step: 570, loss: 0.025002820417284966
step: 580, loss: 0.03770893067121506
step: 590, loss: 0.16534025967121124
step: 600, loss: 0.17945705354213715
step: 610, loss: 0.1429891586303711
step: 620, loss: 0.04261498525738716
step: 630, loss: 0.17747189104557037
step: 640, loss: 0.10417523980140686
step: 650, loss: 0.055721133947372437
step: 660, loss: 0.37591060996055603
step: 670, loss: 0.12282910197973251
step: 680, loss: 0.09225012362003326
step: 690, loss: 0.32216373085975647
step: 700, loss: 0.037976767867803574
step: 710, loss: 0.23457975685596466
step: 720, loss: 0.16345849633216858
step: 730, loss: 0.27821964025497437
step: 740, loss: 0.21025685966014862
step: 750, loss: 0.19923442602157593
step: 760, loss: 0.20236562192440033
step: 770, loss: 0.07910383492708206
step: 780, loss: 0.32508164644241333
step: 790, loss: 0.2396613210439682
step: 800, loss: 0.3128403425216675
step: 810, loss: 0.12885619699954987
step: 820, loss: 0.04365655779838562
step: 830, loss: 0.09396019577980042
step: 840, loss: 0.1021159365773201
step: 850, loss: 0.1556575745344162
step: 860, loss: 0.1585502326488495
step: 870, loss: 0.10300757735967636
step: 880, loss: 0.06769448518753052
step: 890, loss: 0.06082262471318245
step: 900, loss: 0.15576399862766266
step: 910, loss: 0.0764564797282219
step: 920, loss: 0.04399561136960983
step: 930, loss: 0.2959786653518677
step: 940, loss: 0.1081271544098854
step: 950, loss: 0.090920090675354
step: 960, loss: 0.060344547033309937
step: 970, loss: 0.0958065539598465
step: 980, loss: 0.14558546245098114
step: 990, loss: 0.09293323010206223
step: 1000, loss: 0.15743348002433777
step: 1010, loss: 0.07197414338588715
step: 1020, loss: 0.10495951771736145
step: 1030, loss: 0.01800779066979885
epoch 2: dev_f1=0.9436749769159741, f1=0.9294990723562152, best_f1=0.9294990723562152
step: 0, loss: 0.06241398677229881
step: 10, loss: 0.05888143926858902
step: 20, loss: 0.16812026500701904
step: 30, loss: 0.01542351208627224
step: 40, loss: 0.04050925746560097
step: 50, loss: 0.12604950368404388
step: 60, loss: 0.018903039395809174
step: 70, loss: 0.26416245102882385
step: 80, loss: 0.02919940836727619
step: 90, loss: 0.0746222510933876
step: 100, loss: 0.1522056609392166
step: 110, loss: 0.09433279931545258
step: 120, loss: 0.021309377625584602
step: 130, loss: 0.20109105110168457
step: 140, loss: 0.046281278133392334
step: 150, loss: 0.09084469079971313
step: 160, loss: 0.13678887486457825
step: 170, loss: 0.14101439714431763
step: 180, loss: 0.07470627874135971
step: 190, loss: 0.17670617997646332
step: 200, loss: 0.14831587672233582
step: 210, loss: 0.1238698810338974
step: 220, loss: 0.0959012433886528
step: 230, loss: 0.00392525689676404
step: 240, loss: 0.10862405598163605
step: 250, loss: 0.08124972879886627
step: 260, loss: 0.03409774601459503
step: 270, loss: 0.025336576625704765
step: 280, loss: 0.08141301572322845
step: 290, loss: 0.14548908174037933
step: 300, loss: 0.07929489761590958
step: 310, loss: 0.03921930491924286
step: 320, loss: 0.014406394213438034
step: 330, loss: 0.16348052024841309
step: 340, loss: 0.12887032330036163
step: 350, loss: 0.08797091245651245
step: 360, loss: 0.2407098412513733
step: 370, loss: 0.1059725433588028
step: 380, loss: 0.2083483636379242
step: 390, loss: 0.0813673734664917
step: 400, loss: 0.032374873757362366
step: 410, loss: 0.6121970415115356
step: 420, loss: 0.25827768445014954
step: 430, loss: 0.061622072011232376
step: 440, loss: 0.2001657485961914
step: 450, loss: 0.07092529535293579
step: 460, loss: 0.07205728441476822
step: 470, loss: 0.127330482006073
step: 480, loss: 0.023997746407985687
step: 490, loss: 0.09591381996870041
step: 500, loss: 0.09297890961170197
step: 510, loss: 0.11524125188589096
step: 520, loss: 0.27529215812683105
step: 530, loss: 0.19867372512817383
step: 540, loss: 0.06479625403881073
step: 550, loss: 0.0722464993596077
step: 560, loss: 0.11730291694402695
step: 570, loss: 0.19326481223106384
step: 580, loss: 0.05928383767604828
step: 590, loss: 0.12692804634571075
step: 600, loss: 0.14272814989089966
step: 610, loss: 0.13880930840969086
step: 620, loss: 0.11350641399621964
step: 630, loss: 0.187457874417305
step: 640, loss: 0.12045884132385254
step: 650, loss: 0.050567276775836945
step: 660, loss: 0.04812805727124214
step: 670, loss: 0.09983997046947479
step: 680, loss: 0.09209815412759781
step: 690, loss: 0.08233273774385452
step: 700, loss: 0.07298625260591507
step: 710, loss: 0.11281023919582367
step: 720, loss: 0.2972780168056488
step: 730, loss: 0.12424534559249878
step: 740, loss: 0.08291548490524292
step: 750, loss: 0.15748608112335205
step: 760, loss: 0.282402902841568
step: 770, loss: 0.09394039213657379
step: 780, loss: 0.047081511467695236
step: 790, loss: 0.24342331290245056
step: 800, loss: 0.25610196590423584
step: 810, loss: 0.05370895564556122
step: 820, loss: 0.1656065136194229
step: 830, loss: 0.16266119480133057
step: 840, loss: 0.17441953718662262
step: 850, loss: 0.10800918936729431
step: 860, loss: 0.04483368247747421
step: 870, loss: 0.04210878908634186
step: 880, loss: 0.014549839310348034
step: 890, loss: 0.025693709030747414
step: 900, loss: 0.0444987528026104
step: 910, loss: 0.06477601081132889
step: 920, loss: 0.34080249071121216
step: 930, loss: 0.08864292502403259
step: 940, loss: 0.2211831510066986
step: 950, loss: 0.13225671648979187
step: 960, loss: 0.12552067637443542
step: 970, loss: 0.13022153079509735
step: 980, loss: 0.13859905302524567
step: 990, loss: 0.1397007405757904
step: 1000, loss: 0.034012164920568466
step: 1010, loss: 0.12216952443122864
step: 1020, loss: 0.058193691074848175
step: 1030, loss: 0.02919326350092888
epoch 3: dev_f1=0.9492619926199262, f1=0.9302325581395349, best_f1=0.9302325581395349
step: 0, loss: 0.021147606894373894
step: 10, loss: 0.03585866466164589
step: 20, loss: 0.04004392400383949
step: 30, loss: 0.108770951628685
step: 40, loss: 0.1114969253540039
step: 50, loss: 0.014127048663794994
step: 60, loss: 0.1819092333316803
step: 70, loss: 0.008149276487529278
step: 80, loss: 0.014627184718847275
step: 90, loss: 0.015917688608169556
step: 100, loss: 0.006881870795041323
step: 110, loss: 0.00993954949080944
step: 120, loss: 0.012189280241727829
step: 130, loss: 0.3859105110168457
step: 140, loss: 0.12969809770584106
step: 150, loss: 0.040435828268527985
step: 160, loss: 0.01384049840271473
step: 170, loss: 0.2670822739601135
step: 180, loss: 0.05730985477566719
step: 190, loss: 0.010245486162602901
step: 200, loss: 0.13510389626026154
step: 210, loss: 0.4777485132217407
step: 220, loss: 0.03863653540611267
step: 230, loss: 0.0955769345164299
step: 240, loss: 0.027953844517469406
step: 250, loss: 0.10032086819410324
step: 260, loss: 0.06654921919107437
step: 270, loss: 0.07218128442764282
step: 280, loss: 0.041125234216451645
step: 290, loss: 0.1596091389656067
step: 300, loss: 0.11715871095657349
step: 310, loss: 0.046033911406993866
step: 320, loss: 0.2666989266872406
step: 330, loss: 0.01625674031674862
step: 340, loss: 0.028425250202417374
step: 350, loss: 0.03888990730047226
step: 360, loss: 0.06774097681045532
step: 370, loss: 0.014355364255607128
step: 380, loss: 0.06474959850311279
step: 390, loss: 0.06795172393321991
step: 400, loss: 0.094483382999897
step: 410, loss: 0.03323066234588623
step: 420, loss: 0.07528046518564224
step: 430, loss: 0.07526802271604538
step: 440, loss: 0.0636729970574379
step: 450, loss: 0.013745736330747604
step: 460, loss: 0.058281946927309036
step: 470, loss: 0.06885689496994019
step: 480, loss: 0.10745476931333542
step: 490, loss: 0.12013570219278336
step: 500, loss: 0.19319213926792145
step: 510, loss: 0.037907082587480545
step: 520, loss: 0.015113139525055885
step: 530, loss: 0.013820643536746502
step: 540, loss: 0.020293226465582848
step: 550, loss: 0.11997795850038528
step: 560, loss: 0.030362077057361603
step: 570, loss: 0.08792714029550552
step: 580, loss: 0.029781265184283257
step: 590, loss: 0.16044162213802338
step: 600, loss: 0.1047164723277092
step: 610, loss: 0.07460484653711319
step: 620, loss: 0.02808375656604767
step: 630, loss: 0.031501077115535736
step: 640, loss: 0.04786445572972298
step: 650, loss: 0.015537084080278873
step: 660, loss: 0.051777228713035583
step: 670, loss: 0.19947567582130432
step: 680, loss: 0.0909908190369606
step: 690, loss: 0.0682574138045311
step: 700, loss: 0.04053221270442009
step: 710, loss: 0.018505899235606194
step: 720, loss: 0.13957762718200684
step: 730, loss: 0.029688134789466858
step: 740, loss: 0.033286746591329575
step: 750, loss: 0.043980684131383896
step: 760, loss: 0.1332104355096817
step: 770, loss: 0.07176174968481064
step: 780, loss: 0.0752532035112381
step: 790, loss: 0.14342838525772095
step: 800, loss: 0.017882857471704483
step: 810, loss: 0.10229003429412842
step: 820, loss: 0.16871285438537598
step: 830, loss: 0.07149966806173325
step: 840, loss: 0.14497356116771698
step: 850, loss: 0.16872602701187134
step: 860, loss: 0.03466098755598068
step: 870, loss: 0.08769046515226364
step: 880, loss: 0.08857779949903488
step: 890, loss: 0.10871788114309311
step: 900, loss: 0.02676495909690857
step: 910, loss: 0.01963033527135849
step: 920, loss: 0.06559144705533981
step: 930, loss: 0.13599111139774323
step: 940, loss: 0.02871612459421158
step: 950, loss: 0.13128410279750824
step: 960, loss: 0.06236906349658966
step: 970, loss: 0.10739292204380035
step: 980, loss: 0.0534185990691185
step: 990, loss: 0.0225021131336689
step: 1000, loss: 0.1309598833322525
step: 1010, loss: 0.05129022151231766
step: 1020, loss: 0.08295629173517227
step: 1030, loss: 0.007813431322574615
epoch 4: dev_f1=0.9501600365797896, f1=0.9276830953477659, best_f1=0.9276830953477659
step: 0, loss: 0.25792068243026733
step: 10, loss: 0.14616410434246063
step: 20, loss: 0.02494383417069912
step: 30, loss: 0.07146982103586197
step: 40, loss: 0.024655554443597794
step: 50, loss: 0.008142119273543358
step: 60, loss: 0.017175257205963135
step: 70, loss: 0.01545658241957426
step: 80, loss: 0.003986491821706295
step: 90, loss: 0.1736089587211609
step: 100, loss: 0.0455888994038105
step: 110, loss: 0.024741850793361664
step: 120, loss: 0.013630415312945843
step: 130, loss: 0.09931798279285431
step: 140, loss: 0.019810006022453308
step: 150, loss: 0.12583798170089722
step: 160, loss: 0.005304817575961351
step: 170, loss: 0.011824616231024265
step: 180, loss: 0.018396586179733276
step: 190, loss: 0.015149232931435108
step: 200, loss: 0.030644221231341362
step: 210, loss: 0.16725070774555206
step: 220, loss: 0.014049870893359184
step: 230, loss: 0.05716726556420326
step: 240, loss: 0.0537642166018486
step: 250, loss: 0.2411104440689087
step: 260, loss: 0.09940140694379807
step: 270, loss: 0.06373012065887451
step: 280, loss: 0.011679107323288918
step: 290, loss: 0.0003959932364523411
step: 300, loss: 0.06429296731948853
step: 310, loss: 0.10395976901054382
step: 320, loss: 0.10521435737609863
step: 330, loss: 0.015864362940192223
step: 340, loss: 0.01069880835711956
step: 350, loss: 0.024664267897605896
step: 360, loss: 0.05203970521688461
step: 370, loss: 0.1304931938648224
step: 380, loss: 0.025446085259318352
step: 390, loss: 0.10401345044374466
step: 400, loss: 0.049317970871925354
step: 410, loss: 0.10347892343997955
step: 420, loss: 0.044160228222608566
step: 430, loss: 0.041111987084150314
step: 440, loss: 0.029230039566755295
step: 450, loss: 0.005765207577496767
step: 460, loss: 0.009207803755998611
step: 470, loss: 0.060707129538059235
step: 480, loss: 0.06694159656763077
step: 490, loss: 0.09792830795049667
step: 500, loss: 0.060555364936590195
step: 510, loss: 0.07786691188812256
step: 520, loss: 0.06432382017374039
step: 530, loss: 0.15645217895507812
step: 540, loss: 0.057579733431339264
step: 550, loss: 0.15910783410072327
step: 560, loss: 0.10244280099868774
step: 570, loss: 0.011640159413218498
step: 580, loss: 0.053552038967609406
step: 590, loss: 0.016777388751506805
step: 600, loss: 0.058443911373615265
step: 610, loss: 0.1278306096792221
step: 620, loss: 0.016058437526226044
step: 630, loss: 0.007032346446067095
step: 640, loss: 0.011472946964204311
step: 650, loss: 0.004903954919427633
step: 660, loss: 0.11332495510578156
step: 670, loss: 0.024518197402358055
step: 680, loss: 0.04693836346268654
step: 690, loss: 0.07772411406040192
step: 700, loss: 0.017478235065937042
step: 710, loss: 0.005153998266905546
step: 720, loss: 0.009115761145949364
step: 730, loss: 0.10138903558254242
step: 740, loss: 0.07421105355024338
step: 750, loss: 0.012918718159198761
step: 760, loss: 0.0931745171546936
step: 770, loss: 0.006855314131826162
step: 780, loss: 0.00523503590375185
step: 790, loss: 0.05909407138824463
step: 800, loss: 0.02470487542450428
step: 810, loss: 0.006669539958238602
step: 820, loss: 0.016968872398138046
step: 830, loss: 0.021811682730913162
step: 840, loss: 0.023818327113986015
step: 850, loss: 0.07846620678901672
step: 860, loss: 0.04654106870293617
step: 870, loss: 0.054570697247982025
step: 880, loss: 0.08829452842473984
step: 890, loss: 0.050799041986465454
step: 900, loss: 0.08864110708236694
step: 910, loss: 0.10313370823860168
step: 920, loss: 0.005706334952265024
step: 930, loss: 0.020125823095440865
step: 940, loss: 0.015874149277806282
step: 950, loss: 0.008892225101590157
step: 960, loss: 0.0028716442175209522
step: 970, loss: 0.0013463057111948729
step: 980, loss: 0.06151442229747772
step: 990, loss: 0.09173698723316193
step: 1000, loss: 0.06660377979278564
step: 1010, loss: 0.06931696832180023
step: 1020, loss: 0.020956136286258698
step: 1030, loss: 0.09269240498542786
epoch 5: dev_f1=0.9509848831882729, f1=0.9220055710306406, best_f1=0.9220055710306406
step: 0, loss: 0.005254899151623249
step: 10, loss: 0.05709613859653473
step: 20, loss: 0.008746691048145294
step: 30, loss: 0.028399664908647537
step: 40, loss: 0.003551565110683441
step: 50, loss: 0.008029047399759293
step: 60, loss: 0.0869300365447998
step: 70, loss: 0.034415923058986664
step: 80, loss: 0.019015228375792503
step: 90, loss: 0.09677501022815704
step: 100, loss: 0.011442105285823345
step: 110, loss: 0.005465796682983637
step: 120, loss: 0.06518664211034775
step: 130, loss: 0.00566188246011734
step: 140, loss: 0.0600946806371212
step: 150, loss: 0.00699499761685729
step: 160, loss: 0.27293410897254944
step: 170, loss: 0.032614149153232574
step: 180, loss: 0.020263025537133217
step: 190, loss: 0.013969197869300842
step: 200, loss: 0.08295151591300964
step: 210, loss: 0.008189215324819088
step: 220, loss: 0.008638517931103706
step: 230, loss: 0.004284861963242292
step: 240, loss: 0.021692143753170967
step: 250, loss: 0.03574084863066673
step: 260, loss: 0.005341080483049154
step: 270, loss: 0.05903489142656326
step: 280, loss: 0.022566311061382294
step: 290, loss: 0.03997819125652313
step: 300, loss: 0.040342435240745544
step: 310, loss: 0.05212054029107094
step: 320, loss: 0.002481549046933651
step: 330, loss: 0.011944540776312351
step: 340, loss: 0.001251445384696126
step: 350, loss: 0.00784280151128769
step: 360, loss: 0.011305395513772964
step: 370, loss: 0.02811122126877308
step: 380, loss: 0.004275111015886068
step: 390, loss: 0.0005703759379684925
step: 400, loss: 0.01617755927145481
step: 410, loss: 0.01899542659521103
step: 420, loss: 0.017821302637457848
step: 430, loss: 0.03264235705137253
step: 440, loss: 0.004925635643303394
step: 450, loss: 0.13346002995967865
step: 460, loss: 0.020303359255194664
step: 470, loss: 0.006055290810763836
step: 480, loss: 0.048156000673770905
step: 490, loss: 0.09448780864477158
step: 500, loss: 0.06274347007274628
step: 510, loss: 0.010185211896896362
step: 520, loss: 0.002985383616760373
step: 530, loss: 0.0013428267557173967
step: 540, loss: 0.02462759241461754
step: 550, loss: 0.014708120375871658
step: 560, loss: 0.03783746063709259
step: 570, loss: 0.0018082915339618921
step: 580, loss: 0.015546504408121109
step: 590, loss: 0.0054620117880403996
step: 600, loss: 0.016333715990185738
step: 610, loss: 0.004129740409553051
step: 620, loss: 0.014429474249482155
step: 630, loss: 0.002167215570807457
step: 640, loss: 0.006482895463705063
step: 650, loss: 0.05358543619513512
step: 660, loss: 0.0011424246476963162
step: 670, loss: 0.00048425927525386214
step: 680, loss: 0.0007345138001255691
step: 690, loss: 0.06133478879928589
step: 700, loss: 0.015354454517364502
step: 710, loss: 0.019956812262535095
step: 720, loss: 0.06194867193698883
step: 730, loss: 0.020902402698993683
step: 740, loss: 0.005279013887047768
step: 750, loss: 0.05038756504654884
step: 760, loss: 0.032627206295728683
step: 770, loss: 0.027492152526974678
step: 780, loss: 0.018005726858973503
step: 790, loss: 0.06405583769083023
step: 800, loss: 0.017337843775749207
step: 810, loss: 0.01396916899830103
step: 820, loss: 0.012477406300604343
step: 830, loss: 0.0033110587392002344
step: 840, loss: 0.026450349017977715
step: 850, loss: 0.011785372160375118
step: 860, loss: 0.009304736740887165
step: 870, loss: 0.001085243420675397
step: 880, loss: 0.0019122681114822626
step: 890, loss: 0.037503134459257126
step: 900, loss: 0.040934596210718155
step: 910, loss: 0.02731148712337017
step: 920, loss: 0.004550450947135687
step: 930, loss: 0.03217745199799538
step: 940, loss: 0.00541267404332757
step: 950, loss: 0.024768026545643806
step: 960, loss: 0.04577088728547096
step: 970, loss: 0.0008205970516428351
step: 980, loss: 0.015807190909981728
step: 990, loss: 0.009851016104221344
step: 1000, loss: 0.042343322187662125
step: 1010, loss: 0.01469016820192337
step: 1020, loss: 0.0033447605092078447
step: 1030, loss: 0.06453689932823181
epoch 6: dev_f1=0.9467345993515517, f1=0.9248014946286782, best_f1=0.9220055710306406
step: 0, loss: 0.018651532009243965
step: 10, loss: 0.07745137810707092
step: 20, loss: 0.045469239354133606
step: 30, loss: 0.02454238571226597
step: 40, loss: 0.0004143241385463625
step: 50, loss: 0.03932782635092735
step: 60, loss: 0.011376464739441872
step: 70, loss: 0.006946600042283535
step: 80, loss: 0.001939327921718359
step: 90, loss: 0.003210146212950349
step: 100, loss: 0.12924616038799286
step: 110, loss: 0.04029352590441704
step: 120, loss: 0.06342937052249908
step: 130, loss: 0.0016012261621654034
step: 140, loss: 0.0015325754648074508
step: 150, loss: 0.0069803278893232346
step: 160, loss: 0.0011293268762528896
step: 170, loss: 0.037706609815359116
step: 180, loss: 0.02536129392683506
step: 190, loss: 0.00808629672974348
step: 200, loss: 0.005440369248390198
step: 210, loss: 0.04932018741965294
step: 220, loss: 0.00550214946269989
step: 230, loss: 0.003421007189899683
step: 240, loss: 0.0014557864051312208
step: 250, loss: 0.007737716659903526
step: 260, loss: 0.05293441563844681
step: 270, loss: 0.0029619818087667227
step: 280, loss: 0.006530435290187597
step: 290, loss: 0.018998032435774803
step: 300, loss: 0.009372510947287083
step: 310, loss: 0.0020921756513416767
step: 320, loss: 0.004724210128188133
step: 330, loss: 0.044432129710912704
step: 340, loss: 0.0016858013113960624
step: 350, loss: 0.04945915937423706
step: 360, loss: 0.02494177594780922
step: 370, loss: 0.05485821142792702
step: 380, loss: 0.10425098240375519
step: 390, loss: 0.010229796171188354
step: 400, loss: 0.010208673775196075
step: 410, loss: 0.0946791023015976
step: 420, loss: 0.006540280766785145
step: 430, loss: 0.09422655403614044
step: 440, loss: 0.007875884883105755
step: 450, loss: 0.035734035074710846
step: 460, loss: 0.01594948209822178
step: 470, loss: 0.002539093606173992
step: 480, loss: 0.005412813741713762
step: 490, loss: 0.0060126036405563354
step: 500, loss: 0.0032440917566418648
step: 510, loss: 0.001040998729877174
step: 520, loss: 0.0315154604613781
step: 530, loss: 0.0008607082418166101
step: 540, loss: 0.07293662428855896
step: 550, loss: 0.007476030383259058
step: 560, loss: 0.026173977181315422
step: 570, loss: 0.0012312878388911486
step: 580, loss: 0.05590897798538208
step: 590, loss: 0.029607273638248444
step: 600, loss: 0.014010180719196796
step: 610, loss: 0.034035634249448776
step: 620, loss: 0.00035167927853763103
step: 630, loss: 0.20203591883182526
step: 640, loss: 0.00035646589822135866
step: 650, loss: 0.008524938486516476
step: 660, loss: 0.03640585392713547
step: 670, loss: 0.0034535357262939215
step: 680, loss: 0.0008640297455713153
step: 690, loss: 0.07853659987449646
step: 700, loss: 0.0007714235107414424
step: 710, loss: 0.08251259475946426
step: 720, loss: 0.009634489193558693
step: 730, loss: 0.0029694298282265663
step: 740, loss: 0.00037492410046979785
step: 750, loss: 0.010048706084489822
step: 760, loss: 0.001702815294265747
step: 770, loss: 0.00113245181273669
step: 780, loss: 0.010990947484970093
step: 790, loss: 0.04770267754793167
step: 800, loss: 0.007358522154390812
step: 810, loss: 0.004254565108567476
step: 820, loss: 0.08976589143276215
step: 830, loss: 0.013837688602507114
step: 840, loss: 0.021975286304950714
step: 850, loss: 0.07272470742464066
step: 860, loss: 0.014344203285872936
step: 870, loss: 0.041715532541275024
step: 880, loss: 0.0014510067412629724
step: 890, loss: 0.014900177717208862
step: 900, loss: 0.004041184205561876
step: 910, loss: 0.011522913351655006
step: 920, loss: 0.017522528767585754
step: 930, loss: 0.008764929138123989
step: 940, loss: 0.005503650289028883
step: 950, loss: 0.03769734874367714
step: 960, loss: 0.0073053184896707535
step: 970, loss: 0.13540612161159515
step: 980, loss: 0.013305211439728737
step: 990, loss: 0.030331097543239594
step: 1000, loss: 0.000881197745911777
step: 1010, loss: 0.05131728574633598
step: 1020, loss: 0.11884745210409164
step: 1030, loss: 0.00732422387227416
epoch 7: dev_f1=0.9472693032015067, f1=0.9188931297709925, best_f1=0.9220055710306406
step: 0, loss: 0.0509880930185318
step: 10, loss: 0.024566756561398506
step: 20, loss: 0.012274111621081829
step: 30, loss: 0.009963113814592361
step: 40, loss: 0.0014782126527279615
step: 50, loss: 0.00098259630613029
step: 60, loss: 0.0038977747317403555
step: 70, loss: 0.0001338427246082574
step: 80, loss: 0.002157062292098999
step: 90, loss: 0.0012148326495662332
step: 100, loss: 0.006206233520060778
step: 110, loss: 0.03053743578493595
step: 120, loss: 0.005479860585182905
step: 130, loss: 0.0007931854925118387
step: 140, loss: 0.0029470811132341623
step: 150, loss: 0.004936669487506151
step: 160, loss: 0.007294761016964912
step: 170, loss: 0.20990338921546936
step: 180, loss: 0.06827845424413681
step: 190, loss: 0.01765945367515087
step: 200, loss: 0.037047527730464935
step: 210, loss: 0.1100107803940773
step: 220, loss: 0.004845983814448118
step: 230, loss: 0.0029563296120613813
step: 240, loss: 0.003559557953849435
step: 250, loss: 0.024566683918237686
step: 260, loss: 0.002615544246509671
step: 270, loss: 0.0025855794083327055
step: 280, loss: 0.037382110953330994
step: 290, loss: 0.0028721962589770555
step: 300, loss: 0.006081812083721161
step: 310, loss: 0.0014030422316864133
step: 320, loss: 0.09660667926073074
step: 330, loss: 0.03414600342512131
step: 340, loss: 0.00195162498857826
step: 350, loss: 0.0039857178926467896
step: 360, loss: 0.004222370684146881
step: 370, loss: 0.011793849058449268
step: 380, loss: 0.01330374926328659
step: 390, loss: 0.0023864631075412035
step: 400, loss: 0.009233599528670311
step: 410, loss: 0.05249268561601639
step: 420, loss: 0.0031569460406899452
step: 430, loss: 0.0023655213881284
step: 440, loss: 0.04640667885541916
step: 450, loss: 0.0008602273883298039
step: 460, loss: 0.1963755488395691
step: 470, loss: 0.0009988050442188978
step: 480, loss: 0.010536273010075092
step: 490, loss: 0.002537517575547099
step: 500, loss: 0.054567158222198486
step: 510, loss: 0.024071263149380684
step: 520, loss: 0.0038354804273694754
step: 530, loss: 0.002902221167460084
step: 540, loss: 0.021117469295859337
step: 550, loss: 0.016381852328777313
step: 560, loss: 0.03538690134882927
step: 570, loss: 0.012693039141595364
step: 580, loss: 0.00017792337166611105
step: 590, loss: 0.037446971982717514
step: 600, loss: 0.003495597280561924
step: 610, loss: 0.12921884655952454
step: 620, loss: 0.09378058463335037
step: 630, loss: 0.009648201055824757
step: 640, loss: 0.013450931757688522
step: 650, loss: 0.0099369240924716
step: 660, loss: 0.03214092180132866
step: 670, loss: 0.0015366943553090096
step: 680, loss: 0.005534031428396702
step: 690, loss: 0.0031094863079488277
step: 700, loss: 0.02687378041446209
step: 710, loss: 0.04144354164600372
step: 720, loss: 0.005938258022069931
step: 730, loss: 0.00565568869933486
step: 740, loss: 0.02300947718322277
step: 750, loss: 0.019983377307653427
step: 760, loss: 0.1443641036748886
step: 770, loss: 0.016290325671434402
step: 780, loss: 0.0327647440135479
step: 790, loss: 0.001983044436201453
step: 800, loss: 0.0003425719914957881
step: 810, loss: 0.0965074971318245
step: 820, loss: 0.0023870200384408236
step: 830, loss: 0.2326555848121643
step: 840, loss: 0.020546669140458107
step: 850, loss: 0.018332380801439285
step: 860, loss: 0.0410870797932148
step: 870, loss: 0.0004876995226368308
step: 880, loss: 0.003735955571755767
step: 890, loss: 0.04680611193180084
step: 900, loss: 0.013322532176971436
step: 910, loss: 0.004235814791172743
step: 920, loss: 0.03988765552639961
step: 930, loss: 0.01515099499374628
step: 940, loss: 0.057768315076828
step: 950, loss: 0.04237297922372818
step: 960, loss: 0.0012107542715966702
step: 970, loss: 0.04566249996423721
step: 980, loss: 0.04528132826089859
step: 990, loss: 0.009209875017404556
step: 1000, loss: 0.019999975338578224
step: 1010, loss: 0.19140248000621796
step: 1020, loss: 0.02874169498682022
step: 1030, loss: 0.0012455731630325317
epoch 8: dev_f1=0.9499536607970344, f1=0.9318394024276377, best_f1=0.9220055710306406
step: 0, loss: 0.013781913556158543
step: 10, loss: 0.0013663594145327806
step: 20, loss: 0.0009976885048672557
step: 30, loss: 0.001345728407613933
step: 40, loss: 0.0009582152706570923
step: 50, loss: 0.004583658184856176
step: 60, loss: 0.02597477287054062
step: 70, loss: 0.005638685077428818
step: 80, loss: 0.009470365941524506
step: 90, loss: 0.003369293874129653
step: 100, loss: 0.0798848569393158
step: 110, loss: 0.0002484364958945662
step: 120, loss: 0.05811932310461998
step: 130, loss: 0.0042274100705981255
step: 140, loss: 0.00023894256446510553
step: 150, loss: 0.00045874869101680815
step: 160, loss: 0.0033639047760516405
step: 170, loss: 0.02734542079269886
step: 180, loss: 0.0007838120218366385
step: 190, loss: 0.00041765772039070725
step: 200, loss: 0.00039908153121359646
step: 210, loss: 0.0015967313665896654
step: 220, loss: 0.00016956357285380363
step: 230, loss: 0.003508338239043951
step: 240, loss: 0.0009066591737791896
step: 250, loss: 0.0019089580746367574
step: 260, loss: 0.00040389946661889553
step: 270, loss: 0.02987506054341793
step: 280, loss: 0.0027007460594177246
step: 290, loss: 0.0011582942679524422
step: 300, loss: 0.003873261157423258
step: 310, loss: 0.0023575956001877785
step: 320, loss: 0.057172827422618866
step: 330, loss: 0.062115613371133804
step: 340, loss: 0.0001512000017100945
step: 350, loss: 0.0662587508559227
step: 360, loss: 0.001991122728213668
step: 370, loss: 0.01664525270462036
step: 380, loss: 0.0008144021849147975
step: 390, loss: 0.0003212293377146125
step: 400, loss: 0.004843324888497591
step: 410, loss: 0.020372450351715088
step: 420, loss: 0.11167320609092712
step: 430, loss: 0.0041472576558589935
step: 440, loss: 0.0006406024331226945
step: 450, loss: 0.0020869860891252756
step: 460, loss: 0.0005522476276382804
step: 470, loss: 0.0076962001621723175
step: 480, loss: 0.0002725080121308565
step: 490, loss: 0.022889168933033943
step: 500, loss: 0.007750683464109898
step: 510, loss: 0.0037055411376059055
step: 520, loss: 0.01333574391901493
step: 530, loss: 0.06593291461467743
step: 540, loss: 0.00557906087487936
step: 550, loss: 0.0009728898294270039
step: 560, loss: 0.09870028495788574
step: 570, loss: 0.07061618566513062
step: 580, loss: 0.0015374523354694247
step: 590, loss: 0.0006328781018964946
step: 600, loss: 0.006507528945803642
step: 610, loss: 0.0432441420853138
step: 620, loss: 0.057085372507572174
step: 630, loss: 0.0013084611855447292
step: 640, loss: 0.00043717410881072283
step: 650, loss: 0.05545834079384804
step: 660, loss: 0.006904763635247946
step: 670, loss: 0.0023378694895654917
step: 680, loss: 0.002996204188093543
step: 690, loss: 0.0008018100052140653
step: 700, loss: 0.0018572990084066987
step: 710, loss: 0.002761146519333124
step: 720, loss: 0.001022511743940413
step: 730, loss: 0.0014743298524990678
step: 740, loss: 0.0008063055574893951
step: 750, loss: 0.03114687278866768
step: 760, loss: 0.011310762725770473
step: 770, loss: 0.0038257904816418886
step: 780, loss: 0.009431464597582817
step: 790, loss: 0.02087622694671154
step: 800, loss: 0.0007927974802441895
step: 810, loss: 0.003455463796854019
step: 820, loss: 0.03658565506339073
step: 830, loss: 0.0030853315256536007
step: 840, loss: 0.00016270732157863677
step: 850, loss: 0.021411312744021416
step: 860, loss: 0.006526043172925711
step: 870, loss: 0.0022742850705981255
step: 880, loss: 0.00031777689582668245
step: 890, loss: 0.002208487829193473
step: 900, loss: 0.00012613397848326713
step: 910, loss: 0.0025060372427105904
step: 920, loss: 0.031011424958705902
step: 930, loss: 0.0034451766405254602
step: 940, loss: 0.0011484380811452866
step: 950, loss: 0.0006064804038032889
step: 960, loss: 0.0003059321898035705
step: 970, loss: 0.038706984370946884
step: 980, loss: 0.0037601341027766466
step: 990, loss: 0.08657621592283249
step: 1000, loss: 0.000692645029630512
step: 1010, loss: 0.004734623711556196
step: 1020, loss: 0.00017181129078380764
step: 1030, loss: 0.023008758202195168
epoch 9: dev_f1=0.9472701819878675, f1=0.9244570349386214, best_f1=0.9220055710306406
step: 0, loss: 0.0005020318203605711
step: 10, loss: 0.03413430228829384
step: 20, loss: 0.003639517817646265
step: 30, loss: 0.0017011376330628991
step: 40, loss: 0.002577085979282856
step: 50, loss: 0.007767492905259132
step: 60, loss: 0.003668538061901927
step: 70, loss: 0.002496226690709591
step: 80, loss: 0.00020831564324907959
step: 90, loss: 0.015933332964777946
step: 100, loss: 0.035250067710876465
step: 110, loss: 0.00117712770588696
step: 120, loss: 0.0006021845620125532
step: 130, loss: 0.0003791576891671866
step: 140, loss: 0.0018112915568053722
step: 150, loss: 0.00016196182696148753
step: 160, loss: 0.00042547512566670775
step: 170, loss: 0.004277407191693783
step: 180, loss: 0.00020693471014965326
step: 190, loss: 0.02393236570060253
step: 200, loss: 0.0009167343960143626
step: 210, loss: 0.0004061626095790416
step: 220, loss: 0.002702572150155902
step: 230, loss: 0.06213394179940224
step: 240, loss: 0.00016149331349879503
step: 250, loss: 0.0014853683533146977
step: 260, loss: 0.00032696500420570374
step: 270, loss: 0.02271052449941635
step: 280, loss: 0.24445393681526184
step: 290, loss: 0.001583493547514081
step: 300, loss: 0.0002578957355581224
step: 310, loss: 0.000623921980150044
step: 320, loss: 0.0018404601141810417
step: 330, loss: 0.012314753606915474
step: 340, loss: 0.015081419609487057
step: 350, loss: 0.007861154153943062
step: 360, loss: 0.0010122602107003331
step: 370, loss: 0.00284654856659472
step: 380, loss: 0.0030533624812960625
step: 390, loss: 0.0005552354850806296
step: 400, loss: 0.0018280496587976813
step: 410, loss: 0.0016832913970574737
step: 420, loss: 0.002074501710012555
step: 430, loss: 0.06868433952331543
step: 440, loss: 0.0006750453030690551
step: 450, loss: 5.1216091378591955e-05
step: 460, loss: 0.008452490903437138
step: 470, loss: 0.0025848643854260445
step: 480, loss: 0.0005500600091181695
step: 490, loss: 0.0010740658035501838
step: 500, loss: 0.04651786386966705
step: 510, loss: 0.010858209803700447
step: 520, loss: 0.0015240359352901578
step: 530, loss: 0.0010410379618406296
step: 540, loss: 0.0037212164606899023
step: 550, loss: 0.0017092212801799178
step: 560, loss: 0.0004013148427475244
step: 570, loss: 0.0029236534610390663
step: 580, loss: 0.006000899709761143
step: 590, loss: 0.0005107614560984075
step: 600, loss: 0.0016891109989956021
step: 610, loss: 0.08848778158426285
step: 620, loss: 0.028019826859235764
step: 630, loss: 0.005277481395751238
step: 640, loss: 0.009585756808519363
step: 650, loss: 0.04533682018518448
step: 660, loss: 0.06730002909898758
step: 670, loss: 0.011774729937314987
step: 680, loss: 0.001308316714130342
step: 690, loss: 0.002646715845912695
step: 700, loss: 0.00030625791987404227
step: 710, loss: 0.002821672707796097
step: 720, loss: 0.007148060016334057
step: 730, loss: 0.051551129668951035
step: 740, loss: 0.08280843496322632
step: 750, loss: 0.004233501851558685
step: 760, loss: 0.0022693867795169353
step: 770, loss: 0.003810078138485551
step: 780, loss: 0.00021805419237352908
step: 790, loss: 0.00040515311411581933
step: 800, loss: 0.0005075600929558277
step: 810, loss: 0.0034588740672916174
step: 820, loss: 0.02463005855679512
step: 830, loss: 0.0007948616985231638
step: 840, loss: 0.0016580367228016257
step: 850, loss: 0.0007959293434396386
step: 860, loss: 0.003977925982326269
step: 870, loss: 0.023379813879728317
step: 880, loss: 0.00013636010407935828
step: 890, loss: 0.00023256856366060674
step: 900, loss: 0.001996338367462158
step: 910, loss: 0.007166639436036348
step: 920, loss: 0.00035379925975576043
step: 930, loss: 0.0001233443181263283
step: 940, loss: 0.0002786984550766647
step: 950, loss: 0.0359715074300766
step: 960, loss: 0.00147512077819556
step: 970, loss: 0.001694824080914259
step: 980, loss: 0.0002709143445827067
step: 990, loss: 0.004500424023717642
step: 1000, loss: 0.005930696614086628
step: 1010, loss: 0.0025454338174313307
step: 1020, loss: 0.0067417616955935955
step: 1030, loss: 0.0017848730785772204
epoch 10: dev_f1=0.94547134935305, f1=0.9261495587552253, best_f1=0.9220055710306406
step: 0, loss: 0.00012027013872284442
step: 10, loss: 0.007871621288359165
step: 20, loss: 0.0076239872723817825
step: 30, loss: 4.5425520511344075e-05
step: 40, loss: 0.006194754503667355
step: 50, loss: 0.00042741288780234754
step: 60, loss: 6.363783904816955e-05
step: 70, loss: 0.0012869429774582386
step: 80, loss: 0.00040617832564748824
step: 90, loss: 0.002010864205658436
step: 100, loss: 0.0003825437161140144
step: 110, loss: 0.004578446503728628
step: 120, loss: 0.0028319768607616425
step: 130, loss: 0.0015025234315544367
step: 140, loss: 4.921716754324734e-05
step: 150, loss: 0.18460462987422943
step: 160, loss: 0.007478354964405298
step: 170, loss: 0.00023416859039571136
step: 180, loss: 0.00032257079146802425
step: 190, loss: 0.002240134635940194
step: 200, loss: 0.00032853445736691356
step: 210, loss: 0.00034867157228291035
step: 220, loss: 0.00036909582559019327
step: 230, loss: 0.0030774129554629326
step: 240, loss: 6.876265979371965e-05
step: 250, loss: 0.06387776881456375
step: 260, loss: 0.005348938517272472
step: 270, loss: 0.00038278763531707227
step: 280, loss: 0.0002144341415259987
step: 290, loss: 0.01772524043917656
step: 300, loss: 0.009350576438009739
step: 310, loss: 0.0006152244750410318
step: 320, loss: 0.0007420800975523889
step: 330, loss: 0.00010230283805867657
step: 340, loss: 0.001098752487450838
step: 350, loss: 0.0010435815202072263
step: 360, loss: 0.04699324816465378
step: 370, loss: 0.018150843679904938
step: 380, loss: 0.000982920522801578
step: 390, loss: 0.01350049115717411
step: 400, loss: 0.023705309256911278
step: 410, loss: 0.01934925839304924
step: 420, loss: 0.0038877027109265327
step: 430, loss: 0.0009789209580048919
step: 440, loss: 0.052858613431453705
step: 450, loss: 0.00017443613614887
step: 460, loss: 0.0012649510754272342
step: 470, loss: 0.02752675488591194
step: 480, loss: 0.0030222819186747074
step: 490, loss: 0.00023402416263706982
step: 500, loss: 0.00039551968802697957
step: 510, loss: 0.0003575859882403165
step: 520, loss: 0.0033595224376767874
step: 530, loss: 5.5307060392806306e-05
step: 540, loss: 0.02463327720761299
step: 550, loss: 0.0011840388178825378
step: 560, loss: 0.0003132919955532998
step: 570, loss: 0.002438143128529191
step: 580, loss: 0.022080685943365097
step: 590, loss: 0.0010315733961760998
step: 600, loss: 0.0010513067245483398
step: 610, loss: 0.002872616518288851
step: 620, loss: 0.0027996015269309282
step: 630, loss: 0.018396472558379173
step: 640, loss: 0.003748039249330759
step: 650, loss: 0.01628766395151615
step: 660, loss: 0.0036203747149556875
step: 670, loss: 0.0025253247004002333
step: 680, loss: 9.616264287615195e-05
step: 690, loss: 0.0005209090886637568
step: 700, loss: 0.0017482315888628364
step: 710, loss: 0.002233058912679553
step: 720, loss: 0.000618576945271343
step: 730, loss: 0.007721619214862585
step: 740, loss: 0.0005823293467983603
step: 750, loss: 0.0005008612642996013
step: 760, loss: 9.880867582978681e-05
step: 770, loss: 0.00019738134869839996
step: 780, loss: 8.714189607417211e-05
step: 790, loss: 0.000400882912799716
step: 800, loss: 0.00015367397281806916
step: 810, loss: 9.27657019929029e-05
step: 820, loss: 0.15666700899600983
step: 830, loss: 0.0014135601231828332
step: 840, loss: 0.03960076719522476
step: 850, loss: 0.00547772878780961
step: 860, loss: 0.0007873849244788289
step: 870, loss: 0.0012371183838695288
step: 880, loss: 0.000925778818782419
step: 890, loss: 0.005729760508984327
step: 900, loss: 0.00036523991730064154
step: 910, loss: 0.013625925406813622
step: 920, loss: 0.00037167646223679185
step: 930, loss: 0.061598554253578186
step: 940, loss: 0.0021041412837803364
step: 950, loss: 0.0025586504489183426
step: 960, loss: 0.0436139740049839
step: 970, loss: 0.007443950045853853
step: 980, loss: 0.0006083984626457095
step: 990, loss: 0.0009951010579243302
step: 1000, loss: 0.0020570550113916397
step: 1010, loss: 0.2055576890707016
step: 1020, loss: 0.007916898466646671
step: 1030, loss: 0.00018293119501322508
epoch 11: dev_f1=0.9478584729981377, f1=0.9267605633802817, best_f1=0.9220055710306406
step: 0, loss: 0.004748595878481865
step: 10, loss: 0.0003159686457365751
step: 20, loss: 0.00022662161791231483
step: 30, loss: 0.029206132516264915
step: 40, loss: 0.0013481741771101952
step: 50, loss: 0.004919349681586027
step: 60, loss: 0.0022247175220400095
step: 70, loss: 0.0024634089786559343
step: 80, loss: 0.0006702557438984513
step: 90, loss: 0.0009696009801700711
step: 100, loss: 0.0071602994576096535
step: 110, loss: 6.868954369565472e-05
step: 120, loss: 0.0003941862960346043
step: 130, loss: 0.08829149603843689
step: 140, loss: 8.321982022607699e-05
step: 150, loss: 0.000517049222253263
step: 160, loss: 0.00046816066605970263
step: 170, loss: 7.386445213342085e-05
step: 180, loss: 0.00044165298459120095
step: 190, loss: 0.09471584856510162
step: 200, loss: 0.010489065200090408
step: 210, loss: 0.0034316314850002527
step: 220, loss: 0.00010254547669319436
step: 230, loss: 0.012111482210457325
step: 240, loss: 0.10314641147851944
step: 250, loss: 0.0010220961412414908
step: 260, loss: 0.0072227041237056255
step: 270, loss: 0.00011605942563619465
step: 280, loss: 0.0005282772472128272
step: 290, loss: 0.005404003895819187
step: 300, loss: 0.0005577149568125606
step: 310, loss: 0.0010037478059530258
step: 320, loss: 0.0007665836601518095
step: 330, loss: 0.0022629767190665007
step: 340, loss: 0.004130866378545761
step: 350, loss: 0.0062834154814481735
step: 360, loss: 0.0013312282972037792
step: 370, loss: 0.0035989086609333754
step: 380, loss: 0.0004622100677806884
step: 390, loss: 6.358535756589845e-05
step: 400, loss: 0.0005128630436956882
step: 410, loss: 0.00010452362766955048
step: 420, loss: 0.0014656992862001061
step: 430, loss: 0.0007042846991680562
step: 440, loss: 0.0010536800837144256
step: 450, loss: 0.0002465439902152866
step: 460, loss: 0.00018154585268348455
step: 470, loss: 0.010112747550010681
step: 480, loss: 0.00023806773242540658
step: 490, loss: 0.0635690912604332
step: 500, loss: 0.0040586781688034534
step: 510, loss: 0.00016311672516167164
step: 520, loss: 0.09426474571228027
step: 530, loss: 0.006015260238200426
step: 540, loss: 0.001339681795798242
step: 550, loss: 0.00017965855658985674
step: 560, loss: 0.0046110390685498714
step: 570, loss: 0.0009059901349246502
step: 580, loss: 0.05342209339141846
step: 590, loss: 0.0001524698018329218
step: 600, loss: 0.00011138543777633458
step: 610, loss: 0.00033404462737962604
step: 620, loss: 0.0004527087730821222
step: 630, loss: 0.002871451200917363
step: 640, loss: 4.6253029722720385e-05
step: 650, loss: 7.945125253172591e-05
step: 660, loss: 0.00020502098777797073
step: 670, loss: 0.06873943656682968
step: 680, loss: 0.05578802898526192
step: 690, loss: 0.00026235703262500465
step: 700, loss: 0.00030980282463133335
step: 710, loss: 0.028903348371386528
step: 720, loss: 4.337680002208799e-05
step: 730, loss: 0.06879284977912903
step: 740, loss: 0.08217800408601761
step: 750, loss: 0.00016931974096223712
step: 760, loss: 0.03575293347239494
step: 770, loss: 0.005129318684339523
step: 780, loss: 0.0002762936637736857
step: 790, loss: 0.0003183657245244831
step: 800, loss: 0.0016288826009258628
step: 810, loss: 0.0012844123411923647
step: 820, loss: 0.0001503639214206487
step: 830, loss: 0.004278500564396381
step: 840, loss: 0.000686841958668083
step: 850, loss: 0.000855865131597966
step: 860, loss: 0.0013082580408081412
step: 870, loss: 0.004615930374711752
step: 880, loss: 0.02161070890724659
step: 890, loss: 0.04715175926685333
step: 900, loss: 0.00020607863552868366
step: 910, loss: 0.02373647876083851
step: 920, loss: 0.0007648924365639687
step: 930, loss: 5.139830682310276e-05
step: 940, loss: 0.003939945716410875
step: 950, loss: 0.0047584110870957375
step: 960, loss: 0.00014010287122800946
step: 970, loss: 0.000795002852100879
step: 980, loss: 0.005153765436261892
step: 990, loss: 0.006040154490619898
step: 1000, loss: 0.0002502441930118948
step: 1010, loss: 0.0009680991061031818
step: 1020, loss: 0.005789373070001602
step: 1030, loss: 0.005173689220100641
epoch 12: dev_f1=0.9468779123951537, f1=0.9214758751182593, best_f1=0.9220055710306406
step: 0, loss: 0.0005663367919623852
step: 10, loss: 0.0017134076915681362
step: 20, loss: 0.03665420785546303
step: 30, loss: 0.032674599438905716
step: 40, loss: 0.0003707166761159897
step: 50, loss: 0.0541386753320694
step: 60, loss: 0.0009787683375179768
step: 70, loss: 0.00012146674998803064
step: 80, loss: 0.0004001183551736176
step: 90, loss: 0.0015416848473250866
step: 100, loss: 0.00591568648815155
step: 110, loss: 8.687788067618385e-05
step: 120, loss: 0.00024980856687761843
step: 130, loss: 0.005497837904840708
step: 140, loss: 0.0014592683874070644
step: 150, loss: 0.00042480332194827497
step: 160, loss: 0.0026098256930708885
step: 170, loss: 0.0002041565894614905
step: 180, loss: 0.07838206738233566
step: 190, loss: 0.000317467114655301
step: 200, loss: 0.003914813976734877
step: 210, loss: 8.364532550331205e-05
step: 220, loss: 0.0006716279312968254
step: 230, loss: 0.0013334780232980847
step: 240, loss: 0.0018571317195892334
step: 250, loss: 0.0010106521658599377
step: 260, loss: 0.006374535616487265
step: 270, loss: 0.018003283068537712
step: 280, loss: 6.672936433460563e-05
step: 290, loss: 0.0006843439186923206
step: 300, loss: 0.0021393385250121355
step: 310, loss: 0.021342260763049126
step: 320, loss: 0.00029080614331178367
step: 330, loss: 0.044300470501184464
step: 340, loss: 0.00021901448781136423
step: 350, loss: 0.00016293025691993535
step: 360, loss: 4.388449087855406e-05
step: 370, loss: 0.0003456373233348131
step: 380, loss: 0.009830949828028679
step: 390, loss: 0.00018711616576183587
step: 400, loss: 0.0023193235974758863
step: 410, loss: 0.0027669959235936403
step: 420, loss: 8.14318482298404e-05
step: 430, loss: 0.00010322066373191774
step: 440, loss: 0.0006437043775804341
step: 450, loss: 0.0019182489486411214
step: 460, loss: 0.017544271424412727
step: 470, loss: 0.0006944341585040092
step: 480, loss: 0.00033472556970082223
step: 490, loss: 0.0005842908867634833
step: 500, loss: 0.010919504798948765
step: 510, loss: 0.005362091585993767
step: 520, loss: 8.926486771088094e-05
step: 530, loss: 4.9098689487436786e-05
step: 540, loss: 0.00013448727258946747
step: 550, loss: 0.00014603196177631617
step: 560, loss: 0.00039926706813275814
step: 570, loss: 0.00023303738271351904
step: 580, loss: 0.10880086570978165
step: 590, loss: 4.8444257117807865e-05
step: 600, loss: 0.00044138930388726294
step: 610, loss: 5.775678073405288e-05
step: 620, loss: 0.0015910493675619364
step: 630, loss: 0.002324134111404419
step: 640, loss: 0.0017704739002510905
step: 650, loss: 0.00024402585404459387
step: 660, loss: 0.001002784352749586
step: 670, loss: 0.003982897382229567
step: 680, loss: 0.006599578075110912
step: 690, loss: 0.00017917249351739883
step: 700, loss: 0.0013281044084578753
step: 710, loss: 9.742866677697748e-05
step: 720, loss: 9.21298997127451e-05
step: 730, loss: 3.458415812929161e-05
step: 740, loss: 0.011094778776168823
step: 750, loss: 5.509078619070351e-05
step: 760, loss: 5.268658060231246e-05
step: 770, loss: 6.132146518211812e-05
step: 780, loss: 0.0005743267247453332
step: 790, loss: 0.00013875476724933833
step: 800, loss: 0.00047660843119956553
step: 810, loss: 0.0006925342604517937
step: 820, loss: 0.0035502598620951176
step: 830, loss: 0.0030197950545698404
step: 840, loss: 0.0005499976687133312
step: 850, loss: 0.0035533227492123842
step: 860, loss: 0.003128178883343935
step: 870, loss: 0.002824969356879592
step: 880, loss: 0.0004664883890654892
step: 890, loss: 0.014544125646352768
step: 900, loss: 3.443492096266709e-05
step: 910, loss: 4.4159583922009915e-05
step: 920, loss: 0.00024614803260192275
step: 930, loss: 0.0009020153665915132
step: 940, loss: 0.17828676104545593
step: 950, loss: 0.00011381721560610458
step: 960, loss: 0.00012522665201686323
step: 970, loss: 0.026015620678663254
step: 980, loss: 0.018415501341223717
step: 990, loss: 0.0002577847335487604
step: 1000, loss: 0.00016541569493710995
step: 1010, loss: 0.0022280707489699125
step: 1020, loss: 0.000983449979685247
step: 1030, loss: 0.0004324974142946303
epoch 13: dev_f1=0.9457943925233645, f1=0.9344648750589346, best_f1=0.9220055710306406
step: 0, loss: 0.00027946042246185243
step: 10, loss: 2.7744576073018834e-05
step: 20, loss: 0.0035144039429724216
step: 30, loss: 0.000696732837241143
step: 40, loss: 0.00022301971330307424
step: 50, loss: 0.0005521516432054341
step: 60, loss: 3.490790550131351e-05
step: 70, loss: 0.0013896699529141188
step: 80, loss: 0.04542645812034607
step: 90, loss: 0.002662018872797489
step: 100, loss: 0.00010833553824340925
step: 110, loss: 0.030469514429569244
step: 120, loss: 5.72230746911373e-05
step: 130, loss: 0.010928405448794365
step: 140, loss: 9.397022949997336e-05
step: 150, loss: 0.0031658378429710865
step: 160, loss: 0.0003111086552962661
step: 170, loss: 0.009243587031960487
step: 180, loss: 0.025730958208441734
step: 190, loss: 0.0038756674621254206
step: 200, loss: 0.0007503001834265888
step: 210, loss: 0.00047210900811478496
step: 220, loss: 0.00032447301782667637
step: 230, loss: 4.3540589103940874e-05
step: 240, loss: 0.00011302268831059337
step: 250, loss: 0.003603104967623949
step: 260, loss: 8.512611384503543e-05
step: 270, loss: 8.986180182546377e-05
step: 280, loss: 0.0011017698561772704
step: 290, loss: 0.0001402117923134938
step: 300, loss: 0.0005965426098555326
step: 310, loss: 0.00034835521364584565
step: 320, loss: 0.0011954904766753316
step: 330, loss: 0.0004883781657554209
step: 340, loss: 0.000531309749931097
step: 350, loss: 0.005901265423744917
step: 360, loss: 0.0027197529561817646
step: 370, loss: 0.0003111956175416708
step: 380, loss: 0.0006100278114899993
step: 390, loss: 0.0007660194532945752
step: 400, loss: 4.783837721333839e-05
step: 410, loss: 1.9758514099521562e-05
step: 420, loss: 0.00034407892962917686
step: 430, loss: 0.12645018100738525
step: 440, loss: 0.010679427534341812
step: 450, loss: 0.0012378663523122668
step: 460, loss: 0.00019614124903455377
step: 470, loss: 0.004057911224663258
step: 480, loss: 0.00027540227165445685
step: 490, loss: 0.0003358974645379931
step: 500, loss: 9.862320439424366e-05
step: 510, loss: 0.0011098856339231133
step: 520, loss: 5.322582364897244e-05
step: 530, loss: 0.00037568219704553485
step: 540, loss: 0.05900654196739197
step: 550, loss: 0.0021094109397381544
step: 560, loss: 0.00024767155991867185
step: 570, loss: 9.340070391772315e-05
step: 580, loss: 0.00013493344886228442
step: 590, loss: 0.0006761297699995339
step: 600, loss: 0.003701163688674569
step: 610, loss: 0.00514474930241704
step: 620, loss: 0.0015523888869211078
step: 630, loss: 0.026975762099027634
step: 640, loss: 0.00031783716985955834
step: 650, loss: 0.009142711758613586
step: 660, loss: 0.001956381369382143
step: 670, loss: 0.0016379357548430562
step: 680, loss: 0.005162107292562723
step: 690, loss: 0.00017504725838080049
step: 700, loss: 0.010875030420720577
step: 710, loss: 0.00028989819111302495
step: 720, loss: 0.0006646901601925492
step: 730, loss: 6.989259418332949e-05
step: 740, loss: 0.00015783550043124706
step: 750, loss: 0.0003998133761342615
step: 760, loss: 8.934228389989585e-05
step: 770, loss: 0.004227723926305771
step: 780, loss: 5.2638515626313165e-05
step: 790, loss: 3.059347363887355e-05
step: 800, loss: 0.14449982345104218
step: 810, loss: 0.0008363820961676538
step: 820, loss: 0.0011144977761432528
step: 830, loss: 0.0024399368558079004
step: 840, loss: 5.412729296949692e-05
step: 850, loss: 2.7469004635349847e-05
step: 860, loss: 4.54203509434592e-05
step: 870, loss: 0.01574600301682949
step: 880, loss: 0.0036195674911141396
step: 890, loss: 0.002250474411994219
step: 900, loss: 0.07968240976333618
step: 910, loss: 0.0003123792412225157
step: 920, loss: 0.001103983842767775
step: 930, loss: 4.021317727165297e-05
step: 940, loss: 0.00122654193546623
step: 950, loss: 0.0010246793972328305
step: 960, loss: 0.0009728351142257452
step: 970, loss: 0.00017674683476798236
step: 980, loss: 0.004744333680719137
step: 990, loss: 0.005100285168737173
step: 1000, loss: 0.004062481224536896
step: 1010, loss: 0.00010772891982924193
step: 1020, loss: 6.51646769256331e-05
step: 1030, loss: 0.00022484919463749975
epoch 14: dev_f1=0.9474654377880185, f1=0.9310344827586207, best_f1=0.9220055710306406
step: 0, loss: 0.002431736094877124
step: 10, loss: 4.3651456508086994e-05
step: 20, loss: 4.355878263595514e-05
step: 30, loss: 0.00046666967682540417
step: 40, loss: 0.000819242384750396
step: 50, loss: 8.600298315286636e-05
step: 60, loss: 0.0004087035486008972
step: 70, loss: 7.22762561053969e-05
step: 80, loss: 0.0003677654603961855
step: 90, loss: 0.0001070736616384238
step: 100, loss: 6.358582322718576e-05
step: 110, loss: 0.00012388112372718751
step: 120, loss: 6.637284241151065e-05
step: 130, loss: 0.0007523309905081987
step: 140, loss: 2.7764650440076366e-05
step: 150, loss: 0.00011865793931065127
step: 160, loss: 1.953877290361561e-05
step: 170, loss: 0.0009663334931246936
step: 180, loss: 0.019201483577489853
step: 190, loss: 0.007352190557867289
step: 200, loss: 0.0001605097349965945
step: 210, loss: 2.5595076294848695e-05
step: 220, loss: 9.24051710171625e-05
step: 230, loss: 0.0002743488294072449
step: 240, loss: 0.00023893415345810354
step: 250, loss: 0.0015747153665870428
step: 260, loss: 0.046575188636779785
step: 270, loss: 0.025530314072966576
step: 280, loss: 0.000218555040191859
step: 290, loss: 0.009288172237575054
step: 300, loss: 0.0003172254655510187
step: 310, loss: 3.0382127079064958e-05
step: 320, loss: 2.8296450182097033e-05
step: 330, loss: 0.0030802679248154163
step: 340, loss: 3.9177870348794386e-05
step: 350, loss: 7.692844519624487e-05
step: 360, loss: 8.1494334153831e-05
step: 370, loss: 0.005064914468675852
step: 380, loss: 7.847867527743801e-05
step: 390, loss: 0.0005877422518096864
step: 400, loss: 0.0005281476769596338
step: 410, loss: 0.00010464143997523934
step: 420, loss: 1.133965179178631e-05
step: 430, loss: 0.0010147186694666743
step: 440, loss: 9.299148950958624e-05
step: 450, loss: 0.0022534900344908237
step: 460, loss: 0.0007984160329215229
step: 470, loss: 4.79108675790485e-05
step: 480, loss: 0.025764022022485733
step: 490, loss: 0.007924212142825127
step: 500, loss: 2.613153810671065e-05
step: 510, loss: 0.0001610290928510949
step: 520, loss: 4.5102526200935245e-05
step: 530, loss: 8.085343870334327e-05
step: 540, loss: 0.0002710169064812362
step: 550, loss: 3.912665488314815e-05
step: 560, loss: 0.007727070711553097
step: 570, loss: 0.0874832421541214
step: 580, loss: 0.00022302469005808234
step: 590, loss: 8.668742520967498e-05
step: 600, loss: 6.110488902777433e-05
step: 610, loss: 0.0003327175509184599
step: 620, loss: 0.001342486939392984
step: 630, loss: 0.00015071321104187518
step: 640, loss: 0.016205688938498497
step: 650, loss: 4.327647911850363e-05
step: 660, loss: 0.00010303503950126469
step: 670, loss: 9.251349547412246e-05
step: 680, loss: 3.9659695175942034e-05
step: 690, loss: 0.00021064472093712538
step: 700, loss: 5.9686142776627094e-05
step: 710, loss: 0.0021578564774245024
step: 720, loss: 0.0002869754680432379
step: 730, loss: 0.0006381130660884082
step: 740, loss: 0.00019595514459069818
step: 750, loss: 6.190039130160585e-05
step: 760, loss: 5.480061736307107e-05
step: 770, loss: 0.09462136775255203
step: 780, loss: 8.485136640956625e-05
step: 790, loss: 1.3101621334499214e-05
step: 800, loss: 3.4016316931229085e-05
step: 810, loss: 0.005031806416809559
step: 820, loss: 0.027342960238456726
step: 830, loss: 0.001127554103732109
step: 840, loss: 0.007143737748265266
step: 850, loss: 0.000431430438766256
step: 860, loss: 0.00040722463745623827
step: 870, loss: 9.37574659474194e-05
step: 880, loss: 0.00042001603287644684
step: 890, loss: 0.002090981462970376
step: 900, loss: 4.817563240067102e-05
step: 910, loss: 1.938962668646127e-05
step: 920, loss: 0.00021606193331535906
step: 930, loss: 0.0005093137733638287
step: 940, loss: 4.455422822502442e-05
step: 950, loss: 0.00014301130431704223
step: 960, loss: 0.010155494324862957
step: 970, loss: 0.005130808334797621
step: 980, loss: 0.0001786502543836832
step: 990, loss: 0.00020616265828721225
step: 1000, loss: 0.0001547716383356601
step: 1010, loss: 0.0009337419178336859
step: 1020, loss: 8.182604506146163e-05
step: 1030, loss: 0.0015026669716462493
epoch 15: dev_f1=0.9477064220183486, f1=0.9274826789838336, best_f1=0.9220055710306406
step: 0, loss: 0.0009431496728211641
step: 10, loss: 0.00015038959099911153
step: 20, loss: 3.6564175388775766e-05
step: 30, loss: 0.012244660407304764
step: 40, loss: 0.00011980027193203568
step: 50, loss: 0.0046676695346832275
step: 60, loss: 0.003982569556683302
step: 70, loss: 4.129018998355605e-05
step: 80, loss: 0.0006846024771220982
step: 90, loss: 0.004724702797830105
step: 100, loss: 0.0011768670519813895
step: 110, loss: 0.00025578076019883156
step: 120, loss: 2.8686881705652922e-05
step: 130, loss: 0.0009650421561673284
step: 140, loss: 0.00021102908067405224
step: 150, loss: 0.0005403831601142883
step: 160, loss: 1.98925263248384e-05
step: 170, loss: 4.3178264604648575e-05
step: 180, loss: 5.1081944548059255e-05
step: 190, loss: 0.0007512958836741745
step: 200, loss: 0.012845615856349468
step: 210, loss: 0.035837359726428986
step: 220, loss: 0.01403606217354536
step: 230, loss: 0.0005618793074972928
step: 240, loss: 6.366590969264507e-05
step: 250, loss: 7.311157241929322e-05
step: 260, loss: 0.00025366616318933666
step: 270, loss: 0.010601893067359924
step: 280, loss: 0.24855923652648926
step: 290, loss: 0.00018454552628099918
step: 300, loss: 7.311297667911276e-05
step: 310, loss: 0.037869662046432495
step: 320, loss: 6.0203787143109366e-05
step: 330, loss: 5.981186404824257e-05
step: 340, loss: 0.0006411013891920447
step: 350, loss: 9.550515824230388e-05
step: 360, loss: 6.79601653246209e-05
step: 370, loss: 5.9414283896330744e-05
step: 380, loss: 6.357285019475967e-05
step: 390, loss: 9.966524521587417e-05
step: 400, loss: 3.4812026569852605e-05
step: 410, loss: 0.012884017080068588
step: 420, loss: 0.00014595536049455404
step: 430, loss: 0.0008893259218893945
step: 440, loss: 2.64666487055365e-05
step: 450, loss: 6.137888703960925e-05
step: 460, loss: 2.1527914213947952e-05
step: 470, loss: 6.405908789020032e-05
step: 480, loss: 0.00028506494709290564
step: 490, loss: 5.125072129885666e-05
step: 500, loss: 0.00012549517850857228
step: 510, loss: 3.465452027739957e-05
step: 520, loss: 0.0006442213780246675
step: 530, loss: 0.0009983882773667574
step: 540, loss: 0.0014699286548420787
step: 550, loss: 0.00047675846144557
step: 560, loss: 5.839650475536473e-05
step: 570, loss: 0.026036813855171204
step: 580, loss: 0.00022890018590260297
step: 590, loss: 2.3513310225098394e-05
step: 600, loss: 0.000901000399608165
step: 610, loss: 6.934787234058604e-05
step: 620, loss: 0.0004401755868457258
step: 630, loss: 5.8158642787020653e-05
step: 640, loss: 3.670226578833535e-05
step: 650, loss: 0.00013676669914275408
step: 660, loss: 0.0007691301871091127
step: 670, loss: 0.00011318145698169246
step: 680, loss: 5.040965697844513e-05
step: 690, loss: 0.0009272534516640007
step: 700, loss: 0.0019454738358035684
step: 710, loss: 0.000192919687833637
step: 720, loss: 0.0005620731972157955
step: 730, loss: 0.00040332836215384305
step: 740, loss: 3.273606125731021e-05
step: 750, loss: 0.000206086813705042
step: 760, loss: 3.0510625947499648e-05
step: 770, loss: 0.0005860603996552527
step: 780, loss: 0.0018872274085879326
step: 790, loss: 2.041306834144052e-05
step: 800, loss: 9.619181946618482e-05
step: 810, loss: 8.869493467500433e-05
step: 820, loss: 4.9226895498577505e-05
step: 830, loss: 0.00015944447659421712
step: 840, loss: 4.5970351493451744e-05
step: 850, loss: 2.245899486297276e-05
step: 860, loss: 0.00017404271056875587
step: 870, loss: 0.00018625786469783634
step: 880, loss: 3.0490267818095163e-05
step: 890, loss: 3.270613888162188e-05
step: 900, loss: 0.00024825092987157404
step: 910, loss: 8.990237256512046e-05
step: 920, loss: 8.408984285779297e-05
step: 930, loss: 1.5470768630621023e-05
step: 940, loss: 4.5443597628036514e-05
step: 950, loss: 8.753197471378371e-05
step: 960, loss: 2.056302582786884e-05
step: 970, loss: 0.004739777650684118
step: 980, loss: 0.0011048095766454935
step: 990, loss: 0.0005042021512053907
step: 1000, loss: 4.484184682951309e-05
step: 1010, loss: 3.766392183024436e-05
step: 1020, loss: 2.985273749800399e-05
step: 1030, loss: 0.000123203411931172
epoch 16: dev_f1=0.9446009389671362, f1=0.9206650831353919, best_f1=0.9220055710306406
step: 0, loss: 0.0005055854562669992
step: 10, loss: 3.951244434574619e-05
step: 20, loss: 1.3526314432965592e-05
step: 30, loss: 6.422770820790902e-05
step: 40, loss: 0.00012113103730371222
step: 50, loss: 1.691630677669309e-05
step: 60, loss: 2.3531762053607963e-05
step: 70, loss: 5.551740832743235e-05
step: 80, loss: 7.83274372224696e-05
step: 90, loss: 4.5846300054108724e-05
step: 100, loss: 4.7832116251811385e-05
step: 110, loss: 3.485163324512541e-05
step: 120, loss: 3.857874617096968e-05
step: 130, loss: 9.393673099111766e-05
step: 140, loss: 0.0002102940488839522
step: 150, loss: 2.6385352612123825e-05
step: 160, loss: 0.0004001869529020041
step: 170, loss: 0.00017025652050506324
step: 180, loss: 0.0016704198205843568
step: 190, loss: 0.0001290411310037598
step: 200, loss: 8.864085248205811e-05
step: 210, loss: 3.8693673559464514e-05
step: 220, loss: 0.0002516614622436464
step: 230, loss: 0.03026294708251953
step: 240, loss: 0.00019072272698394954
step: 250, loss: 3.503761763568036e-05
step: 260, loss: 0.0031074825674295425
step: 270, loss: 8.093798533082008e-05
step: 280, loss: 3.419223867240362e-05
step: 290, loss: 4.152090332354419e-05
step: 300, loss: 2.0551982743199915e-05
step: 310, loss: 0.0001182158084702678
step: 320, loss: 0.0002786506083793938
step: 330, loss: 0.0007363707409240305
step: 340, loss: 0.0002162484743166715
step: 350, loss: 0.00015908191562630236
step: 360, loss: 0.07949169725179672
step: 370, loss: 5.682788832928054e-05
step: 380, loss: 2.710528133320622e-05
step: 390, loss: 0.0645008534193039
step: 400, loss: 0.00010272764484398067
step: 410, loss: 0.08663013577461243
step: 420, loss: 0.0008833597530610859
step: 430, loss: 0.0001986767747439444
step: 440, loss: 0.0011548572219908237
step: 450, loss: 0.005680319387465715
step: 460, loss: 0.00020256909192539752
step: 470, loss: 0.007387213874608278
step: 480, loss: 0.0001075527397915721
step: 490, loss: 0.00018030917271971703
step: 500, loss: 0.00013091661094222218
step: 510, loss: 0.0007322331075556576
step: 520, loss: 3.5816439776681364e-05
step: 530, loss: 4.5026921725366265e-05
step: 540, loss: 0.0033375085331499577
step: 550, loss: 0.00038632596260868013
step: 560, loss: 0.00016758363926783204
step: 570, loss: 2.309910451003816e-05
step: 580, loss: 0.1136288046836853
step: 590, loss: 0.004120145924389362
step: 600, loss: 4.695284951594658e-05
step: 610, loss: 0.00028597566415555775
step: 620, loss: 0.0018563361372798681
step: 630, loss: 0.0006945114582777023
step: 640, loss: 0.00015199588960967958
step: 650, loss: 0.0020425044931471348
step: 660, loss: 0.000885829038452357
step: 670, loss: 0.00020750197290908545
step: 680, loss: 4.891636854154058e-05
step: 690, loss: 7.692314102314413e-05
step: 700, loss: 7.88484321674332e-05
step: 710, loss: 4.6117656893329695e-05
step: 720, loss: 8.532198989996687e-05
step: 730, loss: 3.8186695746844634e-05
step: 740, loss: 0.0002998021664097905
step: 750, loss: 0.00017028793809004128
step: 760, loss: 5.8990390243707225e-05
step: 770, loss: 0.00016872298147063702
step: 780, loss: 0.00010371916141593829
step: 790, loss: 0.0009748230222612619
step: 800, loss: 5.604633770417422e-05
step: 810, loss: 0.009486604481935501
step: 820, loss: 0.0002504530712030828
step: 830, loss: 0.0002548044139984995
step: 840, loss: 0.08996706455945969
step: 850, loss: 0.0019022757187485695
step: 860, loss: 0.015961874276399612
step: 870, loss: 0.0006393321673385799
step: 880, loss: 0.000122436074889265
step: 890, loss: 7.550173904746771e-05
step: 900, loss: 3.083448973484337e-05
step: 910, loss: 0.0001551248278701678
step: 920, loss: 0.000503449235111475
step: 930, loss: 0.0002761425857897848
step: 940, loss: 0.005244288127869368
step: 950, loss: 8.300330227939412e-05
step: 960, loss: 9.141940245172009e-05
step: 970, loss: 0.0012883276212960482
step: 980, loss: 2.000417953240685e-05
step: 990, loss: 0.0007826490909792483
step: 1000, loss: 6.271321763051674e-05
step: 1010, loss: 0.0014426382258534431
step: 1020, loss: 0.00015528594667557627
step: 1030, loss: 5.612301538349129e-05
epoch 17: dev_f1=0.9474662947466295, f1=0.9279321714554876, best_f1=0.9220055710306406
step: 0, loss: 0.00018384805298410356
step: 10, loss: 0.00016467297973576933
step: 20, loss: 0.00014687044313177466
step: 30, loss: 0.00013543256500270218
step: 40, loss: 7.100618677213788e-05
step: 50, loss: 1.4945636394259054e-05
step: 60, loss: 0.0004084404499735683
step: 70, loss: 0.0001404835347784683
step: 80, loss: 8.548125333618373e-05
step: 90, loss: 3.25049004459288e-05
step: 100, loss: 0.0004186422738712281
step: 110, loss: 7.026570528978482e-05
step: 120, loss: 7.239699334604666e-05
step: 130, loss: 0.001780590508133173
step: 140, loss: 4.7023608203744516e-05
step: 150, loss: 6.72157111694105e-05
step: 160, loss: 1.602590418769978e-05
step: 170, loss: 3.198743434040807e-05
step: 180, loss: 0.0018960169982165098
step: 190, loss: 2.532308644731529e-05
step: 200, loss: 0.028106551617383957
step: 210, loss: 0.04354431480169296
step: 220, loss: 0.0003798647376243025
step: 230, loss: 2.7521127776708454e-05
step: 240, loss: 4.6803274017293006e-05
step: 250, loss: 4.584729686030187e-05
step: 260, loss: 7.30779574951157e-05
step: 270, loss: 3.0234481528168544e-05
step: 280, loss: 6.991333066252992e-05
step: 290, loss: 1.7728320017340593e-05
step: 300, loss: 0.0001156648577307351
step: 310, loss: 0.00019153686298523098
step: 320, loss: 7.108308636816218e-05
step: 330, loss: 3.528945308062248e-05
step: 340, loss: 0.0003849140484817326
step: 350, loss: 2.1919136997894384e-05
step: 360, loss: 0.0018122666515409946
step: 370, loss: 0.000352583359926939
step: 380, loss: 1.464762772229733e-05
step: 390, loss: 1.8875633031711914e-05
step: 400, loss: 0.0031392176169902086
step: 410, loss: 0.0015762097900733352
step: 420, loss: 8.377797348657623e-05
step: 430, loss: 0.0005032980698160827
step: 440, loss: 1.59402970894007e-05
step: 450, loss: 7.354065746767446e-05
step: 460, loss: 0.0011151493526995182
step: 470, loss: 0.00016711947682779282
step: 480, loss: 0.0001202285784529522
step: 490, loss: 0.0013890891568735242
step: 500, loss: 4.473450098885223e-05
step: 510, loss: 0.011309228837490082
step: 520, loss: 0.0022055197041481733
step: 530, loss: 5.7377877965336666e-05
step: 540, loss: 1.6532489098608494e-05
step: 550, loss: 3.41215381922666e-05
step: 560, loss: 5.473338387673721e-05
step: 570, loss: 8.954701479524374e-05
step: 580, loss: 1.859953044913709e-05
step: 590, loss: 0.00013071998546365649
step: 600, loss: 1.9199111193302087e-05
step: 610, loss: 0.0015626884996891022
step: 620, loss: 3.9734546589897946e-05
step: 630, loss: 2.591211705293972e-05
step: 640, loss: 3.390200436115265e-05
step: 650, loss: 0.028934622183442116
step: 660, loss: 7.90727644925937e-05
step: 670, loss: 2.273418976983521e-05
step: 680, loss: 0.0028360479045659304
step: 690, loss: 4.6290806494653225e-05
step: 700, loss: 0.0014796156901866198
step: 710, loss: 0.002791746985167265
step: 720, loss: 0.0008158364798873663
step: 730, loss: 0.05168841779232025
step: 740, loss: 4.974144758307375e-05
step: 750, loss: 4.0032213291851804e-05
step: 760, loss: 5.707700256607495e-05
step: 770, loss: 0.00014329490659292787
step: 780, loss: 5.644759221468121e-05
step: 790, loss: 0.0024545746855437756
step: 800, loss: 5.7893823395716026e-05
step: 810, loss: 0.01047966443002224
step: 820, loss: 0.0033384254202246666
step: 830, loss: 5.0881011702585965e-05
step: 840, loss: 0.00011039872333640233
step: 850, loss: 0.00010444970394019037
step: 860, loss: 0.0004174465429969132
step: 870, loss: 0.00010033979924628511
step: 880, loss: 0.00010840083268703893
step: 890, loss: 0.0011343195801600814
step: 900, loss: 1.6163789041456766e-05
step: 910, loss: 3.950586688006297e-05
step: 920, loss: 4.8668043746147305e-05
step: 930, loss: 0.00015175303269643337
step: 940, loss: 0.0005596992559731007
step: 950, loss: 8.624766633147374e-05
step: 960, loss: 0.08379534631967545
step: 970, loss: 3.863558595185168e-05
step: 980, loss: 6.584070797543973e-05
step: 990, loss: 4.02662371925544e-05
step: 1000, loss: 0.00015254000027198344
step: 1010, loss: 0.00011790326243499294
step: 1020, loss: 2.014177334785927e-05
step: 1030, loss: 0.0002487149031367153
epoch 18: dev_f1=0.9471221338324755, f1=0.9281663516068053, best_f1=0.9220055710306406
step: 0, loss: 2.6102321498910896e-05
step: 10, loss: 6.790942279621959e-05
step: 20, loss: 5.482809501700103e-05
step: 30, loss: 3.633523374446668e-05
step: 40, loss: 3.871997250826098e-05
step: 50, loss: 3.90679451811593e-05
step: 60, loss: 2.647428300406318e-05
step: 70, loss: 0.00040430211811326444
step: 80, loss: 0.00019775096734520048
step: 90, loss: 1.709870957711246e-05
step: 100, loss: 1.8488106434233487e-05
step: 110, loss: 1.3906291314924601e-05
step: 120, loss: 2.3010550648905337e-05
step: 130, loss: 2.9126411391189322e-05
step: 140, loss: 0.0011590730864554644
step: 150, loss: 0.00027090503135696054
step: 160, loss: 2.9606368116219528e-05
step: 170, loss: 2.173635220970027e-05
step: 180, loss: 7.472739525837824e-05
step: 190, loss: 0.00027741663507185876
step: 200, loss: 7.17448492650874e-05
step: 210, loss: 1.1924501450266689e-05
step: 220, loss: 0.0007809762610122561
step: 230, loss: 7.005479710642248e-05
step: 240, loss: 0.00017978536197915673
step: 250, loss: 3.5070963349426165e-05
step: 260, loss: 0.00013881326594855636
step: 270, loss: 6.644741370109841e-05
step: 280, loss: 0.0001303710014326498
step: 290, loss: 0.0006781785050407052
step: 300, loss: 0.0005034673376940191
step: 310, loss: 0.011525045149028301
step: 320, loss: 0.000919582147616893
step: 330, loss: 2.1840332919964567e-05
step: 340, loss: 9.645664249546826e-05
step: 350, loss: 1.5761332178954035e-05
step: 360, loss: 0.00010073300654767081
step: 370, loss: 0.00016885520017240196
step: 380, loss: 0.00014708128583151847
step: 390, loss: 0.0012693096650764346
step: 400, loss: 0.0011154022067785263
step: 410, loss: 0.014673023484647274
step: 420, loss: 1.3753566236118786e-05
step: 430, loss: 0.00016740590217523277
step: 440, loss: 2.0551296984194778e-05
step: 450, loss: 3.016041409864556e-05
step: 460, loss: 1.9542378140613437e-05
step: 470, loss: 0.00014306034427136183
step: 480, loss: 6.585550727322698e-05
step: 490, loss: 0.010415087454020977
step: 500, loss: 1.0762264537333976e-05
step: 510, loss: 0.00017142723663710058
step: 520, loss: 4.872755744145252e-05
step: 530, loss: 0.0037868604995310307
step: 540, loss: 2.4763605324551463e-05
step: 550, loss: 2.2860700482851826e-05
step: 560, loss: 9.77358577074483e-05
step: 570, loss: 1.124278969655279e-05
step: 580, loss: 1.1455113963165786e-05
step: 590, loss: 0.00022249188623391092
step: 600, loss: 6.52011003694497e-05
step: 610, loss: 3.434346217545681e-05
step: 620, loss: 2.9629029086208902e-05
step: 630, loss: 0.00013013655552640557
step: 640, loss: 6.239694630494341e-05
step: 650, loss: 1.7411457520211115e-05
step: 660, loss: 3.35437580361031e-05
step: 670, loss: 2.2350546714733355e-05
step: 680, loss: 0.06506630778312683
step: 690, loss: 0.00018924186588265002
step: 700, loss: 2.1459651179611683e-05
step: 710, loss: 0.00038444180972874165
step: 720, loss: 0.0003397284308448434
step: 730, loss: 0.04186209291219711
step: 740, loss: 3.4243079426232725e-05
step: 750, loss: 4.045759851578623e-05
step: 760, loss: 0.00012277929636184126
step: 770, loss: 1.5273271856131032e-05
step: 780, loss: 6.71406596666202e-05
step: 790, loss: 1.3250592928670812e-05
step: 800, loss: 4.4876087486045435e-05
step: 810, loss: 7.989357982296497e-05
step: 820, loss: 1.7913909687194973e-05
step: 830, loss: 1.3023445717408322e-05
step: 840, loss: 1.1436527529440355e-05
step: 850, loss: 0.001854379428550601
step: 860, loss: 2.118872907885816e-05
step: 870, loss: 8.516340312780812e-05
step: 880, loss: 0.002139184158295393
step: 890, loss: 0.00022332849039230496
step: 900, loss: 0.000513731618411839
step: 910, loss: 0.001739730592817068
step: 920, loss: 0.00437508337199688
step: 930, loss: 5.744795998907648e-05
step: 940, loss: 7.897567229520064e-06
step: 950, loss: 3.2146570447366685e-05
step: 960, loss: 3.8654732634313405e-05
step: 970, loss: 0.0001555619965074584
step: 980, loss: 1.859210715338122e-05
step: 990, loss: 9.259036596631631e-05
step: 1000, loss: 0.0005529741174541414
step: 1010, loss: 2.0361165297799744e-05
step: 1020, loss: 4.892998913419433e-05
step: 1030, loss: 5.563175363931805e-05
epoch 19: dev_f1=0.9457436856875585, f1=0.9282660332541568, best_f1=0.9220055710306406
step: 0, loss: 8.892188816389535e-06
step: 10, loss: 3.202747757313773e-05
step: 20, loss: 1.9039440303458832e-05
step: 30, loss: 1.1272622032265645e-05
step: 40, loss: 4.344676199252717e-05
step: 50, loss: 2.2663429263047874e-05
step: 60, loss: 0.0013748867204412818
step: 70, loss: 5.7518293033353984e-05
step: 80, loss: 0.00022499200713355094
step: 90, loss: 1.0900118468271103e-05
step: 100, loss: 0.0004671609785873443
step: 110, loss: 3.316555739729665e-05
step: 120, loss: 1.4390471733349841e-05
step: 130, loss: 2.198445872636512e-05
step: 140, loss: 0.0007635286310687661
step: 150, loss: 3.256855779909529e-05
step: 160, loss: 0.00014789635315537453
step: 170, loss: 1.903112934087403e-05
step: 180, loss: 5.1053924835287035e-05
step: 190, loss: 0.00014133649528957903
step: 200, loss: 1.6353618775610812e-05
step: 210, loss: 0.0010381498141214252
step: 220, loss: 0.0003213943273294717
step: 230, loss: 2.692360430955887e-05
step: 240, loss: 1.716549559205305e-05
step: 250, loss: 0.0007499463390558958
step: 260, loss: 5.776793113909662e-05
step: 270, loss: 3.8632777432212606e-05
step: 280, loss: 1.6565832993364893e-05
step: 290, loss: 6.876051338622347e-05
step: 300, loss: 1.775800046743825e-05
step: 310, loss: 1.2557627997011878e-05
step: 320, loss: 1.7735157598508522e-05
step: 330, loss: 0.00012043961032759398
step: 340, loss: 1.6866964870132506e-05
step: 350, loss: 0.000780046044383198
step: 360, loss: 6.590285192942247e-05
step: 370, loss: 1.392851299897302e-05
step: 380, loss: 0.00026885996339842677
step: 390, loss: 1.3231894627097063e-05
step: 400, loss: 1.2267208148841746e-05
step: 410, loss: 3.821670907200314e-05
step: 420, loss: 4.9842576117953286e-05
step: 430, loss: 1.7914066120283678e-05
step: 440, loss: 0.00010244091390632093
step: 450, loss: 1.5306964996852912e-05
step: 460, loss: 6.383554136846215e-05
step: 470, loss: 1.0967114576487802e-05
step: 480, loss: 3.425703107495792e-05
step: 490, loss: 1.7548572941450402e-05
step: 500, loss: 9.879317076411098e-06
step: 510, loss: 6.996573938522488e-05
step: 520, loss: 1.5005178283900023e-05
step: 530, loss: 0.002991215093061328
step: 540, loss: 0.00023633042292203754
step: 550, loss: 1.6022106137825176e-05
step: 560, loss: 6.0831363953184336e-05
step: 570, loss: 1.317248370469315e-05
step: 580, loss: 0.0004186536243651062
step: 590, loss: 1.6282991055049933e-05
step: 600, loss: 0.00013800420856568962
step: 610, loss: 1.321343097515637e-05
step: 620, loss: 0.002601414220407605
step: 630, loss: 3.0165443604346365e-05
step: 640, loss: 0.00017405567632522434
step: 650, loss: 1.726632035570219e-05
step: 660, loss: 2.701849371078424e-05
step: 670, loss: 7.49197497498244e-05
step: 680, loss: 8.07131509645842e-05
step: 690, loss: 1.001347027340671e-05
step: 700, loss: 2.2637621441390365e-05
step: 710, loss: 2.579892498033587e-05
step: 720, loss: 1.345557211607229e-05
step: 730, loss: 0.0012634895974770188
step: 740, loss: 0.00012436429096851498
step: 750, loss: 5.6690070778131485e-05
step: 760, loss: 0.00021346614812500775
step: 770, loss: 6.367368041537702e-05
step: 780, loss: 3.5769389796769246e-05
step: 790, loss: 4.035791789647192e-05
step: 800, loss: 0.00022574519971385598
step: 810, loss: 0.0005718103493563831
step: 820, loss: 0.0011239974992349744
step: 830, loss: 0.012046522460877895
step: 840, loss: 0.013106896542012691
step: 850, loss: 5.091533239465207e-05
step: 860, loss: 2.208289697591681e-05
step: 870, loss: 5.93898439547047e-05
step: 880, loss: 1.506849002907984e-05
step: 890, loss: 1.319462444371311e-05
step: 900, loss: 0.0019354780670255423
step: 910, loss: 8.452608199149836e-06
step: 920, loss: 3.1354447855846956e-05
step: 930, loss: 1.9691115085151978e-05
step: 940, loss: 3.48461871908512e-05
step: 950, loss: 2.5627805371186696e-05
step: 960, loss: 1.64392822625814e-05
step: 970, loss: 2.1937446945230477e-05
step: 980, loss: 1.9348644855199382e-05
step: 990, loss: 8.703923231223598e-05
step: 1000, loss: 2.743503137025982e-05
step: 1010, loss: 3.034332621609792e-05
step: 1020, loss: 2.341589060961269e-05
step: 1030, loss: 0.0001547229039715603
epoch 20: dev_f1=0.9476145930776427, f1=0.9275225011842728, best_f1=0.9220055710306406
