cuda
Device: cuda
step: 0, loss: 0.7059483528137207
step: 10, loss: 0.5188065767288208
step: 20, loss: 0.4751264452934265
step: 30, loss: 0.4451479911804199
step: 40, loss: 0.5320905447006226
step: 50, loss: 0.3196120858192444
step: 60, loss: 0.4890640079975128
step: 70, loss: 0.21737991273403168
step: 80, loss: 0.3577117919921875
step: 90, loss: 0.28470465540885925
step: 100, loss: 0.2490197718143463
step: 110, loss: 0.23914097249507904
step: 120, loss: 0.41511085629463196
step: 130, loss: 0.17487534880638123
step: 140, loss: 0.3115992248058319
step: 150, loss: 0.22602079808712006
step: 160, loss: 0.1815965175628662
step: 170, loss: 0.13741758465766907
step: 180, loss: 0.29627105593681335
step: 190, loss: 0.22635036706924438
step: 200, loss: 0.28518280386924744
step: 210, loss: 0.3162774443626404
step: 220, loss: 0.16884775459766388
step: 230, loss: 0.21475227177143097
step: 240, loss: 0.30410680174827576
step: 250, loss: 0.3030603229999542
step: 260, loss: 0.13601116836071014
step: 270, loss: 0.2511495351791382
step: 280, loss: 0.16155244410037994
step: 290, loss: 0.2287118285894394
step: 300, loss: 0.36734291911125183
step: 310, loss: 0.16986975073814392
step: 320, loss: 0.25812244415283203
step: 330, loss: 0.3975363075733185
step: 340, loss: 0.2750788629055023
step: 350, loss: 0.25295594334602356
step: 360, loss: 0.10617278516292572
step: 370, loss: 0.1679011434316635
step: 380, loss: 0.34660303592681885
step: 390, loss: 0.30610841512680054
step: 400, loss: 0.15627135336399078
step: 410, loss: 0.2616986334323883
step: 420, loss: 0.16941770911216736
step: 430, loss: 0.1185268834233284
step: 440, loss: 0.10989340394735336
step: 450, loss: 0.1817466914653778
step: 460, loss: 0.22740334272384644
step: 470, loss: 0.1930747777223587
step: 480, loss: 0.2076125591993332
step: 490, loss: 0.18660792708396912
step: 500, loss: 0.12349764257669449
step: 510, loss: 0.160765141248703
step: 520, loss: 0.24908365309238434
step: 530, loss: 0.17748460173606873
step: 540, loss: 0.2017698436975479
step: 550, loss: 0.09399164468050003
step: 560, loss: 0.13720007240772247
step: 570, loss: 0.192789226770401
step: 580, loss: 0.24541449546813965
step: 590, loss: 0.361816942691803
step: 600, loss: 0.19951331615447998
step: 610, loss: 0.2398599088191986
step: 620, loss: 0.37348082661628723
step: 630, loss: 0.2321484386920929
step: 640, loss: 0.2952640652656555
step: 650, loss: 0.20823238790035248
step: 660, loss: 0.5261982083320618
step: 670, loss: 0.11990644782781601
step: 680, loss: 0.02438744343817234
step: 690, loss: 0.18996219336986542
step: 700, loss: 0.2756253778934479
step: 710, loss: 0.19806233048439026
step: 720, loss: 0.20825845003128052
step: 730, loss: 0.03958045691251755
step: 740, loss: 0.22673633694648743
step: 750, loss: 0.1851729154586792
step: 760, loss: 0.20226623117923737
step: 770, loss: 0.13019925355911255
step: 780, loss: 0.14373713731765747
step: 790, loss: 0.1400166153907776
step: 800, loss: 0.19634924829006195
step: 810, loss: 0.08411460369825363
step: 820, loss: 0.17983271181583405
step: 830, loss: 0.31023967266082764
step: 840, loss: 0.1594206541776657
step: 850, loss: 0.15769371390342712
step: 860, loss: 0.5053808689117432
step: 870, loss: 0.251194566488266
step: 880, loss: 0.1433529555797577
step: 890, loss: 0.16008809208869934
step: 900, loss: 0.1692904829978943
step: 910, loss: 0.12432120740413666
step: 920, loss: 0.3260285556316376
step: 930, loss: 0.20712046325206757
step: 940, loss: 0.19627197086811066
step: 950, loss: 0.09408457577228546
step: 960, loss: 0.15553393959999084
step: 970, loss: 0.1993611752986908
step: 980, loss: 0.3999232351779938
step: 990, loss: 0.21456357836723328
step: 1000, loss: 0.09679196029901505
step: 1010, loss: 0.16541928052902222
step: 1020, loss: 0.12639260292053223
step: 1030, loss: 0.2813914120197296
step: 1040, loss: 0.18487003445625305
step: 1050, loss: 0.23868615925312042
step: 1060, loss: 0.3172058165073395
epoch 1: dev_f1=0.9404157043879908, f1=0.9262180974477957, best_f1=0.9262180974477957
step: 0, loss: 0.14379242062568665
step: 10, loss: 0.22827550768852234
step: 20, loss: 0.08511943370103836
step: 30, loss: 0.02962186187505722
step: 40, loss: 0.053679388016462326
step: 50, loss: 0.16941747069358826
step: 60, loss: 0.2754721939563751
step: 70, loss: 0.15949228405952454
step: 80, loss: 0.10828152298927307
step: 90, loss: 0.11238232254981995
step: 100, loss: 0.15158043801784515
step: 110, loss: 0.09067472070455551
step: 120, loss: 0.04326082393527031
step: 130, loss: 0.13681282103061676
step: 140, loss: 0.12449992448091507
step: 150, loss: 0.23154780268669128
step: 160, loss: 0.07545777410268784
step: 170, loss: 0.08451694250106812
step: 180, loss: 0.2374185174703598
step: 190, loss: 0.2891346514225006
step: 200, loss: 0.14771325886249542
step: 210, loss: 0.1058681532740593
step: 220, loss: 0.13247455656528473
step: 230, loss: 0.1965492218732834
step: 240, loss: 0.05214205011725426
step: 250, loss: 0.17470845580101013
step: 260, loss: 0.08498456329107285
step: 270, loss: 0.1425057351589203
step: 280, loss: 0.1470428854227066
step: 290, loss: 0.31934261322021484
step: 300, loss: 0.15262919664382935
step: 310, loss: 0.15543027222156525
step: 320, loss: 0.08346160501241684
step: 330, loss: 0.23887690901756287
step: 340, loss: 0.2549498677253723
step: 350, loss: 0.14768439531326294
step: 360, loss: 0.02602957934141159
step: 370, loss: 0.25757503509521484
step: 380, loss: 0.20737163722515106
step: 390, loss: 0.25115495920181274
step: 400, loss: 0.4581740200519562
step: 410, loss: 0.2596067190170288
step: 420, loss: 0.16366852819919586
step: 430, loss: 0.16121867299079895
step: 440, loss: 0.01899922639131546
step: 450, loss: 0.3566344678401947
step: 460, loss: 0.33700141310691833
step: 470, loss: 0.2850838899612427
step: 480, loss: 0.04804963991045952
step: 490, loss: 0.03759869933128357
step: 500, loss: 0.44080790877342224
step: 510, loss: 0.2377045750617981
step: 520, loss: 0.16670022904872894
step: 530, loss: 0.13321378827095032
step: 540, loss: 0.10625608265399933
step: 550, loss: 0.24046733975410461
step: 560, loss: 0.09678422659635544
step: 570, loss: 0.25307750701904297
step: 580, loss: 0.15086764097213745
step: 590, loss: 0.06295524537563324
step: 600, loss: 0.07041853666305542
step: 610, loss: 0.22672639787197113
step: 620, loss: 0.29223135113716125
step: 630, loss: 0.1456655114889145
step: 640, loss: 0.29142677783966064
step: 650, loss: 0.14389242231845856
step: 660, loss: 0.05261008441448212
step: 670, loss: 0.2626568675041199
step: 680, loss: 0.07256883382797241
step: 690, loss: 0.18328885734081268
step: 700, loss: 0.32375940680503845
step: 710, loss: 0.15075117349624634
step: 720, loss: 0.07742279767990112
step: 730, loss: 0.3372560739517212
step: 740, loss: 0.06129056215286255
step: 750, loss: 0.20074807107448578
step: 760, loss: 0.10411352664232254
step: 770, loss: 0.07178808748722076
step: 780, loss: 0.15625742077827454
step: 790, loss: 0.16214433312416077
step: 800, loss: 0.08983398228883743
step: 810, loss: 0.08183790743350983
step: 820, loss: 0.12065331637859344
step: 830, loss: 0.27980032563209534
step: 840, loss: 0.12761057913303375
step: 850, loss: 0.23987659811973572
step: 860, loss: 0.10560140013694763
step: 870, loss: 0.039116233587265015
step: 880, loss: 0.22575987875461578
step: 890, loss: 0.23062126338481903
step: 900, loss: 0.11042921245098114
step: 910, loss: 0.11813012510538101
step: 920, loss: 0.10882151871919632
step: 930, loss: 0.3376019597053528
step: 940, loss: 0.03460083156824112
step: 950, loss: 0.057904619723558426
step: 960, loss: 0.0449480302631855
step: 970, loss: 0.09700467437505722
step: 980, loss: 0.05385245382785797
step: 990, loss: 0.24735592305660248
step: 1000, loss: 0.19268903136253357
step: 1010, loss: 0.07486394047737122
step: 1020, loss: 0.14921385049819946
step: 1030, loss: 0.051127541810274124
step: 1040, loss: 0.10356529802083969
step: 1050, loss: 0.11976946890354156
step: 1060, loss: 0.021630486473441124
epoch 2: dev_f1=0.9514925373134329, f1=0.9307298930729893, best_f1=0.9307298930729893
step: 0, loss: 0.050892509520053864
step: 10, loss: 0.1524752527475357
step: 20, loss: 0.11775720119476318
step: 30, loss: 0.15963777899742126
step: 40, loss: 0.0956452265381813
step: 50, loss: 0.06021907553076744
step: 60, loss: 0.12095454335212708
step: 70, loss: 0.12357021868228912
step: 80, loss: 0.02846408076584339
step: 90, loss: 0.10274291783571243
step: 100, loss: 0.016296397894620895
step: 110, loss: 0.20956486463546753
step: 120, loss: 0.0700833797454834
step: 130, loss: 0.1045103594660759
step: 140, loss: 0.08082367479801178
step: 150, loss: 0.10713799297809601
step: 160, loss: 0.09973754733800888
step: 170, loss: 0.10476834326982498
step: 180, loss: 0.05462222173810005
step: 190, loss: 0.00510514248162508
step: 200, loss: 0.07451669126749039
step: 210, loss: 0.1540566235780716
step: 220, loss: 0.029741596430540085
step: 230, loss: 0.1889534592628479
step: 240, loss: 0.17835339903831482
step: 250, loss: 0.10842406749725342
step: 260, loss: 0.05856221541762352
step: 270, loss: 0.1296512335538864
step: 280, loss: 0.0746440440416336
step: 290, loss: 0.04931681975722313
step: 300, loss: 0.18788890540599823
step: 310, loss: 0.12437672913074493
step: 320, loss: 0.05273779109120369
step: 330, loss: 0.11027181148529053
step: 340, loss: 0.07634264975786209
step: 350, loss: 0.1163192167878151
step: 360, loss: 0.0430082231760025
step: 370, loss: 0.33505967259407043
step: 380, loss: 0.1368853747844696
step: 390, loss: 0.055400244891643524
step: 400, loss: 0.1513986885547638
step: 410, loss: 0.04830581694841385
step: 420, loss: 0.08976267278194427
step: 430, loss: 0.16216574609279633
step: 440, loss: 0.1158675029873848
step: 450, loss: 0.07785855978727341
step: 460, loss: 0.12068253010511398
step: 470, loss: 0.10809112340211868
step: 480, loss: 0.1378604918718338
step: 490, loss: 0.05087452381849289
step: 500, loss: 0.03769838809967041
step: 510, loss: 0.07220672816038132
step: 520, loss: 0.016954315826296806
step: 530, loss: 0.14630024135112762
step: 540, loss: 0.12233097851276398
step: 550, loss: 0.12642385065555573
step: 560, loss: 0.026282252743840218
step: 570, loss: 0.10089953243732452
step: 580, loss: 0.08211489021778107
step: 590, loss: 0.11573077738285065
step: 600, loss: 0.03463619947433472
step: 610, loss: 0.041352782398462296
step: 620, loss: 0.1266147792339325
step: 630, loss: 0.09005803614854813
step: 640, loss: 0.31431078910827637
step: 650, loss: 0.12803618609905243
step: 660, loss: 0.1972743570804596
step: 670, loss: 0.0934520736336708
step: 680, loss: 0.05405585467815399
step: 690, loss: 0.041857730597257614
step: 700, loss: 0.06376887857913971
step: 710, loss: 0.10400445014238358
step: 720, loss: 0.07724908739328384
step: 730, loss: 0.07770541310310364
step: 740, loss: 0.08071470260620117
step: 750, loss: 0.019635695964097977
step: 760, loss: 0.19423377513885498
step: 770, loss: 0.1421215683221817
step: 780, loss: 0.07237455248832703
step: 790, loss: 0.11840732395648956
step: 800, loss: 0.0383550226688385
step: 810, loss: 0.16550090909004211
step: 820, loss: 0.16446846723556519
step: 830, loss: 0.10956068336963654
step: 840, loss: 0.057515133172273636
step: 850, loss: 0.04734669253230095
step: 860, loss: 0.155432790517807
step: 870, loss: 0.1164441704750061
step: 880, loss: 0.2521946430206299
step: 890, loss: 0.028374986723065376
step: 900, loss: 0.15436042845249176
step: 910, loss: 0.11447682976722717
step: 920, loss: 0.13927331566810608
step: 930, loss: 0.1375333070755005
step: 940, loss: 0.20929163694381714
step: 950, loss: 0.0806894302368164
step: 960, loss: 0.4198066294193268
step: 970, loss: 0.08503230661153793
step: 980, loss: 0.05304374173283577
step: 990, loss: 0.057670917361974716
step: 1000, loss: 0.11274915933609009
step: 1010, loss: 0.03179597109556198
step: 1020, loss: 0.1606443226337433
step: 1030, loss: 0.046012815088033676
step: 1040, loss: 0.0722469612956047
step: 1050, loss: 0.020033804699778557
step: 1060, loss: 0.3310880959033966
epoch 3: dev_f1=0.9549218031278749, f1=0.9216417910447762, best_f1=0.9216417910447762
step: 0, loss: 0.044862497597932816
step: 10, loss: 0.0534517802298069
step: 20, loss: 0.018872849643230438
step: 30, loss: 0.24178868532180786
step: 40, loss: 0.03611933812499046
step: 50, loss: 0.030775154009461403
step: 60, loss: 0.02442092075943947
step: 70, loss: 0.12292909622192383
step: 80, loss: 0.1238286942243576
step: 90, loss: 0.03523680940270424
step: 100, loss: 0.15227679908275604
step: 110, loss: 0.044796839356422424
step: 120, loss: 0.05876300856471062
step: 130, loss: 0.007809850387275219
step: 140, loss: 0.08147551119327545
step: 150, loss: 0.12875165045261383
step: 160, loss: 0.312684565782547
step: 170, loss: 0.07360073179006577
step: 180, loss: 0.028990110382437706
step: 190, loss: 0.004960852675139904
step: 200, loss: 0.04645075276494026
step: 210, loss: 0.0736062228679657
step: 220, loss: 0.02468758635222912
step: 230, loss: 0.018045814707875252
step: 240, loss: 0.2509576082229614
step: 250, loss: 0.005430648569017649
step: 260, loss: 0.005369968246668577
step: 270, loss: 0.11811571568250656
step: 280, loss: 0.12479127198457718
step: 290, loss: 0.20221804082393646
step: 300, loss: 0.0861184224486351
step: 310, loss: 0.05226460099220276
step: 320, loss: 0.10855284333229065
step: 330, loss: 0.10610061138868332
step: 340, loss: 0.08562591671943665
step: 350, loss: 0.09135796129703522
step: 360, loss: 0.036934029310941696
step: 370, loss: 0.027004042640328407
step: 380, loss: 0.024911673739552498
step: 390, loss: 0.15020599961280823
step: 400, loss: 0.015621949918568134
step: 410, loss: 0.00508283032104373
step: 420, loss: 0.0538385733962059
step: 430, loss: 0.008153451606631279
step: 440, loss: 0.12726570665836334
step: 450, loss: 0.010518552735447884
step: 460, loss: 0.1728353500366211
step: 470, loss: 0.09144800901412964
step: 480, loss: 0.017615685239434242
step: 490, loss: 0.07580611854791641
step: 500, loss: 0.031698185950517654
step: 510, loss: 0.1111498549580574
step: 520, loss: 0.05350064858794212
step: 530, loss: 0.3925214409828186
step: 540, loss: 0.012091733515262604
step: 550, loss: 0.013622618280351162
step: 560, loss: 0.2270977795124054
step: 570, loss: 0.01382160373032093
step: 580, loss: 0.032501861453056335
step: 590, loss: 0.028792930766940117
step: 600, loss: 0.020746147260069847
step: 610, loss: 0.12956714630126953
step: 620, loss: 0.23829711973667145
step: 630, loss: 0.03540310263633728
step: 640, loss: 0.02978731319308281
step: 650, loss: 0.21172691881656647
step: 660, loss: 0.01570412889122963
step: 670, loss: 0.11004659533500671
step: 680, loss: 0.1045205146074295
step: 690, loss: 0.048212483525276184
step: 700, loss: 0.0868593379855156
step: 710, loss: 0.1415654420852661
step: 720, loss: 0.08425004780292511
step: 730, loss: 0.19462552666664124
step: 740, loss: 0.06572891771793365
step: 750, loss: 0.04119332134723663
step: 760, loss: 0.038111332803964615
step: 770, loss: 0.13945962488651276
step: 780, loss: 0.024906989187002182
step: 790, loss: 0.04811292514204979
step: 800, loss: 0.024529261514544487
step: 810, loss: 0.01964724063873291
step: 820, loss: 0.04212138429284096
step: 830, loss: 0.10465342551469803
step: 840, loss: 0.05364362150430679
step: 850, loss: 0.026800205931067467
step: 860, loss: 0.16494999825954437
step: 870, loss: 0.10937032848596573
step: 880, loss: 0.08058278262615204
step: 890, loss: 0.20489345490932465
step: 900, loss: 0.07795129716396332
step: 910, loss: 0.06362814456224442
step: 920, loss: 0.17868159711360931
step: 930, loss: 0.03888453170657158
step: 940, loss: 0.0803295224905014
step: 950, loss: 0.10314573347568512
step: 960, loss: 0.019724087789654732
step: 970, loss: 0.0835094153881073
step: 980, loss: 0.11563228815793991
step: 990, loss: 0.05019361525774002
step: 1000, loss: 0.22016362845897675
step: 1010, loss: 0.006266217678785324
step: 1020, loss: 0.030224746093153954
step: 1030, loss: 0.014974911697208881
step: 1040, loss: 0.011673437431454659
step: 1050, loss: 0.014940699562430382
step: 1060, loss: 0.006133562419563532
epoch 4: dev_f1=0.9466225791213982, f1=0.9182990922121358, best_f1=0.9216417910447762
step: 0, loss: 0.01941261626780033
step: 10, loss: 0.07234805077314377
step: 20, loss: 0.02259303629398346
step: 30, loss: 0.007312231697142124
step: 40, loss: 0.0030783680267632008
step: 50, loss: 0.010317589156329632
step: 60, loss: 0.05217108875513077
step: 70, loss: 0.025907931849360466
step: 80, loss: 0.024617433547973633
step: 90, loss: 0.008275758475065231
step: 100, loss: 0.03756260499358177
step: 110, loss: 0.03130039572715759
step: 120, loss: 0.06389676034450531
step: 130, loss: 0.07038450241088867
step: 140, loss: 0.025637459009885788
step: 150, loss: 0.1212230920791626
step: 160, loss: 0.2455441653728485
step: 170, loss: 0.011229549534618855
step: 180, loss: 0.011213164776563644
step: 190, loss: 0.02020678110420704
step: 200, loss: 0.0034117891918867826
step: 210, loss: 0.014002708718180656
step: 220, loss: 0.0025503309443593025
step: 230, loss: 0.013468344695866108
step: 240, loss: 0.020184241235256195
step: 250, loss: 0.002092452021315694
step: 260, loss: 0.13370198011398315
step: 270, loss: 0.052798207849264145
step: 280, loss: 0.22979101538658142
step: 290, loss: 0.00949004478752613
step: 300, loss: 0.013982328586280346
step: 310, loss: 0.00590058509260416
step: 320, loss: 0.055538348853588104
step: 330, loss: 0.044542744755744934
step: 340, loss: 0.19484981894493103
step: 350, loss: 0.020292486995458603
step: 360, loss: 0.07107479125261307
step: 370, loss: 0.009979075752198696
step: 380, loss: 0.005326906219124794
step: 390, loss: 0.0377156063914299
step: 400, loss: 0.04271214082837105
step: 410, loss: 0.15966252982616425
step: 420, loss: 0.0023184758611023426
step: 430, loss: 0.09716939181089401
step: 440, loss: 0.026107456535100937
step: 450, loss: 0.049911461770534515
step: 460, loss: 0.009602080099284649
step: 470, loss: 0.018281731754541397
step: 480, loss: 0.06860727071762085
step: 490, loss: 0.014043823815882206
step: 500, loss: 0.02767079509794712
step: 510, loss: 0.0045555937103927135
step: 520, loss: 0.08426668494939804
step: 530, loss: 0.20254194736480713
step: 540, loss: 0.12314719706773758
step: 550, loss: 0.03248288482427597
step: 560, loss: 0.0772712305188179
step: 570, loss: 0.0482303723692894
step: 580, loss: 0.012440740130841732
step: 590, loss: 0.007942667230963707
step: 600, loss: 0.00331172370351851
step: 610, loss: 0.014484013430774212
step: 620, loss: 0.00864673312753439
step: 630, loss: 0.017584756016731262
step: 640, loss: 0.02485574781894684
step: 650, loss: 0.05815362185239792
step: 660, loss: 0.03598525747656822
step: 670, loss: 0.17336209118366241
step: 680, loss: 0.1082862988114357
step: 690, loss: 0.015072179958224297
step: 700, loss: 0.15155942738056183
step: 710, loss: 0.04250737279653549
step: 720, loss: 0.003038241760805249
step: 730, loss: 0.023687751963734627
step: 740, loss: 0.09884894639253616
step: 750, loss: 0.07162556797266006
step: 760, loss: 0.0965423732995987
step: 770, loss: 0.008428026922047138
step: 780, loss: 0.03047666698694229
step: 790, loss: 0.01926703006029129
step: 800, loss: 0.03555586189031601
step: 810, loss: 0.06531017273664474
step: 820, loss: 0.06737785786390305
step: 830, loss: 0.02508438751101494
step: 840, loss: 0.01772206276655197
step: 850, loss: 0.12738756835460663
step: 860, loss: 0.08071693778038025
step: 870, loss: 0.0397413931787014
step: 880, loss: 0.01686692424118519
step: 890, loss: 0.08657531440258026
step: 900, loss: 0.050910353660583496
step: 910, loss: 0.08590137958526611
step: 920, loss: 0.09328949451446533
step: 930, loss: 0.0024159359745681286
step: 940, loss: 0.09873330593109131
step: 950, loss: 0.07358186691999435
step: 960, loss: 0.030740635469555855
step: 970, loss: 0.06823629140853882
step: 980, loss: 0.10641215741634369
step: 990, loss: 0.011270729824900627
step: 1000, loss: 0.0030500958673655987
step: 1010, loss: 0.019779779016971588
step: 1020, loss: 0.03190521523356438
step: 1030, loss: 0.06782954186201096
step: 1040, loss: 0.012348877266049385
step: 1050, loss: 0.00889748428016901
step: 1060, loss: 0.12049641460180283
epoch 5: dev_f1=0.9534450651769087, f1=0.926852288815479, best_f1=0.9216417910447762
step: 0, loss: 0.003019636729732156
step: 10, loss: 0.02641015127301216
step: 20, loss: 0.04287150502204895
step: 30, loss: 0.05020743981003761
step: 40, loss: 0.09695781767368317
step: 50, loss: 0.018049227073788643
step: 60, loss: 0.00596996583044529
step: 70, loss: 0.01893872208893299
step: 80, loss: 0.07012062519788742
step: 90, loss: 0.05219269543886185
step: 100, loss: 0.002882776316255331
step: 110, loss: 0.1924995481967926
step: 120, loss: 0.03412148356437683
step: 130, loss: 0.04719599336385727
step: 140, loss: 0.05104227736592293
step: 150, loss: 0.002678988268598914
step: 160, loss: 0.18274341523647308
step: 170, loss: 0.014657174237072468
step: 180, loss: 0.011277075856924057
step: 190, loss: 0.023640815168619156
step: 200, loss: 0.015266074799001217
step: 210, loss: 0.025644849985837936
step: 220, loss: 0.06923527270555496
step: 230, loss: 0.009396811947226524
step: 240, loss: 0.013414478860795498
step: 250, loss: 0.059499189257621765
step: 260, loss: 0.011037026531994343
step: 270, loss: 0.004426309373229742
step: 280, loss: 0.07211808860301971
step: 290, loss: 0.003567739389836788
step: 300, loss: 0.10797377675771713
step: 310, loss: 0.008121318183839321
step: 320, loss: 0.01973888650536537
step: 330, loss: 0.13874174654483795
step: 340, loss: 0.07575240731239319
step: 350, loss: 0.015097840689122677
step: 360, loss: 0.004745323210954666
step: 370, loss: 0.005116200540214777
step: 380, loss: 0.11668290942907333
step: 390, loss: 0.04589815437793732
step: 400, loss: 0.004406968131661415
step: 410, loss: 0.004848592448979616
step: 420, loss: 0.008605730719864368
step: 430, loss: 0.023876121267676353
step: 440, loss: 0.004384289029985666
step: 450, loss: 0.0022740585263818502
step: 460, loss: 0.030682845041155815
step: 470, loss: 0.003891068510711193
step: 480, loss: 0.04410236328840256
step: 490, loss: 0.009089690633118153
step: 500, loss: 0.0026230989024043083
step: 510, loss: 0.12497065961360931
step: 520, loss: 0.06810150295495987
step: 530, loss: 0.08292341977357864
step: 540, loss: 0.009656974114477634
step: 550, loss: 0.0435752309858799
step: 560, loss: 0.007672029547393322
step: 570, loss: 0.005970991216599941
step: 580, loss: 0.004132828209549189
step: 590, loss: 0.052601370960474014
step: 600, loss: 0.07574830949306488
step: 610, loss: 0.05671915039420128
step: 620, loss: 0.005024857819080353
step: 630, loss: 0.020060235634446144
step: 640, loss: 0.00152692012488842
step: 650, loss: 0.008429941721260548
step: 660, loss: 0.03842596337199211
step: 670, loss: 0.030065029859542847
step: 680, loss: 0.04635157436132431
step: 690, loss: 0.01690327189862728
step: 700, loss: 0.03710249438881874
step: 710, loss: 0.0071123517118394375
step: 720, loss: 0.016625836491584778
step: 730, loss: 0.01739056035876274
step: 740, loss: 0.029451526701450348
step: 750, loss: 0.1758594512939453
step: 760, loss: 0.08772759884595871
step: 770, loss: 0.0019656673539429903
step: 780, loss: 0.00910996738821268
step: 790, loss: 0.018035056069493294
step: 800, loss: 0.02000260166823864
step: 810, loss: 0.0061858282424509525
step: 820, loss: 0.01982988975942135
step: 830, loss: 0.0198164451867342
step: 840, loss: 0.020210839807987213
step: 850, loss: 0.006763187702745199
step: 860, loss: 0.020307738333940506
step: 870, loss: 0.006102677900344133
step: 880, loss: 0.01661594770848751
step: 890, loss: 0.010016178712248802
step: 900, loss: 0.0027066192124038935
step: 910, loss: 0.02375764586031437
step: 920, loss: 0.028982410207390785
step: 930, loss: 0.10244271904230118
step: 940, loss: 0.14416462182998657
step: 950, loss: 0.05501958355307579
step: 960, loss: 0.037636272609233856
step: 970, loss: 0.10441137105226517
step: 980, loss: 0.018303193151950836
step: 990, loss: 0.009609279222786427
step: 1000, loss: 0.025034649297595024
step: 1010, loss: 0.055444855242967606
step: 1020, loss: 0.003004352794960141
step: 1030, loss: 0.14006151258945465
step: 1040, loss: 0.04853425920009613
step: 1050, loss: 0.036819685250520706
step: 1060, loss: 0.036722179502248764
epoch 6: dev_f1=0.9521597770552717, f1=0.9353932584269663, best_f1=0.9216417910447762
step: 0, loss: 0.100631482899189
step: 10, loss: 0.00681912899017334
step: 20, loss: 0.02735498920083046
step: 30, loss: 0.004754642024636269
step: 40, loss: 0.06370154768228531
step: 50, loss: 0.0013959077186882496
step: 60, loss: 0.04048048332333565
step: 70, loss: 0.007342539727687836
step: 80, loss: 0.09917891025543213
step: 90, loss: 0.13348601758480072
step: 100, loss: 0.0009698175708763301
step: 110, loss: 0.01289855595678091
step: 120, loss: 0.037959784269332886
step: 130, loss: 0.0037502332124859095
step: 140, loss: 0.0877329409122467
step: 150, loss: 0.0006391087081283331
step: 160, loss: 0.004602574743330479
step: 170, loss: 0.044832248240709305
step: 180, loss: 0.013666315004229546
step: 190, loss: 0.00646549416705966
step: 200, loss: 0.001681269844993949
step: 210, loss: 0.013447439298033714
step: 220, loss: 0.0070527163334190845
step: 230, loss: 0.004592099227011204
step: 240, loss: 0.027571171522140503
step: 250, loss: 0.0005587033228948712
step: 260, loss: 0.015078825876116753
step: 270, loss: 0.035126905888319016
step: 280, loss: 0.009488957934081554
step: 290, loss: 0.002659623743966222
step: 300, loss: 0.03989153355360031
step: 310, loss: 0.1310669481754303
step: 320, loss: 0.09356694668531418
step: 330, loss: 0.006138280499726534
step: 340, loss: 0.07312493026256561
step: 350, loss: 0.021804187446832657
step: 360, loss: 0.03819722682237625
step: 370, loss: 0.009421279653906822
step: 380, loss: 0.02233637310564518
step: 390, loss: 0.06905592232942581
step: 400, loss: 0.0133027583360672
step: 410, loss: 0.005381821189075708
step: 420, loss: 0.05313199386000633
step: 430, loss: 0.1601748764514923
step: 440, loss: 0.19959107041358948
step: 450, loss: 0.0012827827595174313
step: 460, loss: 0.03237198293209076
step: 470, loss: 0.04775827005505562
step: 480, loss: 0.010691151022911072
step: 490, loss: 0.041768934577703476
step: 500, loss: 0.0028258285019546747
step: 510, loss: 0.08782990276813507
step: 520, loss: 0.000686917279381305
step: 530, loss: 0.02182711660861969
step: 540, loss: 0.010155425406992435
step: 550, loss: 0.004538295324891806
step: 560, loss: 0.022916842252016068
step: 570, loss: 0.0022793461102992296
step: 580, loss: 0.004771561361849308
step: 590, loss: 0.0038342636544257402
step: 600, loss: 0.0031255425419658422
step: 610, loss: 0.08281157165765762
step: 620, loss: 0.0024114400148391724
step: 630, loss: 0.005922956857830286
step: 640, loss: 0.003204076550900936
step: 650, loss: 0.005222512874752283
step: 660, loss: 0.0017378017073497176
step: 670, loss: 0.02854214422404766
step: 680, loss: 0.018626416102051735
step: 690, loss: 0.0011292013805359602
step: 700, loss: 0.014732662588357925
step: 710, loss: 0.031669970601797104
step: 720, loss: 0.014062132686376572
step: 730, loss: 0.09206964075565338
step: 740, loss: 0.0057450938038527966
step: 750, loss: 0.0678049623966217
step: 760, loss: 0.039468660950660706
step: 770, loss: 0.033532965928316116
step: 780, loss: 0.027589328587055206
step: 790, loss: 0.0626898854970932
step: 800, loss: 0.018979355692863464
step: 810, loss: 0.002635709010064602
step: 820, loss: 0.0011767949908971786
step: 830, loss: 0.011896926909685135
step: 840, loss: 0.08774230629205704
step: 850, loss: 0.009242507629096508
step: 860, loss: 0.05088688060641289
step: 870, loss: 0.03166768327355385
step: 880, loss: 0.05549418553709984
step: 890, loss: 0.0031041253823786974
step: 900, loss: 0.0038610058836638927
step: 910, loss: 0.01807054691016674
step: 920, loss: 0.02681352198123932
step: 930, loss: 0.002949730260297656
step: 940, loss: 0.0029773046262562275
step: 950, loss: 0.15520787239074707
step: 960, loss: 0.0010526617988944054
step: 970, loss: 0.06457839161157608
step: 980, loss: 0.010302201844751835
step: 990, loss: 0.008128306828439236
step: 1000, loss: 0.0016272231005132198
step: 1010, loss: 0.24161189794540405
step: 1020, loss: 0.03441397100687027
step: 1030, loss: 0.01610196940600872
step: 1040, loss: 0.0011075130896642804
step: 1050, loss: 0.002385696629062295
step: 1060, loss: 0.0007175783975981176
epoch 7: dev_f1=0.9489322191272052, f1=0.923581809657759, best_f1=0.9216417910447762
step: 0, loss: 0.018526820465922356
step: 10, loss: 0.019648415967822075
step: 20, loss: 0.01694585010409355
step: 30, loss: 0.01604481413960457
step: 40, loss: 0.014269218780100346
step: 50, loss: 0.001940529327839613
step: 60, loss: 0.023715823888778687
step: 70, loss: 0.14297954738140106
step: 80, loss: 0.043684739619493484
step: 90, loss: 0.05011070892214775
step: 100, loss: 0.0011345453094691038
step: 110, loss: 0.0043038721196353436
step: 120, loss: 0.011073451489210129
step: 130, loss: 0.01417227927595377
step: 140, loss: 0.021291663870215416
step: 150, loss: 0.0019044677028432488
step: 160, loss: 0.014796772040426731
step: 170, loss: 0.01858806051313877
step: 180, loss: 0.0005399935180321336
step: 190, loss: 0.10547339171171188
step: 200, loss: 0.06009764224290848
step: 210, loss: 0.0008741182973608375
step: 220, loss: 0.018082784488797188
step: 230, loss: 0.0009867019252851605
step: 240, loss: 0.0006937715806998312
step: 250, loss: 0.00288006872870028
step: 260, loss: 0.006794759538024664
step: 270, loss: 0.04501407593488693
step: 280, loss: 0.01035080011934042
step: 290, loss: 0.0004590900498442352
step: 300, loss: 0.004552988335490227
step: 310, loss: 0.000529131677467376
step: 320, loss: 0.003288703504949808
step: 330, loss: 0.034794121980667114
step: 340, loss: 0.02050093375146389
step: 350, loss: 0.11538874357938766
step: 360, loss: 0.011536512523889542
step: 370, loss: 0.04159042611718178
step: 380, loss: 0.0039698779582977295
step: 390, loss: 0.007612396497279406
step: 400, loss: 0.0007865560473874211
step: 410, loss: 0.009979147464036942
step: 420, loss: 0.008817572146654129
step: 430, loss: 0.00277837086468935
step: 440, loss: 0.0007706370088271797
step: 450, loss: 0.0006568481330759823
step: 460, loss: 0.0346369594335556
step: 470, loss: 0.004340962041169405
step: 480, loss: 0.009596935473382473
step: 490, loss: 0.1250319629907608
step: 500, loss: 0.0003825177263934165
step: 510, loss: 0.013068352825939655
step: 520, loss: 0.011149941943585873
step: 530, loss: 0.001954426756128669
step: 540, loss: 0.0028383859898895025
step: 550, loss: 0.027637997642159462
step: 560, loss: 0.01365335751324892
step: 570, loss: 0.0007763668545521796
step: 580, loss: 0.006339056883007288
step: 590, loss: 0.00040482572512701154
step: 600, loss: 0.00801956094801426
step: 610, loss: 0.07409609854221344
step: 620, loss: 0.002585339592769742
step: 630, loss: 0.0003230987349525094
step: 640, loss: 0.0013915249146521091
step: 650, loss: 0.004548444878309965
step: 660, loss: 0.0007689782069064677
step: 670, loss: 0.024005118757486343
step: 680, loss: 0.000913912255782634
step: 690, loss: 0.0012623949442058802
step: 700, loss: 0.004244781564921141
step: 710, loss: 0.009645204991102219
step: 720, loss: 0.008312197402119637
step: 730, loss: 0.002333474112674594
step: 740, loss: 0.004843400791287422
step: 750, loss: 0.0075844088569283485
step: 760, loss: 0.0018817365635186434
step: 770, loss: 0.0007835786673240364
step: 780, loss: 0.03997168689966202
step: 790, loss: 0.00503873685374856
step: 800, loss: 0.004745148122310638
step: 810, loss: 0.0732828825712204
step: 820, loss: 0.0001829975371947512
step: 830, loss: 0.00046987776295281947
step: 840, loss: 0.004115465562790632
step: 850, loss: 0.0014483931008726358
step: 860, loss: 0.003632214153185487
step: 870, loss: 0.07812715321779251
step: 880, loss: 0.011216406710445881
step: 890, loss: 0.02293311059474945
step: 900, loss: 0.01894913986325264
step: 910, loss: 0.0012364968424662948
step: 920, loss: 0.008636228740215302
step: 930, loss: 0.0017144327284768224
step: 940, loss: 0.0005492839845828712
step: 950, loss: 0.034961998462677
step: 960, loss: 0.0005458687082864344
step: 970, loss: 0.026762468740344048
step: 980, loss: 0.001583087956532836
step: 990, loss: 0.025230055674910545
step: 1000, loss: 0.0013106361730024219
step: 1010, loss: 0.001256166840903461
step: 1020, loss: 0.004381390754133463
step: 1030, loss: 0.00453248480334878
step: 1040, loss: 0.0005377228953875601
step: 1050, loss: 0.03756539896130562
step: 1060, loss: 0.0025183074176311493
epoch 8: dev_f1=0.955637707948244, f1=0.9266697804764129, best_f1=0.9266697804764129
step: 0, loss: 0.004241241607815027
step: 10, loss: 0.020132580772042274
step: 20, loss: 0.09911685436964035
step: 30, loss: 0.004857985302805901
step: 40, loss: 0.0035814004950225353
step: 50, loss: 0.0007219687104225159
step: 60, loss: 0.03273426741361618
step: 70, loss: 0.012283792719244957
step: 80, loss: 0.0012445786269381642
step: 90, loss: 0.002314697252586484
step: 100, loss: 0.004950303118675947
step: 110, loss: 0.03887725993990898
step: 120, loss: 0.004142429679632187
step: 130, loss: 0.005307735875248909
step: 140, loss: 0.04473893716931343
step: 150, loss: 0.0006458316347561777
step: 160, loss: 0.032899051904678345
step: 170, loss: 0.004205768462270498
step: 180, loss: 0.0009595828014425933
step: 190, loss: 0.0010995280463248491
step: 200, loss: 0.002393251284956932
step: 210, loss: 0.00045248508104123175
step: 220, loss: 0.0009318935335613787
step: 230, loss: 0.03553493320941925
step: 240, loss: 0.06413419544696808
step: 250, loss: 0.0009801924461498857
step: 260, loss: 0.003516151336953044
step: 270, loss: 0.06302538514137268
step: 280, loss: 0.09648063033819199
step: 290, loss: 0.008629580959677696
step: 300, loss: 0.006714900955557823
step: 310, loss: 0.0012201500358060002
step: 320, loss: 0.036463480442762375
step: 330, loss: 0.060216475278139114
step: 340, loss: 0.04862857609987259
step: 350, loss: 0.0051656984724104404
step: 360, loss: 0.026246454566717148
step: 370, loss: 0.00016873823187779635
step: 380, loss: 0.0017305274959653616
step: 390, loss: 0.002154603600502014
step: 400, loss: 0.016284646466374397
step: 410, loss: 0.0020338587928563356
step: 420, loss: 0.0016433300916105509
step: 430, loss: 0.04518057033419609
step: 440, loss: 0.01203951146453619
step: 450, loss: 0.04224957153201103
step: 460, loss: 0.0011299916077405214
step: 470, loss: 0.005256743170320988
step: 480, loss: 0.0524333231151104
step: 490, loss: 0.00023890020383987576
step: 500, loss: 0.0023736997973173857
step: 510, loss: 0.0003689291188493371
step: 520, loss: 0.0003205902758054435
step: 530, loss: 0.0030486329924315214
step: 540, loss: 0.0004183890123385936
step: 550, loss: 0.08931466937065125
step: 560, loss: 0.01589854247868061
step: 570, loss: 0.006389172747731209
step: 580, loss: 0.012680145911872387
step: 590, loss: 0.002029074588790536
step: 600, loss: 0.0004132633039262146
step: 610, loss: 0.023423729464411736
step: 620, loss: 0.0004374752170406282
step: 630, loss: 0.0006497339927591383
step: 640, loss: 0.03214036300778389
step: 650, loss: 0.0004156676877755672
step: 660, loss: 0.010762200690805912
step: 670, loss: 0.0017573327058926225
step: 680, loss: 0.001543455757200718
step: 690, loss: 0.006331142969429493
step: 700, loss: 0.022747503593564034
step: 710, loss: 0.1341148465871811
step: 720, loss: 0.0021651475690305233
step: 730, loss: 0.0018146556103602052
step: 740, loss: 0.0003459092404227704
step: 750, loss: 0.026028785854578018
step: 760, loss: 0.019320173189044
step: 770, loss: 0.0045188721269369125
step: 780, loss: 0.06953129172325134
step: 790, loss: 0.02620868757367134
step: 800, loss: 0.028197646141052246
step: 810, loss: 0.030119741335511208
step: 820, loss: 0.06950018554925919
step: 830, loss: 0.0003029639774467796
step: 840, loss: 0.0055780187249183655
step: 850, loss: 0.00041882717050611973
step: 860, loss: 0.04745286703109741
step: 870, loss: 0.034478332847356796
step: 880, loss: 0.006064197048544884
step: 890, loss: 0.021965429186820984
step: 900, loss: 0.00020526829757727683
step: 910, loss: 0.001779013779014349
step: 920, loss: 0.002047001849859953
step: 930, loss: 0.0009695690823718905
step: 940, loss: 0.008458494208753109
step: 950, loss: 0.00040273877675645053
step: 960, loss: 0.0006355090881697834
step: 970, loss: 0.016414286568760872
step: 980, loss: 9.822625725064427e-05
step: 990, loss: 0.003531850641593337
step: 1000, loss: 0.04283373802900314
step: 1010, loss: 0.03719890117645264
step: 1020, loss: 0.012227284722030163
step: 1030, loss: 0.0015236128820106387
step: 1040, loss: 0.07703061401844025
step: 1050, loss: 0.06481961160898209
step: 1060, loss: 0.004590642638504505
epoch 9: dev_f1=0.9500233535730968, f1=0.9235880398671096, best_f1=0.9266697804764129
step: 0, loss: 0.0003767767339013517
step: 10, loss: 0.007192910183221102
step: 20, loss: 0.0002837269566953182
step: 30, loss: 0.006906175520271063
step: 40, loss: 0.0012278055073693395
step: 50, loss: 0.0006391015485860407
step: 60, loss: 0.0008596155093982816
step: 70, loss: 0.0009430696372874081
step: 80, loss: 0.005931708496063948
step: 90, loss: 0.007746959570795298
step: 100, loss: 0.0069324360229074955
step: 110, loss: 0.007901531644165516
step: 120, loss: 0.003013035049661994
step: 130, loss: 0.013681337237358093
step: 140, loss: 0.09435627609491348
step: 150, loss: 0.0023554088547825813
step: 160, loss: 0.020198320969939232
step: 170, loss: 0.00018813871429301798
step: 180, loss: 0.0012705584522336721
step: 190, loss: 0.0012472789967432618
step: 200, loss: 0.006070414558053017
step: 210, loss: 0.0036881607957184315
step: 220, loss: 0.01192341186106205
step: 230, loss: 0.01814557984471321
step: 240, loss: 0.0037346696481108665
step: 250, loss: 0.01607273519039154
step: 260, loss: 0.007330009713768959
step: 270, loss: 0.003633007640019059
step: 280, loss: 0.0012725309934467077
step: 290, loss: 0.015353288501501083
step: 300, loss: 0.00104843161534518
step: 310, loss: 0.03989618271589279
step: 320, loss: 0.0001891666470328346
step: 330, loss: 0.00027116286219097674
step: 340, loss: 0.00010661334817996249
step: 350, loss: 0.123066745698452
step: 360, loss: 5.612263339571655e-05
step: 370, loss: 0.023403529077768326
step: 380, loss: 0.00016526642139069736
step: 390, loss: 0.0003167683316860348
step: 400, loss: 0.0006829783087596297
step: 410, loss: 0.03147926554083824
step: 420, loss: 0.0005644714692607522
step: 430, loss: 0.1825457513332367
step: 440, loss: 0.0005370330181904137
step: 450, loss: 0.00031956876046024263
step: 460, loss: 0.007043788209557533
step: 470, loss: 0.00044876764877699316
step: 480, loss: 0.001043509691953659
step: 490, loss: 0.01057053729891777
step: 500, loss: 0.00025647087022662163
step: 510, loss: 0.0003785598382819444
step: 520, loss: 0.020457904785871506
step: 530, loss: 0.08871147036552429
step: 540, loss: 0.005301888100802898
step: 550, loss: 0.0023855462204664946
step: 560, loss: 0.001157112536020577
step: 570, loss: 0.0002504412841517478
step: 580, loss: 0.003106188727542758
step: 590, loss: 0.002696170937269926
step: 600, loss: 0.006762581877410412
step: 610, loss: 0.07102970033884048
step: 620, loss: 0.0002117469412041828
step: 630, loss: 0.0004563668044283986
step: 640, loss: 0.001702817971818149
step: 650, loss: 0.0032243712339550257
step: 660, loss: 0.004896975588053465
step: 670, loss: 0.00021835407824255526
step: 680, loss: 0.0006570856785401702
step: 690, loss: 0.0005191604141145945
step: 700, loss: 0.12036893516778946
step: 710, loss: 0.00214383308775723
step: 720, loss: 0.0658491775393486
step: 730, loss: 0.00025029544485732913
step: 740, loss: 0.004634368699043989
step: 750, loss: 0.10619359463453293
step: 760, loss: 0.0014698341256007552
step: 770, loss: 0.0002721864148043096
step: 780, loss: 0.00014937225205358118
step: 790, loss: 0.0005318679613992572
step: 800, loss: 0.0006310734897851944
step: 810, loss: 0.0004060048668179661
step: 820, loss: 0.035404931753873825
step: 830, loss: 5.5889620853122324e-05
step: 840, loss: 0.00556245818734169
step: 850, loss: 0.01078704185783863
step: 860, loss: 0.007567172404378653
step: 870, loss: 0.001221087877638638
step: 880, loss: 0.003393049817532301
step: 890, loss: 0.0014153476804494858
step: 900, loss: 0.0015578547026962042
step: 910, loss: 0.04799085110425949
step: 920, loss: 0.006680020596832037
step: 930, loss: 0.004955550655722618
step: 940, loss: 0.00026374857407063246
step: 950, loss: 0.0008339708438143134
step: 960, loss: 0.004577682353556156
step: 970, loss: 0.027655161917209625
step: 980, loss: 0.0003819000266958028
step: 990, loss: 0.005101623013615608
step: 1000, loss: 0.0004532530147116631
step: 1010, loss: 0.010184770449995995
step: 1020, loss: 0.0008524964214302599
step: 1030, loss: 0.0009476877748966217
step: 1040, loss: 0.00030688897822983563
step: 1050, loss: 0.0015950171509757638
step: 1060, loss: 0.0019125681137666106
epoch 10: dev_f1=0.951501154734411, f1=0.9312119794103885, best_f1=0.9266697804764129
step: 0, loss: 0.0002132264053216204
step: 10, loss: 0.0005729644908569753
step: 20, loss: 0.07126640528440475
step: 30, loss: 0.12487683445215225
step: 40, loss: 0.0018802967388182878
step: 50, loss: 0.003190194256603718
step: 60, loss: 0.03260340541601181
step: 70, loss: 0.1545756310224533
step: 80, loss: 0.002532120095565915
step: 90, loss: 0.022050149738788605
step: 100, loss: 0.002617079997435212
step: 110, loss: 0.001487521454691887
step: 120, loss: 0.01968761347234249
step: 130, loss: 0.010368538089096546
step: 140, loss: 0.009872881695628166
step: 150, loss: 0.001657022861763835
step: 160, loss: 0.02258244715631008
step: 170, loss: 0.0020940182730555534
step: 180, loss: 0.0010335164843127131
step: 190, loss: 0.010664989240467548
step: 200, loss: 0.009469177573919296
step: 210, loss: 0.0017491172766312957
step: 220, loss: 0.00025800353614613414
step: 230, loss: 0.00023778685135766864
step: 240, loss: 0.0004108974535483867
step: 250, loss: 0.029980584979057312
step: 260, loss: 0.00034166689147241414
step: 270, loss: 0.018083559349179268
step: 280, loss: 0.09284115582704544
step: 290, loss: 0.026124795898795128
step: 300, loss: 0.00533852307125926
step: 310, loss: 0.026087380945682526
step: 320, loss: 6.416968972189352e-05
step: 330, loss: 0.00044210933265276253
step: 340, loss: 0.00792793557047844
step: 350, loss: 0.002102811587974429
step: 360, loss: 0.0004486037069000304
step: 370, loss: 0.001188239548355341
step: 380, loss: 0.043095942586660385
step: 390, loss: 0.08751092106103897
step: 400, loss: 0.0002144193567801267
step: 410, loss: 0.0008060079999268055
step: 420, loss: 0.0006766098667867482
step: 430, loss: 0.028801966458559036
step: 440, loss: 0.0008899529348127544
step: 450, loss: 0.000786312622949481
step: 460, loss: 0.00022386670752894133
step: 470, loss: 0.0010144466068595648
step: 480, loss: 0.00013055810995865613
step: 490, loss: 0.008881025947630405
step: 500, loss: 0.001011111307889223
step: 510, loss: 0.032632265239953995
step: 520, loss: 0.07598647475242615
step: 530, loss: 0.017959075048565865
step: 540, loss: 0.007296256721019745
step: 550, loss: 0.0008433679467998445
step: 560, loss: 0.006870354991406202
step: 570, loss: 0.0004230220802128315
step: 580, loss: 0.00017453743203077465
step: 590, loss: 0.0015972392866387963
step: 600, loss: 0.0011092161294072866
step: 610, loss: 0.0023902731481939554
step: 620, loss: 0.00286102551035583
step: 630, loss: 0.0316319465637207
step: 640, loss: 0.0011673421831801534
step: 650, loss: 0.01695730723440647
step: 660, loss: 0.029870830476284027
step: 670, loss: 0.002138070994988084
step: 680, loss: 0.001389084616675973
step: 690, loss: 0.0004739401047118008
step: 700, loss: 0.0003987194213550538
step: 710, loss: 7.020769407972693e-05
step: 720, loss: 0.044286470860242844
step: 730, loss: 0.0016269417246803641
step: 740, loss: 0.0026387725956737995
step: 750, loss: 0.00014922501577530056
step: 760, loss: 0.0059531740844249725
step: 770, loss: 0.007411590311676264
step: 780, loss: 0.0010151345049962401
step: 790, loss: 0.0002561445871833712
step: 800, loss: 0.00047302572056651115
step: 810, loss: 9.242442320100963e-05
step: 820, loss: 0.00019760557916015387
step: 830, loss: 0.007846255786716938
step: 840, loss: 0.0016058501787483692
step: 850, loss: 0.000187804049346596
step: 860, loss: 0.024770069867372513
step: 870, loss: 0.00010967819252982736
step: 880, loss: 0.00012439634883776307
step: 890, loss: 0.05138641968369484
step: 900, loss: 0.020530950278043747
step: 910, loss: 0.0258791446685791
step: 920, loss: 0.0008822199306450784
step: 930, loss: 0.00022325808822643012
step: 940, loss: 0.0001651189522817731
step: 950, loss: 0.037896085530519485
step: 960, loss: 0.0019846062641590834
step: 970, loss: 0.025254828855395317
step: 980, loss: 0.00011326071398798376
step: 990, loss: 0.08796955645084381
step: 1000, loss: 0.009516841731965542
step: 1010, loss: 0.001373832579702139
step: 1020, loss: 0.0009179920889437199
step: 1030, loss: 0.010094862431287766
step: 1040, loss: 0.003040521638467908
step: 1050, loss: 0.0003565007646102458
step: 1060, loss: 9.313313057646155e-05
epoch 11: dev_f1=0.9512308406874129, f1=0.9198868991517437, best_f1=0.9266697804764129
step: 0, loss: 8.356280159205198e-05
step: 10, loss: 0.020952152088284492
step: 20, loss: 0.07877292484045029
step: 30, loss: 0.0019536721520125866
step: 40, loss: 0.00017438105714973062
step: 50, loss: 0.01709037274122238
step: 60, loss: 0.000572858436498791
step: 70, loss: 0.00770009309053421
step: 80, loss: 0.0020323803182691336
step: 90, loss: 0.0008756226161494851
step: 100, loss: 0.0001394252321915701
step: 110, loss: 0.0006342497654259205
step: 120, loss: 0.0008034928468987346
step: 130, loss: 0.0017720169853419065
step: 140, loss: 0.00022274682123679668
step: 150, loss: 0.0003810133202932775
step: 160, loss: 0.0016764418687671423
step: 170, loss: 0.0005084253498353064
step: 180, loss: 8.982099825516343e-05
step: 190, loss: 6.189689156599343e-05
step: 200, loss: 0.05462260544300079
step: 210, loss: 0.02794252522289753
step: 220, loss: 0.0007407700759358704
step: 230, loss: 0.00026783387875184417
step: 240, loss: 0.026801083236932755
step: 250, loss: 5.166903792996891e-05
step: 260, loss: 0.002146549755707383
step: 270, loss: 0.00048825202975422144
step: 280, loss: 9.434384264750406e-05
step: 290, loss: 0.00020344293443486094
step: 300, loss: 0.01666337251663208
step: 310, loss: 0.0016276226378977299
step: 320, loss: 0.0005958872498013079
step: 330, loss: 0.00302042905241251
step: 340, loss: 0.0023551953490823507
step: 350, loss: 0.00010564881813479587
step: 360, loss: 0.00012841098941862583
step: 370, loss: 0.0020395112223923206
step: 380, loss: 0.0027692688163369894
step: 390, loss: 0.0005097477696835995
step: 400, loss: 0.01046366523951292
step: 410, loss: 0.04541411250829697
step: 420, loss: 0.00016574196342844516
step: 430, loss: 0.0011538773542270064
step: 440, loss: 0.00012649237760342658
step: 450, loss: 0.005617892369627953
step: 460, loss: 0.01126827858388424
step: 470, loss: 0.0001858747418737039
step: 480, loss: 0.0011184533359482884
step: 490, loss: 0.0005257112206891179
step: 500, loss: 0.00047521316446363926
step: 510, loss: 0.00012810633052140474
step: 520, loss: 0.0002452237531542778
step: 530, loss: 0.00014250677486415952
step: 540, loss: 6.150306580821052e-05
step: 550, loss: 0.0012072573881596327
step: 560, loss: 5.4721076594432816e-05
step: 570, loss: 0.00010388425289420411
step: 580, loss: 0.0034457033034414053
step: 590, loss: 0.0004946854896843433
step: 600, loss: 0.009876707568764687
step: 610, loss: 0.009179855696856976
step: 620, loss: 0.0002138743147952482
step: 630, loss: 0.003708393545821309
step: 640, loss: 0.0005534758092835546
step: 650, loss: 0.009543315507471561
step: 660, loss: 4.07196712330915e-05
step: 670, loss: 7.116772030713037e-05
step: 680, loss: 0.00020367275283206254
step: 690, loss: 0.00036652947892434895
step: 700, loss: 0.0004831473925150931
step: 710, loss: 0.00020628773199860007
step: 720, loss: 0.0001542571553727612
step: 730, loss: 7.421131158480421e-05
step: 740, loss: 0.00022499600891023874
step: 750, loss: 0.030643701553344727
step: 760, loss: 0.00030568617512471974
step: 770, loss: 0.0008375539910048246
step: 780, loss: 0.00011729035031748936
step: 790, loss: 0.0013747254852205515
step: 800, loss: 8.152276132022962e-05
step: 810, loss: 0.00012558184971567243
step: 820, loss: 0.04208454117178917
step: 830, loss: 0.0005377323250286281
step: 840, loss: 0.0023697237484157085
step: 850, loss: 0.0002797909255605191
step: 860, loss: 0.004222884774208069
step: 870, loss: 0.0002456718357279897
step: 880, loss: 0.0008876440697349608
step: 890, loss: 0.010955892503261566
step: 900, loss: 0.0006174558075144887
step: 910, loss: 0.0002716517192311585
step: 920, loss: 0.0028958688490092754
step: 930, loss: 0.02922426350414753
step: 940, loss: 0.0001921655930345878
step: 950, loss: 0.025176510214805603
step: 960, loss: 0.004002389498054981
step: 970, loss: 0.004987788386642933
step: 980, loss: 0.0008627300849184394
step: 990, loss: 0.003743403824046254
step: 1000, loss: 0.0003187545808032155
step: 1010, loss: 0.023469170555472374
step: 1020, loss: 0.0001626217708690092
step: 1030, loss: 0.00446636788547039
step: 1040, loss: 0.0034823680762201548
step: 1050, loss: 0.0010905573144555092
step: 1060, loss: 0.025900505483150482
epoch 12: dev_f1=0.9509713228492137, f1=0.9312762973352035, best_f1=0.9266697804764129
step: 0, loss: 0.002891374286264181
step: 10, loss: 0.015410175547003746
step: 20, loss: 0.007407298311591148
step: 30, loss: 0.00037196584162302315
step: 40, loss: 0.0006462426390498877
step: 50, loss: 0.00019193990738131106
step: 60, loss: 0.00046111916890367866
step: 70, loss: 0.0001050587889039889
step: 80, loss: 0.0008958327816799283
step: 90, loss: 0.010797387920320034
step: 100, loss: 0.00035951094469055533
step: 110, loss: 0.0039296746253967285
step: 120, loss: 0.0012634128797799349
step: 130, loss: 0.0015204313676804304
step: 140, loss: 0.001460650353692472
step: 150, loss: 0.00032384711084887385
step: 160, loss: 0.001618743990547955
step: 170, loss: 9.174219303531572e-05
step: 180, loss: 0.0005154976388439536
step: 190, loss: 0.0014972998760640621
step: 200, loss: 0.00032698953873477876
step: 210, loss: 0.00010458759061293676
step: 220, loss: 0.0004020596679765731
step: 230, loss: 0.0018506550695747137
step: 240, loss: 0.0005615862901322544
step: 250, loss: 0.00025962540530599654
step: 260, loss: 0.0008648593793623149
step: 270, loss: 6.739867239957675e-05
step: 280, loss: 0.001671915058977902
step: 290, loss: 0.030520735308527946
step: 300, loss: 8.536235691281036e-05
step: 310, loss: 0.0003354215295985341
step: 320, loss: 0.0032699594739824533
step: 330, loss: 0.010095415636897087
step: 340, loss: 0.00010162895341636613
step: 350, loss: 0.0024343160912394524
step: 360, loss: 0.0024250149726867676
step: 370, loss: 4.763953256770037e-05
step: 380, loss: 0.0015712372260168195
step: 390, loss: 0.00022816238924860954
step: 400, loss: 0.04266566038131714
step: 410, loss: 0.00023499393137171865
step: 420, loss: 0.00024863186990842223
step: 430, loss: 0.0002010002644965425
step: 440, loss: 3.976143125328235e-05
step: 450, loss: 5.023766425438225e-05
step: 460, loss: 0.030636459589004517
step: 470, loss: 0.0008757179020904005
step: 480, loss: 0.01553237996995449
step: 490, loss: 0.0005910019972361624
step: 500, loss: 0.0009820477571338415
step: 510, loss: 0.00015296287892851979
step: 520, loss: 0.0006758601521141827
step: 530, loss: 0.00018683997041080147
step: 540, loss: 0.00986647792160511
step: 550, loss: 0.0001593276101630181
step: 560, loss: 0.0008942118147388101
step: 570, loss: 0.0014839222421869636
step: 580, loss: 0.0001275544345844537
step: 590, loss: 0.00010811071115313098
step: 600, loss: 0.00014411527081392705
step: 610, loss: 0.0002172694366890937
step: 620, loss: 0.009614667855203152
step: 630, loss: 0.00037466647336259484
step: 640, loss: 0.033508192747831345
step: 650, loss: 0.00014972097415011376
step: 660, loss: 0.006822545547038317
step: 670, loss: 0.00010666462912922725
step: 680, loss: 0.0028582634404301643
step: 690, loss: 0.00014781535719521344
step: 700, loss: 0.0008789215935394168
step: 710, loss: 0.00417299522086978
step: 720, loss: 5.100603084429167e-05
step: 730, loss: 0.00018039729911834002
step: 740, loss: 0.00024115617270581424
step: 750, loss: 0.0003530769026838243
step: 760, loss: 0.0010565865086391568
step: 770, loss: 0.0003230363945476711
step: 780, loss: 0.0025077927857637405
step: 790, loss: 0.00017666663916315883
step: 800, loss: 0.00044295264524407685
step: 810, loss: 0.00023202566080726683
step: 820, loss: 0.00012901889567729086
step: 830, loss: 0.06386955827474594
step: 840, loss: 0.0004999471129849553
step: 850, loss: 0.04150448366999626
step: 860, loss: 0.10821636766195297
step: 870, loss: 0.006160444114357233
step: 880, loss: 0.012289853766560555
step: 890, loss: 0.00018254629685543478
step: 900, loss: 0.0005999336135573685
step: 910, loss: 0.01622837781906128
step: 920, loss: 0.0020735443104058504
step: 930, loss: 0.007718889508396387
step: 940, loss: 0.0019558467902243137
step: 950, loss: 0.0001313433749601245
step: 960, loss: 0.009225314483046532
step: 970, loss: 0.0030246207024902105
step: 980, loss: 0.0005609994404949248
step: 990, loss: 0.00028425094205886126
step: 1000, loss: 0.0012429561465978622
step: 1010, loss: 0.00018866898608393967
step: 1020, loss: 0.0029221621807664633
step: 1030, loss: 0.014940478838980198
step: 1040, loss: 0.05750535801053047
step: 1050, loss: 3.233003371860832e-05
step: 1060, loss: 0.0012324504787102342
epoch 13: dev_f1=0.9496535796766744, f1=0.9265325222274216, best_f1=0.9266697804764129
step: 0, loss: 0.007490863092243671
step: 10, loss: 0.007289455272257328
step: 20, loss: 0.0001989621523534879
step: 30, loss: 0.00629142951220274
step: 40, loss: 0.0002960595884360373
step: 50, loss: 0.00019763768068514764
step: 60, loss: 0.0013423273339867592
step: 70, loss: 0.00028055792790837586
step: 80, loss: 0.019782420247793198
step: 90, loss: 0.019539494067430496
step: 100, loss: 0.0014531926717609167
step: 110, loss: 0.00012994326243642718
step: 120, loss: 8.782635995885357e-05
step: 130, loss: 5.862939724465832e-05
step: 140, loss: 0.004558302462100983
step: 150, loss: 0.0013614424970000982
step: 160, loss: 0.007699558045715094
step: 170, loss: 0.0015263408422470093
step: 180, loss: 0.0008027604781091213
step: 190, loss: 0.024574989452958107
step: 200, loss: 3.171875505358912e-05
step: 210, loss: 0.00036686364910565317
step: 220, loss: 0.0006514438427984715
step: 230, loss: 0.0004262830188963562
step: 240, loss: 6.352489435812458e-05
step: 250, loss: 0.002406414831057191
step: 260, loss: 4.1331120883114636e-05
step: 270, loss: 0.009511230513453484
step: 280, loss: 0.002028955379500985
step: 290, loss: 0.00038140115793794394
step: 300, loss: 3.949617894249968e-05
step: 310, loss: 7.464413647539914e-05
step: 320, loss: 0.0019222212722525
step: 330, loss: 0.0012897152919322252
step: 340, loss: 0.0037834872491657734
step: 350, loss: 0.0005245031788945198
step: 360, loss: 0.0007857658783905208
step: 370, loss: 0.0002176168782170862
step: 380, loss: 4.316562262829393e-05
step: 390, loss: 0.0016797686694189906
step: 400, loss: 0.1824878305196762
step: 410, loss: 0.008987020701169968
step: 420, loss: 0.002147440332919359
step: 430, loss: 0.00018661147623788565
step: 440, loss: 0.0004328282957430929
step: 450, loss: 0.0017613408854231238
step: 460, loss: 0.0017823673551902175
step: 470, loss: 0.001932508428581059
step: 480, loss: 0.0037999050691723824
step: 490, loss: 3.466161069809459e-05
step: 500, loss: 5.5452816013712436e-05
step: 510, loss: 0.009255477227270603
step: 520, loss: 0.03051180951297283
step: 530, loss: 0.0002242241462226957
step: 540, loss: 0.0005781567888334394
step: 550, loss: 0.0002344305394217372
step: 560, loss: 0.003875268157571554
step: 570, loss: 0.0007264624000526965
step: 580, loss: 7.835552241886035e-05
step: 590, loss: 0.01779879257082939
step: 600, loss: 0.007250605616718531
step: 610, loss: 0.00042577978456392884
step: 620, loss: 4.720556898973882e-05
step: 630, loss: 0.058571308851242065
step: 640, loss: 7.793372788000852e-05
step: 650, loss: 0.007965920493006706
step: 660, loss: 5.1333652663743123e-05
step: 670, loss: 0.00011128951155114919
step: 680, loss: 0.00021676548931282014
step: 690, loss: 0.0003586783423088491
step: 700, loss: 0.00028005975764244795
step: 710, loss: 3.175677920808084e-05
step: 720, loss: 0.004073054529726505
step: 730, loss: 0.012175490148365498
step: 740, loss: 0.001608450897037983
step: 750, loss: 0.00046122391358949244
step: 760, loss: 0.0011421663220971823
step: 770, loss: 0.00025457204901613295
step: 780, loss: 0.000385025457944721
step: 790, loss: 6.0328264225972816e-05
step: 800, loss: 0.047609951347112656
step: 810, loss: 7.593940244987607e-05
step: 820, loss: 0.001773759489879012
step: 830, loss: 2.9015387553954497e-05
step: 840, loss: 0.001667901873588562
step: 850, loss: 0.00010381660104030743
step: 860, loss: 0.00018942030146718025
step: 870, loss: 8.419212826993316e-05
step: 880, loss: 0.017887121066451073
step: 890, loss: 0.00018281387747265399
step: 900, loss: 0.006840979214757681
step: 910, loss: 0.00027935561956837773
step: 920, loss: 0.008637464605271816
step: 930, loss: 0.00034185938420705497
step: 940, loss: 4.764913683175109e-05
step: 950, loss: 0.0003833344380836934
step: 960, loss: 0.00033164460910484195
step: 970, loss: 5.419419539975934e-05
step: 980, loss: 6.648517592111602e-05
step: 990, loss: 0.011479336768388748
step: 1000, loss: 6.456501432694495e-05
step: 1010, loss: 0.00011502442066557705
step: 1020, loss: 0.0002147353661712259
step: 1030, loss: 6.489159568445757e-05
step: 1040, loss: 6.123375351307914e-05
step: 1050, loss: 0.0003103730268776417
step: 1060, loss: 5.725093433284201e-05
epoch 14: dev_f1=0.9523809523809524, f1=0.9313680331644404, best_f1=0.9266697804764129
step: 0, loss: 0.0006364209111779928
step: 10, loss: 8.042405534069985e-05
step: 20, loss: 0.0001437102328054607
step: 30, loss: 0.0001591037434991449
step: 40, loss: 0.0023691682144999504
step: 50, loss: 0.00015683163655921817
step: 60, loss: 0.0002935313677880913
step: 70, loss: 0.024812476709485054
step: 80, loss: 0.00026775934384204447
step: 90, loss: 0.0009721738169901073
step: 100, loss: 0.0006693742470815778
step: 110, loss: 0.0034781238064169884
step: 120, loss: 5.972639701212756e-05
step: 130, loss: 9.22629697015509e-05
step: 140, loss: 0.00015901660663075745
step: 150, loss: 0.013090244494378567
step: 160, loss: 0.0023151838686317205
step: 170, loss: 0.0025836043059825897
step: 180, loss: 5.6878870964283124e-05
step: 190, loss: 0.001151342410594225
step: 200, loss: 0.00035285335616208613
step: 210, loss: 0.0038311316166073084
step: 220, loss: 7.9342644312419e-05
step: 230, loss: 7.820942846592516e-05
step: 240, loss: 0.00029010692378506064
step: 250, loss: 0.00788151379674673
step: 260, loss: 0.019719423726201057
step: 270, loss: 6.542828486999497e-05
step: 280, loss: 4.705715400632471e-05
step: 290, loss: 0.011503110639750957
step: 300, loss: 4.322848326410167e-05
step: 310, loss: 0.0004364968044683337
step: 320, loss: 0.015637153759598732
step: 330, loss: 0.00019561559020075947
step: 340, loss: 5.7501278206473216e-05
step: 350, loss: 0.00030131873791106045
step: 360, loss: 0.0009019491262733936
step: 370, loss: 0.025567034259438515
step: 380, loss: 4.116080526728183e-05
step: 390, loss: 7.567452121293172e-05
step: 400, loss: 0.0009030077490024269
step: 410, loss: 0.0007094649481587112
step: 420, loss: 7.677361281821504e-05
step: 430, loss: 0.0003349025791976601
step: 440, loss: 3.163575456710532e-05
step: 450, loss: 0.00010537257185205817
step: 460, loss: 0.00012528571824077517
step: 470, loss: 0.0024039794225245714
step: 480, loss: 5.3280138672562316e-05
step: 490, loss: 0.0004845440271310508
step: 500, loss: 0.002197284484282136
step: 510, loss: 0.00225682626478374
step: 520, loss: 0.000150904874317348
step: 530, loss: 0.00023506823345087469
step: 540, loss: 0.000153743036207743
step: 550, loss: 0.00010108607239089906
step: 560, loss: 9.210223652189597e-05
step: 570, loss: 3.1268824386643246e-05
step: 580, loss: 7.634848589077592e-05
step: 590, loss: 0.0003461821179371327
step: 600, loss: 0.0001321525633102283
step: 610, loss: 0.0009553778800182045
step: 620, loss: 0.00017412415763828903
step: 630, loss: 4.343386535765603e-05
step: 640, loss: 0.0004992343601770699
step: 650, loss: 0.0007712162332609296
step: 660, loss: 5.0954626203747466e-05
step: 670, loss: 0.0002877049846574664
step: 680, loss: 0.0001467217953177169
step: 690, loss: 6.734764610882849e-05
step: 700, loss: 0.00012053079262841493
step: 710, loss: 4.286837065592408e-05
step: 720, loss: 0.0002778119232971221
step: 730, loss: 4.153003465034999e-05
step: 740, loss: 0.0005488207680173218
step: 750, loss: 0.003144733374938369
step: 760, loss: 5.8935424021910876e-05
step: 770, loss: 0.00021929747890681028
step: 780, loss: 0.0003473323304206133
step: 790, loss: 0.00014201540034264326
step: 800, loss: 0.0007148278527893126
step: 810, loss: 0.003751577576622367
step: 820, loss: 0.0011797989718616009
step: 830, loss: 4.124495535506867e-05
step: 840, loss: 0.00012060846347594634
step: 850, loss: 8.13815277069807e-05
step: 860, loss: 0.0017272720579057932
step: 870, loss: 0.0012667156988754869
step: 880, loss: 2.145337566616945e-05
step: 890, loss: 0.00031396307167597115
step: 900, loss: 0.00030483247246593237
step: 910, loss: 9.003280138131231e-05
step: 920, loss: 8.608309872215614e-05
step: 930, loss: 8.703507774043828e-05
step: 940, loss: 0.006744474172592163
step: 950, loss: 0.000135393493110314
step: 960, loss: 0.001864791614934802
step: 970, loss: 0.007366199512034655
step: 980, loss: 0.00018835780792869627
step: 990, loss: 8.25206734589301e-05
step: 1000, loss: 0.0003150526899844408
step: 1010, loss: 0.00011872014147229493
step: 1020, loss: 0.00641661649569869
step: 1030, loss: 0.00013800148735754192
step: 1040, loss: 0.008965102955698967
step: 1050, loss: 0.00017360215133521706
step: 1060, loss: 4.422471465659328e-05
epoch 15: dev_f1=0.9488372093023255, f1=0.9313264346190029, best_f1=0.9266697804764129
step: 0, loss: 0.0006722661782987416
step: 10, loss: 7.598097727168351e-05
step: 20, loss: 0.0015782095724716783
step: 30, loss: 0.0001192643103422597
step: 40, loss: 8.364104724023491e-05
step: 50, loss: 7.90666599641554e-05
step: 60, loss: 0.013059057295322418
step: 70, loss: 0.024358320981264114
step: 80, loss: 0.034409258514642715
step: 90, loss: 0.00010028253745986149
step: 100, loss: 3.642364754341543e-05
step: 110, loss: 0.00017287222726736218
step: 120, loss: 0.0033968386705964804
step: 130, loss: 0.0009268549038097262
step: 140, loss: 0.00011906912550330162
step: 150, loss: 0.0004956899210810661
step: 160, loss: 6.076319550629705e-05
step: 170, loss: 0.00014223868492990732
step: 180, loss: 0.0007242845022119582
step: 190, loss: 0.0007204306893981993
step: 200, loss: 0.11084375530481339
step: 210, loss: 7.369993545580655e-05
step: 220, loss: 0.0008895436767488718
step: 230, loss: 0.0001550016604596749
step: 240, loss: 0.00043034012196585536
step: 250, loss: 0.00030386430444195867
step: 260, loss: 0.00011148722842335701
step: 270, loss: 0.00016014082939364016
step: 280, loss: 0.0005059097893536091
step: 290, loss: 5.4449519666377455e-05
step: 300, loss: 1.6350064470316283e-05
step: 310, loss: 2.2436435756389983e-05
step: 320, loss: 0.00025708667817525566
step: 330, loss: 1.6547459381399676e-05
step: 340, loss: 0.0015713294269517064
step: 350, loss: 1.899107883218676e-05
step: 360, loss: 0.1589454710483551
step: 370, loss: 9.085967758437619e-05
step: 380, loss: 0.0001096543128369376
step: 390, loss: 0.00010146923887077719
step: 400, loss: 0.00035203160950914025
step: 410, loss: 9.251254959963262e-05
step: 420, loss: 0.00015679126954637468
step: 430, loss: 0.000642044295091182
step: 440, loss: 0.0003429773496463895
step: 450, loss: 0.0030957944691181183
step: 460, loss: 0.0007756230770610273
step: 470, loss: 0.01748853549361229
step: 480, loss: 3.269109220127575e-05
step: 490, loss: 3.6984067264711484e-05
step: 500, loss: 0.0009651494910940528
step: 510, loss: 4.050642382935621e-05
step: 520, loss: 1.8678098058444448e-05
step: 530, loss: 3.4178272471763194e-05
step: 540, loss: 3.8916034100111574e-05
step: 550, loss: 0.00011143051233375445
step: 560, loss: 0.05368594080209732
step: 570, loss: 3.298062438261695e-05
step: 580, loss: 9.323730046162382e-05
step: 590, loss: 0.0010669776238501072
step: 600, loss: 0.003936104942113161
step: 610, loss: 7.031098357401788e-05
step: 620, loss: 3.865737380692735e-05
step: 630, loss: 0.00013395489077083766
step: 640, loss: 0.0009568686946295202
step: 650, loss: 0.0004112900933250785
step: 660, loss: 0.01709333434700966
step: 670, loss: 4.7463661758229136e-05
step: 680, loss: 0.007673751562833786
step: 690, loss: 0.001158556784503162
step: 700, loss: 0.04589979723095894
step: 710, loss: 0.00018659705528989434
step: 720, loss: 0.0004087994748260826
step: 730, loss: 0.0004914601449854672
step: 740, loss: 0.00017227261560037732
step: 750, loss: 5.5830278142821044e-05
step: 760, loss: 0.040143366903066635
step: 770, loss: 0.00492071220651269
step: 780, loss: 0.002636938588693738
step: 790, loss: 0.0037720142863690853
step: 800, loss: 0.00024535699049010873
step: 810, loss: 0.00010545358236413449
step: 820, loss: 1.6860138202900998e-05
step: 830, loss: 0.006246529053896666
step: 840, loss: 6.553550338139758e-05
step: 850, loss: 2.960370147775393e-05
step: 860, loss: 0.0003169406845699996
step: 870, loss: 0.0005777902551926672
step: 880, loss: 0.0026888172142207623
step: 890, loss: 0.0003117662272416055
step: 900, loss: 0.006553630344569683
step: 910, loss: 0.0025587501004338264
step: 920, loss: 0.00016602445975877345
step: 930, loss: 0.00023494497872889042
step: 940, loss: 0.0002696571755222976
step: 950, loss: 0.0006908561335876584
step: 960, loss: 0.00046401028521358967
step: 970, loss: 4.49435792688746e-05
step: 980, loss: 0.0016642851987853646
step: 990, loss: 4.886850729235448e-05
step: 1000, loss: 5.373020758270286e-05
step: 1010, loss: 0.03956941142678261
step: 1020, loss: 3.620707866502926e-05
step: 1030, loss: 0.002354097319766879
step: 1040, loss: 0.0006508332444354892
step: 1050, loss: 0.006825519725680351
step: 1060, loss: 5.0081725930795074e-05
epoch 16: dev_f1=0.9501630181648812, f1=0.9278642149929278, best_f1=0.9266697804764129
step: 0, loss: 0.00027952552773058414
step: 10, loss: 9.04215412447229e-05
step: 20, loss: 0.00010334679973311722
step: 30, loss: 0.0012572549749165773
step: 40, loss: 0.00010966479749185964
step: 50, loss: 8.26442483230494e-05
step: 60, loss: 7.977856876095757e-05
step: 70, loss: 0.000694009882863611
step: 80, loss: 0.000945744221098721
step: 90, loss: 0.00010291096987202764
step: 100, loss: 0.004689998924732208
step: 110, loss: 6.472407403634861e-05
step: 120, loss: 0.00020398956257849932
step: 130, loss: 0.0014759466284886003
step: 140, loss: 0.015964381396770477
step: 150, loss: 0.00039561715675517917
step: 160, loss: 0.00022318633273243904
step: 170, loss: 0.001543115358799696
step: 180, loss: 0.0007932441658340394
step: 190, loss: 0.0001874098088592291
step: 200, loss: 0.001408263691700995
step: 210, loss: 6.851689249742776e-05
step: 220, loss: 3.583364014048129e-05
step: 230, loss: 9.153053542831913e-05
step: 240, loss: 0.0004175429348833859
step: 250, loss: 1.5805691873538308e-05
step: 260, loss: 5.2482639148365706e-05
step: 270, loss: 0.00043890663073398173
step: 280, loss: 0.0017534032231196761
step: 290, loss: 5.480334584717639e-05
step: 300, loss: 2.0682236936409026e-05
step: 310, loss: 0.09562796354293823
step: 320, loss: 0.00011999806883977726
step: 330, loss: 5.6263677834067494e-05
step: 340, loss: 0.00016844893980305642
step: 350, loss: 8.289731340482831e-05
step: 360, loss: 6.605689850402996e-05
step: 370, loss: 0.00010851666593225673
step: 380, loss: 6.378870602929965e-05
step: 390, loss: 0.024610552936792374
step: 400, loss: 2.805038275255356e-05
step: 410, loss: 3.069377635256387e-05
step: 420, loss: 0.00016928301192820072
step: 430, loss: 0.0016153922770172358
step: 440, loss: 0.00020008748106192797
step: 450, loss: 0.00012434720702003688
step: 460, loss: 6.369319453369826e-05
step: 470, loss: 0.0009727320866659284
step: 480, loss: 0.00018969141819979995
step: 490, loss: 0.00010161202953895554
step: 500, loss: 8.745458762859926e-05
step: 510, loss: 0.00016850637621246278
step: 520, loss: 2.4794651835691184e-05
step: 530, loss: 2.3979086108738557e-05
step: 540, loss: 6.368900358211249e-05
step: 550, loss: 8.389647700823843e-05
step: 560, loss: 0.014715224504470825
step: 570, loss: 0.0005242892657406628
step: 580, loss: 3.148339965264313e-05
step: 590, loss: 0.0008952533244155347
step: 600, loss: 0.0016695646336302161
step: 610, loss: 4.7923356760293245e-05
step: 620, loss: 0.009454425424337387
step: 630, loss: 0.03927440196275711
step: 640, loss: 1.306445301452186e-05
step: 650, loss: 5.481130938278511e-05
step: 660, loss: 0.0005525272572413087
step: 670, loss: 0.053406719118356705
step: 680, loss: 3.3710934076225385e-05
step: 690, loss: 0.027496660128235817
step: 700, loss: 8.770625572651625e-05
step: 710, loss: 6.447375199059024e-05
step: 720, loss: 4.575587809085846e-05
step: 730, loss: 0.00016172000323422253
step: 740, loss: 0.00010838494927156717
step: 750, loss: 4.423603604664095e-05
step: 760, loss: 0.00015701062511652708
step: 770, loss: 0.0006115612923167646
step: 780, loss: 0.00023533777857664973
step: 790, loss: 9.452619997318834e-05
step: 800, loss: 0.0006111719994805753
step: 810, loss: 8.13197621027939e-05
step: 820, loss: 1.7843733076006174e-05
step: 830, loss: 6.189203850226477e-05
step: 840, loss: 0.00011485995491966605
step: 850, loss: 3.91011344618164e-05
step: 860, loss: 0.18361498415470123
step: 870, loss: 0.0005240758182480931
step: 880, loss: 7.62769122957252e-05
step: 890, loss: 1.5005220120656304e-05
step: 900, loss: 3.081799150095321e-05
step: 910, loss: 0.0008058440289460123
step: 920, loss: 0.00045560539001598954
step: 930, loss: 5.390424848883413e-05
step: 940, loss: 0.00012168069224571809
step: 950, loss: 0.001505365245975554
step: 960, loss: 0.00032233711681328714
step: 970, loss: 0.00019040871120523661
step: 980, loss: 0.0014861737145110965
step: 990, loss: 0.011335300281643867
step: 1000, loss: 2.2358441128744744e-05
step: 1010, loss: 5.056512600276619e-05
step: 1020, loss: 0.000409269385272637
step: 1030, loss: 6.0168611526023597e-05
step: 1040, loss: 0.0011130493367090821
step: 1050, loss: 0.0340622216463089
step: 1060, loss: 3.6742530937772244e-05
epoch 17: dev_f1=0.9488847583643123, f1=0.9276315789473684, best_f1=0.9266697804764129
step: 0, loss: 0.00026492978213354945
step: 10, loss: 4.969268411514349e-05
step: 20, loss: 0.0001576170907355845
step: 30, loss: 5.060694456915371e-05
step: 40, loss: 5.332228829502128e-05
step: 50, loss: 0.00012105391215300187
step: 60, loss: 6.434080569306388e-05
step: 70, loss: 4.793427069671452e-05
step: 80, loss: 0.0047910804860293865
step: 90, loss: 0.012225327081978321
step: 100, loss: 4.5661090553039685e-05
step: 110, loss: 0.00029760459437966347
step: 120, loss: 4.919017737847753e-05
step: 130, loss: 0.008269918151199818
step: 140, loss: 5.109770791023038e-05
step: 150, loss: 0.00024150895478669554
step: 160, loss: 0.032548949122428894
step: 170, loss: 0.00013761516311205924
step: 180, loss: 4.880228152615018e-05
step: 190, loss: 0.0003408861521165818
step: 200, loss: 0.00034868650254793465
step: 210, loss: 3.988996468251571e-05
step: 220, loss: 0.0002597074199002236
step: 230, loss: 7.446172821801156e-05
step: 240, loss: 0.00013978724018670619
step: 250, loss: 2.5723426006152295e-05
step: 260, loss: 0.0016279526753351092
step: 270, loss: 0.011033608578145504
step: 280, loss: 0.0002304478985024616
step: 290, loss: 2.117734584317077e-05
step: 300, loss: 0.00010469393600942567
step: 310, loss: 0.0008523830911144614
step: 320, loss: 0.00021294229372870177
step: 330, loss: 0.0027413510251790285
step: 340, loss: 9.997396409744397e-05
step: 350, loss: 0.000413453031796962
step: 360, loss: 0.0003937261353712529
step: 370, loss: 0.004688915330916643
step: 380, loss: 0.015720006078481674
step: 390, loss: 8.573701052227989e-05
step: 400, loss: 0.0003227398556191474
step: 410, loss: 5.8934489061357453e-05
step: 420, loss: 6.802476127631962e-05
step: 430, loss: 4.977858770871535e-05
step: 440, loss: 4.519299545791e-05
step: 450, loss: 3.135353108518757e-05
step: 460, loss: 0.0005607974017038941
step: 470, loss: 3.605919482652098e-05
step: 480, loss: 4.1708706703502685e-05
step: 490, loss: 5.140450593899004e-05
step: 500, loss: 2.4629023755551316e-05
step: 510, loss: 2.787513949442655e-05
step: 520, loss: 4.646178422262892e-05
step: 530, loss: 0.00011421728413552046
step: 540, loss: 2.1128758817212656e-05
step: 550, loss: 0.00010552977619227022
step: 560, loss: 0.0001021523421513848
step: 570, loss: 8.066376904025674e-05
step: 580, loss: 1.9456467271083966e-05
step: 590, loss: 0.0016414750134572387
step: 600, loss: 1.5347806765930727e-05
step: 610, loss: 0.00010770431981654838
step: 620, loss: 3.2463900424772874e-05
step: 630, loss: 9.451880760025233e-05
step: 640, loss: 5.8937315770890564e-05
step: 650, loss: 1.551560671941843e-05
step: 660, loss: 0.00021497029229067266
step: 670, loss: 2.4805298380670138e-05
step: 680, loss: 1.1417901987442747e-05
step: 690, loss: 7.12612527422607e-05
step: 700, loss: 5.05017233081162e-05
step: 710, loss: 0.0006113347481004894
step: 720, loss: 3.157879473292269e-05
step: 730, loss: 3.787929017562419e-05
step: 740, loss: 0.00034829709329642355
step: 750, loss: 1.4178120181895792e-05
step: 760, loss: 0.003165942383930087
step: 770, loss: 2.6381632778793573e-05
step: 780, loss: 3.891631058650091e-05
step: 790, loss: 3.3731197618180886e-05
step: 800, loss: 0.008153209462761879
step: 810, loss: 7.568391447421163e-05
step: 820, loss: 6.210981518961489e-05
step: 830, loss: 5.9995301853632554e-05
step: 840, loss: 0.0004350203671492636
step: 850, loss: 0.0014811938162893057
step: 860, loss: 8.143085869960487e-05
step: 870, loss: 6.069008304621093e-05
step: 880, loss: 0.018400080502033234
step: 890, loss: 0.0007248421898111701
step: 900, loss: 0.0003563073114491999
step: 910, loss: 0.08452469855546951
step: 920, loss: 0.0002836294879671186
step: 930, loss: 0.001513649127446115
step: 940, loss: 0.0009773700730875134
step: 950, loss: 8.865297422744334e-05
step: 960, loss: 2.910365947172977e-05
step: 970, loss: 8.212413376895711e-05
step: 980, loss: 3.869083957397379e-05
step: 990, loss: 3.901660238625482e-05
step: 1000, loss: 1.9203145711799152e-05
step: 1010, loss: 0.0002148855710402131
step: 1020, loss: 8.489712490700185e-05
step: 1030, loss: 2.060006772808265e-05
step: 1040, loss: 0.0001365512580377981
step: 1050, loss: 2.5595723855076358e-05
step: 1060, loss: 8.363972301594913e-05
epoch 18: dev_f1=0.9487895716945998, f1=0.9275911026975864, best_f1=0.9266697804764129
step: 0, loss: 6.139670585980639e-05
step: 10, loss: 1.944173163792584e-05
step: 20, loss: 0.00022652067127637565
step: 30, loss: 2.4328975996468216e-05
step: 40, loss: 0.017901813611388206
step: 50, loss: 1.891634201456327e-05
step: 60, loss: 0.00027301369118504226
step: 70, loss: 0.0017113563371822238
step: 80, loss: 0.00017899177328217775
step: 90, loss: 4.036727113998495e-05
step: 100, loss: 5.753263758379035e-05
step: 110, loss: 0.0005754133453592658
step: 120, loss: 1.5359146345872432e-05
step: 130, loss: 7.15972637408413e-05
step: 140, loss: 0.0022072007413953543
step: 150, loss: 2.7922271328861825e-05
step: 160, loss: 3.820125130005181e-05
step: 170, loss: 0.00022426736541092396
step: 180, loss: 0.00015141010226216167
step: 190, loss: 0.001103160553611815
step: 200, loss: 0.00044090760638937354
step: 210, loss: 1.5671945220674388e-05
step: 220, loss: 0.012974675744771957
step: 230, loss: 1.4867371646687388e-05
step: 240, loss: 0.002316007623448968
step: 250, loss: 0.00014974066289141774
step: 260, loss: 2.1397556338342838e-05
step: 270, loss: 5.871413668501191e-05
step: 280, loss: 0.00019365662592463195
step: 290, loss: 1.7690888853394426e-05
step: 300, loss: 3.5181354178348556e-05
step: 310, loss: 0.0018740849336609244
step: 320, loss: 7.68034442444332e-05
step: 330, loss: 1.6583990145591088e-05
step: 340, loss: 6.40401485725306e-05
step: 350, loss: 4.581842222250998e-05
step: 360, loss: 7.918417395558208e-05
step: 370, loss: 6.724204286001623e-05
step: 380, loss: 0.00021013834339100868
step: 390, loss: 0.0005325361853465438
step: 400, loss: 2.2469161194749177e-05
step: 410, loss: 0.0012880748836323619
step: 420, loss: 1.6904508811421692e-05
step: 430, loss: 3.554804061423056e-05
step: 440, loss: 0.005594187416136265
step: 450, loss: 7.745893526589498e-05
step: 460, loss: 1.425258960807696e-05
step: 470, loss: 0.03120504692196846
step: 480, loss: 3.0053595764911734e-05
step: 490, loss: 1.4472496332018636e-05
step: 500, loss: 1.9207194782211445e-05
step: 510, loss: 0.00022779617574997246
step: 520, loss: 3.141799243167043e-05
step: 530, loss: 9.091132233152166e-05
step: 540, loss: 0.00010804349585669115
step: 550, loss: 0.00010925691458396614
step: 560, loss: 2.5826326236710884e-05
step: 570, loss: 1.800017707864754e-05
step: 580, loss: 0.0008602390298619866
step: 590, loss: 0.00012189570406917483
step: 600, loss: 1.7795046005630866e-05
step: 610, loss: 5.353813321562484e-05
step: 620, loss: 1.932569830387365e-05
step: 630, loss: 0.00030238169711083174
step: 640, loss: 0.00010845305951079354
step: 650, loss: 1.8170580005971715e-05
step: 660, loss: 7.915851892903447e-05
step: 670, loss: 0.02141665667295456
step: 680, loss: 3.816503522102721e-05
step: 690, loss: 0.00017692925757728517
step: 700, loss: 9.734401101013646e-05
step: 710, loss: 2.46971412707353e-05
step: 720, loss: 0.0033176029101014137
step: 730, loss: 9.650651918491349e-05
step: 740, loss: 3.266159910708666e-05
step: 750, loss: 6.018843487254344e-05
step: 760, loss: 5.611194865196012e-05
step: 770, loss: 0.027082534506917
step: 780, loss: 0.0007678216206841171
step: 790, loss: 5.515653901966289e-05
step: 800, loss: 0.0003373462241142988
step: 810, loss: 3.4916589356726035e-05
step: 820, loss: 8.114286902127787e-05
step: 830, loss: 0.0036967515479773283
step: 840, loss: 0.0031854244880378246
step: 850, loss: 0.015340310521423817
step: 860, loss: 0.005483198445290327
step: 870, loss: 3.593356450437568e-05
step: 880, loss: 8.817583147902042e-05
step: 890, loss: 1.4170533177093603e-05
step: 900, loss: 0.012506943196058273
step: 910, loss: 0.00011677361908368766
step: 920, loss: 0.0007806813227944076
step: 930, loss: 0.000311032374156639
step: 940, loss: 0.00015075058036018163
step: 950, loss: 2.205272357969079e-05
step: 960, loss: 2.011949800362345e-05
step: 970, loss: 0.00028492099954746664
step: 980, loss: 2.3293474441743456e-05
step: 990, loss: 4.1959821828641e-05
step: 1000, loss: 0.0005708028329536319
step: 1010, loss: 0.00035661450237967074
step: 1020, loss: 0.001838256954215467
step: 1030, loss: 1.575375245010946e-05
step: 1040, loss: 1.946386691997759e-05
step: 1050, loss: 0.00021242733055260032
step: 1060, loss: 0.00010054936137748882
epoch 19: dev_f1=0.9506057781919852, f1=0.9320113314447592, best_f1=0.9266697804764129
step: 0, loss: 1.614501525182277e-05
step: 10, loss: 5.4618303693132475e-05
step: 20, loss: 3.200541323167272e-05
step: 30, loss: 0.00028362200828269124
step: 40, loss: 0.00892998743802309
step: 50, loss: 0.0007574498886242509
step: 60, loss: 6.68945285724476e-05
step: 70, loss: 0.001131906290538609
step: 80, loss: 0.0002694684371817857
step: 90, loss: 1.438282288290793e-05
step: 100, loss: 0.00017590155766811222
step: 110, loss: 4.575158527586609e-05
step: 120, loss: 4.481666110223159e-05
step: 130, loss: 3.353566353325732e-05
step: 140, loss: 1.8189890397479758e-05
step: 150, loss: 1.5917470591375604e-05
step: 160, loss: 0.00042956098332069814
step: 170, loss: 1.8003762306761928e-05
step: 180, loss: 7.747278141323477e-05
step: 190, loss: 0.00016098916239570826
step: 200, loss: 9.244422835763544e-05
step: 210, loss: 2.7773887268267572e-05
step: 220, loss: 3.1865405617281795e-05
step: 230, loss: 1.1462581824162044e-05
step: 240, loss: 2.0928035155520774e-05
step: 250, loss: 8.389494178118184e-05
step: 260, loss: 1.6346208212780766e-05
step: 270, loss: 7.900528726167977e-05
step: 280, loss: 3.694604674819857e-05
step: 290, loss: 1.3515134924091399e-05
step: 300, loss: 2.727273567870725e-05
step: 310, loss: 0.0002254218707093969
step: 320, loss: 5.006315404898487e-05
step: 330, loss: 6.227470294106752e-05
step: 340, loss: 0.00015597067249473184
step: 350, loss: 0.00038028485141694546
step: 360, loss: 0.0004682935250457376
step: 370, loss: 1.6078034605016e-05
step: 380, loss: 8.393885218538344e-05
step: 390, loss: 1.4431481758947484e-05
step: 400, loss: 4.981788879376836e-05
step: 410, loss: 3.78816548618488e-05
step: 420, loss: 3.2848976843524724e-05
step: 430, loss: 7.460931374225765e-05
step: 440, loss: 1.3064313861832488e-05
step: 450, loss: 0.001091726589947939
step: 460, loss: 3.890381412929855e-05
step: 470, loss: 2.592219243524596e-05
step: 480, loss: 1.250194964086404e-05
step: 490, loss: 1.9269995391368866e-05
step: 500, loss: 2.309400042577181e-05
step: 510, loss: 9.8643999081105e-05
step: 520, loss: 6.467546336352825e-05
step: 530, loss: 2.0950401449226774e-05
step: 540, loss: 2.808285535138566e-05
step: 550, loss: 2.0532161215669475e-05
step: 560, loss: 2.9412569347186945e-05
step: 570, loss: 6.783519347663969e-05
step: 580, loss: 4.257135515217669e-05
step: 590, loss: 0.00014335900777950883
step: 600, loss: 1.3276699974085204e-05
step: 610, loss: 3.4675253118621185e-05
step: 620, loss: 2.547594704083167e-05
step: 630, loss: 3.83250844606664e-05
step: 640, loss: 5.2269235311541706e-05
step: 650, loss: 3.8590762414969504e-05
step: 660, loss: 0.00012142967898398638
step: 670, loss: 0.00046668792492710054
step: 680, loss: 2.4256658434751444e-05
step: 690, loss: 2.5538574845995754e-05
step: 700, loss: 1.8935026673716493e-05
step: 710, loss: 1.864754085545428e-05
step: 720, loss: 0.0031593027524650097
step: 730, loss: 8.626556518720463e-05
step: 740, loss: 0.000425657577579841
step: 750, loss: 2.45863357122289e-05
step: 760, loss: 7.793381519149989e-05
step: 770, loss: 0.00029479319346137345
step: 780, loss: 1.3809385563945398e-05
step: 790, loss: 2.0399009372340515e-05
step: 800, loss: 6.043312168912962e-05
step: 810, loss: 0.00014620134606957436
step: 820, loss: 1.0695171113184188e-05
step: 830, loss: 0.00014284381177276373
step: 840, loss: 0.0002519909758120775
step: 850, loss: 9.34357667574659e-05
step: 860, loss: 7.4863011832349e-05
step: 870, loss: 2.492469866410829e-05
step: 880, loss: 8.586730473325588e-06
step: 890, loss: 0.000186470482731238
step: 900, loss: 7.28722006897442e-05
step: 910, loss: 0.00021099856530781835
step: 920, loss: 0.0036040558479726315
step: 930, loss: 2.3844979295972735e-05
step: 940, loss: 8.295390580315143e-05
step: 950, loss: 0.001342814415693283
step: 960, loss: 1.21181610666099e-05
step: 970, loss: 2.7969457732979208e-05
step: 980, loss: 3.4498400054872036e-05
step: 990, loss: 4.6065630158409476e-05
step: 1000, loss: 2.729484549490735e-05
step: 1010, loss: 1.7437361748307012e-05
step: 1020, loss: 0.007823672145605087
step: 1030, loss: 3.182132059009746e-05
step: 1040, loss: 0.00024580175522714853
step: 1050, loss: 0.00014372148143593222
step: 1060, loss: 4.4497854105429724e-05
epoch 20: dev_f1=0.9521152952115295, f1=0.9286384976525822, best_f1=0.9266697804764129
