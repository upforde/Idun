cuda
Device: cuda
step: 0, loss: 0.7028008103370667
step: 10, loss: 0.5014273524284363
step: 20, loss: 0.5313742756843567
step: 30, loss: 0.3614822328090668
step: 40, loss: 0.45646196603775024
step: 50, loss: 0.247877299785614
step: 60, loss: 0.2592706084251404
step: 70, loss: 0.3916473388671875
step: 80, loss: 0.1829412430524826
step: 90, loss: 0.3452548086643219
step: 100, loss: 0.23117628693580627
step: 110, loss: 0.3811485767364502
step: 120, loss: 0.18300583958625793
step: 130, loss: 0.13833433389663696
step: 140, loss: 0.19127187132835388
step: 150, loss: 0.32984957098960876
step: 160, loss: 0.3000412583351135
step: 170, loss: 0.3449159264564514
step: 180, loss: 0.33776432275772095
step: 190, loss: 0.17866209149360657
step: 200, loss: 0.20756438374519348
step: 210, loss: 0.31060853600502014
step: 220, loss: 0.1451990157365799
step: 230, loss: 0.1841965615749359
step: 240, loss: 0.20826715230941772
step: 250, loss: 0.1292588710784912
step: 260, loss: 0.23561351001262665
step: 270, loss: 0.14257441461086273
step: 280, loss: 0.23381493985652924
step: 290, loss: 0.23650766909122467
step: 300, loss: 0.08837567269802094
step: 310, loss: 0.3063560724258423
step: 320, loss: 0.22258292138576508
step: 330, loss: 0.18954017758369446
step: 340, loss: 0.21138526499271393
step: 350, loss: 0.18350310623645782
step: 360, loss: 0.27775293588638306
step: 370, loss: 0.2676212787628174
step: 380, loss: 0.3356705605983734
step: 390, loss: 0.1194709911942482
step: 400, loss: 0.13881133496761322
step: 410, loss: 0.1239236518740654
step: 420, loss: 0.16835279762744904
step: 430, loss: 0.21144241094589233
step: 440, loss: 0.11833897978067398
step: 450, loss: 0.1366678774356842
step: 460, loss: 0.22040581703186035
step: 470, loss: 0.12272273004055023
step: 480, loss: 0.1845570057630539
step: 490, loss: 0.15601259469985962
step: 500, loss: 0.24022075533866882
step: 510, loss: 0.22252483665943146
step: 520, loss: 0.36551323533058167
step: 530, loss: 0.25257930159568787
step: 540, loss: 0.2711702287197113
step: 550, loss: 0.17037604749202728
step: 560, loss: 0.0972466766834259
step: 570, loss: 0.32322993874549866
step: 580, loss: 0.2746714651584625
step: 590, loss: 0.42691996693611145
step: 600, loss: 0.22156204283237457
step: 610, loss: 0.17372828722000122
step: 620, loss: 0.38843709230422974
step: 630, loss: 0.24583405256271362
step: 640, loss: 0.25659066438674927
step: 650, loss: 0.2225591540336609
step: 660, loss: 0.15872381627559662
step: 670, loss: 0.24301783740520477
step: 680, loss: 0.36906301975250244
step: 690, loss: 0.1165769025683403
step: 700, loss: 0.2530616819858551
step: 710, loss: 0.09980642795562744
step: 720, loss: 0.3352639079093933
step: 730, loss: 0.04924368858337402
step: 740, loss: 0.15618076920509338
step: 750, loss: 0.02855489030480385
step: 760, loss: 0.24581706523895264
step: 770, loss: 0.11301239579916
step: 780, loss: 0.21445699036121368
step: 790, loss: 0.2756379246711731
step: 800, loss: 0.14297807216644287
step: 810, loss: 0.1602429747581482
step: 820, loss: 0.12237944453954697
step: 830, loss: 0.23670436441898346
step: 840, loss: 0.09363758563995361
step: 850, loss: 0.19030669331550598
step: 860, loss: 0.176338329911232
step: 870, loss: 0.22565323114395142
step: 880, loss: 0.18272243440151215
step: 890, loss: 0.14694815874099731
step: 900, loss: 0.15742599964141846
step: 910, loss: 0.19899685680866241
step: 920, loss: 0.3458847105503082
step: 930, loss: 0.3561823070049286
step: 940, loss: 0.21422146260738373
epoch 1: dev_f1=0.94362292051756, f1=0.9320388349514563, best_f1=0.9320388349514563
step: 0, loss: 0.1674300730228424
step: 10, loss: 0.025284219533205032
step: 20, loss: 0.27899953722953796
step: 30, loss: 0.14945976436138153
step: 40, loss: 0.04977364093065262
step: 50, loss: 0.2088349461555481
step: 60, loss: 0.08143377304077148
step: 70, loss: 0.3953593373298645
step: 80, loss: 0.11104549467563629
step: 90, loss: 0.05480102077126503
step: 100, loss: 0.362496554851532
step: 110, loss: 0.16393807530403137
step: 120, loss: 0.18919669091701508
step: 130, loss: 0.26729145646095276
step: 140, loss: 0.11133822053670883
step: 150, loss: 0.17060649394989014
step: 160, loss: 0.24547302722930908
step: 170, loss: 0.12891258299350739
step: 180, loss: 0.14881747961044312
step: 190, loss: 0.21656635403633118
step: 200, loss: 0.28245577216148376
step: 210, loss: 0.1710602194070816
step: 220, loss: 0.1613239049911499
step: 230, loss: 0.11154376715421677
step: 240, loss: 0.12496586889028549
step: 250, loss: 0.12015509605407715
step: 260, loss: 0.12078200280666351
step: 270, loss: 0.10411527007818222
step: 280, loss: 0.1905079185962677
step: 290, loss: 0.10214748978614807
step: 300, loss: 0.0845581516623497
step: 310, loss: 0.1949990838766098
step: 320, loss: 0.06103017181158066
step: 330, loss: 0.21918721497058868
step: 340, loss: 0.1141655370593071
step: 350, loss: 0.13041682541370392
step: 360, loss: 0.15316715836524963
step: 370, loss: 0.36399388313293457
step: 380, loss: 0.21606262028217316
step: 390, loss: 0.07359807193279266
step: 400, loss: 0.05018697679042816
step: 410, loss: 0.174469456076622
step: 420, loss: 0.24783855676651
step: 430, loss: 0.10516407340765
step: 440, loss: 0.16112639009952545
step: 450, loss: 0.043937575072050095
step: 460, loss: 0.16030801832675934
step: 470, loss: 0.09831652790307999
step: 480, loss: 0.20403210818767548
step: 490, loss: 0.051081638783216476
step: 500, loss: 0.4892781376838684
step: 510, loss: 0.22396764159202576
step: 520, loss: 0.1037612184882164
step: 530, loss: 0.10984115302562714
step: 540, loss: 0.09260718524456024
step: 550, loss: 0.1770344227552414
step: 560, loss: 0.14609979093074799
step: 570, loss: 0.36401599645614624
step: 580, loss: 0.18497391045093536
step: 590, loss: 0.018102750182151794
step: 600, loss: 0.1820240318775177
step: 610, loss: 0.2393142729997635
step: 620, loss: 0.0893985852599144
step: 630, loss: 0.10925812274217606
step: 640, loss: 0.16658161580562592
step: 650, loss: 0.1457233875989914
step: 660, loss: 0.20444944500923157
step: 670, loss: 0.07398182898759842
step: 680, loss: 0.26163262128829956
step: 690, loss: 0.3048456907272339
step: 700, loss: 0.19276733696460724
step: 710, loss: 0.2655748128890991
step: 720, loss: 0.4172552227973938
step: 730, loss: 0.2626068890094757
step: 740, loss: 0.24030449986457825
step: 750, loss: 0.15306057035923004
step: 760, loss: 0.1559152454137802
step: 770, loss: 0.4171724319458008
step: 780, loss: 0.1201404258608818
step: 790, loss: 0.1308967024087906
step: 800, loss: 0.191761776804924
step: 810, loss: 0.20617492496967316
step: 820, loss: 0.11179864406585693
step: 830, loss: 0.27473968267440796
step: 840, loss: 0.08585810661315918
step: 850, loss: 0.13894148170948029
step: 860, loss: 0.16903063654899597
step: 870, loss: 0.130170077085495
step: 880, loss: 0.08863658457994461
step: 890, loss: 0.12908175587654114
step: 900, loss: 0.317984014749527
step: 910, loss: 0.15786033868789673
step: 920, loss: 0.23752214014530182
step: 930, loss: 0.11968884617090225
step: 940, loss: 0.050431668758392334
epoch 2: dev_f1=0.9488714877936435, f1=0.9385474860335196, best_f1=0.9385474860335196
step: 0, loss: 0.11819978803396225
step: 10, loss: 0.12525850534439087
step: 20, loss: 0.09140871465206146
step: 30, loss: 0.21570487320423126
step: 40, loss: 0.13959375023841858
step: 50, loss: 0.13508406281471252
step: 60, loss: 0.2757912576198578
step: 70, loss: 0.1591651290655136
step: 80, loss: 0.14405064284801483
step: 90, loss: 0.16350220143795013
step: 100, loss: 0.015932394191622734
step: 110, loss: 0.10107875615358353
step: 120, loss: 0.09409837424755096
step: 130, loss: 0.023985233157873154
step: 140, loss: 0.0787758007645607
step: 150, loss: 0.17960450053215027
step: 160, loss: 0.10546639561653137
step: 170, loss: 0.09620460122823715
step: 180, loss: 0.05834156647324562
step: 190, loss: 0.340599000453949
step: 200, loss: 0.08879486471414566
step: 210, loss: 0.08695795387029648
step: 220, loss: 0.13295093178749084
step: 230, loss: 0.03918592631816864
step: 240, loss: 0.06303990632295609
step: 250, loss: 0.08312031626701355
step: 260, loss: 0.20414452254772186
step: 270, loss: 0.03525666147470474
step: 280, loss: 0.14921723306179047
step: 290, loss: 0.2386239767074585
step: 300, loss: 0.31036150455474854
step: 310, loss: 0.0984545648097992
step: 320, loss: 0.06674167513847351
step: 330, loss: 0.02753712609410286
step: 340, loss: 0.0789928212761879
step: 350, loss: 0.03299097716808319
step: 360, loss: 0.06877560168504715
step: 370, loss: 0.36325082182884216
step: 380, loss: 0.45576798915863037
step: 390, loss: 0.11431777477264404
step: 400, loss: 0.06335765868425369
step: 410, loss: 0.06213228404521942
step: 420, loss: 0.23934772610664368
step: 430, loss: 0.07543420791625977
step: 440, loss: 0.09178721159696579
step: 450, loss: 0.0158672071993351
step: 460, loss: 0.08912180364131927
step: 470, loss: 0.14019238948822021
step: 480, loss: 0.014607005752623081
step: 490, loss: 0.1372418850660324
step: 500, loss: 0.07044330984354019
step: 510, loss: 0.049540430307388306
step: 520, loss: 0.2222442477941513
step: 530, loss: 0.0831359401345253
step: 540, loss: 0.11169221997261047
step: 550, loss: 0.20647314190864563
step: 560, loss: 0.034476038068532944
step: 570, loss: 0.061811212450265884
step: 580, loss: 0.10682982206344604
step: 590, loss: 0.01865626871585846
step: 600, loss: 0.10391576588153839
step: 610, loss: 0.287248432636261
step: 620, loss: 0.03601827099919319
step: 630, loss: 0.10534052550792694
step: 640, loss: 0.052607886493206024
step: 650, loss: 0.038445476442575455
step: 660, loss: 0.06362015753984451
step: 670, loss: 0.254291296005249
step: 680, loss: 0.278438001871109
step: 690, loss: 0.0834708958864212
step: 700, loss: 0.15445931255817413
step: 710, loss: 0.10818833857774734
step: 720, loss: 0.17505674064159393
step: 730, loss: 0.1187572330236435
step: 740, loss: 0.06802282482385635
step: 750, loss: 0.15532371401786804
step: 760, loss: 0.01296795904636383
step: 770, loss: 0.2240399271249771
step: 780, loss: 0.22819194197654724
step: 790, loss: 0.1656738519668579
step: 800, loss: 0.09907209128141403
step: 810, loss: 0.18639644980430603
step: 820, loss: 0.15980181097984314
step: 830, loss: 0.053537994623184204
step: 840, loss: 0.1901853382587433
step: 850, loss: 0.20243410766124725
step: 860, loss: 0.04951419308781624
step: 870, loss: 0.14779874682426453
step: 880, loss: 0.2500646412372589
step: 890, loss: 0.12526793777942657
step: 900, loss: 0.01579364947974682
step: 910, loss: 0.20026397705078125
step: 920, loss: 0.1304764300584793
step: 930, loss: 0.1815146505832672
step: 940, loss: 0.054541125893592834
epoch 3: dev_f1=0.9501411100658514, f1=0.9274269557021678, best_f1=0.9274269557021678
step: 0, loss: 0.0421072319149971
step: 10, loss: 0.1081148013472557
step: 20, loss: 0.14714264869689941
step: 30, loss: 0.09800072759389877
step: 40, loss: 0.09724932909011841
step: 50, loss: 0.0858740359544754
step: 60, loss: 0.17675375938415527
step: 70, loss: 0.2514607310295105
step: 80, loss: 0.018469858914613724
step: 90, loss: 0.017065033316612244
step: 100, loss: 0.0711127370595932
step: 110, loss: 0.07989531010389328
step: 120, loss: 0.013554531149566174
step: 130, loss: 0.07559650391340256
step: 140, loss: 0.2264496088027954
step: 150, loss: 0.014689860865473747
step: 160, loss: 0.02871585264801979
step: 170, loss: 0.22953759133815765
step: 180, loss: 0.08651942014694214
step: 190, loss: 0.13767661154270172
step: 200, loss: 0.1534346491098404
step: 210, loss: 0.05456399545073509
step: 220, loss: 0.0629449263215065
step: 230, loss: 0.030118465423583984
step: 240, loss: 0.030879942700266838
step: 250, loss: 0.011070783250033855
step: 260, loss: 0.02967090904712677
step: 270, loss: 0.0781879872083664
step: 280, loss: 0.0892534926533699
step: 290, loss: 0.18587034940719604
step: 300, loss: 0.06722091883420944
step: 310, loss: 0.024387840181589127
step: 320, loss: 0.1152755469083786
step: 330, loss: 0.06255877763032913
step: 340, loss: 0.07603959739208221
step: 350, loss: 0.03461065888404846
step: 360, loss: 0.21559059619903564
step: 370, loss: 0.0768379271030426
step: 380, loss: 0.05491911619901657
step: 390, loss: 0.013069681823253632
step: 400, loss: 0.11739031970500946
step: 410, loss: 0.01571968011558056
step: 420, loss: 0.027207016944885254
step: 430, loss: 0.19910959899425507
step: 440, loss: 0.01656314730644226
step: 450, loss: 0.0794515311717987
step: 460, loss: 0.09006598591804504
step: 470, loss: 0.09808123111724854
step: 480, loss: 0.052629828453063965
step: 490, loss: 0.03545242175459862
step: 500, loss: 0.055301766842603683
step: 510, loss: 0.05031925439834595
step: 520, loss: 0.008858168497681618
step: 530, loss: 0.0742821916937828
step: 540, loss: 0.09012951701879501
step: 550, loss: 0.09949611127376556
step: 560, loss: 0.051734212785959244
step: 570, loss: 0.16166236996650696
step: 580, loss: 0.0990651547908783
step: 590, loss: 0.02027999609708786
step: 600, loss: 0.27281397581100464
step: 610, loss: 0.08022858202457428
step: 620, loss: 0.1177574023604393
step: 630, loss: 0.15744881331920624
step: 640, loss: 0.10286802798509598
step: 650, loss: 0.05290834233164787
step: 660, loss: 0.12607140839099884
step: 670, loss: 0.09221535176038742
step: 680, loss: 0.059738289564847946
step: 690, loss: 0.0322427898645401
step: 700, loss: 0.03654255345463753
step: 710, loss: 0.08917410671710968
step: 720, loss: 0.027392419055104256
step: 730, loss: 0.04428064450621605
step: 740, loss: 0.1736678034067154
step: 750, loss: 0.10750045627355576
step: 760, loss: 0.04691251739859581
step: 770, loss: 0.09499821811914444
step: 780, loss: 0.011570003814995289
step: 790, loss: 0.13735893368721008
step: 800, loss: 0.04730841517448425
step: 810, loss: 0.01679530367255211
step: 820, loss: 0.09960626065731049
step: 830, loss: 0.011369675397872925
step: 840, loss: 0.05930984765291214
step: 850, loss: 0.11826930195093155
step: 860, loss: 0.05539235845208168
step: 870, loss: 0.022878874093294144
step: 880, loss: 0.03367084637284279
step: 890, loss: 0.1513611078262329
step: 900, loss: 0.029450200498104095
step: 910, loss: 0.04527081176638603
step: 920, loss: 0.02417505532503128
step: 930, loss: 0.04094787314534187
step: 940, loss: 0.02955799177289009
epoch 4: dev_f1=0.9484724122207022, f1=0.9312557286892759, best_f1=0.9274269557021678
step: 0, loss: 0.03427954018115997
step: 10, loss: 0.01299121230840683
step: 20, loss: 0.014231369830667973
step: 30, loss: 0.007484156172722578
step: 40, loss: 0.018593348562717438
step: 50, loss: 0.12448281049728394
step: 60, loss: 0.046834513545036316
step: 70, loss: 0.013673356734216213
step: 80, loss: 0.010772572830319405
step: 90, loss: 0.17854046821594238
step: 100, loss: 0.2008904367685318
step: 110, loss: 0.014150998555123806
step: 120, loss: 0.009753432124853134
step: 130, loss: 0.08751317858695984
step: 140, loss: 0.054040055721998215
step: 150, loss: 0.032013118267059326
step: 160, loss: 0.0036638134624809027
step: 170, loss: 0.029961371794342995
step: 180, loss: 0.008127208799123764
step: 190, loss: 0.05601240694522858
step: 200, loss: 0.06693674623966217
step: 210, loss: 0.03187451511621475
step: 220, loss: 0.05567244440317154
step: 230, loss: 0.13479295372962952
step: 240, loss: 0.07035014033317566
step: 250, loss: 0.07914359867572784
step: 260, loss: 0.11628498882055283
step: 270, loss: 0.027916744351387024
step: 280, loss: 0.020931895822286606
step: 290, loss: 0.005934848450124264
step: 300, loss: 0.017126550897955894
step: 310, loss: 0.1545763909816742
step: 320, loss: 0.020160432904958725
step: 330, loss: 0.13048548996448517
step: 340, loss: 0.00880645401775837
step: 350, loss: 0.007376053370535374
step: 360, loss: 0.003079768270254135
step: 370, loss: 0.013827444985508919
step: 380, loss: 0.15497490763664246
step: 390, loss: 0.008238142356276512
step: 400, loss: 0.0705573633313179
step: 410, loss: 0.02105906419456005
step: 420, loss: 0.04710306599736214
step: 430, loss: 0.028910480439662933
step: 440, loss: 0.006226501893252134
step: 450, loss: 0.05739789083600044
step: 460, loss: 0.01166214793920517
step: 470, loss: 0.00850525964051485
step: 480, loss: 0.003894441295415163
step: 490, loss: 0.05436316877603531
step: 500, loss: 0.005737153347581625
step: 510, loss: 0.11938676238059998
step: 520, loss: 0.020340202376246452
step: 530, loss: 0.06326178461313248
step: 540, loss: 0.02507646195590496
step: 550, loss: 0.005488884169608355
step: 560, loss: 0.03751429542899132
step: 570, loss: 0.011143193580210209
step: 580, loss: 0.002054044511169195
step: 590, loss: 0.019138243049383163
step: 600, loss: 0.04062558338046074
step: 610, loss: 0.01082681119441986
step: 620, loss: 0.033647049218416214
step: 630, loss: 0.007390200160443783
step: 640, loss: 0.020823553204536438
step: 650, loss: 0.06391764432191849
step: 660, loss: 0.09769610315561295
step: 670, loss: 0.07683373987674713
step: 680, loss: 0.04410894215106964
step: 690, loss: 0.04745590314269066
step: 700, loss: 0.02706349454820156
step: 710, loss: 0.003347305813804269
step: 720, loss: 0.03943042829632759
step: 730, loss: 0.03758181259036064
step: 740, loss: 0.015917276963591576
step: 750, loss: 0.008162901736795902
step: 760, loss: 0.01843283511698246
step: 770, loss: 0.01307960320264101
step: 780, loss: 0.06601490080356598
step: 790, loss: 0.19800890982151031
step: 800, loss: 0.10095690935850143
step: 810, loss: 0.014035689644515514
step: 820, loss: 0.012294383719563484
step: 830, loss: 0.05568677559494972
step: 840, loss: 0.03718021139502525
step: 850, loss: 0.12484221160411835
step: 860, loss: 0.08217258006334305
step: 870, loss: 0.02389703504741192
step: 880, loss: 0.0852632224559784
step: 890, loss: 0.2685343623161316
step: 900, loss: 0.041841886937618256
step: 910, loss: 0.05286862328648567
step: 920, loss: 0.060000818222761154
step: 930, loss: 0.04455788806080818
step: 940, loss: 0.061626970767974854
epoch 5: dev_f1=0.9502556950255696, f1=0.928739971684757, best_f1=0.928739971684757
step: 0, loss: 0.020366625860333443
step: 10, loss: 0.003973785322159529
step: 20, loss: 0.021098187193274498
step: 30, loss: 0.041881002485752106
step: 40, loss: 0.08344398438930511
step: 50, loss: 0.013562342151999474
step: 60, loss: 0.022778498008847237
step: 70, loss: 0.02181568555533886
step: 80, loss: 0.02955995686352253
step: 90, loss: 0.12269220501184464
step: 100, loss: 0.01240475382655859
step: 110, loss: 0.07129152864217758
step: 120, loss: 0.028197122737765312
step: 130, loss: 0.017818300053477287
step: 140, loss: 0.07376465201377869
step: 150, loss: 0.06497107446193695
step: 160, loss: 0.003258295124396682
step: 170, loss: 0.03646679222583771
step: 180, loss: 0.00847155973315239
step: 190, loss: 0.029330480843782425
step: 200, loss: 0.03199746459722519
step: 210, loss: 0.020038234069943428
step: 220, loss: 0.016674762591719627
step: 230, loss: 0.05809299275279045
step: 240, loss: 0.0358114019036293
step: 250, loss: 0.03418459743261337
step: 260, loss: 0.002309740288183093
step: 270, loss: 0.11266811192035675
step: 280, loss: 0.027759620919823647
step: 290, loss: 0.0752277821302414
step: 300, loss: 0.00942603312432766
step: 310, loss: 0.003978028427809477
step: 320, loss: 0.016105569899082184
step: 330, loss: 0.00430720578879118
step: 340, loss: 0.04845498129725456
step: 350, loss: 0.007349209859967232
step: 360, loss: 0.059888362884521484
step: 370, loss: 0.05451254919171333
step: 380, loss: 0.07899865508079529
step: 390, loss: 0.014213625341653824
step: 400, loss: 0.008120013400912285
step: 410, loss: 0.14478576183319092
step: 420, loss: 0.009095399640500546
step: 430, loss: 0.21424652636051178
step: 440, loss: 0.0027583655901253223
step: 450, loss: 0.03386836498975754
step: 460, loss: 0.04011117294430733
step: 470, loss: 0.0027652692515403032
step: 480, loss: 0.02653886191546917
step: 490, loss: 0.002193677704781294
step: 500, loss: 0.02237129956483841
step: 510, loss: 0.003066309029236436
step: 520, loss: 0.0012719272635877132
step: 530, loss: 0.00045758142368867993
step: 540, loss: 0.09526598453521729
step: 550, loss: 0.059893280267715454
step: 560, loss: 0.038309697061777115
step: 570, loss: 0.0012762402184307575
step: 580, loss: 0.001413683407008648
step: 590, loss: 0.004398276098072529
step: 600, loss: 0.05721759796142578
step: 610, loss: 0.00106395548209548
step: 620, loss: 0.050971873104572296
step: 630, loss: 0.007638817653059959
step: 640, loss: 0.03560971841216087
step: 650, loss: 0.1109442412853241
step: 660, loss: 0.00021947675850242376
step: 670, loss: 0.006666658446192741
step: 680, loss: 0.17741957306861877
step: 690, loss: 0.035382844507694244
step: 700, loss: 0.024506505578756332
step: 710, loss: 0.020116137340664864
step: 720, loss: 0.07532286643981934
step: 730, loss: 0.03078502044081688
step: 740, loss: 0.024396376684308052
step: 750, loss: 0.004166825674474239
step: 760, loss: 0.004593739751726389
step: 770, loss: 0.005279029253870249
step: 780, loss: 0.011753150261938572
step: 790, loss: 0.10584366321563721
step: 800, loss: 0.003301650285720825
step: 810, loss: 0.024617506191134453
step: 820, loss: 0.02548985183238983
step: 830, loss: 0.04261191561818123
step: 840, loss: 0.002139588352292776
step: 850, loss: 0.009777382016181946
step: 860, loss: 0.17215672135353088
step: 870, loss: 0.014986204914748669
step: 880, loss: 0.027166569605469704
step: 890, loss: 0.02588800899684429
step: 900, loss: 0.07758548110723495
step: 910, loss: 0.13960306346416473
step: 920, loss: 0.07435542345046997
step: 930, loss: 0.02708788774907589
step: 940, loss: 0.0007099692011252046
epoch 6: dev_f1=0.95, f1=0.9264909847434121, best_f1=0.928739971684757
step: 0, loss: 0.003804410807788372
step: 10, loss: 0.00170705106575042
step: 20, loss: 0.022645259276032448
step: 30, loss: 0.2270943522453308
step: 40, loss: 0.0027385682333260775
step: 50, loss: 0.006145371589809656
step: 60, loss: 0.0044275918044149876
step: 70, loss: 0.02175034210085869
step: 80, loss: 0.017977314069867134
step: 90, loss: 0.022095125168561935
step: 100, loss: 0.0029940360691398382
step: 110, loss: 0.0029583617579191923
step: 120, loss: 0.0005507571622729301
step: 130, loss: 0.019991934299468994
step: 140, loss: 0.06116340309381485
step: 150, loss: 0.020455487072467804
step: 160, loss: 0.0016297315014526248
step: 170, loss: 0.027270499616861343
step: 180, loss: 0.11098496615886688
step: 190, loss: 0.11338599771261215
step: 200, loss: 0.000452151958597824
step: 210, loss: 0.0023231219965964556
step: 220, loss: 0.00817272998392582
step: 230, loss: 0.006186996586620808
step: 240, loss: 0.0007729399367235601
step: 250, loss: 0.05922561138868332
step: 260, loss: 0.02849992737174034
step: 270, loss: 0.0090201236307621
step: 280, loss: 0.055725567042827606
step: 290, loss: 0.002783837728202343
step: 300, loss: 0.0028296299278736115
step: 310, loss: 0.020351378247141838
step: 320, loss: 0.0017141065327450633
step: 330, loss: 0.026632290333509445
step: 340, loss: 0.00022092994186095893
step: 350, loss: 0.008235614746809006
step: 360, loss: 0.008574670180678368
step: 370, loss: 0.0028263831045478582
step: 380, loss: 0.03344530239701271
step: 390, loss: 0.1768028885126114
step: 400, loss: 0.07202591001987457
step: 410, loss: 0.0008412961033172905
step: 420, loss: 0.002701088320463896
step: 430, loss: 0.0096839414909482
step: 440, loss: 0.0010142427636310458
step: 450, loss: 0.010978355072438717
step: 460, loss: 0.003346585901454091
step: 470, loss: 0.005990041419863701
step: 480, loss: 0.0017220319714397192
step: 490, loss: 0.06800159811973572
step: 500, loss: 0.008459623903036118
step: 510, loss: 0.035946473479270935
step: 520, loss: 0.0019638545345515013
step: 530, loss: 0.001344608492217958
step: 540, loss: 0.013462935574352741
step: 550, loss: 0.327987939119339
step: 560, loss: 0.00844611506909132
step: 570, loss: 0.010374351404607296
step: 580, loss: 0.1341855525970459
step: 590, loss: 0.006140615791082382
step: 600, loss: 0.0840529352426529
step: 610, loss: 0.009489024057984352
step: 620, loss: 0.002234096173197031
step: 630, loss: 0.16389299929141998
step: 640, loss: 0.024058161303400993
step: 650, loss: 0.05065872520208359
step: 660, loss: 0.16256055235862732
step: 670, loss: 0.03321019932627678
step: 680, loss: 0.0016547117847949266
step: 690, loss: 0.006401645019650459
step: 700, loss: 0.044960521161556244
step: 710, loss: 0.0030319727957248688
step: 720, loss: 0.00038318627048283815
step: 730, loss: 0.15932202339172363
step: 740, loss: 0.0633317306637764
step: 750, loss: 0.09079411625862122
step: 760, loss: 0.034100696444511414
step: 770, loss: 0.00045151851372793317
step: 780, loss: 0.11502119153738022
step: 790, loss: 0.005431011784821749
step: 800, loss: 0.004901463631540537
step: 810, loss: 0.0012797759845852852
step: 820, loss: 0.004888792522251606
step: 830, loss: 0.02621852606534958
step: 840, loss: 0.002656380645930767
step: 850, loss: 0.010822423733770847
step: 860, loss: 0.04368577525019646
step: 870, loss: 0.002833198057487607
step: 880, loss: 0.017276886850595474
step: 890, loss: 0.006805488374084234
step: 900, loss: 0.003189146751537919
step: 910, loss: 0.01877332665026188
step: 920, loss: 0.0037319380789995193
step: 930, loss: 0.1359105110168457
step: 940, loss: 0.02329831011593342
epoch 7: dev_f1=0.9503480278422275, f1=0.9279026217228464, best_f1=0.9279026217228464
step: 0, loss: 0.0009872379014268517
step: 10, loss: 0.01748352311551571
step: 20, loss: 0.015398988500237465
step: 30, loss: 0.005120672285556793
step: 40, loss: 0.0020161832217127085
step: 50, loss: 0.026620279997587204
step: 60, loss: 0.00579781224951148
step: 70, loss: 0.0014584521995857358
step: 80, loss: 0.007999547757208347
step: 90, loss: 0.016760127618908882
step: 100, loss: 0.0027552933897823095
step: 110, loss: 0.000321925530442968
step: 120, loss: 0.0002966549654956907
step: 130, loss: 0.00265737297013402
step: 140, loss: 0.00015615516167599708
step: 150, loss: 0.10129308700561523
step: 160, loss: 0.003974697086960077
step: 170, loss: 0.0685848593711853
step: 180, loss: 0.001500095590017736
step: 190, loss: 0.0009375318186357617
step: 200, loss: 0.0020253541879355907
step: 210, loss: 0.011306176893413067
step: 220, loss: 0.0006532512488774955
step: 230, loss: 0.00283264834433794
step: 240, loss: 0.0006791781052015722
step: 250, loss: 0.0027025684248656034
step: 260, loss: 0.00424642488360405
step: 270, loss: 0.04759533330798149
step: 280, loss: 0.0013377098366618156
step: 290, loss: 0.0005669670063070953
step: 300, loss: 0.000592496304307133
step: 310, loss: 0.1542700082063675
step: 320, loss: 0.000963404483627528
step: 330, loss: 0.07849159836769104
step: 340, loss: 0.014401761814951897
step: 350, loss: 0.03140359744429588
step: 360, loss: 0.022728504613041878
step: 370, loss: 0.054694075137376785
step: 380, loss: 0.024856094270944595
step: 390, loss: 0.0002983987797051668
step: 400, loss: 0.017501212656497955
step: 410, loss: 0.00037120215711183846
step: 420, loss: 0.006486480124294758
step: 430, loss: 0.031449757516384125
step: 440, loss: 0.00169494585134089
step: 450, loss: 0.027136055752635002
step: 460, loss: 0.05717049166560173
step: 470, loss: 0.11640994995832443
step: 480, loss: 0.028129776939749718
step: 490, loss: 0.000726704893168062
step: 500, loss: 0.020924914628267288
step: 510, loss: 0.016203757375478745
step: 520, loss: 0.0012278083013370633
step: 530, loss: 0.01219145581126213
step: 540, loss: 0.006427999120205641
step: 550, loss: 0.004761295858770609
step: 560, loss: 0.001323167933151126
step: 570, loss: 0.06911242753267288
step: 580, loss: 0.026430988684296608
step: 590, loss: 0.0018419548869132996
step: 600, loss: 0.0007062233635224402
step: 610, loss: 0.003808279288932681
step: 620, loss: 0.0034481307957321405
step: 630, loss: 0.012147126719355583
step: 640, loss: 0.00012018020788673311
step: 650, loss: 0.04075070470571518
step: 660, loss: 0.001515782903879881
step: 670, loss: 0.0039327251724898815
step: 680, loss: 0.019139891490340233
step: 690, loss: 0.01946578547358513
step: 700, loss: 0.04477090388536453
step: 710, loss: 0.018390707671642303
step: 720, loss: 0.1428835690021515
step: 730, loss: 0.010331075638532639
step: 740, loss: 0.0003848455671686679
step: 750, loss: 0.02594991773366928
step: 760, loss: 0.00842277891933918
step: 770, loss: 0.0008641274180263281
step: 780, loss: 0.049181729555130005
step: 790, loss: 0.02560025081038475
step: 800, loss: 0.11870142817497253
step: 810, loss: 0.0018821859266608953
step: 820, loss: 0.018791034817695618
step: 830, loss: 0.03666658699512482
step: 840, loss: 0.0020360583439469337
step: 850, loss: 0.0006547123193740845
step: 860, loss: 0.012123110704123974
step: 870, loss: 0.04006633907556534
step: 880, loss: 0.0028618888463824987
step: 890, loss: 0.04055141285061836
step: 900, loss: 0.026115134358406067
step: 910, loss: 0.003558450611308217
step: 920, loss: 0.009937926195561886
step: 930, loss: 0.05138585343956947
step: 940, loss: 0.02537335641682148
epoch 8: dev_f1=0.9511520737327189, f1=0.9289363678588016, best_f1=0.9289363678588016
step: 0, loss: 0.004817987326532602
step: 10, loss: 0.009260477498173714
step: 20, loss: 0.0042647444643080235
step: 30, loss: 0.021501878276467323
step: 40, loss: 0.003703012829646468
step: 50, loss: 0.01270095445215702
step: 60, loss: 0.002588673960417509
step: 70, loss: 0.10083573311567307
step: 80, loss: 0.0091330511495471
step: 90, loss: 0.0005489245522767305
step: 100, loss: 0.003666684264317155
step: 110, loss: 0.04637952893972397
step: 120, loss: 0.0013785824412479997
step: 130, loss: 0.012799747288227081
step: 140, loss: 0.0019397340947762132
step: 150, loss: 0.00035885837860405445
step: 160, loss: 0.0021197644528001547
step: 170, loss: 0.002161777578294277
step: 180, loss: 0.0024423343129456043
step: 190, loss: 0.006937803700566292
step: 200, loss: 0.0003414176171645522
step: 210, loss: 0.0014593441737815738
step: 220, loss: 0.0011750137200579047
step: 230, loss: 0.016984455287456512
step: 240, loss: 0.0004927678382955492
step: 250, loss: 0.0004657828831113875
step: 260, loss: 0.00038723478792235255
step: 270, loss: 0.0006088346126489341
step: 280, loss: 0.002124669961631298
step: 290, loss: 9.805655281525105e-05
step: 300, loss: 0.001051180879585445
step: 310, loss: 0.0002014398924075067
step: 320, loss: 0.0002297937317052856
step: 330, loss: 0.01142512634396553
step: 340, loss: 0.002609212649986148
step: 350, loss: 0.00722101703286171
step: 360, loss: 0.010241223499178886
step: 370, loss: 0.05291130021214485
step: 380, loss: 0.0034915837459266186
step: 390, loss: 0.0002877507940866053
step: 400, loss: 0.04472701996564865
step: 410, loss: 0.0016881483606994152
step: 420, loss: 0.0031937877647578716
step: 430, loss: 0.0007229654002003372
step: 440, loss: 0.009739057160913944
step: 450, loss: 0.0020431717857718468
step: 460, loss: 0.11797390133142471
step: 470, loss: 0.00022126996191218495
step: 480, loss: 0.011216169223189354
step: 490, loss: 0.008551884442567825
step: 500, loss: 0.02897660993039608
step: 510, loss: 0.10799548029899597
step: 520, loss: 0.010365189984440804
step: 530, loss: 0.02193623036146164
step: 540, loss: 0.00013411944382824004
step: 550, loss: 0.000469831982627511
step: 560, loss: 0.00014026492135599256
step: 570, loss: 0.02975376881659031
step: 580, loss: 0.07704675942659378
step: 590, loss: 0.0014356473693624139
step: 600, loss: 0.0045956820249557495
step: 610, loss: 0.00931888073682785
step: 620, loss: 0.005757617764174938
step: 630, loss: 0.0016833256231620908
step: 640, loss: 0.09101170301437378
step: 650, loss: 0.0023515550419688225
step: 660, loss: 0.0075577981770038605
step: 670, loss: 0.0828118622303009
step: 680, loss: 6.598408072022721e-05
step: 690, loss: 0.0021967007778584957
step: 700, loss: 0.10353059321641922
step: 710, loss: 0.0011375406756997108
step: 720, loss: 0.0024572964757680893
step: 730, loss: 0.010409008711576462
step: 740, loss: 0.0026037718635052443
step: 750, loss: 0.001570455846376717
step: 760, loss: 0.0004958303179591894
step: 770, loss: 0.008385268971323967
step: 780, loss: 0.003916981164366007
step: 790, loss: 0.08232537657022476
step: 800, loss: 0.014644691720604897
step: 810, loss: 0.02055627666413784
step: 820, loss: 0.0013551127631217241
step: 830, loss: 0.0028418218716979027
step: 840, loss: 0.0009243898093700409
step: 850, loss: 0.003110021585598588
step: 860, loss: 0.001242655562236905
step: 870, loss: 0.05442115664482117
step: 880, loss: 0.00013047619722783566
step: 890, loss: 0.012694676406681538
step: 900, loss: 0.0007540268125012517
step: 910, loss: 0.0024740532971918583
step: 920, loss: 0.0040687136352062225
step: 930, loss: 0.02230171300470829
step: 940, loss: 0.024971788749098778
epoch 9: dev_f1=0.9478060046189377, f1=0.9310344827586207, best_f1=0.9289363678588016
step: 0, loss: 0.0006419889396056533
step: 10, loss: 0.22546401619911194
step: 20, loss: 0.03204838186502457
step: 30, loss: 0.0004310016520321369
step: 40, loss: 0.001225409796461463
step: 50, loss: 0.0013861076440662146
step: 60, loss: 8.094932127278298e-05
step: 70, loss: 0.0021727478597313166
step: 80, loss: 0.0008582301088608801
step: 90, loss: 0.007917476817965508
step: 100, loss: 0.001101818517781794
step: 110, loss: 0.0030636696610599756
step: 120, loss: 0.0008194991969503462
step: 130, loss: 0.0020662478636950254
step: 140, loss: 0.01317706611007452
step: 150, loss: 0.0017649829387664795
step: 160, loss: 0.0035449955612421036
step: 170, loss: 0.002179098082706332
step: 180, loss: 0.0013906036037951708
step: 190, loss: 0.02937730774283409
step: 200, loss: 0.014229491353034973
step: 210, loss: 0.08641289919614792
step: 220, loss: 0.00041557278018444777
step: 230, loss: 0.0033462063875049353
step: 240, loss: 0.005419108550995588
step: 250, loss: 0.010308484546840191
step: 260, loss: 8.156992407748476e-05
step: 270, loss: 0.00012494610564317554
step: 280, loss: 0.027903761714696884
step: 290, loss: 0.05988752096891403
step: 300, loss: 0.07043866068124771
step: 310, loss: 0.000895682314876467
step: 320, loss: 0.034170277416706085
step: 330, loss: 0.012321406044065952
step: 340, loss: 0.010126718319952488
step: 350, loss: 0.012736162170767784
step: 360, loss: 0.00039953357190825045
step: 370, loss: 0.04617074877023697
step: 380, loss: 0.006216930225491524
step: 390, loss: 0.0044350773096084595
step: 400, loss: 0.0002620626473799348
step: 410, loss: 0.003355652093887329
step: 420, loss: 0.0005153429810889065
step: 430, loss: 0.0002952812355943024
step: 440, loss: 0.000958433432970196
step: 450, loss: 0.07060138881206512
step: 460, loss: 0.003569435328245163
step: 470, loss: 0.041039030998945236
step: 480, loss: 9.436046093469486e-05
step: 490, loss: 0.05806395411491394
step: 500, loss: 0.004402032122015953
step: 510, loss: 0.0016403160989284515
step: 520, loss: 0.0006376811070367694
step: 530, loss: 0.006496687885373831
step: 540, loss: 0.045468684285879135
step: 550, loss: 0.000277974788332358
step: 560, loss: 0.0002844893606379628
step: 570, loss: 0.0030268975533545017
step: 580, loss: 0.00022953988809604198
step: 590, loss: 0.00040969313704408705
step: 600, loss: 0.00036438231472857296
step: 610, loss: 0.0014723296044394374
step: 620, loss: 0.0001563622645335272
step: 630, loss: 0.0033914640080183744
step: 640, loss: 0.02208898589015007
step: 650, loss: 0.00025761828874237835
step: 660, loss: 0.043024156242609024
step: 670, loss: 0.0029034558683633804
step: 680, loss: 0.001984628615900874
step: 690, loss: 0.000697149895131588
step: 700, loss: 0.03228394687175751
step: 710, loss: 0.024614715948700905
step: 720, loss: 0.15692247450351715
step: 730, loss: 0.0011379866627976298
step: 740, loss: 0.00015715420886408538
step: 750, loss: 0.0020890107844024897
step: 760, loss: 0.04563618823885918
step: 770, loss: 0.01230967789888382
step: 780, loss: 0.0006672284798696637
step: 790, loss: 0.002106651896610856
step: 800, loss: 0.0641629621386528
step: 810, loss: 0.0008799771312624216
step: 820, loss: 0.001328547834418714
step: 830, loss: 0.12694957852363586
step: 840, loss: 0.0006748393643647432
step: 850, loss: 0.028182396665215492
step: 860, loss: 0.008974355645477772
step: 870, loss: 0.07508288323879242
step: 880, loss: 0.0006776477675884962
step: 890, loss: 0.010750547051429749
step: 900, loss: 0.007040944416075945
step: 910, loss: 0.0009161765919998288
step: 920, loss: 0.00011596282274695113
step: 930, loss: 0.0018278436036780477
step: 940, loss: 0.005514636170119047
epoch 10: dev_f1=0.9462465245597776, f1=0.932274638019617, best_f1=0.9289363678588016
step: 0, loss: 0.001602605334483087
step: 10, loss: 0.0013805889757350087
step: 20, loss: 0.00010427123197587207
step: 30, loss: 0.0006375160301104188
step: 40, loss: 0.002250144723802805
step: 50, loss: 0.0026274702977389097
step: 60, loss: 0.11006741970777512
step: 70, loss: 0.003999654203653336
step: 80, loss: 0.0016066988464444876
step: 90, loss: 0.0058187865652143955
step: 100, loss: 0.0012318524532020092
step: 110, loss: 0.0010777328861877322
step: 120, loss: 0.00013408789527602494
step: 130, loss: 0.0012249399442225695
step: 140, loss: 0.0002327536349184811
step: 150, loss: 0.0031334259547293186
step: 160, loss: 6.487611244665459e-05
step: 170, loss: 0.00020423956448212266
step: 180, loss: 0.004105597268790007
step: 190, loss: 0.0008599355351179838
step: 200, loss: 0.00043596900650300086
step: 210, loss: 0.0921260416507721
step: 220, loss: 0.0020580801647156477
step: 230, loss: 0.0774579718708992
step: 240, loss: 0.006470357533544302
step: 250, loss: 0.0014896959764882922
step: 260, loss: 0.0001848133688326925
step: 270, loss: 0.006029792129993439
step: 280, loss: 4.973454269929789e-05
step: 290, loss: 0.00016046296514105052
step: 300, loss: 0.006592518649995327
step: 310, loss: 0.00010460501653142273
step: 320, loss: 0.13991208374500275
step: 330, loss: 0.0006765103898942471
step: 340, loss: 0.016933593899011612
step: 350, loss: 0.00023018014326225966
step: 360, loss: 0.0009154186700470746
step: 370, loss: 0.00018945732153952122
step: 380, loss: 0.0001726004120428115
step: 390, loss: 0.015135437250137329
step: 400, loss: 0.012455755844712257
step: 410, loss: 0.010041612200438976
step: 420, loss: 7.335681584663689e-05
step: 430, loss: 0.0014435993507504463
step: 440, loss: 0.04904690384864807
step: 450, loss: 0.006658019032329321
step: 460, loss: 0.016635097563266754
step: 470, loss: 0.014577154070138931
step: 480, loss: 0.0008101814310066402
step: 490, loss: 0.009719645604491234
step: 500, loss: 0.0008649221272207797
step: 510, loss: 0.00020415543986018747
step: 520, loss: 0.004233487881720066
step: 530, loss: 0.00031234073685482144
step: 540, loss: 0.00016518191841896623
step: 550, loss: 0.000195489774341695
step: 560, loss: 0.007200509309768677
step: 570, loss: 0.00027858756948262453
step: 580, loss: 0.0005897428491152823
step: 590, loss: 0.004177991300821304
step: 600, loss: 4.472668297239579e-05
step: 610, loss: 0.0001609798928257078
step: 620, loss: 0.00032008704147301614
step: 630, loss: 0.00820344127714634
step: 640, loss: 0.03175085037946701
step: 650, loss: 0.0001495261094532907
step: 660, loss: 0.00010704315354814753
step: 670, loss: 0.0007036316092126071
step: 680, loss: 0.1709548979997635
step: 690, loss: 0.0025260928086936474
step: 700, loss: 0.0006416455726139247
step: 710, loss: 0.00024964712793007493
step: 720, loss: 0.004551176447421312
step: 730, loss: 0.0031275791116058826
step: 740, loss: 0.002020904328674078
step: 750, loss: 0.0004603010311257094
step: 760, loss: 0.008472560904920101
step: 770, loss: 0.00017194611427839845
step: 780, loss: 0.029572468250989914
step: 790, loss: 0.0019366205669939518
step: 800, loss: 0.015284448862075806
step: 810, loss: 0.007568140979856253
step: 820, loss: 0.00128104817122221
step: 830, loss: 0.0004638533282559365
step: 840, loss: 0.014042852446436882
step: 850, loss: 0.0004646560992114246
step: 860, loss: 0.07966508716344833
step: 870, loss: 0.005427805706858635
step: 880, loss: 0.0027348524890840054
step: 890, loss: 0.003030843334272504
step: 900, loss: 0.007448489312082529
step: 910, loss: 0.00016774545656517148
step: 920, loss: 0.006910425145179033
step: 930, loss: 0.0037013646215200424
step: 940, loss: 0.0011874872725456953
epoch 11: dev_f1=0.9487895716945998, f1=0.9292076887013595, best_f1=0.9289363678588016
step: 0, loss: 0.0021324504632502794
step: 10, loss: 0.0026329434476792812
step: 20, loss: 0.00010399845632491633
step: 30, loss: 7.554279727628455e-05
step: 40, loss: 0.0008532892679795623
step: 50, loss: 0.0009246996487490833
step: 60, loss: 0.0014655296690762043
step: 70, loss: 8.634005644125864e-05
step: 80, loss: 0.0002685390936676413
step: 90, loss: 0.00010343513713451102
step: 100, loss: 4.5464035792974755e-05
step: 110, loss: 0.0002809508005157113
step: 120, loss: 0.040850840508937836
step: 130, loss: 0.18727310001850128
step: 140, loss: 0.013714960776269436
step: 150, loss: 0.005933028645813465
step: 160, loss: 0.000153417800902389
step: 170, loss: 0.0007342332974076271
step: 180, loss: 0.00010753795504570007
step: 190, loss: 0.0002685159561224282
step: 200, loss: 0.0010812639957293868
step: 210, loss: 4.095675467397086e-05
step: 220, loss: 0.00016287158359773457
step: 230, loss: 0.015745531767606735
step: 240, loss: 0.02562992461025715
step: 250, loss: 0.005511073861271143
step: 260, loss: 0.00024960775044746697
step: 270, loss: 0.007316171191632748
step: 280, loss: 2.301413223904092e-05
step: 290, loss: 0.00027075893012806773
step: 300, loss: 0.0001922015071613714
step: 310, loss: 0.00023208158381748945
step: 320, loss: 0.00020410506112966686
step: 330, loss: 6.768219463992864e-05
step: 340, loss: 0.0014123332221060991
step: 350, loss: 9.124559437623248e-05
step: 360, loss: 0.0006624266388826072
step: 370, loss: 0.07498467713594437
step: 380, loss: 0.11749672144651413
step: 390, loss: 0.001208407455123961
step: 400, loss: 0.00013244905858300626
step: 410, loss: 6.241050141397864e-05
step: 420, loss: 0.00259161414578557
step: 430, loss: 9.945741476258263e-05
step: 440, loss: 0.0003290477907285094
step: 450, loss: 0.0006265505217015743
step: 460, loss: 0.0020650203805416822
step: 470, loss: 5.0421054766047746e-05
step: 480, loss: 0.00025617852224968374
step: 490, loss: 0.0007657213718630373
step: 500, loss: 0.0007302616140805185
step: 510, loss: 0.0013218418462201953
step: 520, loss: 0.00022202575928531587
step: 530, loss: 0.0001476683682994917
step: 540, loss: 0.00011864827683893964
step: 550, loss: 5.9263675211695954e-05
step: 560, loss: 0.011660653166472912
step: 570, loss: 0.036750707775354385
step: 580, loss: 0.0006932736723683774
step: 590, loss: 6.19284255662933e-05
step: 600, loss: 0.019951164722442627
step: 610, loss: 0.0006106782821007073
step: 620, loss: 0.0006055138655938208
step: 630, loss: 0.00014676805585622787
step: 640, loss: 0.015347561798989773
step: 650, loss: 0.0012065810151398182
step: 660, loss: 0.00011924125283258036
step: 670, loss: 0.001055389060638845
step: 680, loss: 0.0011255929712206125
step: 690, loss: 0.0976056456565857
step: 700, loss: 0.00029124843422323465
step: 710, loss: 0.00019626396533567458
step: 720, loss: 0.00032911941525526345
step: 730, loss: 0.017778949812054634
step: 740, loss: 0.003868676722049713
step: 750, loss: 0.000542056281119585
step: 760, loss: 0.0006438873242586851
step: 770, loss: 0.0330021046102047
step: 780, loss: 0.0036295989993959665
step: 790, loss: 0.14307628571987152
step: 800, loss: 0.1710587739944458
step: 810, loss: 0.01331652794033289
step: 820, loss: 0.1143331527709961
step: 830, loss: 0.00016964651877060533
step: 840, loss: 0.007376078516244888
step: 850, loss: 0.0001709252828732133
step: 860, loss: 0.001071725389920175
step: 870, loss: 0.03434033691883087
step: 880, loss: 0.0008124999003484845
step: 890, loss: 0.0003930232487618923
step: 900, loss: 0.0015351083129644394
step: 910, loss: 0.0003201091312803328
step: 920, loss: 0.0041710683144629
step: 930, loss: 0.0036635722499340773
step: 940, loss: 0.0021413820795714855
epoch 12: dev_f1=0.9471243042671614, f1=0.933083762283575, best_f1=0.9289363678588016
step: 0, loss: 0.0003201640211045742
step: 10, loss: 0.004495807457715273
step: 20, loss: 0.001732238451950252
step: 30, loss: 4.152170367888175e-05
step: 40, loss: 0.001306772930547595
step: 50, loss: 0.001112618250772357
step: 60, loss: 0.010949315503239632
step: 70, loss: 0.0001346621138509363
step: 80, loss: 0.0009681046940386295
step: 90, loss: 0.010128055699169636
step: 100, loss: 0.00018784130224958062
step: 110, loss: 9.825162851484492e-05
step: 120, loss: 0.0009498227154836059
step: 130, loss: 0.0002901799452956766
step: 140, loss: 0.022869497537612915
step: 150, loss: 0.0004694836970884353
step: 160, loss: 0.000317455327603966
step: 170, loss: 0.0043143052607774734
step: 180, loss: 0.00024194316938519478
step: 190, loss: 0.00022045246441848576
step: 200, loss: 0.0004118325305171311
step: 210, loss: 6.032316741766408e-05
step: 220, loss: 0.00010589798330329359
step: 230, loss: 5.636127389152534e-05
step: 240, loss: 0.0005470407195389271
step: 250, loss: 0.0004319604195188731
step: 260, loss: 0.00042484229197725654
step: 270, loss: 0.0008867953438311815
step: 280, loss: 0.0019563946407288313
step: 290, loss: 0.009740733541548252
step: 300, loss: 0.00018283736426383257
step: 310, loss: 0.00044663273729383945
step: 320, loss: 0.0021896588150411844
step: 330, loss: 0.0005185707123018801
step: 340, loss: 0.0008419175865128636
step: 350, loss: 0.0011879418743774295
step: 360, loss: 0.0003457517013885081
step: 370, loss: 6.358150130836293e-05
step: 380, loss: 0.012669176794588566
step: 390, loss: 0.009659972973167896
step: 400, loss: 0.003496285295113921
step: 410, loss: 0.002685558283701539
step: 420, loss: 0.0016321474686264992
step: 430, loss: 0.0008818747010082006
step: 440, loss: 0.0008999528945423663
step: 450, loss: 0.00030379797681234777
step: 460, loss: 0.0009564912179484963
step: 470, loss: 0.007177605293691158
step: 480, loss: 0.0008284664945676923
step: 490, loss: 0.021351858973503113
step: 500, loss: 0.001372179831378162
step: 510, loss: 0.001119251479394734
step: 520, loss: 0.020680496469140053
step: 530, loss: 0.005734717007726431
step: 540, loss: 0.0005031125037930906
step: 550, loss: 0.0001726398477330804
step: 560, loss: 0.002409248147159815
step: 570, loss: 7.135194755392149e-05
step: 580, loss: 9.314451745012775e-05
step: 590, loss: 0.00041420385241508484
step: 600, loss: 0.0014820060459896922
step: 610, loss: 3.892616950906813e-05
step: 620, loss: 0.0001962760288733989
step: 630, loss: 0.0003042912867385894
step: 640, loss: 0.0032282662577927113
step: 650, loss: 0.023485971614718437
step: 660, loss: 0.0054536378011107445
step: 670, loss: 0.0006406400352716446
step: 680, loss: 0.00023287406656891108
step: 690, loss: 0.0033294244203716516
step: 700, loss: 0.012871436774730682
step: 710, loss: 0.0007703712326474488
step: 720, loss: 0.0037539927288889885
step: 730, loss: 0.00017383488011546433
step: 740, loss: 0.026481643319129944
step: 750, loss: 0.040656864643096924
step: 760, loss: 0.07468313723802567
step: 770, loss: 0.00018723552057053894
step: 780, loss: 0.03634604811668396
step: 790, loss: 0.0004988930304534733
step: 800, loss: 0.000546938506886363
step: 810, loss: 0.0022448308300226927
step: 820, loss: 0.0020146132446825504
step: 830, loss: 0.0019672177731990814
step: 840, loss: 0.04694352671504021
step: 850, loss: 0.003599627409130335
step: 860, loss: 0.032161496579647064
step: 870, loss: 0.005865098908543587
step: 880, loss: 8.241961768362671e-05
step: 890, loss: 0.03623791038990021
step: 900, loss: 0.006218237802386284
step: 910, loss: 0.0001659661647863686
step: 920, loss: 0.0028953629080206156
step: 930, loss: 0.0009037989075295627
step: 940, loss: 0.0001980652305064723
epoch 13: dev_f1=0.9526462395543175, f1=0.9321478708469817, best_f1=0.9321478708469817
step: 0, loss: 0.0013400620082393289
step: 10, loss: 0.00011844226537505165
step: 20, loss: 0.00011323102080496028
step: 30, loss: 0.0011955949012190104
step: 40, loss: 0.020870335400104523
step: 50, loss: 0.00021546281641349196
step: 60, loss: 0.0033645061776041985
step: 70, loss: 0.005172793287783861
step: 80, loss: 0.052488815039396286
step: 90, loss: 0.03672610595822334
step: 100, loss: 0.0022854807320982218
step: 110, loss: 0.0007928091217763722
step: 120, loss: 0.004452075809240341
step: 130, loss: 0.00021324642875697464
step: 140, loss: 0.0004584561684168875
step: 150, loss: 0.0007873573340475559
step: 160, loss: 0.00026146939489990473
step: 170, loss: 3.008298335771542e-05
step: 180, loss: 8.076956146396697e-05
step: 190, loss: 4.362560866866261e-05
step: 200, loss: 0.00039767741691321135
step: 210, loss: 0.0012118493905290961
step: 220, loss: 3.2015752367442474e-05
step: 230, loss: 3.256859054090455e-05
step: 240, loss: 0.03352077677845955
step: 250, loss: 0.0004095238109584898
step: 260, loss: 0.006517946720123291
step: 270, loss: 8.838120993459597e-05
step: 280, loss: 0.02028736099600792
step: 290, loss: 0.0014269878156483173
step: 300, loss: 8.503641583956778e-05
step: 310, loss: 0.03831719979643822
step: 320, loss: 0.025300893932580948
step: 330, loss: 0.0003456820850260556
step: 340, loss: 0.0006389440968632698
step: 350, loss: 0.00017220820882357657
step: 360, loss: 0.01903945580124855
step: 370, loss: 0.0007766127237118781
step: 380, loss: 0.0006731863250024617
step: 390, loss: 0.00025553759769536555
step: 400, loss: 0.0001918693451443687
step: 410, loss: 5.870837776456028e-05
step: 420, loss: 0.0020418628118932247
step: 430, loss: 6.319554086076096e-05
step: 440, loss: 6.403912993846461e-05
step: 450, loss: 0.037729647010564804
step: 460, loss: 6.620164640480652e-05
step: 470, loss: 3.113374623353593e-05
step: 480, loss: 5.547242108150385e-05
step: 490, loss: 1.95423072000267e-05
step: 500, loss: 0.000629046349786222
step: 510, loss: 0.00012504355981945992
step: 520, loss: 0.0003781096893362701
step: 530, loss: 0.054227378219366074
step: 540, loss: 0.010318511165678501
step: 550, loss: 0.001673343824222684
step: 560, loss: 0.05663503706455231
step: 570, loss: 0.008372222073376179
step: 580, loss: 0.009458089247345924
step: 590, loss: 0.02681528776884079
step: 600, loss: 0.003796135541051626
step: 610, loss: 0.00022410432575270534
step: 620, loss: 0.08320789784193039
step: 630, loss: 0.0015300107188522816
step: 640, loss: 0.0010315912077203393
step: 650, loss: 0.011123630218207836
step: 660, loss: 0.00011436193744884804
step: 670, loss: 0.0026295401621609926
step: 680, loss: 0.01351477112621069
step: 690, loss: 0.0014866498531773686
step: 700, loss: 0.00010462122008902952
step: 710, loss: 0.0021803127601742744
step: 720, loss: 0.005225145723670721
step: 730, loss: 0.00019240703841205686
step: 740, loss: 0.0011074802605435252
step: 750, loss: 0.0012252256274223328
step: 760, loss: 1.4215514966053888e-05
step: 770, loss: 4.916069156024605e-05
step: 780, loss: 0.0019187682773917913
step: 790, loss: 0.001632240368053317
step: 800, loss: 0.0014169709756970406
step: 810, loss: 0.000293448509182781
step: 820, loss: 0.00047423303476534784
step: 830, loss: 0.00016132619930431247
step: 840, loss: 0.0016000231262296438
step: 850, loss: 3.021313386852853e-05
step: 860, loss: 0.002260227221995592
step: 870, loss: 3.322303018649109e-05
step: 880, loss: 0.061651792377233505
step: 890, loss: 0.00021465866302605718
step: 900, loss: 7.014984294073656e-05
step: 910, loss: 0.0014683972112834454
step: 920, loss: 6.414551171474159e-05
step: 930, loss: 0.00021325393754523247
step: 940, loss: 0.15991628170013428
epoch 14: dev_f1=0.9476124246638852, f1=0.9351981351981352, best_f1=0.9321478708469817
step: 0, loss: 0.027490539476275444
step: 10, loss: 0.0005860537639819086
step: 20, loss: 0.0007600441458635032
step: 30, loss: 0.00036815763451159
step: 40, loss: 0.00030037324177101254
step: 50, loss: 0.12467566132545471
step: 60, loss: 0.0032371385022997856
step: 70, loss: 0.004700551275163889
step: 80, loss: 0.0014299623435363173
step: 90, loss: 0.0017060578102245927
step: 100, loss: 0.022769568488001823
step: 110, loss: 0.0007183938869275153
step: 120, loss: 0.0005211218958720565
step: 130, loss: 0.0011035352945327759
step: 140, loss: 4.322986933402717e-05
step: 150, loss: 0.0006395502714440227
step: 160, loss: 0.009540831670165062
step: 170, loss: 0.00021849713812116534
step: 180, loss: 4.0763214201433584e-05
step: 190, loss: 0.011567344889044762
step: 200, loss: 0.0006172396242618561
step: 210, loss: 0.00020993349608033895
step: 220, loss: 0.011267578229308128
step: 230, loss: 0.022401170805096626
step: 240, loss: 0.0008090086048468947
step: 250, loss: 0.04432196542620659
step: 260, loss: 0.00831800140440464
step: 270, loss: 0.0003737958031706512
step: 280, loss: 0.011113699525594711
step: 290, loss: 0.0004710123175755143
step: 300, loss: 0.0007192048942670226
step: 310, loss: 0.003193911397829652
step: 320, loss: 0.002001181710511446
step: 330, loss: 6.877278065076098e-05
step: 340, loss: 0.00014221321907825768
step: 350, loss: 6.014257451170124e-05
step: 360, loss: 0.0030009481124579906
step: 370, loss: 0.000679574441164732
step: 380, loss: 0.0010269194608554244
step: 390, loss: 0.00014543553697876632
step: 400, loss: 0.0002633118419907987
step: 410, loss: 0.0006366278976202011
step: 420, loss: 0.00011636019917204976
step: 430, loss: 2.3360466002486646e-05
step: 440, loss: 0.002529183402657509
step: 450, loss: 0.0005942128482274711
step: 460, loss: 5.7701912737684324e-05
step: 470, loss: 9.162589412881061e-05
step: 480, loss: 5.7239391026087105e-05
step: 490, loss: 7.161107350839302e-05
step: 500, loss: 0.00010313494567526504
step: 510, loss: 3.0896357202436775e-05
step: 520, loss: 0.00015913673269096762
step: 530, loss: 0.00019031345436815172
step: 540, loss: 3.700124580063857e-05
step: 550, loss: 0.0034239343367516994
step: 560, loss: 0.00011607923806877807
step: 570, loss: 6.822453724453226e-05
step: 580, loss: 0.0007477325852960348
step: 590, loss: 8.847462595440447e-05
step: 600, loss: 0.00023381981009151787
step: 610, loss: 5.4567630286328495e-05
step: 620, loss: 5.9129888541065156e-05
step: 630, loss: 5.309821790433489e-05
step: 640, loss: 9.79767573880963e-05
step: 650, loss: 8.635928679723293e-05
step: 660, loss: 0.000134030167828314
step: 670, loss: 9.052561654243618e-05
step: 680, loss: 8.835272456053644e-05
step: 690, loss: 3.7086341762915254e-05
step: 700, loss: 0.00010065449168905616
step: 710, loss: 0.0015262090601027012
step: 720, loss: 0.02042868733406067
step: 730, loss: 0.003317487658932805
step: 740, loss: 0.001551119377836585
step: 750, loss: 1.9553513993741944e-05
step: 760, loss: 5.169847281649709e-05
step: 770, loss: 0.000850886688567698
step: 780, loss: 0.0001847077364800498
step: 790, loss: 8.61878288560547e-05
step: 800, loss: 0.001394139602780342
step: 810, loss: 0.013319030404090881
step: 820, loss: 5.316433816915378e-05
step: 830, loss: 0.0004150118329562247
step: 840, loss: 0.00013355100236367434
step: 850, loss: 0.0013125379336997867
step: 860, loss: 5.4700649343430996e-05
step: 870, loss: 9.699568181531504e-05
step: 880, loss: 0.0004856647574342787
step: 890, loss: 7.021187047939748e-05
step: 900, loss: 6.057368955225684e-05
step: 910, loss: 3.7234494811855257e-05
step: 920, loss: 3.100369940511882e-05
step: 930, loss: 0.002571557415649295
step: 940, loss: 0.0021592366974800825
epoch 15: dev_f1=0.9489795918367347, f1=0.9312119794103885, best_f1=0.9321478708469817
step: 0, loss: 6.924523040652275e-05
step: 10, loss: 2.5927016395144165e-05
step: 20, loss: 4.6990273403935134e-05
step: 30, loss: 0.00013131012383382767
step: 40, loss: 9.941935422830284e-05
step: 50, loss: 0.00017459294758737087
step: 60, loss: 0.00017794680024962872
step: 70, loss: 6.374049553414807e-05
step: 80, loss: 0.0001391990081174299
step: 90, loss: 0.00029352118144743145
step: 100, loss: 3.8553054764634e-05
step: 110, loss: 0.0013277381658554077
step: 120, loss: 0.0014854322653263807
step: 130, loss: 2.5520506824250333e-05
step: 140, loss: 2.8359376301523298e-05
step: 150, loss: 6.86186904204078e-05
step: 160, loss: 0.00015080890443641692
step: 170, loss: 0.0002531734644435346
step: 180, loss: 7.445076334988698e-05
step: 190, loss: 4.012939825770445e-05
step: 200, loss: 0.000812021957244724
step: 210, loss: 0.003239296143874526
step: 220, loss: 0.0006413325318135321
step: 230, loss: 0.0004457228060346097
step: 240, loss: 0.00018652176368050277
step: 250, loss: 6.69465953251347e-05
step: 260, loss: 0.0075926813296973705
step: 270, loss: 9.00305894901976e-05
step: 280, loss: 0.027719851583242416
step: 290, loss: 5.0663406000239775e-05
step: 300, loss: 0.0010342891328036785
step: 310, loss: 7.623666897416115e-05
step: 320, loss: 0.027085669338703156
step: 330, loss: 1.661060559854377e-05
step: 340, loss: 0.016812745481729507
step: 350, loss: 0.00028789229691028595
step: 360, loss: 2.3325788788497448e-05
step: 370, loss: 0.00040508437086828053
step: 380, loss: 0.0001586460421094671
step: 390, loss: 3.12072406813968e-05
step: 400, loss: 0.0008924994617700577
step: 410, loss: 0.0001943471288541332
step: 420, loss: 0.0008736596209928393
step: 430, loss: 3.6507772165350616e-05
step: 440, loss: 0.0002353322197450325
step: 450, loss: 0.0002989396161865443
step: 460, loss: 3.623392331064679e-05
step: 470, loss: 0.00011676483700284734
step: 480, loss: 5.791068178950809e-05
step: 490, loss: 5.660419265041128e-05
step: 500, loss: 0.00041466421680524945
step: 510, loss: 0.00041055085603147745
step: 520, loss: 0.00023503707780037075
step: 530, loss: 9.598156611900777e-05
step: 540, loss: 8.862429967848584e-05
step: 550, loss: 0.0004013592842966318
step: 560, loss: 0.0007253809599205852
step: 570, loss: 7.140516390791163e-05
step: 580, loss: 4.6740104153286666e-05
step: 590, loss: 5.084839358460158e-05
step: 600, loss: 0.0011397962225601077
step: 610, loss: 1.924054231494665e-05
step: 620, loss: 0.00020132411736994982
step: 630, loss: 3.0181834517861716e-05
step: 640, loss: 4.0031336538959295e-05
step: 650, loss: 0.0009215212776325643
step: 660, loss: 3.0716113542439416e-05
step: 670, loss: 0.0002170450461562723
step: 680, loss: 0.00043468092917464674
step: 690, loss: 0.09993881732225418
step: 700, loss: 0.0002001948596443981
step: 710, loss: 3.899298098986037e-05
step: 720, loss: 0.010683104395866394
step: 730, loss: 0.0005031349137425423
step: 740, loss: 0.0018380649853497744
step: 750, loss: 4.080563667230308e-05
step: 760, loss: 3.306196231278591e-05
step: 770, loss: 0.0922967940568924
step: 780, loss: 0.00016481186321470886
step: 790, loss: 0.0020279898308217525
step: 800, loss: 2.675778159755282e-05
step: 810, loss: 1.6878891983651556e-05
step: 820, loss: 8.843519754009321e-05
step: 830, loss: 0.009142315946519375
step: 840, loss: 0.0014413141179829836
step: 850, loss: 0.00010820426541613415
step: 860, loss: 9.209057316184044e-05
step: 870, loss: 0.00015208007243927568
step: 880, loss: 0.05831770971417427
step: 890, loss: 2.3304473870666698e-05
step: 900, loss: 0.00029329952667467296
step: 910, loss: 0.00031549850245937705
step: 920, loss: 0.0019708373583853245
step: 930, loss: 2.4936083718785085e-05
step: 940, loss: 0.005545550957322121
epoch 16: dev_f1=0.9489939167056621, f1=0.9346497414198403, best_f1=0.9321478708469817
step: 0, loss: 0.0006822864525020123
step: 10, loss: 5.756513201049529e-05
step: 20, loss: 3.618498521973379e-05
step: 30, loss: 0.00019895077275577933
step: 40, loss: 0.0006215475150384009
step: 50, loss: 4.358115256763995e-05
step: 60, loss: 0.006152309011667967
step: 70, loss: 6.662534724455327e-05
step: 80, loss: 4.3014522816520184e-05
step: 90, loss: 0.0023244526237249374
step: 100, loss: 0.06524363160133362
step: 110, loss: 8.986076863948256e-05
step: 120, loss: 0.0021876092068850994
step: 130, loss: 0.0019815166015177965
step: 140, loss: 0.00012081519525963813
step: 150, loss: 0.0011506136506795883
step: 160, loss: 0.0003544097417034209
step: 170, loss: 0.0003813223447650671
step: 180, loss: 0.002236615866422653
step: 190, loss: 1.777646320988424e-05
step: 200, loss: 7.775436824886128e-05
step: 210, loss: 0.10403761267662048
step: 220, loss: 0.0008596119005233049
step: 230, loss: 0.0011293550487607718
step: 240, loss: 0.00013606768334284425
step: 250, loss: 0.020472325384616852
step: 260, loss: 0.0001054753884091042
step: 270, loss: 5.4985241149552166e-05
step: 280, loss: 0.00013195766950957477
step: 290, loss: 4.4970118324272335e-05
step: 300, loss: 6.310531898634508e-05
step: 310, loss: 0.00018444481247570366
step: 320, loss: 0.0010393373668193817
step: 330, loss: 8.307238749694079e-05
step: 340, loss: 3.832983929896727e-05
step: 350, loss: 2.2424077542382292e-05
step: 360, loss: 0.00023387387045659125
step: 370, loss: 8.033193444134668e-05
step: 380, loss: 0.00046129096881486475
step: 390, loss: 0.0001305561454501003
step: 400, loss: 0.00013670687621925026
step: 410, loss: 0.014267428778111935
step: 420, loss: 0.013991178944706917
step: 430, loss: 0.0013820324093103409
step: 440, loss: 0.0016790879890322685
step: 450, loss: 0.0009301057434640825
step: 460, loss: 7.867916428949684e-05
step: 470, loss: 0.00028364919126033783
step: 480, loss: 2.5841038223006763e-05
step: 490, loss: 3.6231136618880555e-05
step: 500, loss: 0.0004073409072589129
step: 510, loss: 3.7481786421267316e-05
step: 520, loss: 2.3263481125468388e-05
step: 530, loss: 1.5660616554669105e-05
step: 540, loss: 0.000324506894685328
step: 550, loss: 0.00034539346233941615
step: 560, loss: 3.757915328606032e-05
step: 570, loss: 0.01029805839061737
step: 580, loss: 0.008193169720470905
step: 590, loss: 9.78404568741098e-05
step: 600, loss: 2.920149199781008e-05
step: 610, loss: 4.8179328587139025e-05
step: 620, loss: 0.007720934692770243
step: 630, loss: 5.3349991503637284e-05
step: 640, loss: 6.500538438558578e-05
step: 650, loss: 8.130676724249497e-05
step: 660, loss: 9.795925143407658e-05
step: 670, loss: 0.00024123152252286673
step: 680, loss: 4.050668576383032e-05
step: 690, loss: 8.037502266233787e-05
step: 700, loss: 8.728662214707583e-05
step: 710, loss: 0.00048110331408679485
step: 720, loss: 0.0019283504225313663
step: 730, loss: 0.0002819103538058698
step: 740, loss: 9.202518413076177e-05
step: 750, loss: 0.023877091705799103
step: 760, loss: 0.001817844109609723
step: 770, loss: 8.953196083894e-05
step: 780, loss: 4.8074340156745166e-05
step: 790, loss: 0.00010990061855409294
step: 800, loss: 6.97622454026714e-05
step: 810, loss: 0.00018127367366105318
step: 820, loss: 0.00010447729437146336
step: 830, loss: 0.00014308971003629267
step: 840, loss: 0.00038028982817195356
step: 850, loss: 0.0018312695901840925
step: 860, loss: 5.338947084965184e-05
step: 870, loss: 3.9438069507014006e-05
step: 880, loss: 0.0017062003025785089
step: 890, loss: 0.0004035512392874807
step: 900, loss: 0.00017167940677609295
step: 910, loss: 0.0009731724858283997
step: 920, loss: 0.00809992291033268
step: 930, loss: 8.405176049564034e-05
step: 940, loss: 0.000832966121379286
epoch 17: dev_f1=0.9502093997208004, f1=0.9337094499294781, best_f1=0.9321478708469817
step: 0, loss: 9.235901961801574e-05
step: 10, loss: 9.439067071070895e-05
step: 20, loss: 0.00022037244343664497
step: 30, loss: 0.00018427264876663685
step: 40, loss: 8.637701830593869e-05
step: 50, loss: 0.0002037512749666348
step: 60, loss: 9.29201632970944e-05
step: 70, loss: 3.7871355743845925e-05
step: 80, loss: 5.4087882745079696e-05
step: 90, loss: 2.5751178327482194e-05
step: 100, loss: 6.741939432686195e-05
step: 110, loss: 3.0135443012113683e-05
step: 120, loss: 1.6953263184404932e-05
step: 130, loss: 0.00029079391970299184
step: 140, loss: 2.3229529688251205e-05
step: 150, loss: 0.00017314424621872604
step: 160, loss: 0.0001511689624749124
step: 170, loss: 6.993882561801001e-05
step: 180, loss: 0.00011358564370311797
step: 190, loss: 0.0002513333747629076
step: 200, loss: 0.0001668421900831163
step: 210, loss: 7.918687333585694e-05
step: 220, loss: 0.04834914952516556
step: 230, loss: 2.259989923913963e-05
step: 240, loss: 1.8465580069459975e-05
step: 250, loss: 5.679282185155898e-05
step: 260, loss: 0.0010510314023122191
step: 270, loss: 2.3247996068676002e-05
step: 280, loss: 5.576219336944632e-05
step: 290, loss: 9.760409739101306e-05
step: 300, loss: 0.00508217653259635
step: 310, loss: 4.452832945389673e-05
step: 320, loss: 1.3723538359045051e-05
step: 330, loss: 1.281472486880375e-05
step: 340, loss: 0.044211164116859436
step: 350, loss: 0.00012049110227962956
step: 360, loss: 0.0002441965334583074
step: 370, loss: 0.00012019809946650639
step: 380, loss: 5.374663305701688e-05
step: 390, loss: 2.747725920926314e-05
step: 400, loss: 0.00010106064291903749
step: 410, loss: 0.00038039564969949424
step: 420, loss: 0.0001303185272263363
step: 430, loss: 0.00029522666591219604
step: 440, loss: 1.3183604096411727e-05
step: 450, loss: 0.00043434699182398617
step: 460, loss: 0.000504406460095197
step: 470, loss: 1.6260339180007577e-05
step: 480, loss: 0.0004982436657883227
step: 490, loss: 2.307658905920107e-05
step: 500, loss: 0.00038087766733951867
step: 510, loss: 8.685076318215579e-05
step: 520, loss: 3.7287922168616205e-05
step: 530, loss: 6.452028173953295e-05
step: 540, loss: 3.169949559378438e-05
step: 550, loss: 0.000595654419157654
step: 560, loss: 4.939582504448481e-05
step: 570, loss: 0.010039438493549824
step: 580, loss: 2.6511434043641202e-05
step: 590, loss: 0.000316437566652894
step: 600, loss: 9.34562849579379e-05
step: 610, loss: 2.130399298039265e-05
step: 620, loss: 3.779727194341831e-05
step: 630, loss: 0.00011058177187805995
step: 640, loss: 0.00019800734298769385
step: 650, loss: 6.551019760081545e-05
step: 660, loss: 1.518380031484412e-05
step: 670, loss: 3.4481876355130225e-05
step: 680, loss: 4.949885988025926e-05
step: 690, loss: 0.00010521071817493066
step: 700, loss: 0.00011312012793496251
step: 710, loss: 3.001841287186835e-05
step: 720, loss: 0.0001768005167832598
step: 730, loss: 4.9156558816321194e-05
step: 740, loss: 0.004614651203155518
step: 750, loss: 6.636946636717767e-05
step: 760, loss: 1.7467167708673514e-05
step: 770, loss: 7.788456423440948e-05
step: 780, loss: 0.0006095199496485293
step: 790, loss: 7.113995525287464e-05
step: 800, loss: 2.920843689935282e-05
step: 810, loss: 4.812690167455003e-05
step: 820, loss: 8.875240746419877e-05
step: 830, loss: 0.0016944196540862322
step: 840, loss: 0.0005727993557229638
step: 850, loss: 2.719247277127579e-05
step: 860, loss: 0.0007278608973138034
step: 870, loss: 0.00018302700482308865
step: 880, loss: 1.146986960520735e-05
step: 890, loss: 3.101140464423224e-05
step: 900, loss: 0.00032858795020729303
step: 910, loss: 0.004449959844350815
step: 920, loss: 0.0002827938587870449
step: 930, loss: 6.265034608077258e-05
step: 940, loss: 0.001226015854626894
epoch 18: dev_f1=0.9480519480519481, f1=0.9298823529411765, best_f1=0.9321478708469817
step: 0, loss: 0.004340773914009333
step: 10, loss: 7.772499520797282e-05
step: 20, loss: 0.00014519196702167392
step: 30, loss: 5.8669756981544197e-05
step: 40, loss: 3.018858296854887e-05
step: 50, loss: 4.906268077320419e-05
step: 60, loss: 9.199811756843701e-05
step: 70, loss: 2.516299173294101e-05
step: 80, loss: 3.348020254634321e-05
step: 90, loss: 0.00019698105461429805
step: 100, loss: 0.0005980760906822979
step: 110, loss: 0.00015860192070249468
step: 120, loss: 1.497900939284591e-05
step: 130, loss: 0.0001973141188500449
step: 140, loss: 0.0011421673698350787
step: 150, loss: 0.0002746981626842171
step: 160, loss: 0.0024306674022227526
step: 170, loss: 5.2046951168449596e-05
step: 180, loss: 5.819201760459691e-05
step: 190, loss: 8.374614844797179e-05
step: 200, loss: 5.262410195427947e-05
step: 210, loss: 0.00026986049488186836
step: 220, loss: 0.00019057397730648518
step: 230, loss: 0.00016910579870454967
step: 240, loss: 9.703667456051335e-05
step: 250, loss: 0.00032840148196555674
step: 260, loss: 0.0012935036793351173
step: 270, loss: 0.00015481456648558378
step: 280, loss: 3.0268078262452036e-05
step: 290, loss: 0.022275181487202644
step: 300, loss: 5.946363671682775e-05
step: 310, loss: 2.70800319412956e-05
step: 320, loss: 8.217921276809648e-06
step: 330, loss: 0.0008841173257678747
step: 340, loss: 0.00013720110291615129
step: 350, loss: 0.00015716336201876402
step: 360, loss: 0.00011598006676649675
step: 370, loss: 1.2863056326750666e-05
step: 380, loss: 2.1126161300344393e-05
step: 390, loss: 6.526513607241213e-05
step: 400, loss: 0.0012416556710377336
step: 410, loss: 0.0003921875904779881
step: 420, loss: 0.0012903453316539526
step: 430, loss: 0.014509566128253937
step: 440, loss: 0.00011694821296259761
step: 450, loss: 4.836280641029589e-05
step: 460, loss: 5.239223173703067e-05
step: 470, loss: 1.629315192985814e-05
step: 480, loss: 2.293888792337384e-05
step: 490, loss: 0.0002633179537951946
step: 500, loss: 1.5571351468679495e-05
step: 510, loss: 0.00045196368591859937
step: 520, loss: 9.675463661551476e-05
step: 530, loss: 3.202414154657163e-05
step: 540, loss: 0.00010280730202794075
step: 550, loss: 2.4320805096067488e-05
step: 560, loss: 2.5185237973346375e-05
step: 570, loss: 0.013839513063430786
step: 580, loss: 0.00011094148794654757
step: 590, loss: 4.282604641048238e-05
step: 600, loss: 3.117847518296912e-05
step: 610, loss: 1.3868905625713523e-05
step: 620, loss: 0.0002752201398834586
step: 630, loss: 4.9732549086911604e-05
step: 640, loss: 3.2922042009886354e-05
step: 650, loss: 0.003976705949753523
step: 660, loss: 5.9396243159426376e-05
step: 670, loss: 4.6352750359801576e-05
step: 680, loss: 0.0005316257593221962
step: 690, loss: 9.700476766738575e-06
step: 700, loss: 3.819105768343434e-05
step: 710, loss: 2.5813102183747105e-05
step: 720, loss: 0.027490941807627678
step: 730, loss: 0.00040809533675201237
step: 740, loss: 0.004024098161607981
step: 750, loss: 0.0010080174542963505
step: 760, loss: 0.00023667182540521026
step: 770, loss: 0.0016790986992418766
step: 780, loss: 0.00014396721962839365
step: 790, loss: 2.0889110601274297e-05
step: 800, loss: 0.03484596312046051
step: 810, loss: 8.243080083047971e-05
step: 820, loss: 9.261310333386064e-05
step: 830, loss: 0.00031849247170612216
step: 840, loss: 0.00035412918077781796
step: 850, loss: 0.00020943178969901055
step: 860, loss: 1.500510006735567e-05
step: 870, loss: 7.081363582983613e-05
step: 880, loss: 4.4409040128812194e-05
step: 890, loss: 1.7277325241593644e-05
step: 900, loss: 5.0676753744482994e-05
step: 910, loss: 0.000619964674115181
step: 920, loss: 0.00010763118916656822
step: 930, loss: 0.0005236408906057477
step: 940, loss: 4.2780204239534214e-05
epoch 19: dev_f1=0.9506057781919852, f1=0.9340245051837888, best_f1=0.9321478708469817
step: 0, loss: 0.006811769679188728
step: 10, loss: 2.0339153707027435e-05
step: 20, loss: 0.00017328189278487116
step: 30, loss: 5.8675414038589224e-05
step: 40, loss: 1.2166432497906499e-05
step: 50, loss: 2.1810317775816657e-05
step: 60, loss: 0.0005072582280263305
step: 70, loss: 0.0006188201950863004
step: 80, loss: 0.00107599887996912
step: 90, loss: 0.002139624208211899
step: 100, loss: 5.03211522300262e-05
step: 110, loss: 2.8492640922195278e-05
step: 120, loss: 1.731790143821854e-05
step: 130, loss: 2.2010946850059554e-05
step: 140, loss: 1.2806945960619487e-05
step: 150, loss: 1.6577192582190037e-05
step: 160, loss: 8.568095836380962e-06
step: 170, loss: 1.498640631325543e-05
step: 180, loss: 0.00010754365212051198
step: 190, loss: 4.819593232241459e-05
step: 200, loss: 5.854881237610243e-05
step: 210, loss: 1.334366334049264e-05
step: 220, loss: 2.7748174034059048e-05
step: 230, loss: 5.401445378083736e-05
step: 240, loss: 2.3894990590633824e-05
step: 250, loss: 0.00020127928291913122
step: 260, loss: 0.0040630754083395
step: 270, loss: 0.00032018660567700863
step: 280, loss: 3.4510936529841274e-05
step: 290, loss: 2.0752111595356837e-05
step: 300, loss: 1.8252636436955072e-05
step: 310, loss: 1.2520508789748419e-05
step: 320, loss: 6.345552537823096e-05
step: 330, loss: 2.7629379474092275e-05
step: 340, loss: 5.159365537110716e-05
step: 350, loss: 1.626062294235453e-05
step: 360, loss: 2.068479807348922e-05
step: 370, loss: 0.0007690555648878217
step: 380, loss: 3.8662925362586975e-05
step: 390, loss: 0.00038721185410395265
step: 400, loss: 0.0060573965311050415
step: 410, loss: 2.539009801694192e-05
step: 420, loss: 1.030775183608057e-05
step: 430, loss: 0.00025962325162254274
step: 440, loss: 1.0728681445471011e-05
step: 450, loss: 0.0001562010293127969
step: 460, loss: 1.0188555279455613e-05
step: 470, loss: 0.0003432128287386149
step: 480, loss: 0.0008953025098890066
step: 490, loss: 4.2015075450763106e-05
step: 500, loss: 3.7852165405638516e-05
step: 510, loss: 0.0026473423931747675
step: 520, loss: 2.744970697676763e-05
step: 530, loss: 2.74450758297462e-05
step: 540, loss: 7.488367555197328e-05
step: 550, loss: 1.5068428183440119e-05
step: 560, loss: 6.860787107143551e-05
step: 570, loss: 0.0064975363202393055
step: 580, loss: 3.8938534999033436e-05
step: 590, loss: 7.25006393622607e-05
step: 600, loss: 3.089372694375925e-05
step: 610, loss: 2.0588979168678634e-05
step: 620, loss: 0.002335119992494583
step: 630, loss: 1.732939199428074e-05
step: 640, loss: 0.00033165313652716577
step: 650, loss: 1.577244074724149e-05
step: 660, loss: 1.494869684393052e-05
step: 670, loss: 8.664930646773428e-06
step: 680, loss: 0.00010945086978608742
step: 690, loss: 0.00028180793742649257
step: 700, loss: 0.00021666033717337996
step: 710, loss: 0.00020849128486588597
step: 720, loss: 1.9743094526347704e-05
step: 730, loss: 1.939678804774303e-05
step: 740, loss: 0.0006530770333483815
step: 750, loss: 7.107810233719647e-06
step: 760, loss: 2.84256548184203e-05
step: 770, loss: 0.00014860183000564575
step: 780, loss: 2.374629730184097e-05
step: 790, loss: 0.00012725780834443867
step: 800, loss: 2.2629865270573646e-05
step: 810, loss: 4.416074443724938e-05
step: 820, loss: 0.00023617084661964327
step: 830, loss: 7.50106992200017e-05
step: 840, loss: 1.957912536454387e-05
step: 850, loss: 1.1436497516115196e-05
step: 860, loss: 0.00015953279216773808
step: 870, loss: 3.757782542379573e-05
step: 880, loss: 1.0475368981133215e-05
step: 890, loss: 1.2032523954985663e-05
step: 900, loss: 8.497282578900922e-06
step: 910, loss: 0.0013224845752120018
step: 920, loss: 2.281990964547731e-05
step: 930, loss: 4.387896478874609e-05
step: 940, loss: 8.042848094191868e-06
epoch 20: dev_f1=0.951501154734411, f1=0.9342043863742416, best_f1=0.9321478708469817
