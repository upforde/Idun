cuda
Device: cuda
step: 0, loss: 0.6905931830406189
step: 10, loss: 0.41941842436790466
step: 20, loss: 0.33225083351135254
step: 30, loss: 0.1840413212776184
step: 40, loss: 0.20135240256786346
step: 50, loss: 0.2858812212944031
step: 60, loss: 0.19490791857242584
step: 70, loss: 0.2877834141254425
step: 80, loss: 0.2516893446445465
step: 90, loss: 0.17829647660255432
step: 100, loss: 0.21936947107315063
step: 110, loss: 0.15577876567840576
step: 120, loss: 0.24069294333457947
step: 130, loss: 0.17052693665027618
step: 140, loss: 0.34231504797935486
step: 150, loss: 0.3220841586589813
step: 160, loss: 0.2973218262195587
step: 170, loss: 0.2979203462600708
step: 180, loss: 0.3221038281917572
step: 190, loss: 0.3198368549346924
step: 200, loss: 0.3673987090587616
step: 210, loss: 0.4117142856121063
step: 220, loss: 0.21591714024543762
step: 230, loss: 0.15358705818653107
step: 240, loss: 0.3174622654914856
step: 250, loss: 0.4176923930644989
step: 260, loss: 0.24626091122627258
step: 270, loss: 0.13412457704544067
step: 280, loss: 0.24577149748802185
step: 290, loss: 0.3577863276004791
step: 300, loss: 0.19969598948955536
step: 310, loss: 0.16159303486347198
step: 320, loss: 0.23388351500034332
step: 330, loss: 0.08991019427776337
step: 340, loss: 0.10452853888273239
step: 350, loss: 0.21117183566093445
step: 360, loss: 0.11960235983133316
step: 370, loss: 0.19869683682918549
step: 380, loss: 0.0844225212931633
step: 390, loss: 0.3032660484313965
step: 400, loss: 0.28777867555618286
step: 410, loss: 0.30441081523895264
step: 420, loss: 0.4041655361652374
step: 430, loss: 0.22269636392593384
step: 440, loss: 0.17690704762935638
step: 450, loss: 0.11345622688531876
step: 460, loss: 0.280319482088089
step: 470, loss: 0.21119175851345062
step: 480, loss: 0.14039346575737
step: 490, loss: 0.11742503196001053
step: 500, loss: 0.212996244430542
step: 510, loss: 0.2529183626174927
step: 520, loss: 0.2489326000213623
step: 530, loss: 0.1984279751777649
step: 540, loss: 0.18762803077697754
step: 550, loss: 0.3912545144557953
step: 560, loss: 0.22326526045799255
step: 570, loss: 0.2295019030570984
step: 580, loss: 0.06966517865657806
step: 590, loss: 0.3240685760974884
step: 600, loss: 0.10003021359443665
step: 610, loss: 0.11248459666967392
step: 620, loss: 0.18586833775043488
step: 630, loss: 0.14314262568950653
step: 640, loss: 0.2717749774456024
step: 650, loss: 0.214885875582695
step: 660, loss: 0.09947442263364792
step: 670, loss: 0.18620525300502777
step: 680, loss: 0.30572935938835144
step: 690, loss: 0.24353145062923431
step: 700, loss: 0.2585967779159546
step: 710, loss: 0.3436281085014343
step: 720, loss: 0.11528380215167999
step: 730, loss: 0.26226863265037537
step: 740, loss: 0.3120260238647461
step: 750, loss: 0.16906064748764038
step: 760, loss: 0.4659205675125122
step: 770, loss: 0.16483180224895477
step: 780, loss: 0.1116226464509964
step: 790, loss: 0.1936510056257248
step: 800, loss: 0.08264373242855072
step: 810, loss: 0.15523341298103333
step: 820, loss: 0.171247199177742
step: 830, loss: 0.10979723930358887
step: 840, loss: 0.13278646767139435
step: 850, loss: 0.11919903010129929
step: 860, loss: 0.1502118557691574
step: 870, loss: 0.12400412559509277
step: 880, loss: 0.2517532408237457
step: 890, loss: 0.3588387072086334
step: 900, loss: 0.24096077680587769
step: 910, loss: 0.2054508924484253
step: 920, loss: 0.1802062839269638
step: 930, loss: 0.023297566920518875
step: 940, loss: 0.16527040302753448
step: 950, loss: 0.18129944801330566
step: 960, loss: 0.13325203955173492
step: 970, loss: 0.22647427022457123
step: 980, loss: 0.057922787964344025
step: 990, loss: 0.28831517696380615
step: 1000, loss: 0.2862432897090912
step: 1010, loss: 0.1543508768081665
step: 1020, loss: 0.1457781195640564
step: 1030, loss: 0.2863943874835968
step: 1040, loss: 0.1260526180267334
step: 1050, loss: 0.11244076490402222
step: 1060, loss: 0.23315966129302979
epoch 1: dev_f1=0.9289667896678966, f1=0.9189695550351288, best_f1=0.9189695550351288
step: 0, loss: 0.18243488669395447
step: 10, loss: 0.14042676985263824
step: 20, loss: 0.04520058631896973
step: 30, loss: 0.1820518523454666
step: 40, loss: 0.05203380435705185
step: 50, loss: 0.29313382506370544
step: 60, loss: 0.1170370951294899
step: 70, loss: 0.09897822886705399
step: 80, loss: 0.040763840079307556
step: 90, loss: 0.037068773061037064
step: 100, loss: 0.24101698398590088
step: 110, loss: 0.0873420462012291
step: 120, loss: 0.04669211432337761
step: 130, loss: 0.2971283495426178
step: 140, loss: 0.09502750635147095
step: 150, loss: 0.17112702131271362
step: 160, loss: 0.10238818824291229
step: 170, loss: 0.06283427774906158
step: 180, loss: 0.19364233314990997
step: 190, loss: 0.22265462577342987
step: 200, loss: 0.31190744042396545
step: 210, loss: 0.17103123664855957
step: 220, loss: 0.18212202191352844
step: 230, loss: 0.06499947607517242
step: 240, loss: 0.12907809019088745
step: 250, loss: 0.12912167608737946
step: 260, loss: 0.19227153062820435
step: 270, loss: 0.10349021106958389
step: 280, loss: 0.11342930048704147
step: 290, loss: 0.08742760866880417
step: 300, loss: 0.1562744528055191
step: 310, loss: 0.19384866952896118
step: 320, loss: 0.09492720663547516
step: 330, loss: 0.1645967662334442
step: 340, loss: 0.2102266401052475
step: 350, loss: 0.06603175401687622
step: 360, loss: 0.2714902460575104
step: 370, loss: 0.09114901721477509
step: 380, loss: 0.10736949741840363
step: 390, loss: 0.04776841402053833
step: 400, loss: 0.10626199841499329
step: 410, loss: 0.16684745252132416
step: 420, loss: 0.12851150333881378
step: 430, loss: 0.030838442966341972
step: 440, loss: 0.10876387357711792
step: 450, loss: 0.10988819599151611
step: 460, loss: 0.11907287687063217
step: 470, loss: 0.18587905168533325
step: 480, loss: 0.2294754534959793
step: 490, loss: 0.05635048449039459
step: 500, loss: 0.08002802729606628
step: 510, loss: 0.05485859140753746
step: 520, loss: 0.24480271339416504
step: 530, loss: 0.05229412391781807
step: 540, loss: 0.3673555552959442
step: 550, loss: 0.23114533722400665
step: 560, loss: 0.14225099980831146
step: 570, loss: 0.261536568403244
step: 580, loss: 0.11837293207645416
step: 590, loss: 0.3554587662220001
step: 600, loss: 0.28423038125038147
step: 610, loss: 0.07915468513965607
step: 620, loss: 0.33162495493888855
step: 630, loss: 0.0959092453122139
step: 640, loss: 0.10762341320514679
step: 650, loss: 0.2758682370185852
step: 660, loss: 0.14732448756694794
step: 670, loss: 0.2294008880853653
step: 680, loss: 0.19751328229904175
step: 690, loss: 0.11776328831911087
step: 700, loss: 0.2069530189037323
step: 710, loss: 0.4778485596179962
step: 720, loss: 0.27632075548171997
step: 730, loss: 0.05833517760038376
step: 740, loss: 0.0661984458565712
step: 750, loss: 0.1273525208234787
step: 760, loss: 0.16335581243038177
step: 770, loss: 0.03261438012123108
step: 780, loss: 0.14297856390476227
step: 790, loss: 0.40134197473526
step: 800, loss: 0.1431305855512619
step: 810, loss: 0.21694597601890564
step: 820, loss: 0.11841357499361038
step: 830, loss: 0.15890859067440033
step: 840, loss: 0.05257564038038254
step: 850, loss: 0.21306665241718292
step: 860, loss: 0.1954091489315033
step: 870, loss: 0.08844258636236191
step: 880, loss: 0.13555321097373962
step: 890, loss: 0.06281577795743942
step: 900, loss: 0.04480385407805443
step: 910, loss: 0.09014098346233368
step: 920, loss: 0.11789663881063461
step: 930, loss: 0.23026740550994873
step: 940, loss: 0.02485923282802105
step: 950, loss: 0.23972868919372559
step: 960, loss: 0.12406767904758453
step: 970, loss: 0.1210155040025711
step: 980, loss: 0.18541599810123444
step: 990, loss: 0.22279536724090576
step: 1000, loss: 0.22043730318546295
step: 1010, loss: 0.10854656994342804
step: 1020, loss: 0.180287703871727
step: 1030, loss: 0.09428783506155014
step: 1040, loss: 0.20181353390216827
step: 1050, loss: 0.044397592544555664
step: 1060, loss: 0.25495612621307373
epoch 2: dev_f1=0.951048951048951, f1=0.9238005644402634, best_f1=0.9238005644402634
step: 0, loss: 0.13807864487171173
step: 10, loss: 0.04452783986926079
step: 20, loss: 0.016790024936199188
step: 30, loss: 0.11030849069356918
step: 40, loss: 0.22529849410057068
step: 50, loss: 0.0692417323589325
step: 60, loss: 0.07438447326421738
step: 70, loss: 0.170401468873024
step: 80, loss: 0.09378627687692642
step: 90, loss: 0.05483761802315712
step: 100, loss: 0.06164777651429176
step: 110, loss: 0.06543951481580734
step: 120, loss: 0.031115857884287834
step: 130, loss: 0.06561939418315887
step: 140, loss: 0.1839805543422699
step: 150, loss: 0.1453159600496292
step: 160, loss: 0.04456251487135887
step: 170, loss: 0.2793615758419037
step: 180, loss: 0.13596104085445404
step: 190, loss: 0.020244743674993515
step: 200, loss: 0.19215147197246552
step: 210, loss: 0.04582210257649422
step: 220, loss: 0.2340748906135559
step: 230, loss: 0.1256866753101349
step: 240, loss: 0.10818792879581451
step: 250, loss: 0.11455275118350983
step: 260, loss: 0.07354806363582611
step: 270, loss: 0.07879601418972015
step: 280, loss: 0.07134629786014557
step: 290, loss: 0.03620120510458946
step: 300, loss: 0.055416837334632874
step: 310, loss: 0.03711354359984398
step: 320, loss: 0.1679171472787857
step: 330, loss: 0.09720619767904282
step: 340, loss: 0.11298876255750656
step: 350, loss: 0.13718494772911072
step: 360, loss: 0.116437166929245
step: 370, loss: 0.036398179829120636
step: 380, loss: 0.008598665706813335
step: 390, loss: 0.09981334209442139
step: 400, loss: 0.17116093635559082
step: 410, loss: 0.14779269695281982
step: 420, loss: 0.12306983023881912
step: 430, loss: 0.05366026237607002
step: 440, loss: 0.09008368849754333
step: 450, loss: 0.12839244306087494
step: 460, loss: 0.09861800074577332
step: 470, loss: 0.07508942484855652
step: 480, loss: 0.14962178468704224
step: 490, loss: 0.10134465992450714
step: 500, loss: 0.07620128244161606
step: 510, loss: 0.2001393884420395
step: 520, loss: 0.1208379715681076
step: 530, loss: 0.1012660413980484
step: 540, loss: 0.030881274491548538
step: 550, loss: 0.07763363420963287
step: 560, loss: 0.029116865247488022
step: 570, loss: 0.016446061432361603
step: 580, loss: 0.09526996314525604
step: 590, loss: 0.05451444536447525
step: 600, loss: 0.05158299207687378
step: 610, loss: 0.02665659412741661
step: 620, loss: 0.26518312096595764
step: 630, loss: 0.22849705815315247
step: 640, loss: 0.055647850036621094
step: 650, loss: 0.04370063915848732
step: 660, loss: 0.11096791177988052
step: 670, loss: 0.0688641294836998
step: 680, loss: 0.09800368547439575
step: 690, loss: 0.19029609858989716
step: 700, loss: 0.14491361379623413
step: 710, loss: 0.190046489238739
step: 720, loss: 0.06125742942094803
step: 730, loss: 0.1750124990940094
step: 740, loss: 0.22065411508083344
step: 750, loss: 0.04057374224066734
step: 760, loss: 0.05971326306462288
step: 770, loss: 0.08670695126056671
step: 780, loss: 0.12873660027980804
step: 790, loss: 0.1720862090587616
step: 800, loss: 0.3183712959289551
step: 810, loss: 0.11480134725570679
step: 820, loss: 0.22706280648708344
step: 830, loss: 0.1425315886735916
step: 840, loss: 0.039873041212558746
step: 850, loss: 0.1827154904603958
step: 860, loss: 0.03638170287013054
step: 870, loss: 0.04176831617951393
step: 880, loss: 0.2100425660610199
step: 890, loss: 0.036673158407211304
step: 900, loss: 0.07888362556695938
step: 910, loss: 0.034018728882074356
step: 920, loss: 0.06042412668466568
step: 930, loss: 0.05270517244935036
step: 940, loss: 0.04218542203307152
step: 950, loss: 0.02253730408847332
step: 960, loss: 0.21844224631786346
step: 970, loss: 0.17599134147167206
step: 980, loss: 0.06438405811786652
step: 990, loss: 0.11781362444162369
step: 1000, loss: 0.16607604920864105
step: 1010, loss: 0.23402491211891174
step: 1020, loss: 0.13525018095970154
step: 1030, loss: 0.2457723617553711
step: 1040, loss: 0.09443224221467972
step: 1050, loss: 0.2116401344537735
step: 1060, loss: 0.10677051544189453
epoch 3: dev_f1=0.9414498141263941, f1=0.9254426840633737, best_f1=0.9238005644402634
step: 0, loss: 0.032806552946567535
step: 10, loss: 0.034921154379844666
step: 20, loss: 0.12279005348682404
step: 30, loss: 0.022536469623446465
step: 40, loss: 0.06272552907466888
step: 50, loss: 0.16474662721157074
step: 60, loss: 0.12609706819057465
step: 70, loss: 0.11061593145132065
step: 80, loss: 0.0856637954711914
step: 90, loss: 0.029010850936174393
step: 100, loss: 0.03542299196124077
step: 110, loss: 0.022969311103224754
step: 120, loss: 0.06672118604183197
step: 130, loss: 0.14238570630550385
step: 140, loss: 0.030278116464614868
step: 150, loss: 0.0332656130194664
step: 160, loss: 0.00789515022188425
step: 170, loss: 0.029380427673459053
step: 180, loss: 0.05084317550063133
step: 190, loss: 0.07984916865825653
step: 200, loss: 0.08365987241268158
step: 210, loss: 0.0588495209813118
step: 220, loss: 0.22377774119377136
step: 230, loss: 0.19947317242622375
step: 240, loss: 0.026342298835515976
step: 250, loss: 0.0317680686712265
step: 260, loss: 0.12074014544487
step: 270, loss: 0.030381115153431892
step: 280, loss: 0.018605004996061325
step: 290, loss: 0.09307938814163208
step: 300, loss: 0.07727622985839844
step: 310, loss: 0.11366743594408035
step: 320, loss: 0.0641075000166893
step: 330, loss: 0.20955848693847656
step: 340, loss: 0.07359861582517624
step: 350, loss: 0.006716608069837093
step: 360, loss: 0.04860912635922432
step: 370, loss: 0.06490164995193481
step: 380, loss: 0.0762244164943695
step: 390, loss: 0.05346841737627983
step: 400, loss: 0.008052043616771698
step: 410, loss: 0.0504826121032238
step: 420, loss: 0.1495739370584488
step: 430, loss: 0.02348427288234234
step: 440, loss: 0.06843814998865128
step: 450, loss: 0.018558364361524582
step: 460, loss: 0.06458201259374619
step: 470, loss: 0.016129598021507263
step: 480, loss: 0.04236442223191261
step: 490, loss: 0.20059087872505188
step: 500, loss: 0.037947461009025574
step: 510, loss: 0.028590576723217964
step: 520, loss: 0.13797788321971893
step: 530, loss: 0.19453564286231995
step: 540, loss: 0.02399630658328533
step: 550, loss: 0.025598447769880295
step: 560, loss: 0.04185410216450691
step: 570, loss: 0.05521359294652939
step: 580, loss: 0.03995240852236748
step: 590, loss: 0.12716490030288696
step: 600, loss: 0.0419827476143837
step: 610, loss: 0.07368000596761703
step: 620, loss: 0.008550172671675682
step: 630, loss: 0.06822604686021805
step: 640, loss: 0.08180886507034302
step: 650, loss: 0.06149731203913689
step: 660, loss: 0.1620054841041565
step: 670, loss: 0.0617341473698616
step: 680, loss: 0.22110645473003387
step: 690, loss: 0.0898917093873024
step: 700, loss: 0.018115941435098648
step: 710, loss: 0.009683818556368351
step: 720, loss: 0.05716666951775551
step: 730, loss: 0.10722033679485321
step: 740, loss: 0.049329861998558044
step: 750, loss: 0.07236457616090775
step: 760, loss: 0.033326406031847
step: 770, loss: 0.15252907574176788
step: 780, loss: 0.10143256187438965
step: 790, loss: 0.03371191397309303
step: 800, loss: 0.09610262513160706
step: 810, loss: 0.14016224443912506
step: 820, loss: 0.01694195158779621
step: 830, loss: 0.021222345530986786
step: 840, loss: 0.03893198072910309
step: 850, loss: 0.010161188431084156
step: 860, loss: 0.10920783877372742
step: 870, loss: 0.11654742062091827
step: 880, loss: 0.06240000203251839
step: 890, loss: 0.028066318482160568
step: 900, loss: 0.08099422603845596
step: 910, loss: 0.013234271667897701
step: 920, loss: 0.019402990117669106
step: 930, loss: 0.008947629481554031
step: 940, loss: 0.032126810401678085
step: 950, loss: 0.14287275075912476
step: 960, loss: 0.041760947555303574
step: 970, loss: 0.07748156040906906
step: 980, loss: 0.0439913384616375
step: 990, loss: 0.042771756649017334
step: 1000, loss: 0.10938456654548645
step: 1010, loss: 0.01823163591325283
step: 1020, loss: 0.007361156865954399
step: 1030, loss: 0.09257091581821442
step: 1040, loss: 0.1357920616865158
step: 1050, loss: 0.031529247760772705
step: 1060, loss: 0.006348235532641411
epoch 4: dev_f1=0.9490566037735849, f1=0.9125475285171102, best_f1=0.9238005644402634
step: 0, loss: 0.10909226536750793
step: 10, loss: 0.03317178413271904
step: 20, loss: 0.037302277982234955
step: 30, loss: 0.014629775658249855
step: 40, loss: 0.047362711280584335
step: 50, loss: 0.01810423657298088
step: 60, loss: 0.013152399100363255
step: 70, loss: 0.1420346349477768
step: 80, loss: 0.014093765057623386
step: 90, loss: 0.009705588221549988
step: 100, loss: 0.01956845074892044
step: 110, loss: 0.03613805025815964
step: 120, loss: 0.09455907344818115
step: 130, loss: 0.0044442578218877316
step: 140, loss: 0.1807793825864792
step: 150, loss: 0.09609600156545639
step: 160, loss: 0.00424135522916913
step: 170, loss: 0.0035644329618662596
step: 180, loss: 0.008953609503805637
step: 190, loss: 0.008423988707363605
step: 200, loss: 0.031225645914673805
step: 210, loss: 0.0698934942483902
step: 220, loss: 0.03021032176911831
step: 230, loss: 0.0204257033765316
step: 240, loss: 0.058949291706085205
step: 250, loss: 0.02967252768576145
step: 260, loss: 0.04675587639212608
step: 270, loss: 0.0047315810807049274
step: 280, loss: 0.032484911382198334
step: 290, loss: 0.06693968921899796
step: 300, loss: 0.01862366311252117
step: 310, loss: 0.01560458354651928
step: 320, loss: 0.027147594839334488
step: 330, loss: 0.05383158475160599
step: 340, loss: 0.018907804042100906
step: 350, loss: 0.07221977412700653
step: 360, loss: 0.07918842881917953
step: 370, loss: 0.1102665588259697
step: 380, loss: 0.09335370361804962
step: 390, loss: 0.028755242004990578
step: 400, loss: 0.01815309189260006
step: 410, loss: 0.05220593139529228
step: 420, loss: 0.019740942865610123
step: 430, loss: 0.08066163957118988
step: 440, loss: 0.010334905236959457
step: 450, loss: 0.009806553833186626
step: 460, loss: 0.15086473524570465
step: 470, loss: 0.0683322623372078
step: 480, loss: 0.13509471714496613
step: 490, loss: 0.020041927695274353
step: 500, loss: 0.043196018785238266
step: 510, loss: 0.03650539368391037
step: 520, loss: 0.1239064484834671
step: 530, loss: 0.05211970955133438
step: 540, loss: 0.007959946058690548
step: 550, loss: 0.0780477523803711
step: 560, loss: 0.13234654068946838
step: 570, loss: 0.02573665790259838
step: 580, loss: 0.0014750695554539561
step: 590, loss: 0.07223211973905563
step: 600, loss: 0.0033113579265773296
step: 610, loss: 0.059471629559993744
step: 620, loss: 0.04482914134860039
step: 630, loss: 0.06363125145435333
step: 640, loss: 0.022501898929476738
step: 650, loss: 0.07149624079465866
step: 660, loss: 0.07021816819906235
step: 670, loss: 0.0337030254304409
step: 680, loss: 0.0010271522914990783
step: 690, loss: 0.07700581103563309
step: 700, loss: 0.0011746600503101945
step: 710, loss: 0.04730410873889923
step: 720, loss: 0.04295709729194641
step: 730, loss: 0.13632121682167053
step: 740, loss: 0.004325659945607185
step: 750, loss: 0.0037935052532702684
step: 760, loss: 0.03711086884140968
step: 770, loss: 0.031018473207950592
step: 780, loss: 0.02266646735370159
step: 790, loss: 0.025897283107042313
step: 800, loss: 0.017689432948827744
step: 810, loss: 0.06028333306312561
step: 820, loss: 0.02104443684220314
step: 830, loss: 0.09886573255062103
step: 840, loss: 0.13672079145908356
step: 850, loss: 0.0901670828461647
step: 860, loss: 0.005964929237961769
step: 870, loss: 0.08319388329982758
step: 880, loss: 0.00369298760779202
step: 890, loss: 0.10005329549312592
step: 900, loss: 0.04619986191391945
step: 910, loss: 0.02449999377131462
step: 920, loss: 0.046023495495319366
step: 930, loss: 0.0033061595167964697
step: 940, loss: 0.02987811714410782
step: 950, loss: 0.05762897804379463
step: 960, loss: 0.11840467154979706
step: 970, loss: 0.0277609433978796
step: 980, loss: 0.026635441929101944
step: 990, loss: 0.012971008196473122
step: 1000, loss: 0.04949294403195381
step: 1010, loss: 0.010252601467072964
step: 1020, loss: 0.08144571632146835
step: 1030, loss: 0.06011274456977844
step: 1040, loss: 0.01826392486691475
step: 1050, loss: 0.06275559961795807
step: 1060, loss: 0.12039262056350708
epoch 5: dev_f1=0.943466172381835, f1=0.9216241737488197, best_f1=0.9238005644402634
step: 0, loss: 0.018039552494883537
step: 10, loss: 0.026652850210666656
step: 20, loss: 0.0247502438724041
step: 30, loss: 0.030070709064602852
step: 40, loss: 0.017126115038990974
step: 50, loss: 0.0012243244564160705
step: 60, loss: 0.09833567589521408
step: 70, loss: 0.00367784989066422
step: 80, loss: 0.022542104125022888
step: 90, loss: 0.0005484972498379648
step: 100, loss: 0.0786648765206337
step: 110, loss: 0.04863407835364342
step: 120, loss: 0.11580318212509155
step: 130, loss: 0.0004350842209532857
step: 140, loss: 0.018281588330864906
step: 150, loss: 0.09172085672616959
step: 160, loss: 0.007946725003421307
step: 170, loss: 0.039010822772979736
step: 180, loss: 0.0018834891961887479
step: 190, loss: 0.18964342772960663
step: 200, loss: 0.05325378477573395
step: 210, loss: 0.05189204588532448
step: 220, loss: 0.0070299566723406315
step: 230, loss: 0.007331409025937319
step: 240, loss: 0.027713783085346222
step: 250, loss: 0.20827656984329224
step: 260, loss: 0.0030191403347998857
step: 270, loss: 0.005409948527812958
step: 280, loss: 0.03752189129590988
step: 290, loss: 0.004850941710174084
step: 300, loss: 0.045906033366918564
step: 310, loss: 0.013022822327911854
step: 320, loss: 0.06008096784353256
step: 330, loss: 0.0010972575983032584
step: 340, loss: 0.0008988693589344621
step: 350, loss: 0.01010216400027275
step: 360, loss: 0.06174936145544052
step: 370, loss: 0.0011822471860796213
step: 380, loss: 0.0003326777077745646
step: 390, loss: 0.0005217459984123707
step: 400, loss: 0.013345398008823395
step: 410, loss: 0.13651148974895477
step: 420, loss: 0.015292356722056866
step: 430, loss: 0.014429655857384205
step: 440, loss: 0.016520386561751366
step: 450, loss: 0.03581247106194496
step: 460, loss: 0.0021442354191094637
step: 470, loss: 0.01632436364889145
step: 480, loss: 0.0025374272372573614
step: 490, loss: 0.021597832441329956
step: 500, loss: 0.012674876488745213
step: 510, loss: 0.009100096300244331
step: 520, loss: 0.006024389062076807
step: 530, loss: 0.05690348893404007
step: 540, loss: 0.01740839146077633
step: 550, loss: 0.0021547318901866674
step: 560, loss: 0.037659961730241776
step: 570, loss: 0.013606307096779346
step: 580, loss: 0.012620476074516773
step: 590, loss: 0.06955070048570633
step: 600, loss: 0.08018280565738678
step: 610, loss: 0.007226285059005022
step: 620, loss: 0.060844164341688156
step: 630, loss: 0.08832746744155884
step: 640, loss: 0.031104400753974915
step: 650, loss: 0.03716031089425087
step: 660, loss: 0.021323464810848236
step: 670, loss: 0.009407145902514458
step: 680, loss: 0.003476690500974655
step: 690, loss: 0.17558437585830688
step: 700, loss: 0.03772715479135513
step: 710, loss: 0.06756773591041565
step: 720, loss: 0.07626137882471085
step: 730, loss: 0.02074235863983631
step: 740, loss: 0.017047209665179253
step: 750, loss: 0.0020666762720793486
step: 760, loss: 0.0013358300784602761
step: 770, loss: 0.001743839937262237
step: 780, loss: 0.011133654043078423
step: 790, loss: 0.05077579617500305
step: 800, loss: 0.0018619532929733396
step: 810, loss: 0.014297576621174812
step: 820, loss: 0.011191320605576038
step: 830, loss: 0.01620236411690712
step: 840, loss: 0.003942092414945364
step: 850, loss: 0.013322832062840462
step: 860, loss: 0.0065328581258654594
step: 870, loss: 0.016821136698126793
step: 880, loss: 0.2032119184732437
step: 890, loss: 0.02393975667655468
step: 900, loss: 0.02391422726213932
step: 910, loss: 0.03143442049622536
step: 920, loss: 0.03899407759308815
step: 930, loss: 0.13957621157169342
step: 940, loss: 0.012084687128663063
step: 950, loss: 0.0025669930037111044
step: 960, loss: 0.01574750617146492
step: 970, loss: 0.010487201623618603
step: 980, loss: 0.001710151438601315
step: 990, loss: 0.035816553980112076
step: 1000, loss: 0.0070536392740905285
step: 1010, loss: 0.0416405163705349
step: 1020, loss: 0.0054345461539924145
step: 1030, loss: 0.05953122302889824
step: 1040, loss: 0.0011405461700633168
step: 1050, loss: 0.04116608202457428
step: 1060, loss: 0.07602210342884064
epoch 6: dev_f1=0.9463955637707948, f1=0.9189695550351288, best_f1=0.9238005644402634
step: 0, loss: 0.018544070422649384
step: 10, loss: 0.003037780523300171
step: 20, loss: 0.23867788910865784
step: 30, loss: 0.005425002425909042
step: 40, loss: 0.004100593272596598
step: 50, loss: 0.030320508405566216
step: 60, loss: 0.010103842243552208
step: 70, loss: 0.02890031225979328
step: 80, loss: 0.003039188915863633
step: 90, loss: 0.009373600594699383
step: 100, loss: 0.01149033848196268
step: 110, loss: 0.006874750833958387
step: 120, loss: 0.017693638801574707
step: 130, loss: 0.0018311114981770515
step: 140, loss: 0.00454528396949172
step: 150, loss: 0.005142750684171915
step: 160, loss: 0.066812664270401
step: 170, loss: 0.0016235949005931616
step: 180, loss: 0.0006179908523336053
step: 190, loss: 0.03148777410387993
step: 200, loss: 0.07168775796890259
step: 210, loss: 0.029737820848822594
step: 220, loss: 0.12591582536697388
step: 230, loss: 0.00954239908605814
step: 240, loss: 0.0014883114490658045
step: 250, loss: 0.013492200523614883
step: 260, loss: 0.04979018494486809
step: 270, loss: 0.004440209362655878
step: 280, loss: 0.018381105735898018
step: 290, loss: 0.03886556252837181
step: 300, loss: 0.0034741999115794897
step: 310, loss: 0.03177853673696518
step: 320, loss: 0.00796058401465416
step: 330, loss: 0.11114981770515442
step: 340, loss: 0.0034792516380548477
step: 350, loss: 0.0014476827345788479
step: 360, loss: 0.03517492488026619
step: 370, loss: 0.06617706269025803
step: 380, loss: 0.014108637347817421
step: 390, loss: 0.005150517448782921
step: 400, loss: 0.07750214636325836
step: 410, loss: 0.05793442949652672
step: 420, loss: 0.022023789584636688
step: 430, loss: 0.0011998966801911592
step: 440, loss: 0.005221202503889799
step: 450, loss: 0.004068006761372089
step: 460, loss: 0.006500086281448603
step: 470, loss: 0.03254774957895279
step: 480, loss: 0.0037540639750659466
step: 490, loss: 0.042284589260816574
step: 500, loss: 0.009079118259251118
step: 510, loss: 0.01413568202406168
step: 520, loss: 0.022659147158265114
step: 530, loss: 0.014903225935995579
step: 540, loss: 0.014195124618709087
step: 550, loss: 0.021313434466719627
step: 560, loss: 0.0059659467078745365
step: 570, loss: 0.019879193976521492
step: 580, loss: 0.1348918080329895
step: 590, loss: 0.006069665774703026
step: 600, loss: 0.00799341406673193
step: 610, loss: 0.03500528261065483
step: 620, loss: 0.0796029344201088
step: 630, loss: 0.003113496582955122
step: 640, loss: 0.0074001820757985115
step: 650, loss: 0.021238261833786964
step: 660, loss: 0.00831646379083395
step: 670, loss: 0.001106609939597547
step: 680, loss: 0.0011259214952588081
step: 690, loss: 0.0038300384767353535
step: 700, loss: 0.004236891865730286
step: 710, loss: 0.017284909263253212
step: 720, loss: 0.01644349843263626
step: 730, loss: 0.03788762167096138
step: 740, loss: 0.062159307301044464
step: 750, loss: 0.09334641695022583
step: 760, loss: 0.00304497592151165
step: 770, loss: 0.005026767961680889
step: 780, loss: 0.0035637205000966787
step: 790, loss: 0.006017389241605997
step: 800, loss: 0.05232512205839157
step: 810, loss: 0.00413824338465929
step: 820, loss: 0.0059836809523403645
step: 830, loss: 0.0028975477907806635
step: 840, loss: 0.033726662397384644
step: 850, loss: 0.0057233464904129505
step: 860, loss: 0.00877548847347498
step: 870, loss: 0.032386839389801025
step: 880, loss: 0.008427705615758896
step: 890, loss: 0.00023304730711970478
step: 900, loss: 0.0009511648677289486
step: 910, loss: 0.020902028307318687
step: 920, loss: 0.0005364218377508223
step: 930, loss: 0.0007850495167076588
step: 940, loss: 0.05271690711379051
step: 950, loss: 0.006245261989533901
step: 960, loss: 0.0483475886285305
step: 970, loss: 0.03825697302818298
step: 980, loss: 0.0004899646737612784
step: 990, loss: 0.006527856923639774
step: 1000, loss: 0.08242011070251465
step: 1010, loss: 0.04367605224251747
step: 1020, loss: 0.03740830719470978
step: 1030, loss: 0.03278104588389397
step: 1040, loss: 0.1988525390625
step: 1050, loss: 0.002855989383533597
step: 1060, loss: 0.016498329117894173
epoch 7: dev_f1=0.9458955223880597, f1=0.9194536033914271, best_f1=0.9238005644402634
step: 0, loss: 0.00294947880320251
step: 10, loss: 0.002215550048276782
step: 20, loss: 0.006314288359135389
step: 30, loss: 0.00802525319159031
step: 40, loss: 0.002492528408765793
step: 50, loss: 0.005174759775400162
step: 60, loss: 0.0022781523875892162
step: 70, loss: 0.0005318410112522542
step: 80, loss: 0.020306481048464775
step: 90, loss: 0.005770598538219929
step: 100, loss: 0.0024565800558775663
step: 110, loss: 0.013012765906751156
step: 120, loss: 0.1313558667898178
step: 130, loss: 0.00016592777683399618
step: 140, loss: 0.007888849824666977
step: 150, loss: 0.011639505624771118
step: 160, loss: 0.0008609593496657908
step: 170, loss: 0.0002418800868326798
step: 180, loss: 0.028687650337815285
step: 190, loss: 0.032298922538757324
step: 200, loss: 0.000773224513977766
step: 210, loss: 0.00016627514560241252
step: 220, loss: 0.00044252589577808976
step: 230, loss: 0.0038278766442090273
step: 240, loss: 0.003936572466045618
step: 250, loss: 0.007905741222202778
step: 260, loss: 0.011653206311166286
step: 270, loss: 0.0002133922534994781
step: 280, loss: 0.025488538667559624
step: 290, loss: 0.0037038305308669806
step: 300, loss: 0.0017117883544415236
step: 310, loss: 0.013282331638038158
step: 320, loss: 0.0031211511231958866
step: 330, loss: 0.0045547629706561565
step: 340, loss: 0.06136145815253258
step: 350, loss: 0.003500211052596569
step: 360, loss: 0.03115970641374588
step: 370, loss: 0.0035574831999838352
step: 380, loss: 0.005472568795084953
step: 390, loss: 0.015828801319003105
step: 400, loss: 0.0008138844277709723
step: 410, loss: 0.000463476637378335
step: 420, loss: 0.0010574442567303777
step: 430, loss: 0.009975981898605824
step: 440, loss: 0.0047555947676301
step: 450, loss: 0.005747626535594463
step: 460, loss: 0.0003702189715113491
step: 470, loss: 0.005341635551303625
step: 480, loss: 0.001514387084171176
step: 490, loss: 0.035683274269104004
step: 500, loss: 0.0033199135214090347
step: 510, loss: 0.040722910314798355
step: 520, loss: 0.0045114196836948395
step: 530, loss: 0.02041882835328579
step: 540, loss: 0.0023818935733288527
step: 550, loss: 0.0015392708592116833
step: 560, loss: 0.037732239812612534
step: 570, loss: 0.03657064959406853
step: 580, loss: 0.038231443613767624
step: 590, loss: 0.0015865066088736057
step: 600, loss: 0.05446414276957512
step: 610, loss: 0.024620655924081802
step: 620, loss: 0.0007080103969201446
step: 630, loss: 0.01591329462826252
step: 640, loss: 0.0005115009844303131
step: 650, loss: 0.0032700090669095516
step: 660, loss: 0.050339989364147186
step: 670, loss: 0.002608958398923278
step: 680, loss: 0.08899389207363129
step: 690, loss: 0.005950188729912043
step: 700, loss: 0.02069738321006298
step: 710, loss: 0.0012792513007298112
step: 720, loss: 0.0046770949847996235
step: 730, loss: 0.007903349585831165
step: 740, loss: 0.0005251964321359992
step: 750, loss: 0.0011350857093930244
step: 760, loss: 0.04835161939263344
step: 770, loss: 0.0009299608645960689
step: 780, loss: 0.028678379952907562
step: 790, loss: 0.007546841632574797
step: 800, loss: 0.006130322813987732
step: 810, loss: 0.08000212907791138
step: 820, loss: 0.027141142636537552
step: 830, loss: 0.017801277339458466
step: 840, loss: 0.0305903609842062
step: 850, loss: 0.019462771713733673
step: 860, loss: 0.009826034307479858
step: 870, loss: 0.0014292598934844136
step: 880, loss: 0.009118642657995224
step: 890, loss: 0.03396925702691078
step: 900, loss: 0.0018344925483688712
step: 910, loss: 0.10172118246555328
step: 920, loss: 0.018726523965597153
step: 930, loss: 0.0021169870160520077
step: 940, loss: 0.0014546818565577269
step: 950, loss: 0.003974176477640867
step: 960, loss: 0.1063709408044815
step: 970, loss: 0.23704908788204193
step: 980, loss: 0.0006449189386330545
step: 990, loss: 0.014437026344239712
step: 1000, loss: 0.0034945576917380095
step: 1010, loss: 0.0018457158003002405
step: 1020, loss: 0.012280777096748352
step: 1030, loss: 0.01557895913720131
step: 1040, loss: 0.029808146879076958
step: 1050, loss: 0.02217586152255535
step: 1060, loss: 0.0001518461649538949
epoch 8: dev_f1=0.9390243902439025, f1=0.9142040038131554, best_f1=0.9238005644402634
step: 0, loss: 0.005596744827926159
step: 10, loss: 0.0021937384735792875
step: 20, loss: 0.0027798418886959553
step: 30, loss: 0.0002584554604254663
step: 40, loss: 0.0008422863320447505
step: 50, loss: 0.08661578595638275
step: 60, loss: 0.003916195593774319
step: 70, loss: 0.03946874290704727
step: 80, loss: 0.0015181686030700803
step: 90, loss: 0.007979415357112885
step: 100, loss: 0.010094677098095417
step: 110, loss: 0.00304448907263577
step: 120, loss: 0.02459704875946045
step: 130, loss: 0.000504728639498353
step: 140, loss: 0.00011150988575536758
step: 150, loss: 0.001256316783837974
step: 160, loss: 0.0002526570751797408
step: 170, loss: 0.004448790103197098
step: 180, loss: 0.00031579058850184083
step: 190, loss: 0.0032928301952779293
step: 200, loss: 0.027491383254528046
step: 210, loss: 0.0013296524994075298
step: 220, loss: 0.005604512989521027
step: 230, loss: 0.0010486862156540155
step: 240, loss: 0.0008892359910532832
step: 250, loss: 0.0033693185541778803
step: 260, loss: 0.0012296868953853846
step: 270, loss: 0.058712683618068695
step: 280, loss: 0.002319854684174061
step: 290, loss: 0.023770298808813095
step: 300, loss: 0.010185044258832932
step: 310, loss: 0.00010587195720290765
step: 320, loss: 0.002846349496394396
step: 330, loss: 0.003180988598614931
step: 340, loss: 0.0023887180723249912
step: 350, loss: 0.10393176227807999
step: 360, loss: 0.0011351278517395258
step: 370, loss: 0.004509859252721071
step: 380, loss: 0.0016663536662235856
step: 390, loss: 0.005219488870352507
step: 400, loss: 0.011473950929939747
step: 410, loss: 0.028590086847543716
step: 420, loss: 0.00442803418263793
step: 430, loss: 0.0017259500455111265
step: 440, loss: 0.0028631570748984814
step: 450, loss: 0.0026552381459623575
step: 460, loss: 0.0011194334365427494
step: 470, loss: 0.008149241097271442
step: 480, loss: 0.00966964103281498
step: 490, loss: 0.0006431686342693865
step: 500, loss: 0.028277749195694923
step: 510, loss: 0.012700201943516731
step: 520, loss: 0.002300126012414694
step: 530, loss: 6.432402005884796e-05
step: 540, loss: 0.0035460859071463346
step: 550, loss: 0.0002871839969884604
step: 560, loss: 0.00023444148246198893
step: 570, loss: 0.0010007992386817932
step: 580, loss: 0.00019805971533060074
step: 590, loss: 0.004032090771943331
step: 600, loss: 0.0003697285719681531
step: 610, loss: 0.0009334639762528241
step: 620, loss: 0.00027417964884079993
step: 630, loss: 0.004872885998338461
step: 640, loss: 0.0014710458926856518
step: 650, loss: 0.0930013582110405
step: 660, loss: 0.003423344576731324
step: 670, loss: 0.008943221531808376
step: 680, loss: 0.05700455233454704
step: 690, loss: 0.02026231400668621
step: 700, loss: 0.0001792674884200096
step: 710, loss: 0.00027562567265704274
step: 720, loss: 0.016238337382674217
step: 730, loss: 0.05260563641786575
step: 740, loss: 0.03909439221024513
step: 750, loss: 0.0019500565249472857
step: 760, loss: 0.11201844364404678
step: 770, loss: 0.008316393941640854
step: 780, loss: 0.002154846675693989
step: 790, loss: 0.05954136699438095
step: 800, loss: 0.0002849335432983935
step: 810, loss: 0.0029090556781738997
step: 820, loss: 0.0005129823111928999
step: 830, loss: 0.00823811162263155
step: 840, loss: 0.0001347438374068588
step: 850, loss: 0.018547387793660164
step: 860, loss: 0.004112982656806707
step: 870, loss: 0.0008205706253647804
step: 880, loss: 0.0005140349385328591
step: 890, loss: 0.0003266131679993123
step: 900, loss: 0.000879888713825494
step: 910, loss: 0.00028990779537707567
step: 920, loss: 0.02535337582230568
step: 930, loss: 0.014494418166577816
step: 940, loss: 0.0007595131173729897
step: 950, loss: 0.0014648739015683532
step: 960, loss: 0.007278920151293278
step: 970, loss: 0.05890967324376106
step: 980, loss: 0.0031464449129998684
step: 990, loss: 0.05131494626402855
step: 1000, loss: 0.007150521967560053
step: 1010, loss: 0.003999355714768171
step: 1020, loss: 0.0030399691313505173
step: 1030, loss: 0.015357389114797115
step: 1040, loss: 0.11104132235050201
step: 1050, loss: 0.00011798876948887482
step: 1060, loss: 0.0001222746359417215
epoch 9: dev_f1=0.9410099103350638, f1=0.9103908484270735, best_f1=0.9238005644402634
step: 0, loss: 0.000158984461450018
step: 10, loss: 0.001490080845542252
step: 20, loss: 0.000992417335510254
step: 30, loss: 0.0004971157177351415
step: 40, loss: 0.0021885663736611605
step: 50, loss: 0.004829637240618467
step: 60, loss: 0.020291663706302643
step: 70, loss: 0.001023060642182827
step: 80, loss: 9.776655497262254e-05
step: 90, loss: 0.0026492299512028694
step: 100, loss: 0.0012955169659107924
step: 110, loss: 0.0011610176879912615
step: 120, loss: 0.0552818737924099
step: 130, loss: 0.00865075271576643
step: 140, loss: 0.04008815810084343
step: 150, loss: 0.0011745048686861992
step: 160, loss: 0.02810772694647312
step: 170, loss: 0.0035717093851417303
step: 180, loss: 0.0007177108782343566
step: 190, loss: 0.0038502858951687813
step: 200, loss: 0.0026340503245592117
step: 210, loss: 0.0008346706163138151
step: 220, loss: 0.0014688550727441907
step: 230, loss: 0.0025243740528821945
step: 240, loss: 0.0003276683855801821
step: 250, loss: 0.007220062892884016
step: 260, loss: 0.011878591030836105
step: 270, loss: 0.0010314142564311624
step: 280, loss: 0.0017990139313042164
step: 290, loss: 0.007182801607996225
step: 300, loss: 0.054983366280794144
step: 310, loss: 0.007656491827219725
step: 320, loss: 0.004742694552987814
step: 330, loss: 0.0011403398821130395
step: 340, loss: 0.00026668483042158186
step: 350, loss: 0.03579448163509369
step: 360, loss: 0.020063525065779686
step: 370, loss: 0.0003834657254628837
step: 380, loss: 0.0008273152052424848
step: 390, loss: 0.00028300847043283284
step: 400, loss: 0.11062715202569962
step: 410, loss: 0.0009276882046833634
step: 420, loss: 0.2143784463405609
step: 430, loss: 0.00014226281200535595
step: 440, loss: 0.002685675397515297
step: 450, loss: 0.03216138482093811
step: 460, loss: 0.00021755653142463416
step: 470, loss: 0.0029112177435308695
step: 480, loss: 0.0016931375721469522
step: 490, loss: 0.002678793389350176
step: 500, loss: 0.06005718931555748
step: 510, loss: 0.060443565249443054
step: 520, loss: 0.001151657779701054
step: 530, loss: 0.0008440397214144468
step: 540, loss: 0.0019121186342090368
step: 550, loss: 0.0030536851845681667
step: 560, loss: 0.0002018844534177333
step: 570, loss: 0.00024148868396878242
step: 580, loss: 0.015830833464860916
step: 590, loss: 0.00025503250071778893
step: 600, loss: 0.0006129678804427385
step: 610, loss: 0.0007748079369775951
step: 620, loss: 0.006333252880722284
step: 630, loss: 0.00026935560163110495
step: 640, loss: 0.01135969441384077
step: 650, loss: 0.00016622099792584777
step: 660, loss: 0.0002339615602977574
step: 670, loss: 0.007058425340801477
step: 680, loss: 0.028191013261675835
step: 690, loss: 0.00038194621447473764
step: 700, loss: 0.12644919753074646
step: 710, loss: 0.0012064191978424788
step: 720, loss: 0.012399663217365742
step: 730, loss: 0.003583337878808379
step: 740, loss: 0.004860355984419584
step: 750, loss: 0.0803733542561531
step: 760, loss: 0.000979400472715497
step: 770, loss: 0.0020013994071632624
step: 780, loss: 0.00010038136679213494
step: 790, loss: 0.001277185045182705
step: 800, loss: 0.0011251206742599607
step: 810, loss: 0.035181522369384766
step: 820, loss: 0.009497515857219696
step: 830, loss: 0.032744865864515305
step: 840, loss: 0.004617428407073021
step: 850, loss: 0.00041647301986813545
step: 860, loss: 0.002713020658120513
step: 870, loss: 0.12101636081933975
step: 880, loss: 0.0009420994902029634
step: 890, loss: 0.014821651391685009
step: 900, loss: 0.0007861348567530513
step: 910, loss: 0.005454264115542173
step: 920, loss: 0.05543607100844383
step: 930, loss: 0.01747875101864338
step: 940, loss: 0.009365417063236237
step: 950, loss: 0.1664315164089203
step: 960, loss: 0.00015702830569352955
step: 970, loss: 0.003940638620406389
step: 980, loss: 0.002781689865514636
step: 990, loss: 0.06547541916370392
step: 1000, loss: 0.0028786021284759045
step: 1010, loss: 0.0014914064668118954
step: 1020, loss: 0.020866449922323227
step: 1030, loss: 0.015273847617208958
step: 1040, loss: 0.002126409439370036
step: 1050, loss: 0.022648530080914497
step: 1060, loss: 6.414004747057334e-05
epoch 10: dev_f1=0.9455053563111318, f1=0.92090395480226, best_f1=0.9238005644402634
step: 0, loss: 0.00437978794798255
step: 10, loss: 0.028255941346287727
step: 20, loss: 0.020144036039710045
step: 30, loss: 0.00026180181885138154
step: 40, loss: 0.002203679643571377
step: 50, loss: 8.59690408105962e-05
step: 60, loss: 0.004513544496148825
step: 70, loss: 0.001010397681966424
step: 80, loss: 0.0003622147487476468
step: 90, loss: 0.0023667903151363134
step: 100, loss: 0.00018923741299659014
step: 110, loss: 0.09378106892108917
step: 120, loss: 0.0009507833165116608
step: 130, loss: 0.029489226639270782
step: 140, loss: 0.0006195474416017532
step: 150, loss: 0.000879905535839498
step: 160, loss: 0.0002402806276222691
step: 170, loss: 0.00117286026943475
step: 180, loss: 0.0008108580368570983
step: 190, loss: 0.0014966706512495875
step: 200, loss: 0.006246063392609358
step: 210, loss: 0.0009657780174165964
step: 220, loss: 0.00029794967849738896
step: 230, loss: 0.0003436775295995176
step: 240, loss: 0.011548752896487713
step: 250, loss: 0.05468938499689102
step: 260, loss: 0.006561589892953634
step: 270, loss: 0.0008894852944649756
step: 280, loss: 0.002335560042411089
step: 290, loss: 0.00013659970136359334
step: 300, loss: 0.009843201376497746
step: 310, loss: 0.0009072183747775853
step: 320, loss: 8.895812788978219e-05
step: 330, loss: 0.018602846190333366
step: 340, loss: 0.010672483593225479
step: 350, loss: 0.0001660204288782552
step: 360, loss: 0.0005893994239158928
step: 370, loss: 0.0009308242006227374
step: 380, loss: 0.0003510496753733605
step: 390, loss: 0.002503262599930167
step: 400, loss: 0.00042495279922150075
step: 410, loss: 0.001962645212188363
step: 420, loss: 0.0006258816574700177
step: 430, loss: 0.004796821624040604
step: 440, loss: 0.003666623728349805
step: 450, loss: 0.0003350110200699419
step: 460, loss: 6.25569446128793e-05
step: 470, loss: 0.000841198954731226
step: 480, loss: 0.007566069718450308
step: 490, loss: 0.00032286407076753676
step: 500, loss: 0.04420991614460945
step: 510, loss: 0.001239288249053061
step: 520, loss: 0.0004944357206113636
step: 530, loss: 0.0007602053228765726
step: 540, loss: 0.09436381608247757
step: 550, loss: 0.0002819741202984005
step: 560, loss: 0.00031197466887533665
step: 570, loss: 0.0009937717113643885
step: 580, loss: 0.0008451766916550696
step: 590, loss: 0.003215531352907419
step: 600, loss: 0.0011435976484790444
step: 610, loss: 0.0024799108505249023
step: 620, loss: 0.0019252916099503636
step: 630, loss: 0.0017162710428237915
step: 640, loss: 0.0014384451787918806
step: 650, loss: 0.0036720235366374254
step: 660, loss: 0.0008235627319663763
step: 670, loss: 0.004517858382314444
step: 680, loss: 0.004380905069410801
step: 690, loss: 0.00022161955712363124
step: 700, loss: 0.001147740171290934
step: 710, loss: 0.06218067556619644
step: 720, loss: 0.09795846790075302
step: 730, loss: 0.02243507280945778
step: 740, loss: 0.011993180960416794
step: 750, loss: 0.00028712546918541193
step: 760, loss: 0.00022899112082086504
step: 770, loss: 0.07812023907899857
step: 780, loss: 0.0013249097391963005
step: 790, loss: 0.008209949359297752
step: 800, loss: 0.03688950836658478
step: 810, loss: 0.0002661447215359658
step: 820, loss: 0.0032310227397829294
step: 830, loss: 0.0002926587185356766
step: 840, loss: 0.00013581628445535898
step: 850, loss: 0.004978393670171499
step: 860, loss: 5.290920307743363e-05
step: 870, loss: 0.0003657147171907127
step: 880, loss: 0.00017887153080664575
step: 890, loss: 0.04281371831893921
step: 900, loss: 0.0002306931564817205
step: 910, loss: 0.02639145590364933
step: 920, loss: 0.004462509416043758
step: 930, loss: 7.19102899893187e-05
step: 940, loss: 0.013786174356937408
step: 950, loss: 0.00014954336802475154
step: 960, loss: 0.0003293166228104383
step: 970, loss: 0.0008049953612498939
step: 980, loss: 0.001993051264435053
step: 990, loss: 0.042525678873062134
step: 1000, loss: 4.763978722621687e-05
step: 1010, loss: 0.00026330098626203835
step: 1020, loss: 0.003731361124664545
step: 1030, loss: 0.0005398010252974927
step: 1040, loss: 0.022739972919225693
step: 1050, loss: 0.039386145770549774
step: 1060, loss: 2.3036809579934925e-05
epoch 11: dev_f1=0.9491046182846371, f1=0.9219047619047618, best_f1=0.9238005644402634
step: 0, loss: 6.450356158893555e-05
step: 10, loss: 0.0002057706587947905
step: 20, loss: 0.0036141311284154654
step: 30, loss: 8.856951171765104e-05
step: 40, loss: 0.0004183812125120312
step: 50, loss: 0.0014256200520321727
step: 60, loss: 0.0005557695403695107
step: 70, loss: 0.005240337923169136
step: 80, loss: 0.0003973935090471059
step: 90, loss: 0.00034941232297569513
step: 100, loss: 0.005006549879908562
step: 110, loss: 0.0006529968813993037
step: 120, loss: 0.0035799257457256317
step: 130, loss: 0.019289329648017883
step: 140, loss: 0.0005975340609438717
step: 150, loss: 9.289286390412599e-05
step: 160, loss: 0.0019897352904081345
step: 170, loss: 0.09074876457452774
step: 180, loss: 0.0008493835339322686
step: 190, loss: 0.021645670756697655
step: 200, loss: 0.004533972591161728
step: 210, loss: 0.16811954975128174
step: 220, loss: 0.00020336690067779273
step: 230, loss: 0.009713507257401943
step: 240, loss: 0.0009989471873268485
step: 250, loss: 0.016286512836813927
step: 260, loss: 0.029154334217309952
step: 270, loss: 0.0006356461090035737
step: 280, loss: 0.002709339139983058
step: 290, loss: 0.00014046345313545316
step: 300, loss: 0.00012258529022801667
step: 310, loss: 0.0006120181060396135
step: 320, loss: 0.00047341655590571463
step: 330, loss: 0.029828226193785667
step: 340, loss: 0.0005433887126855552
step: 350, loss: 0.01113826222717762
step: 360, loss: 0.000246162002440542
step: 370, loss: 0.0001502516824984923
step: 380, loss: 0.04315459728240967
step: 390, loss: 9.485775808570907e-05
step: 400, loss: 0.000630761671345681
step: 410, loss: 0.005022528115659952
step: 420, loss: 0.0006275017512962222
step: 430, loss: 0.0018643306102603674
step: 440, loss: 0.0011854065814986825
step: 450, loss: 0.0007268281187862158
step: 460, loss: 0.019246960058808327
step: 470, loss: 0.00011464663839433342
step: 480, loss: 0.012044417671859264
step: 490, loss: 0.0018943317700177431
step: 500, loss: 0.001146563794463873
step: 510, loss: 0.0016937842592597008
step: 520, loss: 0.006524017080664635
step: 530, loss: 0.04166248440742493
step: 540, loss: 0.0052085816860198975
step: 550, loss: 0.0004837644228246063
step: 560, loss: 0.033671680837869644
step: 570, loss: 0.025669557973742485
step: 580, loss: 0.00045670956023968756
step: 590, loss: 0.001071579405106604
step: 600, loss: 0.0007607120787724853
step: 610, loss: 0.00011394812463549897
step: 620, loss: 0.0003340273688081652
step: 630, loss: 8.910035830922425e-05
step: 640, loss: 0.00024158178712241352
step: 650, loss: 0.15605740249156952
step: 660, loss: 0.0003606298996601254
step: 670, loss: 0.006439431104809046
step: 680, loss: 0.017818989232182503
step: 690, loss: 0.0037259457167237997
step: 700, loss: 0.00011984545562881976
step: 710, loss: 0.016617871820926666
step: 720, loss: 0.007490949705243111
step: 730, loss: 0.0038984541315585375
step: 740, loss: 0.013156979344785213
step: 750, loss: 0.006257610395550728
step: 760, loss: 0.017888033762574196
step: 770, loss: 0.00014205335173755884
step: 780, loss: 0.00029729222296737134
step: 790, loss: 0.01468568667769432
step: 800, loss: 0.0006400175043381751
step: 810, loss: 0.0009510988020338118
step: 820, loss: 0.026796400547027588
step: 830, loss: 0.001648678444325924
step: 840, loss: 0.10494470596313477
step: 850, loss: 0.002179313451051712
step: 860, loss: 0.048469722270965576
step: 870, loss: 0.001858053612522781
step: 880, loss: 0.0003574940492399037
step: 890, loss: 7.15863861842081e-05
step: 900, loss: 0.0017303680069744587
step: 910, loss: 0.008500770665705204
step: 920, loss: 0.0002889942843466997
step: 930, loss: 0.0514756441116333
step: 940, loss: 0.0032101739197969437
step: 950, loss: 0.00047786449431441724
step: 960, loss: 0.0023530919570475817
step: 970, loss: 0.008667501620948315
step: 980, loss: 0.009934448637068272
step: 990, loss: 0.0034623327665030956
step: 1000, loss: 0.0003656219341792166
step: 1010, loss: 0.00048054414219222963
step: 1020, loss: 0.004545561503618956
step: 1030, loss: 0.039246831089258194
step: 1040, loss: 0.0001611455372767523
step: 1050, loss: 0.00016018591122701764
step: 1060, loss: 0.00011605994222918525
epoch 12: dev_f1=0.9482185273159144, f1=0.9100580270793036, best_f1=0.9238005644402634
step: 0, loss: 0.019578753039240837
step: 10, loss: 0.0005298841279000044
step: 20, loss: 0.0005205826018936932
step: 30, loss: 0.00028956946334801614
step: 40, loss: 0.00553539302200079
step: 50, loss: 0.00016731426876503974
step: 60, loss: 0.0002137539122486487
step: 70, loss: 5.708436947315931e-05
step: 80, loss: 0.0001207739333040081
step: 90, loss: 0.0023926817812025547
step: 100, loss: 0.0024539721198379993
step: 110, loss: 0.0006619293708354235
step: 120, loss: 0.00034510839032009244
step: 130, loss: 0.003614781890064478
step: 140, loss: 0.02948472462594509
step: 150, loss: 0.0004588556766975671
step: 160, loss: 4.994741175323725e-05
step: 170, loss: 0.0001032371073961258
step: 180, loss: 5.255480209598318e-05
step: 190, loss: 0.00020416795450728387
step: 200, loss: 0.00029089360032230616
step: 210, loss: 0.003748830407857895
step: 220, loss: 0.005095974542200565
step: 230, loss: 0.00010576640488579869
step: 240, loss: 0.00022305241145659238
step: 250, loss: 0.00565124349668622
step: 260, loss: 0.000177322217496112
step: 270, loss: 0.009488480165600777
step: 280, loss: 0.0006061671301722527
step: 290, loss: 0.03531717136502266
step: 300, loss: 0.00011268322850810364
step: 310, loss: 0.00027021433925256133
step: 320, loss: 0.000490186212118715
step: 330, loss: 0.0023379565682262182
step: 340, loss: 0.00041091741877608
step: 350, loss: 0.006894929334521294
step: 360, loss: 0.00019151509332004935
step: 370, loss: 0.00029310109675861895
step: 380, loss: 0.01543160155415535
step: 390, loss: 0.0021378295496106148
step: 400, loss: 0.006010896060615778
step: 410, loss: 0.00029067645664326847
step: 420, loss: 0.000166924117365852
step: 430, loss: 0.006592914462089539
step: 440, loss: 0.0005201858002692461
step: 450, loss: 0.004055430646985769
step: 460, loss: 0.0023225205950438976
step: 470, loss: 0.001737168524414301
step: 480, loss: 5.6052173022180796e-05
step: 490, loss: 0.0015964063350111246
step: 500, loss: 0.00015710886509623379
step: 510, loss: 0.01144243311136961
step: 520, loss: 0.000698400370310992
step: 530, loss: 0.0001788398512871936
step: 540, loss: 0.048612695187330246
step: 550, loss: 7.571838796138763e-05
step: 560, loss: 0.0004839233006350696
step: 570, loss: 6.677318015135825e-05
step: 580, loss: 0.00011406414705561474
step: 590, loss: 9.092710388358682e-05
step: 600, loss: 7.080914656398818e-05
step: 610, loss: 0.00010083736560773104
step: 620, loss: 7.823938358342275e-05
step: 630, loss: 0.0005067745223641396
step: 640, loss: 0.010569211095571518
step: 650, loss: 0.0027409661561250687
step: 660, loss: 0.0004249130724929273
step: 670, loss: 0.0011727371020242572
step: 680, loss: 0.00038224124000407755
step: 690, loss: 0.0012780849356204271
step: 700, loss: 4.938554047839716e-05
step: 710, loss: 0.0006869652424938977
step: 720, loss: 0.0006168701802380383
step: 730, loss: 0.000685662729665637
step: 740, loss: 2.8117539841332473e-05
step: 750, loss: 0.0004708529741037637
step: 760, loss: 0.00048733747098594904
step: 770, loss: 0.08624760061502457
step: 780, loss: 0.02916758321225643
step: 790, loss: 9.410074562765658e-05
step: 800, loss: 0.040520887821912766
step: 810, loss: 0.001124776084907353
step: 820, loss: 0.005183137021958828
step: 830, loss: 5.31560908711981e-05
step: 840, loss: 0.002062327926978469
step: 850, loss: 3.465673580649309e-05
step: 860, loss: 0.00823614839464426
step: 870, loss: 0.011467905715107918
step: 880, loss: 0.00038515101186931133
step: 890, loss: 0.029317772015929222
step: 900, loss: 0.0004932434530928731
step: 910, loss: 0.000335423625074327
step: 920, loss: 0.030291054397821426
step: 930, loss: 0.000648503249976784
step: 940, loss: 0.0020224431063979864
step: 950, loss: 0.008966907858848572
step: 960, loss: 0.0011150263017043471
step: 970, loss: 0.023296523839235306
step: 980, loss: 4.834414357901551e-05
step: 990, loss: 0.0017642058664932847
step: 1000, loss: 0.00042415590723976493
step: 1010, loss: 0.003898230381309986
step: 1020, loss: 0.03887731954455376
step: 1030, loss: 0.0007933438173495233
step: 1040, loss: 0.0003868074854835868
step: 1050, loss: 0.00036540941800922155
step: 1060, loss: 0.0004582482797559351
epoch 13: dev_f1=0.9441340782122905, f1=0.9247311827956989, best_f1=0.9238005644402634
step: 0, loss: 0.00017172243678942323
step: 10, loss: 0.000283285160548985
step: 20, loss: 0.0003698683576658368
step: 30, loss: 0.0009023942402563989
step: 40, loss: 0.0005623862380161881
step: 50, loss: 0.00014032493345439434
step: 60, loss: 0.011981397867202759
step: 70, loss: 2.8288186513236724e-05
step: 80, loss: 0.0015400178963318467
step: 90, loss: 0.0001823537895688787
step: 100, loss: 3.37643941747956e-05
step: 110, loss: 0.0006319663370959461
step: 120, loss: 0.09197970479726791
step: 130, loss: 0.0006004165625199676
step: 140, loss: 0.0047137923538684845
step: 150, loss: 0.0016146235866472125
step: 160, loss: 0.00731910765171051
step: 170, loss: 0.0005863931146450341
step: 180, loss: 6.215435860212892e-05
step: 190, loss: 0.00012100046296836808
step: 200, loss: 7.07872532075271e-05
step: 210, loss: 0.00014127868053037673
step: 220, loss: 0.00042519939597696066
step: 230, loss: 0.00013367131759878248
step: 240, loss: 0.0002727885148487985
step: 250, loss: 0.0011413139291107655
step: 260, loss: 0.00011612112575676292
step: 270, loss: 0.0006078381557017565
step: 280, loss: 0.0010109547292813659
step: 290, loss: 0.053238753229379654
step: 300, loss: 0.0068115429021418095
step: 310, loss: 5.593359310296364e-05
step: 320, loss: 0.05954699218273163
step: 330, loss: 0.00014322009519673884
step: 340, loss: 0.0028607104904949665
step: 350, loss: 0.0027514013927429914
step: 360, loss: 0.00021898669365327805
step: 370, loss: 0.0036831721663475037
step: 380, loss: 0.01378561556339264
step: 390, loss: 0.002044333377853036
step: 400, loss: 0.0001090466757887043
step: 410, loss: 5.7031506003113464e-05
step: 420, loss: 0.002412838628515601
step: 430, loss: 6.035949263605289e-05
step: 440, loss: 0.0006715272320434451
step: 450, loss: 0.00030409020837396383
step: 460, loss: 0.0001797211734810844
step: 470, loss: 0.0001713678939267993
step: 480, loss: 0.019426574930548668
step: 490, loss: 0.0016841692849993706
step: 500, loss: 0.0894390270113945
step: 510, loss: 0.00020401716756168753
step: 520, loss: 9.766262519406155e-05
step: 530, loss: 0.002077294047921896
step: 540, loss: 0.038977816700935364
step: 550, loss: 0.003133930964395404
step: 560, loss: 3.425961403991096e-05
step: 570, loss: 6.35741525911726e-05
step: 580, loss: 0.0014942805282771587
step: 590, loss: 0.00039504305459558964
step: 600, loss: 2.860555650840979e-05
step: 610, loss: 3.393939186935313e-05
step: 620, loss: 4.964039908372797e-05
step: 630, loss: 5.791193325421773e-05
step: 640, loss: 0.00025997459306381643
step: 650, loss: 6.083879998186603e-05
step: 660, loss: 0.0008507078164257109
step: 670, loss: 0.00010200933320447803
step: 680, loss: 9.690877050161362e-05
step: 690, loss: 4.28795101470314e-05
step: 700, loss: 0.00011988750338787213
step: 710, loss: 0.013002436608076096
step: 720, loss: 0.0004062371444888413
step: 730, loss: 0.0005016819341108203
step: 740, loss: 0.004956170450896025
step: 750, loss: 0.0007156425854191184
step: 760, loss: 0.004650306887924671
step: 770, loss: 0.0017504437128081918
step: 780, loss: 0.0063069355674088
step: 790, loss: 0.00016861876065377146
step: 800, loss: 0.002605356276035309
step: 810, loss: 0.0022701031994074583
step: 820, loss: 0.001024666242301464
step: 830, loss: 0.0008525819284841418
step: 840, loss: 6.885793118271977e-05
step: 850, loss: 0.0005136586842127144
step: 860, loss: 0.00017454902990721166
step: 870, loss: 0.002439450705423951
step: 880, loss: 0.0013345831539481878
step: 890, loss: 4.011913915746845e-05
step: 900, loss: 6.713104812661186e-05
step: 910, loss: 3.640855720732361e-05
step: 920, loss: 0.009093116037547588
step: 930, loss: 0.0002595056430436671
step: 940, loss: 0.021627020090818405
step: 950, loss: 0.00854289997369051
step: 960, loss: 0.0006647804984822869
step: 970, loss: 4.745591650134884e-05
step: 980, loss: 0.00010695551463868469
step: 990, loss: 0.008004266768693924
step: 1000, loss: 0.002163166645914316
step: 1010, loss: 0.0022779309656471014
step: 1020, loss: 0.0010539384093135595
step: 1030, loss: 0.0002781944931484759
step: 1040, loss: 6.0697631852235645e-05
step: 1050, loss: 0.0006415292154997587
step: 1060, loss: 0.0003144911315757781
epoch 14: dev_f1=0.948405253283302, f1=0.9165474487362899, best_f1=0.9238005644402634
step: 0, loss: 0.000166931509738788
step: 10, loss: 0.001056096632964909
step: 20, loss: 0.08365143090486526
step: 30, loss: 4.7061086661415175e-05
step: 40, loss: 0.0007060006028041244
step: 50, loss: 6.973696872591972e-05
step: 60, loss: 7.818429003236815e-05
step: 70, loss: 0.005064282566308975
step: 80, loss: 4.8966172471409664e-05
step: 90, loss: 0.0001561972894705832
step: 100, loss: 0.0001751171803334728
step: 110, loss: 0.00038730696542188525
step: 120, loss: 0.00023486751888412982
step: 130, loss: 4.903694207314402e-05
step: 140, loss: 0.00019723146397154778
step: 150, loss: 7.100174116203561e-05
step: 160, loss: 0.00010761516023194417
step: 170, loss: 0.014274810440838337
step: 180, loss: 0.0014852308668196201
step: 190, loss: 0.0012494479306042194
step: 200, loss: 2.2667763914796524e-05
step: 210, loss: 0.024649593979120255
step: 220, loss: 0.0002826190320774913
step: 230, loss: 0.00026254000840708613
step: 240, loss: 5.0342172471573576e-05
step: 250, loss: 6.341077096294612e-05
step: 260, loss: 0.0026307946536689997
step: 270, loss: 0.0009474432445131242
step: 280, loss: 0.00037613886524923146
step: 290, loss: 0.00010792929242597893
step: 300, loss: 6.824784213677049e-05
step: 310, loss: 0.11521913856267929
step: 320, loss: 0.0003962626797147095
step: 330, loss: 6.752346234861761e-05
step: 340, loss: 0.019991885870695114
step: 350, loss: 7.875848677940667e-05
step: 360, loss: 4.325945701566525e-05
step: 370, loss: 0.030325330793857574
step: 380, loss: 0.004245000425726175
step: 390, loss: 7.310492946999148e-05
step: 400, loss: 0.09486829489469528
step: 410, loss: 0.0006172345019876957
step: 420, loss: 0.00857244897633791
step: 430, loss: 2.1665582607965916e-05
step: 440, loss: 5.42954403499607e-05
step: 450, loss: 0.00013905952800996602
step: 460, loss: 0.02191118150949478
step: 470, loss: 0.011465792544186115
step: 480, loss: 0.01117821503430605
step: 490, loss: 3.56661512341816e-05
step: 500, loss: 0.0008948720060288906
step: 510, loss: 0.007737910374999046
step: 520, loss: 0.00010395917342975736
step: 530, loss: 3.466563794063404e-05
step: 540, loss: 2.1788211597595364e-05
step: 550, loss: 0.0008199035073630512
step: 560, loss: 0.000610601156949997
step: 570, loss: 0.007834074087440968
step: 580, loss: 2.2462880224338733e-05
step: 590, loss: 0.00010445946827530861
step: 600, loss: 0.001627337303943932
step: 610, loss: 0.011465346440672874
step: 620, loss: 0.0010554298060014844
step: 630, loss: 0.0004888408584520221
step: 640, loss: 8.281633199658245e-05
step: 650, loss: 0.0007547371205873787
step: 660, loss: 4.665168671635911e-05
step: 670, loss: 3.531446782290004e-05
step: 680, loss: 0.0240786150097847
step: 690, loss: 0.0034436695277690887
step: 700, loss: 9.520262392470613e-05
step: 710, loss: 0.00018738482322078198
step: 720, loss: 1.95610828086501e-05
step: 730, loss: 5.081429844722152e-05
step: 740, loss: 0.000114486574602779
step: 750, loss: 2.5565861506038345e-05
step: 760, loss: 0.00025967147666960955
step: 770, loss: 0.0023212479427456856
step: 780, loss: 0.0002176434500142932
step: 790, loss: 0.00039072593790479004
step: 800, loss: 0.001461161533370614
step: 810, loss: 0.0001038463378790766
step: 820, loss: 0.00011118421389255673
step: 830, loss: 7.1904287324287e-05
step: 840, loss: 0.001712033525109291
step: 850, loss: 0.007739991880953312
step: 860, loss: 0.00017529836622998118
step: 870, loss: 6.300013046711683e-05
step: 880, loss: 0.012159781530499458
step: 890, loss: 0.00014701942563988268
step: 900, loss: 0.003756038611754775
step: 910, loss: 6.175320595502853e-05
step: 920, loss: 0.004449980333447456
step: 930, loss: 0.0179012268781662
step: 940, loss: 0.0029529009480029345
step: 950, loss: 0.00048582450835965574
step: 960, loss: 0.0007531867595389485
step: 970, loss: 0.0008607307099737227
step: 980, loss: 0.00011601402366068214
step: 990, loss: 5.3641524573322386e-05
step: 1000, loss: 0.026897521689534187
step: 1010, loss: 0.004532027058303356
step: 1020, loss: 0.0499451719224453
step: 1030, loss: 9.148650133283809e-05
step: 1040, loss: 3.288089283159934e-05
step: 1050, loss: 2.126348772435449e-05
step: 1060, loss: 0.0002659392775967717
epoch 15: dev_f1=0.9443929564411491, f1=0.9237209302325581, best_f1=0.9238005644402634
step: 0, loss: 0.001570767373777926
step: 10, loss: 0.005099360831081867
step: 20, loss: 0.0004414411378093064
step: 30, loss: 9.462284651817754e-05
step: 40, loss: 3.9203601772896945e-05
step: 50, loss: 0.03626858443021774
step: 60, loss: 4.5236160076456144e-05
step: 70, loss: 0.00017866790585685521
step: 80, loss: 0.03137322515249252
step: 90, loss: 4.3082196498289704e-05
step: 100, loss: 0.0015555373392999172
step: 110, loss: 5.0004869990516454e-05
step: 120, loss: 0.0603305883705616
step: 130, loss: 0.0016748876078054309
step: 140, loss: 0.00046749593457207084
step: 150, loss: 3.550077963154763e-05
step: 160, loss: 0.00030745528056286275
step: 170, loss: 0.00036789278965443373
step: 180, loss: 0.02247675135731697
step: 190, loss: 0.0024957265704870224
step: 200, loss: 0.00041891864384524524
step: 210, loss: 4.381593316793442e-05
step: 220, loss: 0.0007481617503799498
step: 230, loss: 4.573506521410309e-05
step: 240, loss: 2.9595614250865765e-05
step: 250, loss: 0.007869604043662548
step: 260, loss: 0.0026455039624124765
step: 270, loss: 0.00025377434212714434
step: 280, loss: 4.1084018448600546e-05
step: 290, loss: 0.00020684066112153232
step: 300, loss: 2.797970228129998e-05
step: 310, loss: 0.0002840288507286459
step: 320, loss: 0.00011971475032623857
step: 330, loss: 2.149069041479379e-05
step: 340, loss: 0.00016302336007356644
step: 350, loss: 0.008718508295714855
step: 360, loss: 0.00024397997185587883
step: 370, loss: 5.1961978897452354e-05
step: 380, loss: 4.651064227800816e-05
step: 390, loss: 0.0003145809459965676
step: 400, loss: 6.149899127194658e-05
step: 410, loss: 0.0002165573969250545
step: 420, loss: 0.00020705982751678675
step: 430, loss: 8.103000436676666e-05
step: 440, loss: 7.576651114504784e-05
step: 450, loss: 2.6395131499157287e-05
step: 460, loss: 0.03037831000983715
step: 470, loss: 0.04810355231165886
step: 480, loss: 0.0428888201713562
step: 490, loss: 0.000157984861289151
step: 500, loss: 0.0001583047560416162
step: 510, loss: 6.871669029351324e-05
step: 520, loss: 0.00011378555063856766
step: 530, loss: 3.750770338228904e-05
step: 540, loss: 0.0002061274863081053
step: 550, loss: 4.628866372513585e-05
step: 560, loss: 0.0007457686006091535
step: 570, loss: 0.0009194593294523656
step: 580, loss: 0.026911314576864243
step: 590, loss: 0.033185143023729324
step: 600, loss: 0.0005138270207680762
step: 610, loss: 0.00032414260203950107
step: 620, loss: 0.0037007220089435577
step: 630, loss: 4.452871871762909e-05
step: 640, loss: 0.00010763484897324815
step: 650, loss: 0.00025699869729578495
step: 660, loss: 0.008043130859732628
step: 670, loss: 0.0001283886085730046
step: 680, loss: 3.271777677582577e-05
step: 690, loss: 2.453030538163148e-05
step: 700, loss: 2.9655680918949656e-05
step: 710, loss: 8.199623698601499e-05
step: 720, loss: 0.0012839377159252763
step: 730, loss: 3.454047691775486e-05
step: 740, loss: 0.0007111155427992344
step: 750, loss: 0.00015695818001404405
step: 760, loss: 0.0002228304510936141
step: 770, loss: 8.872299804352224e-05
step: 780, loss: 5.266204243525863e-05
step: 790, loss: 0.0035993806086480618
step: 800, loss: 0.0015905462205410004
step: 810, loss: 0.00017989847401622683
step: 820, loss: 0.013759888708591461
step: 830, loss: 0.011370647698640823
step: 840, loss: 0.0003254505281802267
step: 850, loss: 0.0009378384565934539
step: 860, loss: 0.0002780962095130235
step: 870, loss: 0.07705546915531158
step: 880, loss: 0.0007986657437868416
step: 890, loss: 0.00023119893739931285
step: 900, loss: 3.014036701642908e-05
step: 910, loss: 0.0002729019906837493
step: 920, loss: 0.00017508583550807089
step: 930, loss: 0.00011942422133870423
step: 940, loss: 0.00010323658352717757
step: 950, loss: 3.07578120555263e-05
step: 960, loss: 0.0002201040624640882
step: 970, loss: 6.921646127011627e-05
step: 980, loss: 0.009116284549236298
step: 990, loss: 0.0004931706353090703
step: 1000, loss: 2.7867816243087873e-05
step: 1010, loss: 0.05080200731754303
step: 1020, loss: 2.9755981813650578e-05
step: 1030, loss: 0.0036536494735628366
step: 1040, loss: 0.00016681598208379
step: 1050, loss: 4.561329114949331e-05
step: 1060, loss: 0.00021305774862412363
epoch 16: dev_f1=0.943449575871819, f1=0.9138180067404911, best_f1=0.9238005644402634
step: 0, loss: 0.000770140322856605
step: 10, loss: 0.00013730660430155694
step: 20, loss: 0.0002906237787101418
step: 30, loss: 5.410132871475071e-05
step: 40, loss: 0.0006292653270065784
step: 50, loss: 0.0001704637979855761
step: 60, loss: 5.234734999248758e-05
step: 70, loss: 0.00021763805125374347
step: 80, loss: 0.0002791078295558691
step: 90, loss: 0.0148545503616333
step: 100, loss: 4.2067465983564034e-05
step: 110, loss: 0.0003376845852471888
step: 120, loss: 4.7385517973452806e-05
step: 130, loss: 3.7138779589440674e-05
step: 140, loss: 0.0002815551415551454
step: 150, loss: 8.229955710703507e-05
step: 160, loss: 0.00023013693862594664
step: 170, loss: 0.0015052893431857228
step: 180, loss: 0.0007995886262506247
step: 190, loss: 3.6956222174922004e-05
step: 200, loss: 6.652023876085877e-05
step: 210, loss: 9.79817341431044e-05
step: 220, loss: 0.00037644722033292055
step: 230, loss: 7.942782394820824e-05
step: 240, loss: 0.00034247635630890727
step: 250, loss: 0.005563163198530674
step: 260, loss: 5.341775977285579e-05
step: 270, loss: 4.377042569103651e-05
step: 280, loss: 0.009960870258510113
step: 290, loss: 8.371593139600009e-05
step: 300, loss: 0.0006540927570313215
step: 310, loss: 0.0001614128559594974
step: 320, loss: 5.1031009206781164e-05
step: 330, loss: 7.518647908000275e-05
step: 340, loss: 3.496339195407927e-05
step: 350, loss: 0.0008491586777381599
step: 360, loss: 0.0003932570107281208
step: 370, loss: 3.1894876883598045e-05
step: 380, loss: 0.00010485002712812275
step: 390, loss: 0.0007246439927257597
step: 400, loss: 7.062151416903362e-05
step: 410, loss: 4.8309047997463495e-05
step: 420, loss: 3.6313696909928694e-05
step: 430, loss: 8.953148062573746e-05
step: 440, loss: 0.00032051230664364994
step: 450, loss: 0.00018888547492679209
step: 460, loss: 2.6955243811244145e-05
step: 470, loss: 0.00012397112732287496
step: 480, loss: 5.005688944947906e-05
step: 490, loss: 2.251879050163552e-05
step: 500, loss: 2.0425361071829684e-05
step: 510, loss: 0.0021962544415146112
step: 520, loss: 5.643553959089331e-05
step: 530, loss: 7.17956354492344e-05
step: 540, loss: 0.0007767820497974753
step: 550, loss: 3.854552051052451e-05
step: 560, loss: 0.00013556556950788945
step: 570, loss: 0.00032721032039262354
step: 580, loss: 0.00012820420670323074
step: 590, loss: 4.45724290329963e-05
step: 600, loss: 0.00014632195234298706
step: 610, loss: 0.00015204590454231948
step: 620, loss: 0.00011130759230582044
step: 630, loss: 2.474994289514143e-05
step: 640, loss: 0.084954172372818
step: 650, loss: 2.8709086109302007e-05
step: 660, loss: 0.001049009501002729
step: 670, loss: 0.00012144426727900282
step: 680, loss: 0.00015468952187802643
step: 690, loss: 3.973105413024314e-05
step: 700, loss: 0.0002519314002711326
step: 710, loss: 0.00019619464001152664
step: 720, loss: 4.019275002065115e-05
step: 730, loss: 0.00027673598378896713
step: 740, loss: 0.004384866915643215
step: 750, loss: 0.0011387178674340248
step: 760, loss: 0.000237340631429106
step: 770, loss: 0.0006475727423094213
step: 780, loss: 4.446011007530615e-05
step: 790, loss: 0.0014508242020383477
step: 800, loss: 0.00022654312488157302
step: 810, loss: 0.00021682454098481685
step: 820, loss: 0.00038443494122475386
step: 830, loss: 0.0001313015673076734
step: 840, loss: 0.0002736957685556263
step: 850, loss: 0.000715102010872215
step: 860, loss: 0.00012852763757109642
step: 870, loss: 0.0016503228107467294
step: 880, loss: 3.0497332772938535e-05
step: 890, loss: 0.00010527260019443929
step: 900, loss: 7.092205487424508e-05
step: 910, loss: 8.322397479787469e-05
step: 920, loss: 5.841637903358787e-05
step: 930, loss: 5.801847146358341e-05
step: 940, loss: 0.02140170708298683
step: 950, loss: 6.307000148808584e-05
step: 960, loss: 4.1934006731025875e-05
step: 970, loss: 0.00822681374847889
step: 980, loss: 6.193421722855419e-05
step: 990, loss: 0.00016714925004635006
step: 1000, loss: 8.945749868871644e-05
step: 1010, loss: 0.00017167443002108485
step: 1020, loss: 0.00016653074999339879
step: 1030, loss: 4.880404594587162e-05
step: 1040, loss: 0.029030365869402885
step: 1050, loss: 5.875848000869155e-05
step: 1060, loss: 3.649580685305409e-05
epoch 17: dev_f1=0.9438414346389806, f1=0.9122468659594987, best_f1=0.9238005644402634
step: 0, loss: 2.3367387257167138e-05
step: 10, loss: 3.805525921052322e-05
step: 20, loss: 1.748992690409068e-05
step: 30, loss: 8.450456516584381e-05
step: 40, loss: 4.247532342560589e-05
step: 50, loss: 7.270515197888017e-05
step: 60, loss: 0.003916861489415169
step: 70, loss: 0.013823924586176872
step: 80, loss: 0.004600937012583017
step: 90, loss: 0.00034482809132896364
step: 100, loss: 3.459631625446491e-05
step: 110, loss: 6.391546776285395e-05
step: 120, loss: 0.17135833203792572
step: 130, loss: 0.0020016587805002928
step: 140, loss: 2.429502819722984e-05
step: 150, loss: 3.8411242712754756e-05
step: 160, loss: 0.020520875230431557
step: 170, loss: 0.01491429191082716
step: 180, loss: 0.0029723085463047028
step: 190, loss: 4.3542564526433125e-05
step: 200, loss: 0.0006407683831639588
step: 210, loss: 3.437553095864132e-05
step: 220, loss: 2.433977715554647e-05
step: 230, loss: 0.0010691063944250345
step: 240, loss: 6.666016270173714e-05
step: 250, loss: 2.1620988263748586e-05
step: 260, loss: 0.011451944708824158
step: 270, loss: 6.503151962533593e-05
step: 280, loss: 0.0020210586953908205
step: 290, loss: 4.129760054638609e-05
step: 300, loss: 0.00012168319517513737
step: 310, loss: 4.531988452072255e-05
step: 320, loss: 0.0004676588287111372
step: 330, loss: 6.495040724985301e-05
step: 340, loss: 0.012316448614001274
step: 350, loss: 7.184974674601108e-05
step: 360, loss: 2.5930858100764453e-05
step: 370, loss: 6.025073889759369e-05
step: 380, loss: 0.00030429483740590513
step: 390, loss: 0.00018485807231627405
step: 400, loss: 0.0001031791907735169
step: 410, loss: 0.0002902057603932917
step: 420, loss: 2.1743888282799162e-05
step: 430, loss: 0.0030765109695494175
step: 440, loss: 0.0018937119748443365
step: 450, loss: 8.03889415692538e-05
step: 460, loss: 0.00042717542964965105
step: 470, loss: 4.8467234591953456e-05
step: 480, loss: 5.2906907512806356e-05
step: 490, loss: 0.010177425108850002
step: 500, loss: 2.8228305382071994e-05
step: 510, loss: 6.376847886713222e-05
step: 520, loss: 0.0002707982202991843
step: 530, loss: 8.50857759360224e-05
step: 540, loss: 0.00012237881310284138
step: 550, loss: 0.026886621490120888
step: 560, loss: 0.0030802246183156967
step: 570, loss: 0.015600819140672684
step: 580, loss: 0.0001545607519801706
step: 590, loss: 9.840090933721513e-05
step: 600, loss: 4.85874516016338e-05
step: 610, loss: 0.0002738875919021666
step: 620, loss: 5.120065907249227e-05
step: 630, loss: 0.0002992893278133124
step: 640, loss: 5.440640597953461e-05
step: 650, loss: 1.8544149497756734e-05
step: 660, loss: 0.0011824558023363352
step: 670, loss: 8.29677446745336e-05
step: 680, loss: 0.0002151752560166642
step: 690, loss: 0.0001551498135086149
step: 700, loss: 0.000125560793094337
step: 710, loss: 2.2502936189994216e-05
step: 720, loss: 0.017825327813625336
step: 730, loss: 3.751084295799956e-05
step: 740, loss: 3.6143137549515814e-05
step: 750, loss: 2.9223456294857897e-05
step: 760, loss: 6.23385130893439e-05
step: 770, loss: 0.0018466297769919038
step: 780, loss: 1.768351830833126e-05
step: 790, loss: 0.00012744411651510745
step: 800, loss: 4.050270945299417e-05
step: 810, loss: 2.0369521735119633e-05
step: 820, loss: 0.0037340361159294844
step: 830, loss: 0.10552239418029785
step: 840, loss: 0.0007163586560636759
step: 850, loss: 1.7597771147848107e-05
step: 860, loss: 0.025486033409833908
step: 870, loss: 0.0001354870037175715
step: 880, loss: 2.9681104933843017e-05
step: 890, loss: 0.00010224636935163289
step: 900, loss: 0.0002816686173900962
step: 910, loss: 1.748252361721825e-05
step: 920, loss: 4.013775469502434e-05
step: 930, loss: 0.001612066407687962
step: 940, loss: 0.029902074486017227
step: 950, loss: 0.00010361376189393923
step: 960, loss: 0.0002890241739805788
step: 970, loss: 2.4954606487881392e-05
step: 980, loss: 0.00017554181977175176
step: 990, loss: 2.0671057427534834e-05
step: 1000, loss: 5.780859282822348e-05
step: 1010, loss: 0.00015437003457918763
step: 1020, loss: 2.6171908757532947e-05
step: 1030, loss: 0.0024051766376942396
step: 1040, loss: 0.00010962601663777605
step: 1050, loss: 3.976429798058234e-05
step: 1060, loss: 0.00014083366841077805
epoch 18: dev_f1=0.9471733086190918, f1=0.9233644859813084, best_f1=0.9238005644402634
step: 0, loss: 0.00019796645210590214
step: 10, loss: 0.00010745759936980903
step: 20, loss: 0.00012177947792224586
step: 30, loss: 7.919144263723865e-05
step: 40, loss: 3.5214903618907556e-05
step: 50, loss: 3.836812902591191e-05
step: 60, loss: 0.0003297265793662518
step: 70, loss: 0.00024224181834142655
step: 80, loss: 3.481794919935055e-05
step: 90, loss: 1.748992690409068e-05
step: 100, loss: 0.011699823662638664
step: 110, loss: 0.000314456905471161
step: 120, loss: 0.0004819610621780157
step: 130, loss: 0.009616311639547348
step: 140, loss: 0.001341704512014985
step: 150, loss: 2.581483931862749e-05
step: 160, loss: 0.005719820503145456
step: 170, loss: 3.559570177458227e-05
step: 180, loss: 0.0001076796543202363
step: 190, loss: 0.0003008090425282717
step: 200, loss: 2.875587233575061e-05
step: 210, loss: 7.431276753777638e-05
step: 220, loss: 0.00014208901848178357
step: 230, loss: 0.0032075282651931047
step: 240, loss: 5.8021218137582764e-05
step: 250, loss: 0.0008915280923247337
step: 260, loss: 0.07227146625518799
step: 270, loss: 1.9925852029700764e-05
step: 280, loss: 5.0793674745364115e-05
step: 290, loss: 6.390557973645627e-05
step: 300, loss: 2.054814285656903e-05
step: 310, loss: 7.495354657294229e-05
step: 320, loss: 3.564325379556976e-05
step: 330, loss: 4.9564176151761785e-05
step: 340, loss: 3.2775522413430735e-05
step: 350, loss: 3.8756279536755756e-05
step: 360, loss: 0.0002655004500411451
step: 370, loss: 8.408468420384452e-05
step: 380, loss: 1.6715010133339092e-05
step: 390, loss: 6.809311162214726e-05
step: 400, loss: 2.62278008449357e-05
step: 410, loss: 0.00010033568105427548
step: 420, loss: 2.8504320653155446e-05
step: 430, loss: 0.0010357963619753718
step: 440, loss: 2.7374901037546806e-05
step: 450, loss: 0.030779259279370308
step: 460, loss: 0.00018459599232301116
step: 470, loss: 8.883062400855124e-05
step: 480, loss: 2.5383045795024373e-05
step: 490, loss: 1.696838444331661e-05
step: 500, loss: 0.0003596408059820533
step: 510, loss: 0.0003050571831408888
step: 520, loss: 5.967135803075507e-05
step: 530, loss: 0.00025539571652188897
step: 540, loss: 5.0572638429002836e-05
step: 550, loss: 0.0001168936796602793
step: 560, loss: 0.00010159591329284012
step: 570, loss: 9.398688416695222e-05
step: 580, loss: 2.4399701942456886e-05
step: 590, loss: 0.0002272262645419687
step: 600, loss: 1.1071452718169894e-05
step: 610, loss: 0.00851846020668745
step: 620, loss: 0.003518515033647418
step: 630, loss: 4.653626456274651e-05
step: 640, loss: 5.449875970953144e-05
step: 650, loss: 4.992292451788671e-05
step: 660, loss: 0.0002636449644342065
step: 670, loss: 4.352240284788422e-05
step: 680, loss: 4.677789911511354e-05
step: 690, loss: 0.00013263126311358064
step: 700, loss: 0.00020896982459817082
step: 710, loss: 1.4062774425838143e-05
step: 720, loss: 0.00012694111501332372
step: 730, loss: 3.6441851989366114e-05
step: 740, loss: 0.0005350178107619286
step: 750, loss: 0.0006177292671054602
step: 760, loss: 2.109554407070391e-05
step: 770, loss: 0.0001229503977810964
step: 780, loss: 2.8307214961387217e-05
step: 790, loss: 0.00018071803788188845
step: 800, loss: 0.00010219023533863947
step: 810, loss: 6.268370634643361e-05
step: 820, loss: 2.8513832148746587e-05
step: 830, loss: 0.00012807546590920538
step: 840, loss: 3.150264092255384e-05
step: 850, loss: 3.08250128000509e-05
step: 860, loss: 2.8522115826490335e-05
step: 870, loss: 8.607258496340364e-05
step: 880, loss: 5.147800038685091e-05
step: 890, loss: 0.00017155859677586704
step: 900, loss: 0.005017900839447975
step: 910, loss: 0.00010212563938694075
step: 920, loss: 0.0017028452130034566
step: 930, loss: 1.8234848539577797e-05
step: 940, loss: 6.285824929364026e-05
step: 950, loss: 7.082826050464064e-05
step: 960, loss: 0.00035128978197462857
step: 970, loss: 0.00011901813559234142
step: 980, loss: 3.1207993743009865e-05
step: 990, loss: 2.2972984879743308e-05
step: 1000, loss: 6.6460132075008e-05
step: 1010, loss: 4.542605165624991e-05
step: 1020, loss: 2.6340641852584668e-05
step: 1030, loss: 6.179861520649865e-05
step: 1040, loss: 3.2366890081902966e-05
step: 1050, loss: 0.0029934088233858347
step: 1060, loss: 2.4297687559737824e-05
epoch 19: dev_f1=0.9463459759481962, f1=0.9253592953175707, best_f1=0.9238005644402634
step: 0, loss: 3.6318488128017634e-05
step: 10, loss: 2.5681309125502594e-05
step: 20, loss: 0.00796830840408802
step: 30, loss: 2.779966962407343e-05
step: 40, loss: 0.003224239917472005
step: 50, loss: 8.791527943685651e-05
step: 60, loss: 2.487654819560703e-05
step: 70, loss: 2.7173869966645725e-05
step: 80, loss: 5.7432331232121214e-05
step: 90, loss: 3.348313475726172e-05
step: 100, loss: 2.4427019525319338e-05
step: 110, loss: 9.204621892422438e-05
step: 120, loss: 4.994883056497201e-05
step: 130, loss: 0.0002882730041164905
step: 140, loss: 0.008064734749495983
step: 150, loss: 7.023745274636894e-05
step: 160, loss: 0.0004386244108900428
step: 170, loss: 0.0013368920190259814
step: 180, loss: 1.541486199130304e-05
step: 190, loss: 5.951432103756815e-05
step: 200, loss: 2.1449273845064454e-05
step: 210, loss: 1.1350690328981727e-05
step: 220, loss: 3.2713465770939365e-05
step: 230, loss: 1.9575994883780368e-05
step: 240, loss: 0.00011947725579375401
step: 250, loss: 0.00024065288016572595
step: 260, loss: 3.97677649743855e-05
step: 270, loss: 2.0886893253191374e-05
step: 280, loss: 3.258188735344447e-05
step: 290, loss: 6.188939732965082e-05
step: 300, loss: 9.099276212509722e-05
step: 310, loss: 0.0037579615600407124
step: 320, loss: 0.0001236557145603001
step: 330, loss: 5.52079982298892e-05
step: 340, loss: 0.0004675632808357477
step: 350, loss: 6.131936243036762e-05
step: 360, loss: 2.3643691747565754e-05
step: 370, loss: 0.00012048608186887577
step: 380, loss: 3.355096487211995e-05
step: 390, loss: 2.4622846467536874e-05
step: 400, loss: 8.721695485292003e-05
step: 410, loss: 0.0012244413373991847
step: 420, loss: 4.767710925079882e-05
step: 430, loss: 2.355782999075018e-05
step: 440, loss: 9.107260848395526e-05
step: 450, loss: 2.7309197321301326e-05
step: 460, loss: 6.031984958099201e-05
step: 470, loss: 0.0018817819654941559
step: 480, loss: 9.223512461176142e-05
step: 490, loss: 1.8249702407047153e-05
step: 500, loss: 1.4941891095077153e-05
step: 510, loss: 0.05108783394098282
step: 520, loss: 0.00011553616059245542
step: 530, loss: 1.9344528482179157e-05
step: 540, loss: 0.0001769198279362172
step: 550, loss: 3.678499342640862e-05
step: 560, loss: 3.2619624107610434e-05
step: 570, loss: 0.0010427210945636034
step: 580, loss: 0.0005660105380229652
step: 590, loss: 0.0015361083205789328
step: 600, loss: 2.9837257898179814e-05
step: 610, loss: 2.356734148634132e-05
step: 620, loss: 2.429417145322077e-05
step: 630, loss: 3.321934855193831e-05
step: 640, loss: 6.867158663226292e-05
step: 650, loss: 6.364107684930786e-05
step: 660, loss: 1.1108720173069742e-05
step: 670, loss: 1.5128118320717476e-05
step: 680, loss: 4.590057142195292e-05
step: 690, loss: 2.5628927687648684e-05
step: 700, loss: 3.253118848078884e-05
step: 710, loss: 2.0480707462411374e-05
step: 720, loss: 0.000749359664041549
step: 730, loss: 3.571224442566745e-05
step: 740, loss: 0.0001091346493922174
step: 750, loss: 6.371075141942129e-05
step: 760, loss: 4.124445331399329e-05
step: 770, loss: 0.0011573702795431018
step: 780, loss: 8.483834244543687e-05
step: 790, loss: 4.9314923671772704e-05
step: 800, loss: 0.0019678189419209957
step: 810, loss: 0.0004114129114896059
step: 820, loss: 0.00043515386641956866
step: 830, loss: 9.395527740707621e-05
step: 840, loss: 3.1487008527619764e-05
step: 850, loss: 0.00489853648468852
step: 860, loss: 4.745863043353893e-05
step: 870, loss: 1.9560518921935e-05
step: 880, loss: 0.0013509608106687665
step: 890, loss: 0.00040537872700951993
step: 900, loss: 6.129968096502125e-05
step: 910, loss: 0.04825718328356743
step: 920, loss: 0.0001651031634537503
step: 930, loss: 0.0008229531813412905
step: 940, loss: 0.0007355549605563283
step: 950, loss: 0.0005574194947257638
step: 960, loss: 0.00023044088447932154
step: 970, loss: 0.0005378050846047699
step: 980, loss: 4.7623154387110844e-05
step: 990, loss: 1.3030843547312543e-05
step: 1000, loss: 0.00017537960957270116
step: 1010, loss: 0.0030949278734624386
step: 1020, loss: 4.349377559265122e-05
step: 1030, loss: 2.6533407435636036e-05
step: 1040, loss: 0.0004852481069974601
step: 1050, loss: 5.3946194384479895e-05
step: 1060, loss: 2.0880697775282897e-05
epoch 20: dev_f1=0.9468331021729081, f1=0.9225058004640372, best_f1=0.9238005644402634
