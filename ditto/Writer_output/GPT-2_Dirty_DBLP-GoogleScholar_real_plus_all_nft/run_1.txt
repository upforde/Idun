cuda
Device: cuda
step: 0, loss: 0.81361323595047
step: 10, loss: 0.44203025102615356
step: 20, loss: 0.43912845849990845
step: 30, loss: 0.536403238773346
step: 40, loss: 0.33185911178588867
step: 50, loss: 0.4425966739654541
step: 60, loss: 0.36567211151123047
step: 70, loss: 0.2220298796892166
step: 80, loss: 0.3053080141544342
step: 90, loss: 0.29824090003967285
step: 100, loss: 0.2410999834537506
step: 110, loss: 0.4061606526374817
step: 120, loss: 0.29433658719062805
step: 130, loss: 0.11559612303972244
step: 140, loss: 0.21449577808380127
step: 150, loss: 0.320769727230072
step: 160, loss: 0.23558759689331055
step: 170, loss: 0.2838706076145172
step: 180, loss: 0.15337461233139038
step: 190, loss: 0.08708550781011581
step: 200, loss: 0.21487562358379364
step: 210, loss: 0.3056912124156952
step: 220, loss: 0.21937909722328186
step: 230, loss: 0.19362251460552216
step: 240, loss: 0.3252090811729431
step: 250, loss: 0.15009745955467224
step: 260, loss: 0.22329320013523102
step: 270, loss: 0.10993945598602295
step: 280, loss: 0.2491074949502945
step: 290, loss: 0.18852552771568298
step: 300, loss: 0.4605880379676819
step: 310, loss: 0.13275796175003052
step: 320, loss: 0.19842416048049927
step: 330, loss: 0.2704330086708069
step: 340, loss: 0.39884063601493835
step: 350, loss: 0.10701524466276169
step: 360, loss: 0.11399424076080322
step: 370, loss: 0.2524271309375763
step: 380, loss: 0.0576852411031723
step: 390, loss: 0.39124420285224915
step: 400, loss: 0.16760072112083435
step: 410, loss: 0.13260893523693085
step: 420, loss: 0.15212129056453705
step: 430, loss: 0.16549313068389893
step: 440, loss: 0.2624976933002472
step: 450, loss: 0.19044218957424164
step: 460, loss: 0.3839125335216522
step: 470, loss: 0.47685757279396057
step: 480, loss: 0.39002010226249695
step: 490, loss: 0.22560739517211914
step: 500, loss: 0.22272351384162903
step: 510, loss: 0.22285038232803345
step: 520, loss: 0.15227016806602478
step: 530, loss: 0.15930640697479248
step: 540, loss: 0.13099777698516846
step: 550, loss: 0.15199078619480133
step: 560, loss: 0.06212269142270088
step: 570, loss: 0.27450183033943176
step: 580, loss: 0.12038596719503403
step: 590, loss: 0.12230068445205688
step: 600, loss: 0.2799326777458191
step: 610, loss: 0.19668011367321014
step: 620, loss: 0.12348424643278122
step: 630, loss: 0.3230246305465698
step: 640, loss: 0.17095573246479034
step: 650, loss: 0.24922806024551392
step: 660, loss: 0.09141189604997635
step: 670, loss: 0.1578591763973236
step: 680, loss: 0.3324320912361145
step: 690, loss: 0.16717688739299774
step: 700, loss: 0.1439472883939743
step: 710, loss: 0.20743565261363983
step: 720, loss: 0.17955967783927917
step: 730, loss: 0.33207520842552185
step: 740, loss: 0.28202688694000244
step: 750, loss: 0.4826448857784271
step: 760, loss: 0.15986932814121246
step: 770, loss: 0.3051345646381378
step: 780, loss: 0.1524636298418045
step: 790, loss: 0.13962578773498535
step: 800, loss: 0.08979231119155884
step: 810, loss: 0.33780616521835327
step: 820, loss: 0.21190297603607178
step: 830, loss: 0.105507992208004
step: 840, loss: 0.4199267625808716
step: 850, loss: 0.2342587262392044
step: 860, loss: 0.3684163987636566
step: 870, loss: 0.16682571172714233
step: 880, loss: 0.09003840386867523
step: 890, loss: 0.23347355425357819
step: 900, loss: 0.13424894213676453
step: 910, loss: 0.15712527930736542
step: 920, loss: 0.060287512838840485
step: 930, loss: 0.22576184570789337
step: 940, loss: 0.18142320215702057
step: 950, loss: 0.2509533166885376
step: 960, loss: 0.28309276700019836
step: 970, loss: 0.23779477179050446
step: 980, loss: 0.21417565643787384
step: 990, loss: 0.3174021542072296
step: 1000, loss: 0.12821468710899353
step: 1010, loss: 0.19598017632961273
step: 1020, loss: 0.1953192949295044
step: 1030, loss: 0.2906305491924286
epoch 1: dev_f1=0.9392523364485983, f1=0.922279792746114, best_f1=0.922279792746114
step: 0, loss: 0.18416492640972137
step: 10, loss: 0.13089928030967712
step: 20, loss: 0.21763253211975098
step: 30, loss: 0.1510019451379776
step: 40, loss: 0.11116362363100052
step: 50, loss: 0.35253283381462097
step: 60, loss: 0.08885609358549118
step: 70, loss: 0.2132357358932495
step: 80, loss: 0.09440401196479797
step: 90, loss: 0.11367164552211761
step: 100, loss: 0.0564386360347271
step: 110, loss: 0.029108934104442596
step: 120, loss: 0.13401272892951965
step: 130, loss: 0.26444047689437866
step: 140, loss: 0.21252574026584625
step: 150, loss: 0.09634906053543091
step: 160, loss: 0.06700234115123749
step: 170, loss: 0.07277709245681763
step: 180, loss: 0.14005838334560394
step: 190, loss: 0.3329989016056061
step: 200, loss: 0.264411985874176
step: 210, loss: 0.11139500141143799
step: 220, loss: 0.256110280752182
step: 230, loss: 0.14593607187271118
step: 240, loss: 0.07195379585027695
step: 250, loss: 0.1084049716591835
step: 260, loss: 0.1181640550494194
step: 270, loss: 0.07585479319095612
step: 280, loss: 0.15340787172317505
step: 290, loss: 0.11429627984762192
step: 300, loss: 0.08460305631160736
step: 310, loss: 0.1207696795463562
step: 320, loss: 0.09911034256219864
step: 330, loss: 0.06227100268006325
step: 340, loss: 0.2232980579137802
step: 350, loss: 0.2690652310848236
step: 360, loss: 0.1807369589805603
step: 370, loss: 0.14917562901973724
step: 380, loss: 0.1908140927553177
step: 390, loss: 0.08586151897907257
step: 400, loss: 0.07599107176065445
step: 410, loss: 0.12610763311386108
step: 420, loss: 0.11191240698099136
step: 430, loss: 0.11798176169395447
step: 440, loss: 0.0973215103149414
step: 450, loss: 0.08822570741176605
step: 460, loss: 0.11159674823284149
step: 470, loss: 0.20639391243457794
step: 480, loss: 0.16460806131362915
step: 490, loss: 0.15093649923801422
step: 500, loss: 0.21191319823265076
step: 510, loss: 0.2206254005432129
step: 520, loss: 0.15205910801887512
step: 530, loss: 0.2620665431022644
step: 540, loss: 0.2093198597431183
step: 550, loss: 0.097425676882267
step: 560, loss: 0.10305340588092804
step: 570, loss: 0.09759411215782166
step: 580, loss: 0.2401457279920578
step: 590, loss: 0.045318663120269775
step: 600, loss: 0.33911699056625366
step: 610, loss: 0.0654575526714325
step: 620, loss: 0.11135256290435791
step: 630, loss: 0.28915441036224365
step: 640, loss: 0.1762799769639969
step: 650, loss: 0.4065607488155365
step: 660, loss: 0.2471521943807602
step: 670, loss: 0.12769408524036407
step: 680, loss: 0.06806852668523788
step: 690, loss: 0.08296327292919159
step: 700, loss: 0.17265520989894867
step: 710, loss: 0.09164661169052124
step: 720, loss: 0.11091208457946777
step: 730, loss: 0.2919009327888489
step: 740, loss: 0.15034770965576172
step: 750, loss: 0.045431870967149734
step: 760, loss: 0.12720559537410736
step: 770, loss: 0.12764732539653778
step: 780, loss: 0.06975120306015015
step: 790, loss: 0.15914204716682434
step: 800, loss: 0.14734748005867004
step: 810, loss: 0.13854548335075378
step: 820, loss: 0.11255810409784317
step: 830, loss: 0.2723800539970398
step: 840, loss: 0.13871514797210693
step: 850, loss: 0.07023866474628448
step: 860, loss: 0.07625497132539749
step: 870, loss: 0.1445229947566986
step: 880, loss: 0.18224488198757172
step: 890, loss: 0.12425543367862701
step: 900, loss: 0.19205722212791443
step: 910, loss: 0.06790401041507721
step: 920, loss: 0.3699548542499542
step: 930, loss: 0.24803364276885986
step: 940, loss: 0.21644845604896545
step: 950, loss: 0.2045753449201584
step: 960, loss: 0.02886594459414482
step: 970, loss: 0.1561957597732544
step: 980, loss: 0.11152581870555878
step: 990, loss: 0.1855088472366333
step: 1000, loss: 0.1526985913515091
step: 1010, loss: 0.0811963677406311
step: 1020, loss: 0.4274994134902954
step: 1030, loss: 0.0838761255145073
epoch 2: dev_f1=0.9451162790697675, f1=0.9284369114877589, best_f1=0.9284369114877589
step: 0, loss: 0.24772712588310242
step: 10, loss: 0.07225801050662994
step: 20, loss: 0.1589086353778839
step: 30, loss: 0.03977268189191818
step: 40, loss: 0.12462838739156723
step: 50, loss: 0.21201828122138977
step: 60, loss: 0.020563405007123947
step: 70, loss: 0.19651497900485992
step: 80, loss: 0.16561686992645264
step: 90, loss: 0.06282921880483627
step: 100, loss: 0.08770103752613068
step: 110, loss: 0.04872597008943558
step: 120, loss: 0.028465792536735535
step: 130, loss: 0.03539971262216568
step: 140, loss: 0.056092020124197006
step: 150, loss: 0.1622430384159088
step: 160, loss: 0.3032849431037903
step: 170, loss: 0.28210967779159546
step: 180, loss: 0.26222315430641174
step: 190, loss: 0.15037651360034943
step: 200, loss: 0.11464228481054306
step: 210, loss: 0.20198063552379608
step: 220, loss: 0.04691367223858833
step: 230, loss: 0.11481886357069016
step: 240, loss: 0.02701880969107151
step: 250, loss: 0.06354627758264542
step: 260, loss: 0.033508818596601486
step: 270, loss: 0.05525874346494675
step: 280, loss: 0.03461432084441185
step: 290, loss: 0.05704256147146225
step: 300, loss: 0.07282516360282898
step: 310, loss: 0.05713113397359848
step: 320, loss: 0.20527860522270203
step: 330, loss: 0.10927784442901611
step: 340, loss: 0.09467417001724243
step: 350, loss: 0.06810443103313446
step: 360, loss: 0.1777975708246231
step: 370, loss: 0.1303560435771942
step: 380, loss: 0.1438472419977188
step: 390, loss: 0.10716326534748077
step: 400, loss: 0.08947159349918365
step: 410, loss: 0.2281724065542221
step: 420, loss: 0.2065010666847229
step: 430, loss: 0.045812420547008514
step: 440, loss: 0.011266294866800308
step: 450, loss: 0.01980813778936863
step: 460, loss: 0.08437442034482956
step: 470, loss: 0.05576233193278313
step: 480, loss: 0.30652984976768494
step: 490, loss: 0.1783677637577057
step: 500, loss: 0.1257016360759735
step: 510, loss: 0.4372629225254059
step: 520, loss: 0.04955008625984192
step: 530, loss: 0.18538811802864075
step: 540, loss: 0.20837192237377167
step: 550, loss: 0.07431315630674362
step: 560, loss: 0.08930950611829758
step: 570, loss: 0.04155946522951126
step: 580, loss: 0.01359900739043951
step: 590, loss: 0.1190851479768753
step: 600, loss: 0.03174551948904991
step: 610, loss: 0.20156259834766388
step: 620, loss: 0.05099569633603096
step: 630, loss: 0.18807296454906464
step: 640, loss: 0.07133940607309341
step: 650, loss: 0.102104552090168
step: 660, loss: 0.050197213888168335
step: 670, loss: 0.16669805347919464
step: 680, loss: 0.24990996718406677
step: 690, loss: 0.06003129854798317
step: 700, loss: 0.1486278474330902
step: 710, loss: 0.33175718784332275
step: 720, loss: 0.3143736720085144
step: 730, loss: 0.2279292643070221
step: 740, loss: 0.09591852873563766
step: 750, loss: 0.08436519652605057
step: 760, loss: 0.27775171399116516
step: 770, loss: 0.11920522898435593
step: 780, loss: 0.013598575256764889
step: 790, loss: 0.025701992213726044
step: 800, loss: 0.04023558273911476
step: 810, loss: 0.16361956298351288
step: 820, loss: 0.029670873656868935
step: 830, loss: 0.05825233459472656
step: 840, loss: 0.033491577953100204
step: 850, loss: 0.024866171181201935
step: 860, loss: 0.11814787983894348
step: 870, loss: 0.09712198376655579
step: 880, loss: 0.10150673240423203
step: 890, loss: 0.09529957920312881
step: 900, loss: 0.14677630364894867
step: 910, loss: 0.07389092445373535
step: 920, loss: 0.20954567193984985
step: 930, loss: 0.09421869367361069
step: 940, loss: 0.16618302464485168
step: 950, loss: 0.12943972647190094
step: 960, loss: 0.21536298096179962
step: 970, loss: 0.018751423805952072
step: 980, loss: 0.09240163117647171
step: 990, loss: 0.1968008577823639
step: 1000, loss: 0.1748470813035965
step: 1010, loss: 0.057497985661029816
step: 1020, loss: 0.08734609186649323
step: 1030, loss: 0.05559704452753067
epoch 3: dev_f1=0.951048951048951, f1=0.9238050165641268, best_f1=0.9238050165641268
step: 0, loss: 0.06649021059274673
step: 10, loss: 0.007995952852070332
step: 20, loss: 0.11450118571519852
step: 30, loss: 0.07561648637056351
step: 40, loss: 0.0904812216758728
step: 50, loss: 0.1370268315076828
step: 60, loss: 0.024871477857232094
step: 70, loss: 0.1280738264322281
step: 80, loss: 0.012149995192885399
step: 90, loss: 0.07617893815040588
step: 100, loss: 0.10311920195817947
step: 110, loss: 0.04018663987517357
step: 120, loss: 0.18730370700359344
step: 130, loss: 0.04007536545395851
step: 140, loss: 0.02728446200489998
step: 150, loss: 0.023223670199513435
step: 160, loss: 0.08310680836439133
step: 170, loss: 0.0698975920677185
step: 180, loss: 0.03915657848119736
step: 190, loss: 0.027668163180351257
step: 200, loss: 0.14175547659397125
step: 210, loss: 0.04376230761408806
step: 220, loss: 0.10366667062044144
step: 230, loss: 0.0423927828669548
step: 240, loss: 0.05503275245428085
step: 250, loss: 0.026558438315987587
step: 260, loss: 0.13202258944511414
step: 270, loss: 0.044726282358169556
step: 280, loss: 0.0355292409658432
step: 290, loss: 0.11092259734869003
step: 300, loss: 0.03339438512921333
step: 310, loss: 0.032596804201602936
step: 320, loss: 0.1269473135471344
step: 330, loss: 0.04525323957204819
step: 340, loss: 0.1252429187297821
step: 350, loss: 0.06730950623750687
step: 360, loss: 0.044729217886924744
step: 370, loss: 0.19359035789966583
step: 380, loss: 0.01582477055490017
step: 390, loss: 0.05251898989081383
step: 400, loss: 0.1711982786655426
step: 410, loss: 0.01950891502201557
step: 420, loss: 0.03633541241288185
step: 430, loss: 0.11636154353618622
step: 440, loss: 0.06114935874938965
step: 450, loss: 0.0037674447521567345
step: 460, loss: 0.23905305564403534
step: 470, loss: 0.14120766520500183
step: 480, loss: 0.06907209753990173
step: 490, loss: 0.10023438930511475
step: 500, loss: 0.21453236043453217
step: 510, loss: 0.17725293338298798
step: 520, loss: 0.19408950209617615
step: 530, loss: 0.3730115592479706
step: 540, loss: 0.06058594584465027
step: 550, loss: 0.061304084956645966
step: 560, loss: 0.04712221398949623
step: 570, loss: 0.19673055410385132
step: 580, loss: 0.05721088498830795
step: 590, loss: 0.0400288887321949
step: 600, loss: 0.20193037390708923
step: 610, loss: 0.025923052802681923
step: 620, loss: 0.1809929758310318
step: 630, loss: 0.1582777053117752
step: 640, loss: 0.05217435583472252
step: 650, loss: 0.09984906017780304
step: 660, loss: 0.02275335043668747
step: 670, loss: 0.050334587693214417
step: 680, loss: 0.1146940067410469
step: 690, loss: 0.2107527107000351
step: 700, loss: 0.13215380907058716
step: 710, loss: 0.07970510423183441
step: 720, loss: 0.029226284474134445
step: 730, loss: 0.058572687208652496
step: 740, loss: 0.02053062804043293
step: 750, loss: 0.1840609461069107
step: 760, loss: 0.12307797372341156
step: 770, loss: 0.056025125086307526
step: 780, loss: 0.2950684428215027
step: 790, loss: 0.2195785492658615
step: 800, loss: 0.0875777080655098
step: 810, loss: 0.02722412347793579
step: 820, loss: 0.10093313455581665
step: 830, loss: 0.056999266147613525
step: 840, loss: 0.0332605354487896
step: 850, loss: 0.011374851688742638
step: 860, loss: 0.2917637228965759
step: 870, loss: 0.05987277254462242
step: 880, loss: 0.07463584095239639
step: 890, loss: 0.06860922276973724
step: 900, loss: 0.0791369080543518
step: 910, loss: 0.04714798927307129
step: 920, loss: 0.06749200820922852
step: 930, loss: 0.27037933468818665
step: 940, loss: 0.023104147985577583
step: 950, loss: 0.162821963429451
step: 960, loss: 0.00700091989710927
step: 970, loss: 0.12669867277145386
step: 980, loss: 0.049225226044654846
step: 990, loss: 0.0430130697786808
step: 1000, loss: 0.10601790249347687
step: 1010, loss: 0.05216844007372856
step: 1020, loss: 0.1268150359392166
step: 1030, loss: 0.04793129488825798
epoch 4: dev_f1=0.9464944649446495, f1=0.9271461716937355, best_f1=0.9238050165641268
step: 0, loss: 0.264602392911911
step: 10, loss: 0.16237981617450714
step: 20, loss: 0.03930704668164253
step: 30, loss: 0.004331294447183609
step: 40, loss: 0.13582907617092133
step: 50, loss: 0.023354576900601387
step: 60, loss: 0.029435185715556145
step: 70, loss: 0.1259104609489441
step: 80, loss: 0.029194626957178116
step: 90, loss: 0.028221547603607178
step: 100, loss: 0.08903489261865616
step: 110, loss: 0.08986785262823105
step: 120, loss: 0.03825724497437477
step: 130, loss: 0.1477646380662918
step: 140, loss: 0.056149017065763474
step: 150, loss: 0.004612430930137634
step: 160, loss: 0.06779327988624573
step: 170, loss: 0.032479703426361084
step: 180, loss: 0.003251939546316862
step: 190, loss: 0.029638340696692467
step: 200, loss: 0.03319207951426506
step: 210, loss: 0.09791186451911926
step: 220, loss: 0.029620405286550522
step: 230, loss: 0.019092857837677002
step: 240, loss: 0.004688833840191364
step: 250, loss: 0.03678807243704796
step: 260, loss: 0.005877465475350618
step: 270, loss: 0.026949042454361916
step: 280, loss: 0.026026573032140732
step: 290, loss: 0.005968887358903885
step: 300, loss: 0.10087189823389053
step: 310, loss: 0.02802458591759205
step: 320, loss: 0.03333062678575516
step: 330, loss: 0.12191540002822876
step: 340, loss: 0.04233572259545326
step: 350, loss: 0.015642832964658737
step: 360, loss: 0.04347921907901764
step: 370, loss: 0.02475760690867901
step: 380, loss: 0.09228329360485077
step: 390, loss: 0.06289999932050705
step: 400, loss: 0.2453433871269226
step: 410, loss: 0.011708092875778675
step: 420, loss: 0.003182121552526951
step: 430, loss: 0.049002956598997116
step: 440, loss: 0.017216656357049942
step: 450, loss: 0.06221562996506691
step: 460, loss: 0.010460767894983292
step: 470, loss: 0.04271172732114792
step: 480, loss: 0.06585905700922012
step: 490, loss: 0.03413193300366402
step: 500, loss: 0.0813196673989296
step: 510, loss: 0.03698444366455078
step: 520, loss: 0.14224013686180115
step: 530, loss: 0.06629690527915955
step: 540, loss: 0.011683187447488308
step: 550, loss: 0.12015726417303085
step: 560, loss: 0.022234231233596802
step: 570, loss: 0.264076828956604
step: 580, loss: 0.08057966828346252
step: 590, loss: 0.06652960926294327
step: 600, loss: 0.007705444935709238
step: 610, loss: 0.04144283011555672
step: 620, loss: 0.03127478435635567
step: 630, loss: 0.10233592987060547
step: 640, loss: 0.15795499086380005
step: 650, loss: 0.029225723817944527
step: 660, loss: 0.024821702390909195
step: 670, loss: 0.18107818067073822
step: 680, loss: 0.0507051981985569
step: 690, loss: 0.040661122649908066
step: 700, loss: 0.015580743551254272
step: 710, loss: 0.11856747418642044
step: 720, loss: 0.060498300939798355
step: 730, loss: 0.036120135337114334
step: 740, loss: 0.00849954504519701
step: 750, loss: 0.1443086862564087
step: 760, loss: 0.12310395389795303
step: 770, loss: 0.06851685792207718
step: 780, loss: 0.12637415528297424
step: 790, loss: 0.07233121991157532
step: 800, loss: 0.04938080534338951
step: 810, loss: 0.019640248268842697
step: 820, loss: 0.00440728385001421
step: 830, loss: 0.1067144125699997
step: 840, loss: 0.06843189895153046
step: 850, loss: 0.008716982789337635
step: 860, loss: 0.021762683987617493
step: 870, loss: 0.02064128778874874
step: 880, loss: 0.1782980114221573
step: 890, loss: 0.03830539807677269
step: 900, loss: 0.0183122456073761
step: 910, loss: 0.059957217425107956
step: 920, loss: 0.05914035439491272
step: 930, loss: 0.1885489970445633
step: 940, loss: 0.3424413502216339
step: 950, loss: 0.0647083967924118
step: 960, loss: 0.02806931547820568
step: 970, loss: 0.11267735064029694
step: 980, loss: 0.07926240563392639
step: 990, loss: 0.015349509194493294
step: 1000, loss: 0.004308344796299934
step: 1010, loss: 0.08597595989704132
step: 1020, loss: 0.05590758100152016
step: 1030, loss: 0.01405816525220871
epoch 5: dev_f1=0.9446768944676894, f1=0.914339801230478, best_f1=0.9238050165641268
step: 0, loss: 0.03238983452320099
step: 10, loss: 0.09876056760549545
step: 20, loss: 0.0044281925074756145
step: 30, loss: 0.05159168317914009
step: 40, loss: 0.07651326805353165
step: 50, loss: 0.11921724677085876
step: 60, loss: 0.0026902081444859505
step: 70, loss: 0.03168228641152382
step: 80, loss: 0.033237725496292114
step: 90, loss: 0.010783607140183449
step: 100, loss: 0.021983647719025612
step: 110, loss: 0.0038107777945697308
step: 120, loss: 0.005452815443277359
step: 130, loss: 0.033791884779930115
step: 140, loss: 0.029424788430333138
step: 150, loss: 0.00752947898581624
step: 160, loss: 0.06655303388834
step: 170, loss: 0.09837948530912399
step: 180, loss: 0.03619201108813286
step: 190, loss: 0.011954889632761478
step: 200, loss: 0.0707443431019783
step: 210, loss: 0.007720008492469788
step: 220, loss: 0.007430180907249451
step: 230, loss: 0.012087979353964329
step: 240, loss: 0.0034799817949533463
step: 250, loss: 0.029982764273881912
step: 260, loss: 0.01138265524059534
step: 270, loss: 0.014114217832684517
step: 280, loss: 0.03488166630268097
step: 290, loss: 0.008819044567644596
step: 300, loss: 0.13570848107337952
step: 310, loss: 0.009615371935069561
step: 320, loss: 0.09425091743469238
step: 330, loss: 0.013082318007946014
step: 340, loss: 0.001635087071917951
step: 350, loss: 0.02742931619286537
step: 360, loss: 0.05005266144871712
step: 370, loss: 0.0020599868148565292
step: 380, loss: 0.035717252641916275
step: 390, loss: 0.005588177125900984
step: 400, loss: 0.1225261464715004
step: 410, loss: 0.0046052937395870686
step: 420, loss: 0.0024571239482611418
step: 430, loss: 0.014764096587896347
step: 440, loss: 0.07208344340324402
step: 450, loss: 0.004784278105944395
step: 460, loss: 0.007829404436051846
step: 470, loss: 0.004881641361862421
step: 480, loss: 0.032692451030015945
step: 490, loss: 0.01569688692688942
step: 500, loss: 0.06812813878059387
step: 510, loss: 0.03353317081928253
step: 520, loss: 0.001424091518856585
step: 530, loss: 0.006698887795209885
step: 540, loss: 0.001782987150363624
step: 550, loss: 0.03174995630979538
step: 560, loss: 0.0121253477409482
step: 570, loss: 0.005699878558516502
step: 580, loss: 0.09808526933193207
step: 590, loss: 0.0018899457063525915
step: 600, loss: 0.11572650074958801
step: 610, loss: 0.18539634346961975
step: 620, loss: 0.031037641689181328
step: 630, loss: 0.05436166003346443
step: 640, loss: 0.04788784310221672
step: 650, loss: 0.05408430099487305
step: 660, loss: 0.07701040059328079
step: 670, loss: 0.020051995292305946
step: 680, loss: 0.08889273554086685
step: 690, loss: 0.17753785848617554
step: 700, loss: 0.27737247943878174
step: 710, loss: 0.005400363821536303
step: 720, loss: 0.1174497902393341
step: 730, loss: 0.0034297024831175804
step: 740, loss: 0.002173160668462515
step: 750, loss: 0.03193319961428642
step: 760, loss: 0.06443461030721664
step: 770, loss: 0.0479583665728569
step: 780, loss: 0.014293489046394825
step: 790, loss: 0.019199730828404427
step: 800, loss: 0.29325470328330994
step: 810, loss: 0.039345595985651016
step: 820, loss: 0.03569162264466286
step: 830, loss: 0.018107028678059578
step: 840, loss: 0.015156509354710579
step: 850, loss: 0.04265420138835907
step: 860, loss: 0.007662524934858084
step: 870, loss: 0.011961801908910275
step: 880, loss: 0.013495112769305706
step: 890, loss: 0.006829904858022928
step: 900, loss: 0.02497948706150055
step: 910, loss: 0.03639140725135803
step: 920, loss: 0.010467400774359703
step: 930, loss: 0.0478525348007679
step: 940, loss: 0.01688924804329872
step: 950, loss: 0.07958939671516418
step: 960, loss: 0.08012060821056366
step: 970, loss: 0.15634186565876007
step: 980, loss: 0.07702697068452835
step: 990, loss: 0.0550333708524704
step: 1000, loss: 0.012698408216238022
step: 1010, loss: 0.017564252018928528
step: 1020, loss: 0.0021351692266762257
step: 1030, loss: 0.15046358108520508
epoch 6: dev_f1=0.9442622950819672, f1=0.9219924812030075, best_f1=0.9238050165641268
step: 0, loss: 0.028118835762143135
step: 10, loss: 0.04179691895842552
step: 20, loss: 0.004000782500952482
step: 30, loss: 0.0019520851783454418
step: 40, loss: 0.0134690897539258
step: 50, loss: 0.0027114790864288807
step: 60, loss: 0.0019644233398139477
step: 70, loss: 0.0007935772300697863
step: 80, loss: 0.003560199635103345
step: 90, loss: 0.005351757165044546
step: 100, loss: 0.015160424634814262
step: 110, loss: 0.12546303868293762
step: 120, loss: 0.005405161529779434
step: 130, loss: 0.004805582109838724
step: 140, loss: 0.012019629590213299
step: 150, loss: 0.011187582276761532
step: 160, loss: 0.005003736354410648
step: 170, loss: 0.026298798620700836
step: 180, loss: 0.007086585275828838
step: 190, loss: 0.003115501720458269
step: 200, loss: 0.008990691043436527
step: 210, loss: 0.019117919728159904
step: 220, loss: 0.0006313828635029495
step: 230, loss: 0.03802714869379997
step: 240, loss: 0.0015129739185795188
step: 250, loss: 0.013822834938764572
step: 260, loss: 0.05794396251440048
step: 270, loss: 0.023463565856218338
step: 280, loss: 0.038489930331707
step: 290, loss: 0.03179049864411354
step: 300, loss: 0.008770521730184555
step: 310, loss: 0.019101427868008614
step: 320, loss: 0.06748173385858536
step: 330, loss: 0.016193144023418427
step: 340, loss: 0.0043136426247656345
step: 350, loss: 0.09059067815542221
step: 360, loss: 0.0229912381619215
step: 370, loss: 0.0017052264884114265
step: 380, loss: 0.09586912393569946
step: 390, loss: 0.01415559183806181
step: 400, loss: 0.03239359334111214
step: 410, loss: 0.011935613118112087
step: 420, loss: 0.0024505138862878084
step: 430, loss: 0.0016944227972999215
step: 440, loss: 0.005115545354783535
step: 450, loss: 0.010076256468892097
step: 460, loss: 0.008306583389639854
step: 470, loss: 0.0028748426120728254
step: 480, loss: 0.0005159541615284979
step: 490, loss: 0.0003320740652270615
step: 500, loss: 0.18991553783416748
step: 510, loss: 0.09583523124456406
step: 520, loss: 0.014172283001244068
step: 530, loss: 0.05328185111284256
step: 540, loss: 0.004823623690754175
step: 550, loss: 0.08535351604223251
step: 560, loss: 0.01046935934573412
step: 570, loss: 0.01908694952726364
step: 580, loss: 0.07832570374011993
step: 590, loss: 0.0015772891929373145
step: 600, loss: 0.002635071985423565
step: 610, loss: 0.011408545076847076
step: 620, loss: 0.013463223353028297
step: 630, loss: 0.003904295153915882
step: 640, loss: 0.05505666136741638
step: 650, loss: 0.1037716343998909
step: 660, loss: 0.010410132817924023
step: 670, loss: 0.007033921778202057
step: 680, loss: 0.0013738090638071299
step: 690, loss: 0.07852029800415039
step: 700, loss: 0.04453469067811966
step: 710, loss: 0.0035436893813312054
step: 720, loss: 0.012328139506280422
step: 730, loss: 0.017141198739409447
step: 740, loss: 0.019977198913693428
step: 750, loss: 0.010262970812618732
step: 760, loss: 0.009507790207862854
step: 770, loss: 0.03545659780502319
step: 780, loss: 0.017012029886245728
step: 790, loss: 0.24580800533294678
step: 800, loss: 0.013397797010838985
step: 810, loss: 0.005071007646620274
step: 820, loss: 0.011423151940107346
step: 830, loss: 0.07470276951789856
step: 840, loss: 0.014459967613220215
step: 850, loss: 0.01939333789050579
step: 860, loss: 0.029232339933514595
step: 870, loss: 0.0012758002849295735
step: 880, loss: 0.18256835639476776
step: 890, loss: 0.024214621633291245
step: 900, loss: 0.024712225422263145
step: 910, loss: 0.01578914374113083
step: 920, loss: 0.04960478097200394
step: 930, loss: 0.0008198674768209457
step: 940, loss: 0.007834567688405514
step: 950, loss: 0.005244872532784939
step: 960, loss: 0.05512335151433945
step: 970, loss: 0.0005919033428654075
step: 980, loss: 0.11800763010978699
step: 990, loss: 0.06547508388757706
step: 1000, loss: 0.16641464829444885
step: 1010, loss: 0.007560968864709139
step: 1020, loss: 0.1047864705324173
step: 1030, loss: 0.007232356816530228
epoch 7: dev_f1=0.939186099679927, f1=0.9310027598896043, best_f1=0.9238050165641268
step: 0, loss: 0.0025927885435521603
step: 10, loss: 0.00029437130433507264
step: 20, loss: 0.014180591329932213
step: 30, loss: 0.01066686026751995
step: 40, loss: 0.028567137196660042
step: 50, loss: 0.027757897973060608
step: 60, loss: 0.007031465880572796
step: 70, loss: 0.0812680572271347
step: 80, loss: 0.002813405357301235
step: 90, loss: 0.041855525225400925
step: 100, loss: 0.01689193770289421
step: 110, loss: 0.0007239619735628366
step: 120, loss: 0.0026111560873687267
step: 130, loss: 0.004286920186132193
step: 140, loss: 0.0011849157745018601
step: 150, loss: 0.00017545802984386683
step: 160, loss: 0.012993806041777134
step: 170, loss: 0.011078549548983574
step: 180, loss: 0.003603145945817232
step: 190, loss: 0.0032226762268692255
step: 200, loss: 0.01562916859984398
step: 210, loss: 0.004066674970090389
step: 220, loss: 0.0016336303669959307
step: 230, loss: 0.0006859843269921839
step: 240, loss: 0.013656415045261383
step: 250, loss: 0.001084366929717362
step: 260, loss: 0.00682744849473238
step: 270, loss: 0.005656199995428324
step: 280, loss: 0.06846994161605835
step: 290, loss: 0.015103365294635296
step: 300, loss: 0.0032494256738573313
step: 310, loss: 0.005336353555321693
step: 320, loss: 0.00023322709603235126
step: 330, loss: 0.04683695361018181
step: 340, loss: 0.06857677549123764
step: 350, loss: 0.010827912017703056
step: 360, loss: 0.0023187631741166115
step: 370, loss: 0.002924466971307993
step: 380, loss: 0.02801823988556862
step: 390, loss: 0.005340900272130966
step: 400, loss: 0.0022163395769894123
step: 410, loss: 0.00042256651795469224
step: 420, loss: 0.015687400475144386
step: 430, loss: 0.003546283580362797
step: 440, loss: 0.028830576688051224
step: 450, loss: 0.0006892393575981259
step: 460, loss: 0.0006620698841288686
step: 470, loss: 0.06414158642292023
step: 480, loss: 0.18901653587818146
step: 490, loss: 0.006140000186860561
step: 500, loss: 0.006572425831109285
step: 510, loss: 0.028963273391127586
step: 520, loss: 0.0033213947899639606
step: 530, loss: 0.0005005174898542464
step: 540, loss: 0.0016563317039981484
step: 550, loss: 0.00444312859326601
step: 560, loss: 0.07234538346529007
step: 570, loss: 0.0012926071649417281
step: 580, loss: 0.06972838938236237
step: 590, loss: 0.02896994911134243
step: 600, loss: 0.0014253940898925066
step: 610, loss: 0.0005100889829918742
step: 620, loss: 0.001613058615475893
step: 630, loss: 0.025684189051389694
step: 640, loss: 0.00109761580824852
step: 650, loss: 0.00042271692655049264
step: 660, loss: 0.00041680759750306606
step: 670, loss: 0.0047507681883871555
step: 680, loss: 0.0011798916384577751
step: 690, loss: 0.0032321163453161716
step: 700, loss: 0.0922391414642334
step: 710, loss: 0.015000148676335812
step: 720, loss: 0.176855206489563
step: 730, loss: 0.014524271711707115
step: 740, loss: 0.002171663334593177
step: 750, loss: 0.02045278064906597
step: 760, loss: 0.08258818835020065
step: 770, loss: 0.03686288371682167
step: 780, loss: 0.011075159534811974
step: 790, loss: 0.021527796983718872
step: 800, loss: 0.13813069462776184
step: 810, loss: 0.007638406939804554
step: 820, loss: 0.0014989855699241161
step: 830, loss: 0.005728716962039471
step: 840, loss: 0.08950351178646088
step: 850, loss: 0.0039060974959284067
step: 860, loss: 0.005811737850308418
step: 870, loss: 0.007011625915765762
step: 880, loss: 0.0038021625950932503
step: 890, loss: 0.018938444554805756
step: 900, loss: 0.05822136625647545
step: 910, loss: 0.023158984258770943
step: 920, loss: 0.00913176592439413
step: 930, loss: 0.005255299154669046
step: 940, loss: 0.002447162987664342
step: 950, loss: 0.0006917212158441544
step: 960, loss: 0.0019039091421291232
step: 970, loss: 0.011705134995281696
step: 980, loss: 0.009123314172029495
step: 990, loss: 0.0007823812193237245
step: 1000, loss: 0.04237795248627663
step: 1010, loss: 0.09480012953281403
step: 1020, loss: 0.0021938306745141745
step: 1030, loss: 0.15197636187076569
epoch 8: dev_f1=0.9460853258321612, f1=0.923222748815166, best_f1=0.9238050165641268
step: 0, loss: 0.002926244167611003
step: 10, loss: 0.024452446028590202
step: 20, loss: 0.0093360785394907
step: 30, loss: 0.0020414998289197683
step: 40, loss: 0.01927364245057106
step: 50, loss: 0.0021948961075395346
step: 60, loss: 0.01227643433958292
step: 70, loss: 0.00444846460595727
step: 80, loss: 0.0009336102521046996
step: 90, loss: 0.011186922900378704
step: 100, loss: 0.001059256144799292
step: 110, loss: 0.0022883880883455276
step: 120, loss: 0.0003611842985264957
step: 130, loss: 0.0015412357170134783
step: 140, loss: 0.0018211720744147897
step: 150, loss: 0.001743218395859003
step: 160, loss: 0.0004206805897410959
step: 170, loss: 0.0003381496062502265
step: 180, loss: 0.00027885223971679807
step: 190, loss: 0.0015641874633729458
step: 200, loss: 0.002954641357064247
step: 210, loss: 0.0010966050904244184
step: 220, loss: 0.0010233477223664522
step: 230, loss: 0.0018744136905297637
step: 240, loss: 0.025469856336712837
step: 250, loss: 0.0030999903101474047
step: 260, loss: 0.021318739280104637
step: 270, loss: 0.11949440836906433
step: 280, loss: 0.011851831339299679
step: 290, loss: 0.0038895905017852783
step: 300, loss: 0.03266890347003937
step: 310, loss: 0.108364038169384
step: 320, loss: 0.013380289077758789
step: 330, loss: 0.0006367666064761579
step: 340, loss: 0.000874374236445874
step: 350, loss: 0.0014085039729252458
step: 360, loss: 0.028784368187189102
step: 370, loss: 0.0003081574977841228
step: 380, loss: 0.00023825958487577736
step: 390, loss: 0.0003832154907286167
step: 400, loss: 0.0005472323391586542
step: 410, loss: 0.014528840780258179
step: 420, loss: 0.00015284196706488729
step: 430, loss: 0.0842282623052597
step: 440, loss: 0.0004251213395036757
step: 450, loss: 0.011739720590412617
step: 460, loss: 0.005915799643844366
step: 470, loss: 0.2533167898654938
step: 480, loss: 0.001324156066402793
step: 490, loss: 0.02043421007692814
step: 500, loss: 0.019767146557569504
step: 510, loss: 0.019668594002723694
step: 520, loss: 0.004169647581875324
step: 530, loss: 0.035397373139858246
step: 540, loss: 0.0015996928559616208
step: 550, loss: 0.08674181997776031
step: 560, loss: 0.0003133431018795818
step: 570, loss: 0.07042182981967926
step: 580, loss: 0.0006691747112199664
step: 590, loss: 0.0013176625361666083
step: 600, loss: 0.0024486789479851723
step: 610, loss: 0.03818294405937195
step: 620, loss: 0.0010084277018904686
step: 630, loss: 0.026851637288928032
step: 640, loss: 0.03344481438398361
step: 650, loss: 0.013942059129476547
step: 660, loss: 0.010659029707312584
step: 670, loss: 0.02674262598156929
step: 680, loss: 0.014623702503740788
step: 690, loss: 0.00037759056431241333
step: 700, loss: 0.015298155136406422
step: 710, loss: 0.009497088380157948
step: 720, loss: 0.012453368864953518
step: 730, loss: 0.001961630769073963
step: 740, loss: 0.0007702679722569883
step: 750, loss: 0.007548724301159382
step: 760, loss: 0.00018299785733688623
step: 770, loss: 0.002502798568457365
step: 780, loss: 0.0022666864097118378
step: 790, loss: 0.14876551926136017
step: 800, loss: 0.0003987841191701591
step: 810, loss: 0.016994277015328407
step: 820, loss: 0.004848867654800415
step: 830, loss: 0.0014169653877615929
step: 840, loss: 0.007564431056380272
step: 850, loss: 0.0764479786157608
step: 860, loss: 0.013386989012360573
step: 870, loss: 0.000839371932670474
step: 880, loss: 0.0016429453389719129
step: 890, loss: 0.027117503806948662
step: 900, loss: 0.0020236102864146233
step: 910, loss: 0.035421282052993774
step: 920, loss: 0.009398329071700573
step: 930, loss: 0.011134209111332893
step: 940, loss: 0.001114479498937726
step: 950, loss: 0.025406692177057266
step: 960, loss: 0.0002347153495065868
step: 970, loss: 0.00017878366634249687
step: 980, loss: 0.0006665989640168846
step: 990, loss: 0.005584862548857927
step: 1000, loss: 0.0013782349415123463
step: 1010, loss: 0.011476305313408375
step: 1020, loss: 0.00038933189352974296
step: 1030, loss: 0.021955175325274467
epoch 9: dev_f1=0.940354147250699, f1=0.92524682651622, best_f1=0.9238050165641268
step: 0, loss: 0.004752248991280794
step: 10, loss: 0.0012723018880933523
step: 20, loss: 0.0014733744319528341
step: 30, loss: 0.0008409587317146361
step: 40, loss: 0.0013164901174604893
step: 50, loss: 0.14132553339004517
step: 60, loss: 0.004576483741402626
step: 70, loss: 0.004582854453474283
step: 80, loss: 0.004967462737113237
step: 90, loss: 0.00012035136023769155
step: 100, loss: 0.0036684535443782806
step: 110, loss: 0.08331240713596344
step: 120, loss: 0.00023177996627055109
step: 130, loss: 0.0002522360591683537
step: 140, loss: 0.0015422168653458357
step: 150, loss: 0.02729763649404049
step: 160, loss: 0.3130412697792053
step: 170, loss: 0.012604191899299622
step: 180, loss: 0.007670808583498001
step: 190, loss: 0.001980892615392804
step: 200, loss: 0.0053875502198934555
step: 210, loss: 0.002541129244491458
step: 220, loss: 0.00046323673450388014
step: 230, loss: 0.023953134194016457
step: 240, loss: 0.002883371664211154
step: 250, loss: 0.0013594917254522443
step: 260, loss: 0.0012219138443470001
step: 270, loss: 0.0012126555666327477
step: 280, loss: 0.015247808769345284
step: 290, loss: 0.01023036427795887
step: 300, loss: 0.07296847552061081
step: 310, loss: 0.008941472508013248
step: 320, loss: 0.0004883056972175837
step: 330, loss: 0.1168583333492279
step: 340, loss: 0.0029002423398196697
step: 350, loss: 0.0021900576539337635
step: 360, loss: 0.0006099903839640319
step: 370, loss: 0.0028173127211630344
step: 380, loss: 0.0007844606298021972
step: 390, loss: 0.0042017376981675625
step: 400, loss: 0.014919797889888287
step: 410, loss: 0.1728893518447876
step: 420, loss: 0.054064422845840454
step: 430, loss: 0.003842287929728627
step: 440, loss: 0.00029496155912056565
step: 450, loss: 0.0008428484434261918
step: 460, loss: 0.0007842463674023747
step: 470, loss: 6.845243478892371e-05
step: 480, loss: 0.005493744742125273
step: 490, loss: 0.020442049950361252
step: 500, loss: 0.004004441201686859
step: 510, loss: 0.0068091051653027534
step: 520, loss: 0.01076248474419117
step: 530, loss: 0.002409584354609251
step: 540, loss: 0.0068180919624865055
step: 550, loss: 0.005351915489882231
step: 560, loss: 0.006906457711011171
step: 570, loss: 0.0018927528290078044
step: 580, loss: 0.0005369313294067979
step: 590, loss: 0.04807477816939354
step: 600, loss: 0.0012009713100269437
step: 610, loss: 0.061787791550159454
step: 620, loss: 0.012909478507936
step: 630, loss: 0.0038046285044401884
step: 640, loss: 0.010421959683299065
step: 650, loss: 0.002507029566913843
step: 660, loss: 0.0021425262093544006
step: 670, loss: 0.000922231178265065
step: 680, loss: 0.008378987200558186
step: 690, loss: 0.03993541747331619
step: 700, loss: 0.016495967283844948
step: 710, loss: 0.19669519364833832
step: 720, loss: 0.0047168792225420475
step: 730, loss: 0.014224459417164326
step: 740, loss: 0.0006784523138776422
step: 750, loss: 0.00840673502534628
step: 760, loss: 0.019175440073013306
step: 770, loss: 0.0002067303576041013
step: 780, loss: 0.0890885442495346
step: 790, loss: 0.04527543485164642
step: 800, loss: 0.07455858588218689
step: 810, loss: 0.11310487985610962
step: 820, loss: 0.0674818754196167
step: 830, loss: 0.0007719824207015336
step: 840, loss: 0.0005359135684557259
step: 850, loss: 0.019891416653990746
step: 860, loss: 0.0016887503443285823
step: 870, loss: 0.0008120450656861067
step: 880, loss: 0.059473197907209396
step: 890, loss: 0.001057304092682898
step: 900, loss: 0.0036549153737723827
step: 910, loss: 0.002278334693983197
step: 920, loss: 0.0035499457735568285
step: 930, loss: 0.00284502562135458
step: 940, loss: 0.03286689147353172
step: 950, loss: 0.0013601842802017927
step: 960, loss: 0.004505540244281292
step: 970, loss: 0.01155074592679739
step: 980, loss: 0.002876369282603264
step: 990, loss: 0.0028341684956103563
step: 1000, loss: 0.0020509555470198393
step: 1010, loss: 0.005286073312163353
step: 1020, loss: 0.004166426602751017
step: 1030, loss: 0.011087742634117603
epoch 10: dev_f1=0.9446009389671362, f1=0.913022585295531, best_f1=0.9238050165641268
step: 0, loss: 0.0008551358478143811
step: 10, loss: 0.0011694688582792878
step: 20, loss: 0.08042110502719879
step: 30, loss: 0.0006703637191094458
step: 40, loss: 0.0010154854971915483
step: 50, loss: 0.04252200946211815
step: 60, loss: 0.006291396915912628
step: 70, loss: 0.0002056276280200109
step: 80, loss: 0.0004430409171618521
step: 90, loss: 0.002251674886792898
step: 100, loss: 0.008643648587167263
step: 110, loss: 0.0007000835030339658
step: 120, loss: 0.0019883913919329643
step: 130, loss: 0.0003725963761098683
step: 140, loss: 0.0004976214258931577
step: 150, loss: 0.0006077472353354096
step: 160, loss: 0.00027479996788315475
step: 170, loss: 0.011744534596800804
step: 180, loss: 0.0004784881602972746
step: 190, loss: 0.007734525483101606
step: 200, loss: 0.001488415990024805
step: 210, loss: 0.0033257075119763613
step: 220, loss: 0.000477246823720634
step: 230, loss: 0.005344482138752937
step: 240, loss: 0.06702619791030884
step: 250, loss: 0.07001972943544388
step: 260, loss: 0.0003916914574801922
step: 270, loss: 0.0012795280199497938
step: 280, loss: 0.0003402124566491693
step: 290, loss: 0.15820643305778503
step: 300, loss: 0.0021548434160649776
step: 310, loss: 0.10565049946308136
step: 320, loss: 0.016320079565048218
step: 330, loss: 0.0007844932260923088
step: 340, loss: 0.000341147358994931
step: 350, loss: 0.003755305428057909
step: 360, loss: 0.01883954554796219
step: 370, loss: 0.0018588716629892588
step: 380, loss: 0.0023018813226372004
step: 390, loss: 0.005014033522456884
step: 400, loss: 0.0005444858688861132
step: 410, loss: 0.00011304008512524888
step: 420, loss: 0.002199570182710886
step: 430, loss: 0.0003173604200128466
step: 440, loss: 0.0005526058375835419
step: 450, loss: 7.561641541542485e-05
step: 460, loss: 0.0003153582802042365
step: 470, loss: 0.0004274364619050175
step: 480, loss: 0.00022478257596958429
step: 490, loss: 0.003983132541179657
step: 500, loss: 0.08473453670740128
step: 510, loss: 0.00047922151861712337
step: 520, loss: 0.004295902326703072
step: 530, loss: 2.870609205274377e-05
step: 540, loss: 0.002536638407036662
step: 550, loss: 0.018377896398305893
step: 560, loss: 0.06325000524520874
step: 570, loss: 0.07058615237474442
step: 580, loss: 0.000993305235169828
step: 590, loss: 0.03617694601416588
step: 600, loss: 0.0021243104711174965
step: 610, loss: 0.001261762692593038
step: 620, loss: 0.001129354815930128
step: 630, loss: 0.032392024993896484
step: 640, loss: 0.0009368495084345341
step: 650, loss: 0.00025723944418132305
step: 660, loss: 0.0010650964686647058
step: 670, loss: 0.0005576765397563577
step: 680, loss: 0.013576997444033623
step: 690, loss: 0.0008258678135462105
step: 700, loss: 0.0006627006805501878
step: 710, loss: 0.0001571660250192508
step: 720, loss: 0.0003527403168845922
step: 730, loss: 0.0003620638162828982
step: 740, loss: 7.522413216065615e-05
step: 750, loss: 0.09604953229427338
step: 760, loss: 0.00011784817615989596
step: 770, loss: 0.0021230492275208235
step: 780, loss: 0.001422225497663021
step: 790, loss: 0.00013711710926145315
step: 800, loss: 0.00023655433324165642
step: 810, loss: 0.0001872486318461597
step: 820, loss: 0.24349302053451538
step: 830, loss: 0.007789928931742907
step: 840, loss: 0.003056618617847562
step: 850, loss: 0.008752849884331226
step: 860, loss: 0.050493404269218445
step: 870, loss: 0.0014643761096522212
step: 880, loss: 0.005325125064700842
step: 890, loss: 0.07402297854423523
step: 900, loss: 0.03816332295536995
step: 910, loss: 0.0001277931296499446
step: 920, loss: 0.0022241894621402025
step: 930, loss: 0.0013144960394129157
step: 940, loss: 0.0001334682892775163
step: 950, loss: 0.0051482911221683025
step: 960, loss: 0.02594469115138054
step: 970, loss: 0.004123277496546507
step: 980, loss: 0.0012300030793994665
step: 990, loss: 0.0006241734954528511
step: 1000, loss: 0.016339072957634926
step: 1010, loss: 0.00012550065002869815
step: 1020, loss: 0.2529774308204651
step: 1030, loss: 0.00013028644025325775
epoch 11: dev_f1=0.942951438000943, f1=0.9135683244809271, best_f1=0.9238050165641268
step: 0, loss: 0.00041533110197633505
step: 10, loss: 0.00010838382877409458
step: 20, loss: 0.0010370024247094989
step: 30, loss: 0.007478455081582069
step: 40, loss: 0.004287714138627052
step: 50, loss: 0.0015185221564024687
step: 60, loss: 0.012195535004138947
step: 70, loss: 0.00022624754637945443
step: 80, loss: 0.006017702165991068
step: 90, loss: 0.00367660797201097
step: 100, loss: 0.001157695660367608
step: 110, loss: 0.00010711630602600053
step: 120, loss: 0.00011005790292983875
step: 130, loss: 0.0001299756986554712
step: 140, loss: 0.00015964536578394473
step: 150, loss: 0.010018031112849712
step: 160, loss: 0.0003767744346987456
step: 170, loss: 0.0036861698608845472
step: 180, loss: 0.04362109303474426
step: 190, loss: 0.00027810496976599097
step: 200, loss: 0.005911017768085003
step: 210, loss: 0.001407967647537589
step: 220, loss: 0.00029941037064418197
step: 230, loss: 0.00012546888319775462
step: 240, loss: 0.002011618111282587
step: 250, loss: 0.0029241652227938175
step: 260, loss: 6.40362486592494e-05
step: 270, loss: 0.0005338744376786053
step: 280, loss: 0.0025310255587100983
step: 290, loss: 0.0012774902861565351
step: 300, loss: 0.00010757230484159663
step: 310, loss: 0.009883908554911613
step: 320, loss: 0.0006384081207215786
step: 330, loss: 0.002689847955480218
step: 340, loss: 0.0030225985683500767
step: 350, loss: 0.0004157639923505485
step: 360, loss: 0.02463303506374359
step: 370, loss: 0.000242048452491872
step: 380, loss: 0.017330467700958252
step: 390, loss: 0.022364897653460503
step: 400, loss: 0.00035674014361575246
step: 410, loss: 0.0026726641226559877
step: 420, loss: 3.5003864468308166e-05
step: 430, loss: 0.009297322481870651
step: 440, loss: 0.0003313704510219395
step: 450, loss: 0.0062134419567883015
step: 460, loss: 8.110188355203718e-05
step: 470, loss: 0.001303289900533855
step: 480, loss: 0.0007888942491263151
step: 490, loss: 0.0060388389974832535
step: 500, loss: 0.0011674162233248353
step: 510, loss: 0.03566543385386467
step: 520, loss: 0.0007833749987185001
step: 530, loss: 0.08650310337543488
step: 540, loss: 0.0007633241475559771
step: 550, loss: 0.00047521915985271335
step: 560, loss: 0.0003753951459657401
step: 570, loss: 0.00013384564954321831
step: 580, loss: 0.004822439979761839
step: 590, loss: 0.00035621380084194243
step: 600, loss: 0.003010108368471265
step: 610, loss: 0.0010274050291627645
step: 620, loss: 0.016548512503504753
step: 630, loss: 0.0006921748863533139
step: 640, loss: 0.00017028473666869104
step: 650, loss: 7.859990728320554e-05
step: 660, loss: 0.003330075182020664
step: 670, loss: 4.4834530854132026e-05
step: 680, loss: 0.0008468808955512941
step: 690, loss: 0.0005807458655908704
step: 700, loss: 0.04474466294050217
step: 710, loss: 0.035264838486909866
step: 720, loss: 0.0006205561221577227
step: 730, loss: 0.05006928741931915
step: 740, loss: 0.00867775920778513
step: 750, loss: 0.052038341760635376
step: 760, loss: 0.01902155764400959
step: 770, loss: 0.003837251802906394
step: 780, loss: 0.025179406628012657
step: 790, loss: 0.0006760805263184011
step: 800, loss: 0.0004912494914606214
step: 810, loss: 0.00017558468971401453
step: 820, loss: 2.9342960260692053e-05
step: 830, loss: 4.433541471371427e-05
step: 840, loss: 9.624806261854246e-05
step: 850, loss: 0.00031751947244629264
step: 860, loss: 0.00014936050865799189
step: 870, loss: 0.0001479593338444829
step: 880, loss: 0.0031742961145937443
step: 890, loss: 0.0004997325595468283
step: 900, loss: 0.048405442386865616
step: 910, loss: 8.18161788629368e-05
step: 920, loss: 0.001647515338845551
step: 930, loss: 0.0009300637757405639
step: 940, loss: 0.0002902463893406093
step: 950, loss: 0.0003855656541418284
step: 960, loss: 0.00016574763867538422
step: 970, loss: 0.003803376806899905
step: 980, loss: 0.0034419121220707893
step: 990, loss: 0.0015787158627063036
step: 1000, loss: 0.00016555460751987994
step: 1010, loss: 0.0002978346892632544
step: 1020, loss: 4.881844142801128e-05
step: 1030, loss: 0.021728049963712692
epoch 12: dev_f1=0.9415645617342129, f1=0.9220468675274988, best_f1=0.9238050165641268
step: 0, loss: 0.002590623451396823
step: 10, loss: 0.0019756213296204805
step: 20, loss: 0.002380752470344305
step: 30, loss: 0.00025670535978861153
step: 40, loss: 8.770338172325864e-05
step: 50, loss: 0.0006936590070836246
step: 60, loss: 0.027295518666505814
step: 70, loss: 0.003415304934605956
step: 80, loss: 0.08357682824134827
step: 90, loss: 0.00043606877443380654
step: 100, loss: 0.0002992057998199016
step: 110, loss: 0.0825553610920906
step: 120, loss: 0.020123817026615143
step: 130, loss: 0.0016627248842269182
step: 140, loss: 0.00023329435498453677
step: 150, loss: 0.00032053314498625696
step: 160, loss: 0.0005401703529059887
step: 170, loss: 0.00023091731418389827
step: 180, loss: 0.0007448364049196243
step: 190, loss: 0.00040802833973430097
step: 200, loss: 0.0001164709756267257
step: 210, loss: 0.0010133297182619572
step: 220, loss: 0.00011185956100234762
step: 230, loss: 0.003414371982216835
step: 240, loss: 0.00010534589819144458
step: 250, loss: 0.0002687647647690028
step: 260, loss: 0.005066619720309973
step: 270, loss: 0.00247598416171968
step: 280, loss: 0.00028487900272011757
step: 290, loss: 0.0006017198320478201
step: 300, loss: 0.0007451798883266747
step: 310, loss: 0.01745501719415188
step: 320, loss: 7.863994687795639e-05
step: 330, loss: 0.02073209546506405
step: 340, loss: 0.0004921198706142604
step: 350, loss: 0.0008290065452456474
step: 360, loss: 0.01807047799229622
step: 370, loss: 0.0003901254676748067
step: 380, loss: 0.00035436247708275914
step: 390, loss: 0.00588960712775588
step: 400, loss: 0.00030642561614513397
step: 410, loss: 0.0003979118773713708
step: 420, loss: 0.0012190135894343257
step: 430, loss: 0.0010276935063302517
step: 440, loss: 0.00033491096110083163
step: 450, loss: 0.0008855009218677878
step: 460, loss: 5.885911014047451e-05
step: 470, loss: 0.0030423724092543125
step: 480, loss: 0.0005882740952074528
step: 490, loss: 3.913469845429063e-05
step: 500, loss: 0.0010829971870407462
step: 510, loss: 0.05982792750000954
step: 520, loss: 0.00018394074868410826
step: 530, loss: 0.0006318685482256114
step: 540, loss: 0.0036823623813688755
step: 550, loss: 5.2425260946620256e-05
step: 560, loss: 0.0003780315164476633
step: 570, loss: 0.0005738656036555767
step: 580, loss: 0.0007263419684022665
step: 590, loss: 0.0001441075437469408
step: 600, loss: 8.857783541316167e-05
step: 610, loss: 0.00042085093446075916
step: 620, loss: 0.029054678976535797
step: 630, loss: 0.01622292771935463
step: 640, loss: 0.00013815228885505348
step: 650, loss: 0.00011674546112772077
step: 660, loss: 0.0008980404236353934
step: 670, loss: 0.00017817741900216788
step: 680, loss: 7.866504893172532e-05
step: 690, loss: 7.352202374022454e-05
step: 700, loss: 0.001567444996908307
step: 710, loss: 0.009222717955708504
step: 720, loss: 4.0531795093556866e-05
step: 730, loss: 0.001807794556953013
step: 740, loss: 0.00022600429656449705
step: 750, loss: 3.200160062988289e-05
step: 760, loss: 5.588668864220381e-05
step: 770, loss: 0.0054778787307441235
step: 780, loss: 0.012667560018599033
step: 790, loss: 0.0018707072595134377
step: 800, loss: 0.0005148766213096678
step: 810, loss: 0.0003102218033745885
step: 820, loss: 0.0005813181051053107
step: 830, loss: 0.015544626861810684
step: 840, loss: 9.447753836866468e-05
step: 850, loss: 0.020596977323293686
step: 860, loss: 0.0022105854004621506
step: 870, loss: 0.00021030590869486332
step: 880, loss: 0.0001803927298169583
step: 890, loss: 0.00032519252272322774
step: 900, loss: 0.005669458769261837
step: 910, loss: 0.0006199457566253841
step: 920, loss: 0.05960654094815254
step: 930, loss: 7.437192107317969e-05
step: 940, loss: 0.006943365093320608
step: 950, loss: 0.0005466795992106199
step: 960, loss: 1.9866120055667125e-05
step: 970, loss: 0.003031282452866435
step: 980, loss: 0.022335970774292946
step: 990, loss: 1.8909142454504035e-05
step: 1000, loss: 0.0055297729559242725
step: 1010, loss: 0.01101809460669756
step: 1020, loss: 0.0005556005053222179
step: 1030, loss: 0.000487966783111915
epoch 13: dev_f1=0.9409005628517824, f1=0.920514040932889, best_f1=0.9238050165641268
step: 0, loss: 0.0005194944678805768
step: 10, loss: 0.002627041656523943
step: 20, loss: 0.0001280243304790929
step: 30, loss: 0.11984176188707352
step: 40, loss: 4.151769826421514e-05
step: 50, loss: 0.0129774808883667
step: 60, loss: 0.003979629836976528
step: 70, loss: 0.004833383485674858
step: 80, loss: 0.00028279313119128346
step: 90, loss: 0.000538912252523005
step: 100, loss: 0.001126064802519977
step: 110, loss: 0.0005813862662762403
step: 120, loss: 3.458135688561015e-05
step: 130, loss: 0.004852246027439833
step: 140, loss: 0.052548184990882874
step: 150, loss: 0.11018414795398712
step: 160, loss: 0.15108810365200043
step: 170, loss: 0.0039430465549230576
step: 180, loss: 0.002419851953163743
step: 190, loss: 0.000272210716502741
step: 200, loss: 0.0010886482195928693
step: 210, loss: 0.0033688703551888466
step: 220, loss: 0.000591352756600827
step: 230, loss: 0.00017420091899111867
step: 240, loss: 0.011844711378216743
step: 250, loss: 5.381182927521877e-05
step: 260, loss: 4.43472781626042e-05
step: 270, loss: 0.0007188093150034547
step: 280, loss: 0.00041317561408504844
step: 290, loss: 0.012576701119542122
step: 300, loss: 8.650156087242067e-05
step: 310, loss: 6.780624244129285e-05
step: 320, loss: 5.8447400078875944e-05
step: 330, loss: 4.468088081921451e-05
step: 340, loss: 0.0019073481671512127
step: 350, loss: 8.588242781115696e-05
step: 360, loss: 0.00011445920972619206
step: 370, loss: 0.0009027936030179262
step: 380, loss: 0.00019537856860551983
step: 390, loss: 0.0009228137205354869
step: 400, loss: 0.0006646048277616501
step: 410, loss: 0.0002264169161207974
step: 420, loss: 0.00010667151218513027
step: 430, loss: 0.008930793963372707
step: 440, loss: 0.00041451395372860134
step: 450, loss: 0.00016083644004538655
step: 460, loss: 0.00020835619943682104
step: 470, loss: 0.00018975062994286418
step: 480, loss: 4.664363223128021e-05
step: 490, loss: 0.00024317683710251004
step: 500, loss: 0.0011193056125193834
step: 510, loss: 0.009336529299616814
step: 520, loss: 8.353289740625769e-05
step: 530, loss: 0.003889121115207672
step: 540, loss: 0.00013654038775712252
step: 550, loss: 0.0044162156991660595
step: 560, loss: 0.00020313856657594442
step: 570, loss: 0.0020107743330299854
step: 580, loss: 5.312547364155762e-05
step: 590, loss: 0.001407463802024722
step: 600, loss: 0.05312385782599449
step: 610, loss: 0.001168669550679624
step: 620, loss: 0.00048071605851873755
step: 630, loss: 0.0006980286561883986
step: 640, loss: 2.079019759548828e-05
step: 650, loss: 0.0002160923759220168
step: 660, loss: 0.001262990408577025
step: 670, loss: 0.011484364978969097
step: 680, loss: 6.999239121796563e-05
step: 690, loss: 0.0001521037775091827
step: 700, loss: 0.00032772275153547525
step: 710, loss: 0.00030592066468670964
step: 720, loss: 0.0014759046025574207
step: 730, loss: 2.5516814275761135e-05
step: 740, loss: 0.0005209294031374156
step: 750, loss: 0.026899250224232674
step: 760, loss: 0.00015950026863720268
step: 770, loss: 0.00036819392698816955
step: 780, loss: 0.00014993372315075248
step: 790, loss: 0.00029171130154281855
step: 800, loss: 0.0018783608684316278
step: 810, loss: 0.0001279033167520538
step: 820, loss: 0.00011482471018098295
step: 830, loss: 0.0008383958484046161
step: 840, loss: 0.0003259407531004399
step: 850, loss: 0.00011555443052202463
step: 860, loss: 0.015027900226414204
step: 870, loss: 0.05676397308707237
step: 880, loss: 0.011770723387598991
step: 890, loss: 0.0005593183450400829
step: 900, loss: 0.010560606606304646
step: 910, loss: 3.959231617045589e-05
step: 920, loss: 0.0198716651648283
step: 930, loss: 5.533512376132421e-05
step: 940, loss: 0.0012345543364062905
step: 950, loss: 0.04058113694190979
step: 960, loss: 6.0440601373557e-05
step: 970, loss: 0.00016729022900108248
step: 980, loss: 0.0010033873841166496
step: 990, loss: 7.071520667523146e-05
step: 1000, loss: 0.003996085841208696
step: 1010, loss: 3.478132566669956e-05
step: 1020, loss: 0.00013878829486202449
step: 1030, loss: 0.0006172847934067249
epoch 14: dev_f1=0.9427230046948356, f1=0.9183770883054891, best_f1=0.9238050165641268
step: 0, loss: 2.976037467306014e-05
step: 10, loss: 0.039336930960416794
step: 20, loss: 0.00747613376006484
step: 30, loss: 0.000555407430510968
step: 40, loss: 8.697400335222483e-05
step: 50, loss: 0.00022569618886336684
step: 60, loss: 0.03975796699523926
step: 70, loss: 0.0005297671305015683
step: 80, loss: 0.00029601092683151364
step: 90, loss: 0.009977053850889206
step: 100, loss: 0.00017788073455449194
step: 110, loss: 0.0037069020327180624
step: 120, loss: 0.0008229055674746633
step: 130, loss: 0.0009481272427365184
step: 140, loss: 0.011803248897194862
step: 150, loss: 4.894677476841025e-05
step: 160, loss: 0.0003482743923086673
step: 170, loss: 0.00012013717787340283
step: 180, loss: 0.00042898161336779594
step: 190, loss: 0.0022493195720016956
step: 200, loss: 0.00017480830138083547
step: 210, loss: 9.368984319735318e-05
step: 220, loss: 5.1528102630982175e-05
step: 230, loss: 4.700320278061554e-05
step: 240, loss: 0.00045283298823051155
step: 250, loss: 0.006391114555299282
step: 260, loss: 0.008591326884925365
step: 270, loss: 1.5776280633872375e-05
step: 280, loss: 0.002441120333969593
step: 290, loss: 0.014122622087597847
step: 300, loss: 0.000509705685544759
step: 310, loss: 0.0001259497948922217
step: 320, loss: 0.0009437261614948511
step: 330, loss: 0.00010566949640633538
step: 340, loss: 0.015922171995043755
step: 350, loss: 0.01638747937977314
step: 360, loss: 0.0006443500751629472
step: 370, loss: 5.0206603191327304e-05
step: 380, loss: 0.0012922693276777864
step: 390, loss: 0.03381430357694626
step: 400, loss: 0.0003224636893719435
step: 410, loss: 0.0007051079301163554
step: 420, loss: 0.040819719433784485
step: 430, loss: 0.04942208155989647
step: 440, loss: 0.0002790261059999466
step: 450, loss: 0.00010304446914233267
step: 460, loss: 0.00022420041204895824
step: 470, loss: 5.300464545143768e-05
step: 480, loss: 0.0004954388714395463
step: 490, loss: 0.00042519360431469977
step: 500, loss: 0.002880384912714362
step: 510, loss: 0.06405584514141083
step: 520, loss: 0.04659159108996391
step: 530, loss: 5.756832251790911e-05
step: 540, loss: 4.6024175389902666e-05
step: 550, loss: 1.821596742956899e-05
step: 560, loss: 0.0003807096218224615
step: 570, loss: 0.0002574675891082734
step: 580, loss: 4.419992183102295e-05
step: 590, loss: 0.005903206765651703
step: 600, loss: 0.037708889693021774
step: 610, loss: 2.2440268367063254e-05
step: 620, loss: 0.0038356275763362646
step: 630, loss: 2.1965728592476808e-05
step: 640, loss: 1.4859875591355376e-05
step: 650, loss: 3.123863280052319e-05
step: 660, loss: 6.67348358547315e-05
step: 670, loss: 0.0004177156661171466
step: 680, loss: 0.0007518631173297763
step: 690, loss: 0.0014615148538723588
step: 700, loss: 0.000513171951752156
step: 710, loss: 0.009915025904774666
step: 720, loss: 0.05811214819550514
step: 730, loss: 0.05242380127310753
step: 740, loss: 0.0012333523482084274
step: 750, loss: 0.005690241698175669
step: 760, loss: 0.00022407918004319072
step: 770, loss: 0.00010015326552093029
step: 780, loss: 0.00020065040735062212
step: 790, loss: 5.899979441892356e-05
step: 800, loss: 0.00040753878420218825
step: 810, loss: 4.377174991532229e-05
step: 820, loss: 2.4623463104944676e-05
step: 830, loss: 0.000938264885917306
step: 840, loss: 7.585934508824721e-05
step: 850, loss: 0.00010220905824098736
step: 860, loss: 0.0011116762179881334
step: 870, loss: 0.002088849199935794
step: 880, loss: 0.00024396121443714947
step: 890, loss: 0.025577275082468987
step: 900, loss: 0.019852446392178535
step: 910, loss: 0.0003066384815610945
step: 920, loss: 4.592866753228009e-05
step: 930, loss: 0.0003785013104788959
step: 940, loss: 0.0023879350628703833
step: 950, loss: 0.00011533848010003567
step: 960, loss: 0.03904776647686958
step: 970, loss: 0.00700624193996191
step: 980, loss: 0.0005302056670188904
step: 990, loss: 0.005480307154357433
step: 1000, loss: 5.6263299484271556e-05
step: 1010, loss: 0.0009933523833751678
step: 1020, loss: 0.004142981953918934
step: 1030, loss: 0.0018982989713549614
epoch 15: dev_f1=0.9373528026377769, f1=0.9206500956022945, best_f1=0.9238050165641268
step: 0, loss: 0.00197790889069438
step: 10, loss: 0.00036764339893125
step: 20, loss: 8.056000660872087e-05
step: 30, loss: 0.0012980030151084065
step: 40, loss: 0.0015413740184158087
step: 50, loss: 0.0009666871628724039
step: 60, loss: 5.43619244126603e-05
step: 70, loss: 0.00010848390957107767
step: 80, loss: 5.4690979595761746e-05
step: 90, loss: 0.0008653298136778176
step: 100, loss: 0.0016184208216145635
step: 110, loss: 0.0001770152011886239
step: 120, loss: 0.00017254785052500665
step: 130, loss: 0.00022546447871718556
step: 140, loss: 0.07315858453512192
step: 150, loss: 0.0004636272497009486
step: 160, loss: 0.0013824962079524994
step: 170, loss: 0.00038467568811029196
step: 180, loss: 0.00018256032490171492
step: 190, loss: 5.2548526582540944e-05
step: 200, loss: 0.023894362151622772
step: 210, loss: 0.0016373140970245004
step: 220, loss: 4.4296382839092985e-05
step: 230, loss: 0.005803908687084913
step: 240, loss: 8.778326446190476e-05
step: 250, loss: 0.01695989817380905
step: 260, loss: 3.0001234335941263e-05
step: 270, loss: 7.212125638034195e-05
step: 280, loss: 6.35476826573722e-05
step: 290, loss: 0.0002372048911638558
step: 300, loss: 2.4414610379608348e-05
step: 310, loss: 0.0006255180342122912
step: 320, loss: 0.0007812804542481899
step: 330, loss: 5.977364708087407e-05
step: 340, loss: 0.00021675437164958566
step: 350, loss: 0.0015184044605121017
step: 360, loss: 0.001736283302307129
step: 370, loss: 6.759083044016734e-05
step: 380, loss: 5.487428279593587e-05
step: 390, loss: 0.01279718242585659
step: 400, loss: 0.0025482478085905313
step: 410, loss: 7.027835818007588e-05
step: 420, loss: 0.0014647484058514237
step: 430, loss: 4.49935942015145e-05
step: 440, loss: 4.439000622369349e-05
step: 450, loss: 0.0003632682200986892
step: 460, loss: 0.00042600827873684466
step: 470, loss: 0.0004530921869445592
step: 480, loss: 0.0004507916164584458
step: 490, loss: 5.716334635508247e-05
step: 500, loss: 0.0012414564844220877
step: 510, loss: 5.336725007509813e-05
step: 520, loss: 0.0006423159502446651
step: 530, loss: 0.00018844858277589083
step: 540, loss: 0.0025048302486538887
step: 550, loss: 0.00025009395903907716
step: 560, loss: 6.082207619328983e-05
step: 570, loss: 0.0041014812886714935
step: 580, loss: 0.00016560161020606756
step: 590, loss: 0.003475152188912034
step: 600, loss: 4.260503192199394e-05
step: 610, loss: 1.7139427654910833e-05
step: 620, loss: 0.00020922208204865456
step: 630, loss: 0.003827939974144101
step: 640, loss: 0.000726431084331125
step: 650, loss: 0.00011194259423064068
step: 660, loss: 0.02012692764401436
step: 670, loss: 0.00015142274787649512
step: 680, loss: 0.001636906061321497
step: 690, loss: 0.0014546049060299993
step: 700, loss: 0.00022915535373613238
step: 710, loss: 0.0005152817466296256
step: 720, loss: 0.00832836702466011
step: 730, loss: 9.763037814991549e-05
step: 740, loss: 0.0015539214946329594
step: 750, loss: 0.0007394253043457866
step: 760, loss: 3.342070340295322e-05
step: 770, loss: 0.00015545045607723296
step: 780, loss: 0.0006440046126954257
step: 790, loss: 4.096937846043147e-05
step: 800, loss: 3.086960350628942e-05
step: 810, loss: 0.0003243153914809227
step: 820, loss: 0.006731340661644936
step: 830, loss: 0.00032575216027908027
step: 840, loss: 0.0102468803524971
step: 850, loss: 0.0444779247045517
step: 860, loss: 0.0031897188164293766
step: 870, loss: 7.695292151765898e-05
step: 880, loss: 1.6480204067192972e-05
step: 890, loss: 2.3636433979845606e-05
step: 900, loss: 3.321536860312335e-05
step: 910, loss: 1.7884254702948965e-05
step: 920, loss: 0.00017820745415519923
step: 930, loss: 0.00010331635712645948
step: 940, loss: 2.3863069145590998e-05
step: 950, loss: 0.006247587967664003
step: 960, loss: 0.0014744827058166265
step: 970, loss: 0.012429461814463139
step: 980, loss: 4.854601138504222e-05
step: 990, loss: 2.2580197764909826e-05
step: 1000, loss: 7.655431545572355e-06
step: 1010, loss: 0.000296427053399384
step: 1020, loss: 0.00023169719497673213
step: 1030, loss: 1.1190639270353131e-05
epoch 16: dev_f1=0.9408476944573824, f1=0.9285714285714286, best_f1=0.9238050165641268
step: 0, loss: 0.00012435379903763533
step: 10, loss: 0.000106743500509765
step: 20, loss: 0.004530796781182289
step: 30, loss: 2.2700893168803304e-05
step: 40, loss: 3.470308001851663e-05
step: 50, loss: 0.00018584664212539792
step: 60, loss: 4.9681562813930213e-05
step: 70, loss: 7.177334191510454e-05
step: 80, loss: 1.5761215763632208e-05
step: 90, loss: 6.422709702746943e-05
step: 100, loss: 0.017338957637548447
step: 110, loss: 0.019184207543730736
step: 120, loss: 2.6644931494956836e-05
step: 130, loss: 2.0324179786257446e-05
step: 140, loss: 2.599347681098152e-05
step: 150, loss: 0.0001182818814413622
step: 160, loss: 3.1951956771081313e-05
step: 170, loss: 7.541500235674903e-05
step: 180, loss: 0.04492805898189545
step: 190, loss: 0.009355088695883751
step: 200, loss: 7.362607721006498e-05
step: 210, loss: 0.02604914829134941
step: 220, loss: 3.648368874564767e-05
step: 230, loss: 0.00013060211495030671
step: 240, loss: 0.001971200807020068
step: 250, loss: 0.00010455106530571356
step: 260, loss: 2.5315543098258786e-05
step: 270, loss: 0.002643903484568
step: 280, loss: 2.6676101697375998e-05
step: 290, loss: 0.000647616689093411
step: 300, loss: 6.787641177652404e-05
step: 310, loss: 1.9128590793116018e-05
step: 320, loss: 3.914455010090023e-05
step: 330, loss: 0.0006967682857066393
step: 340, loss: 1.2144204447395168e-05
step: 350, loss: 0.03562026470899582
step: 360, loss: 0.01610175333917141
step: 370, loss: 2.1827479940839112e-05
step: 380, loss: 2.147881059499923e-05
step: 390, loss: 0.00017811548605095595
step: 400, loss: 1.177923877548892e-05
step: 410, loss: 3.2148585887625813e-05
step: 420, loss: 0.0008883815025910735
step: 430, loss: 2.2637494112132117e-05
step: 440, loss: 0.0026546793524175882
step: 450, loss: 0.000988107523880899
step: 460, loss: 0.00175724015571177
step: 470, loss: 1.0698869118641596e-05
step: 480, loss: 0.00014509301399812102
step: 490, loss: 0.011768140830099583
step: 500, loss: 6.447028863476589e-05
step: 510, loss: 0.00016547073028050363
step: 520, loss: 5.688103919965215e-05
step: 530, loss: 0.046964045614004135
step: 540, loss: 0.00039014877984300256
step: 550, loss: 9.62263293331489e-05
step: 560, loss: 0.0002066797314910218
step: 570, loss: 0.00020643803873099387
step: 580, loss: 0.00811260286718607
step: 590, loss: 3.473696779110469e-05
step: 600, loss: 2.6127050659852102e-05
step: 610, loss: 0.03143030032515526
step: 620, loss: 6.420958379749209e-05
step: 630, loss: 7.150040619308129e-05
step: 640, loss: 2.4167728042812087e-05
step: 650, loss: 8.213923865696415e-05
step: 660, loss: 3.652215309557505e-05
step: 670, loss: 0.00011848654685309157
step: 680, loss: 8.740148041397333e-05
step: 690, loss: 0.0010802606120705605
step: 700, loss: 4.021266067866236e-05
step: 710, loss: 0.025845203548669815
step: 720, loss: 8.532957144780084e-05
step: 730, loss: 1.2989733477297705e-05
step: 740, loss: 0.012283330783247948
step: 750, loss: 1.697178049653303e-05
step: 760, loss: 1.9545655959518626e-05
step: 770, loss: 0.002851630561053753
step: 780, loss: 2.7951433366979472e-05
step: 790, loss: 2.3667122150072828e-05
step: 800, loss: 1.5094505215529352e-05
step: 810, loss: 6.9263725890778e-05
step: 820, loss: 1.876259921118617e-05
step: 830, loss: 0.0004839090397581458
step: 840, loss: 0.0002056450757663697
step: 850, loss: 2.898698403441813e-05
step: 860, loss: 0.000304416345898062
step: 870, loss: 0.0005875971983186901
step: 880, loss: 8.136862015817314e-05
step: 890, loss: 5.944172517047264e-05
step: 900, loss: 0.0004052607109770179
step: 910, loss: 0.013361248187720776
step: 920, loss: 0.00013062045036349446
step: 930, loss: 0.000746826350223273
step: 940, loss: 0.0027585038915276527
step: 950, loss: 3.301776814623736e-05
step: 960, loss: 6.298105290625244e-05
step: 970, loss: 0.000299847248243168
step: 980, loss: 1.0557369932939764e-05
step: 990, loss: 7.474556332454085e-05
step: 1000, loss: 3.6330518923932686e-05
step: 1010, loss: 0.040306758135557175
step: 1020, loss: 1.4710892173752654e-05
step: 1030, loss: 0.0011779775377362967
epoch 17: dev_f1=0.939679547596607, f1=0.9295238095238095, best_f1=0.9238050165641268
step: 0, loss: 0.00015708572755102068
step: 10, loss: 0.00015370747132692486
step: 20, loss: 2.7413088901084848e-05
step: 30, loss: 0.00016254582442343235
step: 40, loss: 7.286117761395872e-05
step: 50, loss: 6.431355723179877e-05
step: 60, loss: 0.004971247632056475
step: 70, loss: 3.833781011053361e-05
step: 80, loss: 0.00026436385815031826
step: 90, loss: 0.00013464356015902013
step: 100, loss: 1.5697891285526566e-05
step: 110, loss: 2.0133495127083734e-05
step: 120, loss: 2.8279378966544755e-05
step: 130, loss: 5.0269696657778695e-05
step: 140, loss: 0.0003233651223126799
step: 150, loss: 0.012609436176717281
step: 160, loss: 0.0006848187185823917
step: 170, loss: 0.018178943544626236
step: 180, loss: 5.30026554770302e-05
step: 190, loss: 2.079356818285305e-05
step: 200, loss: 1.0024644325312693e-05
step: 210, loss: 2.3564927687402815e-05
step: 220, loss: 0.00013857375597581267
step: 230, loss: 0.00036518534761853516
step: 240, loss: 0.036934707313776016
step: 250, loss: 0.0033506036270409822
step: 260, loss: 7.618200470460579e-05
step: 270, loss: 0.000670846551656723
step: 280, loss: 0.0007462382200174034
step: 290, loss: 0.11773025989532471
step: 300, loss: 2.0276040231692605e-05
step: 310, loss: 1.652855826250743e-05
step: 320, loss: 7.197845116024837e-05
step: 330, loss: 1.4025428754393943e-05
step: 340, loss: 2.583878995210398e-05
step: 350, loss: 1.7452215615776367e-05
step: 360, loss: 0.022810716181993484
step: 370, loss: 0.0001404279173584655
step: 380, loss: 1.404010436090175e-05
step: 390, loss: 0.009151809848845005
step: 400, loss: 1.4107375136518385e-05
step: 410, loss: 4.0207800338976085e-05
step: 420, loss: 3.093356644967571e-05
step: 430, loss: 4.853259815718047e-05
step: 440, loss: 9.067550126928836e-05
step: 450, loss: 0.001835809787735343
step: 460, loss: 6.099506572354585e-05
step: 470, loss: 2.0782603314728476e-05
step: 480, loss: 0.01592971757054329
step: 490, loss: 1.3321221558726393e-05
step: 500, loss: 8.839468500809744e-05
step: 510, loss: 5.8842371799983084e-05
step: 520, loss: 1.8435195670463145e-05
step: 530, loss: 0.00011909469321835786
step: 540, loss: 1.2851837709604297e-05
step: 550, loss: 0.00038057006895542145
step: 560, loss: 1.4826228834863286e-05
step: 570, loss: 4.1065268305828795e-05
step: 580, loss: 0.0009284657426178455
step: 590, loss: 1.6450216207886115e-05
step: 600, loss: 9.04118951439159e-06
step: 610, loss: 0.00014211228699423373
step: 620, loss: 4.239754343871027e-05
step: 630, loss: 7.867671229178086e-05
step: 640, loss: 0.0012832584325224161
step: 650, loss: 3.387883407413028e-05
step: 660, loss: 7.979502697708085e-06
step: 670, loss: 1.4066397852730006e-05
step: 680, loss: 0.0004211220657452941
step: 690, loss: 1.534401235403493e-05
step: 700, loss: 3.3733300369931385e-05
step: 710, loss: 1.4151857612887397e-05
step: 720, loss: 4.3737793021136895e-05
step: 730, loss: 0.0003908135986421257
step: 740, loss: 2.435395981592592e-05
step: 750, loss: 2.4473885787301697e-05
step: 760, loss: 2.351619696128182e-05
step: 770, loss: 0.0009830223862081766
step: 780, loss: 0.00029428323614411056
step: 790, loss: 1.8167005691793747e-05
step: 800, loss: 6.980447506066412e-05
step: 810, loss: 0.00015848054317757487
step: 820, loss: 0.00016069156117737293
step: 830, loss: 2.7267717086942866e-05
step: 840, loss: 9.13218900677748e-05
step: 850, loss: 3.063108670176007e-05
step: 860, loss: 0.014207838103175163
step: 870, loss: 0.008554140105843544
step: 880, loss: 9.907436469802633e-05
step: 890, loss: 9.614792361389846e-06
step: 900, loss: 1.613373933651019e-05
step: 910, loss: 1.7980721167987213e-05
step: 920, loss: 1.5831719792913646e-05
step: 930, loss: 4.662430001189932e-05
step: 940, loss: 0.027736550197005272
step: 950, loss: 2.167925049434416e-05
step: 960, loss: 2.552479418227449e-05
step: 970, loss: 3.0908864573575556e-05
step: 980, loss: 0.0019912354182451963
step: 990, loss: 1.4535700756823644e-05
step: 1000, loss: 5.098365363664925e-05
step: 1010, loss: 4.7057310439413413e-05
step: 1020, loss: 0.001717203645966947
step: 1030, loss: 0.0002892912016250193
epoch 18: dev_f1=0.9431123648330982, f1=0.9322595926101374, best_f1=0.9238050165641268
step: 0, loss: 2.1687710614060052e-05
step: 10, loss: 0.01265033707022667
step: 20, loss: 0.00020538223907351494
step: 30, loss: 1.4036582797416486e-05
step: 40, loss: 4.3715790525311604e-05
step: 50, loss: 4.0171998989535496e-05
step: 60, loss: 0.00010890245175687596
step: 70, loss: 0.013681380078196526
step: 80, loss: 2.670855428732466e-05
step: 90, loss: 2.0945040887454525e-05
step: 100, loss: 6.61005760775879e-05
step: 110, loss: 7.54392531234771e-05
step: 120, loss: 0.00023459421936422586
step: 130, loss: 3.1967090762918815e-05
step: 140, loss: 3.661307709990069e-05
step: 150, loss: 6.533554551424459e-05
step: 160, loss: 0.0002086394524667412
step: 170, loss: 1.098555549106095e-05
step: 180, loss: 1.7232650861842558e-05
step: 190, loss: 0.005665313918143511
step: 200, loss: 3.0351073291967623e-05
step: 210, loss: 0.00021203330834396183
step: 220, loss: 0.0001518445205874741
step: 230, loss: 1.649137084314134e-05
step: 240, loss: 7.830508366168942e-06
step: 250, loss: 8.393925963900983e-05
step: 260, loss: 0.0007297396077774465
step: 270, loss: 2.9526967409765348e-05
step: 280, loss: 5.872191468370147e-05
step: 290, loss: 7.148053555283695e-05
step: 300, loss: 2.111343201249838e-05
step: 310, loss: 6.44819883746095e-05
step: 320, loss: 2.5025292416103184e-05
step: 330, loss: 4.2716808820841834e-05
step: 340, loss: 1.4483659469988197e-05
step: 350, loss: 1.6856642105267383e-05
step: 360, loss: 0.0009964464697986841
step: 370, loss: 0.001485150889493525
step: 380, loss: 2.2815958800492808e-05
step: 390, loss: 0.00012894123210571706
step: 400, loss: 1.902431176858954e-05
step: 410, loss: 1.9486118617351167e-05
step: 420, loss: 0.0005001035169698298
step: 430, loss: 1.3138774193066638e-05
step: 440, loss: 7.430573896272108e-05
step: 450, loss: 0.0018201053608208895
step: 460, loss: 1.634998079680372e-05
step: 470, loss: 0.0010413876734673977
step: 480, loss: 0.0003637999470811337
step: 490, loss: 0.000210414087632671
step: 500, loss: 0.0013213437050580978
step: 510, loss: 0.0004050543066114187
step: 520, loss: 8.228138176491484e-05
step: 530, loss: 3.974590072175488e-05
step: 540, loss: 0.00031420448794960976
step: 550, loss: 2.8455313440645114e-05
step: 560, loss: 0.12970127165317535
step: 570, loss: 3.605620440794155e-05
step: 580, loss: 1.145877831731923e-05
step: 590, loss: 0.00013147397839929909
step: 600, loss: 0.00404139282181859
step: 610, loss: 1.949617944774218e-05
step: 620, loss: 4.571108365780674e-05
step: 630, loss: 2.1363528503570706e-05
step: 640, loss: 9.771339136932511e-06
step: 650, loss: 8.307328243972734e-06
step: 660, loss: 0.03263990208506584
step: 670, loss: 2.7438527467893437e-05
step: 680, loss: 0.001370993908494711
step: 690, loss: 0.0003679156943690032
step: 700, loss: 1.951206286321394e-05
step: 710, loss: 0.00015707632701378316
step: 720, loss: 0.015930915251374245
step: 730, loss: 3.158123581670225e-05
step: 740, loss: 2.054019751085434e-05
step: 750, loss: 3.1562700314680114e-05
step: 760, loss: 2.5555662432452664e-05
step: 770, loss: 0.0006053299293853343
step: 780, loss: 5.09099627379328e-05
step: 790, loss: 1.7478192603448406e-05
step: 800, loss: 1.873384098871611e-05
step: 810, loss: 0.00020304870849940926
step: 820, loss: 1.5947456631693058e-05
step: 830, loss: 4.9274905904894695e-05
step: 840, loss: 0.00013870946713723242
step: 850, loss: 4.5182634494267404e-05
step: 860, loss: 0.0002951098431367427
step: 870, loss: 1.8052080122288316e-05
step: 880, loss: 4.6619832573924214e-05
step: 890, loss: 0.0003132774727419019
step: 900, loss: 1.1626471859926824e-05
step: 910, loss: 2.310273157490883e-05
step: 920, loss: 0.007175960578024387
step: 930, loss: 3.290194217697717e-05
step: 940, loss: 7.45053557693609e-06
step: 950, loss: 0.041985318064689636
step: 960, loss: 0.0004383630002848804
step: 970, loss: 2.4525583285139874e-05
step: 980, loss: 1.9661089027067646e-05
step: 990, loss: 3.634077438618988e-05
step: 1000, loss: 7.123420800780877e-05
step: 1010, loss: 0.00012786957086063921
step: 1020, loss: 0.0001368127268506214
step: 1030, loss: 3.7105652154423296e-05
epoch 19: dev_f1=0.9426691729323308, f1=0.933774834437086, best_f1=0.9238050165641268
step: 0, loss: 0.00027503640740178525
step: 10, loss: 3.1277315429179e-05
step: 20, loss: 0.00020687549840658903
step: 30, loss: 5.822167804581113e-05
step: 40, loss: 2.1135356291779317e-05
step: 50, loss: 3.212678348063491e-05
step: 60, loss: 0.000182206611498259
step: 70, loss: 0.0002090295747620985
step: 80, loss: 2.5329522031825036e-05
step: 90, loss: 0.0008334248559549451
step: 100, loss: 6.057446444174275e-05
step: 110, loss: 3.3474676456535235e-05
step: 120, loss: 0.0035806368105113506
step: 130, loss: 9.961305295291822e-06
step: 140, loss: 1.1723066563718021e-05
step: 150, loss: 7.770904630888253e-06
step: 160, loss: 0.00018429107149131596
step: 170, loss: 3.3600641472730786e-05
step: 180, loss: 0.0004092152521479875
step: 190, loss: 4.142574471188709e-05
step: 200, loss: 0.0003575391892809421
step: 210, loss: 0.0005832177703268826
step: 220, loss: 0.016937337815761566
step: 230, loss: 2.3643184249522164e-05
step: 240, loss: 0.0002761927025858313
step: 250, loss: 5.943624273641035e-05
step: 260, loss: 2.8901280529680662e-05
step: 270, loss: 2.77317849395331e-05
step: 280, loss: 0.00018894646200351417
step: 290, loss: 1.6647758457111195e-05
step: 300, loss: 4.252605140209198e-05
step: 310, loss: 9.08534275367856e-05
step: 320, loss: 1.2196257557661738e-05
step: 330, loss: 5.8077057474292815e-06
step: 340, loss: 3.413025115150958e-05
step: 350, loss: 0.0007212745258584619
step: 360, loss: 1.9135577531415038e-05
step: 370, loss: 0.00010257937537971884
step: 380, loss: 0.00047308034845627844
step: 390, loss: 5.9390804381109774e-05
step: 400, loss: 0.0001434081350453198
step: 410, loss: 1.877475733635947e-05
step: 420, loss: 1.5928881111904047e-05
step: 430, loss: 2.6924099074676633e-05
step: 440, loss: 0.00024051967193372548
step: 450, loss: 1.0218324860034045e-05
step: 460, loss: 1.0713761184888426e-05
step: 470, loss: 3.904081677319482e-05
step: 480, loss: 0.006900529842823744
step: 490, loss: 1.346272892988054e-05
step: 500, loss: 2.4390594262513332e-05
step: 510, loss: 0.00025367620401084423
step: 520, loss: 0.0001875483721960336
step: 530, loss: 1.0270527127431706e-05
step: 540, loss: 2.5382214516866952e-05
step: 550, loss: 0.0005178508581593633
step: 560, loss: 0.00019420203170739114
step: 570, loss: 3.7782592698931694e-05
step: 580, loss: 1.0073056728288066e-05
step: 590, loss: 1.8964967239298858e-05
step: 600, loss: 7.901277967903297e-06
step: 610, loss: 4.5841381506761536e-05
step: 620, loss: 8.553195584681816e-06
step: 630, loss: 3.6578261642716825e-05
step: 640, loss: 1.1037710464734118e-05
step: 650, loss: 1.306059584749164e-05
step: 660, loss: 1.1596650438150391e-05
step: 670, loss: 0.006536093074828386
step: 680, loss: 9.794308425625786e-05
step: 690, loss: 4.123603139305487e-05
step: 700, loss: 0.005698045250028372
step: 710, loss: 4.482929580262862e-05
step: 720, loss: 0.0030876128003001213
step: 730, loss: 1.1041633115382865e-05
step: 740, loss: 0.0022415865678340197
step: 750, loss: 5.605605474556796e-05
step: 760, loss: 9.037358722707722e-06
step: 770, loss: 0.017794044688344002
step: 780, loss: 2.04024890990695e-05
step: 790, loss: 4.3440730223665014e-05
step: 800, loss: 6.974153802730143e-05
step: 810, loss: 2.8045687940903008e-05
step: 820, loss: 8.351203723577783e-05
step: 830, loss: 0.0004854504077229649
step: 840, loss: 0.000641964259557426
step: 850, loss: 0.00014541974815074354
step: 860, loss: 2.5822768293437548e-05
step: 870, loss: 1.4248927982407622e-05
step: 880, loss: 3.199758066330105e-05
step: 890, loss: 2.482998934283387e-05
step: 900, loss: 2.4014903829083778e-05
step: 910, loss: 0.000653150025755167
step: 920, loss: 0.00015263183740898967
step: 930, loss: 0.0001527972926851362
step: 940, loss: 1.2323127521085553e-05
step: 950, loss: 0.00031280546681955457
step: 960, loss: 1.5407327737193555e-05
step: 970, loss: 0.0006940491730347276
step: 980, loss: 2.4674416636116803e-05
step: 990, loss: 9.848841727944091e-05
step: 1000, loss: 0.0010422270279377699
step: 1010, loss: 1.928474557644222e-05
step: 1020, loss: 1.5079592230904382e-05
step: 1030, loss: 0.0004205694131087512
epoch 20: dev_f1=0.9448893075836081, f1=0.933649289099526, best_f1=0.9238050165641268
