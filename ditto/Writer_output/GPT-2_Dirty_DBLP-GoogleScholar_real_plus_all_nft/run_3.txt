cuda
Device: cuda
step: 0, loss: 0.6215389370918274
step: 10, loss: 0.3285820186138153
step: 20, loss: 0.3266139328479767
step: 30, loss: 0.4239247143268585
step: 40, loss: 0.14866997301578522
step: 50, loss: 0.26065072417259216
step: 60, loss: 0.32529139518737793
step: 70, loss: 0.3253769278526306
step: 80, loss: 0.16610461473464966
step: 90, loss: 0.2214558720588684
step: 100, loss: 0.6087313890457153
step: 110, loss: 0.27402520179748535
step: 120, loss: 0.2305067777633667
step: 130, loss: 0.1951485127210617
step: 140, loss: 0.14679951965808868
step: 150, loss: 0.2486197054386139
step: 160, loss: 0.17297881841659546
step: 170, loss: 0.26601046323776245
step: 180, loss: 0.15120288729667664
step: 190, loss: 0.28447312116622925
step: 200, loss: 0.22018423676490784
step: 210, loss: 0.15804164111614227
step: 220, loss: 0.18881581723690033
step: 230, loss: 0.524706244468689
step: 240, loss: 0.5813730955123901
step: 250, loss: 0.33584094047546387
step: 260, loss: 0.225608229637146
step: 270, loss: 0.25085118412971497
step: 280, loss: 0.2546582818031311
step: 290, loss: 0.14896315336227417
step: 300, loss: 0.07553063333034515
step: 310, loss: 0.3318609297275543
step: 320, loss: 0.2647358775138855
step: 330, loss: 0.19649168848991394
step: 340, loss: 0.3189624845981598
step: 350, loss: 0.3080969750881195
step: 360, loss: 0.19082742929458618
step: 370, loss: 0.3056642413139343
step: 380, loss: 0.2534732222557068
step: 390, loss: 0.04276241734623909
step: 400, loss: 0.21072886884212494
step: 410, loss: 0.16951750218868256
step: 420, loss: 0.3001188635826111
step: 430, loss: 0.3772408068180084
step: 440, loss: 0.2102481871843338
step: 450, loss: 0.16512224078178406
step: 460, loss: 0.19073648750782013
step: 470, loss: 0.202830508351326
step: 480, loss: 0.5510743856430054
step: 490, loss: 0.355663537979126
step: 500, loss: 0.22345885634422302
step: 510, loss: 0.15131443738937378
step: 520, loss: 0.222791850566864
step: 530, loss: 0.14972619712352753
step: 540, loss: 0.338106632232666
step: 550, loss: 0.2003716379404068
step: 560, loss: 0.19385844469070435
step: 570, loss: 0.2204105257987976
step: 580, loss: 0.20898963510990143
step: 590, loss: 0.28432145714759827
step: 600, loss: 0.1133824959397316
step: 610, loss: 0.09233127534389496
step: 620, loss: 0.1807762086391449
step: 630, loss: 0.14572715759277344
step: 640, loss: 0.17678289115428925
step: 650, loss: 0.25912654399871826
step: 660, loss: 0.24749793112277985
step: 670, loss: 0.1499687284231186
step: 680, loss: 0.23018644750118256
step: 690, loss: 0.13006329536437988
step: 700, loss: 0.06710724532604218
step: 710, loss: 0.2331525683403015
step: 720, loss: 0.17824186384677887
step: 730, loss: 0.15620701014995575
step: 740, loss: 0.08453769236803055
step: 750, loss: 0.20202073454856873
step: 760, loss: 0.12495191395282745
step: 770, loss: 0.06695033609867096
step: 780, loss: 0.18487656116485596
step: 790, loss: 0.14191603660583496
step: 800, loss: 0.39955171942710876
step: 810, loss: 0.24904035031795502
step: 820, loss: 0.21177610754966736
step: 830, loss: 0.13370256125926971
step: 840, loss: 0.22151324152946472
step: 850, loss: 0.10791438817977905
step: 860, loss: 0.25610223412513733
step: 870, loss: 0.18722809851169586
step: 880, loss: 0.2874870300292969
step: 890, loss: 0.2480129897594452
step: 900, loss: 0.19925588369369507
step: 910, loss: 0.16257931292057037
step: 920, loss: 0.11163219064474106
step: 930, loss: 0.20938807725906372
step: 940, loss: 0.10919027030467987
epoch 1: dev_f1=0.9436947417403444, f1=0.9294062646096307, best_f1=0.9294062646096307
step: 0, loss: 0.17017298936843872
step: 10, loss: 0.06515500694513321
step: 20, loss: 0.19152477383613586
step: 30, loss: 0.17786869406700134
step: 40, loss: 0.25229066610336304
step: 50, loss: 0.05159275606274605
step: 60, loss: 0.09702310711145401
step: 70, loss: 0.0709540918469429
step: 80, loss: 0.08768554031848907
step: 90, loss: 0.12912623584270477
step: 100, loss: 0.03368476778268814
step: 110, loss: 0.09578019380569458
step: 120, loss: 0.11439696699380875
step: 130, loss: 0.059036385267972946
step: 140, loss: 0.3061044216156006
step: 150, loss: 0.07034363597631454
step: 160, loss: 0.12264750152826309
step: 170, loss: 0.12919647991657257
step: 180, loss: 0.14380547404289246
step: 190, loss: 0.07622960209846497
step: 200, loss: 0.17114821076393127
step: 210, loss: 0.1557685285806656
step: 220, loss: 0.17305824160575867
step: 230, loss: 0.20613393187522888
step: 240, loss: 0.13019533455371857
step: 250, loss: 0.15370388329029083
step: 260, loss: 0.2938954532146454
step: 270, loss: 0.04840222746133804
step: 280, loss: 0.06800054013729095
step: 290, loss: 0.14978714287281036
step: 300, loss: 0.017033085227012634
step: 310, loss: 0.31200796365737915
step: 320, loss: 0.03595644235610962
step: 330, loss: 0.06106474995613098
step: 340, loss: 0.3037838339805603
step: 350, loss: 0.2425675094127655
step: 360, loss: 0.2308681756258011
step: 370, loss: 0.12101994454860687
step: 380, loss: 0.1337079256772995
step: 390, loss: 0.08652392029762268
step: 400, loss: 0.23761476576328278
step: 410, loss: 0.05995088815689087
step: 420, loss: 0.3439059257507324
step: 430, loss: 0.09142442047595978
step: 440, loss: 0.16512474417686462
step: 450, loss: 0.1933726668357849
step: 460, loss: 0.17677152156829834
step: 470, loss: 0.24647662043571472
step: 480, loss: 0.16254281997680664
step: 490, loss: 0.16425257921218872
step: 500, loss: 0.02357170358300209
step: 510, loss: 0.11474516987800598
step: 520, loss: 0.1428869068622589
step: 530, loss: 0.048676881939172745
step: 540, loss: 0.12067758291959763
step: 550, loss: 0.07336839288473129
step: 560, loss: 0.13589215278625488
step: 570, loss: 0.07934202253818512
step: 580, loss: 0.228266179561615
step: 590, loss: 0.2038736641407013
step: 600, loss: 0.037143878638744354
step: 610, loss: 0.1775609701871872
step: 620, loss: 0.21110334992408752
step: 630, loss: 0.03188355267047882
step: 640, loss: 0.1418466567993164
step: 650, loss: 0.025851484388113022
step: 660, loss: 0.11417737603187561
step: 670, loss: 0.15953849256038666
step: 680, loss: 0.5741866827011108
step: 690, loss: 0.16116026043891907
step: 700, loss: 0.044035084545612335
step: 710, loss: 0.24252712726593018
step: 720, loss: 0.1773034781217575
step: 730, loss: 0.14395968616008759
step: 740, loss: 0.12459463626146317
step: 750, loss: 0.19308368861675262
step: 760, loss: 0.10894935578107834
step: 770, loss: 0.10141656547784805
step: 780, loss: 0.13829545676708221
step: 790, loss: 0.12446027994155884
step: 800, loss: 0.4231686294078827
step: 810, loss: 0.1997450739145279
step: 820, loss: 0.027178915217518806
step: 830, loss: 0.1595858484506607
step: 840, loss: 0.10484529286623001
step: 850, loss: 0.03735750541090965
step: 860, loss: 0.14199213683605194
step: 870, loss: 0.12286530435085297
step: 880, loss: 0.19008713960647583
step: 890, loss: 0.15770868957042694
step: 900, loss: 0.09340527653694153
step: 910, loss: 0.09795274585485458
step: 920, loss: 0.28772497177124023
step: 930, loss: 0.0951024666428566
step: 940, loss: 0.06157023832201958
epoch 2: dev_f1=0.9579831932773109, f1=0.9325789721829325, best_f1=0.9325789721829325
step: 0, loss: 0.07537486404180527
step: 10, loss: 0.11368287354707718
step: 20, loss: 0.12921947240829468
step: 30, loss: 0.15084408223628998
step: 40, loss: 0.04889275133609772
step: 50, loss: 0.16079683601856232
step: 60, loss: 0.059956736862659454
step: 70, loss: 0.11501650512218475
step: 80, loss: 0.10571017116308212
step: 90, loss: 0.07532328367233276
step: 100, loss: 0.08179771155118942
step: 110, loss: 0.0894489735364914
step: 120, loss: 0.09119287878274918
step: 130, loss: 0.005295569077134132
step: 140, loss: 0.1784314215183258
step: 150, loss: 0.050313759595155716
step: 160, loss: 0.07587211579084396
step: 170, loss: 0.19215433299541473
step: 180, loss: 0.01785774528980255
step: 190, loss: 0.06954637169837952
step: 200, loss: 0.08489042520523071
step: 210, loss: 0.018902692943811417
step: 220, loss: 0.3516363203525543
step: 230, loss: 0.0951140969991684
step: 240, loss: 0.1600407063961029
step: 250, loss: 0.0700366348028183
step: 260, loss: 0.1043609157204628
step: 270, loss: 0.06679580360651016
step: 280, loss: 0.051949672400951385
step: 290, loss: 0.07820669561624527
step: 300, loss: 0.06645368039608002
step: 310, loss: 0.15174704790115356
step: 320, loss: 0.017977450042963028
step: 330, loss: 0.16632317006587982
step: 340, loss: 0.11480986326932907
step: 350, loss: 0.054138947278261185
step: 360, loss: 0.05998428910970688
step: 370, loss: 0.025040609762072563
step: 380, loss: 0.06770580261945724
step: 390, loss: 0.040973030030727386
step: 400, loss: 0.19433796405792236
step: 410, loss: 0.054069843143224716
step: 420, loss: 0.11249545216560364
step: 430, loss: 0.13386234641075134
step: 440, loss: 0.14392749965190887
step: 450, loss: 0.09286615997552872
step: 460, loss: 0.2188442200422287
step: 470, loss: 0.24885620176792145
step: 480, loss: 0.06255976110696793
step: 490, loss: 0.03885539621114731
step: 500, loss: 0.0748472735285759
step: 510, loss: 0.021665195003151894
step: 520, loss: 0.06904319673776627
step: 530, loss: 0.019910944625735283
step: 540, loss: 0.21695341169834137
step: 550, loss: 0.03942229971289635
step: 560, loss: 0.0655243769288063
step: 570, loss: 0.14719772338867188
step: 580, loss: 0.20022624731063843
step: 590, loss: 0.07658632844686508
step: 600, loss: 0.20873965322971344
step: 610, loss: 0.036652468144893646
step: 620, loss: 0.05652373284101486
step: 630, loss: 0.026715265586972237
step: 640, loss: 0.12202034890651703
step: 650, loss: 0.11032016575336456
step: 660, loss: 0.11231916397809982
step: 670, loss: 0.06053983420133591
step: 680, loss: 0.012431928887963295
step: 690, loss: 0.050412021577358246
step: 700, loss: 0.06918090581893921
step: 710, loss: 0.09562114626169205
step: 720, loss: 0.1795966625213623
step: 730, loss: 0.05993414297699928
step: 740, loss: 0.1101256012916565
step: 750, loss: 0.10140873491764069
step: 760, loss: 0.07929336279630661
step: 770, loss: 0.14803801476955414
step: 780, loss: 0.15502053499221802
step: 790, loss: 0.20547927916049957
step: 800, loss: 0.2636202871799469
step: 810, loss: 0.08127199113368988
step: 820, loss: 0.04679839313030243
step: 830, loss: 0.08028198033571243
step: 840, loss: 0.019226504489779472
step: 850, loss: 0.08689761161804199
step: 860, loss: 0.20121891796588898
step: 870, loss: 0.20211061835289001
step: 880, loss: 0.11421950161457062
step: 890, loss: 0.10495603829622269
step: 900, loss: 0.05300852283835411
step: 910, loss: 0.0823594257235527
step: 920, loss: 0.02896479144692421
step: 930, loss: 0.1038471907377243
step: 940, loss: 0.18298959732055664
epoch 3: dev_f1=0.9452554744525548, f1=0.9338842975206612, best_f1=0.9325789721829325
step: 0, loss: 0.0680236667394638
step: 10, loss: 0.09428984671831131
step: 20, loss: 0.10928183048963547
step: 30, loss: 0.062133416533470154
step: 40, loss: 0.05120992660522461
step: 50, loss: 0.25745996832847595
step: 60, loss: 0.0689399242401123
step: 70, loss: 0.009744425304234028
step: 80, loss: 0.08607901632785797
step: 90, loss: 0.13876007497310638
step: 100, loss: 0.04776495322585106
step: 110, loss: 0.12383060157299042
step: 120, loss: 0.10675977170467377
step: 130, loss: 0.01371986884623766
step: 140, loss: 0.11727220565080643
step: 150, loss: 0.06869220733642578
step: 160, loss: 0.1901252716779709
step: 170, loss: 0.1574544459581375
step: 180, loss: 0.02186162956058979
step: 190, loss: 0.11335381120443344
step: 200, loss: 0.06702255457639694
step: 210, loss: 0.06306834518909454
step: 220, loss: 0.10017259418964386
step: 230, loss: 0.16278108954429626
step: 240, loss: 0.14294536411762238
step: 250, loss: 0.01852286607027054
step: 260, loss: 0.16512145102024078
step: 270, loss: 0.010598184540867805
step: 280, loss: 0.1538144201040268
step: 290, loss: 0.06649616360664368
step: 300, loss: 0.15979044139385223
step: 310, loss: 0.04558689519762993
step: 320, loss: 0.05916855111718178
step: 330, loss: 0.01863102801144123
step: 340, loss: 0.09238686412572861
step: 350, loss: 0.060972895473241806
step: 360, loss: 0.10873425751924515
step: 370, loss: 0.092648945748806
step: 380, loss: 0.0250252615660429
step: 390, loss: 0.010374918580055237
step: 400, loss: 0.13755804300308228
step: 410, loss: 0.03483850136399269
step: 420, loss: 0.011292423121631145
step: 430, loss: 0.07544088363647461
step: 440, loss: 0.05783312767744064
step: 450, loss: 0.010589954443275928
step: 460, loss: 0.017394548282027245
step: 470, loss: 0.08655638992786407
step: 480, loss: 0.05779304355382919
step: 490, loss: 0.031108032912015915
step: 500, loss: 0.04345798119902611
step: 510, loss: 0.013216308318078518
step: 520, loss: 0.06301321089267731
step: 530, loss: 0.04838124290108681
step: 540, loss: 0.12335755676031113
step: 550, loss: 0.1475587636232376
step: 560, loss: 0.0749918520450592
step: 570, loss: 0.06846559792757034
step: 580, loss: 0.04589476063847542
step: 590, loss: 0.025857187807559967
step: 600, loss: 0.22267267107963562
step: 610, loss: 0.20743034780025482
step: 620, loss: 0.041079502552747726
step: 630, loss: 0.058221351355314255
step: 640, loss: 0.0333462655544281
step: 650, loss: 0.1671127825975418
step: 660, loss: 0.20475594699382782
step: 670, loss: 0.01891086809337139
step: 680, loss: 0.03632432222366333
step: 690, loss: 0.04494989290833473
step: 700, loss: 0.021016791462898254
step: 710, loss: 0.045182544738054276
step: 720, loss: 0.028050556778907776
step: 730, loss: 0.06523196399211884
step: 740, loss: 0.2130700647830963
step: 750, loss: 0.1555338054895401
step: 760, loss: 0.16318507492542267
step: 770, loss: 0.19583351910114288
step: 780, loss: 0.057740189135074615
step: 790, loss: 0.016246696934103966
step: 800, loss: 0.17519158124923706
step: 810, loss: 0.016485970467329025
step: 820, loss: 0.09644601494073868
step: 830, loss: 0.2035643458366394
step: 840, loss: 0.1002427339553833
step: 850, loss: 0.1397390067577362
step: 860, loss: 0.14843423664569855
step: 870, loss: 0.059687331318855286
step: 880, loss: 0.03559085354208946
step: 890, loss: 0.024870481342077255
step: 900, loss: 0.06385647505521774
step: 910, loss: 0.050846755504608154
step: 920, loss: 0.060246821492910385
step: 930, loss: 0.026825962588191032
step: 940, loss: 0.01039091031998396
epoch 4: dev_f1=0.9482999534233814, f1=0.9218455743879472, best_f1=0.9325789721829325
step: 0, loss: 0.15291887521743774
step: 10, loss: 0.02008231356739998
step: 20, loss: 0.10888005793094635
step: 30, loss: 0.27149322628974915
step: 40, loss: 0.007878756150603294
step: 50, loss: 0.05538785830140114
step: 60, loss: 0.022227082401514053
step: 70, loss: 0.03548075258731842
step: 80, loss: 0.0470336377620697
step: 90, loss: 0.04445037245750427
step: 100, loss: 0.011681340634822845
step: 110, loss: 0.003890056861564517
step: 120, loss: 0.09259162843227386
step: 130, loss: 0.0036508599296212196
step: 140, loss: 0.027563313022255898
step: 150, loss: 0.017015118151903152
step: 160, loss: 0.001454529701732099
step: 170, loss: 0.015249937772750854
step: 180, loss: 0.04014788568019867
step: 190, loss: 0.006939855869859457
step: 200, loss: 0.03125408664345741
step: 210, loss: 0.03500167652964592
step: 220, loss: 0.019696826115250587
step: 230, loss: 0.14774127304553986
step: 240, loss: 0.049826230853796005
step: 250, loss: 0.013205636292696
step: 260, loss: 0.04153946042060852
step: 270, loss: 0.019421080127358437
step: 280, loss: 0.006937273778021336
step: 290, loss: 0.004262431524693966
step: 300, loss: 0.07070546597242355
step: 310, loss: 0.11181540042161942
step: 320, loss: 0.050172120332717896
step: 330, loss: 0.10157055407762527
step: 340, loss: 0.08840393275022507
step: 350, loss: 0.003622285556048155
step: 360, loss: 0.09504544734954834
step: 370, loss: 0.11540602892637253
step: 380, loss: 0.25765007734298706
step: 390, loss: 0.02726978249847889
step: 400, loss: 0.09857428073883057
step: 410, loss: 0.002988412044942379
step: 420, loss: 0.04314618185162544
step: 430, loss: 0.06498333811759949
step: 440, loss: 0.07506205141544342
step: 450, loss: 0.006025309208780527
step: 460, loss: 0.013192987069487572
step: 470, loss: 0.030609218403697014
step: 480, loss: 0.022505836561322212
step: 490, loss: 0.07309465855360031
step: 500, loss: 0.012912090867757797
step: 510, loss: 0.006292262114584446
step: 520, loss: 0.025315603241324425
step: 530, loss: 0.10819918662309647
step: 540, loss: 0.03666509687900543
step: 550, loss: 0.1769275814294815
step: 560, loss: 0.04294238239526749
step: 570, loss: 0.014881693758070469
step: 580, loss: 0.016083892434835434
step: 590, loss: 0.11276448518037796
step: 600, loss: 0.0531616248190403
step: 610, loss: 0.0008771023713052273
step: 620, loss: 0.028591906651854515
step: 630, loss: 0.06648339331150055
step: 640, loss: 0.22353887557983398
step: 650, loss: 0.02207711525261402
step: 660, loss: 0.007107194978743792
step: 670, loss: 0.009403220377862453
step: 680, loss: 0.01862950623035431
step: 690, loss: 0.07065249979496002
step: 700, loss: 0.008764049038290977
step: 710, loss: 0.014179388992488384
step: 720, loss: 0.046730589121580124
step: 730, loss: 0.013819553889334202
step: 740, loss: 0.15757596492767334
step: 750, loss: 0.01645037718117237
step: 760, loss: 0.1129845529794693
step: 770, loss: 0.006857344415038824
step: 780, loss: 0.12408941984176636
step: 790, loss: 0.004942853003740311
step: 800, loss: 0.03762989491224289
step: 810, loss: 0.09876572340726852
step: 820, loss: 0.04848797619342804
step: 830, loss: 0.041706591844558716
step: 840, loss: 0.04928475618362427
step: 850, loss: 0.04609664902091026
step: 860, loss: 0.019576599821448326
step: 870, loss: 0.020297367125749588
step: 880, loss: 0.009557805955410004
step: 890, loss: 0.019240662455558777
step: 900, loss: 0.02844155579805374
step: 910, loss: 0.128599151968956
step: 920, loss: 0.009381524287164211
step: 930, loss: 0.05647173151373863
step: 940, loss: 0.015107283368706703
epoch 5: dev_f1=0.9467401285583104, f1=0.9237170596393898, best_f1=0.9325789721829325
step: 0, loss: 0.06099080666899681
step: 10, loss: 0.109987773001194
step: 20, loss: 0.030139101669192314
step: 30, loss: 0.008321821689605713
step: 40, loss: 0.07499230653047562
step: 50, loss: 0.03666659817099571
step: 60, loss: 0.009424349293112755
step: 70, loss: 0.03663066774606705
step: 80, loss: 0.13975758850574493
step: 90, loss: 0.11781308799982071
step: 100, loss: 0.007411143742501736
step: 110, loss: 0.0015552169643342495
step: 120, loss: 0.001033283770084381
step: 130, loss: 0.019372260197997093
step: 140, loss: 0.0012827960308641195
step: 150, loss: 0.004468646366149187
step: 160, loss: 0.16778381168842316
step: 170, loss: 0.006897857412695885
step: 180, loss: 0.0068373484537005424
step: 190, loss: 0.02874704822897911
step: 200, loss: 0.004861496388912201
step: 210, loss: 0.006828945595771074
step: 220, loss: 0.0038969728630036116
step: 230, loss: 0.018284715712070465
step: 240, loss: 0.04123241826891899
step: 250, loss: 0.015063860453665257
step: 260, loss: 0.016506100073456764
step: 270, loss: 0.05658700317144394
step: 280, loss: 0.005241548642516136
step: 290, loss: 0.07427137345075607
step: 300, loss: 0.006342544686049223
step: 310, loss: 0.015886593610048294
step: 320, loss: 0.042354077100753784
step: 330, loss: 0.0737706795334816
step: 340, loss: 0.0017343169311061502
step: 350, loss: 0.027227269485592842
step: 360, loss: 0.05070379748940468
step: 370, loss: 0.08152854442596436
step: 380, loss: 0.014181377366185188
step: 390, loss: 0.010357708670198917
step: 400, loss: 0.025883063673973083
step: 410, loss: 0.1753631979227066
step: 420, loss: 0.026315852999687195
step: 430, loss: 0.02263832837343216
step: 440, loss: 0.002761003328487277
step: 450, loss: 0.048662979155778885
step: 460, loss: 0.009468200616538525
step: 470, loss: 0.010302068665623665
step: 480, loss: 0.005640455521643162
step: 490, loss: 0.037730228155851364
step: 500, loss: 0.07484549283981323
step: 510, loss: 0.0016151932068169117
step: 520, loss: 0.001661548507399857
step: 530, loss: 0.002247943077236414
step: 540, loss: 0.015167437493801117
step: 550, loss: 0.004780205897986889
step: 560, loss: 0.012087150476872921
step: 570, loss: 0.0005318345502018929
step: 580, loss: 0.00438607856631279
step: 590, loss: 0.12040930241346359
step: 600, loss: 0.019320113584399223
step: 610, loss: 0.028155427426099777
step: 620, loss: 0.010343149304389954
step: 630, loss: 0.14113131165504456
step: 640, loss: 0.13280339539051056
step: 650, loss: 0.0363830029964447
step: 660, loss: 0.019353579729795456
step: 670, loss: 0.0011595251271501184
step: 680, loss: 0.025982728227972984
step: 690, loss: 0.054358333349227905
step: 700, loss: 0.09478015452623367
step: 710, loss: 0.001872517284937203
step: 720, loss: 0.03360952064394951
step: 730, loss: 0.03542415052652359
step: 740, loss: 0.01937478967010975
step: 750, loss: 0.004873408004641533
step: 760, loss: 0.19415690004825592
step: 770, loss: 0.01039961539208889
step: 780, loss: 0.010773840360343456
step: 790, loss: 0.006153462454676628
step: 800, loss: 0.04659002646803856
step: 810, loss: 0.009101520292460918
step: 820, loss: 0.04625950753688812
step: 830, loss: 0.2166154831647873
step: 840, loss: 0.02576884627342224
step: 850, loss: 0.14027047157287598
step: 860, loss: 0.25979724526405334
step: 870, loss: 0.023664982989430428
step: 880, loss: 0.017899224534630775
step: 890, loss: 0.021071862429380417
step: 900, loss: 0.014036840759217739
step: 910, loss: 0.012642668560147285
step: 920, loss: 0.03820091858506203
step: 930, loss: 0.0037035916466265917
step: 940, loss: 0.004435715265572071
epoch 6: dev_f1=0.9450139794967382, f1=0.920205319645357, best_f1=0.9325789721829325
step: 0, loss: 0.00409430218860507
step: 10, loss: 0.0035343095660209656
step: 20, loss: 0.0032344097271561623
step: 30, loss: 0.22738617658615112
step: 40, loss: 0.0018494374817237258
step: 50, loss: 0.002251047408208251
step: 60, loss: 0.022598663344979286
step: 70, loss: 0.06356587260961533
step: 80, loss: 0.1215820163488388
step: 90, loss: 0.006457663606852293
step: 100, loss: 0.0018230541609227657
step: 110, loss: 0.0035961333196610212
step: 120, loss: 0.03458497300744057
step: 130, loss: 0.0010647723684087396
step: 140, loss: 0.03128843382000923
step: 150, loss: 0.00026154855731874704
step: 160, loss: 0.0008116853423416615
step: 170, loss: 0.003999455366283655
step: 180, loss: 0.0007166609284467995
step: 190, loss: 0.03272772207856178
step: 200, loss: 0.0019923821091651917
step: 210, loss: 0.10699348896741867
step: 220, loss: 0.0009603527141734958
step: 230, loss: 0.033313143998384476
step: 240, loss: 0.01536540500819683
step: 250, loss: 0.03925188258290291
step: 260, loss: 0.027038104832172394
step: 270, loss: 0.003749008057639003
step: 280, loss: 0.08511168509721756
step: 290, loss: 0.05041978880763054
step: 300, loss: 0.028397196903824806
step: 310, loss: 0.03725700452923775
step: 320, loss: 0.004797318950295448
step: 330, loss: 0.0016933733131736517
step: 340, loss: 0.0013063902733847499
step: 350, loss: 0.04508046805858612
step: 360, loss: 0.003505618078634143
step: 370, loss: 0.008357022888958454
step: 380, loss: 0.09987013041973114
step: 390, loss: 0.002812687074765563
step: 400, loss: 0.0012232420267537236
step: 410, loss: 0.06777019053697586
step: 420, loss: 0.011160243302583694
step: 430, loss: 0.012505549937486649
step: 440, loss: 0.022979455068707466
step: 450, loss: 0.0031457843724638224
step: 460, loss: 0.00732961343601346
step: 470, loss: 0.004915396682918072
step: 480, loss: 0.008543621748685837
step: 490, loss: 0.11049748212099075
step: 500, loss: 0.01116569247096777
step: 510, loss: 0.039792437106370926
step: 520, loss: 0.010853123851120472
step: 530, loss: 0.018544306978583336
step: 540, loss: 0.07904720306396484
step: 550, loss: 0.0052162944339215755
step: 560, loss: 0.1335010677576065
step: 570, loss: 0.004574015736579895
step: 580, loss: 0.0035369880497455597
step: 590, loss: 0.10436952114105225
step: 600, loss: 0.011373703368008137
step: 610, loss: 0.0033683874644339085
step: 620, loss: 0.008866486139595509
step: 630, loss: 0.03685055300593376
step: 640, loss: 0.07925017923116684
step: 650, loss: 0.0058228326961398125
step: 660, loss: 0.005754631944000721
step: 670, loss: 0.0010831494582816958
step: 680, loss: 0.00268972828052938
step: 690, loss: 0.0037903068587183952
step: 700, loss: 0.004060712177306414
step: 710, loss: 0.018741142004728317
step: 720, loss: 0.01100078970193863
step: 730, loss: 0.08118274062871933
step: 740, loss: 0.0037929972168058157
step: 750, loss: 0.04588960111141205
step: 760, loss: 0.04395456612110138
step: 770, loss: 0.042259637266397476
step: 780, loss: 0.023818057030439377
step: 790, loss: 0.00025487891980446875
step: 800, loss: 0.0022199489176273346
step: 810, loss: 0.010143468156456947
step: 820, loss: 0.04221174493432045
step: 830, loss: 0.044977977871894836
step: 840, loss: 0.009573990479111671
step: 850, loss: 0.029032845050096512
step: 860, loss: 0.012231197208166122
step: 870, loss: 0.0170542374253273
step: 880, loss: 0.05087525025010109
step: 890, loss: 0.015328384935855865
step: 900, loss: 0.028897570446133614
step: 910, loss: 0.0009185919188894331
step: 920, loss: 0.01798286847770214
step: 930, loss: 0.03831792250275612
step: 940, loss: 0.05325609818100929
epoch 7: dev_f1=0.9452830188679245, f1=0.9227817745803358, best_f1=0.9325789721829325
step: 0, loss: 0.0012659737840294838
step: 10, loss: 0.0029007107950747013
step: 20, loss: 0.10161831229925156
step: 30, loss: 0.031848467886447906
step: 40, loss: 0.008701604790985584
step: 50, loss: 0.0029581186827272177
step: 60, loss: 0.012395585887134075
step: 70, loss: 0.004553517326712608
step: 80, loss: 0.0022812457755208015
step: 90, loss: 0.04541042819619179
step: 100, loss: 0.006884637288749218
step: 110, loss: 0.00037115419399924576
step: 120, loss: 0.12188852578401566
step: 130, loss: 0.001593353576026857
step: 140, loss: 0.0010509188286960125
step: 150, loss: 0.0014139633858576417
step: 160, loss: 0.05391467735171318
step: 170, loss: 0.0013812335673719645
step: 180, loss: 0.000313415948767215
step: 190, loss: 0.020531263202428818
step: 200, loss: 0.008401831611990929
step: 210, loss: 0.0027677901089191437
step: 220, loss: 0.003522945335134864
step: 230, loss: 0.007838103920221329
step: 240, loss: 0.05658303573727608
step: 250, loss: 0.0388941764831543
step: 260, loss: 0.006378348916769028
step: 270, loss: 0.002494904911145568
step: 280, loss: 0.188557967543602
step: 290, loss: 0.0002913949138019234
step: 300, loss: 0.29626473784446716
step: 310, loss: 0.06882242113351822
step: 320, loss: 0.009026963263750076
step: 330, loss: 0.07030068337917328
step: 340, loss: 0.00130351388361305
step: 350, loss: 0.003172501688823104
step: 360, loss: 0.0005098945694044232
step: 370, loss: 0.004460942465811968
step: 380, loss: 0.0019340146100148559
step: 390, loss: 0.009551411494612694
step: 400, loss: 0.018648041412234306
step: 410, loss: 0.011968066915869713
step: 420, loss: 0.13734351098537445
step: 430, loss: 0.09203330427408218
step: 440, loss: 0.0037750687915831804
step: 450, loss: 0.0009384963195770979
step: 460, loss: 0.03028068318963051
step: 470, loss: 0.059105489403009415
step: 480, loss: 0.00103770790155977
step: 490, loss: 0.002344361739233136
step: 500, loss: 0.0030019728001207113
step: 510, loss: 0.17420263588428497
step: 520, loss: 0.013780131936073303
step: 530, loss: 0.00032758890301920474
step: 540, loss: 0.0005719121545553207
step: 550, loss: 0.000735853856895119
step: 560, loss: 0.00041894748574122787
step: 570, loss: 0.013026168569922447
step: 580, loss: 0.007828576490283012
step: 590, loss: 0.0018325672717764974
step: 600, loss: 0.2331017106771469
step: 610, loss: 0.009280580095946789
step: 620, loss: 0.002794416155666113
step: 630, loss: 0.0696367472410202
step: 640, loss: 0.13466967642307281
step: 650, loss: 0.01270575076341629
step: 660, loss: 0.0019313573138788342
step: 670, loss: 0.0112649230286479
step: 680, loss: 0.002327019814401865
step: 690, loss: 0.00036592825199477375
step: 700, loss: 0.011096070520579815
step: 710, loss: 0.09598448127508163
step: 720, loss: 0.00024590929388068616
step: 730, loss: 0.04693067446351051
step: 740, loss: 0.01412323396652937
step: 750, loss: 0.007009914144873619
step: 760, loss: 0.004595651291310787
step: 770, loss: 0.0015980086755007505
step: 780, loss: 0.0032773823477327824
step: 790, loss: 0.12053351104259491
step: 800, loss: 0.10540652275085449
step: 810, loss: 0.006402122788131237
step: 820, loss: 0.017068933695554733
step: 830, loss: 0.00402915570884943
step: 840, loss: 0.001610179548151791
step: 850, loss: 0.017461806535720825
step: 860, loss: 0.06391092389822006
step: 870, loss: 0.006223181262612343
step: 880, loss: 0.023293813690543175
step: 890, loss: 0.003650626866146922
step: 900, loss: 0.017271757125854492
step: 910, loss: 0.006539011839777231
step: 920, loss: 0.03436220437288284
step: 930, loss: 0.003121260553598404
step: 940, loss: 0.002860922133550048
epoch 8: dev_f1=0.9466292134831461, f1=0.9313264346190029, best_f1=0.9325789721829325
step: 0, loss: 0.0002724010846577585
step: 10, loss: 0.0007876075687818229
step: 20, loss: 0.0036254758015275
step: 30, loss: 0.03617182746529579
step: 40, loss: 0.0009052134701050818
step: 50, loss: 0.003518586978316307
step: 60, loss: 0.0002671660331543535
step: 70, loss: 0.0016941368812695146
step: 80, loss: 0.02270543947815895
step: 90, loss: 0.00160291139036417
step: 100, loss: 0.002710700035095215
step: 110, loss: 0.0009289238369092345
step: 120, loss: 0.010220819152891636
step: 130, loss: 0.001058011082932353
step: 140, loss: 0.0025508087128400803
step: 150, loss: 0.0004970471491105855
step: 160, loss: 0.041749779134988785
step: 170, loss: 0.0003200534265488386
step: 180, loss: 0.01606924645602703
step: 190, loss: 0.07898330688476562
step: 200, loss: 0.09141531586647034
step: 210, loss: 0.007816947996616364
step: 220, loss: 0.0012674774043262005
step: 230, loss: 0.0012600504560396075
step: 240, loss: 0.0015430483035743237
step: 250, loss: 0.0025114428717643023
step: 260, loss: 0.06085783615708351
step: 270, loss: 0.0028899256139993668
step: 280, loss: 0.0010928713018074632
step: 290, loss: 0.006886804476380348
step: 300, loss: 0.0010353685356676579
step: 310, loss: 0.007352618500590324
step: 320, loss: 0.011746051721274853
step: 330, loss: 0.00017830425349529833
step: 340, loss: 0.016946135088801384
step: 350, loss: 0.013544590212404728
step: 360, loss: 0.07375150173902512
step: 370, loss: 0.000525695038959384
step: 380, loss: 0.0019107790431007743
step: 390, loss: 0.01006168033927679
step: 400, loss: 0.012542802840471268
step: 410, loss: 0.0016391545068472624
step: 420, loss: 0.0006819757982157171
step: 430, loss: 0.0008769934065639973
step: 440, loss: 0.006586247123777866
step: 450, loss: 0.013353059999644756
step: 460, loss: 0.012741546146571636
step: 470, loss: 0.07119383662939072
step: 480, loss: 0.020441904664039612
step: 490, loss: 0.011980957351624966
step: 500, loss: 0.0015876427059993148
step: 510, loss: 0.0011128620244562626
step: 520, loss: 0.007513023912906647
step: 530, loss: 0.00033600194728933275
step: 540, loss: 0.00821211189031601
step: 550, loss: 0.00039705695235170424
step: 560, loss: 0.00206601875834167
step: 570, loss: 0.0026150704361498356
step: 580, loss: 0.0006179442862048745
step: 590, loss: 0.0036049792543053627
step: 600, loss: 0.0034443496260792017
step: 610, loss: 0.005210138391703367
step: 620, loss: 0.006375270429998636
step: 630, loss: 0.0008532144711352885
step: 640, loss: 0.07712417095899582
step: 650, loss: 0.015701884403824806
step: 660, loss: 0.010698957368731499
step: 670, loss: 0.0013678866671398282
step: 680, loss: 0.005658828653395176
step: 690, loss: 0.01551651768386364
step: 700, loss: 0.0005295439623296261
step: 710, loss: 0.004991624504327774
step: 720, loss: 0.000505685864482075
step: 730, loss: 0.0001950550067704171
step: 740, loss: 0.0012638852931559086
step: 750, loss: 0.004671500530093908
step: 760, loss: 0.06895621120929718
step: 770, loss: 0.004795438144356012
step: 780, loss: 0.00436902791261673
step: 790, loss: 0.02811133861541748
step: 800, loss: 0.001934182713739574
step: 810, loss: 0.0056541310623288155
step: 820, loss: 0.00027746197883971035
step: 830, loss: 0.000734225322958082
step: 840, loss: 0.004942073952406645
step: 850, loss: 0.0010849720565602183
step: 860, loss: 0.003487068461254239
step: 870, loss: 0.0008802742813713849
step: 880, loss: 0.019813569262623787
step: 890, loss: 0.011474518105387688
step: 900, loss: 0.005506194196641445
step: 910, loss: 0.014284239150583744
step: 920, loss: 0.0005312648136168718
step: 930, loss: 0.008949045091867447
step: 940, loss: 0.004470465239137411
epoch 9: dev_f1=0.949041608228144, f1=0.9306930693069307, best_f1=0.9325789721829325
step: 0, loss: 0.00026693521067500114
step: 10, loss: 0.00013417037553153932
step: 20, loss: 0.0007976994966156781
step: 30, loss: 0.00014145344903226942
step: 40, loss: 0.02048662304878235
step: 50, loss: 0.0008069522446021438
step: 60, loss: 0.006213117390871048
step: 70, loss: 0.0069355433806777
step: 80, loss: 0.0019561632070690393
step: 90, loss: 0.0013487805845215917
step: 100, loss: 0.008901804685592651
step: 110, loss: 0.007070546969771385
step: 120, loss: 0.02303997613489628
step: 130, loss: 0.011214036494493484
step: 140, loss: 0.01673889346420765
step: 150, loss: 0.00016641667752992362
step: 160, loss: 0.00030408179736696184
step: 170, loss: 0.042943235486745834
step: 180, loss: 0.015090293250977993
step: 190, loss: 0.0034731237683445215
step: 200, loss: 0.0006893441313877702
step: 210, loss: 0.0012516084825620055
step: 220, loss: 0.001221949583850801
step: 230, loss: 0.001857672119513154
step: 240, loss: 0.00014331802958622575
step: 250, loss: 0.02019830420613289
step: 260, loss: 0.0001980747329071164
step: 270, loss: 0.0016774326795712113
step: 280, loss: 0.0002818556677084416
step: 290, loss: 0.00029224733589217067
step: 300, loss: 0.00023719866294413805
step: 310, loss: 0.0012411536881700158
step: 320, loss: 0.002063102088868618
step: 330, loss: 0.14366205036640167
step: 340, loss: 0.0003847164916805923
step: 350, loss: 0.0021448712795972824
step: 360, loss: 0.0008527928148396313
step: 370, loss: 0.0005529418704099953
step: 380, loss: 0.0005398484063334763
step: 390, loss: 0.001569744199514389
step: 400, loss: 0.00048603088362142444
step: 410, loss: 0.0009090402163565159
step: 420, loss: 0.13317671418190002
step: 430, loss: 0.009220779873430729
step: 440, loss: 0.007700364571064711
step: 450, loss: 0.03370006009936333
step: 460, loss: 0.0022557333577424288
step: 470, loss: 0.004616051912307739
step: 480, loss: 0.0010255016386508942
step: 490, loss: 0.00035512231988832355
step: 500, loss: 0.0013171815080568194
step: 510, loss: 0.00036406409344635904
step: 520, loss: 0.004902636632323265
step: 530, loss: 0.0001050116989063099
step: 540, loss: 0.00022584992984775454
step: 550, loss: 0.003553772810846567
step: 560, loss: 0.00012329895980656147
step: 570, loss: 0.004588908050209284
step: 580, loss: 0.000665374449454248
step: 590, loss: 0.0021167972590774298
step: 600, loss: 0.0006928569637238979
step: 610, loss: 0.1030135303735733
step: 620, loss: 4.9987167585641146e-05
step: 630, loss: 0.060489505529403687
step: 640, loss: 0.0006858380511403084
step: 650, loss: 9.054770634975284e-05
step: 660, loss: 0.020619012415409088
step: 670, loss: 0.0009632903966121376
step: 680, loss: 0.013594742864370346
step: 690, loss: 0.0003657844790723175
step: 700, loss: 0.015803799033164978
step: 710, loss: 0.07364623248577118
step: 720, loss: 0.0358429029583931
step: 730, loss: 0.0026745139621198177
step: 740, loss: 0.005649122875183821
step: 750, loss: 0.0011714493157342076
step: 760, loss: 0.0024488531053066254
step: 770, loss: 0.0018285054247826338
step: 780, loss: 0.00024032426881603897
step: 790, loss: 0.012874175794422626
step: 800, loss: 0.0005560177378356457
step: 810, loss: 0.00042627897346392274
step: 820, loss: 0.054697588086128235
step: 830, loss: 0.03423970937728882
step: 840, loss: 0.00469411863014102
step: 850, loss: 0.0003053153632208705
step: 860, loss: 0.0035828263498842716
step: 870, loss: 9.198700718116015e-05
step: 880, loss: 0.01480565033853054
step: 890, loss: 0.0014112896751612425
step: 900, loss: 0.0972876101732254
step: 910, loss: 0.0005853926413692534
step: 920, loss: 0.003209795570001006
step: 930, loss: 0.0019197697984054685
step: 940, loss: 0.003901176853105426
epoch 10: dev_f1=0.9485873089393237, f1=0.9296037296037295, best_f1=0.9325789721829325
step: 0, loss: 0.00013603655679617077
step: 10, loss: 0.00012633299047593027
step: 20, loss: 0.0003118863969575614
step: 30, loss: 0.030969465151429176
step: 40, loss: 0.0029224504251033068
step: 50, loss: 0.0021125273779034615
step: 60, loss: 0.0033190767280757427
step: 70, loss: 0.004444082733243704
step: 80, loss: 0.0016843148041516542
step: 90, loss: 0.0002523232833482325
step: 100, loss: 0.0005762873915955424
step: 110, loss: 0.0010377628495916724
step: 120, loss: 0.00015512463869526982
step: 130, loss: 0.01680832915008068
step: 140, loss: 0.00013325786858331412
step: 150, loss: 0.0020477401558309793
step: 160, loss: 0.0022528746630996466
step: 170, loss: 0.002569882431998849
step: 180, loss: 0.00013260316336527467
step: 190, loss: 0.008794027380645275
step: 200, loss: 0.015062324702739716
step: 210, loss: 0.0004954789765179157
step: 220, loss: 0.0012123242486268282
step: 230, loss: 0.1070694774389267
step: 240, loss: 0.0007006756495684385
step: 250, loss: 0.0047946046106517315
step: 260, loss: 0.0025226366706192493
step: 270, loss: 0.06293309479951859
step: 280, loss: 0.0008728668326511979
step: 290, loss: 0.0003645613614935428
step: 300, loss: 0.0005863973638042808
step: 310, loss: 0.0003177410108037293
step: 320, loss: 0.0007306284387595952
step: 330, loss: 0.01218660268932581
step: 340, loss: 0.040678877383470535
step: 350, loss: 0.0030981579329818487
step: 360, loss: 0.001053808955475688
step: 370, loss: 0.0013817765284329653
step: 380, loss: 0.11185213923454285
step: 390, loss: 0.02539324387907982
step: 400, loss: 0.00015373558562714607
step: 410, loss: 0.0020149920601397753
step: 420, loss: 0.017156878486275673
step: 430, loss: 0.0005629552761092782
step: 440, loss: 0.0006139251636341214
step: 450, loss: 0.006886721588671207
step: 460, loss: 0.001065526739694178
step: 470, loss: 0.00017584269517101347
step: 480, loss: 6.938829028513283e-05
step: 490, loss: 0.00042855675565078855
step: 500, loss: 0.0010016715386882424
step: 510, loss: 0.0035947144497185946
step: 520, loss: 0.0003231199807487428
step: 530, loss: 0.00038745958590880036
step: 540, loss: 0.028045380488038063
step: 550, loss: 0.0008000966045074165
step: 560, loss: 0.00041086203418672085
step: 570, loss: 0.00025745906168594956
step: 580, loss: 0.03171335905790329
step: 590, loss: 0.011641568504273891
step: 600, loss: 0.000582331616897136
step: 610, loss: 0.00012829234765376896
step: 620, loss: 0.0030070580542087555
step: 630, loss: 0.0002761016658041626
step: 640, loss: 0.0006729887682013214
step: 650, loss: 6.378952821251005e-05
step: 660, loss: 0.00023943778069224209
step: 670, loss: 0.00013575890625361353
step: 680, loss: 0.00034424688783474267
step: 690, loss: 0.0007866640808060765
step: 700, loss: 6.485563062597066e-05
step: 710, loss: 0.00012676625919993967
step: 720, loss: 0.000156889931531623
step: 730, loss: 0.003183291759341955
step: 740, loss: 0.004992510657757521
step: 750, loss: 0.0003884746110998094
step: 760, loss: 0.0011300191981717944
step: 770, loss: 0.0004913125885650516
step: 780, loss: 0.0004992351168766618
step: 790, loss: 0.012555777095258236
step: 800, loss: 0.00017434803885407746
step: 810, loss: 0.0008103850996121764
step: 820, loss: 0.00021945300977677107
step: 830, loss: 0.000277251994702965
step: 840, loss: 0.002385813044384122
step: 850, loss: 0.08242984116077423
step: 860, loss: 0.0031757450196892023
step: 870, loss: 0.00012409251939971
step: 880, loss: 0.0034922617487609386
step: 890, loss: 0.12093356251716614
step: 900, loss: 0.00092417246196419
step: 910, loss: 0.004047825001180172
step: 920, loss: 0.0006251698941923678
step: 930, loss: 0.013680404983460903
step: 940, loss: 0.0007705293246544898
epoch 11: dev_f1=0.9499766245909304, f1=0.9236569274269557, best_f1=0.9325789721829325
step: 0, loss: 0.001076132757589221
step: 10, loss: 0.006689804140478373
step: 20, loss: 0.009366457350552082
step: 30, loss: 0.0046988362446427345
step: 40, loss: 0.0008149836794473231
step: 50, loss: 0.0003720801614690572
step: 60, loss: 0.0008929418982006609
step: 70, loss: 0.0029054898768663406
step: 80, loss: 0.008551004342734814
step: 90, loss: 0.0003675846674013883
step: 100, loss: 0.0009949005907401443
step: 110, loss: 0.01188125554472208
step: 120, loss: 0.006146216299384832
step: 130, loss: 0.0015142251504585147
step: 140, loss: 9.710506856208667e-05
step: 150, loss: 0.0004734520916827023
step: 160, loss: 0.045541081577539444
step: 170, loss: 7.620736869284883e-05
step: 180, loss: 0.00014113429642748088
step: 190, loss: 0.0001639265683479607
step: 200, loss: 0.019814584404230118
step: 210, loss: 0.0005279126926325262
step: 220, loss: 0.04163563624024391
step: 230, loss: 0.0003315290668979287
step: 240, loss: 0.0004857908352278173
step: 250, loss: 0.0010373493423685431
step: 260, loss: 0.026179421693086624
step: 270, loss: 0.0010074330493807793
step: 280, loss: 0.03220662474632263
step: 290, loss: 0.005476699210703373
step: 300, loss: 0.0023097211960703135
step: 310, loss: 0.003324266290292144
step: 320, loss: 0.00029686157358810306
step: 330, loss: 0.0016971402801573277
step: 340, loss: 0.00014242972247302532
step: 350, loss: 0.0006468046922236681
step: 360, loss: 0.056550826877355576
step: 370, loss: 8.7051244918257e-05
step: 380, loss: 0.00019992094894405454
step: 390, loss: 0.00027850913465954363
step: 400, loss: 0.0014644168550148606
step: 410, loss: 0.01313770841807127
step: 420, loss: 0.0005207290523685515
step: 430, loss: 0.00010994596232194453
step: 440, loss: 0.20149639248847961
step: 450, loss: 0.0025883005000650883
step: 460, loss: 0.0014960429398342967
step: 470, loss: 0.0038448867853730917
step: 480, loss: 0.00036472847568802536
step: 490, loss: 0.0005504405125975609
step: 500, loss: 0.0003377394750714302
step: 510, loss: 0.0019309306517243385
step: 520, loss: 0.0006357862148433924
step: 530, loss: 0.009132860228419304
step: 540, loss: 0.00017833319725468755
step: 550, loss: 9.040423174155876e-05
step: 560, loss: 0.0003351789200678468
step: 570, loss: 0.0006486573838628829
step: 580, loss: 0.0002987190382555127
step: 590, loss: 0.00013600160309579223
step: 600, loss: 0.01832493208348751
step: 610, loss: 0.00037302402779459953
step: 620, loss: 0.00031856674468144774
step: 630, loss: 0.19905976951122284
step: 640, loss: 0.0012835824163630605
step: 650, loss: 0.0025596199557185173
step: 660, loss: 0.0006111931870691478
step: 670, loss: 0.03534989804029465
step: 680, loss: 0.009783106856048107
step: 690, loss: 0.012547497637569904
step: 700, loss: 0.00015881170111242682
step: 710, loss: 0.0011813596356660128
step: 720, loss: 0.034246183931827545
step: 730, loss: 0.0011643938487395644
step: 740, loss: 0.03696979954838753
step: 750, loss: 0.06323952227830887
step: 760, loss: 0.0024876846000552177
step: 770, loss: 0.05236129090189934
step: 780, loss: 0.02686190791428089
step: 790, loss: 0.023399386554956436
step: 800, loss: 0.00027667396352626383
step: 810, loss: 7.890468259574845e-05
step: 820, loss: 6.274801853578538e-05
step: 830, loss: 0.004798160400241613
step: 840, loss: 0.0003257212520111352
step: 850, loss: 0.02861369028687477
step: 860, loss: 0.0003803925064858049
step: 870, loss: 0.0012785483850166202
step: 880, loss: 0.0010443389182910323
step: 890, loss: 0.004508485551923513
step: 900, loss: 0.00033863011049106717
step: 910, loss: 5.2267696446506307e-05
step: 920, loss: 8.835374319460243e-05
step: 930, loss: 0.003689765464514494
step: 940, loss: 0.0003985430230386555
epoch 12: dev_f1=0.9444976076555024, f1=0.9188926663428849, best_f1=0.9325789721829325
step: 0, loss: 0.0003330370527692139
step: 10, loss: 0.0006845034076832235
step: 20, loss: 0.0006133571150712669
step: 30, loss: 0.00929628498852253
step: 40, loss: 0.00045574831892736256
step: 50, loss: 0.0007196514052338898
step: 60, loss: 0.00018286876729689538
step: 70, loss: 0.013633394613862038
step: 80, loss: 0.00026702246395871043
step: 90, loss: 0.09588555246591568
step: 100, loss: 0.0012718585785478354
step: 110, loss: 0.0008343895897269249
step: 120, loss: 0.0014303188072517514
step: 130, loss: 0.015017574653029442
step: 140, loss: 0.14559443295001984
step: 150, loss: 0.0006774592329747975
step: 160, loss: 0.023405971005558968
step: 170, loss: 0.0024183704517781734
step: 180, loss: 8.939881809055805e-05
step: 190, loss: 0.0012689161812886596
step: 200, loss: 0.018072087317705154
step: 210, loss: 0.0003304720448795706
step: 220, loss: 0.0029960700776427984
step: 230, loss: 0.0041739665903151035
step: 240, loss: 0.0007204213761724532
step: 250, loss: 0.0010050437413156033
step: 260, loss: 0.00033897123648785055
step: 270, loss: 0.00019895884906873107
step: 280, loss: 0.0008073459030129015
step: 290, loss: 0.007433929014950991
step: 300, loss: 0.0022286896128207445
step: 310, loss: 0.006084857974201441
step: 320, loss: 0.00179907470010221
step: 330, loss: 0.00016254992806352675
step: 340, loss: 0.0008285011281259358
step: 350, loss: 0.0006382756982930005
step: 360, loss: 0.00013405726349446923
step: 370, loss: 0.001604915247298777
step: 380, loss: 0.00011045663268305361
step: 390, loss: 0.038051024079322815
step: 400, loss: 0.0016219825483858585
step: 410, loss: 0.00046276868670247495
step: 420, loss: 8.092811913229525e-05
step: 430, loss: 0.002888890216127038
step: 440, loss: 0.018793538212776184
step: 450, loss: 0.0018881324212998152
step: 460, loss: 6.184267112985253e-05
step: 470, loss: 9.148479148279876e-05
step: 480, loss: 0.0006187225808389485
step: 490, loss: 0.00010379527520854026
step: 500, loss: 0.0027442341670393944
step: 510, loss: 0.0022873696871101856
step: 520, loss: 0.00012657945626415312
step: 530, loss: 0.002800457412377
step: 540, loss: 0.0004303783643990755
step: 550, loss: 0.0001834915456129238
step: 560, loss: 6.679333455394953e-05
step: 570, loss: 0.02936837449669838
step: 580, loss: 0.00036021240521222353
step: 590, loss: 0.01121568027883768
step: 600, loss: 0.0009363419376313686
step: 610, loss: 5.123914161231369e-05
step: 620, loss: 5.849984518135898e-05
step: 630, loss: 0.001291601569391787
step: 640, loss: 0.00010003324860008433
step: 650, loss: 0.0001532404130557552
step: 660, loss: 0.0004063544620294124
step: 670, loss: 0.0005575211253017187
step: 680, loss: 0.005550654139369726
step: 690, loss: 0.0003445798356551677
step: 700, loss: 0.0123355183750391
step: 710, loss: 5.97495527472347e-05
step: 720, loss: 0.00027507980121299624
step: 730, loss: 4.1348135709995404e-05
step: 740, loss: 0.0004783620242960751
step: 750, loss: 0.00020832587324548513
step: 760, loss: 0.0018916300032287836
step: 770, loss: 0.0007748753996565938
step: 780, loss: 0.0015312590403482318
step: 790, loss: 0.00030135485576465726
step: 800, loss: 0.00017965130973607302
step: 810, loss: 0.007129362318664789
step: 820, loss: 0.00010640119580784813
step: 830, loss: 0.0029223503079265356
step: 840, loss: 0.00023804744705557823
step: 850, loss: 0.05507851019501686
step: 860, loss: 0.00012525012425612658
step: 870, loss: 0.00215156190097332
step: 880, loss: 0.00021797631052322686
step: 890, loss: 0.0005020236130803823
step: 900, loss: 0.00014978167018853128
step: 910, loss: 7.378196460194886e-05
step: 920, loss: 0.0006233969470486045
step: 930, loss: 0.0003353917272761464
step: 940, loss: 0.000605982553679496
epoch 13: dev_f1=0.9470260223048327, f1=0.9273066169617894, best_f1=0.9325789721829325
step: 0, loss: 0.04193039983510971
step: 10, loss: 0.004279914777725935
step: 20, loss: 6.961257167859003e-05
step: 30, loss: 0.0004919389612041414
step: 40, loss: 0.00023547321325168014
step: 50, loss: 0.03447825461626053
step: 60, loss: 0.0027224645018577576
step: 70, loss: 7.9761550296098e-05
step: 80, loss: 0.0011329593835398555
step: 90, loss: 0.0043614949099719524
step: 100, loss: 0.00010428974928800017
step: 110, loss: 0.00019043362408410758
step: 120, loss: 0.00028234554338268936
step: 130, loss: 2.3677099306951277e-05
step: 140, loss: 0.00014775898307561874
step: 150, loss: 0.00030001963023096323
step: 160, loss: 0.0005788769922219217
step: 170, loss: 0.00020970444893464446
step: 180, loss: 0.0001333687687292695
step: 190, loss: 0.0001601151452632621
step: 200, loss: 0.010239660739898682
step: 210, loss: 0.00047498635831288993
step: 220, loss: 0.0006171666900627315
step: 230, loss: 0.05090409889817238
step: 240, loss: 0.0016036138404160738
step: 250, loss: 0.001697931787930429
step: 260, loss: 0.0014353016158565879
step: 270, loss: 0.003985240589827299
step: 280, loss: 0.0015627209795638919
step: 290, loss: 0.0005263693747110665
step: 300, loss: 0.0010371934622526169
step: 310, loss: 0.00028629982261918485
step: 320, loss: 0.00014919904060661793
step: 330, loss: 0.0008964305161498487
step: 340, loss: 0.0001446508540539071
step: 350, loss: 0.03386296331882477
step: 360, loss: 0.0003071788523811847
step: 370, loss: 0.0003667307028081268
step: 380, loss: 0.0538376122713089
step: 390, loss: 0.00590690691024065
step: 400, loss: 0.00029919276130385697
step: 410, loss: 0.0009116957080550492
step: 420, loss: 0.00014039607776794583
step: 430, loss: 0.00023308054369408637
step: 440, loss: 0.0007866236264817417
step: 450, loss: 0.0004645897133741528
step: 460, loss: 0.0004156419599894434
step: 470, loss: 0.0008514449000358582
step: 480, loss: 0.00021133507834747434
step: 490, loss: 0.00030334870098158717
step: 500, loss: 6.9633693783544e-05
step: 510, loss: 0.0003359782858751714
step: 520, loss: 0.002929887268692255
step: 530, loss: 0.000282199151115492
step: 540, loss: 0.00015854588127695024
step: 550, loss: 0.006265636533498764
step: 560, loss: 0.00012161494669271633
step: 570, loss: 0.0003008792700711638
step: 580, loss: 0.0019830933306366205
step: 590, loss: 0.0007274969830177724
step: 600, loss: 0.00034669009619392455
step: 610, loss: 6.170490087242797e-05
step: 620, loss: 0.017031336203217506
step: 630, loss: 0.09790485352277756
step: 640, loss: 0.004276594612747431
step: 650, loss: 0.00022220464597921818
step: 660, loss: 0.00010573185863904655
step: 670, loss: 0.0007712829392403364
step: 680, loss: 0.0008674208074808121
step: 690, loss: 0.00010223968274658546
step: 700, loss: 0.0003182936052326113
step: 710, loss: 0.0007057676557451487
step: 720, loss: 5.1289669499965385e-05
step: 730, loss: 0.00017426528211217374
step: 740, loss: 0.00044422378414310515
step: 750, loss: 0.00012995726137887686
step: 760, loss: 0.0002003760455409065
step: 770, loss: 0.00017760629998520017
step: 780, loss: 0.00017780682537704706
step: 790, loss: 0.0013177713844925165
step: 800, loss: 0.0008052228367887437
step: 810, loss: 0.005980389192700386
step: 820, loss: 0.0005724523798562586
step: 830, loss: 0.00017941056285053492
step: 840, loss: 0.01303755771368742
step: 850, loss: 0.04706662520766258
step: 860, loss: 0.0005720988847315311
step: 870, loss: 0.0021699490025639534
step: 880, loss: 0.00050456786993891
step: 890, loss: 6.204481906024739e-05
step: 900, loss: 0.0013066722312942147
step: 910, loss: 0.0026898658834397793
step: 920, loss: 0.01756451092660427
step: 930, loss: 0.0008793468587100506
step: 940, loss: 0.0008182176388800144
epoch 14: dev_f1=0.9436947417403444, f1=0.9283054003724395, best_f1=0.9325789721829325
step: 0, loss: 0.0008046022849157453
step: 10, loss: 0.006276508327573538
step: 20, loss: 5.6132306781364605e-05
step: 30, loss: 0.012173316441476345
step: 40, loss: 0.0004200004623271525
step: 50, loss: 9.542246698401868e-05
step: 60, loss: 0.0003050898085348308
step: 70, loss: 0.0001547993888380006
step: 80, loss: 5.326000973582268e-05
step: 90, loss: 0.00022699445253238082
step: 100, loss: 5.917677117395215e-05
step: 110, loss: 0.0029327566735446453
step: 120, loss: 0.00012043496099067852
step: 130, loss: 0.0037590113934129477
step: 140, loss: 0.0004738893767353147
step: 150, loss: 0.047525547444820404
step: 160, loss: 0.0008482622215524316
step: 170, loss: 0.0001702882582321763
step: 180, loss: 0.0005611455417238176
step: 190, loss: 0.011769099161028862
step: 200, loss: 6.638091872446239e-05
step: 210, loss: 8.330125274369493e-05
step: 220, loss: 0.00040602972148917615
step: 230, loss: 0.005319830030202866
step: 240, loss: 0.0014813966117799282
step: 250, loss: 0.021926522254943848
step: 260, loss: 0.00013337891141418368
step: 270, loss: 3.4282133128726855e-05
step: 280, loss: 0.09595786780118942
step: 290, loss: 0.0026915522757917643
step: 300, loss: 0.0001555412745801732
step: 310, loss: 0.00015985945356078446
step: 320, loss: 0.0007430269033648074
step: 330, loss: 0.0004221024864818901
step: 340, loss: 0.01995737850666046
step: 350, loss: 0.002406202955171466
step: 360, loss: 0.0019962775986641645
step: 370, loss: 0.02634786069393158
step: 380, loss: 0.00015414370864164084
step: 390, loss: 0.00011125393211841583
step: 400, loss: 0.000953430833760649
step: 410, loss: 0.00011682978220051154
step: 420, loss: 0.0039532361552119255
step: 430, loss: 0.0014992414508014917
step: 440, loss: 0.00011507308954605833
step: 450, loss: 0.00038256257539615035
step: 460, loss: 0.009656942449510098
step: 470, loss: 5.1023838750552386e-05
step: 480, loss: 0.006275497376918793
step: 490, loss: 5.8846162573900074e-05
step: 500, loss: 0.00013811839744448662
step: 510, loss: 0.04403597116470337
step: 520, loss: 5.117736873216927e-05
step: 530, loss: 0.0005414382903836668
step: 540, loss: 0.00011176255065947771
step: 550, loss: 0.00012475426774471998
step: 560, loss: 0.00010408968228148296
step: 570, loss: 7.520774670410901e-05
step: 580, loss: 0.0035895886830985546
step: 590, loss: 0.007147488184273243
step: 600, loss: 0.003723863046616316
step: 610, loss: 0.004889500327408314
step: 620, loss: 0.01869625598192215
step: 630, loss: 0.0002448346931487322
step: 640, loss: 0.000627364672254771
step: 650, loss: 5.7504621508996934e-05
step: 660, loss: 0.0033392782788723707
step: 670, loss: 6.932736141607165e-05
step: 680, loss: 0.00016303856682498008
step: 690, loss: 0.00010261452553095296
step: 700, loss: 0.00446044746786356
step: 710, loss: 0.00022043415810912848
step: 720, loss: 0.0024637412279844284
step: 730, loss: 0.0009848688496276736
step: 740, loss: 0.0005932933418080211
step: 750, loss: 0.00018137259758077562
step: 760, loss: 0.0010860480833798647
step: 770, loss: 0.00011784308298956603
step: 780, loss: 0.018810100853443146
step: 790, loss: 7.019635086180642e-05
step: 800, loss: 0.00043964930227957666
step: 810, loss: 0.00018234376329928637
step: 820, loss: 0.0028551712166517973
step: 830, loss: 0.014767429791390896
step: 840, loss: 0.0001007241226034239
step: 850, loss: 0.0001440210035070777
step: 860, loss: 0.0012372573837637901
step: 870, loss: 0.00025142868980765343
step: 880, loss: 3.504582855384797e-05
step: 890, loss: 0.0016996918711811304
step: 900, loss: 8.792595326667652e-05
step: 910, loss: 0.027722692117094994
step: 920, loss: 0.0008321290370076895
step: 930, loss: 0.0002386047999607399
step: 940, loss: 0.00010090736031997949
epoch 15: dev_f1=0.9478060046189377, f1=0.9281767955801105, best_f1=0.9325789721829325
step: 0, loss: 0.0001027661346597597
step: 10, loss: 0.00024409510660916567
step: 20, loss: 0.0003388242912478745
step: 30, loss: 0.0001918868802022189
step: 40, loss: 0.00024684463278390467
step: 50, loss: 0.009743567556142807
step: 60, loss: 0.00011442411778261885
step: 70, loss: 0.0008771911961957812
step: 80, loss: 0.00017237763677258044
step: 90, loss: 0.0010247688041999936
step: 100, loss: 2.037682497757487e-05
step: 110, loss: 0.0006160668563097715
step: 120, loss: 0.010828565806150436
step: 130, loss: 9.266003326047212e-05
step: 140, loss: 0.056685175746679306
step: 150, loss: 0.0003657451889012009
step: 160, loss: 0.0002750759304035455
step: 170, loss: 3.327590093249455e-05
step: 180, loss: 3.976793595938943e-05
step: 190, loss: 4.507088306127116e-05
step: 200, loss: 0.00010119064972968772
step: 210, loss: 4.805815842701122e-05
step: 220, loss: 0.0730930045247078
step: 230, loss: 0.0006703838589601219
step: 240, loss: 7.896997703937814e-05
step: 250, loss: 5.474515273817815e-05
step: 260, loss: 0.0011616457486525178
step: 270, loss: 0.0011215491686016321
step: 280, loss: 0.0033395295031368732
step: 290, loss: 0.00032668138737790287
step: 300, loss: 0.00236978055909276
step: 310, loss: 0.00010221407865174115
step: 320, loss: 7.290704525075853e-05
step: 330, loss: 0.00020774970471393317
step: 340, loss: 0.00017822904919739813
step: 350, loss: 0.000205389762413688
step: 360, loss: 8.964394510257989e-05
step: 370, loss: 0.0008270786493085325
step: 380, loss: 0.0003242967068217695
step: 390, loss: 5.896517541259527e-05
step: 400, loss: 0.00036943142185918987
step: 410, loss: 0.00012586309458129108
step: 420, loss: 5.0751332310028374e-05
step: 430, loss: 0.0032521262764930725
step: 440, loss: 0.014812535606324673
step: 450, loss: 0.001047024386934936
step: 460, loss: 0.0002474175416864455
step: 470, loss: 0.016373813152313232
step: 480, loss: 0.00015065172920003533
step: 490, loss: 2.788934580166824e-05
step: 500, loss: 0.017347212880849838
step: 510, loss: 0.00033750562579371035
step: 520, loss: 8.204059849958867e-05
step: 530, loss: 0.0007323997560888529
step: 540, loss: 0.0001746772468322888
step: 550, loss: 4.844885552302003e-05
step: 560, loss: 8.208784856833518e-05
step: 570, loss: 4.640301995095797e-05
step: 580, loss: 0.00011933995119761676
step: 590, loss: 0.0009270504233427346
step: 600, loss: 0.0013845291687175632
step: 610, loss: 0.004044673405587673
step: 620, loss: 0.00012322831025812775
step: 630, loss: 9.351017797598615e-05
step: 640, loss: 7.6657859608531e-05
step: 650, loss: 2.0876059352303855e-05
step: 660, loss: 0.00010024395305663347
step: 670, loss: 0.00014945020666345954
step: 680, loss: 0.0008344603120349348
step: 690, loss: 0.0003083195770159364
step: 700, loss: 0.022200021892786026
step: 710, loss: 6.698287324979901e-05
step: 720, loss: 0.02110157161951065
step: 730, loss: 2.7253234293311834e-05
step: 740, loss: 0.00021852132340427488
step: 750, loss: 9.261676314054057e-05
step: 760, loss: 0.00033080807770602405
step: 770, loss: 0.00017321587074548006
step: 780, loss: 5.60782864340581e-05
step: 790, loss: 0.0001253869995707646
step: 800, loss: 0.052263397723436356
step: 810, loss: 0.0002510538324713707
step: 820, loss: 0.010181393474340439
step: 830, loss: 0.000745949859265238
step: 840, loss: 3.81483587261755e-05
step: 850, loss: 3.182341606589034e-05
step: 860, loss: 0.013302173465490341
step: 870, loss: 0.00028205037233419716
step: 880, loss: 5.678190791513771e-05
step: 890, loss: 3.7733341741841286e-05
step: 900, loss: 0.0012776589719578624
step: 910, loss: 8.574624371249229e-05
step: 920, loss: 0.0002742694632615894
step: 930, loss: 0.004541595932096243
step: 940, loss: 0.0009003168670460582
epoch 16: dev_f1=0.9493258949325895, f1=0.9265116279069768, best_f1=0.9325789721829325
step: 0, loss: 0.0005782122607342899
step: 10, loss: 3.833823211607523e-05
step: 20, loss: 0.0003148158430121839
step: 30, loss: 2.504639451217372e-05
step: 40, loss: 0.00012347838492132723
step: 50, loss: 5.513638097909279e-05
step: 60, loss: 0.001507745822891593
step: 70, loss: 0.0008334565791301429
step: 80, loss: 0.0002912426716648042
step: 90, loss: 5.995093670208007e-05
step: 100, loss: 4.855926090385765e-05
step: 110, loss: 3.6057823308510706e-05
step: 120, loss: 0.0001444602239644155
step: 130, loss: 0.0007919254130683839
step: 140, loss: 8.164667815435678e-05
step: 150, loss: 6.419362762244418e-05
step: 160, loss: 0.005223724991083145
step: 170, loss: 7.678449037484825e-05
step: 180, loss: 0.00020797627803403884
step: 190, loss: 0.00216557621024549
step: 200, loss: 5.01602771691978e-05
step: 210, loss: 0.00033496992546133697
step: 220, loss: 6.451577064581215e-05
step: 230, loss: 0.001865397789515555
step: 240, loss: 9.906218474498019e-05
step: 250, loss: 0.01224234327673912
step: 260, loss: 3.727623698068783e-05
step: 270, loss: 0.0005155703984200954
step: 280, loss: 4.0741007978795096e-05
step: 290, loss: 0.0001355031708953902
step: 300, loss: 0.00019009897368960083
step: 310, loss: 0.00390636594966054
step: 320, loss: 8.087201422313228e-05
step: 330, loss: 4.871450437349267e-05
step: 340, loss: 3.362520146765746e-05
step: 350, loss: 0.0007952125160954893
step: 360, loss: 9.527161455480382e-05
step: 370, loss: 0.00034774839878082275
step: 380, loss: 8.296973101096228e-05
step: 390, loss: 0.0006438976852223277
step: 400, loss: 0.00011518751125549898
step: 410, loss: 0.00021140938042663038
step: 420, loss: 0.0018381605623289943
step: 430, loss: 0.00012610582052730024
step: 440, loss: 0.002977413823828101
step: 450, loss: 3.091450344072655e-05
step: 460, loss: 0.0004656988603528589
step: 470, loss: 3.329974424559623e-05
step: 480, loss: 4.981220263289288e-05
step: 490, loss: 0.005200235638767481
step: 500, loss: 0.0001619638060219586
step: 510, loss: 0.00026051554596051574
step: 520, loss: 0.00013631086039822549
step: 530, loss: 0.000820130982901901
step: 540, loss: 2.8269709218875505e-05
step: 550, loss: 6.42246232018806e-05
step: 560, loss: 2.2164535039337352e-05
step: 570, loss: 0.08167722076177597
step: 580, loss: 0.025564953684806824
step: 590, loss: 4.8765014071250334e-05
step: 600, loss: 0.0005816996563225985
step: 610, loss: 4.72078645543661e-05
step: 620, loss: 0.0003583849756978452
step: 630, loss: 0.0001895906898425892
step: 640, loss: 0.0001027407924993895
step: 650, loss: 0.0011395434848964214
step: 660, loss: 7.784893386997283e-05
step: 670, loss: 7.29229359421879e-05
step: 680, loss: 4.99869383929763e-05
step: 690, loss: 0.0003139801847282797
step: 700, loss: 0.0005218538572080433
step: 710, loss: 0.00037754015647806227
step: 720, loss: 0.00017523400310892612
step: 730, loss: 0.04404016211628914
step: 740, loss: 0.0001420717453584075
step: 750, loss: 0.0001204347427119501
step: 760, loss: 8.490985055686906e-05
step: 770, loss: 4.338022699812427e-05
step: 780, loss: 9.932043758453801e-05
step: 790, loss: 6.933377153472975e-05
step: 800, loss: 0.0009063454926945269
step: 810, loss: 0.00020657219283748418
step: 820, loss: 3.840164208668284e-05
step: 830, loss: 3.22279374813661e-05
step: 840, loss: 5.576010516961105e-05
step: 850, loss: 4.8780024371808395e-05
step: 860, loss: 2.767755177046638e-05
step: 870, loss: 0.00026735011488199234
step: 880, loss: 1.913640517159365e-05
step: 890, loss: 3.597362956497818e-05
step: 900, loss: 9.18268779059872e-05
step: 910, loss: 0.0010054389713332057
step: 920, loss: 9.383313590660691e-05
step: 930, loss: 0.00010241607378702611
step: 940, loss: 0.0001928122655954212
epoch 17: dev_f1=0.943342776203966, f1=0.9165876777251185, best_f1=0.9325789721829325
step: 0, loss: 0.027512142434716225
step: 10, loss: 7.893995643826202e-05
step: 20, loss: 3.996930172434077e-05
step: 30, loss: 0.0012787875020876527
step: 40, loss: 0.00023877031344454736
step: 50, loss: 0.00026449316646903753
step: 60, loss: 0.00035639977431856096
step: 70, loss: 3.2613530493108556e-05
step: 80, loss: 9.87226449069567e-05
step: 90, loss: 0.011154488660395145
step: 100, loss: 0.00022912220447324216
step: 110, loss: 0.00027759396471083164
step: 120, loss: 0.00012937061546836048
step: 130, loss: 0.000135508700623177
step: 140, loss: 4.8784000682644546e-05
step: 150, loss: 0.002682277001440525
step: 160, loss: 5.070736006018706e-05
step: 170, loss: 4.428210013429634e-05
step: 180, loss: 6.733095506206155e-05
step: 190, loss: 3.381591523066163e-05
step: 200, loss: 0.04182200878858566
step: 210, loss: 2.4381284674745984e-05
step: 220, loss: 3.91985522583127e-05
step: 230, loss: 0.00022657311637885869
step: 240, loss: 0.0026044114492833614
step: 250, loss: 0.0012083787005394697
step: 260, loss: 9.991352999350056e-05
step: 270, loss: 0.0005587340565398335
step: 280, loss: 0.0023186509497463703
step: 290, loss: 0.0024363903794437647
step: 300, loss: 3.893535540555604e-05
step: 310, loss: 5.028257146477699e-05
step: 320, loss: 3.485402339720167e-05
step: 330, loss: 6.855733954580501e-05
step: 340, loss: 0.0011488244635984302
step: 350, loss: 6.0845162806799635e-05
step: 360, loss: 8.566872566007078e-05
step: 370, loss: 0.00012142982450313866
step: 380, loss: 9.168091492028907e-05
step: 390, loss: 2.1498117348528467e-05
step: 400, loss: 0.000292877055471763
step: 410, loss: 0.0002757552429102361
step: 420, loss: 8.286014781333506e-05
step: 430, loss: 4.387776061776094e-05
step: 440, loss: 3.7921217881375924e-05
step: 450, loss: 0.007559638004750013
step: 460, loss: 0.00025176198687404394
step: 470, loss: 0.0009082994656637311
step: 480, loss: 0.0007369359373115003
step: 490, loss: 0.00013327640772331506
step: 500, loss: 0.0007921797223389149
step: 510, loss: 0.0008430978050455451
step: 520, loss: 2.6322177291149274e-05
step: 530, loss: 5.9892401623073965e-05
step: 540, loss: 0.0001415356673533097
step: 550, loss: 0.00860503688454628
step: 560, loss: 0.0002675307623576373
step: 570, loss: 2.183336255257018e-05
step: 580, loss: 9.646444232203066e-05
step: 590, loss: 0.0006780853727832437
step: 600, loss: 7.844351057428867e-05
step: 610, loss: 0.000519481603987515
step: 620, loss: 2.6932466425932944e-05
step: 630, loss: 4.4753298425348476e-05
step: 640, loss: 7.420377369271591e-05
step: 650, loss: 0.00010872325219679624
step: 660, loss: 0.033249381929636
step: 670, loss: 7.507856207666919e-05
step: 680, loss: 0.0006618868792429566
step: 690, loss: 3.979727262048982e-05
step: 700, loss: 3.0653543944936246e-05
step: 710, loss: 0.0016208481974899769
step: 720, loss: 0.000119015559903346
step: 730, loss: 5.944440999883227e-05
step: 740, loss: 0.00035964124253951013
step: 750, loss: 0.000129305015434511
step: 760, loss: 0.0019141017692163587
step: 770, loss: 3.719382220879197e-05
step: 780, loss: 7.203146378742531e-05
step: 790, loss: 0.000154963752720505
step: 800, loss: 1.5392626664834097e-05
step: 810, loss: 0.00030432228231802583
step: 820, loss: 0.18530011177062988
step: 830, loss: 6.228832353372127e-05
step: 840, loss: 4.510634607868269e-05
step: 850, loss: 0.001852936577051878
step: 860, loss: 0.0009078403236344457
step: 870, loss: 0.0004734491230919957
step: 880, loss: 0.000442678079707548
step: 890, loss: 0.00017160885909106582
step: 900, loss: 0.008803918026387691
step: 910, loss: 4.50252991868183e-05
step: 920, loss: 0.006844825576990843
step: 930, loss: 0.0002737035683821887
step: 940, loss: 0.0009324540733359754
epoch 18: dev_f1=0.9454209065679925, f1=0.9306839186691312, best_f1=0.9325789721829325
step: 0, loss: 0.004574210848659277
step: 10, loss: 0.009111510589718819
step: 20, loss: 5.712903293897398e-05
step: 30, loss: 0.0003617465263232589
step: 40, loss: 0.0002165713522117585
step: 50, loss: 0.00024194570141844451
step: 60, loss: 0.018505079671740532
step: 70, loss: 0.0002200414310209453
step: 80, loss: 5.4926549637457356e-05
step: 90, loss: 0.0002053581119980663
step: 100, loss: 0.06151755154132843
step: 110, loss: 1.8540386008680798e-05
step: 120, loss: 0.0002845203271135688
step: 130, loss: 0.014037812128663063
step: 140, loss: 0.012850652448832989
step: 150, loss: 0.0012972718104720116
step: 160, loss: 4.32019260188099e-05
step: 170, loss: 0.00025373644893988967
step: 180, loss: 0.0032239232677966356
step: 190, loss: 3.116780862910673e-05
step: 200, loss: 0.0009971916442736983
step: 210, loss: 0.00014481565449386835
step: 220, loss: 0.00014462167746387422
step: 230, loss: 6.915350240888074e-05
step: 240, loss: 0.0010418434394523501
step: 250, loss: 0.0007694525411352515
step: 260, loss: 0.02915125899016857
step: 270, loss: 4.291861114325002e-05
step: 280, loss: 3.339556133141741e-05
step: 290, loss: 2.4980749003589153e-05
step: 300, loss: 6.908470822963864e-05
step: 310, loss: 4.4527761929202825e-05
step: 320, loss: 2.9845323297195137e-05
step: 330, loss: 5.1984618039568886e-05
step: 340, loss: 0.00014040159294381738
step: 350, loss: 0.00014735049626324326
step: 360, loss: 6.681001104880124e-05
step: 370, loss: 8.467165025649592e-05
step: 380, loss: 6.411344656953588e-05
step: 390, loss: 7.139573426684365e-05
step: 400, loss: 6.76832496537827e-05
step: 410, loss: 3.156644743285142e-05
step: 420, loss: 5.906314618187025e-05
step: 430, loss: 6.422895239666104e-05
step: 440, loss: 0.00021624172222800553
step: 450, loss: 0.0021729397121816874
step: 460, loss: 6.372395728249103e-05
step: 470, loss: 3.5273184039397165e-05
step: 480, loss: 0.002745554316788912
step: 490, loss: 0.00020829543063882738
step: 500, loss: 6.119824683992192e-05
step: 510, loss: 4.9866044719237834e-05
step: 520, loss: 0.00014439654478337616
step: 530, loss: 6.655770994257182e-05
step: 540, loss: 0.0003267905558459461
step: 550, loss: 0.0007745928596705198
step: 560, loss: 3.317889786558226e-05
step: 570, loss: 3.570979242795147e-05
step: 580, loss: 0.00020602279982995242
step: 590, loss: 5.6036176829366013e-05
step: 600, loss: 0.004689747001975775
step: 610, loss: 1.6882753698155284e-05
step: 620, loss: 7.382674812106416e-05
step: 630, loss: 4.616507067112252e-05
step: 640, loss: 0.036283690482378006
step: 650, loss: 3.615495370468125e-05
step: 660, loss: 4.501071816775948e-05
step: 670, loss: 2.2716052626492456e-05
step: 680, loss: 1.908428021124564e-05
step: 690, loss: 0.00027407167362980545
step: 700, loss: 0.023669550195336342
step: 710, loss: 0.00013318390119820833
step: 720, loss: 8.351154974661767e-05
step: 730, loss: 9.078965376829728e-05
step: 740, loss: 5.512390271178447e-05
step: 750, loss: 5.029350722907111e-05
step: 760, loss: 0.0002181188901886344
step: 770, loss: 0.0009906274499371648
step: 780, loss: 7.708423800067976e-05
step: 790, loss: 2.7051341021433473e-05
step: 800, loss: 3.417983680265024e-05
step: 810, loss: 0.00039154235855676234
step: 820, loss: 0.00010075973113998771
step: 830, loss: 6.836828833911568e-05
step: 840, loss: 0.0007320902077481151
step: 850, loss: 0.009411465376615524
step: 860, loss: 0.005309079773724079
step: 870, loss: 3.6702938814414665e-05
step: 880, loss: 0.000535244180355221
step: 890, loss: 3.4807901101885363e-05
step: 900, loss: 0.0002458175003994256
step: 910, loss: 0.002643387299031019
step: 920, loss: 4.189522223896347e-05
step: 930, loss: 0.005491398274898529
step: 940, loss: 0.001553690410219133
epoch 19: dev_f1=0.9471733086190918, f1=0.9291994447015272, best_f1=0.9325789721829325
step: 0, loss: 0.0011603725142776966
step: 10, loss: 0.0018894841196015477
step: 20, loss: 0.00019309681374579668
step: 30, loss: 6.879712600493804e-05
step: 40, loss: 7.590726454509422e-05
step: 50, loss: 0.00044738451833836734
step: 60, loss: 1.8573902707430534e-05
step: 70, loss: 0.006990350317209959
step: 80, loss: 1.5169210200838279e-05
step: 90, loss: 5.174495163373649e-05
step: 100, loss: 4.102290404262021e-05
step: 110, loss: 2.0592780856532045e-05
step: 120, loss: 5.28262353327591e-05
step: 130, loss: 0.00014718525926582515
step: 140, loss: 0.00019415402493905276
step: 150, loss: 0.0004090290458407253
step: 160, loss: 9.924682672135532e-05
step: 170, loss: 0.00010663935245247558
step: 180, loss: 0.00011083107528975233
step: 190, loss: 0.0006376697565428913
step: 200, loss: 3.859205753542483e-05
step: 210, loss: 0.0013575780903920531
step: 220, loss: 0.003159782150760293
step: 230, loss: 0.022332867607474327
step: 240, loss: 5.061448973719962e-05
step: 250, loss: 3.2039832149166614e-05
step: 260, loss: 5.835726915393025e-05
step: 270, loss: 7.667012687306851e-05
step: 280, loss: 0.00023808469995856285
step: 290, loss: 0.00699338736012578
step: 300, loss: 0.00012693688040599227
step: 310, loss: 3.6195961001794785e-05
step: 320, loss: 2.2179789084475487e-05
step: 330, loss: 3.511170871206559e-05
step: 340, loss: 6.469206709880382e-05
step: 350, loss: 0.000857601233292371
step: 360, loss: 0.0005819148500449955
step: 370, loss: 1.780644743121229e-05
step: 380, loss: 0.13905055820941925
step: 390, loss: 0.00014896379434503615
step: 400, loss: 5.9902271459577605e-05
step: 410, loss: 0.00038065691478550434
step: 420, loss: 0.00012534427514765412
step: 430, loss: 9.725004201754928e-05
step: 440, loss: 0.01057935319840908
step: 450, loss: 3.3286880352534354e-05
step: 460, loss: 0.00034650246379897
step: 470, loss: 0.00021664913219865412
step: 480, loss: 3.373011713847518e-05
step: 490, loss: 6.638783088419586e-05
step: 500, loss: 0.00019940201309509575
step: 510, loss: 2.3595363018102944e-05
step: 520, loss: 0.006117148324847221
step: 530, loss: 4.090667425771244e-05
step: 540, loss: 9.542610496282578e-05
step: 550, loss: 6.098681114963256e-05
step: 560, loss: 2.6492218239582144e-05
step: 570, loss: 0.00011278253077762201
step: 580, loss: 9.335287904832512e-05
step: 590, loss: 0.00016930791025515646
step: 600, loss: 5.7495675719110295e-05
step: 610, loss: 2.1654594092979096e-05
step: 620, loss: 5.769572453573346e-05
step: 630, loss: 0.0002463072305545211
step: 640, loss: 3.9231061236932874e-05
step: 650, loss: 0.0009846080793067813
step: 660, loss: 5.890483589610085e-05
step: 670, loss: 0.00024743235553614795
step: 680, loss: 4.436763992998749e-05
step: 690, loss: 3.520826794556342e-05
step: 700, loss: 0.00012966181384399533
step: 710, loss: 5.479494939208962e-05
step: 720, loss: 0.001289411447942257
step: 730, loss: 0.0008875897037796676
step: 740, loss: 3.279538213973865e-05
step: 750, loss: 2.7494719688547775e-05
step: 760, loss: 0.012608373537659645
step: 770, loss: 3.132106576231308e-05
step: 780, loss: 0.0001790413080016151
step: 790, loss: 0.0029497842770069838
step: 800, loss: 3.5067208955297247e-05
step: 810, loss: 4.0286158764502034e-05
step: 820, loss: 2.5208122679032385e-05
step: 830, loss: 0.0001741447049425915
step: 840, loss: 0.00010205509170191363
step: 850, loss: 0.0001204652144224383
step: 860, loss: 4.596956932800822e-05
step: 870, loss: 6.510081584565341e-05
step: 880, loss: 2.3430913643096574e-05
step: 890, loss: 0.0003104823699686676
step: 900, loss: 4.3288244341965765e-05
step: 910, loss: 2.5054296202142723e-05
step: 920, loss: 6.791555642848834e-05
step: 930, loss: 0.00014807586558163166
step: 940, loss: 3.1324576411861926e-05
epoch 20: dev_f1=0.9485396383866481, f1=0.9302325581395349, best_f1=0.9325789721829325
