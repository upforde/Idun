cuda
Device: cuda
step: 0, loss: 0.7237586975097656
step: 10, loss: 0.46767187118530273
step: 20, loss: 0.4286526143550873
step: 30, loss: 0.42233020067214966
step: 40, loss: 0.5699118375778198
step: 50, loss: 0.4427841305732727
step: 60, loss: 0.5567967891693115
step: 70, loss: 0.42819732427597046
step: 80, loss: 0.35148510336875916
step: 90, loss: 0.1562735140323639
step: 100, loss: 0.47684621810913086
step: 110, loss: 0.29064756631851196
step: 120, loss: 0.2991737723350525
step: 130, loss: 0.2384178787469864
step: 140, loss: 0.24158716201782227
step: 150, loss: 0.24580183625221252
step: 160, loss: 0.27599355578422546
step: 170, loss: 0.5067307949066162
step: 180, loss: 0.2755575180053711
step: 190, loss: 0.12263377010822296
step: 200, loss: 0.22230073809623718
step: 210, loss: 0.2939228415489197
step: 220, loss: 0.31290900707244873
step: 230, loss: 0.2655678689479828
step: 240, loss: 0.22552525997161865
step: 250, loss: 0.647393524646759
step: 260, loss: 0.30993136763572693
step: 270, loss: 0.3397971987724304
step: 280, loss: 0.3774205148220062
step: 290, loss: 0.2985658049583435
step: 300, loss: 0.3286769390106201
step: 310, loss: 0.18520866334438324
step: 320, loss: 0.17845240235328674
step: 330, loss: 0.13049092888832092
step: 340, loss: 0.2791709899902344
step: 350, loss: 0.2891227602958679
step: 360, loss: 0.14928358793258667
step: 370, loss: 0.11204875260591507
step: 380, loss: 0.08823655545711517
step: 390, loss: 0.2870244085788727
step: 400, loss: 0.15119187533855438
step: 410, loss: 0.23814421892166138
step: 420, loss: 0.20222489535808563
step: 430, loss: 0.07346969097852707
step: 440, loss: 0.18107163906097412
step: 450, loss: 0.17025350034236908
step: 460, loss: 0.19760912656784058
step: 470, loss: 0.48183926939964294
step: 480, loss: 0.39194002747535706
step: 490, loss: 0.2632032632827759
step: 500, loss: 0.24822473526000977
step: 510, loss: 0.36529025435447693
step: 520, loss: 0.20282593369483948
step: 530, loss: 0.3636873960494995
step: 540, loss: 0.14623692631721497
step: 550, loss: 0.17614933848381042
step: 560, loss: 0.08745890855789185
step: 570, loss: 0.23153017461299896
step: 580, loss: 0.20230543613433838
step: 590, loss: 0.210478276014328
step: 600, loss: 0.20255501568317413
step: 610, loss: 0.14758802950382233
step: 620, loss: 0.22584880888462067
step: 630, loss: 0.14284385740756989
step: 640, loss: 0.3816315829753876
step: 650, loss: 0.12410876154899597
step: 660, loss: 0.13641013205051422
step: 670, loss: 0.22005824744701385
step: 680, loss: 0.1290593445301056
step: 690, loss: 0.2149306833744049
step: 700, loss: 0.3830300569534302
step: 710, loss: 0.41283705830574036
step: 720, loss: 0.151993066072464
step: 730, loss: 0.17830969393253326
step: 740, loss: 0.40997833013534546
step: 750, loss: 0.06112571805715561
step: 760, loss: 0.4507736563682556
step: 770, loss: 0.09120623767375946
step: 780, loss: 0.11961334198713303
step: 790, loss: 0.35683363676071167
step: 800, loss: 0.19609807431697845
step: 810, loss: 0.24511347711086273
step: 820, loss: 0.2229900062084198
step: 830, loss: 0.1611699014902115
step: 840, loss: 0.15342727303504944
step: 850, loss: 0.20773917436599731
step: 860, loss: 0.09753517061471939
step: 870, loss: 0.3576950430870056
step: 880, loss: 0.34676632285118103
step: 890, loss: 0.305078387260437
step: 900, loss: 0.3243630528450012
step: 910, loss: 0.11456330865621567
step: 920, loss: 0.1665220707654953
step: 930, loss: 0.24830131232738495
step: 940, loss: 0.14814598858356476
step: 950, loss: 0.185637965798378
step: 960, loss: 0.0447893962264061
step: 970, loss: 0.215755432844162
step: 980, loss: 0.18224339187145233
step: 990, loss: 0.2757956385612488
step: 1000, loss: 0.13036364316940308
step: 1010, loss: 0.31395286321640015
step: 1020, loss: 0.13173212110996246
step: 1030, loss: 0.30531346797943115
epoch 1: dev_f1=0.9395910780669144, f1=0.9248120300751881, best_f1=0.9248120300751881
step: 0, loss: 0.08618057519197464
step: 10, loss: 0.09413506090641022
step: 20, loss: 0.11286330223083496
step: 30, loss: 0.06479649990797043
step: 40, loss: 0.39330706000328064
step: 50, loss: 0.20017312467098236
step: 60, loss: 0.04036600887775421
step: 70, loss: 0.06481360644102097
step: 80, loss: 0.19722449779510498
step: 90, loss: 0.0663594976067543
step: 100, loss: 0.10968642681837082
step: 110, loss: 0.05398613214492798
step: 120, loss: 0.08097033947706223
step: 130, loss: 0.32287630438804626
step: 140, loss: 0.12743604183197021
step: 150, loss: 0.2010234147310257
step: 160, loss: 0.07298850268125534
step: 170, loss: 0.11383207887411118
step: 180, loss: 0.1050492599606514
step: 190, loss: 0.1390918791294098
step: 200, loss: 0.1596277356147766
step: 210, loss: 0.15407943725585938
step: 220, loss: 0.3499978184700012
step: 230, loss: 0.03823164477944374
step: 240, loss: 0.17171774804592133
step: 250, loss: 0.02853570692241192
step: 260, loss: 0.22616149485111237
step: 270, loss: 0.1569993793964386
step: 280, loss: 0.12292571365833282
step: 290, loss: 0.14155782759189606
step: 300, loss: 0.10840602964162827
step: 310, loss: 0.2258497029542923
step: 320, loss: 0.041168760508298874
step: 330, loss: 0.06440072506666183
step: 340, loss: 0.12511101365089417
step: 350, loss: 0.13160333037376404
step: 360, loss: 0.22595231235027313
step: 370, loss: 0.34859538078308105
step: 380, loss: 0.15546604990959167
step: 390, loss: 0.0867123082280159
step: 400, loss: 0.19821226596832275
step: 410, loss: 0.03072196990251541
step: 420, loss: 0.19064871966838837
step: 430, loss: 0.238836869597435
step: 440, loss: 0.28750988841056824
step: 450, loss: 0.15004487335681915
step: 460, loss: 0.2271089106798172
step: 470, loss: 0.18323029577732086
step: 480, loss: 0.11177925020456314
step: 490, loss: 0.15340635180473328
step: 500, loss: 0.090945303440094
step: 510, loss: 0.20799390971660614
step: 520, loss: 0.08427800238132477
step: 530, loss: 0.33348867297172546
step: 540, loss: 0.21623316407203674
step: 550, loss: 0.07437442243099213
step: 560, loss: 0.16254855692386627
step: 570, loss: 0.3433075249195099
step: 580, loss: 0.22697515785694122
step: 590, loss: 0.18762245774269104
step: 600, loss: 0.15675805509090424
step: 610, loss: 0.22265391051769257
step: 620, loss: 0.10879639536142349
step: 630, loss: 0.19271837174892426
step: 640, loss: 0.40012243390083313
step: 650, loss: 0.13553950190544128
step: 660, loss: 0.19956731796264648
step: 670, loss: 0.1430763304233551
step: 680, loss: 0.06727439165115356
step: 690, loss: 0.10041207075119019
step: 700, loss: 0.17815254628658295
step: 710, loss: 0.11133415997028351
step: 720, loss: 0.10811175405979156
step: 730, loss: 0.19554488360881805
step: 740, loss: 0.28466060757637024
step: 750, loss: 0.12396363168954849
step: 760, loss: 0.05925678461790085
step: 770, loss: 0.01606283150613308
step: 780, loss: 0.11284659802913666
step: 790, loss: 0.10787774622440338
step: 800, loss: 0.16166101396083832
step: 810, loss: 0.07932527363300323
step: 820, loss: 0.16581040620803833
step: 830, loss: 0.31346651911735535
step: 840, loss: 0.13433612883090973
step: 850, loss: 0.0866367295384407
step: 860, loss: 0.11833498626947403
step: 870, loss: 0.05970638245344162
step: 880, loss: 0.29178065061569214
step: 890, loss: 0.1327032595872879
step: 900, loss: 0.0730026438832283
step: 910, loss: 0.04575394466519356
step: 920, loss: 0.0695391595363617
step: 930, loss: 0.24603770673274994
step: 940, loss: 0.16099198162555695
step: 950, loss: 0.04343228414654732
step: 960, loss: 0.07407385855913162
step: 970, loss: 0.14241687953472137
step: 980, loss: 0.21165995299816132
step: 990, loss: 0.08048547804355621
step: 1000, loss: 0.07211386412382126
step: 1010, loss: 0.11969864368438721
step: 1020, loss: 0.09174187481403351
step: 1030, loss: 0.17063063383102417
epoch 2: dev_f1=0.9509399358092617, f1=0.9286700414173953, best_f1=0.9286700414173953
step: 0, loss: 0.17940035462379456
step: 10, loss: 0.09814544767141342
step: 20, loss: 0.06049162521958351
step: 30, loss: 0.1470244973897934
step: 40, loss: 0.0736052542924881
step: 50, loss: 0.14582687616348267
step: 60, loss: 0.21384793519973755
step: 70, loss: 0.005540326237678528
step: 80, loss: 0.18011365830898285
step: 90, loss: 0.26737210154533386
step: 100, loss: 0.12886843085289001
step: 110, loss: 0.12782935798168182
step: 120, loss: 0.1240796148777008
step: 130, loss: 0.0680738091468811
step: 140, loss: 0.17415426671504974
step: 150, loss: 0.17972977459430695
step: 160, loss: 0.16413022577762604
step: 170, loss: 0.07622332125902176
step: 180, loss: 0.19348497688770294
step: 190, loss: 0.19880346953868866
step: 200, loss: 0.06271909177303314
step: 210, loss: 0.1560164988040924
step: 220, loss: 0.2896900177001953
step: 230, loss: 0.07629001140594482
step: 240, loss: 0.08598484098911285
step: 250, loss: 0.07218979299068451
step: 260, loss: 0.1428977996110916
step: 270, loss: 0.02543659135699272
step: 280, loss: 0.041112255305051804
step: 290, loss: 0.021236898377537727
step: 300, loss: 0.13302399218082428
step: 310, loss: 0.16201913356781006
step: 320, loss: 0.09466931968927383
step: 330, loss: 0.09560036659240723
step: 340, loss: 0.029620066285133362
step: 350, loss: 0.07669150084257126
step: 360, loss: 0.2321314662694931
step: 370, loss: 0.10795402526855469
step: 380, loss: 0.0210457481443882
step: 390, loss: 0.03985810652375221
step: 400, loss: 0.08525454998016357
step: 410, loss: 0.02180185168981552
step: 420, loss: 0.35487914085388184
step: 430, loss: 0.04386623576283455
step: 440, loss: 0.016043441370129585
step: 450, loss: 0.03942682966589928
step: 460, loss: 0.012078485451638699
step: 470, loss: 0.06329367309808731
step: 480, loss: 0.2543456554412842
step: 490, loss: 0.24410103261470795
step: 500, loss: 0.08012352138757706
step: 510, loss: 0.2961060702800751
step: 520, loss: 0.06944898515939713
step: 530, loss: 0.03472112864255905
step: 540, loss: 0.060996223241090775
step: 550, loss: 0.07057923823595047
step: 560, loss: 0.12916545569896698
step: 570, loss: 0.05297742038965225
step: 580, loss: 0.037523094564676285
step: 590, loss: 0.12434268742799759
step: 600, loss: 0.12593111395835876
step: 610, loss: 0.05137128010392189
step: 620, loss: 0.11822830140590668
step: 630, loss: 0.16282504796981812
step: 640, loss: 0.1009623110294342
step: 650, loss: 0.10507389158010483
step: 660, loss: 0.07839778065681458
step: 670, loss: 0.0419677272439003
step: 680, loss: 0.08346066623926163
step: 690, loss: 0.036297284066677094
step: 700, loss: 0.023614192381501198
step: 710, loss: 0.037331487983465195
step: 720, loss: 0.06625829637050629
step: 730, loss: 0.23050902783870697
step: 740, loss: 0.034741006791591644
step: 750, loss: 0.03774010017514229
step: 760, loss: 0.02007104456424713
step: 770, loss: 0.08698563277721405
step: 780, loss: 0.13422119617462158
step: 790, loss: 0.13932961225509644
step: 800, loss: 0.13981668651103973
step: 810, loss: 0.09313473850488663
step: 820, loss: 0.11188583821058273
step: 830, loss: 0.045276839286088943
step: 840, loss: 0.0737854391336441
step: 850, loss: 0.0827767550945282
step: 860, loss: 0.09801428765058517
step: 870, loss: 0.27202108502388
step: 880, loss: 0.12360407412052155
step: 890, loss: 0.12711364030838013
step: 900, loss: 0.08079153299331665
step: 910, loss: 0.18439441919326782
step: 920, loss: 0.22329464554786682
step: 930, loss: 0.13115207850933075
step: 940, loss: 0.02304907515645027
step: 950, loss: 0.22181688249111176
step: 960, loss: 0.0851312205195427
step: 970, loss: 0.02718367427587509
step: 980, loss: 0.06900245696306229
step: 990, loss: 0.26861023902893066
step: 1000, loss: 0.09506592154502869
step: 1010, loss: 0.08372286707162857
step: 1020, loss: 0.05554584041237831
step: 1030, loss: 0.09126865863800049
epoch 3: dev_f1=0.9530450953045096, f1=0.9278642149929278, best_f1=0.9278642149929278
step: 0, loss: 0.013339536264538765
step: 10, loss: 0.036748070269823074
step: 20, loss: 0.11487133055925369
step: 30, loss: 0.05332482233643532
step: 40, loss: 0.04069763422012329
step: 50, loss: 0.10818958282470703
step: 60, loss: 0.006511537823826075
step: 70, loss: 0.028905650600790977
step: 80, loss: 0.15401844680309296
step: 90, loss: 0.014338670298457146
step: 100, loss: 0.10498233139514923
step: 110, loss: 0.1678299605846405
step: 120, loss: 0.11338634788990021
step: 130, loss: 0.04787599295377731
step: 140, loss: 0.059299979358911514
step: 150, loss: 0.030607538297772408
step: 160, loss: 0.04153494909405708
step: 170, loss: 0.04403524845838547
step: 180, loss: 0.0904448851943016
step: 190, loss: 0.1119038462638855
step: 200, loss: 0.14753872156143188
step: 210, loss: 0.09232881665229797
step: 220, loss: 0.0523977093398571
step: 230, loss: 0.010515043511986732
step: 240, loss: 0.126831516623497
step: 250, loss: 0.01245999988168478
step: 260, loss: 0.024201320484280586
step: 270, loss: 0.03175036236643791
step: 280, loss: 0.002737900009378791
step: 290, loss: 0.01589137874543667
step: 300, loss: 0.2644530236721039
step: 310, loss: 0.09572658687829971
step: 320, loss: 0.13890735805034637
step: 330, loss: 0.20499971508979797
step: 340, loss: 0.12056058645248413
step: 350, loss: 0.04234690219163895
step: 360, loss: 0.023083630949258804
step: 370, loss: 0.15545284748077393
step: 380, loss: 0.01992318034172058
step: 390, loss: 0.17882467806339264
step: 400, loss: 0.030239000916481018
step: 410, loss: 0.006367015186697245
step: 420, loss: 0.08732730895280838
step: 430, loss: 0.18346834182739258
step: 440, loss: 0.15143060684204102
step: 450, loss: 0.08998382091522217
step: 460, loss: 0.02340807393193245
step: 470, loss: 0.048382919281721115
step: 480, loss: 0.004511103965342045
step: 490, loss: 0.051367420703172684
step: 500, loss: 0.11941218376159668
step: 510, loss: 0.13201436400413513
step: 520, loss: 0.046890854835510254
step: 530, loss: 0.005756945349276066
step: 540, loss: 0.14331378042697906
step: 550, loss: 0.004712384194135666
step: 560, loss: 0.050868142396211624
step: 570, loss: 0.06872450560331345
step: 580, loss: 0.02541234903037548
step: 590, loss: 0.09643542766571045
step: 600, loss: 0.061934009194374084
step: 610, loss: 0.05535320192575455
step: 620, loss: 0.002468078164383769
step: 630, loss: 0.06766532361507416
step: 640, loss: 0.031677089631557465
step: 650, loss: 0.176565483212471
step: 660, loss: 0.030681148171424866
step: 670, loss: 0.20800939202308655
step: 680, loss: 0.06982021778821945
step: 690, loss: 0.1722884178161621
step: 700, loss: 0.0514267235994339
step: 710, loss: 0.08712822943925858
step: 720, loss: 0.0780709758400917
step: 730, loss: 0.032628145068883896
step: 740, loss: 0.010296848602592945
step: 750, loss: 0.013894743286073208
step: 760, loss: 0.15471063554286957
step: 770, loss: 0.00917583703994751
step: 780, loss: 0.03373492509126663
step: 790, loss: 0.050772495567798615
step: 800, loss: 0.04489279165863991
step: 810, loss: 0.028565410524606705
step: 820, loss: 0.04066133499145508
step: 830, loss: 0.01341789960861206
step: 840, loss: 0.03862860053777695
step: 850, loss: 0.06779859960079193
step: 860, loss: 0.24089430272579193
step: 870, loss: 0.022702384740114212
step: 880, loss: 0.1428547203540802
step: 890, loss: 0.10714243352413177
step: 900, loss: 0.0902266725897789
step: 910, loss: 0.040256060659885406
step: 920, loss: 0.05320684239268303
step: 930, loss: 0.08332868665456772
step: 940, loss: 0.13323310017585754
step: 950, loss: 0.0483524464070797
step: 960, loss: 0.15235520899295807
step: 970, loss: 0.06081129238009453
step: 980, loss: 0.029232457280158997
step: 990, loss: 0.017223931849002838
step: 1000, loss: 0.017494069412350655
step: 1010, loss: 0.042104706168174744
step: 1020, loss: 0.05248501896858215
step: 1030, loss: 0.07271964102983475
epoch 4: dev_f1=0.9480580252690688, f1=0.9191246431969552, best_f1=0.9278642149929278
step: 0, loss: 0.03253687173128128
step: 10, loss: 0.09981994330883026
step: 20, loss: 0.22371727228164673
step: 30, loss: 0.02152925170958042
step: 40, loss: 0.010626236908137798
step: 50, loss: 0.10194618254899979
step: 60, loss: 0.2951957881450653
step: 70, loss: 0.0010868296958506107
step: 80, loss: 0.05898864567279816
step: 90, loss: 0.003813020419329405
step: 100, loss: 0.07125362753868103
step: 110, loss: 0.006785370875149965
step: 120, loss: 0.005183489061892033
step: 130, loss: 0.015527287498116493
step: 140, loss: 0.09738267213106155
step: 150, loss: 0.010278944857418537
step: 160, loss: 0.04503336548805237
step: 170, loss: 0.018940985202789307
step: 180, loss: 0.014101071283221245
step: 190, loss: 0.016482070088386536
step: 200, loss: 0.029641123488545418
step: 210, loss: 0.0318940095603466
step: 220, loss: 0.04698798432946205
step: 230, loss: 0.0053009167313575745
step: 240, loss: 0.030828088521957397
step: 250, loss: 0.03299004212021828
step: 260, loss: 0.01879635639488697
step: 270, loss: 0.04821392148733139
step: 280, loss: 0.027843890711665154
step: 290, loss: 0.0592215396463871
step: 300, loss: 0.009910574182868004
step: 310, loss: 0.07651437819004059
step: 320, loss: 0.030983397737145424
step: 330, loss: 0.1169404536485672
step: 340, loss: 0.09404122084379196
step: 350, loss: 0.02375483326613903
step: 360, loss: 0.06017957627773285
step: 370, loss: 0.005869453307241201
step: 380, loss: 0.017707584425807
step: 390, loss: 0.01752893440425396
step: 400, loss: 0.050149302929639816
step: 410, loss: 0.2932571470737457
step: 420, loss: 0.01817757450044155
step: 430, loss: 0.02972361259162426
step: 440, loss: 0.0021788442973047495
step: 450, loss: 0.16987790167331696
step: 460, loss: 0.02721504494547844
step: 470, loss: 0.012711762450635433
step: 480, loss: 0.15424305200576782
step: 490, loss: 0.036185119301080704
step: 500, loss: 0.010673648677766323
step: 510, loss: 0.003980595152825117
step: 520, loss: 0.047849833965301514
step: 530, loss: 0.17306490242481232
step: 540, loss: 0.01653349958360195
step: 550, loss: 0.1080150380730629
step: 560, loss: 0.04582737013697624
step: 570, loss: 0.04555040970444679
step: 580, loss: 0.0936075896024704
step: 590, loss: 0.045014940202236176
step: 600, loss: 0.006949402391910553
step: 610, loss: 0.003202736610546708
step: 620, loss: 0.015306726098060608
step: 630, loss: 0.05069416016340256
step: 640, loss: 0.01251227781176567
step: 650, loss: 0.01033206656575203
step: 660, loss: 0.002805243246257305
step: 670, loss: 0.140395849943161
step: 680, loss: 0.03224126994609833
step: 690, loss: 0.10638802498579025
step: 700, loss: 0.1265982687473297
step: 710, loss: 0.07213430851697922
step: 720, loss: 0.018117232248187065
step: 730, loss: 0.0786711797118187
step: 740, loss: 0.056715212762355804
step: 750, loss: 0.010722409933805466
step: 760, loss: 0.1269010305404663
step: 770, loss: 0.11147622019052505
step: 780, loss: 0.008011055178940296
step: 790, loss: 0.08769185096025467
step: 800, loss: 0.08049558103084564
step: 810, loss: 0.02361844666302204
step: 820, loss: 0.2935296893119812
step: 830, loss: 0.06421764194965363
step: 840, loss: 0.012334169819951057
step: 850, loss: 0.012098320759832859
step: 860, loss: 0.07432771474123001
step: 870, loss: 0.010736778378486633
step: 880, loss: 0.050612449645996094
step: 890, loss: 0.19237664341926575
step: 900, loss: 0.004102241713553667
step: 910, loss: 0.03143077716231346
step: 920, loss: 0.018499739468097687
step: 930, loss: 0.03397176042199135
step: 940, loss: 0.053113553673028946
step: 950, loss: 0.11421868205070496
step: 960, loss: 0.0876673236489296
step: 970, loss: 0.012527834624052048
step: 980, loss: 0.1454584151506424
step: 990, loss: 0.07732831686735153
step: 1000, loss: 0.16573487222194672
step: 1010, loss: 0.016820525750517845
step: 1020, loss: 0.07002458721399307
step: 1030, loss: 0.027676541358232498
epoch 5: dev_f1=0.9524253731343284, f1=0.9252336448598131, best_f1=0.9278642149929278
step: 0, loss: 0.027970094233751297
step: 10, loss: 0.008231425657868385
step: 20, loss: 0.0013721166178584099
step: 30, loss: 0.11268060654401779
step: 40, loss: 0.002427067141979933
step: 50, loss: 0.04938753694295883
step: 60, loss: 0.01807735487818718
step: 70, loss: 0.01399199664592743
step: 80, loss: 0.013394281268119812
step: 90, loss: 0.0036552874371409416
step: 100, loss: 0.0007599583477713168
step: 110, loss: 0.001979908673092723
step: 120, loss: 0.0051576560363173485
step: 130, loss: 0.015546915121376514
step: 140, loss: 0.005537539720535278
step: 150, loss: 0.07556775957345963
step: 160, loss: 0.006296072155237198
step: 170, loss: 0.18891626596450806
step: 180, loss: 0.03844809532165527
step: 190, loss: 0.011302019469439983
step: 200, loss: 0.005100900772958994
step: 210, loss: 0.058539506047964096
step: 220, loss: 0.05450783669948578
step: 230, loss: 0.084332674741745
step: 240, loss: 0.19340668618679047
step: 250, loss: 0.03175201639533043
step: 260, loss: 0.03866048902273178
step: 270, loss: 0.24129781126976013
step: 280, loss: 0.0013034773292019963
step: 290, loss: 0.02752814069390297
step: 300, loss: 0.07914478331804276
step: 310, loss: 0.02452651411294937
step: 320, loss: 0.0048371958546340466
step: 330, loss: 0.023066598922014236
step: 340, loss: 0.038979001343250275
step: 350, loss: 0.003899172879755497
step: 360, loss: 0.04382352903485298
step: 370, loss: 0.003827627981081605
step: 380, loss: 0.03179370239377022
step: 390, loss: 0.008057573810219765
step: 400, loss: 0.004955322481691837
step: 410, loss: 0.01347885187715292
step: 420, loss: 0.05424224212765694
step: 430, loss: 0.010789438150823116
step: 440, loss: 0.002497043227776885
step: 450, loss: 0.04875030741095543
step: 460, loss: 0.10939597338438034
step: 470, loss: 0.13437306880950928
step: 480, loss: 0.0165833979845047
step: 490, loss: 0.01582285575568676
step: 500, loss: 0.0008174029644578695
step: 510, loss: 0.07856543362140656
step: 520, loss: 0.10299462825059891
step: 530, loss: 0.013819113373756409
step: 540, loss: 0.03184375539422035
step: 550, loss: 0.17570941150188446
step: 560, loss: 0.06257868558168411
step: 570, loss: 0.053086429834365845
step: 580, loss: 0.009135112166404724
step: 590, loss: 0.07261713594198227
step: 600, loss: 0.013031834736466408
step: 610, loss: 0.08600258082151413
step: 620, loss: 0.0017652363749220967
step: 630, loss: 0.017346927896142006
step: 640, loss: 0.10700163245201111
step: 650, loss: 0.017167992889881134
step: 660, loss: 0.002400742843747139
step: 670, loss: 0.0007609495078213513
step: 680, loss: 0.1297953575849533
step: 690, loss: 0.0694875419139862
step: 700, loss: 0.07473284751176834
step: 710, loss: 0.07715253531932831
step: 720, loss: 0.05563075840473175
step: 730, loss: 0.04053087532520294
step: 740, loss: 0.008184931240975857
step: 750, loss: 0.020032374188303947
step: 760, loss: 0.07083779573440552
step: 770, loss: 0.003702031448483467
step: 780, loss: 0.009044469334185123
step: 790, loss: 0.04549656808376312
step: 800, loss: 0.08642555773258209
step: 810, loss: 0.00963355228304863
step: 820, loss: 0.03557317703962326
step: 830, loss: 0.05364358425140381
step: 840, loss: 0.005455688573420048
step: 850, loss: 0.0018049814971163869
step: 860, loss: 0.0022601603996008635
step: 870, loss: 0.0010810255771502852
step: 880, loss: 0.018734827637672424
step: 890, loss: 0.029302392154932022
step: 900, loss: 0.056700918823480606
step: 910, loss: 0.0017357401084154844
step: 920, loss: 0.012524650432169437
step: 930, loss: 0.17338640987873077
step: 940, loss: 0.04567693546414375
step: 950, loss: 0.03625192120671272
step: 960, loss: 0.12032680958509445
step: 970, loss: 0.004897463601082563
step: 980, loss: 0.013839630410075188
step: 990, loss: 0.007910717278718948
step: 1000, loss: 0.000930371112190187
step: 1010, loss: 0.0005512013449333608
step: 1020, loss: 0.002398901851847768
step: 1030, loss: 0.04976145550608635
epoch 6: dev_f1=0.9477543538038496, f1=0.9333333333333335, best_f1=0.9278642149929278
step: 0, loss: 0.004778261296451092
step: 10, loss: 0.005154843907803297
step: 20, loss: 0.02992369793355465
step: 30, loss: 0.20429681241512299
step: 40, loss: 0.006368209142237902
step: 50, loss: 0.013313636183738708
step: 60, loss: 0.0020935621578246355
step: 70, loss: 0.01959816925227642
step: 80, loss: 0.0026474439073354006
step: 90, loss: 0.014240022748708725
step: 100, loss: 0.016842477023601532
step: 110, loss: 0.042246490716934204
step: 120, loss: 0.005993634462356567
step: 130, loss: 0.0014581462601199746
step: 140, loss: 0.0023936638608574867
step: 150, loss: 0.07739266753196716
step: 160, loss: 0.0426785983145237
step: 170, loss: 0.07507136464118958
step: 180, loss: 0.03614320605993271
step: 190, loss: 0.06597078591585159
step: 200, loss: 0.027611948549747467
step: 210, loss: 0.0027311269659549
step: 220, loss: 0.06385371088981628
step: 230, loss: 0.024695340543985367
step: 240, loss: 0.01568775624036789
step: 250, loss: 0.03517676517367363
step: 260, loss: 0.008607241325080395
step: 270, loss: 0.000576071091927588
step: 280, loss: 0.008954068645834923
step: 290, loss: 0.0010881779016926885
step: 300, loss: 0.002574169309809804
step: 310, loss: 0.003737726015970111
step: 320, loss: 0.032381411641836166
step: 330, loss: 0.09900123625993729
step: 340, loss: 0.004062960855662823
step: 350, loss: 0.045822326093912125
step: 360, loss: 0.0005217375000938773
step: 370, loss: 0.010748526081442833
step: 380, loss: 0.03396519646048546
step: 390, loss: 0.009183909744024277
step: 400, loss: 0.0020455028861761093
step: 410, loss: 0.006466382183134556
step: 420, loss: 0.005960661917924881
step: 430, loss: 0.006800724659115076
step: 440, loss: 0.020610345527529716
step: 450, loss: 0.015528151765465736
step: 460, loss: 0.0015864690067246556
step: 470, loss: 0.02058974653482437
step: 480, loss: 0.023073744028806686
step: 490, loss: 0.0013482313370332122
step: 500, loss: 0.017769625410437584
step: 510, loss: 0.00033922804868780077
step: 520, loss: 0.12913598120212555
step: 530, loss: 0.08029717952013016
step: 540, loss: 0.0019144830293953419
step: 550, loss: 0.0012346245348453522
step: 560, loss: 0.04810786247253418
step: 570, loss: 0.012357909232378006
step: 580, loss: 0.05060679838061333
step: 590, loss: 0.007540131453424692
step: 600, loss: 0.0413220040500164
step: 610, loss: 0.018439944833517075
step: 620, loss: 0.00028849084628745914
step: 630, loss: 0.05547153577208519
step: 640, loss: 0.006861773785203695
step: 650, loss: 0.036367982625961304
step: 660, loss: 0.00832369364798069
step: 670, loss: 0.0011655522976070642
step: 680, loss: 0.005757367704063654
step: 690, loss: 0.0013035667361691594
step: 700, loss: 0.0009404985466971993
step: 710, loss: 0.016752207651734352
step: 720, loss: 0.003915078472346067
step: 730, loss: 0.0014154204400256276
step: 740, loss: 0.030224177986383438
step: 750, loss: 0.06417203694581985
step: 760, loss: 0.004616813268512487
step: 770, loss: 0.006699701771140099
step: 780, loss: 0.020129166543483734
step: 790, loss: 0.0009705046541057527
step: 800, loss: 0.0004046279937028885
step: 810, loss: 0.0053663006983697414
step: 820, loss: 0.0034084829967468977
step: 830, loss: 0.004605705384165049
step: 840, loss: 0.0018302233656868339
step: 850, loss: 0.0014797111507505178
step: 860, loss: 0.000503565592225641
step: 870, loss: 0.04414011910557747
step: 880, loss: 0.0047733113169670105
step: 890, loss: 0.002373135183006525
step: 900, loss: 0.011578193865716457
step: 910, loss: 0.03778493404388428
step: 920, loss: 0.025094101205468178
step: 930, loss: 0.1808585673570633
step: 940, loss: 0.0005719152977690101
step: 950, loss: 0.003601371543481946
step: 960, loss: 0.09741409868001938
step: 970, loss: 0.010049266740679741
step: 980, loss: 0.011365503072738647
step: 990, loss: 0.037462521344423294
step: 1000, loss: 0.004375196527689695
step: 1010, loss: 0.050310827791690826
step: 1020, loss: 0.10021975636482239
step: 1030, loss: 0.0064094942063093185
epoch 7: dev_f1=0.9459332393041843, f1=0.9222011385199241, best_f1=0.9278642149929278
step: 0, loss: 0.04268280044198036
step: 10, loss: 0.00158593594096601
step: 20, loss: 0.0034247078001499176
step: 30, loss: 0.0015865202294662595
step: 40, loss: 0.0016819159500300884
step: 50, loss: 0.00042912017670460045
step: 60, loss: 0.0013278977712616324
step: 70, loss: 0.06651443988084793
step: 80, loss: 0.06607246398925781
step: 90, loss: 0.0029596537351608276
step: 100, loss: 0.020808234810829163
step: 110, loss: 0.0022892935667186975
step: 120, loss: 0.11618275195360184
step: 130, loss: 0.0048723528161644936
step: 140, loss: 0.020577898249030113
step: 150, loss: 0.011279897764325142
step: 160, loss: 0.004292323719710112
step: 170, loss: 0.0013942936202511191
step: 180, loss: 0.06616347283124924
step: 190, loss: 0.006928098388016224
step: 200, loss: 0.10007012635469437
step: 210, loss: 0.0009709703153930604
step: 220, loss: 0.0847889855504036
step: 230, loss: 0.03688648343086243
step: 240, loss: 0.0052376072853803635
step: 250, loss: 0.000557954772375524
step: 260, loss: 0.009382840245962143
step: 270, loss: 0.0023464381229132414
step: 280, loss: 0.000767167191952467
step: 290, loss: 0.0008287764503620565
step: 300, loss: 0.005710937548428774
step: 310, loss: 0.00801510363817215
step: 320, loss: 0.0014719674363732338
step: 330, loss: 0.0009379048133268952
step: 340, loss: 0.003627688391134143
step: 350, loss: 0.07339802384376526
step: 360, loss: 0.0012490109074860811
step: 370, loss: 0.003268922446295619
step: 380, loss: 0.1896008849143982
step: 390, loss: 0.00710461288690567
step: 400, loss: 0.0012420977000147104
step: 410, loss: 0.006289912387728691
step: 420, loss: 0.00045272658462636173
step: 430, loss: 0.08388006687164307
step: 440, loss: 0.06678196787834167
step: 450, loss: 0.00019579297804739326
step: 460, loss: 0.0015225905226543546
step: 470, loss: 0.002258694265037775
step: 480, loss: 0.06056796386837959
step: 490, loss: 0.03498668223619461
step: 500, loss: 0.018530791625380516
step: 510, loss: 0.00482916971668601
step: 520, loss: 0.00707858894020319
step: 530, loss: 0.0007555910851806402
step: 540, loss: 0.0010379691375419497
step: 550, loss: 0.0007075251778587699
step: 560, loss: 0.014534110203385353
step: 570, loss: 0.005887159146368504
step: 580, loss: 0.023236120119690895
step: 590, loss: 0.0007504420937038958
step: 600, loss: 0.0006279699737206101
step: 610, loss: 0.023601336404681206
step: 620, loss: 0.0023154737427830696
step: 630, loss: 0.003403335576876998
step: 640, loss: 0.00023417951888404787
step: 650, loss: 0.0009297619108110666
step: 660, loss: 0.00992789026349783
step: 670, loss: 0.0027589485980570316
step: 680, loss: 0.026549577713012695
step: 690, loss: 0.0001690740027697757
step: 700, loss: 0.00015304505359381437
step: 710, loss: 0.002919189864769578
step: 720, loss: 0.00532669248059392
step: 730, loss: 0.02268991246819496
step: 740, loss: 0.010610565543174744
step: 750, loss: 0.12126561254262924
step: 760, loss: 0.0005662844050675631
step: 770, loss: 0.053988002240657806
step: 780, loss: 0.0049730632454156876
step: 790, loss: 0.004094509873539209
step: 800, loss: 0.003389323130249977
step: 810, loss: 0.006734722293913364
step: 820, loss: 0.0005458421655930579
step: 830, loss: 0.0008176880073733628
step: 840, loss: 0.004547111224383116
step: 850, loss: 0.04121380299329758
step: 860, loss: 0.0004979167133569717
step: 870, loss: 0.01687263324856758
step: 880, loss: 0.0010743984021246433
step: 890, loss: 0.011569545604288578
step: 900, loss: 0.005065462086349726
step: 910, loss: 0.0022697215899825096
step: 920, loss: 0.007780136540532112
step: 930, loss: 0.003948012832552195
step: 940, loss: 0.1544785052537918
step: 950, loss: 0.007194156292825937
step: 960, loss: 0.0008704243809916079
step: 970, loss: 0.00896826758980751
step: 980, loss: 0.00640117609873414
step: 990, loss: 0.008112894371151924
step: 1000, loss: 0.002251456491649151
step: 1010, loss: 0.03245694935321808
step: 1020, loss: 0.026247598230838776
step: 1030, loss: 0.000978201860561967
epoch 8: dev_f1=0.9505416862929816, f1=0.9218303145853193, best_f1=0.9278642149929278
step: 0, loss: 0.012166506610810757
step: 10, loss: 0.0071945153176784515
step: 20, loss: 0.0005318144103512168
step: 30, loss: 0.001027299789711833
step: 40, loss: 0.0025350400246679783
step: 50, loss: 0.00025126099353656173
step: 60, loss: 0.01239284873008728
step: 70, loss: 0.005892133805900812
step: 80, loss: 0.00014185709005687386
step: 90, loss: 0.0006169844418764114
step: 100, loss: 0.00877104327082634
step: 110, loss: 0.00020471279276534915
step: 120, loss: 0.0005158305866643786
step: 130, loss: 0.032217081636190414
step: 140, loss: 0.04677244648337364
step: 150, loss: 0.0002318282931810245
step: 160, loss: 0.0043524825014173985
step: 170, loss: 0.00027226912789046764
step: 180, loss: 0.013427912257611752
step: 190, loss: 0.01727256551384926
step: 200, loss: 0.0572512187063694
step: 210, loss: 0.0018901863368228078
step: 220, loss: 0.03273968771100044
step: 230, loss: 0.02361789532005787
step: 240, loss: 0.15234127640724182
step: 250, loss: 0.00547369010746479
step: 260, loss: 0.055417321622371674
step: 270, loss: 0.13817375898361206
step: 280, loss: 0.01800643838942051
step: 290, loss: 0.21924002468585968
step: 300, loss: 0.0055572171695530415
step: 310, loss: 0.003459338564425707
step: 320, loss: 0.14643098413944244
step: 330, loss: 0.05147584527730942
step: 340, loss: 0.011340515688061714
step: 350, loss: 0.07677812874317169
step: 360, loss: 0.03007054515182972
step: 370, loss: 0.012880302965641022
step: 380, loss: 0.035694319754838943
step: 390, loss: 0.11147245019674301
step: 400, loss: 0.0018003965960815549
step: 410, loss: 0.007829451933503151
step: 420, loss: 0.002550653414800763
step: 430, loss: 0.18665297329425812
step: 440, loss: 0.00548574049025774
step: 450, loss: 0.18581125140190125
step: 460, loss: 0.00259150261990726
step: 470, loss: 0.011885994113981724
step: 480, loss: 0.0017051647882908583
step: 490, loss: 0.001801573089323938
step: 500, loss: 0.0015618344768881798
step: 510, loss: 0.02498755417764187
step: 520, loss: 0.023104697465896606
step: 530, loss: 0.004398720804601908
step: 540, loss: 0.02303233928978443
step: 550, loss: 0.0020248296204954386
step: 560, loss: 0.00615177396684885
step: 570, loss: 0.012776937335729599
step: 580, loss: 0.0021611442789435387
step: 590, loss: 0.013492981903254986
step: 600, loss: 0.03384530171751976
step: 610, loss: 0.0007486597751267254
step: 620, loss: 0.0024277574848383665
step: 630, loss: 0.003946962766349316
step: 640, loss: 0.001210868707858026
step: 650, loss: 0.015795907005667686
step: 660, loss: 0.017927199602127075
step: 670, loss: 0.0018021976575255394
step: 680, loss: 0.0023633784148842096
step: 690, loss: 0.0009180246270261705
step: 700, loss: 0.015033476054668427
step: 710, loss: 0.001359178451821208
step: 720, loss: 0.00044106683344580233
step: 730, loss: 0.08748640865087509
step: 740, loss: 0.029812075197696686
step: 750, loss: 0.0018785946303978562
step: 760, loss: 0.0017023051623255014
step: 770, loss: 0.00014037398796062917
step: 780, loss: 0.0011900229146704078
step: 790, loss: 0.001441279542632401
step: 800, loss: 0.00020649329235311598
step: 810, loss: 0.003423097776249051
step: 820, loss: 0.00013173205661587417
step: 830, loss: 0.0004827269003726542
step: 840, loss: 0.004483119118958712
step: 850, loss: 0.013262070715427399
step: 860, loss: 0.018964217975735664
step: 870, loss: 0.05616768077015877
step: 880, loss: 0.019002877175807953
step: 890, loss: 0.001704573747701943
step: 900, loss: 0.03055640496313572
step: 910, loss: 0.20137757062911987
step: 920, loss: 0.0008112744544632733
step: 930, loss: 0.021344434469938278
step: 940, loss: 0.019067946821451187
step: 950, loss: 0.0008592390222474933
step: 960, loss: 0.013861787505447865
step: 970, loss: 0.0006382639403454959
step: 980, loss: 0.027723105624318123
step: 990, loss: 0.003801083192229271
step: 1000, loss: 0.0015888550551608205
step: 1010, loss: 0.07618995755910873
step: 1020, loss: 0.019214950501918793
step: 1030, loss: 0.017702123150229454
epoch 9: dev_f1=0.9494855004677268, f1=0.9193015573383672, best_f1=0.9278642149929278
step: 0, loss: 0.01573367975652218
step: 10, loss: 0.00016248678730335087
step: 20, loss: 0.011065597645938396
step: 30, loss: 0.001891963998787105
step: 40, loss: 0.008223732933402061
step: 50, loss: 0.001808541244827211
step: 60, loss: 0.0015944440383464098
step: 70, loss: 0.00435985391959548
step: 80, loss: 0.00464229192584753
step: 90, loss: 0.0017113725189119577
step: 100, loss: 0.0037398175336420536
step: 110, loss: 0.0012354819336906075
step: 120, loss: 0.00022714605438522995
step: 130, loss: 0.002163400873541832
step: 140, loss: 0.0015611971030011773
step: 150, loss: 0.0018219928024336696
step: 160, loss: 0.0001332090760115534
step: 170, loss: 0.012784037739038467
step: 180, loss: 0.0006266373675316572
step: 190, loss: 0.023104220628738403
step: 200, loss: 0.006238610949367285
step: 210, loss: 0.00432418379932642
step: 220, loss: 0.00026471997261978686
step: 230, loss: 0.001020893338136375
step: 240, loss: 0.004471686203032732
step: 250, loss: 0.05097261071205139
step: 260, loss: 0.002402844373136759
step: 270, loss: 0.0016142037929967046
step: 280, loss: 0.002427496714517474
step: 290, loss: 0.0019995525944978
step: 300, loss: 0.003510827897116542
step: 310, loss: 0.00022419776360038668
step: 320, loss: 0.04296252876520157
step: 330, loss: 0.00026506726862862706
step: 340, loss: 0.0005482375854626298
step: 350, loss: 0.02644023485481739
step: 360, loss: 0.001562366378493607
step: 370, loss: 0.008739489130675793
step: 380, loss: 0.00045849173329770565
step: 390, loss: 0.0015542196342721581
step: 400, loss: 0.002140533411875367
step: 410, loss: 0.015006590634584427
step: 420, loss: 0.0002225744683528319
step: 430, loss: 0.00041646661702543497
step: 440, loss: 0.008897515013813972
step: 450, loss: 0.00013129942817613482
step: 460, loss: 6.745277642039582e-05
step: 470, loss: 0.00424539390951395
step: 480, loss: 0.0019687176682054996
step: 490, loss: 0.0003731227188836783
step: 500, loss: 0.0005387774435803294
step: 510, loss: 0.0008278153836727142
step: 520, loss: 0.0052463398315012455
step: 530, loss: 0.00043544755317270756
step: 540, loss: 0.000973026966676116
step: 550, loss: 0.00043485633796080947
step: 560, loss: 0.001758519560098648
step: 570, loss: 0.005084882024675608
step: 580, loss: 0.00015427212929353118
step: 590, loss: 0.004947701934725046
step: 600, loss: 0.04277734085917473
step: 610, loss: 0.0017348715336993337
step: 620, loss: 0.00010903766087722033
step: 630, loss: 0.00023287216026801616
step: 640, loss: 0.00045926455641165376
step: 650, loss: 0.042712435126304626
step: 660, loss: 0.002251912374049425
step: 670, loss: 0.07700823247432709
step: 680, loss: 0.010750333778560162
step: 690, loss: 0.012681681662797928
step: 700, loss: 0.002271592151373625
step: 710, loss: 0.019238434731960297
step: 720, loss: 0.009280484169721603
step: 730, loss: 0.0018808996537700295
step: 740, loss: 0.0023530032485723495
step: 750, loss: 0.006580328103154898
step: 760, loss: 0.0010114407632499933
step: 770, loss: 0.0002578501880634576
step: 780, loss: 0.008794666267931461
step: 790, loss: 0.000516712199896574
step: 800, loss: 0.005299791693687439
step: 810, loss: 0.000519587192684412
step: 820, loss: 0.0016246866434812546
step: 830, loss: 0.0007801184547133744
step: 840, loss: 0.00013929962005931884
step: 850, loss: 0.0001649423793423921
step: 860, loss: 0.0003698842483572662
step: 870, loss: 0.0024033335503190756
step: 880, loss: 0.011501499451696873
step: 890, loss: 0.0009888883214443922
step: 900, loss: 0.00482608238235116
step: 910, loss: 0.0018490272341296077
step: 920, loss: 0.0004123760445509106
step: 930, loss: 0.001024725497700274
step: 940, loss: 0.014214247465133667
step: 950, loss: 0.1492527574300766
step: 960, loss: 0.059967320412397385
step: 970, loss: 0.0013140375958755612
step: 980, loss: 0.0020465331617742777
step: 990, loss: 0.00033350737066939473
step: 1000, loss: 0.003985644783824682
step: 1010, loss: 0.0007017652969807386
step: 1020, loss: 0.0032527828589081764
step: 1030, loss: 0.04656978324055672
epoch 10: dev_f1=0.951501154734411, f1=0.9246511627906977, best_f1=0.9278642149929278
step: 0, loss: 0.000278075342066586
step: 10, loss: 0.0003856695257127285
step: 20, loss: 0.0009673887398093939
step: 30, loss: 0.00514685083180666
step: 40, loss: 0.009156238287687302
step: 50, loss: 0.027792425826191902
step: 60, loss: 0.0004932243609800935
step: 70, loss: 0.00028356086113490164
step: 80, loss: 0.0008574423845857382
step: 90, loss: 0.0004472876898944378
step: 100, loss: 0.001036932459101081
step: 110, loss: 0.002736482070758939
step: 120, loss: 0.0011770519195124507
step: 130, loss: 0.0011529327603057027
step: 140, loss: 0.005913289729505777
step: 150, loss: 0.000681430974509567
step: 160, loss: 0.07610251009464264
step: 170, loss: 0.03720688074827194
step: 180, loss: 0.001795229152776301
step: 190, loss: 0.00010706749890232459
step: 200, loss: 0.020580798387527466
step: 210, loss: 0.025545908138155937
step: 220, loss: 0.03638344630599022
step: 230, loss: 8.283897477667779e-05
step: 240, loss: 0.0007705088937655091
step: 250, loss: 0.0004048521805088967
step: 260, loss: 0.002825085772201419
step: 270, loss: 0.0046651409938931465
step: 280, loss: 0.0058553628623485565
step: 290, loss: 0.001721601583994925
step: 300, loss: 0.0003257080097682774
step: 310, loss: 0.003773902077227831
step: 320, loss: 0.0011029820889234543
step: 330, loss: 0.0002602323074825108
step: 340, loss: 0.0003985171497333795
step: 350, loss: 0.006120901554822922
step: 360, loss: 0.007073139306157827
step: 370, loss: 0.00733918696641922
step: 380, loss: 0.0021251854486763477
step: 390, loss: 0.0016212410992011428
step: 400, loss: 8.071546471910551e-05
step: 410, loss: 0.0007608140585944057
step: 420, loss: 0.013082782737910748
step: 430, loss: 0.0022165176924318075
step: 440, loss: 0.0011277457233518362
step: 450, loss: 0.003658184316009283
step: 460, loss: 0.00015419363626278937
step: 470, loss: 0.0019095903262495995
step: 480, loss: 0.00011120544513687491
step: 490, loss: 0.004082479979842901
step: 500, loss: 0.00014475810166914016
step: 510, loss: 0.002757031936198473
step: 520, loss: 0.0005907032755203545
step: 530, loss: 9.734996274346486e-05
step: 540, loss: 0.08958262205123901
step: 550, loss: 0.003559488570317626
step: 560, loss: 0.0005603154422715306
step: 570, loss: 0.00017744596698321402
step: 580, loss: 0.0005785287357866764
step: 590, loss: 0.21164652705192566
step: 600, loss: 0.000220880116103217
step: 610, loss: 0.00039934428059495986
step: 620, loss: 0.03553946316242218
step: 630, loss: 0.03233373165130615
step: 640, loss: 0.001200794824399054
step: 650, loss: 0.010341896675527096
step: 660, loss: 0.008389762602746487
step: 670, loss: 0.0008419316727668047
step: 680, loss: 0.00018891191575676203
step: 690, loss: 0.0003888248756993562
step: 700, loss: 0.005560781806707382
step: 710, loss: 0.01752910017967224
step: 720, loss: 0.0011560084531083703
step: 730, loss: 0.0009974255226552486
step: 740, loss: 0.005273158196359873
step: 750, loss: 0.0008277602028101683
step: 760, loss: 0.001556831644847989
step: 770, loss: 0.0026422275695949793
step: 780, loss: 0.00012530900130514055
step: 790, loss: 0.001052035135217011
step: 800, loss: 0.00035295062116347253
step: 810, loss: 0.0014652586542069912
step: 820, loss: 0.005911835003644228
step: 830, loss: 6.834432133473456e-05
step: 840, loss: 0.0047984132543206215
step: 850, loss: 4.5780725486110896e-05
step: 860, loss: 0.003870356595143676
step: 870, loss: 0.0004278648120816797
step: 880, loss: 0.00538743706420064
step: 890, loss: 0.02619056962430477
step: 900, loss: 0.0013778813881799579
step: 910, loss: 0.00012697960482910275
step: 920, loss: 0.0035184042062610388
step: 930, loss: 0.001020026276819408
step: 940, loss: 0.07147844135761261
step: 950, loss: 0.002412633039057255
step: 960, loss: 0.00019746941688936204
step: 970, loss: 0.0004430848639458418
step: 980, loss: 0.042039044201374054
step: 990, loss: 0.0004195887304376811
step: 1000, loss: 0.0011881045065820217
step: 1010, loss: 0.06086978316307068
step: 1020, loss: 0.0006206414545886219
step: 1030, loss: 0.005021422635763884
epoch 11: dev_f1=0.9507892293407614, f1=0.919020715630885, best_f1=0.9278642149929278
step: 0, loss: 6.649278657278046e-05
step: 10, loss: 0.004582379478961229
step: 20, loss: 0.0036407692823559046
step: 30, loss: 0.019813857972621918
step: 40, loss: 0.00017250515520572662
step: 50, loss: 0.04568377137184143
step: 60, loss: 0.0011569305788725615
step: 70, loss: 0.0028656688518822193
step: 80, loss: 0.0011566267348825932
step: 90, loss: 0.0005040796822868288
step: 100, loss: 0.0008820687653496861
step: 110, loss: 0.0013134718174114823
step: 120, loss: 0.0007472552242688835
step: 130, loss: 0.00044892291771247983
step: 140, loss: 0.0138154998421669
step: 150, loss: 0.0007869344553910196
step: 160, loss: 0.06524830311536789
step: 170, loss: 0.00436048861593008
step: 180, loss: 0.0011587833287194371
step: 190, loss: 0.00010388089867774397
step: 200, loss: 0.0004369692469481379
step: 210, loss: 0.00015409773914143443
step: 220, loss: 0.0023676001001149416
step: 230, loss: 4.522447852650657e-05
step: 240, loss: 0.003582644509151578
step: 250, loss: 0.00104110362008214
step: 260, loss: 0.0003376086533535272
step: 270, loss: 0.00027220111223869026
step: 280, loss: 0.0002841610985342413
step: 290, loss: 0.000619757454842329
step: 300, loss: 0.0024981771130114794
step: 310, loss: 0.003041022690013051
step: 320, loss: 0.00019601659732870758
step: 330, loss: 0.0034049400128424168
step: 340, loss: 0.00026901287492364645
step: 350, loss: 0.0002287265087943524
step: 360, loss: 0.00015862085274420679
step: 370, loss: 0.0011919982498511672
step: 380, loss: 0.0010081375949084759
step: 390, loss: 0.0019655940122902393
step: 400, loss: 0.00024950827355496585
step: 410, loss: 0.0004959101788699627
step: 420, loss: 0.0002138936979463324
step: 430, loss: 0.01598265767097473
step: 440, loss: 7.418408495141193e-05
step: 450, loss: 0.02136716991662979
step: 460, loss: 9.96849630610086e-05
step: 470, loss: 0.0007148234872147441
step: 480, loss: 0.09777894616127014
step: 490, loss: 0.11789504438638687
step: 500, loss: 0.003414399456232786
step: 510, loss: 0.038854777812957764
step: 520, loss: 0.001011486048810184
step: 530, loss: 0.03967747092247009
step: 540, loss: 5.8307661674916744e-05
step: 550, loss: 0.00033400236861780286
step: 560, loss: 0.042972810566425323
step: 570, loss: 0.000263181485934183
step: 580, loss: 0.0288558229804039
step: 590, loss: 0.000610066344961524
step: 600, loss: 0.0001705644972389564
step: 610, loss: 0.0005206470959819853
step: 620, loss: 0.005082613322883844
step: 630, loss: 0.0053773000836372375
step: 640, loss: 0.00013624568236991763
step: 650, loss: 0.00030850584153085947
step: 660, loss: 0.0026007727719843388
step: 670, loss: 0.0002610775118228048
step: 680, loss: 0.0037678899243474007
step: 690, loss: 0.006306104362010956
step: 700, loss: 0.014399327337741852
step: 710, loss: 0.00014258408918976784
step: 720, loss: 0.0528167225420475
step: 730, loss: 0.0006064361659809947
step: 740, loss: 0.01840776391327381
step: 750, loss: 0.06150303781032562
step: 760, loss: 0.00011483603157103062
step: 770, loss: 0.01959798112511635
step: 780, loss: 0.0003366911259945482
step: 790, loss: 0.0001374061539536342
step: 800, loss: 0.0043224613182246685
step: 810, loss: 0.027219407260417938
step: 820, loss: 0.0007560369558632374
step: 830, loss: 0.0011816452024504542
step: 840, loss: 0.014908678829669952
step: 850, loss: 0.009782608598470688
step: 860, loss: 0.0018841595156118274
step: 870, loss: 0.002100947080180049
step: 880, loss: 0.00011628285574261099
step: 890, loss: 0.0007209822069853544
step: 900, loss: 0.00023690960370004177
step: 910, loss: 0.01745210401713848
step: 920, loss: 0.010860176756978035
step: 930, loss: 0.0003348719037603587
step: 940, loss: 7.780658779665828e-05
step: 950, loss: 0.0009756911895237863
step: 960, loss: 0.00012450790381990373
step: 970, loss: 0.000509579898789525
step: 980, loss: 8.707086817594245e-05
step: 990, loss: 0.14312410354614258
step: 1000, loss: 0.0008717941818758845
step: 1010, loss: 0.0005412442842498422
step: 1020, loss: 0.024297811090946198
step: 1030, loss: 0.001490617636591196
epoch 12: dev_f1=0.9441860465116279, f1=0.922425952045134, best_f1=0.9278642149929278
step: 0, loss: 0.01032749842852354
step: 10, loss: 0.0006220698123797774
step: 20, loss: 0.0037091972772032022
step: 30, loss: 0.005339723080396652
step: 40, loss: 0.0005101323476992548
step: 50, loss: 0.0009829459013417363
step: 60, loss: 0.0032981319818645716
step: 70, loss: 0.008931547403335571
step: 80, loss: 0.0011315835872665048
step: 90, loss: 0.0006484590703621507
step: 100, loss: 0.002843650057911873
step: 110, loss: 0.007885951548814774
step: 120, loss: 7.124416151782498e-05
step: 130, loss: 0.0003172191500198096
step: 140, loss: 0.0012518377043306828
step: 150, loss: 0.002148946514353156
step: 160, loss: 0.014267059043049812
step: 170, loss: 0.00023799552582204342
step: 180, loss: 0.016256285831332207
step: 190, loss: 0.0006041649612598121
step: 200, loss: 6.129808025434613e-05
step: 210, loss: 0.0004562642425298691
step: 220, loss: 0.003171093761920929
step: 230, loss: 0.01328877080231905
step: 240, loss: 0.00014045812713447958
step: 250, loss: 0.004919850267469883
step: 260, loss: 0.08674027025699615
step: 270, loss: 0.03869485855102539
step: 280, loss: 0.0021523460745811462
step: 290, loss: 0.0003981345798820257
step: 300, loss: 0.0010808840161189437
step: 310, loss: 0.02218112163245678
step: 320, loss: 0.007116885855793953
step: 330, loss: 0.00019855720165651292
step: 340, loss: 0.0006239376962184906
step: 350, loss: 0.00020253345428500324
step: 360, loss: 0.001917362562380731
step: 370, loss: 0.00045864697312936187
step: 380, loss: 0.00042532969382591546
step: 390, loss: 0.00018364163406658918
step: 400, loss: 0.0002849673037417233
step: 410, loss: 0.0005382639938034117
step: 420, loss: 0.0007907618419267237
step: 430, loss: 0.1460750550031662
step: 440, loss: 0.0004230914928484708
step: 450, loss: 0.0009973229607567191
step: 460, loss: 0.0004587843723129481
step: 470, loss: 0.07007994502782822
step: 480, loss: 0.005542628467082977
step: 490, loss: 0.04507821798324585
step: 500, loss: 3.5953387850895524e-05
step: 510, loss: 0.00017146549362223595
step: 520, loss: 0.0002685530052985996
step: 530, loss: 0.0017060962272807956
step: 540, loss: 0.0003123954520560801
step: 550, loss: 0.0039176917634904385
step: 560, loss: 0.0015449030324816704
step: 570, loss: 0.0003349733888171613
step: 580, loss: 0.002981649711728096
step: 590, loss: 0.0002889753086492419
step: 600, loss: 0.00022652471670880914
step: 610, loss: 4.644316140911542e-05
step: 620, loss: 0.00022924371296539903
step: 630, loss: 0.0030145260971039534
step: 640, loss: 0.04269610345363617
step: 650, loss: 0.0015261739026755095
step: 660, loss: 0.0011894642375409603
step: 670, loss: 0.00012262185919098556
step: 680, loss: 0.0010356631828472018
step: 690, loss: 0.0013179127126932144
step: 700, loss: 0.0006575929583050311
step: 710, loss: 0.04194926097989082
step: 720, loss: 0.0031521497294306755
step: 730, loss: 0.001183998421765864
step: 740, loss: 0.00024986208882182837
step: 750, loss: 0.05449340492486954
step: 760, loss: 0.0009329436579719186
step: 770, loss: 0.0012540671741589904
step: 780, loss: 0.00031207958818413317
step: 790, loss: 0.0002675467694643885
step: 800, loss: 0.0001480795326642692
step: 810, loss: 0.00035042152740061283
step: 820, loss: 4.085822365595959e-05
step: 830, loss: 0.002248590113595128
step: 840, loss: 0.0003181180218234658
step: 850, loss: 0.0016434831777587533
step: 860, loss: 5.509032416739501e-05
step: 870, loss: 0.00011701441690092906
step: 880, loss: 3.174165976815857e-05
step: 890, loss: 0.00012717970821540803
step: 900, loss: 0.00020360953931231052
step: 910, loss: 0.005112068261951208
step: 920, loss: 0.0006410757778212428
step: 930, loss: 0.007519998587667942
step: 940, loss: 0.00020243551989551634
step: 950, loss: 0.00011303979408694431
step: 960, loss: 0.003054669825360179
step: 970, loss: 0.0025565121322870255
step: 980, loss: 9.617226896807551e-05
step: 990, loss: 0.005929526872932911
step: 1000, loss: 0.0015872982330620289
step: 1010, loss: 0.0003158388426527381
step: 1020, loss: 0.00016942959337029606
step: 1030, loss: 0.0018577395239844918
epoch 13: dev_f1=0.9501630181648812, f1=0.9264844486333647, best_f1=0.9278642149929278
step: 0, loss: 0.00016809084627311677
step: 10, loss: 5.61899651074782e-05
step: 20, loss: 0.00015190224803518504
step: 30, loss: 0.0002973444643430412
step: 40, loss: 0.0009079392766579986
step: 50, loss: 0.028155876323580742
step: 60, loss: 0.0030708028934895992
step: 70, loss: 0.001115906867198646
step: 80, loss: 2.808705721690785e-05
step: 90, loss: 0.0003937066067010164
step: 100, loss: 6.402016151696444e-05
step: 110, loss: 0.0020897251088172197
step: 120, loss: 5.7468994782539085e-05
step: 130, loss: 0.004808122757822275
step: 140, loss: 0.00013479747576639056
step: 150, loss: 0.00021280617511365563
step: 160, loss: 0.00038306720671243966
step: 170, loss: 0.0003307239676360041
step: 180, loss: 0.0010322952875867486
step: 190, loss: 0.0002116066316375509
step: 200, loss: 0.11623873561620712
step: 210, loss: 0.00025709145120345056
step: 220, loss: 0.0012671133736148477
step: 230, loss: 0.0017190763028338552
step: 240, loss: 0.0001251380454050377
step: 250, loss: 0.0004203550925012678
step: 260, loss: 9.958480950444937e-05
step: 270, loss: 0.0013406963553279638
step: 280, loss: 5.091448838356882e-05
step: 290, loss: 0.010868601500988007
step: 300, loss: 0.0033617732115089893
step: 310, loss: 2.4452099751215428e-05
step: 320, loss: 2.7260866772849113e-05
step: 330, loss: 0.00012044010509271175
step: 340, loss: 0.00014355058374349028
step: 350, loss: 8.603567403042689e-05
step: 360, loss: 0.0005683255149051547
step: 370, loss: 0.009208647534251213
step: 380, loss: 0.007946460507810116
step: 390, loss: 0.05301429331302643
step: 400, loss: 8.183296449715272e-05
step: 410, loss: 0.00012191639689262956
step: 420, loss: 0.00040746276499703526
step: 430, loss: 0.0028672432526946068
step: 440, loss: 0.003850257256999612
step: 450, loss: 0.0001486732071498409
step: 460, loss: 0.0008342858054675162
step: 470, loss: 0.0018090270459651947
step: 480, loss: 0.0002409543376415968
step: 490, loss: 0.01875448413193226
step: 500, loss: 0.006199668627232313
step: 510, loss: 0.004192335531115532
step: 520, loss: 0.0009800093248486519
step: 530, loss: 0.00013495168241206557
step: 540, loss: 0.001680560177192092
step: 550, loss: 0.0020306273363530636
step: 560, loss: 0.0024119464214891195
step: 570, loss: 0.0017074677161872387
step: 580, loss: 0.0003448511997703463
step: 590, loss: 0.008839321322739124
step: 600, loss: 0.0023018636275082827
step: 610, loss: 0.0001273937668884173
step: 620, loss: 0.0006089884554967284
step: 630, loss: 0.0011297359596937895
step: 640, loss: 0.0002894957142416388
step: 650, loss: 0.0002012703916989267
step: 660, loss: 0.0005108647746965289
step: 670, loss: 3.520227619446814e-05
step: 680, loss: 0.0014826473779976368
step: 690, loss: 0.05633971095085144
step: 700, loss: 0.0007652095519006252
step: 710, loss: 0.0005043072160333395
step: 720, loss: 3.9267484680749476e-05
step: 730, loss: 4.107707354705781e-05
step: 740, loss: 0.01249680295586586
step: 750, loss: 8.185175101971254e-05
step: 760, loss: 5.591417721007019e-05
step: 770, loss: 0.1473238170146942
step: 780, loss: 0.003680422203615308
step: 790, loss: 0.00011990183702437207
step: 800, loss: 0.0003203809610567987
step: 810, loss: 5.498825339600444e-05
step: 820, loss: 9.529391536489129e-05
step: 830, loss: 0.0009334944188594818
step: 840, loss: 0.003242193255573511
step: 850, loss: 7.039048796286806e-05
step: 860, loss: 3.5562428820412606e-05
step: 870, loss: 0.004033391363918781
step: 880, loss: 0.00023509367019869387
step: 890, loss: 0.002612919779494405
step: 900, loss: 0.0010016041342169046
step: 910, loss: 0.0031583188101649284
step: 920, loss: 3.557397212716751e-05
step: 930, loss: 0.0005701763438992202
step: 940, loss: 6.630265124840662e-05
step: 950, loss: 0.0008120412821881473
step: 960, loss: 0.00015609424735885113
step: 970, loss: 0.0005498079117387533
step: 980, loss: 0.0003683595568872988
step: 990, loss: 0.0004773158871103078
step: 1000, loss: 4.467315011424944e-05
step: 1010, loss: 0.0001893080770969391
step: 1020, loss: 8.969583723228425e-05
step: 1030, loss: 0.0016160220839083195
epoch 14: dev_f1=0.9511737089201877, f1=0.9167855444602948, best_f1=0.9278642149929278
step: 0, loss: 4.554050610749982e-05
step: 10, loss: 0.0032149977050721645
step: 20, loss: 0.001717943698167801
step: 30, loss: 0.0011249958770349622
step: 40, loss: 0.02060174010694027
step: 50, loss: 0.011556611396372318
step: 60, loss: 4.930736395181157e-05
step: 70, loss: 0.00020613500964827836
step: 80, loss: 0.00017721278709359467
step: 90, loss: 0.008276952430605888
step: 100, loss: 9.788798342924565e-05
step: 110, loss: 0.0004703352169599384
step: 120, loss: 0.002024930203333497
step: 130, loss: 0.0001656414824537933
step: 140, loss: 6.816675886511803e-05
step: 150, loss: 5.073787906439975e-05
step: 160, loss: 0.003225509310141206
step: 170, loss: 2.686178413568996e-05
step: 180, loss: 0.0008615215192548931
step: 190, loss: 5.617284477921203e-05
step: 200, loss: 3.424078749958426e-05
step: 210, loss: 0.0002473026397638023
step: 220, loss: 0.0004201700212433934
step: 230, loss: 0.0007315690745599568
step: 240, loss: 0.0005456553772091866
step: 250, loss: 4.4561573304235935e-05
step: 260, loss: 0.00015721852832939476
step: 270, loss: 0.001017053029499948
step: 280, loss: 0.001956682652235031
step: 290, loss: 0.09144235402345657
step: 300, loss: 5.294690345181152e-05
step: 310, loss: 4.3224899854976684e-05
step: 320, loss: 0.0009271403541788459
step: 330, loss: 0.00014079417451284826
step: 340, loss: 0.0005166687187738717
step: 350, loss: 0.00010002669296227396
step: 360, loss: 0.0001449970732210204
step: 370, loss: 0.0038458500057458878
step: 380, loss: 0.0012515401467680931
step: 390, loss: 5.085053271614015e-05
step: 400, loss: 0.00019241029804106802
step: 410, loss: 0.00013704677985515445
step: 420, loss: 0.00012200089258840308
step: 430, loss: 0.0003045995836146176
step: 440, loss: 3.799861224251799e-05
step: 450, loss: 0.007058506831526756
step: 460, loss: 0.038016434758901596
step: 470, loss: 0.0004195246146991849
step: 480, loss: 0.0035920878872275352
step: 490, loss: 0.0017034686170518398
step: 500, loss: 0.00030322163365781307
step: 510, loss: 6.502458563772961e-05
step: 520, loss: 2.234341445728205e-05
step: 530, loss: 3.181537249474786e-05
step: 540, loss: 7.402721530525014e-05
step: 550, loss: 0.0007782494649291039
step: 560, loss: 1.7944115825230256e-05
step: 570, loss: 0.06604945659637451
step: 580, loss: 5.221734318183735e-05
step: 590, loss: 0.0014312750427052379
step: 600, loss: 1.5225013157760259e-05
step: 610, loss: 6.050683441571891e-05
step: 620, loss: 0.0004713513480965048
step: 630, loss: 0.00010726368054747581
step: 640, loss: 9.062629396794364e-05
step: 650, loss: 0.00011719427129719406
step: 660, loss: 0.16229471564292908
step: 670, loss: 0.00010635354556143284
step: 680, loss: 3.728197407326661e-05
step: 690, loss: 0.000153365996084176
step: 700, loss: 0.004347243346273899
step: 710, loss: 0.03957062214612961
step: 720, loss: 0.0024228517431765795
step: 730, loss: 0.001823080820031464
step: 740, loss: 8.158115815604106e-05
step: 750, loss: 0.0008801168296486139
step: 760, loss: 4.786502540810034e-05
step: 770, loss: 0.00010333710088161752
step: 780, loss: 0.0008754472364671528
step: 790, loss: 0.00013724187738262117
step: 800, loss: 0.0001341813476756215
step: 810, loss: 7.208213355625048e-05
step: 820, loss: 0.001283706515096128
step: 830, loss: 0.039158765226602554
step: 840, loss: 0.00020638994465116411
step: 850, loss: 0.000241038782405667
step: 860, loss: 9.669008431956172e-05
step: 870, loss: 0.0001748310460243374
step: 880, loss: 0.00029008486308157444
step: 890, loss: 0.0007049692212603986
step: 900, loss: 0.00019260280532762408
step: 910, loss: 1.5277166312444024e-05
step: 920, loss: 0.0002664076164364815
step: 930, loss: 0.003619846422225237
step: 940, loss: 0.00018813511996995658
step: 950, loss: 0.0012321574613451958
step: 960, loss: 0.0006213185261003673
step: 970, loss: 0.000750437960959971
step: 980, loss: 0.001798198907636106
step: 990, loss: 8.184221223928034e-05
step: 1000, loss: 0.008181679993867874
step: 1010, loss: 0.0009414275991730392
step: 1020, loss: 0.0024192235432565212
step: 1030, loss: 2.6832243747776374e-05
epoch 15: dev_f1=0.9516728624535317, f1=0.9261176470588235, best_f1=0.9278642149929278
step: 0, loss: 0.0009082411415874958
step: 10, loss: 0.013470238074660301
step: 20, loss: 0.0005788887501694262
step: 30, loss: 0.0001096357882488519
step: 40, loss: 0.00020139600383117795
step: 50, loss: 0.00031516276067122817
step: 60, loss: 0.0046892971731722355
step: 70, loss: 4.3856965930899605e-05
step: 80, loss: 0.0003285969141870737
step: 90, loss: 0.13442616164684296
step: 100, loss: 0.0002893460332415998
step: 110, loss: 0.00024058928829617798
step: 120, loss: 0.002784514334052801
step: 130, loss: 0.00019658388919197023
step: 140, loss: 0.0002513550571165979
step: 150, loss: 0.00011225136404391378
step: 160, loss: 3.148071118630469e-05
step: 170, loss: 0.00029679754516109824
step: 180, loss: 8.805505058262497e-05
step: 190, loss: 0.00815581064671278
step: 200, loss: 9.704982949187979e-05
step: 210, loss: 0.00010178217780776322
step: 220, loss: 0.00016504121595062315
step: 230, loss: 8.767633698880672e-05
step: 240, loss: 2.3277356376638636e-05
step: 250, loss: 0.0006466889753937721
step: 260, loss: 3.7260891986079514e-05
step: 270, loss: 6.858059350633994e-05
step: 280, loss: 0.0007420510519295931
step: 290, loss: 0.0002552922524046153
step: 300, loss: 0.0019007751252502203
step: 310, loss: 5.488702663569711e-05
step: 320, loss: 0.0007085422985255718
step: 330, loss: 0.00047153045306913555
step: 340, loss: 0.0033221952617168427
step: 350, loss: 6.009582648403011e-05
step: 360, loss: 0.0015962504548951983
step: 370, loss: 0.0005728239193558693
step: 380, loss: 0.0023985514417290688
step: 390, loss: 0.005133657716214657
step: 400, loss: 0.00040086483932100236
step: 410, loss: 5.95155252085533e-05
step: 420, loss: 3.9111160731408745e-05
step: 430, loss: 0.00021335267229005694
step: 440, loss: 2.8195039703859948e-05
step: 450, loss: 0.00028475443832576275
step: 460, loss: 0.00010059333726530895
step: 470, loss: 1.319479360972764e-05
step: 480, loss: 0.0012996888253837824
step: 490, loss: 3.695765190059319e-05
step: 500, loss: 3.381458736839704e-05
step: 510, loss: 8.659558079671115e-05
step: 520, loss: 2.586889786471147e-05
step: 530, loss: 1.568687366670929e-05
step: 540, loss: 0.03269708529114723
step: 550, loss: 0.00011703452037181705
step: 560, loss: 0.00019373834948055446
step: 570, loss: 2.4041153665166348e-05
step: 580, loss: 0.0003335677902214229
step: 590, loss: 7.452115823980421e-05
step: 600, loss: 0.006078553851693869
step: 610, loss: 0.0007861778140068054
step: 620, loss: 4.352477481006645e-05
step: 630, loss: 0.0017524053109809756
step: 640, loss: 0.1274702250957489
step: 650, loss: 0.001384686678647995
step: 660, loss: 7.069919956848025e-05
step: 670, loss: 2.769149978121277e-05
step: 680, loss: 0.013371977023780346
step: 690, loss: 0.03214780613780022
step: 700, loss: 0.000181598195922561
step: 710, loss: 4.031181742902845e-05
step: 720, loss: 0.0018860023701563478
step: 730, loss: 0.0028584380634129047
step: 740, loss: 3.2395550078945234e-05
step: 750, loss: 0.02164372056722641
step: 760, loss: 0.00043436995474621654
step: 770, loss: 0.00022391777019947767
step: 780, loss: 0.0071842242032289505
step: 790, loss: 0.0021174708381295204
step: 800, loss: 6.382672290783376e-05
step: 810, loss: 3.4739274269668385e-05
step: 820, loss: 0.00011955406080232933
step: 830, loss: 8.31595971249044e-05
step: 840, loss: 5.9028403484262526e-05
step: 850, loss: 0.00030502647859975696
step: 860, loss: 2.5889354219543748e-05
step: 870, loss: 0.003645229386165738
step: 880, loss: 0.00011310045374557376
step: 890, loss: 3.8005266105756164e-05
step: 900, loss: 0.0001572018227307126
step: 910, loss: 6.889453652547672e-05
step: 920, loss: 0.032045114785432816
step: 930, loss: 2.983097692776937e-05
step: 940, loss: 2.159101677534636e-05
step: 950, loss: 0.00038337305886670947
step: 960, loss: 2.3237558707478456e-05
step: 970, loss: 5.7979897974291816e-05
step: 980, loss: 0.010618023574352264
step: 990, loss: 8.790782885625958e-05
step: 1000, loss: 0.00041884343954734504
step: 1010, loss: 0.0001546234416309744
step: 1020, loss: 0.0009994799038395286
step: 1030, loss: 0.00011754172737710178
epoch 16: dev_f1=0.9534016775396085, f1=0.9310670443814919, best_f1=0.9310670443814919
step: 0, loss: 0.00011153622472193092
step: 10, loss: 3.651264705695212e-05
step: 20, loss: 2.0227838831488043e-05
step: 30, loss: 0.0021976218558847904
step: 40, loss: 0.0003669516881927848
step: 50, loss: 0.0026408310513943434
step: 60, loss: 5.201703606871888e-05
step: 70, loss: 0.0194623414427042
step: 80, loss: 0.00010684472363209352
step: 90, loss: 0.09679380804300308
step: 100, loss: 0.0006422394653782248
step: 110, loss: 2.4850000045262277e-05
step: 120, loss: 2.2697609892929904e-05
step: 130, loss: 0.00010546354315010831
step: 140, loss: 7.198883395176381e-05
step: 150, loss: 6.0258164012338966e-05
step: 160, loss: 0.0003745652793440968
step: 170, loss: 0.0004855834995396435
step: 180, loss: 3.525155989336781e-05
step: 190, loss: 2.3300464818021283e-05
step: 200, loss: 2.7148747903993353e-05
step: 210, loss: 0.0044439127668738365
step: 220, loss: 4.5509881601901725e-05
step: 230, loss: 3.9715534512652084e-05
step: 240, loss: 0.00013578037032857537
step: 250, loss: 0.0006416623946279287
step: 260, loss: 0.0001742849126458168
step: 270, loss: 0.020097432658076286
step: 280, loss: 1.9456794689176604e-05
step: 290, loss: 4.859806358581409e-05
step: 300, loss: 0.00029602841823361814
step: 310, loss: 2.4097549612633884e-05
step: 320, loss: 2.1169080355321057e-05
step: 330, loss: 5.8096760767512023e-05
step: 340, loss: 0.001354540348984301
step: 350, loss: 2.2685640942654572e-05
step: 360, loss: 0.01968574896454811
step: 370, loss: 0.0010079949861392379
step: 380, loss: 1.1283803360129241e-05
step: 390, loss: 0.00014275666035246104
step: 400, loss: 0.0005162520101293921
step: 410, loss: 0.030970128253102303
step: 420, loss: 0.00013709221093449742
step: 430, loss: 0.006945135537534952
step: 440, loss: 0.0008842775132507086
step: 450, loss: 0.0008709151879884303
step: 460, loss: 0.00010217467934126034
step: 470, loss: 0.0017727711237967014
step: 480, loss: 3.7018027796875685e-05
step: 490, loss: 0.00011010586604243144
step: 500, loss: 0.0003552418784238398
step: 510, loss: 0.00016831461107358336
step: 520, loss: 1.7355443560518324e-05
step: 530, loss: 0.00022801666636951268
step: 540, loss: 0.00013500050408765674
step: 550, loss: 0.0002615179982967675
step: 560, loss: 0.00010234572982881218
step: 570, loss: 9.308649896411225e-05
step: 580, loss: 2.5176565031870268e-05
step: 590, loss: 0.00017799636407289654
step: 600, loss: 0.000953996554017067
step: 610, loss: 0.00095957494340837
step: 620, loss: 0.0017679996090009809
step: 630, loss: 6.30427966825664e-05
step: 640, loss: 8.069676550803706e-05
step: 650, loss: 2.310316813236568e-05
step: 660, loss: 3.320133328088559e-05
step: 670, loss: 6.441879668273032e-05
step: 680, loss: 1.6413328921771608e-05
step: 690, loss: 0.00875435397028923
step: 700, loss: 0.0002348675043322146
step: 710, loss: 0.033016905188560486
step: 720, loss: 0.0006417804979719222
step: 730, loss: 0.0012690348085016012
step: 740, loss: 0.00011664073099382222
step: 750, loss: 0.00027722626691684127
step: 760, loss: 4.1506362322252244e-05
step: 770, loss: 0.0022737581748515368
step: 780, loss: 0.006212948355823755
step: 790, loss: 4.771491148858331e-05
step: 800, loss: 0.06980395317077637
step: 810, loss: 0.0012677215272560716
step: 820, loss: 0.004125503357499838
step: 830, loss: 4.706571053247899e-05
step: 840, loss: 8.89540824573487e-05
step: 850, loss: 2.0696927094832063e-05
step: 860, loss: 5.137947664479725e-05
step: 870, loss: 7.550432201242074e-05
step: 880, loss: 0.00017615582328289747
step: 890, loss: 0.00010689721239032224
step: 900, loss: 3.0410516046686098e-05
step: 910, loss: 4.2147723434027284e-05
step: 920, loss: 3.801227649091743e-05
step: 930, loss: 1.3246930393506773e-05
step: 940, loss: 2.5371427909703925e-05
step: 950, loss: 9.88324245554395e-05
step: 960, loss: 3.930487946490757e-05
step: 970, loss: 3.180026396876201e-05
step: 980, loss: 0.0002509265614207834
step: 990, loss: 3.383802322787233e-05
step: 1000, loss: 0.0022023492492735386
step: 1010, loss: 1.7411646695109084e-05
step: 1020, loss: 0.00033958954736590385
step: 1030, loss: 0.002997018164023757
epoch 17: dev_f1=0.9500699953336444, f1=0.9225653206650831, best_f1=0.9310670443814919
step: 0, loss: 0.0004511475854087621
step: 10, loss: 1.4878464753564913e-05
step: 20, loss: 0.009294488467276096
step: 30, loss: 0.00010406378714833409
step: 40, loss: 0.00034962157951667905
step: 50, loss: 1.87560472113546e-05
step: 60, loss: 8.278050518129021e-05
step: 70, loss: 1.550821980345063e-05
step: 80, loss: 0.000230671459576115
step: 90, loss: 6.965724605834112e-05
step: 100, loss: 2.8473759812186472e-05
step: 110, loss: 0.00017534980725031346
step: 120, loss: 2.946628774225246e-05
step: 130, loss: 5.374578540795483e-05
step: 140, loss: 0.00013272355135995895
step: 150, loss: 9.59718890953809e-05
step: 160, loss: 0.0002035885991062969
step: 170, loss: 4.0705835999688134e-05
step: 180, loss: 0.0001229470653925091
step: 190, loss: 0.00032986392034217715
step: 200, loss: 0.00788330752402544
step: 210, loss: 0.0007042462239041924
step: 220, loss: 2.8943890356458724e-05
step: 230, loss: 0.00047143135452643037
step: 240, loss: 0.1421315222978592
step: 250, loss: 3.1198072974802926e-05
step: 260, loss: 3.5714976547751576e-05
step: 270, loss: 0.00011485756112961099
step: 280, loss: 4.390958201838657e-05
step: 290, loss: 0.000160743307787925
step: 300, loss: 3.4685272112255916e-05
step: 310, loss: 7.589424785692245e-05
step: 320, loss: 0.0006259301444515586
step: 330, loss: 0.0011181328445672989
step: 340, loss: 2.2559681383427233e-05
step: 350, loss: 0.0007082266383804381
step: 360, loss: 3.829913475783542e-05
step: 370, loss: 0.054718051105737686
step: 380, loss: 0.00019076411263085902
step: 390, loss: 1.9788187273661606e-05
step: 400, loss: 0.00011191080557182431
step: 410, loss: 1.3075617971480824e-05
step: 420, loss: 0.0025901186745613813
step: 430, loss: 0.00015424563025590032
step: 440, loss: 0.0001046857432811521
step: 450, loss: 0.0031444814521819353
step: 460, loss: 3.632223524618894e-05
step: 470, loss: 0.00011158685811096802
step: 480, loss: 9.383694123243913e-05
step: 490, loss: 0.00018865987658500671
step: 500, loss: 5.658991358359344e-05
step: 510, loss: 0.0007679993286728859
step: 520, loss: 9.261229570256546e-05
step: 530, loss: 0.0031932767014950514
step: 540, loss: 0.0013274900848045945
step: 550, loss: 6.030136501067318e-05
step: 560, loss: 0.0006584156071767211
step: 570, loss: 3.144163201795891e-05
step: 580, loss: 3.62067403330002e-05
step: 590, loss: 2.4947425117716193e-05
step: 600, loss: 0.0006137556047178805
step: 610, loss: 3.5923429095419124e-05
step: 620, loss: 0.00020348560065031052
step: 630, loss: 1.780288584996015e-05
step: 640, loss: 2.0104045688640326e-05
step: 650, loss: 0.0018762426916509867
step: 660, loss: 2.6760271794046275e-05
step: 670, loss: 8.616544619144406e-06
step: 680, loss: 3.959870446124114e-05
step: 690, loss: 0.0011928091989830136
step: 700, loss: 8.316561434185132e-05
step: 710, loss: 2.4912773369578645e-05
step: 720, loss: 7.913707668194547e-05
step: 730, loss: 0.04281080141663551
step: 740, loss: 0.00011292740236967802
step: 750, loss: 0.00012105786299798638
step: 760, loss: 0.00011178192653460428
step: 770, loss: 1.4610350262955762e-05
step: 780, loss: 3.616969479480758e-05
step: 790, loss: 0.00036344665568321943
step: 800, loss: 3.7694917409680784e-05
step: 810, loss: 0.0021275035105645657
step: 820, loss: 0.00013658903480973095
step: 830, loss: 0.036604009568691254
step: 840, loss: 1.8827084204531275e-05
step: 850, loss: 1.7843529349192977e-05
step: 860, loss: 5.996786057949066e-05
step: 870, loss: 2.6421881557325833e-05
step: 880, loss: 0.0004506498225964606
step: 890, loss: 0.00020407639385666698
step: 900, loss: 0.0013536758488044143
step: 910, loss: 0.0001214679577969946
step: 920, loss: 2.535298335715197e-05
step: 930, loss: 3.091045800829306e-05
step: 940, loss: 0.0015496816486120224
step: 950, loss: 0.000242566253291443
step: 960, loss: 0.00020449391740839928
step: 970, loss: 2.475684777891729e-05
step: 980, loss: 0.0002626653586048633
step: 990, loss: 0.0006011394434608519
step: 1000, loss: 1.5265823094523512e-05
step: 1010, loss: 0.0001000359479803592
step: 1020, loss: 8.222761971410364e-05
step: 1030, loss: 1.0717576515162364e-05
epoch 18: dev_f1=0.9497464269248502, f1=0.9280742459396751, best_f1=0.9310670443814919
step: 0, loss: 2.4693044906598516e-05
step: 10, loss: 0.04266645759344101
step: 20, loss: 2.9073878977214918e-05
step: 30, loss: 0.000914284901227802
step: 40, loss: 4.9226397095480934e-05
step: 50, loss: 3.9484268199885264e-05
step: 60, loss: 7.598901720484719e-05
step: 70, loss: 4.7709527279948816e-05
step: 80, loss: 0.0010195052018389106
step: 90, loss: 3.170091440551914e-05
step: 100, loss: 0.00024358282098546624
step: 110, loss: 3.99932250729762e-05
step: 120, loss: 0.0004056735779158771
step: 130, loss: 2.4678769477759488e-05
step: 140, loss: 8.153344970196486e-05
step: 150, loss: 2.0011599190183915e-05
step: 160, loss: 5.5276777857216075e-05
step: 170, loss: 8.896303188521415e-05
step: 180, loss: 0.0012915268307551742
step: 190, loss: 0.0002566211041994393
step: 200, loss: 0.00010154395567951724
step: 210, loss: 1.877141767181456e-05
step: 220, loss: 0.0003100278554484248
step: 230, loss: 0.0012252702144905925
step: 240, loss: 0.00023086061992216855
step: 250, loss: 2.8969412596779875e-05
step: 260, loss: 0.0001510556903667748
step: 270, loss: 7.099917274899781e-05
step: 280, loss: 2.0015308109577745e-05
step: 290, loss: 0.0017430075677111745
step: 300, loss: 0.0002685127838049084
step: 310, loss: 0.0002518411201890558
step: 320, loss: 0.0001361940085189417
step: 330, loss: 4.296967017580755e-05
step: 340, loss: 0.02370474860072136
step: 350, loss: 4.704399179900065e-05
step: 360, loss: 4.8357658670283854e-05
step: 370, loss: 2.16394109884277e-05
step: 380, loss: 1.0132703209819738e-05
step: 390, loss: 2.520019916119054e-05
step: 400, loss: 2.2198371880222112e-05
step: 410, loss: 6.317272345768288e-05
step: 420, loss: 9.73410078586312e-06
step: 430, loss: 1.5370063920272514e-05
step: 440, loss: 0.05693356692790985
step: 450, loss: 3.1791976653039455e-05
step: 460, loss: 5.3504987590713426e-05
step: 470, loss: 0.0010696934768930078
step: 480, loss: 8.436266944045201e-05
step: 490, loss: 7.300200377358124e-05
step: 500, loss: 0.0008696712320670485
step: 510, loss: 2.20382098632399e-05
step: 520, loss: 1.677430554991588e-05
step: 530, loss: 8.654152770759538e-05
step: 540, loss: 2.7248901460552588e-05
step: 550, loss: 0.00013526204566005617
step: 560, loss: 7.468925468856469e-05
step: 570, loss: 0.0007914322195574641
step: 580, loss: 2.1378395103965886e-05
step: 590, loss: 8.866954885888845e-05
step: 600, loss: 8.744428487261757e-05
step: 610, loss: 0.0006906979251652956
step: 620, loss: 0.0018244072562083602
step: 630, loss: 1.5332881957874633e-05
step: 640, loss: 2.4496568585163914e-05
step: 650, loss: 3.521119651850313e-05
step: 660, loss: 9.789981959329452e-06
step: 670, loss: 0.0008348789415322244
step: 680, loss: 1.6506484826095402e-05
step: 690, loss: 2.359511563554406e-05
step: 700, loss: 0.004356783349066973
step: 710, loss: 3.851567453239113e-05
step: 720, loss: 1.2770143257512245e-05
step: 730, loss: 3.32686940964777e-05
step: 740, loss: 1.908760896185413e-05
step: 750, loss: 1.504985812061932e-05
step: 760, loss: 2.51360543188639e-05
step: 770, loss: 0.016820214688777924
step: 780, loss: 8.69186405907385e-05
step: 790, loss: 1.817148040572647e-05
step: 800, loss: 0.00022826124040875584
step: 810, loss: 0.00012411798525135964
step: 820, loss: 0.00015177570458035916
step: 830, loss: 0.00036489954800345004
step: 840, loss: 2.505277188902255e-05
step: 850, loss: 0.002887690206989646
step: 860, loss: 2.3363600121228956e-05
step: 870, loss: 0.0002783026429824531
step: 880, loss: 0.00010015959560405463
step: 890, loss: 0.001161172054708004
step: 900, loss: 8.007902943063527e-05
step: 910, loss: 0.0015949116786941886
step: 920, loss: 0.023048128932714462
step: 930, loss: 0.00028420111630111933
step: 940, loss: 3.631844083429314e-05
step: 950, loss: 1.8103384718415327e-05
step: 960, loss: 3.984397335443646e-05
step: 970, loss: 0.00013071848661638796
step: 980, loss: 1.7854761608759873e-05
step: 990, loss: 0.0007875816081650555
step: 1000, loss: 2.8555115932249464e-05
step: 1010, loss: 0.00019460314069874585
step: 1020, loss: 2.2022701159585267e-05
step: 1030, loss: 0.009877512231469154
epoch 19: dev_f1=0.9505773672055428, f1=0.9301025163094129, best_f1=0.9310670443814919
step: 0, loss: 4.433949652593583e-05
step: 10, loss: 1.750848605297506e-05
step: 20, loss: 1.453212826163508e-05
step: 30, loss: 0.00019734485249500722
step: 40, loss: 9.551585208100732e-06
step: 50, loss: 0.0003986322262790054
step: 60, loss: 2.9174670999054797e-05
step: 70, loss: 3.710139208124019e-05
step: 80, loss: 5.3079318604432046e-05
step: 90, loss: 3.397105319891125e-05
step: 100, loss: 0.0004291123477742076
step: 110, loss: 7.521319639636204e-05
step: 120, loss: 5.030010288464837e-05
step: 130, loss: 5.692769991583191e-05
step: 140, loss: 5.988294287817553e-05
step: 150, loss: 0.00041404174407944083
step: 160, loss: 0.007161542773246765
step: 170, loss: 7.681440911255777e-05
step: 180, loss: 1.4293726962932851e-05
step: 190, loss: 0.00024361960822716355
step: 200, loss: 0.020336344838142395
step: 210, loss: 2.8932661734870635e-05
step: 220, loss: 0.00018290946900378913
step: 230, loss: 3.4973967558471486e-05
step: 240, loss: 2.5308443582616746e-05
step: 250, loss: 0.0003669455472845584
step: 260, loss: 3.373863728484139e-05
step: 270, loss: 6.198227492859587e-05
step: 280, loss: 3.268941509304568e-05
step: 290, loss: 0.004373122472316027
step: 300, loss: 1.62265969265718e-05
step: 310, loss: 0.00016173633048310876
step: 320, loss: 1.0777182978927158e-05
step: 330, loss: 1.634630280022975e-05
step: 340, loss: 2.7103065804112703e-05
step: 350, loss: 0.00036749106948263943
step: 360, loss: 0.0002313540899194777
step: 370, loss: 4.508261918090284e-05
step: 380, loss: 0.0002679226454347372
step: 390, loss: 4.588687443174422e-05
step: 400, loss: 0.0014188874047249556
step: 410, loss: 0.00012821535347029567
step: 420, loss: 2.6906520361080766e-05
step: 430, loss: 1.545966551930178e-05
step: 440, loss: 0.00026636451366357505
step: 450, loss: 0.00013779141590930521
step: 460, loss: 4.752324821311049e-05
step: 470, loss: 1.540009179734625e-05
step: 480, loss: 0.0016230371547862887
step: 490, loss: 2.3549688194179907e-05
step: 500, loss: 2.852085708582308e-05
step: 510, loss: 8.307197276735678e-05
step: 520, loss: 0.00025825746706686914
step: 530, loss: 8.527215686626732e-05
step: 540, loss: 3.4004944609478116e-05
step: 550, loss: 0.00015088383224792778
step: 560, loss: 0.010576914995908737
step: 570, loss: 0.00024801254039630294
step: 580, loss: 3.644993557827547e-05
step: 590, loss: 4.137299401918426e-05
step: 600, loss: 2.7024019800592214e-05
step: 610, loss: 4.892907236353494e-05
step: 620, loss: 4.7218549298122525e-05
step: 630, loss: 0.0008313821745105088
step: 640, loss: 4.405032086651772e-05
step: 650, loss: 0.00013348422362469137
step: 660, loss: 2.1296777049428783e-05
step: 670, loss: 1.1175763575010933e-05
step: 680, loss: 2.4391207261942327e-05
step: 690, loss: 2.4980872694868594e-05
step: 700, loss: 0.008059842512011528
step: 710, loss: 3.302597178844735e-05
step: 720, loss: 1.219269324792549e-05
step: 730, loss: 5.0911872676806524e-05
step: 740, loss: 6.205240060808137e-05
step: 750, loss: 3.208793350495398e-05
step: 760, loss: 5.598811185336672e-05
step: 770, loss: 0.00027887080796062946
step: 780, loss: 2.7446389140095562e-05
step: 790, loss: 0.00016094770398922265
step: 800, loss: 6.030530857970007e-05
step: 810, loss: 4.2600524466251954e-05
step: 820, loss: 1.7527079762658104e-05
step: 830, loss: 0.014151707291603088
step: 840, loss: 3.105869473074563e-05
step: 850, loss: 1.906928446260281e-05
step: 860, loss: 6.075387500459328e-05
step: 870, loss: 1.2114514902350493e-05
step: 880, loss: 1.518771387054585e-05
step: 890, loss: 0.0006703246617689729
step: 900, loss: 3.346343874000013e-05
step: 910, loss: 5.775859972345643e-05
step: 920, loss: 4.0082246414385736e-05
step: 930, loss: 2.1739933799835853e-05
step: 940, loss: 1.0501485121494625e-05
step: 950, loss: 2.086467793560587e-05
step: 960, loss: 3.223736348445527e-05
step: 970, loss: 1.1887200344062876e-05
step: 980, loss: 0.001131814089603722
step: 990, loss: 5.3590614697895944e-05
step: 1000, loss: 9.4129383796826e-05
step: 1010, loss: 0.00012382115528453141
step: 1020, loss: 6.915500853210688e-05
step: 1030, loss: 1.2605956726474687e-05
epoch 20: dev_f1=0.951061865189289, f1=0.9288040949278734, best_f1=0.9310670443814919
