cuda
Device: cuda
step: 0, loss: 0.5810155868530273
step: 10, loss: 0.5723131895065308
step: 20, loss: 0.31871747970581055
step: 30, loss: 0.2433691769838333
step: 40, loss: 0.258482426404953
step: 50, loss: 0.320669025182724
step: 60, loss: 0.40423285961151123
step: 70, loss: 0.32076096534729004
step: 80, loss: 0.30238646268844604
step: 90, loss: 0.1587512493133545
step: 100, loss: 0.36266714334487915
step: 110, loss: 0.31253358721733093
step: 120, loss: 0.41201192140579224
step: 130, loss: 0.22142890095710754
step: 140, loss: 0.42402464151382446
step: 150, loss: 0.09825873374938965
step: 160, loss: 0.38923218846321106
step: 170, loss: 0.31295374035835266
step: 180, loss: 0.3123093843460083
step: 190, loss: 0.2872788608074188
step: 200, loss: 0.4806690216064453
step: 210, loss: 0.4100273549556732
step: 220, loss: 0.24879147112369537
step: 230, loss: 0.3137631416320801
step: 240, loss: 0.38199475407600403
step: 250, loss: 0.2759673297405243
step: 260, loss: 0.3181166648864746
step: 270, loss: 0.48369577527046204
step: 280, loss: 0.40115728974342346
step: 290, loss: 0.35724374651908875
step: 300, loss: 0.35631024837493896
step: 310, loss: 0.5487583875656128
step: 320, loss: 0.24643388390541077
step: 330, loss: 0.3427785038948059
step: 340, loss: 0.3405865728855133
step: 350, loss: 0.1145205870270729
epoch 1: dev_f1=0.3982102908277405, f1=0.2911694510739857, best_f1=0.2911694510739857
step: 0, loss: 0.33823487162590027
step: 10, loss: 0.4170273244380951
step: 20, loss: 0.15075641870498657
step: 30, loss: 0.26569902896881104
step: 40, loss: 0.24368461966514587
step: 50, loss: 0.2591743469238281
step: 60, loss: 0.23710715770721436
step: 70, loss: 0.21079117059707642
step: 80, loss: 0.4337906837463379
step: 90, loss: 0.2009020894765854
step: 100, loss: 0.2254854142665863
step: 110, loss: 0.1485123485326767
step: 120, loss: 0.24401764571666718
step: 130, loss: 0.3252853453159332
step: 140, loss: 0.24908818304538727
step: 150, loss: 0.09029492735862732
step: 160, loss: 0.40274542570114136
step: 170, loss: 0.26490840315818787
step: 180, loss: 0.5231706500053406
step: 190, loss: 0.09155277162790298
step: 200, loss: 0.1643594652414322
step: 210, loss: 0.1940838098526001
step: 220, loss: 0.1846514791250229
step: 230, loss: 0.1484089493751526
step: 240, loss: 0.39191949367523193
step: 250, loss: 0.2723560333251953
step: 260, loss: 0.12337353825569153
step: 270, loss: 0.2251129001379013
step: 280, loss: 0.24650298058986664
step: 290, loss: 0.2305510938167572
step: 300, loss: 0.475534588098526
step: 310, loss: 0.2994130849838257
step: 320, loss: 0.2318042367696762
step: 330, loss: 0.21417084336280823
step: 340, loss: 0.09023518115282059
step: 350, loss: 0.3909572660923004
epoch 2: dev_f1=0.739454094292804, f1=0.608695652173913, best_f1=0.608695652173913
step: 0, loss: 0.18156404793262482
step: 10, loss: 0.14725328981876373
step: 20, loss: 0.3677760064601898
step: 30, loss: 0.19484791159629822
step: 40, loss: 0.14700284600257874
step: 50, loss: 0.41848739981651306
step: 60, loss: 0.08362586796283722
step: 70, loss: 0.16446872055530548
step: 80, loss: 0.08014100790023804
step: 90, loss: 0.4297313094139099
step: 100, loss: 0.1398218423128128
step: 110, loss: 0.2547919750213623
step: 120, loss: 0.3081223666667938
step: 130, loss: 0.3042433559894562
step: 140, loss: 0.2252490222454071
step: 150, loss: 0.24809269607067108
step: 160, loss: 0.13589166104793549
step: 170, loss: 0.16814659535884857
step: 180, loss: 0.2019103765487671
step: 190, loss: 0.09570684283971786
step: 200, loss: 0.16338852047920227
step: 210, loss: 0.035086099058389664
step: 220, loss: 0.09997737407684326
step: 230, loss: 0.26330262422561646
step: 240, loss: 0.23959949612617493
step: 250, loss: 0.12404923141002655
step: 260, loss: 0.12143982201814651
step: 270, loss: 0.35454848408699036
step: 280, loss: 0.09199123829603195
step: 290, loss: 0.11594319343566895
step: 300, loss: 0.07631569355726242
step: 310, loss: 0.16218936443328857
step: 320, loss: 0.24220407009124756
step: 330, loss: 0.10991593450307846
step: 340, loss: 0.0752919390797615
step: 350, loss: 0.12721306085586548
epoch 3: dev_f1=0.7888631090487238, f1=0.6844660194174758, best_f1=0.6844660194174758
step: 0, loss: 0.24031008780002594
step: 10, loss: 0.08493781089782715
step: 20, loss: 0.07752421498298645
step: 30, loss: 0.31757938861846924
step: 40, loss: 0.20645296573638916
step: 50, loss: 0.1316881626844406
step: 60, loss: 0.19055666029453278
step: 70, loss: 0.07521788775920868
step: 80, loss: 0.07588780671358109
step: 90, loss: 0.2018120288848877
step: 100, loss: 0.14654265344142914
step: 110, loss: 0.12111163139343262
step: 120, loss: 0.13131043314933777
step: 130, loss: 0.26496604084968567
step: 140, loss: 0.3272433876991272
step: 150, loss: 0.163133904337883
step: 160, loss: 0.124672532081604
step: 170, loss: 0.12074069678783417
step: 180, loss: 0.17856764793395996
step: 190, loss: 0.10728655755519867
step: 200, loss: 0.15236259996891022
step: 210, loss: 0.16382817924022675
step: 220, loss: 0.1943618208169937
step: 230, loss: 0.2821325361728668
step: 240, loss: 0.1201707199215889
step: 250, loss: 0.1445629596710205
step: 260, loss: 0.28596895933151245
step: 270, loss: 0.25397542119026184
step: 280, loss: 0.1563524752855301
step: 290, loss: 0.35527104139328003
step: 300, loss: 0.23194453120231628
step: 310, loss: 0.22482162714004517
step: 320, loss: 0.0926654264330864
step: 330, loss: 0.16159014403820038
step: 340, loss: 0.39699748158454895
step: 350, loss: 0.11415809392929077
epoch 4: dev_f1=0.8164251207729469, f1=0.7669172932330827, best_f1=0.7669172932330827
step: 0, loss: 0.13955450057983398
step: 10, loss: 0.0879947766661644
step: 20, loss: 0.17107945680618286
step: 30, loss: 0.1472465991973877
step: 40, loss: 0.20996488630771637
step: 50, loss: 0.09866213798522949
step: 60, loss: 0.07117614895105362
step: 70, loss: 0.027425367385149002
step: 80, loss: 0.1351737082004547
step: 90, loss: 0.13254445791244507
step: 100, loss: 0.2747966945171356
step: 110, loss: 0.1070808544754982
step: 120, loss: 0.07823944836854935
step: 130, loss: 0.13224782049655914
step: 140, loss: 0.032916780561208725
step: 150, loss: 0.04243174567818642
step: 160, loss: 0.1464606523513794
step: 170, loss: 0.026200788095593452
step: 180, loss: 0.14122888445854187
step: 190, loss: 0.15981779992580414
step: 200, loss: 0.33037588000297546
step: 210, loss: 0.09675882011651993
step: 220, loss: 0.06485281884670258
step: 230, loss: 0.31221580505371094
step: 240, loss: 0.09526664018630981
step: 250, loss: 0.0815703272819519
step: 260, loss: 0.14755167067050934
step: 270, loss: 0.021266663447022438
step: 280, loss: 0.06565581262111664
step: 290, loss: 0.15161028504371643
step: 300, loss: 0.0532216839492321
step: 310, loss: 0.05623822659254074
step: 320, loss: 0.20542794466018677
step: 330, loss: 0.08961549401283264
step: 340, loss: 0.05418464168906212
step: 350, loss: 0.27296528220176697
epoch 5: dev_f1=0.8599508599508598, f1=0.7346938775510204, best_f1=0.7346938775510204
step: 0, loss: 0.0740484669804573
step: 10, loss: 0.08614002168178558
step: 20, loss: 0.08330614864826202
step: 30, loss: 0.06387125700712204
step: 40, loss: 0.1162356585264206
step: 50, loss: 0.22290261089801788
step: 60, loss: 0.07845655083656311
step: 70, loss: 0.12310770153999329
step: 80, loss: 0.22089937329292297
step: 90, loss: 0.18774884939193726
step: 100, loss: 0.012010548263788223
step: 110, loss: 0.14322689175605774
step: 120, loss: 0.040446408092975616
step: 130, loss: 0.18961632251739502
step: 140, loss: 0.13512875139713287
step: 150, loss: 0.010690689086914062
step: 160, loss: 0.04703567549586296
step: 170, loss: 0.010326114483177662
step: 180, loss: 0.0759723037481308
step: 190, loss: 0.08233428001403809
step: 200, loss: 0.1299414038658142
step: 210, loss: 0.06828827410936356
step: 220, loss: 0.11358117312192917
step: 230, loss: 0.0034919229801744223
step: 240, loss: 0.008731326088309288
step: 250, loss: 0.01579340547323227
step: 260, loss: 0.05135190486907959
step: 270, loss: 0.016702523455023766
step: 280, loss: 0.07473485916852951
step: 290, loss: 0.01564081758260727
step: 300, loss: 0.03268841281533241
step: 310, loss: 0.04460803419351578
step: 320, loss: 0.02032209001481533
step: 330, loss: 0.10967360436916351
step: 340, loss: 0.03828483074903488
step: 350, loss: 0.023638205602765083
epoch 6: dev_f1=0.8352668213457077, f1=0.7799043062200957, best_f1=0.7346938775510204
step: 0, loss: 0.05805940926074982
step: 10, loss: 0.043794360011816025
step: 20, loss: 0.11503341048955917
step: 30, loss: 0.13844376802444458
step: 40, loss: 0.023123174905776978
step: 50, loss: 0.0011178456479683518
step: 60, loss: 0.14944963157176971
step: 70, loss: 0.0037846597842872143
step: 80, loss: 0.18646548688411713
step: 90, loss: 0.04447136074304581
step: 100, loss: 0.023511018604040146
step: 110, loss: 0.07362367957830429
step: 120, loss: 0.17855098843574524
step: 130, loss: 0.011832395568490028
step: 140, loss: 0.04258675128221512
step: 150, loss: 0.021567678079009056
step: 160, loss: 0.03930816054344177
step: 170, loss: 0.0285565834492445
step: 180, loss: 0.10850467532873154
step: 190, loss: 0.02118506282567978
step: 200, loss: 0.03128272294998169
step: 210, loss: 0.0041685509495437145
step: 220, loss: 0.022554390132427216
step: 230, loss: 0.009347144514322281
step: 240, loss: 0.1367621272802353
step: 250, loss: 0.0016250003827735782
step: 260, loss: 0.06768933683633804
step: 270, loss: 0.05891171097755432
step: 280, loss: 0.09459526091814041
step: 290, loss: 0.01246359571814537
step: 300, loss: 0.30918532609939575
step: 310, loss: 0.03554967790842056
step: 320, loss: 0.019839370623230934
step: 330, loss: 0.059548065066337585
step: 340, loss: 0.020219258964061737
step: 350, loss: 0.0998503640294075
epoch 7: dev_f1=0.837092731829574, f1=0.7751937984496124, best_f1=0.7346938775510204
step: 0, loss: 0.06669753044843674
step: 10, loss: 0.05808085575699806
step: 20, loss: 0.012752178125083447
step: 30, loss: 0.006515972316265106
step: 40, loss: 0.07267569750547409
step: 50, loss: 0.014630869962275028
step: 60, loss: 0.14861884713172913
step: 70, loss: 0.09404898434877396
step: 80, loss: 0.12375073879957199
step: 90, loss: 0.10961131751537323
step: 100, loss: 0.02542296051979065
step: 110, loss: 0.05484490469098091
step: 120, loss: 0.15153393149375916
step: 130, loss: 0.011160402558743954
step: 140, loss: 0.0008956810343079269
step: 150, loss: 0.020882677286863327
step: 160, loss: 0.2099485695362091
step: 170, loss: 0.03920827805995941
step: 180, loss: 0.03397046774625778
step: 190, loss: 0.05924929678440094
step: 200, loss: 0.057271163910627365
step: 210, loss: 0.14943644404411316
step: 220, loss: 0.012069298885762691
step: 230, loss: 0.005496252793818712
step: 240, loss: 0.03194810077548027
step: 250, loss: 0.14927448332309723
step: 260, loss: 0.06657912582159042
step: 270, loss: 0.04928417503833771
step: 280, loss: 0.006495525129139423
step: 290, loss: 0.03220219165086746
step: 300, loss: 0.011314383707940578
step: 310, loss: 0.01855594664812088
step: 320, loss: 0.012917484156787395
step: 330, loss: 0.014113075099885464
step: 340, loss: 0.006658966653048992
step: 350, loss: 0.058459822088479996
epoch 8: dev_f1=0.8660287081339713, f1=0.801980198019802, best_f1=0.801980198019802
step: 0, loss: 0.06270861625671387
step: 10, loss: 0.024295184761285782
step: 20, loss: 0.0997222438454628
step: 30, loss: 0.008501759730279446
step: 40, loss: 0.008180912584066391
step: 50, loss: 0.06477776914834976
step: 60, loss: 0.014767236076295376
step: 70, loss: 0.07876437902450562
step: 80, loss: 0.038648758083581924
step: 90, loss: 0.07957711815834045
step: 100, loss: 0.010293220169842243
step: 110, loss: 0.0017121564596891403
step: 120, loss: 0.01053073164075613
step: 130, loss: 0.029783163219690323
step: 140, loss: 0.03274733945727348
step: 150, loss: 0.005253027658909559
step: 160, loss: 0.025732308626174927
step: 170, loss: 0.017901161685585976
step: 180, loss: 0.036765992641448975
step: 190, loss: 0.022376738488674164
step: 200, loss: 0.006705147679895163
step: 210, loss: 0.04156867414712906
step: 220, loss: 0.0014685499481856823
step: 230, loss: 0.011493576690554619
step: 240, loss: 0.001005141413770616
step: 250, loss: 0.0011014421470463276
step: 260, loss: 0.007465497124940157
step: 270, loss: 0.0031369682401418686
step: 280, loss: 0.0052865357138216496
step: 290, loss: 0.01129356399178505
step: 300, loss: 0.03274182602763176
step: 310, loss: 0.011240780353546143
step: 320, loss: 0.004193455912172794
step: 330, loss: 0.001608185120858252
step: 340, loss: 0.05628044530749321
step: 350, loss: 0.06247588247060776
epoch 9: dev_f1=0.8337236533957846, f1=0.765375854214123, best_f1=0.801980198019802
step: 0, loss: 0.0038396872114390135
step: 10, loss: 0.014846667647361755
step: 20, loss: 0.015749014914035797
step: 30, loss: 0.0033401919063180685
step: 40, loss: 0.007085428573191166
step: 50, loss: 0.009478805586695671
step: 60, loss: 0.02604789100587368
step: 70, loss: 0.02306010201573372
step: 80, loss: 0.006321874912828207
step: 90, loss: 0.005278929136693478
step: 100, loss: 0.029621662572026253
step: 110, loss: 0.005510873161256313
step: 120, loss: 0.05911598354578018
step: 130, loss: 0.021387333050370216
step: 140, loss: 0.0027221261989325285
step: 150, loss: 0.0009932821849361062
step: 160, loss: 0.020483996719121933
step: 170, loss: 0.0620083250105381
step: 180, loss: 0.0014808806590735912
step: 190, loss: 0.029061738401651382
step: 200, loss: 0.015899037942290306
step: 210, loss: 0.06466376036405563
step: 220, loss: 0.0005471956101246178
step: 230, loss: 0.006204668898135424
step: 240, loss: 0.0013533466262742877
step: 250, loss: 0.03539934381842613
step: 260, loss: 0.0035182919818907976
step: 270, loss: 0.014852814376354218
step: 280, loss: 0.0651017427444458
step: 290, loss: 0.036535199731588364
step: 300, loss: 0.007265462540090084
step: 310, loss: 0.0100061921402812
step: 320, loss: 0.005060745868831873
step: 330, loss: 0.0823071300983429
step: 340, loss: 0.11847362667322159
step: 350, loss: 0.0017492385813966393
epoch 10: dev_f1=0.8463356973995272, f1=0.7666666666666666, best_f1=0.801980198019802
step: 0, loss: 0.0010781347518786788
step: 10, loss: 0.07219750434160233
step: 20, loss: 0.006308877374976873
step: 30, loss: 0.0006908762152306736
step: 40, loss: 0.010352591052651405
step: 50, loss: 0.0008312048157677054
step: 60, loss: 0.024517042562365532
step: 70, loss: 0.003800561185926199
step: 80, loss: 0.12014824151992798
step: 90, loss: 0.037470124661922455
step: 100, loss: 0.024121573194861412
step: 110, loss: 0.008456559851765633
step: 120, loss: 0.0038411328569054604
step: 130, loss: 0.007582961581647396
step: 140, loss: 0.010258957743644714
step: 150, loss: 0.032444458454847336
step: 160, loss: 0.03315261751413345
step: 170, loss: 0.07572728395462036
step: 180, loss: 0.010724659077823162
step: 190, loss: 0.03327693045139313
step: 200, loss: 0.02127046510577202
step: 210, loss: 0.0019177068024873734
step: 220, loss: 0.0009362092823721468
step: 230, loss: 0.0033544348552823067
step: 240, loss: 0.01644737645983696
step: 250, loss: 0.07516077160835266
step: 260, loss: 0.0006394515512511134
step: 270, loss: 0.0036190820392221212
step: 280, loss: 0.0010794864501804113
step: 290, loss: 0.00692245876416564
step: 300, loss: 0.018096718937158585
step: 310, loss: 0.0020586398895829916
step: 320, loss: 0.01857367344200611
step: 330, loss: 0.0010591282043606043
step: 340, loss: 0.0010512610897421837
step: 350, loss: 0.00967636052519083
epoch 11: dev_f1=0.8477157360406091, f1=0.7604166666666665, best_f1=0.801980198019802
step: 0, loss: 0.000896760611794889
step: 10, loss: 0.00047238077968358994
step: 20, loss: 0.03660180792212486
step: 30, loss: 0.00370497303083539
step: 40, loss: 0.02557629533112049
step: 50, loss: 0.003988892305642366
step: 60, loss: 0.07840046286582947
step: 70, loss: 0.004556142725050449
step: 80, loss: 0.004295811057090759
step: 90, loss: 0.0009040620643645525
step: 100, loss: 0.02939523756504059
step: 110, loss: 0.012604490853846073
step: 120, loss: 0.0004399597819428891
step: 130, loss: 0.004343043081462383
step: 140, loss: 0.0016100897919386625
step: 150, loss: 0.0009305027779191732
step: 160, loss: 0.0030407358426600695
step: 170, loss: 0.0010108021087944508
step: 180, loss: 0.010891204699873924
step: 190, loss: 0.0064069111831486225
step: 200, loss: 0.00792777631431818
step: 210, loss: 0.003553404239937663
step: 220, loss: 0.006125245243310928
step: 230, loss: 0.12188255041837692
step: 240, loss: 0.006941466126590967
step: 250, loss: 0.012351248413324356
step: 260, loss: 0.03582633659243584
step: 270, loss: 0.02160745859146118
step: 280, loss: 0.033294469118118286
step: 290, loss: 0.021380389109253883
step: 300, loss: 0.0040543838404119015
step: 310, loss: 0.00284807151183486
step: 320, loss: 0.00033753307070583105
step: 330, loss: 0.014464505016803741
step: 340, loss: 0.00024417179520241916
step: 350, loss: 0.0006550478865392506
epoch 12: dev_f1=0.8399999999999999, f1=0.7688442211055277, best_f1=0.801980198019802
step: 0, loss: 0.0016012430423870683
step: 10, loss: 0.0007390098762698472
step: 20, loss: 0.000834158097859472
step: 30, loss: 0.005219690967351198
step: 40, loss: 0.0005225224304012954
step: 50, loss: 0.00023154316295403987
step: 60, loss: 0.0005335641326382756
step: 70, loss: 0.000875568890478462
step: 80, loss: 0.0010564137483015656
step: 90, loss: 0.0004158858791925013
step: 100, loss: 0.01637054979801178
step: 110, loss: 0.003413780592381954
step: 120, loss: 0.033494092524051666
step: 130, loss: 0.008681155741214752
step: 140, loss: 0.0009852341609075665
step: 150, loss: 0.005437260027974844
step: 160, loss: 0.005909699015319347
step: 170, loss: 0.009478571824729443
step: 180, loss: 0.0014925713185220957
step: 190, loss: 0.0007135612540878356
step: 200, loss: 0.035512056201696396
step: 210, loss: 0.0003300346143078059
step: 220, loss: 0.00016941819922067225
step: 230, loss: 0.0001258014963241294
step: 240, loss: 0.0022342493757605553
step: 250, loss: 0.025304267182946205
step: 260, loss: 0.0004839870089199394
step: 270, loss: 0.0003203496744390577
step: 280, loss: 0.0018715433543547988
step: 290, loss: 0.0010603365954011679
step: 300, loss: 0.00025029564858414233
step: 310, loss: 0.0003712934267241508
step: 320, loss: 0.00016007536032702774
step: 330, loss: 0.0005892390036024153
step: 340, loss: 0.0004341299645602703
step: 350, loss: 0.0004754714318551123
epoch 13: dev_f1=0.8407310704960835, f1=0.7391304347826088, best_f1=0.801980198019802
step: 0, loss: 0.0006213803426362574
step: 10, loss: 0.007505220361053944
step: 20, loss: 0.12290239334106445
step: 30, loss: 0.0003506128559820354
step: 40, loss: 0.0004743693280033767
step: 50, loss: 0.025099018588662148
step: 60, loss: 0.004408813081681728
step: 70, loss: 0.003523927880451083
step: 80, loss: 0.0068561178632080555
step: 90, loss: 0.004584058653563261
step: 100, loss: 0.0010328833013772964
step: 110, loss: 0.06732605397701263
step: 120, loss: 0.0009584858198650181
step: 130, loss: 0.0005524430889636278
step: 140, loss: 0.031040800735354424
step: 150, loss: 0.06593329459428787
step: 160, loss: 0.00038429308915510774
step: 170, loss: 0.00045252751442603767
step: 180, loss: 0.002248767064884305
step: 190, loss: 0.10487184673547745
step: 200, loss: 0.0058390358462929726
step: 210, loss: 0.0002131127257598564
step: 220, loss: 0.0016547141131013632
step: 230, loss: 0.04528692737221718
step: 240, loss: 9.213730663759634e-05
step: 250, loss: 0.001015670713968575
step: 260, loss: 0.022884394973516464
step: 270, loss: 0.0005588622880168259
step: 280, loss: 0.053642768412828445
step: 290, loss: 0.007277991157025099
step: 300, loss: 0.00983241107314825
step: 310, loss: 0.00025862513575702906
step: 320, loss: 0.0010158199584111571
step: 330, loss: 0.001901378040201962
step: 340, loss: 0.0057870810851454735
step: 350, loss: 0.024973493069410324
epoch 14: dev_f1=0.8390243902439024, f1=0.7481296758104738, best_f1=0.801980198019802
step: 0, loss: 0.00016145322297234088
step: 10, loss: 0.0006061602616682649
step: 20, loss: 0.0007803080370649695
step: 30, loss: 0.024642251431941986
step: 40, loss: 0.00023606844479218125
step: 50, loss: 0.0012425571912899613
step: 60, loss: 0.013193069025874138
step: 70, loss: 0.007438903674483299
step: 80, loss: 0.0012250312138348818
step: 90, loss: 0.022442270070314407
step: 100, loss: 0.05328299477696419
step: 110, loss: 0.019670186564326286
step: 120, loss: 0.004849966615438461
step: 130, loss: 0.00028770777862519026
step: 140, loss: 0.0010246458696201444
step: 150, loss: 0.03659219667315483
step: 160, loss: 0.0002763302472885698
step: 170, loss: 0.0006059741717763245
step: 180, loss: 0.001713213394396007
step: 190, loss: 0.11249016970396042
step: 200, loss: 0.0018548975931480527
step: 210, loss: 0.0023571618366986513
step: 220, loss: 0.06791534274816513
step: 230, loss: 0.0015609952388331294
step: 240, loss: 0.0032787269446998835
step: 250, loss: 0.00031093027791939676
step: 260, loss: 0.0007488891133107245
step: 270, loss: 0.00010945204849122092
step: 280, loss: 0.007841942831873894
step: 290, loss: 0.00030913608497940004
step: 300, loss: 0.00011779708438552916
step: 310, loss: 6.729218148393556e-05
step: 320, loss: 0.00023194904497358948
step: 330, loss: 0.00010080475476570427
step: 340, loss: 0.00018622100469656289
step: 350, loss: 0.0025170373264700174
epoch 15: dev_f1=0.8353808353808354, f1=0.7536945812807883, best_f1=0.801980198019802
step: 0, loss: 0.04601103812456131
step: 10, loss: 3.95350725739263e-05
step: 20, loss: 0.0036900111008435488
step: 30, loss: 0.004964262247085571
step: 40, loss: 0.00019947925466112792
step: 50, loss: 0.00023533169587608427
step: 60, loss: 0.028997639194130898
step: 70, loss: 0.013235192745923996
step: 80, loss: 9.487925854045898e-05
step: 90, loss: 0.0010316231055185199
step: 100, loss: 0.00017276930157095194
step: 110, loss: 0.0025154980830848217
step: 120, loss: 0.01335492916405201
step: 130, loss: 0.0005434132181107998
step: 140, loss: 0.00013454978761728853
step: 150, loss: 0.00014403452223632485
step: 160, loss: 0.00023640639847144485
step: 170, loss: 0.0010899035260081291
step: 180, loss: 0.005308422259986401
step: 190, loss: 0.00011574559175642207
step: 200, loss: 0.0012969652889296412
step: 210, loss: 0.0016398982843384147
step: 220, loss: 0.0007211193442344666
step: 230, loss: 0.0029222406446933746
step: 240, loss: 0.0017169067868962884
step: 250, loss: 0.00023502127442043275
step: 260, loss: 0.00033240808988921344
step: 270, loss: 0.00024581290199421346
step: 280, loss: 0.01911434344947338
step: 290, loss: 0.002863211091607809
step: 300, loss: 0.0014908509328961372
step: 310, loss: 0.0022305494640022516
step: 320, loss: 0.0017966236919164658
step: 330, loss: 0.00015418537077493966
step: 340, loss: 0.05253257974982262
step: 350, loss: 0.0014491536421701312
epoch 16: dev_f1=0.827930174563591, f1=0.7455919395465995, best_f1=0.801980198019802
step: 0, loss: 0.000568389194086194
step: 10, loss: 0.03490307927131653
step: 20, loss: 0.04890602082014084
step: 30, loss: 0.0001250567293027416
step: 40, loss: 0.0019704466685652733
step: 50, loss: 0.002832937752828002
step: 60, loss: 0.04018787294626236
step: 70, loss: 0.00025451130932196975
step: 80, loss: 0.001939991838298738
step: 90, loss: 0.02096816897392273
step: 100, loss: 9.934245463227853e-05
step: 110, loss: 0.008463590405881405
step: 120, loss: 0.08859100192785263
step: 130, loss: 0.0013050594134256244
step: 140, loss: 0.0031764621380716562
step: 150, loss: 0.0005778339691460133
step: 160, loss: 0.00032498323707841337
step: 170, loss: 0.01285529788583517
step: 180, loss: 0.0003591773856896907
step: 190, loss: 0.002943196799606085
step: 200, loss: 0.10242068022489548
step: 210, loss: 0.0024089128710329533
step: 220, loss: 0.022791588678956032
step: 230, loss: 0.00011446199641795829
step: 240, loss: 0.0036977685522288084
step: 250, loss: 0.0005236404831521213
step: 260, loss: 0.006171532440930605
step: 270, loss: 0.00011800335050793365
step: 280, loss: 0.00015899819845799357
step: 290, loss: 0.006549140904098749
step: 300, loss: 0.0003271854075137526
step: 310, loss: 0.0007971322047524154
step: 320, loss: 0.015022553503513336
step: 330, loss: 0.00020919002417940646
step: 340, loss: 8.439915836788714e-05
step: 350, loss: 0.09906739741563797
epoch 17: dev_f1=0.8470588235294118, f1=0.7612293144208038, best_f1=0.801980198019802
step: 0, loss: 0.004685434978455305
step: 10, loss: 0.010256518609821796
step: 20, loss: 0.00033702075597830117
step: 30, loss: 0.00024874592781998217
step: 40, loss: 0.0003285167913418263
step: 50, loss: 6.848693737993017e-05
step: 60, loss: 8.207814971683547e-05
step: 70, loss: 0.028943242505192757
step: 80, loss: 0.0001567453728057444
step: 90, loss: 4.807958612218499e-05
step: 100, loss: 0.0005353663000278175
step: 110, loss: 0.011383067816495895
step: 120, loss: 0.00015465346223209053
step: 130, loss: 0.0007830020622350276
step: 140, loss: 0.00011533885117387399
step: 150, loss: 0.011419819667935371
step: 160, loss: 0.0004723675374407321
step: 170, loss: 0.001997369574382901
step: 180, loss: 0.009705780074000359
step: 190, loss: 0.004158136900514364
step: 200, loss: 0.0005164333269931376
step: 210, loss: 0.004556040745228529
step: 220, loss: 0.0022311226930469275
step: 230, loss: 0.021778911352157593
step: 240, loss: 8.31006036605686e-05
step: 250, loss: 0.0017480159876868129
step: 260, loss: 6.81120582157746e-05
step: 270, loss: 8.276178414234892e-05
step: 280, loss: 0.0005682470509782434
step: 290, loss: 0.00043547915993258357
step: 300, loss: 0.00013254230725578964
step: 310, loss: 0.0002513935905881226
step: 320, loss: 0.0017296768492087722
step: 330, loss: 0.00023496853827964514
step: 340, loss: 0.00405183294788003
step: 350, loss: 8.956245437730104e-05
epoch 18: dev_f1=0.840506329113924, f1=0.766839378238342, best_f1=0.801980198019802
step: 0, loss: 0.00029596470994874835
step: 10, loss: 0.0003478795988485217
step: 20, loss: 0.00016351701924577355
step: 30, loss: 7.968107092892751e-05
step: 40, loss: 7.493622251786292e-05
step: 50, loss: 0.00036222365451976657
step: 60, loss: 0.0001969473232747987
step: 70, loss: 0.00013695849338546395
step: 80, loss: 0.00038052344461902976
step: 90, loss: 6.082801701268181e-05
step: 100, loss: 0.00015242259541992098
step: 110, loss: 0.03346351161599159
step: 120, loss: 7.777359860483557e-05
step: 130, loss: 0.001220043865032494
step: 140, loss: 0.000751607003621757
step: 150, loss: 0.011775893159210682
step: 160, loss: 0.0005967714823782444
step: 170, loss: 0.00712588569149375
step: 180, loss: 6.498276343336329e-05
step: 190, loss: 0.00031911680707708
step: 200, loss: 0.00018961027672048658
step: 210, loss: 6.751306500518695e-05
step: 220, loss: 9.84307043836452e-05
step: 230, loss: 0.0011765974340960383
step: 240, loss: 0.00812361016869545
step: 250, loss: 0.0001402236957801506
step: 260, loss: 0.00015004286251496524
step: 270, loss: 0.00035123061388731003
step: 280, loss: 0.013636845164000988
step: 290, loss: 0.00021475694666150957
step: 300, loss: 0.0006762624252587557
step: 310, loss: 0.027597127482295036
step: 320, loss: 0.00021490047220140696
step: 330, loss: 8.352300937986001e-05
step: 340, loss: 0.00011966752208536491
step: 350, loss: 3.990223558503203e-05
epoch 19: dev_f1=0.8418367346938775, f1=0.762402088772846, best_f1=0.801980198019802
step: 0, loss: 0.0003293837362434715
step: 10, loss: 6.030828080838546e-05
step: 20, loss: 0.00019351589435245842
step: 30, loss: 0.0013328810455277562
step: 40, loss: 0.0008116458193399012
step: 50, loss: 0.0003784825385082513
step: 60, loss: 8.647036156617105e-05
step: 70, loss: 0.00013863792992196977
step: 80, loss: 0.013487243093550205
step: 90, loss: 0.0012102123582735658
step: 100, loss: 0.00284279091283679
step: 110, loss: 0.00011995338718406856
step: 120, loss: 7.407261728076264e-05
step: 130, loss: 0.0001602257543709129
step: 140, loss: 0.04940608888864517
step: 150, loss: 0.0001554148766444996
step: 160, loss: 5.5282394896494225e-05
step: 170, loss: 6.862371083116159e-05
step: 180, loss: 0.00010110872244695202
step: 190, loss: 0.0002537438122089952
step: 200, loss: 7.008195825619623e-05
step: 210, loss: 0.001879019313491881
step: 220, loss: 0.001024919911287725
step: 230, loss: 0.00011786304094130173
step: 240, loss: 0.012992427684366703
step: 250, loss: 0.0002736974856816232
step: 260, loss: 0.0005128158954903483
step: 270, loss: 0.00044489462743513286
step: 280, loss: 0.0013066799147054553
step: 290, loss: 5.729314580094069e-05
step: 300, loss: 0.017497440800070763
step: 310, loss: 0.00013110558211337775
step: 320, loss: 0.0003391949867364019
step: 330, loss: 0.0008221737225539982
step: 340, loss: 0.00011333456495776772
step: 350, loss: 0.010451140813529491
epoch 20: dev_f1=0.8423772609819121, f1=0.7506702412868632, best_f1=0.801980198019802
