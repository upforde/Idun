cuda
Device: cuda
step: 0, loss: 0.6417015790939331
step: 10, loss: 0.2350517362356186
step: 20, loss: 0.23301976919174194
step: 30, loss: 0.3760089874267578
step: 40, loss: 0.23359793424606323
step: 50, loss: 0.6170638203620911
step: 60, loss: 0.35368549823760986
step: 70, loss: 0.5124292969703674
step: 80, loss: 0.40582796931266785
step: 90, loss: 0.36730095744132996
step: 100, loss: 0.15687549114227295
step: 110, loss: 0.2369503676891327
step: 120, loss: 0.26228925585746765
step: 130, loss: 0.3245275616645813
step: 140, loss: 0.5877844095230103
step: 150, loss: 0.29286259412765503
step: 160, loss: 0.7220305800437927
step: 170, loss: 0.2380763590335846
step: 180, loss: 0.4689329266548157
step: 190, loss: 0.404739648103714
step: 200, loss: 0.1432347446680069
step: 210, loss: 0.40491753816604614
step: 220, loss: 0.3075103461742401
step: 230, loss: 0.24369415640830994
step: 240, loss: 0.19799606502056122
step: 250, loss: 0.32913491129875183
step: 260, loss: 0.42953887581825256
step: 270, loss: 0.2993429899215698
step: 280, loss: 0.28345146775245667
step: 290, loss: 0.5506892800331116
step: 300, loss: 0.23808974027633667
step: 310, loss: 0.16846390068531036
step: 320, loss: 0.40985435247421265
step: 330, loss: 0.2754857540130615
step: 340, loss: 0.3831566274166107
step: 350, loss: 0.3288942873477936
epoch 1: dev_f1=0.44389027431421446, f1=0.2879581151832461, best_f1=0.2879581151832461
step: 0, loss: 0.5008098483085632
step: 10, loss: 0.10688640177249908
step: 20, loss: 0.5308958888053894
step: 30, loss: 0.45019444823265076
step: 40, loss: 0.3432510495185852
step: 50, loss: 0.27125462889671326
step: 60, loss: 0.2555510401725769
step: 70, loss: 0.5052328705787659
step: 80, loss: 0.18452195823192596
step: 90, loss: 0.13511548936367035
step: 100, loss: 0.18292619287967682
step: 110, loss: 0.3886130154132843
step: 120, loss: 0.21599699556827545
step: 130, loss: 0.4025701582431793
step: 140, loss: 0.20597204566001892
step: 150, loss: 0.4214050769805908
step: 160, loss: 0.27849140763282776
step: 170, loss: 0.43555861711502075
step: 180, loss: 0.2565254271030426
step: 190, loss: 0.2795927822589874
step: 200, loss: 0.4207786023616791
step: 210, loss: 0.16199520230293274
step: 220, loss: 0.25867897272109985
step: 230, loss: 0.19120214879512787
step: 240, loss: 0.22143369913101196
step: 250, loss: 0.3458312153816223
step: 260, loss: 0.18351979553699493
step: 270, loss: 0.08340969681739807
step: 280, loss: 0.20596382021903992
step: 290, loss: 0.17789143323898315
step: 300, loss: 0.21816392242908478
step: 310, loss: 0.39263755083084106
step: 320, loss: 0.31914347410202026
step: 330, loss: 0.4408624768257141
step: 340, loss: 0.11620968580245972
step: 350, loss: 0.3873481750488281
epoch 2: dev_f1=0.6779661016949152, f1=0.5642317380352645, best_f1=0.5642317380352645
step: 0, loss: 0.18741130828857422
step: 10, loss: 0.08157610893249512
step: 20, loss: 0.1427328735589981
step: 30, loss: 0.22861529886722565
step: 40, loss: 0.16949452459812164
step: 50, loss: 0.22000189125537872
step: 60, loss: 0.20324991643428802
step: 70, loss: 0.2021973729133606
step: 80, loss: 0.2695225775241852
step: 90, loss: 0.3209983706474304
step: 100, loss: 0.23813673853874207
step: 110, loss: 0.05770409479737282
step: 120, loss: 0.25440481305122375
step: 130, loss: 0.2527610659599304
step: 140, loss: 0.29126855731010437
step: 150, loss: 0.15554961562156677
step: 160, loss: 0.27131029963493347
step: 170, loss: 0.28662946820259094
step: 180, loss: 0.34293171763420105
step: 190, loss: 0.3318169414997101
step: 200, loss: 0.12163019925355911
step: 210, loss: 0.21271131932735443
step: 220, loss: 0.16954311728477478
step: 230, loss: 0.20311054587364197
step: 240, loss: 0.043113164603710175
step: 250, loss: 0.19008034467697144
step: 260, loss: 0.14517149329185486
step: 270, loss: 0.1683698445558548
step: 280, loss: 0.14768996834754944
step: 290, loss: 0.16970185935497284
step: 300, loss: 0.23431530594825745
step: 310, loss: 0.2966969609260559
step: 320, loss: 0.2152685821056366
step: 330, loss: 0.22177739441394806
step: 340, loss: 0.19896747171878815
step: 350, loss: 0.14284992218017578
epoch 3: dev_f1=0.7538461538461538, f1=0.6542553191489361, best_f1=0.6542553191489361
step: 0, loss: 0.1601146012544632
step: 10, loss: 0.24381192028522491
step: 20, loss: 0.246659055352211
step: 30, loss: 0.3092542886734009
step: 40, loss: 0.06306444853544235
step: 50, loss: 0.14404258131980896
step: 60, loss: 0.07548525184392929
step: 70, loss: 0.1044543981552124
step: 80, loss: 0.2859351634979248
step: 90, loss: 0.07798340916633606
step: 100, loss: 0.19171319901943207
step: 110, loss: 0.09706740081310272
step: 120, loss: 0.22665755450725555
step: 130, loss: 0.2915920615196228
step: 140, loss: 0.10394790023565292
step: 150, loss: 0.30386948585510254
step: 160, loss: 0.046245675534009933
step: 170, loss: 0.13464471697807312
step: 180, loss: 0.10133442282676697
step: 190, loss: 0.09926573187112808
step: 200, loss: 0.36959636211395264
step: 210, loss: 0.12044177204370499
step: 220, loss: 0.07947663962841034
step: 230, loss: 0.21087726950645447
step: 240, loss: 0.026463575661182404
step: 250, loss: 0.06439731270074844
step: 260, loss: 0.21332789957523346
step: 270, loss: 0.17137818038463593
step: 280, loss: 0.206415593624115
step: 290, loss: 0.28069359064102173
step: 300, loss: 0.17452409863471985
step: 310, loss: 0.10324330627918243
step: 320, loss: 0.08777780085802078
step: 330, loss: 0.36705368757247925
step: 340, loss: 0.0949418917298317
step: 350, loss: 0.10118511319160461
epoch 4: dev_f1=0.7944572748267898, f1=0.7256235827664399, best_f1=0.7256235827664399
step: 0, loss: 0.16824214160442352
step: 10, loss: 0.0521463043987751
step: 20, loss: 0.10419180244207382
step: 30, loss: 0.14643950760364532
step: 40, loss: 0.21844492852687836
step: 50, loss: 0.07614894956350327
step: 60, loss: 0.2690306603908539
step: 70, loss: 0.3216264843940735
step: 80, loss: 0.12843576073646545
step: 90, loss: 0.05938855558633804
step: 100, loss: 0.043385911732912064
step: 110, loss: 0.0942055955529213
step: 120, loss: 0.04343276098370552
step: 130, loss: 0.2926505208015442
step: 140, loss: 0.1685435175895691
step: 150, loss: 0.06589943915605545
step: 160, loss: 0.1106589138507843
step: 170, loss: 0.06320121884346008
step: 180, loss: 0.08212092518806458
step: 190, loss: 0.14152850210666656
step: 200, loss: 0.013912254013121128
step: 210, loss: 0.22639115154743195
step: 220, loss: 0.07899490743875504
step: 230, loss: 0.04471735283732414
step: 240, loss: 0.06508281826972961
step: 250, loss: 0.25796064734458923
step: 260, loss: 0.10033424198627472
step: 270, loss: 0.04118940606713295
step: 280, loss: 0.1324542611837387
step: 290, loss: 0.15164265036582947
step: 300, loss: 0.015467541292309761
step: 310, loss: 0.08093562722206116
step: 320, loss: 0.11737567186355591
step: 330, loss: 0.20765440165996552
step: 340, loss: 0.23346255719661713
step: 350, loss: 0.19392435252666473
epoch 5: dev_f1=0.8194444444444444, f1=0.7792792792792792, best_f1=0.7792792792792792
step: 0, loss: 0.10140666365623474
step: 10, loss: 0.027845002710819244
step: 20, loss: 0.019103946164250374
step: 30, loss: 0.09927365183830261
step: 40, loss: 0.041412435472011566
step: 50, loss: 0.07946781069040298
step: 60, loss: 0.08445394784212112
step: 70, loss: 0.0689387246966362
step: 80, loss: 0.1956416368484497
step: 90, loss: 0.0884840339422226
step: 100, loss: 0.05246346443891525
step: 110, loss: 0.03518594428896904
step: 120, loss: 0.08613187074661255
step: 130, loss: 0.06961774080991745
step: 140, loss: 0.1932203769683838
step: 150, loss: 0.038150034844875336
step: 160, loss: 0.1771913766860962
step: 170, loss: 0.04831201955676079
step: 180, loss: 0.10793040692806244
step: 190, loss: 0.0380413793027401
step: 200, loss: 0.09573765844106674
step: 210, loss: 0.026258373633027077
step: 220, loss: 0.0821947455406189
step: 230, loss: 0.0437079556286335
step: 240, loss: 0.013849470764398575
step: 250, loss: 0.03464164957404137
step: 260, loss: 0.06984379887580872
step: 270, loss: 0.060233037918806076
step: 280, loss: 0.051361143589019775
step: 290, loss: 0.07539011538028717
step: 300, loss: 0.15450723469257355
step: 310, loss: 0.13328328728675842
step: 320, loss: 0.08013807237148285
step: 330, loss: 0.10564069449901581
step: 340, loss: 0.026795677840709686
step: 350, loss: 0.07218070328235626
epoch 6: dev_f1=0.8071065989847717, f1=0.7365728900255755, best_f1=0.7792792792792792
step: 0, loss: 0.018884021788835526
step: 10, loss: 0.021348776295781136
step: 20, loss: 0.02470160834491253
step: 30, loss: 0.06727471947669983
step: 40, loss: 0.011239832267165184
step: 50, loss: 0.03405578434467316
step: 60, loss: 0.06877808272838593
step: 70, loss: 0.1687554568052292
step: 80, loss: 0.037408843636512756
step: 90, loss: 0.18529924750328064
step: 100, loss: 0.1415627896785736
step: 110, loss: 0.13562774658203125
step: 120, loss: 0.033550843596458435
step: 130, loss: 0.005704073701053858
step: 140, loss: 0.07578713446855545
step: 150, loss: 0.020077958703041077
step: 160, loss: 0.02874957025051117
step: 170, loss: 0.030441002920269966
step: 180, loss: 0.023796243593096733
step: 190, loss: 0.022051675245165825
step: 200, loss: 0.02385309338569641
step: 210, loss: 0.33692044019699097
step: 220, loss: 0.03805430606007576
step: 230, loss: 0.07658708840608597
step: 240, loss: 0.23174495995044708
step: 250, loss: 0.17164725065231323
step: 260, loss: 0.01858719438314438
step: 270, loss: 0.08982966840267181
step: 280, loss: 0.005934745538979769
step: 290, loss: 0.04583074524998665
step: 300, loss: 0.20992369949817657
step: 310, loss: 0.13738374412059784
step: 320, loss: 0.001651706057600677
step: 330, loss: 0.004395985044538975
step: 340, loss: 0.02998894825577736
step: 350, loss: 0.07429327070713043
epoch 7: dev_f1=0.8238341968911919, f1=0.7688311688311689, best_f1=0.7688311688311689
step: 0, loss: 0.0064782691188156605
step: 10, loss: 0.00877711083739996
step: 20, loss: 0.02630135603249073
step: 30, loss: 0.06452032923698425
step: 40, loss: 0.008876618929207325
step: 50, loss: 0.20755703747272491
step: 60, loss: 0.025521475821733475
step: 70, loss: 0.02318536676466465
step: 80, loss: 0.0578649528324604
step: 90, loss: 0.02473658323287964
step: 100, loss: 0.0054863193072378635
step: 110, loss: 0.04303225129842758
step: 120, loss: 0.006450403016060591
step: 130, loss: 0.005754241719841957
step: 140, loss: 0.004303122870624065
step: 150, loss: 0.008412474766373634
step: 160, loss: 0.11817095428705215
step: 170, loss: 0.03537536785006523
step: 180, loss: 0.024844644591212273
step: 190, loss: 0.004364559426903725
step: 200, loss: 0.085232213139534
step: 210, loss: 0.153789222240448
step: 220, loss: 0.0022648819722235203
step: 230, loss: 0.02157270908355713
step: 240, loss: 0.06765945255756378
step: 250, loss: 0.07575869560241699
step: 260, loss: 0.09241144359111786
step: 270, loss: 0.07571347802877426
step: 280, loss: 0.08449991047382355
step: 290, loss: 0.1956114023923874
step: 300, loss: 0.17305223643779755
step: 310, loss: 0.01724008470773697
step: 320, loss: 0.05595356598496437
step: 330, loss: 0.014601374045014381
step: 340, loss: 0.008825628086924553
step: 350, loss: 0.06333953142166138
epoch 8: dev_f1=0.8095238095238095, f1=0.7799043062200957, best_f1=0.7688311688311689
step: 0, loss: 0.04469633847475052
step: 10, loss: 0.05869390815496445
step: 20, loss: 0.0013273870572447777
step: 30, loss: 0.06270158290863037
step: 40, loss: 0.032359231263399124
step: 50, loss: 0.008261578157544136
step: 60, loss: 0.003646615892648697
step: 70, loss: 0.06550876796245575
step: 80, loss: 0.015517405234277248
step: 90, loss: 0.0014912975020706654
step: 100, loss: 0.018097877502441406
step: 110, loss: 0.029859328642487526
step: 120, loss: 0.0006964621716178954
step: 130, loss: 0.004429372027516365
step: 140, loss: 0.017968231812119484
step: 150, loss: 0.0016868272796273232
step: 160, loss: 0.004744148813188076
step: 170, loss: 0.08230476081371307
step: 180, loss: 0.012900070287287235
step: 190, loss: 0.0047378502786159515
step: 200, loss: 0.018995186313986778
step: 210, loss: 0.12623557448387146
step: 220, loss: 0.0011066036531701684
step: 230, loss: 0.007089938502758741
step: 240, loss: 0.0021927414927631617
step: 250, loss: 0.04607918858528137
step: 260, loss: 0.027002569288015366
step: 270, loss: 0.0029418524354696274
step: 280, loss: 0.003523494815453887
step: 290, loss: 0.010121009312570095
step: 300, loss: 0.12927021086215973
step: 310, loss: 0.03831351548433304
step: 320, loss: 0.0030261846259236336
step: 330, loss: 0.0805683508515358
step: 340, loss: 0.05855574086308479
step: 350, loss: 0.07043691724538803
epoch 9: dev_f1=0.821256038647343, f1=0.7904761904761904, best_f1=0.7688311688311689
step: 0, loss: 0.002697373041883111
step: 10, loss: 0.010708218440413475
step: 20, loss: 0.02868739888072014
step: 30, loss: 0.023608241230249405
step: 40, loss: 0.016971437260508537
step: 50, loss: 0.12474356591701508
step: 60, loss: 0.005148278549313545
step: 70, loss: 0.013624603860080242
step: 80, loss: 0.02943132258951664
step: 90, loss: 0.006420386955142021
step: 100, loss: 0.15545342862606049
step: 110, loss: 0.19444401562213898
step: 120, loss: 0.021751128137111664
step: 130, loss: 0.0846359133720398
step: 140, loss: 0.07482724636793137
step: 150, loss: 0.0008798312628641725
step: 160, loss: 0.015361098572611809
step: 170, loss: 0.0004632908385246992
step: 180, loss: 0.0024694260209798813
step: 190, loss: 0.09699233621358871
step: 200, loss: 0.0005902592674829066
step: 210, loss: 0.03344058245420456
step: 220, loss: 0.00645275367423892
step: 230, loss: 0.0032570832408964634
step: 240, loss: 0.031809061765670776
step: 250, loss: 0.010776587761938572
step: 260, loss: 0.004173237830400467
step: 270, loss: 0.01288052462041378
step: 280, loss: 0.006554293911904097
step: 290, loss: 0.01546262577176094
step: 300, loss: 0.0011160949943587184
step: 310, loss: 0.05060264468193054
step: 320, loss: 0.0032121234107762575
step: 330, loss: 0.003872994799166918
step: 340, loss: 0.002703582402318716
step: 350, loss: 0.057991355657577515
epoch 10: dev_f1=0.7816711590296497, f1=0.7302452316076294, best_f1=0.7688311688311689
step: 0, loss: 0.0009954150300472975
step: 10, loss: 0.02640218287706375
step: 20, loss: 0.09595848619937897
step: 30, loss: 0.03067578189074993
step: 40, loss: 0.01429952122271061
step: 50, loss: 0.0033527484629303217
step: 60, loss: 0.004420086741447449
step: 70, loss: 0.0023737517185509205
step: 80, loss: 0.014642656780779362
step: 90, loss: 0.12306685000658035
step: 100, loss: 0.0038163599092513323
step: 110, loss: 0.002853117184713483
step: 120, loss: 0.07285474985837936
step: 130, loss: 0.008388987742364407
step: 140, loss: 0.023978207260370255
step: 150, loss: 0.0005760292988270521
step: 160, loss: 0.2357058823108673
step: 170, loss: 0.02177329547703266
step: 180, loss: 0.00968284159898758
step: 190, loss: 0.011030477471649647
step: 200, loss: 0.18492451310157776
step: 210, loss: 0.0027041295543313026
step: 220, loss: 0.0026466527488082647
step: 230, loss: 0.0011726391967386007
step: 240, loss: 0.0016253235517069697
step: 250, loss: 0.055766522884368896
step: 260, loss: 0.014158434234559536
step: 270, loss: 0.022519191727042198
step: 280, loss: 0.0427761971950531
step: 290, loss: 0.0018763814587146044
step: 300, loss: 0.025543415918946266
step: 310, loss: 0.002731088548898697
step: 320, loss: 0.0359230674803257
step: 330, loss: 0.00225256010890007
step: 340, loss: 0.0070375362411141396
step: 350, loss: 0.010099411942064762
epoch 11: dev_f1=0.8018867924528301, f1=0.7625570776255708, best_f1=0.7688311688311689
step: 0, loss: 0.000368349690688774
step: 10, loss: 0.014362852089107037
step: 20, loss: 0.000856270082294941
step: 30, loss: 0.0895930677652359
step: 40, loss: 0.04440001770853996
step: 50, loss: 0.0005656878347508609
step: 60, loss: 0.0014670353848487139
step: 70, loss: 0.0015350441681221128
step: 80, loss: 0.0011020561214536428
step: 90, loss: 0.11032195389270782
step: 100, loss: 0.009080571122467518
step: 110, loss: 0.0003425026952754706
step: 120, loss: 0.0014994761440902948
step: 130, loss: 0.06537507474422455
step: 140, loss: 0.026903383433818817
step: 150, loss: 0.02772887982428074
step: 160, loss: 0.0007040580385364592
step: 170, loss: 0.008116211742162704
step: 180, loss: 0.0027638208121061325
step: 190, loss: 0.02113356813788414
step: 200, loss: 0.00173892208840698
step: 210, loss: 0.00539266224950552
step: 220, loss: 0.0017063198611140251
step: 230, loss: 0.0002881276304833591
step: 240, loss: 0.029788728803396225
step: 250, loss: 0.011701026931405067
step: 260, loss: 0.0013316342374309897
step: 270, loss: 0.08276262879371643
step: 280, loss: 0.001745648798532784
step: 290, loss: 0.008091626688838005
step: 300, loss: 0.01798543520271778
step: 310, loss: 0.007657778915017843
step: 320, loss: 0.006436724215745926
step: 330, loss: 0.009120641276240349
step: 340, loss: 0.021622352302074432
step: 350, loss: 0.0007408923120237887
epoch 12: dev_f1=0.817155756207675, f1=0.7637969094922737, best_f1=0.7688311688311689
step: 0, loss: 0.006354711018502712
step: 10, loss: 0.006751109380275011
step: 20, loss: 0.004693159833550453
step: 30, loss: 0.014561892487108707
step: 40, loss: 0.011828793212771416
step: 50, loss: 0.013246112503111362
step: 60, loss: 0.010800627060234547
step: 70, loss: 0.0010928907431662083
step: 80, loss: 0.0020002874080091715
step: 90, loss: 0.0017172821098938584
step: 100, loss: 0.017728598788380623
step: 110, loss: 0.012359611690044403
step: 120, loss: 0.0003317170776426792
step: 130, loss: 0.024259764701128006
step: 140, loss: 0.01201879046857357
step: 150, loss: 0.0081627843901515
step: 160, loss: 0.05448568984866142
step: 170, loss: 0.05220647528767586
step: 180, loss: 0.000367105909390375
step: 190, loss: 0.00047255904064513743
step: 200, loss: 0.0006716693751513958
step: 210, loss: 0.004747353028506041
step: 220, loss: 0.006767562590539455
step: 230, loss: 0.003949855454266071
step: 240, loss: 0.0005394481122493744
step: 250, loss: 0.0034449519589543343
step: 260, loss: 0.029650617390871048
step: 270, loss: 0.030911700800061226
step: 280, loss: 0.0002016452344832942
step: 290, loss: 0.010284044779837132
step: 300, loss: 0.00028787142946384847
step: 310, loss: 0.015070563182234764
step: 320, loss: 0.0026545373257249594
step: 330, loss: 0.008435463532805443
step: 340, loss: 0.0001815067371353507
step: 350, loss: 0.017279770225286484
epoch 13: dev_f1=0.8130841121495326, f1=0.7699757869249395, best_f1=0.7688311688311689
step: 0, loss: 0.0005022321711294353
step: 10, loss: 0.001420048181898892
step: 20, loss: 0.001538793439976871
step: 30, loss: 0.013293178752064705
step: 40, loss: 0.013039597310125828
step: 50, loss: 0.06961479783058167
step: 60, loss: 0.002002672292292118
step: 70, loss: 0.006462324410676956
step: 80, loss: 0.002024604007601738
step: 90, loss: 0.0006106566288508475
step: 100, loss: 0.003193219192326069
step: 110, loss: 0.0007346267229877412
step: 120, loss: 0.0011783537920564413
step: 130, loss: 0.0013516067992895842
step: 140, loss: 0.004735017195343971
step: 150, loss: 0.0036244092043489218
step: 160, loss: 0.015053335577249527
step: 170, loss: 0.010096296668052673
step: 180, loss: 0.013618016615509987
step: 190, loss: 0.026144590228796005
step: 200, loss: 0.00025515814195387065
step: 210, loss: 0.0007171687320806086
step: 220, loss: 0.0010973555035889149
step: 230, loss: 0.0003416593244764954
step: 240, loss: 0.014460531994700432
step: 250, loss: 0.001379017485305667
step: 260, loss: 0.03392203897237778
step: 270, loss: 0.0004917765036225319
step: 280, loss: 0.001948696793988347
step: 290, loss: 0.009418841451406479
step: 300, loss: 0.07705521583557129
step: 310, loss: 0.0103971092030406
step: 320, loss: 0.005717519670724869
step: 330, loss: 0.002414942253381014
step: 340, loss: 0.0028831064701080322
step: 350, loss: 0.003427052404731512
epoch 14: dev_f1=0.8066037735849056, f1=0.7728337236533958, best_f1=0.7688311688311689
step: 0, loss: 0.05387208238244057
step: 10, loss: 0.017350541427731514
step: 20, loss: 0.028892602771520615
step: 30, loss: 0.006092221010476351
step: 40, loss: 0.011053214780986309
step: 50, loss: 0.00714939646422863
step: 60, loss: 0.0007923393859528005
step: 70, loss: 0.0007411320111714303
step: 80, loss: 0.0007948415586724877
step: 90, loss: 0.1069260686635971
step: 100, loss: 0.00032412109430879354
step: 110, loss: 0.0023400390055030584
step: 120, loss: 0.009235084056854248
step: 130, loss: 0.003434597048908472
step: 140, loss: 0.000764957454521209
step: 150, loss: 0.0001914068270707503
step: 160, loss: 0.0008229987579397857
step: 170, loss: 0.07976692169904709
step: 180, loss: 0.002863276982679963
step: 190, loss: 0.00031133004813455045
step: 200, loss: 0.00033893543877638876
step: 210, loss: 0.00012967227667104453
step: 220, loss: 0.008647182025015354
step: 230, loss: 0.003986814059317112
step: 240, loss: 0.0003881732118315995
step: 250, loss: 0.06541483104228973
step: 260, loss: 0.0008630682132206857
step: 270, loss: 9.92420973489061e-05
step: 280, loss: 0.0005554005037993193
step: 290, loss: 0.010699141770601273
step: 300, loss: 0.001907626399770379
step: 310, loss: 0.0036132989916950464
step: 320, loss: 0.0004599669191520661
step: 330, loss: 0.05290808528661728
step: 340, loss: 0.0025379308499395847
step: 350, loss: 0.0037459279410541058
epoch 15: dev_f1=0.7999999999999999, f1=0.771764705882353, best_f1=0.7688311688311689
step: 0, loss: 0.000167376987519674
step: 10, loss: 0.0021068286150693893
step: 20, loss: 0.0010200310498476028
step: 30, loss: 0.02438756451010704
step: 40, loss: 0.0003032279491890222
step: 50, loss: 0.00025062618078663945
step: 60, loss: 0.0005962811992503703
step: 70, loss: 0.00026624641031958163
step: 80, loss: 0.0016134706092998385
step: 90, loss: 0.0021893333178013563
step: 100, loss: 0.0008037649095058441
step: 110, loss: 0.004541791044175625
step: 120, loss: 0.014432376250624657
step: 130, loss: 0.01929505355656147
step: 140, loss: 0.00048465444706380367
step: 150, loss: 0.022224657237529755
step: 160, loss: 0.01128909457474947
step: 170, loss: 0.0008191381348297
step: 180, loss: 0.008469372987747192
step: 190, loss: 0.0003585462109185755
step: 200, loss: 0.013696413487195969
step: 210, loss: 0.00037552896537818015
step: 220, loss: 0.0006427112384699285
step: 230, loss: 0.019375404343008995
step: 240, loss: 0.00030974691617302597
step: 250, loss: 0.0005986643373034894
step: 260, loss: 0.016259511932730675
step: 270, loss: 0.12397493422031403
step: 280, loss: 0.0016514005837962031
step: 290, loss: 0.0006976365111768246
step: 300, loss: 0.014189175330102444
step: 310, loss: 0.00026445998810231686
step: 320, loss: 0.021780304610729218
step: 330, loss: 0.0017013548640534282
step: 340, loss: 0.0027268892154097557
step: 350, loss: 0.008559023961424828
epoch 16: dev_f1=0.8047058823529412, f1=0.7822014051522249, best_f1=0.7688311688311689
step: 0, loss: 0.00526853883638978
step: 10, loss: 0.0028621326200664043
step: 20, loss: 0.02861586958169937
step: 30, loss: 0.0011529793264344335
step: 40, loss: 0.021686092019081116
step: 50, loss: 0.0002772397128865123
step: 60, loss: 0.025195695459842682
step: 70, loss: 0.0009506344795227051
step: 80, loss: 0.00017036522331181914
step: 90, loss: 0.0004045036621391773
step: 100, loss: 0.0004570006567519158
step: 110, loss: 0.006453815381973982
step: 120, loss: 0.0016450568800792098
step: 130, loss: 0.0010248352773487568
step: 140, loss: 0.0004010593402199447
step: 150, loss: 0.0005450487951748073
step: 160, loss: 0.0004145675920881331
step: 170, loss: 0.0009419638081453741
step: 180, loss: 0.0014760561753064394
step: 190, loss: 0.022587863728404045
step: 200, loss: 0.0005759351188316941
step: 210, loss: 0.003279895754531026
step: 220, loss: 0.0015081706224009395
step: 230, loss: 0.003381583606824279
step: 240, loss: 0.002494234126061201
step: 250, loss: 0.05108076333999634
step: 260, loss: 0.0036795453634113073
step: 270, loss: 0.0016205913852900267
step: 280, loss: 0.0011949484469369054
step: 290, loss: 0.00015985645586624742
step: 300, loss: 0.00012965263158548623
step: 310, loss: 0.0007869328837841749
step: 320, loss: 0.0007920400239527225
step: 330, loss: 0.006375513970851898
step: 340, loss: 0.00038214121013879776
step: 350, loss: 7.15351416147314e-05
epoch 17: dev_f1=0.7990430622009569, f1=0.7915690866510539, best_f1=0.7688311688311689
step: 0, loss: 0.00019859995518345386
step: 10, loss: 0.0013703524600714445
step: 20, loss: 0.0010236790403723717
step: 30, loss: 0.0003124652721453458
step: 40, loss: 0.014910921454429626
step: 50, loss: 0.0008549094200134277
step: 60, loss: 0.0002369415742577985
step: 70, loss: 0.00012734110350720584
step: 80, loss: 0.0004079208883922547
step: 90, loss: 0.00038622974534519017
step: 100, loss: 0.008845124393701553
step: 110, loss: 0.0012084402842447162
step: 120, loss: 0.06033257022500038
step: 130, loss: 0.0011046366998925805
step: 140, loss: 0.0005891704931855202
step: 150, loss: 0.00013003563799429685
step: 160, loss: 0.01977379620075226
step: 170, loss: 0.023171937093138695
step: 180, loss: 0.014336399734020233
step: 190, loss: 0.0010288620833307505
step: 200, loss: 0.0022082417272031307
step: 210, loss: 0.0003239115176256746
step: 220, loss: 0.0009811336640268564
step: 230, loss: 0.0018870431231334805
step: 240, loss: 0.02067245915532112
step: 250, loss: 0.0011594179086387157
step: 260, loss: 0.00019747934129554778
step: 270, loss: 0.0002733664005063474
step: 280, loss: 0.000436525559052825
step: 290, loss: 0.0003570254484657198
step: 300, loss: 0.00033509600325487554
step: 310, loss: 0.026785295456647873
step: 320, loss: 0.00042743879021145403
step: 330, loss: 4.081682345713489e-05
step: 340, loss: 0.00010995075717801228
step: 350, loss: 0.018830982968211174
epoch 18: dev_f1=0.8056872037914692, f1=0.7895981087470448, best_f1=0.7688311688311689
step: 0, loss: 0.0050239902921020985
step: 10, loss: 0.00027271435828879476
step: 20, loss: 0.0003711169119924307
step: 30, loss: 0.0002359981881454587
step: 40, loss: 0.0006122997147031128
step: 50, loss: 0.0012675193138420582
step: 60, loss: 0.00033639351022429764
step: 70, loss: 0.0002594697580207139
step: 80, loss: 0.0050617000088095665
step: 90, loss: 0.005433203186839819
step: 100, loss: 0.000381933874450624
step: 110, loss: 0.00014688310329802334
step: 120, loss: 0.00015563966007903218
step: 130, loss: 0.0001700283755781129
step: 140, loss: 0.0002618087164591998
step: 150, loss: 0.0001327520440099761
step: 160, loss: 0.002745092613622546
step: 170, loss: 0.0004690174828283489
step: 180, loss: 0.0006562127964571118
step: 190, loss: 0.0006420941790565848
step: 200, loss: 8.670956594869494e-05
step: 210, loss: 7.556563650723547e-05
step: 220, loss: 0.004075703676789999
step: 230, loss: 0.0001502300874562934
step: 240, loss: 0.008559769950807095
step: 250, loss: 0.0007185788126662374
step: 260, loss: 0.0013002692721784115
step: 270, loss: 0.0024653456639498472
step: 280, loss: 0.007584179285913706
step: 290, loss: 0.00013435445725917816
step: 300, loss: 0.0006260587251745164
step: 310, loss: 0.00017468197620473802
step: 320, loss: 0.00016376814164686948
step: 330, loss: 0.00022504381195176393
step: 340, loss: 0.0001499492791481316
step: 350, loss: 0.00011641001765383407
epoch 19: dev_f1=0.8038277511961723, f1=0.7867298578199052, best_f1=0.7688311688311689
step: 0, loss: 0.00016918376786634326
step: 10, loss: 0.0071750362403690815
step: 20, loss: 0.0007515352917835116
step: 30, loss: 0.0004965437692590058
step: 40, loss: 0.0053406283259391785
step: 50, loss: 0.028013236820697784
step: 60, loss: 0.00030838913517072797
step: 70, loss: 9.304386185249314e-05
step: 80, loss: 0.00016813243564683944
step: 90, loss: 0.001464553759433329
step: 100, loss: 0.0009731133468449116
step: 110, loss: 0.00010511151049286127
step: 120, loss: 0.005959603004157543
step: 130, loss: 0.0005541057325899601
step: 140, loss: 0.004404325503855944
step: 150, loss: 0.001140710897743702
step: 160, loss: 0.00010964787361444905
step: 170, loss: 0.004744572564959526
step: 180, loss: 0.0002282695786561817
step: 190, loss: 8.088313916232437e-05
step: 200, loss: 0.00020025619596708566
step: 210, loss: 0.00044495690963231027
step: 220, loss: 0.000533427344635129
step: 230, loss: 0.0012979678576812148
step: 240, loss: 0.054887644946575165
step: 250, loss: 0.00023578162654303014
step: 260, loss: 0.0002111120120389387
step: 270, loss: 0.00013235645019449294
step: 280, loss: 0.0001945996773429215
step: 290, loss: 0.00019707584579009563
step: 300, loss: 0.0005732164136134088
step: 310, loss: 0.00018849348998628557
step: 320, loss: 7.018267206149176e-05
step: 330, loss: 0.00016883958596736193
step: 340, loss: 0.00023513824271503836
step: 350, loss: 0.011997544206678867
epoch 20: dev_f1=0.8057553956834533, f1=0.7799043062200957, best_f1=0.7688311688311689
