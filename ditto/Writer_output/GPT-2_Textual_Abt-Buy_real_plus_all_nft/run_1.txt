cuda
Device: cuda
step: 0, loss: 0.8666296005249023
step: 10, loss: 0.3063618540763855
step: 20, loss: 0.32141000032424927
step: 30, loss: 0.631133496761322
step: 40, loss: 0.5109620690345764
step: 50, loss: 0.23145852982997894
step: 60, loss: 0.3592623472213745
step: 70, loss: 0.5106664299964905
step: 80, loss: 0.4724240005016327
step: 90, loss: 0.3340708315372467
step: 100, loss: 0.3561860918998718
step: 110, loss: 0.32490798830986023
step: 120, loss: 0.134031742811203
step: 130, loss: 0.19896934926509857
step: 140, loss: 0.3965603709220886
step: 150, loss: 0.5342666506767273
step: 160, loss: 0.3581283688545227
step: 170, loss: 0.5162491202354431
step: 180, loss: 0.2227173000574112
step: 190, loss: 0.15981793403625488
step: 200, loss: 0.2073661983013153
step: 210, loss: 0.1297593116760254
step: 220, loss: 0.5407997369766235
step: 230, loss: 0.5161329507827759
step: 240, loss: 0.44150352478027344
step: 250, loss: 0.2721256613731384
step: 260, loss: 0.3722352087497711
step: 270, loss: 0.3857448697090149
step: 280, loss: 0.33941131830215454
step: 290, loss: 0.289113312959671
step: 300, loss: 0.17020969092845917
step: 310, loss: 0.35516995191574097
step: 320, loss: 0.24420082569122314
step: 330, loss: 0.45126017928123474
step: 340, loss: 0.46066951751708984
step: 350, loss: 0.27509403228759766
epoch 1: dev_f1=0.5641025641025641, f1=0.42622950819672134, best_f1=0.42622950819672134
step: 0, loss: 0.1785556972026825
step: 10, loss: 0.2421445995569229
step: 20, loss: 0.08642955124378204
step: 30, loss: 0.4157436490058899
step: 40, loss: 0.44210726022720337
step: 50, loss: 0.17313696444034576
step: 60, loss: 0.2594344913959503
step: 70, loss: 0.15901440382003784
step: 80, loss: 0.24859009683132172
step: 90, loss: 0.3673097491264343
step: 100, loss: 0.4331268072128296
step: 110, loss: 0.12867407500743866
step: 120, loss: 0.33372896909713745
step: 130, loss: 0.24643464386463165
step: 140, loss: 0.27294066548347473
step: 150, loss: 0.2334747314453125
step: 160, loss: 0.3343869149684906
step: 170, loss: 0.27161532640457153
step: 180, loss: 0.19886761903762817
step: 190, loss: 0.31618285179138184
step: 200, loss: 0.22461296617984772
step: 210, loss: 0.2660779058933258
step: 220, loss: 0.32848408818244934
step: 230, loss: 0.19351701438426971
step: 240, loss: 0.2690087556838989
step: 250, loss: 0.23247897624969482
step: 260, loss: 0.3328682780265808
step: 270, loss: 0.19863496720790863
step: 280, loss: 0.40712329745292664
step: 290, loss: 0.1874084770679474
step: 300, loss: 0.13667850196361542
step: 310, loss: 0.11898863315582275
step: 320, loss: 0.34686464071273804
step: 330, loss: 0.2533911466598511
step: 340, loss: 0.3990592956542969
step: 350, loss: 0.3062213361263275
epoch 2: dev_f1=0.6973365617433414, f1=0.5750636132315522, best_f1=0.5750636132315522
step: 0, loss: 0.3473239541053772
step: 10, loss: 0.26728758215904236
step: 20, loss: 0.12715324759483337
step: 30, loss: 0.2205491065979004
step: 40, loss: 0.18136748671531677
step: 50, loss: 0.21055470407009125
step: 60, loss: 0.2604599595069885
step: 70, loss: 0.3150027096271515
step: 80, loss: 0.13706514239311218
step: 90, loss: 0.2101449817419052
step: 100, loss: 0.05305799841880798
step: 110, loss: 0.2695907652378082
step: 120, loss: 0.19515933096408844
step: 130, loss: 0.3680480122566223
step: 140, loss: 0.14105446636676788
step: 150, loss: 0.17818307876586914
step: 160, loss: 0.29889458417892456
step: 170, loss: 0.2438972145318985
step: 180, loss: 0.2685314118862152
step: 190, loss: 0.13924117386341095
step: 200, loss: 0.2303687483072281
step: 210, loss: 0.33754533529281616
step: 220, loss: 0.24859724938869476
step: 230, loss: 0.1507224589586258
step: 240, loss: 0.3672884702682495
step: 250, loss: 0.20256756246089935
step: 260, loss: 0.1737067997455597
step: 270, loss: 0.22439216077327728
step: 280, loss: 0.17680639028549194
step: 290, loss: 0.12806464731693268
step: 300, loss: 0.38814637064933777
step: 310, loss: 0.18749219179153442
step: 320, loss: 0.1337345540523529
step: 330, loss: 0.19436776638031006
step: 340, loss: 0.23991814255714417
step: 350, loss: 0.22574661672115326
epoch 3: dev_f1=0.8123515439429927, f1=0.7302325581395348, best_f1=0.7302325581395348
step: 0, loss: 0.06387776881456375
step: 10, loss: 0.10279600322246552
step: 20, loss: 0.12469211220741272
step: 30, loss: 0.05446171760559082
step: 40, loss: 0.12139084190130234
step: 50, loss: 0.16774562001228333
step: 60, loss: 0.3781833052635193
step: 70, loss: 0.11805613338947296
step: 80, loss: 0.3260439336299896
step: 90, loss: 0.3011527359485626
step: 100, loss: 0.09823178499937057
step: 110, loss: 0.21588242053985596
step: 120, loss: 0.13795801997184753
step: 130, loss: 0.14975491166114807
step: 140, loss: 0.134706050157547
step: 150, loss: 0.061926476657390594
step: 160, loss: 0.23065321147441864
step: 170, loss: 0.18243056535720825
step: 180, loss: 0.17064787447452545
step: 190, loss: 0.048910465091466904
step: 200, loss: 0.06769061088562012
step: 210, loss: 0.1252225786447525
step: 220, loss: 0.2636450231075287
step: 230, loss: 0.18137314915657043
step: 240, loss: 0.18597407639026642
step: 250, loss: 0.19113682210445404
step: 260, loss: 0.13735546171665192
step: 270, loss: 0.22636562585830688
step: 280, loss: 0.10478201508522034
step: 290, loss: 0.3344303071498871
step: 300, loss: 0.21941763162612915
step: 310, loss: 0.18065953254699707
step: 320, loss: 0.18274115025997162
step: 330, loss: 0.06978289783000946
step: 340, loss: 0.29411715269088745
step: 350, loss: 0.4150771200656891
epoch 4: dev_f1=0.832244008714597, f1=0.7654867256637168, best_f1=0.7654867256637168
step: 0, loss: 0.08696962147951126
step: 10, loss: 0.1327211856842041
step: 20, loss: 0.14840111136436462
step: 30, loss: 0.23074710369110107
step: 40, loss: 0.1738997995853424
step: 50, loss: 0.023661578074097633
step: 60, loss: 0.09256976842880249
step: 70, loss: 0.14248953759670258
step: 80, loss: 0.37627074122428894
step: 90, loss: 0.05450384318828583
step: 100, loss: 0.11966554820537567
step: 110, loss: 0.07188888639211655
step: 120, loss: 0.12311403453350067
step: 130, loss: 0.24126368761062622
step: 140, loss: 0.0931672602891922
step: 150, loss: 0.042561981827020645
step: 160, loss: 0.13973253965377808
step: 170, loss: 0.15259963274002075
step: 180, loss: 0.20843607187271118
step: 190, loss: 0.12631279230117798
step: 200, loss: 0.2003197818994522
step: 210, loss: 0.10722445696592331
step: 220, loss: 0.22626590728759766
step: 230, loss: 0.06518813222646713
step: 240, loss: 0.12113042920827866
step: 250, loss: 0.0919613316655159
step: 260, loss: 0.16570830345153809
step: 270, loss: 0.03844047337770462
step: 280, loss: 0.05993277579545975
step: 290, loss: 0.17114850878715515
step: 300, loss: 0.07854360342025757
step: 310, loss: 0.06610071659088135
step: 320, loss: 0.3682778477668762
step: 330, loss: 0.15617163479328156
step: 340, loss: 0.25366005301475525
step: 350, loss: 0.08619434386491776
epoch 5: dev_f1=0.8094117647058824, f1=0.7436489607390301, best_f1=0.7654867256637168
step: 0, loss: 0.08174612373113632
step: 10, loss: 0.10712132602930069
step: 20, loss: 0.0833493024110794
step: 30, loss: 0.08361155539751053
step: 40, loss: 0.005880516953766346
step: 50, loss: 0.03705037012696266
step: 60, loss: 0.15543913841247559
step: 70, loss: 0.0861576646566391
step: 80, loss: 0.44031187891960144
step: 90, loss: 0.034599319100379944
step: 100, loss: 0.1252133548259735
step: 110, loss: 0.18054097890853882
step: 120, loss: 0.05339674651622772
step: 130, loss: 0.023086318746209145
step: 140, loss: 0.043351780623197556
step: 150, loss: 0.015005317516624928
step: 160, loss: 0.15630501508712769
step: 170, loss: 0.06286052614450455
step: 180, loss: 0.1178210899233818
step: 190, loss: 0.20381757616996765
step: 200, loss: 0.02935255691409111
step: 210, loss: 0.0201223473995924
step: 220, loss: 0.13606390357017517
step: 230, loss: 0.013008279725909233
step: 240, loss: 0.05289814621210098
step: 250, loss: 0.04949786514043808
step: 260, loss: 0.20914272964000702
step: 270, loss: 0.1337510049343109
step: 280, loss: 0.10309033840894699
step: 290, loss: 0.16721180081367493
step: 300, loss: 0.0538129098713398
step: 310, loss: 0.11361244320869446
step: 320, loss: 0.10978927463293076
step: 330, loss: 0.032027099281549454
step: 340, loss: 0.3303780257701874
step: 350, loss: 0.05558200180530548
epoch 6: dev_f1=0.8387096774193549, f1=0.7741935483870966, best_f1=0.7741935483870966
step: 0, loss: 0.05362258851528168
step: 10, loss: 0.05352512747049332
step: 20, loss: 0.029556794092059135
step: 30, loss: 0.07643599808216095
step: 40, loss: 0.025395069271326065
step: 50, loss: 0.008504304103553295
step: 60, loss: 0.013420631177723408
step: 70, loss: 0.008654838427901268
step: 80, loss: 0.020116576924920082
step: 90, loss: 0.10232778638601303
step: 100, loss: 0.07419277727603912
step: 110, loss: 0.042505986988544464
step: 120, loss: 0.009149912744760513
step: 130, loss: 0.1664801687002182
step: 140, loss: 0.11531344801187515
step: 150, loss: 0.03768961504101753
step: 160, loss: 0.01519080251455307
step: 170, loss: 0.0034328883048146963
step: 180, loss: 0.03066573478281498
step: 190, loss: 0.013563784770667553
step: 200, loss: 0.11573122441768646
step: 210, loss: 0.06747601926326752
step: 220, loss: 0.23834095895290375
step: 230, loss: 0.07731134444475174
step: 240, loss: 0.12936203181743622
step: 250, loss: 0.008675480261445045
step: 260, loss: 0.2133319228887558
step: 270, loss: 0.09807336330413818
step: 280, loss: 0.06498801708221436
step: 290, loss: 0.06445090472698212
step: 300, loss: 0.02683662623167038
step: 310, loss: 0.12585951387882233
step: 320, loss: 0.04943381994962692
step: 330, loss: 0.03249424695968628
step: 340, loss: 0.007656026631593704
step: 350, loss: 0.09102466702461243
epoch 7: dev_f1=0.8243559718969554, f1=0.7599067599067598, best_f1=0.7741935483870966
step: 0, loss: 0.010184981860220432
step: 10, loss: 0.03948752209544182
step: 20, loss: 0.07530184835195541
step: 30, loss: 0.056573569774627686
step: 40, loss: 0.039115190505981445
step: 50, loss: 0.010380883701145649
step: 60, loss: 0.011673806235194206
step: 70, loss: 0.02525409124791622
step: 80, loss: 0.0037583878729492426
step: 90, loss: 0.0061470684595406055
step: 100, loss: 0.008846063166856766
step: 110, loss: 0.01997479796409607
step: 120, loss: 0.1300530731678009
step: 130, loss: 0.01615011692047119
step: 140, loss: 0.0074087404645979404
step: 150, loss: 0.016601484268903732
step: 160, loss: 0.07235057651996613
step: 170, loss: 0.0853753313422203
step: 180, loss: 0.06539856642484665
step: 190, loss: 0.07635795325040817
step: 200, loss: 0.05729975178837776
step: 210, loss: 0.06713441759347916
step: 220, loss: 0.014329074881970882
step: 230, loss: 0.029755983501672745
step: 240, loss: 0.003399185836315155
step: 250, loss: 0.01085143443197012
step: 260, loss: 0.005106526892632246
step: 270, loss: 0.025702618062496185
step: 280, loss: 0.1105661690235138
step: 290, loss: 0.13941046595573425
step: 300, loss: 0.0017502690898254514
step: 310, loss: 0.055534347891807556
step: 320, loss: 0.07991163432598114
step: 330, loss: 0.059530358761548996
step: 340, loss: 0.013043858110904694
step: 350, loss: 0.01385896373540163
epoch 8: dev_f1=0.8439024390243902, f1=0.7642679900744417, best_f1=0.7642679900744417
step: 0, loss: 0.016916615888476372
step: 10, loss: 0.015604836866259575
step: 20, loss: 0.01884865015745163
step: 30, loss: 0.12746503949165344
step: 40, loss: 0.018914369866251945
step: 50, loss: 0.00777829997241497
step: 60, loss: 0.0006331922486424446
step: 70, loss: 0.08019617199897766
step: 80, loss: 0.03454442694783211
step: 90, loss: 0.01168848481029272
step: 100, loss: 0.04533195123076439
step: 110, loss: 0.00376259908080101
step: 120, loss: 0.03865507245063782
step: 130, loss: 0.020295524969697
step: 140, loss: 0.04210679233074188
step: 150, loss: 0.11229865998029709
step: 160, loss: 0.0024266336113214493
step: 170, loss: 0.007330498658120632
step: 180, loss: 0.0006407546461559832
step: 190, loss: 0.009366449899971485
step: 200, loss: 0.04729640856385231
step: 210, loss: 0.01870786026120186
step: 220, loss: 0.001616497291252017
step: 230, loss: 0.008356585167348385
step: 240, loss: 0.12217643111944199
step: 250, loss: 0.06959149241447449
step: 260, loss: 0.03179240971803665
step: 270, loss: 0.014466190710663795
step: 280, loss: 0.05651476979255676
step: 290, loss: 0.014991569332778454
step: 300, loss: 0.0011813243618234992
step: 310, loss: 0.018363412469625473
step: 320, loss: 0.021809658035635948
step: 330, loss: 0.0026969502214342356
step: 340, loss: 0.04310980811715126
step: 350, loss: 0.04246336966753006
epoch 9: dev_f1=0.7990196078431373, f1=0.7237163814180928, best_f1=0.7642679900744417
step: 0, loss: 0.000976554409135133
step: 10, loss: 0.03262963145971298
step: 20, loss: 0.007147573865950108
step: 30, loss: 0.09923143684864044
step: 40, loss: 0.03459199517965317
step: 50, loss: 0.0024482414592057467
step: 60, loss: 0.0004416508018039167
step: 70, loss: 0.00739858765155077
step: 80, loss: 0.008648872375488281
step: 90, loss: 0.002978761214762926
step: 100, loss: 0.008048949763178825
step: 110, loss: 0.04307583346962929
step: 120, loss: 0.006545170210301876
step: 130, loss: 0.0008492484921589494
step: 140, loss: 0.03847686946392059
step: 150, loss: 0.010970155708491802
step: 160, loss: 0.007474215235561132
step: 170, loss: 0.09746737778186798
step: 180, loss: 0.11863149702548981
step: 190, loss: 0.05929924547672272
step: 200, loss: 0.009755137376487255
step: 210, loss: 0.004957714583724737
step: 220, loss: 0.027690598741173744
step: 230, loss: 0.10236860066652298
step: 240, loss: 0.04455173760652542
step: 250, loss: 0.012388891540467739
step: 260, loss: 0.010368633083999157
step: 270, loss: 0.0026769216638058424
step: 280, loss: 0.008692680858075619
step: 290, loss: 0.13856591284275055
step: 300, loss: 0.010515200905501842
step: 310, loss: 0.02320072613656521
step: 320, loss: 0.030037391930818558
step: 330, loss: 0.00587865523993969
step: 340, loss: 0.006003418937325478
step: 350, loss: 0.042389318346977234
epoch 10: dev_f1=0.8257756563245824, f1=0.7623529411764706, best_f1=0.7642679900744417
step: 0, loss: 0.008440548554062843
step: 10, loss: 0.05090095102787018
step: 20, loss: 0.008206113241612911
step: 30, loss: 0.04045376926660538
step: 40, loss: 0.0157148614525795
step: 50, loss: 0.0032597603276371956
step: 60, loss: 0.03885238990187645
step: 70, loss: 0.09588028490543365
step: 80, loss: 0.010172197595238686
step: 90, loss: 0.011437688954174519
step: 100, loss: 0.0035224645398557186
step: 110, loss: 0.02781539037823677
step: 120, loss: 0.010572508908808231
step: 130, loss: 0.12906159460544586
step: 140, loss: 0.027724675834178925
step: 150, loss: 0.01601547561585903
step: 160, loss: 0.00223992089740932
step: 170, loss: 0.002246754476800561
step: 180, loss: 0.024016834795475006
step: 190, loss: 0.023257562890648842
step: 200, loss: 0.0031622652895748615
step: 210, loss: 0.05784730613231659
step: 220, loss: 0.008479895070195198
step: 230, loss: 0.001405077870003879
step: 240, loss: 0.023581966757774353
step: 250, loss: 0.0730375200510025
step: 260, loss: 0.027570147067308426
step: 270, loss: 0.0013377182185649872
step: 280, loss: 0.0006096124416217208
step: 290, loss: 0.0011104414006695151
step: 300, loss: 0.0009464189643040299
step: 310, loss: 0.0026559215039014816
step: 320, loss: 0.003280444536358118
step: 330, loss: 0.02447558008134365
step: 340, loss: 0.0008399330545216799
step: 350, loss: 0.0023972727358341217
epoch 11: dev_f1=0.8009708737864077, f1=0.7342995169082126, best_f1=0.7642679900744417
step: 0, loss: 0.0011315057054162025
step: 10, loss: 0.011754105798900127
step: 20, loss: 0.0006100558675825596
step: 30, loss: 0.11028165370225906
step: 40, loss: 0.0012487642234191298
step: 50, loss: 0.010137428529560566
step: 60, loss: 0.0029418712947517633
step: 70, loss: 0.003798633348196745
step: 80, loss: 0.004747194238007069
step: 90, loss: 0.0261522363871336
step: 100, loss: 0.0022155605256557465
step: 110, loss: 0.00032330446993000805
step: 120, loss: 0.02320714108645916
step: 130, loss: 0.005798314698040485
step: 140, loss: 0.0015530965756624937
step: 150, loss: 0.002098312135785818
step: 160, loss: 0.019274991005659103
step: 170, loss: 0.00788460485637188
step: 180, loss: 0.00029877349152229726
step: 190, loss: 0.00026886328123509884
step: 200, loss: 0.0015305452980101109
step: 210, loss: 0.00861902441829443
step: 220, loss: 0.007008614018559456
step: 230, loss: 0.02080926112830639
step: 240, loss: 0.003309115068987012
step: 250, loss: 0.005680403206497431
step: 260, loss: 0.0031928541138768196
step: 270, loss: 0.0019623765256255865
step: 280, loss: 0.0028214703779667616
step: 290, loss: 0.002978681121021509
step: 300, loss: 0.0149382334202528
step: 310, loss: 0.0989612564444542
step: 320, loss: 0.023050203919410706
step: 330, loss: 0.003879113821312785
step: 340, loss: 0.08628805726766586
step: 350, loss: 0.05947528034448624
epoch 12: dev_f1=0.821852731591449, f1=0.7281553398058251, best_f1=0.7642679900744417
step: 0, loss: 0.0019111050060018897
step: 10, loss: 0.004292552825063467
step: 20, loss: 0.020915577188134193
step: 30, loss: 0.024318505078554153
step: 40, loss: 0.0064238812774419785
step: 50, loss: 0.0076450686901807785
step: 60, loss: 0.00807354599237442
step: 70, loss: 0.01221836730837822
step: 80, loss: 0.0010379486484453082
step: 90, loss: 0.006140333600342274
step: 100, loss: 0.04361054673790932
step: 110, loss: 0.050948865711688995
step: 120, loss: 0.001432329067029059
step: 130, loss: 0.007790871895849705
step: 140, loss: 0.00032679157448001206
step: 150, loss: 0.0018561615142971277
step: 160, loss: 0.0002454396162647754
step: 170, loss: 0.010729153640568256
step: 180, loss: 0.0010925214737653732
step: 190, loss: 0.0009582223719917238
step: 200, loss: 0.0016552434535697103
step: 210, loss: 0.002956775249913335
step: 220, loss: 0.008731381967663765
step: 230, loss: 9.966778452508152e-05
step: 240, loss: 0.0007633261848241091
step: 250, loss: 0.006056997459381819
step: 260, loss: 0.011517906561493874
step: 270, loss: 0.00039323093369603157
step: 280, loss: 0.0073427846655249596
step: 290, loss: 0.005100123584270477
step: 300, loss: 0.0010041113710030913
step: 310, loss: 0.001856815186329186
step: 320, loss: 0.018163569271564484
step: 330, loss: 0.052053116261959076
step: 340, loss: 0.008112595416605473
step: 350, loss: 0.10543017089366913
epoch 13: dev_f1=0.8337595907928389, f1=0.7506561679790027, best_f1=0.7642679900744417
step: 0, loss: 0.0021849717013537884
step: 10, loss: 0.0013488944387063384
step: 20, loss: 0.00021685418323613703
step: 30, loss: 0.00016462360508739948
step: 40, loss: 0.0002725269878283143
step: 50, loss: 0.007273870054632425
step: 60, loss: 0.0017698250012472272
step: 70, loss: 0.011937621980905533
step: 80, loss: 0.00238376809284091
step: 90, loss: 0.0031773278024047613
step: 100, loss: 0.00017038060468621552
step: 110, loss: 0.0010014872532337904
step: 120, loss: 0.0017102808924391866
step: 130, loss: 0.012566887773573399
step: 140, loss: 0.0027190253604203463
step: 150, loss: 0.0007559895166195929
step: 160, loss: 0.00022182297834660858
step: 170, loss: 0.00030478695407509804
step: 180, loss: 0.0020623726304620504
step: 190, loss: 0.1743975281715393
step: 200, loss: 0.006695729214698076
step: 210, loss: 0.08604786545038223
step: 220, loss: 0.00024353699700441211
step: 230, loss: 0.12080785632133484
step: 240, loss: 0.0007201570551842451
step: 250, loss: 0.024654047563672066
step: 260, loss: 0.0001859576877905056
step: 270, loss: 0.000337695557391271
step: 280, loss: 0.0004623921704478562
step: 290, loss: 0.0007605167338624597
step: 300, loss: 0.03895467519760132
step: 310, loss: 0.0588969923555851
step: 320, loss: 0.00027205151855014265
step: 330, loss: 0.005526355467736721
step: 340, loss: 0.00208160444162786
step: 350, loss: 0.00026470955344848335
epoch 14: dev_f1=0.8241469816272966, f1=0.7560321715817695, best_f1=0.7642679900744417
step: 0, loss: 0.00017922418192029
step: 10, loss: 0.008168489672243595
step: 20, loss: 0.00014127438771538436
step: 30, loss: 0.01162763126194477
step: 40, loss: 5.601951488642953e-05
step: 50, loss: 0.0008281009504571557
step: 60, loss: 0.0014896650100126863
step: 70, loss: 0.00027038235566578805
step: 80, loss: 0.002711003879085183
step: 90, loss: 0.005560652352869511
step: 100, loss: 0.00024593493435531855
step: 110, loss: 0.00014717582962475717
step: 120, loss: 0.06891017407178879
step: 130, loss: 0.00014597020344808698
step: 140, loss: 0.0003059736918658018
step: 150, loss: 0.0015456920955330133
step: 160, loss: 0.000225427356781438
step: 170, loss: 0.038942184299230576
step: 180, loss: 0.0005582281155511737
step: 190, loss: 0.0008038564119488001
step: 200, loss: 0.009725607000291348
step: 210, loss: 0.0044296737760305405
step: 220, loss: 0.16614662110805511
step: 230, loss: 0.04599914699792862
step: 240, loss: 0.005311592016369104
step: 250, loss: 0.005026702769100666
step: 260, loss: 0.0008227246580645442
step: 270, loss: 0.0016784915933385491
step: 280, loss: 0.01137357484549284
step: 290, loss: 0.0007444118964485824
step: 300, loss: 0.02059042453765869
step: 310, loss: 0.004203634802252054
step: 320, loss: 0.0009254887118004262
step: 330, loss: 0.0007323095924220979
step: 340, loss: 0.005522255785763264
step: 350, loss: 0.0006561289192177355
epoch 15: dev_f1=0.8358974358974359, f1=0.75, best_f1=0.7642679900744417
step: 0, loss: 0.02070472203195095
step: 10, loss: 0.001863135490566492
step: 20, loss: 0.0014837909257039428
step: 30, loss: 0.0013272014912217855
step: 40, loss: 0.0010680465493351221
step: 50, loss: 0.00014431914314627647
step: 60, loss: 0.0002476368972565979
step: 70, loss: 0.0014678353909403086
step: 80, loss: 0.006254973355680704
step: 90, loss: 0.0016821817262098193
step: 100, loss: 0.0018556356662884355
step: 110, loss: 0.006022276356816292
step: 120, loss: 0.0008187131024897099
step: 130, loss: 0.004577220883220434
step: 140, loss: 0.00039645974175073206
step: 150, loss: 0.0027398669626563787
step: 160, loss: 0.006040828302502632
step: 170, loss: 9.275311458623037e-05
step: 180, loss: 0.0002429051382932812
step: 190, loss: 0.02818405255675316
step: 200, loss: 0.00024385435972362757
step: 210, loss: 9.595437586540356e-05
step: 220, loss: 0.0003609339182730764
step: 230, loss: 0.0012270980514585972
step: 240, loss: 0.00020938324450980872
step: 250, loss: 0.0005674616550095379
step: 260, loss: 0.005467790644615889
step: 270, loss: 0.0013848596718162298
step: 280, loss: 0.09430127590894699
step: 290, loss: 0.0001365950156468898
step: 300, loss: 9.558568854117766e-05
step: 310, loss: 0.010678200051188469
step: 320, loss: 0.00615394301712513
step: 330, loss: 0.020675312727689743
step: 340, loss: 0.0005089199403300881
step: 350, loss: 0.0010384242050349712
epoch 16: dev_f1=0.8353808353808354, f1=0.7587939698492463, best_f1=0.7642679900744417
step: 0, loss: 0.0029875754844397306
step: 10, loss: 0.0002531538484618068
step: 20, loss: 0.0005059441900812089
step: 30, loss: 0.0002672418486326933
step: 40, loss: 0.0028170146979391575
step: 50, loss: 0.000389100139727816
step: 60, loss: 0.001514931907877326
step: 70, loss: 0.000291158416075632
step: 80, loss: 6.723919796058908e-05
step: 90, loss: 0.04662175476551056
step: 100, loss: 0.0037678785156458616
step: 110, loss: 0.0003934463020414114
step: 120, loss: 0.23950456082820892
step: 130, loss: 0.000944165454711765
step: 140, loss: 0.019158756360411644
step: 150, loss: 0.0016727305483072996
step: 160, loss: 0.0788186714053154
step: 170, loss: 0.09142235666513443
step: 180, loss: 0.0006744465208612382
step: 190, loss: 0.0006473548128269613
step: 200, loss: 0.008206892758607864
step: 210, loss: 0.0021315342746675014
step: 220, loss: 0.04065559431910515
step: 230, loss: 0.018170850351452827
step: 240, loss: 0.0017956160008907318
step: 250, loss: 0.0005841356469318271
step: 260, loss: 0.00040157060720957816
step: 270, loss: 0.004779125563800335
step: 280, loss: 0.02726777084171772
step: 290, loss: 8.38907653815113e-05
step: 300, loss: 0.0004348380316514522
step: 310, loss: 0.003636961104348302
step: 320, loss: 0.02538750320672989
step: 330, loss: 0.005296613089740276
step: 340, loss: 0.001217261073179543
step: 350, loss: 0.0003107162192463875
epoch 17: dev_f1=0.8329177057356608, f1=0.7506297229219144, best_f1=0.7642679900744417
step: 0, loss: 0.0004169176972936839
step: 10, loss: 0.00011728280514944345
step: 20, loss: 0.014429652132093906
step: 30, loss: 0.0015166280791163445
step: 40, loss: 0.0023061761166900396
step: 50, loss: 9.644376405049115e-05
step: 60, loss: 0.00014735155855305493
step: 70, loss: 0.0041167535819113255
step: 80, loss: 0.00025169627042487264
step: 90, loss: 0.000762270821724087
step: 100, loss: 0.0005521549610421062
step: 110, loss: 0.0006318689556792378
step: 120, loss: 9.366578160552308e-05
step: 130, loss: 5.76590646232944e-05
step: 140, loss: 7.141316746128723e-05
step: 150, loss: 0.0007325700717046857
step: 160, loss: 0.058951131999492645
step: 170, loss: 0.000286571157630533
step: 180, loss: 0.0005911857006140053
step: 190, loss: 0.0001992897450691089
step: 200, loss: 0.0007403600611723959
step: 210, loss: 0.010809364728629589
step: 220, loss: 0.00921581219881773
step: 230, loss: 0.00035671854857355356
step: 240, loss: 0.0043330746702849865
step: 250, loss: 0.003381061367690563
step: 260, loss: 0.019265448674559593
step: 270, loss: 0.000906675704754889
step: 280, loss: 0.0009445730247534811
step: 290, loss: 5.8829147747019306e-05
step: 300, loss: 0.002397931879386306
step: 310, loss: 0.0002698371245060116
step: 320, loss: 0.00014824581739958376
step: 330, loss: 0.00016769167268648744
step: 340, loss: 0.01595177873969078
step: 350, loss: 0.002780233509838581
epoch 18: dev_f1=0.8346055979643764, f1=0.7570332480818416, best_f1=0.7642679900744417
step: 0, loss: 0.00012572859122883528
step: 10, loss: 0.0004062243679072708
step: 20, loss: 0.003293189685791731
step: 30, loss: 0.012725205160677433
step: 40, loss: 0.00010586312419036403
step: 50, loss: 0.00019382005848456174
step: 60, loss: 0.0018688178388401866
step: 70, loss: 0.0003212947631254792
step: 80, loss: 0.00016034438158385456
step: 90, loss: 0.0020716150756925344
step: 100, loss: 0.0030009751208126545
step: 110, loss: 0.0001267076877411455
step: 120, loss: 0.00016014790162444115
step: 130, loss: 0.0006976926815696061
step: 140, loss: 0.0009193603182211518
step: 150, loss: 0.00015184268704615533
step: 160, loss: 0.0014170428039506078
step: 170, loss: 0.0003753716591745615
step: 180, loss: 0.0008894313941709697
step: 190, loss: 0.00138696632348001
step: 200, loss: 0.0007619339739903808
step: 210, loss: 0.09329278767108917
step: 220, loss: 0.008077665232121944
step: 230, loss: 0.0004464008379727602
step: 240, loss: 6.377222598530352e-05
step: 250, loss: 0.0002824070688802749
step: 260, loss: 0.0030184555798768997
step: 270, loss: 0.0003827709297183901
step: 280, loss: 0.0014785388484597206
step: 290, loss: 0.00010306473268428817
step: 300, loss: 0.001617403351701796
step: 310, loss: 0.00031887280056253076
step: 320, loss: 6.942744948901236e-05
step: 330, loss: 0.0003918635193258524
step: 340, loss: 0.00019400942255742848
step: 350, loss: 0.00017726219084579498
epoch 19: dev_f1=0.8258706467661691, f1=0.760705289672544, best_f1=0.7642679900744417
step: 0, loss: 0.0008556384709663689
step: 10, loss: 0.0029206194449216127
step: 20, loss: 7.077059854054824e-05
step: 30, loss: 0.000744021323043853
step: 40, loss: 0.0003101666225120425
step: 50, loss: 0.00024057445989456028
step: 60, loss: 0.00011825442197732627
step: 70, loss: 0.00018360720423515886
step: 80, loss: 6.027004201314412e-05
step: 90, loss: 0.00011468906450318173
step: 100, loss: 0.00026232973323203623
step: 110, loss: 0.0002092812064802274
step: 120, loss: 0.0001791573449736461
step: 130, loss: 0.0011810774449259043
step: 140, loss: 0.0008651287062093616
step: 150, loss: 0.00033407227601855993
step: 160, loss: 0.001413470134139061
step: 170, loss: 0.000619115075096488
step: 180, loss: 0.05625663325190544
step: 190, loss: 0.0006481252494268119
step: 200, loss: 6.129506073193625e-05
step: 210, loss: 0.00016165207489393651
step: 220, loss: 8.69063296704553e-05
step: 230, loss: 0.019330570474267006
step: 240, loss: 0.0005318594630807638
step: 250, loss: 0.0061995284631848335
step: 260, loss: 0.00014319701585918665
step: 270, loss: 0.004230906721204519
step: 280, loss: 6.63225437165238e-05
step: 290, loss: 0.0003294551861472428
step: 300, loss: 0.002198296133428812
step: 310, loss: 0.0002576716069597751
step: 320, loss: 0.00022579685901291668
step: 330, loss: 0.0006564485956914723
step: 340, loss: 0.00014122338325250894
step: 350, loss: 5.786121982964687e-05
epoch 20: dev_f1=0.8325123152709358, f1=0.7669172932330827, best_f1=0.7642679900744417
