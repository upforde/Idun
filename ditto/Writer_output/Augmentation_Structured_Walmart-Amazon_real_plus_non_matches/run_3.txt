cuda
Device: cuda
step: 0, loss: 0.6525493860244751
step: 10, loss: 0.23204612731933594
step: 20, loss: 0.14810216426849365
step: 30, loss: 0.23481832444667816
step: 40, loss: 0.14410874247550964
step: 50, loss: 0.1368091106414795
step: 60, loss: 0.14615359902381897
step: 70, loss: 0.053947266191244125
step: 80, loss: 0.04886264726519585
step: 90, loss: 0.23007555305957794
step: 100, loss: 0.2327861338853836
step: 110, loss: 0.14166182279586792
step: 120, loss: 0.045845579355955124
step: 130, loss: 0.2300446629524231
step: 140, loss: 0.040471021085977554
step: 150, loss: 0.4748876690864563
step: 160, loss: 0.1303899884223938
step: 170, loss: 0.12374335527420044
step: 180, loss: 0.10099957138299942
step: 190, loss: 0.21898570656776428
step: 200, loss: 0.3393862545490265
step: 210, loss: 0.09763436019420624
step: 220, loss: 0.4040093421936035
step: 230, loss: 0.133076012134552
step: 240, loss: 0.19329778850078583
step: 250, loss: 0.023317568004131317
step: 260, loss: 0.07089933753013611
step: 270, loss: 0.3940572440624237
step: 280, loss: 0.021527931094169617
step: 290, loss: 0.22635143995285034
step: 300, loss: 0.18549583852291107
step: 310, loss: 0.17024002969264984
step: 320, loss: 0.10176091641187668
step: 330, loss: 0.10393140465021133
step: 340, loss: 0.1921110600233078
step: 350, loss: 0.19899483025074005
step: 360, loss: 0.12273327261209488
epoch 1: dev_f1=0.6237113402061856, f1=0.6578947368421052, best_f1=0.6578947368421052
step: 0, loss: 0.18591347336769104
step: 10, loss: 0.06459333747625351
step: 20, loss: 0.03372564911842346
step: 30, loss: 0.10173601657152176
step: 40, loss: 0.1584978848695755
step: 50, loss: 0.07679431140422821
step: 60, loss: 0.11831451207399368
step: 70, loss: 0.03498411178588867
step: 80, loss: 0.19267800450325012
step: 90, loss: 0.07064302265644073
step: 100, loss: 0.15430627763271332
step: 110, loss: 0.28156352043151855
step: 120, loss: 0.16471680998802185
step: 130, loss: 0.07481886446475983
step: 140, loss: 0.10911894589662552
step: 150, loss: 0.22031575441360474
step: 160, loss: 0.130833700299263
step: 170, loss: 0.11550280451774597
step: 180, loss: 0.08935288339853287
step: 190, loss: 0.06031918153166771
step: 200, loss: 0.24200768768787384
step: 210, loss: 0.05453056842088699
step: 220, loss: 0.1372070014476776
step: 230, loss: 0.20889487862586975
step: 240, loss: 0.09836728870868683
step: 250, loss: 0.11728046834468842
step: 260, loss: 0.07824300229549408
step: 270, loss: 0.16448338329792023
step: 280, loss: 0.10670477151870728
step: 290, loss: 0.04217325896024704
step: 300, loss: 0.1125674843788147
step: 310, loss: 0.11667647212743759
step: 320, loss: 0.03721477836370468
step: 330, loss: 0.38924306631088257
step: 340, loss: 0.002937471494078636
step: 350, loss: 0.04277186468243599
step: 360, loss: 0.12997004389762878
epoch 2: dev_f1=0.7543859649122807, f1=0.7343283582089553, best_f1=0.7343283582089553
step: 0, loss: 0.04545695334672928
step: 10, loss: 0.038054242730140686
step: 20, loss: 0.09457565099000931
step: 30, loss: 0.0225161574780941
step: 40, loss: 0.09233690798282623
step: 50, loss: 0.22094137966632843
step: 60, loss: 0.03863193094730377
step: 70, loss: 0.07261002063751221
step: 80, loss: 0.04677130654454231
step: 90, loss: 0.06080052629113197
step: 100, loss: 0.22125238180160522
step: 110, loss: 0.04203077778220177
step: 120, loss: 0.09453926980495453
step: 130, loss: 0.13148514926433563
step: 140, loss: 0.16650786995887756
step: 150, loss: 0.061702288687229156
step: 160, loss: 0.029231682419776917
step: 170, loss: 0.23710133135318756
step: 180, loss: 0.09521383792161942
step: 190, loss: 0.02342830039560795
step: 200, loss: 0.07454931735992432
step: 210, loss: 0.05835511162877083
step: 220, loss: 0.04694686457514763
step: 230, loss: 0.07064827531576157
step: 240, loss: 0.02737065777182579
step: 250, loss: 0.03204101324081421
step: 260, loss: 0.19063004851341248
step: 270, loss: 0.22728826105594635
step: 280, loss: 0.10822124779224396
step: 290, loss: 0.26742398738861084
step: 300, loss: 0.06307913362979889
step: 310, loss: 0.09996859729290009
step: 320, loss: 0.10753887891769409
step: 330, loss: 0.03439176827669144
step: 340, loss: 0.025825243443250656
step: 350, loss: 0.10060332715511322
step: 360, loss: 0.13849367201328278
epoch 3: dev_f1=0.7440758293838864, f1=0.7416267942583731, best_f1=0.7343283582089553
step: 0, loss: 0.048390232026576996
step: 10, loss: 0.05933056026697159
step: 20, loss: 0.07276289165019989
step: 30, loss: 0.06693804264068604
step: 40, loss: 0.04040997102856636
step: 50, loss: 0.23723550140857697
step: 60, loss: 0.03478404879570007
step: 70, loss: 0.0469420850276947
step: 80, loss: 0.04063091054558754
step: 90, loss: 0.022018352523446083
step: 100, loss: 0.12183638662099838
step: 110, loss: 0.07099694013595581
step: 120, loss: 0.05898328870534897
step: 130, loss: 0.06298420578241348
step: 140, loss: 0.020588522776961327
step: 150, loss: 0.15939606726169586
step: 160, loss: 0.059736218303442
step: 170, loss: 0.015600285492837429
step: 180, loss: 0.04609109088778496
step: 190, loss: 0.08236543834209442
step: 200, loss: 0.015057748183608055
step: 210, loss: 0.02383783459663391
step: 220, loss: 0.07977424561977386
step: 230, loss: 0.00882772821933031
step: 240, loss: 0.06271502375602722
step: 250, loss: 0.07958285510540009
step: 260, loss: 0.0716504156589508
step: 270, loss: 0.0969332605600357
step: 280, loss: 0.007832375355064869
step: 290, loss: 0.014783067628741264
step: 300, loss: 0.05057918280363083
step: 310, loss: 0.13106685876846313
step: 320, loss: 0.031090758740901947
step: 330, loss: 0.030827993527054787
step: 340, loss: 0.051201995462179184
step: 350, loss: 0.04982325807213783
step: 360, loss: 0.05120151862502098
epoch 4: dev_f1=0.7626262626262625, f1=0.79155672823219, best_f1=0.79155672823219
step: 0, loss: 0.01945735141634941
step: 10, loss: 0.0027984073385596275
step: 20, loss: 0.00984388031065464
step: 30, loss: 0.058733291923999786
step: 40, loss: 0.00035591464256867766
step: 50, loss: 0.029447242617607117
step: 60, loss: 0.024090467020869255
step: 70, loss: 0.030899787321686745
step: 80, loss: 0.061532873660326004
step: 90, loss: 0.04284573346376419
step: 100, loss: 0.04837369546294212
step: 110, loss: 0.026285771280527115
step: 120, loss: 0.004676640033721924
step: 130, loss: 0.0444747693836689
step: 140, loss: 0.029577819630503654
step: 150, loss: 0.07341491430997849
step: 160, loss: 0.24901703000068665
step: 170, loss: 0.07693067938089371
step: 180, loss: 0.07684414833784103
step: 190, loss: 0.013332795351743698
step: 200, loss: 0.016109680756926537
step: 210, loss: 0.0821332037448883
step: 220, loss: 0.04788155108690262
step: 230, loss: 0.08053992688655853
step: 240, loss: 0.09009498357772827
step: 250, loss: 0.040194638073444366
step: 260, loss: 0.060914263129234314
step: 270, loss: 0.03611110895872116
step: 280, loss: 0.029579870402812958
step: 290, loss: 0.03760940209031105
step: 300, loss: 0.050549838691949844
step: 310, loss: 0.09091433137655258
step: 320, loss: 0.0493299625813961
step: 330, loss: 0.056506965309381485
step: 340, loss: 0.04481462016701698
step: 350, loss: 0.1535087525844574
step: 360, loss: 0.07286661118268967
epoch 5: dev_f1=0.746031746031746, f1=0.7302452316076293, best_f1=0.79155672823219
step: 0, loss: 0.10168769955635071
step: 10, loss: 0.02648482471704483
step: 20, loss: 0.04722773656249046
step: 30, loss: 0.03355279937386513
step: 40, loss: 0.06694395840167999
step: 50, loss: 0.013355901464819908
step: 60, loss: 0.02616482600569725
step: 70, loss: 0.09758549928665161
step: 80, loss: 0.08348670601844788
step: 90, loss: 0.016444958746433258
step: 100, loss: 0.022166745737195015
step: 110, loss: 0.11774087697267532
step: 120, loss: 0.015657950192689896
step: 130, loss: 0.00833109486848116
step: 140, loss: 0.025825301185250282
step: 150, loss: 0.02114635705947876
step: 160, loss: 0.08251393586397171
step: 170, loss: 0.0671810731291771
step: 180, loss: 0.027133654803037643
step: 190, loss: 0.04707131162285805
step: 200, loss: 0.02527177520096302
step: 210, loss: 0.0040494902059435844
step: 220, loss: 0.041611719876527786
step: 230, loss: 0.055175818502902985
step: 240, loss: 0.046105287969112396
step: 250, loss: 0.14405545592308044
step: 260, loss: 0.12588614225387573
step: 270, loss: 0.017749790102243423
step: 280, loss: 0.02070010080933571
step: 290, loss: 0.037850070744752884
step: 300, loss: 0.1388653814792633
step: 310, loss: 0.03403998166322708
step: 320, loss: 0.10173694789409637
step: 330, loss: 0.07563947141170502
step: 340, loss: 0.014801361598074436
step: 350, loss: 0.08694133907556534
step: 360, loss: 0.07399730384349823
epoch 6: dev_f1=0.767123287671233, f1=0.7413793103448276, best_f1=0.7413793103448276
step: 0, loss: 0.02880900911986828
step: 10, loss: 0.08804947882890701
step: 20, loss: 0.014109930023550987
step: 30, loss: 0.03580379858613014
step: 40, loss: 0.09785924106836319
step: 50, loss: 0.008611551485955715
step: 60, loss: 0.0958784744143486
step: 70, loss: 9.624236554373056e-05
step: 80, loss: 0.035451244562864304
step: 90, loss: 0.02292858436703682
step: 100, loss: 0.06153417006134987
step: 110, loss: 0.009540481492877007
step: 120, loss: 0.036584459245204926
step: 130, loss: 0.005215839482843876
step: 140, loss: 0.06908223032951355
step: 150, loss: 0.022699154913425446
step: 160, loss: 0.01558453869074583
step: 170, loss: 0.11255526542663574
step: 180, loss: 0.10326613485813141
step: 190, loss: 0.0464634895324707
step: 200, loss: 0.10105977952480316
step: 210, loss: 0.032421890646219254
step: 220, loss: 0.056749120354652405
step: 230, loss: 0.04321189224720001
step: 240, loss: 0.06581929326057434
step: 250, loss: 0.024704983457922935
step: 260, loss: 0.03420685976743698
step: 270, loss: 0.012460891157388687
step: 280, loss: 0.004134116694331169
step: 290, loss: 0.00820070132613182
step: 300, loss: 0.024581464007496834
step: 310, loss: 0.1230265349149704
step: 320, loss: 0.09481505304574966
step: 330, loss: 0.08913612365722656
step: 340, loss: 0.05286825820803642
step: 350, loss: 0.041284941136837006
step: 360, loss: 0.07097715884447098
epoch 7: dev_f1=0.7647058823529412, f1=0.7473118279569892, best_f1=0.7413793103448276
step: 0, loss: 0.06510703265666962
step: 10, loss: 0.09588197618722916
step: 20, loss: 0.06157048046588898
step: 30, loss: 0.06661448627710342
step: 40, loss: 0.022158775478601456
step: 50, loss: 0.0895131528377533
step: 60, loss: 0.03429846465587616
step: 70, loss: 0.01897447183728218
step: 80, loss: 0.09450235217809677
step: 90, loss: 0.049477286636829376
step: 100, loss: 0.08297999203205109
step: 110, loss: 0.05660582706332207
step: 120, loss: 0.00015415191592182964
step: 130, loss: 0.049439556896686554
step: 140, loss: 0.22724728286266327
step: 150, loss: 0.0008230534149333835
step: 160, loss: 0.05278775468468666
step: 170, loss: 0.037753596901893616
step: 180, loss: 0.14168202877044678
step: 190, loss: 0.055228933691978455
step: 200, loss: 0.020986733958125114
step: 210, loss: 0.054338302463293076
step: 220, loss: 0.031040681526064873
step: 230, loss: 0.012278588488698006
step: 240, loss: 0.013893780298531055
step: 250, loss: 0.004105675965547562
step: 260, loss: 0.04169340431690216
step: 270, loss: 0.01228463463485241
step: 280, loss: 8.75534096849151e-05
step: 290, loss: 0.09703993797302246
step: 300, loss: 0.02437896467745304
step: 310, loss: 0.02483447827398777
step: 320, loss: 0.08718469738960266
step: 330, loss: 0.04221873730421066
step: 340, loss: 0.03759409114718437
step: 350, loss: 0.04792119562625885
step: 360, loss: 0.14147287607192993
epoch 8: dev_f1=0.7379679144385027, f1=0.7411444141689373, best_f1=0.7413793103448276
step: 0, loss: 0.05930483713746071
step: 10, loss: 0.07457847148180008
step: 20, loss: 0.02010934427380562
step: 30, loss: 0.032802827656269073
step: 40, loss: 0.05268331244587898
step: 50, loss: 0.04623211547732353
step: 60, loss: 0.0028182922396808863
step: 70, loss: 0.04195604473352432
step: 80, loss: 0.07638061791658401
step: 90, loss: 0.0071851471439003944
step: 100, loss: 0.03704708442091942
step: 110, loss: 0.017167750746011734
step: 120, loss: 0.0010328376665711403
step: 130, loss: 0.018657099455595016
step: 140, loss: 0.06029978394508362
step: 150, loss: 0.019768942147493362
step: 160, loss: 0.18198463320732117
step: 170, loss: 0.013211152516305447
step: 180, loss: 0.017944052815437317
step: 190, loss: 0.00012430359493009746
step: 200, loss: 0.04927460849285126
step: 210, loss: 0.0019787424243986607
step: 220, loss: 0.03148111701011658
step: 230, loss: 0.019018348306417465
step: 240, loss: 0.06987382471561432
step: 250, loss: 0.05841342732310295
step: 260, loss: 0.029228392988443375
step: 270, loss: 0.05595022439956665
step: 280, loss: 0.13107766211032867
step: 290, loss: 0.09255018085241318
step: 300, loss: 0.09495650976896286
step: 310, loss: 0.010499373078346252
step: 320, loss: 0.04223880171775818
step: 330, loss: 0.02207643911242485
step: 340, loss: 0.05179388448596001
step: 350, loss: 0.14695857465267181
step: 360, loss: 0.004435703158378601
epoch 9: dev_f1=0.7382198952879582, f1=0.7527472527472527, best_f1=0.7413793103448276
step: 0, loss: 0.03284717723727226
step: 10, loss: 0.029858935624361038
step: 20, loss: 0.026754945516586304
step: 30, loss: 0.021467924118041992
step: 40, loss: 0.008251910097897053
step: 50, loss: 0.0246160589158535
step: 60, loss: 0.01052931323647499
step: 70, loss: 0.13260537385940552
step: 80, loss: 0.017335154116153717
step: 90, loss: 0.02124110236763954
step: 100, loss: 0.0652279332280159
step: 110, loss: 0.04986180365085602
step: 120, loss: 0.056274641305208206
step: 130, loss: 0.07302748411893845
step: 140, loss: 0.05593933165073395
step: 150, loss: 0.015515738166868687
step: 160, loss: 0.07350360602140427
step: 170, loss: 0.06420153379440308
step: 180, loss: 0.004433055873960257
step: 190, loss: 0.015240148641169071
step: 200, loss: 0.0031700909603387117
step: 210, loss: 0.020060008391737938
step: 220, loss: 0.04527535289525986
step: 230, loss: 0.11911732703447342
step: 240, loss: 0.010341407731175423
step: 250, loss: 0.04386357590556145
step: 260, loss: 0.02906450256705284
step: 270, loss: 0.0536588653922081
step: 280, loss: 0.02520935609936714
step: 290, loss: 0.05077948048710823
step: 300, loss: 0.03285562992095947
step: 310, loss: 0.07487894594669342
step: 320, loss: 0.018583988770842552
step: 330, loss: 0.13594289124011993
step: 340, loss: 0.004314304329454899
step: 350, loss: 0.0916256308555603
step: 360, loss: 0.06061406061053276
epoch 10: dev_f1=0.7206703910614525, f1=0.7130434782608697, best_f1=0.7413793103448276
step: 0, loss: 0.007384616415947676
step: 10, loss: 0.03560493141412735
step: 20, loss: 3.720349559444003e-05
step: 30, loss: 0.06733246147632599
step: 40, loss: 0.029850633814930916
step: 50, loss: 0.001370586920529604
step: 60, loss: 0.054676201194524765
step: 70, loss: 8.681764302309602e-05
step: 80, loss: 0.008443980477750301
step: 90, loss: 0.056946635246276855
step: 100, loss: 0.004692671820521355
step: 110, loss: 0.02564109116792679
step: 120, loss: 0.002402366604655981
step: 130, loss: 0.0008671603281982243
step: 140, loss: 0.013205562718212605
step: 150, loss: 0.03205890208482742
step: 160, loss: 0.010317671112716198
step: 170, loss: 0.0006700531812384725
step: 180, loss: 0.008594142273068428
step: 190, loss: 0.01467335969209671
step: 200, loss: 0.016045894473791122
step: 210, loss: 0.02355949766933918
step: 220, loss: 0.020880287513136864
step: 230, loss: 0.0456729494035244
step: 240, loss: 0.004860721528530121
step: 250, loss: 0.007603105623275042
step: 260, loss: 0.15109962224960327
step: 270, loss: 0.044613707810640335
step: 280, loss: 0.0024779834784567356
step: 290, loss: 0.04170230031013489
step: 300, loss: 0.09026113897562027
step: 310, loss: 0.00646207295358181
step: 320, loss: 0.0012119191233068705
step: 330, loss: 0.02127126231789589
step: 340, loss: 0.013898506760597229
step: 350, loss: 0.01758400723338127
step: 360, loss: 0.007483670487999916
epoch 11: dev_f1=0.7821522309711286, f1=0.7257617728531854, best_f1=0.7257617728531854
step: 0, loss: 0.02418195828795433
step: 10, loss: 0.02444091998040676
step: 20, loss: 0.029995610937476158
step: 30, loss: 0.009041763842105865
step: 40, loss: 0.0016486021922901273
step: 50, loss: 0.018888719379901886
step: 60, loss: 0.04961078241467476
step: 70, loss: 0.020347651094198227
step: 80, loss: 0.0037995800375938416
step: 90, loss: 0.011999169364571571
step: 100, loss: 0.0011669355444610119
step: 110, loss: 0.165467768907547
step: 120, loss: 0.054243676364421844
step: 130, loss: 0.11590202152729034
step: 140, loss: 0.00935340952128172
step: 150, loss: 0.028248168528079987
step: 160, loss: 0.0031609220895916224
step: 170, loss: 0.039436306804418564
step: 180, loss: 0.023293325677514076
step: 190, loss: 0.06757187098264694
step: 200, loss: 0.1282937079668045
step: 210, loss: 0.03949865698814392
step: 220, loss: 0.03895407170057297
step: 230, loss: 0.008479815907776356
step: 240, loss: 0.019697753712534904
step: 250, loss: 0.029216762632131577
step: 260, loss: 0.018746988847851753
step: 270, loss: 0.006022267043590546
step: 280, loss: 0.0018599617760628462
step: 290, loss: 0.010917801409959793
step: 300, loss: 0.03711980953812599
step: 310, loss: 0.04447090998291969
step: 320, loss: 0.04517022520303726
step: 330, loss: 0.027538549154996872
step: 340, loss: 0.038233157247304916
step: 350, loss: 0.030784642323851585
step: 360, loss: 0.009153618477284908
epoch 12: dev_f1=0.7611548556430445, f1=0.7322404371584699, best_f1=0.7257617728531854
step: 0, loss: 0.03453117609024048
step: 10, loss: 0.002659268444404006
step: 20, loss: 0.09070076793432236
step: 30, loss: 0.022110991179943085
step: 40, loss: 0.009531651623547077
step: 50, loss: 0.010145032778382301
step: 60, loss: 0.019422968849539757
step: 70, loss: 0.01186702586710453
step: 80, loss: 0.02532864362001419
step: 90, loss: 0.014013569802045822
step: 100, loss: 0.0018461544532328844
step: 110, loss: 0.045338671654462814
step: 120, loss: 0.02014133520424366
step: 130, loss: 0.0846865251660347
step: 140, loss: 0.04512287676334381
step: 150, loss: 0.001382645801641047
step: 160, loss: 0.001996096223592758
step: 170, loss: 0.06276309490203857
step: 180, loss: 0.0076618557795882225
step: 190, loss: 0.0023242870811372995
step: 200, loss: 0.003971964120864868
step: 210, loss: 5.1340753998374566e-05
step: 220, loss: 8.848773723002523e-05
step: 230, loss: 0.0036926616448909044
step: 240, loss: 0.001167472219094634
step: 250, loss: 0.0005866121500730515
step: 260, loss: 0.007777980994433165
step: 270, loss: 0.00032907433342188597
step: 280, loss: 0.1421949565410614
step: 290, loss: 0.08972007781267166
step: 300, loss: 0.00019855628488585353
step: 310, loss: 9.690741717349738e-05
step: 320, loss: 0.02136380784213543
step: 330, loss: 0.03183310106396675
step: 340, loss: 5.0799153541447595e-05
step: 350, loss: 0.028425350785255432
step: 360, loss: 0.0031488053500652313
epoch 13: dev_f1=0.7783783783783784, f1=0.7126436781609196, best_f1=0.7257617728531854
step: 0, loss: 0.026730192825198174
step: 10, loss: 0.005710586905479431
step: 20, loss: 0.027806833386421204
step: 30, loss: 0.008666804991662502
step: 40, loss: 0.08408818393945694
step: 50, loss: 0.1172773689031601
step: 60, loss: 0.07788725942373276
step: 70, loss: 0.022980792447924614
step: 80, loss: 0.02823883295059204
step: 90, loss: 0.00467465678229928
step: 100, loss: 0.007533424999564886
step: 110, loss: 0.003714225022122264
step: 120, loss: 0.0003234539180994034
step: 130, loss: 0.06605258584022522
step: 140, loss: 0.0711585283279419
step: 150, loss: 0.08223135024309158
step: 160, loss: 0.10998658835887909
step: 170, loss: 0.04528535529971123
step: 180, loss: 0.034496963024139404
step: 190, loss: 0.013754515908658504
step: 200, loss: 0.08947961777448654
step: 210, loss: 0.0394534096121788
step: 220, loss: 4.768093640450388e-05
step: 230, loss: 0.0011316189775243402
step: 240, loss: 0.0006590271950699389
step: 250, loss: 0.01425604335963726
step: 260, loss: 0.02140691876411438
step: 270, loss: 0.17704492807388306
step: 280, loss: 0.14568758010864258
step: 290, loss: 0.0013472953578457236
step: 300, loss: 0.020425762981176376
step: 310, loss: 0.0059417420998215675
step: 320, loss: 0.017934447154402733
step: 330, loss: 0.011953596025705338
step: 340, loss: 0.027831070125102997
step: 350, loss: 0.01339139323681593
step: 360, loss: 0.052790526300668716
epoch 14: dev_f1=0.726775956284153, f1=0.7011494252873564, best_f1=0.7257617728531854
step: 0, loss: 0.041945815086364746
step: 10, loss: 0.010594448074698448
step: 20, loss: 0.032261092215776443
step: 30, loss: 0.0032249900978058577
step: 40, loss: 0.011496719904243946
step: 50, loss: 0.06387151777744293
step: 60, loss: 0.005111296195536852
step: 70, loss: 0.0003505146596580744
step: 80, loss: 0.010044964030385017
step: 90, loss: 0.001207584049552679
step: 100, loss: 0.01822562888264656
step: 110, loss: 0.03889722749590874
step: 120, loss: 0.024097295477986336
step: 130, loss: 0.0007692290237173438
step: 140, loss: 0.0002689379034563899
step: 150, loss: 0.008628142066299915
step: 160, loss: 0.03310345485806465
step: 170, loss: 3.126905357930809e-05
step: 180, loss: 0.04902895912528038
step: 190, loss: 0.008641578257083893
step: 200, loss: 0.0208422914147377
step: 210, loss: 0.041547466069459915
step: 220, loss: 0.02443111315369606
step: 230, loss: 0.07452208548784256
step: 240, loss: 0.18653862178325653
step: 250, loss: 0.02357296086847782
step: 260, loss: 0.0016555878100916743
step: 270, loss: 0.004524169489741325
step: 280, loss: 0.0046600354835391045
step: 290, loss: 0.0031866130884736776
step: 300, loss: 0.02405780740082264
step: 310, loss: 0.11524864286184311
step: 320, loss: 0.011997580528259277
step: 330, loss: 0.0032949247397482395
step: 340, loss: 0.025465555489063263
step: 350, loss: 0.0458434522151947
step: 360, loss: 0.11431685090065002
epoch 15: dev_f1=0.7570332480818414, f1=0.7084468664850135, best_f1=0.7257617728531854
step: 0, loss: 0.0007561618695035577
step: 10, loss: 0.0008509117178618908
step: 20, loss: 0.025648901239037514
step: 30, loss: 0.04407961294054985
step: 40, loss: 0.06027622148394585
step: 50, loss: 0.0498177707195282
step: 60, loss: 0.01845582202076912
step: 70, loss: 0.05686097592115402
step: 80, loss: 0.002333079231902957
step: 90, loss: 0.011017361655831337
step: 100, loss: 0.03378045931458473
step: 110, loss: 0.015622871927917004
step: 120, loss: 0.031114939600229263
step: 130, loss: 0.005559092853218317
step: 140, loss: 0.0031439638696610928
step: 150, loss: 0.03391818329691887
step: 160, loss: 0.08515966683626175
step: 170, loss: 0.005736274179071188
step: 180, loss: 0.05184394121170044
step: 190, loss: 0.043175652623176575
step: 200, loss: 0.0023234051186591387
step: 210, loss: 3.13507262035273e-05
step: 220, loss: 0.07941920310258865
step: 230, loss: 0.037416473031044006
step: 240, loss: 0.00025819576694630086
step: 250, loss: 0.027440929785370827
step: 260, loss: 0.03354712575674057
step: 270, loss: 0.0863768458366394
step: 280, loss: 0.00013713788939639926
step: 290, loss: 0.0019288851181045175
step: 300, loss: 0.041104741394519806
step: 310, loss: 0.0644868016242981
step: 320, loss: 0.0022774082608520985
step: 330, loss: 0.018194856122136116
step: 340, loss: 0.11930575966835022
step: 350, loss: 0.012053484097123146
step: 360, loss: 0.004405597224831581
epoch 16: dev_f1=0.78125, f1=0.7380281690140845, best_f1=0.7257617728531854
step: 0, loss: 0.002375565469264984
step: 10, loss: 0.011483428999781609
step: 20, loss: 0.060576487332582474
step: 30, loss: 0.014712111093103886
step: 40, loss: 0.04778071865439415
step: 50, loss: 0.0775723084807396
step: 60, loss: 0.00524681992828846
step: 70, loss: 0.012182402424514294
step: 80, loss: 0.09192335605621338
step: 90, loss: 0.008484100922942162
step: 100, loss: 0.0008771372959017754
step: 110, loss: 0.02323264069855213
step: 120, loss: 0.10246994346380234
step: 130, loss: 0.0015166791854426265
step: 140, loss: 0.009901465848088264
step: 150, loss: 0.05936719849705696
step: 160, loss: 0.002731574233621359
step: 170, loss: 3.908539656549692e-05
step: 180, loss: 0.0033646428491920233
step: 190, loss: 6.668583955615759e-05
step: 200, loss: 0.027108341455459595
step: 210, loss: 0.011942065320909023
step: 220, loss: 0.001707766205072403
step: 230, loss: 0.09356269985437393
step: 240, loss: 0.0001966632844414562
step: 250, loss: 0.0009744652779772878
step: 260, loss: 0.028606750071048737
step: 270, loss: 0.003156450344249606
step: 280, loss: 0.05997307226061821
step: 290, loss: 0.00016470647824462503
step: 300, loss: 0.05029527470469475
step: 310, loss: 0.00026531759067438543
step: 320, loss: 0.0032612725626677275
step: 330, loss: 0.007605782710015774
step: 340, loss: 0.009725061245262623
step: 350, loss: 0.00026526162400841713
step: 360, loss: 3.6584478948498145e-05
epoch 17: dev_f1=0.75, f1=0.7034883720930233, best_f1=0.7257617728531854
step: 0, loss: 0.03690847009420395
step: 10, loss: 0.0246608704328537
step: 20, loss: 0.012799924239516258
step: 30, loss: 0.03966109827160835
step: 40, loss: 3.826428292086348e-05
step: 50, loss: 0.014994772151112556
step: 60, loss: 0.00012747822620440274
step: 70, loss: 0.00035011180443689227
step: 80, loss: 0.01023051980882883
step: 90, loss: 0.08485044538974762
step: 100, loss: 0.04848891869187355
step: 110, loss: 0.00045737982145510614
step: 120, loss: 0.004474987741559744
step: 130, loss: 0.046568140387535095
step: 140, loss: 0.010915206745266914
step: 150, loss: 0.015268913470208645
step: 160, loss: 0.004464888945221901
step: 170, loss: 0.02015087939798832
step: 180, loss: 0.00029201031429693103
step: 190, loss: 6.690529698971659e-05
step: 200, loss: 0.01887463964521885
step: 210, loss: 0.00035834338632412255
step: 220, loss: 0.028701776638627052
step: 230, loss: 0.0657668486237526
step: 240, loss: 0.010585520416498184
step: 250, loss: 0.030513189733028412
step: 260, loss: 0.02607826702296734
step: 270, loss: 0.04252565652132034
step: 280, loss: 3.1205992854665965e-05
step: 290, loss: 0.04587417468428612
step: 300, loss: 0.031349048018455505
step: 310, loss: 0.001552353729493916
step: 320, loss: 0.04389193654060364
step: 330, loss: 0.007750886492431164
step: 340, loss: 3.88464359275531e-05
step: 350, loss: 0.034277237951755524
step: 360, loss: 0.007360340096056461
epoch 18: dev_f1=0.7513812154696132, f1=0.7113702623906706, best_f1=0.7257617728531854
step: 0, loss: 0.05165297910571098
step: 10, loss: 0.000327626388752833
step: 20, loss: 0.0009664944373071194
step: 30, loss: 0.0011814413592219353
step: 40, loss: 0.060273122042417526
step: 50, loss: 0.0029973590280860662
step: 60, loss: 0.0007617226801812649
step: 70, loss: 0.074339359998703
step: 80, loss: 0.11834479868412018
step: 90, loss: 0.0005915376241318882
step: 100, loss: 0.0021702644880861044
step: 110, loss: 0.010815026238560677
step: 120, loss: 0.047463856637477875
step: 130, loss: 0.01530024316161871
step: 140, loss: 0.0014513290952891111
step: 150, loss: 0.12769800424575806
step: 160, loss: 0.026329001411795616
step: 170, loss: 4.586033901432529e-05
step: 180, loss: 0.03552882373332977
step: 190, loss: 0.0633116289973259
step: 200, loss: 0.00019455369329079986
step: 210, loss: 9.474774560658261e-05
step: 220, loss: 0.026444735005497932
step: 230, loss: 0.00040179688949137926
step: 240, loss: 0.02339886501431465
step: 250, loss: 0.014436166733503342
step: 260, loss: 0.003194846911355853
step: 270, loss: 0.001687851152382791
step: 280, loss: 0.00038122813566587865
step: 290, loss: 0.035753365606069565
step: 300, loss: 0.000821833498775959
step: 310, loss: 0.016255449503660202
step: 320, loss: 0.0053120930679142475
step: 330, loss: 0.010908931493759155
step: 340, loss: 0.012216847389936447
step: 350, loss: 0.00046933814883232117
step: 360, loss: 0.027667773887515068
epoch 19: dev_f1=0.7506849315068493, f1=0.7076023391812866, best_f1=0.7257617728531854
step: 0, loss: 0.054230812937021255
step: 10, loss: 0.0025378838181495667
step: 20, loss: 0.0025927084498107433
step: 30, loss: 0.021212439984083176
step: 40, loss: 0.00036983133759349585
step: 50, loss: 0.0005712027777917683
step: 60, loss: 0.02977781556546688
step: 70, loss: 4.3577114411164075e-05
step: 80, loss: 0.0002443541307002306
step: 90, loss: 0.02079928293824196
step: 100, loss: 0.00019860897737089545
step: 110, loss: 0.032807063311338425
step: 120, loss: 0.0032952313777059317
step: 130, loss: 0.00198023091070354
step: 140, loss: 0.05006011575460434
step: 150, loss: 0.03915146365761757
step: 160, loss: 0.0005428369040600955
step: 170, loss: 5.5942819017218426e-05
step: 180, loss: 0.009187678806483746
step: 190, loss: 8.755789167480543e-05
step: 200, loss: 4.59538096038159e-05
step: 210, loss: 0.07541946321725845
step: 220, loss: 0.02191605605185032
step: 230, loss: 0.029782265424728394
step: 240, loss: 0.0006269790465012193
step: 250, loss: 0.01611308567225933
step: 260, loss: 0.05664762482047081
step: 270, loss: 0.04124995321035385
step: 280, loss: 7.683226431254297e-05
step: 290, loss: 0.00037758349208161235
step: 300, loss: 0.0007574011106044054
step: 310, loss: 0.029342880472540855
step: 320, loss: 0.0007206349400803447
step: 330, loss: 0.0008262461051344872
step: 340, loss: 0.0022228925954550505
step: 350, loss: 0.03611358255147934
step: 360, loss: 0.004520690534263849
epoch 20: dev_f1=0.7526881720430108, f1=0.7262247838616714, best_f1=0.7257617728531854
