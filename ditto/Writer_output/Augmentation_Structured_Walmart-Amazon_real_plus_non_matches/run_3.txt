cuda
Device: cuda
step: 0, loss: 0.6493858098983765
step: 10, loss: 0.23879548907279968
step: 20, loss: 0.14936630427837372
step: 30, loss: 0.23831745982170105
step: 40, loss: 0.1384117305278778
step: 50, loss: 0.14515092968940735
step: 60, loss: 0.1539890170097351
step: 70, loss: 0.045496225357055664
step: 80, loss: 0.05087243765592575
step: 90, loss: 0.22835475206375122
step: 100, loss: 0.23013128340244293
step: 110, loss: 0.1407860517501831
step: 120, loss: 0.04922116920351982
step: 130, loss: 0.23265652358531952
step: 140, loss: 0.039662618190050125
step: 150, loss: 0.4848087430000305
step: 160, loss: 0.13926009833812714
step: 170, loss: 0.15379413962364197
step: 180, loss: 0.09625408798456192
step: 190, loss: 0.2630993127822876
step: 200, loss: 0.3760799169540405
step: 210, loss: 0.12094996869564056
step: 220, loss: 0.4358368217945099
step: 230, loss: 0.1511261910200119
step: 240, loss: 0.20701558887958527
step: 250, loss: 0.026299621909856796
step: 260, loss: 0.085708849132061
step: 270, loss: 0.3290925621986389
step: 280, loss: 0.009952515363693237
step: 290, loss: 0.20411692559719086
step: 300, loss: 0.18878719210624695
step: 310, loss: 0.18020737171173096
step: 320, loss: 0.12780751287937164
step: 330, loss: 0.13216470181941986
step: 340, loss: 0.31065598130226135
step: 350, loss: 0.15628837049007416
step: 360, loss: 0.12597014009952545
epoch 1: dev_f1=0.5641025641025641, f1=0.5812807881773399, best_f1=0.5812807881773399
step: 0, loss: 0.20518743991851807
step: 10, loss: 0.06608448922634125
step: 20, loss: 0.03638162091374397
step: 30, loss: 0.0648256465792656
step: 40, loss: 0.12641598284244537
step: 50, loss: 0.1350458413362503
step: 60, loss: 0.11640874296426773
step: 70, loss: 0.04729028791189194
step: 80, loss: 0.21001039445400238
step: 90, loss: 0.08912191540002823
step: 100, loss: 0.13371506333351135
step: 110, loss: 0.1740676760673523
step: 120, loss: 0.14815545082092285
step: 130, loss: 0.05448829010128975
step: 140, loss: 0.1045645922422409
step: 150, loss: 0.25740835070610046
step: 160, loss: 0.13007307052612305
step: 170, loss: 0.1585243046283722
step: 180, loss: 0.10180320590734482
step: 190, loss: 0.10810171812772751
step: 200, loss: 0.16432148218154907
step: 210, loss: 0.13633862137794495
step: 220, loss: 0.09228023886680603
step: 230, loss: 0.21711619198322296
step: 240, loss: 0.1117413118481636
step: 250, loss: 0.08910912275314331
step: 260, loss: 0.07642891258001328
step: 270, loss: 0.2010580450296402
step: 280, loss: 0.059545211493968964
step: 290, loss: 0.046141162514686584
step: 300, loss: 0.09649744629859924
step: 310, loss: 0.07157621532678604
step: 320, loss: 0.0371464304625988
step: 330, loss: 0.4331596791744232
step: 340, loss: 0.006114508491009474
step: 350, loss: 0.07562285661697388
step: 360, loss: 0.09902617335319519
epoch 2: dev_f1=0.6984126984126985, f1=0.6889460154241646, best_f1=0.6889460154241646
step: 0, loss: 0.04656359180808067
step: 10, loss: 0.030251460149884224
step: 20, loss: 0.0596625879406929
step: 30, loss: 0.024347610771656036
step: 40, loss: 0.11936414986848831
step: 50, loss: 0.21366921067237854
step: 60, loss: 0.0501260980963707
step: 70, loss: 0.06258097290992737
step: 80, loss: 0.07596937566995621
step: 90, loss: 0.04748516157269478
step: 100, loss: 0.1248892992734909
step: 110, loss: 0.07701098173856735
step: 120, loss: 0.13997702300548553
step: 130, loss: 0.0557648241519928
step: 140, loss: 0.20136620104312897
step: 150, loss: 0.08128751814365387
step: 160, loss: 0.021263135597109795
step: 170, loss: 0.31478649377822876
step: 180, loss: 0.1446361392736435
step: 190, loss: 0.033767685294151306
step: 200, loss: 0.2679239511489868
step: 210, loss: 0.03929606080055237
step: 220, loss: 0.04508237913250923
step: 230, loss: 0.10668689012527466
step: 240, loss: 0.03358268737792969
step: 250, loss: 0.041786231100559235
step: 260, loss: 0.15241144597530365
step: 270, loss: 0.2179410457611084
step: 280, loss: 0.11535102874040604
step: 290, loss: 0.11443990468978882
step: 300, loss: 0.04153212532401085
step: 310, loss: 0.11108716577291489
step: 320, loss: 0.09061963856220245
step: 330, loss: 0.029893577098846436
step: 340, loss: 0.044292908161878586
step: 350, loss: 0.35137319564819336
step: 360, loss: 0.1862611621618271
epoch 3: dev_f1=0.7322404371584699, f1=0.7445652173913043, best_f1=0.7445652173913043
step: 0, loss: 0.09554201364517212
step: 10, loss: 0.08956246823072433
step: 20, loss: 0.07684902101755142
step: 30, loss: 0.047970909625291824
step: 40, loss: 0.0965622290968895
step: 50, loss: 0.28793108463287354
step: 60, loss: 0.06804890930652618
step: 70, loss: 0.13173362612724304
step: 80, loss: 0.05042826756834984
step: 90, loss: 0.029980255290865898
step: 100, loss: 0.0931113213300705
step: 110, loss: 0.1702582985162735
step: 120, loss: 0.05464141070842743
step: 130, loss: 0.07558660209178925
step: 140, loss: 0.030424993485212326
step: 150, loss: 0.1845952868461609
step: 160, loss: 0.06353715062141418
step: 170, loss: 0.020557396113872528
step: 180, loss: 0.044980064034461975
step: 190, loss: 0.07685723900794983
step: 200, loss: 0.035831157118082047
step: 210, loss: 0.020841006189584732
step: 220, loss: 0.07752320915460587
step: 230, loss: 0.004392664879560471
step: 240, loss: 0.04406895861029625
step: 250, loss: 0.11533622443675995
step: 260, loss: 0.05945894122123718
step: 270, loss: 0.0942823514342308
step: 280, loss: 0.013012442737817764
step: 290, loss: 0.033025600016117096
step: 300, loss: 0.027054084464907646
step: 310, loss: 0.1353723257780075
step: 320, loss: 0.03830251842737198
step: 330, loss: 0.019622696563601494
step: 340, loss: 0.058739643543958664
step: 350, loss: 0.04533134773373604
step: 360, loss: 0.0882815346121788
epoch 4: dev_f1=0.7555555555555555, f1=0.7399999999999999, best_f1=0.7399999999999999
step: 0, loss: 0.06382494419813156
step: 10, loss: 0.00103371508885175
step: 20, loss: 0.003100173780694604
step: 30, loss: 0.0833805501461029
step: 40, loss: 0.004944432061165571
step: 50, loss: 0.02649281732738018
step: 60, loss: 0.018524309620261192
step: 70, loss: 0.07867749035358429
step: 80, loss: 0.11858658492565155
step: 90, loss: 0.012300949543714523
step: 100, loss: 0.046725984662771225
step: 110, loss: 0.026157191023230553
step: 120, loss: 0.006796616595238447
step: 130, loss: 0.03859073668718338
step: 140, loss: 0.04849893972277641
step: 150, loss: 0.08283773064613342
step: 160, loss: 0.1224990040063858
step: 170, loss: 0.08794229477643967
step: 180, loss: 0.12244397401809692
step: 190, loss: 0.013281580992043018
step: 200, loss: 0.017911134287714958
step: 210, loss: 0.07493199408054352
step: 220, loss: 0.05917016416788101
step: 230, loss: 0.10994293540716171
step: 240, loss: 0.11298827081918716
step: 250, loss: 0.14878472685813904
step: 260, loss: 0.10016274452209473
step: 270, loss: 0.07751917839050293
step: 280, loss: 0.05583368241786957
step: 290, loss: 0.044938988983631134
step: 300, loss: 0.008976360782980919
step: 310, loss: 0.08779444545507431
step: 320, loss: 0.034885428845882416
step: 330, loss: 0.10819781571626663
step: 340, loss: 0.10768632590770721
step: 350, loss: 0.10370778292417526
step: 360, loss: 0.04262807220220566
epoch 5: dev_f1=0.7455919395465995, f1=0.7098445595854923, best_f1=0.7399999999999999
step: 0, loss: 0.09639675170183182
step: 10, loss: 0.012933272868394852
step: 20, loss: 0.03656507283449173
step: 30, loss: 0.058468688279390335
step: 40, loss: 0.03293870761990547
step: 50, loss: 0.013141162693500519
step: 60, loss: 0.06645015627145767
step: 70, loss: 0.19606700539588928
step: 80, loss: 0.0466991625726223
step: 90, loss: 0.021575111895799637
step: 100, loss: 0.03553333505988121
step: 110, loss: 0.07217945903539658
step: 120, loss: 0.01397809199988842
step: 130, loss: 0.02364904060959816
step: 140, loss: 0.029220907017588615
step: 150, loss: 0.01851998083293438
step: 160, loss: 0.07634712010622025
step: 170, loss: 0.13779102265834808
step: 180, loss: 0.02326350100338459
step: 190, loss: 0.0473850816488266
step: 200, loss: 0.039323993027210236
step: 210, loss: 0.02887839451432228
step: 220, loss: 0.025919463485479355
step: 230, loss: 0.06965973973274231
step: 240, loss: 0.054163865745067596
step: 250, loss: 0.2158312350511551
step: 260, loss: 0.09852396696805954
step: 270, loss: 0.060454048216342926
step: 280, loss: 0.04495358094573021
step: 290, loss: 0.021427879109978676
step: 300, loss: 0.14879880845546722
step: 310, loss: 0.0341121107339859
step: 320, loss: 0.03572240099310875
step: 330, loss: 0.16187047958374023
step: 340, loss: 0.01712729036808014
step: 350, loss: 0.06264032423496246
step: 360, loss: 0.10043046623468399
epoch 6: dev_f1=0.744186046511628, f1=0.7651715039577835, best_f1=0.7399999999999999
step: 0, loss: 0.03000122681260109
step: 10, loss: 0.08114329725503922
step: 20, loss: 0.024540213868021965
step: 30, loss: 0.021296918392181396
step: 40, loss: 0.18054437637329102
step: 50, loss: 0.013554345816373825
step: 60, loss: 0.19714310765266418
step: 70, loss: 0.0017279103631153703
step: 80, loss: 0.037114217877388
step: 90, loss: 0.05069718509912491
step: 100, loss: 0.04897051304578781
step: 110, loss: 0.012107674032449722
step: 120, loss: 0.03328048437833786
step: 130, loss: 0.007099771406501532
step: 140, loss: 0.06951302289962769
step: 150, loss: 0.09506100416183472
step: 160, loss: 0.025878608226776123
step: 170, loss: 0.10886019468307495
step: 180, loss: 0.08659256249666214
step: 190, loss: 0.05952802672982216
step: 200, loss: 0.0822032019495964
step: 210, loss: 0.04125264659523964
step: 220, loss: 0.1321277767419815
step: 230, loss: 0.024743029847741127
step: 240, loss: 0.07042884081602097
step: 250, loss: 0.023284265771508217
step: 260, loss: 0.054886285215616226
step: 270, loss: 0.03305532783269882
step: 280, loss: 0.013720332644879818
step: 290, loss: 0.014564523473381996
step: 300, loss: 0.020228372886776924
step: 310, loss: 0.10329999774694443
step: 320, loss: 0.10667123645544052
step: 330, loss: 0.07290659099817276
step: 340, loss: 0.10441818088293076
step: 350, loss: 0.030942540615797043
step: 360, loss: 0.028660869225859642
epoch 7: dev_f1=0.7645429362880887, f1=0.7692307692307692, best_f1=0.7692307692307692
step: 0, loss: 0.024476611986756325
step: 10, loss: 0.05186185613274574
step: 20, loss: 0.057407818734645844
step: 30, loss: 0.01805100217461586
step: 40, loss: 0.036527760326862335
step: 50, loss: 0.08639102429151535
step: 60, loss: 0.06525296717882156
step: 70, loss: 0.09183803200721741
step: 80, loss: 0.07905212789773941
step: 90, loss: 0.02891627699136734
step: 100, loss: 0.09122036397457123
step: 110, loss: 0.11495059728622437
step: 120, loss: 0.0021739520598202944
step: 130, loss: 0.03488422557711601
step: 140, loss: 0.06283296644687653
step: 150, loss: 0.011837377212941647
step: 160, loss: 0.05099278315901756
step: 170, loss: 0.05631009116768837
step: 180, loss: 0.14878852665424347
step: 190, loss: 0.06622500717639923
step: 200, loss: 0.04882548004388809
step: 210, loss: 0.078370101749897
step: 220, loss: 0.045040059834718704
step: 230, loss: 0.018692364916205406
step: 240, loss: 0.009293382056057453
step: 250, loss: 0.009358595125377178
step: 260, loss: 0.004863050300627947
step: 270, loss: 0.01541927270591259
step: 280, loss: 0.000638139492366463
step: 290, loss: 0.13085824251174927
step: 300, loss: 0.01357207540422678
step: 310, loss: 0.03399739786982536
step: 320, loss: 0.07366422563791275
step: 330, loss: 0.07119424641132355
step: 340, loss: 0.038919463753700256
step: 350, loss: 0.0287445317953825
step: 360, loss: 0.0870019793510437
epoch 8: dev_f1=0.773841961852861, f1=0.7624309392265193, best_f1=0.7624309392265193
step: 0, loss: 0.05868779122829437
step: 10, loss: 0.06677568703889847
step: 20, loss: 0.02542802505195141
step: 30, loss: 0.09982731938362122
step: 40, loss: 0.05856215953826904
step: 50, loss: 0.05710342153906822
step: 60, loss: 9.999985923059285e-05
step: 70, loss: 0.03941180184483528
step: 80, loss: 0.03184088319540024
step: 90, loss: 0.07222387194633484
step: 100, loss: 0.0005105847958475351
step: 110, loss: 0.02360534481704235
step: 120, loss: 0.00021325264242477715
step: 130, loss: 0.014904997311532497
step: 140, loss: 0.02574997767806053
step: 150, loss: 0.15554353594779968
step: 160, loss: 0.24528314173221588
step: 170, loss: 0.0633978545665741
step: 180, loss: 0.02273775078356266
step: 190, loss: 0.00022504276421386749
step: 200, loss: 0.0759522020816803
step: 210, loss: 0.0055549126118421555
step: 220, loss: 0.07258666306734085
step: 230, loss: 0.0013542661909013987
step: 240, loss: 0.16191145777702332
step: 250, loss: 0.04512499272823334
step: 260, loss: 0.01028672605752945
step: 270, loss: 0.04787302762269974
step: 280, loss: 0.16708464920520782
step: 290, loss: 0.16980944573879242
step: 300, loss: 0.11165783554315567
step: 310, loss: 0.005378903821110725
step: 320, loss: 0.01975753717124462
step: 330, loss: 0.006416488904505968
step: 340, loss: 0.027310246601700783
step: 350, loss: 0.15295258164405823
step: 360, loss: 0.06305993348360062
epoch 9: dev_f1=0.735632183908046, f1=0.7083333333333334, best_f1=0.7624309392265193
step: 0, loss: 0.04944487288594246
step: 10, loss: 0.04070569947361946
step: 20, loss: 0.0563800074160099
step: 30, loss: 0.052932608872652054
step: 40, loss: 0.0439910888671875
step: 50, loss: 0.022798987105488777
step: 60, loss: 0.012665335088968277
step: 70, loss: 0.1498723030090332
step: 80, loss: 0.032727211713790894
step: 90, loss: 0.005910808686167002
step: 100, loss: 0.09220679104328156
step: 110, loss: 0.08700890839099884
step: 120, loss: 0.10437678545713425
step: 130, loss: 0.05824543908238411
step: 140, loss: 0.022205106914043427
step: 150, loss: 0.03055141493678093
step: 160, loss: 0.05394956097006798
step: 170, loss: 0.03566201403737068
step: 180, loss: 0.010579749010503292
step: 190, loss: 0.008416530676186085
step: 200, loss: 0.006342833861708641
step: 210, loss: 0.016192998737096786
step: 220, loss: 0.04597408324480057
step: 230, loss: 0.20381323993206024
step: 240, loss: 0.010113201104104519
step: 250, loss: 0.03287544101476669
step: 260, loss: 0.020939882844686508
step: 270, loss: 0.04656058922410011
step: 280, loss: 0.010348965413868427
step: 290, loss: 0.06975895911455154
step: 300, loss: 0.024117566645145416
step: 310, loss: 0.059674303978681564
step: 320, loss: 0.045971136540174484
step: 330, loss: 0.1488153040409088
step: 340, loss: 0.01004714798182249
step: 350, loss: 0.11737614870071411
step: 360, loss: 0.09427142143249512
epoch 10: dev_f1=0.7637362637362638, f1=0.7584269662921349, best_f1=0.7624309392265193
step: 0, loss: 0.015204784460365772
step: 10, loss: 0.04791463166475296
step: 20, loss: 0.00036429351894184947
step: 30, loss: 0.03997647017240524
step: 40, loss: 0.04955156892538071
step: 50, loss: 4.40981202700641e-05
step: 60, loss: 0.03193939849734306
step: 70, loss: 0.012347262352705002
step: 80, loss: 0.016304191201925278
step: 90, loss: 0.0936574712395668
step: 100, loss: 0.016035448759794235
step: 110, loss: 0.04236042872071266
step: 120, loss: 0.013208340853452682
step: 130, loss: 0.00026325887301936746
step: 140, loss: 0.01279300544410944
step: 150, loss: 0.03130873665213585
step: 160, loss: 0.024073990061879158
step: 170, loss: 0.020025912672281265
step: 180, loss: 0.011621073819696903
step: 190, loss: 0.010165019892156124
step: 200, loss: 0.01614776998758316
step: 210, loss: 0.06085769087076187
step: 220, loss: 0.0023693437688052654
step: 230, loss: 0.02617512457072735
step: 240, loss: 0.005846603773534298
step: 250, loss: 0.04786069691181183
step: 260, loss: 0.11695605516433716
step: 270, loss: 0.012140569277107716
step: 280, loss: 0.031403809785842896
step: 290, loss: 0.10431522876024246
step: 300, loss: 0.07683142274618149
step: 310, loss: 0.0075235068798065186
step: 320, loss: 0.0014760593185201287
step: 330, loss: 0.009359795600175858
step: 340, loss: 0.024009980261325836
step: 350, loss: 0.0242207869887352
step: 360, loss: 0.029945502057671547
epoch 11: dev_f1=0.7696202531645571, f1=0.7566137566137565, best_f1=0.7624309392265193
step: 0, loss: 0.02649678848683834
step: 10, loss: 0.028920892626047134
step: 20, loss: 0.034674737602472305
step: 30, loss: 0.017364880070090294
step: 40, loss: 0.006087221205234528
step: 50, loss: 0.03343178331851959
step: 60, loss: 0.0319419763982296
step: 70, loss: 0.060807473957538605
step: 80, loss: 0.06472115963697433
step: 90, loss: 0.010345296934247017
step: 100, loss: 0.0025138382334262133
step: 110, loss: 0.11015623062849045
step: 120, loss: 0.09004480391740799
step: 130, loss: 0.028413165360689163
step: 140, loss: 0.008596661500632763
step: 150, loss: 0.038301076740026474
step: 160, loss: 0.01423998549580574
step: 170, loss: 0.007708634715527296
step: 180, loss: 0.024185746908187866
step: 190, loss: 0.16983626782894135
step: 200, loss: 0.15151217579841614
step: 210, loss: 0.048211753368377686
step: 220, loss: 0.039862554520368576
step: 230, loss: 0.011180493049323559
step: 240, loss: 0.09973283112049103
step: 250, loss: 0.021722571924328804
step: 260, loss: 0.016186552122235298
step: 270, loss: 0.005026310216635466
step: 280, loss: 0.00629966426640749
step: 290, loss: 0.030091920867562294
step: 300, loss: 0.033793676644563675
step: 310, loss: 0.02107623964548111
step: 320, loss: 0.07216350734233856
step: 330, loss: 0.060075100511312485
step: 340, loss: 0.09063439816236496
step: 350, loss: 0.02372528240084648
step: 360, loss: 0.01275215670466423
epoch 12: dev_f1=0.7575757575757577, f1=0.7532467532467532, best_f1=0.7624309392265193
step: 0, loss: 0.04012371972203255
step: 10, loss: 9.896655683405697e-05
step: 20, loss: 0.06993463635444641
step: 30, loss: 0.02253396436572075
step: 40, loss: 0.0064492784440517426
step: 50, loss: 0.014346135780215263
step: 60, loss: 0.04032235965132713
step: 70, loss: 0.019719943404197693
step: 80, loss: 0.06247219070792198
step: 90, loss: 0.008367513306438923
step: 100, loss: 0.003446166403591633
step: 110, loss: 0.02536751888692379
step: 120, loss: 0.02920682169497013
step: 130, loss: 0.04991888254880905
step: 140, loss: 0.05849326029419899
step: 150, loss: 0.027060765773057938
step: 160, loss: 0.007841257378458977
step: 170, loss: 0.06195712089538574
step: 180, loss: 0.013946106657385826
step: 190, loss: 0.004773684777319431
step: 200, loss: 0.014473468996584415
step: 210, loss: 0.000519227352924645
step: 220, loss: 6.382871652022004e-05
step: 230, loss: 0.039171002805233
step: 240, loss: 0.0001326865458395332
step: 250, loss: 0.0051675415597856045
step: 260, loss: 0.0012738460209220648
step: 270, loss: 0.005466503091156483
step: 280, loss: 0.12597748637199402
step: 290, loss: 0.17591102421283722
step: 300, loss: 0.0018888304475694895
step: 310, loss: 0.0004451656714081764
step: 320, loss: 0.05728156119585037
step: 330, loss: 0.029499266296625137
step: 340, loss: 0.00024600402684882283
step: 350, loss: 0.06895076483488083
step: 360, loss: 0.014441614039242268
epoch 13: dev_f1=0.7593052109181142, f1=0.739795918367347, best_f1=0.7624309392265193
step: 0, loss: 0.016466308385133743
step: 10, loss: 0.01833743415772915
step: 20, loss: 0.01688184030354023
step: 30, loss: 0.012365102767944336
step: 40, loss: 0.021423734724521637
step: 50, loss: 0.010162333957850933
step: 60, loss: 0.06365038454532623
step: 70, loss: 0.027943504974246025
step: 80, loss: 0.0026106610894203186
step: 90, loss: 0.04213627055287361
step: 100, loss: 0.04331694543361664
step: 110, loss: 0.007571573834866285
step: 120, loss: 0.015403356403112411
step: 130, loss: 0.09437938034534454
step: 140, loss: 0.0682133361697197
step: 150, loss: 0.052413079887628555
step: 160, loss: 0.028646402060985565
step: 170, loss: 0.0560106597840786
step: 180, loss: 0.029966896399855614
step: 190, loss: 0.016265375539660454
step: 200, loss: 0.10698714107275009
step: 210, loss: 0.09367974102497101
step: 220, loss: 0.0036396654322743416
step: 230, loss: 0.010682904161512852
step: 240, loss: 0.021623145788908005
step: 250, loss: 0.054955366998910904
step: 260, loss: 0.023829929530620575
step: 270, loss: 0.029079493135213852
step: 280, loss: 0.06715715676546097
step: 290, loss: 0.002950847614556551
step: 300, loss: 0.012881672009825706
step: 310, loss: 0.019624724984169006
step: 320, loss: 0.01977602206170559
step: 330, loss: 0.024744194000959396
step: 340, loss: 0.012408586218953133
step: 350, loss: 0.057519905269145966
step: 360, loss: 0.08214469254016876
epoch 14: dev_f1=0.7235023041474654, f1=0.7416267942583731, best_f1=0.7624309392265193
step: 0, loss: 0.039175406098365784
step: 10, loss: 0.00540117546916008
step: 20, loss: 0.026241686195135117
step: 30, loss: 0.0017599908169358969
step: 40, loss: 0.015825778245925903
step: 50, loss: 0.07313434034585953
step: 60, loss: 0.016587603837251663
step: 70, loss: 3.331401967443526e-05
step: 80, loss: 0.005519204773008823
step: 90, loss: 0.003514179028570652
step: 100, loss: 0.06676604598760605
step: 110, loss: 0.004564631264656782
step: 120, loss: 0.021542992442846298
step: 130, loss: 2.7875590603798628e-05
step: 140, loss: 0.0021119771990925074
step: 150, loss: 0.003755661193281412
step: 160, loss: 0.056260477751493454
step: 170, loss: 4.394428469822742e-05
step: 180, loss: 0.10026491433382034
step: 190, loss: 0.01019868440926075
step: 200, loss: 0.03398328274488449
step: 210, loss: 0.09108513593673706
step: 220, loss: 0.08789224922657013
step: 230, loss: 0.07827067375183105
step: 240, loss: 0.0457100048661232
step: 250, loss: 0.003069344675168395
step: 260, loss: 0.002750931540504098
step: 270, loss: 0.07871092110872269
step: 280, loss: 0.0358060821890831
step: 290, loss: 0.00658717704936862
step: 300, loss: 0.15166525542736053
step: 310, loss: 0.11818541586399078
step: 320, loss: 0.01986592821776867
step: 330, loss: 0.005509017501026392
step: 340, loss: 0.039345283061265945
step: 350, loss: 0.08792329579591751
step: 360, loss: 0.18149659037590027
epoch 15: dev_f1=0.751842751842752, f1=0.7468030690537084, best_f1=0.7624309392265193
step: 0, loss: 0.0031149571295827627
step: 10, loss: 0.003745205467566848
step: 20, loss: 0.026955757290124893
step: 30, loss: 0.02243415266275406
step: 40, loss: 0.022748712450265884
step: 50, loss: 0.05358406528830528
step: 60, loss: 0.02626766823232174
step: 70, loss: 0.03116345778107643
step: 80, loss: 0.0036188485100865364
step: 90, loss: 0.0016043345676735044
step: 100, loss: 0.010700293816626072
step: 110, loss: 0.010177357122302055
step: 120, loss: 0.023767787963151932
step: 130, loss: 0.030653078109025955
step: 140, loss: 0.002102697268128395
step: 150, loss: 0.04111495241522789
step: 160, loss: 0.134613037109375
step: 170, loss: 0.005408154800534248
step: 180, loss: 0.08089248090982437
step: 190, loss: 0.04551495239138603
step: 200, loss: 0.03734832629561424
step: 210, loss: 0.0001372202386846766
step: 220, loss: 0.004672178067266941
step: 230, loss: 0.006354901473969221
step: 240, loss: 0.0581950843334198
step: 250, loss: 0.05986486002802849
step: 260, loss: 0.04268335551023483
step: 270, loss: 0.09913008660078049
step: 280, loss: 0.010082420893013477
step: 290, loss: 0.0017837602645158768
step: 300, loss: 0.06984061002731323
step: 310, loss: 0.06290815770626068
step: 320, loss: 0.004601132124662399
step: 330, loss: 0.014945423230528831
step: 340, loss: 0.09159228950738907
step: 350, loss: 0.009325209073722363
step: 360, loss: 0.013742360286414623
epoch 16: dev_f1=0.7616580310880829, f1=0.7433155080213903, best_f1=0.7624309392265193
step: 0, loss: 0.007908075116574764
step: 10, loss: 0.012604276649653912
step: 20, loss: 0.03356399014592171
step: 30, loss: 0.038512203842401505
step: 40, loss: 0.055633850395679474
step: 50, loss: 0.05676570162177086
step: 60, loss: 0.0030191191472113132
step: 70, loss: 0.044515352696180344
step: 80, loss: 0.034794989973306656
step: 90, loss: 0.008763683959841728
step: 100, loss: 0.0052459049038589
step: 110, loss: 0.03241709619760513
step: 120, loss: 0.09903561323881149
step: 130, loss: 0.002152123488485813
step: 140, loss: 0.041328638792037964
step: 150, loss: 0.05507209524512291
step: 160, loss: 0.007913350127637386
step: 170, loss: 2.9234995963633992e-05
step: 180, loss: 0.004396736156195402
step: 190, loss: 5.307667379383929e-05
step: 200, loss: 0.07337481528520584
step: 210, loss: 0.012676367536187172
step: 220, loss: 0.027000315487384796
step: 230, loss: 0.05639512836933136
step: 240, loss: 0.005599514115601778
step: 250, loss: 0.0008588723721913993
step: 260, loss: 0.008745968341827393
step: 270, loss: 0.002685330808162689
step: 280, loss: 0.0832219049334526
step: 290, loss: 0.0014925618888810277
step: 300, loss: 0.03690331429243088
step: 310, loss: 0.002940349280834198
step: 320, loss: 0.0024120393209159374
step: 330, loss: 0.005369072314351797
step: 340, loss: 0.014814574271440506
step: 350, loss: 0.0010662692366167903
step: 360, loss: 4.4108335714554414e-05
epoch 17: dev_f1=0.7524752475247525, f1=0.7333333333333334, best_f1=0.7624309392265193
step: 0, loss: 0.05058877170085907
step: 10, loss: 0.03419959172606468
step: 20, loss: 0.00986303761601448
step: 30, loss: 0.04365186020731926
step: 40, loss: 0.003460467327386141
step: 50, loss: 0.009738466702401638
step: 60, loss: 0.0009870058856904507
step: 70, loss: 0.005731186829507351
step: 80, loss: 0.008455568924546242
step: 90, loss: 0.10380210727453232
step: 100, loss: 0.057372841984033585
step: 110, loss: 0.0005470674950629473
step: 120, loss: 0.015812302008271217
step: 130, loss: 0.052534811198711395
step: 140, loss: 0.010421480052173138
step: 150, loss: 0.006519068032503128
step: 160, loss: 0.010368870571255684
step: 170, loss: 0.005636382382363081
step: 180, loss: 0.002236573025584221
step: 190, loss: 0.0008803183445706964
step: 200, loss: 0.029574789106845856
step: 210, loss: 0.0012951333774253726
step: 220, loss: 0.005807064473628998
step: 230, loss: 0.08130620419979095
step: 240, loss: 0.012170016765594482
step: 250, loss: 0.02552642859518528
step: 260, loss: 0.03297097608447075
step: 270, loss: 0.03026772104203701
step: 280, loss: 2.4690731152077205e-05
step: 290, loss: 0.08784211426973343
step: 300, loss: 0.08135849237442017
step: 310, loss: 0.0053466311655938625
step: 320, loss: 0.05176490172743797
step: 330, loss: 0.03856835141777992
step: 340, loss: 2.019456042035017e-05
step: 350, loss: 0.043149784207344055
step: 360, loss: 0.008608599193394184
epoch 18: dev_f1=0.7445255474452556, f1=0.739795918367347, best_f1=0.7624309392265193
step: 0, loss: 0.006752703804522753
step: 10, loss: 0.0025915359146893024
step: 20, loss: 0.039419256150722504
step: 30, loss: 0.00818135030567646
step: 40, loss: 0.03551075607538223
step: 50, loss: 0.00047064709360711277
step: 60, loss: 0.0007324705948121846
step: 70, loss: 0.0463130921125412
step: 80, loss: 0.034360162913799286
step: 90, loss: 0.00095840246649459
step: 100, loss: 0.002931681927293539
step: 110, loss: 0.008873355574905872
step: 120, loss: 0.006006371695548296
step: 130, loss: 0.039591994136571884
step: 140, loss: 0.003903241828083992
step: 150, loss: 0.021414564922451973
step: 160, loss: 0.04810883849859238
step: 170, loss: 0.00051697320304811
step: 180, loss: 0.033357713371515274
step: 190, loss: 0.05927303433418274
step: 200, loss: 0.0011880045058205724
step: 210, loss: 0.0028733930084854364
step: 220, loss: 0.014296365901827812
step: 230, loss: 0.004448572639375925
step: 240, loss: 0.04502150043845177
step: 250, loss: 0.044566649943590164
step: 260, loss: 0.005915043409913778
step: 270, loss: 0.003374233841896057
step: 280, loss: 0.011496649123728275
step: 290, loss: 0.03407688066363335
step: 300, loss: 0.008076357655227184
step: 310, loss: 0.021573524922132492
step: 320, loss: 0.0035897057969123125
step: 330, loss: 0.01068856567144394
step: 340, loss: 0.01175696775317192
step: 350, loss: 0.006096099503338337
step: 360, loss: 0.0237008985131979
epoch 19: dev_f1=0.745679012345679, f1=0.7409326424870466, best_f1=0.7624309392265193
step: 0, loss: 0.037348389625549316
step: 10, loss: 0.012488951906561852
step: 20, loss: 0.023388702422380447
step: 30, loss: 0.04614971950650215
step: 40, loss: 4.045761306770146e-05
step: 50, loss: 0.003878073301166296
step: 60, loss: 0.03577825054526329
step: 70, loss: 2.4154343918780796e-05
step: 80, loss: 0.0007555504562333226
step: 90, loss: 0.08532547950744629
step: 100, loss: 0.0017677900614216924
step: 110, loss: 0.029150985181331635
step: 120, loss: 0.0027533182874321938
step: 130, loss: 0.018344257026910782
step: 140, loss: 0.02140570990741253
step: 150, loss: 0.027621066197752953
step: 160, loss: 0.000696210830938071
step: 170, loss: 2.3673783289268613e-05
step: 180, loss: 0.00032380421180278063
step: 190, loss: 0.023485740646719933
step: 200, loss: 0.000456586159998551
step: 210, loss: 0.04015769809484482
step: 220, loss: 0.0265920739620924
step: 230, loss: 0.0016078769695013762
step: 240, loss: 0.04379856213927269
step: 250, loss: 0.05130640044808388
step: 260, loss: 0.07112254947423935
step: 270, loss: 0.07402536273002625
step: 280, loss: 2.5178800569847226e-05
step: 290, loss: 0.00018573548004496843
step: 300, loss: 0.00737634114921093
step: 310, loss: 0.012417618185281754
step: 320, loss: 0.022210972383618355
step: 330, loss: 0.0022421868052333593
step: 340, loss: 0.0023079344537109137
step: 350, loss: 0.06144430488348007
step: 360, loss: 0.003791606519371271
epoch 20: dev_f1=0.7481296758104737, f1=0.7415143603133159, best_f1=0.7624309392265193
