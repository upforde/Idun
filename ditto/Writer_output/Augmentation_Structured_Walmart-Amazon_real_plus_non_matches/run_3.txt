cuda
Device: cuda
step: 0, loss: 1.0986924171447754
step: 10, loss: 0.13994264602661133
step: 20, loss: 0.02818663977086544
step: 30, loss: 0.08456950634717941
step: 40, loss: 0.14032651484012604
step: 50, loss: 0.3166273534297943
step: 60, loss: 0.232399582862854
step: 70, loss: 0.04828967526555061
step: 80, loss: 0.055456001311540604
step: 90, loss: 0.150187686085701
step: 100, loss: 0.13840103149414062
step: 110, loss: 0.13721776008605957
step: 120, loss: 0.13409090042114258
step: 130, loss: 0.23212769627571106
step: 140, loss: 0.13529306650161743
step: 150, loss: 0.03641727939248085
step: 160, loss: 0.2243930846452713
step: 170, loss: 0.1292157918214798
step: 180, loss: 0.1550789177417755
step: 190, loss: 0.12904499471187592
step: 200, loss: 0.11903370171785355
step: 210, loss: 0.25314298272132874
step: 220, loss: 0.09473652392625809
step: 230, loss: 0.1917610764503479
step: 240, loss: 0.17733575403690338
step: 250, loss: 0.1227424144744873
step: 260, loss: 0.14744071662425995
step: 270, loss: 0.10155898332595825
step: 280, loss: 0.12565307319164276
step: 290, loss: 0.11014077067375183
step: 300, loss: 0.08423905074596405
step: 310, loss: 0.22946931421756744
step: 320, loss: 0.209156796336174
step: 330, loss: 0.21985414624214172
step: 340, loss: 0.1890878975391388
step: 350, loss: 0.07514915615320206
step: 360, loss: 0.08487530797719955
epoch 1: dev_f1=0.555858310626703, f1=0.5418994413407822, best_f1=0.5418994413407822
step: 0, loss: 0.13681289553642273
step: 10, loss: 0.33244553208351135
step: 20, loss: 0.11730286478996277
step: 30, loss: 0.11640729010105133
step: 40, loss: 0.34088370203971863
step: 50, loss: 0.29347148537635803
step: 60, loss: 0.13476191461086273
step: 70, loss: 0.12018832564353943
step: 80, loss: 0.006404737010598183
step: 90, loss: 0.08759812265634537
step: 100, loss: 0.20939059555530548
step: 110, loss: 0.037978462874889374
step: 120, loss: 0.10451143234968185
step: 130, loss: 0.03436809405684471
step: 140, loss: 0.25127309560775757
step: 150, loss: 0.1508670151233673
step: 160, loss: 0.2282123863697052
step: 170, loss: 0.11201012134552002
step: 180, loss: 0.03397404029965401
step: 190, loss: 0.16878841817378998
step: 200, loss: 0.08848972618579865
step: 210, loss: 0.26896294951438904
step: 220, loss: 0.1789005547761917
step: 230, loss: 0.038248926401138306
step: 240, loss: 0.2132354974746704
step: 250, loss: 0.029286211356520653
step: 260, loss: 0.26036763191223145
step: 270, loss: 0.012876294553279877
step: 280, loss: 0.1215246170759201
step: 290, loss: 0.1634482890367508
step: 300, loss: 0.04561491683125496
step: 310, loss: 0.04510117694735527
step: 320, loss: 0.08352688699960709
step: 330, loss: 0.054367970675230026
step: 340, loss: 0.04250217601656914
step: 350, loss: 0.054445765912532806
step: 360, loss: 0.11965841799974442
epoch 2: dev_f1=0.7130919220055711, f1=0.7344632768361581, best_f1=0.7344632768361581
step: 0, loss: 0.009523149579763412
step: 10, loss: 0.0841507539153099
step: 20, loss: 0.028753606602549553
step: 30, loss: 0.049546897411346436
step: 40, loss: 0.051993053406476974
step: 50, loss: 0.08008433133363724
step: 60, loss: 0.03424905240535736
step: 70, loss: 0.0731426402926445
step: 80, loss: 0.022416479885578156
step: 90, loss: 0.04848552495241165
step: 100, loss: 0.06269393116235733
step: 110, loss: 0.06581896543502808
step: 120, loss: 0.0597042590379715
step: 130, loss: 0.01924987882375717
step: 140, loss: 0.1553766280412674
step: 150, loss: 0.09925520420074463
step: 160, loss: 0.06929248571395874
step: 170, loss: 0.017113888636231422
step: 180, loss: 0.08494284003973007
step: 190, loss: 0.10059291869401932
step: 200, loss: 0.08943300694227219
step: 210, loss: 0.2074446678161621
step: 220, loss: 0.18012239038944244
step: 230, loss: 0.14964506030082703
step: 240, loss: 0.04052706062793732
step: 250, loss: 0.19827409088611603
step: 260, loss: 0.09245377033948898
step: 270, loss: 0.04856117069721222
step: 280, loss: 0.08234428614377975
step: 290, loss: 0.047953393310308456
step: 300, loss: 0.08864734321832657
step: 310, loss: 0.018986087292432785
step: 320, loss: 0.23511959612369537
step: 330, loss: 0.056994762271642685
step: 340, loss: 0.2057419866323471
step: 350, loss: 0.08834201842546463
step: 360, loss: 0.05298174172639847
epoch 3: dev_f1=0.7191011235955057, f1=0.7107438016528925, best_f1=0.7107438016528925
step: 0, loss: 0.08793799579143524
step: 10, loss: 0.12890338897705078
step: 20, loss: 0.0403335765004158
step: 30, loss: 0.08979509770870209
step: 40, loss: 0.26232367753982544
step: 50, loss: 0.06358682364225388
step: 60, loss: 0.09186393022537231
step: 70, loss: 0.08328935503959656
step: 80, loss: 0.052671678364276886
step: 90, loss: 0.030297474935650826
step: 100, loss: 0.0850776731967926
step: 110, loss: 0.008846187964081764
step: 120, loss: 0.15539276599884033
step: 130, loss: 0.019524602219462395
step: 140, loss: 0.0064294529147446156
step: 150, loss: 0.07726313173770905
step: 160, loss: 0.09819775819778442
step: 170, loss: 0.08682762831449509
step: 180, loss: 0.07483712583780289
step: 190, loss: 0.10701059550046921
step: 200, loss: 0.0791063979268074
step: 210, loss: 0.050494369119405746
step: 220, loss: 0.08938299119472504
step: 230, loss: 0.15402427315711975
step: 240, loss: 0.14177978038787842
step: 250, loss: 0.061170756816864014
step: 260, loss: 0.06871646642684937
step: 270, loss: 0.12371989339590073
step: 280, loss: 0.1340501457452774
step: 290, loss: 0.044918786734342575
step: 300, loss: 0.010487077757716179
step: 310, loss: 0.057965222746133804
step: 320, loss: 0.017388995736837387
step: 330, loss: 0.13499197363853455
step: 340, loss: 0.016704048961400986
step: 350, loss: 0.16524948179721832
step: 360, loss: 0.0571216382086277
epoch 4: dev_f1=0.7012987012987013, f1=0.7258485639686684, best_f1=0.7107438016528925
step: 0, loss: 0.1929854303598404
step: 10, loss: 0.015059671364724636
step: 20, loss: 0.04960819333791733
step: 30, loss: 0.15161770582199097
step: 40, loss: 0.1047213152050972
step: 50, loss: 0.09781789034605026
step: 60, loss: 0.14461372792720795
step: 70, loss: 0.015062960796058178
step: 80, loss: 0.11068037152290344
step: 90, loss: 0.03599490225315094
step: 100, loss: 0.053988952189683914
step: 110, loss: 0.004299820400774479
step: 120, loss: 0.00964718870818615
step: 130, loss: 0.046512801200151443
step: 140, loss: 0.04160593822598457
step: 150, loss: 0.20071269571781158
step: 160, loss: 0.0752914696931839
step: 170, loss: 0.07567150145769119
step: 180, loss: 0.03491145372390747
step: 190, loss: 0.05895470827817917
step: 200, loss: 0.11339887231588364
step: 210, loss: 0.016911502927541733
step: 220, loss: 0.20157207548618317
step: 230, loss: 0.06051483377814293
step: 240, loss: 0.03321380913257599
step: 250, loss: 0.04985262453556061
step: 260, loss: 0.10993840545415878
step: 270, loss: 0.062069278210401535
step: 280, loss: 0.03664896637201309
step: 290, loss: 0.008445589803159237
step: 300, loss: 0.04592984542250633
step: 310, loss: 0.14237026870250702
step: 320, loss: 0.06583492457866669
step: 330, loss: 0.024427250027656555
step: 340, loss: 0.06490572541952133
step: 350, loss: 0.11626993119716644
step: 360, loss: 0.07418914884328842
epoch 5: dev_f1=0.7315789473684211, f1=0.7166666666666668, best_f1=0.7166666666666668
step: 0, loss: 0.04548927769064903
step: 10, loss: 0.16008269786834717
step: 20, loss: 0.13259533047676086
step: 30, loss: 0.08021646738052368
step: 40, loss: 0.0230919998139143
step: 50, loss: 0.05439633131027222
step: 60, loss: 0.04045944660902023
step: 70, loss: 0.023014450445771217
step: 80, loss: 0.15628771483898163
step: 90, loss: 0.025815071538090706
step: 100, loss: 0.23215509951114655
step: 110, loss: 0.08213844150304794
step: 120, loss: 0.06765195727348328
step: 130, loss: 0.0709272027015686
step: 140, loss: 0.02094200812280178
step: 150, loss: 0.12923724949359894
step: 160, loss: 0.07625925540924072
step: 170, loss: 0.024287307634949684
step: 180, loss: 0.03084990754723549
step: 190, loss: 0.09467703849077225
step: 200, loss: 0.133106529712677
step: 210, loss: 0.014467132277786732
step: 220, loss: 0.06100885197520256
step: 230, loss: 0.03322560340166092
step: 240, loss: 0.14467644691467285
step: 250, loss: 0.0016314401291310787
step: 260, loss: 0.05443233251571655
step: 270, loss: 0.09057120978832245
step: 280, loss: 0.07685357332229614
step: 290, loss: 0.0378841795027256
step: 300, loss: 0.03462647646665573
step: 310, loss: 0.03426332771778107
step: 320, loss: 0.05094840005040169
step: 330, loss: 0.052205972373485565
step: 340, loss: 0.006277222651988268
step: 350, loss: 0.19271843135356903
step: 360, loss: 0.06324341893196106
epoch 6: dev_f1=0.7131782945736433, f1=0.7345844504021448, best_f1=0.7166666666666668
step: 0, loss: 0.04597117751836777
step: 10, loss: 0.019427848979830742
step: 20, loss: 0.09500038623809814
step: 30, loss: 0.07973027229309082
step: 40, loss: 0.04688473418354988
step: 50, loss: 0.04263719916343689
step: 60, loss: 0.064793162047863
step: 70, loss: 0.018953602761030197
step: 80, loss: 0.015510160475969315
step: 90, loss: 0.06281784176826477
step: 100, loss: 0.05030376836657524
step: 110, loss: 0.04773060977458954
step: 120, loss: 0.08022119104862213
step: 130, loss: 0.045459359884262085
step: 140, loss: 0.0527338944375515
step: 150, loss: 0.047573477029800415
step: 160, loss: 0.02602866291999817
step: 170, loss: 0.03735508397221565
step: 180, loss: 0.025646016001701355
step: 190, loss: 0.04930763319134712
step: 200, loss: 0.03232990577816963
step: 210, loss: 0.018172290176153183
step: 220, loss: 0.07581067830324173
step: 230, loss: 0.0004264080780558288
step: 240, loss: 0.07704532146453857
step: 250, loss: 0.006533819250762463
step: 260, loss: 0.027227548882365227
step: 270, loss: 0.00948943942785263
step: 280, loss: 0.07370366156101227
step: 290, loss: 0.0013321604346856475
step: 300, loss: 0.15688784420490265
step: 310, loss: 0.09071490168571472
step: 320, loss: 0.08279852569103241
step: 330, loss: 0.1198347806930542
step: 340, loss: 0.01785440556704998
step: 350, loss: 0.07967102527618408
step: 360, loss: 0.014104703441262245
epoch 7: dev_f1=0.7310704960835509, f1=0.7313019390581716, best_f1=0.7166666666666668
step: 0, loss: 0.0665925145149231
step: 10, loss: 0.07976632565259933
step: 20, loss: 0.020520634949207306
step: 30, loss: 0.05032289773225784
step: 40, loss: 0.018542909994721413
step: 50, loss: 0.04699309170246124
step: 60, loss: 0.03631388396024704
step: 70, loss: 0.05595974624156952
step: 80, loss: 0.03192185238003731
step: 90, loss: 0.015421014279127121
step: 100, loss: 0.037374671548604965
step: 110, loss: 0.027506045997142792
step: 120, loss: 0.003230937523767352
step: 130, loss: 0.01476315874606371
step: 140, loss: 0.0495074987411499
step: 150, loss: 0.0839349552989006
step: 160, loss: 0.0009628368425182998
step: 170, loss: 0.01675235480070114
step: 180, loss: 0.03697748854756355
step: 190, loss: 0.03987496346235275
step: 200, loss: 0.019833827391266823
step: 210, loss: 0.07526922971010208
step: 220, loss: 0.058027151972055435
step: 230, loss: 0.03748909756541252
step: 240, loss: 0.08585608005523682
step: 250, loss: 0.07782285660505295
step: 260, loss: 0.009521820582449436
step: 270, loss: 0.0037809237837791443
step: 280, loss: 0.026173507794737816
step: 290, loss: 0.08002589643001556
step: 300, loss: 0.02262044884264469
step: 310, loss: 0.003307140665128827
step: 320, loss: 0.034480948001146317
step: 330, loss: 0.00035484705585986376
step: 340, loss: 0.042127080261707306
step: 350, loss: 0.028442678973078728
step: 360, loss: 0.01684596762061119
epoch 8: dev_f1=0.7126436781609194, f1=0.7254901960784313, best_f1=0.7166666666666668
step: 0, loss: 0.0345170758664608
step: 10, loss: 0.0429893396794796
step: 20, loss: 0.07206155359745026
step: 30, loss: 0.010673115961253643
step: 40, loss: 0.00997698400169611
step: 50, loss: 0.04383738711476326
step: 60, loss: 0.13538530468940735
step: 70, loss: 0.00868452899158001
step: 80, loss: 0.012601079419255257
step: 90, loss: 0.03131662681698799
step: 100, loss: 0.0075212037190794945
step: 110, loss: 0.04063761979341507
step: 120, loss: 0.010775954462587833
step: 130, loss: 0.011910302564501762
step: 140, loss: 0.010114663280546665
step: 150, loss: 0.16875527799129486
step: 160, loss: 0.029152968898415565
step: 170, loss: 0.05817732587456703
step: 180, loss: 0.019123157486319542
step: 190, loss: 0.05662163347005844
step: 200, loss: 0.000664945924654603
step: 210, loss: 0.04380812123417854
step: 220, loss: 0.13946154713630676
step: 230, loss: 0.06786651909351349
step: 240, loss: 0.19442220032215118
step: 250, loss: 0.012302658520638943
step: 260, loss: 0.06350862234830856
step: 270, loss: 0.02033357322216034
step: 280, loss: 0.05514243617653847
step: 290, loss: 0.02520066499710083
step: 300, loss: 0.0441727414727211
step: 310, loss: 0.0277940072119236
step: 320, loss: 0.08193007856607437
step: 330, loss: 0.05777185410261154
step: 340, loss: 0.16569384932518005
step: 350, loss: 0.14536534249782562
step: 360, loss: 0.06819376349449158
epoch 9: dev_f1=0.7169811320754718, f1=0.7333333333333333, best_f1=0.7166666666666668
step: 0, loss: 0.06821052730083466
step: 10, loss: 0.017879147082567215
step: 20, loss: 0.07926762104034424
step: 30, loss: 0.004864508286118507
step: 40, loss: 0.008306507021188736
step: 50, loss: 0.014301644638180733
step: 60, loss: 0.024156253784894943
step: 70, loss: 0.04323012754321098
step: 80, loss: 0.01749584637582302
step: 90, loss: 0.06169518828392029
step: 100, loss: 0.11901290714740753
step: 110, loss: 0.02855442836880684
step: 120, loss: 0.056002747267484665
step: 130, loss: 0.014596035704016685
step: 140, loss: 0.04313875362277031
step: 150, loss: 0.013322529383003712
step: 160, loss: 0.035757049918174744
step: 170, loss: 0.06425635516643524
step: 180, loss: 0.060889530926942825
step: 190, loss: 0.018701819702982903
step: 200, loss: 0.0537228025496006
step: 210, loss: 0.03711940720677376
step: 220, loss: 0.07690878212451935
step: 230, loss: 0.047644857317209244
step: 240, loss: 0.018505103886127472
step: 250, loss: 0.10223281383514404
step: 260, loss: 0.07772725820541382
step: 270, loss: 0.003050625789910555
step: 280, loss: 0.13241589069366455
step: 290, loss: 0.030474623665213585
step: 300, loss: 0.027437590062618256
step: 310, loss: 0.05521741136908531
step: 320, loss: 0.012715201824903488
step: 330, loss: 0.020395366474986076
step: 340, loss: 0.09207379072904587
step: 350, loss: 0.05171540379524231
step: 360, loss: 0.0521552599966526
epoch 10: dev_f1=0.7379134860050889, f1=0.7440633245382585, best_f1=0.7440633245382585
step: 0, loss: 0.0010472979629412293
step: 10, loss: 0.0017734355060383677
step: 20, loss: 0.032172586768865585
step: 30, loss: 0.042198341339826584
step: 40, loss: 0.047458868473768234
step: 50, loss: 0.034149300307035446
step: 60, loss: 0.023802200332283974
step: 70, loss: 0.03610420972108841
step: 80, loss: 0.011495658196508884
step: 90, loss: 0.000177613808773458
step: 100, loss: 0.012883437797427177
step: 110, loss: 0.001060454873368144
step: 120, loss: 0.003791092662140727
step: 130, loss: 0.027241520583629608
step: 140, loss: 0.05408583581447601
step: 150, loss: 0.07978575676679611
step: 160, loss: 0.0016249374020844698
step: 170, loss: 0.004421981982886791
step: 180, loss: 0.00039447250310331583
step: 190, loss: 0.008565349504351616
step: 200, loss: 0.016402168199419975
step: 210, loss: 0.005513041280210018
step: 220, loss: 0.21562601625919342
step: 230, loss: 0.005875966511666775
step: 240, loss: 0.0011359783820807934
step: 250, loss: 0.013606380671262741
step: 260, loss: 0.0076473169028759
step: 270, loss: 0.013137705624103546
step: 280, loss: 0.06669854372739792
step: 290, loss: 0.008097902871668339
step: 300, loss: 0.1515084058046341
step: 310, loss: 0.12289978563785553
step: 320, loss: 0.09702087938785553
step: 330, loss: 0.008359632454812527
step: 340, loss: 0.04120646417140961
step: 350, loss: 0.027611956000328064
step: 360, loss: 0.019979827105998993
epoch 11: dev_f1=0.7407407407407407, f1=0.7235142118863048, best_f1=0.7235142118863048
step: 0, loss: 0.012985145673155785
step: 10, loss: 0.030063798651099205
step: 20, loss: 0.020359573885798454
step: 30, loss: 0.0307285375893116
step: 40, loss: 0.10558012872934341
step: 50, loss: 0.010245630517601967
step: 60, loss: 0.04123110696673393
step: 70, loss: 0.10677962005138397
step: 80, loss: 0.11273559182882309
step: 90, loss: 0.034498393535614014
step: 100, loss: 0.04368312284350395
step: 110, loss: 0.0061840396374464035
step: 120, loss: 0.0016164949629455805
step: 130, loss: 0.01743430085480213
step: 140, loss: 0.0077460999600589275
step: 150, loss: 0.0068049356341362
step: 160, loss: 0.0007990016601979733
step: 170, loss: 0.02858736738562584
step: 180, loss: 0.09542141109704971
step: 190, loss: 7.354702393058687e-05
step: 200, loss: 0.07094310224056244
step: 210, loss: 5.8469115174375474e-05
step: 220, loss: 0.016279440373182297
step: 230, loss: 0.004141433630138636
step: 240, loss: 0.01729702763259411
step: 250, loss: 0.019442161545157433
step: 260, loss: 0.08267135173082352
step: 270, loss: 0.007562911603599787
step: 280, loss: 0.016146086156368256
step: 290, loss: 0.010261183604598045
step: 300, loss: 0.12619063258171082
step: 310, loss: 0.049715686589479446
step: 320, loss: 0.031683795154094696
step: 330, loss: 0.01811404898762703
step: 340, loss: 0.016614926978945732
step: 350, loss: 0.037858039140701294
step: 360, loss: 0.056033067405223846
epoch 12: dev_f1=0.7239583333333334, f1=0.7326203208556149, best_f1=0.7235142118863048
step: 0, loss: 0.07184862345457077
step: 10, loss: 0.0023070238530635834
step: 20, loss: 0.0010205996222794056
step: 30, loss: 0.031367428600788116
step: 40, loss: 0.16338089108467102
step: 50, loss: 0.0062448373064398766
step: 60, loss: 0.020352285355329514
step: 70, loss: 0.00032384131918661296
step: 80, loss: 0.00023328974202740937
step: 90, loss: 0.18068018555641174
step: 100, loss: 0.041405316442251205
step: 110, loss: 0.014640887267887592
step: 120, loss: 0.028839606791734695
step: 130, loss: 0.005146882962435484
step: 140, loss: 0.06391824781894684
step: 150, loss: 0.001997584942728281
step: 160, loss: 0.0006829666090197861
step: 170, loss: 0.011694376356899738
step: 180, loss: 0.18513157963752747
step: 190, loss: 0.001011585001833737
step: 200, loss: 0.12633664906024933
step: 210, loss: 0.00852214265614748
step: 220, loss: 0.013730323873460293
step: 230, loss: 0.037874553352594376
step: 240, loss: 0.06521973758935928
step: 250, loss: 0.10615797340869904
step: 260, loss: 0.008960263803601265
step: 270, loss: 0.08545593172311783
step: 280, loss: 0.06132075563073158
step: 290, loss: 0.010978897102177143
step: 300, loss: 0.0016726619796827435
step: 310, loss: 0.006432877853512764
step: 320, loss: 0.10672048479318619
step: 330, loss: 0.002978244097903371
step: 340, loss: 0.004156417213380337
step: 350, loss: 6.966249929973856e-05
step: 360, loss: 0.06466715037822723
epoch 13: dev_f1=0.7329842931937172, f1=0.733509234828496, best_f1=0.7235142118863048
step: 0, loss: 0.000989048508927226
step: 10, loss: 0.001134916441515088
step: 20, loss: 0.0023415207397192717
step: 30, loss: 0.05220554769039154
step: 40, loss: 4.638338214135729e-05
step: 50, loss: 0.01206807978451252
step: 60, loss: 0.042768560349941254
step: 70, loss: 0.0403948612511158
step: 80, loss: 0.03684750199317932
step: 90, loss: 0.00199706107378006
step: 100, loss: 0.019875159487128258
step: 110, loss: 0.03373698517680168
step: 120, loss: 0.00920872949063778
step: 130, loss: 0.011374491266906261
step: 140, loss: 0.06997540593147278
step: 150, loss: 0.08724398910999298
step: 160, loss: 0.0029531701002269983
step: 170, loss: 0.013494567014276981
step: 180, loss: 0.05517321825027466
step: 190, loss: 0.06778591871261597
step: 200, loss: 0.0031779585406184196
step: 210, loss: 0.003489437513053417
step: 220, loss: 0.04235817864537239
step: 230, loss: 0.07663212716579437
step: 240, loss: 0.03082694113254547
step: 250, loss: 0.0032937463838607073
step: 260, loss: 0.05076616257429123
step: 270, loss: 0.049773044884204865
step: 280, loss: 0.0003538622986525297
step: 290, loss: 0.03749852627515793
step: 300, loss: 0.021974436938762665
step: 310, loss: 0.018939800560474396
step: 320, loss: 0.008393369615077972
step: 330, loss: 0.014609177596867085
step: 340, loss: 0.055049870163202286
step: 350, loss: 0.00035975160426460207
step: 360, loss: 0.022118832916021347
epoch 14: dev_f1=0.7351351351351353, f1=0.7287671232876712, best_f1=0.7235142118863048
step: 0, loss: 0.04672567546367645
step: 10, loss: 0.04720838740468025
step: 20, loss: 0.01528722234070301
step: 30, loss: 0.016095658764243126
step: 40, loss: 0.0005015154602006078
step: 50, loss: 0.00021954573458060622
step: 60, loss: 0.02392115630209446
step: 70, loss: 0.0012192043941468
step: 80, loss: 0.03740531951189041
step: 90, loss: 0.008025061339139938
step: 100, loss: 0.0008046093862503767
step: 110, loss: 0.00016631701146252453
step: 120, loss: 0.0003957787121180445
step: 130, loss: 0.010256761685013771
step: 140, loss: 0.009900666773319244
step: 150, loss: 0.0595388300716877
step: 160, loss: 0.0009659318602643907
step: 170, loss: 0.032645877450704575
step: 180, loss: 0.00013254980149213225
step: 190, loss: 0.006478166673332453
step: 200, loss: 0.004673977382481098
step: 210, loss: 0.0006351271294988692
step: 220, loss: 0.015149775892496109
step: 230, loss: 0.014291482977569103
step: 240, loss: 4.684151281253435e-05
step: 250, loss: 0.01952367275953293
step: 260, loss: 0.0025720081757754087
step: 270, loss: 0.004564446397125721
step: 280, loss: 0.0017835909966379404
step: 290, loss: 0.013140251860022545
step: 300, loss: 0.07314113527536392
step: 310, loss: 0.01537507213652134
step: 320, loss: 0.002533541526645422
step: 330, loss: 0.04111623018980026
step: 340, loss: 0.01843208260834217
step: 350, loss: 0.020793002098798752
step: 360, loss: 0.0381435789167881
epoch 15: dev_f1=0.7192118226600984, f1=0.7225130890052356, best_f1=0.7235142118863048
step: 0, loss: 0.032301925122737885
step: 10, loss: 0.07995911687612534
step: 20, loss: 0.0006861594156362116
step: 30, loss: 0.007753410842269659
step: 40, loss: 0.019791746512055397
step: 50, loss: 0.02238006703555584
step: 60, loss: 0.051903095096349716
step: 70, loss: 0.0015700453659519553
step: 80, loss: 0.0012796034570783377
step: 90, loss: 0.0017402108060196042
step: 100, loss: 0.01965259574353695
step: 110, loss: 0.0029421739745885134
step: 120, loss: 0.07083380967378616
step: 130, loss: 3.0203445930965245e-05
step: 140, loss: 0.01343492977321148
step: 150, loss: 0.006168633233755827
step: 160, loss: 0.061997223645448685
step: 170, loss: 0.00039660901529714465
step: 180, loss: 0.00014684705820400268
step: 190, loss: 0.06452682614326477
step: 200, loss: 0.10027167201042175
step: 210, loss: 0.024982454255223274
step: 220, loss: 2.4925529942265712e-05
step: 230, loss: 0.0006677503697574139
step: 240, loss: 0.040616896003484726
step: 250, loss: 0.025024475529789925
step: 260, loss: 0.12705005705356598
step: 270, loss: 5.362497904570773e-05
step: 280, loss: 0.007363385520875454
step: 290, loss: 0.016864873468875885
step: 300, loss: 0.002682366641238332
step: 310, loss: 0.012086312286555767
step: 320, loss: 0.09640970081090927
step: 330, loss: 0.0005330420099198818
step: 340, loss: 0.0003485853667370975
step: 350, loss: 2.286923881911207e-05
step: 360, loss: 0.09463513642549515
epoch 16: dev_f1=0.7373737373737375, f1=0.7239583333333334, best_f1=0.7235142118863048
step: 0, loss: 0.0003018253482878208
step: 10, loss: 0.02077476494014263
step: 20, loss: 0.009515214711427689
step: 30, loss: 0.0022723600268363953
step: 40, loss: 0.006778600625693798
step: 50, loss: 0.0766829252243042
step: 60, loss: 0.0014531617052853107
step: 70, loss: 3.0196606530807912e-05
step: 80, loss: 4.148989683017135e-05
step: 90, loss: 4.1571031033527106e-05
step: 100, loss: 0.030603274703025818
step: 110, loss: 0.02028743550181389
step: 120, loss: 0.022088700905442238
step: 130, loss: 0.02689312770962715
step: 140, loss: 0.00010775600094348192
step: 150, loss: 0.08460699021816254
step: 160, loss: 0.003374266205355525
step: 170, loss: 0.02439740113914013
step: 180, loss: 9.087325452128425e-05
step: 190, loss: 0.02341841161251068
step: 200, loss: 0.03113781102001667
step: 210, loss: 0.01216061133891344
step: 220, loss: 0.1258712261915207
step: 230, loss: 0.027634430676698685
step: 240, loss: 0.045163191854953766
step: 250, loss: 7.319515134440735e-05
step: 260, loss: 0.02203710377216339
step: 270, loss: 0.008125104941427708
step: 280, loss: 0.0002639015729073435
step: 290, loss: 0.012445700354874134
step: 300, loss: 0.017971204593777657
step: 310, loss: 0.002036028541624546
step: 320, loss: 0.01812945492565632
step: 330, loss: 0.003569571999832988
step: 340, loss: 0.00010349159128963947
step: 350, loss: 0.007657352369278669
step: 360, loss: 0.05412406846880913
epoch 17: dev_f1=0.7272727272727273, f1=0.7178082191780822, best_f1=0.7235142118863048
step: 0, loss: 0.00028473950806073844
step: 10, loss: 0.00233105244114995
step: 20, loss: 0.013457213528454304
step: 30, loss: 0.005119475070387125
step: 40, loss: 0.016355520114302635
step: 50, loss: 2.9551067200372927e-05
step: 60, loss: 0.00035479426151141524
step: 70, loss: 0.03283987566828728
step: 80, loss: 0.0023516807705163956
step: 90, loss: 2.8989357815589756e-05
step: 100, loss: 0.01702614314854145
step: 110, loss: 0.00030756983323954046
step: 120, loss: 0.0001101884845411405
step: 130, loss: 0.028136026114225388
step: 140, loss: 0.0007258825353346765
step: 150, loss: 2.3927192160044797e-05
step: 160, loss: 0.0016592745669186115
step: 170, loss: 0.04104338958859444
step: 180, loss: 0.025295939296483994
step: 190, loss: 0.021459249779582024
step: 200, loss: 0.027195340022444725
step: 210, loss: 0.0002632555551826954
step: 220, loss: 0.023826798424124718
step: 230, loss: 0.017635134980082512
step: 240, loss: 0.0030747498385608196
step: 250, loss: 0.07354813814163208
step: 260, loss: 7.372763502644375e-05
step: 270, loss: 0.00019559463544283062
step: 280, loss: 0.00029400509083643556
step: 290, loss: 0.0195913128554821
step: 300, loss: 0.043886493891477585
step: 310, loss: 0.0019180674571543932
step: 320, loss: 0.029672948643565178
step: 330, loss: 0.005191431380808353
step: 340, loss: 0.0022225098218768835
step: 350, loss: 0.0008026008144952357
step: 360, loss: 0.0006577617605216801
epoch 18: dev_f1=0.7187499999999999, f1=0.7219251336898397, best_f1=0.7235142118863048
step: 0, loss: 0.0024655836168676615
step: 10, loss: 0.002214596839621663
step: 20, loss: 0.007823796942830086
step: 30, loss: 0.00034103222424164414
step: 40, loss: 0.015283884480595589
step: 50, loss: 0.00021733778703492135
step: 60, loss: 0.053314078599214554
step: 70, loss: 0.0009596073650754988
step: 80, loss: 0.03394709900021553
step: 90, loss: 0.013434702530503273
step: 100, loss: 0.018102189525961876
step: 110, loss: 0.003404570510610938
step: 120, loss: 0.0003653477178886533
step: 130, loss: 0.05060567334294319
step: 140, loss: 0.030704684555530548
step: 150, loss: 0.11137869209051132
step: 160, loss: 0.00048659712774679065
step: 170, loss: 0.06985552608966827
step: 180, loss: 0.00010652639321051538
step: 190, loss: 0.008448404259979725
step: 200, loss: 2.622539977892302e-05
step: 210, loss: 0.02495020627975464
step: 220, loss: 0.00024291874433401972
step: 230, loss: 0.00036555863334797323
step: 240, loss: 0.0006204990786500275
step: 250, loss: 0.009127654135227203
step: 260, loss: 0.011460061185061932
step: 270, loss: 0.0012273399624973536
step: 280, loss: 0.025501636788249016
step: 290, loss: 3.884901889250614e-05
step: 300, loss: 0.025716157630085945
step: 310, loss: 0.014686552807688713
step: 320, loss: 0.0007872937130741775
step: 330, loss: 0.04994971677660942
step: 340, loss: 0.016217239201068878
step: 350, loss: 0.04021527245640755
step: 360, loss: 0.10311265289783478
epoch 19: dev_f1=0.7238605898123326, f1=0.7202216066481995, best_f1=0.7235142118863048
step: 0, loss: 0.006519846152514219
step: 10, loss: 0.009827046655118465
step: 20, loss: 0.018030036240816116
step: 30, loss: 8.560195419704542e-05
step: 40, loss: 0.06988658010959625
step: 50, loss: 0.015231181867420673
step: 60, loss: 0.0020641011651605368
step: 70, loss: 0.0244899969547987
step: 80, loss: 0.01370949111878872
step: 90, loss: 0.013062291778624058
step: 100, loss: 0.00011612071830313653
step: 110, loss: 3.2356398151023313e-05
step: 120, loss: 0.029581710696220398
step: 130, loss: 0.031687378883361816
step: 140, loss: 0.05933826044201851
step: 150, loss: 0.04128076136112213
step: 160, loss: 0.042742423713207245
step: 170, loss: 0.00852995365858078
step: 180, loss: 9.352427878184244e-05
step: 190, loss: 0.01835334114730358
step: 200, loss: 2.8274342184886336e-05
step: 210, loss: 0.03365696594119072
step: 220, loss: 0.0004717702104244381
step: 230, loss: 0.027797747403383255
step: 240, loss: 0.029262028634548187
step: 250, loss: 0.01830383576452732
step: 260, loss: 0.00010968872084049508
step: 270, loss: 0.0004495092434808612
step: 280, loss: 7.311951776500791e-05
step: 290, loss: 0.030537208542227745
step: 300, loss: 0.01662861742079258
step: 310, loss: 0.008370981551706791
step: 320, loss: 0.017998309805989265
step: 330, loss: 0.0001842776546254754
step: 340, loss: 0.006105371285229921
step: 350, loss: 0.029874511063098907
step: 360, loss: 0.00031812561792321503
epoch 20: dev_f1=0.7272727272727272, f1=0.7319587628865978, best_f1=0.7235142118863048
