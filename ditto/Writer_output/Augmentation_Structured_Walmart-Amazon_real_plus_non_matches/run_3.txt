cuda
Device: cuda
step: 0, loss: 0.6527023911476135
step: 10, loss: 0.32917550206184387
step: 20, loss: 0.07158832252025604
step: 30, loss: 0.36105480790138245
step: 40, loss: 0.08554080128669739
step: 50, loss: 0.23251041769981384
step: 60, loss: 0.3863360285758972
step: 70, loss: 0.2097657471895218
step: 80, loss: 0.13400298357009888
step: 90, loss: 0.04330061003565788
step: 100, loss: 0.2087128460407257
step: 110, loss: 0.20646870136260986
step: 120, loss: 0.25780802965164185
step: 130, loss: 0.22195415198802948
step: 140, loss: 0.22789108753204346
step: 150, loss: 0.08071058243513107
step: 160, loss: 0.13427433371543884
step: 170, loss: 0.280773788690567
step: 180, loss: 0.1060071587562561
step: 190, loss: 0.011350950226187706
step: 200, loss: 0.18505975604057312
step: 210, loss: 0.1899726688861847
step: 220, loss: 0.13028347492218018
step: 230, loss: 0.2908758521080017
step: 240, loss: 0.03658919408917427
step: 250, loss: 0.2616751194000244
step: 260, loss: 0.1258922517299652
step: 270, loss: 0.17051135003566742
step: 280, loss: 0.13656079769134521
step: 290, loss: 0.12850937247276306
step: 300, loss: 0.034119173884391785
step: 310, loss: 0.2776471972465515
step: 320, loss: 0.04028637707233429
step: 330, loss: 0.1072985902428627
step: 340, loss: 0.21227233111858368
step: 350, loss: 0.0040004318580031395
step: 360, loss: 0.08745608478784561
epoch 1: dev_f1=0.6379746835443039, f1=0.639386189258312, best_f1=0.639386189258312
step: 0, loss: 0.2203158438205719
step: 10, loss: 0.08743493258953094
step: 20, loss: 0.23884795606136322
step: 30, loss: 0.376863956451416
step: 40, loss: 0.1171322613954544
step: 50, loss: 0.09145139902830124
step: 60, loss: 0.08021318912506104
step: 70, loss: 0.01661459170281887
step: 80, loss: 0.1027408018708229
step: 90, loss: 0.2726459205150604
step: 100, loss: 0.0833936408162117
step: 110, loss: 0.013581154868006706
step: 120, loss: 0.16256597638130188
step: 130, loss: 0.17240945994853973
step: 140, loss: 0.09582724422216415
step: 150, loss: 0.320622980594635
step: 160, loss: 0.07982958108186722
step: 170, loss: 0.052872221916913986
step: 180, loss: 0.20575517416000366
step: 190, loss: 0.1307198852300644
step: 200, loss: 0.20696358382701874
step: 210, loss: 0.08140382170677185
step: 220, loss: 0.20220091938972473
step: 230, loss: 0.17168475687503815
step: 240, loss: 0.031029392033815384
step: 250, loss: 0.07207316905260086
step: 260, loss: 0.15904660522937775
step: 270, loss: 0.07801767438650131
step: 280, loss: 0.11733216792345047
step: 290, loss: 0.08224958926439285
step: 300, loss: 0.052025776356458664
step: 310, loss: 0.1376192718744278
step: 320, loss: 0.27274447679519653
step: 330, loss: 0.166741281747818
step: 340, loss: 0.03806932270526886
step: 350, loss: 0.4700952470302582
step: 360, loss: 0.10662683099508286
epoch 2: dev_f1=0.7015706806282722, f1=0.6811989100817438, best_f1=0.6811989100817438
step: 0, loss: 0.0370032861828804
step: 10, loss: 0.00469698291271925
step: 20, loss: 0.17021724581718445
step: 30, loss: 0.1014886125922203
step: 40, loss: 0.059974346309900284
step: 50, loss: 0.030590981245040894
step: 60, loss: 0.043581318110227585
step: 70, loss: 0.13249114155769348
step: 80, loss: 0.00629167165607214
step: 90, loss: 0.07304468005895615
step: 100, loss: 0.18531660735607147
step: 110, loss: 0.07032747566699982
step: 120, loss: 0.08160358667373657
step: 130, loss: 0.032827507704496384
step: 140, loss: 0.16986924409866333
step: 150, loss: 0.04680194333195686
step: 160, loss: 0.10905592143535614
step: 170, loss: 0.09882772713899612
step: 180, loss: 0.08702395856380463
step: 190, loss: 0.04009801894426346
step: 200, loss: 0.04854865372180939
step: 210, loss: 0.24086743593215942
step: 220, loss: 0.010052871890366077
step: 230, loss: 0.3792421817779541
step: 240, loss: 0.1290183961391449
step: 250, loss: 0.044940486550331116
step: 260, loss: 0.047734156250953674
step: 270, loss: 0.12511226534843445
step: 280, loss: 0.09272582828998566
step: 290, loss: 0.017727863043546677
step: 300, loss: 0.00476818298920989
step: 310, loss: 0.08769452571868896
step: 320, loss: 0.10646942257881165
step: 330, loss: 0.040599383413791656
step: 340, loss: 0.008400891907513142
step: 350, loss: 0.13827675580978394
step: 360, loss: 0.08346500992774963
epoch 3: dev_f1=0.7466666666666666, f1=0.7433155080213903, best_f1=0.7433155080213903
step: 0, loss: 0.07996418327093124
step: 10, loss: 0.14151206612586975
step: 20, loss: 0.09360698610544205
step: 30, loss: 0.06286139786243439
step: 40, loss: 0.15825150907039642
step: 50, loss: 0.07010767608880997
step: 60, loss: 0.08665931224822998
step: 70, loss: 0.025872744619846344
step: 80, loss: 0.104004867374897
step: 90, loss: 0.06071264669299126
step: 100, loss: 0.08135969191789627
step: 110, loss: 0.08378518372774124
step: 120, loss: 0.08652523905038834
step: 130, loss: 0.07395056635141373
step: 140, loss: 0.059224825352430344
step: 150, loss: 0.11392464488744736
step: 160, loss: 0.07494591921567917
step: 170, loss: 0.038147151470184326
step: 180, loss: 0.2631206810474396
step: 190, loss: 0.04298604279756546
step: 200, loss: 0.03149231895804405
step: 210, loss: 0.025061331689357758
step: 220, loss: 0.03339841589331627
step: 230, loss: 0.07822459936141968
step: 240, loss: 0.06203845515847206
step: 250, loss: 0.010875668376684189
step: 260, loss: 0.09986840933561325
step: 270, loss: 0.09403272718191147
step: 280, loss: 0.1611335277557373
step: 290, loss: 0.1739790290594101
step: 300, loss: 0.17136913537979126
step: 310, loss: 0.03316536918282509
step: 320, loss: 0.039758313447237015
step: 330, loss: 0.014824960380792618
step: 340, loss: 0.06226665526628494
step: 350, loss: 0.03770356625318527
step: 360, loss: 0.17980775237083435
epoch 4: dev_f1=0.739946380697051, f1=0.7377049180327869, best_f1=0.7433155080213903
step: 0, loss: 0.24533824622631073
step: 10, loss: 0.10779862105846405
step: 20, loss: 0.03663778677582741
step: 30, loss: 0.06806313991546631
step: 40, loss: 0.09746963530778885
step: 50, loss: 0.08783167600631714
step: 60, loss: 0.024413498118519783
step: 70, loss: 0.20837624371051788
step: 80, loss: 0.030381452292203903
step: 90, loss: 0.1256789118051529
step: 100, loss: 0.035529471933841705
step: 110, loss: 0.1074008122086525
step: 120, loss: 0.09959927201271057
step: 130, loss: 0.18618719279766083
step: 140, loss: 0.10420215129852295
step: 150, loss: 0.15194109082221985
step: 160, loss: 0.04802349954843521
step: 170, loss: 0.13213194906711578
step: 180, loss: 0.10748782753944397
step: 190, loss: 0.03373468294739723
step: 200, loss: 0.03939168527722359
step: 210, loss: 0.007716483436524868
step: 220, loss: 0.03656133636832237
step: 230, loss: 0.01911882311105728
step: 240, loss: 0.06566186249256134
step: 250, loss: 0.018872661516070366
step: 260, loss: 0.03364584594964981
step: 270, loss: 0.029960457235574722
step: 280, loss: 0.03128768876194954
step: 290, loss: 0.0509321354329586
step: 300, loss: 0.08882277458906174
step: 310, loss: 0.009230095893144608
step: 320, loss: 0.1717098355293274
step: 330, loss: 0.0640152245759964
step: 340, loss: 0.24876749515533447
step: 350, loss: 0.004245334770530462
step: 360, loss: 0.1413128823041916
epoch 5: dev_f1=0.7135678391959798, f1=0.7091836734693878, best_f1=0.7433155080213903
step: 0, loss: 0.046028170734643936
step: 10, loss: 0.04520361125469208
step: 20, loss: 0.003810308640822768
step: 30, loss: 0.06654378771781921
step: 40, loss: 0.004848090466111898
step: 50, loss: 0.09206004440784454
step: 60, loss: 0.09848524630069733
step: 70, loss: 0.019728919491171837
step: 80, loss: 0.041545476764440536
step: 90, loss: 0.02279394492506981
step: 100, loss: 0.1108229011297226
step: 110, loss: 0.10336359590291977
step: 120, loss: 0.06390856951475143
step: 130, loss: 0.0441967211663723
step: 140, loss: 0.04769595339894295
step: 150, loss: 0.03489936888217926
step: 160, loss: 0.0417507030069828
step: 170, loss: 0.06734815239906311
step: 180, loss: 0.020487332716584206
step: 190, loss: 0.02097812294960022
step: 200, loss: 0.046905938535928726
step: 210, loss: 0.06690436601638794
step: 220, loss: 0.007966605946421623
step: 230, loss: 0.005977425258606672
step: 240, loss: 0.028190305456519127
step: 250, loss: 0.02999107725918293
step: 260, loss: 0.07038214057683945
step: 270, loss: 0.04297735542058945
step: 280, loss: 0.15186133980751038
step: 290, loss: 0.026645667850971222
step: 300, loss: 0.13181769847869873
step: 310, loss: 0.0390465147793293
step: 320, loss: 0.06389280408620834
step: 330, loss: 0.04846346750855446
step: 340, loss: 0.00044349065865390003
step: 350, loss: 0.07220441848039627
step: 360, loss: 0.07162004709243774
epoch 6: dev_f1=0.6945169712793733, f1=0.6929133858267716, best_f1=0.7433155080213903
step: 0, loss: 0.15138691663742065
step: 10, loss: 0.0012879350688308477
step: 20, loss: 0.08577659726142883
step: 30, loss: 0.06305105239152908
step: 40, loss: 0.09316442161798477
step: 50, loss: 0.1019618883728981
step: 60, loss: 0.0011113827349618077
step: 70, loss: 0.06328687816858292
step: 80, loss: 0.02350524440407753
step: 90, loss: 0.012872248888015747
step: 100, loss: 0.012577904388308525
step: 110, loss: 0.058066681027412415
step: 120, loss: 0.032760921865701675
step: 130, loss: 0.03147829696536064
step: 140, loss: 0.028471410274505615
step: 150, loss: 0.03588155284523964
step: 160, loss: 0.07532180100679398
step: 170, loss: 0.1170773059129715
step: 180, loss: 0.01226565521210432
step: 190, loss: 0.05855121463537216
step: 200, loss: 0.04837583377957344
step: 210, loss: 0.10638395696878433
step: 220, loss: 0.1778351366519928
step: 230, loss: 0.04714150354266167
step: 240, loss: 0.05266870558261871
step: 250, loss: 0.10140559077262878
step: 260, loss: 0.03994954377412796
step: 270, loss: 0.05723636597394943
step: 280, loss: 0.026841677725315094
step: 290, loss: 0.11093547940254211
step: 300, loss: 0.06605859845876694
step: 310, loss: 0.035762786865234375
step: 320, loss: 0.16989760100841522
step: 330, loss: 0.08151264488697052
step: 340, loss: 0.05214749276638031
step: 350, loss: 0.049401331692934036
step: 360, loss: 0.10189694911241531
epoch 7: dev_f1=0.7191601049868767, f1=0.7228260869565217, best_f1=0.7433155080213903
step: 0, loss: 0.02834293618798256
step: 10, loss: 0.07974717020988464
step: 20, loss: 0.01074216142296791
step: 30, loss: 0.07627221196889877
step: 40, loss: 0.009355378337204456
step: 50, loss: 0.1390754133462906
step: 60, loss: 0.0004704725288320333
step: 70, loss: 0.01936805620789528
step: 80, loss: 0.0011003768304362893
step: 90, loss: 0.02870071493089199
step: 100, loss: 0.007283355109393597
step: 110, loss: 0.03286087140440941
step: 120, loss: 0.016534997150301933
step: 130, loss: 0.09904645383358002
step: 140, loss: 0.010516169480979443
step: 150, loss: 0.10347701609134674
step: 160, loss: 0.01435184571892023
step: 170, loss: 0.061352379620075226
step: 180, loss: 0.0012324147392064333
step: 190, loss: 0.044285599142313004
step: 200, loss: 0.038491394370794296
step: 210, loss: 0.1327216625213623
step: 220, loss: 0.03573070839047432
step: 230, loss: 0.05154350772500038
step: 240, loss: 0.017617259174585342
step: 250, loss: 0.07390668988227844
step: 260, loss: 0.037288814783096313
step: 270, loss: 0.09625878930091858
step: 280, loss: 0.1583707481622696
step: 290, loss: 0.09600139409303665
step: 300, loss: 0.08600009977817535
step: 310, loss: 0.06072959303855896
step: 320, loss: 0.03959761932492256
step: 330, loss: 0.04436248913407326
step: 340, loss: 0.09400808811187744
step: 350, loss: 0.050597358494997025
step: 360, loss: 0.01635311171412468
epoch 8: dev_f1=0.7443037974683544, f1=0.722077922077922, best_f1=0.7433155080213903
step: 0, loss: 0.034020859748125076
step: 10, loss: 0.0004996747593395412
step: 20, loss: 0.003971099853515625
step: 30, loss: 0.05200360342860222
step: 40, loss: 0.05885668098926544
step: 50, loss: 0.02288386970758438
step: 60, loss: 0.023957952857017517
step: 70, loss: 0.03519028425216675
step: 80, loss: 0.030791042372584343
step: 90, loss: 0.020684530958533287
step: 100, loss: 0.01671004854142666
step: 110, loss: 0.050461940467357635
step: 120, loss: 0.0001655293453950435
step: 130, loss: 0.020463258028030396
step: 140, loss: 0.051628876477479935
step: 150, loss: 8.294550207210705e-05
step: 160, loss: 0.03844212368130684
step: 170, loss: 0.05044553428888321
step: 180, loss: 0.006955024786293507
step: 190, loss: 0.012768045999109745
step: 200, loss: 0.037818606942892075
step: 210, loss: 0.044638071209192276
step: 220, loss: 0.16852989792823792
step: 230, loss: 0.04012209549546242
step: 240, loss: 0.07577966898679733
step: 250, loss: 0.05720053240656853
step: 260, loss: 0.06791575998067856
step: 270, loss: 0.05604150891304016
step: 280, loss: 0.008335079997777939
step: 290, loss: 0.08916081488132477
step: 300, loss: 0.021715790033340454
step: 310, loss: 0.012901419773697853
step: 320, loss: 0.141330748796463
step: 330, loss: 0.12967118620872498
step: 340, loss: 0.030060697346925735
step: 350, loss: 0.00887003168463707
step: 360, loss: 0.052849747240543365
epoch 9: dev_f1=0.7263427109974423, f1=0.7139107611548556, best_f1=0.7433155080213903
step: 0, loss: 0.007335439790040255
step: 10, loss: 0.09038034081459045
step: 20, loss: 0.040847085416316986
step: 30, loss: 0.06034538522362709
step: 40, loss: 0.0011365895625203848
step: 50, loss: 0.006831508595496416
step: 60, loss: 0.007273872382938862
step: 70, loss: 0.002480693394318223
step: 80, loss: 0.04901925101876259
step: 90, loss: 0.058086272329092026
step: 100, loss: 3.9724014641251415e-05
step: 110, loss: 0.04491262137889862
step: 120, loss: 0.08466862142086029
step: 130, loss: 0.03357234597206116
step: 140, loss: 0.01830364018678665
step: 150, loss: 0.018689772114157677
step: 160, loss: 0.1030115932226181
step: 170, loss: 0.05069667100906372
step: 180, loss: 0.027529098093509674
step: 190, loss: 0.028443749994039536
step: 200, loss: 0.013172430917620659
step: 210, loss: 0.07232677191495895
step: 220, loss: 0.01985880546271801
step: 230, loss: 0.0002105385938193649
step: 240, loss: 0.1140233725309372
step: 250, loss: 0.01121680997312069
step: 260, loss: 0.0008365096873603761
step: 270, loss: 0.04240905120968819
step: 280, loss: 0.009772267192602158
step: 290, loss: 0.039163876324892044
step: 300, loss: 0.007325586397200823
step: 310, loss: 0.04126792028546333
step: 320, loss: 0.043245431035757065
step: 330, loss: 0.00010506839316803962
step: 340, loss: 0.05752405896782875
step: 350, loss: 0.010817497037351131
step: 360, loss: 0.056193459779024124
epoch 10: dev_f1=0.7012345679012345, f1=0.7131782945736433, best_f1=0.7433155080213903
step: 0, loss: 0.07728632539510727
step: 10, loss: 0.020501989871263504
step: 20, loss: 0.03679896146059036
step: 30, loss: 0.009070240892469883
step: 40, loss: 0.06169983744621277
step: 50, loss: 0.002587362425401807
step: 60, loss: 0.016879191622138023
step: 70, loss: 4.5736818719888106e-05
step: 80, loss: 0.028231285512447357
step: 90, loss: 0.05001400038599968
step: 100, loss: 0.024042051285505295
step: 110, loss: 0.14268122613430023
step: 120, loss: 0.075302854180336
step: 130, loss: 0.00046532988199032843
step: 140, loss: 0.06945641338825226
step: 150, loss: 0.007080347742885351
step: 160, loss: 0.02476544864475727
step: 170, loss: 0.011202003806829453
step: 180, loss: 0.02575245499610901
step: 190, loss: 0.0023635849356651306
step: 200, loss: 0.00015403771249111742
step: 210, loss: 0.0159289613366127
step: 220, loss: 0.0033347676508128643
step: 230, loss: 0.004968918859958649
step: 240, loss: 0.05045728385448456
step: 250, loss: 0.057926662266254425
step: 260, loss: 0.07206599414348602
step: 270, loss: 0.012528094463050365
step: 280, loss: 0.012469732202589512
step: 290, loss: 0.04293013736605644
step: 300, loss: 0.043523047119379044
step: 310, loss: 0.023155301809310913
step: 320, loss: 0.02540876530110836
step: 330, loss: 0.0016652710037305951
step: 340, loss: 0.08795387297868729
step: 350, loss: 0.00391434645280242
step: 360, loss: 0.13827113807201385
epoch 11: dev_f1=0.7321867321867322, f1=0.7405541561712846, best_f1=0.7433155080213903
step: 0, loss: 0.06990442425012589
step: 10, loss: 0.03598528727889061
step: 20, loss: 0.0609755776822567
step: 30, loss: 0.006067383568733931
step: 40, loss: 0.06958312541246414
step: 50, loss: 0.057938896119594574
step: 60, loss: 7.034118607407436e-05
step: 70, loss: 0.07004857063293457
step: 80, loss: 0.028272680938243866
step: 90, loss: 0.014501873403787613
step: 100, loss: 0.01836983487010002
step: 110, loss: 0.01970304548740387
step: 120, loss: 0.00382251781411469
step: 130, loss: 0.05691587179899216
step: 140, loss: 0.004298780113458633
step: 150, loss: 0.009433136321604252
step: 160, loss: 0.00012757025251630694
step: 170, loss: 0.034235600382089615
step: 180, loss: 0.012984510511159897
step: 190, loss: 0.005890534725040197
step: 200, loss: 0.006926593370735645
step: 210, loss: 0.08413220196962357
step: 220, loss: 0.03906910866498947
step: 230, loss: 0.011471016332507133
step: 240, loss: 0.04878374934196472
step: 250, loss: 0.010854709893465042
step: 260, loss: 0.006910588592290878
step: 270, loss: 0.017217518761754036
step: 280, loss: 0.06920550018548965
step: 290, loss: 0.07611711323261261
step: 300, loss: 0.025505458936095238
step: 310, loss: 0.020391318947076797
step: 320, loss: 0.01577863097190857
step: 330, loss: 0.033111684024333954
step: 340, loss: 0.040355537086725235
step: 350, loss: 0.021871881559491158
step: 360, loss: 0.00032607195316813886
epoch 12: dev_f1=0.7238605898123326, f1=0.6985915492957746, best_f1=0.7433155080213903
step: 0, loss: 0.006738917902112007
step: 10, loss: 0.0019068877445533872
step: 20, loss: 0.06328529119491577
step: 30, loss: 0.04474613070487976
step: 40, loss: 0.017114488407969475
step: 50, loss: 0.0019032483687624335
step: 60, loss: 0.029047170653939247
step: 70, loss: 0.05012320354580879
step: 80, loss: 0.023306475952267647
step: 90, loss: 0.027222607284784317
step: 100, loss: 0.0017402665689587593
step: 110, loss: 0.007139412220567465
step: 120, loss: 0.00013198418309912086
step: 130, loss: 0.016648124903440475
step: 140, loss: 0.01051006093621254
step: 150, loss: 0.07572605460882187
step: 160, loss: 0.005368529818952084
step: 170, loss: 0.03844821825623512
step: 180, loss: 0.008733655326068401
step: 190, loss: 0.06076883152127266
step: 200, loss: 0.01726783625781536
step: 210, loss: 0.04322401061654091
step: 220, loss: 0.0004282950540073216
step: 230, loss: 0.09278290718793869
step: 240, loss: 0.003114327322691679
step: 250, loss: 0.000491378246806562
step: 260, loss: 0.007252323441207409
step: 270, loss: 0.024111434817314148
step: 280, loss: 0.08385632932186127
step: 290, loss: 0.0009470333461649716
step: 300, loss: 0.05080360919237137
step: 310, loss: 0.11189061403274536
step: 320, loss: 0.05635755881667137
step: 330, loss: 0.011504404246807098
step: 340, loss: 0.0033665525261312723
step: 350, loss: 0.06143992021679878
step: 360, loss: 0.007405031472444534
epoch 13: dev_f1=0.7282608695652173, f1=0.7159090909090909, best_f1=0.7433155080213903
step: 0, loss: 0.018898390233516693
step: 10, loss: 0.00012863113079220057
step: 20, loss: 0.027910226956009865
step: 30, loss: 0.04888828098773956
step: 40, loss: 0.04321173205971718
step: 50, loss: 0.0010052099823951721
step: 60, loss: 0.008992909453809261
step: 70, loss: 0.0015080750454217196
step: 80, loss: 0.044694624841213226
step: 90, loss: 0.00019086679094471037
step: 100, loss: 0.024940891191363335
step: 110, loss: 0.0050644115544855595
step: 120, loss: 0.004919426515698433
step: 130, loss: 0.00047172216000035405
step: 140, loss: 0.014105559326708317
step: 150, loss: 0.005675655324012041
step: 160, loss: 0.053310658782720566
step: 170, loss: 0.008275413885712624
step: 180, loss: 0.01578676328063011
step: 190, loss: 0.00034535740269348025
step: 200, loss: 0.002571905730292201
step: 210, loss: 0.010605789721012115
step: 220, loss: 0.003946218173950911
step: 230, loss: 0.019156329333782196
step: 240, loss: 0.017902769148349762
step: 250, loss: 0.0022436529397964478
step: 260, loss: 0.04205456003546715
step: 270, loss: 0.0008212300017476082
step: 280, loss: 0.025403544306755066
step: 290, loss: 0.011537469923496246
step: 300, loss: 0.007245809305459261
step: 310, loss: 0.01951565220952034
step: 320, loss: 0.0021281212102621794
step: 330, loss: 0.004321811720728874
step: 340, loss: 0.028572743758559227
step: 350, loss: 0.007553288713097572
step: 360, loss: 0.03712136298418045
epoch 14: dev_f1=0.7188264058679708, f1=0.732824427480916, best_f1=0.7433155080213903
step: 0, loss: 0.06770672649145126
step: 10, loss: 0.09858720749616623
step: 20, loss: 0.06297224760055542
step: 30, loss: 0.002930914517492056
step: 40, loss: 0.023019473999738693
step: 50, loss: 2.441148717480246e-05
step: 60, loss: 0.01940290443599224
step: 70, loss: 0.06691588461399078
step: 80, loss: 0.018650230020284653
step: 90, loss: 0.04055245965719223
step: 100, loss: 0.04297645762562752
step: 110, loss: 0.0032909787259995937
step: 120, loss: 0.010497387498617172
step: 130, loss: 0.07844095677137375
step: 140, loss: 0.0309634730219841
step: 150, loss: 0.0056864735670387745
step: 160, loss: 0.04109072685241699
step: 170, loss: 0.022320078685879707
step: 180, loss: 0.011314373463392258
step: 190, loss: 0.06196165457367897
step: 200, loss: 4.22588964283932e-05
step: 210, loss: 0.06703880429267883
step: 220, loss: 0.027569584548473358
step: 230, loss: 7.151628233259544e-05
step: 240, loss: 0.03335915878415108
step: 250, loss: 0.00032744318014010787
step: 260, loss: 4.072344017913565e-05
step: 270, loss: 0.06513325124979019
step: 280, loss: 0.02985280193388462
step: 290, loss: 4.7723162424517795e-05
step: 300, loss: 0.0244359839707613
step: 310, loss: 0.07548820227384567
step: 320, loss: 0.0001461170904804021
step: 330, loss: 0.005827403161674738
step: 340, loss: 0.013487185351550579
step: 350, loss: 2.6147203243453987e-05
step: 360, loss: 0.043403565883636475
epoch 15: dev_f1=0.7277353689567431, f1=0.7068493150684931, best_f1=0.7433155080213903
step: 0, loss: 0.010354297235608101
step: 10, loss: 0.012523746117949486
step: 20, loss: 0.0003986368828918785
step: 30, loss: 0.0008014917839318514
step: 40, loss: 3.238278804928996e-05
step: 50, loss: 0.0014972686767578125
step: 60, loss: 0.0005230411770753562
step: 70, loss: 0.09329554438591003
step: 80, loss: 0.00010099486826220527
step: 90, loss: 0.12005767226219177
step: 100, loss: 0.004441904369741678
step: 110, loss: 0.024966299533843994
step: 120, loss: 0.0002971501962747425
step: 130, loss: 0.019382819533348083
step: 140, loss: 0.012018601410090923
step: 150, loss: 0.012343802489340305
step: 160, loss: 0.004957607947289944
step: 170, loss: 0.046854954212903976
step: 180, loss: 0.021221140399575233
step: 190, loss: 0.09474459290504456
step: 200, loss: 0.08152632415294647
step: 210, loss: 0.059144772589206696
step: 220, loss: 0.007156697567552328
step: 230, loss: 0.010707139037549496
step: 240, loss: 2.532767211960163e-05
step: 250, loss: 0.004057967569679022
step: 260, loss: 0.00021732239110860974
step: 270, loss: 0.0004342361935414374
step: 280, loss: 3.095615466008894e-05
step: 290, loss: 0.0009421518770977855
step: 300, loss: 0.020344601944088936
step: 310, loss: 0.014090816490352154
step: 320, loss: 0.007452234160155058
step: 330, loss: 0.05396692827343941
step: 340, loss: 0.002681017154827714
step: 350, loss: 0.00026271422393620014
step: 360, loss: 0.04224828630685806
epoch 16: dev_f1=0.7201946472019465, f1=0.7116883116883116, best_f1=0.7433155080213903
step: 0, loss: 0.00017503945855423808
step: 10, loss: 0.17978107929229736
step: 20, loss: 0.025993065908551216
step: 30, loss: 0.05971851199865341
step: 40, loss: 0.00038103325641714036
step: 50, loss: 0.00012401078129187226
step: 60, loss: 0.00026104823336936533
step: 70, loss: 0.00045995457912795246
step: 80, loss: 0.0006970514077693224
step: 90, loss: 0.006770959589630365
step: 100, loss: 0.002129813889041543
step: 110, loss: 0.02115905098617077
step: 120, loss: 0.022181527689099312
step: 130, loss: 0.06729542464017868
step: 140, loss: 2.238859815406613e-05
step: 150, loss: 0.0847042128443718
step: 160, loss: 0.00044675610843114555
step: 170, loss: 0.05673442408442497
step: 180, loss: 0.0022770550567656755
step: 190, loss: 0.06538248062133789
step: 200, loss: 0.06977768242359161
step: 210, loss: 0.05789709463715553
step: 220, loss: 0.0008586343610659242
step: 230, loss: 7.682561408728361e-05
step: 240, loss: 0.07523539662361145
step: 250, loss: 0.018862083554267883
step: 260, loss: 0.07442692667245865
step: 270, loss: 4.922816515318118e-05
step: 280, loss: 0.07518972456455231
step: 290, loss: 0.0011131224455311894
step: 300, loss: 0.09601491689682007
step: 310, loss: 3.205411121598445e-05
step: 320, loss: 0.005059742834419012
step: 330, loss: 0.020923923701047897
step: 340, loss: 1.8350589016336016e-05
step: 350, loss: 0.0016823039622977376
step: 360, loss: 0.02288038283586502
epoch 17: dev_f1=0.7277227722772278, f1=0.7142857142857143, best_f1=0.7433155080213903
step: 0, loss: 0.03997787460684776
step: 10, loss: 0.04477986320853233
step: 20, loss: 0.05929167941212654
step: 30, loss: 0.022526590153574944
step: 40, loss: 7.788827497279271e-05
step: 50, loss: 0.014290791004896164
step: 60, loss: 0.019907716661691666
step: 70, loss: 0.0007152354228310287
step: 80, loss: 0.005375095643103123
step: 90, loss: 0.050175298005342484
step: 100, loss: 8.531103958375752e-05
step: 110, loss: 0.011863948777318
step: 120, loss: 0.032546911388635635
step: 130, loss: 0.007312333676964045
step: 140, loss: 0.004583312664180994
step: 150, loss: 0.04099388048052788
step: 160, loss: 0.015643952414393425
step: 170, loss: 0.00011890200403286144
step: 180, loss: 0.04740676283836365
step: 190, loss: 0.00011699941387632862
step: 200, loss: 0.04729475453495979
step: 210, loss: 0.07472065836191177
step: 220, loss: 0.0002165787445846945
step: 230, loss: 0.02067898027598858
step: 240, loss: 0.009875037707388401
step: 250, loss: 0.004272981081157923
step: 260, loss: 5.2328567107906565e-05
step: 270, loss: 0.02238282933831215
step: 280, loss: 0.000915553595405072
step: 290, loss: 0.013735921122133732
step: 300, loss: 0.04107733815908432
step: 310, loss: 0.023891009390354156
step: 320, loss: 3.8146652514114976e-05
step: 330, loss: 0.004156889393925667
step: 340, loss: 0.0029552411288022995
step: 350, loss: 0.0175305288285017
step: 360, loss: 0.006104645319283009
epoch 18: dev_f1=0.7204030226700252, f1=0.7065217391304348, best_f1=0.7433155080213903
step: 0, loss: 0.00031317753018811345
step: 10, loss: 0.03666573390364647
step: 20, loss: 0.011741072870790958
step: 30, loss: 0.031760234385728836
step: 40, loss: 0.020765701308846474
step: 50, loss: 0.00010763280442915857
step: 60, loss: 0.0009339714888483286
step: 70, loss: 0.02285817638039589
step: 80, loss: 0.01894388347864151
step: 90, loss: 0.0041594854556024075
step: 100, loss: 0.0016122222878038883
step: 110, loss: 0.024287331849336624
step: 120, loss: 0.02044316753745079
step: 130, loss: 0.001974676502868533
step: 140, loss: 0.015415270812809467
step: 150, loss: 0.0017017180798575282
step: 160, loss: 0.002814620267599821
step: 170, loss: 0.07325846701860428
step: 180, loss: 0.02264145389199257
step: 190, loss: 0.061308346688747406
step: 200, loss: 0.02310570515692234
step: 210, loss: 0.03723275661468506
step: 220, loss: 0.045493826270103455
step: 230, loss: 0.0017864556284621358
step: 240, loss: 0.0018824178259819746
step: 250, loss: 0.0004043409717269242
step: 260, loss: 0.022915713489055634
step: 270, loss: 0.019557176157832146
step: 280, loss: 0.029038626700639725
step: 290, loss: 2.038082675426267e-05
step: 300, loss: 2.5886165531119332e-05
step: 310, loss: 0.00548917893320322
step: 320, loss: 0.029226090759038925
step: 330, loss: 2.7234777007834055e-05
step: 340, loss: 0.0018239718629047275
step: 350, loss: 0.017039509490132332
step: 360, loss: 0.00017394652240909636
epoch 19: dev_f1=0.7146401985111663, f1=0.7184986595174263, best_f1=0.7433155080213903
step: 0, loss: 0.0345296636223793
step: 10, loss: 0.02140151523053646
step: 20, loss: 0.014838224276900291
step: 30, loss: 0.010877472348511219
step: 40, loss: 0.0634152814745903
step: 50, loss: 2.214652340626344e-05
step: 60, loss: 0.002152844564989209
step: 70, loss: 7.190459291450679e-05
step: 80, loss: 0.027490682899951935
step: 90, loss: 0.0365992970764637
step: 100, loss: 0.006864598020911217
step: 110, loss: 8.879419328877702e-05
step: 120, loss: 0.013791991397738457
step: 130, loss: 0.00027624116046354175
step: 140, loss: 0.013841848820447922
step: 150, loss: 0.000335625431034714
step: 160, loss: 0.006222995463758707
step: 170, loss: 4.048539631185122e-05
step: 180, loss: 3.0370911190402694e-05
step: 190, loss: 0.018879756331443787
step: 200, loss: 0.00017753979773260653
step: 210, loss: 0.0031788612250238657
step: 220, loss: 0.03630542382597923
step: 230, loss: 0.0006046200287528336
step: 240, loss: 9.523687185719609e-05
step: 250, loss: 9.53264971030876e-05
step: 260, loss: 0.05476267635822296
step: 270, loss: 0.019938087090849876
step: 280, loss: 0.00024281683727167547
step: 290, loss: 0.007952707819640636
step: 300, loss: 0.028802206739783287
step: 310, loss: 0.039780836552381516
step: 320, loss: 0.0603463388979435
step: 330, loss: 0.00033291129511781037
step: 340, loss: 1.9546385374269448e-05
step: 350, loss: 2.1498390196939e-05
step: 360, loss: 0.08110146969556808
epoch 20: dev_f1=0.7185929648241205, f1=0.6994535519125683, best_f1=0.7433155080213903
