cuda
Device: cuda
step: 0, loss: 0.7321768403053284
step: 10, loss: 0.5069276690483093
step: 20, loss: 0.18177156150341034
step: 30, loss: 0.23352427780628204
step: 40, loss: 0.14474233984947205
step: 50, loss: 0.24511489272117615
step: 60, loss: 0.14134015142917633
step: 70, loss: 0.1543240249156952
step: 80, loss: 0.3267723321914673
step: 90, loss: 0.13948209583759308
step: 100, loss: 0.13307790458202362
step: 110, loss: 0.13918867707252502
step: 120, loss: 0.41684451699256897
step: 130, loss: 0.13389024138450623
step: 140, loss: 0.2446414679288864
step: 150, loss: 0.2163093537092209
step: 160, loss: 0.24771538376808167
step: 170, loss: 0.19306199252605438
step: 180, loss: 0.24591974914073944
step: 190, loss: 0.48787468671798706
step: 200, loss: 0.12168192118406296
step: 210, loss: 0.13346506655216217
step: 220, loss: 0.12539219856262207
step: 230, loss: 0.3019998371601105
step: 240, loss: 0.13210360705852509
step: 250, loss: 0.1347716599702835
step: 260, loss: 0.22808843851089478
step: 270, loss: 0.20863795280456543
step: 280, loss: 0.0814269483089447
step: 290, loss: 0.2526035010814667
step: 300, loss: 0.1816650629043579
step: 310, loss: 0.29790714383125305
step: 320, loss: 0.08983362466096878
step: 330, loss: 0.07636428624391556
step: 340, loss: 0.16731369495391846
step: 350, loss: 0.07239227741956711
step: 360, loss: 0.1630193442106247
epoch 1: dev_f1=0.6023391812865497, f1=0.6397694524495677, best_f1=0.6397694524495677
step: 0, loss: 0.15821386873722076
step: 10, loss: 0.20303314924240112
step: 20, loss: 0.03750363364815712
step: 30, loss: 0.112489715218544
step: 40, loss: 0.06592914462089539
step: 50, loss: 0.18527214229106903
step: 60, loss: 0.05198661610484123
step: 70, loss: 0.03580453619360924
step: 80, loss: 0.16944804787635803
step: 90, loss: 0.1100093275308609
step: 100, loss: 0.20922642946243286
step: 110, loss: 0.16267794370651245
step: 120, loss: 0.11195742338895798
step: 130, loss: 0.07418947666883469
step: 140, loss: 0.06655418872833252
step: 150, loss: 0.17291991412639618
step: 160, loss: 0.11765716224908829
step: 170, loss: 0.160398930311203
step: 180, loss: 0.11669658124446869
step: 190, loss: 0.029291056096553802
step: 200, loss: 0.2073696404695511
step: 210, loss: 0.03717120736837387
step: 220, loss: 0.18123282492160797
step: 230, loss: 0.04600178450345993
step: 240, loss: 0.09700144827365875
step: 250, loss: 0.06971091032028198
step: 260, loss: 0.08978889882564545
step: 270, loss: 0.11158508062362671
step: 280, loss: 0.10368964076042175
step: 290, loss: 0.13946616649627686
step: 300, loss: 0.07363096624612808
step: 310, loss: 0.040575381368398666
step: 320, loss: 0.11371760815382004
step: 330, loss: 0.030868954956531525
step: 340, loss: 0.016662120819091797
step: 350, loss: 0.05254862830042839
step: 360, loss: 0.13989880681037903
epoch 2: dev_f1=0.7138810198300283, f1=0.7394957983193278, best_f1=0.7394957983193278
step: 0, loss: 0.05345698073506355
step: 10, loss: 0.18924976885318756
step: 20, loss: 0.09799523651599884
step: 30, loss: 0.084914930164814
step: 40, loss: 0.12003079801797867
step: 50, loss: 0.1085459366440773
step: 60, loss: 0.028490157797932625
step: 70, loss: 0.10962469130754471
step: 80, loss: 0.05020521208643913
step: 90, loss: 0.01874328777194023
step: 100, loss: 0.06454802304506302
step: 110, loss: 0.08169948309659958
step: 120, loss: 0.23117975890636444
step: 130, loss: 0.044426318258047104
step: 140, loss: 0.20186351239681244
step: 150, loss: 0.13153792917728424
step: 160, loss: 0.10386668890714645
step: 170, loss: 0.12263509631156921
step: 180, loss: 0.23008227348327637
step: 190, loss: 0.1035267561674118
step: 200, loss: 0.019977573305368423
step: 210, loss: 0.006494800094515085
step: 220, loss: 0.060960859060287476
step: 230, loss: 0.039011452347040176
step: 240, loss: 0.08930789679288864
step: 250, loss: 0.01952979527413845
step: 260, loss: 0.27321889996528625
step: 270, loss: 0.051848139613866806
step: 280, loss: 0.06006467342376709
step: 290, loss: 0.1713731288909912
step: 300, loss: 0.08224856853485107
step: 310, loss: 0.22389279305934906
step: 320, loss: 0.046105965971946716
step: 330, loss: 0.09178711473941803
step: 340, loss: 0.09042157977819443
step: 350, loss: 0.10514652729034424
step: 360, loss: 0.05198199301958084
epoch 3: dev_f1=0.7458563535911602, f1=0.7506849315068493, best_f1=0.7506849315068493
step: 0, loss: 0.05042652413249016
step: 10, loss: 0.05843405798077583
step: 20, loss: 0.05255745351314545
step: 30, loss: 0.07083754241466522
step: 40, loss: 0.02281571924686432
step: 50, loss: 0.07538540661334991
step: 60, loss: 0.13224071264266968
step: 70, loss: 0.005062096752226353
step: 80, loss: 0.21921223402023315
step: 90, loss: 0.03048052452504635
step: 100, loss: 0.0008114160154946148
step: 110, loss: 0.013314447365701199
step: 120, loss: 0.05618741735816002
step: 130, loss: 0.049140192568302155
step: 140, loss: 0.05857175961136818
step: 150, loss: 0.15368901193141937
step: 160, loss: 0.007451704237610102
step: 170, loss: 0.06447630375623703
step: 180, loss: 0.02335277944803238
step: 190, loss: 0.07772301137447357
step: 200, loss: 0.004296084865927696
step: 210, loss: 0.11690391600131989
step: 220, loss: 0.05793939530849457
step: 230, loss: 0.04425964131951332
step: 240, loss: 0.01347419060766697
step: 250, loss: 0.15778295695781708
step: 260, loss: 0.10855971276760101
step: 270, loss: 0.13406839966773987
step: 280, loss: 0.02083410695195198
step: 290, loss: 0.10084501653909683
step: 300, loss: 0.061756715178489685
step: 310, loss: 0.103339284658432
step: 320, loss: 0.2237684279680252
step: 330, loss: 0.14239263534545898
step: 340, loss: 0.056114889681339264
step: 350, loss: 0.044769540429115295
step: 360, loss: 0.06829877197742462
epoch 4: dev_f1=0.743455497382199, f1=0.7629427792915532, best_f1=0.7506849315068493
step: 0, loss: 0.11535421013832092
step: 10, loss: 0.04239502549171448
step: 20, loss: 0.015707634389400482
step: 30, loss: 0.08357101678848267
step: 40, loss: 0.036336977034807205
step: 50, loss: 0.07248497754335403
step: 60, loss: 0.09563799202442169
step: 70, loss: 0.013211957179009914
step: 80, loss: 0.041888341307640076
step: 90, loss: 0.05931280925869942
step: 100, loss: 0.042417217046022415
step: 110, loss: 0.04391007125377655
step: 120, loss: 0.041424818336963654
step: 130, loss: 0.06657577306032181
step: 140, loss: 0.047446735203266144
step: 150, loss: 0.008510098792612553
step: 160, loss: 0.12063512951135635
step: 170, loss: 0.0443250872194767
step: 180, loss: 0.06878107786178589
step: 190, loss: 0.13117200136184692
step: 200, loss: 0.08222492039203644
step: 210, loss: 0.30278146266937256
step: 220, loss: 0.08508102595806122
step: 230, loss: 0.05330709367990494
step: 240, loss: 0.01647781766951084
step: 250, loss: 0.10576865077018738
step: 260, loss: 0.06696353107690811
step: 270, loss: 0.06081731244921684
step: 280, loss: 0.026008885353803635
step: 290, loss: 0.03968191519379616
step: 300, loss: 0.026006806641817093
step: 310, loss: 0.054567135870456696
step: 320, loss: 0.0339471697807312
step: 330, loss: 0.044303249567747116
step: 340, loss: 0.004945412743836641
step: 350, loss: 0.10214762389659882
step: 360, loss: 0.0050072926096618176
epoch 5: dev_f1=0.7405405405405405, f1=0.743661971830986, best_f1=0.7506849315068493
step: 0, loss: 0.05534921586513519
step: 10, loss: 0.025018274784088135
step: 20, loss: 0.020878776907920837
step: 30, loss: 0.05914118140935898
step: 40, loss: 0.014356417581439018
step: 50, loss: 0.13275009393692017
step: 60, loss: 0.10072880983352661
step: 70, loss: 0.02660229243338108
step: 80, loss: 0.006542689632624388
step: 90, loss: 0.06388343125581741
step: 100, loss: 0.026874274015426636
step: 110, loss: 0.08907562494277954
step: 120, loss: 0.008717428892850876
step: 130, loss: 0.05221513286232948
step: 140, loss: 0.07974233478307724
step: 150, loss: 0.019441192969679832
step: 160, loss: 0.008533444255590439
step: 170, loss: 0.09665104746818542
step: 180, loss: 0.03951721638441086
step: 190, loss: 0.02860100567340851
step: 200, loss: 0.03531087934970856
step: 210, loss: 0.024473989382386208
step: 220, loss: 0.019422439858317375
step: 230, loss: 0.11437713354825974
step: 240, loss: 0.015579981729388237
step: 250, loss: 0.02549668587744236
step: 260, loss: 0.03559429571032524
step: 270, loss: 0.010184147395193577
step: 280, loss: 0.11991636455059052
step: 290, loss: 0.07506581395864487
step: 300, loss: 0.1394421011209488
step: 310, loss: 0.00093743548495695
step: 320, loss: 0.0006515058339573443
step: 330, loss: 0.008855295367538929
step: 340, loss: 0.22951588034629822
step: 350, loss: 0.11289436370134354
step: 360, loss: 0.01995890960097313
epoch 6: dev_f1=0.768421052631579, f1=0.7561643835616437, best_f1=0.7561643835616437
step: 0, loss: 0.061727892607450485
step: 10, loss: 0.08367086201906204
step: 20, loss: 0.05032147094607353
step: 30, loss: 0.014487938955426216
step: 40, loss: 0.008163264021277428
step: 50, loss: 0.04148922860622406
step: 60, loss: 0.07802104204893112
step: 70, loss: 0.02805180661380291
step: 80, loss: 0.08252391964197159
step: 90, loss: 0.02835536189377308
step: 100, loss: 0.07560746371746063
step: 110, loss: 0.07946357131004333
step: 120, loss: 0.035060808062553406
step: 130, loss: 0.00809716060757637
step: 140, loss: 0.013150467537343502
step: 150, loss: 0.13032616674900055
step: 160, loss: 0.16701553761959076
step: 170, loss: 0.07591141015291214
step: 180, loss: 0.11855890601873398
step: 190, loss: 0.03445986658334732
step: 200, loss: 0.020221982151269913
step: 210, loss: 0.058397237211465836
step: 220, loss: 0.1784874051809311
step: 230, loss: 0.04031422361731529
step: 240, loss: 0.018984366208314896
step: 250, loss: 0.4016483426094055
step: 260, loss: 0.03886663541197777
step: 270, loss: 0.04779783636331558
step: 280, loss: 0.007842838764190674
step: 290, loss: 0.025155996903777122
step: 300, loss: 0.03497929871082306
step: 310, loss: 0.08170485496520996
step: 320, loss: 0.007284865248948336
step: 330, loss: 0.14136482775211334
step: 340, loss: 0.006666447035968304
step: 350, loss: 0.043617621064186096
step: 360, loss: 0.033291324973106384
epoch 7: dev_f1=0.7420814479638009, f1=0.7211538461538461, best_f1=0.7561643835616437
step: 0, loss: 0.03395363315939903
step: 10, loss: 0.02969791740179062
step: 20, loss: 0.0668591558933258
step: 30, loss: 0.012647980824112892
step: 40, loss: 9.704846161184832e-05
step: 50, loss: 0.007947402074933052
step: 60, loss: 0.03861268237233162
step: 70, loss: 0.017133451998233795
step: 80, loss: 0.004561740439385176
step: 90, loss: 0.03456330671906471
step: 100, loss: 0.15002170205116272
step: 110, loss: 0.0786527767777443
step: 120, loss: 0.022780628874897957
step: 130, loss: 0.1491333395242691
step: 140, loss: 0.024116063490509987
step: 150, loss: 0.0300705935806036
step: 160, loss: 0.05280306935310364
step: 170, loss: 0.13189423084259033
step: 180, loss: 0.00405126204714179
step: 190, loss: 0.011240248568356037
step: 200, loss: 0.013349809683859348
step: 210, loss: 0.09587366133928299
step: 220, loss: 0.01268729567527771
step: 230, loss: 0.002964103128761053
step: 240, loss: 0.10617487877607346
step: 250, loss: 0.002486087381839752
step: 260, loss: 0.12098950147628784
step: 270, loss: 0.07208855450153351
step: 280, loss: 0.05019135773181915
step: 290, loss: 0.023689575493335724
step: 300, loss: 0.04591749981045723
step: 310, loss: 0.03164397180080414
step: 320, loss: 0.06258229166269302
step: 330, loss: 0.06473688781261444
step: 340, loss: 0.06846290081739426
step: 350, loss: 0.031068293377757072
step: 360, loss: 0.024172108620405197
epoch 8: dev_f1=0.7419354838709677, f1=0.7195467422096318, best_f1=0.7561643835616437
step: 0, loss: 0.06031602993607521
step: 10, loss: 0.03214583545923233
step: 20, loss: 0.04404176026582718
step: 30, loss: 0.00405161501839757
step: 40, loss: 8.581759175285697e-05
step: 50, loss: 0.03860735148191452
step: 60, loss: 0.04007504880428314
step: 70, loss: 0.08026519417762756
step: 80, loss: 0.07510025799274445
step: 90, loss: 0.08887642621994019
step: 100, loss: 0.020146595314145088
step: 110, loss: 0.002087361877784133
step: 120, loss: 0.0011425093980506063
step: 130, loss: 0.005963688716292381
step: 140, loss: 0.005226900335401297
step: 150, loss: 0.0029429413843899965
step: 160, loss: 0.03849928081035614
step: 170, loss: 0.01158186886459589
step: 180, loss: 0.030994340777397156
step: 190, loss: 0.05227518454194069
step: 200, loss: 0.053662221878767014
step: 210, loss: 0.015202833339571953
step: 220, loss: 0.06232263520359993
step: 230, loss: 0.04074998199939728
step: 240, loss: 0.10808472335338593
step: 250, loss: 0.07654894143342972
step: 260, loss: 0.011029655113816261
step: 270, loss: 0.07567436993122101
step: 280, loss: 0.0452180951833725
step: 290, loss: 0.02712998166680336
step: 300, loss: 0.0016417906153947115
step: 310, loss: 0.03934997320175171
step: 320, loss: 0.04007379710674286
step: 330, loss: 0.0539611354470253
step: 340, loss: 0.09683427214622498
step: 350, loss: 0.12363580614328384
step: 360, loss: 0.0331026166677475
epoch 9: dev_f1=0.7606382978723404, f1=0.7422096317280454, best_f1=0.7561643835616437
step: 0, loss: 0.06397552788257599
step: 10, loss: 0.003274301066994667
step: 20, loss: 0.015137461014091969
step: 30, loss: 4.439894837560132e-05
step: 40, loss: 0.007675786502659321
step: 50, loss: 0.029905451461672783
step: 60, loss: 0.02601362019777298
step: 70, loss: 0.03436259925365448
step: 80, loss: 0.007623844314366579
step: 90, loss: 0.08567588776350021
step: 100, loss: 8.993308438220993e-05
step: 110, loss: 0.023346172645688057
step: 120, loss: 0.04357150197029114
step: 130, loss: 0.0044654845260083675
step: 140, loss: 0.1330927014350891
step: 150, loss: 0.02996249869465828
step: 160, loss: 0.04985840991139412
step: 170, loss: 0.03156745433807373
step: 180, loss: 0.08302406221628189
step: 190, loss: 0.018691599369049072
step: 200, loss: 0.09775418043136597
step: 210, loss: 0.01213907077908516
step: 220, loss: 0.04517608508467674
step: 230, loss: 0.00680488720536232
step: 240, loss: 0.007878298871219158
step: 250, loss: 0.04708288982510567
step: 260, loss: 0.05000399053096771
step: 270, loss: 0.05070512741804123
step: 280, loss: 0.02280591055750847
step: 290, loss: 0.030854245647788048
step: 300, loss: 0.02012450248003006
step: 310, loss: 0.05112358182668686
step: 320, loss: 0.13762131333351135
step: 330, loss: 0.0023108948953449726
step: 340, loss: 0.013812942430377007
step: 350, loss: 0.04402369633316994
step: 360, loss: 0.01975792646408081
epoch 10: dev_f1=0.7578947368421052, f1=0.7590027700831025, best_f1=0.7561643835616437
step: 0, loss: 0.007363968528807163
step: 10, loss: 0.001785428263247013
step: 20, loss: 0.0686601847410202
step: 30, loss: 0.0661492571234703
step: 40, loss: 0.0001897703332360834
step: 50, loss: 0.00296982005238533
step: 60, loss: 0.007122397422790527
step: 70, loss: 0.02167787030339241
step: 80, loss: 0.01614793762564659
step: 90, loss: 0.08264981955289841
step: 100, loss: 0.06641927361488342
step: 110, loss: 0.047245170921087265
step: 120, loss: 0.0033847952727228403
step: 130, loss: 0.014003862626850605
step: 140, loss: 0.006737728603184223
step: 150, loss: 0.10447632521390915
step: 160, loss: 0.037665195763111115
step: 170, loss: 0.038727134466171265
step: 180, loss: 0.010724948719143867
step: 190, loss: 0.06936141103506088
step: 200, loss: 0.01468847319483757
step: 210, loss: 0.0033064221497625113
step: 220, loss: 0.04601418599486351
step: 230, loss: 0.11709646880626678
step: 240, loss: 0.015996014699339867
step: 250, loss: 0.044700559228658676
step: 260, loss: 0.10052231699228287
step: 270, loss: 0.041504763066768646
step: 280, loss: 0.07643722742795944
step: 290, loss: 0.01858506351709366
step: 300, loss: 0.0031537965405732393
step: 310, loss: 0.0060820491053164005
step: 320, loss: 0.006791774183511734
step: 330, loss: 0.020086806267499924
step: 340, loss: 0.009018979035317898
step: 350, loss: 0.07587850093841553
step: 360, loss: 0.005568439606577158
epoch 11: dev_f1=0.7519582245430808, f1=0.7297297297297297, best_f1=0.7561643835616437
step: 0, loss: 0.024873249232769012
step: 10, loss: 0.007713443599641323
step: 20, loss: 0.006235166452825069
step: 30, loss: 0.014393524266779423
step: 40, loss: 0.044101279228925705
step: 50, loss: 7.42705597076565e-05
step: 60, loss: 0.006220437586307526
step: 70, loss: 0.008999088779091835
step: 80, loss: 0.003219430334866047
step: 90, loss: 0.0014965595910325646
step: 100, loss: 0.01147691160440445
step: 110, loss: 0.06192360818386078
step: 120, loss: 0.07317346334457397
step: 130, loss: 0.03823332488536835
step: 140, loss: 0.011512856930494308
step: 150, loss: 0.10491969436407089
step: 160, loss: 0.11863884329795837
step: 170, loss: 0.04809315502643585
step: 180, loss: 0.04030705615878105
step: 190, loss: 0.04428582265973091
step: 200, loss: 0.025410331785678864
step: 210, loss: 0.0031439231242984533
step: 220, loss: 0.011905759572982788
step: 230, loss: 0.052199892699718475
step: 240, loss: 0.009236159734427929
step: 250, loss: 3.7352430808823556e-05
step: 260, loss: 0.09192730486392975
step: 270, loss: 0.04333667457103729
step: 280, loss: 0.0748317763209343
step: 290, loss: 0.010641582310199738
step: 300, loss: 0.027774937450885773
step: 310, loss: 0.0009787797462195158
step: 320, loss: 0.03124331310391426
step: 330, loss: 0.006540251895785332
step: 340, loss: 0.027468282729387283
step: 350, loss: 0.028877628967165947
step: 360, loss: 0.012007014825940132
epoch 12: dev_f1=0.7480106100795757, f1=0.7675070028011204, best_f1=0.7561643835616437
step: 0, loss: 0.08947305381298065
step: 10, loss: 0.021820444613695145
step: 20, loss: 0.026545556262135506
step: 30, loss: 0.00239930534735322
step: 40, loss: 0.0033210422843694687
step: 50, loss: 0.0004851249686907977
step: 60, loss: 0.05732344090938568
step: 70, loss: 0.001880389405414462
step: 80, loss: 0.001080974005162716
step: 90, loss: 0.03315792232751846
step: 100, loss: 0.021542754024267197
step: 110, loss: 0.05609295144677162
step: 120, loss: 0.025183873251080513
step: 130, loss: 0.0022538763005286455
step: 140, loss: 0.021672140806913376
step: 150, loss: 0.06685984134674072
step: 160, loss: 3.192445001332089e-05
step: 170, loss: 0.01925189048051834
step: 180, loss: 0.001043904572725296
step: 190, loss: 0.05297710746526718
step: 200, loss: 0.002866994356736541
step: 210, loss: 4.3689822632586583e-05
step: 220, loss: 0.0012231292203068733
step: 230, loss: 0.10747449845075607
step: 240, loss: 0.0019576624035835266
step: 250, loss: 0.04906930774450302
step: 260, loss: 0.052986931055784225
step: 270, loss: 0.0012054009130224586
step: 280, loss: 0.010773173533380032
step: 290, loss: 0.01668313518166542
step: 300, loss: 0.038661353290081024
step: 310, loss: 0.0004729683278128505
step: 320, loss: 0.022236516699194908
step: 330, loss: 7.212444324977696e-05
step: 340, loss: 0.005711764562875032
step: 350, loss: 0.06189446523785591
step: 360, loss: 0.006838344503194094
epoch 13: dev_f1=0.7598944591029023, f1=0.7486033519553073, best_f1=0.7561643835616437
step: 0, loss: 3.4505956136854365e-05
step: 10, loss: 0.07288005948066711
step: 20, loss: 0.02049802988767624
step: 30, loss: 9.435982065042481e-05
step: 40, loss: 0.0013683178694918752
step: 50, loss: 0.0012503653997555375
step: 60, loss: 0.000312550226226449
step: 70, loss: 0.028232507407665253
step: 80, loss: 0.04387487843632698
step: 90, loss: 0.0017666140338405967
step: 100, loss: 0.014811279252171516
step: 110, loss: 0.05095572769641876
step: 120, loss: 0.016188953071832657
step: 130, loss: 0.01717127300798893
step: 140, loss: 0.010917228646576405
step: 150, loss: 0.027861706912517548
step: 160, loss: 0.015811040997505188
step: 170, loss: 0.06251516193151474
step: 180, loss: 0.03305456414818764
step: 190, loss: 0.006069234572350979
step: 200, loss: 0.0016133328899741173
step: 210, loss: 0.0027684324886649847
step: 220, loss: 0.07057173550128937
step: 230, loss: 0.006393143907189369
step: 240, loss: 0.015066198073327541
step: 250, loss: 0.012362126260995865
step: 260, loss: 0.030432119965553284
step: 270, loss: 0.018960751593112946
step: 280, loss: 0.004181391559541225
step: 290, loss: 0.034769490361213684
step: 300, loss: 0.029485415667295456
step: 310, loss: 5.776837497251108e-05
step: 320, loss: 0.046382419764995575
step: 330, loss: 5.8342822740087286e-05
step: 340, loss: 0.04884067550301552
step: 350, loss: 0.0064161717891693115
step: 360, loss: 0.21224159002304077
epoch 14: dev_f1=0.7626666666666667, f1=0.7520891364902507, best_f1=0.7561643835616437
step: 0, loss: 0.0001567950821481645
step: 10, loss: 0.02757493034005165
step: 20, loss: 0.05948646739125252
step: 30, loss: 0.0040412284433841705
step: 40, loss: 0.08358024060726166
step: 50, loss: 0.027405159547924995
step: 60, loss: 0.023932423442602158
step: 70, loss: 0.0008218596340157092
step: 80, loss: 0.001154150813817978
step: 90, loss: 0.023120639845728874
step: 100, loss: 0.010795030742883682
step: 110, loss: 0.028575217351317406
step: 120, loss: 0.11745969951152802
step: 130, loss: 0.0002685119106899947
step: 140, loss: 0.09836014360189438
step: 150, loss: 0.005048735998570919
step: 160, loss: 0.018111221492290497
step: 170, loss: 0.06791704148054123
step: 180, loss: 0.002315741265192628
step: 190, loss: 0.11742709577083588
step: 200, loss: 0.0660410225391388
step: 210, loss: 2.6541902116150595e-05
step: 220, loss: 0.00026596602401696146
step: 230, loss: 0.010854333639144897
step: 240, loss: 0.02384643442928791
step: 250, loss: 0.0001281117438338697
step: 260, loss: 0.05031413584947586
step: 270, loss: 3.2036154152592644e-05
step: 280, loss: 0.0004776179266627878
step: 290, loss: 0.03012089617550373
step: 300, loss: 0.027571413666009903
step: 310, loss: 0.02631520852446556
step: 320, loss: 0.01968788541853428
step: 330, loss: 0.017165042459964752
step: 340, loss: 0.0028328504413366318
step: 350, loss: 0.004619881510734558
step: 360, loss: 0.007853560149669647
epoch 15: dev_f1=0.7421052631578948, f1=0.7403314917127072, best_f1=0.7561643835616437
step: 0, loss: 0.001450993469916284
step: 10, loss: 0.00453636609017849
step: 20, loss: 0.07438714802265167
step: 30, loss: 0.049427807331085205
step: 40, loss: 5.2843664889223874e-05
step: 50, loss: 0.02634616382420063
step: 60, loss: 0.01644108258187771
step: 70, loss: 0.00014063343405723572
step: 80, loss: 1.9419730961089954e-05
step: 90, loss: 0.035429585725069046
step: 100, loss: 0.0037506402004510164
step: 110, loss: 0.002437171759083867
step: 120, loss: 0.0005228124791756272
step: 130, loss: 0.01498202234506607
step: 140, loss: 0.0594668835401535
step: 150, loss: 0.018683435395359993
step: 160, loss: 0.014244623482227325
step: 170, loss: 0.0005429363809525967
step: 180, loss: 0.04490993544459343
step: 190, loss: 0.024032769724726677
step: 200, loss: 5.0555441703181714e-05
step: 210, loss: 0.020293772220611572
step: 220, loss: 0.005102707538753748
step: 230, loss: 0.018375158309936523
step: 240, loss: 0.08327946811914444
step: 250, loss: 0.0022215794306248426
step: 260, loss: 0.014467807486653328
step: 270, loss: 0.027028091251850128
step: 280, loss: 0.018150096759200096
step: 290, loss: 0.0539097934961319
step: 300, loss: 0.029427198693156242
step: 310, loss: 0.0009946575155481696
step: 320, loss: 0.055615607649087906
step: 330, loss: 0.016585296019911766
step: 340, loss: 0.012321015819907188
step: 350, loss: 0.052781473845243454
step: 360, loss: 0.04387481510639191
epoch 16: dev_f1=0.7466666666666666, f1=0.747191011235955, best_f1=0.7561643835616437
step: 0, loss: 0.18200917541980743
step: 10, loss: 0.03222735598683357
step: 20, loss: 0.01558462344110012
step: 30, loss: 0.0665656104683876
step: 40, loss: 3.3667914976831526e-05
step: 50, loss: 0.011991997249424458
step: 60, loss: 2.4660952476551756e-05
step: 70, loss: 0.028621815145015717
step: 80, loss: 4.167895167483948e-05
step: 90, loss: 0.00840121041983366
step: 100, loss: 0.05839337036013603
step: 110, loss: 0.08269604295492172
step: 120, loss: 2.313735785719473e-05
step: 130, loss: 0.0005993666709400713
step: 140, loss: 0.02551271580159664
step: 150, loss: 9.683921234682202e-05
step: 160, loss: 0.00038905165274627507
step: 170, loss: 0.04319056496024132
step: 180, loss: 0.025600740686058998
step: 190, loss: 0.04062087833881378
step: 200, loss: 0.019481724128127098
step: 210, loss: 0.0424199178814888
step: 220, loss: 0.07937545329332352
step: 230, loss: 0.011153833009302616
step: 240, loss: 3.08583075820934e-05
step: 250, loss: 0.0044640745036304
step: 260, loss: 0.051571156829595566
step: 270, loss: 0.00014996965182945132
step: 280, loss: 0.02315378747880459
step: 290, loss: 0.0027463375590741634
step: 300, loss: 0.007452366407960653
step: 310, loss: 1.9684153812704608e-05
step: 320, loss: 0.03703949227929115
step: 330, loss: 0.0096454918384552
step: 340, loss: 0.024436326697468758
step: 350, loss: 0.07785894721746445
step: 360, loss: 0.004851167090237141
epoch 17: dev_f1=0.7540983606557378, f1=0.7392550143266476, best_f1=0.7561643835616437
step: 0, loss: 0.00011682455078698695
step: 10, loss: 0.0008826832054182887
step: 20, loss: 0.00024147516523953527
step: 30, loss: 0.002211937215179205
step: 40, loss: 0.0025605540722608566
step: 50, loss: 0.03246030956506729
step: 60, loss: 0.022623848170042038
step: 70, loss: 0.002929793670773506
step: 80, loss: 0.012687096372246742
step: 90, loss: 0.004849628079682589
step: 100, loss: 0.04314228892326355
step: 110, loss: 0.00036684656515717506
step: 120, loss: 0.0001656875101616606
step: 130, loss: 0.0001319013099418953
step: 140, loss: 0.004764254670590162
step: 150, loss: 0.054616257548332214
step: 160, loss: 0.04265426844358444
step: 170, loss: 0.0008384164539165795
step: 180, loss: 0.011954263783991337
step: 190, loss: 2.7468624466564506e-05
step: 200, loss: 9.662681259214878e-05
step: 210, loss: 0.024739986285567284
step: 220, loss: 0.021604333072900772
step: 230, loss: 0.0002012592158280313
step: 240, loss: 0.064140185713768
step: 250, loss: 5.899826646782458e-05
step: 260, loss: 0.029577212408185005
step: 270, loss: 0.04041047766804695
step: 280, loss: 0.000962897960562259
step: 290, loss: 0.011953114531934261
step: 300, loss: 0.002704046433791518
step: 310, loss: 0.019989242777228355
step: 320, loss: 0.006130042020231485
step: 330, loss: 0.02179579995572567
step: 340, loss: 0.030110647901892662
step: 350, loss: 0.03944626823067665
step: 360, loss: 0.022466976195573807
epoch 18: dev_f1=0.743661971830986, f1=0.7267441860465116, best_f1=0.7561643835616437
step: 0, loss: 0.024643942713737488
step: 10, loss: 0.023373622447252274
step: 20, loss: 0.03605353459715843
step: 30, loss: 0.0002552302030380815
step: 40, loss: 0.0004095063195563853
step: 50, loss: 0.016801804304122925
step: 60, loss: 0.04556163027882576
step: 70, loss: 0.026146259158849716
step: 80, loss: 0.00043691956670954823
step: 90, loss: 0.00047934497706592083
step: 100, loss: 0.024020420387387276
step: 110, loss: 0.00011732162238331512
step: 120, loss: 0.0012328261509537697
step: 130, loss: 0.023608343675732613
step: 140, loss: 0.0004978589713573456
step: 150, loss: 0.000134194633574225
step: 160, loss: 0.018738610669970512
step: 170, loss: 0.028855662792921066
step: 180, loss: 3.448697680141777e-05
step: 190, loss: 0.00011525192530825734
step: 200, loss: 0.0036876434460282326
step: 210, loss: 0.030120428651571274
step: 220, loss: 0.020408110693097115
step: 230, loss: 1.8510758309275843e-05
step: 240, loss: 2.438154479023069e-05
step: 250, loss: 9.757007501320913e-05
step: 260, loss: 0.043247442692518234
step: 270, loss: 0.02361469529569149
step: 280, loss: 0.031476058065891266
step: 290, loss: 0.00018282278324477375
step: 300, loss: 0.02984376810491085
step: 310, loss: 0.01162138395011425
step: 320, loss: 0.031774941831827164
step: 330, loss: 0.04453088715672493
step: 340, loss: 0.00013409108214545995
step: 350, loss: 0.014500792138278484
step: 360, loss: 0.06482184678316116
epoch 19: dev_f1=0.7540983606557378, f1=0.7449856733524355, best_f1=0.7561643835616437
step: 0, loss: 0.02521669492125511
step: 10, loss: 0.01277082972228527
step: 20, loss: 0.02617037482559681
step: 30, loss: 0.0004449493426363915
step: 40, loss: 0.045949291437864304
step: 50, loss: 2.263446367578581e-05
step: 60, loss: 0.0003231869777664542
step: 70, loss: 0.006001549772918224
step: 80, loss: 0.016264498233795166
step: 90, loss: 3.0757619242649525e-05
step: 100, loss: 0.05556977540254593
step: 110, loss: 0.02153940312564373
step: 120, loss: 0.017649320885539055
step: 130, loss: 0.03967013955116272
step: 140, loss: 0.0369722880423069
step: 150, loss: 2.501860581105575e-05
step: 160, loss: 0.00030858637182973325
step: 170, loss: 0.1241891160607338
step: 180, loss: 0.033962104469537735
step: 190, loss: 0.01130541693419218
step: 200, loss: 0.03354043513536453
step: 210, loss: 0.038289401680231094
step: 220, loss: 0.0018280295189470053
step: 230, loss: 0.01835426688194275
step: 240, loss: 0.0004024237277917564
step: 250, loss: 0.012648707255721092
step: 260, loss: 2.727206992858555e-05
step: 270, loss: 1.9099354176432826e-05
step: 280, loss: 0.0004235927190165967
step: 290, loss: 0.02988707832992077
step: 300, loss: 0.045621875673532486
step: 310, loss: 0.04401593655347824
step: 320, loss: 1.9810844605672173e-05
step: 330, loss: 7.783762703184038e-05
step: 340, loss: 0.0017995131202042103
step: 350, loss: 0.031652506440877914
step: 360, loss: 0.0001052096631610766
epoch 20: dev_f1=0.7513513513513514, f1=0.7428571428571429, best_f1=0.7561643835616437
