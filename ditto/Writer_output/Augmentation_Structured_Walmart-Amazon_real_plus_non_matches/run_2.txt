cuda
Device: cuda
step: 0, loss: 0.7515438795089722
step: 10, loss: 0.37221893668174744
step: 20, loss: 0.1654752790927887
step: 30, loss: 0.023593004792928696
step: 40, loss: 0.23695603013038635
step: 50, loss: 0.16138707101345062
step: 60, loss: 0.023914512246847153
step: 70, loss: 0.04294711351394653
step: 80, loss: 0.2342282235622406
step: 90, loss: 0.14312958717346191
step: 100, loss: 0.23628951609134674
step: 110, loss: 0.13570989668369293
step: 120, loss: 0.1341429501771927
step: 130, loss: 0.2303355485200882
step: 140, loss: 0.13571366667747498
step: 150, loss: 0.2444836050271988
step: 160, loss: 0.12942466139793396
step: 170, loss: 0.21815651655197144
step: 180, loss: 0.15326137840747833
step: 190, loss: 0.22813892364501953
step: 200, loss: 0.15378053486347198
step: 210, loss: 0.5379854440689087
step: 220, loss: 0.22264347970485687
step: 230, loss: 0.21896220743656158
step: 240, loss: 0.17137892544269562
step: 250, loss: 0.01753121241927147
step: 260, loss: 0.14886268973350525
step: 270, loss: 0.08802464604377747
step: 280, loss: 0.11997730284929276
step: 290, loss: 0.11874684691429138
step: 300, loss: 0.20930063724517822
step: 310, loss: 0.15408232808113098
step: 320, loss: 0.12407132238149643
step: 330, loss: 0.12412450462579727
step: 340, loss: 0.2151116132736206
step: 350, loss: 0.31132540106773376
step: 360, loss: 0.33965253829956055
epoch 1: dev_f1=0.6435643564356435, f1=0.6533665835411472, best_f1=0.6533665835411472
step: 0, loss: 0.1450025737285614
step: 10, loss: 0.270816832780838
step: 20, loss: 0.07163811475038528
step: 30, loss: 0.009360558353364468
step: 40, loss: 0.18601568043231964
step: 50, loss: 0.26904991269111633
step: 60, loss: 0.060609519481658936
step: 70, loss: 0.3931061625480652
step: 80, loss: 0.23580387234687805
step: 90, loss: 0.1452445387840271
step: 100, loss: 0.06799590587615967
step: 110, loss: 0.052990809082984924
step: 120, loss: 0.018174128606915474
step: 130, loss: 0.1439725011587143
step: 140, loss: 0.02091529220342636
step: 150, loss: 0.01828888989984989
step: 160, loss: 0.21973897516727448
step: 170, loss: 0.027524951845407486
step: 180, loss: 0.0817565992474556
step: 190, loss: 0.13574211299419403
step: 200, loss: 0.10561291873455048
step: 210, loss: 0.07372105866670609
step: 220, loss: 0.0281191598623991
step: 230, loss: 0.08612369745969772
step: 240, loss: 0.1054353266954422
step: 250, loss: 0.05920641869306564
step: 260, loss: 0.012580160982906818
step: 270, loss: 0.10137751698493958
step: 280, loss: 0.1639828383922577
step: 290, loss: 0.1527571827173233
step: 300, loss: 0.01898222044110298
step: 310, loss: 0.013330608606338501
step: 320, loss: 0.36264297366142273
step: 330, loss: 0.09396500140428543
step: 340, loss: 0.17536169290542603
step: 350, loss: 0.13715404272079468
step: 360, loss: 0.045041523873806
epoch 2: dev_f1=0.721311475409836, f1=0.7431693989071039, best_f1=0.7431693989071039
step: 0, loss: 0.08224369585514069
step: 10, loss: 0.08782120794057846
step: 20, loss: 0.04278860241174698
step: 30, loss: 0.04416686296463013
step: 40, loss: 0.07763618230819702
step: 50, loss: 0.04775935411453247
step: 60, loss: 0.07606205344200134
step: 70, loss: 0.31149059534072876
step: 80, loss: 0.04447853937745094
step: 90, loss: 0.09138808399438858
step: 100, loss: 0.020666640251874924
step: 110, loss: 0.043317634612321854
step: 120, loss: 0.010045530274510384
step: 130, loss: 0.05472169816493988
step: 140, loss: 0.07178496569395065
step: 150, loss: 0.18325360119342804
step: 160, loss: 0.08283980190753937
step: 170, loss: 0.03838055953383446
step: 180, loss: 0.28497764468193054
step: 190, loss: 0.16174186766147614
step: 200, loss: 0.11683390289545059
step: 210, loss: 0.04902048408985138
step: 220, loss: 0.1061488464474678
step: 230, loss: 0.12848901748657227
step: 240, loss: 0.05819812789559364
step: 250, loss: 0.08447795361280441
step: 260, loss: 0.015096430666744709
step: 270, loss: 0.10231835395097733
step: 280, loss: 0.17952661216259003
step: 290, loss: 0.13531073927879333
step: 300, loss: 0.030589908361434937
step: 310, loss: 0.06684248149394989
step: 320, loss: 0.03323635458946228
step: 330, loss: 0.06145273149013519
step: 340, loss: 0.03244062885642052
step: 350, loss: 0.08944596350193024
step: 360, loss: 0.10049061477184296
epoch 3: dev_f1=0.7666666666666667, f1=0.7262569832402234, best_f1=0.7262569832402234
step: 0, loss: 0.03584633395075798
step: 10, loss: 0.005796385928988457
step: 20, loss: 0.017713895067572594
step: 30, loss: 0.13867197930812836
step: 40, loss: 0.0894545167684555
step: 50, loss: 0.044798098504543304
step: 60, loss: 0.11974051594734192
step: 70, loss: 0.017150472849607468
step: 80, loss: 0.12332519888877869
step: 90, loss: 0.07998183369636536
step: 100, loss: 0.08602962642908096
step: 110, loss: 0.012429545633494854
step: 120, loss: 0.0004944122629240155
step: 130, loss: 0.05109675973653793
step: 140, loss: 0.08715663105249405
step: 150, loss: 0.13422338664531708
step: 160, loss: 0.09081530570983887
step: 170, loss: 0.24061577022075653
step: 180, loss: 0.10822054743766785
step: 190, loss: 0.09675747901201248
step: 200, loss: 0.057168588042259216
step: 210, loss: 0.04048996791243553
step: 220, loss: 0.11506536602973938
step: 230, loss: 0.02510177157819271
step: 240, loss: 0.030036119744181633
step: 250, loss: 0.09548373520374298
step: 260, loss: 0.07294752448797226
step: 270, loss: 0.056138522922992706
step: 280, loss: 0.06152350455522537
step: 290, loss: 0.17094339430332184
step: 300, loss: 0.11203192919492722
step: 310, loss: 0.18115265667438507
step: 320, loss: 0.028267452493309975
step: 330, loss: 0.025733282789587975
step: 340, loss: 0.09257011860609055
step: 350, loss: 0.14213919639587402
step: 360, loss: 0.12345589697360992
epoch 4: dev_f1=0.7183098591549296, f1=0.7358024691358025, best_f1=0.7262569832402234
step: 0, loss: 0.06306397914886475
step: 10, loss: 0.023828469216823578
step: 20, loss: 0.0015103730838745832
step: 30, loss: 0.024711664766073227
step: 40, loss: 0.07198257744312286
step: 50, loss: 0.0007419082103297114
step: 60, loss: 0.03995869681239128
step: 70, loss: 0.10181594640016556
step: 80, loss: 0.0007072709267958999
step: 90, loss: 0.04646223410964012
step: 100, loss: 0.03274579346179962
step: 110, loss: 0.05436164140701294
step: 120, loss: 0.0835694819688797
step: 130, loss: 0.10020732134580612
step: 140, loss: 0.01563088595867157
step: 150, loss: 0.1215319111943245
step: 160, loss: 0.06596988439559937
step: 170, loss: 0.0918312817811966
step: 180, loss: 0.08527187258005142
step: 190, loss: 0.08930971473455429
step: 200, loss: 0.056638773530721664
step: 210, loss: 0.06454448401927948
step: 220, loss: 0.01081688143312931
step: 230, loss: 0.2034435123205185
step: 240, loss: 0.04665420576930046
step: 250, loss: 0.3389168083667755
step: 260, loss: 0.04943236708641052
step: 270, loss: 0.04731181636452675
step: 280, loss: 0.03433706983923912
step: 290, loss: 0.02645472064614296
step: 300, loss: 0.03531434386968613
step: 310, loss: 0.08713521808385849
step: 320, loss: 0.03190328925848007
step: 330, loss: 0.029432766139507294
step: 340, loss: 0.0017828138079494238
step: 350, loss: 0.01599310338497162
step: 360, loss: 0.05021297186613083
epoch 5: dev_f1=0.7613941018766757, f1=0.7526881720430108, best_f1=0.7262569832402234
step: 0, loss: 0.005167193710803986
step: 10, loss: 0.027961745858192444
step: 20, loss: 0.0005973662482574582
step: 30, loss: 0.2093472182750702
step: 40, loss: 0.05251700058579445
step: 50, loss: 0.0033421360421925783
step: 60, loss: 0.07304453104734421
step: 70, loss: 0.04981214925646782
step: 80, loss: 0.01460194867104292
step: 90, loss: 0.002027104841545224
step: 100, loss: 0.04463471099734306
step: 110, loss: 0.009283261373639107
step: 120, loss: 0.0647730678319931
step: 130, loss: 0.013384665362536907
step: 140, loss: 0.06162178888916969
step: 150, loss: 0.05281565338373184
step: 160, loss: 0.035076677799224854
step: 170, loss: 0.009198732674121857
step: 180, loss: 0.10667635500431061
step: 190, loss: 0.10486190021038055
step: 200, loss: 0.05649859458208084
step: 210, loss: 0.15908703207969666
step: 220, loss: 0.03534761443734169
step: 230, loss: 0.029408257454633713
step: 240, loss: 0.08011092245578766
step: 250, loss: 0.018232956528663635
step: 260, loss: 0.053641628473997116
step: 270, loss: 0.006267996039241552
step: 280, loss: 0.04382551088929176
step: 290, loss: 0.1062830463051796
step: 300, loss: 0.0167605672031641
step: 310, loss: 0.059278421103954315
step: 320, loss: 0.08813169598579407
step: 330, loss: 0.008732943795621395
step: 340, loss: 0.0225671473890543
step: 350, loss: 0.02760702185332775
step: 360, loss: 0.02810848318040371
epoch 6: dev_f1=0.7005347593582888, f1=0.6978021978021979, best_f1=0.7262569832402234
step: 0, loss: 0.09272988140583038
step: 10, loss: 0.09250600636005402
step: 20, loss: 0.011732292361557484
step: 30, loss: 0.06785192340612411
step: 40, loss: 0.00036195683060213923
step: 50, loss: 0.0008388606947846711
step: 60, loss: 0.1725056916475296
step: 70, loss: 0.017574531957507133
step: 80, loss: 0.07067882269620895
step: 90, loss: 0.09504890441894531
step: 100, loss: 0.05461584031581879
step: 110, loss: 0.027263810858130455
step: 120, loss: 0.017865069210529327
step: 130, loss: 0.20623236894607544
step: 140, loss: 0.02378002367913723
step: 150, loss: 0.03621486574411392
step: 160, loss: 0.03813480958342552
step: 170, loss: 0.09856437146663666
step: 180, loss: 0.0831926167011261
step: 190, loss: 0.0019827329088002443
step: 200, loss: 0.02245158702135086
step: 210, loss: 0.03795435652136803
step: 220, loss: 0.047246113419532776
step: 230, loss: 0.012560120783746243
step: 240, loss: 0.034405969083309174
step: 250, loss: 0.07611388713121414
step: 260, loss: 0.0667077824473381
step: 270, loss: 0.10570232570171356
step: 280, loss: 0.02659074030816555
step: 290, loss: 0.055011384189128876
step: 300, loss: 0.16831621527671814
step: 310, loss: 0.0767965242266655
step: 320, loss: 0.04514601081609726
step: 330, loss: 0.016162084415555
step: 340, loss: 0.02184363268315792
step: 350, loss: 0.09414909034967422
step: 360, loss: 0.09653046727180481
epoch 7: dev_f1=0.7461139896373058, f1=0.7291666666666667, best_f1=0.7262569832402234
step: 0, loss: 0.018578123301267624
step: 10, loss: 0.08304090797901154
step: 20, loss: 0.042988695204257965
step: 30, loss: 0.0001435394660802558
step: 40, loss: 0.07139185816049576
step: 50, loss: 0.005951285362243652
step: 60, loss: 0.0317540168762207
step: 70, loss: 0.010597488842904568
step: 80, loss: 0.03332589939236641
step: 90, loss: 0.039761368185281754
step: 100, loss: 0.006814834661781788
step: 110, loss: 0.07037265598773956
step: 120, loss: 0.040789443999528885
step: 130, loss: 0.034628093242645264
step: 140, loss: 0.03383919224143028
step: 150, loss: 0.027313074097037315
step: 160, loss: 0.08404234051704407
step: 170, loss: 0.07522986084222794
step: 180, loss: 0.024115663021802902
step: 190, loss: 0.012432808987796307
step: 200, loss: 0.025886205956339836
step: 210, loss: 0.0044056992046535015
step: 220, loss: 0.04878001660108566
step: 230, loss: 0.020226720720529556
step: 240, loss: 0.08035165071487427
step: 250, loss: 0.04569350928068161
step: 260, loss: 0.04057260602712631
step: 270, loss: 0.0042688860557973385
step: 280, loss: 0.07667770981788635
step: 290, loss: 0.017884427681565285
step: 300, loss: 0.16563788056373596
step: 310, loss: 0.042622629553079605
step: 320, loss: 0.08567360788583755
step: 330, loss: 0.08024343103170395
step: 340, loss: 0.03870588168501854
step: 350, loss: 0.026590906083583832
step: 360, loss: 0.020069438964128494
epoch 8: dev_f1=0.7228260869565217, f1=0.7206703910614525, best_f1=0.7262569832402234
step: 0, loss: 0.0956166461110115
step: 10, loss: 0.0651368796825409
step: 20, loss: 0.10077036172151566
step: 30, loss: 5.294122456689365e-05
step: 40, loss: 4.179996540187858e-05
step: 50, loss: 0.01660376787185669
step: 60, loss: 0.0636679083108902
step: 70, loss: 0.032971106469631195
step: 80, loss: 0.012884175404906273
step: 90, loss: 0.13034740090370178
step: 100, loss: 0.05191055312752724
step: 110, loss: 0.025539904832839966
step: 120, loss: 0.030249565839767456
step: 130, loss: 0.06703604757785797
step: 140, loss: 0.0643981322646141
step: 150, loss: 0.006982781924307346
step: 160, loss: 0.14492462575435638
step: 170, loss: 0.03008272312581539
step: 180, loss: 0.023478440940380096
step: 190, loss: 0.0023493540938943624
step: 200, loss: 0.033308614045381546
step: 210, loss: 0.042430102825164795
step: 220, loss: 0.013936764560639858
step: 230, loss: 0.08705928921699524
step: 240, loss: 0.003707245225086808
step: 250, loss: 0.081853486597538
step: 260, loss: 0.016852792352437973
step: 270, loss: 0.0626545250415802
step: 280, loss: 0.021979475393891335
step: 290, loss: 0.010013780556619167
step: 300, loss: 0.007879222743213177
step: 310, loss: 0.02849895879626274
step: 320, loss: 0.06979263573884964
step: 330, loss: 0.013843631371855736
step: 340, loss: 0.0489046573638916
step: 350, loss: 0.1265733689069748
step: 360, loss: 0.04115873947739601
epoch 9: dev_f1=0.7354497354497355, f1=0.7204301075268816, best_f1=0.7262569832402234
step: 0, loss: 0.0036714542657136917
step: 10, loss: 0.10505031049251556
step: 20, loss: 0.07233557850122452
step: 30, loss: 0.05898800119757652
step: 40, loss: 0.01026446558535099
step: 50, loss: 0.09103579074144363
step: 60, loss: 0.06993810832500458
step: 70, loss: 0.03334728255867958
step: 80, loss: 0.001156692742370069
step: 90, loss: 0.06341331452131271
step: 100, loss: 0.03217965364456177
step: 110, loss: 0.00697623984888196
step: 120, loss: 9.949107334250584e-05
step: 130, loss: 0.007125800475478172
step: 140, loss: 0.03751518949866295
step: 150, loss: 0.020755216479301453
step: 160, loss: 0.003756156424060464
step: 170, loss: 0.030585963279008865
step: 180, loss: 0.02139563485980034
step: 190, loss: 0.1672419160604477
step: 200, loss: 0.04248534515500069
step: 210, loss: 0.004319935105741024
step: 220, loss: 0.011843603104352951
step: 230, loss: 0.07052186876535416
step: 240, loss: 0.01697472110390663
step: 250, loss: 0.010503347963094711
step: 260, loss: 0.027939805760979652
step: 270, loss: 0.013132908381521702
step: 280, loss: 0.007192693650722504
step: 290, loss: 0.007363201584666967
step: 300, loss: 0.061571989208459854
step: 310, loss: 0.013090286403894424
step: 320, loss: 0.04358517751097679
step: 330, loss: 0.17211243510246277
step: 340, loss: 0.057409051805734634
step: 350, loss: 0.030208926647901535
step: 360, loss: 0.003479653038084507
epoch 10: dev_f1=0.721311475409836, f1=0.7236467236467237, best_f1=0.7262569832402234
step: 0, loss: 0.0006435772520489991
step: 10, loss: 0.005315626971423626
step: 20, loss: 0.0046666464768350124
step: 30, loss: 0.050744593143463135
step: 40, loss: 0.022005882114171982
step: 50, loss: 0.0442846305668354
step: 60, loss: 0.0480387918651104
step: 70, loss: 0.0018579913303256035
step: 80, loss: 0.01805226132273674
step: 90, loss: 0.008771521970629692
step: 100, loss: 0.23458324372768402
step: 110, loss: 0.013245404697954655
step: 120, loss: 0.01849399320781231
step: 130, loss: 0.03549424558877945
step: 140, loss: 0.05093428120017052
step: 150, loss: 0.012893148697912693
step: 160, loss: 0.11190658062696457
step: 170, loss: 0.003533551935106516
step: 180, loss: 0.05098820850253105
step: 190, loss: 0.08934024721384048
step: 200, loss: 0.0030134778935462236
step: 210, loss: 0.07609658688306808
step: 220, loss: 0.005319321993738413
step: 230, loss: 0.050905246287584305
step: 240, loss: 0.12244774401187897
step: 250, loss: 0.04858653247356415
step: 260, loss: 0.07688025385141373
step: 270, loss: 0.047383107244968414
step: 280, loss: 0.01187127735465765
step: 290, loss: 0.004310288466513157
step: 300, loss: 0.009509257040917873
step: 310, loss: 0.01772928237915039
step: 320, loss: 0.0009623310179449618
step: 330, loss: 0.0040364135056734085
step: 340, loss: 0.06619805097579956
step: 350, loss: 0.03687767684459686
step: 360, loss: 0.06282366067171097
epoch 11: dev_f1=0.7216494845360825, f1=0.7204301075268816, best_f1=0.7262569832402234
step: 0, loss: 0.04935452714562416
step: 10, loss: 0.02734106406569481
step: 20, loss: 0.028774945065379143
step: 30, loss: 0.002576070139184594
step: 40, loss: 0.0012245478574186563
step: 50, loss: 0.030705388635396957
step: 60, loss: 0.01822405867278576
step: 70, loss: 0.0010198346571996808
step: 80, loss: 0.009454264305531979
step: 90, loss: 0.01602802611887455
step: 100, loss: 0.005464234855026007
step: 110, loss: 0.001399804139509797
step: 120, loss: 0.05381195619702339
step: 130, loss: 0.06619161367416382
step: 140, loss: 0.0448148250579834
step: 150, loss: 0.04307900369167328
step: 160, loss: 0.019025582820177078
step: 170, loss: 0.011464291252195835
step: 180, loss: 0.08573885262012482
step: 190, loss: 0.0010776867857202888
step: 200, loss: 0.01319477055221796
step: 210, loss: 0.01740565150976181
step: 220, loss: 0.0019024754874408245
step: 230, loss: 0.03732684999704361
step: 240, loss: 0.0017755774315446615
step: 250, loss: 0.06936971843242645
step: 260, loss: 0.006728533189743757
step: 270, loss: 0.06822826713323593
step: 280, loss: 0.0005658255540765822
step: 290, loss: 0.05878806859254837
step: 300, loss: 0.015143054537475109
step: 310, loss: 0.008052252233028412
step: 320, loss: 0.011253430508077145
step: 330, loss: 0.05020773410797119
step: 340, loss: 0.0061633712612092495
step: 350, loss: 7.795315468683839e-05
step: 360, loss: 0.06779677420854568
epoch 12: dev_f1=0.6898550724637681, f1=0.6943620178041544, best_f1=0.7262569832402234
step: 0, loss: 0.00010106674017151818
step: 10, loss: 0.0029946782160550356
step: 20, loss: 0.028015580028295517
step: 30, loss: 0.0003254040493629873
step: 40, loss: 0.008754147216677666
step: 50, loss: 0.009862614795565605
step: 60, loss: 0.01893446408212185
step: 70, loss: 0.05804070457816124
step: 80, loss: 0.000267081952188164
step: 90, loss: 0.03745719790458679
step: 100, loss: 0.001619409886188805
step: 110, loss: 0.07503856718540192
step: 120, loss: 0.024942150339484215
step: 130, loss: 0.010414808988571167
step: 140, loss: 0.023937903344631195
step: 150, loss: 0.012528295628726482
step: 160, loss: 0.006697615142911673
step: 170, loss: 0.016002245247364044
step: 180, loss: 0.002054307609796524
step: 190, loss: 0.027861295267939568
step: 200, loss: 0.08991668373346329
step: 210, loss: 0.015440165065228939
step: 220, loss: 0.0008353656739927828
step: 230, loss: 0.004745079204440117
step: 240, loss: 0.03512364625930786
step: 250, loss: 0.007825043983757496
step: 260, loss: 0.003562019905075431
step: 270, loss: 0.004418815486133099
step: 280, loss: 3.966474469052628e-05
step: 290, loss: 0.006710678339004517
step: 300, loss: 0.023057596758008003
step: 310, loss: 0.18198272585868835
step: 320, loss: 0.003550541354343295
step: 330, loss: 0.0013493770966306329
step: 340, loss: 0.09366578608751297
step: 350, loss: 0.011011443100869656
step: 360, loss: 0.0637468546628952
epoch 13: dev_f1=0.746031746031746, f1=0.7146814404432134, best_f1=0.7262569832402234
step: 0, loss: 0.07099200040102005
step: 10, loss: 0.004050040617585182
step: 20, loss: 0.010142154060304165
step: 30, loss: 0.004217027220875025
step: 40, loss: 0.07397717237472534
step: 50, loss: 0.0024144246708601713
step: 60, loss: 4.675051968661137e-05
step: 70, loss: 0.019461603835225105
step: 80, loss: 0.0009563531493768096
step: 90, loss: 3.2553463825024664e-05
step: 100, loss: 0.0012335494393482804
step: 110, loss: 0.024399928748607635
step: 120, loss: 0.019204692915081978
step: 130, loss: 0.06005188450217247
step: 140, loss: 0.056874830275774
step: 150, loss: 0.04226378723978996
step: 160, loss: 0.10462930798530579
step: 170, loss: 0.0004108374996576458
step: 180, loss: 0.0065719205886125565
step: 190, loss: 0.00012901290028821677
step: 200, loss: 0.012513160705566406
step: 210, loss: 0.034860871732234955
step: 220, loss: 0.00044828999671153724
step: 230, loss: 0.0021833551581948996
step: 240, loss: 0.05418289825320244
step: 250, loss: 6.941119499970227e-05
step: 260, loss: 0.00036145272315479815
step: 270, loss: 0.00048088488983921707
step: 280, loss: 0.0036044956650584936
step: 290, loss: 0.010091261006891727
step: 300, loss: 0.06802626699209213
step: 310, loss: 0.010420856066048145
step: 320, loss: 0.00020464102271944284
step: 330, loss: 0.081149160861969
step: 340, loss: 0.053464125841856
step: 350, loss: 0.08433239161968231
step: 360, loss: 0.09726668894290924
epoch 14: dev_f1=0.7214854111405835, f1=0.6855524079320112, best_f1=0.7262569832402234
step: 0, loss: 0.02661447413265705
step: 10, loss: 0.0020613675005733967
step: 20, loss: 0.0009798158425837755
step: 30, loss: 0.02215094119310379
step: 40, loss: 0.008543601259589195
step: 50, loss: 0.0023262605536729097
step: 60, loss: 0.03718293085694313
step: 70, loss: 0.005802077706903219
step: 80, loss: 0.02146226540207863
step: 90, loss: 0.00018840179836843163
step: 100, loss: 0.03487939015030861
step: 110, loss: 0.0026389912236481905
step: 120, loss: 0.0003007370396517217
step: 130, loss: 5.525494634639472e-05
step: 140, loss: 0.057373493909835815
step: 150, loss: 0.022197764366865158
step: 160, loss: 0.0013550518779084086
step: 170, loss: 0.001226706081070006
step: 180, loss: 0.00021356357319746166
step: 190, loss: 3.555227885954082e-05
step: 200, loss: 0.000623998639639467
step: 210, loss: 0.000621150596998632
step: 220, loss: 0.0010060399072244763
step: 230, loss: 0.015406426973640919
step: 240, loss: 0.02647891268134117
step: 250, loss: 0.0006122955237515271
step: 260, loss: 0.0005940936971455812
step: 270, loss: 0.061572372913360596
step: 280, loss: 0.038187768310308456
step: 290, loss: 0.03311576694250107
step: 300, loss: 0.03701500967144966
step: 310, loss: 0.05574183166027069
step: 320, loss: 0.0028995147440582514
step: 330, loss: 0.15296611189842224
step: 340, loss: 3.40535152645316e-05
step: 350, loss: 0.0012695365585386753
step: 360, loss: 0.061219412833452225
epoch 15: dev_f1=0.7052631578947368, f1=0.6942148760330578, best_f1=0.7262569832402234
step: 0, loss: 0.0754338949918747
step: 10, loss: 0.000737279187887907
step: 20, loss: 0.0007093565072864294
step: 30, loss: 0.0013904046500101686
step: 40, loss: 0.0513959676027298
step: 50, loss: 0.0019608894363045692
step: 60, loss: 0.010484995320439339
step: 70, loss: 0.0002514267689548433
step: 80, loss: 0.03940315172076225
step: 90, loss: 0.042588550597429276
step: 100, loss: 4.6849258069414645e-05
step: 110, loss: 0.0006907936767674983
step: 120, loss: 0.010390576906502247
step: 130, loss: 0.024838043376803398
step: 140, loss: 0.01458918396383524
step: 150, loss: 0.036584652960300446
step: 160, loss: 0.05943801999092102
step: 170, loss: 0.03429647535085678
step: 180, loss: 0.0004895199672318995
step: 190, loss: 0.0006252891034819186
step: 200, loss: 0.041573815047740936
step: 210, loss: 0.0011603288585320115
step: 220, loss: 0.0030450851190835238
step: 230, loss: 0.04872557520866394
step: 240, loss: 0.009592615999281406
step: 250, loss: 0.000527929631061852
step: 260, loss: 0.0010624475544318557
step: 270, loss: 0.03415427356958389
step: 280, loss: 0.022013256326317787
step: 290, loss: 0.00332687608897686
step: 300, loss: 0.003338887821882963
step: 310, loss: 0.015187597833573818
step: 320, loss: 0.024897873401641846
step: 330, loss: 0.0010438355384394526
step: 340, loss: 0.0002423419209662825
step: 350, loss: 0.0002834626939147711
step: 360, loss: 0.0001233443181263283
epoch 16: dev_f1=0.7068062827225131, f1=0.6939890710382514, best_f1=0.7262569832402234
step: 0, loss: 0.02356640063226223
step: 10, loss: 7.441621710313484e-05
step: 20, loss: 0.005187186412513256
step: 30, loss: 0.014628968201577663
step: 40, loss: 0.042492687702178955
step: 50, loss: 0.00010945517715299502
step: 60, loss: 9.746696014190093e-05
step: 70, loss: 0.020845018327236176
step: 80, loss: 0.019607361406087875
step: 90, loss: 0.0001700296124909073
step: 100, loss: 0.00022876383445691317
step: 110, loss: 0.00038961137761361897
step: 120, loss: 0.0022250295151025057
step: 130, loss: 9.069271618500352e-05
step: 140, loss: 0.04190180078148842
step: 150, loss: 0.011738688684999943
step: 160, loss: 0.029284311458468437
step: 170, loss: 0.0011424206895753741
step: 180, loss: 0.015960149466991425
step: 190, loss: 0.001691223937086761
step: 200, loss: 0.037190645933151245
step: 210, loss: 0.04035249352455139
step: 220, loss: 0.00039198333979584277
step: 230, loss: 0.027278058230876923
step: 240, loss: 0.005815248005092144
step: 250, loss: 1.9665567378979176e-05
step: 260, loss: 0.003136914223432541
step: 270, loss: 0.011213850229978561
step: 280, loss: 0.07842390984296799
step: 290, loss: 0.03401092812418938
step: 300, loss: 0.07319401949644089
step: 310, loss: 0.012942171655595303
step: 320, loss: 0.051579032093286514
step: 330, loss: 0.0043071419931948185
step: 340, loss: 0.006658637896180153
step: 350, loss: 0.0030904454179108143
step: 360, loss: 0.020581388846039772
epoch 17: dev_f1=0.7131367292225201, f1=0.6763848396501457, best_f1=0.7262569832402234
step: 0, loss: 0.05985196307301521
step: 10, loss: 0.00012538993905764073
step: 20, loss: 0.009118830785155296
step: 30, loss: 0.01771606132388115
step: 40, loss: 0.0013387725921347737
step: 50, loss: 0.0016093269223347306
step: 60, loss: 0.01121827494353056
step: 70, loss: 0.0188580509275198
step: 80, loss: 0.04537906125187874
step: 90, loss: 0.020347176119685173
step: 100, loss: 3.4449814847903326e-05
step: 110, loss: 0.004531983286142349
step: 120, loss: 0.019761785864830017
step: 130, loss: 0.025706734508275986
step: 140, loss: 0.00020260126620996743
step: 150, loss: 2.9089707823004574e-05
step: 160, loss: 3.291733082733117e-05
step: 170, loss: 0.002018909202888608
step: 180, loss: 0.0007237079553306103
step: 190, loss: 0.020415429025888443
step: 200, loss: 0.0025793705135583878
step: 210, loss: 0.023791424930095673
step: 220, loss: 0.03275027871131897
step: 230, loss: 0.006109185051172972
step: 240, loss: 0.000543671369086951
step: 250, loss: 0.0016619781963527203
step: 260, loss: 0.006385209038853645
step: 270, loss: 0.011483467184007168
step: 280, loss: 0.041632287204265594
step: 290, loss: 0.024521218612790108
step: 300, loss: 6.634969031438231e-05
step: 310, loss: 0.00016657725791446865
step: 320, loss: 0.024281548336148262
step: 330, loss: 0.033403441309928894
step: 340, loss: 0.006695512682199478
step: 350, loss: 0.002809590194374323
step: 360, loss: 0.008419026620686054
epoch 18: dev_f1=0.7018469656992085, f1=0.6910112359550561, best_f1=0.7262569832402234
step: 0, loss: 0.00017959167598746717
step: 10, loss: 0.023180613294243813
step: 20, loss: 0.0001074361425708048
step: 30, loss: 3.14434728352353e-05
step: 40, loss: 0.009129848331212997
step: 50, loss: 0.00010658193059498444
step: 60, loss: 1.4874961379973684e-05
step: 70, loss: 0.0049197375774383545
step: 80, loss: 0.05561757832765579
step: 90, loss: 0.05345860496163368
step: 100, loss: 1.7829062926466577e-05
step: 110, loss: 0.029294803738594055
step: 120, loss: 1.752730349835474e-05
step: 130, loss: 0.0006532730767503381
step: 140, loss: 0.05100100487470627
step: 150, loss: 0.0005607751663774252
step: 160, loss: 0.004486316815018654
step: 170, loss: 0.006707448977977037
step: 180, loss: 0.05805305019021034
step: 190, loss: 0.028518589213490486
step: 200, loss: 0.034724269062280655
step: 210, loss: 1.7531036064610817e-05
step: 220, loss: 0.01950123719871044
step: 230, loss: 0.01454794593155384
step: 240, loss: 1.7329875845462084e-05
step: 250, loss: 0.07065565884113312
step: 260, loss: 0.028887314721941948
step: 270, loss: 0.0008722002967260778
step: 280, loss: 0.0034751729108393192
step: 290, loss: 0.008258114568889141
step: 300, loss: 0.00040627375710755587
step: 310, loss: 0.010218266397714615
step: 320, loss: 0.11089450120925903
step: 330, loss: 0.005674794316291809
step: 340, loss: 0.03391578048467636
step: 350, loss: 0.00045238196616992354
step: 360, loss: 1.8544109479989856e-05
epoch 19: dev_f1=0.707774798927614, f1=0.696629213483146, best_f1=0.7262569832402234
step: 0, loss: 0.0007242733263410628
step: 10, loss: 0.00046521128388121724
step: 20, loss: 0.040783174335956573
step: 30, loss: 0.007248192559927702
step: 40, loss: 4.654418080463074e-05
step: 50, loss: 0.0004480063507799059
step: 60, loss: 2.005293390539009e-05
step: 70, loss: 0.0041410475969314575
step: 80, loss: 0.00567069835960865
step: 90, loss: 1.5586483641527593e-05
step: 100, loss: 0.022329354658722878
step: 110, loss: 0.0003880989388562739
step: 120, loss: 0.00018829965847544372
step: 130, loss: 0.008623815141618252
step: 140, loss: 0.0025280884001404047
step: 150, loss: 0.00010437479795655236
step: 160, loss: 0.00017912259500008076
step: 170, loss: 0.001468776841647923
step: 180, loss: 0.0005157454288564622
step: 190, loss: 0.00010054017184302211
step: 200, loss: 0.0002074997901218012
step: 210, loss: 8.64879330038093e-05
step: 220, loss: 0.011134804226458073
step: 230, loss: 0.009252620860934258
step: 240, loss: 0.0016354204853996634
step: 250, loss: 0.0007077092304825783
step: 260, loss: 9.532299736747518e-05
step: 270, loss: 0.0519409142434597
step: 280, loss: 6.874808605061844e-05
step: 290, loss: 0.022698286920785904
step: 300, loss: 0.02894253470003605
step: 310, loss: 0.00025896559236571193
step: 320, loss: 0.021786564961075783
step: 330, loss: 0.015440352261066437
step: 340, loss: 0.03963097184896469
step: 350, loss: 0.03414461761713028
step: 360, loss: 0.01636747270822525
epoch 20: dev_f1=0.7058823529411764, f1=0.6925207756232686, best_f1=0.7262569832402234
