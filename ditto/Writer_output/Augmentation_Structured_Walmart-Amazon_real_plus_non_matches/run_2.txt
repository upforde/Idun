cuda
Device: cuda
step: 0, loss: 0.865808367729187
step: 10, loss: 0.4189551770687103
step: 20, loss: 0.1415870487689972
step: 30, loss: 0.13931412994861603
step: 40, loss: 0.1471954584121704
step: 50, loss: 0.047240156680345535
step: 60, loss: 0.06116673722863197
step: 70, loss: 0.23410432040691376
step: 80, loss: 0.06172710657119751
step: 90, loss: 0.2269565314054489
step: 100, loss: 0.2250773012638092
step: 110, loss: 0.06059028208255768
step: 120, loss: 0.23564337193965912
step: 130, loss: 0.25969648361206055
step: 140, loss: 0.12486713379621506
step: 150, loss: 0.3147178888320923
step: 160, loss: 0.2653864324092865
step: 170, loss: 0.20385466516017914
step: 180, loss: 0.25240492820739746
step: 190, loss: 0.10672680288553238
step: 200, loss: 0.024938371032476425
step: 210, loss: 0.19843165576457977
step: 220, loss: 0.11258891224861145
step: 230, loss: 0.11660966277122498
step: 240, loss: 0.10616019368171692
step: 250, loss: 0.16394862532615662
step: 260, loss: 0.10072091221809387
step: 270, loss: 0.12711788713932037
step: 280, loss: 0.10643263906240463
step: 290, loss: 0.07394377887248993
step: 300, loss: 0.23480653762817383
step: 310, loss: 0.1852462738752365
step: 320, loss: 0.09312081336975098
step: 330, loss: 0.17878109216690063
step: 340, loss: 0.12581495940685272
step: 350, loss: 0.03627534210681915
step: 360, loss: 0.014404188841581345
epoch 1: dev_f1=0.5105263157894737, f1=0.5215053763440861, best_f1=0.5215053763440861
step: 0, loss: 0.23456653952598572
step: 10, loss: 0.04664648324251175
step: 20, loss: 0.18154433369636536
step: 30, loss: 0.09983684867620468
step: 40, loss: 0.21095910668373108
step: 50, loss: 0.18629932403564453
step: 60, loss: 0.08807359635829926
step: 70, loss: 0.1377512365579605
step: 80, loss: 0.07265064120292664
step: 90, loss: 0.06227460131049156
step: 100, loss: 0.05999531224370003
step: 110, loss: 0.16575221717357635
step: 120, loss: 0.2760196626186371
step: 130, loss: 0.1538449227809906
step: 140, loss: 0.1532163918018341
step: 150, loss: 0.09110948443412781
step: 160, loss: 0.22899700701236725
step: 170, loss: 0.10097359865903854
step: 180, loss: 0.10799464583396912
step: 190, loss: 0.05582474172115326
step: 200, loss: 0.18408572673797607
step: 210, loss: 0.3012984097003937
step: 220, loss: 0.14287512004375458
step: 230, loss: 0.08526314795017242
step: 240, loss: 0.3073177635669708
step: 250, loss: 0.08722422271966934
step: 260, loss: 0.04283769056200981
step: 270, loss: 0.024397529661655426
step: 280, loss: 0.20661018788814545
step: 290, loss: 0.09856006503105164
step: 300, loss: 0.17601551115512848
step: 310, loss: 0.009583008475601673
step: 320, loss: 0.062244564294815063
step: 330, loss: 0.14866741001605988
step: 340, loss: 0.07817602902650833
step: 350, loss: 0.020932532846927643
step: 360, loss: 0.07888801395893097
epoch 2: dev_f1=0.696808510638298, f1=0.7169811320754718, best_f1=0.7169811320754718
step: 0, loss: 0.04953895881772041
step: 10, loss: 0.10247514396905899
step: 20, loss: 0.07010433077812195
step: 30, loss: 0.06148992106318474
step: 40, loss: 0.03352457284927368
step: 50, loss: 0.07485716044902802
step: 60, loss: 0.14390958845615387
step: 70, loss: 0.35714051127433777
step: 80, loss: 0.0652170404791832
step: 90, loss: 0.01342793833464384
step: 100, loss: 0.08908245712518692
step: 110, loss: 0.12158431857824326
step: 120, loss: 0.06707210838794708
step: 130, loss: 0.14564844965934753
step: 140, loss: 0.05637509748339653
step: 150, loss: 0.2312905341386795
step: 160, loss: 0.04903675243258476
step: 170, loss: 0.058023542165756226
step: 180, loss: 0.081143319606781
step: 190, loss: 0.11638223379850388
step: 200, loss: 0.0409998819231987
step: 210, loss: 0.03174479678273201
step: 220, loss: 0.021100038662552834
step: 230, loss: 0.14033150672912598
step: 240, loss: 0.10074972361326218
step: 250, loss: 0.025831231847405434
step: 260, loss: 0.0628712922334671
step: 270, loss: 0.06492336839437485
step: 280, loss: 0.03296907991170883
step: 290, loss: 0.07697255164384842
step: 300, loss: 0.07378216087818146
step: 310, loss: 0.051473841071128845
step: 320, loss: 0.0749627873301506
step: 330, loss: 0.018760763108730316
step: 340, loss: 0.009514769539237022
step: 350, loss: 0.17191198468208313
step: 360, loss: 0.12156311422586441
epoch 3: dev_f1=0.7159904534606206, f1=0.7396593673965938, best_f1=0.7396593673965938
step: 0, loss: 0.04088219627737999
step: 10, loss: 0.044678784906864166
step: 20, loss: 0.03283332288265228
step: 30, loss: 0.07319928705692291
step: 40, loss: 0.04570566117763519
step: 50, loss: 0.03627077862620354
step: 60, loss: 0.05941930040717125
step: 70, loss: 0.07595875859260559
step: 80, loss: 0.044078528881073
step: 90, loss: 0.05292204022407532
step: 100, loss: 0.09501033276319504
step: 110, loss: 0.11516141891479492
step: 120, loss: 0.07690171152353287
step: 130, loss: 0.06689178943634033
step: 140, loss: 0.1252625733613968
step: 150, loss: 0.032512255012989044
step: 160, loss: 0.04737451300024986
step: 170, loss: 0.08275313675403595
step: 180, loss: 0.06757870316505432
step: 190, loss: 0.02255999483168125
step: 200, loss: 0.06359026581048965
step: 210, loss: 0.23052607476711273
step: 220, loss: 0.24736618995666504
step: 230, loss: 0.13944929838180542
step: 240, loss: 0.16713979840278625
step: 250, loss: 0.06519665569067001
step: 260, loss: 0.05158499628305435
step: 270, loss: 0.07074527442455292
step: 280, loss: 0.057728901505470276
step: 290, loss: 0.02657242678105831
step: 300, loss: 0.004092277493327856
step: 310, loss: 0.104802705347538
step: 320, loss: 0.03989476338028908
step: 330, loss: 0.09357955306768417
step: 340, loss: 0.028198717162013054
step: 350, loss: 0.06408295780420303
step: 360, loss: 0.06998050957918167
epoch 4: dev_f1=0.7457627118644068, f1=0.7304347826086957, best_f1=0.7304347826086957
step: 0, loss: 0.004244863986968994
step: 10, loss: 0.06108105555176735
step: 20, loss: 0.1093268096446991
step: 30, loss: 0.020628299564123154
step: 40, loss: 0.06556466966867447
step: 50, loss: 0.0004878753679804504
step: 60, loss: 0.07598654925823212
step: 70, loss: 0.06794050335884094
step: 80, loss: 0.030601656064391136
step: 90, loss: 0.04317620396614075
step: 100, loss: 0.06385141611099243
step: 110, loss: 0.04975394159555435
step: 120, loss: 0.0739692896604538
step: 130, loss: 0.03105160966515541
step: 140, loss: 0.05008454620838165
step: 150, loss: 0.09029214084148407
step: 160, loss: 0.021861353889107704
step: 170, loss: 0.03778093308210373
step: 180, loss: 0.1924436390399933
step: 190, loss: 0.10056864470243454
step: 200, loss: 0.01961849071085453
step: 210, loss: 0.01458737626671791
step: 220, loss: 0.14830555021762848
step: 230, loss: 0.05941397696733475
step: 240, loss: 0.13509252667427063
step: 250, loss: 0.0995117574930191
step: 260, loss: 0.04618041217327118
step: 270, loss: 0.10946433991193771
step: 280, loss: 0.05649467930197716
step: 290, loss: 0.020671991631388664
step: 300, loss: 0.10297641903162003
step: 310, loss: 0.18338845670223236
step: 320, loss: 0.10005229711532593
step: 330, loss: 0.11564642935991287
step: 340, loss: 0.06744059920310974
step: 350, loss: 0.08432628214359283
step: 360, loss: 0.017293982207775116
epoch 5: dev_f1=0.739795918367347, f1=0.7336956521739131, best_f1=0.7304347826086957
step: 0, loss: 0.05243149772286415
step: 10, loss: 0.08785608410835266
step: 20, loss: 0.03843018412590027
step: 30, loss: 0.008736941032111645
step: 40, loss: 0.05995400995016098
step: 50, loss: 0.022812096402049065
step: 60, loss: 0.01059324387460947
step: 70, loss: 0.045601896941661835
step: 80, loss: 0.03568941727280617
step: 90, loss: 0.06237984076142311
step: 100, loss: 0.0737842470407486
step: 110, loss: 0.043714821338653564
step: 120, loss: 0.05108538269996643
step: 130, loss: 0.06630576401948929
step: 140, loss: 0.09666081517934799
step: 150, loss: 0.010752594098448753
step: 160, loss: 0.08931417763233185
step: 170, loss: 0.017815865576267242
step: 180, loss: 0.07723921537399292
step: 190, loss: 0.021858204156160355
step: 200, loss: 0.0058342693373560905
step: 210, loss: 0.008712290786206722
step: 220, loss: 0.08542964607477188
step: 230, loss: 0.15658938884735107
step: 240, loss: 0.0620424784719944
step: 250, loss: 0.13732106983661652
step: 260, loss: 0.0007268129265867174
step: 270, loss: 0.030250679701566696
step: 280, loss: 0.054732248187065125
step: 290, loss: 0.07611095160245895
step: 300, loss: 0.027270209044218063
step: 310, loss: 0.04950692132115364
step: 320, loss: 0.03339015692472458
step: 330, loss: 0.022427845746278763
step: 340, loss: 0.00730544188991189
step: 350, loss: 0.09242869913578033
step: 360, loss: 0.036710675805807114
epoch 6: dev_f1=0.7590027700831025, f1=0.7752808988764045, best_f1=0.7752808988764045
step: 0, loss: 0.033890966325998306
step: 10, loss: 0.03689828887581825
step: 20, loss: 0.011871116235852242
step: 30, loss: 0.05053182318806648
step: 40, loss: 0.030525043606758118
step: 50, loss: 0.00011477881344035268
step: 60, loss: 0.0013194498606026173
step: 70, loss: 0.038121819496154785
step: 80, loss: 0.004084466956555843
step: 90, loss: 0.0070425705052912235
step: 100, loss: 0.03179130330681801
step: 110, loss: 0.15180163085460663
step: 120, loss: 0.0649690330028534
step: 130, loss: 0.0601409412920475
step: 140, loss: 0.09585614502429962
step: 150, loss: 0.05078912898898125
step: 160, loss: 0.07023182511329651
step: 170, loss: 0.07181453704833984
step: 180, loss: 0.03505731746554375
step: 190, loss: 0.04736567661166191
step: 200, loss: 0.06361301243305206
step: 210, loss: 0.013376107439398766
step: 220, loss: 0.018507422879338264
step: 230, loss: 0.056856632232666016
step: 240, loss: 0.08542058616876602
step: 250, loss: 0.02605983428657055
step: 260, loss: 0.06270770728588104
step: 270, loss: 0.08602733910083771
step: 280, loss: 0.009358581155538559
step: 290, loss: 0.10660874843597412
step: 300, loss: 0.007896028459072113
step: 310, loss: 0.03417317196726799
step: 320, loss: 0.009870183654129505
step: 330, loss: 0.0033306078985333443
step: 340, loss: 0.05301934480667114
step: 350, loss: 0.01672077737748623
step: 360, loss: 0.0684463381767273
epoch 7: dev_f1=0.7524752475247525, f1=0.7480916030534353, best_f1=0.7752808988764045
step: 0, loss: 0.027704373002052307
step: 10, loss: 0.052724145352840424
step: 20, loss: 0.01652105338871479
step: 30, loss: 0.01223395112901926
step: 40, loss: 0.05912056937813759
step: 50, loss: 0.04852375388145447
step: 60, loss: 0.05613122135400772
step: 70, loss: 0.03263425454497337
step: 80, loss: 0.03750971332192421
step: 90, loss: 0.21664240956306458
step: 100, loss: 0.08722159266471863
step: 110, loss: 0.10255958884954453
step: 120, loss: 0.03351682424545288
step: 130, loss: 0.08811231702566147
step: 140, loss: 0.008795561268925667
step: 150, loss: 0.009915956296026707
step: 160, loss: 0.052029963582754135
step: 170, loss: 0.0479525625705719
step: 180, loss: 0.06913024187088013
step: 190, loss: 0.1044391468167305
step: 200, loss: 0.001189291593618691
step: 210, loss: 0.029354549944400787
step: 220, loss: 0.11723456531763077
step: 230, loss: 0.13973309099674225
step: 240, loss: 0.052597805857658386
step: 250, loss: 0.09423685073852539
step: 260, loss: 0.033329371362924576
step: 270, loss: 0.10552037507295609
step: 280, loss: 0.051776222884655
step: 290, loss: 0.005495772697031498
step: 300, loss: 0.10303345322608948
step: 310, loss: 0.023883383721113205
step: 320, loss: 0.07728063315153122
step: 330, loss: 0.03402147814631462
step: 340, loss: 0.09805038571357727
step: 350, loss: 0.13457532227039337
step: 360, loss: 0.06769198179244995
epoch 8: dev_f1=0.7411444141689373, f1=0.7298850574712643, best_f1=0.7752808988764045
step: 0, loss: 0.07033421844244003
step: 10, loss: 0.08669178187847137
step: 20, loss: 0.03444350138306618
step: 30, loss: 0.004932992625981569
step: 40, loss: 0.004873858764767647
step: 50, loss: 0.0353466272354126
step: 60, loss: 0.07095670700073242
step: 70, loss: 0.018307628110051155
step: 80, loss: 0.10503572970628738
step: 90, loss: 0.012742428109049797
step: 100, loss: 0.0952325090765953
step: 110, loss: 0.06251415610313416
step: 120, loss: 0.028908951207995415
step: 130, loss: 0.2468523383140564
step: 140, loss: 0.01272529922425747
step: 150, loss: 0.09511221945285797
step: 160, loss: 0.031245652586221695
step: 170, loss: 0.08205607533454895
step: 180, loss: 0.008676433004438877
step: 190, loss: 0.002498065121471882
step: 200, loss: 0.02320699393749237
step: 210, loss: 0.07978320121765137
step: 220, loss: 0.04431429132819176
step: 230, loss: 0.0009726468124426901
step: 240, loss: 0.08393096178770065
step: 250, loss: 0.05662216618657112
step: 260, loss: 0.02054096944630146
step: 270, loss: 0.09818859398365021
step: 280, loss: 0.03970698267221451
step: 290, loss: 0.020713862031698227
step: 300, loss: 0.023142104968428612
step: 310, loss: 0.13361819088459015
step: 320, loss: 0.0702250674366951
step: 330, loss: 0.026010457426309586
step: 340, loss: 0.05533308535814285
step: 350, loss: 0.016513261944055557
step: 360, loss: 0.039920300245285034
epoch 9: dev_f1=0.7461139896373058, f1=0.745945945945946, best_f1=0.7752808988764045
step: 0, loss: 0.08155783265829086
step: 10, loss: 0.03785501793026924
step: 20, loss: 0.061630088835954666
step: 30, loss: 0.01989271119236946
step: 40, loss: 0.01155909150838852
step: 50, loss: 0.0341050960123539
step: 60, loss: 0.011876226402819157
step: 70, loss: 9.247798880096525e-05
step: 80, loss: 0.07841984182596207
step: 90, loss: 0.08102568238973618
step: 100, loss: 0.05321628600358963
step: 110, loss: 0.0011671028332784772
step: 120, loss: 0.020263860002160072
step: 130, loss: 0.052198536694049835
step: 140, loss: 0.09058079123497009
step: 150, loss: 0.03194878250360489
step: 160, loss: 0.016672465950250626
step: 170, loss: 0.039502374827861786
step: 180, loss: 0.0882205069065094
step: 190, loss: 0.01190501730889082
step: 200, loss: 0.07929400354623795
step: 210, loss: 6.053449396858923e-05
step: 220, loss: 0.10335961729288101
step: 230, loss: 0.020442891865968704
step: 240, loss: 0.10429414361715317
step: 250, loss: 0.03493455424904823
step: 260, loss: 0.0067037297412753105
step: 270, loss: 0.005429259967058897
step: 280, loss: 0.067221499979496
step: 290, loss: 0.08662957698106766
step: 300, loss: 0.021563194692134857
step: 310, loss: 0.07361114770174026
step: 320, loss: 0.013954969123005867
step: 330, loss: 0.03519878163933754
step: 340, loss: 0.015564198605716228
step: 350, loss: 0.01219983771443367
step: 360, loss: 0.06398779153823853
epoch 10: dev_f1=0.7414634146341464, f1=0.7539267015706806, best_f1=0.7752808988764045
step: 0, loss: 0.0002322396612726152
step: 10, loss: 0.006635864265263081
step: 20, loss: 0.09142786264419556
step: 30, loss: 0.08196272701025009
step: 40, loss: 0.025942914187908173
step: 50, loss: 0.022873805835843086
step: 60, loss: 0.0030252025462687016
step: 70, loss: 0.017817407846450806
step: 80, loss: 0.06735856086015701
step: 90, loss: 0.1341668665409088
step: 100, loss: 0.05743790045380592
step: 110, loss: 0.026345886290073395
step: 120, loss: 0.03186279162764549
step: 130, loss: 0.07009002566337585
step: 140, loss: 0.009337425231933594
step: 150, loss: 0.003954253625124693
step: 160, loss: 0.00026241556042805314
step: 170, loss: 0.05961618572473526
step: 180, loss: 0.027148038148880005
step: 190, loss: 0.022206954658031464
step: 200, loss: 0.0008222930482588708
step: 210, loss: 0.14190833270549774
step: 220, loss: 0.0008421824313700199
step: 230, loss: 0.06623006612062454
step: 240, loss: 0.020472323521971703
step: 250, loss: 0.004005143418908119
step: 260, loss: 0.08768671005964279
step: 270, loss: 0.0037680279929190874
step: 280, loss: 0.144814133644104
step: 290, loss: 0.06329767405986786
step: 300, loss: 0.03128534555435181
step: 310, loss: 0.04126530885696411
step: 320, loss: 0.0005046419682912529
step: 330, loss: 0.07548888027667999
step: 340, loss: 0.0007839867612347007
step: 350, loss: 0.056893836706876755
step: 360, loss: 0.1113322302699089
epoch 11: dev_f1=0.7428571428571429, f1=0.6904109589041095, best_f1=0.7752808988764045
step: 0, loss: 0.027792135253548622
step: 10, loss: 0.03027231991291046
step: 20, loss: 0.02169906347990036
step: 30, loss: 0.025388015434145927
step: 40, loss: 0.0032573386561125517
step: 50, loss: 0.04615595191717148
step: 60, loss: 0.0038711600936949253
step: 70, loss: 0.0035023419186472893
step: 80, loss: 0.007894583977758884
step: 90, loss: 0.01887846365571022
step: 100, loss: 0.017380693927407265
step: 110, loss: 0.026011865586042404
step: 120, loss: 0.11347445845603943
step: 130, loss: 0.03383326157927513
step: 140, loss: 0.01808551885187626
step: 150, loss: 0.06383654475212097
step: 160, loss: 0.022793561220169067
step: 170, loss: 0.049337808042764664
step: 180, loss: 0.0506308451294899
step: 190, loss: 0.013983465731143951
step: 200, loss: 0.07771831750869751
step: 210, loss: 0.07573595643043518
step: 220, loss: 0.0027656969614326954
step: 230, loss: 0.028522280976176262
step: 240, loss: 0.252127081155777
step: 250, loss: 0.02430153638124466
step: 260, loss: 0.023137642070651054
step: 270, loss: 0.0005311578279361129
step: 280, loss: 0.06422878801822662
step: 290, loss: 0.0619208887219429
step: 300, loss: 0.008900372311472893
step: 310, loss: 0.06423939019441605
step: 320, loss: 0.06842837482690811
step: 330, loss: 0.19654986262321472
step: 340, loss: 0.012696560472249985
step: 350, loss: 0.04059121385216713
step: 360, loss: 0.025512663647532463
epoch 12: dev_f1=0.7135678391959798, f1=0.7204030226700252, best_f1=0.7752808988764045
step: 0, loss: 0.008285373449325562
step: 10, loss: 0.0009680097573436797
step: 20, loss: 0.023059794679284096
step: 30, loss: 0.023503556847572327
step: 40, loss: 0.004822641145437956
step: 50, loss: 0.009588289074599743
step: 60, loss: 0.0065760537981987
step: 70, loss: 0.011822243221104145
step: 80, loss: 0.009394781664013863
step: 90, loss: 0.008921212516725063
step: 100, loss: 0.010697743855416775
step: 110, loss: 0.0032817241735756397
step: 120, loss: 0.006054980680346489
step: 130, loss: 0.003667919896543026
step: 140, loss: 0.12580639123916626
step: 150, loss: 0.07713556289672852
step: 160, loss: 0.08628086000680923
step: 170, loss: 0.0013569414149969816
step: 180, loss: 0.033272869884967804
step: 190, loss: 0.05079058185219765
step: 200, loss: 0.10366314649581909
step: 210, loss: 0.044606443494558334
step: 220, loss: 0.007040099706500769
step: 230, loss: 0.0028075582813471556
step: 240, loss: 0.024893751367926598
step: 250, loss: 0.013515276834368706
step: 260, loss: 0.12106524407863617
step: 270, loss: 0.017712663859128952
step: 280, loss: 0.023646758869290352
step: 290, loss: 0.005374094005674124
step: 300, loss: 4.752736640512012e-05
step: 310, loss: 0.010781657882034779
step: 320, loss: 0.04499391093850136
step: 330, loss: 0.03431367129087448
step: 340, loss: 0.002063973806798458
step: 350, loss: 0.012581531889736652
step: 360, loss: 0.027903063222765923
epoch 13: dev_f1=0.7506849315068493, f1=0.7228915662650602, best_f1=0.7752808988764045
step: 0, loss: 0.011522741056978703
step: 10, loss: 0.046465374529361725
step: 20, loss: 0.02743256464600563
step: 30, loss: 0.001298260991461575
step: 40, loss: 0.0014405592810362577
step: 50, loss: 0.02697637304663658
step: 60, loss: 0.008203018456697464
step: 70, loss: 0.11014453321695328
step: 80, loss: 4.136740608373657e-05
step: 90, loss: 0.011896184645593166
step: 100, loss: 0.025449706241488457
step: 110, loss: 0.03821263462305069
step: 120, loss: 0.05140269175171852
step: 130, loss: 0.01727118156850338
step: 140, loss: 0.01876400224864483
step: 150, loss: 0.006875390652567148
step: 160, loss: 4.517044362728484e-05
step: 170, loss: 0.0018917619017884135
step: 180, loss: 0.04433130845427513
step: 190, loss: 0.04176095128059387
step: 200, loss: 0.10758490860462189
step: 210, loss: 0.01538516953587532
step: 220, loss: 0.037608325481414795
step: 230, loss: 0.00790258776396513
step: 240, loss: 6.601024506380782e-05
step: 250, loss: 0.003453669138252735
step: 260, loss: 0.023339111357927322
step: 270, loss: 0.010637668892741203
step: 280, loss: 0.001039089635014534
step: 290, loss: 0.006116693839430809
step: 300, loss: 7.709627971053123e-05
step: 310, loss: 0.02884507179260254
step: 320, loss: 0.016209686174988747
step: 330, loss: 0.06551018357276917
step: 340, loss: 0.0578303262591362
step: 350, loss: 0.13406455516815186
step: 360, loss: 0.06254738569259644
epoch 14: dev_f1=0.7560321715817695, f1=0.7267441860465116, best_f1=0.7752808988764045
step: 0, loss: 0.03250958397984505
step: 10, loss: 0.014062684029340744
step: 20, loss: 2.8318900149315596e-05
step: 30, loss: 0.001142140943557024
step: 40, loss: 0.007088314741849899
step: 50, loss: 0.015396018512547016
step: 60, loss: 0.013858065009117126
step: 70, loss: 0.0651809573173523
step: 80, loss: 0.0574839785695076
step: 90, loss: 0.035613175481557846
step: 100, loss: 0.018127726390957832
step: 110, loss: 0.07502676546573639
step: 120, loss: 0.012244654819369316
step: 130, loss: 0.0714021772146225
step: 140, loss: 0.04030591994524002
step: 150, loss: 0.016673902049660683
step: 160, loss: 0.010031386278569698
step: 170, loss: 0.0021939422003924847
step: 180, loss: 0.012661047279834747
step: 190, loss: 0.028946399688720703
step: 200, loss: 0.006442738696932793
step: 210, loss: 0.00035831434070132673
step: 220, loss: 0.01407354511320591
step: 230, loss: 0.02487630769610405
step: 240, loss: 3.088520315941423e-05
step: 250, loss: 0.0020117294043302536
step: 260, loss: 2.7670717827277258e-05
step: 270, loss: 0.024188164621591568
step: 280, loss: 0.08002673089504242
step: 290, loss: 0.0016061015194281936
step: 300, loss: 0.000273458514129743
step: 310, loss: 0.11486959457397461
step: 320, loss: 0.013563419692218304
step: 330, loss: 0.021393897011876106
step: 340, loss: 0.12813755869865417
step: 350, loss: 0.0026417654007673264
step: 360, loss: 0.0126881655305624
epoch 15: dev_f1=0.7461139896373058, f1=0.7391304347826086, best_f1=0.7752808988764045
step: 0, loss: 0.05591670796275139
step: 10, loss: 0.032013315707445145
step: 20, loss: 0.09279725700616837
step: 30, loss: 0.003739501116797328
step: 40, loss: 0.013515490107238293
step: 50, loss: 0.002271817298606038
step: 60, loss: 0.027022570371627808
step: 70, loss: 0.0022236211225390434
step: 80, loss: 0.035317156463861465
step: 90, loss: 0.03155631572008133
step: 100, loss: 0.00205097789876163
step: 110, loss: 0.017358239740133286
step: 120, loss: 0.0530623123049736
step: 130, loss: 0.020028190687298775
step: 140, loss: 0.0033150052186101675
step: 150, loss: 0.0051269191317260265
step: 160, loss: 3.963555354857817e-05
step: 170, loss: 0.037211932241916656
step: 180, loss: 0.039614781737327576
step: 190, loss: 0.07516621053218842
step: 200, loss: 0.02570301480591297
step: 210, loss: 0.02941841073334217
step: 220, loss: 0.032231952995061874
step: 230, loss: 0.00010436488810228184
step: 240, loss: 0.04705411195755005
step: 250, loss: 0.020318495109677315
step: 260, loss: 0.002831321209669113
step: 270, loss: 0.04036710411310196
step: 280, loss: 0.008209582418203354
step: 290, loss: 0.0017519791144877672
step: 300, loss: 0.004044259432703257
step: 310, loss: 0.04205868020653725
step: 320, loss: 0.002327329246327281
step: 330, loss: 0.000350949791027233
step: 340, loss: 0.0016272390494123101
step: 350, loss: 0.0040620011277496815
step: 360, loss: 0.004399893805384636
epoch 16: dev_f1=0.7407407407407407, f1=0.724233983286908, best_f1=0.7752808988764045
step: 0, loss: 0.012644612230360508
step: 10, loss: 0.001494243391789496
step: 20, loss: 0.01428048126399517
step: 30, loss: 0.005925337318331003
step: 40, loss: 0.04762241244316101
step: 50, loss: 0.0020395934116095304
step: 60, loss: 0.044171467423439026
step: 70, loss: 0.01267322339117527
step: 80, loss: 3.4989217965630814e-05
step: 90, loss: 0.00017907211440615356
step: 100, loss: 0.00011339992488501593
step: 110, loss: 0.008759909309446812
step: 120, loss: 0.0005711638368666172
step: 130, loss: 0.004791676066815853
step: 140, loss: 0.020120451226830482
step: 150, loss: 2.5197339709848166e-05
step: 160, loss: 0.0002443105331622064
step: 170, loss: 0.04842237010598183
step: 180, loss: 0.015306170098483562
step: 190, loss: 6.433447560993955e-05
step: 200, loss: 0.03529760241508484
step: 210, loss: 0.018522774800658226
step: 220, loss: 0.0009979085298255086
step: 230, loss: 0.029262332245707512
step: 240, loss: 0.000402760662836954
step: 250, loss: 5.698786480934359e-05
step: 260, loss: 0.04255937039852142
step: 270, loss: 0.0033560479059815407
step: 280, loss: 0.019118785858154297
step: 290, loss: 0.019391590729355812
step: 300, loss: 0.026201318949460983
step: 310, loss: 0.017112843692302704
step: 320, loss: 6.017183841322549e-05
step: 330, loss: 0.012113901786506176
step: 340, loss: 0.06722788512706757
step: 350, loss: 3.3749547583283857e-05
step: 360, loss: 0.015125378035008907
epoch 17: dev_f1=0.7387862796833773, f1=0.732394366197183, best_f1=0.7752808988764045
step: 0, loss: 0.028475262224674225
step: 10, loss: 0.00031470664544031024
step: 20, loss: 2.8698395908577368e-05
step: 30, loss: 0.029909465461969376
step: 40, loss: 0.00015688984422013164
step: 50, loss: 0.044908616691827774
step: 60, loss: 0.0023773987777531147
step: 70, loss: 0.001884029945358634
step: 80, loss: 0.049105338752269745
step: 90, loss: 0.019810300320386887
step: 100, loss: 0.0011646461207419634
step: 110, loss: 0.0015316426288336515
step: 120, loss: 0.00032316544093191624
step: 130, loss: 0.013952096924185753
step: 140, loss: 0.032479748129844666
step: 150, loss: 0.010025613009929657
step: 160, loss: 0.106051504611969
step: 170, loss: 0.0001646801392780617
step: 180, loss: 7.794168777763844e-05
step: 190, loss: 0.003084579249843955
step: 200, loss: 0.00024001658312045038
step: 210, loss: 0.032706670463085175
step: 220, loss: 0.00434047169983387
step: 230, loss: 0.012619714252650738
step: 240, loss: 0.050550676882267
step: 250, loss: 0.03256751224398613
step: 260, loss: 0.04148992523550987
step: 270, loss: 0.006567433010786772
step: 280, loss: 0.033695559948682785
step: 290, loss: 0.00017217599088326097
step: 300, loss: 2.854546437447425e-05
step: 310, loss: 0.04181135818362236
step: 320, loss: 0.023962192237377167
step: 330, loss: 0.06780090928077698
step: 340, loss: 0.058149125427007675
step: 350, loss: 0.01749066449701786
step: 360, loss: 0.015130382962524891
epoch 18: dev_f1=0.7563451776649746, f1=0.7333333333333333, best_f1=0.7752808988764045
step: 0, loss: 0.0005950567428953946
step: 10, loss: 0.007643675431609154
step: 20, loss: 6.688896974083036e-05
step: 30, loss: 0.00037662891554646194
step: 40, loss: 0.004525770433247089
step: 50, loss: 0.01737610250711441
step: 60, loss: 2.039198443526402e-05
step: 70, loss: 0.0008088836329989135
step: 80, loss: 0.003027804894372821
step: 90, loss: 0.03248877078294754
step: 100, loss: 0.03455675020813942
step: 110, loss: 0.01615714840590954
step: 120, loss: 0.013185554184019566
step: 130, loss: 0.07109661400318146
step: 140, loss: 0.01291095931082964
step: 150, loss: 0.008952141739428043
step: 160, loss: 0.0039034164510667324
step: 170, loss: 0.00018059759167954326
step: 180, loss: 0.020762445405125618
step: 190, loss: 0.0012478888966143131
step: 200, loss: 0.037932783365249634
step: 210, loss: 0.06752221286296844
step: 220, loss: 0.051357463002204895
step: 230, loss: 2.9017915949225426e-05
step: 240, loss: 9.503270121058449e-05
step: 250, loss: 0.0008065883303061128
step: 260, loss: 0.0106776999309659
step: 270, loss: 0.0004563289403449744
step: 280, loss: 0.019765185192227364
step: 290, loss: 0.004640250466763973
step: 300, loss: 0.0007084087701514363
step: 310, loss: 8.878953667590395e-05
step: 320, loss: 0.06713365763425827
step: 330, loss: 0.0070953392423689365
step: 340, loss: 0.08048129081726074
step: 350, loss: 0.03508003428578377
step: 360, loss: 0.03135405853390694
epoch 19: dev_f1=0.7415143603133159, f1=0.7293447293447294, best_f1=0.7752808988764045
step: 0, loss: 0.00015055094263516366
step: 10, loss: 2.805796430038754e-05
step: 20, loss: 0.040761422365903854
step: 30, loss: 0.07380745559930801
step: 40, loss: 0.01587042026221752
step: 50, loss: 0.02316717430949211
step: 60, loss: 0.0001440736959921196
step: 70, loss: 0.00037194968899711967
step: 80, loss: 0.00013881438644602895
step: 90, loss: 0.0058805076405406
step: 100, loss: 0.0007945672841742635
step: 110, loss: 2.5268127501476556e-05
step: 120, loss: 0.051280125975608826
step: 130, loss: 0.01550978235900402
step: 140, loss: 0.0036804485134780407
step: 150, loss: 0.0002952725626528263
step: 160, loss: 0.009399035945534706
step: 170, loss: 0.11532256007194519
step: 180, loss: 0.00039674274739809334
step: 190, loss: 0.02728467807173729
step: 200, loss: 0.03615798056125641
step: 210, loss: 0.001997416140511632
step: 220, loss: 0.000591953401453793
step: 230, loss: 0.0001441488420823589
step: 240, loss: 0.0013897251337766647
step: 250, loss: 0.005664013791829348
step: 260, loss: 0.024694915860891342
step: 270, loss: 0.052592869848012924
step: 280, loss: 9.51910624280572e-05
step: 290, loss: 0.06556094437837601
step: 300, loss: 0.011319541372358799
step: 310, loss: 2.166227022826206e-05
step: 320, loss: 0.027740193530917168
step: 330, loss: 0.00028893863782286644
step: 340, loss: 0.042566508054733276
step: 350, loss: 0.00019210652681067586
step: 360, loss: 3.211840885342099e-05
epoch 20: dev_f1=0.7448979591836734, f1=0.7359550561797753, best_f1=0.7752808988764045
