cuda
Device: cuda
step: 0, loss: 0.7930420637130737
step: 10, loss: 0.04177671670913696
step: 20, loss: 0.4262024164199829
step: 30, loss: 0.059014804661273956
step: 40, loss: 0.14971354603767395
step: 50, loss: 0.041045743972063065
step: 60, loss: 0.4094756841659546
step: 70, loss: 0.38767144083976746
step: 80, loss: 0.3023979961872101
step: 90, loss: 0.06599976122379303
step: 100, loss: 0.03952421247959137
step: 110, loss: 0.2285902500152588
step: 120, loss: 0.01960422843694687
step: 130, loss: 0.23574687540531158
step: 140, loss: 0.1343553215265274
step: 150, loss: 0.036318060010671616
step: 160, loss: 0.019142525270581245
step: 170, loss: 0.35587114095687866
step: 180, loss: 0.13509653508663177
step: 190, loss: 0.29564306139945984
step: 200, loss: 0.18116527795791626
step: 210, loss: 0.1201431155204773
step: 220, loss: 0.23898518085479736
step: 230, loss: 0.013124912977218628
step: 240, loss: 0.0515463724732399
step: 250, loss: 0.22271353006362915
step: 260, loss: 0.010020241141319275
step: 270, loss: 0.11096426844596863
step: 280, loss: 0.3553777039051056
step: 290, loss: 0.20034129917621613
step: 300, loss: 0.21237070858478546
step: 310, loss: 0.11772335320711136
step: 320, loss: 0.21853378415107727
step: 330, loss: 0.13460750877857208
step: 340, loss: 0.1156635656952858
step: 350, loss: 0.04069866985082626
step: 360, loss: 0.11864206939935684
epoch 1: dev_f1=0.6578249336870027, f1=0.6404199475065616, best_f1=0.6404199475065616
step: 0, loss: 0.10639042407274246
step: 10, loss: 0.011911098845303059
step: 20, loss: 0.09555912017822266
step: 30, loss: 0.2962401509284973
step: 40, loss: 0.059930432587862015
step: 50, loss: 0.0688205435872078
step: 60, loss: 0.12576264142990112
step: 70, loss: 0.22520983219146729
step: 80, loss: 0.25560927391052246
step: 90, loss: 0.2055744081735611
step: 100, loss: 0.0164778009057045
step: 110, loss: 0.046033017337322235
step: 120, loss: 0.08597483485937119
step: 130, loss: 0.018916992470622063
step: 140, loss: 0.24963510036468506
step: 150, loss: 0.07155773043632507
step: 160, loss: 0.2045546919107437
step: 170, loss: 0.2182508409023285
step: 180, loss: 0.23164980113506317
step: 190, loss: 0.11612219363451004
step: 200, loss: 0.14787811040878296
step: 210, loss: 0.10901125520467758
step: 220, loss: 0.08210334926843643
step: 230, loss: 0.09377678483724594
step: 240, loss: 0.2547348439693451
step: 250, loss: 0.07549578696489334
step: 260, loss: 0.15945924818515778
step: 270, loss: 0.16327005624771118
step: 280, loss: 0.10104557871818542
step: 290, loss: 0.0812414214015007
step: 300, loss: 0.4508557915687561
step: 310, loss: 0.15120697021484375
step: 320, loss: 0.12024559080600739
step: 330, loss: 0.05584326013922691
step: 340, loss: 0.05687941983342171
step: 350, loss: 0.07250835001468658
step: 360, loss: 0.06429670751094818
epoch 2: dev_f1=0.7111111111111112, f1=0.7215909090909091, best_f1=0.7215909090909091
step: 0, loss: 0.2614663541316986
step: 10, loss: 0.09519565850496292
step: 20, loss: 0.08262691646814346
step: 30, loss: 0.3464145362377167
step: 40, loss: 0.1820305734872818
step: 50, loss: 0.1642066091299057
step: 60, loss: 0.12382186949253082
step: 70, loss: 0.35689473152160645
step: 80, loss: 0.0702141746878624
step: 90, loss: 0.08394653350114822
step: 100, loss: 0.030509669333696365
step: 110, loss: 0.08148898184299469
step: 120, loss: 0.37694430351257324
step: 130, loss: 0.04633717983961105
step: 140, loss: 0.15445134043693542
step: 150, loss: 0.09185504168272018
step: 160, loss: 0.12080539762973785
step: 170, loss: 0.060218650847673416
step: 180, loss: 0.16815604269504547
step: 190, loss: 0.030301691964268684
step: 200, loss: 0.16809317469596863
step: 210, loss: 0.07893125712871552
step: 220, loss: 0.1158788651227951
step: 230, loss: 0.006777528673410416
step: 240, loss: 0.12282852083444595
step: 250, loss: 0.14434599876403809
step: 260, loss: 0.12793377041816711
step: 270, loss: 0.05601077526807785
step: 280, loss: 0.0945739895105362
step: 290, loss: 0.052556365728378296
step: 300, loss: 0.05739611014723778
step: 310, loss: 0.05628501623868942
step: 320, loss: 0.10133077949285507
step: 330, loss: 0.16953018307685852
step: 340, loss: 0.08316730707883835
step: 350, loss: 0.028768638148903847
step: 360, loss: 0.11587750166654587
epoch 3: dev_f1=0.7180851063829788, f1=0.7371273712737126, best_f1=0.7371273712737126
step: 0, loss: 0.18130622804164886
step: 10, loss: 0.22640004754066467
step: 20, loss: 0.053430620580911636
step: 30, loss: 0.057705458253622055
step: 40, loss: 0.043834853917360306
step: 50, loss: 0.1508558839559555
step: 60, loss: 0.014665260910987854
step: 70, loss: 0.03319469839334488
step: 80, loss: 0.039122048765420914
step: 90, loss: 0.04005654528737068
step: 100, loss: 0.04789295792579651
step: 110, loss: 0.15438596904277802
step: 120, loss: 0.12901607155799866
step: 130, loss: 0.0795179083943367
step: 140, loss: 0.08342466503381729
step: 150, loss: 0.034118764102458954
step: 160, loss: 0.01254235114902258
step: 170, loss: 0.1462327390909195
step: 180, loss: 0.09452447295188904
step: 190, loss: 0.04530489444732666
step: 200, loss: 0.0719589963555336
step: 210, loss: 0.12730729579925537
step: 220, loss: 0.20316775143146515
step: 230, loss: 0.04323788359761238
step: 240, loss: 0.1292962282896042
step: 250, loss: 0.04255148768424988
step: 260, loss: 0.05897165834903717
step: 270, loss: 0.06799530237913132
step: 280, loss: 0.04869905486702919
step: 290, loss: 0.08325792849063873
step: 300, loss: 0.16496555507183075
step: 310, loss: 0.019793208688497543
step: 320, loss: 0.017603911459445953
step: 330, loss: 0.07923732697963715
step: 340, loss: 0.1166217029094696
step: 350, loss: 0.0611397922039032
step: 360, loss: 0.08452761173248291
epoch 4: dev_f1=0.7564766839378239, f1=0.7388888888888889, best_f1=0.7388888888888889
step: 0, loss: 0.0866168960928917
step: 10, loss: 0.09268729388713837
step: 20, loss: 0.1310913860797882
step: 30, loss: 0.04268695041537285
step: 40, loss: 0.0470215268433094
step: 50, loss: 0.049146413803100586
step: 60, loss: 0.04898039251565933
step: 70, loss: 0.08994986116886139
step: 80, loss: 0.034886933863162994
step: 90, loss: 0.02413490042090416
step: 100, loss: 0.03976179286837578
step: 110, loss: 0.06402091681957245
step: 120, loss: 0.01028359029442072
step: 130, loss: 0.04285427927970886
step: 140, loss: 0.03548956662416458
step: 150, loss: 0.1608549952507019
step: 160, loss: 0.04551847279071808
step: 170, loss: 0.002048288471996784
step: 180, loss: 0.027782713994383812
step: 190, loss: 0.10726680606603622
step: 200, loss: 0.08116942644119263
step: 210, loss: 0.023774493485689163
step: 220, loss: 0.03357740119099617
step: 230, loss: 0.0457792766392231
step: 240, loss: 0.052776411175727844
step: 250, loss: 0.08205842226743698
step: 260, loss: 0.10906150937080383
step: 270, loss: 0.10307373851537704
step: 280, loss: 0.007860708050429821
step: 290, loss: 0.005876152776181698
step: 300, loss: 0.07931950688362122
step: 310, loss: 0.07410215586423874
step: 320, loss: 0.11283029615879059
step: 330, loss: 0.09556382894515991
step: 340, loss: 0.028841886669397354
step: 350, loss: 0.0632484033703804
step: 360, loss: 0.1185196191072464
epoch 5: dev_f1=0.7616279069767441, f1=0.7228915662650602, best_f1=0.7228915662650602
step: 0, loss: 0.07928359508514404
step: 10, loss: 0.03915189206600189
step: 20, loss: 0.0668831318616867
step: 30, loss: 0.06894524395465851
step: 40, loss: 0.06679199635982513
step: 50, loss: 0.01152836624532938
step: 60, loss: 0.12287414819002151
step: 70, loss: 0.02401980757713318
step: 80, loss: 0.0005853471229784191
step: 90, loss: 0.013179629109799862
step: 100, loss: 0.027300171554088593
step: 110, loss: 0.04858845844864845
step: 120, loss: 0.03558655455708504
step: 130, loss: 0.1313352733850479
step: 140, loss: 0.035714466124773026
step: 150, loss: 0.022705648094415665
step: 160, loss: 0.08196109533309937
step: 170, loss: 0.09073428064584732
step: 180, loss: 0.05920415371656418
step: 190, loss: 0.008485980331897736
step: 200, loss: 0.050291821360588074
step: 210, loss: 0.05694464594125748
step: 220, loss: 0.10783164948225021
step: 230, loss: 0.07661741226911545
step: 240, loss: 0.032136280089616776
step: 250, loss: 0.021642712876200676
step: 260, loss: 0.10784704238176346
step: 270, loss: 0.07844403386116028
step: 280, loss: 0.05617475137114525
step: 290, loss: 0.04845550283789635
step: 300, loss: 0.06141585484147072
step: 310, loss: 0.056438546627759933
step: 320, loss: 0.1282176375389099
step: 330, loss: 0.049577079713344574
step: 340, loss: 0.03185812756419182
step: 350, loss: 0.07188646495342255
step: 360, loss: 0.05916498601436615
epoch 6: dev_f1=0.7304347826086957, f1=0.6606060606060606, best_f1=0.7228915662650602
step: 0, loss: 0.0806233212351799
step: 10, loss: 0.10951492190361023
step: 20, loss: 0.0937059223651886
step: 30, loss: 0.0678955540060997
step: 40, loss: 0.0714898556470871
step: 50, loss: 0.0027456823736429214
step: 60, loss: 0.04943806305527687
step: 70, loss: 0.03866494074463844
step: 80, loss: 0.06258068978786469
step: 90, loss: 0.0071578179486095905
step: 100, loss: 0.2811768651008606
step: 110, loss: 0.07930424809455872
step: 120, loss: 0.015265882946550846
step: 130, loss: 0.09904145449399948
step: 140, loss: 0.013090056367218494
step: 150, loss: 0.042426422238349915
step: 160, loss: 0.26278167963027954
step: 170, loss: 0.0002327508555026725
step: 180, loss: 0.09937011450529099
step: 190, loss: 0.08297869563102722
step: 200, loss: 0.09546870738267899
step: 210, loss: 0.1272725909948349
step: 220, loss: 0.1808459609746933
step: 230, loss: 0.03637721389532089
step: 240, loss: 0.007404410745948553
step: 250, loss: 0.005699166562408209
step: 260, loss: 0.04414455220103264
step: 270, loss: 0.04315336421132088
step: 280, loss: 0.0013813297264277935
step: 290, loss: 0.0024225646629929543
step: 300, loss: 0.11397324502468109
step: 310, loss: 0.071165069937706
step: 320, loss: 0.011212983168661594
step: 330, loss: 0.011600572615861893
step: 340, loss: 0.044850245118141174
step: 350, loss: 0.0762881338596344
step: 360, loss: 0.0488714836537838
epoch 7: dev_f1=0.7311827956989247, f1=0.709141274238227, best_f1=0.7228915662650602
step: 0, loss: 0.0005822767852805555
step: 10, loss: 0.04236089810729027
step: 20, loss: 0.007824769243597984
step: 30, loss: 0.02066729962825775
step: 40, loss: 0.0069221979938447475
step: 50, loss: 0.0005623585893772542
step: 60, loss: 0.02076846919953823
step: 70, loss: 0.004875986836850643
step: 80, loss: 0.010375522077083588
step: 90, loss: 0.0030549156945198774
step: 100, loss: 0.06277205795049667
step: 110, loss: 0.08299443870782852
step: 120, loss: 0.04395875334739685
step: 130, loss: 0.018747342750430107
step: 140, loss: 0.0329679511487484
step: 150, loss: 0.12125539779663086
step: 160, loss: 0.023279443383216858
step: 170, loss: 0.02595418132841587
step: 180, loss: 0.013611617498099804
step: 190, loss: 0.0005141422152519226
step: 200, loss: 0.003053961554542184
step: 210, loss: 0.08722696453332901
step: 220, loss: 0.0645289346575737
step: 230, loss: 0.023494401946663857
step: 240, loss: 0.05756840854883194
step: 250, loss: 0.00913227442651987
step: 260, loss: 0.011045398190617561
step: 270, loss: 0.0662459209561348
step: 280, loss: 0.07025039941072464
step: 290, loss: 0.017590926960110664
step: 300, loss: 0.02631603367626667
step: 310, loss: 0.01972169801592827
step: 320, loss: 0.03390469402074814
step: 330, loss: 0.015088262967765331
step: 340, loss: 0.006924908608198166
step: 350, loss: 0.05967865511775017
step: 360, loss: 0.04074949398636818
epoch 8: dev_f1=0.7794871794871795, f1=0.7554347826086956, best_f1=0.7554347826086956
step: 0, loss: 0.09640337526798248
step: 10, loss: 0.03638589382171631
step: 20, loss: 0.0583532452583313
step: 30, loss: 0.005266539286822081
step: 40, loss: 0.005921822041273117
step: 50, loss: 0.017664168030023575
step: 60, loss: 0.03215838596224785
step: 70, loss: 0.059586044400930405
step: 80, loss: 0.06768092513084412
step: 90, loss: 0.017846085131168365
step: 100, loss: 0.01825677789747715
step: 110, loss: 0.03057275339961052
step: 120, loss: 0.0037846590857952833
step: 130, loss: 0.040572285652160645
step: 140, loss: 0.003093280829489231
step: 150, loss: 0.010744718834757805
step: 160, loss: 0.015471328049898148
step: 170, loss: 0.0706377774477005
step: 180, loss: 0.034604091197252274
step: 190, loss: 0.0603463314473629
step: 200, loss: 0.03110552206635475
step: 210, loss: 0.02201092801988125
step: 220, loss: 0.017399217933416367
step: 230, loss: 0.007994353771209717
step: 240, loss: 0.04315980523824692
step: 250, loss: 0.3134712278842926
step: 260, loss: 0.004620961379259825
step: 270, loss: 0.026727229356765747
step: 280, loss: 0.041190702468156815
step: 290, loss: 0.010789790190756321
step: 300, loss: 0.08782348036766052
step: 310, loss: 0.043507207185029984
step: 320, loss: 0.02070818841457367
step: 330, loss: 0.11587534844875336
step: 340, loss: 0.016196811571717262
step: 350, loss: 0.1402207911014557
step: 360, loss: 0.02999819628894329
epoch 9: dev_f1=0.7548209366391184, f1=0.7052023121387283, best_f1=0.7554347826086956
step: 0, loss: 0.1126609519124031
step: 10, loss: 0.06695132702589035
step: 20, loss: 0.07333189994096756
step: 30, loss: 0.04202072694897652
step: 40, loss: 0.01862921006977558
step: 50, loss: 0.016083160415291786
step: 60, loss: 0.0030181456822901964
step: 70, loss: 0.01303726527839899
step: 80, loss: 0.11416468769311905
step: 90, loss: 0.0005121774156577885
step: 100, loss: 0.02905927412211895
step: 110, loss: 0.03818130120635033
step: 120, loss: 0.00041942414827644825
step: 130, loss: 0.1401500105857849
step: 140, loss: 0.052791763097047806
step: 150, loss: 0.015228528529405594
step: 160, loss: 0.05008566007018089
step: 170, loss: 0.012666231021285057
step: 180, loss: 0.008125168271362782
step: 190, loss: 0.02915779873728752
step: 200, loss: 0.034415483474731445
step: 210, loss: 0.010369569063186646
step: 220, loss: 0.017197871580719948
step: 230, loss: 0.003728047478944063
step: 240, loss: 0.2215670794248581
step: 250, loss: 0.0028188813012093306
step: 260, loss: 0.07752139866352081
step: 270, loss: 0.04057818651199341
step: 280, loss: 0.023780375719070435
step: 290, loss: 0.08303829282522202
step: 300, loss: 0.06299234926700592
step: 310, loss: 0.03698590025305748
step: 320, loss: 0.02596278302371502
step: 330, loss: 0.0052858684211969376
step: 340, loss: 0.1313537061214447
step: 350, loss: 0.03106686845421791
step: 360, loss: 0.044139377772808075
epoch 10: dev_f1=0.7552083333333333, f1=0.7103825136612021, best_f1=0.7554347826086956
step: 0, loss: 0.023454299196600914
step: 10, loss: 0.007870749570429325
step: 20, loss: 0.05386056378483772
step: 30, loss: 0.02017240598797798
step: 40, loss: 0.01295939739793539
step: 50, loss: 0.00840693898499012
step: 60, loss: 0.056009482592344284
step: 70, loss: 0.023680344223976135
step: 80, loss: 0.0030214160215109587
step: 90, loss: 0.02647048979997635
step: 100, loss: 0.009624384343624115
step: 110, loss: 0.10268330574035645
step: 120, loss: 0.040203772485256195
step: 130, loss: 0.015946734696626663
step: 140, loss: 0.009313453920185566
step: 150, loss: 0.07534996420145035
step: 160, loss: 0.06082013621926308
step: 170, loss: 0.01404590904712677
step: 180, loss: 0.0061401608400046825
step: 190, loss: 0.06027662009000778
step: 200, loss: 0.04743935167789459
step: 210, loss: 0.009076850488781929
step: 220, loss: 0.0310739167034626
step: 230, loss: 0.010106662288308144
step: 240, loss: 0.035570014268159866
step: 250, loss: 0.12155845016241074
step: 260, loss: 0.03149716183543205
step: 270, loss: 0.10248229652643204
step: 280, loss: 0.009167595766484737
step: 290, loss: 0.002880833111703396
step: 300, loss: 0.13935983180999756
step: 310, loss: 0.03018338605761528
step: 320, loss: 0.028528761118650436
step: 330, loss: 0.05334891006350517
step: 340, loss: 0.010053589940071106
step: 350, loss: 0.025746524333953857
step: 360, loss: 0.02215680293738842
epoch 11: dev_f1=0.736842105263158, f1=0.7182320441988949, best_f1=0.7554347826086956
step: 0, loss: 0.08132806420326233
step: 10, loss: 0.015140890143811703
step: 20, loss: 0.01689898781478405
step: 30, loss: 0.00011575809912756085
step: 40, loss: 0.03954154998064041
step: 50, loss: 0.025193333625793457
step: 60, loss: 0.015141583979129791
step: 70, loss: 5.450142998597585e-05
step: 80, loss: 0.000969103304669261
step: 90, loss: 0.0022314151283353567
step: 100, loss: 0.001748888287693262
step: 110, loss: 0.0029604104347527027
step: 120, loss: 0.0031193350441753864
step: 130, loss: 0.02435891516506672
step: 140, loss: 0.0662253201007843
step: 150, loss: 0.01932339556515217
step: 160, loss: 0.03359467163681984
step: 170, loss: 0.002913741860538721
step: 180, loss: 0.09806288778781891
step: 190, loss: 0.10430505871772766
step: 200, loss: 0.0001413248392054811
step: 210, loss: 0.03630240634083748
step: 220, loss: 0.00148527801502496
step: 230, loss: 0.07142910361289978
step: 240, loss: 0.06792394816875458
step: 250, loss: 0.10272783786058426
step: 260, loss: 0.008776435628533363
step: 270, loss: 0.07232940196990967
step: 280, loss: 0.042460307478904724
step: 290, loss: 0.015186162665486336
step: 300, loss: 0.044792961329221725
step: 310, loss: 0.00276799313724041
step: 320, loss: 0.04568802937865257
step: 330, loss: 3.239798388676718e-05
step: 340, loss: 4.850292680202983e-05
step: 350, loss: 0.01839660480618477
step: 360, loss: 0.05155187472701073
epoch 12: dev_f1=0.7219251336898397, f1=0.7016574585635359, best_f1=0.7554347826086956
step: 0, loss: 0.002966811414808035
step: 10, loss: 0.037609051913022995
step: 20, loss: 0.04584614187479019
step: 30, loss: 2.376330849074293e-05
step: 40, loss: 0.01076996698975563
step: 50, loss: 0.04067084565758705
step: 60, loss: 0.021152734756469727
step: 70, loss: 0.01484296191483736
step: 80, loss: 0.008760873228311539
step: 90, loss: 0.01850954256951809
step: 100, loss: 0.023430263623595238
step: 110, loss: 0.002832656027749181
step: 120, loss: 0.10533730685710907
step: 130, loss: 0.01627495139837265
step: 140, loss: 0.019720517098903656
step: 150, loss: 0.02620425447821617
step: 160, loss: 0.014562835916876793
step: 170, loss: 0.025062764063477516
step: 180, loss: 0.0005682525224983692
step: 190, loss: 0.014844034798443317
step: 200, loss: 0.10093030333518982
step: 210, loss: 5.5780001275707036e-05
step: 220, loss: 0.08089090138673782
step: 230, loss: 0.009853992611169815
step: 240, loss: 0.030524060130119324
step: 250, loss: 0.018986035138368607
step: 260, loss: 0.009075815789401531
step: 270, loss: 0.02229188196361065
step: 280, loss: 0.03235994651913643
step: 290, loss: 0.0032223775051534176
step: 300, loss: 0.025342203676700592
step: 310, loss: 0.03028886765241623
step: 320, loss: 0.08479323238134384
step: 330, loss: 0.022777002304792404
step: 340, loss: 0.06037314608693123
step: 350, loss: 0.13379158079624176
step: 360, loss: 0.005347108002752066
epoch 13: dev_f1=0.736, f1=0.7098591549295775, best_f1=0.7554347826086956
step: 0, loss: 0.0678028017282486
step: 10, loss: 0.028566041961312294
step: 20, loss: 0.024523328989744186
step: 30, loss: 0.047512609511613846
step: 40, loss: 0.0256666112691164
step: 50, loss: 0.011503376998007298
step: 60, loss: 2.8497626772150397e-05
step: 70, loss: 0.028535369783639908
step: 80, loss: 0.037544362246990204
step: 90, loss: 0.04692724719643593
step: 100, loss: 0.0072051724418997765
step: 110, loss: 0.001604509656317532
step: 120, loss: 0.052837952971458435
step: 130, loss: 0.06571841984987259
step: 140, loss: 0.03695300593972206
step: 150, loss: 0.010499328374862671
step: 160, loss: 2.7503248929861e-05
step: 170, loss: 0.0461808443069458
step: 180, loss: 0.043152015656232834
step: 190, loss: 0.05425985902547836
step: 200, loss: 0.08448705077171326
step: 210, loss: 2.7220181436860003e-05
step: 220, loss: 0.0015718290815129876
step: 230, loss: 3.5916411434300244e-05
step: 240, loss: 0.015090695582330227
step: 250, loss: 2.9719747544731945e-05
step: 260, loss: 0.010299988090991974
step: 270, loss: 0.0013645099243149161
step: 280, loss: 0.11853210628032684
step: 290, loss: 0.001011422136798501
step: 300, loss: 0.004214223939925432
step: 310, loss: 0.11656230688095093
step: 320, loss: 0.005496155004948378
step: 330, loss: 0.015089131891727448
step: 340, loss: 0.033807381987571716
step: 350, loss: 0.027863197028636932
step: 360, loss: 0.006260153837502003
epoch 14: dev_f1=0.7191601049868767, f1=0.7022471910112359, best_f1=0.7554347826086956
step: 0, loss: 0.008896948769688606
step: 10, loss: 0.0791947990655899
step: 20, loss: 0.004416564013808966
step: 30, loss: 0.0030849084723740816
step: 40, loss: 0.01583804190158844
step: 50, loss: 0.002415318973362446
step: 60, loss: 0.008416461758315563
step: 70, loss: 0.012722671963274479
step: 80, loss: 0.060444943606853485
step: 90, loss: 0.013191165402531624
step: 100, loss: 0.01955752819776535
step: 110, loss: 0.008678312413394451
step: 120, loss: 0.0005263928906060755
step: 130, loss: 0.0005240684258751571
step: 140, loss: 0.0041066431440413
step: 150, loss: 0.013715550303459167
step: 160, loss: 0.05912299081683159
step: 170, loss: 0.04696737602353096
step: 180, loss: 0.012588157318532467
step: 190, loss: 0.0004535856714937836
step: 200, loss: 0.0334060974419117
step: 210, loss: 0.060137029737234116
step: 220, loss: 0.07364603132009506
step: 230, loss: 0.045957788825035095
step: 240, loss: 0.014465267769992352
step: 250, loss: 0.06201241537928581
step: 260, loss: 3.467742135399021e-05
step: 270, loss: 0.09666723757982254
step: 280, loss: 0.001653220853768289
step: 290, loss: 3.242773163947277e-05
step: 300, loss: 0.011955737136304379
step: 310, loss: 0.004650178365409374
step: 320, loss: 2.396768468315713e-05
step: 330, loss: 0.0537668839097023
step: 340, loss: 0.010166311636567116
step: 350, loss: 0.022978199645876884
step: 360, loss: 0.05516158044338226
epoch 15: dev_f1=0.7107438016528925, f1=0.6804733727810651, best_f1=0.7554347826086956
step: 0, loss: 0.009063174948096275
step: 10, loss: 0.031787674874067307
step: 20, loss: 0.04175548255443573
step: 30, loss: 0.05120177939534187
step: 40, loss: 0.005138036794960499
step: 50, loss: 0.0029563966672867537
step: 60, loss: 0.010825048200786114
step: 70, loss: 0.0010662928689271212
step: 80, loss: 0.010846891440451145
step: 90, loss: 3.171594289597124e-05
step: 100, loss: 0.01308745052665472
step: 110, loss: 0.0005431320169009268
step: 120, loss: 0.003896445734426379
step: 130, loss: 0.0009015007526613772
step: 140, loss: 0.0017364113591611385
step: 150, loss: 0.0002390064182691276
step: 160, loss: 0.04240388050675392
step: 170, loss: 0.023853817954659462
step: 180, loss: 3.688384822453372e-05
step: 190, loss: 0.0004572570906020701
step: 200, loss: 0.0002996478579007089
step: 210, loss: 0.17064818739891052
step: 220, loss: 0.027648212388157845
step: 230, loss: 0.000808105047326535
step: 240, loss: 0.02725641243159771
step: 250, loss: 0.0008725698571652174
step: 260, loss: 2.4646184101584367e-05
step: 270, loss: 2.3584476366522722e-05
step: 280, loss: 0.00017155107343569398
step: 290, loss: 0.0010833470150828362
step: 300, loss: 0.02267131768167019
step: 310, loss: 0.002642716048285365
step: 320, loss: 0.01454874500632286
step: 330, loss: 0.013687025755643845
step: 340, loss: 0.0025163497775793076
step: 350, loss: 0.043385956436395645
step: 360, loss: 0.00016691922792233527
epoch 16: dev_f1=0.7197802197802198, f1=0.7, best_f1=0.7554347826086956
step: 0, loss: 5.466501534101553e-05
step: 10, loss: 0.05392066761851311
step: 20, loss: 0.0002408272703178227
step: 30, loss: 0.013847952708601952
step: 40, loss: 0.0028667880687862635
step: 50, loss: 0.000695476308465004
step: 60, loss: 0.06223548576235771
step: 70, loss: 0.02562764286994934
step: 80, loss: 0.017292480915784836
step: 90, loss: 0.00047000922495499253
step: 100, loss: 0.07263579964637756
step: 110, loss: 0.0023146956227719784
step: 120, loss: 0.003346153302118182
step: 130, loss: 0.0013224363792687654
step: 140, loss: 0.02100553922355175
step: 150, loss: 0.008440057747066021
step: 160, loss: 0.0229906365275383
step: 170, loss: 0.0011654507834464312
step: 180, loss: 0.037682972848415375
step: 190, loss: 3.6140485462965444e-05
step: 200, loss: 0.06015723571181297
step: 210, loss: 0.029650039970874786
step: 220, loss: 0.008097375743091106
step: 230, loss: 0.027673771604895592
step: 240, loss: 0.00019120560318697244
step: 250, loss: 0.009849092923104763
step: 260, loss: 0.06664903461933136
step: 270, loss: 0.0029584236908704042
step: 280, loss: 2.3897324354038574e-05
step: 290, loss: 0.05616394057869911
step: 300, loss: 0.0032850264105945826
step: 310, loss: 0.04216867685317993
step: 320, loss: 0.048298511654138565
step: 330, loss: 0.05129600316286087
step: 340, loss: 0.04281625896692276
step: 350, loss: 0.04629891738295555
step: 360, loss: 0.027581609785556793
epoch 17: dev_f1=0.7131367292225201, f1=0.6991404011461319, best_f1=0.7554347826086956
step: 0, loss: 0.0005362502997741103
step: 10, loss: 0.012925294227898121
step: 20, loss: 0.001547930296510458
step: 30, loss: 0.03922650218009949
step: 40, loss: 0.000195827116840519
step: 50, loss: 0.00012195131421322003
step: 60, loss: 0.07395737618207932
step: 70, loss: 0.00010936771286651492
step: 80, loss: 0.0037671069148927927
step: 90, loss: 0.002621124964207411
step: 100, loss: 0.0007294229581020772
step: 110, loss: 0.00025218151859007776
step: 120, loss: 0.07510105520486832
step: 130, loss: 0.0028650176245719194
step: 140, loss: 0.007809135597199202
step: 150, loss: 0.08380933105945587
step: 160, loss: 0.0014669004594907165
step: 170, loss: 2.5428204025956802e-05
step: 180, loss: 7.7040349424351e-05
step: 190, loss: 0.058528248220682144
step: 200, loss: 0.0504472553730011
step: 210, loss: 0.0060870954766869545
step: 220, loss: 0.08460414409637451
step: 230, loss: 4.875706508755684e-05
step: 240, loss: 0.002509437035769224
step: 250, loss: 0.015303222462534904
step: 260, loss: 0.061935920268297195
step: 270, loss: 0.07004439830780029
step: 280, loss: 0.0021580832544714212
step: 290, loss: 0.0006942123873159289
step: 300, loss: 0.0047882371582090855
step: 310, loss: 9.022604353958741e-05
step: 320, loss: 0.020966582000255585
step: 330, loss: 0.0007759083528071642
step: 340, loss: 0.022582843899726868
step: 350, loss: 0.004687611944973469
step: 360, loss: 0.0008217565482482314
epoch 18: dev_f1=0.7257617728531854, f1=0.6884272997032641, best_f1=0.7554347826086956
step: 0, loss: 2.0898445654893294e-05
step: 10, loss: 0.07308467477560043
step: 20, loss: 0.011393233202397823
step: 30, loss: 0.0010566640412434936
step: 40, loss: 0.02074470743536949
step: 50, loss: 0.02420094795525074
step: 60, loss: 0.00029444409301504493
step: 70, loss: 0.03835320472717285
step: 80, loss: 0.03830169141292572
step: 90, loss: 0.01326417550444603
step: 100, loss: 5.896856964682229e-05
step: 110, loss: 0.0007130258018150926
step: 120, loss: 0.0005466751754283905
step: 130, loss: 0.005751634482294321
step: 140, loss: 0.022800995036959648
step: 150, loss: 0.011828732676804066
step: 160, loss: 0.0031444095075130463
step: 170, loss: 0.1426815390586853
step: 180, loss: 0.018894130364060402
step: 190, loss: 0.0013503010850399733
step: 200, loss: 0.042828287929296494
step: 210, loss: 0.016650257632136345
step: 220, loss: 0.019436461851000786
step: 230, loss: 1.9628132577054203e-05
step: 240, loss: 0.002033867407590151
step: 250, loss: 0.0001150730240624398
step: 260, loss: 0.03825990855693817
step: 270, loss: 0.008054767735302448
step: 280, loss: 0.04582683742046356
step: 290, loss: 2.438848423480522e-05
step: 300, loss: 0.038051724433898926
step: 310, loss: 0.030747516080737114
step: 320, loss: 0.004688412416726351
step: 330, loss: 0.02189299277961254
step: 340, loss: 0.010328141041100025
step: 350, loss: 0.010031051933765411
step: 360, loss: 0.009752340614795685
epoch 19: dev_f1=0.7164948453608248, f1=0.6946778711484594, best_f1=0.7554347826086956
step: 0, loss: 0.0008948119357228279
step: 10, loss: 0.003924115095287561
step: 20, loss: 0.0006938297301530838
step: 30, loss: 2.897808917623479e-05
step: 40, loss: 0.025757838040590286
step: 50, loss: 0.02006753720343113
step: 60, loss: 0.0007169035961851478
step: 70, loss: 0.0002368926361668855
step: 80, loss: 0.0005965926684439182
step: 90, loss: 0.00025059067411348224
step: 100, loss: 0.0003978869062848389
step: 110, loss: 0.004248454235494137
step: 120, loss: 0.0010882830247282982
step: 130, loss: 0.039574313908815384
step: 140, loss: 0.014860624447464943
step: 150, loss: 0.04474533721804619
step: 160, loss: 0.0007949238060973585
step: 170, loss: 0.008687658235430717
step: 180, loss: 0.02503708004951477
step: 190, loss: 0.02186433970928192
step: 200, loss: 0.014234296977519989
step: 210, loss: 0.010704861022531986
step: 220, loss: 0.02163490653038025
step: 230, loss: 0.00024436222156509757
step: 240, loss: 0.03094392828643322
step: 250, loss: 0.01533144898712635
step: 260, loss: 0.02643776312470436
step: 270, loss: 0.0010017752647399902
step: 280, loss: 3.3318799978587776e-05
step: 290, loss: 0.005428172182291746
step: 300, loss: 0.020343316718935966
step: 310, loss: 0.015147322788834572
step: 320, loss: 0.016730038449168205
step: 330, loss: 0.07507749646902084
step: 340, loss: 0.059555161744356155
step: 350, loss: 0.027835756540298462
step: 360, loss: 6.854157982161269e-05
epoch 20: dev_f1=0.7277628032345013, f1=0.7014492753623188, best_f1=0.7554347826086956
