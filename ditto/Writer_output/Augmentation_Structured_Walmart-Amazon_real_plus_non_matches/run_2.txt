cuda
Device: cuda
step: 0, loss: 0.7189847230911255
step: 10, loss: 0.26741868257522583
step: 20, loss: 0.24085259437561035
step: 30, loss: 0.05043281242251396
step: 40, loss: 0.23856103420257568
step: 50, loss: 0.15171515941619873
step: 60, loss: 0.039680302143096924
step: 70, loss: 0.24996361136436462
step: 80, loss: 0.15523763000965118
step: 90, loss: 0.04891492426395416
step: 100, loss: 0.15479974448680878
step: 110, loss: 0.13166533410549164
step: 120, loss: 0.07874158769845963
step: 130, loss: 0.3613661527633667
step: 140, loss: 0.23044268786907196
step: 150, loss: 0.04407927021384239
step: 160, loss: 0.21186435222625732
step: 170, loss: 0.2057323008775711
step: 180, loss: 0.012408461421728134
step: 190, loss: 0.25282225012779236
step: 200, loss: 0.12985369563102722
step: 210, loss: 0.1316852569580078
step: 220, loss: 0.17847877740859985
step: 230, loss: 0.25223076343536377
step: 240, loss: 0.0841917023062706
step: 250, loss: 0.09537617117166519
step: 260, loss: 0.08259308338165283
step: 270, loss: 0.016203463077545166
step: 280, loss: 0.1055682972073555
step: 290, loss: 0.04800190404057503
step: 300, loss: 0.15292277932167053
step: 310, loss: 0.01866157539188862
step: 320, loss: 0.10658878833055496
step: 330, loss: 0.25121045112609863
step: 340, loss: 0.3588087856769562
step: 350, loss: 0.03559153899550438
step: 360, loss: 0.04393943026661873
epoch 1: dev_f1=0.6005830903790087, f1=0.6, best_f1=0.6
step: 0, loss: 0.10309106111526489
step: 10, loss: 0.10498294234275818
step: 20, loss: 0.22696565091609955
step: 30, loss: 0.09899087250232697
step: 40, loss: 0.06800170987844467
step: 50, loss: 0.19637489318847656
step: 60, loss: 0.05757157504558563
step: 70, loss: 0.1506051868200302
step: 80, loss: 0.050750911235809326
step: 90, loss: 0.07560078054666519
step: 100, loss: 0.08595940470695496
step: 110, loss: 0.10144021362066269
step: 120, loss: 0.28190895915031433
step: 130, loss: 0.2780483663082123
step: 140, loss: 0.03481919318437576
step: 150, loss: 0.07692345231771469
step: 160, loss: 0.14944013953208923
step: 170, loss: 0.14804737269878387
step: 180, loss: 0.008513967506587505
step: 190, loss: 0.06305627524852753
step: 200, loss: 0.08871571719646454
step: 210, loss: 0.18893714249134064
step: 220, loss: 0.0329679436981678
step: 230, loss: 0.17650744318962097
step: 240, loss: 0.12555646896362305
step: 250, loss: 0.01735994778573513
step: 260, loss: 0.03254294767975807
step: 270, loss: 0.24821791052818298
step: 280, loss: 0.11056222021579742
step: 290, loss: 0.10751672089099884
step: 300, loss: 0.07809865474700928
step: 310, loss: 0.09792747348546982
step: 320, loss: 0.09227265417575836
step: 330, loss: 0.21808621287345886
step: 340, loss: 0.23637163639068604
step: 350, loss: 0.10506211221218109
step: 360, loss: 0.18422558903694153
epoch 2: dev_f1=0.7356948228882835, f1=0.7318435754189944, best_f1=0.7318435754189944
step: 0, loss: 0.10447803139686584
step: 10, loss: 0.09909035265445709
step: 20, loss: 0.24303804337978363
step: 30, loss: 0.04501800611615181
step: 40, loss: 0.09539055079221725
step: 50, loss: 0.046876177191734314
step: 60, loss: 0.0350579135119915
step: 70, loss: 0.1930590569972992
step: 80, loss: 0.1283397078514099
step: 90, loss: 0.1420707106590271
step: 100, loss: 0.1603022813796997
step: 110, loss: 0.0949760153889656
step: 120, loss: 0.08803065866231918
step: 130, loss: 0.0408058799803257
step: 140, loss: 0.08395837992429733
step: 150, loss: 0.0387016236782074
step: 160, loss: 0.12946927547454834
step: 170, loss: 0.0967705249786377
step: 180, loss: 0.057214535772800446
step: 190, loss: 0.14965444803237915
step: 200, loss: 0.02426350861787796
step: 210, loss: 0.051811058074235916
step: 220, loss: 0.028719602152705193
step: 230, loss: 0.11445340514183044
step: 240, loss: 0.2752460539340973
step: 250, loss: 0.04651607573032379
step: 260, loss: 0.08362022042274475
step: 270, loss: 0.12751738727092743
step: 280, loss: 0.11586875468492508
step: 290, loss: 0.06268930435180664
step: 300, loss: 0.03867923468351364
step: 310, loss: 0.007977495901286602
step: 320, loss: 0.18988636136054993
step: 330, loss: 0.07261920720338821
step: 340, loss: 0.08271745592355728
step: 350, loss: 0.052330613136291504
step: 360, loss: 0.08071442693471909
epoch 3: dev_f1=0.7413333333333334, f1=0.7433155080213903, best_f1=0.7433155080213903
step: 0, loss: 0.1978190541267395
step: 10, loss: 0.0510188564658165
step: 20, loss: 0.05470369756221771
step: 30, loss: 0.07794976979494095
step: 40, loss: 0.0011636054841801524
step: 50, loss: 0.22245490550994873
step: 60, loss: 0.029633676633238792
step: 70, loss: 0.11282335221767426
step: 80, loss: 0.05842319875955582
step: 90, loss: 0.16497109830379486
step: 100, loss: 0.02339284121990204
step: 110, loss: 0.02588377147912979
step: 120, loss: 0.04866640269756317
step: 130, loss: 0.0013777039712294936
step: 140, loss: 0.271390825510025
step: 150, loss: 0.033040065318346024
step: 160, loss: 0.06851062923669815
step: 170, loss: 0.05393586307764053
step: 180, loss: 0.09195131808519363
step: 190, loss: 0.02369025908410549
step: 200, loss: 0.13517630100250244
step: 210, loss: 0.07942765206098557
step: 220, loss: 0.054809462279081345
step: 230, loss: 0.25908729434013367
step: 240, loss: 0.09647276997566223
step: 250, loss: 0.07021041959524155
step: 260, loss: 0.002314178738743067
step: 270, loss: 0.07803274691104889
step: 280, loss: 0.11823803186416626
step: 290, loss: 0.1048307791352272
step: 300, loss: 0.06431678682565689
step: 310, loss: 0.03869129344820976
step: 320, loss: 0.08978798985481262
step: 330, loss: 0.06760109961032867
step: 340, loss: 0.11152549833059311
step: 350, loss: 0.022314365953207016
step: 360, loss: 0.0716690868139267
epoch 4: dev_f1=0.732824427480916, f1=0.7191601049868767, best_f1=0.7433155080213903
step: 0, loss: 0.05795039236545563
step: 10, loss: 0.31506994366645813
step: 20, loss: 0.017946340143680573
step: 30, loss: 0.0886642187833786
step: 40, loss: 0.03227081522345543
step: 50, loss: 0.03795323893427849
step: 60, loss: 0.09211663901805878
step: 70, loss: 0.017176950350403786
step: 80, loss: 0.06976575404405594
step: 90, loss: 0.10465271025896072
step: 100, loss: 0.06722944974899292
step: 110, loss: 0.07138581573963165
step: 120, loss: 0.10433173179626465
step: 130, loss: 0.0006082780309952796
step: 140, loss: 0.03212723881006241
step: 150, loss: 0.03968364745378494
step: 160, loss: 0.021320145577192307
step: 170, loss: 0.21364039182662964
step: 180, loss: 0.07335390895605087
step: 190, loss: 0.0015891820657998323
step: 200, loss: 0.059706222265958786
step: 210, loss: 0.02895992062985897
step: 220, loss: 0.045823123306035995
step: 230, loss: 0.02994636818766594
step: 240, loss: 0.1822129487991333
step: 250, loss: 0.07928231358528137
step: 260, loss: 0.11859937012195587
step: 270, loss: 0.018422430381178856
step: 280, loss: 0.10224524140357971
step: 290, loss: 0.04115591570734978
step: 300, loss: 0.020511895418167114
step: 310, loss: 0.036358792334795
step: 320, loss: 0.015833228826522827
step: 330, loss: 0.07970906794071198
step: 340, loss: 0.047208189964294434
step: 350, loss: 0.010046799667179585
step: 360, loss: 0.2117723971605301
epoch 5: dev_f1=0.7079207920792079, f1=0.7384615384615385, best_f1=0.7433155080213903
step: 0, loss: 0.012091412208974361
step: 10, loss: 0.06329968571662903
step: 20, loss: 0.022273292765021324
step: 30, loss: 0.0095933573320508
step: 40, loss: 0.06114920601248741
step: 50, loss: 0.006747966166585684
step: 60, loss: 0.017156042158603668
step: 70, loss: 0.06843086332082748
step: 80, loss: 0.06362099200487137
step: 90, loss: 0.07053615897893906
step: 100, loss: 0.09630265086889267
step: 110, loss: 0.0581083670258522
step: 120, loss: 0.10825129598379135
step: 130, loss: 0.04582897201180458
step: 140, loss: 0.06504802405834198
step: 150, loss: 0.09546268731355667
step: 160, loss: 0.018556756898760796
step: 170, loss: 0.055969513952732086
step: 180, loss: 0.0443473756313324
step: 190, loss: 0.026071080937981606
step: 200, loss: 0.06667809933423996
step: 210, loss: 0.1809985637664795
step: 220, loss: 0.05211358889937401
step: 230, loss: 0.05840645357966423
step: 240, loss: 0.0305845495313406
step: 250, loss: 0.01092618703842163
step: 260, loss: 0.0646451935172081
step: 270, loss: 0.18573899567127228
step: 280, loss: 0.15406115353107452
step: 290, loss: 0.03586215153336525
step: 300, loss: 0.06316323578357697
step: 310, loss: 0.01414472796022892
step: 320, loss: 0.1225142776966095
step: 330, loss: 0.013644380494952202
step: 340, loss: 0.0006799445254728198
step: 350, loss: 0.008851475082337856
step: 360, loss: 0.008881697431206703
epoch 6: dev_f1=0.7530562347188262, f1=0.7531806615776082, best_f1=0.7531806615776082
step: 0, loss: 0.018519224599003792
step: 10, loss: 0.016562115401029587
step: 20, loss: 0.005916295573115349
step: 30, loss: 0.00583810918033123
step: 40, loss: 0.03550674766302109
step: 50, loss: 0.02603822574019432
step: 60, loss: 0.002545306459069252
step: 70, loss: 0.10777109116315842
step: 80, loss: 0.021140800788998604
step: 90, loss: 0.11914245784282684
step: 100, loss: 0.0901453047990799
step: 110, loss: 0.01889602281153202
step: 120, loss: 0.08209820091724396
step: 130, loss: 0.056588366627693176
step: 140, loss: 0.07594773173332214
step: 150, loss: 0.020499106496572495
step: 160, loss: 0.03609449043869972
step: 170, loss: 0.012520997785031796
step: 180, loss: 0.0007621831609867513
step: 190, loss: 0.0029063138645142317
step: 200, loss: 0.05352499708533287
step: 210, loss: 0.05668037757277489
step: 220, loss: 0.05017292872071266
step: 230, loss: 0.08810508251190186
step: 240, loss: 0.07286983728408813
step: 250, loss: 0.113331638276577
step: 260, loss: 0.02302115224301815
step: 270, loss: 0.06931405514478683
step: 280, loss: 0.04819353297352791
step: 290, loss: 0.030382245779037476
step: 300, loss: 0.06332550197839737
step: 310, loss: 0.16476354002952576
step: 320, loss: 0.054371513426303864
step: 330, loss: 0.09473145008087158
step: 340, loss: 0.15810976922512054
step: 350, loss: 0.07286767661571503
step: 360, loss: 0.000763276475481689
epoch 7: dev_f1=0.7468671679197996, f1=0.7409326424870466, best_f1=0.7531806615776082
step: 0, loss: 0.06269408017396927
step: 10, loss: 0.031707048416137695
step: 20, loss: 0.012555452063679695
step: 30, loss: 0.07718294858932495
step: 40, loss: 0.0012159566394984722
step: 50, loss: 0.012664579786360264
step: 60, loss: 0.030940044671297073
step: 70, loss: 0.01637979783117771
step: 80, loss: 0.02247457206249237
step: 90, loss: 0.01512617152184248
step: 100, loss: 0.010080458596348763
step: 110, loss: 0.04812023416161537
step: 120, loss: 0.021604303270578384
step: 130, loss: 0.262732595205307
step: 140, loss: 0.009340666234493256
step: 150, loss: 0.013627967797219753
step: 160, loss: 0.07065918296575546
step: 170, loss: 0.08805503696203232
step: 180, loss: 0.054912809282541275
step: 190, loss: 0.015619764104485512
step: 200, loss: 0.0854167565703392
step: 210, loss: 0.02724641188979149
step: 220, loss: 0.005374826490879059
step: 230, loss: 0.07325942069292068
step: 240, loss: 0.08241873234510422
step: 250, loss: 0.07590142637491226
step: 260, loss: 0.005606363527476788
step: 270, loss: 0.05887201800942421
step: 280, loss: 0.008106498047709465
step: 290, loss: 0.04506392031908035
step: 300, loss: 0.0033721784129738808
step: 310, loss: 0.048681896179914474
step: 320, loss: 0.004964231513440609
step: 330, loss: 0.1295779049396515
step: 340, loss: 0.06417457014322281
step: 350, loss: 0.007604468148201704
step: 360, loss: 0.005256207659840584
epoch 8: dev_f1=0.7551020408163265, f1=0.7277628032345013, best_f1=0.7277628032345013
step: 0, loss: 0.027402155101299286
step: 10, loss: 0.056963883340358734
step: 20, loss: 0.07525983452796936
step: 30, loss: 0.09992039948701859
step: 40, loss: 0.10059995949268341
step: 50, loss: 0.054330505430698395
step: 60, loss: 0.037438079714775085
step: 70, loss: 0.06168169528245926
step: 80, loss: 0.025974920019507408
step: 90, loss: 0.03905826434493065
step: 100, loss: 0.047043971717357635
step: 110, loss: 0.03907427191734314
step: 120, loss: 0.05550592020153999
step: 130, loss: 0.007323575206100941
step: 140, loss: 0.1361335813999176
step: 150, loss: 0.03188151493668556
step: 160, loss: 0.06240354850888252
step: 170, loss: 0.01667884550988674
step: 180, loss: 0.09938927739858627
step: 190, loss: 0.044924505054950714
step: 200, loss: 0.03529713675379753
step: 210, loss: 0.058235835283994675
step: 220, loss: 0.05948004126548767
step: 230, loss: 0.03190864250063896
step: 240, loss: 0.026520680636167526
step: 250, loss: 0.06736762821674347
step: 260, loss: 0.0910792127251625
step: 270, loss: 0.011846553534269333
step: 280, loss: 0.035221077501773834
step: 290, loss: 0.1902841180562973
step: 300, loss: 0.16444571316242218
step: 310, loss: 0.050200313329696655
step: 320, loss: 0.004101216793060303
step: 330, loss: 0.04952433332800865
step: 340, loss: 0.06745204329490662
step: 350, loss: 0.06960532814264297
step: 360, loss: 0.0333770327270031
epoch 9: dev_f1=0.6967418546365916, f1=0.7095115681233932, best_f1=0.7277628032345013
step: 0, loss: 0.041849005967378616
step: 10, loss: 0.028414104133844376
step: 20, loss: 0.025755763053894043
step: 30, loss: 0.2546672224998474
step: 40, loss: 0.005630273371934891
step: 50, loss: 0.0026641683652997017
step: 60, loss: 0.018985947594046593
step: 70, loss: 0.09525315463542938
step: 80, loss: 0.0899803638458252
step: 90, loss: 0.05954619124531746
step: 100, loss: 0.0002565213362686336
step: 110, loss: 0.005947754718363285
step: 120, loss: 0.025216851383447647
step: 130, loss: 0.010377001017332077
step: 140, loss: 0.0559924878180027
step: 150, loss: 0.009692702442407608
step: 160, loss: 0.001366250216960907
step: 170, loss: 0.017107496038079262
step: 180, loss: 0.005272827576845884
step: 190, loss: 0.056362394243478775
step: 200, loss: 0.01119946874678135
step: 210, loss: 0.04103781655430794
step: 220, loss: 0.034959807991981506
step: 230, loss: 0.00884182844310999
step: 240, loss: 0.027861569076776505
step: 250, loss: 0.010695313103497028
step: 260, loss: 0.059111181646585464
step: 270, loss: 0.01329212449491024
step: 280, loss: 0.010098819620907307
step: 290, loss: 0.026197226718068123
step: 300, loss: 0.04230532422661781
step: 310, loss: 0.02969961427152157
step: 320, loss: 0.11216277629137039
step: 330, loss: 0.06059761345386505
step: 340, loss: 0.0028710952028632164
step: 350, loss: 0.014374221675097942
step: 360, loss: 0.01829610951244831
epoch 10: dev_f1=0.7487684729064039, f1=0.7659574468085106, best_f1=0.7277628032345013
step: 0, loss: 0.02061193436384201
step: 10, loss: 0.012313448823988438
step: 20, loss: 0.018104849383234978
step: 30, loss: 0.018212174996733665
step: 40, loss: 0.02368375100195408
step: 50, loss: 0.014436572790145874
step: 60, loss: 0.036837246268987656
step: 70, loss: 0.028626540675759315
step: 80, loss: 0.0007451660349033773
step: 90, loss: 0.01510429847985506
step: 100, loss: 0.07549645006656647
step: 110, loss: 0.03094290755689144
step: 120, loss: 0.0219943318516016
step: 130, loss: 0.012182689271867275
step: 140, loss: 0.009620049968361855
step: 150, loss: 0.029854850843548775
step: 160, loss: 0.005712611600756645
step: 170, loss: 0.02745273895561695
step: 180, loss: 0.0018811335321515799
step: 190, loss: 0.008770722895860672
step: 200, loss: 0.038115765899419785
step: 210, loss: 0.016734391450881958
step: 220, loss: 0.096854567527771
step: 230, loss: 0.0037891396787017584
step: 240, loss: 0.0012270411243662238
step: 250, loss: 0.04706582427024841
step: 260, loss: 0.07653926312923431
step: 270, loss: 0.020098283886909485
step: 280, loss: 0.00018430895579513162
step: 290, loss: 0.004853908438235521
step: 300, loss: 0.002824862953275442
step: 310, loss: 0.010706685483455658
step: 320, loss: 0.04956846311688423
step: 330, loss: 0.00482509471476078
step: 340, loss: 0.13325053453445435
step: 350, loss: 0.017728449776768684
step: 360, loss: 0.010806502774357796
epoch 11: dev_f1=0.7518796992481204, f1=0.75, best_f1=0.7277628032345013
step: 0, loss: 0.012805124744772911
step: 10, loss: 0.02894044667482376
step: 20, loss: 0.0032137075904756784
step: 30, loss: 0.0007239864207804203
step: 40, loss: 0.0028795592952519655
step: 50, loss: 0.023475512862205505
step: 60, loss: 0.02941059321165085
step: 70, loss: 0.08343932777643204
step: 80, loss: 0.058581892400979996
step: 90, loss: 0.004972684197127819
step: 100, loss: 0.04047997668385506
step: 110, loss: 0.002084052190184593
step: 120, loss: 0.0077952053397893906
step: 130, loss: 0.011859066784381866
step: 140, loss: 0.08440001308917999
step: 150, loss: 0.025155123323202133
step: 160, loss: 0.022878337651491165
step: 170, loss: 0.022319674491882324
step: 180, loss: 0.023509245365858078
step: 190, loss: 0.006243910640478134
step: 200, loss: 0.009907184168696404
step: 210, loss: 0.0014055066276341677
step: 220, loss: 0.018698224797844887
step: 230, loss: 0.1262216567993164
step: 240, loss: 0.000299719104077667
step: 250, loss: 0.016611779108643532
step: 260, loss: 0.008589687757194042
step: 270, loss: 0.057428304105997086
step: 280, loss: 0.000787121884059161
step: 290, loss: 0.032269518822431564
step: 300, loss: 0.02432381734251976
step: 310, loss: 0.03799327090382576
step: 320, loss: 0.026094261556863785
step: 330, loss: 0.03587549552321434
step: 340, loss: 0.033480655401945114
step: 350, loss: 0.012078612111508846
step: 360, loss: 0.10327945649623871
epoch 12: dev_f1=0.749379652605459, f1=0.7557840616966581, best_f1=0.7277628032345013
step: 0, loss: 0.0647406354546547
step: 10, loss: 0.0017444731201976538
step: 20, loss: 0.011907480657100677
step: 30, loss: 0.02879973128437996
step: 40, loss: 0.005682898685336113
step: 50, loss: 0.0003999704495072365
step: 60, loss: 0.011163054965436459
step: 70, loss: 0.0028000224847346544
step: 80, loss: 0.0237056203186512
step: 90, loss: 0.0100658955052495
step: 100, loss: 0.10866061598062515
step: 110, loss: 0.021088728681206703
step: 120, loss: 0.16692854464054108
step: 130, loss: 0.012026016600430012
step: 140, loss: 0.00010722508886829019
step: 150, loss: 0.03260621055960655
step: 160, loss: 0.010290279053151608
step: 170, loss: 0.09775853902101517
step: 180, loss: 0.0482051745057106
step: 190, loss: 0.028428222984075546
step: 200, loss: 0.025294333696365356
step: 210, loss: 0.04333559796214104
step: 220, loss: 0.01132145058363676
step: 230, loss: 0.0013955658068880439
step: 240, loss: 0.0012905672192573547
step: 250, loss: 0.014642893336713314
step: 260, loss: 0.06019856780767441
step: 270, loss: 0.01359510701149702
step: 280, loss: 0.04681255668401718
step: 290, loss: 0.011940211988985538
step: 300, loss: 0.013317388482391834
step: 310, loss: 0.11221741139888763
step: 320, loss: 0.036245476454496384
step: 330, loss: 0.02855406329035759
step: 340, loss: 0.0401819571852684
step: 350, loss: 0.0016977878985926509
step: 360, loss: 0.0004123148391954601
epoch 13: dev_f1=0.7374005305039788, f1=0.718918918918919, best_f1=0.7277628032345013
step: 0, loss: 0.12856464087963104
step: 10, loss: 0.006277864798903465
step: 20, loss: 0.003977158572524786
step: 30, loss: 0.017887378111481667
step: 40, loss: 0.01017322763800621
step: 50, loss: 0.04527406767010689
step: 60, loss: 0.005389085970818996
step: 70, loss: 0.022176947444677353
step: 80, loss: 0.0026911210734397173
step: 90, loss: 0.05193599313497543
step: 100, loss: 0.11288069188594818
step: 110, loss: 0.048817433416843414
step: 120, loss: 0.01565401814877987
step: 130, loss: 0.027871472761034966
step: 140, loss: 0.001570525811985135
step: 150, loss: 0.07329792529344559
step: 160, loss: 0.012622792273759842
step: 170, loss: 0.0004674969532061368
step: 180, loss: 0.011395758017897606
step: 190, loss: 0.07573933154344559
step: 200, loss: 0.0021398751996457577
step: 210, loss: 0.0038035959005355835
step: 220, loss: 0.025910094380378723
step: 230, loss: 0.00012387153401505202
step: 240, loss: 0.012226576916873455
step: 250, loss: 0.0199632178992033
step: 260, loss: 0.1157427728176117
step: 270, loss: 0.019311770796775818
step: 280, loss: 0.0016143261454999447
step: 290, loss: 0.017253683879971504
step: 300, loss: 0.018189914524555206
step: 310, loss: 0.01043429970741272
step: 320, loss: 0.002517064567655325
step: 330, loss: 0.00040474566048942506
step: 340, loss: 0.020312195643782616
step: 350, loss: 0.03617333248257637
step: 360, loss: 4.000332410214469e-05
epoch 14: dev_f1=0.7439353099730459, f1=0.7353760445682451, best_f1=0.7277628032345013
step: 0, loss: 0.04381546378135681
step: 10, loss: 0.024667739868164062
step: 20, loss: 0.05045164376497269
step: 30, loss: 9.093624248635024e-05
step: 40, loss: 0.004692272748798132
step: 50, loss: 0.03594931587576866
step: 60, loss: 1.907327168737538e-05
step: 70, loss: 0.0643908753991127
step: 80, loss: 0.013163011521100998
step: 90, loss: 0.0015183181967586279
step: 100, loss: 0.0016831017564982176
step: 110, loss: 4.5554050302598625e-05
step: 120, loss: 0.002686500083655119
step: 130, loss: 0.08703068643808365
step: 140, loss: 0.018903642892837524
step: 150, loss: 0.006829498801380396
step: 160, loss: 0.04010390117764473
step: 170, loss: 0.0395786315202713
step: 180, loss: 0.0039722369983792305
step: 190, loss: 0.00253538740798831
step: 200, loss: 0.08076746016740799
step: 210, loss: 0.04938405379652977
step: 220, loss: 0.009976869449019432
step: 230, loss: 0.06142400577664375
step: 240, loss: 0.04262595996260643
step: 250, loss: 0.07522504776716232
step: 260, loss: 0.004705497529357672
step: 270, loss: 0.014150410890579224
step: 280, loss: 0.02686520293354988
step: 290, loss: 0.00010325256153009832
step: 300, loss: 0.0462459996342659
step: 310, loss: 0.09799293428659439
step: 320, loss: 0.03992636129260063
step: 330, loss: 0.021862175315618515
step: 340, loss: 5.162556408322416e-05
step: 350, loss: 0.03501705825328827
step: 360, loss: 0.06169935688376427
epoch 15: dev_f1=0.7250000000000001, f1=0.7473684210526317, best_f1=0.7277628032345013
step: 0, loss: 0.006514126434922218
step: 10, loss: 0.00030249240808188915
step: 20, loss: 0.06664619594812393
step: 30, loss: 0.0035704602487385273
step: 40, loss: 0.012758569791913033
step: 50, loss: 8.356084435945377e-05
step: 60, loss: 0.017911212518811226
step: 70, loss: 0.09281039237976074
step: 80, loss: 0.0010707544861361384
step: 90, loss: 0.004483456257730722
step: 100, loss: 0.006430187728255987
step: 110, loss: 0.05247395858168602
step: 120, loss: 0.05037393048405647
step: 130, loss: 0.035483598709106445
step: 140, loss: 5.598982534138486e-05
step: 150, loss: 0.006477219983935356
step: 160, loss: 0.004341337364166975
step: 170, loss: 0.028333554044365883
step: 180, loss: 0.0011927152518182993
step: 190, loss: 0.010546294040977955
step: 200, loss: 0.051040854305028915
step: 210, loss: 0.03433464094996452
step: 220, loss: 0.0016032635467126966
step: 230, loss: 0.054139140993356705
step: 240, loss: 0.04461481794714928
step: 250, loss: 0.003965823445469141
step: 260, loss: 0.000555091944988817
step: 270, loss: 0.09190433472394943
step: 280, loss: 0.00341693009249866
step: 290, loss: 7.300794095499441e-05
step: 300, loss: 0.0634818747639656
step: 310, loss: 0.04267735406756401
step: 320, loss: 0.0672370195388794
step: 330, loss: 0.07759340852499008
step: 340, loss: 0.0013549490831792355
step: 350, loss: 3.383934745215811e-05
step: 360, loss: 0.020308272913098335
epoch 16: dev_f1=0.7427184466019418, f1=0.7493670886075949, best_f1=0.7277628032345013
step: 0, loss: 0.01652430184185505
step: 10, loss: 0.011610588990151882
step: 20, loss: 0.006795103661715984
step: 30, loss: 0.00031996562029235065
step: 40, loss: 0.002903170185163617
step: 50, loss: 0.008521159179508686
step: 60, loss: 0.03265321999788284
step: 70, loss: 0.0005739417974837124
step: 80, loss: 0.05199173092842102
step: 90, loss: 0.028556250035762787
step: 100, loss: 0.03856612369418144
step: 110, loss: 0.0009118360467255116
step: 120, loss: 5.097930261399597e-05
step: 130, loss: 0.000677571923006326
step: 140, loss: 0.018545428290963173
step: 150, loss: 0.03216661140322685
step: 160, loss: 0.03157931938767433
step: 170, loss: 0.003789949929341674
step: 180, loss: 0.015527341514825821
step: 190, loss: 0.0049749622121453285
step: 200, loss: 0.001337137771770358
step: 210, loss: 0.05678676441311836
step: 220, loss: 0.059441354125738144
step: 230, loss: 0.0015357622178271413
step: 240, loss: 0.022856250405311584
step: 250, loss: 0.024416841566562653
step: 260, loss: 0.05673176422715187
step: 270, loss: 0.030176766216754913
step: 280, loss: 0.019057542085647583
step: 290, loss: 0.04359430447220802
step: 300, loss: 0.013120749033987522
step: 310, loss: 0.014917690306901932
step: 320, loss: 0.10078717768192291
step: 330, loss: 0.000458801252534613
step: 340, loss: 0.01596722938120365
step: 350, loss: 0.007075842935591936
step: 360, loss: 0.018907414749264717
epoch 17: dev_f1=0.7324675324675326, f1=0.7458563535911602, best_f1=0.7277628032345013
step: 0, loss: 0.08968491852283478
step: 10, loss: 0.021190837025642395
step: 20, loss: 0.04130079224705696
step: 30, loss: 0.0034774946980178356
step: 40, loss: 0.00015187110693659633
step: 50, loss: 0.03251427039504051
step: 60, loss: 0.048254404217004776
step: 70, loss: 0.0014245235361158848
step: 80, loss: 0.0013425410725176334
step: 90, loss: 0.019383607432246208
step: 100, loss: 0.0006382333813235164
step: 110, loss: 0.02523455023765564
step: 120, loss: 0.0006612192955799401
step: 130, loss: 0.012658338062465191
step: 140, loss: 0.01343030110001564
step: 150, loss: 0.0060112024657428265
step: 160, loss: 0.050754010677337646
step: 170, loss: 0.052372727543115616
step: 180, loss: 0.03272716701030731
step: 190, loss: 2.1539257431868464e-05
step: 200, loss: 0.00015947074280120432
step: 210, loss: 0.09562785923480988
step: 220, loss: 6.361764098983258e-05
step: 230, loss: 0.03232807666063309
step: 240, loss: 0.0014053030172362924
step: 250, loss: 0.02307964116334915
step: 260, loss: 0.08833521604537964
step: 270, loss: 0.0008846003911457956
step: 280, loss: 0.0016379583394154906
step: 290, loss: 0.00013819376181345433
step: 300, loss: 0.022925501689314842
step: 310, loss: 0.002494881395250559
step: 320, loss: 0.04544064402580261
step: 330, loss: 0.03395698592066765
step: 340, loss: 0.01162508875131607
step: 350, loss: 0.0001101270827348344
step: 360, loss: 0.00033985634217970073
epoch 18: dev_f1=0.7281795511221945, f1=0.7338501291989663, best_f1=0.7277628032345013
step: 0, loss: 0.06721330434083939
step: 10, loss: 0.009244002401828766
step: 20, loss: 0.009608794935047626
step: 30, loss: 0.005481037311255932
step: 40, loss: 4.868202086072415e-05
step: 50, loss: 0.0332057923078537
step: 60, loss: 0.02279188670217991
step: 70, loss: 0.007056414149701595
step: 80, loss: 0.03216015174984932
step: 90, loss: 0.0008943200809881091
step: 100, loss: 7.777578866807744e-05
step: 110, loss: 0.01291170809417963
step: 120, loss: 0.006910932250320911
step: 130, loss: 0.048633161932229996
step: 140, loss: 0.000165731311426498
step: 150, loss: 0.07976929843425751
step: 160, loss: 0.020047850906848907
step: 170, loss: 0.007667316123843193
step: 180, loss: 0.0195484459400177
step: 190, loss: 0.008622052147984505
step: 200, loss: 0.00020445053814910352
step: 210, loss: 9.373744978802279e-05
step: 220, loss: 0.04663786664605141
step: 230, loss: 0.024132857099175453
step: 240, loss: 0.07559084892272949
step: 250, loss: 0.00034120699274353683
step: 260, loss: 0.0006291497265920043
step: 270, loss: 0.005169067531824112
step: 280, loss: 0.021412452682852745
step: 290, loss: 0.008065798319876194
step: 300, loss: 0.028987618163228035
step: 310, loss: 0.014512619934976101
step: 320, loss: 0.0002229939418612048
step: 330, loss: 0.015588774345815182
step: 340, loss: 0.06646687537431717
step: 350, loss: 0.010061060078442097
step: 360, loss: 0.0344492606818676
epoch 19: dev_f1=0.7231920199501246, f1=0.734375, best_f1=0.7277628032345013
step: 0, loss: 0.022463273257017136
step: 10, loss: 0.0022303129080682993
step: 20, loss: 0.008247526362538338
step: 30, loss: 0.003612552070990205
step: 40, loss: 0.019216708838939667
step: 50, loss: 0.00034670508466660976
step: 60, loss: 0.02824009582400322
step: 70, loss: 0.0027765403501689434
step: 80, loss: 0.05904108285903931
step: 90, loss: 0.002122575184330344
step: 100, loss: 0.025749871507287025
step: 110, loss: 0.03800451382994652
step: 120, loss: 0.012706873938441277
step: 130, loss: 0.0012418517144396901
step: 140, loss: 0.0016491168644279242
step: 150, loss: 0.006495524663478136
step: 160, loss: 0.015911513939499855
step: 170, loss: 0.03888826444745064
step: 180, loss: 0.019335594028234482
step: 190, loss: 0.008740109391510487
step: 200, loss: 0.045935604721307755
step: 210, loss: 0.041194818913936615
step: 220, loss: 0.000720029347576201
step: 230, loss: 0.015666354447603226
step: 240, loss: 0.007433752529323101
step: 250, loss: 0.033525947481393814
step: 260, loss: 0.05749162659049034
step: 270, loss: 0.00010139020741917193
step: 280, loss: 0.011231504380702972
step: 290, loss: 0.0004981620004400611
step: 300, loss: 0.01698722504079342
step: 310, loss: 0.019616298377513885
step: 320, loss: 0.001635221648029983
step: 330, loss: 4.83350595459342e-05
step: 340, loss: 0.011087306775152683
step: 350, loss: 0.03308182582259178
step: 360, loss: 2.419513839413412e-05
epoch 20: dev_f1=0.7208121827411167, f1=0.7401574803149608, best_f1=0.7277628032345013
