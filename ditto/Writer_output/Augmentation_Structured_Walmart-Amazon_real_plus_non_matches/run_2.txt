cuda
Device: cuda
step: 0, loss: 0.7358414530754089
step: 10, loss: 0.3727624714374542
step: 20, loss: 0.16204167902469635
step: 30, loss: 0.021546419709920883
step: 40, loss: 0.23172372579574585
step: 50, loss: 0.14885786175727844
step: 60, loss: 0.02092054858803749
step: 70, loss: 0.07559814304113388
step: 80, loss: 0.23648133873939514
step: 90, loss: 0.14455975592136383
step: 100, loss: 0.235340878367424
step: 110, loss: 0.1357319951057434
step: 120, loss: 0.13193200528621674
step: 130, loss: 0.22713343799114227
step: 140, loss: 0.13205286860466003
step: 150, loss: 0.26176849007606506
step: 160, loss: 0.11970414966344833
step: 170, loss: 0.2190753072500229
step: 180, loss: 0.1487172394990921
step: 190, loss: 0.26442497968673706
step: 200, loss: 0.1714990884065628
step: 210, loss: 0.470944344997406
step: 220, loss: 0.21677161753177643
step: 230, loss: 0.2226513773202896
step: 240, loss: 0.1924894154071808
step: 250, loss: 0.035810232162475586
step: 260, loss: 0.1034841537475586
step: 270, loss: 0.10956660658121109
step: 280, loss: 0.15743662416934967
step: 290, loss: 0.15804637968540192
step: 300, loss: 0.2078506052494049
step: 310, loss: 0.16363364458084106
step: 320, loss: 0.11206916719675064
step: 330, loss: 0.11572378128767014
step: 340, loss: 0.35954585671424866
step: 350, loss: 0.21262036263942719
step: 360, loss: 0.41417717933654785
epoch 1: dev_f1=0.5950920245398773, f1=0.6646884272997032, best_f1=0.6646884272997032
step: 0, loss: 0.17692388594150543
step: 10, loss: 0.23775751888751984
step: 20, loss: 0.07962869852781296
step: 30, loss: 0.0173617135733366
step: 40, loss: 0.17321880161762238
step: 50, loss: 0.20100486278533936
step: 60, loss: 0.09766490757465363
step: 70, loss: 0.30421358346939087
step: 80, loss: 0.31600862741470337
step: 90, loss: 0.14119407534599304
step: 100, loss: 0.09521108120679855
step: 110, loss: 0.037733662873506546
step: 120, loss: 0.028357863426208496
step: 130, loss: 0.16398194432258606
step: 140, loss: 0.032313909381628036
step: 150, loss: 0.027934672310948372
step: 160, loss: 0.14910025894641876
step: 170, loss: 0.035487283021211624
step: 180, loss: 0.09979450702667236
step: 190, loss: 0.16123633086681366
step: 200, loss: 0.14560359716415405
step: 210, loss: 0.07523146271705627
step: 220, loss: 0.01880800351500511
step: 230, loss: 0.11225691437721252
step: 240, loss: 0.14130714535713196
step: 250, loss: 0.09250295162200928
step: 260, loss: 0.026303794234991074
step: 270, loss: 0.11628031730651855
step: 280, loss: 0.13092200458049774
step: 290, loss: 0.14654703438282013
step: 300, loss: 0.009726855903863907
step: 310, loss: 0.024196183308959007
step: 320, loss: 0.4223092198371887
step: 330, loss: 0.08749519288539886
step: 340, loss: 0.17128966748714447
step: 350, loss: 0.16797767579555511
step: 360, loss: 0.03078446537256241
epoch 2: dev_f1=0.6608695652173914, f1=0.7195467422096318, best_f1=0.7195467422096318
step: 0, loss: 0.0865878239274025
step: 10, loss: 0.10188012570142746
step: 20, loss: 0.06536221504211426
step: 30, loss: 0.05042794346809387
step: 40, loss: 0.10155385732650757
step: 50, loss: 0.06714825332164764
step: 60, loss: 0.0990898534655571
step: 70, loss: 0.34298574924468994
step: 80, loss: 0.057683564722537994
step: 90, loss: 0.06910732388496399
step: 100, loss: 0.021674232557415962
step: 110, loss: 0.18225419521331787
step: 120, loss: 0.01398403663188219
step: 130, loss: 0.06313925236463547
step: 140, loss: 0.06887209415435791
step: 150, loss: 0.1852836161851883
step: 160, loss: 0.13842418789863586
step: 170, loss: 0.008503264747560024
step: 180, loss: 0.07939121872186661
step: 190, loss: 0.12383469939231873
step: 200, loss: 0.12713681161403656
step: 210, loss: 0.029785292223095894
step: 220, loss: 0.0735044851899147
step: 230, loss: 0.19855600595474243
step: 240, loss: 0.046572767198085785
step: 250, loss: 0.1332738846540451
step: 260, loss: 0.02507505938410759
step: 270, loss: 0.13375140726566315
step: 280, loss: 0.1315508484840393
step: 290, loss: 0.14414940774440765
step: 300, loss: 0.01460617408156395
step: 310, loss: 0.09369555115699768
step: 320, loss: 0.03393520787358284
step: 330, loss: 0.06014510244131088
step: 340, loss: 0.07253840565681458
step: 350, loss: 0.08459706604480743
step: 360, loss: 0.11961409449577332
epoch 3: dev_f1=0.7178082191780822, f1=0.7344632768361581, best_f1=0.7344632768361581
step: 0, loss: 0.04457603394985199
step: 10, loss: 0.005545683670789003
step: 20, loss: 0.02301415055990219
step: 30, loss: 0.13174381852149963
step: 40, loss: 0.0509953536093235
step: 50, loss: 0.034433357417583466
step: 60, loss: 0.08863150328397751
step: 70, loss: 0.021888840943574905
step: 80, loss: 0.09920033812522888
step: 90, loss: 0.05674527958035469
step: 100, loss: 0.11702095717191696
step: 110, loss: 0.007733746897429228
step: 120, loss: 0.0006182555225677788
step: 130, loss: 0.12984907627105713
step: 140, loss: 0.08767042309045792
step: 150, loss: 0.11244672536849976
step: 160, loss: 0.2160942256450653
step: 170, loss: 0.17138609290122986
step: 180, loss: 0.09976426512002945
step: 190, loss: 0.11526140570640564
step: 200, loss: 0.06609775871038437
step: 210, loss: 0.036348141729831696
step: 220, loss: 0.077968530356884
step: 230, loss: 0.0744895339012146
step: 240, loss: 0.03912198543548584
step: 250, loss: 0.057021696120500565
step: 260, loss: 0.057060640305280685
step: 270, loss: 0.06504283100366592
step: 280, loss: 0.06943017244338989
step: 290, loss: 0.12608617544174194
step: 300, loss: 0.10449715703725815
step: 310, loss: 0.1258133500814438
step: 320, loss: 0.03677989915013313
step: 330, loss: 0.05086085945367813
step: 340, loss: 0.11760207265615463
step: 350, loss: 0.16091705858707428
step: 360, loss: 0.0955677330493927
epoch 4: dev_f1=0.7423822714681441, f1=0.7247191011235956, best_f1=0.7247191011235956
step: 0, loss: 0.17009595036506653
step: 10, loss: 0.01415711734443903
step: 20, loss: 0.0006130963447503746
step: 30, loss: 0.08798227459192276
step: 40, loss: 0.12097734957933426
step: 50, loss: 0.0006694192998111248
step: 60, loss: 0.03348854184150696
step: 70, loss: 0.06615567952394485
step: 80, loss: 0.0005657162400893867
step: 90, loss: 0.037514958530664444
step: 100, loss: 0.027468714863061905
step: 110, loss: 0.046047646552324295
step: 120, loss: 0.08434489369392395
step: 130, loss: 0.03871573135256767
step: 140, loss: 0.031187331303954124
step: 150, loss: 0.14913715422153473
step: 160, loss: 0.04487689584493637
step: 170, loss: 0.13156984746456146
step: 180, loss: 0.05656834691762924
step: 190, loss: 0.07664619386196136
step: 200, loss: 0.07684832811355591
step: 210, loss: 0.04782335087656975
step: 220, loss: 0.020309047773480415
step: 230, loss: 0.21456195414066315
step: 240, loss: 0.06217767670750618
step: 250, loss: 0.1476222276687622
step: 260, loss: 0.07142709940671921
step: 270, loss: 0.0938681960105896
step: 280, loss: 0.017746318131685257
step: 290, loss: 0.013164536096155643
step: 300, loss: 0.05636265501379967
step: 310, loss: 0.06295033544301987
step: 320, loss: 0.04557424783706665
step: 330, loss: 0.07657775282859802
step: 340, loss: 0.010691204108297825
step: 350, loss: 0.04340964928269386
step: 360, loss: 0.050614986568689346
epoch 5: dev_f1=0.7158469945355191, f1=0.724233983286908, best_f1=0.7247191011235956
step: 0, loss: 0.008786056190729141
step: 10, loss: 0.04501403123140335
step: 20, loss: 0.0014190762303769588
step: 30, loss: 0.12914279103279114
step: 40, loss: 0.13254888355731964
step: 50, loss: 0.00032141056726686656
step: 60, loss: 0.061379652470350266
step: 70, loss: 0.07724121958017349
step: 80, loss: 0.028091048821806908
step: 90, loss: 0.0004126369021832943
step: 100, loss: 0.015893952921032906
step: 110, loss: 0.01133737526834011
step: 120, loss: 0.06357035785913467
step: 130, loss: 0.02356516569852829
step: 140, loss: 0.039878688752651215
step: 150, loss: 0.06369247287511826
step: 160, loss: 0.02780591882765293
step: 170, loss: 0.03088776394724846
step: 180, loss: 0.023748332634568214
step: 190, loss: 0.052291493862867355
step: 200, loss: 0.05875373259186745
step: 210, loss: 0.14750592410564423
step: 220, loss: 0.06342680752277374
step: 230, loss: 0.04411303997039795
step: 240, loss: 0.07728442549705505
step: 250, loss: 0.020591385662555695
step: 260, loss: 0.04101891443133354
step: 270, loss: 0.009335143491625786
step: 280, loss: 0.018298041075468063
step: 290, loss: 0.06862521916627884
step: 300, loss: 0.033924542367458344
step: 310, loss: 0.03154332935810089
step: 320, loss: 0.10674001276493073
step: 330, loss: 0.012410897761583328
step: 340, loss: 0.2247498333454132
step: 350, loss: 0.03354116901755333
step: 360, loss: 0.025029029697179794
epoch 6: dev_f1=0.7580645161290323, f1=0.743801652892562, best_f1=0.743801652892562
step: 0, loss: 0.09801929444074631
step: 10, loss: 0.055899690836668015
step: 20, loss: 0.023178832605481148
step: 30, loss: 0.038497570902109146
step: 40, loss: 0.0005398808280006051
step: 50, loss: 0.001055756350979209
step: 60, loss: 0.134078711271286
step: 70, loss: 0.016913767904043198
step: 80, loss: 0.08993931114673615
step: 90, loss: 0.11360097676515579
step: 100, loss: 0.038151029497385025
step: 110, loss: 0.010985340923070908
step: 120, loss: 0.022894974797964096
step: 130, loss: 0.1741855889558792
step: 140, loss: 0.052146442234516144
step: 150, loss: 0.06176244094967842
step: 160, loss: 0.02810828946530819
step: 170, loss: 0.14080965518951416
step: 180, loss: 0.1490103155374527
step: 190, loss: 0.004720151424407959
step: 200, loss: 0.03503946587443352
step: 210, loss: 0.08056731522083282
step: 220, loss: 0.04578595608472824
step: 230, loss: 0.014907690696418285
step: 240, loss: 0.0895310640335083
step: 250, loss: 0.07103611528873444
step: 260, loss: 0.036055780947208405
step: 270, loss: 0.13748422265052795
step: 280, loss: 0.08325359970331192
step: 290, loss: 0.056385524570941925
step: 300, loss: 0.052597369998693466
step: 310, loss: 0.11341113597154617
step: 320, loss: 0.013025406748056412
step: 330, loss: 0.03872929513454437
step: 340, loss: 0.028998222202062607
step: 350, loss: 0.07310232520103455
step: 360, loss: 0.11516500264406204
epoch 7: dev_f1=0.7350000000000001, f1=0.7382198952879582, best_f1=0.743801652892562
step: 0, loss: 0.012501700781285763
step: 10, loss: 0.060323428362607956
step: 20, loss: 0.036601390689611435
step: 30, loss: 0.016525480896234512
step: 40, loss: 0.02676057070493698
step: 50, loss: 0.015467696823179722
step: 60, loss: 0.009820518083870411
step: 70, loss: 0.010034254752099514
step: 80, loss: 0.02118336781859398
step: 90, loss: 0.00952257588505745
step: 100, loss: 0.017551198601722717
step: 110, loss: 0.072659932076931
step: 120, loss: 0.049490559846162796
step: 130, loss: 0.029657846316695213
step: 140, loss: 0.034295350313186646
step: 150, loss: 0.018002377822995186
step: 160, loss: 0.1143152117729187
step: 170, loss: 0.023028209805488586
step: 180, loss: 0.06215159222483635
step: 190, loss: 0.042107097804546356
step: 200, loss: 0.05026056617498398
step: 210, loss: 0.012647926807403564
step: 220, loss: 0.08023978024721146
step: 230, loss: 0.030634526163339615
step: 240, loss: 0.04784437641501427
step: 250, loss: 0.03001968376338482
step: 260, loss: 0.051375143229961395
step: 270, loss: 0.004518359433859587
step: 280, loss: 0.03517690300941467
step: 290, loss: 0.03416111692786217
step: 300, loss: 0.07668299973011017
step: 310, loss: 0.07123956084251404
step: 320, loss: 0.10637450963258743
step: 330, loss: 0.11156831681728363
step: 340, loss: 0.04212130606174469
step: 350, loss: 0.061222050338983536
step: 360, loss: 0.024644682183861732
epoch 8: dev_f1=0.7079207920792079, f1=0.7153652392947103, best_f1=0.743801652892562
step: 0, loss: 0.07997302711009979
step: 10, loss: 0.05705996975302696
step: 20, loss: 0.04618343710899353
step: 30, loss: 7.091456063790247e-05
step: 40, loss: 8.004661503946409e-05
step: 50, loss: 0.030513251200318336
step: 60, loss: 0.030802233144640923
step: 70, loss: 0.03633132949471474
step: 80, loss: 0.044284429401159286
step: 90, loss: 0.04040951654314995
step: 100, loss: 0.06458575278520584
step: 110, loss: 0.02382991649210453
step: 120, loss: 0.033050499856472015
step: 130, loss: 0.11008287221193314
step: 140, loss: 0.0963134840130806
step: 150, loss: 0.008685179054737091
step: 160, loss: 0.03864118084311485
step: 170, loss: 0.026784438639879227
step: 180, loss: 0.046167079359292984
step: 190, loss: 0.015408609993755817
step: 200, loss: 0.05785282328724861
step: 210, loss: 0.04008569195866585
step: 220, loss: 0.06992781907320023
step: 230, loss: 0.022094346582889557
step: 240, loss: 0.01552543230354786
step: 250, loss: 0.06622691452503204
step: 260, loss: 0.03164779767394066
step: 270, loss: 0.05530840903520584
step: 280, loss: 0.015148013830184937
step: 290, loss: 0.008442911319434643
step: 300, loss: 0.14135578274726868
step: 310, loss: 0.07406335324048996
step: 320, loss: 0.10444370657205582
step: 330, loss: 0.04643470048904419
step: 340, loss: 0.04532506689429283
step: 350, loss: 0.12772709131240845
step: 360, loss: 0.043916888535022736
epoch 9: dev_f1=0.7525773195876289, f1=0.7407407407407407, best_f1=0.743801652892562
step: 0, loss: 0.02202589064836502
step: 10, loss: 0.10051834583282471
step: 20, loss: 0.11261657625436783
step: 30, loss: 0.053541406989097595
step: 40, loss: 0.12434463202953339
step: 50, loss: 0.0743151381611824
step: 60, loss: 0.046890370547771454
step: 70, loss: 0.01020373497158289
step: 80, loss: 0.008446737192571163
step: 90, loss: 0.04162977635860443
step: 100, loss: 0.052331939339637756
step: 110, loss: 0.014148302376270294
step: 120, loss: 0.00039331341395154595
step: 130, loss: 0.0041725244373083115
step: 140, loss: 0.02704481966793537
step: 150, loss: 0.06754225492477417
step: 160, loss: 0.0032964423298835754
step: 170, loss: 0.038608960807323456
step: 180, loss: 0.08605632930994034
step: 190, loss: 0.3007357716560364
step: 200, loss: 0.05111919716000557
step: 210, loss: 0.0062667918391525745
step: 220, loss: 0.008010515943169594
step: 230, loss: 0.06886555999517441
step: 240, loss: 0.06746140867471695
step: 250, loss: 0.008309880271553993
step: 260, loss: 0.07957914471626282
step: 270, loss: 0.0023350517731159925
step: 280, loss: 0.008824193850159645
step: 290, loss: 0.01756465993821621
step: 300, loss: 0.08643153309822083
step: 310, loss: 0.02729111909866333
step: 320, loss: 0.008532191626727581
step: 330, loss: 0.08582915365695953
step: 340, loss: 0.08945872634649277
step: 350, loss: 0.12615588307380676
step: 360, loss: 0.0027691826689988375
epoch 10: dev_f1=0.7142857142857143, f1=0.7480916030534353, best_f1=0.743801652892562
step: 0, loss: 0.0010872007114812732
step: 10, loss: 0.007886060513556004
step: 20, loss: 0.00023498274094890803
step: 30, loss: 0.011650714091956615
step: 40, loss: 0.015670794993638992
step: 50, loss: 0.011188729666173458
step: 60, loss: 0.07273504137992859
step: 70, loss: 0.002833117265254259
step: 80, loss: 0.06561729311943054
step: 90, loss: 0.00687175989151001
step: 100, loss: 0.12729844450950623
step: 110, loss: 0.006365850102156401
step: 120, loss: 0.0073278602212667465
step: 130, loss: 0.03897729143500328
step: 140, loss: 0.04922337457537651
step: 150, loss: 0.008345535025000572
step: 160, loss: 0.16898705065250397
step: 170, loss: 0.015323789790272713
step: 180, loss: 0.023581238463521004
step: 190, loss: 0.11801283061504364
step: 200, loss: 0.0012071131495758891
step: 210, loss: 0.03882569074630737
step: 220, loss: 0.0005886805593036115
step: 230, loss: 0.049240268766880035
step: 240, loss: 0.07263465970754623
step: 250, loss: 0.04805788770318031
step: 260, loss: 0.12313318252563477
step: 270, loss: 0.04538600891828537
step: 280, loss: 0.02682909183204174
step: 290, loss: 0.02043270505964756
step: 300, loss: 0.033377159386873245
step: 310, loss: 0.012478580698370934
step: 320, loss: 0.007853568531572819
step: 330, loss: 0.00927991233766079
step: 340, loss: 0.08394307643175125
step: 350, loss: 0.06158074736595154
step: 360, loss: 0.05743873119354248
epoch 11: dev_f1=0.717557251908397, f1=0.7365728900255755, best_f1=0.743801652892562
step: 0, loss: 0.06421083956956863
step: 10, loss: 0.05162110924720764
step: 20, loss: 0.03070618398487568
step: 30, loss: 0.0021313615143299103
step: 40, loss: 0.0022895841393619776
step: 50, loss: 0.006932615302503109
step: 60, loss: 0.0743335485458374
step: 70, loss: 0.0008124350570142269
step: 80, loss: 0.024773139506578445
step: 90, loss: 0.018295668065547943
step: 100, loss: 0.019131874665617943
step: 110, loss: 0.00162755255587399
step: 120, loss: 0.03981535881757736
step: 130, loss: 0.10423924028873444
step: 140, loss: 0.03807849809527397
step: 150, loss: 0.03811551630496979
step: 160, loss: 0.033900294452905655
step: 170, loss: 0.035727132111787796
step: 180, loss: 0.07985881716012955
step: 190, loss: 0.0015934814000502229
step: 200, loss: 0.021481633186340332
step: 210, loss: 0.018489299342036247
step: 220, loss: 0.042491842061281204
step: 230, loss: 0.11604717373847961
step: 240, loss: 0.009384140372276306
step: 250, loss: 0.12877944111824036
step: 260, loss: 0.010881965048611164
step: 270, loss: 0.0396188348531723
step: 280, loss: 0.008543957024812698
step: 290, loss: 0.054393112659454346
step: 300, loss: 0.009060349315404892
step: 310, loss: 0.01199385803192854
step: 320, loss: 0.020819982513785362
step: 330, loss: 0.029042115435004234
step: 340, loss: 0.007727429736405611
step: 350, loss: 0.0006312684854492545
step: 360, loss: 0.03497418761253357
epoch 12: dev_f1=0.7114427860696517, f1=0.7183462532299743, best_f1=0.743801652892562
step: 0, loss: 0.0013144100084900856
step: 10, loss: 0.0024799087550491095
step: 20, loss: 0.005923271644860506
step: 30, loss: 0.00026204093592241406
step: 40, loss: 0.024984437972307205
step: 50, loss: 0.005918268114328384
step: 60, loss: 0.007457719650119543
step: 70, loss: 0.05064470320940018
step: 80, loss: 0.013072079978883266
step: 90, loss: 0.15085601806640625
step: 100, loss: 0.01522443164139986
step: 110, loss: 0.025782480835914612
step: 120, loss: 0.027635615319013596
step: 130, loss: 0.009841561317443848
step: 140, loss: 0.062254298478364944
step: 150, loss: 0.026824206113815308
step: 160, loss: 0.006004285532981157
step: 170, loss: 0.014583841897547245
step: 180, loss: 0.005046753212809563
step: 190, loss: 0.05243103951215744
step: 200, loss: 0.0906338095664978
step: 210, loss: 0.004548585973680019
step: 220, loss: 0.0008695993456058204
step: 230, loss: 0.013962650671601295
step: 240, loss: 0.07683970034122467
step: 250, loss: 0.02643481083214283
step: 260, loss: 0.0036024085711687803
step: 270, loss: 0.0402098186314106
step: 280, loss: 0.009183584712445736
step: 290, loss: 0.019215214997529984
step: 300, loss: 0.1467445343732834
step: 310, loss: 0.0901053249835968
step: 320, loss: 0.007604210637509823
step: 330, loss: 0.013480124995112419
step: 340, loss: 0.017379943281412125
step: 350, loss: 0.0030202497728168964
step: 360, loss: 0.04986157268285751
epoch 13: dev_f1=0.7101827676240209, f1=0.7452054794520547, best_f1=0.743801652892562
step: 0, loss: 0.016385972499847412
step: 10, loss: 0.002607805887237191
step: 20, loss: 0.005608793348073959
step: 30, loss: 0.0007892342400737107
step: 40, loss: 0.09752070158720016
step: 50, loss: 0.002497476525604725
step: 60, loss: 3.055802881135605e-05
step: 70, loss: 0.033702973276376724
step: 80, loss: 0.0010341934394091368
step: 90, loss: 5.573461749008857e-05
step: 100, loss: 0.003289758460596204
step: 110, loss: 0.04058975726366043
step: 120, loss: 0.09987791627645493
step: 130, loss: 0.056810371577739716
step: 140, loss: 0.09113664925098419
step: 150, loss: 0.018176643177866936
step: 160, loss: 0.07144543528556824
step: 170, loss: 0.058220621198415756
step: 180, loss: 0.01998726651072502
step: 190, loss: 5.42468078492675e-05
step: 200, loss: 0.10310366004705429
step: 210, loss: 0.04124702140688896
step: 220, loss: 0.004289850126951933
step: 230, loss: 0.030805857852101326
step: 240, loss: 0.12281451374292374
step: 250, loss: 8.520209667040035e-05
step: 260, loss: 0.0021869989577680826
step: 270, loss: 0.017385419458150864
step: 280, loss: 0.005500858183950186
step: 290, loss: 0.047519199550151825
step: 300, loss: 0.07941804826259613
step: 310, loss: 0.0015569402603432536
step: 320, loss: 4.032663127873093e-05
step: 330, loss: 0.07435569912195206
step: 340, loss: 0.04384879022836685
step: 350, loss: 0.05775882676243782
step: 360, loss: 0.08050329238176346
epoch 14: dev_f1=0.7157894736842104, f1=0.7287671232876712, best_f1=0.743801652892562
step: 0, loss: 0.010713305324316025
step: 10, loss: 0.0011134365340694785
step: 20, loss: 0.002849496668204665
step: 30, loss: 0.03178686648607254
step: 40, loss: 0.01288715098053217
step: 50, loss: 0.006640553008764982
step: 60, loss: 0.07478465884923935
step: 70, loss: 0.0004975972697138786
step: 80, loss: 0.03602312132716179
step: 90, loss: 0.026837455108761787
step: 100, loss: 0.0259621050208807
step: 110, loss: 0.006255425978451967
step: 120, loss: 0.00023738163872621953
step: 130, loss: 0.00011312875722069293
step: 140, loss: 0.07121208310127258
step: 150, loss: 0.019364893436431885
step: 160, loss: 0.006166491191834211
step: 170, loss: 0.0018384137656539679
step: 180, loss: 2.7726884582079947e-05
step: 190, loss: 4.190715480945073e-05
step: 200, loss: 0.005226816050708294
step: 210, loss: 0.02136438712477684
step: 220, loss: 0.031041361391544342
step: 230, loss: 0.001120218774303794
step: 240, loss: 0.06954500079154968
step: 250, loss: 0.004251401871442795
step: 260, loss: 0.02113771252334118
step: 270, loss: 0.07348451763391495
step: 280, loss: 0.051464248448610306
step: 290, loss: 0.05426624417304993
step: 300, loss: 0.23719149827957153
step: 310, loss: 0.10730470716953278
step: 320, loss: 0.05172891542315483
step: 330, loss: 0.0452842116355896
step: 340, loss: 2.3923348635435104e-05
step: 350, loss: 0.021340908482670784
step: 360, loss: 0.08238383382558823
epoch 15: dev_f1=0.7047146401985112, f1=0.7150259067357513, best_f1=0.743801652892562
step: 0, loss: 0.16038136184215546
step: 10, loss: 0.012399274855852127
step: 20, loss: 0.014197323471307755
step: 30, loss: 0.009541278705000877
step: 40, loss: 0.04295763000845909
step: 50, loss: 0.09043808281421661
step: 60, loss: 0.018629807978868484
step: 70, loss: 0.0009059336734935641
step: 80, loss: 0.14061473309993744
step: 90, loss: 0.06007501482963562
step: 100, loss: 0.00037868929211981595
step: 110, loss: 0.004347114823758602
step: 120, loss: 0.04816228896379471
step: 130, loss: 0.029658032581210136
step: 140, loss: 0.004184248391538858
step: 150, loss: 0.015066537074744701
step: 160, loss: 0.04453452676534653
step: 170, loss: 0.03484423831105232
step: 180, loss: 0.0005286242812871933
step: 190, loss: 0.005490489769726992
step: 200, loss: 0.04678347706794739
step: 210, loss: 0.00019594210607465357
step: 220, loss: 0.015957195311784744
step: 230, loss: 0.031131954863667488
step: 240, loss: 0.018081754446029663
step: 250, loss: 0.009749404154717922
step: 260, loss: 0.0027114369440823793
step: 270, loss: 0.0580982007086277
step: 280, loss: 0.013988872058689594
step: 290, loss: 0.0014964892761781812
step: 300, loss: 0.01099315844476223
step: 310, loss: 0.012253161519765854
step: 320, loss: 0.0044666435569524765
step: 330, loss: 0.005466200411319733
step: 340, loss: 0.00374614424072206
step: 350, loss: 0.00019871076801791787
step: 360, loss: 0.0005040797987021506
epoch 16: dev_f1=0.6963350785340314, f1=0.7130919220055711, best_f1=0.743801652892562
step: 0, loss: 0.009979087859392166
step: 10, loss: 2.9090089810779318e-05
step: 20, loss: 0.00013264597509987652
step: 30, loss: 0.0022738403640687466
step: 40, loss: 0.09943313896656036
step: 50, loss: 7.499523781007156e-05
step: 60, loss: 0.00024070021754596382
step: 70, loss: 0.030857577919960022
step: 80, loss: 0.0507926382124424
step: 90, loss: 0.007163856644183397
step: 100, loss: 0.0003155001613777131
step: 110, loss: 0.003026684746146202
step: 120, loss: 0.010160244069993496
step: 130, loss: 0.0010701967403292656
step: 140, loss: 0.04653874412178993
step: 150, loss: 0.027901694178581238
step: 160, loss: 0.012523974291980267
step: 170, loss: 0.004166184458881617
step: 180, loss: 0.026026559993624687
step: 190, loss: 0.0366046205163002
step: 200, loss: 0.054100193083286285
step: 210, loss: 0.09778545051813126
step: 220, loss: 0.0006934654666110873
step: 230, loss: 0.021539852023124695
step: 240, loss: 0.0039034048095345497
step: 250, loss: 2.3215710825752467e-05
step: 260, loss: 0.0304056778550148
step: 270, loss: 0.011778715997934341
step: 280, loss: 0.08561553806066513
step: 290, loss: 0.09112608432769775
step: 300, loss: 0.07035058736801147
step: 310, loss: 0.03574260696768761
step: 320, loss: 0.08884356915950775
step: 330, loss: 0.06292445212602615
step: 340, loss: 0.0217440202832222
step: 350, loss: 0.04350314289331436
step: 360, loss: 0.027660658583045006
epoch 17: dev_f1=0.7047619047619048, f1=0.7205882352941175, best_f1=0.743801652892562
step: 0, loss: 0.04441815987229347
step: 10, loss: 0.00025204085977748036
step: 20, loss: 0.011596746742725372
step: 30, loss: 0.012169416062533855
step: 40, loss: 0.013824430294334888
step: 50, loss: 0.024837037548422813
step: 60, loss: 0.003335668006911874
step: 70, loss: 0.051696471869945526
step: 80, loss: 0.029638268053531647
step: 90, loss: 0.020684175193309784
step: 100, loss: 2.860952190530952e-05
step: 110, loss: 0.0004593147023115307
step: 120, loss: 0.03273883834481239
step: 130, loss: 0.04715636000037193
step: 140, loss: 0.0021104884799569845
step: 150, loss: 2.4065027901087888e-05
step: 160, loss: 2.1688296328647994e-05
step: 170, loss: 0.002328534610569477
step: 180, loss: 0.0019216712098568678
step: 190, loss: 0.032549429684877396
step: 200, loss: 0.021007115021348
step: 210, loss: 0.02638409659266472
step: 220, loss: 0.037856802344322205
step: 230, loss: 0.01686791144311428
step: 240, loss: 0.0028558322228491306
step: 250, loss: 0.017207540571689606
step: 260, loss: 0.010509776882827282
step: 270, loss: 0.022849442437291145
step: 280, loss: 0.050648752599954605
step: 290, loss: 0.027987103909254074
step: 300, loss: 2.3070399038260803e-05
step: 310, loss: 0.0005966284079477191
step: 320, loss: 0.09499453753232956
step: 330, loss: 0.013875966891646385
step: 340, loss: 0.014510608278214931
step: 350, loss: 0.0002551834040787071
step: 360, loss: 0.009945986792445183
epoch 18: dev_f1=0.6954177897574124, f1=0.7025495750708215, best_f1=0.743801652892562
step: 0, loss: 0.005202409811317921
step: 10, loss: 0.025792144238948822
step: 20, loss: 0.0035419315099716187
step: 30, loss: 2.112583206326235e-05
step: 40, loss: 0.023815859109163284
step: 50, loss: 0.00012742006219923496
step: 60, loss: 1.9203676856704988e-05
step: 70, loss: 0.0006437471020035446
step: 80, loss: 0.04102141037583351
step: 90, loss: 0.07269463688135147
step: 100, loss: 2.204224256274756e-05
step: 110, loss: 0.013221127912402153
step: 120, loss: 5.6501972721889615e-05
step: 130, loss: 0.13846279680728912
step: 140, loss: 0.049597349017858505
step: 150, loss: 0.0011464605340734124
step: 160, loss: 0.01886875368654728
step: 170, loss: 0.0007260155980475247
step: 180, loss: 0.053276143968105316
step: 190, loss: 0.02147144265472889
step: 200, loss: 0.031511880457401276
step: 210, loss: 5.943662108620629e-05
step: 220, loss: 0.039042066782712936
step: 230, loss: 0.02504674904048443
step: 240, loss: 2.169956496800296e-05
step: 250, loss: 0.03750894218683243
step: 260, loss: 0.05413379147648811
step: 270, loss: 0.00018610956612974405
step: 280, loss: 0.0031007020734250546
step: 290, loss: 0.015912435948848724
step: 300, loss: 0.00015225853712763637
step: 310, loss: 0.0009629928972572088
step: 320, loss: 0.047189753502607346
step: 330, loss: 0.0019670783076435328
step: 340, loss: 0.1774236410856247
step: 350, loss: 0.003986419644206762
step: 360, loss: 2.7335379854775965e-05
epoch 19: dev_f1=0.6934673366834171, f1=0.7052631578947368, best_f1=0.743801652892562
step: 0, loss: 0.00030585116473957896
step: 10, loss: 0.007043579127639532
step: 20, loss: 0.03695651888847351
step: 30, loss: 0.021679027006030083
step: 40, loss: 7.980522786965594e-05
step: 50, loss: 0.0007680983981117606
step: 60, loss: 2.4042423319770023e-05
step: 70, loss: 0.002480194205418229
step: 80, loss: 0.029672812670469284
step: 90, loss: 1.9091919966740534e-05
step: 100, loss: 0.024092091247439384
step: 110, loss: 0.0020436702761799097
step: 120, loss: 0.00018183937936555594
step: 130, loss: 0.01850632019340992
step: 140, loss: 0.00025784975150600076
step: 150, loss: 0.002047610469162464
step: 160, loss: 0.00032230830402113497
step: 170, loss: 0.005486116278916597
step: 180, loss: 0.0007873337017372251
step: 190, loss: 0.0003494212869554758
step: 200, loss: 0.010246261954307556
step: 210, loss: 0.001008738181553781
step: 220, loss: 0.028376661241054535
step: 230, loss: 0.027965180575847626
step: 240, loss: 0.0027774523478001356
step: 250, loss: 0.00021914028911851346
step: 260, loss: 0.0003395706880837679
step: 270, loss: 0.03082261234521866
step: 280, loss: 0.0001883803342934698
step: 290, loss: 0.05914847180247307
step: 300, loss: 0.027260422706604004
step: 310, loss: 0.0002885271387640387
step: 320, loss: 0.014344587922096252
step: 330, loss: 0.012751036323606968
step: 340, loss: 0.04046623781323433
step: 350, loss: 0.01507735438644886
step: 360, loss: 0.05057578533887863
epoch 20: dev_f1=0.6894736842105263, f1=0.7025495750708215, best_f1=0.743801652892562
