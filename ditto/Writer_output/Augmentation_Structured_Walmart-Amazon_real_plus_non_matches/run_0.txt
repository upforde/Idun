cuda
Device: cuda
step: 0, loss: 0.6932770013809204
step: 10, loss: 0.33124786615371704
step: 20, loss: 0.1479385793209076
step: 30, loss: 0.24017907679080963
step: 40, loss: 0.4594156742095947
step: 50, loss: 0.22948144376277924
step: 60, loss: 0.04015757143497467
step: 70, loss: 0.2417530119419098
step: 80, loss: 0.2276415377855301
step: 90, loss: 0.1358276605606079
step: 100, loss: 0.16212977468967438
step: 110, loss: 0.40291494131088257
step: 120, loss: 0.20913536846637726
step: 130, loss: 0.11795563995838165
step: 140, loss: 0.2157074213027954
step: 150, loss: 0.01919466257095337
step: 160, loss: 0.11712504178285599
step: 170, loss: 0.22889752686023712
step: 180, loss: 0.2993348240852356
step: 190, loss: 0.20737020671367645
step: 200, loss: 0.21170863509178162
step: 210, loss: 0.17995545268058777
step: 220, loss: 0.07216884195804596
step: 230, loss: 0.08589289337396622
step: 240, loss: 0.3789534866809845
step: 250, loss: 0.0748581811785698
step: 260, loss: 0.02449173852801323
step: 270, loss: 0.094969742000103
step: 280, loss: 0.3662697374820709
step: 290, loss: 0.21818280220031738
step: 300, loss: 0.04245176538825035
step: 310, loss: 0.04981129616498947
step: 320, loss: 0.08166409283876419
step: 330, loss: 0.2301677167415619
step: 340, loss: 0.1889905333518982
step: 350, loss: 0.28250107169151306
step: 360, loss: 0.07857287675142288
epoch 1: dev_f1=0.639386189258312, f1=0.6293333333333334, best_f1=0.6293333333333334
step: 0, loss: 0.11759309470653534
step: 10, loss: 0.2612234055995941
step: 20, loss: 0.07295747101306915
step: 30, loss: 0.13899526000022888
step: 40, loss: 0.103207528591156
step: 50, loss: 0.444354772567749
step: 60, loss: 0.12487178295850754
step: 70, loss: 0.04687479883432388
step: 80, loss: 0.057537585496902466
step: 90, loss: 0.03960132971405983
step: 100, loss: 0.0386909581720829
step: 110, loss: 0.0571209155023098
step: 120, loss: 0.09191562235355377
step: 130, loss: 0.08033785969018936
step: 140, loss: 0.1121094822883606
step: 150, loss: 0.20332811772823334
step: 160, loss: 0.08231998980045319
step: 170, loss: 0.05353892222046852
step: 180, loss: 0.01569977030158043
step: 190, loss: 0.04351417347788811
step: 200, loss: 0.26898348331451416
step: 210, loss: 0.01161060482263565
step: 220, loss: 0.1659601777791977
step: 230, loss: 0.13394895195960999
step: 240, loss: 0.10469424724578857
step: 250, loss: 0.19631172716617584
step: 260, loss: 0.11471088230609894
step: 270, loss: 0.15789812803268433
step: 280, loss: 0.18487948179244995
step: 290, loss: 0.04106178507208824
step: 300, loss: 0.07482223212718964
step: 310, loss: 0.17032724618911743
step: 320, loss: 0.10974877327680588
step: 330, loss: 0.020878855139017105
step: 340, loss: 0.1088356003165245
step: 350, loss: 0.20903392136096954
step: 360, loss: 0.1183086633682251
epoch 2: dev_f1=0.7356948228882835, f1=0.7507163323782234, best_f1=0.7507163323782234
step: 0, loss: 0.2591049373149872
step: 10, loss: 0.03369115665555
step: 20, loss: 0.04054778069257736
step: 30, loss: 0.056389518082141876
step: 40, loss: 0.03915821760892868
step: 50, loss: 0.09826155751943588
step: 60, loss: 0.04861673712730408
step: 70, loss: 0.0035210340283811092
step: 80, loss: 0.003619577968493104
step: 90, loss: 0.0110775800421834
step: 100, loss: 0.02481147088110447
step: 110, loss: 0.0748494490981102
step: 120, loss: 0.04977774620056152
step: 130, loss: 0.02800462394952774
step: 140, loss: 0.06772115081548691
step: 150, loss: 0.17520947754383087
step: 160, loss: 0.18686971068382263
step: 170, loss: 0.06143541634082794
step: 180, loss: 0.0067781382240355015
step: 190, loss: 0.25739628076553345
step: 200, loss: 0.045155514031648636
step: 210, loss: 0.1153327226638794
step: 220, loss: 0.17416085302829742
step: 230, loss: 0.20179174840450287
step: 240, loss: 0.08303600549697876
step: 250, loss: 0.1937260627746582
step: 260, loss: 0.012349884025752544
step: 270, loss: 0.1739765852689743
step: 280, loss: 0.12589411437511444
step: 290, loss: 0.0015395608497783542
step: 300, loss: 0.02865554764866829
step: 310, loss: 0.12290284782648087
step: 320, loss: 0.06407217681407928
step: 330, loss: 0.07534954696893692
step: 340, loss: 0.06321454048156738
step: 350, loss: 0.07843378186225891
step: 360, loss: 0.14438733458518982
epoch 3: dev_f1=0.7341772151898734, f1=0.7187499999999999, best_f1=0.7507163323782234
step: 0, loss: 0.06443912535905838
step: 10, loss: 0.08396782726049423
step: 20, loss: 0.03923279047012329
step: 30, loss: 0.06567579507827759
step: 40, loss: 0.11315086483955383
step: 50, loss: 0.09229378402233124
step: 60, loss: 0.03409654274582863
step: 70, loss: 0.10977323353290558
step: 80, loss: 0.043038975447416306
step: 90, loss: 0.059764713048934937
step: 100, loss: 0.02279922179877758
step: 110, loss: 0.08754116296768188
step: 120, loss: 0.10469711571931839
step: 130, loss: 0.02013401687145233
step: 140, loss: 0.025565478950738907
step: 150, loss: 0.09268034994602203
step: 160, loss: 0.0012500762240961194
step: 170, loss: 0.057868339121341705
step: 180, loss: 0.2149714082479477
step: 190, loss: 0.28024277091026306
step: 200, loss: 0.11012231558561325
step: 210, loss: 0.03287695348262787
step: 220, loss: 0.0786142647266388
step: 230, loss: 0.054329194128513336
step: 240, loss: 0.16837447881698608
step: 250, loss: 0.05080219358205795
step: 260, loss: 0.09871269762516022
step: 270, loss: 0.11699321866035461
step: 280, loss: 0.07774760574102402
step: 290, loss: 0.059576865285634995
step: 300, loss: 0.01509688701480627
step: 310, loss: 0.10124789923429489
step: 320, loss: 0.05819452181458473
step: 330, loss: 0.00038493447937071323
step: 340, loss: 0.013570926152169704
step: 350, loss: 0.039091188460588455
step: 360, loss: 0.05088098719716072
epoch 4: dev_f1=0.75177304964539, f1=0.7334963325183375, best_f1=0.7334963325183375
step: 0, loss: 0.0735543891787529
step: 10, loss: 0.03301225230097771
step: 20, loss: 0.10491608828306198
step: 30, loss: 0.05512787029147148
step: 40, loss: 0.07945926487445831
step: 50, loss: 0.10972870141267776
step: 60, loss: 0.04906340315937996
step: 70, loss: 0.0006991504342295229
step: 80, loss: 0.01654709503054619
step: 90, loss: 0.044843386858701706
step: 100, loss: 0.09853821992874146
step: 110, loss: 0.06043481454253197
step: 120, loss: 0.008275137282907963
step: 130, loss: 0.0015282018575817347
step: 140, loss: 0.030856149271130562
step: 150, loss: 0.03148647025227547
step: 160, loss: 0.003784129861742258
step: 170, loss: 0.2650868892669678
step: 180, loss: 0.10992026329040527
step: 190, loss: 0.012675769627094269
step: 200, loss: 0.05484619364142418
step: 210, loss: 0.03444838523864746
step: 220, loss: 0.07743322104215622
step: 230, loss: 0.03561396151781082
step: 240, loss: 0.03547031059861183
step: 250, loss: 0.02000769041478634
step: 260, loss: 0.06846391409635544
step: 270, loss: 0.031726330518722534
step: 280, loss: 0.07043160498142242
step: 290, loss: 0.07456453889608383
step: 300, loss: 0.06076178327202797
step: 310, loss: 0.06236030533909798
step: 320, loss: 0.0005506221204996109
step: 330, loss: 0.16750697791576385
step: 340, loss: 0.15141627192497253
step: 350, loss: 0.06270750612020493
step: 360, loss: 0.06575343757867813
epoch 5: dev_f1=0.7659574468085106, f1=0.7640449438202247, best_f1=0.7640449438202247
step: 0, loss: 0.12104930728673935
step: 10, loss: 0.02563103288412094
step: 20, loss: 0.017549332231283188
step: 30, loss: 0.07421956211328506
step: 40, loss: 0.05046387389302254
step: 50, loss: 0.0007745788316242397
step: 60, loss: 0.042291898280382156
step: 70, loss: 0.053196512162685394
step: 80, loss: 0.030202707275748253
step: 90, loss: 0.11665727943181992
step: 100, loss: 0.08727573603391647
step: 110, loss: 0.04386988282203674
step: 120, loss: 0.045989952981472015
step: 130, loss: 0.022057536989450455
step: 140, loss: 0.1017785519361496
step: 150, loss: 0.013848231174051762
step: 160, loss: 0.09281747043132782
step: 170, loss: 0.03403646871447563
step: 180, loss: 0.04475969448685646
step: 190, loss: 0.09736751019954681
step: 200, loss: 0.05536280944943428
step: 210, loss: 0.0005505321896634996
step: 220, loss: 0.10477400571107864
step: 230, loss: 0.08502855896949768
step: 240, loss: 0.03675541654229164
step: 250, loss: 0.044005315750837326
step: 260, loss: 0.02923075295984745
step: 270, loss: 0.031206676736474037
step: 280, loss: 0.24234826862812042
step: 290, loss: 0.07646836340427399
step: 300, loss: 0.17052152752876282
step: 310, loss: 0.12039965391159058
step: 320, loss: 0.10971823334693909
step: 330, loss: 0.0265338234603405
step: 340, loss: 0.07232604175806046
step: 350, loss: 0.05337608978152275
step: 360, loss: 0.0031163240782916546
epoch 6: dev_f1=0.7647058823529412, f1=0.7403314917127072, best_f1=0.7640449438202247
step: 0, loss: 0.05624665692448616
step: 10, loss: 0.03394223377108574
step: 20, loss: 0.1287471055984497
step: 30, loss: 0.02435445412993431
step: 40, loss: 0.05287984013557434
step: 50, loss: 0.006195940542966127
step: 60, loss: 0.06018670275807381
step: 70, loss: 0.018336940556764603
step: 80, loss: 0.006423177197575569
step: 90, loss: 0.03194389119744301
step: 100, loss: 0.013243437744677067
step: 110, loss: 0.08622444421052933
step: 120, loss: 0.024620315060019493
step: 130, loss: 0.030496884137392044
step: 140, loss: 0.0757085531949997
step: 150, loss: 0.1566176563501358
step: 160, loss: 0.28918203711509705
step: 170, loss: 0.05295944586396217
step: 180, loss: 0.12653207778930664
step: 190, loss: 0.02271549589931965
step: 200, loss: 0.029928628355264664
step: 210, loss: 0.054494064301252365
step: 220, loss: 0.07746551930904388
step: 230, loss: 0.008669489994645119
step: 240, loss: 0.12121224403381348
step: 250, loss: 0.07152649015188217
step: 260, loss: 0.00179671763908118
step: 270, loss: 0.09743606299161911
step: 280, loss: 0.00820760615170002
step: 290, loss: 0.001297495444305241
step: 300, loss: 0.00969872996211052
step: 310, loss: 0.011088049039244652
step: 320, loss: 0.09629576653242111
step: 330, loss: 0.17018699645996094
step: 340, loss: 0.03149455040693283
step: 350, loss: 0.09417799860239029
step: 360, loss: 0.11038989573717117
epoch 7: dev_f1=0.7202072538860104, f1=0.7351351351351353, best_f1=0.7640449438202247
step: 0, loss: 0.028956715017557144
step: 10, loss: 0.14508698880672455
step: 20, loss: 0.053585201501846313
step: 30, loss: 0.008883129805326462
step: 40, loss: 0.0587419830262661
step: 50, loss: 0.01132532674819231
step: 60, loss: 0.1429828256368637
step: 70, loss: 0.06759390234947205
step: 80, loss: 0.11438369005918503
step: 90, loss: 0.02201862446963787
step: 100, loss: 0.024229245260357857
step: 110, loss: 0.10572829097509384
step: 120, loss: 0.0057392180897295475
step: 130, loss: 0.05495176091790199
step: 140, loss: 0.032409872859716415
step: 150, loss: 0.08784732967615128
step: 160, loss: 0.026775280013680458
step: 170, loss: 0.10422369837760925
step: 180, loss: 0.014066335745155811
step: 190, loss: 0.06330960988998413
step: 200, loss: 0.0762479156255722
step: 210, loss: 0.04292532056570053
step: 220, loss: 0.05201209336519241
step: 230, loss: 0.009117770940065384
step: 240, loss: 0.035476941615343094
step: 250, loss: 0.04896693676710129
step: 260, loss: 0.11568820476531982
step: 270, loss: 0.05618329346179962
step: 280, loss: 0.04793681204319
step: 290, loss: 0.06248351186513901
step: 300, loss: 0.025111673399806023
step: 310, loss: 0.06315407156944275
step: 320, loss: 0.09180927276611328
step: 330, loss: 0.08005683124065399
step: 340, loss: 0.009530831128358841
step: 350, loss: 0.11413982510566711
step: 360, loss: 0.003434157930314541
epoch 8: dev_f1=0.7277227722772278, f1=0.7223719676549865, best_f1=0.7640449438202247
step: 0, loss: 0.044901732355356216
step: 10, loss: 0.03406721353530884
step: 20, loss: 0.0002493149950169027
step: 30, loss: 0.13238020241260529
step: 40, loss: 0.05422866716980934
step: 50, loss: 0.003926035016775131
step: 60, loss: 0.1841699182987213
step: 70, loss: 0.0011524427682161331
step: 80, loss: 0.07457586377859116
step: 90, loss: 0.04476368799805641
step: 100, loss: 0.026380369439721107
step: 110, loss: 0.03617408871650696
step: 120, loss: 0.09236480295658112
step: 130, loss: 0.019430387765169144
step: 140, loss: 0.017686937004327774
step: 150, loss: 0.009942490607500076
step: 160, loss: 0.030365310609340668
step: 170, loss: 0.06000079959630966
step: 180, loss: 0.020050350576639175
step: 190, loss: 0.009356331080198288
step: 200, loss: 0.14892850816249847
step: 210, loss: 0.011991643346846104
step: 220, loss: 0.00019201393297407776
step: 230, loss: 0.08922865241765976
step: 240, loss: 0.01418935414403677
step: 250, loss: 0.06337787955999374
step: 260, loss: 0.0581563375890255
step: 270, loss: 0.046647049486637115
step: 280, loss: 0.06453953683376312
step: 290, loss: 0.0541890412569046
step: 300, loss: 0.03191182389855385
step: 310, loss: 0.06234981119632721
step: 320, loss: 0.03131356090307236
step: 330, loss: 0.0010096863843500614
step: 340, loss: 0.007433001417666674
step: 350, loss: 0.014196999371051788
step: 360, loss: 0.005152290221303701
epoch 9: dev_f1=0.733509234828496, f1=0.7267605633802817, best_f1=0.7640449438202247
step: 0, loss: 0.024284929037094116
step: 10, loss: 0.1151658222079277
step: 20, loss: 0.06443782150745392
step: 30, loss: 0.04167783632874489
step: 40, loss: 0.033440615981817245
step: 50, loss: 0.0031582664232701063
step: 60, loss: 0.0398082509636879
step: 70, loss: 0.005905108526349068
step: 80, loss: 0.0734633356332779
step: 90, loss: 0.08717741817235947
step: 100, loss: 0.09401973336935043
step: 110, loss: 0.08070177584886551
step: 120, loss: 0.018942808732390404
step: 130, loss: 0.0005796614568680525
step: 140, loss: 0.041350651532411575
step: 150, loss: 0.14202958345413208
step: 160, loss: 0.006225328892469406
step: 170, loss: 0.007486432325094938
step: 180, loss: 0.024540770798921585
step: 190, loss: 8.679106394993141e-05
step: 200, loss: 0.0013089800486341119
step: 210, loss: 0.012550664134323597
step: 220, loss: 0.07429757714271545
step: 230, loss: 0.05272366479039192
step: 240, loss: 0.011413304135203362
step: 250, loss: 0.0019191906321793795
step: 260, loss: 0.021043721586465836
step: 270, loss: 0.000288462673779577
step: 280, loss: 0.019186917692422867
step: 290, loss: 0.03529622033238411
step: 300, loss: 0.008913012221455574
step: 310, loss: 0.011804903857409954
step: 320, loss: 0.08740082383155823
step: 330, loss: 0.08811318129301071
step: 340, loss: 0.01893088035285473
step: 350, loss: 0.014803828671574593
step: 360, loss: 0.039314933121204376
epoch 10: dev_f1=0.7422680412371134, f1=0.7506849315068493, best_f1=0.7640449438202247
step: 0, loss: 0.0765366181731224
step: 10, loss: 0.0009456518455408514
step: 20, loss: 0.023044390603899956
step: 30, loss: 0.085760697722435
step: 40, loss: 0.01742885820567608
step: 50, loss: 0.03324653580784798
step: 60, loss: 0.008491085842251778
step: 70, loss: 0.006449706852436066
step: 80, loss: 0.010397059842944145
step: 90, loss: 0.05176183581352234
step: 100, loss: 0.02908247523009777
step: 110, loss: 0.005252521019428968
step: 120, loss: 0.01602374203503132
step: 130, loss: 0.0038363360799849033
step: 140, loss: 0.05974556505680084
step: 150, loss: 0.019903233274817467
step: 160, loss: 0.0053009591065347195
step: 170, loss: 0.03641566261649132
step: 180, loss: 0.021361209452152252
step: 190, loss: 0.05437527969479561
step: 200, loss: 0.0526270717382431
step: 210, loss: 0.14433971047401428
step: 220, loss: 0.0851697027683258
step: 230, loss: 0.009919161908328533
step: 240, loss: 0.00012112069816794246
step: 250, loss: 0.1885184794664383
step: 260, loss: 0.003969457931816578
step: 270, loss: 0.0027320398949086666
step: 280, loss: 0.026284340769052505
step: 290, loss: 0.029041996225714684
step: 300, loss: 0.05548878014087677
step: 310, loss: 0.19854110479354858
step: 320, loss: 0.05230037868022919
step: 330, loss: 0.0016562168020755053
step: 340, loss: 0.08279499411582947
step: 350, loss: 0.13285322487354279
step: 360, loss: 0.003667843993753195
epoch 11: dev_f1=0.7475247524752476, f1=0.753315649867374, best_f1=0.7640449438202247
step: 0, loss: 0.02004343271255493
step: 10, loss: 0.007793935015797615
step: 20, loss: 0.011292541399598122
step: 30, loss: 0.0006911549717187881
step: 40, loss: 0.020049236714839935
step: 50, loss: 0.0948597863316536
step: 60, loss: 0.0077065397053956985
step: 70, loss: 0.02754448540508747
step: 80, loss: 0.06474847346544266
step: 90, loss: 0.1019730493426323
step: 100, loss: 0.09742743521928787
step: 110, loss: 0.01699555106461048
step: 120, loss: 0.057150207459926605
step: 130, loss: 0.004549744073301554
step: 140, loss: 0.04980478063225746
step: 150, loss: 0.07475078850984573
step: 160, loss: 0.01455150917172432
step: 170, loss: 0.023001354187726974
step: 180, loss: 0.0026524290442466736
step: 190, loss: 0.09156037867069244
step: 200, loss: 0.040049247443675995
step: 210, loss: 0.1028224527835846
step: 220, loss: 0.0020112174097448587
step: 230, loss: 0.027014417573809624
step: 240, loss: 0.008016402833163738
step: 250, loss: 0.018894586712121964
step: 260, loss: 0.06941031664609909
step: 270, loss: 0.01955650933086872
step: 280, loss: 0.004216282162815332
step: 290, loss: 0.03261366859078407
step: 300, loss: 0.06924249976873398
step: 310, loss: 0.0671868845820427
step: 320, loss: 0.017288077622652054
step: 330, loss: 0.09976250678300858
step: 340, loss: 0.09302110970020294
step: 350, loss: 0.05596953257918358
step: 360, loss: 0.024833261966705322
epoch 12: dev_f1=0.7403598971722366, f1=0.7423822714681441, best_f1=0.7640449438202247
step: 0, loss: 0.006019599735736847
step: 10, loss: 0.002088349312543869
step: 20, loss: 0.004630839917808771
step: 30, loss: 0.0023682056926190853
step: 40, loss: 0.00013254392251837999
step: 50, loss: 0.003912021871656179
step: 60, loss: 0.0008135742973536253
step: 70, loss: 0.01150825247168541
step: 80, loss: 0.002187559613958001
step: 90, loss: 0.0016189786838367581
step: 100, loss: 0.11734753847122192
step: 110, loss: 0.0300297811627388
step: 120, loss: 9.748653246788308e-05
step: 130, loss: 0.07562101632356644
step: 140, loss: 0.0036269379779696465
step: 150, loss: 0.0193320419639349
step: 160, loss: 0.02181810513138771
step: 170, loss: 0.04969615116715431
step: 180, loss: 0.029717443510890007
step: 190, loss: 0.083835668861866
step: 200, loss: 0.02704370580613613
step: 210, loss: 0.04321872815489769
step: 220, loss: 0.00018135711434297264
step: 230, loss: 0.001196530763991177
step: 240, loss: 0.05131559073925018
step: 250, loss: 0.10165576636791229
step: 260, loss: 0.0849645659327507
step: 270, loss: 0.0068806242197752
step: 280, loss: 0.002373595954850316
step: 290, loss: 0.0006832997896708548
step: 300, loss: 0.0553692951798439
step: 310, loss: 0.05456866696476936
step: 320, loss: 0.026414405554533005
step: 330, loss: 0.0013849874958395958
step: 340, loss: 0.0009533147676847875
step: 350, loss: 0.04042235389351845
step: 360, loss: 0.001016519614495337
epoch 13: dev_f1=0.7511737089201878, f1=0.7344913151364764, best_f1=0.7640449438202247
step: 0, loss: 0.06239345297217369
step: 10, loss: 0.003521548118442297
step: 20, loss: 0.0003234387841075659
step: 30, loss: 0.04330536723136902
step: 40, loss: 0.01231081411242485
step: 50, loss: 0.036641675978899
step: 60, loss: 3.076990833505988e-05
step: 70, loss: 4.134709161007777e-05
step: 80, loss: 0.0008716156589798629
step: 90, loss: 0.05023184046149254
step: 100, loss: 0.0007766835042275488
step: 110, loss: 0.016123512759804726
step: 120, loss: 0.05046849697828293
step: 130, loss: 0.008627879433333874
step: 140, loss: 0.0009799605468288064
step: 150, loss: 0.00016027537640184164
step: 160, loss: 0.010569390840828419
step: 170, loss: 0.0006661823717877269
step: 180, loss: 0.0377640500664711
step: 190, loss: 0.01361046452075243
step: 200, loss: 0.005256402771919966
step: 210, loss: 0.002270455239340663
step: 220, loss: 0.0015548324445262551
step: 230, loss: 0.008131744340062141
step: 240, loss: 0.0730379968881607
step: 250, loss: 0.0008793245069682598
step: 260, loss: 0.028998546302318573
step: 270, loss: 0.004464400466531515
step: 280, loss: 0.002015070989727974
step: 290, loss: 0.007990720681846142
step: 300, loss: 0.11253352463245392
step: 310, loss: 0.00212156237103045
step: 320, loss: 0.020771397277712822
step: 330, loss: 0.07684630155563354
step: 340, loss: 0.0006933195982128382
step: 350, loss: 0.018723182380199432
step: 360, loss: 0.029172033071517944
epoch 14: dev_f1=0.7391304347826088, f1=0.7022900763358778, best_f1=0.7640449438202247
step: 0, loss: 0.0352415032684803
step: 10, loss: 0.012304291129112244
step: 20, loss: 0.039958808571100235
step: 30, loss: 0.01984102837741375
step: 40, loss: 0.02384445257484913
step: 50, loss: 0.000846737006213516
step: 60, loss: 0.0016222673002630472
step: 70, loss: 0.013738797977566719
step: 80, loss: 0.17999377846717834
step: 90, loss: 0.016689633950591087
step: 100, loss: 0.03457114100456238
step: 110, loss: 0.022227244451642036
step: 120, loss: 0.009475026279687881
step: 130, loss: 0.0011913166381418705
step: 140, loss: 0.037715617567300797
step: 150, loss: 0.00282842805609107
step: 160, loss: 0.20911598205566406
step: 170, loss: 0.004888416733592749
step: 180, loss: 0.0020116078667342663
step: 190, loss: 0.031567592173814774
step: 200, loss: 0.01806022971868515
step: 210, loss: 0.01576511189341545
step: 220, loss: 0.0110686756670475
step: 230, loss: 0.06528382003307343
step: 240, loss: 0.008858295157551765
step: 250, loss: 0.03444915637373924
step: 260, loss: 0.013715129345655441
step: 270, loss: 0.026256436482071877
step: 280, loss: 0.06154879182577133
step: 290, loss: 0.002362188883125782
step: 300, loss: 0.004061673767864704
step: 310, loss: 0.0302415918558836
step: 320, loss: 0.022047655656933784
step: 330, loss: 0.01791851408779621
step: 340, loss: 0.001260860706679523
step: 350, loss: 0.054746467620134354
step: 360, loss: 0.01857702061533928
epoch 15: dev_f1=0.7427184466019418, f1=0.7131782945736433, best_f1=0.7640449438202247
step: 0, loss: 0.003638083580881357
step: 10, loss: 0.050895825028419495
step: 20, loss: 0.0306523647159338
step: 30, loss: 0.020714718848466873
step: 40, loss: 0.0004936797195114195
step: 50, loss: 0.03298070281744003
step: 60, loss: 0.04471350833773613
step: 70, loss: 0.030974747613072395
step: 80, loss: 0.02685195952653885
step: 90, loss: 0.05042747035622597
step: 100, loss: 0.03283654525876045
step: 110, loss: 0.0036130016669631004
step: 120, loss: 0.0009030714281834662
step: 130, loss: 0.007682716939598322
step: 140, loss: 4.768298094859347e-05
step: 150, loss: 0.034792643040418625
step: 160, loss: 0.00022133691527415067
step: 170, loss: 0.01999453268945217
step: 180, loss: 0.01700449362397194
step: 190, loss: 0.0021201428025960922
step: 200, loss: 0.052868664264678955
step: 210, loss: 3.400137575226836e-05
step: 220, loss: 0.029449691995978355
step: 230, loss: 0.02918568067252636
step: 240, loss: 0.0006953985430300236
step: 250, loss: 0.03161022439599037
step: 260, loss: 0.007778469938784838
step: 270, loss: 0.0009100582101382315
step: 280, loss: 0.005613512825220823
step: 290, loss: 0.0157887265086174
step: 300, loss: 0.02722197026014328
step: 310, loss: 0.007284972351044416
step: 320, loss: 7.314418326132e-05
step: 330, loss: 0.07531163841485977
step: 340, loss: 0.02633838541805744
step: 350, loss: 0.0004342565080150962
step: 360, loss: 0.00014405688853003085
epoch 16: dev_f1=0.73, f1=0.7157894736842104, best_f1=0.7640449438202247
step: 0, loss: 0.0008189278887584805
step: 10, loss: 0.0013548042625188828
step: 20, loss: 2.82964338111924e-05
step: 30, loss: 0.02391001395881176
step: 40, loss: 0.061601750552654266
step: 50, loss: 0.00016303075244650245
step: 60, loss: 0.0011083014542236924
step: 70, loss: 0.00042785261757671833
step: 80, loss: 0.03773689642548561
step: 90, loss: 0.023312801495194435
step: 100, loss: 0.010988791473209858
step: 110, loss: 0.038533955812454224
step: 120, loss: 0.01099400408565998
step: 130, loss: 0.03611678257584572
step: 140, loss: 0.0076577914878726006
step: 150, loss: 6.013559686834924e-05
step: 160, loss: 0.055862534791231155
step: 170, loss: 0.025075608864426613
step: 180, loss: 0.11186984181404114
step: 190, loss: 0.048317622393369675
step: 200, loss: 0.0014814973110333085
step: 210, loss: 8.297628664877266e-05
step: 220, loss: 0.0052918377332389355
step: 230, loss: 0.0010479431366547942
step: 240, loss: 0.0005990301724523306
step: 250, loss: 0.0003951040853280574
step: 260, loss: 0.09635254740715027
step: 270, loss: 0.02369868941605091
step: 280, loss: 0.04847864434123039
step: 290, loss: 0.0016052817227318883
step: 300, loss: 0.029346948489546776
step: 310, loss: 3.352994826855138e-05
step: 320, loss: 2.4679500711499713e-05
step: 330, loss: 0.04717078432440758
step: 340, loss: 2.7405336368246935e-05
step: 350, loss: 4.4036783947376534e-05
step: 360, loss: 0.000646978325676173
epoch 17: dev_f1=0.747663551401869, f1=0.7167919799498748, best_f1=0.7640449438202247
step: 0, loss: 0.0004874838632531464
step: 10, loss: 0.02622319385409355
step: 20, loss: 0.036417681723833084
step: 30, loss: 0.006194811314344406
step: 40, loss: 0.00502468878403306
step: 50, loss: 0.026572978124022484
step: 60, loss: 0.00016387902724090964
step: 70, loss: 0.00021907036716584116
step: 80, loss: 0.005737246014177799
step: 90, loss: 0.0005772782606072724
step: 100, loss: 0.04872797802090645
step: 110, loss: 0.012746370397508144
step: 120, loss: 9.867918561212718e-05
step: 130, loss: 0.02882351167500019
step: 140, loss: 9.476134437136352e-05
step: 150, loss: 0.0012159006437286735
step: 160, loss: 0.0436372384428978
step: 170, loss: 9.056057024281472e-05
step: 180, loss: 4.2106967157451436e-05
step: 190, loss: 0.022744033485651016
step: 200, loss: 0.19721519947052002
step: 210, loss: 0.03487410396337509
step: 220, loss: 0.035404905676841736
step: 230, loss: 0.011882156133651733
step: 240, loss: 0.02821020595729351
step: 250, loss: 0.009411834180355072
step: 260, loss: 0.0027779918164014816
step: 270, loss: 0.011221552267670631
step: 280, loss: 0.044855136424303055
step: 290, loss: 0.0006011313525959849
step: 300, loss: 0.0014988223556429148
step: 310, loss: 0.020523812621831894
step: 320, loss: 0.025000568479299545
step: 330, loss: 0.02524655871093273
step: 340, loss: 0.0018906815676018596
step: 350, loss: 0.0037479118909686804
step: 360, loss: 0.020157968625426292
epoch 18: dev_f1=0.7500000000000001, f1=0.7239583333333334, best_f1=0.7640449438202247
step: 0, loss: 0.00039038911927491426
step: 10, loss: 0.028234658762812614
step: 20, loss: 0.0004482177901081741
step: 30, loss: 0.002868443261831999
step: 40, loss: 0.009712588973343372
step: 50, loss: 3.167866088915616e-05
step: 60, loss: 0.01588265970349312
step: 70, loss: 0.00019507447723299265
step: 80, loss: 0.027500808238983154
step: 90, loss: 6.787555321352556e-05
step: 100, loss: 6.36733093415387e-05
step: 110, loss: 0.0005211338866502047
step: 120, loss: 0.004429211840033531
step: 130, loss: 0.01123634073883295
step: 140, loss: 0.03620050475001335
step: 150, loss: 0.008161675184965134
step: 160, loss: 0.02602474018931389
step: 170, loss: 0.009811037220060825
step: 180, loss: 0.013407775200903416
step: 190, loss: 0.0018926121992990375
step: 200, loss: 0.01207135058939457
step: 210, loss: 5.0296515837544575e-05
step: 220, loss: 0.10166078805923462
step: 230, loss: 0.00034192073508165777
step: 240, loss: 0.003729742718860507
step: 250, loss: 0.00036595072015188634
step: 260, loss: 0.10624796152114868
step: 270, loss: 0.005420283414423466
step: 280, loss: 0.027341891080141068
step: 290, loss: 0.03488248586654663
step: 300, loss: 0.0029985338915139437
step: 310, loss: 0.0875614583492279
step: 320, loss: 0.004722628276795149
step: 330, loss: 0.00010207291052211076
step: 340, loss: 0.005172166973352432
step: 350, loss: 0.04974951967597008
step: 360, loss: 0.000201430098968558
epoch 19: dev_f1=0.7389162561576355, f1=0.7216494845360825, best_f1=0.7640449438202247
step: 0, loss: 0.0005503441789187491
step: 10, loss: 0.027575787156820297
step: 20, loss: 0.01825287565588951
step: 30, loss: 0.0004219455295242369
step: 40, loss: 0.0012985910288989544
step: 50, loss: 0.03895089775323868
step: 60, loss: 0.0021239309571683407
step: 70, loss: 0.08279570937156677
step: 80, loss: 0.008409255184233189
step: 90, loss: 0.0010481063509359956
step: 100, loss: 0.07292347401380539
step: 110, loss: 0.00035702442983165383
step: 120, loss: 0.0014622752787545323
step: 130, loss: 2.423621481284499e-05
step: 140, loss: 0.0349733866751194
step: 150, loss: 0.04735291749238968
step: 160, loss: 0.012821774929761887
step: 170, loss: 0.027396688237786293
step: 180, loss: 0.0012207882246002555
step: 190, loss: 0.0025441902689635754
step: 200, loss: 0.01445959135890007
step: 210, loss: 0.0232625063508749
step: 220, loss: 0.008591648191213608
step: 230, loss: 0.03428279608488083
step: 240, loss: 0.02455606870353222
step: 250, loss: 0.05636363476514816
step: 260, loss: 0.0013868912355974317
step: 270, loss: 0.0005775554454885423
step: 280, loss: 0.0003066138597205281
step: 290, loss: 0.00013848654634784907
step: 300, loss: 0.059485506266355515
step: 310, loss: 0.0007448622491210699
step: 320, loss: 0.016306068748235703
step: 330, loss: 0.018137596547603607
step: 340, loss: 0.008772390894591808
step: 350, loss: 0.0006582363275811076
step: 360, loss: 0.01175153348594904
epoch 20: dev_f1=0.7429906542056074, f1=0.72, best_f1=0.7640449438202247
