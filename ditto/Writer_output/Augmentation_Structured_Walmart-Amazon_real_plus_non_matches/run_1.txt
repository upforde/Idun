cuda
Device: cuda
step: 0, loss: 0.8612173199653625
step: 10, loss: 0.34207308292388916
step: 20, loss: 0.15265147387981415
step: 30, loss: 0.14654509723186493
step: 40, loss: 0.14134706556797028
step: 50, loss: 0.052721139043569565
step: 60, loss: 0.16354890167713165
step: 70, loss: 0.23933672904968262
step: 80, loss: 0.3258228600025177
step: 90, loss: 0.395874559879303
step: 100, loss: 0.04527588188648224
step: 110, loss: 0.1397833228111267
step: 120, loss: 0.041035812348127365
step: 130, loss: 0.1356147974729538
step: 140, loss: 0.31929948925971985
step: 150, loss: 0.7100845575332642
step: 160, loss: 0.1520925611257553
step: 170, loss: 0.23486807942390442
step: 180, loss: 0.06168181449174881
step: 190, loss: 0.22425389289855957
step: 200, loss: 0.3793860375881195
step: 210, loss: 0.21872855722904205
step: 220, loss: 0.2292063981294632
step: 230, loss: 0.19459405541419983
step: 240, loss: 0.168702632188797
step: 250, loss: 0.17313094437122345
step: 260, loss: 0.076545849442482
step: 270, loss: 0.12338016927242279
step: 280, loss: 0.36478474736213684
step: 290, loss: 0.19920720160007477
step: 300, loss: 0.2844836711883545
step: 310, loss: 0.21344618499279022
step: 320, loss: 0.24847961962223053
step: 330, loss: 0.03106413222849369
step: 340, loss: 0.01490350067615509
step: 350, loss: 0.1278463751077652
step: 360, loss: 0.14198799431324005
epoch 1: dev_f1=0.5161290322580646, f1=0.5782493368700266, best_f1=0.5782493368700266
step: 0, loss: 0.08473637700080872
step: 10, loss: 0.26095065474510193
step: 20, loss: 0.025334756821393967
step: 30, loss: 0.026128200814127922
step: 40, loss: 0.05638106167316437
step: 50, loss: 0.55238276720047
step: 60, loss: 0.2266983985900879
step: 70, loss: 0.12391585856676102
step: 80, loss: 0.09832214564085007
step: 90, loss: 0.24360232055187225
step: 100, loss: 0.07600367814302444
step: 110, loss: 0.07250084728002548
step: 120, loss: 0.11559348553419113
step: 130, loss: 0.2059769630432129
step: 140, loss: 0.15799759328365326
step: 150, loss: 0.17262130975723267
step: 160, loss: 0.1649896502494812
step: 170, loss: 0.1240798607468605
step: 180, loss: 0.31144845485687256
step: 190, loss: 0.3115209639072418
step: 200, loss: 0.21996170282363892
step: 210, loss: 0.03243039548397064
step: 220, loss: 0.03819103166460991
step: 230, loss: 0.33776918053627014
step: 240, loss: 0.02128862962126732
step: 250, loss: 0.1992676556110382
step: 260, loss: 0.16149833798408508
step: 270, loss: 0.01651107519865036
step: 280, loss: 0.1402454674243927
step: 290, loss: 0.0383121483027935
step: 300, loss: 0.0570383295416832
step: 310, loss: 0.18447203934192657
step: 320, loss: 0.053425442427396774
step: 330, loss: 0.06890157610177994
step: 340, loss: 0.11414127051830292
step: 350, loss: 0.09945741295814514
step: 360, loss: 0.0032799176406115294
epoch 2: dev_f1=0.6997518610421836, f1=0.7213930348258706, best_f1=0.7213930348258706
step: 0, loss: 0.0942002534866333
step: 10, loss: 0.26639115810394287
step: 20, loss: 0.10667932778596878
step: 30, loss: 0.11554475873708725
step: 40, loss: 0.06445440649986267
step: 50, loss: 0.021419700235128403
step: 60, loss: 0.02754073403775692
step: 70, loss: 0.06144418194890022
step: 80, loss: 0.04508103430271149
step: 90, loss: 0.05972757935523987
step: 100, loss: 0.06531432271003723
step: 110, loss: 0.01200571097433567
step: 120, loss: 0.11021684855222702
step: 130, loss: 0.04937126114964485
step: 140, loss: 0.014440612867474556
step: 150, loss: 0.03379201143980026
step: 160, loss: 0.11360251158475876
step: 170, loss: 0.010601024143397808
step: 180, loss: 0.15557017922401428
step: 190, loss: 0.045612625777721405
step: 200, loss: 0.07946382462978363
step: 210, loss: 0.20425772666931152
step: 220, loss: 0.07680673897266388
step: 230, loss: 0.02247455157339573
step: 240, loss: 0.029730062931776047
step: 250, loss: 0.10117876529693604
step: 260, loss: 0.0713185966014862
step: 270, loss: 0.11199972778558731
step: 280, loss: 0.019170014187693596
step: 290, loss: 0.07146506011486053
step: 300, loss: 0.12363123893737793
step: 310, loss: 0.08042606711387634
step: 320, loss: 0.08233581483364105
step: 330, loss: 0.19829371571540833
step: 340, loss: 0.04373960569500923
step: 350, loss: 0.051135968416929245
step: 360, loss: 0.009025820530951023
epoch 3: dev_f1=0.7139240506329113, f1=0.7296587926509187, best_f1=0.7296587926509187
step: 0, loss: 0.10381332784891129
step: 10, loss: 0.0739235058426857
step: 20, loss: 0.11288520693778992
step: 30, loss: 0.09319420903921127
step: 40, loss: 0.11683996021747589
step: 50, loss: 0.09327907860279083
step: 60, loss: 0.054915569722652435
step: 70, loss: 0.053783927112817764
step: 80, loss: 0.06551865488290787
step: 90, loss: 0.15772545337677002
step: 100, loss: 0.0404951274394989
step: 110, loss: 0.010888546705245972
step: 120, loss: 0.02405884675681591
step: 130, loss: 0.027280842885375023
step: 140, loss: 0.06378895789384842
step: 150, loss: 0.0409342497587204
step: 160, loss: 0.03126762807369232
step: 170, loss: 0.020915744826197624
step: 180, loss: 0.06689397990703583
step: 190, loss: 0.10995905101299286
step: 200, loss: 0.19976307451725006
step: 210, loss: 0.07837332040071487
step: 220, loss: 0.06801922619342804
step: 230, loss: 0.05162747576832771
step: 240, loss: 0.00788834411650896
step: 250, loss: 0.012786274775862694
step: 260, loss: 0.23902106285095215
step: 270, loss: 0.1010967493057251
step: 280, loss: 0.04916326701641083
step: 290, loss: 0.11702984571456909
step: 300, loss: 0.029370635747909546
step: 310, loss: 0.0012102429755032063
step: 320, loss: 0.14533782005310059
step: 330, loss: 0.12362179905176163
step: 340, loss: 0.00011949513282161206
step: 350, loss: 0.034248653799295425
step: 360, loss: 0.10573960095643997
epoch 4: dev_f1=0.7314578005115089, f1=0.7642276422764227, best_f1=0.7642276422764227
step: 0, loss: 0.12314998358488083
step: 10, loss: 0.022574201226234436
step: 20, loss: 0.0005230396636761725
step: 30, loss: 0.058858249336481094
step: 40, loss: 0.07045388966798782
step: 50, loss: 0.035933442413806915
step: 60, loss: 0.18058869242668152
step: 70, loss: 0.040139202028512955
step: 80, loss: 0.16911350190639496
step: 90, loss: 0.006866766139864922
step: 100, loss: 0.033593013882637024
step: 110, loss: 0.01977735012769699
step: 120, loss: 0.036183539777994156
step: 130, loss: 0.035067327320575714
step: 140, loss: 0.14344973862171173
step: 150, loss: 0.0677173063158989
step: 160, loss: 0.022310324013233185
step: 170, loss: 0.0047322907485067844
step: 180, loss: 0.1195753961801529
step: 190, loss: 0.018268901854753494
step: 200, loss: 0.04126033931970596
step: 210, loss: 0.025416512042284012
step: 220, loss: 0.10296299308538437
step: 230, loss: 0.09450100362300873
step: 240, loss: 0.09839240461587906
step: 250, loss: 0.10480736941099167
step: 260, loss: 0.07541793584823608
step: 270, loss: 0.06267958134412766
step: 280, loss: 0.031175389885902405
step: 290, loss: 0.02708469144999981
step: 300, loss: 0.07189416885375977
step: 310, loss: 0.047163546085357666
step: 320, loss: 0.04611247405409813
step: 330, loss: 0.09293363243341446
step: 340, loss: 0.030793579295277596
step: 350, loss: 0.04144439101219177
step: 360, loss: 0.017447253689169884
epoch 5: dev_f1=0.7597765363128492, f1=0.7455621301775147, best_f1=0.7455621301775147
step: 0, loss: 0.25039219856262207
step: 10, loss: 0.08208883553743362
step: 20, loss: 0.013383404351770878
step: 30, loss: 0.0018308882135897875
step: 40, loss: 0.03943759948015213
step: 50, loss: 0.036543961614370346
step: 60, loss: 0.04937955364584923
step: 70, loss: 0.020901314914226532
step: 80, loss: 0.03932831436395645
step: 90, loss: 0.026198094710707664
step: 100, loss: 0.06665442883968353
step: 110, loss: 0.002889105584472418
step: 120, loss: 0.06821846216917038
step: 130, loss: 0.047144364565610886
step: 140, loss: 0.06111357733607292
step: 150, loss: 0.12759089469909668
step: 160, loss: 0.17537552118301392
step: 170, loss: 0.044970735907554626
step: 180, loss: 0.04797900468111038
step: 190, loss: 0.08765760064125061
step: 200, loss: 0.043106675148010254
step: 210, loss: 0.009610873647034168
step: 220, loss: 0.03916772082448006
step: 230, loss: 0.06352189928293228
step: 240, loss: 0.04650867357850075
step: 250, loss: 0.02051783725619316
step: 260, loss: 0.09336010366678238
step: 270, loss: 0.1098078265786171
step: 280, loss: 0.021816307678818703
step: 290, loss: 0.07364854961633682
step: 300, loss: 0.14305011928081512
step: 310, loss: 0.08338034898042679
step: 320, loss: 0.018608562648296356
step: 330, loss: 0.07044143229722977
step: 340, loss: 0.04212777316570282
step: 350, loss: 0.19874978065490723
step: 360, loss: 0.03282769024372101
epoch 6: dev_f1=0.7493261455525607, f1=0.7463556851311953, best_f1=0.7455621301775147
step: 0, loss: 0.052900541573762894
step: 10, loss: 0.05057623237371445
step: 20, loss: 0.09837105870246887
step: 30, loss: 0.09125403314828873
step: 40, loss: 0.1357222944498062
step: 50, loss: 0.03879218176007271
step: 60, loss: 0.0002050864859484136
step: 70, loss: 0.022586174309253693
step: 80, loss: 0.0745314210653305
step: 90, loss: 0.014611134305596352
step: 100, loss: 0.003810989437624812
step: 110, loss: 0.06544230878353119
step: 120, loss: 0.332011342048645
step: 130, loss: 0.01794109120965004
step: 140, loss: 0.015047692693769932
step: 150, loss: 0.04397200420498848
step: 160, loss: 0.09093119204044342
step: 170, loss: 0.027455966919660568
step: 180, loss: 0.016919320449233055
step: 190, loss: 0.10302089154720306
step: 200, loss: 0.07261863350868225
step: 210, loss: 0.06599113345146179
step: 220, loss: 0.0015161357587203383
step: 230, loss: 0.02531685121357441
step: 240, loss: 0.13978876173496246
step: 250, loss: 0.04827824607491493
step: 260, loss: 0.09566514939069748
step: 270, loss: 0.07807022333145142
step: 280, loss: 0.07762467116117477
step: 290, loss: 0.0154738649725914
step: 300, loss: 0.030096810311079025
step: 310, loss: 0.038023002445697784
step: 320, loss: 0.12495969980955124
step: 330, loss: 0.07578162848949432
step: 340, loss: 0.09373066574335098
step: 350, loss: 0.01832241378724575
step: 360, loss: 0.07763773202896118
epoch 7: dev_f1=0.7351351351351353, f1=0.7374301675977653, best_f1=0.7455621301775147
step: 0, loss: 0.09796194732189178
step: 10, loss: 0.02966667339205742
step: 20, loss: 0.013912922702729702
step: 30, loss: 0.1417703479528427
step: 40, loss: 0.030040688812732697
step: 50, loss: 0.025519108399748802
step: 60, loss: 0.05389194190502167
step: 70, loss: 0.0732763335108757
step: 80, loss: 0.044655416160821915
step: 90, loss: 0.03280254080891609
step: 100, loss: 0.013272205367684364
step: 110, loss: 8.389587310375646e-05
step: 120, loss: 0.00011305828957119957
step: 130, loss: 0.00812929030507803
step: 140, loss: 0.13731855154037476
step: 150, loss: 0.0899079442024231
step: 160, loss: 0.01639004983007908
step: 170, loss: 0.01912044920027256
step: 180, loss: 0.022591710090637207
step: 190, loss: 0.1718778908252716
step: 200, loss: 0.08229757100343704
step: 210, loss: 0.10819151252508163
step: 220, loss: 0.02855072356760502
step: 230, loss: 0.057385221123695374
step: 240, loss: 0.07256827503442764
step: 250, loss: 0.010568720288574696
step: 260, loss: 0.0871584340929985
step: 270, loss: 0.12814505398273468
step: 280, loss: 0.03410109505057335
step: 290, loss: 0.060046907514333725
step: 300, loss: 0.04467436298727989
step: 310, loss: 0.010002003982663155
step: 320, loss: 0.022983519360423088
step: 330, loss: 0.08457529544830322
step: 340, loss: 0.05765780806541443
step: 350, loss: 0.06854483485221863
step: 360, loss: 0.032171644270420074
epoch 8: dev_f1=0.7317073170731707, f1=0.753623188405797, best_f1=0.7455621301775147
step: 0, loss: 0.03830862417817116
step: 10, loss: 0.04711248725652695
step: 20, loss: 0.06323829293251038
step: 30, loss: 0.035831984132528305
step: 40, loss: 0.015304846689105034
step: 50, loss: 0.040576960891485214
step: 60, loss: 0.16402718424797058
step: 70, loss: 0.04406624287366867
step: 80, loss: 0.011423700489103794
step: 90, loss: 0.14202377200126648
step: 100, loss: 0.020781276747584343
step: 110, loss: 0.01095235999673605
step: 120, loss: 0.027857128530740738
step: 130, loss: 0.11185066401958466
step: 140, loss: 0.12157213687896729
step: 150, loss: 0.05290135741233826
step: 160, loss: 0.06656884402036667
step: 170, loss: 0.02565549686551094
step: 180, loss: 0.011201241053640842
step: 190, loss: 0.07877008616924286
step: 200, loss: 0.07905245572328568
step: 210, loss: 0.010029333643615246
step: 220, loss: 0.008673574775457382
step: 230, loss: 0.055414438247680664
step: 240, loss: 0.007805999834090471
step: 250, loss: 0.014338672161102295
step: 260, loss: 0.04162340983748436
step: 270, loss: 0.041168637573719025
step: 280, loss: 0.06832355260848999
step: 290, loss: 0.00028396924608387053
step: 300, loss: 0.05045565217733383
step: 310, loss: 0.00012054871331201866
step: 320, loss: 0.005504502449184656
step: 330, loss: 0.02626059576869011
step: 340, loss: 0.02909005433320999
step: 350, loss: 0.003417941043153405
step: 360, loss: 0.018120119348168373
epoch 9: dev_f1=0.7254408060453401, f1=0.7318435754189944, best_f1=0.7455621301775147
step: 0, loss: 0.005255857948213816
step: 10, loss: 0.03487922623753548
step: 20, loss: 0.1351686269044876
step: 30, loss: 0.04565257579088211
step: 40, loss: 0.03789832070469856
step: 50, loss: 6.151277193566784e-05
step: 60, loss: 0.0007572238682769239
step: 70, loss: 0.012530766427516937
step: 80, loss: 0.05001300945878029
step: 90, loss: 0.0034568810369819403
step: 100, loss: 0.05082644149661064
step: 110, loss: 0.009680239483714104
step: 120, loss: 0.006974904332309961
step: 130, loss: 0.0944690927863121
step: 140, loss: 0.08179136365652084
step: 150, loss: 0.0353224091231823
step: 160, loss: 0.018790805712342262
step: 170, loss: 0.02377834916114807
step: 180, loss: 0.09983932971954346
step: 190, loss: 0.09960474818944931
step: 200, loss: 0.0009252643212676048
step: 210, loss: 0.0221292395144701
step: 220, loss: 0.034729503095149994
step: 230, loss: 0.01336529292166233
step: 240, loss: 0.05434224754571915
step: 250, loss: 0.013278428465127945
step: 260, loss: 0.01889968477189541
step: 270, loss: 0.027679644525051117
step: 280, loss: 0.17502999305725098
step: 290, loss: 0.0454108901321888
step: 300, loss: 0.0055678668431937695
step: 310, loss: 0.10682236403226852
step: 320, loss: 0.06445357203483582
step: 330, loss: 5.828369103255682e-05
step: 340, loss: 0.03409582003951073
step: 350, loss: 0.007043655961751938
step: 360, loss: 0.08669913560152054
epoch 10: dev_f1=0.7268041237113403, f1=0.7272727272727273, best_f1=0.7455621301775147
step: 0, loss: 0.021177539601922035
step: 10, loss: 0.02733447216451168
step: 20, loss: 0.18382102251052856
step: 30, loss: 0.006924774963408709
step: 40, loss: 0.018679983913898468
step: 50, loss: 0.017187833786010742
step: 60, loss: 0.0012143140193074942
step: 70, loss: 0.01757911965250969
step: 80, loss: 0.04488391801714897
step: 90, loss: 0.16740502417087555
step: 100, loss: 0.04215607792139053
step: 110, loss: 0.05406072735786438
step: 120, loss: 0.039766620844602585
step: 130, loss: 0.06680498272180557
step: 140, loss: 0.03750176355242729
step: 150, loss: 0.01728666201233864
step: 160, loss: 0.07439000904560089
step: 170, loss: 0.024393567815423012
step: 180, loss: 0.03087674453854561
step: 190, loss: 0.03885330259799957
step: 200, loss: 0.02366361767053604
step: 210, loss: 0.07300606369972229
step: 220, loss: 0.14181798696517944
step: 230, loss: 0.0401432141661644
step: 240, loss: 0.010680112987756729
step: 250, loss: 0.07040292024612427
step: 260, loss: 0.009630897082388401
step: 270, loss: 0.029374420642852783
step: 280, loss: 8.114191587083042e-05
step: 290, loss: 0.024143971502780914
step: 300, loss: 0.025684772059321404
step: 310, loss: 0.07461000978946686
step: 320, loss: 0.00011620708392001688
step: 330, loss: 0.04151856526732445
step: 340, loss: 3.727989678736776e-05
step: 350, loss: 0.04348919168114662
step: 360, loss: 0.07386426627635956
epoch 11: dev_f1=0.709832134292566, f1=0.7208121827411167, best_f1=0.7455621301775147
step: 0, loss: 0.02567150630056858
step: 10, loss: 0.008963854983448982
step: 20, loss: 0.047019511461257935
step: 30, loss: 0.023168757557868958
step: 40, loss: 0.014863546937704086
step: 50, loss: 0.012726250104606152
step: 60, loss: 0.006651957519352436
step: 70, loss: 0.00155482382979244
step: 80, loss: 0.02276110090315342
step: 90, loss: 0.025613324716687202
step: 100, loss: 0.028556544333696365
step: 110, loss: 0.028787165880203247
step: 120, loss: 0.032628513872623444
step: 130, loss: 0.03371736407279968
step: 140, loss: 4.958428689860739e-05
step: 150, loss: 0.02369312010705471
step: 160, loss: 0.026755400002002716
step: 170, loss: 0.01982274278998375
step: 180, loss: 0.0215248204767704
step: 190, loss: 0.012222064658999443
step: 200, loss: 0.0026947471778839827
step: 210, loss: 0.007508761715143919
step: 220, loss: 0.007545520551502705
step: 230, loss: 0.014217824675142765
step: 240, loss: 0.008021801710128784
step: 250, loss: 0.013421967625617981
step: 260, loss: 0.03582169488072395
step: 270, loss: 0.03445618227124214
step: 280, loss: 0.009311086498200893
step: 290, loss: 0.004929024260491133
step: 300, loss: 0.043251775205135345
step: 310, loss: 0.013755680993199348
step: 320, loss: 0.026701437309384346
step: 330, loss: 0.03139704838395119
step: 340, loss: 0.03530910611152649
step: 350, loss: 2.1595091311610304e-05
step: 360, loss: 0.018933042883872986
epoch 12: dev_f1=0.6927083333333334, f1=0.7103825136612021, best_f1=0.7455621301775147
step: 0, loss: 0.06103707477450371
step: 10, loss: 0.013452161103487015
step: 20, loss: 2.0514929929049686e-05
step: 30, loss: 0.041820887476205826
step: 40, loss: 0.16654565930366516
step: 50, loss: 2.668342312972527e-05
step: 60, loss: 0.05394935607910156
step: 70, loss: 0.10435441136360168
step: 80, loss: 0.007106459699571133
step: 90, loss: 0.0177866593003273
step: 100, loss: 0.049871861934661865
step: 110, loss: 0.0073277149349451065
step: 120, loss: 0.013796022161841393
step: 130, loss: 0.024876078590750694
step: 140, loss: 0.08364124596118927
step: 150, loss: 0.06052694842219353
step: 160, loss: 0.025536825880408287
step: 170, loss: 0.010296822525560856
step: 180, loss: 0.0039530484937131405
step: 190, loss: 0.0011025217827409506
step: 200, loss: 0.0021270308643579483
step: 210, loss: 0.016432220116257668
step: 220, loss: 0.014964890666306019
step: 230, loss: 0.014093415811657906
step: 240, loss: 0.015622563660144806
step: 250, loss: 0.0019117167685180902
step: 260, loss: 0.002293887548148632
step: 270, loss: 0.06582717597484589
step: 280, loss: 0.07844043523073196
step: 290, loss: 0.0004317881539463997
step: 300, loss: 0.007283152546733618
step: 310, loss: 0.0038305148482322693
step: 320, loss: 0.03836061805486679
step: 330, loss: 0.001201024278998375
step: 340, loss: 0.11285126209259033
step: 350, loss: 0.06458724290132523
step: 360, loss: 0.08651746809482574
epoch 13: dev_f1=0.722488038277512, f1=0.7295918367346937, best_f1=0.7455621301775147
step: 0, loss: 0.013932405039668083
step: 10, loss: 0.011345220729708672
step: 20, loss: 0.009150554426014423
step: 30, loss: 0.04599238187074661
step: 40, loss: 0.001932294457219541
step: 50, loss: 0.06352606415748596
step: 60, loss: 0.01265539787709713
step: 70, loss: 0.00907797273248434
step: 80, loss: 0.03354768827557564
step: 90, loss: 0.0495486781001091
step: 100, loss: 0.0016141515225172043
step: 110, loss: 0.01449007447808981
step: 120, loss: 0.004474628251045942
step: 130, loss: 0.16656382381916046
step: 140, loss: 0.01704138144850731
step: 150, loss: 0.00020043850236106664
step: 160, loss: 0.06161612272262573
step: 170, loss: 0.020205972716212273
step: 180, loss: 0.05829009786248207
step: 190, loss: 0.015087177976965904
step: 200, loss: 0.018600596114993095
step: 210, loss: 0.06147138774394989
step: 220, loss: 0.08807861059904099
step: 230, loss: 0.135929673910141
step: 240, loss: 0.13328823447227478
step: 250, loss: 0.0351121723651886
step: 260, loss: 0.018715227022767067
step: 270, loss: 0.08814304322004318
step: 280, loss: 2.6303401682525873e-05
step: 290, loss: 0.012926403433084488
step: 300, loss: 0.003244677558541298
step: 310, loss: 0.03482397273182869
step: 320, loss: 0.003915482200682163
step: 330, loss: 0.03944205492734909
step: 340, loss: 0.0010984266409650445
step: 350, loss: 0.041155558079481125
step: 360, loss: 0.07928980141878128
epoch 14: dev_f1=0.6906474820143885, f1=0.7071240105540898, best_f1=0.7455621301775147
step: 0, loss: 0.028287893161177635
step: 10, loss: 0.06141546741127968
step: 20, loss: 0.006094137206673622
step: 30, loss: 0.015429101884365082
step: 40, loss: 0.05420389771461487
step: 50, loss: 0.000549444870557636
step: 60, loss: 0.057488616555929184
step: 70, loss: 0.04730071872472763
step: 80, loss: 0.002296939492225647
step: 90, loss: 0.06284137815237045
step: 100, loss: 8.522675489075482e-05
step: 110, loss: 0.013686450198292732
step: 120, loss: 0.004363771062344313
step: 130, loss: 0.0057311593554914
step: 140, loss: 0.007965628057718277
step: 150, loss: 0.07706538587808609
step: 160, loss: 0.002979008248075843
step: 170, loss: 0.0007673525251448154
step: 180, loss: 0.10461608320474625
step: 190, loss: 0.011211367323994637
step: 200, loss: 0.031766973435878754
step: 210, loss: 0.018708698451519012
step: 220, loss: 0.016669753938913345
step: 230, loss: 0.12120966613292694
step: 240, loss: 0.005153527483344078
step: 250, loss: 0.027551278471946716
step: 260, loss: 0.016358448192477226
step: 270, loss: 3.564278449630365e-05
step: 280, loss: 4.099115540157072e-05
step: 290, loss: 0.006409407593309879
step: 300, loss: 7.775397534715012e-05
step: 310, loss: 0.0663631409406662
step: 320, loss: 0.0044037518091499805
step: 330, loss: 0.028615491464734077
step: 340, loss: 0.12120489776134491
step: 350, loss: 0.033670611679553986
step: 360, loss: 0.03345584124326706
epoch 15: dev_f1=0.7080103359173127, f1=0.7052341597796142, best_f1=0.7455621301775147
step: 0, loss: 0.016138168051838875
step: 10, loss: 0.01870037242770195
step: 20, loss: 0.010889451950788498
step: 30, loss: 0.011922480538487434
step: 40, loss: 0.052758850157260895
step: 50, loss: 0.0004932995070703328
step: 60, loss: 0.0005332054570317268
step: 70, loss: 0.000217695880564861
step: 80, loss: 0.004211151972413063
step: 90, loss: 0.015035352669656277
step: 100, loss: 0.018735142424702644
step: 110, loss: 0.028183061629533768
step: 120, loss: 0.15847378969192505
step: 130, loss: 0.00027247719117440283
step: 140, loss: 0.10241910815238953
step: 150, loss: 0.0069439648650586605
step: 160, loss: 0.09636549651622772
step: 170, loss: 0.0003692072641570121
step: 180, loss: 0.1225532740354538
step: 190, loss: 0.002054384211078286
step: 200, loss: 0.002931572962552309
step: 210, loss: 0.004657866898924112
step: 220, loss: 0.09532708674669266
step: 230, loss: 3.4204651456093416e-05
step: 240, loss: 0.0430544950067997
step: 250, loss: 0.08757943660020828
step: 260, loss: 0.03795314207673073
step: 270, loss: 5.9554909967118874e-05
step: 280, loss: 0.0018709148280322552
step: 290, loss: 0.06300969421863556
step: 300, loss: 0.019157271832227707
step: 310, loss: 0.06434814631938934
step: 320, loss: 0.0004030131967738271
step: 330, loss: 0.00011410064325900748
step: 340, loss: 0.00931956060230732
step: 350, loss: 0.0035770584363490343
step: 360, loss: 0.01846904493868351
epoch 16: dev_f1=0.7105882352941176, f1=0.7341772151898734, best_f1=0.7455621301775147
step: 0, loss: 0.010777602903544903
step: 10, loss: 0.0653107762336731
step: 20, loss: 0.05746092274785042
step: 30, loss: 0.011128822341561317
step: 40, loss: 0.00028264091815799475
step: 50, loss: 0.0027170837856829166
step: 60, loss: 0.0012430441565811634
step: 70, loss: 0.0007079575443640351
step: 80, loss: 2.0809240595554e-05
step: 90, loss: 0.06258714944124222
step: 100, loss: 0.00861163716763258
step: 110, loss: 0.09436575323343277
step: 120, loss: 0.040465522557497025
step: 130, loss: 0.0031557048205286264
step: 140, loss: 0.010368525050580502
step: 150, loss: 3.2381125492975116e-05
step: 160, loss: 0.03508085012435913
step: 170, loss: 0.04777080938220024
step: 180, loss: 0.020968228578567505
step: 190, loss: 0.04943491518497467
step: 200, loss: 0.02760091982781887
step: 210, loss: 0.03475679084658623
step: 220, loss: 0.10371682792901993
step: 230, loss: 0.07479401677846909
step: 240, loss: 0.022520067170262337
step: 250, loss: 0.14718104898929596
step: 260, loss: 0.0026300514582544565
step: 270, loss: 0.0409114845097065
step: 280, loss: 0.0011901071993634105
step: 290, loss: 0.008016630075871944
step: 300, loss: 8.42043591546826e-05
step: 310, loss: 0.005559179000556469
step: 320, loss: 0.045524079352617264
step: 330, loss: 4.111712769372389e-05
step: 340, loss: 0.0011017981451004744
step: 350, loss: 0.03745167329907417
step: 360, loss: 0.020944777876138687
epoch 17: dev_f1=0.7111111111111111, f1=0.7297297297297297, best_f1=0.7455621301775147
step: 0, loss: 0.0005923451390117407
step: 10, loss: 0.008737538941204548
step: 20, loss: 0.022157132625579834
step: 30, loss: 0.026596905663609505
step: 40, loss: 0.016197342425584793
step: 50, loss: 0.06608738005161285
step: 60, loss: 0.03717930614948273
step: 70, loss: 0.06928882002830505
step: 80, loss: 0.01718323491513729
step: 90, loss: 0.019090844318270683
step: 100, loss: 7.174145139288157e-05
step: 110, loss: 0.0030665427912026644
step: 120, loss: 0.018133290112018585
step: 130, loss: 0.0018127431394532323
step: 140, loss: 0.003451381344348192
step: 150, loss: 0.010892095975577831
step: 160, loss: 0.002880142070353031
step: 170, loss: 0.0002366776898270473
step: 180, loss: 0.0002009723539231345
step: 190, loss: 0.09118088334798813
step: 200, loss: 0.00023661990417167544
step: 210, loss: 0.044355567544698715
step: 220, loss: 0.00024197979655582458
step: 230, loss: 0.03053267113864422
step: 240, loss: 0.0136469891294837
step: 250, loss: 0.011073239147663116
step: 260, loss: 0.11653914302587509
step: 270, loss: 0.1029869019985199
step: 280, loss: 0.020174788311123848
step: 290, loss: 0.00011583328887354583
step: 300, loss: 0.0059229591861367226
step: 310, loss: 0.0033283554948866367
step: 320, loss: 0.03692447394132614
step: 330, loss: 0.02485046721994877
step: 340, loss: 0.019203994423151016
step: 350, loss: 4.61355630250182e-05
step: 360, loss: 0.000855030317325145
epoch 18: dev_f1=0.7153284671532846, f1=0.733509234828496, best_f1=0.7455621301775147
step: 0, loss: 0.0005002063699066639
step: 10, loss: 3.278918666183017e-05
step: 20, loss: 3.2068637665361166e-05
step: 30, loss: 0.00982424896210432
step: 40, loss: 0.004749713931232691
step: 50, loss: 0.0004392708360683173
step: 60, loss: 0.05858087167143822
step: 70, loss: 0.024787433445453644
step: 80, loss: 0.05652780085802078
step: 90, loss: 0.017466899007558823
step: 100, loss: 0.0004077970515936613
step: 110, loss: 0.000425155769335106
step: 120, loss: 0.010442634113132954
step: 130, loss: 0.0018269437132403255
step: 140, loss: 0.022664207965135574
step: 150, loss: 0.00020622381998691708
step: 160, loss: 0.001546294311992824
step: 170, loss: 0.00021309618023224175
step: 180, loss: 0.00026158097898587584
step: 190, loss: 0.0009182745707221329
step: 200, loss: 3.442382876528427e-05
step: 210, loss: 0.12155917286872864
step: 220, loss: 0.05961678549647331
step: 230, loss: 0.04646872729063034
step: 240, loss: 0.09003803133964539
step: 250, loss: 0.018606357276439667
step: 260, loss: 0.06345715373754501
step: 270, loss: 0.03585503250360489
step: 280, loss: 0.038113947957754135
step: 290, loss: 0.0055149514228105545
step: 300, loss: 0.022745059803128242
step: 310, loss: 0.031410083174705505
step: 320, loss: 0.015031518414616585
step: 330, loss: 0.00832830835133791
step: 340, loss: 0.017399383708834648
step: 350, loss: 2.4359283997910097e-05
step: 360, loss: 0.05846630409359932
epoch 19: dev_f1=0.7035175879396985, f1=0.7228260869565217, best_f1=0.7455621301775147
step: 0, loss: 0.005455376580357552
step: 10, loss: 0.0002696037117857486
step: 20, loss: 0.023868951946496964
step: 30, loss: 0.0001727939088596031
step: 40, loss: 0.0035752374678850174
step: 50, loss: 0.002763680648058653
step: 60, loss: 0.010940955020487309
step: 70, loss: 0.0005406806594692171
step: 80, loss: 0.019751347601413727
step: 90, loss: 0.0008054157951846719
step: 100, loss: 4.967816130374558e-05
step: 110, loss: 0.18641974031925201
step: 120, loss: 0.0013965655816718936
step: 130, loss: 0.022355817258358
step: 140, loss: 0.016221908852458
step: 150, loss: 0.032832883298397064
step: 160, loss: 9.921888704411685e-05
step: 170, loss: 0.0030212069395929575
step: 180, loss: 0.007617816794663668
step: 190, loss: 0.003432947676628828
step: 200, loss: 0.0005135782994329929
step: 210, loss: 0.0018671154975891113
step: 220, loss: 0.019283173605799675
step: 230, loss: 0.041932363063097
step: 240, loss: 0.04108867049217224
step: 250, loss: 0.03342186659574509
step: 260, loss: 0.09582571685314178
step: 270, loss: 0.00016964176029432565
step: 280, loss: 0.012591351754963398
step: 290, loss: 0.06261391192674637
step: 300, loss: 0.03736715763807297
step: 310, loss: 0.0018907259218394756
step: 320, loss: 0.0021520424634218216
step: 330, loss: 0.026982717216014862
step: 340, loss: 0.026728760451078415
step: 350, loss: 0.00075330346589908
step: 360, loss: 0.024369020015001297
epoch 20: dev_f1=0.7068062827225131, f1=0.7231638418079097, best_f1=0.7455621301775147
