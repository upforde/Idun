cuda
Device: cuda
step: 0, loss: 0.9747860431671143
step: 10, loss: 0.2448902279138565
step: 20, loss: 0.14218929409980774
step: 30, loss: 0.22164088487625122
step: 40, loss: 0.23973897099494934
step: 50, loss: 0.24548569321632385
step: 60, loss: 0.035962630063295364
step: 70, loss: 0.3209512531757355
step: 80, loss: 0.0569063276052475
step: 90, loss: 0.4202900230884552
step: 100, loss: 0.3834399878978729
step: 110, loss: 0.25646835565567017
step: 120, loss: 0.0703270211815834
step: 130, loss: 0.1330077201128006
step: 140, loss: 0.23738977313041687
step: 150, loss: 0.15327833592891693
step: 160, loss: 0.017889639362692833
step: 170, loss: 0.1982438713312149
step: 180, loss: 0.13841871917247772
step: 190, loss: 0.10600321739912033
step: 200, loss: 0.2924816906452179
step: 210, loss: 0.16112934052944183
step: 220, loss: 0.056864239275455475
step: 230, loss: 0.09204573929309845
step: 240, loss: 0.2118319571018219
step: 250, loss: 0.023102348670363426
step: 260, loss: 0.10524622350931168
step: 270, loss: 0.026091769337654114
step: 280, loss: 0.2103428840637207
step: 290, loss: 0.6053200960159302
step: 300, loss: 0.1724037528038025
step: 310, loss: 0.23274283111095428
step: 320, loss: 0.09658513963222504
step: 330, loss: 0.10295416414737701
step: 340, loss: 0.019916098564863205
step: 350, loss: 0.1166081428527832
step: 360, loss: 0.021006952971220016
epoch 1: dev_f1=0.6077922077922079, f1=0.6233062330623306, best_f1=0.6233062330623306
step: 0, loss: 0.18604055047035217
step: 10, loss: 0.1646716594696045
step: 20, loss: 0.13147862255573273
step: 30, loss: 0.4161989986896515
step: 40, loss: 0.1471177190542221
step: 50, loss: 0.10211890190839767
step: 60, loss: 0.09112309664487839
step: 70, loss: 0.1547669619321823
step: 80, loss: 0.05533445253968239
step: 90, loss: 0.1277007758617401
step: 100, loss: 0.055738549679517746
step: 110, loss: 0.050336942076683044
step: 120, loss: 0.27886641025543213
step: 130, loss: 0.05950859189033508
step: 140, loss: 0.1926424652338028
step: 150, loss: 0.24679599702358246
step: 160, loss: 0.1470879465341568
step: 170, loss: 0.0714123398065567
step: 180, loss: 0.14323775470256805
step: 190, loss: 0.1218205913901329
step: 200, loss: 0.05201609060168266
step: 210, loss: 0.10388809442520142
step: 220, loss: 0.1149546429514885
step: 230, loss: 0.23879113793373108
step: 240, loss: 0.11704003065824509
step: 250, loss: 0.1046522855758667
step: 260, loss: 0.13294535875320435
step: 270, loss: 0.004121862351894379
step: 280, loss: 0.13489072024822235
step: 290, loss: 0.044145360589027405
step: 300, loss: 0.13694296777248383
step: 310, loss: 0.06500765681266785
step: 320, loss: 0.21525314450263977
step: 330, loss: 0.09193705767393112
step: 340, loss: 0.1425999253988266
step: 350, loss: 0.02380148321390152
step: 360, loss: 0.07230333983898163
epoch 2: dev_f1=0.733509234828496, f1=0.7631578947368421, best_f1=0.7631578947368421
step: 0, loss: 0.0654425248503685
step: 10, loss: 0.0345827117562294
step: 20, loss: 0.22429484128952026
step: 30, loss: 0.06944800168275833
step: 40, loss: 0.06038987636566162
step: 50, loss: 0.05602506548166275
step: 60, loss: 0.10793929547071457
step: 70, loss: 0.10142387449741364
step: 80, loss: 0.07909176498651505
step: 90, loss: 0.10839051753282547
step: 100, loss: 0.07554923743009567
step: 110, loss: 0.12529240548610687
step: 120, loss: 0.11172884702682495
step: 130, loss: 0.01869288459420204
step: 140, loss: 0.04172097146511078
step: 150, loss: 0.0918150320649147
step: 160, loss: 0.05034291371703148
step: 170, loss: 0.04453664645552635
step: 180, loss: 0.10251487046480179
step: 190, loss: 0.15857362747192383
step: 200, loss: 0.20926439762115479
step: 210, loss: 0.08480112254619598
step: 220, loss: 0.08070692420005798
step: 230, loss: 0.07628042995929718
step: 240, loss: 0.03349611908197403
step: 250, loss: 0.003895949339494109
step: 260, loss: 0.14941473305225372
step: 270, loss: 0.12987938523292542
step: 280, loss: 0.02653449960052967
step: 290, loss: 0.08089792728424072
step: 300, loss: 0.0012284262338653207
step: 310, loss: 0.0643756091594696
step: 320, loss: 0.05080416798591614
step: 330, loss: 0.23573410511016846
step: 340, loss: 0.04395848140120506
step: 350, loss: 0.021878832951188087
step: 360, loss: 0.016017351299524307
epoch 3: dev_f1=0.7162534435261707, f1=0.7206703910614525, best_f1=0.7631578947368421
step: 0, loss: 0.13451853394508362
step: 10, loss: 0.06832367926836014
step: 20, loss: 0.1908206343650818
step: 30, loss: 0.08438660204410553
step: 40, loss: 0.082566037774086
step: 50, loss: 0.10391931980848312
step: 60, loss: 0.05638793483376503
step: 70, loss: 0.1701899617910385
step: 80, loss: 0.01775076985359192
step: 90, loss: 0.045161329209804535
step: 100, loss: 0.04880647733807564
step: 110, loss: 0.06073504313826561
step: 120, loss: 0.07017198950052261
step: 130, loss: 0.050495076924562454
step: 140, loss: 0.017499757930636406
step: 150, loss: 0.07951164245605469
step: 160, loss: 0.11581528931856155
step: 170, loss: 0.016391733661293983
step: 180, loss: 0.03457947075366974
step: 190, loss: 0.04822642356157303
step: 200, loss: 0.07535038143396378
step: 210, loss: 0.002964938059449196
step: 220, loss: 0.04753221571445465
step: 230, loss: 0.021572686731815338
step: 240, loss: 0.13418300449848175
step: 250, loss: 0.0657082349061966
step: 260, loss: 0.08383452892303467
step: 270, loss: 0.04543044790625572
step: 280, loss: 0.06663569808006287
step: 290, loss: 0.11170383542776108
step: 300, loss: 0.08898117393255234
step: 310, loss: 0.08608118444681168
step: 320, loss: 0.20378808677196503
step: 330, loss: 0.07614430785179138
step: 340, loss: 0.053080808371305466
step: 350, loss: 0.14888213574886322
step: 360, loss: 0.05769165977835655
epoch 4: dev_f1=0.7492795389048991, f1=0.7405247813411078, best_f1=0.7405247813411078
step: 0, loss: 0.033906593918800354
step: 10, loss: 0.04911814257502556
step: 20, loss: 0.05565979704260826
step: 30, loss: 0.05929850414395332
step: 40, loss: 0.03175973892211914
step: 50, loss: 0.08225597441196442
step: 60, loss: 0.018195630982518196
step: 70, loss: 0.05741415172815323
step: 80, loss: 0.020706893876194954
step: 90, loss: 0.11723126471042633
step: 100, loss: 0.06145915761590004
step: 110, loss: 0.00044555062777362764
step: 120, loss: 0.09223014861345291
step: 130, loss: 0.1359531134366989
step: 140, loss: 0.11508064717054367
step: 150, loss: 0.0001938420900842175
step: 160, loss: 0.12627993524074554
step: 170, loss: 0.045078128576278687
step: 180, loss: 0.13271880149841309
step: 190, loss: 0.02801523543894291
step: 200, loss: 0.027638066560029984
step: 210, loss: 0.16272899508476257
step: 220, loss: 0.043032266199588776
step: 230, loss: 0.21789959073066711
step: 240, loss: 0.0603950209915638
step: 250, loss: 0.14023196697235107
step: 260, loss: 0.02822755090892315
step: 270, loss: 0.041744425892829895
step: 280, loss: 0.048592276871204376
step: 290, loss: 0.041968006640672684
step: 300, loss: 0.011737270280718803
step: 310, loss: 0.09462634474039078
step: 320, loss: 0.1028733029961586
step: 330, loss: 0.053562574088573456
step: 340, loss: 0.09328531473875046
step: 350, loss: 0.01545740757137537
step: 360, loss: 0.11487317830324173
epoch 5: dev_f1=0.7547169811320755, f1=0.7449856733524355, best_f1=0.7449856733524355
step: 0, loss: 0.00984495785087347
step: 10, loss: 0.005804548505693674
step: 20, loss: 0.07073985785245895
step: 30, loss: 0.05035780370235443
step: 40, loss: 0.056364383548498154
step: 50, loss: 0.03826235234737396
step: 60, loss: 0.07605310529470444
step: 70, loss: 0.10550080984830856
step: 80, loss: 0.054455555975437164
step: 90, loss: 0.03808402270078659
step: 100, loss: 0.051637619733810425
step: 110, loss: 0.05074587091803551
step: 120, loss: 0.11817382276058197
step: 130, loss: 0.001107136602513492
step: 140, loss: 0.03915844112634659
step: 150, loss: 0.0006281265523284674
step: 160, loss: 0.04821904003620148
step: 170, loss: 0.09433955699205399
step: 180, loss: 0.018203921616077423
step: 190, loss: 0.002565375529229641
step: 200, loss: 0.058236006647348404
step: 210, loss: 0.12022143602371216
step: 220, loss: 0.04333600774407387
step: 230, loss: 0.04313801974058151
step: 240, loss: 0.02781073749065399
step: 250, loss: 0.10712749511003494
step: 260, loss: 0.0025452286936342716
step: 270, loss: 0.004213507287204266
step: 280, loss: 0.024605806916952133
step: 290, loss: 0.07089021056890488
step: 300, loss: 0.04117278754711151
step: 310, loss: 0.12152599543333054
step: 320, loss: 0.02768191136419773
step: 330, loss: 0.0004838822642341256
step: 340, loss: 0.10584133118391037
step: 350, loss: 0.14691409468650818
step: 360, loss: 0.09219218045473099
epoch 6: dev_f1=0.7226107226107227, f1=0.7205882352941175, best_f1=0.7449856733524355
step: 0, loss: 0.0464172400534153
step: 10, loss: 0.07466720789670944
step: 20, loss: 0.06469537317752838
step: 30, loss: 0.013265450485050678
step: 40, loss: 0.03922576457262039
step: 50, loss: 0.01161018293350935
step: 60, loss: 0.00034662021789699793
step: 70, loss: 0.05152886360883713
step: 80, loss: 0.1283760815858841
step: 90, loss: 0.07549431174993515
step: 100, loss: 0.1748168170452118
step: 110, loss: 0.06713929772377014
step: 120, loss: 0.036976929754018784
step: 130, loss: 0.043825216591358185
step: 140, loss: 0.06402382254600525
step: 150, loss: 0.04894208163022995
step: 160, loss: 0.02303059957921505
step: 170, loss: 0.01661032997071743
step: 180, loss: 0.043697815388441086
step: 190, loss: 0.08141829073429108
step: 200, loss: 0.04050741717219353
step: 210, loss: 0.06264634430408478
step: 220, loss: 0.0531589575111866
step: 230, loss: 0.04690464586019516
step: 240, loss: 0.05021369457244873
step: 250, loss: 0.06964614987373352
step: 260, loss: 0.024952679872512817
step: 270, loss: 0.0013766881311312318
step: 280, loss: 0.08448217064142227
step: 290, loss: 0.015578330494463444
step: 300, loss: 0.007659432012587786
step: 310, loss: 0.011875486932694912
step: 320, loss: 0.009711633436381817
step: 330, loss: 0.021996278315782547
step: 340, loss: 0.058215636759996414
step: 350, loss: 0.03994303569197655
step: 360, loss: 0.016607286408543587
epoch 7: dev_f1=0.7285714285714286, f1=0.7474747474747474, best_f1=0.7449856733524355
step: 0, loss: 0.023237835615873337
step: 10, loss: 0.09872693568468094
step: 20, loss: 0.057226333767175674
step: 30, loss: 0.0495578907430172
step: 40, loss: 0.09270155429840088
step: 50, loss: 0.09664848446846008
step: 60, loss: 0.026908544823527336
step: 70, loss: 0.00422163400799036
step: 80, loss: 0.05648476257920265
step: 90, loss: 0.030929818749427795
step: 100, loss: 0.053464893251657486
step: 110, loss: 0.008242156356573105
step: 120, loss: 0.07427448779344559
step: 130, loss: 0.1330873966217041
step: 140, loss: 0.070628322660923
step: 150, loss: 0.13766436278820038
step: 160, loss: 0.1284167468547821
step: 170, loss: 0.07807392627000809
step: 180, loss: 0.022975463420152664
step: 190, loss: 0.008850885555148125
step: 200, loss: 0.0638895183801651
step: 210, loss: 0.040755100548267365
step: 220, loss: 0.08472287654876709
step: 230, loss: 0.08393758535385132
step: 240, loss: 0.00012974976561963558
step: 250, loss: 0.031180407851934433
step: 260, loss: 0.06578633189201355
step: 270, loss: 0.0015554599231109023
step: 280, loss: 0.03145911172032356
step: 290, loss: 0.13034570217132568
step: 300, loss: 0.08540744334459305
step: 310, loss: 0.09981001168489456
step: 320, loss: 0.20359283685684204
step: 330, loss: 0.13371866941452026
step: 340, loss: 0.061479825526475906
step: 350, loss: 0.03602369874715805
step: 360, loss: 0.02118222787976265
epoch 8: dev_f1=0.7707808564231737, f1=0.7643979057591622, best_f1=0.7643979057591622
step: 0, loss: 0.07303546369075775
step: 10, loss: 0.030954493209719658
step: 20, loss: 0.08385511487722397
step: 30, loss: 0.03451951965689659
step: 40, loss: 0.015438694506883621
step: 50, loss: 5.485012297867797e-05
step: 60, loss: 0.08054158091545105
step: 70, loss: 0.012423882260918617
step: 80, loss: 0.03267021104693413
step: 90, loss: 0.0003772307245526463
step: 100, loss: 0.15354323387145996
step: 110, loss: 0.18675170838832855
step: 120, loss: 0.011013413779437542
step: 130, loss: 0.14364546537399292
step: 140, loss: 0.011102110147476196
step: 150, loss: 0.051041845232248306
step: 160, loss: 0.023852182552218437
step: 170, loss: 0.038047805428504944
step: 180, loss: 0.01680007576942444
step: 190, loss: 0.008371444419026375
step: 200, loss: 0.08232320100069046
step: 210, loss: 0.07084177434444427
step: 220, loss: 5.640568633680232e-05
step: 230, loss: 0.1426742672920227
step: 240, loss: 0.0001339537848252803
step: 250, loss: 0.01585586741566658
step: 260, loss: 0.08609987795352936
step: 270, loss: 0.03769736364483833
step: 280, loss: 0.115130715072155
step: 290, loss: 0.04793473705649376
step: 300, loss: 0.009546009823679924
step: 310, loss: 0.013929634355008602
step: 320, loss: 0.04984774440526962
step: 330, loss: 0.06593558192253113
step: 340, loss: 0.08390551060438156
step: 350, loss: 0.08383508026599884
step: 360, loss: 0.0808805376291275
epoch 9: dev_f1=0.7178217821782177, f1=0.7604166666666666, best_f1=0.7643979057591622
step: 0, loss: 0.041481249034404755
step: 10, loss: 0.05611814931035042
step: 20, loss: 0.00788204651325941
step: 30, loss: 0.024962695315480232
step: 40, loss: 0.04162338003516197
step: 50, loss: 0.011814129538834095
step: 60, loss: 0.07972867041826248
step: 70, loss: 0.0015972948167473078
step: 80, loss: 0.005229658912867308
step: 90, loss: 0.004120067227631807
step: 100, loss: 5.99611084908247e-05
step: 110, loss: 0.06566666811704636
step: 120, loss: 0.00763231934979558
step: 130, loss: 0.0008700487669557333
step: 140, loss: 0.00011858686775667593
step: 150, loss: 0.0036816559731960297
step: 160, loss: 0.02726847305893898
step: 170, loss: 0.01823475770652294
step: 180, loss: 0.07019627094268799
step: 190, loss: 0.004296546336263418
step: 200, loss: 0.004180680960416794
step: 210, loss: 0.032103531062603
step: 220, loss: 0.006392219569534063
step: 230, loss: 0.03445040062069893
step: 240, loss: 0.021657545119524002
step: 250, loss: 0.036219045519828796
step: 260, loss: 0.03928164020180702
step: 270, loss: 0.032559920102357864
step: 280, loss: 0.11868970841169357
step: 290, loss: 0.048309147357940674
step: 300, loss: 0.003135758452117443
step: 310, loss: 0.013113151304423809
step: 320, loss: 0.2576480507850647
step: 330, loss: 0.01707671768963337
step: 340, loss: 0.14469274878501892
step: 350, loss: 0.021596631035208702
step: 360, loss: 0.03850560635328293
epoch 10: dev_f1=0.7734806629834254, f1=0.7401129943502824, best_f1=0.7401129943502824
step: 0, loss: 0.03735310211777687
step: 10, loss: 0.028261415660381317
step: 20, loss: 0.002450957428663969
step: 30, loss: 0.042150434106588364
step: 40, loss: 5.904649515287019e-05
step: 50, loss: 0.1642160415649414
step: 60, loss: 0.002578176325187087
step: 70, loss: 0.0030152343679219484
step: 80, loss: 0.10132327675819397
step: 90, loss: 0.016989069059491158
step: 100, loss: 0.016216391697525978
step: 110, loss: 0.016829855740070343
step: 120, loss: 0.10191735625267029
step: 130, loss: 0.07217777520418167
step: 140, loss: 6.747688166797161e-05
step: 150, loss: 0.018639743328094482
step: 160, loss: 0.040247172117233276
step: 170, loss: 0.04200616478919983
step: 180, loss: 0.07366669178009033
step: 190, loss: 0.0029696214478462934
step: 200, loss: 0.03754148259758949
step: 210, loss: 0.05450167879462242
step: 220, loss: 0.005722322966903448
step: 230, loss: 0.10116808116436005
step: 240, loss: 5.904781210119836e-05
step: 250, loss: 0.004418474156409502
step: 260, loss: 0.04824969545006752
step: 270, loss: 0.021373631432652473
step: 280, loss: 0.03862592205405235
step: 290, loss: 0.06403125077486038
step: 300, loss: 0.014780210331082344
step: 310, loss: 0.0057874820195138454
step: 320, loss: 0.11193116009235382
step: 330, loss: 0.04431229829788208
step: 340, loss: 0.09484264999628067
step: 350, loss: 0.007068201899528503
step: 360, loss: 0.00011363512749085203
epoch 11: dev_f1=0.7430025445292621, f1=0.7598944591029023, best_f1=0.7401129943502824
step: 0, loss: 0.018102062866091728
step: 10, loss: 0.14019325375556946
step: 20, loss: 0.007946389727294445
step: 30, loss: 0.022843360900878906
step: 40, loss: 0.05992886796593666
step: 50, loss: 0.007363275624811649
step: 60, loss: 0.017409158870577812
step: 70, loss: 0.0007490493007935584
step: 80, loss: 0.06299106031656265
step: 90, loss: 0.0786634162068367
step: 100, loss: 0.011680291965603828
step: 110, loss: 0.024640342220664024
step: 120, loss: 0.043340474367141724
step: 130, loss: 6.548516830662265e-05
step: 140, loss: 0.03585559502243996
step: 150, loss: 0.041131388396024704
step: 160, loss: 0.06049611419439316
step: 170, loss: 0.06798552721738815
step: 180, loss: 0.0013610328314825892
step: 190, loss: 7.45436773286201e-05
step: 200, loss: 0.0024335996713489294
step: 210, loss: 0.002321544336155057
step: 220, loss: 2.6687541321734898e-05
step: 230, loss: 0.02554246224462986
step: 240, loss: 0.047218214720487595
step: 250, loss: 0.16323016583919525
step: 260, loss: 0.02128993719816208
step: 270, loss: 0.10319303721189499
step: 280, loss: 0.03764200210571289
step: 290, loss: 0.018157467246055603
step: 300, loss: 0.01858394779264927
step: 310, loss: 0.018828677013516426
step: 320, loss: 0.00014746766828466207
step: 330, loss: 0.03757310286164284
step: 340, loss: 0.000700801145285368
step: 350, loss: 0.0024896508548408747
step: 360, loss: 0.056467026472091675
epoch 12: dev_f1=0.7368421052631579, f1=0.7537688442211056, best_f1=0.7401129943502824
step: 0, loss: 0.020584091544151306
step: 10, loss: 0.00027869525365531445
step: 20, loss: 0.03135447949171066
step: 30, loss: 0.06100424751639366
step: 40, loss: 0.09549994766712189
step: 50, loss: 0.08402954041957855
step: 60, loss: 0.0015017392579466105
step: 70, loss: 0.002525879302993417
step: 80, loss: 0.08514373004436493
step: 90, loss: 0.004612204618752003
step: 100, loss: 0.030131518840789795
step: 110, loss: 0.03175538405776024
step: 120, loss: 0.01040632650256157
step: 130, loss: 5.795130709884688e-05
step: 140, loss: 0.02650640904903412
step: 150, loss: 0.03365648165345192
step: 160, loss: 7.601254765177146e-05
step: 170, loss: 0.00024003619910217822
step: 180, loss: 0.1212548092007637
step: 190, loss: 0.000232651800615713
step: 200, loss: 0.048307329416275024
step: 210, loss: 0.09898701310157776
step: 220, loss: 0.05329129844903946
step: 230, loss: 0.07396603375673294
step: 240, loss: 0.031005099415779114
step: 250, loss: 0.018871858716011047
step: 260, loss: 0.0022528558038175106
step: 270, loss: 3.1138191843638197e-05
step: 280, loss: 0.029342638328671455
step: 290, loss: 0.0408787727355957
step: 300, loss: 0.07586195319890976
step: 310, loss: 0.0012016380205750465
step: 320, loss: 0.017375869676470757
step: 330, loss: 0.11131765693426132
step: 340, loss: 0.04255906119942665
step: 350, loss: 0.019578002393245697
step: 360, loss: 0.0012540146708488464
epoch 13: dev_f1=0.7331670822942644, f1=0.7371134020618555, best_f1=0.7401129943502824
step: 0, loss: 0.03147748112678528
step: 10, loss: 4.6756391384406015e-05
step: 20, loss: 0.0015335424104705453
step: 30, loss: 0.03905468434095383
step: 40, loss: 0.0008285213261842728
step: 50, loss: 0.05367712676525116
step: 60, loss: 5.4726293456042185e-05
step: 70, loss: 0.008444159291684628
step: 80, loss: 0.0020892343018203974
step: 90, loss: 0.04444961994886398
step: 100, loss: 0.025671344250440598
step: 110, loss: 0.04084688425064087
step: 120, loss: 0.02468854933977127
step: 130, loss: 0.05507946386933327
step: 140, loss: 0.030412448570132256
step: 150, loss: 0.022224705666303635
step: 160, loss: 0.019294558092951775
step: 170, loss: 0.0051376852206885815
step: 180, loss: 0.06692028045654297
step: 190, loss: 0.001384716248139739
step: 200, loss: 0.034004125744104385
step: 210, loss: 0.035159774124622345
step: 220, loss: 0.047822099179029465
step: 230, loss: 0.03399286046624184
step: 240, loss: 0.013981571421027184
step: 250, loss: 0.009662642143666744
step: 260, loss: 0.028051182627677917
step: 270, loss: 0.0018689193530008197
step: 280, loss: 0.00020865218539256603
step: 290, loss: 0.005928638391196728
step: 300, loss: 7.317816925933585e-05
step: 310, loss: 0.02320205047726631
step: 320, loss: 0.00240644090808928
step: 330, loss: 0.0974060520529747
step: 340, loss: 0.0001501951483078301
step: 350, loss: 0.04967555031180382
step: 360, loss: 0.07018517702817917
epoch 14: dev_f1=0.7611940298507462, f1=0.7531806615776082, best_f1=0.7401129943502824
step: 0, loss: 0.016906091943383217
step: 10, loss: 0.0328553132712841
step: 20, loss: 0.041607923805713654
step: 30, loss: 2.4761175154708326e-05
step: 40, loss: 0.00035979715175926685
step: 50, loss: 0.030695531517267227
step: 60, loss: 0.010237399488687515
step: 70, loss: 0.05200505629181862
step: 80, loss: 0.07496966421604156
step: 90, loss: 3.0389644962269813e-05
step: 100, loss: 0.002260048408061266
step: 110, loss: 0.020596817135810852
step: 120, loss: 0.004483485594391823
step: 130, loss: 0.07257735729217529
step: 140, loss: 0.027103915810585022
step: 150, loss: 0.06242299824953079
step: 160, loss: 0.014128810726106167
step: 170, loss: 0.00020974002836737782
step: 180, loss: 0.06525837630033493
step: 190, loss: 0.021710461005568504
step: 200, loss: 0.004176885820925236
step: 210, loss: 0.019603880122303963
step: 220, loss: 0.026937613263726234
step: 230, loss: 0.008254551328718662
step: 240, loss: 0.058788832277059555
step: 250, loss: 0.03474932909011841
step: 260, loss: 0.011272466741502285
step: 270, loss: 0.0006164040532894433
step: 280, loss: 0.08738856762647629
step: 290, loss: 0.024790752679109573
step: 300, loss: 0.035870980471372604
step: 310, loss: 0.04597393423318863
step: 320, loss: 0.004982948303222656
step: 330, loss: 0.002107833279296756
step: 340, loss: 0.050290390849113464
step: 350, loss: 0.01714140921831131
step: 360, loss: 0.010913926176726818
epoch 15: dev_f1=0.7342465753424658, f1=0.7048710601719199, best_f1=0.7401129943502824
step: 0, loss: 0.024845808744430542
step: 10, loss: 0.0746254175901413
step: 20, loss: 0.0001677794207353145
step: 30, loss: 0.017275428399443626
step: 40, loss: 0.0002948012843262404
step: 50, loss: 0.005684154573827982
step: 60, loss: 0.001529366709291935
step: 70, loss: 0.0006990249967202544
step: 80, loss: 0.00046285460120998323
step: 90, loss: 0.1334138959646225
step: 100, loss: 0.001676093670539558
step: 110, loss: 0.001358540146611631
step: 120, loss: 0.024073870852589607
step: 130, loss: 0.0024079037830233574
step: 140, loss: 0.004304453730583191
step: 150, loss: 0.06586657464504242
step: 160, loss: 0.04572392255067825
step: 170, loss: 0.04224863275885582
step: 180, loss: 3.084749187109992e-05
step: 190, loss: 0.0039246464148163795
step: 200, loss: 7.419459871016443e-05
step: 210, loss: 0.0008636049460619688
step: 220, loss: 0.0500134639441967
step: 230, loss: 0.00047951919259503484
step: 240, loss: 0.06933869421482086
step: 250, loss: 0.0003953262057621032
step: 260, loss: 0.04678269103169441
step: 270, loss: 2.5297864340245724e-05
step: 280, loss: 0.03551546111702919
step: 290, loss: 0.052279774099588394
step: 300, loss: 0.08051960170269012
step: 310, loss: 0.04675012081861496
step: 320, loss: 0.0610092431306839
step: 330, loss: 0.0652150958776474
step: 340, loss: 0.0007386087090708315
step: 350, loss: 0.0006155538721941411
step: 360, loss: 0.14526289701461792
epoch 16: dev_f1=0.7506297229219143, f1=0.7395833333333334, best_f1=0.7401129943502824
step: 0, loss: 0.003776022233068943
step: 10, loss: 0.06986430287361145
step: 20, loss: 0.0260381530970335
step: 30, loss: 0.02148582600057125
step: 40, loss: 0.03596317023038864
step: 50, loss: 1.9423430785536766e-05
step: 60, loss: 0.059433747082948685
step: 70, loss: 0.0009856829419732094
step: 80, loss: 0.04266649857163429
step: 90, loss: 0.00022877234732732177
step: 100, loss: 0.06476399302482605
step: 110, loss: 0.001334389322437346
step: 120, loss: 0.018061919137835503
step: 130, loss: 0.006439641583710909
step: 140, loss: 0.057203419506549835
step: 150, loss: 0.01810469478368759
step: 160, loss: 0.00810872483998537
step: 170, loss: 0.0006223231321200728
step: 180, loss: 0.003628046717494726
step: 190, loss: 0.02831108309328556
step: 200, loss: 0.13016387820243835
step: 210, loss: 0.021097367629408836
step: 220, loss: 0.015434607863426208
step: 230, loss: 0.0009612541180104017
step: 240, loss: 9.436127584194764e-05
step: 250, loss: 0.014209415763616562
step: 260, loss: 2.8090300475014374e-05
step: 270, loss: 0.0638950765132904
step: 280, loss: 0.04137837514281273
step: 290, loss: 0.00039553645183332264
step: 300, loss: 0.03802501782774925
step: 310, loss: 0.008673292584717274
step: 320, loss: 0.009594464674592018
step: 330, loss: 0.003219359554350376
step: 340, loss: 0.05983046442270279
step: 350, loss: 0.006020318251103163
step: 360, loss: 0.00041140217217616737
epoch 17: dev_f1=0.7606382978723404, f1=0.7374301675977653, best_f1=0.7401129943502824
step: 0, loss: 0.017203770577907562
step: 10, loss: 0.016894349828362465
step: 20, loss: 0.016292376443743706
step: 30, loss: 0.08028968423604965
step: 40, loss: 0.01854393258690834
step: 50, loss: 0.0003547398664522916
step: 60, loss: 0.03852539882063866
step: 70, loss: 4.520404399954714e-05
step: 80, loss: 0.0001483846572227776
step: 90, loss: 0.03852812200784683
step: 100, loss: 0.03520636633038521
step: 110, loss: 0.024192195385694504
step: 120, loss: 3.715997081599198e-05
step: 130, loss: 0.0025679918471723795
step: 140, loss: 0.0006911966484040022
step: 150, loss: 0.11565849184989929
step: 160, loss: 0.00011979238479398191
step: 170, loss: 0.015239871107041836
step: 180, loss: 8.873716433299705e-05
step: 190, loss: 0.01081144716590643
step: 200, loss: 8.352329314220697e-05
step: 210, loss: 0.031179359182715416
step: 220, loss: 0.012697666883468628
step: 230, loss: 0.09466257691383362
step: 240, loss: 0.020097222179174423
step: 250, loss: 0.018454566597938538
step: 260, loss: 0.024268044158816338
step: 270, loss: 6.285308336373419e-05
step: 280, loss: 0.03689076751470566
step: 290, loss: 0.0173011664301157
step: 300, loss: 0.056807562708854675
step: 310, loss: 0.04131897911429405
step: 320, loss: 0.03256429359316826
step: 330, loss: 0.030265560373663902
step: 340, loss: 0.04106244072318077
step: 350, loss: 0.022061612457036972
step: 360, loss: 0.0171140655875206
epoch 18: dev_f1=0.7486910994764396, f1=0.7333333333333333, best_f1=0.7401129943502824
step: 0, loss: 0.06566867977380753
step: 10, loss: 0.0002408840082352981
step: 20, loss: 0.03878231719136238
step: 30, loss: 0.015530040487647057
step: 40, loss: 0.036205269396305084
step: 50, loss: 7.538433419540524e-05
step: 60, loss: 0.00016667440650053322
step: 70, loss: 2.2585538317798637e-05
step: 80, loss: 0.04879383370280266
step: 90, loss: 0.019998271018266678
step: 100, loss: 4.092154267709702e-05
step: 110, loss: 0.09522724896669388
step: 120, loss: 0.06424107402563095
step: 130, loss: 4.0157676266971976e-05
step: 140, loss: 0.0033761891536414623
step: 150, loss: 1.6692831195541658e-05
step: 160, loss: 2.9594340958283283e-05
step: 170, loss: 0.05983239412307739
step: 180, loss: 0.033901315182447433
step: 190, loss: 0.005683975759893656
step: 200, loss: 0.017009660601615906
step: 210, loss: 0.024215955287218094
step: 220, loss: 0.09351243078708649
step: 230, loss: 0.000128397936350666
step: 240, loss: 0.00015027611516416073
step: 250, loss: 0.0001906838151626289
step: 260, loss: 9.83680656645447e-05
step: 270, loss: 0.05624890327453613
step: 280, loss: 0.04147368296980858
step: 290, loss: 0.0027479820419102907
step: 300, loss: 0.0026398974005132914
step: 310, loss: 9.303120168624446e-05
step: 320, loss: 8.188057108782232e-05
step: 330, loss: 3.9550654037157074e-05
step: 340, loss: 0.0453583225607872
step: 350, loss: 0.044134292751550674
step: 360, loss: 0.015231582336127758
epoch 19: dev_f1=0.7433155080213903, f1=0.7430167597765364, best_f1=0.7401129943502824
step: 0, loss: 0.018169544637203217
step: 10, loss: 0.0333082489669323
step: 20, loss: 0.04164629429578781
step: 30, loss: 0.003361163195222616
step: 40, loss: 0.036621686071157455
step: 50, loss: 0.012362743727862835
step: 60, loss: 0.0003355202206876129
step: 70, loss: 0.012279655784368515
step: 80, loss: 5.817978671984747e-05
step: 90, loss: 5.630129453493282e-05
step: 100, loss: 0.020663946866989136
step: 110, loss: 0.03840029239654541
step: 120, loss: 0.022674264386296272
step: 130, loss: 0.024649735540151596
step: 140, loss: 0.08411271870136261
step: 150, loss: 0.05434112250804901
step: 160, loss: 0.007489299867302179
step: 170, loss: 0.026604756712913513
step: 180, loss: 0.09183298051357269
step: 190, loss: 7.157011714298278e-05
step: 200, loss: 0.037176359444856644
step: 210, loss: 3.179254417773336e-05
step: 220, loss: 0.05669110640883446
step: 230, loss: 0.00015738452202640474
step: 240, loss: 0.04500645026564598
step: 250, loss: 0.002461335388943553
step: 260, loss: 0.00014706410001963377
step: 270, loss: 0.00022429361706599593
step: 280, loss: 0.03327985107898712
step: 290, loss: 0.006574786268174648
step: 300, loss: 4.397618613438681e-05
step: 310, loss: 0.015343541279435158
step: 320, loss: 0.036342646926641464
step: 330, loss: 0.004086472559720278
step: 340, loss: 0.001465657027438283
step: 350, loss: 0.003132305573672056
step: 360, loss: 2.1550265955738723e-05
epoch 20: dev_f1=0.75, f1=0.743801652892562, best_f1=0.7401129943502824
