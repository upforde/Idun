cuda
Device: cuda
step: 0, loss: 0.6976061463356018
step: 10, loss: 0.030084537342190742
step: 20, loss: 0.1369110345840454
step: 30, loss: 0.24319657683372498
step: 40, loss: 0.2337011992931366
step: 50, loss: 0.14231473207473755
step: 60, loss: 0.31419575214385986
step: 70, loss: 0.3084414303302765
step: 80, loss: 0.23234276473522186
step: 90, loss: 0.14014670252799988
step: 100, loss: 0.13693182170391083
step: 110, loss: 0.3951016962528229
step: 120, loss: 0.13387435674667358
step: 130, loss: 0.20252491533756256
step: 140, loss: 0.09499615430831909
step: 150, loss: 0.1895333081483841
step: 160, loss: 0.11139313876628876
step: 170, loss: 0.23939786851406097
step: 180, loss: 0.34683793783187866
step: 190, loss: 0.4133599102497101
step: 200, loss: 0.169149711728096
step: 210, loss: 0.1875327229499817
step: 220, loss: 0.42509183287620544
step: 230, loss: 0.06760787963867188
step: 240, loss: 0.13404764235019684
step: 250, loss: 0.1920696645975113
step: 260, loss: 0.15639685094356537
step: 270, loss: 0.13551059365272522
step: 280, loss: 0.027562959119677544
step: 290, loss: 0.18695801496505737
step: 300, loss: 0.23874299228191376
step: 310, loss: 0.04080147296190262
step: 320, loss: 0.08119623363018036
step: 330, loss: 0.07825949043035507
step: 340, loss: 0.1819775551557541
step: 350, loss: 0.35598310828208923
step: 360, loss: 0.12229251861572266
epoch 1: dev_f1=0.6339066339066339, f1=0.6600496277915633, best_f1=0.6600496277915633
step: 0, loss: 0.20369954407215118
step: 10, loss: 0.13010770082473755
step: 20, loss: 0.11774368584156036
step: 30, loss: 0.05113435909152031
step: 40, loss: 0.05635283887386322
step: 50, loss: 0.20800931751728058
step: 60, loss: 0.0380885973572731
step: 70, loss: 0.26276490092277527
step: 80, loss: 0.26158154010772705
step: 90, loss: 0.17830826342105865
step: 100, loss: 0.27008897066116333
step: 110, loss: 0.06038481742143631
step: 120, loss: 0.08005038648843765
step: 130, loss: 0.2051449418067932
step: 140, loss: 0.1757296770811081
step: 150, loss: 0.1255275458097458
step: 160, loss: 0.08532744646072388
step: 170, loss: 0.2611270546913147
step: 180, loss: 0.11950672417879105
step: 190, loss: 0.26989278197288513
step: 200, loss: 0.09614042937755585
step: 210, loss: 0.2211904525756836
step: 220, loss: 0.10560785233974457
step: 230, loss: 0.039665140211582184
step: 240, loss: 0.2823256254196167
step: 250, loss: 0.03268808126449585
step: 260, loss: 0.08671650290489197
step: 270, loss: 0.06561658531427383
step: 280, loss: 0.06869086623191833
step: 290, loss: 0.15195654332637787
step: 300, loss: 0.16822804510593414
step: 310, loss: 0.031595584005117416
step: 320, loss: 0.027127938345074654
step: 330, loss: 0.05733631178736687
step: 340, loss: 0.06891214102506638
step: 350, loss: 0.3193128705024719
step: 360, loss: 0.14583538472652435
epoch 2: dev_f1=0.7186629526462396, f1=0.7802197802197802, best_f1=0.7802197802197802
step: 0, loss: 0.11649858206510544
step: 10, loss: 0.0029397900216281414
step: 20, loss: 0.10110490769147873
step: 30, loss: 0.16152337193489075
step: 40, loss: 0.19356998801231384
step: 50, loss: 0.05659911036491394
step: 60, loss: 0.02058638446033001
step: 70, loss: 0.04883730784058571
step: 80, loss: 0.130176842212677
step: 90, loss: 0.1631394922733307
step: 100, loss: 0.03883061185479164
step: 110, loss: 0.07383374869823456
step: 120, loss: 0.20306599140167236
step: 130, loss: 0.055214930325746536
step: 140, loss: 0.20331615209579468
step: 150, loss: 0.16906794905662537
step: 160, loss: 0.045428283512592316
step: 170, loss: 0.01853778213262558
step: 180, loss: 0.019191648811101913
step: 190, loss: 0.09121650457382202
step: 200, loss: 0.06863235682249069
step: 210, loss: 0.07278716564178467
step: 220, loss: 0.0019885925576090813
step: 230, loss: 0.08829052746295929
step: 240, loss: 0.004436968360096216
step: 250, loss: 0.05857953056693077
step: 260, loss: 0.13273964822292328
step: 270, loss: 0.08902913331985474
step: 280, loss: 0.23633931577205658
step: 290, loss: 0.1619025468826294
step: 300, loss: 0.09578058868646622
step: 310, loss: 0.15372057259082794
step: 320, loss: 0.09713902324438095
step: 330, loss: 0.13545554876327515
step: 340, loss: 0.08366430550813675
step: 350, loss: 0.11984983086585999
step: 360, loss: 0.060677964240312576
epoch 3: dev_f1=0.7407407407407407, f1=0.7415730337078652, best_f1=0.7415730337078652
step: 0, loss: 0.004139483440667391
step: 10, loss: 0.024253178387880325
step: 20, loss: 0.026324640959501266
step: 30, loss: 0.052874598652124405
step: 40, loss: 0.08466068655252457
step: 50, loss: 0.015612262301146984
step: 60, loss: 0.047258518636226654
step: 70, loss: 0.009709392674267292
step: 80, loss: 0.015127388760447502
step: 90, loss: 0.29012396931648254
step: 100, loss: 0.03339046984910965
step: 110, loss: 0.045540958642959595
step: 120, loss: 0.02045196108520031
step: 130, loss: 0.024721896275877953
step: 140, loss: 0.07074803858995438
step: 150, loss: 0.022583944723010063
step: 160, loss: 0.08580070734024048
step: 170, loss: 0.03719434514641762
step: 180, loss: 0.013119123876094818
step: 190, loss: 0.10050839185714722
step: 200, loss: 0.049849044531583786
step: 210, loss: 0.18088799715042114
step: 220, loss: 0.20433309674263
step: 230, loss: 0.18644484877586365
step: 240, loss: 0.043061692267656326
step: 250, loss: 0.011961654759943485
step: 260, loss: 0.07002832740545273
step: 270, loss: 0.015088808722794056
step: 280, loss: 0.03885132819414139
step: 290, loss: 0.1319071501493454
step: 300, loss: 0.11453993618488312
step: 310, loss: 0.03727422282099724
step: 320, loss: 0.08600091189146042
step: 330, loss: 0.10237294435501099
step: 340, loss: 0.09309743344783783
step: 350, loss: 0.07275455445051193
step: 360, loss: 0.15146727859973907
epoch 4: dev_f1=0.7513227513227512, f1=0.7175141242937854, best_f1=0.7175141242937854
step: 0, loss: 0.02914360538125038
step: 10, loss: 0.03438449651002884
step: 20, loss: 0.04273119941353798
step: 30, loss: 0.030147317796945572
step: 40, loss: 0.025569794699549675
step: 50, loss: 0.1108652651309967
step: 60, loss: 0.02807118371129036
step: 70, loss: 0.009349402971565723
step: 80, loss: 0.09631644189357758
step: 90, loss: 0.028048884123563766
step: 100, loss: 0.014327377080917358
step: 110, loss: 0.15556250512599945
step: 120, loss: 0.09339549392461777
step: 130, loss: 0.03236508369445801
step: 140, loss: 0.04563391953706741
step: 150, loss: 0.05181236192584038
step: 160, loss: 0.03814616799354553
step: 170, loss: 0.13545961678028107
step: 180, loss: 0.05888886749744415
step: 190, loss: 0.06123381853103638
step: 200, loss: 0.010468821972608566
step: 210, loss: 0.08707049489021301
step: 220, loss: 0.12989650666713715
step: 230, loss: 0.029562298208475113
step: 240, loss: 0.055745672434568405
step: 250, loss: 0.08423085510730743
step: 260, loss: 0.08875466138124466
step: 270, loss: 0.14798545837402344
step: 280, loss: 0.08451713621616364
step: 290, loss: 0.006043668836355209
step: 300, loss: 0.031745534390211105
step: 310, loss: 0.016152337193489075
step: 320, loss: 0.06372693926095963
step: 330, loss: 0.008777220733463764
step: 340, loss: 0.07502956688404083
step: 350, loss: 0.043745458126068115
step: 360, loss: 0.07321193814277649
epoch 5: dev_f1=0.7348066298342542, f1=0.7449856733524355, best_f1=0.7175141242937854
step: 0, loss: 0.08654947578907013
step: 10, loss: 0.04423771798610687
step: 20, loss: 0.04198569804430008
step: 30, loss: 0.020415140315890312
step: 40, loss: 0.019881298765540123
step: 50, loss: 0.10220704972743988
step: 60, loss: 0.01601947844028473
step: 70, loss: 0.06853382289409637
step: 80, loss: 0.03006822057068348
step: 90, loss: 0.062454741448163986
step: 100, loss: 0.028027547523379326
step: 110, loss: 0.06782079488039017
step: 120, loss: 0.07330921292304993
step: 130, loss: 0.06588058173656464
step: 140, loss: 0.049142055213451385
step: 150, loss: 0.13359320163726807
step: 160, loss: 0.10082492977380753
step: 170, loss: 0.09151335060596466
step: 180, loss: 0.06964704394340515
step: 190, loss: 0.02758297696709633
step: 200, loss: 0.01622399315237999
step: 210, loss: 0.07028244435787201
step: 220, loss: 0.04052888602018356
step: 230, loss: 0.17058196663856506
step: 240, loss: 0.017597386613488197
step: 250, loss: 0.013286823406815529
step: 260, loss: 0.021648120135068893
step: 270, loss: 0.029802877455949783
step: 280, loss: 0.09940563887357712
step: 290, loss: 0.0013988715363666415
step: 300, loss: 0.015642084181308746
step: 310, loss: 0.0559835210442543
step: 320, loss: 0.04618412256240845
step: 330, loss: 0.0011614782270044088
step: 340, loss: 0.011681867763400078
step: 350, loss: 0.06506521254777908
step: 360, loss: 0.02357780747115612
epoch 6: dev_f1=0.7466666666666666, f1=0.7138810198300283, best_f1=0.7175141242937854
step: 0, loss: 0.012842762283980846
step: 10, loss: 0.023054948076605797
step: 20, loss: 0.023784760385751724
step: 30, loss: 0.001638741814531386
step: 40, loss: 0.048313990235328674
step: 50, loss: 0.036356955766677856
step: 60, loss: 0.1839066445827484
step: 70, loss: 0.07496024668216705
step: 80, loss: 0.04697652906179428
step: 90, loss: 0.04462708532810211
step: 100, loss: 0.10295383632183075
step: 110, loss: 0.07080622017383575
step: 120, loss: 0.011867902241647243
step: 130, loss: 0.125844344496727
step: 140, loss: 0.03739321604371071
step: 150, loss: 0.010737383738160133
step: 160, loss: 0.0704839900135994
step: 170, loss: 0.0038822598289698362
step: 180, loss: 0.02111712470650673
step: 190, loss: 0.020032986998558044
step: 200, loss: 0.029529230669140816
step: 210, loss: 0.016535118222236633
step: 220, loss: 0.00807046890258789
step: 230, loss: 0.025385063141584396
step: 240, loss: 0.07428198307752609
step: 250, loss: 0.03940209746360779
step: 260, loss: 0.047808341681957245
step: 270, loss: 0.10075076669454575
step: 280, loss: 0.1635594367980957
step: 290, loss: 0.03970056027173996
step: 300, loss: 0.04423534870147705
step: 310, loss: 0.027627410367131233
step: 320, loss: 0.0032640155404806137
step: 330, loss: 0.0026855473406612873
step: 340, loss: 0.041244588792324066
step: 350, loss: 0.059527602046728134
step: 360, loss: 0.036978524178266525
epoch 7: dev_f1=0.7309644670050761, f1=0.7362637362637363, best_f1=0.7175141242937854
step: 0, loss: 0.003564653219655156
step: 10, loss: 0.045369669795036316
step: 20, loss: 0.061105385422706604
step: 30, loss: 0.05540843680500984
step: 40, loss: 0.04786391928792
step: 50, loss: 0.04955441877245903
step: 60, loss: 0.040278006345033646
step: 70, loss: 0.0727854073047638
step: 80, loss: 0.006401036866009235
step: 90, loss: 0.0032473800238221884
step: 100, loss: 0.04348623752593994
step: 110, loss: 0.04085610434412956
step: 120, loss: 0.039347339421510696
step: 130, loss: 0.0628138929605484
step: 140, loss: 0.039854347705841064
step: 150, loss: 0.013081797398626804
step: 160, loss: 0.05518126115202904
step: 170, loss: 0.020981615409255028
step: 180, loss: 0.008172471076250076
step: 190, loss: 0.021174348890781403
step: 200, loss: 0.029089121147990227
step: 210, loss: 0.055766407400369644
step: 220, loss: 0.011722911149263382
step: 230, loss: 0.008109943941235542
step: 240, loss: 0.07895705103874207
step: 250, loss: 0.032315097749233246
step: 260, loss: 0.045534297823905945
step: 270, loss: 0.10300923883914948
step: 280, loss: 0.09417107701301575
step: 290, loss: 0.014807185158133507
step: 300, loss: 0.05036773532629013
step: 310, loss: 0.05081229656934738
step: 320, loss: 0.034491490572690964
step: 330, loss: 0.023754339665174484
step: 340, loss: 0.03447073698043823
step: 350, loss: 0.022222507745027542
step: 360, loss: 0.03178831562399864
epoch 8: dev_f1=0.7067669172932332, f1=0.7142857142857143, best_f1=0.7175141242937854
step: 0, loss: 0.007745121140033007
step: 10, loss: 0.011594428680837154
step: 20, loss: 0.07968608289957047
step: 30, loss: 0.008056926541030407
step: 40, loss: 0.022684725001454353
step: 50, loss: 0.030443541705608368
step: 60, loss: 0.08105969429016113
step: 70, loss: 0.07967787981033325
step: 80, loss: 0.021339014172554016
step: 90, loss: 0.04118235036730766
step: 100, loss: 0.07145550847053528
step: 110, loss: 0.03302904590964317
step: 120, loss: 0.01353128906339407
step: 130, loss: 0.03491727262735367
step: 140, loss: 0.010850208811461926
step: 150, loss: 0.05252198129892349
step: 160, loss: 5.922122727497481e-05
step: 170, loss: 0.039964258670806885
step: 180, loss: 0.035336799919605255
step: 190, loss: 0.047342609614133835
step: 200, loss: 0.08390938490629196
step: 210, loss: 0.02426106482744217
step: 220, loss: 0.0032343536149710417
step: 230, loss: 0.018482210114598274
step: 240, loss: 0.016322588548064232
step: 250, loss: 0.022906197234988213
step: 260, loss: 0.04268815368413925
step: 270, loss: 0.00897279568016529
step: 280, loss: 0.034628793597221375
step: 290, loss: 0.014045746996998787
step: 300, loss: 0.11776534467935562
step: 310, loss: 0.020877329632639885
step: 320, loss: 0.0034668154548853636
step: 330, loss: 0.03020472452044487
step: 340, loss: 0.016492968425154686
step: 350, loss: 0.18918085098266602
step: 360, loss: 0.12109275162220001
epoch 9: dev_f1=0.733509234828496, f1=0.7231638418079097, best_f1=0.7175141242937854
step: 0, loss: 0.03484804928302765
step: 10, loss: 0.027242550626397133
step: 20, loss: 0.01933850347995758
step: 30, loss: 0.02663886733353138
step: 40, loss: 0.06267406791448593
step: 50, loss: 0.03482021018862724
step: 60, loss: 0.0048150718212127686
step: 70, loss: 0.05946848914027214
step: 80, loss: 0.005644307937473059
step: 90, loss: 0.008484281599521637
step: 100, loss: 0.0715189129114151
step: 110, loss: 0.06394048780202866
step: 120, loss: 0.126139298081398
step: 130, loss: 0.0037143235094845295
step: 140, loss: 0.011490242555737495
step: 150, loss: 0.0360824353992939
step: 160, loss: 0.0019131700973957777
step: 170, loss: 0.02718922682106495
step: 180, loss: 0.10136502236127853
step: 190, loss: 0.01602504774928093
step: 200, loss: 0.0007615774520672858
step: 210, loss: 0.0004865227092523128
step: 220, loss: 0.020152851939201355
step: 230, loss: 0.01607624813914299
step: 240, loss: 3.990020195487887e-05
step: 250, loss: 0.03426666930317879
step: 260, loss: 0.0050487513653934
step: 270, loss: 0.015431312844157219
step: 280, loss: 0.09013006836175919
step: 290, loss: 0.019977064803242683
step: 300, loss: 0.03868913650512695
step: 310, loss: 0.027110261842608452
step: 320, loss: 0.09526000171899796
step: 330, loss: 0.07292423397302628
step: 340, loss: 0.061227478086948395
step: 350, loss: 0.014804753474891186
step: 360, loss: 0.031896188855171204
epoch 10: dev_f1=0.7393617021276595, f1=0.7089337175792507, best_f1=0.7175141242937854
step: 0, loss: 0.011036652140319347
step: 10, loss: 0.1047365814447403
step: 20, loss: 0.011067220941185951
step: 30, loss: 0.021330438554286957
step: 40, loss: 0.0075515927746891975
step: 50, loss: 0.001975600142031908
step: 60, loss: 0.03593087196350098
step: 70, loss: 0.00619051419198513
step: 80, loss: 0.05319637432694435
step: 90, loss: 0.007469498086720705
step: 100, loss: 0.012393905781209469
step: 110, loss: 0.0002777514746412635
step: 120, loss: 0.019301680848002434
step: 130, loss: 0.04420948773622513
step: 140, loss: 0.007028816267848015
step: 150, loss: 0.0498855784535408
step: 160, loss: 0.06936673074960709
step: 170, loss: 0.12229156494140625
step: 180, loss: 0.027431810274720192
step: 190, loss: 0.005801530089229345
step: 200, loss: 0.021706651896238327
step: 210, loss: 0.00789091270416975
step: 220, loss: 0.12712517380714417
step: 230, loss: 0.06536991894245148
step: 240, loss: 0.032772719860076904
step: 250, loss: 0.08984790742397308
step: 260, loss: 0.19556525349617004
step: 270, loss: 0.013878782279789448
step: 280, loss: 0.03844853863120079
step: 290, loss: 0.021832533180713654
step: 300, loss: 0.003982994705438614
step: 310, loss: 0.03786825016140938
step: 320, loss: 0.10528941452503204
step: 330, loss: 0.038458336144685745
step: 340, loss: 0.0004307162016630173
step: 350, loss: 0.0278311800211668
step: 360, loss: 0.03260774537920952
epoch 11: dev_f1=0.732824427480916, f1=0.7162534435261707, best_f1=0.7175141242937854
step: 0, loss: 0.022524073719978333
step: 10, loss: 0.017323508858680725
step: 20, loss: 0.01339374203234911
step: 30, loss: 0.019977129995822906
step: 40, loss: 0.020021580159664154
step: 50, loss: 0.08213737607002258
step: 60, loss: 0.005451537668704987
step: 70, loss: 0.0016434313729405403
step: 80, loss: 0.029790950939059258
step: 90, loss: 0.006944417487829924
step: 100, loss: 0.007001715246587992
step: 110, loss: 0.0010875113075599074
step: 120, loss: 0.017039494588971138
step: 130, loss: 0.027574898675084114
step: 140, loss: 0.0015177130699157715
step: 150, loss: 0.019046694040298462
step: 160, loss: 0.0019034853903576732
step: 170, loss: 0.013815701007843018
step: 180, loss: 0.003870793618261814
step: 190, loss: 0.038365043699741364
step: 200, loss: 0.0082650575786829
step: 210, loss: 0.16108942031860352
step: 220, loss: 0.00024062521697487682
step: 230, loss: 0.06457952409982681
step: 240, loss: 0.0019397935830056667
step: 250, loss: 0.006461949087679386
step: 260, loss: 0.019199112430214882
step: 270, loss: 0.03216584771871567
step: 280, loss: 0.000902591971680522
step: 290, loss: 0.024297472089529037
step: 300, loss: 0.019674265757203102
step: 310, loss: 0.027651190757751465
step: 320, loss: 0.019836021587252617
step: 330, loss: 0.03768954798579216
step: 340, loss: 0.017229290679097176
step: 350, loss: 0.011779282242059708
step: 360, loss: 0.16591563820838928
epoch 12: dev_f1=0.7345844504021448, f1=0.7102272727272727, best_f1=0.7175141242937854
step: 0, loss: 0.004986851941794157
step: 10, loss: 0.0002913344360422343
step: 20, loss: 0.00995432399213314
step: 30, loss: 0.001139176427386701
step: 40, loss: 0.058839790523052216
step: 50, loss: 0.01893969625234604
step: 60, loss: 0.0003777781093958765
step: 70, loss: 0.028940686956048012
step: 80, loss: 4.88582591060549e-05
step: 90, loss: 0.005539828911423683
step: 100, loss: 0.0033418333623558283
step: 110, loss: 0.0029077348299324512
step: 120, loss: 2.7990770831820555e-05
step: 130, loss: 0.009229930117726326
step: 140, loss: 0.09037834405899048
step: 150, loss: 0.061883289366960526
step: 160, loss: 0.000561607361305505
step: 170, loss: 0.008307499811053276
step: 180, loss: 0.004253729246556759
step: 190, loss: 0.00033719875500537455
step: 200, loss: 0.014020453207194805
step: 210, loss: 0.021027283743023872
step: 220, loss: 0.09589362889528275
step: 230, loss: 0.0018301715608686209
step: 240, loss: 0.04951364919543266
step: 250, loss: 0.02124262973666191
step: 260, loss: 0.14629389345645905
step: 270, loss: 0.006390740629285574
step: 280, loss: 0.02421053685247898
step: 290, loss: 0.06244068592786789
step: 300, loss: 0.03565499559044838
step: 310, loss: 0.026107821613550186
step: 320, loss: 0.02940804697573185
step: 330, loss: 4.9068243242800236e-05
step: 340, loss: 0.1707785278558731
step: 350, loss: 0.03704505413770676
step: 360, loss: 0.023966578766703606
epoch 13: dev_f1=0.7512953367875648, f1=0.7313019390581716, best_f1=0.7175141242937854
step: 0, loss: 0.01880326308310032
step: 10, loss: 0.0008562840521335602
step: 20, loss: 0.01833905279636383
step: 30, loss: 0.03168156370520592
step: 40, loss: 0.07792173326015472
step: 50, loss: 0.04148785397410393
step: 60, loss: 0.07168527692556381
step: 70, loss: 0.0018329035956412554
step: 80, loss: 0.027058616280555725
step: 90, loss: 0.017086133360862732
step: 100, loss: 0.06460093706846237
step: 110, loss: 0.0040853917598724365
step: 120, loss: 0.0013376805000007153
step: 130, loss: 0.031115375459194183
step: 140, loss: 0.003215046366676688
step: 150, loss: 0.05325142294168472
step: 160, loss: 0.041913390159606934
step: 170, loss: 0.01688404381275177
step: 180, loss: 0.014459754340350628
step: 190, loss: 0.002137138042598963
step: 200, loss: 0.017953377217054367
step: 210, loss: 0.024148376658558846
step: 220, loss: 0.0012193359434604645
step: 230, loss: 0.0011146189644932747
step: 240, loss: 0.0003264519909862429
step: 250, loss: 0.05796061456203461
step: 260, loss: 0.00890464149415493
step: 270, loss: 0.006051518954336643
step: 280, loss: 0.008807123638689518
step: 290, loss: 0.001793754636310041
step: 300, loss: 0.11816594004631042
step: 310, loss: 3.100769754382782e-05
step: 320, loss: 0.01422821544110775
step: 330, loss: 0.054097916930913925
step: 340, loss: 0.07776457071304321
step: 350, loss: 0.024138784036040306
step: 360, loss: 0.011430994607508183
epoch 14: dev_f1=0.7577319587628867, f1=0.7197802197802198, best_f1=0.7197802197802198
step: 0, loss: 0.001005257829092443
step: 10, loss: 2.785282595141325e-05
step: 20, loss: 0.0075073703192174435
step: 30, loss: 0.005793774966150522
step: 40, loss: 0.0192633755505085
step: 50, loss: 0.00026126220473088324
step: 60, loss: 0.02454492263495922
step: 70, loss: 0.09042482078075409
step: 80, loss: 0.0922999233007431
step: 90, loss: 3.915547131327912e-05
step: 100, loss: 0.003540555713698268
step: 110, loss: 0.1273786425590515
step: 120, loss: 0.007988600060343742
step: 130, loss: 0.026673059910535812
step: 140, loss: 0.004584170877933502
step: 150, loss: 0.01465591136366129
step: 160, loss: 0.03367558494210243
step: 170, loss: 0.0003959143941756338
step: 180, loss: 0.08690641075372696
step: 190, loss: 0.008260770700871944
step: 200, loss: 0.01632092520594597
step: 210, loss: 0.005352331325411797
step: 220, loss: 0.02295418083667755
step: 230, loss: 0.0013470577541738749
step: 240, loss: 0.0015459258574992418
step: 250, loss: 0.054562997072935104
step: 260, loss: 0.0036025913432240486
step: 270, loss: 0.0006895670085214078
step: 280, loss: 0.0007010403787717223
step: 290, loss: 0.02230553701519966
step: 300, loss: 0.00030491608777083457
step: 310, loss: 0.005715809762477875
step: 320, loss: 0.0006127400556579232
step: 330, loss: 0.0004256066167727113
step: 340, loss: 0.03979816660284996
step: 350, loss: 0.0009963532211259007
step: 360, loss: 0.0029757656157016754
epoch 15: dev_f1=0.7409470752089136, f1=0.735042735042735, best_f1=0.7197802197802198
step: 0, loss: 0.010400857776403427
step: 10, loss: 0.04840104654431343
step: 20, loss: 0.013660524040460587
step: 30, loss: 0.006352537777274847
step: 40, loss: 0.013580221682786942
step: 50, loss: 0.00023222183517646044
step: 60, loss: 0.007366552017629147
step: 70, loss: 0.01300627738237381
step: 80, loss: 1.8801327314577065e-05
step: 90, loss: 0.01609431952238083
step: 100, loss: 0.007008740678429604
step: 110, loss: 0.016521714627742767
step: 120, loss: 1.84213731699856e-05
step: 130, loss: 0.00026822465588338673
step: 140, loss: 2.810202022374142e-05
step: 150, loss: 0.02266314998269081
step: 160, loss: 0.005321660544723272
step: 170, loss: 0.01923779584467411
step: 180, loss: 0.017604995518922806
step: 190, loss: 0.008707942441105843
step: 200, loss: 0.0008721560006961226
step: 210, loss: 0.03648047521710396
step: 220, loss: 0.02209842950105667
step: 230, loss: 0.02633591927587986
step: 240, loss: 0.06123451888561249
step: 250, loss: 0.022484319284558296
step: 260, loss: 0.0010509559651836753
step: 270, loss: 0.02219212055206299
step: 280, loss: 0.04445743188261986
step: 290, loss: 0.09218361228704453
step: 300, loss: 0.017485806718468666
step: 310, loss: 0.008370294235646725
step: 320, loss: 0.0002221017493866384
step: 330, loss: 0.003465408692136407
step: 340, loss: 0.0012987239751964808
step: 350, loss: 3.459490108070895e-05
step: 360, loss: 0.020486269146203995
epoch 16: dev_f1=0.7526315789473683, f1=0.7423822714681441, best_f1=0.7197802197802198
step: 0, loss: 0.0024583369959145784
step: 10, loss: 0.001320582116022706
step: 20, loss: 0.019235795363783836
step: 30, loss: 0.03999173641204834
step: 40, loss: 0.0027589290402829647
step: 50, loss: 0.001304033910855651
step: 60, loss: 0.00961746834218502
step: 70, loss: 0.01928560808300972
step: 80, loss: 0.0001324488257523626
step: 90, loss: 0.03816518187522888
step: 100, loss: 0.0993662029504776
step: 110, loss: 0.00247989222407341
step: 120, loss: 9.926759958034381e-05
step: 130, loss: 0.07074811309576035
step: 140, loss: 0.07326801121234894
step: 150, loss: 0.033151689916849136
step: 160, loss: 0.0017649828223511577
step: 170, loss: 0.015922868624329567
step: 180, loss: 0.03498479723930359
step: 190, loss: 0.003207392990589142
step: 200, loss: 0.04840143397450447
step: 210, loss: 0.0037521852646023035
step: 220, loss: 0.021784070879220963
step: 230, loss: 0.026950867846608162
step: 240, loss: 0.042960550636053085
step: 250, loss: 1.666678326728288e-05
step: 260, loss: 0.030541185289621353
step: 270, loss: 0.07898278534412384
step: 280, loss: 0.01958271488547325
step: 290, loss: 8.358708873856813e-05
step: 300, loss: 0.0002672050322871655
step: 310, loss: 0.035177018493413925
step: 320, loss: 0.0035776991862803698
step: 330, loss: 0.02648705616593361
step: 340, loss: 0.00017540817498229444
step: 350, loss: 0.03586651384830475
step: 360, loss: 0.012179958634078503
epoch 17: dev_f1=0.7461139896373058, f1=0.7362637362637363, best_f1=0.7197802197802198
step: 0, loss: 4.674054798670113e-05
step: 10, loss: 0.039335913956165314
step: 20, loss: 0.0013175313360989094
step: 30, loss: 0.04052417725324631
step: 40, loss: 0.00038548005977645516
step: 50, loss: 0.0005655881250277162
step: 60, loss: 0.0004538917855825275
step: 70, loss: 0.007267142180353403
step: 80, loss: 0.03356858715415001
step: 90, loss: 0.013589649461209774
step: 100, loss: 0.000581362284719944
step: 110, loss: 8.959405386121944e-05
step: 120, loss: 1.9538678316166624e-05
step: 130, loss: 0.00014192660455591977
step: 140, loss: 1.6018606402212754e-05
step: 150, loss: 0.0036708724219352007
step: 160, loss: 0.04354177415370941
step: 170, loss: 0.00013658140960615128
step: 180, loss: 0.019097981974482536
step: 190, loss: 0.004023123532533646
step: 200, loss: 0.025658078491687775
step: 210, loss: 0.0042639304883778095
step: 220, loss: 0.0009252768941223621
step: 230, loss: 0.016788944602012634
step: 240, loss: 0.01840204745531082
step: 250, loss: 0.02137158438563347
step: 260, loss: 0.18306055665016174
step: 270, loss: 0.01111541036516428
step: 280, loss: 0.05737913399934769
step: 290, loss: 0.0531190000474453
step: 300, loss: 0.001794078154489398
step: 310, loss: 0.045419465750455856
step: 320, loss: 0.015637151896953583
step: 330, loss: 0.0003159701300319284
step: 340, loss: 0.02256319858133793
step: 350, loss: 0.08163874596357346
step: 360, loss: 0.035353727638721466
epoch 18: dev_f1=0.7403598971722366, f1=0.7282608695652173, best_f1=0.7197802197802198
step: 0, loss: 0.0003912659885827452
step: 10, loss: 4.212681233184412e-05
step: 20, loss: 2.999810931214597e-05
step: 30, loss: 0.012097055092453957
step: 40, loss: 0.06399507820606232
step: 50, loss: 0.036410506814718246
step: 60, loss: 0.0254818182438612
step: 70, loss: 0.019619302824139595
step: 80, loss: 1.819775570766069e-05
step: 90, loss: 0.04440642520785332
step: 100, loss: 0.003796851262450218
step: 110, loss: 0.017804328352212906
step: 120, loss: 0.000272593111731112
step: 130, loss: 0.0015081717865541577
step: 140, loss: 0.018202481791377068
step: 150, loss: 0.03279242664575577
step: 160, loss: 0.0012144561624154449
step: 170, loss: 0.00020367135584820062
step: 180, loss: 2.129329186573159e-05
step: 190, loss: 0.02208837680518627
step: 200, loss: 0.00012655099271796644
step: 210, loss: 0.00018848899344448
step: 220, loss: 0.010415452532470226
step: 230, loss: 1.351152423012536e-05
step: 240, loss: 0.00011995372187811881
step: 250, loss: 0.0015183156356215477
step: 260, loss: 0.0001016322203213349
step: 270, loss: 0.01946663111448288
step: 280, loss: 0.00036085298052057624
step: 290, loss: 0.05013509839773178
step: 300, loss: 0.011355086229741573
step: 310, loss: 0.026101024821400642
step: 320, loss: 0.02995026670396328
step: 330, loss: 0.062157489359378815
step: 340, loss: 0.019702089950442314
step: 350, loss: 0.04827658459544182
step: 360, loss: 0.03027038462460041
epoch 19: dev_f1=0.7368421052631579, f1=0.7362318840579711, best_f1=0.7197802197802198
step: 0, loss: 0.010377869009971619
step: 10, loss: 0.009117559529840946
step: 20, loss: 0.014702660031616688
step: 30, loss: 0.00026441365480422974
step: 40, loss: 0.09919845312833786
step: 50, loss: 6.054097684682347e-05
step: 60, loss: 0.015397889539599419
step: 70, loss: 0.019165461882948875
step: 80, loss: 0.01043962687253952
step: 90, loss: 0.009378216229379177
step: 100, loss: 0.010213028639554977
step: 110, loss: 6.817979738116264e-05
step: 120, loss: 0.00021327586728148162
step: 130, loss: 0.05663970112800598
step: 140, loss: 0.017482217401266098
step: 150, loss: 1.4662627108918969e-05
step: 160, loss: 0.04678922891616821
step: 170, loss: 1.3440750990412198e-05
step: 180, loss: 0.00011894541967194527
step: 190, loss: 0.02649262547492981
step: 200, loss: 0.051743268966674805
step: 210, loss: 0.0030493121594190598
step: 220, loss: 0.004902161657810211
step: 230, loss: 0.04513700306415558
step: 240, loss: 0.09479707479476929
step: 250, loss: 0.0004293588863220066
step: 260, loss: 0.01493047084659338
step: 270, loss: 0.019174782559275627
step: 280, loss: 0.00030310661531984806
step: 290, loss: 0.00805672537535429
step: 300, loss: 0.00313508789986372
step: 310, loss: 0.03576198220252991
step: 320, loss: 0.0031408483628183603
step: 330, loss: 0.00518383365124464
step: 340, loss: 0.012559042312204838
step: 350, loss: 0.0017130621708929539
step: 360, loss: 0.016976838931441307
epoch 20: dev_f1=0.7374301675977653, f1=0.7346938775510203, best_f1=0.7197802197802198
