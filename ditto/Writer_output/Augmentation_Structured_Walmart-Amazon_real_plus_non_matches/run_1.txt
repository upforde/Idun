cuda
Device: cuda
step: 0, loss: 0.5584151744842529
step: 10, loss: 0.1497192084789276
step: 20, loss: 0.3503435552120209
step: 30, loss: 0.3313944637775421
step: 40, loss: 0.31393328309059143
step: 50, loss: 0.03687822073698044
step: 60, loss: 0.3580661714076996
step: 70, loss: 0.0714777261018753
step: 80, loss: 0.032601695507764816
step: 90, loss: 0.22943075001239777
step: 100, loss: 0.1340698003768921
step: 110, loss: 0.4220848083496094
step: 120, loss: 0.30840474367141724
step: 130, loss: 0.12905171513557434
step: 140, loss: 0.04885160177946091
step: 150, loss: 0.18150921165943146
step: 160, loss: 0.13692724704742432
step: 170, loss: 0.3359285295009613
step: 180, loss: 0.39075329899787903
step: 190, loss: 0.025088222697377205
step: 200, loss: 0.060475751757621765
step: 210, loss: 0.04644431173801422
step: 220, loss: 0.02915172651410103
step: 230, loss: 0.34277838468551636
step: 240, loss: 0.08897588402032852
step: 250, loss: 0.1324433833360672
step: 260, loss: 0.08962196111679077
step: 270, loss: 0.057767849415540695
step: 280, loss: 0.16061636805534363
step: 290, loss: 0.0660625696182251
step: 300, loss: 0.21817070245742798
step: 310, loss: 0.1478356420993805
step: 320, loss: 0.27982082962989807
step: 330, loss: 0.058246713131666183
step: 340, loss: 0.08190908282995224
step: 350, loss: 0.07747212797403336
step: 360, loss: 0.01654108799993992
epoch 1: dev_f1=0.6633416458852868, f1=0.6875000000000001, best_f1=0.6875000000000001
step: 0, loss: 0.1111181303858757
step: 10, loss: 0.060161132365465164
step: 20, loss: 0.3166486620903015
step: 30, loss: 0.036868561059236526
step: 40, loss: 0.02165253460407257
step: 50, loss: 0.36586129665374756
step: 60, loss: 0.030486976727843285
step: 70, loss: 0.031553030014038086
step: 80, loss: 0.30788654088974
step: 90, loss: 0.06806504726409912
step: 100, loss: 0.18917174637317657
step: 110, loss: 0.26843494176864624
step: 120, loss: 0.06543537229299545
step: 130, loss: 0.0842784196138382
step: 140, loss: 0.03933984786272049
step: 150, loss: 0.24230164289474487
step: 160, loss: 0.09153898060321808
step: 170, loss: 0.3402508795261383
step: 180, loss: 0.09580079466104507
step: 190, loss: 0.1999225914478302
step: 200, loss: 0.12164594233036041
step: 210, loss: 0.0729449912905693
step: 220, loss: 0.060738224536180496
step: 230, loss: 0.02514943853020668
step: 240, loss: 0.046516381204128265
step: 250, loss: 0.1250363290309906
step: 260, loss: 0.052117545157670975
step: 270, loss: 0.10806678235530853
step: 280, loss: 0.1189846396446228
step: 290, loss: 0.06980309635400772
step: 300, loss: 0.24840737879276276
step: 310, loss: 0.19300152361392975
step: 320, loss: 0.06798747926950455
step: 330, loss: 0.1970841884613037
step: 340, loss: 0.13009744882583618
step: 350, loss: 0.030337244272232056
step: 360, loss: 0.08633743226528168
epoch 2: dev_f1=0.7035175879396985, f1=0.7095238095238094, best_f1=0.7095238095238094
step: 0, loss: 0.09550346434116364
step: 10, loss: 0.08760347217321396
step: 20, loss: 0.01859245076775551
step: 30, loss: 0.10157995671033859
step: 40, loss: 0.021604832261800766
step: 50, loss: 0.10953227430582047
step: 60, loss: 0.13215908408164978
step: 70, loss: 0.04007704555988312
step: 80, loss: 0.13675807416439056
step: 90, loss: 0.08737295866012573
step: 100, loss: 0.048360660672187805
step: 110, loss: 0.1181526705622673
step: 120, loss: 0.021928569301962852
step: 130, loss: 0.09748532623052597
step: 140, loss: 0.0771593302488327
step: 150, loss: 0.06017553061246872
step: 160, loss: 0.05075376108288765
step: 170, loss: 0.0022002181503921747
step: 180, loss: 0.08143917471170425
step: 190, loss: 0.14895132184028625
step: 200, loss: 0.09366539120674133
step: 210, loss: 0.08808945119380951
step: 220, loss: 0.10958608984947205
step: 230, loss: 0.054573673754930496
step: 240, loss: 0.10948937386274338
step: 250, loss: 0.17555634677410126
step: 260, loss: 0.07421720027923584
step: 270, loss: 0.10944940894842148
step: 280, loss: 0.11836796998977661
step: 290, loss: 0.11499305069446564
step: 300, loss: 0.20973777770996094
step: 310, loss: 0.1570664346218109
step: 320, loss: 0.11530756950378418
step: 330, loss: 0.036304228007793427
step: 340, loss: 0.045449454337358475
step: 350, loss: 0.007610886357724667
step: 360, loss: 0.03086608648300171
epoch 3: dev_f1=0.7020202020202021, f1=0.7209876543209877, best_f1=0.7095238095238094
step: 0, loss: 0.0390394926071167
step: 10, loss: 0.09249187260866165
step: 20, loss: 0.07650492340326309
step: 30, loss: 0.074189193546772
step: 40, loss: 0.03464604541659355
step: 50, loss: 0.07146503031253815
step: 60, loss: 0.09227382391691208
step: 70, loss: 0.02268037013709545
step: 80, loss: 0.14986345171928406
step: 90, loss: 0.053656063973903656
step: 100, loss: 0.04697216674685478
step: 110, loss: 0.04909070208668709
step: 120, loss: 0.09082239121198654
step: 130, loss: 0.03845784068107605
step: 140, loss: 0.16390573978424072
step: 150, loss: 0.05102357268333435
step: 160, loss: 0.02264956757426262
step: 170, loss: 0.007398244924843311
step: 180, loss: 0.057176098227500916
step: 190, loss: 0.073374442756176
step: 200, loss: 0.018494650721549988
step: 210, loss: 0.036038659512996674
step: 220, loss: 0.08657824993133545
step: 230, loss: 0.03887391462922096
step: 240, loss: 0.060268402099609375
step: 250, loss: 0.07394999265670776
step: 260, loss: 0.11265602707862854
step: 270, loss: 0.11936484277248383
step: 280, loss: 0.06567651778459549
step: 290, loss: 0.04503589868545532
step: 300, loss: 0.2863927483558655
step: 310, loss: 0.10818445682525635
step: 320, loss: 0.005686499644070864
step: 330, loss: 0.041380319744348526
step: 340, loss: 0.07630229741334915
step: 350, loss: 0.10180254280567169
step: 360, loss: 0.2245110720396042
epoch 4: dev_f1=0.7365591397849462, f1=0.7394957983193278, best_f1=0.7394957983193278
step: 0, loss: 0.06633731722831726
step: 10, loss: 0.09616893529891968
step: 20, loss: 0.019438767805695534
step: 30, loss: 0.09351344406604767
step: 40, loss: 0.040943343192338943
step: 50, loss: 0.02000328339636326
step: 60, loss: 0.05010296404361725
step: 70, loss: 0.00506366603076458
step: 80, loss: 0.08537713438272476
step: 90, loss: 0.049771636724472046
step: 100, loss: 0.06487061828374863
step: 110, loss: 0.04426214471459389
step: 120, loss: 0.04971010610461235
step: 130, loss: 0.09135925769805908
step: 140, loss: 0.06305071711540222
step: 150, loss: 0.11557711660861969
step: 160, loss: 0.11085319519042969
step: 170, loss: 0.04153196141123772
step: 180, loss: 0.031465254724025726
step: 190, loss: 0.07167711108922958
step: 200, loss: 0.11586533486843109
step: 210, loss: 0.052535030990839005
step: 220, loss: 0.06663355976343155
step: 230, loss: 0.048006460070610046
step: 240, loss: 0.012052170932292938
step: 250, loss: 0.033857397735118866
step: 260, loss: 0.13959190249443054
step: 270, loss: 0.01665542647242546
step: 280, loss: 0.0674913227558136
step: 290, loss: 0.04457378759980202
step: 300, loss: 0.03512602671980858
step: 310, loss: 0.07867594808340073
step: 320, loss: 0.017061330378055573
step: 330, loss: 0.028624704107642174
step: 340, loss: 0.008791801519691944
step: 350, loss: 0.19342905282974243
step: 360, loss: 0.11849403381347656
epoch 5: dev_f1=0.728538283062645, f1=0.7250608272506084, best_f1=0.7394957983193278
step: 0, loss: 0.06586300581693649
step: 10, loss: 0.00040443780017085373
step: 20, loss: 0.3096873164176941
step: 30, loss: 0.02136741578578949
step: 40, loss: 0.11250313371419907
step: 50, loss: 0.08543268591165543
step: 60, loss: 0.025354258716106415
step: 70, loss: 0.035093024373054504
step: 80, loss: 0.09602881968021393
step: 90, loss: 0.01701859012246132
step: 100, loss: 0.12049634009599686
step: 110, loss: 0.09184940159320831
step: 120, loss: 0.06248930096626282
step: 130, loss: 0.05331284925341606
step: 140, loss: 0.04660645127296448
step: 150, loss: 0.013024716638028622
step: 160, loss: 0.008713144809007645
step: 170, loss: 0.004219081252813339
step: 180, loss: 0.0012841676361858845
step: 190, loss: 0.07015331834554672
step: 200, loss: 0.009580519050359726
step: 210, loss: 0.11246132850646973
step: 220, loss: 0.014423215761780739
step: 230, loss: 0.039145562797784805
step: 240, loss: 0.07572760432958603
step: 250, loss: 0.06974053382873535
step: 260, loss: 0.1573927402496338
step: 270, loss: 0.0541246272623539
step: 280, loss: 0.06857434660196304
step: 290, loss: 0.055824100971221924
step: 300, loss: 0.06668970733880997
step: 310, loss: 0.06367980688810349
step: 320, loss: 0.1977289617061615
step: 330, loss: 0.0861329510807991
step: 340, loss: 0.058716051280498505
step: 350, loss: 0.025795403867959976
step: 360, loss: 0.009745312854647636
epoch 6: dev_f1=0.7751937984496123, f1=0.7387862796833773, best_f1=0.7387862796833773
step: 0, loss: 0.029520446434617043
step: 10, loss: 0.03284581005573273
step: 20, loss: 0.04928623512387276
step: 30, loss: 0.0455758236348629
step: 40, loss: 0.02646704390645027
step: 50, loss: 0.1475408971309662
step: 60, loss: 0.0681358277797699
step: 70, loss: 0.008793728426098824
step: 80, loss: 0.08600296080112457
step: 90, loss: 0.04029442369937897
step: 100, loss: 0.0007009071414358914
step: 110, loss: 0.004235497210174799
step: 120, loss: 0.05682630091905594
step: 130, loss: 0.04280707612633705
step: 140, loss: 0.06789033114910126
step: 150, loss: 0.08690234273672104
step: 160, loss: 0.0315178819000721
step: 170, loss: 0.03251959756016731
step: 180, loss: 0.05260429531335831
step: 190, loss: 0.06532470136880875
step: 200, loss: 0.006413004361093044
step: 210, loss: 0.0010242436546832323
step: 220, loss: 0.03681960701942444
step: 230, loss: 0.0378548689186573
step: 240, loss: 0.022001907229423523
step: 250, loss: 0.07242018729448318
step: 260, loss: 0.10263177007436752
step: 270, loss: 0.10647861659526825
step: 280, loss: 0.057049091905355453
step: 290, loss: 0.0075377728790044785
step: 300, loss: 0.000389164371881634
step: 310, loss: 0.0918581485748291
step: 320, loss: 0.08825241774320602
step: 330, loss: 0.05128442868590355
step: 340, loss: 0.0003294271300546825
step: 350, loss: 0.1104440838098526
step: 360, loss: 0.2006864696741104
epoch 7: dev_f1=0.7268170426065164, f1=0.7286821705426356, best_f1=0.7387862796833773
step: 0, loss: 0.006079003214836121
step: 10, loss: 0.11414901912212372
step: 20, loss: 0.01448563951998949
step: 30, loss: 0.004108778201043606
step: 40, loss: 0.15396732091903687
step: 50, loss: 0.050863150507211685
step: 60, loss: 0.06763187050819397
step: 70, loss: 0.017759036272764206
step: 80, loss: 0.10820028185844421
step: 90, loss: 0.0032594245858490467
step: 100, loss: 0.04338853806257248
step: 110, loss: 0.1306055188179016
step: 120, loss: 0.02344387397170067
step: 130, loss: 0.007264299783855677
step: 140, loss: 0.06098414212465286
step: 150, loss: 0.001800286932848394
step: 160, loss: 0.07654832303524017
step: 170, loss: 0.023910097777843475
step: 180, loss: 0.0490262396633625
step: 190, loss: 0.03767181932926178
step: 200, loss: 0.015099930576980114
step: 210, loss: 0.00241758837364614
step: 220, loss: 0.06471367180347443
step: 230, loss: 0.08608568459749222
step: 240, loss: 0.0896606519818306
step: 250, loss: 0.14909125864505768
step: 260, loss: 5.697922097169794e-05
step: 270, loss: 0.07584425061941147
step: 280, loss: 0.017366886138916016
step: 290, loss: 0.054384224116802216
step: 300, loss: 0.01696065068244934
step: 310, loss: 0.03556930646300316
step: 320, loss: 0.08874860405921936
step: 330, loss: 0.01260854210704565
step: 340, loss: 0.004315077792853117
step: 350, loss: 0.020983919501304626
step: 360, loss: 0.10024247318506241
epoch 8: dev_f1=0.7358490566037736, f1=0.7268292682926828, best_f1=0.7387862796833773
step: 0, loss: 0.002691329689696431
step: 10, loss: 0.030530229210853577
step: 20, loss: 0.0024403524585068226
step: 30, loss: 0.006455527152866125
step: 40, loss: 0.022720299661159515
step: 50, loss: 0.05146114155650139
step: 60, loss: 0.0008688188972882926
step: 70, loss: 0.07544230669736862
step: 80, loss: 0.16782605648040771
step: 90, loss: 0.005480654537677765
step: 100, loss: 0.03569694608449936
step: 110, loss: 0.057440001517534256
step: 120, loss: 0.005409822333604097
step: 130, loss: 0.023417111486196518
step: 140, loss: 0.08226452767848969
step: 150, loss: 0.10084737092256546
step: 160, loss: 0.12210620194673538
step: 170, loss: 0.001315318513661623
step: 180, loss: 0.030044494196772575
step: 190, loss: 0.04170098528265953
step: 200, loss: 0.05876266211271286
step: 210, loss: 0.038077957928180695
step: 220, loss: 0.024023426696658134
step: 230, loss: 0.06941599398851395
step: 240, loss: 0.06565185636281967
step: 250, loss: 0.06864985078573227
step: 260, loss: 0.012800793163478374
step: 270, loss: 0.02846689522266388
step: 280, loss: 0.08525274693965912
step: 290, loss: 0.030801180750131607
step: 300, loss: 0.003380199195817113
step: 310, loss: 0.010863693431019783
step: 320, loss: 0.07334250956773758
step: 330, loss: 0.02502480521798134
step: 340, loss: 0.03740975633263588
step: 350, loss: 0.033650293946266174
step: 360, loss: 0.04966585710644722
epoch 9: dev_f1=0.7064439140811456, f1=0.7002518891687657, best_f1=0.7387862796833773
step: 0, loss: 0.06991741061210632
step: 10, loss: 0.060824137181043625
step: 20, loss: 0.0034588193520903587
step: 30, loss: 0.061423931270837784
step: 40, loss: 0.007437516935169697
step: 50, loss: 0.0044627138413488865
step: 60, loss: 0.04769185185432434
step: 70, loss: 0.008447766304016113
step: 80, loss: 0.046323735266923904
step: 90, loss: 0.03924812749028206
step: 100, loss: 0.0817297026515007
step: 110, loss: 0.15184810757637024
step: 120, loss: 0.00044254414387978613
step: 130, loss: 0.04208079352974892
step: 140, loss: 0.00026231913943775
step: 150, loss: 0.09225314855575562
step: 160, loss: 0.014574543572962284
step: 170, loss: 0.008275586180388927
step: 180, loss: 0.0014849429717287421
step: 190, loss: 0.04577213525772095
step: 200, loss: 0.02925340086221695
step: 210, loss: 0.13272953033447266
step: 220, loss: 0.029215127229690552
step: 230, loss: 0.002867172472178936
step: 240, loss: 0.05064045637845993
step: 250, loss: 0.012906821444630623
step: 260, loss: 0.017155615612864494
step: 270, loss: 0.00158537772949785
step: 280, loss: 0.016913937404751778
step: 290, loss: 0.08497984707355499
step: 300, loss: 0.01535740401595831
step: 310, loss: 0.10427896678447723
step: 320, loss: 0.014552513137459755
step: 330, loss: 0.13873933255672455
step: 340, loss: 0.03522825613617897
step: 350, loss: 0.059639912098646164
step: 360, loss: 0.21620513498783112
epoch 10: dev_f1=0.7338129496402879, f1=0.7213930348258706, best_f1=0.7387862796833773
step: 0, loss: 0.019304784014821053
step: 10, loss: 0.01628471165895462
step: 20, loss: 0.05524298921227455
step: 30, loss: 0.00894155539572239
step: 40, loss: 0.0231222752481699
step: 50, loss: 0.09233852475881577
step: 60, loss: 0.004141641780734062
step: 70, loss: 0.006106079090386629
step: 80, loss: 0.005530940368771553
step: 90, loss: 0.06829094886779785
step: 100, loss: 0.018282009288668633
step: 110, loss: 0.039338331669569016
step: 120, loss: 0.008248118683695793
step: 130, loss: 0.024981729686260223
step: 140, loss: 0.07985594123601913
step: 150, loss: 0.04547874256968498
step: 160, loss: 0.05175379663705826
step: 170, loss: 0.012456778436899185
step: 180, loss: 0.04411005228757858
step: 190, loss: 0.054259542375802994
step: 200, loss: 0.037010353058576584
step: 210, loss: 0.01888575777411461
step: 220, loss: 0.00013049595872871578
step: 230, loss: 0.0002682636841200292
step: 240, loss: 0.0057078939862549305
step: 250, loss: 0.060624025762081146
step: 260, loss: 0.005832954775542021
step: 270, loss: 0.011065913364291191
step: 280, loss: 0.04410957545042038
step: 290, loss: 0.008912941440939903
step: 300, loss: 0.06718248128890991
step: 310, loss: 0.0018350332975387573
step: 320, loss: 0.016704609617590904
step: 330, loss: 0.0020194915123283863
step: 340, loss: 0.027628060430288315
step: 350, loss: 0.036632806062698364
step: 360, loss: 0.01767154410481453
epoch 11: dev_f1=0.7263922518159805, f1=0.7360406091370559, best_f1=0.7387862796833773
step: 0, loss: 0.033229682594537735
step: 10, loss: 0.018048075959086418
step: 20, loss: 0.003383815987035632
step: 30, loss: 0.0010369759984314442
step: 40, loss: 0.025635020807385445
step: 50, loss: 0.006802041083574295
step: 60, loss: 2.6374538720119745e-05
step: 70, loss: 0.0056252493523061275
step: 80, loss: 0.0009442223818041384
step: 90, loss: 0.08658270537853241
step: 100, loss: 0.03745117783546448
step: 110, loss: 0.03044499084353447
step: 120, loss: 0.003270888002589345
step: 130, loss: 0.003408918622881174
step: 140, loss: 0.10565114766359329
step: 150, loss: 0.0009410917409695685
step: 160, loss: 0.09413968026638031
step: 170, loss: 0.030280426144599915
step: 180, loss: 0.00582565413787961
step: 190, loss: 0.0012653282610699534
step: 200, loss: 0.007605337537825108
step: 210, loss: 0.028908293694257736
step: 220, loss: 0.033510103821754456
step: 230, loss: 0.0025215083733201027
step: 240, loss: 0.002925975015386939
step: 250, loss: 0.07325232774019241
step: 260, loss: 0.03372115269303322
step: 270, loss: 0.043199680745601654
step: 280, loss: 0.08845646679401398
step: 290, loss: 0.005477670580148697
step: 300, loss: 0.021077241748571396
step: 310, loss: 0.024301238358020782
step: 320, loss: 0.062161825597286224
step: 330, loss: 0.08583579212427139
step: 340, loss: 0.020841330289840698
step: 350, loss: 0.021880649030208588
step: 360, loss: 0.04527093470096588
epoch 12: dev_f1=0.7379134860050889, f1=0.7465940054495912, best_f1=0.7387862796833773
step: 0, loss: 0.07868736982345581
step: 10, loss: 0.025090841576457024
step: 20, loss: 0.030090825632214546
step: 30, loss: 0.006219550967216492
step: 40, loss: 0.026777472347021103
step: 50, loss: 0.00012539353338070214
step: 60, loss: 0.03436073288321495
step: 70, loss: 6.252519960980862e-05
step: 80, loss: 2.4731754820095375e-05
step: 90, loss: 0.027891390025615692
step: 100, loss: 0.020532887428998947
step: 110, loss: 0.054237835109233856
step: 120, loss: 0.017808154225349426
step: 130, loss: 0.00012014994717901573
step: 140, loss: 0.022620700299739838
step: 150, loss: 0.000559363339561969
step: 160, loss: 0.026455223560333252
step: 170, loss: 0.0443519689142704
step: 180, loss: 0.005753892008215189
step: 190, loss: 0.01614990457892418
step: 200, loss: 0.001734910300001502
step: 210, loss: 0.017271628603339195
step: 220, loss: 0.04387018084526062
step: 230, loss: 0.004333456512540579
step: 240, loss: 2.594236866571009e-05
step: 250, loss: 0.009074250236153603
step: 260, loss: 0.008648404851555824
step: 270, loss: 0.11803577840328217
step: 280, loss: 0.0029093949124217033
step: 290, loss: 0.04506300017237663
step: 300, loss: 0.029381733387708664
step: 310, loss: 0.08442220091819763
step: 320, loss: 0.1257203370332718
step: 330, loss: 0.021992003545165062
step: 340, loss: 0.024585044011473656
step: 350, loss: 0.007041153963655233
step: 360, loss: 0.030330408364534378
epoch 13: dev_f1=0.7164179104477613, f1=0.7248677248677249, best_f1=0.7387862796833773
step: 0, loss: 0.01018637977540493
step: 10, loss: 0.09286659210920334
step: 20, loss: 0.0027500749565660954
step: 30, loss: 0.030188729986548424
step: 40, loss: 0.03888200595974922
step: 50, loss: 2.5793484383029863e-05
step: 60, loss: 0.023974506184458733
step: 70, loss: 0.0019218226661905646
step: 80, loss: 2.97419883281691e-05
step: 90, loss: 0.09338630735874176
step: 100, loss: 0.029029706493020058
step: 110, loss: 0.07475842535495758
step: 120, loss: 0.037157583981752396
step: 130, loss: 0.02164357155561447
step: 140, loss: 0.015866046771407127
step: 150, loss: 0.028621502220630646
step: 160, loss: 0.01590133272111416
step: 170, loss: 0.024646222591400146
step: 180, loss: 0.004381708800792694
step: 190, loss: 0.07346513867378235
step: 200, loss: 0.0426969975233078
step: 210, loss: 0.06429985165596008
step: 220, loss: 0.004090190399438143
step: 230, loss: 0.010263540782034397
step: 240, loss: 0.0015145171200856566
step: 250, loss: 0.08122152835130692
step: 260, loss: 0.06283833086490631
step: 270, loss: 0.007456016261130571
step: 280, loss: 0.003045885358005762
step: 290, loss: 0.07175047695636749
step: 300, loss: 0.0039306385442614555
step: 310, loss: 0.027265232056379318
step: 320, loss: 0.004295231308788061
step: 330, loss: 0.0003632828884292394
step: 340, loss: 0.03640523552894592
step: 350, loss: 0.0021647128742188215
step: 360, loss: 0.01946963742375374
epoch 14: dev_f1=0.7336683417085428, f1=0.7329842931937172, best_f1=0.7387862796833773
step: 0, loss: 0.004258577711880207
step: 10, loss: 0.010227303020656109
step: 20, loss: 6.579838372999802e-05
step: 30, loss: 0.028725290670990944
step: 40, loss: 0.0016160006634891033
step: 50, loss: 0.0029818974435329437
step: 60, loss: 0.0002297436149092391
step: 70, loss: 0.0018926237244158983
step: 80, loss: 0.09628414362668991
step: 90, loss: 0.001460378640331328
step: 100, loss: 0.11488138884305954
step: 110, loss: 0.05390150845050812
step: 120, loss: 0.0028672562912106514
step: 130, loss: 0.09383648633956909
step: 140, loss: 0.03682228922843933
step: 150, loss: 0.02065902203321457
step: 160, loss: 0.01726650819182396
step: 170, loss: 0.02606733702123165
step: 180, loss: 0.0001136486534960568
step: 190, loss: 0.017663948237895966
step: 200, loss: 0.0019283350557088852
step: 210, loss: 0.0005135987303219736
step: 220, loss: 0.010141580365598202
step: 230, loss: 0.012726206332445145
step: 240, loss: 0.004265284165740013
step: 250, loss: 0.1715555638074875
step: 260, loss: 0.04378117620944977
step: 270, loss: 0.06203971058130264
step: 280, loss: 0.017837166786193848
step: 290, loss: 0.04337559640407562
step: 300, loss: 0.0783434584736824
step: 310, loss: 5.128732664161362e-05
step: 320, loss: 0.0160761009901762
step: 330, loss: 0.008190078660845757
step: 340, loss: 0.05106460675597191
step: 350, loss: 0.044310443103313446
step: 360, loss: 0.0215089600533247
epoch 15: dev_f1=0.7336683417085428, f1=0.7292225201072386, best_f1=0.7387862796833773
step: 0, loss: 0.006347857415676117
step: 10, loss: 0.019273454323410988
step: 20, loss: 0.0009539358434267342
step: 30, loss: 0.002120161661878228
step: 40, loss: 0.0354425385594368
step: 50, loss: 1.86670440598391e-05
step: 60, loss: 0.010863058269023895
step: 70, loss: 0.011336174793541431
step: 80, loss: 0.02000342309474945
step: 90, loss: 0.013918377459049225
step: 100, loss: 0.0009898594580590725
step: 110, loss: 0.0006541945040225983
step: 120, loss: 0.00021720219228882343
step: 130, loss: 5.0739861762849614e-05
step: 140, loss: 0.03917744755744934
step: 150, loss: 0.007020585238933563
step: 160, loss: 0.017306214198470116
step: 170, loss: 0.010151276364922523
step: 180, loss: 0.01787523366510868
step: 190, loss: 0.006566379684954882
step: 200, loss: 0.0003549414686858654
step: 210, loss: 0.022655656561255455
step: 220, loss: 0.00038882819353602827
step: 230, loss: 0.023185113444924355
step: 240, loss: 0.0014087314484640956
step: 250, loss: 0.0017370409332215786
step: 260, loss: 0.0013258251128718257
step: 270, loss: 0.02490948885679245
step: 280, loss: 0.0483117550611496
step: 290, loss: 0.018091507256031036
step: 300, loss: 0.03222713991999626
step: 310, loss: 0.0031239681411534548
step: 320, loss: 0.02689407765865326
step: 330, loss: 0.029106274247169495
step: 340, loss: 0.024158861488103867
step: 350, loss: 0.017833150923252106
step: 360, loss: 0.000936329597607255
epoch 16: dev_f1=0.7272727272727273, f1=0.7218045112781954, best_f1=0.7387862796833773
step: 0, loss: 0.012621869333088398
step: 10, loss: 0.02611253596842289
step: 20, loss: 0.001292690052650869
step: 30, loss: 0.007743471767753363
step: 40, loss: 0.0005427648429758847
step: 50, loss: 0.0382009856402874
step: 60, loss: 2.1103502149344422e-05
step: 70, loss: 0.05615249648690224
step: 80, loss: 0.09444557130336761
step: 90, loss: 0.03335228189826012
step: 100, loss: 2.320817657164298e-05
step: 110, loss: 0.01316558476537466
step: 120, loss: 0.023652495816349983
step: 130, loss: 0.028597507625818253
step: 140, loss: 2.199727896368131e-05
step: 150, loss: 4.587309013004415e-05
step: 160, loss: 0.006850415375083685
step: 170, loss: 0.13305993378162384
step: 180, loss: 0.032207731157541275
step: 190, loss: 0.020486092194914818
step: 200, loss: 0.020975371822714806
step: 210, loss: 0.0003073459374718368
step: 220, loss: 0.06459754705429077
step: 230, loss: 0.019717806950211525
step: 240, loss: 0.0009661950170993805
step: 250, loss: 0.03171675279736519
step: 260, loss: 0.015112697146832943
step: 270, loss: 5.56850791326724e-05
step: 280, loss: 0.017818178981542587
step: 290, loss: 0.040209006518125534
step: 300, loss: 0.0033322428353130817
step: 310, loss: 0.00020682481408584863
step: 320, loss: 0.00014450914750341326
step: 330, loss: 0.0017843869281932712
step: 340, loss: 0.09962095320224762
step: 350, loss: 0.0002088892215397209
step: 360, loss: 0.0384640172123909
epoch 17: dev_f1=0.717557251908397, f1=0.7258064516129032, best_f1=0.7387862796833773
step: 0, loss: 0.0415988489985466
step: 10, loss: 0.0035033472813665867
step: 20, loss: 0.04247380420565605
step: 30, loss: 0.0036917298566550016
step: 40, loss: 9.215361933456734e-05
step: 50, loss: 0.0007864454528316855
step: 60, loss: 5.941151539445855e-05
step: 70, loss: 0.0005044740973971784
step: 80, loss: 0.0006445577600970864
step: 90, loss: 4.456223177840002e-05
step: 100, loss: 7.813261618139222e-05
step: 110, loss: 7.153168553486466e-05
step: 120, loss: 0.0002902987180277705
step: 130, loss: 0.006774052046239376
step: 140, loss: 0.016073187813162804
step: 150, loss: 0.002491891384124756
step: 160, loss: 0.000670012435875833
step: 170, loss: 0.06183430179953575
step: 180, loss: 0.02709006331861019
step: 190, loss: 0.00020650585065595806
step: 200, loss: 0.03935834392905235
step: 210, loss: 4.7770772653166205e-05
step: 220, loss: 0.02675643190741539
step: 230, loss: 6.993442366365343e-05
step: 240, loss: 0.008286119438707829
step: 250, loss: 0.01994364708662033
step: 260, loss: 0.04603459686040878
step: 270, loss: 0.0003512258408591151
step: 280, loss: 0.001048469915986061
step: 290, loss: 0.026143169030547142
step: 300, loss: 7.943321543280035e-05
step: 310, loss: 0.05735505744814873
step: 320, loss: 0.0223253034055233
step: 330, loss: 0.0016044186195358634
step: 340, loss: 0.07911547273397446
step: 350, loss: 0.003558393567800522
step: 360, loss: 7.686549361096695e-05
epoch 18: dev_f1=0.716577540106952, f1=0.7146974063400575, best_f1=0.7387862796833773
step: 0, loss: 0.03655323013663292
step: 10, loss: 0.0006596562452614307
step: 20, loss: 0.007103268057107925
step: 30, loss: 0.03520272672176361
step: 40, loss: 0.06654113531112671
step: 50, loss: 0.03143049776554108
step: 60, loss: 0.0539516806602478
step: 70, loss: 0.01245124638080597
step: 80, loss: 0.00014334972365759313
step: 90, loss: 0.04549379646778107
step: 100, loss: 0.0021075874101370573
step: 110, loss: 0.006374896503984928
step: 120, loss: 0.03223156929016113
step: 130, loss: 0.0001756198180373758
step: 140, loss: 0.000365543644875288
step: 150, loss: 0.00028211562312208116
step: 160, loss: 0.015918636694550514
step: 170, loss: 0.004433539230376482
step: 180, loss: 0.012281033210456371
step: 190, loss: 0.0009880465222522616
step: 200, loss: 0.011882795952260494
step: 210, loss: 0.027932414785027504
step: 220, loss: 0.007521484047174454
step: 230, loss: 0.025613345205783844
step: 240, loss: 0.06015482544898987
step: 250, loss: 0.00031479058088734746
step: 260, loss: 0.01108373049646616
step: 270, loss: 0.003798529040068388
step: 280, loss: 0.022218752652406693
step: 290, loss: 0.017484450712800026
step: 300, loss: 0.01983923278748989
step: 310, loss: 0.046418894082307816
step: 320, loss: 0.0006047737551853061
step: 330, loss: 2.1237572582322173e-05
step: 340, loss: 0.04046176001429558
step: 350, loss: 0.000254711601883173
step: 360, loss: 0.012977090664207935
epoch 19: dev_f1=0.7161125319693094, f1=0.7204301075268816, best_f1=0.7387862796833773
step: 0, loss: 0.00018316885689273477
step: 10, loss: 0.01695714145898819
step: 20, loss: 8.900370448827744e-05
step: 30, loss: 0.0006502701435238123
step: 40, loss: 0.023593388497829437
step: 50, loss: 0.0001797758013708517
step: 60, loss: 5.121716458234005e-05
step: 70, loss: 0.00930375512689352
step: 80, loss: 0.03251809626817703
step: 90, loss: 0.030501078814268112
step: 100, loss: 0.044093433767557144
step: 110, loss: 0.01346604898571968
step: 120, loss: 0.023956695571541786
step: 130, loss: 0.03382527828216553
step: 140, loss: 0.0018831627676263452
step: 150, loss: 0.00029177588294260204
step: 160, loss: 0.04373854026198387
step: 170, loss: 2.543170739954803e-05
step: 180, loss: 0.010980135761201382
step: 190, loss: 0.04171736538410187
step: 200, loss: 0.006993315648287535
step: 210, loss: 0.012811997905373573
step: 220, loss: 0.00020419292559381574
step: 230, loss: 0.03358141705393791
step: 240, loss: 0.0269545316696167
step: 250, loss: 0.00017385350656695664
step: 260, loss: 0.0536327138543129
step: 270, loss: 0.03220445290207863
step: 280, loss: 0.005340451840311289
step: 290, loss: 0.0001020689815049991
step: 300, loss: 0.006044044625014067
step: 310, loss: 0.0003213479358237237
step: 320, loss: 0.008783182129263878
step: 330, loss: 0.002152492757886648
step: 340, loss: 0.0010065260576084256
step: 350, loss: 0.04535027593374252
step: 360, loss: 0.014179769903421402
epoch 20: dev_f1=0.7197943444730078, f1=0.7208672086720868, best_f1=0.7387862796833773
