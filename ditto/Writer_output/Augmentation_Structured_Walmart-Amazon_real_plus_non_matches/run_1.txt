cuda
Device: cuda
step: 0, loss: 0.6426658034324646
step: 10, loss: 0.06097060441970825
step: 20, loss: 0.14591430127620697
step: 30, loss: 0.2449771910905838
step: 40, loss: 0.14077171683311462
step: 50, loss: 0.14034046232700348
step: 60, loss: 0.2363021969795227
step: 70, loss: 0.23317033052444458
step: 80, loss: 0.1375054121017456
step: 90, loss: 0.13987676799297333
step: 100, loss: 0.0678931400179863
step: 110, loss: 0.14769978821277618
step: 120, loss: 0.1415172517299652
step: 130, loss: 0.2971499562263489
step: 140, loss: 0.0554843507707119
step: 150, loss: 0.3447115123271942
step: 160, loss: 0.1450558453798294
step: 170, loss: 0.11807479709386826
step: 180, loss: 0.12693949043750763
step: 190, loss: 0.2603425085544586
step: 200, loss: 0.16359876096248627
step: 210, loss: 0.12263071537017822
step: 220, loss: 0.21966536343097687
step: 230, loss: 0.16086962819099426
step: 240, loss: 0.23237033188343048
step: 250, loss: 0.33094078302383423
step: 260, loss: 0.22893425822257996
step: 270, loss: 0.20225612819194794
step: 280, loss: 0.08803565800189972
step: 290, loss: 0.13112685084342957
step: 300, loss: 0.289819598197937
step: 310, loss: 0.09413067251443863
step: 320, loss: 0.21905356645584106
step: 330, loss: 0.14034833014011383
step: 340, loss: 0.17891070246696472
step: 350, loss: 0.10390523076057434
step: 360, loss: 0.0022968563716858625
epoch 1: dev_f1=0.17216770740410348, f1=0.17216770740410348, best_f1=0.17216770740410348
step: 0, loss: 0.10389803349971771
step: 10, loss: 0.2372453659772873
step: 20, loss: 0.0892656072974205
step: 30, loss: 0.037448130548000336
step: 40, loss: 0.05223211646080017
step: 50, loss: 0.20506396889686584
step: 60, loss: 0.1306130588054657
step: 70, loss: 0.2924320101737976
step: 80, loss: 0.042358849197626114
step: 90, loss: 0.09712990373373032
step: 100, loss: 0.042867302894592285
step: 110, loss: 0.15146876871585846
step: 120, loss: 0.0634535700082779
step: 130, loss: 0.1347029209136963
step: 140, loss: 0.26327645778656006
step: 150, loss: 0.09400589019060135
step: 160, loss: 0.04872698336839676
step: 170, loss: 0.26535797119140625
step: 180, loss: 0.11188440024852753
step: 190, loss: 0.01973619870841503
step: 200, loss: 0.09581571072340012
step: 210, loss: 0.021671921014785767
step: 220, loss: 0.0036610763054341078
step: 230, loss: 0.313138484954834
step: 240, loss: 0.05576545372605324
step: 250, loss: 0.037611257284879684
step: 260, loss: 0.024496695026755333
step: 270, loss: 0.041041575372219086
step: 280, loss: 0.06692530959844589
step: 290, loss: 0.014299100264906883
step: 300, loss: 0.29439619183540344
step: 310, loss: 0.10639502108097076
step: 320, loss: 0.22324274480342865
step: 330, loss: 0.155844047665596
step: 340, loss: 0.11009123176336288
step: 350, loss: 0.10247335582971573
step: 360, loss: 0.1321573406457901
epoch 2: dev_f1=0.6870229007633588, f1=0.7076923076923077, best_f1=0.7076923076923077
step: 0, loss: 0.15247416496276855
step: 10, loss: 0.0685100257396698
step: 20, loss: 0.08996877074241638
step: 30, loss: 0.1452162265777588
step: 40, loss: 0.060251813381910324
step: 50, loss: 0.03179360553622246
step: 60, loss: 0.0581337995827198
step: 70, loss: 0.1151171550154686
step: 80, loss: 0.0869707316160202
step: 90, loss: 0.055731624364852905
step: 100, loss: 0.07908346503973007
step: 110, loss: 0.02128780074417591
step: 120, loss: 0.07980859279632568
step: 130, loss: 0.18065296113491058
step: 140, loss: 0.15558212995529175
step: 150, loss: 0.04561660438776016
step: 160, loss: 0.016232537105679512
step: 170, loss: 0.1934591829776764
step: 180, loss: 0.07481682300567627
step: 190, loss: 0.19711348414421082
step: 200, loss: 0.11821682751178741
step: 210, loss: 0.07886063307523727
step: 220, loss: 0.13535283505916595
step: 230, loss: 0.15366306900978088
step: 240, loss: 0.14685438573360443
step: 250, loss: 0.15636783838272095
step: 260, loss: 0.050309475511312485
step: 270, loss: 0.08220003545284271
step: 280, loss: 0.1534477025270462
step: 290, loss: 0.07127232849597931
step: 300, loss: 0.17056025564670563
step: 310, loss: 0.027247736230492592
step: 320, loss: 0.03196698799729347
step: 330, loss: 0.08760546892881393
step: 340, loss: 0.10064499080181122
step: 350, loss: 0.23702548444271088
step: 360, loss: 0.12839601933956146
epoch 3: dev_f1=0.7149532710280374, f1=0.7389162561576355, best_f1=0.7389162561576355
step: 0, loss: 0.00910840556025505
step: 10, loss: 0.11011245101690292
step: 20, loss: 0.10462141782045364
step: 30, loss: 0.08304211497306824
step: 40, loss: 0.024270283058285713
step: 50, loss: 0.038811810314655304
step: 60, loss: 0.23661546409130096
step: 70, loss: 0.0925009697675705
step: 80, loss: 0.08463426679372787
step: 90, loss: 0.12682148814201355
step: 100, loss: 0.17293697595596313
step: 110, loss: 0.10009074211120605
step: 120, loss: 0.033423833549022675
step: 130, loss: 0.1408628672361374
step: 140, loss: 0.05236876755952835
step: 150, loss: 0.051034919917583466
step: 160, loss: 0.08752501010894775
step: 170, loss: 0.05557495355606079
step: 180, loss: 0.014923118986189365
step: 190, loss: 0.03737044706940651
step: 200, loss: 0.14174216985702515
step: 210, loss: 0.11966519057750702
step: 220, loss: 0.12497834861278534
step: 230, loss: 0.04089615121483803
step: 240, loss: 0.024148399010300636
step: 250, loss: 0.10822649300098419
step: 260, loss: 0.02928764373064041
step: 270, loss: 0.041164617985486984
step: 280, loss: 0.04432185739278793
step: 290, loss: 0.08784960955381393
step: 300, loss: 0.09698303788900375
step: 310, loss: 0.10868552327156067
step: 320, loss: 0.04369518905878067
step: 330, loss: 0.16569659113883972
step: 340, loss: 0.18858972191810608
step: 350, loss: 0.07877381145954132
step: 360, loss: 0.11273884773254395
epoch 4: dev_f1=0.7616707616707618, f1=0.7736842105263158, best_f1=0.7736842105263158
step: 0, loss: 0.010863727889955044
step: 10, loss: 0.0010069694835692644
step: 20, loss: 0.027073675766587257
step: 30, loss: 0.0029332914855331182
step: 40, loss: 0.07058821618556976
step: 50, loss: 0.036600176244974136
step: 60, loss: 0.0014783472288399935
step: 70, loss: 0.08618911355733871
step: 80, loss: 0.01079509500414133
step: 90, loss: 0.09514564275741577
step: 100, loss: 0.06926066428422928
step: 110, loss: 0.01342857163399458
step: 120, loss: 0.10231516510248184
step: 130, loss: 0.0688188448548317
step: 140, loss: 0.018652653321623802
step: 150, loss: 0.03719136118888855
step: 160, loss: 0.06567120552062988
step: 170, loss: 0.08142316341400146
step: 180, loss: 0.0814102366566658
step: 190, loss: 0.16605323553085327
step: 200, loss: 0.13197964429855347
step: 210, loss: 0.16783681511878967
step: 220, loss: 0.008730319328606129
step: 230, loss: 0.10063691437244415
step: 240, loss: 0.1342601329088211
step: 250, loss: 0.10545540601015091
step: 260, loss: 0.1154065728187561
step: 270, loss: 0.09390345215797424
step: 280, loss: 0.03844287618994713
step: 290, loss: 0.03890836983919144
step: 300, loss: 0.08574405312538147
step: 310, loss: 0.015224820002913475
step: 320, loss: 0.03044714964926243
step: 330, loss: 0.2816091775894165
step: 340, loss: 0.12264302372932434
step: 350, loss: 0.11393038183450699
step: 360, loss: 0.07039009779691696
epoch 5: dev_f1=0.743455497382199, f1=0.7795698924731183, best_f1=0.7736842105263158
step: 0, loss: 0.047990188002586365
step: 10, loss: 0.0702212005853653
step: 20, loss: 0.13018685579299927
step: 30, loss: 0.07063787430524826
step: 40, loss: 0.06626378744840622
step: 50, loss: 0.03359358385205269
step: 60, loss: 0.0005333350854925811
step: 70, loss: 0.011552299372851849
step: 80, loss: 0.15529723465442657
step: 90, loss: 0.3027624487876892
step: 100, loss: 0.10016492754220963
step: 110, loss: 0.07042311877012253
step: 120, loss: 0.05768253654241562
step: 130, loss: 0.13483616709709167
step: 140, loss: 0.03762609511613846
step: 150, loss: 0.020668968558311462
step: 160, loss: 0.15234050154685974
step: 170, loss: 0.07198665291070938
step: 180, loss: 0.08899755775928497
step: 190, loss: 0.06562498211860657
step: 200, loss: 0.026574771851301193
step: 210, loss: 0.0006895596161484718
step: 220, loss: 0.022943060845136642
step: 230, loss: 0.06601405143737793
step: 240, loss: 0.004006336908787489
step: 250, loss: 0.0012240069918334484
step: 260, loss: 0.04864455386996269
step: 270, loss: 0.03761386498808861
step: 280, loss: 0.09125502407550812
step: 290, loss: 0.06933066248893738
step: 300, loss: 0.13061188161373138
step: 310, loss: 0.05188140645623207
step: 320, loss: 0.0005198754370212555
step: 330, loss: 0.00029198109405115247
step: 340, loss: 0.2530745565891266
step: 350, loss: 0.0318196602165699
step: 360, loss: 0.028476091101765633
epoch 6: dev_f1=0.7378640776699029, f1=0.7461139896373058, best_f1=0.7736842105263158
step: 0, loss: 0.04512227326631546
step: 10, loss: 0.02613351307809353
step: 20, loss: 0.04475903883576393
step: 30, loss: 0.016136212274432182
step: 40, loss: 0.009980788454413414
step: 50, loss: 0.007964268326759338
step: 60, loss: 0.11772192269563675
step: 70, loss: 0.04338568076491356
step: 80, loss: 0.013344807550311089
step: 90, loss: 0.045826371759176254
step: 100, loss: 0.036490630358457565
step: 110, loss: 0.00037638237699866295
step: 120, loss: 0.031155355274677277
step: 130, loss: 0.07810146361589432
step: 140, loss: 0.009345407597720623
step: 150, loss: 0.00958202127367258
step: 160, loss: 0.0990358218550682
step: 170, loss: 0.03627917915582657
step: 180, loss: 0.03708408400416374
step: 190, loss: 0.017899109050631523
step: 200, loss: 0.10778345912694931
step: 210, loss: 0.021464690566062927
step: 220, loss: 0.06837855279445648
step: 230, loss: 0.04216230288147926
step: 240, loss: 0.07015804201364517
step: 250, loss: 0.0009391880594193935
step: 260, loss: 0.013147692196071148
step: 270, loss: 0.011601092293858528
step: 280, loss: 0.12703944742679596
step: 290, loss: 0.05779702216386795
step: 300, loss: 0.040417689830064774
step: 310, loss: 0.00032066067797131836
step: 320, loss: 0.0468820258975029
step: 330, loss: 0.01052461750805378
step: 340, loss: 0.0035664148163050413
step: 350, loss: 0.08349048346281052
step: 360, loss: 0.029116325080394745
epoch 7: dev_f1=0.7320954907161804, f1=0.7308781869688386, best_f1=0.7736842105263158
step: 0, loss: 0.03248709440231323
step: 10, loss: 0.0002822867827489972
step: 20, loss: 0.0006597501342184842
step: 30, loss: 0.019561180844902992
step: 40, loss: 0.02987394668161869
step: 50, loss: 0.011762319132685661
step: 60, loss: 0.007018638774752617
step: 70, loss: 0.036086294800043106
step: 80, loss: 0.08236373960971832
step: 90, loss: 0.029093941673636436
step: 100, loss: 0.017008841037750244
step: 110, loss: 0.007537647616118193
step: 120, loss: 0.0016708829207345843
step: 130, loss: 0.006161386147141457
step: 140, loss: 0.09917578846216202
step: 150, loss: 0.13122981786727905
step: 160, loss: 0.08633009344339371
step: 170, loss: 0.07646334916353226
step: 180, loss: 0.0006051828386262059
step: 190, loss: 0.01222072634845972
step: 200, loss: 0.02346024103462696
step: 210, loss: 0.09726448357105255
step: 220, loss: 0.10667452216148376
step: 230, loss: 0.06341902166604996
step: 240, loss: 0.0008368197013624012
step: 250, loss: 0.05618938431143761
step: 260, loss: 0.018365785479545593
step: 270, loss: 0.022524533793330193
step: 280, loss: 0.06500749289989471
step: 290, loss: 0.084930919110775
step: 300, loss: 0.04429188370704651
step: 310, loss: 0.057309895753860474
step: 320, loss: 0.07546915858983994
step: 330, loss: 0.061513420194387436
step: 340, loss: 0.06456181406974792
step: 350, loss: 0.06787727773189545
step: 360, loss: 0.0350593738257885
epoch 8: dev_f1=0.7350835322195705, f1=0.751269035532995, best_f1=0.7736842105263158
step: 0, loss: 0.024994544684886932
step: 10, loss: 0.05944904685020447
step: 20, loss: 0.01617540419101715
step: 30, loss: 0.045917779207229614
step: 40, loss: 0.0036198177840560675
step: 50, loss: 0.023306386545300484
step: 60, loss: 0.04514468461275101
step: 70, loss: 0.029145950451493263
step: 80, loss: 0.011563966050744057
step: 90, loss: 0.06993847340345383
step: 100, loss: 0.0008492931956425309
step: 110, loss: 0.03698783367872238
step: 120, loss: 0.02055319771170616
step: 130, loss: 0.05136654153466225
step: 140, loss: 0.1387307494878769
step: 150, loss: 0.09262578189373016
step: 160, loss: 0.004358927719295025
step: 170, loss: 0.0005948435282334685
step: 180, loss: 0.02452024258673191
step: 190, loss: 0.015660962089896202
step: 200, loss: 0.017843924462795258
step: 210, loss: 0.005065304227173328
step: 220, loss: 0.045935120433568954
step: 230, loss: 0.06794679909944534
step: 240, loss: 0.02280454710125923
step: 250, loss: 0.05209443345665932
step: 260, loss: 0.04245499148964882
step: 270, loss: 0.012965453788638115
step: 280, loss: 0.03651830554008484
step: 290, loss: 0.05978092551231384
step: 300, loss: 0.034641899168491364
step: 310, loss: 0.02035469561815262
step: 320, loss: 0.09055085480213165
step: 330, loss: 0.07179023325443268
step: 340, loss: 0.005763898137956858
step: 350, loss: 0.02401406690478325
step: 360, loss: 0.025855470448732376
epoch 9: dev_f1=0.76, f1=0.7857142857142857, best_f1=0.7736842105263158
step: 0, loss: 0.03600771352648735
step: 10, loss: 0.06067197397351265
step: 20, loss: 0.045075107365846634
step: 30, loss: 0.0007983159739524126
step: 40, loss: 0.018205076456069946
step: 50, loss: 0.00827510841190815
step: 60, loss: 0.07223313301801682
step: 70, loss: 0.001470961607992649
step: 80, loss: 0.040601108223199844
step: 90, loss: 0.0008560890564695001
step: 100, loss: 0.0001158532832050696
step: 110, loss: 0.005246502812951803
step: 120, loss: 0.06503749638795853
step: 130, loss: 0.1133957952260971
step: 140, loss: 0.07409492880105972
step: 150, loss: 0.09105696529150009
step: 160, loss: 0.09169187396764755
step: 170, loss: 0.026974668726325035
step: 180, loss: 0.01774192787706852
step: 190, loss: 0.04053003713488579
step: 200, loss: 0.05049719288945198
step: 210, loss: 0.07154456526041031
step: 220, loss: 0.06921917200088501
step: 230, loss: 0.0033245147205889225
step: 240, loss: 0.043160583823919296
step: 250, loss: 0.07301852852106094
step: 260, loss: 0.004618017468601465
step: 270, loss: 0.031186170876026154
step: 280, loss: 0.005215611308813095
step: 290, loss: 0.00015646596148144454
step: 300, loss: 0.13020378351211548
step: 310, loss: 0.01172864530235529
step: 320, loss: 0.06109728664159775
step: 330, loss: 0.017901115119457245
step: 340, loss: 0.06817648559808731
step: 350, loss: 0.08260618150234222
step: 360, loss: 0.10290621966123581
epoch 10: dev_f1=0.7455919395465995, f1=0.7613941018766757, best_f1=0.7736842105263158
step: 0, loss: 0.07080253213644028
step: 10, loss: 0.008576653897762299
step: 20, loss: 0.06322751939296722
step: 30, loss: 0.030858587473630905
step: 40, loss: 0.024907942861318588
step: 50, loss: 0.09642627090215683
step: 60, loss: 0.0064211091957986355
step: 70, loss: 0.0710601881146431
step: 80, loss: 0.0003848582273349166
step: 90, loss: 0.02651394158601761
step: 100, loss: 0.03623204305768013
step: 110, loss: 0.009342590346932411
step: 120, loss: 0.021603520959615707
step: 130, loss: 0.014572649262845516
step: 140, loss: 0.017528407275676727
step: 150, loss: 0.07135345041751862
step: 160, loss: 0.01793772354722023
step: 170, loss: 0.0003311983891762793
step: 180, loss: 0.013080758973956108
step: 190, loss: 0.07463584095239639
step: 200, loss: 0.02533307671546936
step: 210, loss: 0.08376192301511765
step: 220, loss: 0.006300413981080055
step: 230, loss: 0.2043275386095047
step: 240, loss: 0.07153761386871338
step: 250, loss: 8.89827060746029e-05
step: 260, loss: 0.0016657436499372125
step: 270, loss: 0.09291224926710129
step: 280, loss: 0.04306723177433014
step: 290, loss: 0.1048227921128273
step: 300, loss: 0.01710544526576996
step: 310, loss: 0.08557449281215668
step: 320, loss: 0.11407996714115143
step: 330, loss: 0.0003055562265217304
step: 340, loss: 0.029380660504102707
step: 350, loss: 0.02733151987195015
step: 360, loss: 0.07664723694324493
epoch 11: dev_f1=0.7511520737327189, f1=0.7722772277227723, best_f1=0.7736842105263158
step: 0, loss: 0.024076150730252266
step: 10, loss: 0.013982487842440605
step: 20, loss: 0.1127977967262268
step: 30, loss: 0.01715383678674698
step: 40, loss: 6.881141598569229e-05
step: 50, loss: 0.03882265090942383
step: 60, loss: 0.029594149440526962
step: 70, loss: 0.009495501406490803
step: 80, loss: 0.0028466139920055866
step: 90, loss: 0.053604867309331894
step: 100, loss: 0.005515271332114935
step: 110, loss: 0.010319286957383156
step: 120, loss: 0.03446938097476959
step: 130, loss: 0.027619097381830215
step: 140, loss: 0.0002979277051053941
step: 150, loss: 0.006516055203974247
step: 160, loss: 0.0028708658646792173
step: 170, loss: 0.04133309796452522
step: 180, loss: 0.004357823170721531
step: 190, loss: 0.009431167505681515
step: 200, loss: 0.015285247936844826
step: 210, loss: 0.09576467424631119
step: 220, loss: 0.05153464898467064
step: 230, loss: 0.0135257039219141
step: 240, loss: 0.05573488026857376
step: 250, loss: 0.004410687368363142
step: 260, loss: 0.003149467520415783
step: 270, loss: 0.05957547202706337
step: 280, loss: 0.0002860967942979187
step: 290, loss: 0.00014927615120541304
step: 300, loss: 0.019325459375977516
step: 310, loss: 0.02799447439610958
step: 320, loss: 0.052027516067028046
step: 330, loss: 0.08766836673021317
step: 340, loss: 0.0456656813621521
step: 350, loss: 0.025729339569807053
step: 360, loss: 0.0001311586966039613
epoch 12: dev_f1=0.7455919395465995, f1=0.7340425531914895, best_f1=0.7736842105263158
step: 0, loss: 0.10700367391109467
step: 10, loss: 0.03106122650206089
step: 20, loss: 0.015762798488140106
step: 30, loss: 0.01707601174712181
step: 40, loss: 0.019535066559910774
step: 50, loss: 0.02973051555454731
step: 60, loss: 0.022034090012311935
step: 70, loss: 0.02609947696328163
step: 80, loss: 0.008298232220113277
step: 90, loss: 0.04942378029227257
step: 100, loss: 0.0003885653568431735
step: 110, loss: 0.0068184551782906055
step: 120, loss: 0.03069310449063778
step: 130, loss: 0.006271207705140114
step: 140, loss: 0.17217817902565002
step: 150, loss: 0.031212175264954567
step: 160, loss: 0.01017632894217968
step: 170, loss: 0.00023168462212197483
step: 180, loss: 0.016137445345520973
step: 190, loss: 0.0008234857232309878
step: 200, loss: 0.006149108521640301
step: 210, loss: 0.04249010235071182
step: 220, loss: 0.0001583644188940525
step: 230, loss: 0.011585492640733719
step: 240, loss: 0.021123012527823448
step: 250, loss: 0.0024778854567557573
step: 260, loss: 0.13071230053901672
step: 270, loss: 0.0009654866298660636
step: 280, loss: 0.12703604996204376
step: 290, loss: 0.07287484407424927
step: 300, loss: 0.11901163309812546
step: 310, loss: 0.004374885931611061
step: 320, loss: 0.06174920126795769
step: 330, loss: 0.014573927037417889
step: 340, loss: 0.00478054815903306
step: 350, loss: 0.024107933044433594
step: 360, loss: 0.009619214572012424
epoch 13: dev_f1=0.7607655502392344, f1=0.7493670886075949, best_f1=0.7736842105263158
step: 0, loss: 0.020416202023625374
step: 10, loss: 0.014892535284161568
step: 20, loss: 0.014455808326601982
step: 30, loss: 0.04577077552676201
step: 40, loss: 0.0003099417663179338
step: 50, loss: 0.020028505474328995
step: 60, loss: 0.018405960872769356
step: 70, loss: 0.0003352555795572698
step: 80, loss: 0.006179726682603359
step: 90, loss: 0.03010808303952217
step: 100, loss: 0.0014761375496163964
step: 110, loss: 0.01465945690870285
step: 120, loss: 0.014968988485634327
step: 130, loss: 0.00232102838344872
step: 140, loss: 0.016527535393834114
step: 150, loss: 0.1198853999376297
step: 160, loss: 0.020460790023207664
step: 170, loss: 0.020112045109272003
step: 180, loss: 0.14038002490997314
step: 190, loss: 0.0046257381327450275
step: 200, loss: 0.0013089317362755537
step: 210, loss: 0.012008650228381157
step: 220, loss: 0.003543522674590349
step: 230, loss: 0.08574797958135605
step: 240, loss: 0.004508489742875099
step: 250, loss: 0.004239663481712341
step: 260, loss: 7.64205542509444e-05
step: 270, loss: 0.0693822130560875
step: 280, loss: 0.04307274892926216
step: 290, loss: 0.0007130745216272771
step: 300, loss: 0.05375606194138527
step: 310, loss: 0.0488513819873333
step: 320, loss: 0.05831974372267723
step: 330, loss: 0.002611578442156315
step: 340, loss: 0.06901610642671585
step: 350, loss: 0.0018785656429827213
step: 360, loss: 0.021270208060741425
epoch 14: dev_f1=0.7560975609756098, f1=0.7506426735218509, best_f1=0.7736842105263158
step: 0, loss: 0.013003011234104633
step: 10, loss: 0.0015142234042286873
step: 20, loss: 0.037880152463912964
step: 30, loss: 0.03686147555708885
step: 40, loss: 0.0019003351917490363
step: 50, loss: 0.003639647737145424
step: 60, loss: 0.005524719599634409
step: 70, loss: 0.11592486500740051
step: 80, loss: 0.08336298167705536
step: 90, loss: 0.023942653089761734
step: 100, loss: 0.02959154173731804
step: 110, loss: 0.0016376024577766657
step: 120, loss: 0.0015430273488163948
step: 130, loss: 0.015300657600164413
step: 140, loss: 0.03421061486005783
step: 150, loss: 0.053945958614349365
step: 160, loss: 0.00016831461107358336
step: 170, loss: 0.045750368386507034
step: 180, loss: 0.007088148966431618
step: 190, loss: 0.04070776328444481
step: 200, loss: 0.0038046028930693865
step: 210, loss: 0.027099665254354477
step: 220, loss: 0.10573787242174149
step: 230, loss: 0.014420034363865852
step: 240, loss: 0.0015385295264422894
step: 250, loss: 0.005967344157397747
step: 260, loss: 0.013376346789300442
step: 270, loss: 0.013810980133712292
step: 280, loss: 0.028986655175685883
step: 290, loss: 0.043769583106040955
step: 300, loss: 0.051739614456892014
step: 310, loss: 0.03140099719166756
step: 320, loss: 0.029246516525745392
step: 330, loss: 0.006249783094972372
step: 340, loss: 0.004594000056385994
step: 350, loss: 0.0028461283072829247
step: 360, loss: 0.001677786698564887
epoch 15: dev_f1=0.76144578313253, f1=0.7462686567164178, best_f1=0.7736842105263158
step: 0, loss: 0.026992080733180046
step: 10, loss: 0.018632633611559868
step: 20, loss: 0.0879472941160202
step: 30, loss: 0.003257380798459053
step: 40, loss: 0.004784987773746252
step: 50, loss: 0.09925618767738342
step: 60, loss: 0.0005468049785122275
step: 70, loss: 0.045850206166505814
step: 80, loss: 0.004562136251479387
step: 90, loss: 0.0015430892817676067
step: 100, loss: 0.0017768836114555597
step: 110, loss: 0.017379986122250557
step: 120, loss: 0.00843789055943489
step: 130, loss: 0.03121432103216648
step: 140, loss: 0.0008795977337285876
step: 150, loss: 0.040293242782354355
step: 160, loss: 0.04121340438723564
step: 170, loss: 0.0016390492673963308
step: 180, loss: 0.00030506798066198826
step: 190, loss: 0.01554781012237072
step: 200, loss: 0.03878191113471985
step: 210, loss: 0.022343315184116364
step: 220, loss: 0.007525267079472542
step: 230, loss: 0.023032767698168755
step: 240, loss: 0.014888755045831203
step: 250, loss: 0.017356114462018013
step: 260, loss: 0.052618060261011124
step: 270, loss: 0.018306614831089973
step: 280, loss: 0.04026491194963455
step: 290, loss: 0.020457666367292404
step: 300, loss: 0.00023169499763753265
step: 310, loss: 0.00364710227586329
step: 320, loss: 0.021005282178521156
step: 330, loss: 0.007355634588748217
step: 340, loss: 0.0029862707015126944
step: 350, loss: 0.04002450034022331
step: 360, loss: 0.011601322330534458
epoch 16: dev_f1=0.7542579075425789, f1=0.7422680412371134, best_f1=0.7736842105263158
step: 0, loss: 0.0016976159531623125
step: 10, loss: 0.018738379701972008
step: 20, loss: 0.01447196677327156
step: 30, loss: 0.04807012900710106
step: 40, loss: 0.031300850212574005
step: 50, loss: 0.04502115398645401
step: 60, loss: 0.003387038130313158
step: 70, loss: 0.013313139788806438
step: 80, loss: 0.03654367849230766
step: 90, loss: 0.00019418206647969782
step: 100, loss: 0.032909926027059555
step: 110, loss: 0.0007907063700258732
step: 120, loss: 0.016008902341127396
step: 130, loss: 0.0022067795507609844
step: 140, loss: 0.004798970650881529
step: 150, loss: 0.004342564381659031
step: 160, loss: 4.301580702303909e-05
step: 170, loss: 0.03489185497164726
step: 180, loss: 0.00014912162441760302
step: 190, loss: 0.0012892611557617784
step: 200, loss: 0.014425303786993027
step: 210, loss: 4.6048546209931374e-05
step: 220, loss: 0.0021928357891738415
step: 230, loss: 0.0014074936043471098
step: 240, loss: 7.79928159317933e-05
step: 250, loss: 7.096995977917686e-05
step: 260, loss: 0.0003880786243826151
step: 270, loss: 3.6938985431334004e-05
step: 280, loss: 0.01441420242190361
step: 290, loss: 0.04558880627155304
step: 300, loss: 0.0010220517870038748
step: 310, loss: 0.05343404784798622
step: 320, loss: 0.015031113289296627
step: 330, loss: 0.009356444701552391
step: 340, loss: 0.00039898688555695117
step: 350, loss: 0.00031941698398441076
step: 360, loss: 0.04344269633293152
epoch 17: dev_f1=0.7578947368421052, f1=0.718918918918919, best_f1=0.7736842105263158
step: 0, loss: 0.00011359103518771008
step: 10, loss: 0.0009107927326112986
step: 20, loss: 0.0005893718916922808
step: 30, loss: 0.06130621209740639
step: 40, loss: 0.06170499697327614
step: 50, loss: 0.0002518242981750518
step: 60, loss: 0.0072579351253807545
step: 70, loss: 0.042696770280599594
step: 80, loss: 8.869181328918785e-05
step: 90, loss: 0.042383819818496704
step: 100, loss: 0.005602202843874693
step: 110, loss: 0.020384330302476883
step: 120, loss: 0.024924755096435547
step: 130, loss: 0.02975773997604847
step: 140, loss: 0.03397746384143829
step: 150, loss: 0.016143226996064186
step: 160, loss: 0.032767318189144135
step: 170, loss: 0.04665353149175644
step: 180, loss: 0.018013637512922287
step: 190, loss: 0.04111553728580475
step: 200, loss: 0.032959889620542526
step: 210, loss: 0.0650126114487648
step: 220, loss: 0.07267586141824722
step: 230, loss: 0.0806695967912674
step: 240, loss: 0.006226639728993177
step: 250, loss: 0.0006327296723611653
step: 260, loss: 0.030374843627214432
step: 270, loss: 0.00041572118061594665
step: 280, loss: 0.0107395239174366
step: 290, loss: 0.0007512692827731371
step: 300, loss: 0.013492758385837078
step: 310, loss: 0.0004360368475317955
step: 320, loss: 0.04649345949292183
step: 330, loss: 0.00341825932264328
step: 340, loss: 0.00041611414053477347
step: 350, loss: 0.02849188633263111
step: 360, loss: 5.0283229938941076e-05
epoch 18: dev_f1=0.7446808510638299, f1=0.7208672086720868, best_f1=0.7736842105263158
step: 0, loss: 0.10031608492136002
step: 10, loss: 0.0010027214884757996
step: 20, loss: 0.0115556251257658
step: 30, loss: 0.00014615051622968167
step: 40, loss: 0.01386147178709507
step: 50, loss: 0.014080473221838474
step: 60, loss: 0.015026151202619076
step: 70, loss: 0.017214294523000717
step: 80, loss: 0.03343624249100685
step: 90, loss: 0.044815465807914734
step: 100, loss: 0.00024320813827216625
step: 110, loss: 3.0944640457164496e-05
step: 120, loss: 0.018343467265367508
step: 130, loss: 0.06713587045669556
step: 140, loss: 0.01441161148250103
step: 150, loss: 0.0004418562166392803
step: 160, loss: 0.010346433147788048
step: 170, loss: 0.0012291062157601118
step: 180, loss: 0.0005086558521725237
step: 190, loss: 0.010104379616677761
step: 200, loss: 3.07176960632205e-05
step: 210, loss: 0.012279778718948364
step: 220, loss: 0.00014073347847443074
step: 230, loss: 0.0899709016084671
step: 240, loss: 0.0003239443467464298
step: 250, loss: 0.00024652143474668264
step: 260, loss: 0.010611011646687984
step: 270, loss: 0.003272529225796461
step: 280, loss: 0.02051975578069687
step: 290, loss: 0.0059813945554196835
step: 300, loss: 0.0002148306230083108
step: 310, loss: 0.017698287963867188
step: 320, loss: 0.006731972564011812
step: 330, loss: 0.02095569670200348
step: 340, loss: 0.06042210012674332
step: 350, loss: 0.03356236219406128
step: 360, loss: 0.004001358058303595
epoch 19: dev_f1=0.75, f1=0.7611548556430445, best_f1=0.7736842105263158
step: 0, loss: 0.04599490389227867
step: 10, loss: 0.005288479849696159
step: 20, loss: 0.01737101376056671
step: 30, loss: 9.953814878826961e-05
step: 40, loss: 0.02157139591872692
step: 50, loss: 0.00948366243392229
step: 60, loss: 0.021630896255373955
step: 70, loss: 0.00017584093438927084
step: 80, loss: 0.00898543931543827
step: 90, loss: 0.00010959430073853582
step: 100, loss: 0.0601322315633297
step: 110, loss: 0.01827889308333397
step: 120, loss: 0.016910459846258163
step: 130, loss: 0.0132146580144763
step: 140, loss: 0.04825694486498833
step: 150, loss: 4.752893073600717e-05
step: 160, loss: 0.062148019671440125
step: 170, loss: 0.023592431098222733
step: 180, loss: 0.018642941489815712
step: 190, loss: 0.00990824494510889
step: 200, loss: 0.016804739832878113
step: 210, loss: 0.00016839223098941147
step: 220, loss: 0.00011701942275976762
step: 230, loss: 0.005247669760137796
step: 240, loss: 0.0007288954220712185
step: 250, loss: 0.0005598132847808301
step: 260, loss: 0.029866909608244896
step: 270, loss: 0.00012164266081526875
step: 280, loss: 0.0004931016592308879
step: 290, loss: 0.013102283701300621
step: 300, loss: 0.0003383222792763263
step: 310, loss: 0.026921460404992104
step: 320, loss: 5.753450022893958e-05
step: 330, loss: 0.0001882571232272312
step: 340, loss: 0.020798569545149803
step: 350, loss: 0.02722996659576893
step: 360, loss: 0.009311331436038017
epoch 20: dev_f1=0.7480916030534353, f1=0.7473684210526317, best_f1=0.7736842105263158
