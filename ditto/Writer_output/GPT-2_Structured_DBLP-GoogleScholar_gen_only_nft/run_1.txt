cuda
Device: cuda
step: 0, loss: 0.6581367254257202
step: 10, loss: 0.4430832862854004
step: 20, loss: 0.37087634205818176
step: 30, loss: 0.3959963917732239
step: 40, loss: 0.33054643869400024
step: 50, loss: 0.28444093465805054
step: 60, loss: 0.32861071825027466
step: 70, loss: 0.3516252040863037
step: 80, loss: 0.3913879990577698
step: 90, loss: 0.32816821336746216
step: 100, loss: 0.35579633712768555
step: 110, loss: 0.34553858637809753
step: 120, loss: 0.2239275574684143
step: 130, loss: 0.07350039482116699
step: 140, loss: 0.2661497890949249
step: 150, loss: 0.41145825386047363
step: 160, loss: 0.4046398997306824
step: 170, loss: 0.18366995453834534
step: 180, loss: 0.38527819514274597
step: 190, loss: 0.3734336793422699
step: 200, loss: 0.2808794379234314
step: 210, loss: 0.3109113276004791
step: 220, loss: 0.33914703130722046
step: 230, loss: 0.2957209348678589
step: 240, loss: 0.2738402187824249
step: 250, loss: 0.38750943541526794
step: 260, loss: 0.16306883096694946
step: 270, loss: 0.2412082552909851
step: 280, loss: 0.4164961278438568
step: 290, loss: 0.18089276552200317
step: 300, loss: 0.2067517638206482
step: 310, loss: 0.21346567571163177
step: 320, loss: 0.13223110139369965
step: 330, loss: 0.2788752019405365
step: 340, loss: 0.31532934308052063
step: 350, loss: 0.1334572434425354
step: 360, loss: 0.1779876947402954
step: 370, loss: 0.18649767339229584
step: 380, loss: 0.25178447365760803
step: 390, loss: 0.22927343845367432
step: 400, loss: 0.13989484310150146
step: 410, loss: 0.3905940651893616
step: 420, loss: 0.34768518805503845
step: 430, loss: 0.3532749116420746
step: 440, loss: 0.32163217663764954
step: 450, loss: 0.0940496101975441
step: 460, loss: 0.22503246366977692
step: 470, loss: 0.15553437173366547
step: 480, loss: 0.4786933660507202
step: 490, loss: 0.47247055172920227
step: 500, loss: 0.2762691378593445
step: 510, loss: 0.2487000823020935
step: 520, loss: 0.19419020414352417
step: 530, loss: 0.08600327372550964
epoch 1: dev_f1=0.8618331053351573, f1=0.8167293233082706, best_f1=0.8167293233082706
step: 0, loss: 0.10119245201349258
step: 10, loss: 0.12376932054758072
step: 20, loss: 0.07908868789672852
step: 30, loss: 0.04839303344488144
step: 40, loss: 0.11688367277383804
step: 50, loss: 0.19899971783161163
step: 60, loss: 0.12860362231731415
step: 70, loss: 0.1360185444355011
step: 80, loss: 0.14226143062114716
step: 90, loss: 0.1676817536354065
step: 100, loss: 0.14544670283794403
step: 110, loss: 0.24111682176589966
step: 120, loss: 0.2015446126461029
step: 130, loss: 0.3946569561958313
step: 140, loss: 0.06652414798736572
step: 150, loss: 0.27158451080322266
step: 160, loss: 0.20357666909694672
step: 170, loss: 0.24311763048171997
step: 180, loss: 0.13366925716400146
step: 190, loss: 0.16295526921749115
step: 200, loss: 0.22250278294086456
step: 210, loss: 0.14239822328090668
step: 220, loss: 0.2488064020872116
step: 230, loss: 0.14516299962997437
step: 240, loss: 0.1488218456506729
step: 250, loss: 0.3066979646682739
step: 260, loss: 0.0468258261680603
step: 270, loss: 0.19056075811386108
step: 280, loss: 0.30932891368865967
step: 290, loss: 0.0854606106877327
step: 300, loss: 0.17518950998783112
step: 310, loss: 0.2873121500015259
step: 320, loss: 0.12784737348556519
step: 330, loss: 0.06152842938899994
step: 340, loss: 0.1323847472667694
step: 350, loss: 0.16068202257156372
step: 360, loss: 0.1728868931531906
step: 370, loss: 0.1123611330986023
step: 380, loss: 0.07959431409835815
step: 390, loss: 0.261974573135376
step: 400, loss: 0.11728152632713318
step: 410, loss: 0.11018180847167969
step: 420, loss: 0.07572776079177856
step: 430, loss: 0.10403800755739212
step: 440, loss: 0.3729216456413269
step: 450, loss: 0.12463133037090302
step: 460, loss: 0.28464338183403015
step: 470, loss: 0.07142314314842224
step: 480, loss: 0.07100307941436768
step: 490, loss: 0.3743387460708618
step: 500, loss: 0.3303317427635193
step: 510, loss: 0.06489643454551697
step: 520, loss: 0.20247071981430054
step: 530, loss: 0.25299689173698425
epoch 2: dev_f1=0.8796338672768879, f1=0.7973609802073516, best_f1=0.7973609802073516
step: 0, loss: 0.10554756969213486
step: 10, loss: 0.07328040897846222
step: 20, loss: 0.19601233303546906
step: 30, loss: 0.1780814379453659
step: 40, loss: 0.16343186795711517
step: 50, loss: 0.03233979269862175
step: 60, loss: 0.11198505014181137
step: 70, loss: 0.260739266872406
step: 80, loss: 0.10932512581348419
step: 90, loss: 0.06994311511516571
step: 100, loss: 0.2433209866285324
step: 110, loss: 0.12429121881723404
step: 120, loss: 0.0721089243888855
step: 130, loss: 0.10679920762777328
step: 140, loss: 0.15788204967975616
step: 150, loss: 0.14033396542072296
step: 160, loss: 0.05726587772369385
step: 170, loss: 0.21739289164543152
step: 180, loss: 0.19751755893230438
step: 190, loss: 0.09215813130140305
step: 200, loss: 0.08183225244283676
step: 210, loss: 0.34902775287628174
step: 220, loss: 0.14101935923099518
step: 230, loss: 0.13272641599178314
step: 240, loss: 0.05346475914120674
step: 250, loss: 0.24845632910728455
step: 260, loss: 0.033298641443252563
step: 270, loss: 0.08628926426172256
step: 280, loss: 0.08390460163354874
step: 290, loss: 0.09371883422136307
step: 300, loss: 0.12520259618759155
step: 310, loss: 0.17359894514083862
step: 320, loss: 0.07859138399362564
step: 330, loss: 0.07457070797681808
step: 340, loss: 0.12212622165679932
step: 350, loss: 0.17489558458328247
step: 360, loss: 0.19954611361026764
step: 370, loss: 0.0688760057091713
step: 380, loss: 0.15398406982421875
step: 390, loss: 0.1792188584804535
step: 400, loss: 0.036572977900505066
step: 410, loss: 0.16841991245746613
step: 420, loss: 0.06903678923845291
step: 430, loss: 0.1586540937423706
step: 440, loss: 0.05192049220204353
step: 450, loss: 0.07743679732084274
step: 460, loss: 0.11277708411216736
step: 470, loss: 0.028166959062218666
step: 480, loss: 0.19276443123817444
step: 490, loss: 0.08854041993618011
step: 500, loss: 0.2460974007844925
step: 510, loss: 0.08526088297367096
step: 520, loss: 0.06988940387964249
step: 530, loss: 0.07596278935670853
epoch 3: dev_f1=0.8808530366249422, f1=0.7699665231946438, best_f1=0.7699665231946438
step: 0, loss: 0.24422763288021088
step: 10, loss: 0.019464312121272087
step: 20, loss: 0.028982503339648247
step: 30, loss: 0.17938478291034698
step: 40, loss: 0.10751430690288544
step: 50, loss: 0.03981320559978485
step: 60, loss: 0.017048219218850136
step: 70, loss: 0.01737850345671177
step: 80, loss: 0.08648403733968735
step: 90, loss: 0.08991080522537231
step: 100, loss: 0.1544688194990158
step: 110, loss: 0.04588300734758377
step: 120, loss: 0.03190905228257179
step: 130, loss: 0.040015414357185364
step: 140, loss: 0.10016562789678574
step: 150, loss: 0.14667223393917084
step: 160, loss: 0.17191199958324432
step: 170, loss: 0.0644969716668129
step: 180, loss: 0.07154238969087601
step: 190, loss: 0.01774008385837078
step: 200, loss: 0.0850016251206398
step: 210, loss: 0.09148846566677094
step: 220, loss: 0.0650644302368164
step: 230, loss: 0.12424497306346893
step: 240, loss: 0.04679471254348755
step: 250, loss: 0.11324436962604523
step: 260, loss: 0.36285391449928284
step: 270, loss: 0.08925901353359222
step: 280, loss: 0.14400865137577057
step: 290, loss: 0.06810860335826874
step: 300, loss: 0.06608105450868607
step: 310, loss: 0.044498831033706665
step: 320, loss: 0.11551260203123093
step: 330, loss: 0.029701145365834236
step: 340, loss: 0.040823474526405334
step: 350, loss: 0.029348192736506462
step: 360, loss: 0.03488216549158096
step: 370, loss: 0.17601580917835236
step: 380, loss: 0.02736559882760048
step: 390, loss: 0.16187605261802673
step: 400, loss: 0.04051823168992996
step: 410, loss: 0.031825482845306396
step: 420, loss: 0.05598771944642067
step: 430, loss: 0.08339884877204895
step: 440, loss: 0.07824178040027618
step: 450, loss: 0.26945188641548157
step: 460, loss: 0.17162641882896423
step: 470, loss: 0.04050809517502785
step: 480, loss: 0.012016486376523972
step: 490, loss: 0.1263761818408966
step: 500, loss: 0.055868614464998245
step: 510, loss: 0.10469713807106018
step: 520, loss: 0.02962406910955906
step: 530, loss: 0.07723613828420639
epoch 4: dev_f1=0.8775034932463903, f1=0.76878612716763, best_f1=0.7699665231946438
step: 0, loss: 0.030660010874271393
step: 10, loss: 0.051511913537979126
step: 20, loss: 0.04497646540403366
step: 30, loss: 0.00860847532749176
step: 40, loss: 0.0016992916353046894
step: 50, loss: 0.030722003430128098
step: 60, loss: 0.009503277949988842
step: 70, loss: 0.02588946744799614
step: 80, loss: 0.005043874494731426
step: 90, loss: 0.09995248168706894
step: 100, loss: 0.008794271387159824
step: 110, loss: 0.019860485568642616
step: 120, loss: 0.05393299460411072
step: 130, loss: 0.03452439233660698
step: 140, loss: 0.09478852897882462
step: 150, loss: 0.10862842202186584
step: 160, loss: 0.06572701781988144
step: 170, loss: 0.016689559444785118
step: 180, loss: 0.0433284267783165
step: 190, loss: 0.0650310292840004
step: 200, loss: 0.07984457165002823
step: 210, loss: 0.04712265729904175
step: 220, loss: 0.02973506972193718
step: 230, loss: 0.04404934123158455
step: 240, loss: 0.13135449588298798
step: 250, loss: 0.04271510988473892
step: 260, loss: 0.22957661747932434
step: 270, loss: 0.09184856712818146
step: 280, loss: 0.09589002281427383
step: 290, loss: 0.0817679613828659
step: 300, loss: 0.1329108029603958
step: 310, loss: 0.06472571194171906
step: 320, loss: 0.1490938365459442
step: 330, loss: 0.030176745727658272
step: 340, loss: 0.026507891714572906
step: 350, loss: 0.017590699717402458
step: 360, loss: 0.09225469082593918
step: 370, loss: 0.046668753027915955
step: 380, loss: 0.07784929126501083
step: 390, loss: 0.031127026304602623
step: 400, loss: 0.1350134313106537
step: 410, loss: 0.026594538241624832
step: 420, loss: 0.01790449395775795
step: 430, loss: 0.1257248967885971
step: 440, loss: 0.06320461630821228
step: 450, loss: 0.1133788451552391
step: 460, loss: 0.029122507199645042
step: 470, loss: 0.03983304277062416
step: 480, loss: 0.01911494880914688
step: 490, loss: 0.00923630129545927
step: 500, loss: 0.0776023343205452
step: 510, loss: 0.06883296370506287
step: 520, loss: 0.2992756962776184
step: 530, loss: 0.05224097892642021
epoch 5: dev_f1=0.870741950536631, f1=0.7443237907206318, best_f1=0.7699665231946438
step: 0, loss: 0.07687553763389587
step: 10, loss: 0.00597689813002944
step: 20, loss: 0.025850558653473854
step: 30, loss: 0.10553140193223953
step: 40, loss: 0.01342961098998785
step: 50, loss: 0.020963309332728386
step: 60, loss: 0.011753885075449944
step: 70, loss: 0.02138678915798664
step: 80, loss: 0.011271418072283268
step: 90, loss: 0.18848036229610443
step: 100, loss: 0.0038113552145659924
step: 110, loss: 0.05073259398341179
step: 120, loss: 0.07543456554412842
step: 130, loss: 0.042246852070093155
step: 140, loss: 0.01173105463385582
step: 150, loss: 0.04334697127342224
step: 160, loss: 0.005808097310364246
step: 170, loss: 0.03577883169054985
step: 180, loss: 0.0012604882940649986
step: 190, loss: 0.020216962322592735
step: 200, loss: 0.012345299124717712
step: 210, loss: 0.024304507300257683
step: 220, loss: 0.06582438945770264
step: 230, loss: 0.020364120602607727
step: 240, loss: 0.004588688723742962
step: 250, loss: 0.06368165463209152
step: 260, loss: 0.02159212715923786
step: 270, loss: 0.04924916848540306
step: 280, loss: 0.0054925656877458096
step: 290, loss: 0.16868609189987183
step: 300, loss: 0.030140696093440056
step: 310, loss: 0.1560101956129074
step: 320, loss: 0.034833069890737534
step: 330, loss: 0.05162285640835762
step: 340, loss: 0.019971128553152084
step: 350, loss: 0.019618239253759384
step: 360, loss: 0.012157763354480267
step: 370, loss: 0.016118837520480156
step: 380, loss: 0.009241227991878986
step: 390, loss: 0.002254719380289316
step: 400, loss: 0.14722023904323578
step: 410, loss: 0.014211947098374367
step: 420, loss: 0.005940820090472698
step: 430, loss: 0.009807155467569828
step: 440, loss: 0.012437223456799984
step: 450, loss: 0.1118304654955864
step: 460, loss: 0.24400752782821655
step: 470, loss: 0.024635685607790947
step: 480, loss: 0.010025275871157646
step: 490, loss: 0.0897771567106247
step: 500, loss: 0.00997666735202074
step: 510, loss: 0.011234614998102188
step: 520, loss: 0.01804114505648613
step: 530, loss: 0.045981280505657196
epoch 6: dev_f1=0.8494279176201374, f1=0.7227769852591537, best_f1=0.7699665231946438
step: 0, loss: 0.10972930490970612
step: 10, loss: 0.05067998543381691
step: 20, loss: 0.014659887179732323
step: 30, loss: 0.01765107735991478
step: 40, loss: 0.018694767728447914
step: 50, loss: 0.007468725088983774
step: 60, loss: 0.018191691488027573
step: 70, loss: 0.11650094389915466
step: 80, loss: 0.019085781648755074
step: 90, loss: 0.0018189202528446913
step: 100, loss: 0.010985350236296654
step: 110, loss: 0.08669745922088623
step: 120, loss: 0.06557478755712509
step: 130, loss: 0.05488627031445503
step: 140, loss: 0.05099192634224892
step: 150, loss: 0.017110202461481094
step: 160, loss: 0.03150925785303116
step: 170, loss: 0.05721203610301018
step: 180, loss: 0.11141843348741531
step: 190, loss: 0.02121094800531864
step: 200, loss: 0.01385059766471386
step: 210, loss: 0.09822896122932434
step: 220, loss: 0.011602062731981277
step: 230, loss: 0.001977898646146059
step: 240, loss: 0.0007970558945089579
step: 250, loss: 0.0725349634885788
step: 260, loss: 0.0052395593374967575
step: 270, loss: 0.002320782281458378
step: 280, loss: 0.0007249868358485401
step: 290, loss: 0.0026944868732243776
step: 300, loss: 0.029839888215065002
step: 310, loss: 0.00334346666932106
step: 320, loss: 0.0025025352369993925
step: 330, loss: 0.0058578141033649445
step: 340, loss: 0.10582344233989716
step: 350, loss: 0.009830859489738941
step: 360, loss: 0.009583179838955402
step: 370, loss: 0.036783743649721146
step: 380, loss: 0.005335995461791754
step: 390, loss: 0.1476992815732956
step: 400, loss: 0.11204216629266739
step: 410, loss: 0.0036355643533170223
step: 420, loss: 0.0023451894521713257
step: 430, loss: 0.11155341565608978
step: 440, loss: 0.0017044813139364123
step: 450, loss: 0.03342514485120773
step: 460, loss: 0.028305428102612495
step: 470, loss: 0.000821030349470675
step: 480, loss: 0.09943771362304688
step: 490, loss: 0.0047748698852956295
step: 500, loss: 0.0017762159695848823
step: 510, loss: 0.1237928494811058
step: 520, loss: 0.09322632104158401
step: 530, loss: 0.007086819503456354
epoch 7: dev_f1=0.868952559887271, f1=0.7375249500998003, best_f1=0.7699665231946438
step: 0, loss: 0.09101603180170059
step: 10, loss: 0.006411438342183828
step: 20, loss: 0.008227274753153324
step: 30, loss: 0.006332827731966972
step: 40, loss: 0.0029160345438867807
step: 50, loss: 0.001484943088144064
step: 60, loss: 0.0014962691348046064
step: 70, loss: 0.00761063676327467
step: 80, loss: 0.0003444732283242047
step: 90, loss: 0.0031806048937141895
step: 100, loss: 0.003439114661887288
step: 110, loss: 0.010945565067231655
step: 120, loss: 0.0013599162921309471
step: 130, loss: 0.12836097180843353
step: 140, loss: 0.008373589254915714
step: 150, loss: 0.004774823784828186
step: 160, loss: 0.008682334795594215
step: 170, loss: 0.0038262305315583944
step: 180, loss: 0.0033248532563447952
step: 190, loss: 0.004671758972108364
step: 200, loss: 0.027183065190911293
step: 210, loss: 0.029519766569137573
step: 220, loss: 0.007830338552594185
step: 230, loss: 0.007962488569319248
step: 240, loss: 0.003342155134305358
step: 250, loss: 0.007978025823831558
step: 260, loss: 0.06475885212421417
step: 270, loss: 0.0007245392771437764
step: 280, loss: 0.013452684506773949
step: 290, loss: 0.018851231783628464
step: 300, loss: 0.09630396217107773
step: 310, loss: 0.006916126236319542
step: 320, loss: 0.0028444835916161537
step: 330, loss: 0.004887248855084181
step: 340, loss: 0.024325968697667122
step: 350, loss: 0.002952690701931715
step: 360, loss: 0.07300398498773575
step: 370, loss: 0.04244856536388397
step: 380, loss: 0.003514850977808237
step: 390, loss: 0.006351763382554054
step: 400, loss: 0.016421746462583542
step: 410, loss: 0.024550244212150574
step: 420, loss: 0.02179831825196743
step: 430, loss: 0.0016308327903971076
step: 440, loss: 0.0028390635270625353
step: 450, loss: 0.0008516711532138288
step: 460, loss: 0.003805152140557766
step: 470, loss: 0.01642582006752491
step: 480, loss: 0.005347842816263437
step: 490, loss: 0.020796775817871094
step: 500, loss: 0.006355617195367813
step: 510, loss: 0.0035389461554586887
step: 520, loss: 0.04043744131922722
step: 530, loss: 0.02979450300335884
epoch 8: dev_f1=0.8615384615384615, f1=0.7436893203883496, best_f1=0.7699665231946438
step: 0, loss: 0.026628775522112846
step: 10, loss: 0.011859631165862083
step: 20, loss: 0.009316522628068924
step: 30, loss: 0.024985233321785927
step: 40, loss: 0.009381994605064392
step: 50, loss: 0.011583664454519749
step: 60, loss: 0.01644178293645382
step: 70, loss: 0.0020895779598504305
step: 80, loss: 0.012158838100731373
step: 90, loss: 0.0033072936348617077
step: 100, loss: 0.027275318279862404
step: 110, loss: 0.042226191610097885
step: 120, loss: 0.013998955488204956
step: 130, loss: 0.013050167821347713
step: 140, loss: 0.0008912002085708082
step: 150, loss: 0.009795716032385826
step: 160, loss: 0.05131211504340172
step: 170, loss: 0.001732399221509695
step: 180, loss: 0.007292110938578844
step: 190, loss: 0.009462445043027401
step: 200, loss: 0.0635945275425911
step: 210, loss: 0.002614540746435523
step: 220, loss: 0.0010281329741701484
step: 230, loss: 0.03304154798388481
step: 240, loss: 0.03300102427601814
step: 250, loss: 0.0004972892347723246
step: 260, loss: 0.02802778035402298
step: 270, loss: 0.0051795062609016895
step: 280, loss: 0.029987115412950516
step: 290, loss: 0.02320295386016369
step: 300, loss: 0.026881270110607147
step: 310, loss: 0.008592389523983002
step: 320, loss: 0.002443814417347312
step: 330, loss: 0.16543368995189667
step: 340, loss: 0.019840817898511887
step: 350, loss: 0.011484014801681042
step: 360, loss: 0.0016281623393297195
step: 370, loss: 0.04970451444387436
step: 380, loss: 0.08924848586320877
step: 390, loss: 0.21146045625209808
step: 400, loss: 0.07693133503198624
step: 410, loss: 0.007397371344268322
step: 420, loss: 0.016273390501737595
step: 430, loss: 0.0040920511819422245
step: 440, loss: 0.00041957979556173086
step: 450, loss: 0.005237006116658449
step: 460, loss: 0.002349257003515959
step: 470, loss: 0.017171313986182213
step: 480, loss: 0.053699202835559845
step: 490, loss: 0.0009098740993067622
step: 500, loss: 0.017922470346093178
step: 510, loss: 0.006600749678909779
step: 520, loss: 0.010715091601014137
step: 530, loss: 0.010100302286446095
epoch 9: dev_f1=0.8637627432808155, f1=0.7197265624999999, best_f1=0.7699665231946438
step: 0, loss: 0.0034911518450826406
step: 10, loss: 0.0008389087743125856
step: 20, loss: 0.00537019083276391
step: 30, loss: 0.0033774925395846367
step: 40, loss: 0.0010581295937299728
step: 50, loss: 0.00745678786188364
step: 60, loss: 0.0014886282151564956
step: 70, loss: 0.0020989791955798864
step: 80, loss: 0.001459059421904385
step: 90, loss: 0.017466166988015175
step: 100, loss: 0.017919808626174927
step: 110, loss: 0.001855029258877039
step: 120, loss: 0.007537411525845528
step: 130, loss: 0.00015995743160601705
step: 140, loss: 0.0018660416826605797
step: 150, loss: 0.0012733610346913338
step: 160, loss: 0.00022525257372763008
step: 170, loss: 0.00010150801244890317
step: 180, loss: 0.00034508525277487934
step: 190, loss: 0.009078582748770714
step: 200, loss: 0.001915230881422758
step: 210, loss: 0.005936355330049992
step: 220, loss: 0.0021703599486500025
step: 230, loss: 0.001560119679197669
step: 240, loss: 0.0036389499437063932
step: 250, loss: 0.0011725728400051594
step: 260, loss: 0.00012780145334545523
step: 270, loss: 0.04584881290793419
step: 280, loss: 0.0009314997005276382
step: 290, loss: 0.00015245695249177516
step: 300, loss: 0.022297710180282593
step: 310, loss: 0.0011067446321249008
step: 320, loss: 0.04144943878054619
step: 330, loss: 0.0009206437389366329
step: 340, loss: 0.003415114711970091
step: 350, loss: 0.00033088491181842983
step: 360, loss: 0.001822162070311606
step: 370, loss: 0.01178789883852005
step: 380, loss: 0.016486316919326782
step: 390, loss: 0.0009442131267860532
step: 400, loss: 0.019984014332294464
step: 410, loss: 0.0005203440086916089
step: 420, loss: 0.16262146830558777
step: 430, loss: 0.011382064782083035
step: 440, loss: 0.005682964343577623
step: 450, loss: 0.002121914178133011
step: 460, loss: 0.019517378881573677
step: 470, loss: 0.005010724067687988
step: 480, loss: 0.014149647206068039
step: 490, loss: 0.0058038863353431225
step: 500, loss: 0.006450527347624302
step: 510, loss: 0.010565832257270813
step: 520, loss: 0.016965948045253754
step: 530, loss: 0.00015605588851030916
epoch 10: dev_f1=0.8434296365330849, f1=0.699203187250996, best_f1=0.7699665231946438
step: 0, loss: 0.0003679104847833514
step: 10, loss: 0.001737105892971158
step: 20, loss: 0.06644702702760696
step: 30, loss: 0.022747954353690147
step: 40, loss: 0.0009432415245100856
step: 50, loss: 0.001932819141075015
step: 60, loss: 0.0010047921678051353
step: 70, loss: 0.000857782841194421
step: 80, loss: 0.10152747482061386
step: 90, loss: 0.008863930590450764
step: 100, loss: 0.0006183671648614109
step: 110, loss: 0.1671847254037857
step: 120, loss: 0.00040065747452899814
step: 130, loss: 0.043758831918239594
step: 140, loss: 0.004541241098195314
step: 150, loss: 0.0024805129505693913
step: 160, loss: 0.00021799150272272527
step: 170, loss: 0.0030806423164904118
step: 180, loss: 0.0005401443340815604
step: 190, loss: 6.184037192724645e-05
step: 200, loss: 0.0389096699655056
step: 210, loss: 0.009226268157362938
step: 220, loss: 0.00013113641762174666
step: 230, loss: 0.02690933831036091
step: 240, loss: 0.0035465960390865803
step: 250, loss: 0.001346960780210793
step: 260, loss: 0.015330534428358078
step: 270, loss: 0.01676037348806858
step: 280, loss: 0.0008037998923100531
step: 290, loss: 0.013641915284097195
step: 300, loss: 0.01905955746769905
step: 310, loss: 0.0028022851329296827
step: 320, loss: 0.01750812865793705
step: 330, loss: 0.020035257562994957
step: 340, loss: 0.003327967831864953
step: 350, loss: 0.030900875106453896
step: 360, loss: 0.0030271834693849087
step: 370, loss: 0.0001450604759156704
step: 380, loss: 0.020294995978474617
step: 390, loss: 0.002271846169605851
step: 400, loss: 0.00037722333217971027
step: 410, loss: 0.00097935541998595
step: 420, loss: 0.0005504519795067608
step: 430, loss: 0.0014299473259598017
step: 440, loss: 0.0014502875274047256
step: 450, loss: 0.06505823135375977
step: 460, loss: 0.011595851741731167
step: 470, loss: 8.981566497823223e-05
step: 480, loss: 0.0002404858823865652
step: 490, loss: 0.00021191526320762932
step: 500, loss: 0.0033662994392216206
step: 510, loss: 0.00012369724572636187
step: 520, loss: 0.0004764089244417846
step: 530, loss: 0.008040748536586761
epoch 11: dev_f1=0.8661267270128633, f1=0.7305327868852459, best_f1=0.7699665231946438
step: 0, loss: 0.000395559094613418
step: 10, loss: 0.0019039191538468003
step: 20, loss: 0.060799505561590195
step: 30, loss: 0.0005051358602941036
step: 40, loss: 0.0005171025986783206
step: 50, loss: 0.0008420450612902641
step: 60, loss: 0.0003721426473930478
step: 70, loss: 0.005321237724274397
step: 80, loss: 0.0010841827606782317
step: 90, loss: 0.0007997654611244798
step: 100, loss: 0.0011468336451798677
step: 110, loss: 0.0631674975156784
step: 120, loss: 0.0006553602870553732
step: 130, loss: 0.00014726117660757154
step: 140, loss: 0.00014384013775270432
step: 150, loss: 0.00020788036636076868
step: 160, loss: 0.0049016838893294334
step: 170, loss: 0.0011303037172183394
step: 180, loss: 0.0004367128130979836
step: 190, loss: 0.03177788481116295
step: 200, loss: 0.011933447793126106
step: 210, loss: 0.0005595423863269389
step: 220, loss: 0.00014811732398811728
step: 230, loss: 0.06475862860679626
step: 240, loss: 0.0022232760675251484
step: 250, loss: 0.0004056132456753403
step: 260, loss: 0.00015287453425116837
step: 270, loss: 0.0017774299485608935
step: 280, loss: 0.00023806477838661522
step: 290, loss: 0.00015264999819919467
step: 300, loss: 0.0018048660131171346
step: 310, loss: 8.70371877681464e-05
step: 320, loss: 9.819471597438678e-05
step: 330, loss: 0.002905077300965786
step: 340, loss: 0.0002627199573908001
step: 350, loss: 6.776601367164403e-05
step: 360, loss: 0.0005971174105070531
step: 370, loss: 0.0063512506894767284
step: 380, loss: 0.00034499121829867363
step: 390, loss: 0.012829598970711231
step: 400, loss: 0.00028259181999601424
step: 410, loss: 0.000548671290744096
step: 420, loss: 0.034179460257291794
step: 430, loss: 7.321240263991058e-05
step: 440, loss: 0.0034773224033415318
step: 450, loss: 0.008796067908406258
step: 460, loss: 0.002403480000793934
step: 470, loss: 0.00022768111375626177
step: 480, loss: 0.00013998133363202214
step: 490, loss: 0.009287383407354355
step: 500, loss: 0.0006186304381117225
step: 510, loss: 0.06737613677978516
step: 520, loss: 0.0014871617313474417
step: 530, loss: 0.002123038051649928
epoch 12: dev_f1=0.8503521126760563, f1=0.7211759301791457, best_f1=0.7699665231946438
step: 0, loss: 0.001933886669576168
step: 10, loss: 0.009174127131700516
step: 20, loss: 0.0033823554404079914
step: 30, loss: 0.003263469086959958
step: 40, loss: 0.00036390929017215967
step: 50, loss: 4.9670165026327595e-05
step: 60, loss: 0.009061108343303204
step: 70, loss: 0.008093541488051414
step: 80, loss: 0.0001474692253395915
step: 90, loss: 0.000479861453641206
step: 100, loss: 0.0002793298044707626
step: 110, loss: 0.005504996050149202
step: 120, loss: 0.008159463293850422
step: 130, loss: 0.0005814574542455375
step: 140, loss: 0.00010352709796279669
step: 150, loss: 0.0021249225828796625
step: 160, loss: 0.00013914644659962505
step: 170, loss: 0.0024394034408032894
step: 180, loss: 0.00215601222589612
step: 190, loss: 0.00022243671992328018
step: 200, loss: 0.0007327143684960902
step: 210, loss: 2.9041606467217207e-05
step: 220, loss: 0.04963071644306183
step: 230, loss: 0.00025901090702973306
step: 240, loss: 0.0011132644722238183
step: 250, loss: 0.00025376409757882357
step: 260, loss: 2.3431504814652726e-05
step: 270, loss: 0.0016057853354141116
step: 280, loss: 0.0008569506462663412
step: 290, loss: 0.0006230067228898406
step: 300, loss: 0.007866962812840939
step: 310, loss: 0.07479957491159439
step: 320, loss: 0.17707416415214539
step: 330, loss: 0.0026768608950078487
step: 340, loss: 9.63527345447801e-05
step: 350, loss: 0.0011105299927294254
step: 360, loss: 0.0001615455694263801
step: 370, loss: 0.0011137021938338876
step: 380, loss: 0.0025894043501466513
step: 390, loss: 4.075885590282269e-05
step: 400, loss: 0.00018811716290656477
step: 410, loss: 0.000303268781863153
step: 420, loss: 0.007232731208205223
step: 430, loss: 4.761311720358208e-05
step: 440, loss: 0.0001531681336928159
step: 450, loss: 0.00021814421052113175
step: 460, loss: 0.0005864183767698705
step: 470, loss: 9.387620229972526e-05
step: 480, loss: 0.006067579612135887
step: 490, loss: 0.03492262214422226
step: 500, loss: 0.0006763734272681177
step: 510, loss: 0.0017784369410946965
step: 520, loss: 0.07241678237915039
step: 530, loss: 0.15732243657112122
epoch 13: dev_f1=0.8675799086757991, f1=0.7485604606525913, best_f1=0.7699665231946438
step: 0, loss: 0.0005023076664656401
step: 10, loss: 0.0003231052542105317
step: 20, loss: 0.0014797109179198742
step: 30, loss: 0.0013918455224484205
step: 40, loss: 0.003885160433128476
step: 50, loss: 7.284882303792983e-05
step: 60, loss: 0.0006660918588750064
step: 70, loss: 0.0003514162381179631
step: 80, loss: 0.0010105669498443604
step: 90, loss: 0.0010305236792191863
step: 100, loss: 0.00043143524089828134
step: 110, loss: 0.00015162609633989632
step: 120, loss: 0.0010770849185064435
step: 130, loss: 0.0010097824269905686
step: 140, loss: 3.486011701170355e-05
step: 150, loss: 9.77862800937146e-05
step: 160, loss: 0.0007100203074514866
step: 170, loss: 0.00010417041630716994
step: 180, loss: 0.00241207517683506
step: 190, loss: 0.017460966482758522
step: 200, loss: 0.04227718710899353
step: 210, loss: 0.0007624220452271402
step: 220, loss: 0.29868173599243164
step: 230, loss: 0.00013592455070465803
step: 240, loss: 0.0007710968493483961
step: 250, loss: 0.00019057032477576286
step: 260, loss: 0.0027210554108023643
step: 270, loss: 0.00169939745683223
step: 280, loss: 0.0005298813339322805
step: 290, loss: 0.0018617849564179778
step: 300, loss: 0.00020985372248105705
step: 310, loss: 0.0006723505794070661
step: 320, loss: 0.00025463345809839666
step: 330, loss: 8.755358430789784e-05
step: 340, loss: 0.06060805544257164
step: 350, loss: 0.007670599967241287
step: 360, loss: 0.0033873110078275204
step: 370, loss: 0.008800416253507137
step: 380, loss: 0.010229986160993576
step: 390, loss: 5.507765308720991e-05
step: 400, loss: 0.0001510339934611693
step: 410, loss: 2.5204735720762983e-05
step: 420, loss: 0.000681691977661103
step: 430, loss: 4.167571751167998e-05
step: 440, loss: 0.0002616646233946085
step: 450, loss: 4.980199446436018e-05
step: 460, loss: 0.007200212217867374
step: 470, loss: 0.0010302766459062696
step: 480, loss: 0.13647770881652832
step: 490, loss: 0.0002469885803293437
step: 500, loss: 0.019757356494665146
step: 510, loss: 0.0008728897664695978
step: 520, loss: 0.0042255898006260395
step: 530, loss: 0.003167266258969903
epoch 14: dev_f1=0.8525821596244132, f1=0.7197231833910036, best_f1=0.7699665231946438
step: 0, loss: 0.004942408762872219
step: 10, loss: 0.005893137771636248
step: 20, loss: 5.262266131467186e-05
step: 30, loss: 0.00011266457295278087
step: 40, loss: 0.0001182437626994215
step: 50, loss: 0.003347586141899228
step: 60, loss: 0.03809671849012375
step: 70, loss: 0.00010025957453763112
step: 80, loss: 7.128727884264663e-05
step: 90, loss: 8.612852252554148e-05
step: 100, loss: 0.012846002355217934
step: 110, loss: 0.00037445497582666576
step: 120, loss: 0.054532285779714584
step: 130, loss: 0.0014731163391843438
step: 140, loss: 0.0001917561748996377
step: 150, loss: 9.916944691212848e-05
step: 160, loss: 0.00024107069475576282
step: 170, loss: 0.00020264381601009518
step: 180, loss: 0.0028985377866774797
step: 190, loss: 5.274946670397185e-05
step: 200, loss: 0.00011077609087806195
step: 210, loss: 0.0018386808224022388
step: 220, loss: 2.756263165792916e-05
step: 230, loss: 0.0011144273448735476
step: 240, loss: 0.0007494178717024624
step: 250, loss: 0.0001061591028701514
step: 260, loss: 0.049296457320451736
step: 270, loss: 8.054861973505467e-05
step: 280, loss: 9.412888903170824e-05
step: 290, loss: 0.0009630502900108695
step: 300, loss: 7.040105265332386e-05
step: 310, loss: 0.0014357550535351038
step: 320, loss: 9.746252908371389e-05
step: 330, loss: 0.017224127426743507
step: 340, loss: 0.00011621356679825112
step: 350, loss: 0.001110748155042529
step: 360, loss: 0.005085733253508806
step: 370, loss: 0.0004007638490293175
step: 380, loss: 8.754160080570728e-05
step: 390, loss: 0.003071941900998354
step: 400, loss: 0.0015115870628505945
step: 410, loss: 6.194110756041482e-05
step: 420, loss: 0.0003353179490659386
step: 430, loss: 0.02249201387166977
step: 440, loss: 0.0015906346961855888
step: 450, loss: 0.00022239790996536613
step: 460, loss: 0.0008101898711174726
step: 470, loss: 4.650639311876148e-05
step: 480, loss: 4.969206565874629e-05
step: 490, loss: 7.67538440413773e-05
step: 500, loss: 3.423400630708784e-05
step: 510, loss: 5.974882878945209e-05
step: 520, loss: 6.232033047126606e-05
step: 530, loss: 0.0002869065210688859
epoch 15: dev_f1=0.8623255813953488, f1=0.7317554240631164, best_f1=0.7699665231946438
step: 0, loss: 6.316398503258824e-05
step: 10, loss: 0.00029682161402888596
step: 20, loss: 0.00027339262305758893
step: 30, loss: 0.0032859935890883207
step: 40, loss: 8.300584886455908e-05
step: 50, loss: 0.0017999501433223486
step: 60, loss: 9.047547064255923e-05
step: 70, loss: 0.006715115159749985
step: 80, loss: 3.0051171052036807e-05
step: 90, loss: 0.00127899250946939
step: 100, loss: 5.126711766934022e-05
step: 110, loss: 0.00035627512261271477
step: 120, loss: 0.0005400279187597334
step: 130, loss: 0.0003346945159137249
step: 140, loss: 0.0006419483688659966
step: 150, loss: 0.0004599952371791005
step: 160, loss: 0.000478213099995628
step: 170, loss: 0.0020294650457799435
step: 180, loss: 8.538054680684581e-05
step: 190, loss: 6.992366252234206e-05
step: 200, loss: 0.0007876206655055285
step: 210, loss: 0.000264440372120589
step: 220, loss: 7.833827112335712e-05
step: 230, loss: 0.0042920466512441635
step: 240, loss: 0.00016876895097084343
step: 250, loss: 6.262421084102243e-05
step: 260, loss: 3.351899067638442e-05
step: 270, loss: 0.00011012649338226765
step: 280, loss: 0.18628977239131927
step: 290, loss: 8.191551751224324e-05
step: 300, loss: 0.000448829960078001
step: 310, loss: 0.00015007445472292602
step: 320, loss: 7.661693234695122e-05
step: 330, loss: 5.647951547871344e-05
step: 340, loss: 0.0006823344738222659
step: 350, loss: 9.284970292355865e-05
step: 360, loss: 0.00017939165991265327
step: 370, loss: 5.7093249779427424e-05
step: 380, loss: 0.00039304280653595924
step: 390, loss: 0.0027798968367278576
step: 400, loss: 0.00014008987636771053
step: 410, loss: 0.00019120218348689377
step: 420, loss: 4.958722638548352e-05
step: 430, loss: 5.104007141198963e-05
step: 440, loss: 6.899298750795424e-05
step: 450, loss: 3.3031243219738826e-05
step: 460, loss: 0.0017389343120157719
step: 470, loss: 0.00028851203387603164
step: 480, loss: 0.00020196633704472333
step: 490, loss: 8.248031372204423e-05
step: 500, loss: 0.0004794942506123334
step: 510, loss: 4.1086957935476676e-05
step: 520, loss: 0.001524571911431849
step: 530, loss: 0.0002000061358558014
epoch 16: dev_f1=0.86468330134357, f1=0.7217030114226377, best_f1=0.7699665231946438
step: 0, loss: 9.087109356187284e-05
step: 10, loss: 0.0002999544667545706
step: 20, loss: 0.00021676725009456277
step: 30, loss: 0.00013806142669636756
step: 40, loss: 0.0019777268171310425
step: 50, loss: 0.0006106824148446321
step: 60, loss: 0.00039271367131732404
step: 70, loss: 0.00013503599620889872
step: 80, loss: 0.0005261898040771484
step: 90, loss: 6.7926463088952e-05
step: 100, loss: 0.0029149928595870733
step: 110, loss: 7.494397141272202e-05
step: 120, loss: 0.015140993520617485
step: 130, loss: 0.0016741588478907943
step: 140, loss: 0.00366141926497221
step: 150, loss: 7.69136895542033e-05
step: 160, loss: 0.00011017278302460909
step: 170, loss: 0.0021213667932897806
step: 180, loss: 0.004825829528272152
step: 190, loss: 3.791809285758063e-05
step: 200, loss: 0.00040738642564974725
step: 210, loss: 0.00017080138786695898
step: 220, loss: 0.00017225115152541548
step: 230, loss: 6.89966618665494e-05
step: 240, loss: 3.378573092049919e-05
step: 250, loss: 0.00030403665732592344
step: 260, loss: 9.906654304359108e-05
step: 270, loss: 8.958599210018292e-05
step: 280, loss: 4.318118590163067e-05
step: 290, loss: 0.00024247015244327486
step: 300, loss: 0.0006060246960259974
step: 310, loss: 0.10330682247877121
step: 320, loss: 7.513786113122478e-05
step: 330, loss: 0.00017328346439171582
step: 340, loss: 4.483301017899066e-05
step: 350, loss: 6.259981455514207e-05
step: 360, loss: 0.0002585030742920935
step: 370, loss: 8.14893573988229e-05
step: 380, loss: 0.00011714651191141456
step: 390, loss: 0.0009529333328828216
step: 400, loss: 2.6914549380308017e-05
step: 410, loss: 7.005390943959355e-05
step: 420, loss: 0.00010707476758398116
step: 430, loss: 0.0001069030913640745
step: 440, loss: 0.012355170212686062
step: 450, loss: 0.00011590190842980519
step: 460, loss: 9.617110481485724e-05
step: 470, loss: 0.0004502298543229699
step: 480, loss: 0.00010293292143614963
step: 490, loss: 0.003335138550028205
step: 500, loss: 7.017712050583214e-05
step: 510, loss: 0.002411340596154332
step: 520, loss: 4.7310291847679764e-05
step: 530, loss: 0.00032525573624297976
epoch 17: dev_f1=0.8674136321195144, f1=0.7315604616156547, best_f1=0.7699665231946438
step: 0, loss: 0.00035551644396036863
step: 10, loss: 8.916755177779123e-05
step: 20, loss: 0.0001862892968347296
step: 30, loss: 5.6118897191481665e-05
step: 40, loss: 0.0001823118218453601
step: 50, loss: 0.0001632197090657428
step: 60, loss: 0.00012128039088565856
step: 70, loss: 0.0003963389026466757
step: 80, loss: 2.8456499421736225e-05
step: 90, loss: 0.00018003683362621814
step: 100, loss: 0.0009067255305126309
step: 110, loss: 0.0003120569745078683
step: 120, loss: 0.00039950848440639675
step: 130, loss: 2.2485026420326903e-05
step: 140, loss: 8.590488141635433e-05
step: 150, loss: 8.061889093369246e-05
step: 160, loss: 2.5655157514847815e-05
step: 170, loss: 0.00012821420386899263
step: 180, loss: 4.113879185752012e-05
step: 190, loss: 0.0007851332775317132
step: 200, loss: 4.2907784518320113e-05
step: 210, loss: 0.0014171309303492308
step: 220, loss: 2.736514579737559e-05
step: 230, loss: 0.0006288255099207163
step: 240, loss: 0.00015397432434838265
step: 250, loss: 8.457173680653796e-05
step: 260, loss: 0.0010623355628922582
step: 270, loss: 6.373643554979935e-05
step: 280, loss: 0.00025733967777341604
step: 290, loss: 0.00014469368034042418
step: 300, loss: 0.0008426857530139387
step: 310, loss: 0.0029893252067267895
step: 320, loss: 9.283658437198028e-05
step: 330, loss: 0.0006005240720696747
step: 340, loss: 0.009425077587366104
step: 350, loss: 2.4891218345146626e-05
step: 360, loss: 0.0007386289071291685
step: 370, loss: 3.3117717975983396e-05
step: 380, loss: 0.00013345683692023158
step: 390, loss: 0.0017773814033716917
step: 400, loss: 9.461865556659177e-05
step: 410, loss: 8.381578663829714e-05
step: 420, loss: 4.3106039811391383e-05
step: 430, loss: 0.0009016579133458436
step: 440, loss: 3.371921047801152e-05
step: 450, loss: 5.0175753131043166e-05
step: 460, loss: 0.0002313492150278762
step: 470, loss: 9.369812323711812e-05
step: 480, loss: 0.00018086239288095385
step: 490, loss: 4.916544276056811e-05
step: 500, loss: 3.0240920750657097e-05
step: 510, loss: 8.786010585026816e-05
step: 520, loss: 9.913653775583953e-05
step: 530, loss: 0.0005078155663795769
epoch 18: dev_f1=0.860759493670886, f1=0.7194388777555111, best_f1=0.7699665231946438
step: 0, loss: 5.905545549467206e-05
step: 10, loss: 8.94655822776258e-05
step: 20, loss: 2.1747855498688295e-05
step: 30, loss: 0.00028026942163705826
step: 40, loss: 0.0002629119553603232
step: 50, loss: 0.0054666162468492985
step: 60, loss: 0.00018994591664522886
step: 70, loss: 0.00022779304708819836
step: 80, loss: 3.445761831244454e-05
step: 90, loss: 0.002293582772836089
step: 100, loss: 0.0005341151845641434
step: 110, loss: 3.3440250263083726e-05
step: 120, loss: 0.00011923338752239943
step: 130, loss: 4.599798558047041e-05
step: 140, loss: 0.0037011257372796535
step: 150, loss: 7.500942592741922e-05
step: 160, loss: 0.002225529635325074
step: 170, loss: 0.00010431375994812697
step: 180, loss: 5.900876931264065e-05
step: 190, loss: 4.110994268557988e-05
step: 200, loss: 1.887948383227922e-05
step: 210, loss: 6.0723086789948866e-05
step: 220, loss: 2.956971002276987e-05
step: 230, loss: 4.643192369258031e-05
step: 240, loss: 0.0002385083062108606
step: 250, loss: 1.885712845250964e-05
step: 260, loss: 0.0354166217148304
step: 270, loss: 0.0017236822750419378
step: 280, loss: 0.00023795958259142935
step: 290, loss: 0.00010566552373347804
step: 300, loss: 4.066097244503908e-05
step: 310, loss: 6.836243846919388e-05
step: 320, loss: 3.442930392338894e-05
step: 330, loss: 0.00014724228822160512
step: 340, loss: 9.198447514791042e-05
step: 350, loss: 5.977403270662762e-05
step: 360, loss: 3.8576738006668165e-05
step: 370, loss: 9.603839862393215e-05
step: 380, loss: 1.8328169971937314e-05
step: 390, loss: 0.00018768230802379549
step: 400, loss: 0.0009234267636202276
step: 410, loss: 8.220325253205374e-05
step: 420, loss: 4.6899505832698196e-05
step: 430, loss: 4.3372754589654505e-05
step: 440, loss: 3.7103050999576226e-05
step: 450, loss: 3.4478474844945595e-05
step: 460, loss: 8.766567043494433e-05
step: 470, loss: 0.00035402114735916257
step: 480, loss: 4.978264041710645e-05
step: 490, loss: 0.00022451271070167422
step: 500, loss: 0.00018549036758486181
step: 510, loss: 0.0021191209089010954
step: 520, loss: 0.0009279479272663593
step: 530, loss: 4.2339161154814065e-05
epoch 19: dev_f1=0.8617961842717543, f1=0.7154228855721393, best_f1=0.7699665231946438
step: 0, loss: 0.00016502823564223945
step: 10, loss: 3.9062211726559326e-05
step: 20, loss: 0.00010601324902381748
step: 30, loss: 4.885870293946937e-05
step: 40, loss: 3.7470465031219646e-05
step: 50, loss: 2.133045745722484e-05
step: 60, loss: 2.5427712898817845e-05
step: 70, loss: 0.001212280592881143
step: 80, loss: 3.5053337342105806e-05
step: 90, loss: 0.0001202489947900176
step: 100, loss: 0.00031083670910447836
step: 110, loss: 6.780234980396926e-05
step: 120, loss: 4.259009438101202e-05
step: 130, loss: 0.0003402566071599722
step: 140, loss: 6.696706259390339e-05
step: 150, loss: 0.021283958107233047
step: 160, loss: 0.00656057707965374
step: 170, loss: 7.280991121660918e-05
step: 180, loss: 0.00019899233302567154
step: 190, loss: 3.934040432795882e-05
step: 200, loss: 0.0016610858729109168
step: 210, loss: 1.8488351997802965e-05
step: 220, loss: 3.881999509758316e-05
step: 230, loss: 3.683052636915818e-05
step: 240, loss: 2.1501793526113033e-05
step: 250, loss: 0.0024655621964484453
step: 260, loss: 0.05143412947654724
step: 270, loss: 0.00020984324510209262
step: 280, loss: 0.0003302482364233583
step: 290, loss: 4.7712619561934844e-05
step: 300, loss: 3.254210969316773e-05
step: 310, loss: 0.00026524451095610857
step: 320, loss: 0.0003121623594779521
step: 330, loss: 0.00020956085063517094
step: 340, loss: 7.22764598322101e-05
step: 350, loss: 3.639394708443433e-05
step: 360, loss: 5.8015160902868956e-05
step: 370, loss: 4.704805542132817e-05
step: 380, loss: 5.774410965386778e-05
step: 390, loss: 0.00014014207408763468
step: 400, loss: 6.403552106348798e-05
step: 410, loss: 0.0010516713373363018
step: 420, loss: 0.00045404949923977256
step: 430, loss: 0.00015469061327166855
step: 440, loss: 0.023441560566425323
step: 450, loss: 0.00017324404325336218
step: 460, loss: 6.987962842686102e-05
step: 470, loss: 0.0006037382408976555
step: 480, loss: 0.00020252658578101546
step: 490, loss: 0.0007856395677663386
step: 500, loss: 4.3513031414477155e-05
step: 510, loss: 3.080332317040302e-05
step: 520, loss: 0.0008162554586306214
step: 530, loss: 8.200795127777383e-05
epoch 20: dev_f1=0.8613953488372094, f1=0.7183308494783905, best_f1=0.7699665231946438
