cuda
Device: cuda
step: 0, loss: 0.7658550143241882
step: 10, loss: 0.4308159351348877
step: 20, loss: 0.4398992359638214
step: 30, loss: 0.4322226047515869
step: 40, loss: 0.43535834550857544
step: 50, loss: 0.3966924846172333
step: 60, loss: 0.3763096332550049
step: 70, loss: 0.20247066020965576
step: 80, loss: 0.34431275725364685
step: 90, loss: 0.4522685110569
step: 100, loss: 0.35624998807907104
step: 110, loss: 0.2469685971736908
step: 120, loss: 0.43359166383743286
step: 130, loss: 0.39421209692955017
step: 140, loss: 0.2663785517215729
step: 150, loss: 0.3611079156398773
step: 160, loss: 0.1264452040195465
step: 170, loss: 0.15817111730575562
step: 180, loss: 0.3060314655303955
step: 190, loss: 0.22779019176959991
step: 200, loss: 0.3314476013183594
step: 210, loss: 0.27121374011039734
step: 220, loss: 0.18390926718711853
step: 230, loss: 0.33427464962005615
step: 240, loss: 0.4856986105442047
step: 250, loss: 0.3589233458042145
step: 260, loss: 0.24810852110385895
step: 270, loss: 0.26535525918006897
step: 280, loss: 0.19998987019062042
step: 290, loss: 0.2705925405025482
step: 300, loss: 0.26481661200523376
step: 310, loss: 0.2892136871814728
step: 320, loss: 0.18456070125102997
step: 330, loss: 0.28592562675476074
step: 340, loss: 0.24690759181976318
step: 350, loss: 0.3865761458873749
step: 360, loss: 0.6665361523628235
step: 370, loss: 0.4085666537284851
step: 380, loss: 0.24016152322292328
step: 390, loss: 0.12146014720201492
step: 400, loss: 0.23696812987327576
step: 410, loss: 0.26538175344467163
step: 420, loss: 0.37384796142578125
step: 430, loss: 0.2403399795293808
step: 440, loss: 0.2584913372993469
step: 450, loss: 0.06579229980707169
step: 460, loss: 0.24128670990467072
step: 470, loss: 0.4265885353088379
step: 480, loss: 0.26204073429107666
step: 490, loss: 0.2642834484577179
step: 500, loss: 0.2991172671318054
step: 510, loss: 0.21290962398052216
step: 520, loss: 0.33814218640327454
step: 530, loss: 0.1953602135181427
epoch 1: dev_f1=0.8385370205173952, f1=0.8165840468679586, best_f1=0.8165840468679586
step: 0, loss: 0.3199688196182251
step: 10, loss: 0.1505240648984909
step: 20, loss: 0.042991895228624344
step: 30, loss: 0.09667094051837921
step: 40, loss: 0.31180819869041443
step: 50, loss: 0.3705558776855469
step: 60, loss: 0.2447287142276764
step: 70, loss: 0.20800301432609558
step: 80, loss: 0.1641351729631424
step: 90, loss: 0.4802941381931305
step: 100, loss: 0.1347731500864029
step: 110, loss: 0.1863420307636261
step: 120, loss: 0.18663008511066437
step: 130, loss: 0.25098717212677
step: 140, loss: 0.39841902256011963
step: 150, loss: 0.25625962018966675
step: 160, loss: 0.16531556844711304
step: 170, loss: 0.2829713821411133
step: 180, loss: 0.14543545246124268
step: 190, loss: 0.11340408027172089
step: 200, loss: 0.11622704565525055
step: 210, loss: 0.137400820851326
step: 220, loss: 0.26272428035736084
step: 230, loss: 0.18890851736068726
step: 240, loss: 0.37558913230895996
step: 250, loss: 0.221317321062088
step: 260, loss: 0.10212606936693192
step: 270, loss: 0.24490594863891602
step: 280, loss: 0.2916926145553589
step: 290, loss: 0.15384283661842346
step: 300, loss: 0.17302602529525757
step: 310, loss: 0.09009387344121933
step: 320, loss: 0.11619935929775238
step: 330, loss: 0.21813073754310608
step: 340, loss: 0.21416549384593964
step: 350, loss: 0.28426316380500793
step: 360, loss: 0.2594809830188751
step: 370, loss: 0.15483923256397247
step: 380, loss: 0.26205310225486755
step: 390, loss: 0.28361979126930237
step: 400, loss: 0.12496345490217209
step: 410, loss: 0.1781412661075592
step: 420, loss: 0.15768735110759735
step: 430, loss: 0.2424941062927246
step: 440, loss: 0.07477037608623505
step: 450, loss: 0.24789896607398987
step: 460, loss: 0.24911662936210632
step: 470, loss: 0.279979407787323
step: 480, loss: 0.2671453356742859
step: 490, loss: 0.23325495421886444
step: 500, loss: 0.34745991230010986
step: 510, loss: 0.14862915873527527
step: 520, loss: 0.12177614122629166
step: 530, loss: 0.24373485147953033
epoch 2: dev_f1=0.8775877587758776, f1=0.8111824014665446, best_f1=0.8111824014665446
step: 0, loss: 0.26905936002731323
step: 10, loss: 0.11089898645877838
step: 20, loss: 0.09294852614402771
step: 30, loss: 0.017331194132566452
step: 40, loss: 0.07390962541103363
step: 50, loss: 0.07122288644313812
step: 60, loss: 0.08774591237306595
step: 70, loss: 0.2624428868293762
step: 80, loss: 0.03182050585746765
step: 90, loss: 0.07396665960550308
step: 100, loss: 0.23610396683216095
step: 110, loss: 0.02102498896420002
step: 120, loss: 0.11051696538925171
step: 130, loss: 0.16743452847003937
step: 140, loss: 0.1091121956706047
step: 150, loss: 0.12924008071422577
step: 160, loss: 0.15217310190200806
step: 170, loss: 0.1267450451850891
step: 180, loss: 0.060928840190172195
step: 190, loss: 0.2492324858903885
step: 200, loss: 0.2506897449493408
step: 210, loss: 0.1162445992231369
step: 220, loss: 0.21902593970298767
step: 230, loss: 0.28081974387168884
step: 240, loss: 0.11078911274671555
step: 250, loss: 0.19476498663425446
step: 260, loss: 0.1373511105775833
step: 270, loss: 0.04893884435296059
step: 280, loss: 0.16907909512519836
step: 290, loss: 0.07567714899778366
step: 300, loss: 0.07924272865056992
step: 310, loss: 0.12769946455955505
step: 320, loss: 0.25377240777015686
step: 330, loss: 0.11721839010715485
step: 340, loss: 0.09344016760587692
step: 350, loss: 0.2490675449371338
step: 360, loss: 0.1718037724494934
step: 370, loss: 0.22841361165046692
step: 380, loss: 0.38154366612434387
step: 390, loss: 0.11520382016897202
step: 400, loss: 0.0763123407959938
step: 410, loss: 0.2019461691379547
step: 420, loss: 0.1327115297317505
step: 430, loss: 0.25267088413238525
step: 440, loss: 0.2390098124742508
step: 450, loss: 0.2178911566734314
step: 460, loss: 0.16540561616420746
step: 470, loss: 0.15256908535957336
step: 480, loss: 0.43562036752700806
step: 490, loss: 0.1390513926744461
step: 500, loss: 0.1078658178448677
step: 510, loss: 0.13644817471504211
step: 520, loss: 0.12660793960094452
step: 530, loss: 0.23964793980121613
epoch 3: dev_f1=0.8622641509433963, f1=0.7381546134663343, best_f1=0.8111824014665446
step: 0, loss: 0.05514862760901451
step: 10, loss: 0.006033380050212145
step: 20, loss: 0.22497014701366425
step: 30, loss: 0.03599768504500389
step: 40, loss: 0.05640638619661331
step: 50, loss: 0.0913567841053009
step: 60, loss: 0.033921271562576294
step: 70, loss: 0.11258362233638763
step: 80, loss: 0.10579756647348404
step: 90, loss: 0.09437794238328934
step: 100, loss: 0.01917780190706253
step: 110, loss: 0.03613235056400299
step: 120, loss: 0.09466647356748581
step: 130, loss: 0.17801278829574585
step: 140, loss: 0.12881503999233246
step: 150, loss: 0.10806895047426224
step: 160, loss: 0.19876788556575775
step: 170, loss: 0.1424204558134079
step: 180, loss: 0.033614467829465866
step: 190, loss: 0.08839467912912369
step: 200, loss: 0.16094866394996643
step: 210, loss: 0.16210302710533142
step: 220, loss: 0.33005502820014954
step: 230, loss: 0.09846749901771545
step: 240, loss: 0.1739989072084427
step: 250, loss: 0.03550773113965988
step: 260, loss: 0.027128027752041817
step: 270, loss: 0.10382596403360367
step: 280, loss: 0.04049728065729141
step: 290, loss: 0.09851358085870743
step: 300, loss: 0.2576848864555359
step: 310, loss: 0.04698653891682625
step: 320, loss: 0.023551179096102715
step: 330, loss: 0.006565152667462826
step: 340, loss: 0.04899056628346443
step: 350, loss: 0.17643029987812042
step: 360, loss: 0.01459045335650444
step: 370, loss: 0.16787967085838318
step: 380, loss: 0.027362795546650887
step: 390, loss: 0.15737047791481018
step: 400, loss: 0.028257014229893684
step: 410, loss: 0.057447437196969986
step: 420, loss: 0.05113659426569939
step: 430, loss: 0.10606690496206284
step: 440, loss: 0.28362950682640076
step: 450, loss: 0.09184495359659195
step: 460, loss: 0.11012701690196991
step: 470, loss: 0.011093870736658573
step: 480, loss: 0.07798689603805542
step: 490, loss: 0.029900191351771355
step: 500, loss: 0.06255345046520233
step: 510, loss: 0.12202444672584534
step: 520, loss: 0.009589117020368576
step: 530, loss: 0.4098561704158783
epoch 4: dev_f1=0.8733874820831342, f1=0.7358684480986639, best_f1=0.8111824014665446
step: 0, loss: 0.06051211059093475
step: 10, loss: 0.01974061317741871
step: 20, loss: 0.04253297299146652
step: 30, loss: 0.013874221593141556
step: 40, loss: 0.21143315732479095
step: 50, loss: 0.03714917600154877
step: 60, loss: 0.08229226619005203
step: 70, loss: 0.07526671886444092
step: 80, loss: 0.027297645807266235
step: 90, loss: 0.05508238077163696
step: 100, loss: 0.03579302504658699
step: 110, loss: 0.06878231465816498
step: 120, loss: 0.0050926473923027515
step: 130, loss: 0.028679171577095985
step: 140, loss: 0.062315210700035095
step: 150, loss: 0.042267851531505585
step: 160, loss: 0.10580302029848099
step: 170, loss: 0.013312282972037792
step: 180, loss: 0.007854791358113289
step: 190, loss: 0.035842277109622955
step: 200, loss: 0.11236025393009186
step: 210, loss: 0.09837102890014648
step: 220, loss: 0.038355764001607895
step: 230, loss: 0.02293536625802517
step: 240, loss: 0.007565945386886597
step: 250, loss: 0.04082580655813217
step: 260, loss: 0.03802631050348282
step: 270, loss: 0.14599846303462982
step: 280, loss: 0.034627318382263184
step: 290, loss: 0.17411743104457855
step: 300, loss: 0.059716612100601196
step: 310, loss: 0.010369444265961647
step: 320, loss: 0.33296605944633484
step: 330, loss: 0.20856091380119324
step: 340, loss: 0.16834653913974762
step: 350, loss: 0.10777121037244797
step: 360, loss: 0.03760291635990143
step: 370, loss: 0.06900542229413986
step: 380, loss: 0.06729980558156967
step: 390, loss: 0.055223096162080765
step: 400, loss: 0.008327473886311054
step: 410, loss: 0.08828043192625046
step: 420, loss: 0.046516112983226776
step: 430, loss: 0.08472369611263275
step: 440, loss: 0.06336111575365067
step: 450, loss: 0.0707748681306839
step: 460, loss: 0.016966314986348152
step: 470, loss: 0.0945291519165039
step: 480, loss: 0.059703778475522995
step: 490, loss: 0.10591791570186615
step: 500, loss: 0.10402679443359375
step: 510, loss: 0.20685672760009766
step: 520, loss: 0.04038691893219948
step: 530, loss: 0.04965793341398239
epoch 5: dev_f1=0.8765719608756404, f1=0.7593582887700535, best_f1=0.8111824014665446
step: 0, loss: 0.014863185584545135
step: 10, loss: 0.019177449867129326
step: 20, loss: 0.08489732444286346
step: 30, loss: 0.009404018521308899
step: 40, loss: 0.1497516632080078
step: 50, loss: 0.16432222723960876
step: 60, loss: 0.09655927121639252
step: 70, loss: 0.00627578841522336
step: 80, loss: 0.15136276185512543
step: 90, loss: 0.09687936305999756
step: 100, loss: 0.025373853743076324
step: 110, loss: 0.1129697635769844
step: 120, loss: 0.06467179954051971
step: 130, loss: 0.08157489448785782
step: 140, loss: 0.03273599594831467
step: 150, loss: 0.038144346326589584
step: 160, loss: 0.0074906726367771626
step: 170, loss: 0.07228363305330276
step: 180, loss: 0.11351009458303452
step: 190, loss: 0.13450856506824493
step: 200, loss: 0.06573136895895004
step: 210, loss: 0.029943132773041725
step: 220, loss: 0.030889788642525673
step: 230, loss: 0.011059043928980827
step: 240, loss: 0.029812075197696686
step: 250, loss: 0.10154937952756882
step: 260, loss: 0.002970702014863491
step: 270, loss: 0.04024326428771019
step: 280, loss: 0.02619640715420246
step: 290, loss: 0.03236275911331177
step: 300, loss: 0.04068027436733246
step: 310, loss: 0.010080551728606224
step: 320, loss: 0.019440310075879097
step: 330, loss: 0.01702350564301014
step: 340, loss: 0.002993635833263397
step: 350, loss: 0.07070821523666382
step: 360, loss: 0.007458266336470842
step: 370, loss: 0.042003996670246124
step: 380, loss: 0.08339269459247589
step: 390, loss: 0.04465988650918007
step: 400, loss: 0.020844077691435814
step: 410, loss: 0.23705194890499115
step: 420, loss: 0.09346552938222885
step: 430, loss: 0.0072090160101652145
step: 440, loss: 0.0723319873213768
step: 450, loss: 0.042816292494535446
step: 460, loss: 0.03169146552681923
step: 470, loss: 0.06348362565040588
step: 480, loss: 0.10918806493282318
step: 490, loss: 0.03458588570356369
step: 500, loss: 0.023373430594801903
step: 510, loss: 0.09344379603862762
step: 520, loss: 0.07385426014661789
step: 530, loss: 0.03024309314787388
epoch 6: dev_f1=0.8832951945080092, f1=0.7580952380952383, best_f1=0.7580952380952383
step: 0, loss: 0.05457042157649994
step: 10, loss: 0.025664987042546272
step: 20, loss: 0.020605117082595825
step: 30, loss: 0.01823362335562706
step: 40, loss: 0.05192529782652855
step: 50, loss: 0.01504028495401144
step: 60, loss: 0.014884901233017445
step: 70, loss: 0.019279412925243378
step: 80, loss: 0.0017469048034399748
step: 90, loss: 0.014822608791291714
step: 100, loss: 0.05718646198511124
step: 110, loss: 0.03399690240621567
step: 120, loss: 0.002516675740480423
step: 130, loss: 0.016621362417936325
step: 140, loss: 0.012558156624436378
step: 150, loss: 0.002532342681661248
step: 160, loss: 0.2253943532705307
step: 170, loss: 0.005115906707942486
step: 180, loss: 0.004645108710974455
step: 190, loss: 0.0025104419328272343
step: 200, loss: 0.004794061183929443
step: 210, loss: 0.054017964750528336
step: 220, loss: 0.012469531036913395
step: 230, loss: 0.012788535095751286
step: 240, loss: 0.010933098383247852
step: 250, loss: 0.0478275828063488
step: 260, loss: 0.0054214028641581535
step: 270, loss: 0.005497003439813852
step: 280, loss: 0.04645576700568199
step: 290, loss: 0.015371667221188545
step: 300, loss: 0.050234243273735046
step: 310, loss: 0.04696270078420639
step: 320, loss: 0.007571361493319273
step: 330, loss: 0.0020097270607948303
step: 340, loss: 0.033594269305467606
step: 350, loss: 0.023060202598571777
step: 360, loss: 0.0036342439707368612
step: 370, loss: 0.0052761901170015335
step: 380, loss: 0.011356621980667114
step: 390, loss: 0.012308725155889988
step: 400, loss: 0.057931359857320786
step: 410, loss: 0.20496372878551483
step: 420, loss: 0.021200906485319138
step: 430, loss: 0.0663428083062172
step: 440, loss: 0.027357133105397224
step: 450, loss: 0.05018932744860649
step: 460, loss: 0.10274489223957062
step: 470, loss: 0.006014538928866386
step: 480, loss: 0.24630819261074066
step: 490, loss: 0.01888955384492874
step: 500, loss: 0.017169438302516937
step: 510, loss: 0.01593293435871601
step: 520, loss: 0.01641238108277321
step: 530, loss: 0.013097903691232204
epoch 7: dev_f1=0.8811381367599815, f1=0.7655272026961965, best_f1=0.7580952380952383
step: 0, loss: 0.01719006709754467
step: 10, loss: 0.0038667405024170876
step: 20, loss: 0.027083709836006165
step: 30, loss: 0.0021022220607846975
step: 40, loss: 0.07135244458913803
step: 50, loss: 0.022907748818397522
step: 60, loss: 0.004964884836226702
step: 70, loss: 0.0012317446526139975
step: 80, loss: 0.0516267791390419
step: 90, loss: 0.0036999310832470655
step: 100, loss: 0.0007460590568371117
step: 110, loss: 0.0026754180435091257
step: 120, loss: 0.020881814882159233
step: 130, loss: 0.04930778965353966
step: 140, loss: 0.024836717173457146
step: 150, loss: 0.0035733298864215612
step: 160, loss: 0.049134910106658936
step: 170, loss: 0.06919186562299728
step: 180, loss: 0.03264371305704117
step: 190, loss: 0.0005837104981765151
step: 200, loss: 0.003798685735091567
step: 210, loss: 0.0157533697783947
step: 220, loss: 0.20869208872318268
step: 230, loss: 0.02721482515335083
step: 240, loss: 0.013514075428247452
step: 250, loss: 0.0354890301823616
step: 260, loss: 0.003909626044332981
step: 270, loss: 0.0010121342493221164
step: 280, loss: 0.04327903687953949
step: 290, loss: 0.03278367966413498
step: 300, loss: 0.020324893295764923
step: 310, loss: 0.01452354434877634
step: 320, loss: 0.015268546529114246
step: 330, loss: 0.020808402448892593
step: 340, loss: 0.022372687235474586
step: 350, loss: 0.029788076877593994
step: 360, loss: 0.0018939522560685873
step: 370, loss: 0.01419430784881115
step: 380, loss: 0.015701068565249443
step: 390, loss: 0.0008251610561273992
step: 400, loss: 0.003023226046934724
step: 410, loss: 0.11212241649627686
step: 420, loss: 0.001983834197744727
step: 430, loss: 0.012228304520249367
step: 440, loss: 0.009444321505725384
step: 450, loss: 0.13310390710830688
step: 460, loss: 0.007821902632713318
step: 470, loss: 0.008649450726807117
step: 480, loss: 0.006201610434800386
step: 490, loss: 0.0021674102172255516
step: 500, loss: 0.0022185847628861666
step: 510, loss: 0.00015437872207257897
step: 520, loss: 0.022869393229484558
step: 530, loss: 0.003690449520945549
epoch 8: dev_f1=0.8671769473210267, f1=0.7292555713608345, best_f1=0.7580952380952383
step: 0, loss: 0.00041534053161740303
step: 10, loss: 0.0003430906217545271
step: 20, loss: 0.0010460340417921543
step: 30, loss: 0.0008660643943585455
step: 40, loss: 0.0025327035691589117
step: 50, loss: 0.01381324976682663
step: 60, loss: 0.025739450007677078
step: 70, loss: 0.0029924095142632723
step: 80, loss: 0.052940063178539276
step: 90, loss: 0.0004380699247121811
step: 100, loss: 0.0022457002196460962
step: 110, loss: 0.09688197821378708
step: 120, loss: 0.001530709327198565
step: 130, loss: 0.0004018023610115051
step: 140, loss: 0.008772582747042179
step: 150, loss: 0.002572200261056423
step: 160, loss: 0.19694072008132935
step: 170, loss: 0.00014311107224784791
step: 180, loss: 0.0016200578538700938
step: 190, loss: 0.0017470287857577205
step: 200, loss: 0.0001737808488542214
step: 210, loss: 0.005739114712923765
step: 220, loss: 0.0013507145922631025
step: 230, loss: 0.005205488298088312
step: 240, loss: 0.013346794061362743
step: 250, loss: 0.03362211585044861
step: 260, loss: 0.01779129169881344
step: 270, loss: 0.012529981322586536
step: 280, loss: 0.008108248002827168
step: 290, loss: 0.015925787389278412
step: 300, loss: 0.019890516996383667
step: 310, loss: 0.0041100080125033855
step: 320, loss: 0.0033788892906159163
step: 330, loss: 0.02463582344353199
step: 340, loss: 0.011095983907580376
step: 350, loss: 0.0008549845078960061
step: 360, loss: 0.007439108099788427
step: 370, loss: 0.0011328659020364285
step: 380, loss: 0.1366277039051056
step: 390, loss: 0.05052880197763443
step: 400, loss: 0.009357016533613205
step: 410, loss: 0.13274861872196198
step: 420, loss: 0.021601369604468346
step: 430, loss: 0.007934891618788242
step: 440, loss: 0.06514443457126617
step: 450, loss: 0.001592828193679452
step: 460, loss: 0.02105327695608139
step: 470, loss: 0.0039584399200975895
step: 480, loss: 0.010593049228191376
step: 490, loss: 0.0231851227581501
step: 500, loss: 0.004998072981834412
step: 510, loss: 0.0314917154610157
step: 520, loss: 0.034701891243457794
step: 530, loss: 0.18184123933315277
epoch 9: dev_f1=0.8472647702407001, f1=0.7357980162308386, best_f1=0.7580952380952383
step: 0, loss: 0.0011863884283229709
step: 10, loss: 0.0014891332248225808
step: 20, loss: 0.01446943636983633
step: 30, loss: 0.012198011390864849
step: 40, loss: 0.0010107278358191252
step: 50, loss: 0.0016961682122200727
step: 60, loss: 0.0004882696084678173
step: 70, loss: 0.0002544843591749668
step: 80, loss: 9.563479397911578e-05
step: 90, loss: 0.0017273855628445745
step: 100, loss: 0.03215780481696129
step: 110, loss: 0.0006735531496815383
step: 120, loss: 0.009534868411719799
step: 130, loss: 0.002947775414213538
step: 140, loss: 0.142482727766037
step: 150, loss: 0.009497029706835747
step: 160, loss: 0.011950076557695866
step: 170, loss: 0.007277398370206356
step: 180, loss: 0.0890287235379219
step: 190, loss: 0.0025533847510814667
step: 200, loss: 0.013652754947543144
step: 210, loss: 0.00011168897617608309
step: 220, loss: 0.07337258011102676
step: 230, loss: 0.039251018315553665
step: 240, loss: 0.0011944733560085297
step: 250, loss: 0.05395015329122543
step: 260, loss: 0.0001999598171096295
step: 270, loss: 0.00268506514839828
step: 280, loss: 0.0014420155202969909
step: 290, loss: 0.050595104694366455
step: 300, loss: 0.0005093036452308297
step: 310, loss: 0.000665360304992646
step: 320, loss: 0.026680240407586098
step: 330, loss: 0.0016487200045958161
step: 340, loss: 0.013508054427802563
step: 350, loss: 0.00037512651761062443
step: 360, loss: 0.011397883296012878
step: 370, loss: 0.006456044968217611
step: 380, loss: 0.0042106276378035545
step: 390, loss: 0.02207999862730503
step: 400, loss: 0.02699197456240654
step: 410, loss: 0.0381629578769207
step: 420, loss: 0.012304022908210754
step: 430, loss: 0.0031053621787577868
step: 440, loss: 0.0015901931328698993
step: 450, loss: 0.001409210148267448
step: 460, loss: 0.00034737621899694204
step: 470, loss: 0.013464818708598614
step: 480, loss: 0.062408458441495895
step: 490, loss: 0.00010814141569426283
step: 500, loss: 0.00509306276217103
step: 510, loss: 0.0021742917597293854
step: 520, loss: 0.03788651525974274
step: 530, loss: 0.005823805928230286
epoch 10: dev_f1=0.8637002341920375, f1=0.7300492610837438, best_f1=0.7580952380952383
step: 0, loss: 0.0008452639449387789
step: 10, loss: 0.002628705929964781
step: 20, loss: 0.0009136802982538939
step: 30, loss: 0.00590041559189558
step: 40, loss: 0.00035643819137476385
step: 50, loss: 0.13998165726661682
step: 60, loss: 0.06931725889444351
step: 70, loss: 0.0007658788235858083
step: 80, loss: 0.0034984068479388952
step: 90, loss: 0.005758919753134251
step: 100, loss: 0.0019116827752441168
step: 110, loss: 0.0032563076820224524
step: 120, loss: 0.0029809530824422836
step: 130, loss: 0.0007492535514757037
step: 140, loss: 0.00026177166728302836
step: 150, loss: 0.022420469671487808
step: 160, loss: 5.953427171334624e-05
step: 170, loss: 0.00027301794034428895
step: 180, loss: 0.004508808720856905
step: 190, loss: 9.771715122042224e-05
step: 200, loss: 0.001543054822832346
step: 210, loss: 0.0003151123528368771
step: 220, loss: 0.013333133421838284
step: 230, loss: 0.0007568871369585395
step: 240, loss: 0.007203185930848122
step: 250, loss: 0.0046449024230241776
step: 260, loss: 0.019762925803661346
step: 270, loss: 0.00023515892098657787
step: 280, loss: 0.0010197351220995188
step: 290, loss: 0.0003236921620555222
step: 300, loss: 0.0025829218793660402
step: 310, loss: 0.0009774636710062623
step: 320, loss: 0.0002499017573427409
step: 330, loss: 0.2195974737405777
step: 340, loss: 0.0019052957650274038
step: 350, loss: 0.000552691868506372
step: 360, loss: 0.00036125758197158575
step: 370, loss: 0.005778973922133446
step: 380, loss: 0.008163630962371826
step: 390, loss: 0.00016504332597833127
step: 400, loss: 0.013101010583341122
step: 410, loss: 0.05233234912157059
step: 420, loss: 0.006557505577802658
step: 430, loss: 0.000394131027860567
step: 440, loss: 0.00022726536553818733
step: 450, loss: 8.709151006769389e-05
step: 460, loss: 0.0017821796936914325
step: 470, loss: 0.0002882402332033962
step: 480, loss: 0.004702769685536623
step: 490, loss: 0.01614135503768921
step: 500, loss: 0.0009216543985530734
step: 510, loss: 0.00019666577281896025
step: 520, loss: 0.0015616498421877623
step: 530, loss: 0.05913151055574417
epoch 11: dev_f1=0.8623853211009174, f1=0.7238842569887199, best_f1=0.7580952380952383
step: 0, loss: 0.00013755395775660872
step: 10, loss: 0.0054954709485173225
step: 20, loss: 0.001001534634269774
step: 30, loss: 0.00020753049466293305
step: 40, loss: 0.005701466463506222
step: 50, loss: 0.001285851001739502
step: 60, loss: 0.0001264442689716816
step: 70, loss: 0.004037083126604557
step: 80, loss: 0.00010077529441332445
step: 90, loss: 0.0008522204589098692
step: 100, loss: 0.0014771247515454888
step: 110, loss: 0.003700902918353677
step: 120, loss: 0.0029921059031039476
step: 130, loss: 0.0016845236532390118
step: 140, loss: 0.0002899190003518015
step: 150, loss: 0.0012501293094828725
step: 160, loss: 6.327976734610274e-05
step: 170, loss: 0.0007847485831007361
step: 180, loss: 0.010611012578010559
step: 190, loss: 0.00019833706028293818
step: 200, loss: 0.0005882953992113471
step: 210, loss: 0.014102594926953316
step: 220, loss: 0.005431431345641613
step: 230, loss: 0.0003736386715900153
step: 240, loss: 0.00030960343428887427
step: 250, loss: 0.00010332833335269243
step: 260, loss: 0.012781965546309948
step: 270, loss: 0.005947479046881199
step: 280, loss: 0.005081406328827143
step: 290, loss: 0.13933256268501282
step: 300, loss: 0.0016031446866691113
step: 310, loss: 0.0021131818648427725
step: 320, loss: 0.0010836746077984571
step: 330, loss: 0.0002819729270413518
step: 340, loss: 0.0003844682942144573
step: 350, loss: 0.0007175629143603146
step: 360, loss: 0.0007905742386355996
step: 370, loss: 0.0990326926112175
step: 380, loss: 0.013401848264038563
step: 390, loss: 0.05632641538977623
step: 400, loss: 0.028470931574702263
step: 410, loss: 0.0158404391258955
step: 420, loss: 0.00014761494821868837
step: 430, loss: 0.005042249336838722
step: 440, loss: 0.0009336115908809006
step: 450, loss: 0.03131817653775215
step: 460, loss: 0.012455759570002556
step: 470, loss: 0.024887176230549812
step: 480, loss: 0.00031365742324851453
step: 490, loss: 0.000141655866173096
step: 500, loss: 0.0002015548961935565
step: 510, loss: 0.005823948420584202
step: 520, loss: 0.00283212773501873
step: 530, loss: 0.0017826760886237025
epoch 12: dev_f1=0.855721393034826, f1=0.7256300523062291, best_f1=0.7580952380952383
step: 0, loss: 0.012828854843974113
step: 10, loss: 0.0015751358587294817
step: 20, loss: 0.007863491773605347
step: 30, loss: 0.0012816328089684248
step: 40, loss: 0.00013766651682090014
step: 50, loss: 0.0006301848916336894
step: 60, loss: 0.0009403267758898437
step: 70, loss: 0.0014448785223066807
step: 80, loss: 0.0014174802927300334
step: 90, loss: 0.00062355468980968
step: 100, loss: 0.0002821316884364933
step: 110, loss: 0.00048285661614499986
step: 120, loss: 0.00010234313958790153
step: 130, loss: 0.00010198913514614105
step: 140, loss: 0.00020375636813696474
step: 150, loss: 0.0012364840367808938
step: 160, loss: 0.0001393052953062579
step: 170, loss: 0.028277700766921043
step: 180, loss: 0.0038772106636315584
step: 190, loss: 0.00020024988043587655
step: 200, loss: 0.007492908276617527
step: 210, loss: 0.000733987195417285
step: 220, loss: 6.89634180162102e-05
step: 230, loss: 0.0013292974326759577
step: 240, loss: 5.321919888956472e-05
step: 250, loss: 0.0006770283216610551
step: 260, loss: 0.005456971004605293
step: 270, loss: 0.00018756395729724318
step: 280, loss: 0.004765180870890617
step: 290, loss: 0.000774442742113024
step: 300, loss: 4.913390148431063e-05
step: 310, loss: 0.0007816749275662005
step: 320, loss: 5.481495463754982e-05
step: 330, loss: 0.0016939364140853286
step: 340, loss: 0.001718516112305224
step: 350, loss: 4.8812922614160925e-05
step: 360, loss: 0.0001506407861597836
step: 370, loss: 0.0040002851746976376
step: 380, loss: 0.000133110472233966
step: 390, loss: 0.0007143609691411257
step: 400, loss: 0.004971921909600496
step: 410, loss: 8.769116539042443e-05
step: 420, loss: 0.0012906041229143739
step: 430, loss: 0.00023247643548529595
step: 440, loss: 0.003015827154740691
step: 450, loss: 0.04246281087398529
step: 460, loss: 9.447902266401798e-05
step: 470, loss: 0.001666491269133985
step: 480, loss: 0.0014599639689549804
step: 490, loss: 0.0033265191596001387
step: 500, loss: 8.967450412455946e-05
step: 510, loss: 0.00014693754201289266
step: 520, loss: 0.0005752297001890838
step: 530, loss: 0.00015239125059451908
epoch 13: dev_f1=0.8638239339752406, f1=0.7298988926336063, best_f1=0.7580952380952383
step: 0, loss: 0.00023698904260527343
step: 10, loss: 6.341523840092123e-05
step: 20, loss: 0.00022120578796602786
step: 30, loss: 0.008630406111478806
step: 40, loss: 0.00044820740004070103
step: 50, loss: 0.001877904636785388
step: 60, loss: 0.0728347972035408
step: 70, loss: 0.0003397600376047194
step: 80, loss: 9.180721099255607e-05
step: 90, loss: 0.007856898941099644
step: 100, loss: 6.169613334350288e-05
step: 110, loss: 0.00015691971930209547
step: 120, loss: 0.0001923790987348184
step: 130, loss: 0.0003677040513139218
step: 140, loss: 0.002906546927988529
step: 150, loss: 6.056824349798262e-05
step: 160, loss: 0.007781210821121931
step: 170, loss: 0.018770016729831696
step: 180, loss: 0.0010084515670314431
step: 190, loss: 0.00011337828618707135
step: 200, loss: 0.008412291295826435
step: 210, loss: 0.0004672138602472842
step: 220, loss: 0.0005105368327349424
step: 230, loss: 5.609626168734394e-05
step: 240, loss: 0.03141403943300247
step: 250, loss: 4.432754576555453e-05
step: 260, loss: 0.004020374733954668
step: 270, loss: 5.14658895554021e-05
step: 280, loss: 0.006635288707911968
step: 290, loss: 5.4854848713148385e-05
step: 300, loss: 5.778990816907026e-05
step: 310, loss: 5.0498954806244e-05
step: 320, loss: 0.00038765696808695793
step: 330, loss: 0.0010665254667401314
step: 340, loss: 0.0032597589306533337
step: 350, loss: 0.00012743991101160645
step: 360, loss: 0.009843146428465843
step: 370, loss: 0.0002464700664859265
step: 380, loss: 0.00018709916912484914
step: 390, loss: 0.004801650531589985
step: 400, loss: 0.00012274573964532465
step: 410, loss: 0.004999190103262663
step: 420, loss: 0.0007815543212927878
step: 430, loss: 0.03505692258477211
step: 440, loss: 0.0007643146673217416
step: 450, loss: 0.11390016973018646
step: 460, loss: 0.003701007692143321
step: 470, loss: 0.04033641889691353
step: 480, loss: 0.0025360207073390484
step: 490, loss: 6.806630699429661e-05
step: 500, loss: 3.74971677956637e-05
step: 510, loss: 0.001231127418577671
step: 520, loss: 0.009369351901113987
step: 530, loss: 0.0001454213197575882
epoch 14: dev_f1=0.868515205724508, f1=0.7454630060493251, best_f1=0.7580952380952383
step: 0, loss: 0.0005479940446093678
step: 10, loss: 0.0008385007968172431
step: 20, loss: 0.004653776530176401
step: 30, loss: 3.1844727345742285e-05
step: 40, loss: 0.0002058815589407459
step: 50, loss: 0.0016677079256623983
step: 60, loss: 0.0014887352008372545
step: 70, loss: 0.0021022481378167868
step: 80, loss: 0.0005719169275835156
step: 90, loss: 3.195083627360873e-05
step: 100, loss: 0.00035724358167499304
step: 110, loss: 0.0005109118646942079
step: 120, loss: 0.00035180518170818686
step: 130, loss: 0.000276066770311445
step: 140, loss: 0.002051076153293252
step: 150, loss: 0.015497379936277866
step: 160, loss: 0.004714666865766048
step: 170, loss: 0.0003175599849782884
step: 180, loss: 5.315435191732831e-05
step: 190, loss: 0.0005768533446826041
step: 200, loss: 0.006472198758274317
step: 210, loss: 0.0006398386904038489
step: 220, loss: 0.005186325870454311
step: 230, loss: 0.0002543065929785371
step: 240, loss: 0.0005667149089276791
step: 250, loss: 0.00034114334266632795
step: 260, loss: 0.00019325911125633866
step: 270, loss: 5.0996008212678134e-05
step: 280, loss: 0.001754788332618773
step: 290, loss: 0.00018515379633754492
step: 300, loss: 0.005770455580204725
step: 310, loss: 0.002098632510751486
step: 320, loss: 0.03638455644249916
step: 330, loss: 0.0009879379067569971
step: 340, loss: 0.0008773402078077197
step: 350, loss: 0.004727629013359547
step: 360, loss: 0.00042481417767703533
step: 370, loss: 9.351876360597089e-05
step: 380, loss: 0.00021474985987879336
step: 390, loss: 0.0002886632864829153
step: 400, loss: 0.0006733884802088141
step: 410, loss: 0.07463927567005157
step: 420, loss: 0.0002574001264292747
step: 430, loss: 0.023949917405843735
step: 440, loss: 0.00010728785855462775
step: 450, loss: 3.91055982618127e-05
step: 460, loss: 0.003599771298468113
step: 470, loss: 0.0005750813870690763
step: 480, loss: 0.0007663947762921453
step: 490, loss: 0.0009915066184476018
step: 500, loss: 6.100214159232564e-05
step: 510, loss: 3.525455031194724e-05
step: 520, loss: 0.00918625108897686
step: 530, loss: 0.000940944766625762
epoch 15: dev_f1=0.8687910028116212, f1=0.7279046673286991, best_f1=0.7580952380952383
step: 0, loss: 0.0006575345178134739
step: 10, loss: 4.2312367440899834e-05
step: 20, loss: 5.315257658367045e-05
step: 30, loss: 0.00017482819384895265
step: 40, loss: 0.0017003144603222609
step: 50, loss: 0.0003342562122270465
step: 60, loss: 0.00011263693158980459
step: 70, loss: 6.380753620760515e-05
step: 80, loss: 0.0010943259112536907
step: 90, loss: 4.883224028162658e-05
step: 100, loss: 0.00026093923952430487
step: 110, loss: 8.027935837162659e-05
step: 120, loss: 0.00042830611346289515
step: 130, loss: 4.4223703298484907e-05
step: 140, loss: 0.0003603692748583853
step: 150, loss: 0.00010465861123520881
step: 160, loss: 2.6184285161434673e-05
step: 170, loss: 3.494922930258326e-05
step: 180, loss: 0.00012778233212884516
step: 190, loss: 5.353233791538514e-05
step: 200, loss: 0.0003462715249042958
step: 210, loss: 2.5755825845408253e-05
step: 220, loss: 2.0637779016396962e-05
step: 230, loss: 3.325423676869832e-05
step: 240, loss: 0.00038682325975969434
step: 250, loss: 0.00021215529704932123
step: 260, loss: 0.002442918485030532
step: 270, loss: 0.07211057841777802
step: 280, loss: 0.0012046009069308639
step: 290, loss: 0.00025259898393414915
step: 300, loss: 8.628039358882234e-05
step: 310, loss: 0.000303298031212762
step: 320, loss: 0.0009246424306184053
step: 330, loss: 0.00047082314267754555
step: 340, loss: 7.079751958372071e-05
step: 350, loss: 0.0022268507163971663
step: 360, loss: 0.00012100177264073864
step: 370, loss: 0.00021115555136930197
step: 380, loss: 0.00012561139010358602
step: 390, loss: 7.527064008172601e-05
step: 400, loss: 0.0016920133493840694
step: 410, loss: 6.616881000809371e-05
step: 420, loss: 0.031100396066904068
step: 430, loss: 0.0036110742948949337
step: 440, loss: 3.398413537070155e-05
step: 450, loss: 0.00012083463661838323
step: 460, loss: 9.612314897822216e-05
step: 470, loss: 6.938012666068971e-05
step: 480, loss: 0.0056583392433822155
step: 490, loss: 0.0019788495264947414
step: 500, loss: 3.4936805604957044e-05
step: 510, loss: 0.0006564220529980958
step: 520, loss: 0.003571930807083845
step: 530, loss: 6.075745477573946e-05
epoch 16: dev_f1=0.8674807779285392, f1=0.7342491710090004, best_f1=0.7580952380952383
step: 0, loss: 0.008443448692560196
step: 10, loss: 2.994259739352856e-05
step: 20, loss: 0.00015414679364766926
step: 30, loss: 0.08069484680891037
step: 40, loss: 0.0003266431740485132
step: 50, loss: 5.2749994210898876e-05
step: 60, loss: 0.00387017079629004
step: 70, loss: 0.0007806881330907345
step: 80, loss: 0.0007307738997042179
step: 90, loss: 0.00016717269318178296
step: 100, loss: 6.226592813618481e-05
step: 110, loss: 4.177867958787829e-05
step: 120, loss: 3.295978604000993e-05
step: 130, loss: 0.007930214516818523
step: 140, loss: 0.00024209916591644287
step: 150, loss: 0.000794983992818743
step: 160, loss: 7.851632835809141e-05
step: 170, loss: 0.00017260741151403636
step: 180, loss: 6.322694389382377e-05
step: 190, loss: 0.00012690281437244266
step: 200, loss: 0.00022924445511307567
step: 210, loss: 2.699233482417185e-05
step: 220, loss: 0.0020230519585311413
step: 230, loss: 0.043727289885282516
step: 240, loss: 5.936858360655606e-05
step: 250, loss: 0.0003080868918914348
step: 260, loss: 6.188629049574956e-05
step: 270, loss: 6.936176941962913e-05
step: 280, loss: 5.458998566609807e-05
step: 290, loss: 0.06889384239912033
step: 300, loss: 6.766697333659977e-05
step: 310, loss: 0.010039775632321835
step: 320, loss: 0.007618612144142389
step: 330, loss: 0.016096163541078568
step: 340, loss: 0.014242702163755894
step: 350, loss: 5.8689274737844244e-05
step: 360, loss: 0.004191935528069735
step: 370, loss: 2.6224623070447706e-05
step: 380, loss: 1.8145659851143137e-05
step: 390, loss: 0.00019722015713341534
step: 400, loss: 2.5051906050066464e-05
step: 410, loss: 6.891880912007764e-05
step: 420, loss: 0.0001357791043119505
step: 430, loss: 0.023695632815361023
step: 440, loss: 0.0006104628555476665
step: 450, loss: 6.875369581393898e-05
step: 460, loss: 0.0034408981446176767
step: 470, loss: 0.00012495138798840344
step: 480, loss: 0.00014120568812359124
step: 490, loss: 5.267760934657417e-05
step: 500, loss: 0.008648743852972984
step: 510, loss: 5.5566022638231516e-05
step: 520, loss: 0.00010237479000352323
step: 530, loss: 4.258889384800568e-05
epoch 17: dev_f1=0.8697674418604651, f1=0.7258304412493803, best_f1=0.7580952380952383
step: 0, loss: 2.9977791200508364e-05
step: 10, loss: 5.06690121255815e-05
step: 20, loss: 0.0004006338713224977
step: 30, loss: 5.664084528689273e-05
step: 40, loss: 0.0006640718202106655
step: 50, loss: 3.162261418765411e-05
step: 60, loss: 7.637543603777885e-05
step: 70, loss: 0.000312044401653111
step: 80, loss: 0.005016991402953863
step: 90, loss: 0.0005139465210959315
step: 100, loss: 4.681927021010779e-05
step: 110, loss: 0.0026520106475800276
step: 120, loss: 3.4065677027683705e-05
step: 130, loss: 0.01065565925091505
step: 140, loss: 7.429937977576628e-05
step: 150, loss: 5.344858072930947e-05
step: 160, loss: 0.0004648526373784989
step: 170, loss: 0.00021232689323369414
step: 180, loss: 0.010339472442865372
step: 190, loss: 3.543672210071236e-05
step: 200, loss: 0.0002250831894343719
step: 210, loss: 0.00015326030552387238
step: 220, loss: 0.00011029711458832026
step: 230, loss: 0.00024918856797739863
step: 240, loss: 6.505608325824142e-05
step: 250, loss: 0.00010482274956302717
step: 260, loss: 4.1551367758074775e-05
step: 270, loss: 0.0024273754097521305
step: 280, loss: 2.5070537958526984e-05
step: 290, loss: 0.00025823243777267635
step: 300, loss: 3.286328865215182e-05
step: 310, loss: 3.68482869816944e-05
step: 320, loss: 0.00010486996325198561
step: 330, loss: 0.0001835664443206042
step: 340, loss: 0.0002087450702674687
step: 350, loss: 3.589527841540985e-05
step: 360, loss: 8.210176747525111e-05
step: 370, loss: 0.001402430352754891
step: 380, loss: 0.006469231564551592
step: 390, loss: 0.06648500263690948
step: 400, loss: 3.5444933018879965e-05
step: 410, loss: 6.0654350818367675e-05
step: 420, loss: 2.602778113214299e-05
step: 430, loss: 0.0003278427757322788
step: 440, loss: 0.00010543875396251678
step: 450, loss: 0.001744515961036086
step: 460, loss: 5.688376768375747e-05
step: 470, loss: 1.9903862266801298e-05
step: 480, loss: 5.638570655719377e-05
step: 490, loss: 3.183830267516896e-05
step: 500, loss: 0.0001164115674328059
step: 510, loss: 2.464192220941186e-05
step: 520, loss: 0.0019377643475309014
step: 530, loss: 3.9717509935144335e-05
epoch 18: dev_f1=0.8696461824953444, f1=0.718562874251497, best_f1=0.7580952380952383
step: 0, loss: 0.08683013170957565
step: 10, loss: 5.8529258240014315e-05
step: 20, loss: 6.021639273967594e-05
step: 30, loss: 4.750867810798809e-05
step: 40, loss: 0.0001000019401544705
step: 50, loss: 0.014593701809644699
step: 60, loss: 3.295821443316527e-05
step: 70, loss: 0.0002870876051019877
step: 80, loss: 5.684485222445801e-05
step: 90, loss: 0.00017396430484950542
step: 100, loss: 2.7659087209030986e-05
step: 110, loss: 0.0015747654251754284
step: 120, loss: 3.1170515285339206e-05
step: 130, loss: 0.00014361827925313264
step: 140, loss: 0.004466376267373562
step: 150, loss: 0.0038558251690119505
step: 160, loss: 1.7076532458304428e-05
step: 170, loss: 3.961917900596745e-05
step: 180, loss: 3.2325024221790954e-05
step: 190, loss: 0.001035587745718658
step: 200, loss: 0.0007532099261879921
step: 210, loss: 4.011344208265655e-05
step: 220, loss: 2.731654967647046e-05
step: 230, loss: 3.7208727007964626e-05
step: 240, loss: 0.04174860194325447
step: 250, loss: 5.590596265392378e-05
step: 260, loss: 4.3718970118789e-05
step: 270, loss: 3.7138288462301716e-05
step: 280, loss: 0.07044747471809387
step: 290, loss: 3.3294232707703486e-05
step: 300, loss: 0.00012090005475329235
step: 310, loss: 0.00016190837777685374
step: 320, loss: 0.00010750137880677357
step: 330, loss: 0.000535801809746772
step: 340, loss: 9.53431663219817e-05
step: 350, loss: 0.00015159582835622132
step: 360, loss: 8.971659553935751e-05
step: 370, loss: 0.00031715838122181594
step: 380, loss: 2.5640612875577062e-05
step: 390, loss: 4.238792826072313e-05
step: 400, loss: 1.6633221093798056e-05
step: 410, loss: 0.00011502786219352856
step: 420, loss: 8.160420111380517e-05
step: 430, loss: 6.024917820468545e-05
step: 440, loss: 2.4128072254825383e-05
step: 450, loss: 2.012374716287013e-05
step: 460, loss: 4.83591684314888e-05
step: 470, loss: 0.00015788822202011943
step: 480, loss: 3.459985600784421e-05
step: 490, loss: 6.363974534906447e-05
step: 500, loss: 0.0011951562482863665
step: 510, loss: 0.00013038801262155175
step: 520, loss: 4.8250331019517034e-05
step: 530, loss: 4.6997440222185105e-05
epoch 19: dev_f1=0.8679073990013618, f1=0.7264916467780429, best_f1=0.7580952380952383
step: 0, loss: 2.7748727006837726e-05
step: 10, loss: 4.608951348927803e-05
step: 20, loss: 5.322049401002005e-05
step: 30, loss: 0.0011950702173635364
step: 40, loss: 2.7465175662655383e-05
step: 50, loss: 0.00010037956963060424
step: 60, loss: 2.1445795937324874e-05
step: 70, loss: 2.0947021766914986e-05
step: 80, loss: 3.442717206780799e-05
step: 90, loss: 0.00015876954421401024
step: 100, loss: 5.75975573156029e-05
step: 110, loss: 1.9896418962161988e-05
step: 120, loss: 5.853715629200451e-05
step: 130, loss: 3.2425996323581785e-05
step: 140, loss: 0.0002063143183477223
step: 150, loss: 0.003431362798437476
step: 160, loss: 6.532917177537456e-05
step: 170, loss: 3.6428442399483174e-05
step: 180, loss: 0.0006736315554007888
step: 190, loss: 0.00048252628766931593
step: 200, loss: 0.0007704662857577205
step: 210, loss: 2.3862850866862573e-05
step: 220, loss: 0.00014469449524767697
step: 230, loss: 2.334967393835541e-05
step: 240, loss: 2.4929004212026484e-05
step: 250, loss: 0.00047549366718158126
step: 260, loss: 0.00011749187979148701
step: 270, loss: 1.9672830603667535e-05
step: 280, loss: 0.00018107345385942608
step: 290, loss: 3.312380795250647e-05
step: 300, loss: 6.705264240736142e-05
step: 310, loss: 0.006233702879399061
step: 320, loss: 4.0624887333251536e-05
step: 330, loss: 6.138379831099883e-05
step: 340, loss: 0.00020911329193040729
step: 350, loss: 0.00021578857558779418
step: 360, loss: 5.922860509599559e-05
step: 370, loss: 0.00016654731007292867
step: 380, loss: 0.0027067321352660656
step: 390, loss: 8.099815750028938e-05
step: 400, loss: 4.753087705466896e-05
step: 410, loss: 4.569007796817459e-05
step: 420, loss: 6.382737774401903e-05
step: 430, loss: 0.0001468497939640656
step: 440, loss: 3.088166704401374e-05
step: 450, loss: 1.9471804989734665e-05
step: 460, loss: 4.79751979582943e-05
step: 470, loss: 0.001545172417536378
step: 480, loss: 0.0002888066810555756
step: 490, loss: 0.07423631101846695
step: 500, loss: 3.418531559873372e-05
step: 510, loss: 0.00014232621470000595
step: 520, loss: 3.136200757580809e-05
step: 530, loss: 0.00014081985864322633
epoch 20: dev_f1=0.8693284936479129, f1=0.7290076335877862, best_f1=0.7580952380952383
