cuda
Device: cuda
step: 0, loss: 0.924832284450531
step: 10, loss: 0.4017649292945862
step: 20, loss: 0.441639244556427
step: 30, loss: 0.35369807481765747
step: 40, loss: 0.3532003164291382
step: 50, loss: 0.4719083607196808
step: 60, loss: 0.5123034715652466
step: 70, loss: 0.47223350405693054
step: 80, loss: 0.2091848999261856
step: 90, loss: 0.36808520555496216
step: 100, loss: 0.2513265609741211
step: 110, loss: 0.290676474571228
step: 120, loss: 0.18815405666828156
step: 130, loss: 0.26785826683044434
step: 140, loss: 0.15324805676937103
step: 150, loss: 0.4320612847805023
step: 160, loss: 0.41969338059425354
step: 170, loss: 0.305452436208725
step: 180, loss: 0.37619784474372864
step: 190, loss: 0.39834311604499817
step: 200, loss: 0.2638917863368988
step: 210, loss: 0.26594722270965576
step: 220, loss: 0.36336418986320496
step: 230, loss: 0.1640930473804474
step: 240, loss: 0.39422693848609924
step: 250, loss: 0.3463020622730255
step: 260, loss: 0.40709546208381653
step: 270, loss: 0.22962620854377747
step: 280, loss: 0.29357513785362244
step: 290, loss: 0.508133053779602
step: 300, loss: 0.15747171640396118
step: 310, loss: 0.2562373876571655
step: 320, loss: 0.18809860944747925
step: 330, loss: 0.39968904852867126
step: 340, loss: 0.24472112953662872
step: 350, loss: 0.22448094189167023
step: 360, loss: 0.22083891928195953
step: 370, loss: 0.20459939539432526
step: 380, loss: 0.18699441850185394
step: 390, loss: 0.5158413648605347
step: 400, loss: 0.2968698740005493
step: 410, loss: 0.19617009162902832
step: 420, loss: 0.22197255492210388
step: 430, loss: 0.21098487079143524
step: 440, loss: 0.16053365170955658
step: 450, loss: 0.335195392370224
step: 460, loss: 0.2739584445953369
step: 470, loss: 0.13479959964752197
step: 480, loss: 0.2989002764225006
step: 490, loss: 0.4498369097709656
step: 500, loss: 0.3220323324203491
step: 510, loss: 0.2222370207309723
step: 520, loss: 0.10923215001821518
step: 530, loss: 0.19393856823444366
epoch 1: dev_f1=0.8481675392670157, f1=0.8039119804400977, best_f1=0.8039119804400977
step: 0, loss: 0.3047534227371216
step: 10, loss: 0.11645419895648956
step: 20, loss: 0.24890953302383423
step: 30, loss: 0.371736079454422
step: 40, loss: 0.3445630669593811
step: 50, loss: 0.37837356328964233
step: 60, loss: 0.1403317153453827
step: 70, loss: 0.3127909004688263
step: 80, loss: 0.217703714966774
step: 90, loss: 0.269150972366333
step: 100, loss: 0.08601906150579453
step: 110, loss: 0.1222756952047348
step: 120, loss: 0.1463695913553238
step: 130, loss: 0.40664491057395935
step: 140, loss: 0.24459193646907806
step: 150, loss: 0.14808788895606995
step: 160, loss: 0.1882394701242447
step: 170, loss: 0.12293416261672974
step: 180, loss: 0.26966145634651184
step: 190, loss: 0.11149481683969498
step: 200, loss: 0.17177432775497437
step: 210, loss: 0.08584591746330261
step: 220, loss: 0.2678711712360382
step: 230, loss: 0.08103906363248825
step: 240, loss: 0.2503869831562042
step: 250, loss: 0.08154580742120743
step: 260, loss: 0.19292907416820526
step: 270, loss: 0.10643383115530014
step: 280, loss: 0.2166139930486679
step: 290, loss: 0.15489254891872406
step: 300, loss: 0.1297309249639511
step: 310, loss: 0.17193621397018433
step: 320, loss: 0.17024123668670654
step: 330, loss: 0.1641780138015747
step: 340, loss: 0.062379006296396255
step: 350, loss: 0.18987423181533813
step: 360, loss: 0.25176727771759033
step: 370, loss: 0.23893511295318604
step: 380, loss: 0.15658307075500488
step: 390, loss: 0.36476266384124756
step: 400, loss: 0.13665708899497986
step: 410, loss: 0.1533833146095276
step: 420, loss: 0.08841901272535324
step: 430, loss: 0.1996801346540451
step: 440, loss: 0.20857009291648865
step: 450, loss: 0.1273771971464157
step: 460, loss: 0.45768606662750244
step: 470, loss: 0.4556918144226074
step: 480, loss: 0.10571479052305222
step: 490, loss: 0.16557791829109192
step: 500, loss: 0.18796807527542114
step: 510, loss: 0.34241777658462524
step: 520, loss: 0.14108683168888092
step: 530, loss: 0.0681266039609909
epoch 2: dev_f1=0.865324384787472, f1=0.7836846929422548, best_f1=0.7836846929422548
step: 0, loss: 0.10036079585552216
step: 10, loss: 0.15295147895812988
step: 20, loss: 0.07019934803247452
step: 30, loss: 0.27319642901420593
step: 40, loss: 0.13711242377758026
step: 50, loss: 0.31112098693847656
step: 60, loss: 0.08837347477674484
step: 70, loss: 0.043192412704229355
step: 80, loss: 0.13499724864959717
step: 90, loss: 0.23093871772289276
step: 100, loss: 0.06206424534320831
step: 110, loss: 0.1118507981300354
step: 120, loss: 0.09347600489854813
step: 130, loss: 0.1952073872089386
step: 140, loss: 0.1006285697221756
step: 150, loss: 0.0666741132736206
step: 160, loss: 0.04524008929729462
step: 170, loss: 0.15282225608825684
step: 180, loss: 0.2878766655921936
step: 190, loss: 0.10864537954330444
step: 200, loss: 0.14611056447029114
step: 210, loss: 0.16054485738277435
step: 220, loss: 0.4250553250312805
step: 230, loss: 0.2532782554626465
step: 240, loss: 0.06331097334623337
step: 250, loss: 0.04610217362642288
step: 260, loss: 0.07250392436981201
step: 270, loss: 0.08383351564407349
step: 280, loss: 0.05138947814702988
step: 290, loss: 0.09186627715826035
step: 300, loss: 0.07087696343660355
step: 310, loss: 0.025503009557724
step: 320, loss: 0.1319897323846817
step: 330, loss: 0.1466493010520935
step: 340, loss: 0.1756109893321991
step: 350, loss: 0.06471925228834152
step: 360, loss: 0.166434645652771
step: 370, loss: 0.17712679505348206
step: 380, loss: 0.42592376470565796
step: 390, loss: 0.2917955219745636
step: 400, loss: 0.09010734409093857
step: 410, loss: 0.04996992647647858
step: 420, loss: 0.11827442795038223
step: 430, loss: 0.11188829690217972
step: 440, loss: 0.13797560334205627
step: 450, loss: 0.13953429460525513
step: 460, loss: 0.07376962900161743
step: 470, loss: 0.05761415883898735
step: 480, loss: 0.07025294005870819
step: 490, loss: 0.0544494204223156
step: 500, loss: 0.03324498236179352
step: 510, loss: 0.08263495564460754
step: 520, loss: 0.12314323335886002
step: 530, loss: 0.15612909197807312
epoch 3: dev_f1=0.8869485294117647, f1=0.7786259541984732, best_f1=0.7786259541984732
step: 0, loss: 0.07328519225120544
step: 10, loss: 0.031138703227043152
step: 20, loss: 0.022434024140238762
step: 30, loss: 0.03550094738602638
step: 40, loss: 0.018931763246655464
step: 50, loss: 0.2568137049674988
step: 60, loss: 0.05144665017724037
step: 70, loss: 0.07432590425014496
step: 80, loss: 0.0691179558634758
step: 90, loss: 0.01396735105663538
step: 100, loss: 0.1751941591501236
step: 110, loss: 0.16365541517734528
step: 120, loss: 0.04525255411863327
step: 130, loss: 0.12129534780979156
step: 140, loss: 0.0706230103969574
step: 150, loss: 0.08619850128889084
step: 160, loss: 0.1417289823293686
step: 170, loss: 0.05500365421175957
step: 180, loss: 0.18784350156784058
step: 190, loss: 0.18392980098724365
step: 200, loss: 0.09398901462554932
step: 210, loss: 0.03186817839741707
step: 220, loss: 0.16254086792469025
step: 230, loss: 0.02845618687570095
step: 240, loss: 0.06736359745264053
step: 250, loss: 0.018559211865067482
step: 260, loss: 0.1195840984582901
step: 270, loss: 0.05959368124604225
step: 280, loss: 0.22590290009975433
step: 290, loss: 0.11515491455793381
step: 300, loss: 0.057869650423526764
step: 310, loss: 0.048802174627780914
step: 320, loss: 0.03493545576930046
step: 330, loss: 0.12101832777261734
step: 340, loss: 0.06885804980993271
step: 350, loss: 0.09867405146360397
step: 360, loss: 0.1078743264079094
step: 370, loss: 0.10271193087100983
step: 380, loss: 0.08440393954515457
step: 390, loss: 0.02208762615919113
step: 400, loss: 0.07235478609800339
step: 410, loss: 0.11644022166728973
step: 420, loss: 0.11368708312511444
step: 430, loss: 0.04269109293818474
step: 440, loss: 0.23670105636119843
step: 450, loss: 0.07634488493204117
step: 460, loss: 0.12929575145244598
step: 470, loss: 0.08742600679397583
step: 480, loss: 0.1737755388021469
step: 490, loss: 0.0729798823595047
step: 500, loss: 0.1717335283756256
step: 510, loss: 0.1094769686460495
step: 520, loss: 0.029208173975348473
step: 530, loss: 0.1968676745891571
epoch 4: dev_f1=0.8969917958067456, f1=0.7902298850574713, best_f1=0.7902298850574713
step: 0, loss: 0.03986232355237007
step: 10, loss: 0.03378544747829437
step: 20, loss: 0.04470609128475189
step: 30, loss: 0.040143031626939774
step: 40, loss: 0.021622272208333015
step: 50, loss: 0.06377433985471725
step: 60, loss: 0.046166013926267624
step: 70, loss: 0.04197593778371811
step: 80, loss: 0.015499208122491837
step: 90, loss: 0.08365970104932785
step: 100, loss: 0.10918941348791122
step: 110, loss: 0.02133333496749401
step: 120, loss: 0.1082369014620781
step: 130, loss: 0.0046392278745770454
step: 140, loss: 0.08884226530790329
step: 150, loss: 0.044148463755846024
step: 160, loss: 0.027902932837605476
step: 170, loss: 0.10652211308479309
step: 180, loss: 0.05691051110625267
step: 190, loss: 0.02106439881026745
step: 200, loss: 0.07128385454416275
step: 210, loss: 0.026913713663816452
step: 220, loss: 0.06687755137681961
step: 230, loss: 0.010985588654875755
step: 240, loss: 0.05871345475316048
step: 250, loss: 0.03584043309092522
step: 260, loss: 0.06902670860290527
step: 270, loss: 0.08093049377202988
step: 280, loss: 0.08394887298345566
step: 290, loss: 0.12607179582118988
step: 300, loss: 0.04603966325521469
step: 310, loss: 0.06099151447415352
step: 320, loss: 0.022502196952700615
step: 330, loss: 0.1361236423254013
step: 340, loss: 0.13528858125209808
step: 350, loss: 0.04255152493715286
step: 360, loss: 0.08494460582733154
step: 370, loss: 0.0553608275949955
step: 380, loss: 0.09646380692720413
step: 390, loss: 0.07689481228590012
step: 400, loss: 0.1519991010427475
step: 410, loss: 0.051048438996076584
step: 420, loss: 0.019104665145277977
step: 430, loss: 0.04368461295962334
step: 440, loss: 0.058083467185497284
step: 450, loss: 0.04632344841957092
step: 460, loss: 0.2033819556236267
step: 470, loss: 0.028792422264814377
step: 480, loss: 0.00704564806073904
step: 490, loss: 0.05945991352200508
step: 500, loss: 0.025899115949869156
step: 510, loss: 0.03372702747583389
step: 520, loss: 0.14591462910175323
step: 530, loss: 0.04713692516088486
epoch 5: dev_f1=0.8776716689404274, f1=0.738625363020329, best_f1=0.7902298850574713
step: 0, loss: 0.07204148173332214
step: 10, loss: 0.06440500915050507
step: 20, loss: 0.006858319975435734
step: 30, loss: 0.016516556963324547
step: 40, loss: 0.008383531123399734
step: 50, loss: 0.026696255430579185
step: 60, loss: 0.02081899717450142
step: 70, loss: 0.002813266357406974
step: 80, loss: 0.027003765106201172
step: 90, loss: 0.006757666356861591
step: 100, loss: 0.017745092511177063
step: 110, loss: 0.09212851524353027
step: 120, loss: 0.045660682022571564
step: 130, loss: 0.018519558012485504
step: 140, loss: 0.06678247451782227
step: 150, loss: 0.004421176388859749
step: 160, loss: 0.051870543509721756
step: 170, loss: 0.013525603339076042
step: 180, loss: 0.01067537721246481
step: 190, loss: 0.007324875332415104
step: 200, loss: 0.003650722559541464
step: 210, loss: 0.06458298861980438
step: 220, loss: 0.01737431064248085
step: 230, loss: 0.005400140769779682
step: 240, loss: 0.10874047875404358
step: 250, loss: 0.012730986811220646
step: 260, loss: 0.005624672397971153
step: 270, loss: 0.0005622824537567794
step: 280, loss: 0.06363309919834137
step: 290, loss: 0.030979294329881668
step: 300, loss: 0.003083072369918227
step: 310, loss: 0.029622914269566536
step: 320, loss: 0.11170294880867004
step: 330, loss: 0.1222909688949585
step: 340, loss: 0.046063292771577835
step: 350, loss: 0.030783167108893394
step: 360, loss: 0.05355967953801155
step: 370, loss: 0.006010250188410282
step: 380, loss: 0.14044125378131866
step: 390, loss: 0.12218718975782394
step: 400, loss: 0.005461906548589468
step: 410, loss: 0.10488830506801605
step: 420, loss: 0.027222827076911926
step: 430, loss: 0.07992229610681534
step: 440, loss: 0.04364466667175293
step: 450, loss: 0.01755906268954277
step: 460, loss: 0.0012680250220000744
step: 470, loss: 0.0909481793642044
step: 480, loss: 0.08683829009532928
step: 490, loss: 0.007038218900561333
step: 500, loss: 0.04437621310353279
step: 510, loss: 0.005347810219973326
step: 520, loss: 0.002919852966442704
step: 530, loss: 0.0028939656913280487
epoch 6: dev_f1=0.8790613718411554, f1=0.7645665561345335, best_f1=0.7902298850574713
step: 0, loss: 0.02072967402637005
step: 10, loss: 0.08508776128292084
step: 20, loss: 0.029696201905608177
step: 30, loss: 0.011416793800890446
step: 40, loss: 0.001185072585940361
step: 50, loss: 0.03053407557308674
step: 60, loss: 0.008311680518090725
step: 70, loss: 0.0076379319652915
step: 80, loss: 0.013256478123366833
step: 90, loss: 0.0030606219079345465
step: 100, loss: 0.03224572166800499
step: 110, loss: 0.010186202824115753
step: 120, loss: 0.0015049079665914178
step: 130, loss: 0.0025287047028541565
step: 140, loss: 0.009892622008919716
step: 150, loss: 0.005987801123410463
step: 160, loss: 0.013755559921264648
step: 170, loss: 0.03542666509747505
step: 180, loss: 0.023114554584026337
step: 190, loss: 0.010838714428246021
step: 200, loss: 0.010143081657588482
step: 210, loss: 0.12018784880638123
step: 220, loss: 0.015677599236369133
step: 230, loss: 0.0056884922087192535
step: 240, loss: 0.10876521468162537
step: 250, loss: 0.008601967245340347
step: 260, loss: 0.00010088375711347908
step: 270, loss: 0.0016631007893010974
step: 280, loss: 0.0810178816318512
step: 290, loss: 0.02705535665154457
step: 300, loss: 0.15373332798480988
step: 310, loss: 0.0065042260102927685
step: 320, loss: 0.004244872368872166
step: 330, loss: 0.023051895201206207
step: 340, loss: 0.0198594368994236
step: 350, loss: 0.0029342682100832462
step: 360, loss: 0.007890446111559868
step: 370, loss: 0.0013555801706388593
step: 380, loss: 0.07481185346841812
step: 390, loss: 0.015034007839858532
step: 400, loss: 0.1730709969997406
step: 410, loss: 0.011640465818345547
step: 420, loss: 0.09222188591957092
step: 430, loss: 0.06468871980905533
step: 440, loss: 0.006671966053545475
step: 450, loss: 0.04291987419128418
step: 460, loss: 0.015229822136461735
step: 470, loss: 0.001691595301963389
step: 480, loss: 0.005207199137657881
step: 490, loss: 0.0011002758983522654
step: 500, loss: 0.04527929797768593
step: 510, loss: 0.051509298384189606
step: 520, loss: 0.04224865511059761
step: 530, loss: 0.006126448977738619
epoch 7: dev_f1=0.8884792626728111, f1=0.7638483965014577, best_f1=0.7902298850574713
step: 0, loss: 0.008634512312710285
step: 10, loss: 0.028001930564641953
step: 20, loss: 0.022601095959544182
step: 30, loss: 0.007706001400947571
step: 40, loss: 0.017686640843749046
step: 50, loss: 0.01581752672791481
step: 60, loss: 0.00705114146694541
step: 70, loss: 0.0016620433889329433
step: 80, loss: 0.14130979776382446
step: 90, loss: 0.0011701661860570312
step: 100, loss: 0.17984344065189362
step: 110, loss: 0.017073892056941986
step: 120, loss: 0.01342454832047224
step: 130, loss: 0.0020667463541030884
step: 140, loss: 0.024342050775885582
step: 150, loss: 0.0007499338244087994
step: 160, loss: 0.009992619976401329
step: 170, loss: 0.0008239704766310751
step: 180, loss: 0.009434321895241737
step: 190, loss: 0.010627096518874168
step: 200, loss: 0.01531470101326704
step: 210, loss: 0.0005946854362264276
step: 220, loss: 0.006478792522102594
step: 230, loss: 0.0018214184092357755
step: 240, loss: 0.016415487974882126
step: 250, loss: 0.000554156955331564
step: 260, loss: 0.09137912094593048
step: 270, loss: 0.002557520056143403
step: 280, loss: 0.029283780604600906
step: 290, loss: 0.0014452387113124132
step: 300, loss: 0.027278749272227287
step: 310, loss: 0.003156200982630253
step: 320, loss: 0.005127992480993271
step: 330, loss: 0.0008087492897175252
step: 340, loss: 0.017858611419796944
step: 350, loss: 0.028623320162296295
step: 360, loss: 0.023433754220604897
step: 370, loss: 0.002662147395312786
step: 380, loss: 0.04600178822875023
step: 390, loss: 0.019222933799028397
step: 400, loss: 0.0009799003601074219
step: 410, loss: 0.0020338615868240595
step: 420, loss: 0.0030369581654667854
step: 430, loss: 0.0025112670846283436
step: 440, loss: 0.031147746369242668
step: 450, loss: 0.0052942694164812565
step: 460, loss: 0.12698474526405334
step: 470, loss: 0.04177657142281532
step: 480, loss: 0.021279213950037956
step: 490, loss: 0.0013103107921779156
step: 500, loss: 0.0016944509698078036
step: 510, loss: 0.00016525539103895426
step: 520, loss: 0.005343489348888397
step: 530, loss: 0.16951680183410645
epoch 8: dev_f1=0.8742514970059879, f1=0.7382550335570469, best_f1=0.7902298850574713
step: 0, loss: 0.1667543202638626
step: 10, loss: 0.014258205890655518
step: 20, loss: 0.0025601403322070837
step: 30, loss: 0.001882900600321591
step: 40, loss: 0.0016256754752248526
step: 50, loss: 0.14327161014080048
step: 60, loss: 0.002374969655647874
step: 70, loss: 0.0005692974664270878
step: 80, loss: 0.006336251273751259
step: 90, loss: 0.0010472850408405066
step: 100, loss: 0.015158357098698616
step: 110, loss: 0.00022929353872314095
step: 120, loss: 0.004253331106156111
step: 130, loss: 0.0482947863638401
step: 140, loss: 0.002108509885147214
step: 150, loss: 0.15719424188137054
step: 160, loss: 0.0005187960923649371
step: 170, loss: 0.0013648913009092212
step: 180, loss: 0.0003962680057156831
step: 190, loss: 0.0027335681952536106
step: 200, loss: 0.014567269012331963
step: 210, loss: 0.0004124729020986706
step: 220, loss: 0.005094030871987343
step: 230, loss: 0.019215840846300125
step: 240, loss: 0.04355014115571976
step: 250, loss: 0.0001294684043386951
step: 260, loss: 0.0016022108029574156
step: 270, loss: 0.002070971764624119
step: 280, loss: 0.0013796176062896848
step: 290, loss: 0.00022938870824873447
step: 300, loss: 0.028786538168787956
step: 310, loss: 0.005313819739967585
step: 320, loss: 0.006810678169131279
step: 330, loss: 0.0065797059796750546
step: 340, loss: 0.03484172374010086
step: 350, loss: 0.0016420413739979267
step: 360, loss: 0.011032233014702797
step: 370, loss: 0.05813346430659294
step: 380, loss: 0.0015031200600787997
step: 390, loss: 0.029399199411273003
step: 400, loss: 0.0037796082906425
step: 410, loss: 0.0026437402702867985
step: 420, loss: 0.0006565094226971269
step: 430, loss: 0.003849232103675604
step: 440, loss: 0.007429338060319424
step: 450, loss: 0.010724962688982487
step: 460, loss: 0.004121065139770508
step: 470, loss: 0.02085070312023163
step: 480, loss: 0.00018060342699754983
step: 490, loss: 0.14760568737983704
step: 500, loss: 0.0019255299121141434
step: 510, loss: 0.0021197448950260878
step: 520, loss: 0.013428237289190292
step: 530, loss: 0.0004209493054077029
epoch 9: dev_f1=0.8665127020785219, f1=0.7458617332035054, best_f1=0.7902298850574713
step: 0, loss: 0.00387836922891438
step: 10, loss: 0.0004506082914303988
step: 20, loss: 0.017718089744448662
step: 30, loss: 0.00835923757404089
step: 40, loss: 0.006200537085533142
step: 50, loss: 0.0013604118721559644
step: 60, loss: 0.06891939043998718
step: 70, loss: 0.05047120153903961
step: 80, loss: 0.0014463940169662237
step: 90, loss: 0.026208952069282532
step: 100, loss: 0.00013826887879986316
step: 110, loss: 0.00599806010723114
step: 120, loss: 0.006121017038822174
step: 130, loss: 0.0007383423508144915
step: 140, loss: 0.006324571557343006
step: 150, loss: 0.002347312169149518
step: 160, loss: 0.029708856716752052
step: 170, loss: 0.0025122412480413914
step: 180, loss: 0.00041089183650910854
step: 190, loss: 0.001693394617177546
step: 200, loss: 0.014972799457609653
step: 210, loss: 0.00013606635911855847
step: 220, loss: 0.0006645002868026495
step: 230, loss: 0.0032133322674781084
step: 240, loss: 9.580150071997195e-05
step: 250, loss: 0.0010914972517639399
step: 260, loss: 0.0739869773387909
step: 270, loss: 0.0003385295858606696
step: 280, loss: 0.000139873125590384
step: 290, loss: 0.007722674869000912
step: 300, loss: 0.0370638333261013
step: 310, loss: 0.004027072340250015
step: 320, loss: 0.0005441544926725328
step: 330, loss: 0.028043406084179878
step: 340, loss: 0.0005656679859384894
step: 350, loss: 0.10494471341371536
step: 360, loss: 0.023499680683016777
step: 370, loss: 0.01235104352235794
step: 380, loss: 0.001439601182937622
step: 390, loss: 0.0008117672405205667
step: 400, loss: 0.013443424366414547
step: 410, loss: 0.005103491712361574
step: 420, loss: 0.0037650722078979015
step: 430, loss: 0.0018988685915246606
step: 440, loss: 0.07222256809473038
step: 450, loss: 0.00015360064571723342
step: 460, loss: 0.002252180129289627
step: 470, loss: 0.0002383637911407277
step: 480, loss: 0.0024299020878970623
step: 490, loss: 0.000309741182718426
step: 500, loss: 0.0026530588511377573
step: 510, loss: 0.01809696853160858
step: 520, loss: 0.0005058255628682673
step: 530, loss: 0.05288118124008179
epoch 10: dev_f1=0.872626215840667, f1=0.7380254154447703, best_f1=0.7902298850574713
step: 0, loss: 0.046667568385601044
step: 10, loss: 0.002331944415345788
step: 20, loss: 0.01468733511865139
step: 30, loss: 0.04326675087213516
step: 40, loss: 0.01224170345813036
step: 50, loss: 0.0009160545305348933
step: 60, loss: 0.0026855627074837685
step: 70, loss: 0.001580039388500154
step: 80, loss: 0.00027477697585709393
step: 90, loss: 0.00045614383998326957
step: 100, loss: 0.0034177054185420275
step: 110, loss: 0.001919659785926342
step: 120, loss: 0.11721264570951462
step: 130, loss: 0.0006933859549462795
step: 140, loss: 9.413063526153564e-05
step: 150, loss: 0.003232318442314863
step: 160, loss: 0.010635417886078358
step: 170, loss: 0.0007809441303834319
step: 180, loss: 0.0007420032634399831
step: 190, loss: 0.011476552113890648
step: 200, loss: 0.0005673097330145538
step: 210, loss: 0.0002520446141716093
step: 220, loss: 0.0029022011440247297
step: 230, loss: 0.018288034945726395
step: 240, loss: 0.1425279676914215
step: 250, loss: 5.301542114466429e-05
step: 260, loss: 0.031240368261933327
step: 270, loss: 0.00542067177593708
step: 280, loss: 6.37189659755677e-05
step: 290, loss: 0.0005826073465868831
step: 300, loss: 0.00779421441257
step: 310, loss: 0.00866845715790987
step: 320, loss: 0.021774128079414368
step: 330, loss: 0.0012003476731479168
step: 340, loss: 0.011849399656057358
step: 350, loss: 0.0033705441746860743
step: 360, loss: 0.0006544860661961138
step: 370, loss: 0.0004026892129331827
step: 380, loss: 0.00025005009956657887
step: 390, loss: 0.006841736845672131
step: 400, loss: 0.0005074110231362283
step: 410, loss: 0.0004917082260362804
step: 420, loss: 0.038207974284887314
step: 430, loss: 0.0017921224934980273
step: 440, loss: 0.001286776503548026
step: 450, loss: 0.00298875430598855
step: 460, loss: 0.004121213220059872
step: 470, loss: 0.00027313674218021333
step: 480, loss: 0.03668919950723648
step: 490, loss: 0.10685213655233383
step: 500, loss: 0.00012022518058074638
step: 510, loss: 0.009558514691889286
step: 520, loss: 0.0010182153200730681
step: 530, loss: 0.0004150449822191149
epoch 11: dev_f1=0.8496309963099631, f1=0.7197265624999999, best_f1=0.7902298850574713
step: 0, loss: 0.00025572848971933126
step: 10, loss: 0.00301312655210495
step: 20, loss: 0.006441822275519371
step: 30, loss: 0.004115233197808266
step: 40, loss: 0.00013196005602367222
step: 50, loss: 0.0006080998573452234
step: 60, loss: 0.004465452861040831
step: 70, loss: 0.03608478233218193
step: 80, loss: 0.00037332571810111403
step: 90, loss: 0.005083990748971701
step: 100, loss: 0.24235476553440094
step: 110, loss: 0.04418836906552315
step: 120, loss: 0.0002785481628961861
step: 130, loss: 0.002939200960099697
step: 140, loss: 0.00021179909526836127
step: 150, loss: 0.00037320650881156325
step: 160, loss: 0.00012138985039200634
step: 170, loss: 9.648158447816968e-05
step: 180, loss: 0.01807696744799614
step: 190, loss: 0.0014418559148907661
step: 200, loss: 0.00034357537515461445
step: 210, loss: 0.08575408905744553
step: 220, loss: 0.015902679413557053
step: 230, loss: 0.0024938250426203012
step: 240, loss: 0.0008028943557292223
step: 250, loss: 0.031245311722159386
step: 260, loss: 0.0005772315198555589
step: 270, loss: 0.027501102536916733
step: 280, loss: 0.0006694036419503391
step: 290, loss: 0.00033064853050746024
step: 300, loss: 0.00038162257988005877
step: 310, loss: 0.0009517564903944731
step: 320, loss: 0.0287290271371603
step: 330, loss: 0.002365723717957735
step: 340, loss: 0.0005108292680233717
step: 350, loss: 0.048131730407476425
step: 360, loss: 0.032368410378694534
step: 370, loss: 0.02425498142838478
step: 380, loss: 0.025260737165808678
step: 390, loss: 0.0005126344040036201
step: 400, loss: 0.0023174232337623835
step: 410, loss: 0.0001438949111616239
step: 420, loss: 0.0013320209691300988
step: 430, loss: 0.00033509376225993037
step: 440, loss: 0.0003509626549202949
step: 450, loss: 0.0010860918555408716
step: 460, loss: 0.0006558280438184738
step: 470, loss: 0.0024123857729136944
step: 480, loss: 0.0012221639044582844
step: 490, loss: 0.0029427639674395323
step: 500, loss: 0.00017154745000880212
step: 510, loss: 0.004244585055857897
step: 520, loss: 0.00011757801985368133
step: 530, loss: 0.046212852001190186
epoch 12: dev_f1=0.867546654528903, f1=0.7583572110792741, best_f1=0.7902298850574713
step: 0, loss: 0.00012819323455914855
step: 10, loss: 0.00023535764194093645
step: 20, loss: 0.0001435695303371176
step: 30, loss: 0.00019920867634937167
step: 40, loss: 5.6616641813889146e-05
step: 50, loss: 0.00015058642020449042
step: 60, loss: 0.0007958761416375637
step: 70, loss: 0.00036803859984502196
step: 80, loss: 0.055935025215148926
step: 90, loss: 0.006177802104502916
step: 100, loss: 0.02388899028301239
step: 110, loss: 0.00011535745579749346
step: 120, loss: 0.0014958744868636131
step: 130, loss: 0.00034620435326360166
step: 140, loss: 0.0008440939127467573
step: 150, loss: 0.0004216619418002665
step: 160, loss: 0.00020065462740603834
step: 170, loss: 0.0009982187766581774
step: 180, loss: 0.0012823707656934857
step: 190, loss: 0.0005694584106095135
step: 200, loss: 0.0016870293766260147
step: 210, loss: 0.00012186765525257215
step: 220, loss: 0.01395232044160366
step: 230, loss: 0.0009412409272044897
step: 240, loss: 0.0009598910110071301
step: 250, loss: 5.432604666566476e-05
step: 260, loss: 0.00030405179131776094
step: 270, loss: 9.094461711356416e-05
step: 280, loss: 0.0014991478528827429
step: 290, loss: 0.02547438256442547
step: 300, loss: 0.0007187032024376094
step: 310, loss: 0.02164783887565136
step: 320, loss: 0.00042701439815573394
step: 330, loss: 0.00019644822168629616
step: 340, loss: 0.0010246861493214965
step: 350, loss: 0.0005928674363531172
step: 360, loss: 0.00018913426902145147
step: 370, loss: 0.06579220294952393
step: 380, loss: 0.02235417626798153
step: 390, loss: 0.0001869251864263788
step: 400, loss: 0.08549069613218307
step: 410, loss: 0.017809225246310234
step: 420, loss: 0.0001299005962209776
step: 430, loss: 0.002301134867593646
step: 440, loss: 0.0001268766645807773
step: 450, loss: 0.0003114807768724859
step: 460, loss: 0.007698287721723318
step: 470, loss: 0.06443183124065399
step: 480, loss: 0.0003251908638048917
step: 490, loss: 0.22596131265163422
step: 500, loss: 0.00014594619278796017
step: 510, loss: 0.00018237510812468827
step: 520, loss: 0.00029325284413062036
step: 530, loss: 0.0004298051935620606
epoch 13: dev_f1=0.8739495798319328, f1=0.7451756556160316, best_f1=0.7902298850574713
step: 0, loss: 0.003376523731276393
step: 10, loss: 0.0006249768193811178
step: 20, loss: 0.0011276679579168558
step: 30, loss: 0.00036221707705408335
step: 40, loss: 0.0007533454918302596
step: 50, loss: 0.0002688225358724594
step: 60, loss: 0.000852661207318306
step: 70, loss: 8.239022281486541e-05
step: 80, loss: 0.005522019229829311
step: 90, loss: 9.641698125051335e-05
step: 100, loss: 0.000786785501986742
step: 110, loss: 0.007892917841672897
step: 120, loss: 0.0024272678419947624
step: 130, loss: 5.750538548454642e-05
step: 140, loss: 4.4720000005327165e-05
step: 150, loss: 0.00036019503022544086
step: 160, loss: 0.105139821767807
step: 170, loss: 0.0005081598064862192
step: 180, loss: 0.0020170111674815416
step: 190, loss: 0.0013096689945086837
step: 200, loss: 0.0036328856367617846
step: 210, loss: 0.00024131870304699987
step: 220, loss: 0.0003524039639160037
step: 230, loss: 0.00035030703293159604
step: 240, loss: 5.918852548347786e-05
step: 250, loss: 0.0008563201990909874
step: 260, loss: 0.028960147872567177
step: 270, loss: 0.00022776323021389544
step: 280, loss: 0.0001876204478321597
step: 290, loss: 0.0016791012603789568
step: 300, loss: 4.014187288703397e-05
step: 310, loss: 9.053324902197346e-05
step: 320, loss: 0.0005112371291033924
step: 330, loss: 5.90095623920206e-05
step: 340, loss: 0.0014094768557697535
step: 350, loss: 0.0003791108320001513
step: 360, loss: 0.030656157061457634
step: 370, loss: 0.0005248278612270951
step: 380, loss: 0.00016743956075515598
step: 390, loss: 0.051002953201532364
step: 400, loss: 0.004458022303879261
step: 410, loss: 0.0018486479530110955
step: 420, loss: 0.001197251258417964
step: 430, loss: 0.0005591001827269793
step: 440, loss: 0.0005989630590192974
step: 450, loss: 0.0026901024393737316
step: 460, loss: 0.0005881353281438351
step: 470, loss: 0.0008369245915673673
step: 480, loss: 0.0006532687693834305
step: 490, loss: 0.00020838754426222295
step: 500, loss: 0.001283365534618497
step: 510, loss: 0.00016985672118607908
step: 520, loss: 0.0006894688121974468
step: 530, loss: 0.0039762104861438274
epoch 14: dev_f1=0.8585585585585586, f1=0.7390493942218079, best_f1=0.7902298850574713
step: 0, loss: 6.467549246735871e-05
step: 10, loss: 0.0001559931697556749
step: 20, loss: 0.0002574624086264521
step: 30, loss: 0.00020627479534596205
step: 40, loss: 0.0001561748213134706
step: 50, loss: 0.0003782259300351143
step: 60, loss: 0.0008209512452594936
step: 70, loss: 0.00020229823712725192
step: 80, loss: 0.0018414449878036976
step: 90, loss: 0.04503033682703972
step: 100, loss: 0.00032518067746423185
step: 110, loss: 6.928228685865179e-05
step: 120, loss: 0.0015814396319910884
step: 130, loss: 0.0031167424749583006
step: 140, loss: 0.00012164610234322026
step: 150, loss: 0.0010214393259957433
step: 160, loss: 0.0007112332386896014
step: 170, loss: 0.00024247640976682305
step: 180, loss: 5.832561510032974e-05
step: 190, loss: 0.0002495798980817199
step: 200, loss: 0.00012792929192073643
step: 210, loss: 0.00029091801843605936
step: 220, loss: 0.01345445029437542
step: 230, loss: 0.11525227129459381
step: 240, loss: 0.12102597206830978
step: 250, loss: 0.0030423717107623816
step: 260, loss: 0.00030768936267122626
step: 270, loss: 0.01102381944656372
step: 280, loss: 4.989301669411361e-05
step: 290, loss: 0.0009918393334373832
step: 300, loss: 0.0020387389231473207
step: 310, loss: 0.05527246743440628
step: 320, loss: 0.005937002599239349
step: 330, loss: 0.0001428610848961398
step: 340, loss: 0.00038708289503119886
step: 350, loss: 0.0017224506009370089
step: 360, loss: 6.628136907238513e-05
step: 370, loss: 3.9984039176488295e-05
step: 380, loss: 0.00027764274273067713
step: 390, loss: 0.0001318393333349377
step: 400, loss: 0.00020326745288912207
step: 410, loss: 5.772865188191645e-05
step: 420, loss: 0.00016157115169335157
step: 430, loss: 5.604492253041826e-05
step: 440, loss: 0.00046702948748134077
step: 450, loss: 0.0004623047716449946
step: 460, loss: 0.0008222248870879412
step: 470, loss: 0.000343477790011093
step: 480, loss: 0.00018813479982782155
step: 490, loss: 5.159001739230007e-05
step: 500, loss: 0.00033412911579944193
step: 510, loss: 0.005877928342670202
step: 520, loss: 0.011434043757617474
step: 530, loss: 4.275760147720575e-05
epoch 15: dev_f1=0.8661909009812666, f1=0.7435185185185186, best_f1=0.7902298850574713
step: 0, loss: 0.00011853768228320405
step: 10, loss: 0.00016794304247014225
step: 20, loss: 0.00036785643897019327
step: 30, loss: 0.0002099599951179698
step: 40, loss: 6.506522913696244e-05
step: 50, loss: 4.014719161204994e-05
step: 60, loss: 4.1091123421210796e-05
step: 70, loss: 0.00013300716818775982
step: 80, loss: 2.2988280761637725e-05
step: 90, loss: 0.0003428218187764287
step: 100, loss: 0.00022602698300033808
step: 110, loss: 0.0012667401460930705
step: 120, loss: 4.6042401663726196e-05
step: 130, loss: 0.00021077922428958118
step: 140, loss: 0.0006948477821424603
step: 150, loss: 0.0001395651197526604
step: 160, loss: 3.697060310514644e-05
step: 170, loss: 4.7293979150708765e-05
step: 180, loss: 6.331865733955055e-05
step: 190, loss: 0.00019941873324569315
step: 200, loss: 7.511553121730685e-05
step: 210, loss: 3.5977140214527026e-05
step: 220, loss: 0.0010838592424988747
step: 230, loss: 0.0008331852732226253
step: 240, loss: 0.00023568312462884933
step: 250, loss: 0.008974484167993069
step: 260, loss: 7.770692172925919e-05
step: 270, loss: 0.018705351278185844
step: 280, loss: 0.0017631002701818943
step: 290, loss: 7.00077653164044e-05
step: 300, loss: 0.0005679840687662363
step: 310, loss: 3.437165287323296e-05
step: 320, loss: 0.00021072360686957836
step: 330, loss: 0.0004592124605551362
step: 340, loss: 5.703785063815303e-05
step: 350, loss: 0.00012854149099439383
step: 360, loss: 0.00017327908426523209
step: 370, loss: 4.2931573261739686e-05
step: 380, loss: 0.024341542273759842
step: 390, loss: 0.0010124840773642063
step: 400, loss: 2.512635364837479e-05
step: 410, loss: 0.002744025085121393
step: 420, loss: 5.316064562066458e-05
step: 430, loss: 3.756450314540416e-05
step: 440, loss: 1.654001243878156e-05
step: 450, loss: 0.0005071182386018336
step: 460, loss: 0.0005640605231747031
step: 470, loss: 0.004350514151155949
step: 480, loss: 6.624098750762641e-05
step: 490, loss: 5.060822513769381e-05
step: 500, loss: 0.00017090882465709
step: 510, loss: 0.0019217722583562136
step: 520, loss: 6.48643690510653e-05
step: 530, loss: 4.732195884571411e-05
epoch 16: dev_f1=0.8647925033467202, f1=0.7430718647252231, best_f1=0.7902298850574713
step: 0, loss: 0.0009129374520853162
step: 10, loss: 0.021476780995726585
step: 20, loss: 0.009434131905436516
step: 30, loss: 2.920039332821034e-05
step: 40, loss: 0.0003868399653583765
step: 50, loss: 0.0008112963405437768
step: 60, loss: 4.803240517503582e-05
step: 70, loss: 8.403965330217034e-05
step: 80, loss: 0.0013766201445832849
step: 90, loss: 5.6887824030127376e-05
step: 100, loss: 4.5183260226622224e-05
step: 110, loss: 4.5994900574442e-05
step: 120, loss: 0.0004617464146576822
step: 130, loss: 1.8033750166068785e-05
step: 140, loss: 4.805685966857709e-05
step: 150, loss: 0.0013913880102336407
step: 160, loss: 0.001728575793094933
step: 170, loss: 0.00017773907165974379
step: 180, loss: 0.00012999714817851782
step: 190, loss: 0.001466288580559194
step: 200, loss: 0.000677924370393157
step: 210, loss: 0.0026806972455233335
step: 220, loss: 6.187975668581203e-05
step: 230, loss: 0.0004066181427333504
step: 240, loss: 0.004634121432900429
step: 250, loss: 0.00010713817755458876
step: 260, loss: 0.11530403047800064
step: 270, loss: 0.00015046721091493964
step: 280, loss: 5.684341522282921e-05
step: 290, loss: 4.166557846474461e-05
step: 300, loss: 6.536418368341401e-05
step: 310, loss: 0.00013051924179308116
step: 320, loss: 0.0011348994448781013
step: 330, loss: 0.0008160255965776742
step: 340, loss: 6.879287684569135e-05
step: 350, loss: 3.511987961246632e-05
step: 360, loss: 0.00010493886657059193
step: 370, loss: 3.3577111025806516e-05
step: 380, loss: 0.0005574527313001454
step: 390, loss: 1.4811598703090567e-05
step: 400, loss: 0.0018236128380522132
step: 410, loss: 2.1970945454086177e-05
step: 420, loss: 3.486640707706101e-05
step: 430, loss: 2.276089981023688e-05
step: 440, loss: 0.0052228267304599285
step: 450, loss: 4.984263068763539e-05
step: 460, loss: 0.019308481365442276
step: 470, loss: 0.00013528901035897434
step: 480, loss: 9.096150461118668e-05
step: 490, loss: 3.4310993214603513e-05
step: 500, loss: 3.3220505429198965e-05
step: 510, loss: 0.00028112943982705474
step: 520, loss: 0.0003282155084889382
step: 530, loss: 0.0002233339037047699
epoch 17: dev_f1=0.8710832587287377, f1=0.7600749765698219, best_f1=0.7902298850574713
step: 0, loss: 9.948574734153226e-05
step: 10, loss: 0.0014812650624662638
step: 20, loss: 7.552278111688793e-05
step: 30, loss: 0.0009580624173395336
step: 40, loss: 0.0005162852467037737
step: 50, loss: 0.0001383170165354386
step: 60, loss: 5.7366181863471866e-05
step: 70, loss: 9.31368995225057e-05
step: 80, loss: 0.0019799619913101196
step: 90, loss: 7.550408918177709e-05
step: 100, loss: 7.956821355037391e-05
step: 110, loss: 0.0006083834450691938
step: 120, loss: 0.0011742679635062814
step: 130, loss: 5.925238292547874e-05
step: 140, loss: 0.028130922466516495
step: 150, loss: 0.0036863302811980247
step: 160, loss: 0.00010010215191869065
step: 170, loss: 0.026934713125228882
step: 180, loss: 0.0010037064785137773
step: 190, loss: 4.0073980926536024e-05
step: 200, loss: 0.01270756684243679
step: 210, loss: 5.4653890401823446e-05
step: 220, loss: 0.00010995540651492774
step: 230, loss: 0.00021740519150625914
step: 240, loss: 7.797197758918628e-05
step: 250, loss: 0.0010345957707613707
step: 260, loss: 0.00024166418006643653
step: 270, loss: 2.6779600375448354e-05
step: 280, loss: 0.00010072454460896552
step: 290, loss: 2.5774463210836984e-05
step: 300, loss: 0.00021677181939594448
step: 310, loss: 6.731900066370144e-05
step: 320, loss: 0.00040967835229821503
step: 330, loss: 4.269391138223e-05
step: 340, loss: 0.0003475445555523038
step: 350, loss: 3.8862144720042124e-05
step: 360, loss: 2.4771732569206506e-05
step: 370, loss: 3.604337325668894e-05
step: 380, loss: 0.006198043469339609
step: 390, loss: 7.939559873193502e-05
step: 400, loss: 4.750184962176718e-05
step: 410, loss: 3.7536814488703385e-05
step: 420, loss: 5.185070040170103e-05
step: 430, loss: 0.0001681439025560394
step: 440, loss: 5.5271499149966985e-05
step: 450, loss: 2.3121725462260656e-05
step: 460, loss: 0.0009329762542620301
step: 470, loss: 0.0004902620567008853
step: 480, loss: 5.718917600461282e-05
step: 490, loss: 5.8047909988090396e-05
step: 500, loss: 5.863545447937213e-05
step: 510, loss: 1.54336157720536e-05
step: 520, loss: 8.829592115944251e-05
step: 530, loss: 2.4043927624006756e-05
epoch 18: dev_f1=0.8681166126793152, f1=0.7467980295566501, best_f1=0.7902298850574713
step: 0, loss: 0.00012907372729387134
step: 10, loss: 8.048889867495745e-05
step: 20, loss: 1.968745345948264e-05
step: 30, loss: 4.8641599278198555e-05
step: 40, loss: 0.000146032907650806
step: 50, loss: 0.0301187913864851
step: 60, loss: 1.5638459444744512e-05
step: 70, loss: 0.0005872587789781392
step: 80, loss: 0.003109693294391036
step: 90, loss: 7.713151717325673e-05
step: 100, loss: 0.0002836345520336181
step: 110, loss: 3.619068957050331e-05
step: 120, loss: 0.0001145399219240062
step: 130, loss: 4.9211423174710944e-05
step: 140, loss: 6.237297202460468e-05
step: 150, loss: 0.00011231491953367367
step: 160, loss: 9.778293315321207e-05
step: 170, loss: 0.002881744410842657
step: 180, loss: 6.0961883718846366e-05
step: 190, loss: 0.0006407411419786513
step: 200, loss: 3.6691366403829306e-05
step: 210, loss: 4.449998232303187e-05
step: 220, loss: 0.0026444068644195795
step: 230, loss: 0.00010921243665507063
step: 240, loss: 0.00015290734882000834
step: 250, loss: 0.00030140773742459714
step: 260, loss: 2.0045377823407762e-05
step: 270, loss: 0.00011006033309968188
step: 280, loss: 1.557524228701368e-05
step: 290, loss: 2.2190741219674237e-05
step: 300, loss: 2.8682434276561253e-05
step: 310, loss: 1.7318594473181292e-05
step: 320, loss: 0.00013030061381869018
step: 330, loss: 2.079771365970373e-05
step: 340, loss: 1.7706022845231928e-05
step: 350, loss: 3.171092248521745e-05
step: 360, loss: 0.00034572952426970005
step: 370, loss: 5.3230731282383204e-05
step: 380, loss: 2.455976755300071e-05
step: 390, loss: 0.000750302686356008
step: 400, loss: 0.0006710482412017882
step: 410, loss: 9.674973989604041e-05
step: 420, loss: 4.273648664820939e-05
step: 430, loss: 5.8137698943028226e-05
step: 440, loss: 2.1434752852655947e-05
step: 450, loss: 1.9739974959520623e-05
step: 460, loss: 0.007417713291943073
step: 470, loss: 3.367464159964584e-05
step: 480, loss: 0.0005630208761431277
step: 490, loss: 0.00017642298189457506
step: 500, loss: 0.00011422089301049709
step: 510, loss: 3.218104757252149e-05
step: 520, loss: 0.00017452341853640974
step: 530, loss: 3.733931589522399e-05
epoch 19: dev_f1=0.8718877320054323, f1=0.7596751075011945, best_f1=0.7902298850574713
step: 0, loss: 0.00020495621720328927
step: 10, loss: 2.4685083189979196e-05
step: 20, loss: 2.3021091692498885e-05
step: 30, loss: 0.007311485707759857
step: 40, loss: 0.00023123802384361625
step: 50, loss: 3.089172241743654e-05
step: 60, loss: 2.1393785573309287e-05
step: 70, loss: 0.00017587633919902146
step: 80, loss: 0.0024063019081950188
step: 90, loss: 0.00031104026129469275
step: 100, loss: 0.00013256391684990376
step: 110, loss: 2.0991488781874068e-05
step: 120, loss: 1.887185499072075e-05
step: 130, loss: 8.73142562340945e-05
step: 140, loss: 4.5245655201142654e-05
step: 150, loss: 8.310706471092999e-05
step: 160, loss: 0.020827973261475563
step: 170, loss: 0.0014087818562984467
step: 180, loss: 0.0007718544802628458
step: 190, loss: 0.0001124856062233448
step: 200, loss: 2.661620055732783e-05
step: 210, loss: 0.000696424045599997
step: 220, loss: 1.3448167919705156e-05
step: 230, loss: 0.03940349817276001
step: 240, loss: 3.326277146697976e-05
step: 250, loss: 9.361473348690197e-05
step: 260, loss: 3.368213583598845e-05
step: 270, loss: 9.090633830055594e-05
step: 280, loss: 0.004029788542538881
step: 290, loss: 6.018149360897951e-05
step: 300, loss: 3.799782643909566e-05
step: 310, loss: 0.00014120440755505115
step: 320, loss: 7.293592352652922e-05
step: 330, loss: 4.088915011379868e-05
step: 340, loss: 0.0003117772575933486
step: 350, loss: 2.2834808987681754e-05
step: 360, loss: 4.103815808775835e-05
step: 370, loss: 5.993132072035223e-05
step: 380, loss: 5.9256395616102964e-05
step: 390, loss: 0.00018846413877326995
step: 400, loss: 2.7662970751407556e-05
step: 410, loss: 2.3646867703064345e-05
step: 420, loss: 4.552894097287208e-05
step: 430, loss: 9.227939881384373e-05
step: 440, loss: 2.096899515890982e-05
step: 450, loss: 0.00011343754886183888
step: 460, loss: 0.0001126904899138026
step: 470, loss: 1.6983156456262805e-05
step: 480, loss: 4.432315472513437e-05
step: 490, loss: 3.9200800529215485e-05
step: 500, loss: 2.6426483600516804e-05
step: 510, loss: 8.184972102753818e-05
step: 520, loss: 2.2566884581465274e-05
step: 530, loss: 2.4913393644965254e-05
epoch 20: dev_f1=0.8657657657657658, f1=0.7537735849056604, best_f1=0.7902298850574713
