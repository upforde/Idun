cuda
Device: cuda
step: 0, loss: 0.8570951223373413
step: 10, loss: 0.06815384328365326
step: 20, loss: 0.14987729489803314
step: 30, loss: 0.4979501962661743
step: 40, loss: 0.17995519936084747
step: 50, loss: 0.23500236868858337
step: 60, loss: 0.3122076094150543
step: 70, loss: 0.3150840103626251
step: 80, loss: 0.21792787313461304
step: 90, loss: 0.29272186756134033
step: 100, loss: 0.25752660632133484
step: 110, loss: 0.4681818187236786
step: 120, loss: 0.21808072924613953
step: 130, loss: 0.34002482891082764
step: 140, loss: 0.13986776769161224
step: 150, loss: 0.392685204744339
step: 160, loss: 0.23427924513816833
step: 170, loss: 0.12000171840190887
step: 180, loss: 0.310829222202301
step: 190, loss: 0.21413151919841766
step: 200, loss: 0.2996886074542999
step: 210, loss: 0.2085132896900177
step: 220, loss: 0.11495548486709595
step: 230, loss: 0.27619829773902893
step: 240, loss: 0.27195215225219727
step: 250, loss: 0.25916898250579834
step: 260, loss: 0.029123011976480484
step: 270, loss: 0.1651729941368103
step: 280, loss: 0.2745080888271332
step: 290, loss: 0.32608699798583984
step: 300, loss: 0.30472949147224426
step: 310, loss: 0.18959058821201324
step: 320, loss: 0.15960237383842468
step: 330, loss: 0.3255136013031006
step: 340, loss: 0.30836793780326843
step: 350, loss: 0.14137499034404755
step: 360, loss: 0.24537836015224457
step: 370, loss: 0.15610052645206451
step: 380, loss: 0.21643520891666412
epoch 1: dev_f1=0.5882352941176471, f1=0.5604113110539847, best_f1=0.5604113110539847
step: 0, loss: 0.19170041382312775
step: 10, loss: 0.11209635436534882
step: 20, loss: 0.2391325682401657
step: 30, loss: 0.21352618932724
step: 40, loss: 0.1301298886537552
step: 50, loss: 0.06429436802864075
step: 60, loss: 0.13459357619285583
step: 70, loss: 0.03098100610077381
step: 80, loss: 0.2432468980550766
step: 90, loss: 0.16896843910217285
step: 100, loss: 0.16839058697223663
step: 110, loss: 0.09318356215953827
step: 120, loss: 0.12071610987186432
step: 130, loss: 0.18392887711524963
step: 140, loss: 0.07092466950416565
step: 150, loss: 0.06916140764951706
step: 160, loss: 0.03879181668162346
step: 170, loss: 0.3028968870639801
step: 180, loss: 0.1617501974105835
step: 190, loss: 0.01755402982234955
step: 200, loss: 0.14225107431411743
step: 210, loss: 0.1577514111995697
step: 220, loss: 0.15261344611644745
step: 230, loss: 0.10656397044658661
step: 240, loss: 0.029494106769561768
step: 250, loss: 0.14731533825397491
step: 260, loss: 0.14592842757701874
step: 270, loss: 0.18166393041610718
step: 280, loss: 0.0313386395573616
step: 290, loss: 0.14756713807582855
step: 300, loss: 0.14152346551418304
step: 310, loss: 0.08575745671987534
step: 320, loss: 0.1543261557817459
step: 330, loss: 0.2463294118642807
step: 340, loss: 0.05592384934425354
step: 350, loss: 0.18935254216194153
step: 360, loss: 0.20404598116874695
step: 370, loss: 0.06376293301582336
step: 380, loss: 0.1422586739063263
epoch 2: dev_f1=0.7174447174447175, f1=0.695, best_f1=0.695
step: 0, loss: 0.10212504863739014
step: 10, loss: 0.07450202852487564
step: 20, loss: 0.08409364521503448
step: 30, loss: 0.031976453959941864
step: 40, loss: 0.07962009310722351
step: 50, loss: 0.16903382539749146
step: 60, loss: 0.09738066792488098
step: 70, loss: 0.07976911216974258
step: 80, loss: 0.17885613441467285
step: 90, loss: 0.09277509152889252
step: 100, loss: 0.14755825698375702
step: 110, loss: 0.09317713975906372
step: 120, loss: 0.18982701003551483
step: 130, loss: 0.11500294506549835
step: 140, loss: 0.06965457648038864
step: 150, loss: 0.061516571789979935
step: 160, loss: 0.018127838149666786
step: 170, loss: 0.14604759216308594
step: 180, loss: 0.11408943682909012
step: 190, loss: 0.052619654685258865
step: 200, loss: 0.14454229176044464
step: 210, loss: 0.08499766886234283
step: 220, loss: 0.11078217625617981
step: 230, loss: 0.06432594358921051
step: 240, loss: 0.0461428165435791
step: 250, loss: 0.06506849080324173
step: 260, loss: 0.014754367992281914
step: 270, loss: 0.09243027865886688
step: 280, loss: 0.014146104454994202
step: 290, loss: 0.06730090081691742
step: 300, loss: 0.037939995527267456
step: 310, loss: 0.11661174148321152
step: 320, loss: 0.031307775527238846
step: 330, loss: 0.060468222945928574
step: 340, loss: 0.024579085409641266
step: 350, loss: 0.023601435124874115
step: 360, loss: 0.030757756903767586
step: 370, loss: 0.09469472616910934
step: 380, loss: 0.07143096625804901
epoch 3: dev_f1=0.7083333333333334, f1=0.7219512195121951, best_f1=0.695
step: 0, loss: 0.04413542523980141
step: 10, loss: 0.04943685978651047
step: 20, loss: 0.04199127480387688
step: 30, loss: 0.10865586251020432
step: 40, loss: 0.16564759612083435
step: 50, loss: 0.03742928430438042
step: 60, loss: 0.13635845482349396
step: 70, loss: 0.03412172198295593
step: 80, loss: 0.11281991004943848
step: 90, loss: 0.13015559315681458
step: 100, loss: 0.04093140363693237
step: 110, loss: 0.2775312066078186
step: 120, loss: 0.06007866561412811
step: 130, loss: 0.09097020328044891
step: 140, loss: 0.03258749470114708
step: 150, loss: 0.06839368492364883
step: 160, loss: 0.03372376784682274
step: 170, loss: 0.054773781448602676
step: 180, loss: 0.04920925199985504
step: 190, loss: 0.04435189440846443
step: 200, loss: 0.06757890433073044
step: 210, loss: 0.08125011622905731
step: 220, loss: 0.05971846729516983
step: 230, loss: 0.016110673546791077
step: 240, loss: 0.03686398267745972
step: 250, loss: 0.07325658202171326
step: 260, loss: 0.04980187863111496
step: 270, loss: 0.22764337062835693
step: 280, loss: 0.09934505820274353
step: 290, loss: 0.12077515572309494
step: 300, loss: 0.08540572971105576
step: 310, loss: 0.11907114833593369
step: 320, loss: 0.16118022799491882
step: 330, loss: 0.12447530776262283
step: 340, loss: 0.007208226248621941
step: 350, loss: 0.14691610634326935
step: 360, loss: 0.09044893831014633
step: 370, loss: 0.14923851191997528
step: 380, loss: 0.1899782419204712
epoch 4: dev_f1=0.6962962962962963, f1=0.7025641025641026, best_f1=0.695
step: 0, loss: 0.1018521636724472
step: 10, loss: 0.030886631458997726
step: 20, loss: 0.0040601277723908424
step: 30, loss: 0.07977793365716934
step: 40, loss: 0.03828854113817215
step: 50, loss: 0.042250942438840866
step: 60, loss: 0.021447470411658287
step: 70, loss: 0.02530185878276825
step: 80, loss: 0.010253767482936382
step: 90, loss: 0.08329696953296661
step: 100, loss: 0.043025579303503036
step: 110, loss: 0.07112594693899155
step: 120, loss: 0.008882591500878334
step: 130, loss: 0.07281278818845749
step: 140, loss: 0.015403829514980316
step: 150, loss: 0.012468276545405388
step: 160, loss: 0.070072703063488
step: 170, loss: 0.11099547147750854
step: 180, loss: 0.04270367696881294
step: 190, loss: 0.09046338498592377
step: 200, loss: 0.0860450491309166
step: 210, loss: 0.11237593740224838
step: 220, loss: 0.029449449852108955
step: 230, loss: 0.046028558164834976
step: 240, loss: 0.15525561571121216
step: 250, loss: 0.021158475428819656
step: 260, loss: 0.10795898735523224
step: 270, loss: 0.005384291987866163
step: 280, loss: 0.14102430641651154
step: 290, loss: 0.0985797718167305
step: 300, loss: 0.04513787105679512
step: 310, loss: 0.03548617288470268
step: 320, loss: 0.012289018370211124
step: 330, loss: 0.07572025805711746
step: 340, loss: 0.07987654209136963
step: 350, loss: 0.11881361156702042
step: 360, loss: 0.016520585864782333
step: 370, loss: 0.05065340921282768
step: 380, loss: 0.06206067278981209
epoch 5: dev_f1=0.6965174129353234, f1=0.6836734693877551, best_f1=0.695
step: 0, loss: 0.12940537929534912
step: 10, loss: 0.07964900135993958
step: 20, loss: 0.037547554820775986
step: 30, loss: 0.09654583781957626
step: 40, loss: 0.04908150061964989
step: 50, loss: 0.02367352694272995
step: 60, loss: 0.031356219202280045
step: 70, loss: 0.00014175070100463927
step: 80, loss: 0.19778361916542053
step: 90, loss: 0.04329906776547432
step: 100, loss: 0.011495621874928474
step: 110, loss: 0.032250698655843735
step: 120, loss: 0.06692469865083694
step: 130, loss: 0.04932626336812973
step: 140, loss: 0.022521087899804115
step: 150, loss: 0.0503060519695282
step: 160, loss: 0.06318818777799606
step: 170, loss: 0.04434485360980034
step: 180, loss: 0.055698245763778687
step: 190, loss: 0.0024802940897643566
step: 200, loss: 0.01557200402021408
step: 210, loss: 0.00912536308169365
step: 220, loss: 0.08412958681583405
step: 230, loss: 0.12344134598970413
step: 240, loss: 0.029963726177811623
step: 250, loss: 0.0073623559437692165
step: 260, loss: 0.10069394111633301
step: 270, loss: 0.017901506274938583
step: 280, loss: 0.0007045153179205954
step: 290, loss: 0.047858402132987976
step: 300, loss: 0.009483423084020615
step: 310, loss: 0.07571166008710861
step: 320, loss: 0.045864906162023544
step: 330, loss: 0.010435860604047775
step: 340, loss: 0.05793977901339531
step: 350, loss: 0.07922860980033875
step: 360, loss: 0.06590709835290909
step: 370, loss: 0.02537211962044239
step: 380, loss: 0.08544278889894485
epoch 6: dev_f1=0.719626168224299, f1=0.7153652392947103, best_f1=0.7153652392947103
step: 0, loss: 0.023220160976052284
step: 10, loss: 0.03499211370944977
step: 20, loss: 0.10148131847381592
step: 30, loss: 0.005073795560747385
step: 40, loss: 0.06986898928880692
step: 50, loss: 0.01119999773800373
step: 60, loss: 0.09225787222385406
step: 70, loss: 0.09529200196266174
step: 80, loss: 0.05361644923686981
step: 90, loss: 0.031061779707670212
step: 100, loss: 0.12200654298067093
step: 110, loss: 0.01712004281580448
step: 120, loss: 0.053866639733314514
step: 130, loss: 0.04601120576262474
step: 140, loss: 0.033751387149095535
step: 150, loss: 0.002146545797586441
step: 160, loss: 0.007738342974334955
step: 170, loss: 0.03193114325404167
step: 180, loss: 0.15499679744243622
step: 190, loss: 0.027289539575576782
step: 200, loss: 0.03454536572098732
step: 210, loss: 0.12447613477706909
step: 220, loss: 0.07931293547153473
step: 230, loss: 0.011551152914762497
step: 240, loss: 0.022304115816950798
step: 250, loss: 0.0456254817545414
step: 260, loss: 0.05817156285047531
step: 270, loss: 0.04519461467862129
step: 280, loss: 0.07804102450609207
step: 290, loss: 0.07005146145820618
step: 300, loss: 0.004821429960429668
step: 310, loss: 0.009624858386814594
step: 320, loss: 0.12227097898721695
step: 330, loss: 0.011080092750489712
step: 340, loss: 0.14350105822086334
step: 350, loss: 0.032385848462581635
step: 360, loss: 0.021924322471022606
step: 370, loss: 0.03551782667636871
step: 380, loss: 0.03538510203361511
epoch 7: dev_f1=0.7149532710280374, f1=0.7231920199501246, best_f1=0.7153652392947103
step: 0, loss: 0.15223069489002228
step: 10, loss: 0.015897627919912338
step: 20, loss: 0.032364971935749054
step: 30, loss: 0.05924500897526741
step: 40, loss: 0.004110788460820913
step: 50, loss: 0.1040642112493515
step: 60, loss: 0.05470968782901764
step: 70, loss: 0.006416291929781437
step: 80, loss: 0.08077758550643921
step: 90, loss: 0.12665964663028717
step: 100, loss: 0.11470630764961243
step: 110, loss: 0.020088378340005875
step: 120, loss: 0.06375953555107117
step: 130, loss: 0.0008422959363088012
step: 140, loss: 0.01368052326142788
step: 150, loss: 0.035543814301490784
step: 160, loss: 0.04987137019634247
step: 170, loss: 0.009647658094763756
step: 180, loss: 0.054095882922410965
step: 190, loss: 0.07677347213029861
step: 200, loss: 0.020654354244470596
step: 210, loss: 0.03762270137667656
step: 220, loss: 0.06530310213565826
step: 230, loss: 0.0767536386847496
step: 240, loss: 0.0016501715872436762
step: 250, loss: 0.06874420493841171
step: 260, loss: 0.062395110726356506
step: 270, loss: 0.11307014524936676
step: 280, loss: 0.0031664599664509296
step: 290, loss: 0.07312899827957153
step: 300, loss: 0.052544523030519485
step: 310, loss: 0.029292341321706772
step: 320, loss: 0.007869953289628029
step: 330, loss: 0.002097024582326412
step: 340, loss: 0.02099684625864029
step: 350, loss: 0.012411106377840042
step: 360, loss: 0.004478129558265209
step: 370, loss: 0.01570417732000351
step: 380, loss: 0.029968220740556717
epoch 8: dev_f1=0.7230046948356808, f1=0.7029702970297028, best_f1=0.7029702970297028
step: 0, loss: 0.01199396513402462
step: 10, loss: 0.005693511571735144
step: 20, loss: 0.00015893735690042377
step: 30, loss: 0.06480050832033157
step: 40, loss: 0.0015779788373038173
step: 50, loss: 0.014695504680275917
step: 60, loss: 0.12988464534282684
step: 70, loss: 0.10501904040575027
step: 80, loss: 0.03105039894580841
step: 90, loss: 0.054133184254169464
step: 100, loss: 0.06592690199613571
step: 110, loss: 0.00015305641863960773
step: 120, loss: 0.03873617202043533
step: 130, loss: 0.001218615216203034
step: 140, loss: 0.03288748115301132
step: 150, loss: 0.035559773445129395
step: 160, loss: 0.0250347089022398
step: 170, loss: 0.059042803943157196
step: 180, loss: 0.09202714264392853
step: 190, loss: 0.327118843793869
step: 200, loss: 0.007203411776572466
step: 210, loss: 0.07522105425596237
step: 220, loss: 0.041160181164741516
step: 230, loss: 0.06191660091280937
step: 240, loss: 0.07493509352207184
step: 250, loss: 0.012921526096761227
step: 260, loss: 0.0854056105017662
step: 270, loss: 0.07018374651670456
step: 280, loss: 0.03220439329743385
step: 290, loss: 0.05653198063373566
step: 300, loss: 0.00035095971543341875
step: 310, loss: 0.017054114490747452
step: 320, loss: 0.017571408301591873
step: 330, loss: 0.1305714249610901
step: 340, loss: 0.0033654686994850636
step: 350, loss: 0.040541552007198334
step: 360, loss: 0.0671469047665596
step: 370, loss: 0.057485297322273254
step: 380, loss: 0.09584048390388489
epoch 9: dev_f1=0.7306791569086649, f1=0.7146401985111663, best_f1=0.7146401985111663
step: 0, loss: 0.06176290288567543
step: 10, loss: 0.0967414379119873
step: 20, loss: 0.01937129721045494
step: 30, loss: 0.013088714331388474
step: 40, loss: 0.007714443374425173
step: 50, loss: 0.02167505770921707
step: 60, loss: 0.03671512007713318
step: 70, loss: 0.013693543151021004
step: 80, loss: 0.0016984139801934361
step: 90, loss: 0.0023794251028448343
step: 100, loss: 0.005740954540669918
step: 110, loss: 0.07454876601696014
step: 120, loss: 0.0074190860614180565
step: 130, loss: 0.010165221989154816
step: 140, loss: 0.004896317142993212
step: 150, loss: 0.02500651404261589
step: 160, loss: 0.012359421700239182
step: 170, loss: 0.0014124286826699972
step: 180, loss: 0.0026587890461087227
step: 190, loss: 0.01869210973381996
step: 200, loss: 0.0007836110889911652
step: 210, loss: 0.11192638427019119
step: 220, loss: 0.007620618678629398
step: 230, loss: 0.021228328347206116
step: 240, loss: 0.0481448769569397
step: 250, loss: 0.07483188062906265
step: 260, loss: 0.0065747275948524475
step: 270, loss: 0.028733955696225166
step: 280, loss: 0.010997717268764973
step: 290, loss: 0.004130782093852758
step: 300, loss: 0.009893138892948627
step: 310, loss: 0.0004369376110844314
step: 320, loss: 0.01010197028517723
step: 330, loss: 0.04089175537228584
step: 340, loss: 0.00183407636359334
step: 350, loss: 0.02055647410452366
step: 360, loss: 0.08776033669710159
step: 370, loss: 0.01854562573134899
step: 380, loss: 0.03103322722017765
epoch 10: dev_f1=0.7079207920792079, f1=0.7183462532299743, best_f1=0.7146401985111663
step: 0, loss: 0.020311692729592323
step: 10, loss: 0.018327638506889343
step: 20, loss: 0.048741117119789124
step: 30, loss: 0.0006073176627978683
step: 40, loss: 0.03818390145897865
step: 50, loss: 0.06991980969905853
step: 60, loss: 0.0204562209546566
step: 70, loss: 0.0031805727630853653
step: 80, loss: 0.00010727596963988617
step: 90, loss: 0.030866939574480057
step: 100, loss: 0.005712020210921764
step: 110, loss: 0.008447089232504368
step: 120, loss: 0.04526878520846367
step: 130, loss: 0.013876719400286674
step: 140, loss: 0.043502531945705414
step: 150, loss: 0.00431604590266943
step: 160, loss: 0.00020430229778867215
step: 170, loss: 0.040742456912994385
step: 180, loss: 0.008269375190138817
step: 190, loss: 0.030872153118252754
step: 200, loss: 0.007639194838702679
step: 210, loss: 0.041536860167980194
step: 220, loss: 0.015171944163739681
step: 230, loss: 0.07486508786678314
step: 240, loss: 8.033939229790121e-05
step: 250, loss: 0.024536969140172005
step: 260, loss: 0.016842840239405632
step: 270, loss: 0.04538656771183014
step: 280, loss: 4.0857481508282945e-05
step: 290, loss: 0.04434909299015999
step: 300, loss: 0.061217520385980606
step: 310, loss: 0.04744107276201248
step: 320, loss: 0.002378554316237569
step: 330, loss: 0.04790825769305229
step: 340, loss: 0.050437457859516144
step: 350, loss: 0.1833307296037674
step: 360, loss: 0.11859490722417831
step: 370, loss: 0.014569137245416641
step: 380, loss: 0.00260849017649889
epoch 11: dev_f1=0.7259953161592505, f1=0.7167070217917676, best_f1=0.7146401985111663
step: 0, loss: 0.0021019114647060633
step: 10, loss: 0.017714710906147957
step: 20, loss: 0.03225037455558777
step: 30, loss: 0.034819938242435455
step: 40, loss: 0.0007958306232467294
step: 50, loss: 4.969620567862876e-05
step: 60, loss: 0.0016037651803344488
step: 70, loss: 0.045520104467868805
step: 80, loss: 0.04152742400765419
step: 90, loss: 0.01481712143868208
step: 100, loss: 0.023222915828227997
step: 110, loss: 0.00010773102985695004
step: 120, loss: 0.06401053071022034
step: 130, loss: 0.03362317383289337
step: 140, loss: 0.021893372759222984
step: 150, loss: 0.0012631957652047276
step: 160, loss: 0.09482031315565109
step: 170, loss: 0.04055798053741455
step: 180, loss: 0.0041901832446455956
step: 190, loss: 0.05969611927866936
step: 200, loss: 0.05544699355959892
step: 210, loss: 0.000678337411954999
step: 220, loss: 0.007950539700686932
step: 230, loss: 0.10100657492876053
step: 240, loss: 0.0813537985086441
step: 250, loss: 0.08268794417381287
step: 260, loss: 0.07454518228769302
step: 270, loss: 0.019618786871433258
step: 280, loss: 0.05726815015077591
step: 290, loss: 0.04002461954951286
step: 300, loss: 0.0073951538652181625
step: 310, loss: 0.020362693816423416
step: 320, loss: 0.0038290596567094326
step: 330, loss: 0.0703040063381195
step: 340, loss: 0.02740277163684368
step: 350, loss: 0.04485716670751572
step: 360, loss: 0.07144898921251297
step: 370, loss: 0.051981061697006226
step: 380, loss: 0.053694482892751694
epoch 12: dev_f1=0.7256235827664399, f1=0.722488038277512, best_f1=0.7146401985111663
step: 0, loss: 0.08801928907632828
step: 10, loss: 0.0662614107131958
step: 20, loss: 0.026132918894290924
step: 30, loss: 0.040373485535383224
step: 40, loss: 0.00793921947479248
step: 50, loss: 0.07493526488542557
step: 60, loss: 0.10960868746042252
step: 70, loss: 0.010442257858812809
step: 80, loss: 0.0010810884414240718
step: 90, loss: 0.06334514170885086
step: 100, loss: 0.03939799591898918
step: 110, loss: 0.055136922746896744
step: 120, loss: 0.0028363927267491817
step: 130, loss: 0.00270824134349823
step: 140, loss: 7.381593604804948e-05
step: 150, loss: 0.0005418210639618337
step: 160, loss: 0.0921960175037384
step: 170, loss: 0.007886095903813839
step: 180, loss: 0.03789833188056946
step: 190, loss: 0.0003537698066793382
step: 200, loss: 0.016456356272101402
step: 210, loss: 0.04338160157203674
step: 220, loss: 0.012771974317729473
step: 230, loss: 0.004690108820796013
step: 240, loss: 0.01676327735185623
step: 250, loss: 0.12795330584049225
step: 260, loss: 0.003629667917266488
step: 270, loss: 0.03058740869164467
step: 280, loss: 0.011725051328539848
step: 290, loss: 0.0015973401023074985
step: 300, loss: 0.00010538056812947616
step: 310, loss: 0.07795079052448273
step: 320, loss: 0.0031051042024046183
step: 330, loss: 0.05498312786221504
step: 340, loss: 0.016510192304849625
step: 350, loss: 0.0007364794728346169
step: 360, loss: 0.0013158827787265182
step: 370, loss: 0.01636243239045143
step: 380, loss: 0.0016012529376894236
epoch 13: dev_f1=0.7342995169082126, f1=0.7371134020618555, best_f1=0.7371134020618555
step: 0, loss: 0.0014777444303035736
step: 10, loss: 0.03247525170445442
step: 20, loss: 0.0013195961946621537
step: 30, loss: 0.004580957815051079
step: 40, loss: 0.05140523985028267
step: 50, loss: 0.000685380888171494
step: 60, loss: 0.04295792803168297
step: 70, loss: 0.002267379779368639
step: 80, loss: 0.008975543081760406
step: 90, loss: 0.048681169748306274
step: 100, loss: 6.783092976547778e-05
step: 110, loss: 0.013581234961748123
step: 120, loss: 0.026599973440170288
step: 130, loss: 7.373512926278636e-05
step: 140, loss: 0.0024694353342056274
step: 150, loss: 0.0023077474907040596
step: 160, loss: 0.0012673799647018313
step: 170, loss: 0.0620453804731369
step: 180, loss: 0.00011478715168777853
step: 190, loss: 5.6876480812206864e-05
step: 200, loss: 4.086368790012784e-05
step: 210, loss: 0.0008458843803964555
step: 220, loss: 0.015456641092896461
step: 230, loss: 0.23748283088207245
step: 240, loss: 5.971208884147927e-05
step: 250, loss: 0.00040175204048864543
step: 260, loss: 0.01023110095411539
step: 270, loss: 0.09689763933420181
step: 280, loss: 0.07000277191400528
step: 290, loss: 0.0006827180041000247
step: 300, loss: 0.028883054852485657
step: 310, loss: 0.003480124520137906
step: 320, loss: 0.003953386098146439
step: 330, loss: 0.024017300456762314
step: 340, loss: 0.11548399180173874
step: 350, loss: 0.017305899411439896
step: 360, loss: 0.015201834961771965
step: 370, loss: 0.03666163980960846
step: 380, loss: 0.017765803262591362
epoch 14: dev_f1=0.7169811320754718, f1=0.7360406091370559, best_f1=0.7371134020618555
step: 0, loss: 0.024845095351338387
step: 10, loss: 0.014424906112253666
step: 20, loss: 0.019521256908774376
step: 30, loss: 6.0266294894972816e-05
step: 40, loss: 0.03022533655166626
step: 50, loss: 4.109190922463313e-05
step: 60, loss: 0.00012731176684610546
step: 70, loss: 0.015878628939390182
step: 80, loss: 0.053155090659856796
step: 90, loss: 0.01464671641588211
step: 100, loss: 0.0003142811474390328
step: 110, loss: 0.04694553464651108
step: 120, loss: 0.044582027941942215
step: 130, loss: 0.0006631696596741676
step: 140, loss: 0.0005704888608306646
step: 150, loss: 0.0052622100338339806
step: 160, loss: 0.001823168946430087
step: 170, loss: 0.0002760257921181619
step: 180, loss: 0.03344035893678665
step: 190, loss: 0.0012383691500872374
step: 200, loss: 0.04002949967980385
step: 210, loss: 2.8941240088897757e-05
step: 220, loss: 3.3165491913678125e-05
step: 230, loss: 0.00295906700193882
step: 240, loss: 0.05071480944752693
step: 250, loss: 0.0008385023102164268
step: 260, loss: 0.002482926705852151
step: 270, loss: 0.008046889677643776
step: 280, loss: 5.392995080910623e-05
step: 290, loss: 0.014271300286054611
step: 300, loss: 0.0007247778121381998
step: 310, loss: 0.019351143389940262
step: 320, loss: 0.044215794652700424
step: 330, loss: 0.03319684788584709
step: 340, loss: 0.018480811268091202
step: 350, loss: 0.07782521843910217
step: 360, loss: 0.006533067673444748
step: 370, loss: 0.028198864310979843
step: 380, loss: 0.024511512368917465
epoch 15: dev_f1=0.7245657568238213, f1=0.7080103359173127, best_f1=0.7371134020618555
step: 0, loss: 0.0011642674217000604
step: 10, loss: 0.0019723239820450544
step: 20, loss: 0.0025892758276313543
step: 30, loss: 0.025270214304327965
step: 40, loss: 0.0008901891415007412
step: 50, loss: 0.024542007595300674
step: 60, loss: 0.0698506087064743
step: 70, loss: 2.9287621146067977e-05
step: 80, loss: 0.007592613808810711
step: 90, loss: 0.0052913520485162735
step: 100, loss: 0.0027985642664134502
step: 110, loss: 0.0003941725299227983
step: 120, loss: 0.012607848271727562
step: 130, loss: 0.008602350950241089
step: 140, loss: 6.209926505107433e-05
step: 150, loss: 0.003981305751949549
step: 160, loss: 0.017920702695846558
step: 170, loss: 0.04716721922159195
step: 180, loss: 2.826321724569425e-05
step: 190, loss: 0.22679458558559418
step: 200, loss: 0.027306441217660904
step: 210, loss: 0.000888654962182045
step: 220, loss: 0.0018038098933175206
step: 230, loss: 0.05364861339330673
step: 240, loss: 5.420442175818607e-05
step: 250, loss: 0.0016317531699314713
step: 260, loss: 4.1821276681730524e-05
step: 270, loss: 0.033103056252002716
step: 280, loss: 0.019047798588871956
step: 290, loss: 0.0008697314187884331
step: 300, loss: 0.006220417562872171
step: 310, loss: 5.8867477491730824e-05
step: 320, loss: 6.913319521117955e-05
step: 330, loss: 0.0029843871016055346
step: 340, loss: 0.03655627369880676
step: 350, loss: 0.040574103593826294
step: 360, loss: 0.0036781819071620703
step: 370, loss: 0.031038714572787285
step: 380, loss: 0.0007975619519129395
epoch 16: dev_f1=0.7050000000000001, f1=0.7049608355091384, best_f1=0.7371134020618555
step: 0, loss: 0.009194226935505867
step: 10, loss: 0.004851918201893568
step: 20, loss: 0.03425747901201248
step: 30, loss: 0.014011836610734463
step: 40, loss: 0.054729163646698
step: 50, loss: 0.000565042020753026
step: 60, loss: 0.0023346878588199615
step: 70, loss: 0.020409129559993744
step: 80, loss: 0.004079651553183794
step: 90, loss: 0.021501971408724785
step: 100, loss: 0.020687665790319443
step: 110, loss: 0.055672310292720795
step: 120, loss: 0.005986807402223349
step: 130, loss: 0.037591926753520966
step: 140, loss: 0.0009717366192489862
step: 150, loss: 0.010081763379275799
step: 160, loss: 2.852766374417115e-05
step: 170, loss: 0.0014423372922465205
step: 180, loss: 0.006084430497139692
step: 190, loss: 0.05806609243154526
step: 200, loss: 0.03569759055972099
step: 210, loss: 0.06728611141443253
step: 220, loss: 0.0022510450799018145
step: 230, loss: 0.049553077667951584
step: 240, loss: 0.04080374911427498
step: 250, loss: 0.0059165870770812035
step: 260, loss: 0.01847170665860176
step: 270, loss: 0.0011883890256285667
step: 280, loss: 0.0794910341501236
step: 290, loss: 0.0036638211458921432
step: 300, loss: 0.0012363444548100233
step: 310, loss: 2.5074472432606854e-05
step: 320, loss: 3.470310548436828e-05
step: 330, loss: 0.019769074395298958
step: 340, loss: 0.004259507171809673
step: 350, loss: 3.3816184441093355e-05
step: 360, loss: 0.00012858450645580888
step: 370, loss: 0.00013612299517262727
step: 380, loss: 0.029949091374874115
epoch 17: dev_f1=0.6940874035989718, f1=0.7010869565217391, best_f1=0.7371134020618555
step: 0, loss: 0.03692479059100151
step: 10, loss: 0.033738140016794205
step: 20, loss: 0.0002354000462219119
step: 30, loss: 0.008295254781842232
step: 40, loss: 0.0011729190591722727
step: 50, loss: 0.014347335323691368
step: 60, loss: 0.02870829962193966
step: 70, loss: 0.00023122027050703764
step: 80, loss: 0.045591190457344055
step: 90, loss: 0.09778869897127151
step: 100, loss: 0.00010415230644866824
step: 110, loss: 0.00034183962270617485
step: 120, loss: 0.03146021440625191
step: 130, loss: 0.007982526905834675
step: 140, loss: 0.0015516222920268774
step: 150, loss: 3.750837640836835e-05
step: 160, loss: 0.048388056457042694
step: 170, loss: 0.002574492711573839
step: 180, loss: 0.0005236809374764562
step: 190, loss: 0.00012976468133274466
step: 200, loss: 0.03527427837252617
step: 210, loss: 0.00038487304118461907
step: 220, loss: 0.031134193763136864
step: 230, loss: 0.016995694488286972
step: 240, loss: 0.00032219619606621563
step: 250, loss: 0.0566425621509552
step: 260, loss: 0.052602462470531464
step: 270, loss: 0.00026855006581172347
step: 280, loss: 0.0032875039614737034
step: 290, loss: 0.014575975015759468
step: 300, loss: 0.052292127162218094
step: 310, loss: 0.030958419665694237
step: 320, loss: 0.005645876284688711
step: 330, loss: 4.2264906369382516e-05
step: 340, loss: 0.04399565979838371
step: 350, loss: 6.23153755441308e-05
step: 360, loss: 0.0009413164225406945
step: 370, loss: 4.245964009896852e-05
step: 380, loss: 0.024280495941638947
epoch 18: dev_f1=0.7100000000000001, f1=0.7005347593582888, best_f1=0.7371134020618555
step: 0, loss: 0.020369892939925194
step: 10, loss: 0.012096177786588669
step: 20, loss: 0.0007668088073842227
step: 30, loss: 0.0224864911288023
step: 40, loss: 5.133684680913575e-05
step: 50, loss: 0.055392779409885406
step: 60, loss: 9.868461347650737e-05
step: 70, loss: 0.05590393766760826
step: 80, loss: 0.024590270593762398
step: 90, loss: 0.012806683778762817
step: 100, loss: 0.0008008643635548651
step: 110, loss: 0.0006965668289922178
step: 120, loss: 0.0187700092792511
step: 130, loss: 0.0001326005149167031
step: 140, loss: 4.0321720007341355e-05
step: 150, loss: 0.0056833834387362
step: 160, loss: 0.034757476300001144
step: 170, loss: 0.00010448202374391258
step: 180, loss: 0.00015885532775428146
step: 190, loss: 0.04528973251581192
step: 200, loss: 0.019321277737617493
step: 210, loss: 4.736061964649707e-05
step: 220, loss: 0.02110377512872219
step: 230, loss: 0.004864387679845095
step: 240, loss: 4.5144344767322764e-05
step: 250, loss: 0.012354387901723385
step: 260, loss: 0.00017569890769664198
step: 270, loss: 0.05295110121369362
step: 280, loss: 0.004122401122003794
step: 290, loss: 0.04119919613003731
step: 300, loss: 3.1574483728036284e-05
step: 310, loss: 0.019626842811703682
step: 320, loss: 0.0025905980728566647
step: 330, loss: 6.340360414469615e-05
step: 340, loss: 3.298236333648674e-05
step: 350, loss: 3.655004547908902e-05
step: 360, loss: 3.3600754250073805e-05
step: 370, loss: 0.024961378425359726
step: 380, loss: 0.030319461598992348
epoch 19: dev_f1=0.7032418952618454, f1=0.6951871657754011, best_f1=0.7371134020618555
step: 0, loss: 0.0001553259789943695
step: 10, loss: 0.01670522801578045
step: 20, loss: 0.057821113616228104
step: 30, loss: 0.04055167734622955
step: 40, loss: 0.03929930552840233
step: 50, loss: 0.005129833705723286
step: 60, loss: 0.02278990112245083
step: 70, loss: 0.028548650443553925
step: 80, loss: 0.0007981664384715259
step: 90, loss: 0.005335619207471609
step: 100, loss: 0.05814763531088829
step: 110, loss: 0.00015362555859610438
step: 120, loss: 0.0006403001607395709
step: 130, loss: 0.041440825909376144
step: 140, loss: 0.03394792228937149
step: 150, loss: 0.0001072390004992485
step: 160, loss: 2.4992543330881745e-05
step: 170, loss: 0.05958370119333267
step: 180, loss: 5.76623497181572e-05
step: 190, loss: 2.3290163881029002e-05
step: 200, loss: 0.0004255908716004342
step: 210, loss: 4.438959149410948e-05
step: 220, loss: 0.0036871740594506264
step: 230, loss: 0.00011663494660751894
step: 240, loss: 5.069173130323179e-05
step: 250, loss: 0.003192185191437602
step: 260, loss: 0.0003904253535438329
step: 270, loss: 0.0020968408789485693
step: 280, loss: 0.03412167355418205
step: 290, loss: 0.006356310099363327
step: 300, loss: 0.03636631742119789
step: 310, loss: 0.015148704871535301
step: 320, loss: 0.0012099319137632847
step: 330, loss: 0.0035393154248595238
step: 340, loss: 0.001032236497849226
step: 350, loss: 0.02025732956826687
step: 360, loss: 0.01751120574772358
step: 370, loss: 0.04318840056657791
step: 380, loss: 0.03631511330604553
epoch 20: dev_f1=0.6883468834688347, f1=0.6949152542372882, best_f1=0.7371134020618555
