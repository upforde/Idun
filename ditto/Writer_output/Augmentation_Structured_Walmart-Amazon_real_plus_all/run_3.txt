cuda
Device: cuda
step: 0, loss: 0.7725468873977661
step: 10, loss: 0.39465686678886414
step: 20, loss: 0.318734735250473
step: 30, loss: 0.38485899567604065
step: 40, loss: 0.4536117911338806
step: 50, loss: 0.1629324108362198
step: 60, loss: 0.5425205230712891
step: 70, loss: 0.3063282072544098
step: 80, loss: 0.31063300371170044
step: 90, loss: 0.4412584900856018
step: 100, loss: 0.23067137598991394
step: 110, loss: 0.28846028447151184
step: 120, loss: 0.3046225607395172
step: 130, loss: 0.34879985451698303
step: 140, loss: 0.5460116863250732
step: 150, loss: 0.23901675641536713
step: 160, loss: 0.16673986613750458
step: 170, loss: 0.3760412633419037
step: 180, loss: 0.21376639604568481
step: 190, loss: 0.25179657340049744
step: 200, loss: 0.20205576717853546
step: 210, loss: 0.25824612379074097
step: 220, loss: 0.581250011920929
step: 230, loss: 0.17808391153812408
step: 240, loss: 0.20988693833351135
step: 250, loss: 0.15011318027973175
step: 260, loss: 0.15414221584796906
step: 270, loss: 0.04547114297747612
step: 280, loss: 0.023962296545505524
step: 290, loss: 0.12363745272159576
step: 300, loss: 0.2554057836532593
step: 310, loss: 0.15119381248950958
step: 320, loss: 0.26594841480255127
step: 330, loss: 0.15489356219768524
step: 340, loss: 0.28378796577453613
step: 350, loss: 0.05574336647987366
step: 360, loss: 0.15878765285015106
step: 370, loss: 0.27860915660858154
step: 380, loss: 0.2792445719242096
epoch 1: dev_f1=0.5191256830601094, f1=0.5468354430379747, best_f1=0.5468354430379747
step: 0, loss: 0.11999727040529251
step: 10, loss: 0.3408830761909485
step: 20, loss: 0.16874255239963531
step: 30, loss: 0.1643572598695755
step: 40, loss: 0.34592968225479126
step: 50, loss: 0.04380451515316963
step: 60, loss: 0.13333015143871307
step: 70, loss: 0.08342430740594864
step: 80, loss: 0.0403619185090065
step: 90, loss: 0.0644053965806961
step: 100, loss: 0.051111288368701935
step: 110, loss: 0.0638832300901413
step: 120, loss: 0.07293941080570221
step: 130, loss: 0.10120943933725357
step: 140, loss: 0.09914495050907135
step: 150, loss: 0.209497332572937
step: 160, loss: 0.1181177943944931
step: 170, loss: 0.11600376665592194
step: 180, loss: 0.06810243427753448
step: 190, loss: 0.09611312299966812
step: 200, loss: 0.08472847193479538
step: 210, loss: 0.11608314514160156
step: 220, loss: 0.10705143958330154
step: 230, loss: 0.05985533446073532
step: 240, loss: 0.22198036313056946
step: 250, loss: 0.06585250794887543
step: 260, loss: 0.24754156172275543
step: 270, loss: 0.16637958586215973
step: 280, loss: 0.020375946536660194
step: 290, loss: 0.08773699402809143
step: 300, loss: 0.017542479559779167
step: 310, loss: 0.15840575098991394
step: 320, loss: 0.03618212044239044
step: 330, loss: 0.22909817099571228
step: 340, loss: 0.15348725020885468
step: 350, loss: 0.04147331044077873
step: 360, loss: 0.0778411403298378
step: 370, loss: 0.07019179314374924
step: 380, loss: 0.07764700055122375
epoch 2: dev_f1=0.6522781774580335, f1=0.6843373493975903, best_f1=0.6843373493975903
step: 0, loss: 0.03594043850898743
step: 10, loss: 0.1093776598572731
step: 20, loss: 0.051927462220191956
step: 30, loss: 0.002099307719618082
step: 40, loss: 0.08058713376522064
step: 50, loss: 0.04918335750699043
step: 60, loss: 0.0945982113480568
step: 70, loss: 0.04556684568524361
step: 80, loss: 0.08543693274259567
step: 90, loss: 0.05727469548583031
step: 100, loss: 0.20274697244167328
step: 110, loss: 0.11961551010608673
step: 120, loss: 0.15505152940750122
step: 130, loss: 0.1072019711136818
step: 140, loss: 0.027435554191470146
step: 150, loss: 0.16054442524909973
step: 160, loss: 0.0733313262462616
step: 170, loss: 0.2024586796760559
step: 180, loss: 0.06362025439739227
step: 190, loss: 0.022708803415298462
step: 200, loss: 0.029846185818314552
step: 210, loss: 0.15600207448005676
step: 220, loss: 0.05630679801106453
step: 230, loss: 0.0780290886759758
step: 240, loss: 0.052142076194286346
step: 250, loss: 0.08765563368797302
step: 260, loss: 0.1426430642604828
step: 270, loss: 0.07851633429527283
step: 280, loss: 0.09366817027330399
step: 290, loss: 0.05310633406043053
step: 300, loss: 0.02249271236360073
step: 310, loss: 0.06505865603685379
step: 320, loss: 0.09926354885101318
step: 330, loss: 0.15499934554100037
step: 340, loss: 0.24092890322208405
step: 350, loss: 0.020053332671523094
step: 360, loss: 0.06216301769018173
step: 370, loss: 0.07412037998437881
step: 380, loss: 0.06785283982753754
epoch 3: dev_f1=0.6650943396226415, f1=0.6864988558352403, best_f1=0.6864988558352403
step: 0, loss: 0.01944570802152157
step: 10, loss: 0.05078243464231491
step: 20, loss: 0.32353949546813965
step: 30, loss: 0.055111341178417206
step: 40, loss: 0.03215790167450905
step: 50, loss: 0.10417158901691437
step: 60, loss: 0.03675839677453041
step: 70, loss: 0.16452278196811676
step: 80, loss: 0.08897260576486588
step: 90, loss: 0.08926175534725189
step: 100, loss: 0.1350153237581253
step: 110, loss: 0.02815062180161476
step: 120, loss: 0.12023431807756424
step: 130, loss: 0.04609730839729309
step: 140, loss: 0.09293535351753235
step: 150, loss: 0.0423099547624588
step: 160, loss: 0.07447748631238937
step: 170, loss: 0.030957674607634544
step: 180, loss: 0.07390322536230087
step: 190, loss: 0.04265324026346207
step: 200, loss: 0.1444578766822815
step: 210, loss: 0.13708196580410004
step: 220, loss: 0.04519198089838028
step: 230, loss: 0.007862862199544907
step: 240, loss: 0.057803038507699966
step: 250, loss: 0.0984182059764862
step: 260, loss: 0.0595095269382
step: 270, loss: 0.10682974755764008
step: 280, loss: 0.03301643580198288
step: 290, loss: 0.08295764774084091
step: 300, loss: 0.0794370099902153
step: 310, loss: 0.1876082420349121
step: 320, loss: 0.028521224856376648
step: 330, loss: 0.014233537949621677
step: 340, loss: 0.05512789264321327
step: 350, loss: 0.12021813541650772
step: 360, loss: 0.0008654621778987348
step: 370, loss: 0.1692105084657669
step: 380, loss: 0.08438532054424286
epoch 4: dev_f1=0.6923076923076923, f1=0.7300771208226221, best_f1=0.7300771208226221
step: 0, loss: 0.038837507367134094
step: 10, loss: 0.08489495515823364
step: 20, loss: 0.04648994654417038
step: 30, loss: 0.09256837517023087
step: 40, loss: 0.016252825036644936
step: 50, loss: 0.1001303493976593
step: 60, loss: 0.0010459031909704208
step: 70, loss: 0.0004247108881827444
step: 80, loss: 0.05817566066980362
step: 90, loss: 0.026341473683714867
step: 100, loss: 0.06656329333782196
step: 110, loss: 0.12980371713638306
step: 120, loss: 0.12608610093593597
step: 130, loss: 0.15125435590744019
step: 140, loss: 0.06030910834670067
step: 150, loss: 0.04351862892508507
step: 160, loss: 0.01595046930015087
step: 170, loss: 0.1282593160867691
step: 180, loss: 0.0655340850353241
step: 190, loss: 0.09169789403676987
step: 200, loss: 0.11361505836248398
step: 210, loss: 0.0777449905872345
step: 220, loss: 0.17919649183750153
step: 230, loss: 0.18659856915473938
step: 240, loss: 0.08625373244285583
step: 250, loss: 0.07608199119567871
step: 260, loss: 0.019118476659059525
step: 270, loss: 0.018351860344409943
step: 280, loss: 0.17664530873298645
step: 290, loss: 0.12924204766750336
step: 300, loss: 0.019671550020575523
step: 310, loss: 0.1266217827796936
step: 320, loss: 0.18707133829593658
step: 330, loss: 0.058945417404174805
step: 340, loss: 0.06378809362649918
step: 350, loss: 0.12945666909217834
step: 360, loss: 0.09973730146884918
step: 370, loss: 0.05303255096077919
step: 380, loss: 0.07066473364830017
epoch 5: dev_f1=0.7107843137254902, f1=0.6825775656324582, best_f1=0.6825775656324582
step: 0, loss: 0.025509942322969437
step: 10, loss: 0.05981672555208206
step: 20, loss: 0.05254124850034714
step: 30, loss: 0.026529287919402122
step: 40, loss: 0.0668528601527214
step: 50, loss: 0.11129394173622131
step: 60, loss: 0.006436109077185392
step: 70, loss: 0.021550791338086128
step: 80, loss: 0.07936345040798187
step: 90, loss: 0.06332751363515854
step: 100, loss: 0.04233599826693535
step: 110, loss: 0.10346351563930511
step: 120, loss: 0.07520866394042969
step: 130, loss: 0.05905311927199364
step: 140, loss: 0.06361187249422073
step: 150, loss: 0.05773787200450897
step: 160, loss: 0.03157949447631836
step: 170, loss: 0.027225865051150322
step: 180, loss: 0.059066273272037506
step: 190, loss: 0.01385609619319439
step: 200, loss: 0.02981666848063469
step: 210, loss: 0.043426815420389175
step: 220, loss: 0.014711945317685604
step: 230, loss: 0.013997461646795273
step: 240, loss: 0.03366663306951523
step: 250, loss: 0.1733582466840744
step: 260, loss: 0.03586867079138756
step: 270, loss: 0.03895283490419388
step: 280, loss: 0.0030376287177205086
step: 290, loss: 0.007498479448258877
step: 300, loss: 0.059215519577264786
step: 310, loss: 0.024962669238448143
step: 320, loss: 0.06143983453512192
step: 330, loss: 0.0011249310337007046
step: 340, loss: 0.06886830180883408
step: 350, loss: 0.10895844548940659
step: 360, loss: 0.01196901872754097
step: 370, loss: 0.02279367297887802
step: 380, loss: 0.07413958013057709
epoch 6: dev_f1=0.6991869918699186, f1=0.6939890710382514, best_f1=0.6825775656324582
step: 0, loss: 0.020230084657669067
step: 10, loss: 0.14660687744617462
step: 20, loss: 0.14158084988594055
step: 30, loss: 0.08582288026809692
step: 40, loss: 0.023921841755509377
step: 50, loss: 0.06557369977235794
step: 60, loss: 0.004398029297590256
step: 70, loss: 0.04336405172944069
step: 80, loss: 0.023413823917508125
step: 90, loss: 0.012634390965104103
step: 100, loss: 0.03146374598145485
step: 110, loss: 0.007151598576456308
step: 120, loss: 0.2547619938850403
step: 130, loss: 0.13670940697193146
step: 140, loss: 0.04963281378149986
step: 150, loss: 0.10569204390048981
step: 160, loss: 0.0018328919541090727
step: 170, loss: 0.049616631120443344
step: 180, loss: 0.01187032088637352
step: 190, loss: 0.269284725189209
step: 200, loss: 0.11314773559570312
step: 210, loss: 0.09278738498687744
step: 220, loss: 0.05982549861073494
step: 230, loss: 0.13111643493175507
step: 240, loss: 0.011182836256921291
step: 250, loss: 0.013269136659801006
step: 260, loss: 0.0023061048705130816
step: 270, loss: 0.0013582204701378942
step: 280, loss: 0.09360872954130173
step: 290, loss: 0.05729559063911438
step: 300, loss: 0.06064281612634659
step: 310, loss: 0.11056052893400192
step: 320, loss: 0.009280787780880928
step: 330, loss: 0.05346355959773064
step: 340, loss: 0.10951918363571167
step: 350, loss: 0.0536399707198143
step: 360, loss: 0.007689815945923328
step: 370, loss: 0.06850115209817886
step: 380, loss: 0.009932970628142357
epoch 7: dev_f1=0.7416267942583731, f1=0.7577937649880095, best_f1=0.7577937649880095
step: 0, loss: 0.02135358192026615
step: 10, loss: 0.05310512334108353
step: 20, loss: 0.04332873597741127
step: 30, loss: 0.025962399318814278
step: 40, loss: 0.09498830884695053
step: 50, loss: 0.03085482493042946
step: 60, loss: 0.015203128568828106
step: 70, loss: 0.013811895623803139
step: 80, loss: 0.01737629808485508
step: 90, loss: 0.004588156007230282
step: 100, loss: 0.029459422454237938
step: 110, loss: 0.13795971870422363
step: 120, loss: 0.006877997890114784
step: 130, loss: 0.0031112832948565483
step: 140, loss: 0.009000600315630436
step: 150, loss: 0.014701743610203266
step: 160, loss: 0.09485364705324173
step: 170, loss: 0.11894838511943817
step: 180, loss: 0.0828663781285286
step: 190, loss: 0.014431430958211422
step: 200, loss: 0.06451268494129181
step: 210, loss: 0.04337354004383087
step: 220, loss: 0.08089740574359894
step: 230, loss: 0.016940083354711533
step: 240, loss: 0.03648968040943146
step: 250, loss: 0.086443230509758
step: 260, loss: 0.06699257344007492
step: 270, loss: 0.13406865298748016
step: 280, loss: 0.009042096324265003
step: 290, loss: 0.028849735856056213
step: 300, loss: 0.03371464088559151
step: 310, loss: 0.037679605185985565
step: 320, loss: 0.017131812870502472
step: 330, loss: 0.005840132012963295
step: 340, loss: 0.08860532194375992
step: 350, loss: 0.03416896611452103
step: 360, loss: 0.09298793226480484
step: 370, loss: 0.08060766756534576
step: 380, loss: 0.036901868879795074
epoch 8: dev_f1=0.7115384615384616, f1=0.7432762836185819, best_f1=0.7577937649880095
step: 0, loss: 0.002017433289438486
step: 10, loss: 0.00045257166493684053
step: 20, loss: 0.02970057539641857
step: 30, loss: 0.015514574944972992
step: 40, loss: 0.07940227538347244
step: 50, loss: 0.003191879251971841
step: 60, loss: 0.06242876499891281
step: 70, loss: 0.05094004049897194
step: 80, loss: 0.09484999626874924
step: 90, loss: 0.030090253800153732
step: 100, loss: 0.0034119451884180307
step: 110, loss: 0.05566480755805969
step: 120, loss: 0.020473061129450798
step: 130, loss: 0.03186420351266861
step: 140, loss: 0.02226710133254528
step: 150, loss: 0.051108866930007935
step: 160, loss: 0.006678397301584482
step: 170, loss: 0.06523439288139343
step: 180, loss: 0.07734059542417526
step: 190, loss: 0.004926555790007114
step: 200, loss: 0.02194092981517315
step: 210, loss: 0.05613092705607414
step: 220, loss: 0.05575984716415405
step: 230, loss: 0.035622552037239075
step: 240, loss: 0.04985015466809273
step: 250, loss: 0.03033185750246048
step: 260, loss: 0.046905115246772766
step: 270, loss: 0.029579544439911842
step: 280, loss: 0.02552562952041626
step: 290, loss: 0.0006733701447956264
step: 300, loss: 0.09226899594068527
step: 310, loss: 0.029888052493333817
step: 320, loss: 0.06084791198372841
step: 330, loss: 0.020924195647239685
step: 340, loss: 0.030315831303596497
step: 350, loss: 0.026505084708333015
step: 360, loss: 0.008142857812345028
step: 370, loss: 0.043857671320438385
step: 380, loss: 0.06534432619810104
epoch 9: dev_f1=0.7606382978723404, f1=0.7296587926509187, best_f1=0.7296587926509187
step: 0, loss: 0.043793268501758575
step: 10, loss: 0.01660175807774067
step: 20, loss: 0.007001493126153946
step: 30, loss: 0.015896467491984367
step: 40, loss: 0.015631699934601784
step: 50, loss: 0.07369206845760345
step: 60, loss: 0.006358730141073465
step: 70, loss: 0.04536935314536095
step: 80, loss: 0.02721652016043663
step: 90, loss: 0.10919024050235748
step: 100, loss: 0.031981002539396286
step: 110, loss: 0.06046225503087044
step: 120, loss: 0.004723627120256424
step: 130, loss: 0.030794238671660423
step: 140, loss: 0.033783942461013794
step: 150, loss: 0.003855277318507433
step: 160, loss: 0.033052925020456314
step: 170, loss: 0.08402357250452042
step: 180, loss: 0.00281759025529027
step: 190, loss: 0.005149969831109047
step: 200, loss: 0.05655934289097786
step: 210, loss: 0.03452498838305473
step: 220, loss: 0.05539083480834961
step: 230, loss: 0.012736901640892029
step: 240, loss: 0.1319936066865921
step: 250, loss: 0.034039027988910675
step: 260, loss: 0.05234723165631294
step: 270, loss: 0.0464949831366539
step: 280, loss: 0.01739686168730259
step: 290, loss: 0.0001743681641528383
step: 300, loss: 0.01124733965843916
step: 310, loss: 0.07325644046068192
step: 320, loss: 0.10839973390102386
step: 330, loss: 0.09705293923616409
step: 340, loss: 0.06286492198705673
step: 350, loss: 0.006625938229262829
step: 360, loss: 0.0033475307282060385
step: 370, loss: 0.007571074180305004
step: 380, loss: 0.01115218736231327
epoch 10: dev_f1=0.725925925925926, f1=0.7085427135678392, best_f1=0.7296587926509187
step: 0, loss: 0.04431325942277908
step: 10, loss: 0.0898468866944313
step: 20, loss: 0.018689913675189018
step: 30, loss: 0.009867849759757519
step: 40, loss: 0.0444277822971344
step: 50, loss: 0.02561582438647747
step: 60, loss: 0.02641412429511547
step: 70, loss: 0.04645726829767227
step: 80, loss: 0.09187936037778854
step: 90, loss: 0.01100260578095913
step: 100, loss: 0.11883622407913208
step: 110, loss: 0.04520874097943306
step: 120, loss: 0.09560608863830566
step: 130, loss: 0.027744557708501816
step: 140, loss: 0.012767870910465717
step: 150, loss: 0.0020560764241963625
step: 160, loss: 0.013252468779683113
step: 170, loss: 0.0001016805981635116
step: 180, loss: 0.27547216415405273
step: 190, loss: 0.014459868893027306
step: 200, loss: 0.0670921802520752
step: 210, loss: 0.00917143002152443
step: 220, loss: 0.003198174759745598
step: 230, loss: 0.03526289016008377
step: 240, loss: 0.02165665104985237
step: 250, loss: 0.07879607379436493
step: 260, loss: 0.06254951655864716
step: 270, loss: 0.07918770611286163
step: 280, loss: 0.06131286174058914
step: 290, loss: 0.10575588047504425
step: 300, loss: 0.03276980668306351
step: 310, loss: 0.03494562581181526
step: 320, loss: 7.967180135892704e-05
step: 330, loss: 0.05633311718702316
step: 340, loss: 0.015106280334293842
step: 350, loss: 0.07468260824680328
step: 360, loss: 0.011662553995847702
step: 370, loss: 0.07803220301866531
step: 380, loss: 0.020529689267277718
epoch 11: dev_f1=0.7244897959183673, f1=0.7108753315649867, best_f1=0.7296587926509187
step: 0, loss: 0.12185182422399521
step: 10, loss: 0.006707090884447098
step: 20, loss: 0.022694602608680725
step: 30, loss: 0.00459982780739665
step: 40, loss: 0.03042314015328884
step: 50, loss: 0.0013136302586644888
step: 60, loss: 0.0006195672322064638
step: 70, loss: 0.032105352729558945
step: 80, loss: 0.09026079624891281
step: 90, loss: 0.022994130849838257
step: 100, loss: 0.016867203637957573
step: 110, loss: 0.004747371189296246
step: 120, loss: 0.0038709305226802826
step: 130, loss: 0.029982896521687508
step: 140, loss: 0.07869058847427368
step: 150, loss: 0.00011876209464389831
step: 160, loss: 0.07473352551460266
step: 170, loss: 0.020395314320921898
step: 180, loss: 0.024307996034622192
step: 190, loss: 0.08581522852182388
step: 200, loss: 0.00018336510402150452
step: 210, loss: 0.043361224234104156
step: 220, loss: 0.007837883196771145
step: 230, loss: 0.0074112629517912865
step: 240, loss: 0.009822210296988487
step: 250, loss: 8.418360084760934e-05
step: 260, loss: 0.00489761820062995
step: 270, loss: 0.009925895370543003
step: 280, loss: 0.04881194233894348
step: 290, loss: 0.08323759585618973
step: 300, loss: 0.009390447288751602
step: 310, loss: 0.05977567285299301
step: 320, loss: 0.00043013039976358414
step: 330, loss: 0.05801377817988396
step: 340, loss: 0.020677288994193077
step: 350, loss: 0.019987106323242188
step: 360, loss: 0.03519756346940994
step: 370, loss: 0.04718490689992905
step: 380, loss: 0.027270369231700897
epoch 12: dev_f1=0.7228915662650602, f1=0.6947890818858561, best_f1=0.7296587926509187
step: 0, loss: 0.04327954351902008
step: 10, loss: 0.00035982122062705457
step: 20, loss: 0.003935203887522221
step: 30, loss: 0.026565471664071083
step: 40, loss: 0.027723556384444237
step: 50, loss: 0.04932711273431778
step: 60, loss: 0.01104799285531044
step: 70, loss: 0.03339558467268944
step: 80, loss: 0.0463128387928009
step: 90, loss: 0.006486011203378439
step: 100, loss: 0.07121351361274719
step: 110, loss: 0.023726768791675568
step: 120, loss: 0.08449229598045349
step: 130, loss: 0.0008096300880424678
step: 140, loss: 0.004546071402728558
step: 150, loss: 0.007087071891874075
step: 160, loss: 0.0055044167675077915
step: 170, loss: 0.00750310393050313
step: 180, loss: 0.002384788356721401
step: 190, loss: 0.005137080326676369
step: 200, loss: 0.0810200646519661
step: 210, loss: 0.031984757632017136
step: 220, loss: 0.05997078865766525
step: 230, loss: 0.020620742812752724
step: 240, loss: 0.021964631974697113
step: 250, loss: 0.09414342790842056
step: 260, loss: 0.0008199747535400093
step: 270, loss: 0.04246252775192261
step: 280, loss: 0.023240799084305763
step: 290, loss: 0.02535203844308853
step: 300, loss: 0.05835114046931267
step: 310, loss: 0.027844704687595367
step: 320, loss: 0.007971960119903088
step: 330, loss: 7.149459997890517e-05
step: 340, loss: 0.0077014886774122715
step: 350, loss: 0.007546429987996817
step: 360, loss: 0.02027704194188118
step: 370, loss: 0.0182790644466877
step: 380, loss: 0.06443572789430618
epoch 13: dev_f1=0.6743515850144093, f1=0.7002801120448179, best_f1=0.7296587926509187
step: 0, loss: 0.018715910613536835
step: 10, loss: 0.0001164823115686886
step: 20, loss: 0.01872633397579193
step: 30, loss: 0.11251284927129745
step: 40, loss: 0.04847944155335426
step: 50, loss: 0.055345311760902405
step: 60, loss: 0.002091786125674844
step: 70, loss: 0.03255961462855339
step: 80, loss: 0.00108614144846797
step: 90, loss: 0.008331126533448696
step: 100, loss: 0.000256885658018291
step: 110, loss: 0.0021331687457859516
step: 120, loss: 0.0017067557200789452
step: 130, loss: 5.373075691750273e-05
step: 140, loss: 0.028464222326874733
step: 150, loss: 0.0012351120822131634
step: 160, loss: 0.017184963449835777
step: 170, loss: 7.551638555014506e-05
step: 180, loss: 0.04495105519890785
step: 190, loss: 0.05265285447239876
step: 200, loss: 0.00022187316790223122
step: 210, loss: 0.010683156549930573
step: 220, loss: 0.0019165397388860583
step: 230, loss: 0.009314879775047302
step: 240, loss: 0.0019097782205790281
step: 250, loss: 0.03069107048213482
step: 260, loss: 0.03503393009305
step: 270, loss: 0.015523046255111694
step: 280, loss: 0.00014966900926083326
step: 290, loss: 0.0007978728390298784
step: 300, loss: 0.04066753387451172
step: 310, loss: 0.05182811617851257
step: 320, loss: 0.008560040965676308
step: 330, loss: 0.016698472201824188
step: 340, loss: 0.15621012449264526
step: 350, loss: 0.027727702632546425
step: 360, loss: 0.023078281432390213
step: 370, loss: 0.025426005944609642
step: 380, loss: 5.4408752475865185e-05
epoch 14: dev_f1=0.7013698630136985, f1=0.7029972752043598, best_f1=0.7296587926509187
step: 0, loss: 0.006375233642756939
step: 10, loss: 0.0062203058041632175
step: 20, loss: 0.03482850268483162
step: 30, loss: 0.021787261590361595
step: 40, loss: 0.02437032200396061
step: 50, loss: 0.06756645441055298
step: 60, loss: 0.012517405673861504
step: 70, loss: 0.004327748902142048
step: 80, loss: 0.040019791573286057
step: 90, loss: 0.015133109875023365
step: 100, loss: 0.0003705651906784624
step: 110, loss: 0.013651556335389614
step: 120, loss: 0.011994989588856697
step: 130, loss: 0.00018807272135745734
step: 140, loss: 0.08160155266523361
step: 150, loss: 0.013728680089116096
step: 160, loss: 0.003004449652507901
step: 170, loss: 0.013895039446651936
step: 180, loss: 0.04873352870345116
step: 190, loss: 0.04134770482778549
step: 200, loss: 0.09395765513181686
step: 210, loss: 0.004169607535004616
step: 220, loss: 0.000487155863083899
step: 230, loss: 0.0004330012889113277
step: 240, loss: 0.0005442352266982198
step: 250, loss: 0.01412808895111084
step: 260, loss: 0.003947973717004061
step: 270, loss: 0.036041293293237686
step: 280, loss: 0.001837925985455513
step: 290, loss: 0.050002571195364
step: 300, loss: 0.038269758224487305
step: 310, loss: 0.007906815968453884
step: 320, loss: 0.03258363530039787
step: 330, loss: 0.03193189576268196
step: 340, loss: 0.0003240915830247104
step: 350, loss: 0.041689444333314896
step: 360, loss: 0.024563239887356758
step: 370, loss: 0.0494985394179821
step: 380, loss: 0.0001117312494898215
epoch 15: dev_f1=0.6904761904761906, f1=0.6983372921615202, best_f1=0.7296587926509187
step: 0, loss: 0.052810706198215485
step: 10, loss: 0.00035294354893267155
step: 20, loss: 0.000669320288579911
step: 30, loss: 0.0706310048699379
step: 40, loss: 0.11111379414796829
step: 50, loss: 0.04191805422306061
step: 60, loss: 0.038608368486166
step: 70, loss: 0.04093394801020622
step: 80, loss: 0.0642629936337471
step: 90, loss: 0.0741497352719307
step: 100, loss: 0.004718731623142958
step: 110, loss: 0.03557410091161728
step: 120, loss: 0.004117286764085293
step: 130, loss: 0.0007223273278214037
step: 140, loss: 0.0048091053031384945
step: 150, loss: 0.013209322467446327
step: 160, loss: 0.002251415979117155
step: 170, loss: 0.000955138064455241
step: 180, loss: 0.04944135993719101
step: 190, loss: 0.017879169434309006
step: 200, loss: 0.018659723922610283
step: 210, loss: 0.0029758326709270477
step: 220, loss: 0.024001572281122208
step: 230, loss: 8.96649289643392e-05
step: 240, loss: 0.006272355560213327
step: 250, loss: 0.005069746170192957
step: 260, loss: 0.0030019425321370363
step: 270, loss: 0.00039733239100314677
step: 280, loss: 0.03830358386039734
step: 290, loss: 0.02077954262495041
step: 300, loss: 0.0043683527037501335
step: 310, loss: 0.03278951346874237
step: 320, loss: 0.018667802214622498
step: 330, loss: 0.0012557125883176923
step: 340, loss: 0.005953485146164894
step: 350, loss: 0.03190254420042038
step: 360, loss: 0.00010478640615474433
step: 370, loss: 0.005248557310551405
step: 380, loss: 0.015564565546810627
epoch 16: dev_f1=0.7002518891687657, f1=0.715, best_f1=0.7296587926509187
step: 0, loss: 0.033208027482032776
step: 10, loss: 0.0002572209050413221
step: 20, loss: 0.0019080634228885174
step: 30, loss: 0.002622036263346672
step: 40, loss: 0.021926244720816612
step: 50, loss: 0.016559112817049026
step: 60, loss: 0.007815252058207989
step: 70, loss: 0.020921308547258377
step: 80, loss: 0.0005148311611264944
step: 90, loss: 0.010403880849480629
step: 100, loss: 0.005684786010533571
step: 110, loss: 0.005112390499562025
step: 120, loss: 0.00011646335769910365
step: 130, loss: 0.002070576651021838
step: 140, loss: 0.05315782502293587
step: 150, loss: 2.9328346499823965e-05
step: 160, loss: 0.005848123226314783
step: 170, loss: 0.0006142014754004776
step: 180, loss: 0.0020650909282267094
step: 190, loss: 0.0003350634651724249
step: 200, loss: 0.043588683009147644
step: 210, loss: 0.0018867304315790534
step: 220, loss: 4.1329858504468575e-05
step: 230, loss: 0.046450186520814896
step: 240, loss: 0.03725111111998558
step: 250, loss: 0.0033736336044967175
step: 260, loss: 0.025146041065454483
step: 270, loss: 0.027348676696419716
step: 280, loss: 0.00033715885365381837
step: 290, loss: 0.021365126594901085
step: 300, loss: 0.016515012830495834
step: 310, loss: 0.0022629525046795607
step: 320, loss: 0.02447357214987278
step: 330, loss: 0.007932579144835472
step: 340, loss: 0.01979970559477806
step: 350, loss: 0.03940221667289734
step: 360, loss: 0.025854671373963356
step: 370, loss: 0.015070095658302307
step: 380, loss: 0.0001144583075074479
epoch 17: dev_f1=0.693877551020408, f1=0.6931818181818182, best_f1=0.7296587926509187
step: 0, loss: 0.014917180873453617
step: 10, loss: 0.05984096974134445
step: 20, loss: 7.625373109476641e-05
step: 30, loss: 0.03228938207030296
step: 40, loss: 0.0023480041418224573
step: 50, loss: 0.0645008385181427
step: 60, loss: 0.0001144966809079051
step: 70, loss: 0.03874007984995842
step: 80, loss: 0.0002821917296387255
step: 90, loss: 0.0605430081486702
step: 100, loss: 5.197679638513364e-05
step: 110, loss: 0.011441346257925034
step: 120, loss: 0.00047230737982317805
step: 130, loss: 0.00592513382434845
step: 140, loss: 0.005765883252024651
step: 150, loss: 7.079136412357911e-05
step: 160, loss: 8.382463420275599e-05
step: 170, loss: 0.006350700277835131
step: 180, loss: 0.002481006784364581
step: 190, loss: 4.393707786221057e-05
step: 200, loss: 0.03203165903687477
step: 210, loss: 0.03726029023528099
step: 220, loss: 0.002392430789768696
step: 230, loss: 0.023383203893899918
step: 240, loss: 0.07113043963909149
step: 250, loss: 0.1300216168165207
step: 260, loss: 0.03714483231306076
step: 270, loss: 0.04811801761388779
step: 280, loss: 0.024071358144283295
step: 290, loss: 8.567933400627226e-05
step: 300, loss: 0.0005556925316341221
step: 310, loss: 2.71902736130869e-05
step: 320, loss: 0.05344726890325546
step: 330, loss: 0.015546022914350033
step: 340, loss: 0.00014307374658528715
step: 350, loss: 4.153397821937688e-05
step: 360, loss: 0.01809399574995041
step: 370, loss: 0.0061315749771893024
step: 380, loss: 0.06646883487701416
epoch 18: dev_f1=0.6900269541778975, f1=0.7228260869565217, best_f1=0.7296587926509187
step: 0, loss: 0.0038117067888379097
step: 10, loss: 0.030602706596255302
step: 20, loss: 0.06947443634271622
step: 30, loss: 0.04229972884058952
step: 40, loss: 0.018031824380159378
step: 50, loss: 0.008597693406045437
step: 60, loss: 0.07802720367908478
step: 70, loss: 0.0023984150029718876
step: 80, loss: 0.028449246659874916
step: 90, loss: 0.026973333209753036
step: 100, loss: 9.45000138017349e-05
step: 110, loss: 0.028424028307199478
step: 120, loss: 0.009027992375195026
step: 130, loss: 0.0004529152938630432
step: 140, loss: 0.01236159447580576
step: 150, loss: 0.009978868067264557
step: 160, loss: 4.255498060956597e-05
step: 170, loss: 0.0012139583704993129
step: 180, loss: 0.06758329272270203
step: 190, loss: 0.00019539636559784412
step: 200, loss: 0.0005497900419868529
step: 210, loss: 0.012070344761013985
step: 220, loss: 0.00028014660347253084
step: 230, loss: 0.0002638364094309509
step: 240, loss: 0.0018544717459008098
step: 250, loss: 0.0003087013028562069
step: 260, loss: 0.0022007497027516365
step: 270, loss: 0.03687172755599022
step: 280, loss: 0.010692475363612175
step: 290, loss: 0.06180017068982124
step: 300, loss: 0.007775633130222559
step: 310, loss: 0.05820075422525406
step: 320, loss: 0.026882505044341087
step: 330, loss: 0.07414300739765167
step: 340, loss: 0.016903096809983253
step: 350, loss: 0.09374449402093887
step: 360, loss: 3.6674231523647904e-05
step: 370, loss: 0.024270538240671158
step: 380, loss: 3.889246363542043e-05
epoch 19: dev_f1=0.6969696969696969, f1=0.7058823529411764, best_f1=0.7296587926509187
step: 0, loss: 0.07944012433290482
step: 10, loss: 0.014442972838878632
step: 20, loss: 0.00860803946852684
step: 30, loss: 2.938811303465627e-05
step: 40, loss: 8.474622154608369e-05
step: 50, loss: 0.017554812133312225
step: 60, loss: 0.0674237459897995
step: 70, loss: 0.026557955890893936
step: 80, loss: 0.0013774969847872853
step: 90, loss: 0.010472845286130905
step: 100, loss: 0.010186083614826202
step: 110, loss: 0.04412855952978134
step: 120, loss: 0.007570488378405571
step: 130, loss: 0.052373550832271576
step: 140, loss: 7.330899825319648e-05
step: 150, loss: 0.0011052575428038836
step: 160, loss: 0.015595135278999805
step: 170, loss: 3.663704410428181e-05
step: 180, loss: 0.035486675798892975
step: 190, loss: 0.02603152208030224
step: 200, loss: 0.0767221748828888
step: 210, loss: 0.11040262877941132
step: 220, loss: 0.0008119124104268849
step: 230, loss: 0.018211189657449722
step: 240, loss: 0.028735807165503502
step: 250, loss: 0.03224365413188934
step: 260, loss: 0.0002140781143680215
step: 270, loss: 0.007552989758551121
step: 280, loss: 0.0005912782507948577
step: 290, loss: 0.021055199205875397
step: 300, loss: 0.08092834055423737
step: 310, loss: 0.01171119138598442
step: 320, loss: 0.03222658485174179
step: 330, loss: 0.0434655100107193
step: 340, loss: 0.03189370036125183
step: 350, loss: 0.0003121051995549351
step: 360, loss: 0.0065590450540184975
step: 370, loss: 4.0864371840143576e-05
step: 380, loss: 0.00013662042329087853
epoch 20: dev_f1=0.6925064599483204, f1=0.7189873417721518, best_f1=0.7296587926509187
