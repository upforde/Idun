cuda
Device: cuda
step: 0, loss: 0.6569106578826904
step: 10, loss: 0.3744334578514099
step: 20, loss: 0.12507103383541107
step: 30, loss: 0.3818339407444
step: 40, loss: 0.36539942026138306
step: 50, loss: 0.4128810167312622
step: 60, loss: 0.4336061179637909
step: 70, loss: 0.06507854908704758
step: 80, loss: 0.26027894020080566
step: 90, loss: 0.32672300934791565
step: 100, loss: 0.48043644428253174
step: 110, loss: 0.30426645278930664
step: 120, loss: 0.14441342651844025
step: 130, loss: 0.1996195912361145
step: 140, loss: 0.23579485714435577
step: 150, loss: 0.5106250643730164
step: 160, loss: 0.34711721539497375
step: 170, loss: 0.33610597252845764
step: 180, loss: 0.30919936299324036
step: 190, loss: 0.38046908378601074
step: 200, loss: 0.3737913966178894
step: 210, loss: 0.1951039880514145
step: 220, loss: 0.2705455422401428
step: 230, loss: 0.17295196652412415
step: 240, loss: 0.20894591510295868
step: 250, loss: 0.1447376310825348
step: 260, loss: 0.33799946308135986
step: 270, loss: 0.26032477617263794
step: 280, loss: 0.1253606379032135
step: 290, loss: 0.17791491746902466
step: 300, loss: 0.3552134335041046
step: 310, loss: 0.13354332745075226
step: 320, loss: 0.2188687026500702
step: 330, loss: 0.2137472778558731
step: 340, loss: 0.2337699979543686
step: 350, loss: 0.1949191689491272
step: 360, loss: 0.18230532109737396
step: 370, loss: 0.2059902548789978
step: 380, loss: 0.22809912264347076
epoch 1: dev_f1=0.41300191204588915, f1=0.4208494208494209, best_f1=0.4208494208494209
step: 0, loss: 0.15758192539215088
step: 10, loss: 0.17028848826885223
step: 20, loss: 0.09295816719532013
step: 30, loss: 0.18045812845230103
step: 40, loss: 0.31466352939605713
step: 50, loss: 0.09793364256620407
step: 60, loss: 0.07141216844320297
step: 70, loss: 0.15589319169521332
step: 80, loss: 0.3403892517089844
step: 90, loss: 0.23127637803554535
step: 100, loss: 0.20323362946510315
step: 110, loss: 0.32095181941986084
step: 120, loss: 0.20045623183250427
step: 130, loss: 0.14206400513648987
step: 140, loss: 0.2469458132982254
step: 150, loss: 0.11689938604831696
step: 160, loss: 0.16636554896831512
step: 170, loss: 0.07451188564300537
step: 180, loss: 0.08652088046073914
step: 190, loss: 0.24504625797271729
step: 200, loss: 0.10438725352287292
step: 210, loss: 0.09981001913547516
step: 220, loss: 0.1421792060136795
step: 230, loss: 0.34187424182891846
step: 240, loss: 0.010932199656963348
step: 250, loss: 0.23068131506443024
step: 260, loss: 0.17646357417106628
step: 270, loss: 0.11225336045026779
step: 280, loss: 0.12784305214881897
step: 290, loss: 0.16888198256492615
step: 300, loss: 0.16624097526073456
step: 310, loss: 0.13458533585071564
step: 320, loss: 0.06814882159233093
step: 330, loss: 0.09512254595756531
step: 340, loss: 0.15933877229690552
step: 350, loss: 0.07965818047523499
step: 360, loss: 0.09700193256139755
step: 370, loss: 0.07194732874631882
step: 380, loss: 0.11050514876842499
epoch 2: dev_f1=0.5748218527315915, f1=0.6522781774580335, best_f1=0.6522781774580335
step: 0, loss: 0.07497913390398026
step: 10, loss: 0.027296166867017746
step: 20, loss: 0.25176218152046204
step: 30, loss: 0.04286256805062294
step: 40, loss: 0.13626934587955475
step: 50, loss: 0.058941494673490524
step: 60, loss: 0.043127644807100296
step: 70, loss: 0.0034884416963905096
step: 80, loss: 0.02438238263130188
step: 90, loss: 0.12354420870542526
step: 100, loss: 0.13302992284297943
step: 110, loss: 0.1499343067407608
step: 120, loss: 0.054834913462400436
step: 130, loss: 0.1283859759569168
step: 140, loss: 0.1337631493806839
step: 150, loss: 0.07523006945848465
step: 160, loss: 0.11180582642555237
step: 170, loss: 0.1318570077419281
step: 180, loss: 0.13736803829669952
step: 190, loss: 0.11181662231683731
step: 200, loss: 0.07760600745677948
step: 210, loss: 0.07163755595684052
step: 220, loss: 0.0016543884994462132
step: 230, loss: 0.1951128989458084
step: 240, loss: 0.1074465811252594
step: 250, loss: 0.090670645236969
step: 260, loss: 0.07854106277227402
step: 270, loss: 0.1259486824274063
step: 280, loss: 0.10355881601572037
step: 290, loss: 0.21632790565490723
step: 300, loss: 0.10443787276744843
step: 310, loss: 0.05799490958452225
step: 320, loss: 0.098388671875
step: 330, loss: 0.05180314928293228
step: 340, loss: 0.07184470444917679
step: 350, loss: 0.13671764731407166
step: 360, loss: 0.01900934986770153
step: 370, loss: 0.02031947299838066
step: 380, loss: 0.07894958555698395
epoch 3: dev_f1=0.6575963718820862, f1=0.6590389016018307, best_f1=0.6590389016018307
step: 0, loss: 0.014451651833951473
step: 10, loss: 0.09477321058511734
step: 20, loss: 0.04966522753238678
step: 30, loss: 0.08912311494350433
step: 40, loss: 0.07654433697462082
step: 50, loss: 0.128627747297287
step: 60, loss: 0.07706474512815475
step: 70, loss: 0.055014342069625854
step: 80, loss: 0.013049331493675709
step: 90, loss: 0.05048414319753647
step: 100, loss: 0.0011605352628976107
step: 110, loss: 0.08222567290067673
step: 120, loss: 0.08876705914735794
step: 130, loss: 0.08886151760816574
step: 140, loss: 0.016596296802163124
step: 150, loss: 0.1876545250415802
step: 160, loss: 0.0004880279302597046
step: 170, loss: 0.11107013374567032
step: 180, loss: 0.026952793821692467
step: 190, loss: 0.14393851161003113
step: 200, loss: 0.00804784707725048
step: 210, loss: 0.20057937502861023
step: 220, loss: 0.0718848705291748
step: 230, loss: 0.08156684041023254
step: 240, loss: 0.061167702078819275
step: 250, loss: 0.04941750690340996
step: 260, loss: 0.10970120877027512
step: 270, loss: 0.015195058658719063
step: 280, loss: 0.022252213209867477
step: 290, loss: 0.21947546303272247
step: 300, loss: 0.03741488605737686
step: 310, loss: 0.08809817582368851
step: 320, loss: 0.08090409636497498
step: 330, loss: 0.09543698281049728
step: 340, loss: 0.05069854483008385
step: 350, loss: 0.21842481195926666
step: 360, loss: 0.2728046476840973
step: 370, loss: 0.04238356649875641
step: 380, loss: 0.0807182714343071
epoch 4: dev_f1=0.6390804597701151, f1=0.6651583710407241, best_f1=0.6590389016018307
step: 0, loss: 0.09042330086231232
step: 10, loss: 0.061173271387815475
step: 20, loss: 0.017324088141322136
step: 30, loss: 0.04075772315263748
step: 40, loss: 0.0014646971831098199
step: 50, loss: 0.06461866199970245
step: 60, loss: 0.01507478579878807
step: 70, loss: 0.06060471013188362
step: 80, loss: 0.01477077603340149
step: 90, loss: 0.23019887506961823
step: 100, loss: 0.21001863479614258
step: 110, loss: 0.05545390397310257
step: 120, loss: 0.06933479011058807
step: 130, loss: 0.06381996721029282
step: 140, loss: 0.021273277699947357
step: 150, loss: 0.046685557812452316
step: 160, loss: 0.035729389637708664
step: 170, loss: 0.046620216220617294
step: 180, loss: 0.04538539797067642
step: 190, loss: 0.11960410326719284
step: 200, loss: 0.12059418857097626
step: 210, loss: 0.0439729243516922
step: 220, loss: 0.027509387582540512
step: 230, loss: 0.012073039077222347
step: 240, loss: 0.12094397842884064
step: 250, loss: 0.171502485871315
step: 260, loss: 0.1012578159570694
step: 270, loss: 0.04914327710866928
step: 280, loss: 0.05047842487692833
step: 290, loss: 0.18985526263713837
step: 300, loss: 0.04781440645456314
step: 310, loss: 0.1039682924747467
step: 320, loss: 0.05854284390807152
step: 330, loss: 0.040330104529857635
step: 340, loss: 0.0221087746322155
step: 350, loss: 0.026081867516040802
step: 360, loss: 0.14202626049518585
step: 370, loss: 0.07561486959457397
step: 380, loss: 0.21645589172840118
epoch 5: dev_f1=0.6758620689655174, f1=0.6997635933806147, best_f1=0.6997635933806147
step: 0, loss: 0.04465491697192192
step: 10, loss: 0.029012728482484818
step: 20, loss: 0.05687684193253517
step: 30, loss: 0.0010285816388204694
step: 40, loss: 0.01897573471069336
step: 50, loss: 0.009146326221525669
step: 60, loss: 0.07589984685182571
step: 70, loss: 0.06506279110908508
step: 80, loss: 0.010653223842382431
step: 90, loss: 0.03505583852529526
step: 100, loss: 0.04722670465707779
step: 110, loss: 0.0631575882434845
step: 120, loss: 0.006029900163412094
step: 130, loss: 0.06617637723684311
step: 140, loss: 0.013534615747630596
step: 150, loss: 0.008626029826700687
step: 160, loss: 0.005730877164751291
step: 170, loss: 0.08248893916606903
step: 180, loss: 0.11816523224115372
step: 190, loss: 0.08970825374126434
step: 200, loss: 0.015063879080116749
step: 210, loss: 0.036359600722789764
step: 220, loss: 0.020838897675275803
step: 230, loss: 0.039421916007995605
step: 240, loss: 0.09673325717449188
step: 250, loss: 0.02771155722439289
step: 260, loss: 0.02593381144106388
step: 270, loss: 0.18447935581207275
step: 280, loss: 0.0901302918791771
step: 290, loss: 0.05096236988902092
step: 300, loss: 0.015359366312623024
step: 310, loss: 0.01725689321756363
step: 320, loss: 0.10488834977149963
step: 330, loss: 0.07469745725393295
step: 340, loss: 0.03810301795601845
step: 350, loss: 0.07710525393486023
step: 360, loss: 0.02964078262448311
step: 370, loss: 0.006420641206204891
step: 380, loss: 0.0275739636272192
epoch 6: dev_f1=0.681704260651629, f1=0.6855670103092784, best_f1=0.6855670103092784
step: 0, loss: 0.05583572760224342
step: 10, loss: 0.06602490693330765
step: 20, loss: 0.13035675883293152
step: 30, loss: 0.09028729051351547
step: 40, loss: 0.04060155898332596
step: 50, loss: 0.027127133682370186
step: 60, loss: 0.020207539200782776
step: 70, loss: 0.03196597099304199
step: 80, loss: 0.017705975100398064
step: 90, loss: 0.001527257147245109
step: 100, loss: 0.04927888140082359
step: 110, loss: 0.010513586923480034
step: 120, loss: 0.12158128619194031
step: 130, loss: 0.015734927728772163
step: 140, loss: 0.06853028386831284
step: 150, loss: 0.07498384267091751
step: 160, loss: 0.03810006007552147
step: 170, loss: 0.025319978594779968
step: 180, loss: 0.007090925704687834
step: 190, loss: 0.03655315935611725
step: 200, loss: 0.01919500157237053
step: 210, loss: 0.014877187088131905
step: 220, loss: 0.0008046067086979747
step: 230, loss: 0.07863873988389969
step: 240, loss: 0.08851170539855957
step: 250, loss: 0.058575063943862915
step: 260, loss: 0.02889193780720234
step: 270, loss: 0.04123372584581375
step: 280, loss: 0.026552436873316765
step: 290, loss: 0.012266349047422409
step: 300, loss: 0.04555528238415718
step: 310, loss: 0.002554862527176738
step: 320, loss: 0.00025388787616975605
step: 330, loss: 0.047664616256952286
step: 340, loss: 0.09675762057304382
step: 350, loss: 0.10120312124490738
step: 360, loss: 0.24189314246177673
step: 370, loss: 0.07134730368852615
step: 380, loss: 0.12315694987773895
epoch 7: dev_f1=0.7121951219512195, f1=0.7150259067357513, best_f1=0.7150259067357513
step: 0, loss: 0.05353277921676636
step: 10, loss: 0.018359480425715446
step: 20, loss: 0.07083211094141006
step: 30, loss: 0.055395886301994324
step: 40, loss: 0.027635866776108742
step: 50, loss: 0.01606118492782116
step: 60, loss: 0.047927048057317734
step: 70, loss: 0.04629978537559509
step: 80, loss: 0.010654781013727188
step: 90, loss: 0.06273945420980453
step: 100, loss: 0.004148619249463081
step: 110, loss: 0.05677514523267746
step: 120, loss: 0.04921125993132591
step: 130, loss: 0.01499742828309536
step: 140, loss: 0.06527545303106308
step: 150, loss: 0.027802102267742157
step: 160, loss: 0.012888827361166477
step: 170, loss: 0.04887611046433449
step: 180, loss: 0.04120808094739914
step: 190, loss: 0.01843028888106346
step: 200, loss: 0.11299091577529907
step: 210, loss: 0.00015730792074464262
step: 220, loss: 0.02778359316289425
step: 230, loss: 0.0015066770138218999
step: 240, loss: 0.007014025468379259
step: 250, loss: 0.08867497742176056
step: 260, loss: 0.018698107451200485
step: 270, loss: 0.009174203500151634
step: 280, loss: 0.06758634746074677
step: 290, loss: 0.07693782448768616
step: 300, loss: 0.07680988311767578
step: 310, loss: 0.031910452991724014
step: 320, loss: 0.021374661475419998
step: 330, loss: 0.00544957909733057
step: 340, loss: 0.00010260297131026164
step: 350, loss: 0.054792147129774094
step: 360, loss: 0.04694146662950516
step: 370, loss: 0.01342467125505209
step: 380, loss: 0.00011305377847747877
epoch 8: dev_f1=0.6773333333333335, f1=0.7146666666666668, best_f1=0.7150259067357513
step: 0, loss: 0.02591492421925068
step: 10, loss: 0.0009398373076692224
step: 20, loss: 0.02301919460296631
step: 30, loss: 0.010151405818760395
step: 40, loss: 0.0032250448130071163
step: 50, loss: 0.023705117404460907
step: 60, loss: 0.05052368715405464
step: 70, loss: 0.00898806657642126
step: 80, loss: 0.00025645445566624403
step: 90, loss: 0.0025227623991668224
step: 100, loss: 0.025868821889162064
step: 110, loss: 0.045149609446525574
step: 120, loss: 0.015834134072065353
step: 130, loss: 0.051585134118795395
step: 140, loss: 0.005157949402928352
step: 150, loss: 0.1336297243833542
step: 160, loss: 0.05399163067340851
step: 170, loss: 0.04249003902077675
step: 180, loss: 0.015868406742811203
step: 190, loss: 0.00305367773398757
step: 200, loss: 0.08687331527471542
step: 210, loss: 0.11087201535701752
step: 220, loss: 0.034165192395448685
step: 230, loss: 0.18319061398506165
step: 240, loss: 0.0255622286349535
step: 250, loss: 0.0066961124539375305
step: 260, loss: 0.04309320077300072
step: 270, loss: 0.015620715916156769
step: 280, loss: 0.0637727677822113
step: 290, loss: 0.013788377866148949
step: 300, loss: 0.09566178172826767
step: 310, loss: 0.06486412137746811
step: 320, loss: 0.09045366197824478
step: 330, loss: 0.02517964504659176
step: 340, loss: 0.0292586050927639
step: 350, loss: 0.0645938441157341
step: 360, loss: 0.0492168553173542
step: 370, loss: 0.03663450479507446
step: 380, loss: 0.0174440685659647
epoch 9: dev_f1=0.7214854111405835, f1=0.6931818181818182, best_f1=0.6931818181818182
step: 0, loss: 0.06886258721351624
step: 10, loss: 0.043799638748168945
step: 20, loss: 0.017152737826108932
step: 30, loss: 0.0028535393066704273
step: 40, loss: 0.002317145699635148
step: 50, loss: 0.1598903089761734
step: 60, loss: 0.0203990675508976
step: 70, loss: 0.039074648171663284
step: 80, loss: 0.004477744922041893
step: 90, loss: 0.0018425713060423732
step: 100, loss: 0.06714197993278503
step: 110, loss: 0.011927839368581772
step: 120, loss: 0.07313463091850281
step: 130, loss: 8.07700416771695e-05
step: 140, loss: 0.04855125769972801
step: 150, loss: 0.00012309635349083692
step: 160, loss: 0.012399956583976746
step: 170, loss: 0.01240189652889967
step: 180, loss: 0.0055124396458268166
step: 190, loss: 0.0065282913856208324
step: 200, loss: 0.02063789963722229
step: 210, loss: 0.05491147190332413
step: 220, loss: 0.05444367229938507
step: 230, loss: 0.01555959414690733
step: 240, loss: 0.02848299965262413
step: 250, loss: 0.11198145151138306
step: 260, loss: 0.020190123468637466
step: 270, loss: 0.0015018550911918283
step: 280, loss: 0.01047723088413477
step: 290, loss: 0.026254385709762573
step: 300, loss: 0.004203415475785732
step: 310, loss: 0.009577405638992786
step: 320, loss: 0.02703893929719925
step: 330, loss: 0.10226254165172577
step: 340, loss: 0.01098345685750246
step: 350, loss: 0.0005234218551777303
step: 360, loss: 0.062351956963539124
step: 370, loss: 0.13365538418293
step: 380, loss: 0.1114160344004631
epoch 10: dev_f1=0.6843373493975903, f1=0.703883495145631, best_f1=0.6931818181818182
step: 0, loss: 0.06476110219955444
step: 10, loss: 0.0007316808332689106
step: 20, loss: 0.17061497271060944
step: 30, loss: 0.005886548198759556
step: 40, loss: 0.0011662126053124666
step: 50, loss: 0.009103931486606598
step: 60, loss: 0.025018703192472458
step: 70, loss: 0.03443874046206474
step: 80, loss: 0.00011864981206599623
step: 90, loss: 0.007124886382371187
step: 100, loss: 0.00883832760155201
step: 110, loss: 0.00719106663018465
step: 120, loss: 0.0009902436286211014
step: 130, loss: 0.003159651532769203
step: 140, loss: 0.13626326620578766
step: 150, loss: 0.05550230294466019
step: 160, loss: 0.01793004758656025
step: 170, loss: 0.0465720109641552
step: 180, loss: 0.05140770226716995
step: 190, loss: 0.004495774861425161
step: 200, loss: 0.002744387835264206
step: 210, loss: 0.0318138413131237
step: 220, loss: 0.0026304922066628933
step: 230, loss: 0.027542347088456154
step: 240, loss: 0.0699457973241806
step: 250, loss: 0.04864704608917236
step: 260, loss: 0.009812855161726475
step: 270, loss: 0.0009950189851224422
step: 280, loss: 0.15836744010448456
step: 290, loss: 0.012928690761327744
step: 300, loss: 0.0033141272142529488
step: 310, loss: 0.006548924837261438
step: 320, loss: 0.01856875978410244
step: 330, loss: 0.013925047591328621
step: 340, loss: 0.018019655719399452
step: 350, loss: 0.23899076879024506
step: 360, loss: 0.03463197126984596
step: 370, loss: 0.06876292824745178
step: 380, loss: 0.03443068265914917
epoch 11: dev_f1=0.715, f1=0.72, best_f1=0.6931818181818182
step: 0, loss: 0.026495542377233505
step: 10, loss: 0.013774680905044079
step: 20, loss: 0.03532189130783081
step: 30, loss: 0.023351605981588364
step: 40, loss: 0.0084817660972476
step: 50, loss: 0.04443958401679993
step: 60, loss: 0.015173470601439476
step: 70, loss: 0.004113640170544386
step: 80, loss: 0.0009863926097750664
step: 90, loss: 0.006895187310874462
step: 100, loss: 0.015557103790342808
step: 110, loss: 0.0003190120914950967
step: 120, loss: 0.001957097090780735
step: 130, loss: 0.004476848058402538
step: 140, loss: 0.019655190408229828
step: 150, loss: 0.03387527912855148
step: 160, loss: 0.0037694324273616076
step: 170, loss: 0.008507682010531425
step: 180, loss: 0.02163674682378769
step: 190, loss: 0.03328418359160423
step: 200, loss: 0.03323047235608101
step: 210, loss: 0.15686514973640442
step: 220, loss: 0.0006529906531795859
step: 230, loss: 0.0563541017472744
step: 240, loss: 0.0005805438850075006
step: 250, loss: 0.019604289904236794
step: 260, loss: 0.04323948174715042
step: 270, loss: 0.011364234611392021
step: 280, loss: 0.029915934428572655
step: 290, loss: 0.0064950138330459595
step: 300, loss: 0.009923983365297318
step: 310, loss: 0.003549292217940092
step: 320, loss: 0.0022296712268143892
step: 330, loss: 0.10319547355175018
step: 340, loss: 0.0013937019975855947
step: 350, loss: 0.008582820184528828
step: 360, loss: 0.02850927785038948
step: 370, loss: 0.04012785851955414
step: 380, loss: 0.059221792966127396
epoch 12: dev_f1=0.7272727272727272, f1=0.7430025445292621, best_f1=0.7430025445292621
step: 0, loss: 0.011720209382474422
step: 10, loss: 0.01570703648030758
step: 20, loss: 0.0016761381411924958
step: 30, loss: 0.06669358164072037
step: 40, loss: 0.09059812128543854
step: 50, loss: 0.009945118799805641
step: 60, loss: 0.02184852585196495
step: 70, loss: 0.021075844764709473
step: 80, loss: 0.022331777960062027
step: 90, loss: 0.0012335018254816532
step: 100, loss: 0.03775126114487648
step: 110, loss: 0.0028006541542708874
step: 120, loss: 0.0006211865693330765
step: 130, loss: 8.256269939010963e-05
step: 140, loss: 0.09504101425409317
step: 150, loss: 0.06185503304004669
step: 160, loss: 0.0033290043938905
step: 170, loss: 0.007529060821980238
step: 180, loss: 0.005856398958712816
step: 190, loss: 0.001210288959555328
step: 200, loss: 0.0021177949383854866
step: 210, loss: 0.0026398897171020508
step: 220, loss: 0.034401047974824905
step: 230, loss: 3.009950160048902e-05
step: 240, loss: 0.011066689155995846
step: 250, loss: 0.05046737566590309
step: 260, loss: 0.05058441311120987
step: 270, loss: 0.07112482190132141
step: 280, loss: 0.001931827049702406
step: 290, loss: 0.11944965273141861
step: 300, loss: 0.06614978611469269
step: 310, loss: 0.01849295385181904
step: 320, loss: 0.02244269847869873
step: 330, loss: 0.04408237338066101
step: 340, loss: 0.00023691651585977525
step: 350, loss: 0.07147788256406784
step: 360, loss: 0.002881431020796299
step: 370, loss: 0.007060072384774685
step: 380, loss: 0.0024920571595430374
epoch 13: dev_f1=0.6907216494845362, f1=0.6886075949367089, best_f1=0.7430025445292621
step: 0, loss: 0.052411433309316635
step: 10, loss: 0.02085595391690731
step: 20, loss: 0.008031354285776615
step: 30, loss: 0.0010677712270990014
step: 40, loss: 0.0005747112445533276
step: 50, loss: 0.0002726487582549453
step: 60, loss: 0.04855665937066078
step: 70, loss: 0.0427432581782341
step: 80, loss: 0.0027081456501036882
step: 90, loss: 0.0488688088953495
step: 100, loss: 0.04701891168951988
step: 110, loss: 3.275384733569808e-05
step: 120, loss: 0.0038618796970695257
step: 130, loss: 0.040663398802280426
step: 140, loss: 0.07983222603797913
step: 150, loss: 0.000744731689337641
step: 160, loss: 0.029581043869256973
step: 170, loss: 0.011657007969915867
step: 180, loss: 0.017045635730028152
step: 190, loss: 0.00014989750343374908
step: 200, loss: 0.042109470814466476
step: 210, loss: 0.06723810732364655
step: 220, loss: 0.01904166303575039
step: 230, loss: 0.006670583039522171
step: 240, loss: 0.00016440106264781207
step: 250, loss: 0.00030524731846526265
step: 260, loss: 0.10068638622760773
step: 270, loss: 0.05748014524579048
step: 280, loss: 0.021448390558362007
step: 290, loss: 0.008943330496549606
step: 300, loss: 0.015636786818504333
step: 310, loss: 0.07176603376865387
step: 320, loss: 0.052092138677835464
step: 330, loss: 0.0025605857372283936
step: 340, loss: 0.00016088125994428992
step: 350, loss: 0.025346428155899048
step: 360, loss: 0.02015191689133644
step: 370, loss: 0.024708837270736694
step: 380, loss: 0.014221967197954655
epoch 14: dev_f1=0.67, f1=0.7103274559193955, best_f1=0.7430025445292621
step: 0, loss: 0.011339082382619381
step: 10, loss: 0.026198994368314743
step: 20, loss: 0.07644950598478317
step: 30, loss: 0.10020735114812851
step: 40, loss: 0.016371119767427444
step: 50, loss: 0.020396925508975983
step: 60, loss: 0.0059787253849208355
step: 70, loss: 0.0046841418370604515
step: 80, loss: 0.002537832595407963
step: 90, loss: 0.001910514896735549
step: 100, loss: 0.00960682425647974
step: 110, loss: 0.024486027657985687
step: 120, loss: 0.004311325028538704
step: 130, loss: 0.003181770443916321
step: 140, loss: 0.09000419825315475
step: 150, loss: 0.031329091638326645
step: 160, loss: 0.0034921711776405573
step: 170, loss: 0.021063098683953285
step: 180, loss: 0.03386794403195381
step: 190, loss: 0.033789876848459244
step: 200, loss: 0.008687521331012249
step: 210, loss: 0.04767615720629692
step: 220, loss: 0.004418343771249056
step: 230, loss: 0.0214364193379879
step: 240, loss: 8.846470882417634e-05
step: 250, loss: 0.006214488297700882
step: 260, loss: 0.05504786968231201
step: 270, loss: 0.03859294578433037
step: 280, loss: 0.02345067821443081
step: 290, loss: 0.00024077770649455488
step: 300, loss: 0.024486087262630463
step: 310, loss: 0.04553171247243881
step: 320, loss: 0.05504050478339195
step: 330, loss: 0.07865988463163376
step: 340, loss: 0.006803032010793686
step: 350, loss: 0.005283997394144535
step: 360, loss: 0.09615229815244675
step: 370, loss: 0.002639820333570242
step: 380, loss: 0.0002879606036003679
epoch 15: dev_f1=0.7102803738317758, f1=0.6761904761904761, best_f1=0.7430025445292621
step: 0, loss: 7.049317355267704e-05
step: 10, loss: 0.00260134506970644
step: 20, loss: 0.06493660062551498
step: 30, loss: 0.008143305778503418
step: 40, loss: 0.00012208902626298368
step: 50, loss: 0.04001545161008835
step: 60, loss: 5.74142650293652e-05
step: 70, loss: 0.03281135857105255
step: 80, loss: 0.00011394093598937616
step: 90, loss: 0.06111221760511398
step: 100, loss: 0.0018429472111165524
step: 110, loss: 0.0010806936770677567
step: 120, loss: 0.0014516775263473392
step: 130, loss: 0.0013411019463092089
step: 140, loss: 8.104239532258362e-05
step: 150, loss: 0.07054248452186584
step: 160, loss: 0.00011319114855723456
step: 170, loss: 0.01042792946100235
step: 180, loss: 0.028674855828285217
step: 190, loss: 0.02422327734529972
step: 200, loss: 0.040499962866306305
step: 210, loss: 0.003899482311680913
step: 220, loss: 0.02275346964597702
step: 230, loss: 0.005155275110155344
step: 240, loss: 0.07980067282915115
step: 250, loss: 0.0126657048240304
step: 260, loss: 0.010416949167847633
step: 270, loss: 0.03661515936255455
step: 280, loss: 0.02543848566710949
step: 290, loss: 0.06047995388507843
step: 300, loss: 0.00020625986508093774
step: 310, loss: 0.001249523600563407
step: 320, loss: 0.0017342783976346254
step: 330, loss: 0.013598413206636906
step: 340, loss: 4.509339851210825e-05
step: 350, loss: 0.014998337253928185
step: 360, loss: 0.04807541146874428
step: 370, loss: 3.358809772180393e-05
step: 380, loss: 0.013680502772331238
epoch 16: dev_f1=0.6831955922865013, f1=0.6961325966850829, best_f1=0.7430025445292621
step: 0, loss: 0.02624685689806938
step: 10, loss: 0.016600485891103745
step: 20, loss: 0.0055850292555987835
step: 30, loss: 9.602443606127053e-05
step: 40, loss: 0.012743025086820126
step: 50, loss: 0.19138693809509277
step: 60, loss: 0.040388189256191254
step: 70, loss: 0.026761269196867943
step: 80, loss: 0.0159983579069376
step: 90, loss: 0.05753381550312042
step: 100, loss: 0.00034914931165985763
step: 110, loss: 0.022958772256970406
step: 120, loss: 0.12371455878019333
step: 130, loss: 0.002565651433542371
step: 140, loss: 0.035637930035591125
step: 150, loss: 0.0016265390440821648
step: 160, loss: 0.03839236870408058
step: 170, loss: 0.06099953129887581
step: 180, loss: 0.0004337176214903593
step: 190, loss: 0.017398446798324585
step: 200, loss: 0.00012541581236291677
step: 210, loss: 0.021110646426677704
step: 220, loss: 0.010200092568993568
step: 230, loss: 0.0423797182738781
step: 240, loss: 0.04747955501079559
step: 250, loss: 0.0005491073243319988
step: 260, loss: 0.08204860240221024
step: 270, loss: 0.00010495363676454872
step: 280, loss: 5.5070406233426183e-05
step: 290, loss: 0.03693252429366112
step: 300, loss: 0.0057905144058167934
step: 310, loss: 0.02019256167113781
step: 320, loss: 0.0028583460953086615
step: 330, loss: 0.006760875228792429
step: 340, loss: 0.0018153305863961577
step: 350, loss: 0.011187508702278137
step: 360, loss: 0.011041004210710526
step: 370, loss: 0.00012540013995021582
step: 380, loss: 0.02379572205245495
epoch 17: dev_f1=0.6898395721925134, f1=0.6939890710382514, best_f1=0.7430025445292621
step: 0, loss: 0.0012993891723453999
step: 10, loss: 0.07775654643774033
step: 20, loss: 0.0160669032484293
step: 30, loss: 9.324846905656159e-05
step: 40, loss: 0.007208301220089197
step: 50, loss: 0.01801406405866146
step: 60, loss: 0.00889266561716795
step: 70, loss: 0.028884224593639374
step: 80, loss: 0.04477323591709137
step: 90, loss: 0.0001177671947516501
step: 100, loss: 5.884942220291123e-05
step: 110, loss: 0.029953425750136375
step: 120, loss: 0.00036077213007956743
step: 130, loss: 5.6522210797993466e-05
step: 140, loss: 0.02115778997540474
step: 150, loss: 0.0001259873533854261
step: 160, loss: 0.010499229654669762
step: 170, loss: 0.022740328684449196
step: 180, loss: 0.06949716806411743
step: 190, loss: 0.040419917553663254
step: 200, loss: 4.296424594940618e-05
step: 210, loss: 0.014444774016737938
step: 220, loss: 0.003370349295437336
step: 230, loss: 0.00010805685451487079
step: 240, loss: 0.013000342063605785
step: 250, loss: 0.03650033846497536
step: 260, loss: 0.023432966321706772
step: 270, loss: 0.024159647524356842
step: 280, loss: 3.370086051290855e-05
step: 290, loss: 0.003078221809118986
step: 300, loss: 4.040521162096411e-05
step: 310, loss: 0.007754533085972071
step: 320, loss: 0.0016845521749928594
step: 330, loss: 0.02341747283935547
step: 340, loss: 4.201017873128876e-05
step: 350, loss: 0.005799181759357452
step: 360, loss: 0.034405071288347244
step: 370, loss: 0.0338483564555645
step: 380, loss: 0.022526046261191368
epoch 18: dev_f1=0.6883468834688347, f1=0.7016574585635359, best_f1=0.7430025445292621
step: 0, loss: 0.00025014489074237645
step: 10, loss: 0.008896937593817711
step: 20, loss: 0.007999089546501637
step: 30, loss: 0.0009502433240413666
step: 40, loss: 0.03389711678028107
step: 50, loss: 0.009633304551243782
step: 60, loss: 0.008979559876024723
step: 70, loss: 0.010107196867465973
step: 80, loss: 0.0037550050765275955
step: 90, loss: 5.6599543313495815e-05
step: 100, loss: 8.017845539143309e-05
step: 110, loss: 0.06465698778629303
step: 120, loss: 0.014941830188035965
step: 130, loss: 0.02317410707473755
step: 140, loss: 0.0036750505678355694
step: 150, loss: 0.008837727829813957
step: 160, loss: 0.034844979643821716
step: 170, loss: 0.03616998344659805
step: 180, loss: 0.021779952570796013
step: 190, loss: 0.017183348536491394
step: 200, loss: 0.0006746876169927418
step: 210, loss: 0.03654065728187561
step: 220, loss: 0.0030915220268070698
step: 230, loss: 0.06066671386361122
step: 240, loss: 0.0002270881668664515
step: 250, loss: 0.01735115610063076
step: 260, loss: 3.532378832460381e-05
step: 270, loss: 0.0739968940615654
step: 280, loss: 0.07156404107809067
step: 290, loss: 0.024573741480708122
step: 300, loss: 0.0008779531344771385
step: 310, loss: 0.03126271814107895
step: 320, loss: 0.00010254591325065121
step: 330, loss: 0.04711073264479637
step: 340, loss: 0.00011331587302265689
step: 350, loss: 0.008134567178785801
step: 360, loss: 0.006595612037926912
step: 370, loss: 8.184216858353466e-05
step: 380, loss: 0.0006750283064320683
epoch 19: dev_f1=0.7040000000000001, f1=0.7055702917771883, best_f1=0.7430025445292621
step: 0, loss: 0.0003748599556274712
step: 10, loss: 0.02874491550028324
step: 20, loss: 0.0003088325320277363
step: 30, loss: 0.05929980054497719
step: 40, loss: 0.06572422385215759
step: 50, loss: 0.004571907222270966
step: 60, loss: 0.003753781085833907
step: 70, loss: 0.003424725029617548
step: 80, loss: 0.01571943610906601
step: 90, loss: 0.02869138866662979
step: 100, loss: 5.648095248034224e-05
step: 110, loss: 0.04249121621251106
step: 120, loss: 0.030498672276735306
step: 130, loss: 0.009565683081746101
step: 140, loss: 0.028441868722438812
step: 150, loss: 0.07063695043325424
step: 160, loss: 0.007115977816283703
step: 170, loss: 0.0006242769886739552
step: 180, loss: 0.0006370125338435173
step: 190, loss: 0.028016332536935806
step: 200, loss: 0.0011980400886386633
step: 210, loss: 0.026129167526960373
step: 220, loss: 0.02414056472480297
step: 230, loss: 0.07128865271806717
step: 240, loss: 0.0351441316306591
step: 250, loss: 0.009054143913090229
step: 260, loss: 0.00974356010556221
step: 270, loss: 0.02782372012734413
step: 280, loss: 9.31156610022299e-05
step: 290, loss: 0.029981223866343498
step: 300, loss: 0.009633914567530155
step: 310, loss: 0.00037831588997505605
step: 320, loss: 4.177480877842754e-05
step: 330, loss: 0.003904445096850395
step: 340, loss: 0.0008686924702487886
step: 350, loss: 5.889472959097475e-05
step: 360, loss: 0.024786019697785378
step: 370, loss: 0.013048626482486725
step: 380, loss: 0.03510190173983574
epoch 20: dev_f1=0.6937669376693768, f1=0.6920980926430518, best_f1=0.7430025445292621
