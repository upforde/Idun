cuda
Device: cuda
step: 0, loss: 0.5587427616119385
step: 10, loss: 0.3709266781806946
step: 20, loss: 0.3218638300895691
step: 30, loss: 0.23706769943237305
step: 40, loss: 0.1471312791109085
step: 50, loss: 0.39481616020202637
step: 60, loss: 0.31225964426994324
step: 70, loss: 0.21736052632331848
step: 80, loss: 0.2778521776199341
step: 90, loss: 0.32682594656944275
step: 100, loss: 0.39204028248786926
step: 110, loss: 0.49172621965408325
step: 120, loss: 0.12937046587467194
step: 130, loss: 0.2153274416923523
step: 140, loss: 0.13369791209697723
step: 150, loss: 0.18188020586967468
step: 160, loss: 0.3597393035888672
step: 170, loss: 0.4082428216934204
step: 180, loss: 0.2142476737499237
step: 190, loss: 0.022324034944176674
step: 200, loss: 0.24129442870616913
step: 210, loss: 0.15736301243305206
step: 220, loss: 0.2570973336696625
step: 230, loss: 0.21667593717575073
step: 240, loss: 0.3532519042491913
step: 250, loss: 0.23503758013248444
step: 260, loss: 0.3370736837387085
step: 270, loss: 0.27899688482284546
step: 280, loss: 0.2757956385612488
step: 290, loss: 0.24345089495182037
step: 300, loss: 0.18229977786540985
step: 310, loss: 0.3799173831939697
step: 320, loss: 0.15648332238197327
step: 330, loss: 0.06426703929901123
step: 340, loss: 0.25864169001579285
step: 350, loss: 0.1910383254289627
step: 360, loss: 0.08260898292064667
step: 370, loss: 0.21591763198375702
step: 380, loss: 0.029418520629405975
epoch 1: dev_f1=0.576923076923077, f1=0.563063063063063, best_f1=0.563063063063063
step: 0, loss: 0.1320103108882904
step: 10, loss: 0.01943781226873398
step: 20, loss: 0.1375170350074768
step: 30, loss: 0.09401753544807434
step: 40, loss: 0.17557145655155182
step: 50, loss: 0.032170772552490234
step: 60, loss: 0.2884270250797272
step: 70, loss: 0.06628303974866867
step: 80, loss: 0.1285620480775833
step: 90, loss: 0.20336280763149261
step: 100, loss: 0.25260189175605774
step: 110, loss: 0.07893756031990051
step: 120, loss: 0.09456013143062592
step: 130, loss: 0.061259254813194275
step: 140, loss: 0.11728335916996002
step: 150, loss: 0.03253798559308052
step: 160, loss: 0.04857642948627472
step: 170, loss: 0.07240093499422073
step: 180, loss: 0.09422174096107483
step: 190, loss: 0.15354681015014648
step: 200, loss: 0.14670228958129883
step: 210, loss: 0.038658615201711655
step: 220, loss: 0.12513309717178345
step: 230, loss: 0.12490261346101761
step: 240, loss: 0.04538077116012573
step: 250, loss: 0.07891583442687988
step: 260, loss: 0.18065883219242096
step: 270, loss: 0.09791543334722519
step: 280, loss: 0.3464401960372925
step: 290, loss: 0.13031789660453796
step: 300, loss: 0.052011456340551376
step: 310, loss: 0.1406654417514801
step: 320, loss: 0.10590725392103195
step: 330, loss: 0.03839483857154846
step: 340, loss: 0.05084330588579178
step: 350, loss: 0.17485938966274261
step: 360, loss: 0.047467190772295
step: 370, loss: 0.1582324504852295
step: 380, loss: 0.21654194593429565
epoch 2: dev_f1=0.6465116279069768, f1=0.6760563380281691, best_f1=0.6760563380281691
step: 0, loss: 0.0564739890396595
step: 10, loss: 0.13240164518356323
step: 20, loss: 0.11445286124944687
step: 30, loss: 0.07560035586357117
step: 40, loss: 0.06155729666352272
step: 50, loss: 0.1919480413198471
step: 60, loss: 0.21133634448051453
step: 70, loss: 0.18354226648807526
step: 80, loss: 0.18958480656147003
step: 90, loss: 0.2099785953760147
step: 100, loss: 0.11958099901676178
step: 110, loss: 0.1633267104625702
step: 120, loss: 0.05430047586560249
step: 130, loss: 0.11016108095645905
step: 140, loss: 0.021813083440065384
step: 150, loss: 0.10761664062738419
step: 160, loss: 0.10999893397092819
step: 170, loss: 0.034165896475315094
step: 180, loss: 0.11068577319383621
step: 190, loss: 0.020090840756893158
step: 200, loss: 0.1613112986087799
step: 210, loss: 0.061351340264081955
step: 220, loss: 0.030195243656635284
step: 230, loss: 0.019432438537478447
step: 240, loss: 0.052302345633506775
step: 250, loss: 0.09803671389818192
step: 260, loss: 0.1291731745004654
step: 270, loss: 0.4975631535053253
step: 280, loss: 0.07340819388628006
step: 290, loss: 0.09002341330051422
step: 300, loss: 0.032648153603076935
step: 310, loss: 0.055525463074445724
step: 320, loss: 0.16600218415260315
step: 330, loss: 0.08907506614923477
step: 340, loss: 0.159524068236351
step: 350, loss: 0.09016767889261246
step: 360, loss: 0.026795361191034317
step: 370, loss: 0.0739138200879097
step: 380, loss: 0.027425052598118782
epoch 3: dev_f1=0.662280701754386, f1=0.6935123042505593, best_f1=0.6935123042505593
step: 0, loss: 0.02380300499498844
step: 10, loss: 0.0530778169631958
step: 20, loss: 0.12037072330713272
step: 30, loss: 0.15242256224155426
step: 40, loss: 0.08982344716787338
step: 50, loss: 0.2854643762111664
step: 60, loss: 0.1360107660293579
step: 70, loss: 0.1625198870897293
step: 80, loss: 0.02561812847852707
step: 90, loss: 0.02414155751466751
step: 100, loss: 0.17882311344146729
step: 110, loss: 0.0836738646030426
step: 120, loss: 0.0071268230676651
step: 130, loss: 0.15790878236293793
step: 140, loss: 0.12337802350521088
step: 150, loss: 0.057257864624261856
step: 160, loss: 0.04752464219927788
step: 170, loss: 0.04531625285744667
step: 180, loss: 0.08303175866603851
step: 190, loss: 0.004934390541166067
step: 200, loss: 0.2443803995847702
step: 210, loss: 0.02695521153509617
step: 220, loss: 0.014333559200167656
step: 230, loss: 0.028257332742214203
step: 240, loss: 0.06495970487594604
step: 250, loss: 0.030263274908065796
step: 260, loss: 0.001995605183765292
step: 270, loss: 0.03517279773950577
step: 280, loss: 0.004802067764103413
step: 290, loss: 0.0689406469464302
step: 300, loss: 0.019154798239469528
step: 310, loss: 0.17840944230556488
step: 320, loss: 0.08213455975055695
step: 330, loss: 0.0024419198743999004
step: 340, loss: 0.2674501836299896
step: 350, loss: 0.01959414780139923
step: 360, loss: 0.13474810123443604
step: 370, loss: 0.11646605283021927
step: 380, loss: 0.031389616429805756
epoch 4: dev_f1=0.7005076142131978, f1=0.734375, best_f1=0.734375
step: 0, loss: 0.1415836662054062
step: 10, loss: 0.12017358839511871
step: 20, loss: 0.0002859463857021183
step: 30, loss: 0.20952454209327698
step: 40, loss: 0.049025241285562515
step: 50, loss: 0.07363596558570862
step: 60, loss: 0.05437431484460831
step: 70, loss: 0.04299764335155487
step: 80, loss: 0.10421337932348251
step: 90, loss: 0.11215342581272125
step: 100, loss: 0.05468739941716194
step: 110, loss: 0.07520311325788498
step: 120, loss: 0.08902950584888458
step: 130, loss: 0.0635601282119751
step: 140, loss: 0.021762993186712265
step: 150, loss: 0.054012756794691086
step: 160, loss: 0.07153219729661942
step: 170, loss: 0.008327611722052097
step: 180, loss: 0.13617980480194092
step: 190, loss: 0.0371532067656517
step: 200, loss: 0.04115958884358406
step: 210, loss: 0.11910947412252426
step: 220, loss: 0.019995098933577538
step: 230, loss: 0.046860471367836
step: 240, loss: 0.021971290931105614
step: 250, loss: 0.023940959945321083
step: 260, loss: 0.00974182691425085
step: 270, loss: 0.06863372772932053
step: 280, loss: 0.0788298025727272
step: 290, loss: 0.1539929360151291
step: 300, loss: 0.05191534385085106
step: 310, loss: 0.03884592279791832
step: 320, loss: 0.08502142876386642
step: 330, loss: 0.010320588946342468
step: 340, loss: 0.05020037293434143
step: 350, loss: 0.06211242079734802
step: 360, loss: 0.07233293354511261
step: 370, loss: 0.06777853518724442
step: 380, loss: 0.08661259710788727
epoch 5: dev_f1=0.7308641975308642, f1=0.751269035532995, best_f1=0.751269035532995
step: 0, loss: 0.08602479100227356
step: 10, loss: 0.014826808124780655
step: 20, loss: 0.3080577254295349
step: 30, loss: 0.03563350439071655
step: 40, loss: 0.024677418172359467
step: 50, loss: 0.06284656375646591
step: 60, loss: 0.087832510471344
step: 70, loss: 0.04278542101383209
step: 80, loss: 0.010880300775170326
step: 90, loss: 0.03199256584048271
step: 100, loss: 0.023734500631690025
step: 110, loss: 0.03523051366209984
step: 120, loss: 0.08966207504272461
step: 130, loss: 0.014821668155491352
step: 140, loss: 0.06466319411993027
step: 150, loss: 0.015064124017953873
step: 160, loss: 0.22972357273101807
step: 170, loss: 0.08429877460002899
step: 180, loss: 0.025937674567103386
step: 190, loss: 0.04531843587756157
step: 200, loss: 0.11555081605911255
step: 210, loss: 0.08765977621078491
step: 220, loss: 0.03489027917385101
step: 230, loss: 0.2316642552614212
step: 240, loss: 0.0012688945280387998
step: 250, loss: 0.014772841706871986
step: 260, loss: 0.04075086489319801
step: 270, loss: 0.005018271040171385
step: 280, loss: 0.07105856388807297
step: 290, loss: 0.10244797170162201
step: 300, loss: 0.008290546014904976
step: 310, loss: 0.022841639816761017
step: 320, loss: 0.01384379155933857
step: 330, loss: 0.0417017862200737
step: 340, loss: 0.02148476056754589
step: 350, loss: 0.04995987191796303
step: 360, loss: 0.11472560465335846
step: 370, loss: 0.02102210558950901
step: 380, loss: 0.04322367534041405
epoch 6: dev_f1=0.7613941018766757, f1=0.7292225201072386, best_f1=0.7292225201072386
step: 0, loss: 0.011490028351545334
step: 10, loss: 0.05365822836756706
step: 20, loss: 0.0068945265375077724
step: 30, loss: 0.11642508208751678
step: 40, loss: 0.0725959837436676
step: 50, loss: 0.0032303561456501484
step: 60, loss: 0.007436876650899649
step: 70, loss: 0.009026103653013706
step: 80, loss: 0.09256810694932938
step: 90, loss: 0.022680196911096573
step: 100, loss: 0.006806761026382446
step: 110, loss: 0.02939411625266075
step: 120, loss: 0.055322129279375076
step: 130, loss: 0.10572139918804169
step: 140, loss: 0.05668336898088455
step: 150, loss: 0.01487048901617527
step: 160, loss: 0.002958911005407572
step: 170, loss: 0.07350383698940277
step: 180, loss: 0.003950989805161953
step: 190, loss: 0.2107861042022705
step: 200, loss: 0.2642979919910431
step: 210, loss: 0.04850168526172638
step: 220, loss: 0.023705922067165375
step: 230, loss: 0.030959462746977806
step: 240, loss: 0.042169466614723206
step: 250, loss: 0.009820607490837574
step: 260, loss: 0.06398948282003403
step: 270, loss: 0.01636769250035286
step: 280, loss: 0.001648000325076282
step: 290, loss: 0.09905984997749329
step: 300, loss: 0.13686631619930267
step: 310, loss: 0.11770817637443542
step: 320, loss: 0.04948072135448456
step: 330, loss: 0.04082139581441879
step: 340, loss: 0.012404259294271469
step: 350, loss: 0.02682747319340706
step: 360, loss: 0.1472068727016449
step: 370, loss: 0.07867933809757233
step: 380, loss: 0.022093240171670914
epoch 7: dev_f1=0.6870229007633588, f1=0.7195767195767196, best_f1=0.7292225201072386
step: 0, loss: 0.017451317980885506
step: 10, loss: 0.010252445936203003
step: 20, loss: 0.06936024129390717
step: 30, loss: 0.011122661642730236
step: 40, loss: 0.13809329271316528
step: 50, loss: 0.0023947253357619047
step: 60, loss: 0.13387422263622284
step: 70, loss: 0.03794237598776817
step: 80, loss: 0.057920970022678375
step: 90, loss: 0.07813186198472977
step: 100, loss: 0.06996447592973709
step: 110, loss: 0.0573347769677639
step: 120, loss: 0.052121445536613464
step: 130, loss: 0.010844551026821136
step: 140, loss: 0.05753538757562637
step: 150, loss: 0.062178581953048706
step: 160, loss: 0.03936861827969551
step: 170, loss: 0.011376425623893738
step: 180, loss: 0.07819417864084244
step: 190, loss: 0.024043042212724686
step: 200, loss: 0.0093324463814497
step: 210, loss: 0.03776860609650612
step: 220, loss: 0.014211500063538551
step: 230, loss: 0.11568551510572433
step: 240, loss: 0.03143863379955292
step: 250, loss: 0.11090690642595291
step: 260, loss: 0.0010495522292330861
step: 270, loss: 0.07344692945480347
step: 280, loss: 0.064949631690979
step: 290, loss: 0.046833254396915436
step: 300, loss: 0.024249278008937836
step: 310, loss: 0.037248048931360245
step: 320, loss: 0.03402625396847725
step: 330, loss: 0.05191609263420105
step: 340, loss: 0.05505290627479553
step: 350, loss: 0.04788462817668915
step: 360, loss: 0.041519030928611755
step: 370, loss: 0.10483955591917038
step: 380, loss: 0.09848649054765701
epoch 8: dev_f1=0.7177033492822966, f1=0.7277108433734939, best_f1=0.7292225201072386
step: 0, loss: 0.08859408646821976
step: 10, loss: 0.06157700717449188
step: 20, loss: 0.0039599305018782616
step: 30, loss: 0.10883385688066483
step: 40, loss: 0.003754395293071866
step: 50, loss: 0.001753873424604535
step: 60, loss: 0.00022546104446519166
step: 70, loss: 0.05284474045038223
step: 80, loss: 0.0009742627153173089
step: 90, loss: 0.09536860883235931
step: 100, loss: 0.004205827135592699
step: 110, loss: 0.14653266966342926
step: 120, loss: 0.15217232704162598
step: 130, loss: 0.053991254419088364
step: 140, loss: 0.0017227687640115619
step: 150, loss: 0.20415528118610382
step: 160, loss: 0.171369269490242
step: 170, loss: 0.007718842476606369
step: 180, loss: 0.025156302377581596
step: 190, loss: 0.0012759072706103325
step: 200, loss: 0.02491326443850994
step: 210, loss: 0.06243908032774925
step: 220, loss: 0.1616975963115692
step: 230, loss: 0.03279917314648628
step: 240, loss: 0.0412738174200058
step: 250, loss: 0.012866560369729996
step: 260, loss: 0.02509171888232231
step: 270, loss: 0.05226370692253113
step: 280, loss: 0.03198210895061493
step: 290, loss: 0.0052664615213871
step: 300, loss: 0.09057693183422089
step: 310, loss: 0.12667645514011383
step: 320, loss: 0.12321717292070389
step: 330, loss: 0.008311568759381771
step: 340, loss: 0.007028736639767885
step: 350, loss: 0.0958973839879036
step: 360, loss: 0.05946006998419762
step: 370, loss: 0.022144529968500137
step: 380, loss: 0.043691281229257584
epoch 9: dev_f1=0.6888888888888888, f1=0.7055555555555556, best_f1=0.7292225201072386
step: 0, loss: 0.039898376911878586
step: 10, loss: 0.03465677797794342
step: 20, loss: 0.04218991473317146
step: 30, loss: 0.00024511368246749043
step: 40, loss: 0.24796929955482483
step: 50, loss: 0.0012043272145092487
step: 60, loss: 0.005006400402635336
step: 70, loss: 0.06344716250896454
step: 80, loss: 0.03193831071257591
step: 90, loss: 0.03671807795763016
step: 100, loss: 0.009090228006243706
step: 110, loss: 0.020256390795111656
step: 120, loss: 0.04152214899659157
step: 130, loss: 0.011269151233136654
step: 140, loss: 0.04347303882241249
step: 150, loss: 0.06437932699918747
step: 160, loss: 0.16170963644981384
step: 170, loss: 0.001063074916601181
step: 180, loss: 0.0008619489381089807
step: 190, loss: 0.04188845306634903
step: 200, loss: 0.13539044559001923
step: 210, loss: 0.018947269767522812
step: 220, loss: 0.016263527795672417
step: 230, loss: 0.021169157698750496
step: 240, loss: 0.0036437243688851595
step: 250, loss: 0.12834812700748444
step: 260, loss: 0.03316868841648102
step: 270, loss: 0.07973545789718628
step: 280, loss: 0.018669957295060158
step: 290, loss: 0.0058790287002921104
step: 300, loss: 0.008890136145055294
step: 310, loss: 0.0050502861849963665
step: 320, loss: 0.09421775490045547
step: 330, loss: 0.00468659121543169
step: 340, loss: 0.03922292962670326
step: 350, loss: 0.028435952961444855
step: 360, loss: 0.12317423522472382
step: 370, loss: 0.0008183561149053276
step: 380, loss: 0.012948724441230297
epoch 10: dev_f1=0.7213930348258706, f1=0.7150259067357513, best_f1=0.7292225201072386
step: 0, loss: 0.07556036859750748
step: 10, loss: 0.045950859785079956
step: 20, loss: 0.05262663587927818
step: 30, loss: 0.023199565708637238
step: 40, loss: 0.00014537076640408486
step: 50, loss: 0.20298440754413605
step: 60, loss: 0.08513086289167404
step: 70, loss: 0.004284231457859278
step: 80, loss: 0.08957044035196304
step: 90, loss: 0.00037834857357665896
step: 100, loss: 0.018368389457464218
step: 110, loss: 0.029495583847165108
step: 120, loss: 0.007265148684382439
step: 130, loss: 0.00833619199693203
step: 140, loss: 0.17947301268577576
step: 150, loss: 0.1788974106311798
step: 160, loss: 0.009135122410953045
step: 170, loss: 0.01745188795030117
step: 180, loss: 0.08308520913124084
step: 190, loss: 0.019478952512145042
step: 200, loss: 0.09415611624717712
step: 210, loss: 0.01883538067340851
step: 220, loss: 0.020179355517029762
step: 230, loss: 0.010812560096383095
step: 240, loss: 0.1028573215007782
step: 250, loss: 0.003924587741494179
step: 260, loss: 0.03021402284502983
step: 270, loss: 0.07766859233379364
step: 280, loss: 0.00679399399086833
step: 290, loss: 0.0012697067577391863
step: 300, loss: 0.00019690759654622525
step: 310, loss: 0.031225193291902542
step: 320, loss: 0.037406738847494125
step: 330, loss: 0.04025883600115776
step: 340, loss: 0.03902484476566315
step: 350, loss: 0.0002673433336894959
step: 360, loss: 0.012103686109185219
step: 370, loss: 0.00017159245908260345
step: 380, loss: 0.058052513748407364
epoch 11: dev_f1=0.7386934673366835, f1=0.7324675324675326, best_f1=0.7292225201072386
step: 0, loss: 0.0039719403721392155
step: 10, loss: 0.01212398987263441
step: 20, loss: 0.0006358998361974955
step: 30, loss: 0.016172192990779877
step: 40, loss: 0.001392032136209309
step: 50, loss: 0.07796741276979446
step: 60, loss: 0.011099974624812603
step: 70, loss: 0.05546143651008606
step: 80, loss: 0.0011490725446492434
step: 90, loss: 0.02718120440840721
step: 100, loss: 0.08212362974882126
step: 110, loss: 0.0006064721965231001
step: 120, loss: 0.02805403247475624
step: 130, loss: 0.0034840372391045094
step: 140, loss: 0.03954534977674484
step: 150, loss: 0.05217151716351509
step: 160, loss: 0.025841908529400826
step: 170, loss: 0.0004020422347821295
step: 180, loss: 0.00031942909117788076
step: 190, loss: 0.00034774033701978624
step: 200, loss: 0.1108643114566803
step: 210, loss: 0.0018369074678048491
step: 220, loss: 0.0011982031865045428
step: 230, loss: 0.11535757780075073
step: 240, loss: 0.02176016941666603
step: 250, loss: 0.035195592790842056
step: 260, loss: 0.024300135672092438
step: 270, loss: 0.0038087661378085613
step: 280, loss: 0.0161662008613348
step: 290, loss: 0.009983131662011147
step: 300, loss: 0.16917909681797028
step: 310, loss: 0.040240511298179626
step: 320, loss: 0.04763343930244446
step: 330, loss: 0.08801629394292831
step: 340, loss: 0.001838433789089322
step: 350, loss: 0.07510782033205032
step: 360, loss: 0.0034684548154473305
step: 370, loss: 0.0033994875848293304
step: 380, loss: 0.02750634402036667
epoch 12: dev_f1=0.7321867321867322, f1=0.724935732647815, best_f1=0.7292225201072386
step: 0, loss: 0.004943644627928734
step: 10, loss: 0.01502685621380806
step: 20, loss: 0.006738681346178055
step: 30, loss: 0.0011400432558730245
step: 40, loss: 0.0014809693675488234
step: 50, loss: 0.004651355557143688
step: 60, loss: 0.0011150444624945521
step: 70, loss: 0.04042324051260948
step: 80, loss: 0.013400179333984852
step: 90, loss: 0.0022139851935207844
step: 100, loss: 0.00039015288348309696
step: 110, loss: 7.164192356867716e-05
step: 120, loss: 0.002397839678451419
step: 130, loss: 0.03465473651885986
step: 140, loss: 0.05801418796181679
step: 150, loss: 0.06194193288683891
step: 160, loss: 0.03216668963432312
step: 170, loss: 0.09810780733823776
step: 180, loss: 0.005277418531477451
step: 190, loss: 0.05386169254779816
step: 200, loss: 0.05924619361758232
step: 210, loss: 0.012040547095239162
step: 220, loss: 0.034943487495183945
step: 230, loss: 8.327720570378006e-05
step: 240, loss: 0.08213615417480469
step: 250, loss: 0.00918043963611126
step: 260, loss: 0.00012268278806004673
step: 270, loss: 0.10926907509565353
step: 280, loss: 0.03919921815395355
step: 290, loss: 0.024380894377827644
step: 300, loss: 0.0640416145324707
step: 310, loss: 0.002474050037562847
step: 320, loss: 0.02547631412744522
step: 330, loss: 0.02155684307217598
step: 340, loss: 0.1402917057275772
step: 350, loss: 0.005767097696661949
step: 360, loss: 0.037897493690252304
step: 370, loss: 0.0020955889485776424
step: 380, loss: 0.0057479869574308395
epoch 13: dev_f1=0.7330097087378641, f1=0.7204030226700252, best_f1=0.7292225201072386
step: 0, loss: 0.012896657921373844
step: 10, loss: 0.018070627003908157
step: 20, loss: 0.013591431081295013
step: 30, loss: 0.0028918194584548473
step: 40, loss: 0.030908359214663506
step: 50, loss: 0.04752035811543465
step: 60, loss: 0.020862871780991554
step: 70, loss: 0.003078843466937542
step: 80, loss: 0.0004039922496303916
step: 90, loss: 0.09337923675775528
step: 100, loss: 0.020882990211248398
step: 110, loss: 0.017397752031683922
step: 120, loss: 0.0013750536600127816
step: 130, loss: 0.09229470789432526
step: 140, loss: 0.0005458059604279697
step: 150, loss: 0.006199666764587164
step: 160, loss: 0.023061295971274376
step: 170, loss: 0.0004994700429961085
step: 180, loss: 0.0268019400537014
step: 190, loss: 0.01837482862174511
step: 200, loss: 0.001705419854260981
step: 210, loss: 0.000913171679712832
step: 220, loss: 0.027700331062078476
step: 230, loss: 0.00549545930698514
step: 240, loss: 0.028913013637065887
step: 250, loss: 0.01714163087308407
step: 260, loss: 0.0033200541511178017
step: 270, loss: 0.012597387656569481
step: 280, loss: 8.027849980862811e-05
step: 290, loss: 0.05092916637659073
step: 300, loss: 0.003025361569598317
step: 310, loss: 0.049401119351387024
step: 320, loss: 0.0007171255419962108
step: 330, loss: 0.001466961926780641
step: 340, loss: 0.0258344579488039
step: 350, loss: 0.00014038552762940526
step: 360, loss: 0.01709933765232563
step: 370, loss: 0.02893802337348461
step: 380, loss: 0.009891838766634464
epoch 14: dev_f1=0.7329842931937172, f1=0.7193460490463215, best_f1=0.7292225201072386
step: 0, loss: 0.06538812071084976
step: 10, loss: 0.015836462378501892
step: 20, loss: 0.004741119686514139
step: 30, loss: 0.006075924728065729
step: 40, loss: 0.07260655611753464
step: 50, loss: 0.014400061219930649
step: 60, loss: 0.01196066103875637
step: 70, loss: 0.00024467124603688717
step: 80, loss: 0.0075573790818452835
step: 90, loss: 0.035081539303064346
step: 100, loss: 0.023081857711076736
step: 110, loss: 0.0015794356586411595
step: 120, loss: 0.002134940354153514
step: 130, loss: 4.7826950321905315e-05
step: 140, loss: 0.0025100093334913254
step: 150, loss: 0.004693822935223579
step: 160, loss: 0.017955167219042778
step: 170, loss: 0.0341007374227047
step: 180, loss: 0.00018249732966069132
step: 190, loss: 0.0749894380569458
step: 200, loss: 0.017109520733356476
step: 210, loss: 0.002306506736204028
step: 220, loss: 0.029459692537784576
step: 230, loss: 0.012169556692242622
step: 240, loss: 0.05338318645954132
step: 250, loss: 0.004597104620188475
step: 260, loss: 0.002284037182107568
step: 270, loss: 0.001498201978392899
step: 280, loss: 0.0026170590426772833
step: 290, loss: 0.04293787479400635
step: 300, loss: 6.397081597242504e-05
step: 310, loss: 0.00048380339285358787
step: 320, loss: 0.003623593132942915
step: 330, loss: 0.015906354412436485
step: 340, loss: 0.0007991456077434123
step: 350, loss: 0.001364172319881618
step: 360, loss: 0.05929407477378845
step: 370, loss: 0.03919892758131027
step: 380, loss: 0.005962172988802195
epoch 15: dev_f1=0.7167919799498748, f1=0.7, best_f1=0.7292225201072386
step: 0, loss: 0.05507954955101013
step: 10, loss: 0.002851450350135565
step: 20, loss: 0.0059396643191576
step: 30, loss: 0.0006153391441330314
step: 40, loss: 0.033724911510944366
step: 50, loss: 0.0021100109443068504
step: 60, loss: 7.535782060585916e-05
step: 70, loss: 0.006838228087872267
step: 80, loss: 0.0028347948100417852
step: 90, loss: 0.0039076535031199455
step: 100, loss: 0.045509446412324905
step: 110, loss: 0.00011477014049887657
step: 120, loss: 0.0044627198949456215
step: 130, loss: 0.003060730639845133
step: 140, loss: 0.038412660360336304
step: 150, loss: 6.624416710110381e-05
step: 160, loss: 5.4745396482758224e-05
step: 170, loss: 0.025385813787579536
step: 180, loss: 0.010681107640266418
step: 190, loss: 0.016612891107797623
step: 200, loss: 0.015317151322960854
step: 210, loss: 0.045472804456949234
step: 220, loss: 0.004431567154824734
step: 230, loss: 0.0012190468842163682
step: 240, loss: 0.00011634903057711199
step: 250, loss: 0.0013345163315534592
step: 260, loss: 0.019346287474036217
step: 270, loss: 0.036376629024744034
step: 280, loss: 0.010995110496878624
step: 290, loss: 0.0011466046562418342
step: 300, loss: 0.03696449100971222
step: 310, loss: 0.000548891257494688
step: 320, loss: 0.043952036648988724
step: 330, loss: 0.022287875413894653
step: 340, loss: 0.00013049198605585843
step: 350, loss: 0.12581059336662292
step: 360, loss: 0.009725775569677353
step: 370, loss: 0.030469000339508057
step: 380, loss: 0.012051599100232124
epoch 16: dev_f1=0.7232876712328767, f1=0.7272727272727272, best_f1=0.7292225201072386
step: 0, loss: 0.05900188907980919
step: 10, loss: 0.01891396753489971
step: 20, loss: 0.015186266042292118
step: 30, loss: 0.022474471479654312
step: 40, loss: 0.0005844556726515293
step: 50, loss: 0.010390100069344044
step: 60, loss: 0.03591031953692436
step: 70, loss: 0.01650148630142212
step: 80, loss: 5.474049612530507e-05
step: 90, loss: 0.0015562169719487429
step: 100, loss: 0.0007103057578206062
step: 110, loss: 0.023999696597456932
step: 120, loss: 0.012888675555586815
step: 130, loss: 0.0028244543354958296
step: 140, loss: 0.00012499862350523472
step: 150, loss: 0.0018350532045587897
step: 160, loss: 0.0011233023833483458
step: 170, loss: 0.03401869535446167
step: 180, loss: 0.02105952799320221
step: 190, loss: 0.00212910957634449
step: 200, loss: 0.03033900260925293
step: 210, loss: 0.0001403787755407393
step: 220, loss: 0.022381406277418137
step: 230, loss: 0.0032811430282890797
step: 240, loss: 0.013142012991011143
step: 250, loss: 0.09403364360332489
step: 260, loss: 0.0005008282023482025
step: 270, loss: 0.04885876923799515
step: 280, loss: 0.00045523358858190477
step: 290, loss: 0.04449810832738876
step: 300, loss: 0.09607801586389542
step: 310, loss: 0.044014908373355865
step: 320, loss: 0.028435256332159042
step: 330, loss: 0.00011933239147765562
step: 340, loss: 0.048712313175201416
step: 350, loss: 0.022205276414752007
step: 360, loss: 0.013921578414738178
step: 370, loss: 0.058326490223407745
step: 380, loss: 0.0008277683518826962
epoch 17: dev_f1=0.7193460490463215, f1=0.6906077348066297, best_f1=0.7292225201072386
step: 0, loss: 0.00020212992967572063
step: 10, loss: 0.021382277831435204
step: 20, loss: 0.0005017566145397723
step: 30, loss: 4.4584565330296755e-05
step: 40, loss: 0.0012789691099897027
step: 50, loss: 0.0013571071904152632
step: 60, loss: 0.04644234851002693
step: 70, loss: 0.015596226789057255
step: 80, loss: 0.02954115718603134
step: 90, loss: 0.010832044295966625
step: 100, loss: 0.0001547828724142164
step: 110, loss: 0.020532650873064995
step: 120, loss: 0.0023866731207817793
step: 130, loss: 0.045905161648988724
step: 140, loss: 8.041723049245775e-05
step: 150, loss: 0.002374869305640459
step: 160, loss: 0.00010668029426597059
step: 170, loss: 0.02295610122382641
step: 180, loss: 0.002639682497829199
step: 190, loss: 0.0604088231921196
step: 200, loss: 0.024281533434987068
step: 210, loss: 0.0692560151219368
step: 220, loss: 0.0346105583012104
step: 230, loss: 0.03318646550178528
step: 240, loss: 0.019919414073228836
step: 250, loss: 0.00026946922298520803
step: 260, loss: 0.021587209776043892
step: 270, loss: 3.2021580409491435e-05
step: 280, loss: 0.0990094467997551
step: 290, loss: 0.02089075744152069
step: 300, loss: 0.008719653822481632
step: 310, loss: 0.02189778909087181
step: 320, loss: 0.04867184907197952
step: 330, loss: 0.006185992620885372
step: 340, loss: 0.016072247177362442
step: 350, loss: 0.015314701944589615
step: 360, loss: 0.0006116103031672537
step: 370, loss: 0.02363778091967106
step: 380, loss: 0.002623284235596657
epoch 18: dev_f1=0.7306666666666668, f1=0.7055555555555556, best_f1=0.7292225201072386
step: 0, loss: 0.01772429421544075
step: 10, loss: 0.03547019511461258
step: 20, loss: 4.808826997759752e-05
step: 30, loss: 0.013982987031340599
step: 40, loss: 0.00014854907931294292
step: 50, loss: 0.023498933762311935
step: 60, loss: 0.0007448678370565176
step: 70, loss: 0.006309207528829575
step: 80, loss: 0.015551500953733921
step: 90, loss: 0.049734052270650864
step: 100, loss: 0.0001463007793063298
step: 110, loss: 0.0016881305491551757
step: 120, loss: 0.00818517804145813
step: 130, loss: 0.03374924138188362
step: 140, loss: 0.07085052132606506
step: 150, loss: 0.0023602121509611607
step: 160, loss: 7.272798393387347e-05
step: 170, loss: 0.017054570838809013
step: 180, loss: 0.05814269185066223
step: 190, loss: 0.0005734104779548943
step: 200, loss: 5.927174788666889e-05
step: 210, loss: 0.01844593696296215
step: 220, loss: 0.025635425001382828
step: 230, loss: 0.027351774275302887
step: 240, loss: 0.002107494743540883
step: 250, loss: 0.04834242910146713
step: 260, loss: 0.0012682114029303193
step: 270, loss: 0.013164149597287178
step: 280, loss: 0.05482948571443558
step: 290, loss: 0.023807480931282043
step: 300, loss: 0.0002822517999447882
step: 310, loss: 0.0004373893316369504
step: 320, loss: 0.000348633126122877
step: 330, loss: 0.04206029325723648
step: 340, loss: 8.845045522321016e-05
step: 350, loss: 0.05970637872815132
step: 360, loss: 0.028333114460110664
step: 370, loss: 0.0001434995065210387
step: 380, loss: 0.012174367904663086
epoch 19: dev_f1=0.7365591397849462, f1=0.7150837988826816, best_f1=0.7292225201072386
step: 0, loss: 0.009520106948912144
step: 10, loss: 0.045421767979860306
step: 20, loss: 0.039396580308675766
step: 30, loss: 0.00025803703465498984
step: 40, loss: 4.157530565862544e-05
step: 50, loss: 9.1893358330708e-05
step: 60, loss: 0.022748667746782303
step: 70, loss: 0.10523135960102081
step: 80, loss: 0.039306677877902985
step: 90, loss: 0.031255826354026794
step: 100, loss: 0.0320010632276535
step: 110, loss: 0.00018837676907423884
step: 120, loss: 0.0001007040191325359
step: 130, loss: 0.051798105239868164
step: 140, loss: 0.007504332810640335
step: 150, loss: 0.0012309238081797957
step: 160, loss: 0.0001371186663163826
step: 170, loss: 0.0194279495626688
step: 180, loss: 0.010234936140477657
step: 190, loss: 4.210657425574027e-05
step: 200, loss: 0.0001373742998111993
step: 210, loss: 0.024205688387155533
step: 220, loss: 0.002870991127565503
step: 230, loss: 0.006885856855660677
step: 240, loss: 0.025178875774145126
step: 250, loss: 0.01396937295794487
step: 260, loss: 4.386852015159093e-05
step: 270, loss: 0.002483086660504341
step: 280, loss: 0.001190663082525134
step: 290, loss: 0.01805928908288479
step: 300, loss: 0.014265215955674648
step: 310, loss: 0.027371075004339218
step: 320, loss: 0.0009389608749188483
step: 330, loss: 0.003369913436472416
step: 340, loss: 0.0021319896914064884
step: 350, loss: 0.004543309565633535
step: 360, loss: 0.03117186203598976
step: 370, loss: 0.0007998531218618155
step: 380, loss: 0.00012975452409591526
epoch 20: dev_f1=0.7301587301587302, f1=0.7206703910614525, best_f1=0.7292225201072386
