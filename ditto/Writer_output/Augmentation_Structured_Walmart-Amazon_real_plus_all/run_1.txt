cuda
Device: cuda
step: 0, loss: 0.696995735168457
step: 10, loss: 0.1676175445318222
step: 20, loss: 0.3986636698246002
step: 30, loss: 0.2503261864185333
step: 40, loss: 0.4684414863586426
step: 50, loss: 0.24700795114040375
step: 60, loss: 0.3850526809692383
step: 70, loss: 0.3636927008628845
step: 80, loss: 0.23222112655639648
step: 90, loss: 0.30593249201774597
step: 100, loss: 0.3148511052131653
step: 110, loss: 0.34918394684791565
step: 120, loss: 0.3481397032737732
step: 130, loss: 0.41856735944747925
step: 140, loss: 0.31994834542274475
step: 150, loss: 0.2810072600841522
step: 160, loss: 0.28962600231170654
step: 170, loss: 0.26764407753944397
step: 180, loss: 0.23163053393363953
step: 190, loss: 0.655009388923645
step: 200, loss: 0.29620203375816345
step: 210, loss: 0.22972828149795532
step: 220, loss: 0.26250845193862915
step: 230, loss: 0.09059112519025803
step: 240, loss: 0.49153777956962585
step: 250, loss: 0.17862184345722198
step: 260, loss: 0.06943913549184799
step: 270, loss: 0.1292344033718109
step: 280, loss: 0.3774135708808899
step: 290, loss: 0.1821870058774948
step: 300, loss: 0.024954749271273613
step: 310, loss: 0.09588811546564102
step: 320, loss: 0.124283067882061
step: 330, loss: 0.2581862211227417
step: 340, loss: 0.253640741109848
step: 350, loss: 0.12631697952747345
step: 360, loss: 0.14842981100082397
step: 370, loss: 0.16321292519569397
step: 380, loss: 0.22494655847549438
epoch 1: dev_f1=0.5833333333333334, f1=0.5961123110151189, best_f1=0.5961123110151189
step: 0, loss: 0.10156162083148956
step: 10, loss: 0.18077370524406433
step: 20, loss: 0.07323277741670609
step: 30, loss: 0.14649316668510437
step: 40, loss: 0.149521142244339
step: 50, loss: 0.03310070186853409
step: 60, loss: 0.09698539227247238
step: 70, loss: 0.2627742886543274
step: 80, loss: 0.11311207711696625
step: 90, loss: 0.0927901342511177
step: 100, loss: 0.058093417435884476
step: 110, loss: 0.06551550328731537
step: 120, loss: 0.06758338212966919
step: 130, loss: 0.02667512558400631
step: 140, loss: 0.09221841394901276
step: 150, loss: 0.0860297679901123
step: 160, loss: 0.06200472265481949
step: 170, loss: 0.08186153322458267
step: 180, loss: 0.1924700289964676
step: 190, loss: 0.17520613968372345
step: 200, loss: 0.031514521688222885
step: 210, loss: 0.16344697773456573
step: 220, loss: 0.12886828184127808
step: 230, loss: 0.10135602205991745
step: 240, loss: 0.16116027534008026
step: 250, loss: 0.1857912242412567
step: 260, loss: 0.013029595836997032
step: 270, loss: 0.1128050684928894
step: 280, loss: 0.12264084070920944
step: 290, loss: 0.08324296772480011
step: 300, loss: 0.05571384355425835
step: 310, loss: 0.18198613822460175
step: 320, loss: 0.14269329607486725
step: 330, loss: 0.10138756036758423
step: 340, loss: 0.3508407473564148
step: 350, loss: 0.12659285962581635
step: 360, loss: 0.20217308402061462
step: 370, loss: 0.16268929839134216
step: 380, loss: 0.15658646821975708
epoch 2: dev_f1=0.6756756756756757, f1=0.6666666666666667, best_f1=0.6666666666666667
step: 0, loss: 0.0471331849694252
step: 10, loss: 0.10284626483917236
step: 20, loss: 0.023958446457982063
step: 30, loss: 0.046240657567977905
step: 40, loss: 0.1234237402677536
step: 50, loss: 0.10612000524997711
step: 60, loss: 0.12278469651937485
step: 70, loss: 0.10520043969154358
step: 80, loss: 0.08482806384563446
step: 90, loss: 0.07229551672935486
step: 100, loss: 0.04255620390176773
step: 110, loss: 0.21664303541183472
step: 120, loss: 0.15868279337882996
step: 130, loss: 0.04414096847176552
step: 140, loss: 0.11700699478387833
step: 150, loss: 0.029267089441418648
step: 160, loss: 0.11555948853492737
step: 170, loss: 0.17906087636947632
step: 180, loss: 0.04033659026026726
step: 190, loss: 0.010882716625928879
step: 200, loss: 0.04806380346417427
step: 210, loss: 0.08140340447425842
step: 220, loss: 0.06647756695747375
step: 230, loss: 0.09937340766191483
step: 240, loss: 0.023020921275019646
step: 250, loss: 0.06139880791306496
step: 260, loss: 0.059263937175273895
step: 270, loss: 0.026372943073511124
step: 280, loss: 0.20108869671821594
step: 290, loss: 0.20308169722557068
step: 300, loss: 0.16453708708286285
step: 310, loss: 0.16672265529632568
step: 320, loss: 0.020222067832946777
step: 330, loss: 0.05103568732738495
step: 340, loss: 0.16555023193359375
step: 350, loss: 0.02439621090888977
step: 360, loss: 0.06938783824443817
step: 370, loss: 0.02908131666481495
step: 380, loss: 0.13125354051589966
epoch 3: dev_f1=0.6804123711340206, f1=0.7015706806282722, best_f1=0.7015706806282722
step: 0, loss: 0.09407250583171844
step: 10, loss: 0.0023112716153264046
step: 20, loss: 0.026750614866614342
step: 30, loss: 0.05424068123102188
step: 40, loss: 0.018463026732206345
step: 50, loss: 0.048639096319675446
step: 60, loss: 0.05383875593543053
step: 70, loss: 0.06730180978775024
step: 80, loss: 0.07384286820888519
step: 90, loss: 0.06538798660039902
step: 100, loss: 0.06735259294509888
step: 110, loss: 0.06658033281564713
step: 120, loss: 0.05675346404314041
step: 130, loss: 0.04526587948203087
step: 140, loss: 0.02351674623787403
step: 150, loss: 0.15300431847572327
step: 160, loss: 0.03180120885372162
step: 170, loss: 0.10938442498445511
step: 180, loss: 0.07992278784513474
step: 190, loss: 0.028711317107081413
step: 200, loss: 0.0376972071826458
step: 210, loss: 0.026684576645493507
step: 220, loss: 0.04762105271220207
step: 230, loss: 0.08917495608329773
step: 240, loss: 0.08438156545162201
step: 250, loss: 0.06490805000066757
step: 260, loss: 0.16413308680057526
step: 270, loss: 0.0729220062494278
step: 280, loss: 0.12945713102817535
step: 290, loss: 0.02076081745326519
step: 300, loss: 0.2742702066898346
step: 310, loss: 0.05325903370976448
step: 320, loss: 0.011973833665251732
step: 330, loss: 0.08605120331048965
step: 340, loss: 0.07837199419736862
step: 350, loss: 0.03361067175865173
step: 360, loss: 0.0546812079846859
step: 370, loss: 0.13422298431396484
step: 380, loss: 0.09376023709774017
epoch 4: dev_f1=0.6872037914691943, f1=0.7105882352941176, best_f1=0.7105882352941176
step: 0, loss: 0.09437782317399979
step: 10, loss: 0.023419801145792007
step: 20, loss: 0.0778876394033432
step: 30, loss: 0.0381016880273819
step: 40, loss: 0.09156636148691177
step: 50, loss: 0.08980682492256165
step: 60, loss: 0.013300830498337746
step: 70, loss: 0.07596128433942795
step: 80, loss: 0.16932041943073273
step: 90, loss: 0.030973630025982857
step: 100, loss: 0.05417114123702049
step: 110, loss: 0.04728977754712105
step: 120, loss: 0.08872994780540466
step: 130, loss: 0.0304104033857584
step: 140, loss: 0.0028081443160772324
step: 150, loss: 0.04955613613128662
step: 160, loss: 0.03495429456233978
step: 170, loss: 0.0625181570649147
step: 180, loss: 0.08287754654884338
step: 190, loss: 0.015861153602600098
step: 200, loss: 0.11538045853376389
step: 210, loss: 0.018695471808314323
step: 220, loss: 0.15773425996303558
step: 230, loss: 0.058468010276556015
step: 240, loss: 0.09279409050941467
step: 250, loss: 0.07703933119773865
step: 260, loss: 0.06575647741556168
step: 270, loss: 0.05712727829813957
step: 280, loss: 0.18745510280132294
step: 290, loss: 0.10769389569759369
step: 300, loss: 0.037405263632535934
step: 310, loss: 0.12519274652004242
step: 320, loss: 0.11873532831668854
step: 330, loss: 0.07760855555534363
step: 340, loss: 0.026050077751278877
step: 350, loss: 0.03639492765069008
step: 360, loss: 0.07255663722753525
step: 370, loss: 0.06051471456885338
step: 380, loss: 0.05216002091765404
epoch 5: dev_f1=0.6700251889168766, f1=0.69, best_f1=0.7105882352941176
step: 0, loss: 0.06298942863941193
step: 10, loss: 0.0008075904916040599
step: 20, loss: 0.11502571403980255
step: 30, loss: 0.07818537205457687
step: 40, loss: 0.015526414848864079
step: 50, loss: 0.09155181795358658
step: 60, loss: 0.017997339367866516
step: 70, loss: 0.04705333709716797
step: 80, loss: 0.055771078914403915
step: 90, loss: 0.00024671279243193567
step: 100, loss: 0.0513874813914299
step: 110, loss: 0.05232005566358566
step: 120, loss: 0.034962818026542664
step: 130, loss: 0.02898082137107849
step: 140, loss: 0.00745679996907711
step: 150, loss: 0.19297340512275696
step: 160, loss: 0.011595336720347404
step: 170, loss: 0.012934585101902485
step: 180, loss: 0.0697968378663063
step: 190, loss: 0.023002946749329567
step: 200, loss: 0.030202869325876236
step: 210, loss: 0.2055470049381256
step: 220, loss: 0.09599661827087402
step: 230, loss: 0.0036946875043213367
step: 240, loss: 0.1070110946893692
step: 250, loss: 0.05356105789542198
step: 260, loss: 0.16193079948425293
step: 270, loss: 0.04980364814400673
step: 280, loss: 0.1072319895029068
step: 290, loss: 0.07100728899240494
step: 300, loss: 0.004434030503034592
step: 310, loss: 0.06193988025188446
step: 320, loss: 0.008163628168404102
step: 330, loss: 0.09302270412445068
step: 340, loss: 0.022333983331918716
step: 350, loss: 0.15437456965446472
step: 360, loss: 0.012655490078032017
step: 370, loss: 0.010607249103486538
step: 380, loss: 0.1920146495103836
epoch 6: dev_f1=0.7292225201072386, f1=0.7248677248677249, best_f1=0.7248677248677249
step: 0, loss: 0.0774872675538063
step: 10, loss: 0.03163417428731918
step: 20, loss: 0.04565456137061119
step: 30, loss: 0.036687083542346954
step: 40, loss: 0.10521034896373749
step: 50, loss: 0.07166009396314621
step: 60, loss: 0.15171733498573303
step: 70, loss: 0.0030327863059937954
step: 80, loss: 0.0015875335084274411
step: 90, loss: 0.024104440584778786
step: 100, loss: 0.0005152600351721048
step: 110, loss: 0.0204948540776968
step: 120, loss: 0.01696142554283142
step: 130, loss: 0.009309276007115841
step: 140, loss: 0.03880912438035011
step: 150, loss: 0.03020266629755497
step: 160, loss: 0.03149093687534332
step: 170, loss: 0.07505301386117935
step: 180, loss: 0.08408238738775253
step: 190, loss: 0.029489565640687943
step: 200, loss: 0.03777128458023071
step: 210, loss: 0.048023030161857605
step: 220, loss: 0.143394336104393
step: 230, loss: 0.024817775934934616
step: 240, loss: 0.00325515354052186
step: 250, loss: 0.0346548818051815
step: 260, loss: 0.1011081263422966
step: 270, loss: 0.03674180060625076
step: 280, loss: 0.014003392308950424
step: 290, loss: 0.10126738250255585
step: 300, loss: 0.07335349172353745
step: 310, loss: 0.03229660168290138
step: 320, loss: 0.043163418769836426
step: 330, loss: 0.045374155044555664
step: 340, loss: 0.013449433259665966
step: 350, loss: 0.005143307149410248
step: 360, loss: 0.021783126518130302
step: 370, loss: 0.02611575834453106
step: 380, loss: 0.06277550756931305
epoch 7: dev_f1=0.7155963302752294, f1=0.7353629976580796, best_f1=0.7248677248677249
step: 0, loss: 0.026148594915866852
step: 10, loss: 0.05950228497385979
step: 20, loss: 0.0006767436861991882
step: 30, loss: 0.014753036201000214
step: 40, loss: 0.00012922116729896516
step: 50, loss: 0.08840575814247131
step: 60, loss: 0.04781600087881088
step: 70, loss: 0.028776124119758606
step: 80, loss: 0.04314602166414261
step: 90, loss: 0.1047113686800003
step: 100, loss: 0.030135173350572586
step: 110, loss: 0.005845777224749327
step: 120, loss: 0.036883097141981125
step: 130, loss: 0.10159660130739212
step: 140, loss: 0.15899550914764404
step: 150, loss: 0.02745196223258972
step: 160, loss: 0.08497701585292816
step: 170, loss: 0.08133218437433243
step: 180, loss: 0.048946231603622437
step: 190, loss: 0.06150408834218979
step: 200, loss: 0.14583149552345276
step: 210, loss: 0.061699289828538895
step: 220, loss: 0.0016052088467404246
step: 230, loss: 0.15639610588550568
step: 240, loss: 0.0686468780040741
step: 250, loss: 0.024145763367414474
step: 260, loss: 0.069552481174469
step: 270, loss: 0.041848670691251755
step: 280, loss: 0.029881684109568596
step: 290, loss: 0.007650194689631462
step: 300, loss: 0.030204324051737785
step: 310, loss: 0.08086613565683365
step: 320, loss: 0.0028923486825078726
step: 330, loss: 0.01579371839761734
step: 340, loss: 0.02664106711745262
step: 350, loss: 0.09302384406328201
step: 360, loss: 0.10514199733734131
step: 370, loss: 0.009245796129107475
step: 380, loss: 0.08218130469322205
epoch 8: dev_f1=0.724233983286908, f1=0.7247956403269755, best_f1=0.7248677248677249
step: 0, loss: 0.0773804783821106
step: 10, loss: 0.010838470421731472
step: 20, loss: 0.08506176620721817
step: 30, loss: 0.1138598769903183
step: 40, loss: 0.06552524119615555
step: 50, loss: 0.020653175190091133
step: 60, loss: 0.10605408251285553
step: 70, loss: 0.012387656606733799
step: 80, loss: 0.024453232064843178
step: 90, loss: 0.0012593850260600448
step: 100, loss: 0.04570148140192032
step: 110, loss: 0.02577385865151882
step: 120, loss: 0.045954082161188126
step: 130, loss: 0.03514116257429123
step: 140, loss: 0.030580870807170868
step: 150, loss: 0.065170057117939
step: 160, loss: 0.06459318846464157
step: 170, loss: 0.12662677466869354
step: 180, loss: 0.01335908379405737
step: 190, loss: 0.1328371912240982
step: 200, loss: 0.025060635060071945
step: 210, loss: 0.0331435389816761
step: 220, loss: 0.0603693388402462
step: 230, loss: 0.011149859987199306
step: 240, loss: 0.01931397058069706
step: 250, loss: 0.018931327387690544
step: 260, loss: 0.04667758196592331
step: 270, loss: 0.05657937377691269
step: 280, loss: 0.09661970287561417
step: 290, loss: 0.07231622189283371
step: 300, loss: 0.006064439192414284
step: 310, loss: 0.11631383746862411
step: 320, loss: 0.02308434061706066
step: 330, loss: 0.05447319149971008
step: 340, loss: 0.1260131299495697
step: 350, loss: 0.053885165601968765
step: 360, loss: 0.11516062915325165
step: 370, loss: 0.044412873685359955
step: 380, loss: 0.025810835883021355
epoch 9: dev_f1=0.6877828054298643, f1=0.7036144578313254, best_f1=0.7248677248677249
step: 0, loss: 0.008543711155653
step: 10, loss: 0.00859584379941225
step: 20, loss: 0.002941656392067671
step: 30, loss: 0.04756692051887512
step: 40, loss: 0.015068436041474342
step: 50, loss: 0.000428824161645025
step: 60, loss: 0.0002646960492711514
step: 70, loss: 0.00010150087473448366
step: 80, loss: 0.0043152556754648685
step: 90, loss: 0.030596062541007996
step: 100, loss: 0.08448239415884018
step: 110, loss: 0.07804551720619202
step: 120, loss: 0.015094351954758167
step: 130, loss: 0.02087310329079628
step: 140, loss: 0.0003970865800511092
step: 150, loss: 0.009136979468166828
step: 160, loss: 0.091909259557724
step: 170, loss: 0.008453493937849998
step: 180, loss: 0.03305739164352417
step: 190, loss: 0.027055636048316956
step: 200, loss: 0.060738950967788696
step: 210, loss: 0.06159045547246933
step: 220, loss: 0.08412466198205948
step: 230, loss: 0.013193732127547264
step: 240, loss: 0.002356852637603879
step: 250, loss: 0.05766768008470535
step: 260, loss: 0.01447642408311367
step: 270, loss: 0.08472944796085358
step: 280, loss: 0.03605194017291069
step: 290, loss: 6.213745655259117e-05
step: 300, loss: 0.020256293937563896
step: 310, loss: 0.03390127792954445
step: 320, loss: 0.006296074017882347
step: 330, loss: 0.072797492146492
step: 340, loss: 0.029336407780647278
step: 350, loss: 0.1176304817199707
step: 360, loss: 0.04288874939084053
step: 370, loss: 0.09031462669372559
step: 380, loss: 0.012522272765636444
epoch 10: dev_f1=0.7184466019417476, f1=0.7236180904522613, best_f1=0.7248677248677249
step: 0, loss: 0.05553648620843887
step: 10, loss: 0.012038035318255424
step: 20, loss: 0.11104156076908112
step: 30, loss: 0.037720099091529846
step: 40, loss: 0.02670992724597454
step: 50, loss: 0.1022348552942276
step: 60, loss: 0.00044585077557712793
step: 70, loss: 0.037278104573488235
step: 80, loss: 0.004053959157317877
step: 90, loss: 0.03279764950275421
step: 100, loss: 0.24763575196266174
step: 110, loss: 0.07122049480676651
step: 120, loss: 0.044730398803949356
step: 130, loss: 0.13065752387046814
step: 140, loss: 0.003175258869305253
step: 150, loss: 0.02934185042977333
step: 160, loss: 0.10826210677623749
step: 170, loss: 0.047379717230796814
step: 180, loss: 0.027975285425782204
step: 190, loss: 0.10087092220783234
step: 200, loss: 0.04383512958884239
step: 210, loss: 0.037042465060949326
step: 220, loss: 0.006397508084774017
step: 230, loss: 0.06534981727600098
step: 240, loss: 0.020855560898780823
step: 250, loss: 0.007537370081990957
step: 260, loss: 0.030964143574237823
step: 270, loss: 0.07533850520849228
step: 280, loss: 0.022996006533503532
step: 290, loss: 0.1080377921462059
step: 300, loss: 0.1556323617696762
step: 310, loss: 0.010901076719164848
step: 320, loss: 0.02531357854604721
step: 330, loss: 0.002188249258324504
step: 340, loss: 0.07336658239364624
step: 350, loss: 0.08200506865978241
step: 360, loss: 0.0024937994312494993
step: 370, loss: 0.022199584171175957
step: 380, loss: 0.05438671261072159
epoch 11: dev_f1=0.7153652392947103, f1=0.7365728900255755, best_f1=0.7248677248677249
step: 0, loss: 0.02935205027461052
step: 10, loss: 0.0053732567466795444
step: 20, loss: 0.005159485619515181
step: 30, loss: 0.0036522408481687307
step: 40, loss: 0.027348048985004425
step: 50, loss: 0.028650445863604546
step: 60, loss: 0.02965317852795124
step: 70, loss: 0.047130659222602844
step: 80, loss: 0.029332315549254417
step: 90, loss: 0.009640113450586796
step: 100, loss: 0.1209709569811821
step: 110, loss: 0.0020423848181962967
step: 120, loss: 0.10439388453960419
step: 130, loss: 4.1117593355011195e-05
step: 140, loss: 0.013758949004113674
step: 150, loss: 0.08488041907548904
step: 160, loss: 0.04824110493063927
step: 170, loss: 0.020973987877368927
step: 180, loss: 0.054451264441013336
step: 190, loss: 0.029142731800675392
step: 200, loss: 0.035406410694122314
step: 210, loss: 0.009024370461702347
step: 220, loss: 0.04188995063304901
step: 230, loss: 0.08096393197774887
step: 240, loss: 0.00029574104701168835
step: 250, loss: 0.012712029740214348
step: 260, loss: 0.04737970232963562
step: 270, loss: 0.0073899151757359505
step: 280, loss: 0.0048223258927464485
step: 290, loss: 0.019563883543014526
step: 300, loss: 0.022297168150544167
step: 310, loss: 0.035710908472537994
step: 320, loss: 0.042838387191295624
step: 330, loss: 0.010003202594816685
step: 340, loss: 0.00261665228754282
step: 350, loss: 0.0490262545645237
step: 360, loss: 0.023040201514959335
step: 370, loss: 0.0606936514377594
step: 380, loss: 0.036484211683273315
epoch 12: dev_f1=0.684863523573201, f1=0.7319587628865978, best_f1=0.7248677248677249
step: 0, loss: 0.034741032868623734
step: 10, loss: 0.03528546541929245
step: 20, loss: 0.046086158603429794
step: 30, loss: 0.006953481584787369
step: 40, loss: 0.05617976188659668
step: 50, loss: 0.004063180182129145
step: 60, loss: 0.004480078816413879
step: 70, loss: 0.04395703971385956
step: 80, loss: 0.015018726699054241
step: 90, loss: 0.00019353597599547356
step: 100, loss: 0.01035491842776537
step: 110, loss: 0.06304889917373657
step: 120, loss: 0.017277443781495094
step: 130, loss: 0.04702901095151901
step: 140, loss: 0.013738426379859447
step: 150, loss: 0.04865141585469246
step: 160, loss: 0.0006377801764756441
step: 170, loss: 0.0587761364877224
step: 180, loss: 0.0919857993721962
step: 190, loss: 0.0013630939647555351
step: 200, loss: 0.007943546399474144
step: 210, loss: 0.0024149962700903416
step: 220, loss: 0.3218095302581787
step: 230, loss: 4.044787783641368e-05
step: 240, loss: 7.118033681763336e-05
step: 250, loss: 0.02802557498216629
step: 260, loss: 0.03782782703638077
step: 270, loss: 0.033577293157577515
step: 280, loss: 5.392909952206537e-05
step: 290, loss: 5.408827564679086e-05
step: 300, loss: 0.05195509269833565
step: 310, loss: 0.017187219113111496
step: 320, loss: 0.015442613512277603
step: 330, loss: 0.01753018982708454
step: 340, loss: 0.009523015469312668
step: 350, loss: 0.05003809556365013
step: 360, loss: 0.09783606976270676
step: 370, loss: 0.004130197688937187
step: 380, loss: 0.07618984580039978
epoch 13: dev_f1=0.6717557251908398, f1=0.722077922077922, best_f1=0.7248677248677249
step: 0, loss: 0.0170166976749897
step: 10, loss: 0.0014354598242789507
step: 20, loss: 0.018546251580119133
step: 30, loss: 0.06461622565984726
step: 40, loss: 0.00017608738562557846
step: 50, loss: 0.00030481358407996595
step: 60, loss: 0.002019908744841814
step: 70, loss: 0.009372813627123833
step: 80, loss: 0.0809907466173172
step: 90, loss: 0.10336221009492874
step: 100, loss: 0.033330295234918594
step: 110, loss: 0.04061686247587204
step: 120, loss: 0.041502900421619415
step: 130, loss: 0.03406967222690582
step: 140, loss: 0.02139085717499256
step: 150, loss: 0.01504936907440424
step: 160, loss: 0.05791530758142471
step: 170, loss: 0.010705327615141869
step: 180, loss: 0.0002005053829634562
step: 190, loss: 0.041720468550920486
step: 200, loss: 0.07215143740177155
step: 210, loss: 0.02109263464808464
step: 220, loss: 0.018322033807635307
step: 230, loss: 0.05318450927734375
step: 240, loss: 0.02690907195210457
step: 250, loss: 0.13381892442703247
step: 260, loss: 0.025678984820842743
step: 270, loss: 0.011011863127350807
step: 280, loss: 0.007335882168263197
step: 290, loss: 0.05699899420142174
step: 300, loss: 0.06094541773200035
step: 310, loss: 0.009067866019904613
step: 320, loss: 0.018441200256347656
step: 330, loss: 0.006071913056075573
step: 340, loss: 0.012829718180000782
step: 350, loss: 0.002832884667441249
step: 360, loss: 0.002145832171663642
step: 370, loss: 0.0014878743095323443
step: 380, loss: 0.14718443155288696
epoch 14: dev_f1=0.7027027027027027, f1=0.7161125319693094, best_f1=0.7248677248677249
step: 0, loss: 0.006943915970623493
step: 10, loss: 0.014038140885531902
step: 20, loss: 0.03130977973341942
step: 30, loss: 0.002014092169702053
step: 40, loss: 5.668695303029381e-05
step: 50, loss: 0.03338366374373436
step: 60, loss: 6.856821710243821e-05
step: 70, loss: 0.01949973590672016
step: 80, loss: 7.002524944255129e-05
step: 90, loss: 0.03632213547825813
step: 100, loss: 0.009314557537436485
step: 110, loss: 0.16519857943058014
step: 120, loss: 0.0006609043339267373
step: 130, loss: 0.02244454436004162
step: 140, loss: 0.0363701730966568
step: 150, loss: 0.042419202625751495
step: 160, loss: 0.04438796639442444
step: 170, loss: 0.019847890362143517
step: 180, loss: 0.00013933388981968164
step: 190, loss: 0.020737584680318832
step: 200, loss: 0.00020468974253162742
step: 210, loss: 0.0002528787881601602
step: 220, loss: 0.03223232552409172
step: 230, loss: 0.07531266659498215
step: 240, loss: 0.003004197496920824
step: 250, loss: 0.00344419339671731
step: 260, loss: 0.03751106187701225
step: 270, loss: 0.011763827875256538
step: 280, loss: 0.013015956617891788
step: 290, loss: 0.012223887257277966
step: 300, loss: 0.012279869057238102
step: 310, loss: 0.00019609584705904126
step: 320, loss: 0.004339692648500204
step: 330, loss: 0.00011693578562699258
step: 340, loss: 0.024656474590301514
step: 350, loss: 8.94166951184161e-05
step: 360, loss: 0.010109972208738327
step: 370, loss: 0.0006886448827572167
step: 380, loss: 0.04159985110163689
epoch 15: dev_f1=0.7074468085106383, f1=0.7210526315789473, best_f1=0.7248677248677249
step: 0, loss: 0.00709545286372304
step: 10, loss: 0.006811997387558222
step: 20, loss: 0.05034433305263519
step: 30, loss: 0.007840834558010101
step: 40, loss: 0.03414624184370041
step: 50, loss: 0.01207389310002327
step: 60, loss: 0.022481435909867287
step: 70, loss: 0.0013817065628245473
step: 80, loss: 0.001386180054396391
step: 90, loss: 0.0009172188583761454
step: 100, loss: 0.010070182383060455
step: 110, loss: 0.0030295555479824543
step: 120, loss: 0.04526539519429207
step: 130, loss: 0.00626479322090745
step: 140, loss: 0.016782386228442192
step: 150, loss: 0.0016772012459114194
step: 160, loss: 0.032086361199617386
step: 170, loss: 0.002935637952759862
step: 180, loss: 0.024652592837810516
step: 190, loss: 0.03247925639152527
step: 200, loss: 0.030655141919851303
step: 210, loss: 0.03151531517505646
step: 220, loss: 0.07795052230358124
step: 230, loss: 0.0005211030365899205
step: 240, loss: 0.020537152886390686
step: 250, loss: 0.011901771649718285
step: 260, loss: 0.03564034774899483
step: 270, loss: 0.004109016619622707
step: 280, loss: 0.06260450184345245
step: 290, loss: 0.0034745335578918457
step: 300, loss: 0.04173868149518967
step: 310, loss: 0.058633580803871155
step: 320, loss: 0.006252458319067955
step: 330, loss: 0.048960600048303604
step: 340, loss: 0.012199513614177704
step: 350, loss: 0.005519434809684753
step: 360, loss: 0.011642671190202236
step: 370, loss: 0.0016527017578482628
step: 380, loss: 0.042909231036901474
epoch 16: dev_f1=0.6969696969696969, f1=0.7310704960835509, best_f1=0.7248677248677249
step: 0, loss: 0.002840582514181733
step: 10, loss: 5.367855919757858e-05
step: 20, loss: 2.6937059374176897e-05
step: 30, loss: 0.008255809545516968
step: 40, loss: 0.006349467672407627
step: 50, loss: 0.0637500137090683
step: 60, loss: 4.481550058699213e-05
step: 70, loss: 0.0069907051511108875
step: 80, loss: 0.030430959537625313
step: 90, loss: 0.005856783594936132
step: 100, loss: 0.007844563573598862
step: 110, loss: 0.006203002296388149
step: 120, loss: 0.01621883362531662
step: 130, loss: 0.05947408452630043
step: 140, loss: 0.006137512624263763
step: 150, loss: 0.06290793418884277
step: 160, loss: 0.01872037909924984
step: 170, loss: 0.06122429668903351
step: 180, loss: 0.00041459614294581115
step: 190, loss: 0.00036038292455486953
step: 200, loss: 0.10963950306177139
step: 210, loss: 0.0017553435172885656
step: 220, loss: 0.029481682926416397
step: 230, loss: 0.03529513254761696
step: 240, loss: 0.04416957497596741
step: 250, loss: 0.007093136198818684
step: 260, loss: 6.103159103076905e-05
step: 270, loss: 6.614765879930928e-05
step: 280, loss: 0.00011700639879563823
step: 290, loss: 0.04928251728415489
step: 300, loss: 0.0050446330569684505
step: 310, loss: 0.03517156466841698
step: 320, loss: 0.002438346156850457
step: 330, loss: 0.02246391959488392
step: 340, loss: 0.009496157057583332
step: 350, loss: 0.03634968027472496
step: 360, loss: 0.0006834686500951648
step: 370, loss: 3.745577851077542e-05
step: 380, loss: 0.0028520640917122364
epoch 17: dev_f1=0.6974358974358974, f1=0.7329842931937172, best_f1=0.7248677248677249
step: 0, loss: 0.03470715507864952
step: 10, loss: 0.012970889918506145
step: 20, loss: 0.00041928020073100924
step: 30, loss: 0.011553331278264523
step: 40, loss: 0.00751057593151927
step: 50, loss: 0.0294048935174942
step: 60, loss: 0.0014380485517904162
step: 70, loss: 4.247033575666137e-05
step: 80, loss: 0.003008788451552391
step: 90, loss: 0.0038502311799675226
step: 100, loss: 0.008395969867706299
step: 110, loss: 0.0452062264084816
step: 120, loss: 0.025598622858524323
step: 130, loss: 0.020443156361579895
step: 140, loss: 0.0004344874760136008
step: 150, loss: 0.009348435327410698
step: 160, loss: 0.003548922250047326
step: 170, loss: 0.008629434742033482
step: 180, loss: 0.028685158118605614
step: 190, loss: 0.016801128163933754
step: 200, loss: 0.026666535064578056
step: 210, loss: 0.05923795327544212
step: 220, loss: 0.0006282495451159775
step: 230, loss: 0.03382463753223419
step: 240, loss: 0.0006060937885195017
step: 250, loss: 0.013566853478550911
step: 260, loss: 3.123203350696713e-05
step: 270, loss: 0.019214153289794922
step: 280, loss: 0.004560096655040979
step: 290, loss: 0.0005154633545316756
step: 300, loss: 0.05055639147758484
step: 310, loss: 0.030437791720032692
step: 320, loss: 0.025038590654730797
step: 330, loss: 0.0031752882059663534
step: 340, loss: 0.029037250205874443
step: 350, loss: 0.03302699699997902
step: 360, loss: 0.013547064736485481
step: 370, loss: 0.03197973221540451
step: 380, loss: 0.0006662994856014848
epoch 18: dev_f1=0.6969696969696969, f1=0.7286821705426356, best_f1=0.7248677248677249
step: 0, loss: 0.001406665425747633
step: 10, loss: 0.0022082526702433825
step: 20, loss: 0.002389649860560894
step: 30, loss: 0.012705468572676182
step: 40, loss: 0.030033083632588387
step: 50, loss: 0.002092249458655715
step: 60, loss: 0.018237633630633354
step: 70, loss: 0.005939343478530645
step: 80, loss: 0.00020793692965526134
step: 90, loss: 0.008025255985558033
step: 100, loss: 0.019816312938928604
step: 110, loss: 0.003864852013066411
step: 120, loss: 0.0009527750662527978
step: 130, loss: 0.08744382113218307
step: 140, loss: 7.030484994174913e-05
step: 150, loss: 8.501132833771408e-05
step: 160, loss: 0.039988067001104355
step: 170, loss: 0.05798618122935295
step: 180, loss: 0.01593870297074318
step: 190, loss: 0.0016059536719694734
step: 200, loss: 0.0009399092523381114
step: 210, loss: 0.019648300483822823
step: 220, loss: 0.013850899413228035
step: 230, loss: 0.004924796987324953
step: 240, loss: 0.0413663312792778
step: 250, loss: 0.018287038430571556
step: 260, loss: 4.177891241852194e-05
step: 270, loss: 0.009324907325208187
step: 280, loss: 0.032733697444200516
step: 290, loss: 0.001489147893153131
step: 300, loss: 3.992100027971901e-05
step: 310, loss: 0.035056959837675095
step: 320, loss: 0.000141716911457479
step: 330, loss: 0.0004105670377612114
step: 340, loss: 0.0013474352890625596
step: 350, loss: 0.028886722400784492
step: 360, loss: 0.05048142001032829
step: 370, loss: 0.0005760001367889345
step: 380, loss: 0.001465491484850645
epoch 19: dev_f1=0.6997389033942559, f1=0.7329842931937172, best_f1=0.7248677248677249
step: 0, loss: 0.0013141469098627567
step: 10, loss: 0.0004024305089842528
step: 20, loss: 7.99063200247474e-05
step: 30, loss: 0.025166312232613564
step: 40, loss: 0.003933312371373177
step: 50, loss: 0.01024420652538538
step: 60, loss: 0.03400536626577377
step: 70, loss: 0.00044396231533028185
step: 80, loss: 0.00041369214886799455
step: 90, loss: 0.009641287848353386
step: 100, loss: 0.034913644194602966
step: 110, loss: 0.06303700804710388
step: 120, loss: 0.017092125490307808
step: 130, loss: 0.0021505006588995457
step: 140, loss: 0.0002049178146990016
step: 150, loss: 0.0032575814984738827
step: 160, loss: 0.0218821968883276
step: 170, loss: 0.03411565721035004
step: 180, loss: 0.03388446196913719
step: 190, loss: 0.0019712578505277634
step: 200, loss: 6.138138269307092e-05
step: 210, loss: 0.029149536043405533
step: 220, loss: 0.0008044824935495853
step: 230, loss: 0.00019916209566872567
step: 240, loss: 0.0005059177055954933
step: 250, loss: 0.00028159472276456654
step: 260, loss: 0.0004773703694809228
step: 270, loss: 0.007130187936127186
step: 280, loss: 0.0003761517582461238
step: 290, loss: 0.01246980857104063
step: 300, loss: 4.591813558363356e-05
step: 310, loss: 0.00019085299572907388
step: 320, loss: 0.04086964204907417
step: 330, loss: 0.04505983740091324
step: 340, loss: 0.08018263429403305
step: 350, loss: 0.016439473256468773
step: 360, loss: 0.0015808746684342623
step: 370, loss: 0.018309079110622406
step: 380, loss: 0.0001542968675494194
epoch 20: dev_f1=0.6878306878306877, f1=0.7320954907161804, best_f1=0.7248677248677249
