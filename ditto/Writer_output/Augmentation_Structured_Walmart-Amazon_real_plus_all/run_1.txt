cuda
Device: cuda
step: 0, loss: 0.7520924806594849
step: 10, loss: 0.6618520021438599
step: 20, loss: 0.37480974197387695
step: 30, loss: 0.3208000659942627
step: 40, loss: 0.0602903738617897
step: 50, loss: 0.37674134969711304
step: 60, loss: 0.36810535192489624
step: 70, loss: 0.4320386052131653
step: 80, loss: 0.3897281885147095
step: 90, loss: 0.2800499200820923
step: 100, loss: 0.21419662237167358
step: 110, loss: 0.2770478129386902
step: 120, loss: 0.43101218342781067
step: 130, loss: 0.23678605258464813
step: 140, loss: 0.35852858424186707
step: 150, loss: 0.2903531789779663
step: 160, loss: 0.3752519190311432
step: 170, loss: 0.11088387668132782
step: 180, loss: 0.20688271522521973
step: 190, loss: 0.2499251365661621
step: 200, loss: 0.22560317814350128
step: 210, loss: 0.0996759906411171
step: 220, loss: 0.17016440629959106
step: 230, loss: 0.11301173269748688
step: 240, loss: 0.22036883234977722
step: 250, loss: 0.06223941221833229
step: 260, loss: 0.13338392972946167
step: 270, loss: 0.1376803070306778
step: 280, loss: 0.1733216941356659
step: 290, loss: 0.11744694411754608
step: 300, loss: 0.16507470607757568
step: 310, loss: 0.12982666492462158
step: 320, loss: 0.20217585563659668
step: 330, loss: 0.12088274955749512
step: 340, loss: 0.11138468980789185
step: 350, loss: 0.28238674998283386
step: 360, loss: 0.09233755618333817
step: 370, loss: 0.12932388484477997
step: 380, loss: 0.07962241023778915
epoch 1: dev_f1=0.5529953917050692, f1=0.5589519650655023, best_f1=0.5589519650655023
step: 0, loss: 0.12771067023277283
step: 10, loss: 0.23442354798316956
step: 20, loss: 0.145993173122406
step: 30, loss: 0.21243830025196075
step: 40, loss: 0.12276109308004379
step: 50, loss: 0.06693392246961594
step: 60, loss: 0.2929379343986511
step: 70, loss: 0.07625433802604675
step: 80, loss: 0.2940540313720703
step: 90, loss: 0.06121939420700073
step: 100, loss: 0.09684153646230698
step: 110, loss: 0.09580747783184052
step: 120, loss: 0.15814310312271118
step: 130, loss: 0.2168695032596588
step: 140, loss: 0.15726898610591888
step: 150, loss: 0.05632997676730156
step: 160, loss: 0.09078185260295868
step: 170, loss: 0.048040520399808884
step: 180, loss: 0.04421769455075264
step: 190, loss: 0.09343194961547852
step: 200, loss: 0.16534975171089172
step: 210, loss: 0.12641799449920654
step: 220, loss: 0.03885470703244209
step: 230, loss: 0.15392492711544037
step: 240, loss: 0.0661671981215477
step: 250, loss: 0.08580323308706284
step: 260, loss: 0.0938904657959938
step: 270, loss: 0.05704302340745926
step: 280, loss: 0.19594718515872955
step: 290, loss: 0.19734790921211243
step: 300, loss: 0.12120793759822845
step: 310, loss: 0.17674142122268677
step: 320, loss: 0.09297266602516174
step: 330, loss: 0.04011598229408264
step: 340, loss: 0.03320962190628052
step: 350, loss: 0.129332035779953
step: 360, loss: 0.11001166701316833
step: 370, loss: 0.07552220672369003
step: 380, loss: 0.18821009993553162
epoch 2: dev_f1=0.669833729216152, f1=0.6995073891625616, best_f1=0.6995073891625616
step: 0, loss: 0.1582292914390564
step: 10, loss: 0.09915009886026382
step: 20, loss: 0.3484908640384674
step: 30, loss: 0.08415302634239197
step: 40, loss: 0.014955513179302216
step: 50, loss: 0.2004949450492859
step: 60, loss: 0.2324901521205902
step: 70, loss: 0.05422472581267357
step: 80, loss: 0.022129811346530914
step: 90, loss: 0.060346100479364395
step: 100, loss: 0.06123732030391693
step: 110, loss: 0.2589573562145233
step: 120, loss: 0.1115846112370491
step: 130, loss: 0.009481582790613174
step: 140, loss: 0.013430687598884106
step: 150, loss: 0.12043106555938721
step: 160, loss: 0.05042025074362755
step: 170, loss: 0.07584771513938904
step: 180, loss: 0.06327985227108002
step: 190, loss: 0.10684045404195786
step: 200, loss: 0.03687193989753723
step: 210, loss: 0.2318771481513977
step: 220, loss: 0.041092079132795334
step: 230, loss: 0.022372853010892868
step: 240, loss: 0.031245049089193344
step: 250, loss: 0.027266087010502815
step: 260, loss: 0.09312620759010315
step: 270, loss: 0.102114737033844
step: 280, loss: 0.09682463854551315
step: 290, loss: 0.10679822415113449
step: 300, loss: 0.26663461327552795
step: 310, loss: 0.17004479467868805
step: 320, loss: 0.05343130603432655
step: 330, loss: 0.16109751164913177
step: 340, loss: 0.06308816373348236
step: 350, loss: 0.03469700366258621
step: 360, loss: 0.08805804699659348
step: 370, loss: 0.11579877138137817
step: 380, loss: 0.09699515998363495
epoch 3: dev_f1=0.6538461538461539, f1=0.6199095022624433, best_f1=0.6995073891625616
step: 0, loss: 0.09456181526184082
step: 10, loss: 0.16505217552185059
step: 20, loss: 0.0024292811285704374
step: 30, loss: 0.18951983749866486
step: 40, loss: 0.05528762564063072
step: 50, loss: 0.12062320858240128
step: 60, loss: 0.1599208265542984
step: 70, loss: 0.003947564400732517
step: 80, loss: 0.022787315770983696
step: 90, loss: 0.008252509869635105
step: 100, loss: 0.10590574890375137
step: 110, loss: 0.09565404802560806
step: 120, loss: 0.0533314049243927
step: 130, loss: 0.08498271554708481
step: 140, loss: 0.21583546698093414
step: 150, loss: 0.03454577550292015
step: 160, loss: 0.11865807324647903
step: 170, loss: 0.0904446691274643
step: 180, loss: 0.027545157819986343
step: 190, loss: 0.046339504420757294
step: 200, loss: 0.05668213590979576
step: 210, loss: 0.042369287461042404
step: 220, loss: 0.012745168060064316
step: 230, loss: 0.04693804308772087
step: 240, loss: 0.0381096675992012
step: 250, loss: 0.08962849527597427
step: 260, loss: 0.03902918100357056
step: 270, loss: 0.0353870652616024
step: 280, loss: 0.09182990342378616
step: 290, loss: 0.06507623195648193
step: 300, loss: 0.1778106838464737
step: 310, loss: 0.050939254462718964
step: 320, loss: 0.14634285867214203
step: 330, loss: 0.08281899243593216
step: 340, loss: 0.09419332444667816
step: 350, loss: 0.13024325668811798
step: 360, loss: 0.0669264942407608
step: 370, loss: 0.20196551084518433
step: 380, loss: 0.03501670062541962
epoch 4: dev_f1=0.6774193548387096, f1=0.6647887323943661, best_f1=0.6647887323943661
step: 0, loss: 0.04235094040632248
step: 10, loss: 0.029485251754522324
step: 20, loss: 0.03707798197865486
step: 30, loss: 0.03299621120095253
step: 40, loss: 0.01850869692862034
step: 50, loss: 0.10939202457666397
step: 60, loss: 0.1734159141778946
step: 70, loss: 0.10601171106100082
step: 80, loss: 0.07694536447525024
step: 90, loss: 0.06797739118337631
step: 100, loss: 0.02526671811938286
step: 110, loss: 0.059671882539987564
step: 120, loss: 0.015204188413918018
step: 130, loss: 0.03766355663537979
step: 140, loss: 0.03351510316133499
step: 150, loss: 0.05353895202279091
step: 160, loss: 0.024299995973706245
step: 170, loss: 0.2419033944606781
step: 180, loss: 0.07865201681852341
step: 190, loss: 0.040615182369947433
step: 200, loss: 0.0420658253133297
step: 210, loss: 0.054612867534160614
step: 220, loss: 0.08233603090047836
step: 230, loss: 0.06283456087112427
step: 240, loss: 0.124933622777462
step: 250, loss: 0.0874839574098587
step: 260, loss: 0.2334386706352234
step: 270, loss: 0.04750324785709381
step: 280, loss: 0.19622451066970825
step: 290, loss: 0.025789136067032814
step: 300, loss: 0.053468409925699234
step: 310, loss: 0.10897495597600937
step: 320, loss: 0.04089006781578064
step: 330, loss: 0.05771317332983017
step: 340, loss: 0.07704249024391174
step: 350, loss: 0.05200277268886566
step: 360, loss: 0.08847951143980026
step: 370, loss: 0.0805753841996193
step: 380, loss: 0.04864517226815224
epoch 5: dev_f1=0.6813725490196078, f1=0.7282051282051282, best_f1=0.7282051282051282
step: 0, loss: 0.07102598249912262
step: 10, loss: 0.04709045961499214
step: 20, loss: 0.013290381990373135
step: 30, loss: 0.10683842748403549
step: 40, loss: 0.09723549336194992
step: 50, loss: 0.06024205684661865
step: 60, loss: 0.06179419159889221
step: 70, loss: 0.023509472608566284
step: 80, loss: 0.05408662185072899
step: 90, loss: 0.04566521570086479
step: 100, loss: 0.025582080706954002
step: 110, loss: 0.1302415281534195
step: 120, loss: 0.07491764426231384
step: 130, loss: 0.03636529669165611
step: 140, loss: 0.0046804179437458515
step: 150, loss: 0.03669605776667595
step: 160, loss: 0.029398374259471893
step: 170, loss: 0.08534138649702072
step: 180, loss: 0.06936246901750565
step: 190, loss: 0.030218955129384995
step: 200, loss: 0.1155724748969078
step: 210, loss: 0.0021848436444997787
step: 220, loss: 0.09087170660495758
step: 230, loss: 0.013959143310785294
step: 240, loss: 0.12031625211238861
step: 250, loss: 0.021757986396551132
step: 260, loss: 0.05729611590504646
step: 270, loss: 0.02568427473306656
step: 280, loss: 0.00782093033194542
step: 290, loss: 0.04401712864637375
step: 300, loss: 0.06914740800857544
step: 310, loss: 0.046754155308008194
step: 320, loss: 0.06231733039021492
step: 330, loss: 0.016577545553445816
step: 340, loss: 0.002790022874251008
step: 350, loss: 0.0439394973218441
step: 360, loss: 0.027950655668973923
step: 370, loss: 0.0936490148305893
step: 380, loss: 0.0005505646113306284
epoch 6: dev_f1=0.6923076923076923, f1=0.7146666666666668, best_f1=0.7146666666666668
step: 0, loss: 0.03323419392108917
step: 10, loss: 0.02021893858909607
step: 20, loss: 0.0637350082397461
step: 30, loss: 0.058967363089323044
step: 40, loss: 0.0004125634441152215
step: 50, loss: 0.04615482687950134
step: 60, loss: 0.07933031022548676
step: 70, loss: 0.06490800529718399
step: 80, loss: 0.1425548642873764
step: 90, loss: 0.06574324518442154
step: 100, loss: 0.16704006493091583
step: 110, loss: 0.15307925641536713
step: 120, loss: 0.09931661188602448
step: 130, loss: 0.010957800783216953
step: 140, loss: 0.08341801166534424
step: 150, loss: 0.018917541950941086
step: 160, loss: 0.0019932687282562256
step: 170, loss: 0.03000253438949585
step: 180, loss: 0.033695414662361145
step: 190, loss: 0.026931002736091614
step: 200, loss: 0.14703673124313354
step: 210, loss: 0.0002420363889541477
step: 220, loss: 0.0816773846745491
step: 230, loss: 0.03734826296567917
step: 240, loss: 0.08753141015768051
step: 250, loss: 0.1704348623752594
step: 260, loss: 0.010995705612003803
step: 270, loss: 0.21680137515068054
step: 280, loss: 0.1242467537522316
step: 290, loss: 0.04019465669989586
step: 300, loss: 0.07410084456205368
step: 310, loss: 0.05525177717208862
step: 320, loss: 0.044396404176950455
step: 330, loss: 0.05463963374495506
step: 340, loss: 0.0463070347905159
step: 350, loss: 0.009977268986403942
step: 360, loss: 0.1077842116355896
step: 370, loss: 0.18708130717277527
step: 380, loss: 0.07953223586082458
epoch 7: dev_f1=0.6791443850267379, f1=0.7134831460674158, best_f1=0.7146666666666668
step: 0, loss: 0.05002825707197189
step: 10, loss: 0.12204498052597046
step: 20, loss: 0.05043860152363777
step: 30, loss: 0.04244859144091606
step: 40, loss: 0.0983361303806305
step: 50, loss: 0.019592346623539925
step: 60, loss: 0.044412847608327866
step: 70, loss: 0.01339686568826437
step: 80, loss: 0.01170559786260128
step: 90, loss: 0.23178508877754211
step: 100, loss: 0.05822436138987541
step: 110, loss: 0.06435173004865646
step: 120, loss: 0.03207607567310333
step: 130, loss: 0.020425206050276756
step: 140, loss: 0.04477594792842865
step: 150, loss: 0.004656687378883362
step: 160, loss: 0.11143981665372849
step: 170, loss: 0.06072439253330231
step: 180, loss: 0.08224441856145859
step: 190, loss: 0.04094969108700752
step: 200, loss: 0.04792473465204239
step: 210, loss: 0.005712921731173992
step: 220, loss: 0.05542704463005066
step: 230, loss: 0.08843038976192474
step: 240, loss: 0.08608237653970718
step: 250, loss: 0.0021086272317916155
step: 260, loss: 0.018205367028713226
step: 270, loss: 0.01956890895962715
step: 280, loss: 0.03171619400382042
step: 290, loss: 0.07427400350570679
step: 300, loss: 0.20078326761722565
step: 310, loss: 0.045582786202430725
step: 320, loss: 0.021132906898856163
step: 330, loss: 0.033643607050180435
step: 340, loss: 0.01892622746527195
step: 350, loss: 0.02028193511068821
step: 360, loss: 0.03693137317895889
step: 370, loss: 0.003155142767354846
step: 380, loss: 0.05340416729450226
epoch 8: dev_f1=0.673469387755102, f1=0.7182320441988949, best_f1=0.7146666666666668
step: 0, loss: 0.0501662939786911
step: 10, loss: 0.03164612129330635
step: 20, loss: 0.0843430906534195
step: 30, loss: 0.03304193168878555
step: 40, loss: 0.024942487478256226
step: 50, loss: 9.04084590729326e-05
step: 60, loss: 0.05231396481394768
step: 70, loss: 0.02116760052740574
step: 80, loss: 0.010345106944441795
step: 90, loss: 0.0006146876257844269
step: 100, loss: 0.011577090248465538
step: 110, loss: 0.02461717650294304
step: 120, loss: 0.005459637381136417
step: 130, loss: 0.015000119805335999
step: 140, loss: 0.020652353763580322
step: 150, loss: 0.05129439756274223
step: 160, loss: 0.00023572033387608826
step: 170, loss: 0.008438102900981903
step: 180, loss: 0.06460106372833252
step: 190, loss: 0.057393115013837814
step: 200, loss: 0.05577271059155464
step: 210, loss: 0.16596131026744843
step: 220, loss: 0.034782636910676956
step: 230, loss: 0.012891019694507122
step: 240, loss: 0.044132299721241
step: 250, loss: 0.03106996789574623
step: 260, loss: 0.0032713357359170914
step: 270, loss: 0.008808497339487076
step: 280, loss: 0.005468935240060091
step: 290, loss: 0.01681886427104473
step: 300, loss: 0.011830069124698639
step: 310, loss: 0.05579620227217674
step: 320, loss: 0.02245030365884304
step: 330, loss: 0.01688983477652073
step: 340, loss: 0.025729281827807426
step: 350, loss: 0.0020639754366129637
step: 360, loss: 0.06794798374176025
step: 370, loss: 0.008628280833363533
step: 380, loss: 0.006046250928193331
epoch 9: dev_f1=0.6580976863753214, f1=0.6809651474530832, best_f1=0.7146666666666668
step: 0, loss: 0.01104092225432396
step: 10, loss: 0.08923212438821793
step: 20, loss: 0.06485097855329514
step: 30, loss: 0.017977701500058174
step: 40, loss: 0.06848081201314926
step: 50, loss: 0.13333657383918762
step: 60, loss: 0.05448523908853531
step: 70, loss: 0.020202280953526497
step: 80, loss: 0.007679216098040342
step: 90, loss: 0.020430708304047585
step: 100, loss: 0.08275424689054489
step: 110, loss: 0.06803165376186371
step: 120, loss: 0.00176651228684932
step: 130, loss: 0.008763897232711315
step: 140, loss: 0.045707475394010544
step: 150, loss: 0.00917783658951521
step: 160, loss: 0.06707002967596054
step: 170, loss: 0.08386628329753876
step: 180, loss: 0.0004550933663267642
step: 190, loss: 0.019254431128501892
step: 200, loss: 0.0002611960517242551
step: 210, loss: 0.0002531508798711002
step: 220, loss: 0.012075211852788925
step: 230, loss: 0.1781274825334549
step: 240, loss: 0.06126577779650688
step: 250, loss: 0.04172937199473381
step: 260, loss: 0.0028588115237653255
step: 270, loss: 0.023412911221385002
step: 280, loss: 0.05867607891559601
step: 290, loss: 0.011769972741603851
step: 300, loss: 0.1889990270137787
step: 310, loss: 0.05930525064468384
step: 320, loss: 0.06491435319185257
step: 330, loss: 0.05243409425020218
step: 340, loss: 0.13510429859161377
step: 350, loss: 0.054739296436309814
step: 360, loss: 0.050064992159605026
step: 370, loss: 0.036333825439214706
step: 380, loss: 0.04972733557224274
epoch 10: dev_f1=0.6731234866828089, f1=0.7073791348600508, best_f1=0.7146666666666668
step: 0, loss: 0.10001765936613083
step: 10, loss: 0.06603090465068817
step: 20, loss: 0.0180360060185194
step: 30, loss: 0.04670329391956329
step: 40, loss: 0.004853358492255211
step: 50, loss: 0.06087088957428932
step: 60, loss: 0.0018443261506035924
step: 70, loss: 0.06625178456306458
step: 80, loss: 0.02927990071475506
step: 90, loss: 0.006335956044495106
step: 100, loss: 0.01944800466299057
step: 110, loss: 0.11651019752025604
step: 120, loss: 0.07615398615598679
step: 130, loss: 0.11619370430707932
step: 140, loss: 0.049031827598810196
step: 150, loss: 0.08803502470254898
step: 160, loss: 0.0700361356139183
step: 170, loss: 0.03462645411491394
step: 180, loss: 0.04463977366685867
step: 190, loss: 0.04223870113492012
step: 200, loss: 0.027094736695289612
step: 210, loss: 0.10109124332666397
step: 220, loss: 0.01794760301709175
step: 230, loss: 0.0948089063167572
step: 240, loss: 0.00022429453383665532
step: 250, loss: 0.06504137068986893
step: 260, loss: 0.02366151660680771
step: 270, loss: 0.02678459696471691
step: 280, loss: 0.15213730931282043
step: 290, loss: 0.10891856998205185
step: 300, loss: 0.02723972126841545
step: 310, loss: 0.06356063485145569
step: 320, loss: 0.02502191998064518
step: 330, loss: 0.00011049904423998669
step: 340, loss: 0.01313219964504242
step: 350, loss: 0.0011261216131970286
step: 360, loss: 0.0520540289580822
step: 370, loss: 0.25392967462539673
step: 380, loss: 0.14103759825229645
epoch 11: dev_f1=0.6804597701149425, f1=0.6861313868613139, best_f1=0.7146666666666668
step: 0, loss: 0.0017483211122453213
step: 10, loss: 0.10839840024709702
step: 20, loss: 0.048670198768377304
step: 30, loss: 0.0029008775018155575
step: 40, loss: 0.0003335355140734464
step: 50, loss: 0.010388998314738274
step: 60, loss: 0.054503798484802246
step: 70, loss: 0.05367554724216461
step: 80, loss: 0.08423099666833878
step: 90, loss: 0.020058082416653633
step: 100, loss: 0.02127346210181713
step: 110, loss: 0.00011549476766958833
step: 120, loss: 0.059854235500097275
step: 130, loss: 0.004668832756578922
step: 140, loss: 0.07684165239334106
step: 150, loss: 0.020305313169956207
step: 160, loss: 0.00775440176948905
step: 170, loss: 0.021032234653830528
step: 180, loss: 0.008146323263645172
step: 190, loss: 0.01754649169743061
step: 200, loss: 0.005493097007274628
step: 210, loss: 0.20735947787761688
step: 220, loss: 0.06549063324928284
step: 230, loss: 0.03982982784509659
step: 240, loss: 0.03910483792424202
step: 250, loss: 0.028691422194242477
step: 260, loss: 0.012619192712008953
step: 270, loss: 0.08853134512901306
step: 280, loss: 0.028700174763798714
step: 290, loss: 0.14224810898303986
step: 300, loss: 0.03422072157263756
step: 310, loss: 0.044090501964092255
step: 320, loss: 0.0013476454187184572
step: 330, loss: 0.04029105231165886
step: 340, loss: 0.00039836348150856793
step: 350, loss: 0.12374763935804367
step: 360, loss: 0.09429897367954254
step: 370, loss: 0.001533545320853591
step: 380, loss: 0.028167717158794403
epoch 12: dev_f1=0.6682926829268292, f1=0.6875000000000001, best_f1=0.7146666666666668
step: 0, loss: 0.034144509583711624
step: 10, loss: 0.047711487859487534
step: 20, loss: 0.026441387832164764
step: 30, loss: 0.004844416864216328
step: 40, loss: 0.0005645144847221673
step: 50, loss: 0.04323175549507141
step: 60, loss: 0.000303423817967996
step: 70, loss: 0.003811163129284978
step: 80, loss: 0.018608788028359413
step: 90, loss: 0.15633989870548248
step: 100, loss: 0.032093316316604614
step: 110, loss: 0.021487461403012276
step: 120, loss: 0.019912684336304665
step: 130, loss: 0.04262340068817139
step: 140, loss: 0.01435775589197874
step: 150, loss: 0.013705589808523655
step: 160, loss: 0.06847523897886276
step: 170, loss: 0.016073359176516533
step: 180, loss: 0.005243153311312199
step: 190, loss: 0.03780156373977661
step: 200, loss: 0.0035404169466346502
step: 210, loss: 0.025095883756875992
step: 220, loss: 0.010057826526463032
step: 230, loss: 0.03729249909520149
step: 240, loss: 0.08256220072507858
step: 250, loss: 0.044622957706451416
step: 260, loss: 0.051150817424058914
step: 270, loss: 0.016173752024769783
step: 280, loss: 0.018744047731161118
step: 290, loss: 0.04045584425330162
step: 300, loss: 0.0250799972563982
step: 310, loss: 0.07651187479496002
step: 320, loss: 0.04585406556725502
step: 330, loss: 6.752552144462243e-05
step: 340, loss: 0.02267340198159218
step: 350, loss: 0.0699758380651474
step: 360, loss: 0.00024479377316311
step: 370, loss: 0.07816646993160248
step: 380, loss: 0.00020996923558413982
epoch 13: dev_f1=0.6563876651982379, f1=0.6872037914691943, best_f1=0.7146666666666668
step: 0, loss: 0.1564856320619583
step: 10, loss: 0.030781926587224007
step: 20, loss: 0.006735010538250208
step: 30, loss: 0.052239369601011276
step: 40, loss: 0.05651312693953514
step: 50, loss: 0.08266439288854599
step: 60, loss: 0.011109686456620693
step: 70, loss: 0.05931273475289345
step: 80, loss: 0.04433212801814079
step: 90, loss: 0.016729434952139854
step: 100, loss: 0.02340579405426979
step: 110, loss: 0.0935758724808693
step: 120, loss: 0.039203476160764694
step: 130, loss: 0.003930859267711639
step: 140, loss: 0.09605339914560318
step: 150, loss: 0.026524251326918602
step: 160, loss: 0.0030621951445937157
step: 170, loss: 0.0005169237265363336
step: 180, loss: 0.0036402621772140265
step: 190, loss: 0.0421057753264904
step: 200, loss: 0.005041199270635843
step: 210, loss: 0.010923332534730434
step: 220, loss: 0.007114690728485584
step: 230, loss: 0.0019548023119568825
step: 240, loss: 9.152338316198438e-05
step: 250, loss: 0.06752055883407593
step: 260, loss: 0.1017414852976799
step: 270, loss: 0.07064882665872574
step: 280, loss: 0.02159775048494339
step: 290, loss: 0.0003272673347964883
step: 300, loss: 0.00011414729669922963
step: 310, loss: 0.015932200476527214
step: 320, loss: 0.00888439267873764
step: 330, loss: 0.004917465150356293
step: 340, loss: 0.05923726409673691
step: 350, loss: 0.014263606630265713
step: 360, loss: 0.0015368105378001928
step: 370, loss: 0.0015817537205293775
step: 380, loss: 0.026507483795285225
epoch 14: dev_f1=0.6682808716707022, f1=0.6889460154241646, best_f1=0.7146666666666668
step: 0, loss: 0.00923073012381792
step: 10, loss: 0.0323127880692482
step: 20, loss: 0.025810955092310905
step: 30, loss: 0.06401238590478897
step: 40, loss: 0.000556647137273103
step: 50, loss: 0.023912936449050903
step: 60, loss: 0.01637795753777027
step: 70, loss: 0.07747393101453781
step: 80, loss: 0.06977944076061249
step: 90, loss: 0.0065419115126132965
step: 100, loss: 4.4783118937630206e-05
step: 110, loss: 0.0018530088709667325
step: 120, loss: 0.0011215746635571122
step: 130, loss: 0.04491390660405159
step: 140, loss: 8.481657278025523e-05
step: 150, loss: 0.0004816410655621439
step: 160, loss: 0.00039961535367183387
step: 170, loss: 0.01795991137623787
step: 180, loss: 0.004058872815221548
step: 190, loss: 0.006700853351503611
step: 200, loss: 0.002668962115421891
step: 210, loss: 0.12479729950428009
step: 220, loss: 0.02361089549958706
step: 230, loss: 0.01873890310525894
step: 240, loss: 0.015601268038153648
step: 250, loss: 0.12299265712499619
step: 260, loss: 0.04243706911802292
step: 270, loss: 0.013791874051094055
step: 280, loss: 0.13917291164398193
step: 290, loss: 0.011603018268942833
step: 300, loss: 0.02004283294081688
step: 310, loss: 0.009148063138127327
step: 320, loss: 0.004632263444364071
step: 330, loss: 0.021739289164543152
step: 340, loss: 0.030244510620832443
step: 350, loss: 0.0035989913158118725
step: 360, loss: 0.026510268449783325
step: 370, loss: 0.04989231377840042
step: 380, loss: 0.011848965659737587
epoch 15: dev_f1=0.659846547314578, f1=0.6972972972972973, best_f1=0.7146666666666668
step: 0, loss: 0.002580878557637334
step: 10, loss: 0.0045941295102238655
step: 20, loss: 0.02273952029645443
step: 30, loss: 0.06623911112546921
step: 40, loss: 0.022696221247315407
step: 50, loss: 0.008848294615745544
step: 60, loss: 0.0005765318055637181
step: 70, loss: 0.0191545058041811
step: 80, loss: 0.006265971343964338
step: 90, loss: 0.025509333238005638
step: 100, loss: 0.0114067904651165
step: 110, loss: 0.0011403870303183794
step: 120, loss: 0.010375836864113808
step: 130, loss: 3.474110781098716e-05
step: 140, loss: 0.0683998316526413
step: 150, loss: 0.036538273096084595
step: 160, loss: 0.10197553038597107
step: 170, loss: 0.02998616360127926
step: 180, loss: 0.0019804639741778374
step: 190, loss: 7.890768756624311e-05
step: 200, loss: 0.0009712428436614573
step: 210, loss: 0.06625515222549438
step: 220, loss: 0.03019673004746437
step: 230, loss: 0.05487659573554993
step: 240, loss: 0.046385057270526886
step: 250, loss: 0.01958429254591465
step: 260, loss: 0.03108082339167595
step: 270, loss: 0.02504008635878563
step: 280, loss: 0.003070702077820897
step: 290, loss: 0.0002249764947919175
step: 300, loss: 0.05446949228644371
step: 310, loss: 0.011541847139596939
step: 320, loss: 0.01625736430287361
step: 330, loss: 0.02192729152739048
step: 340, loss: 0.08349388092756271
step: 350, loss: 0.015716347843408585
step: 360, loss: 0.004444862250238657
step: 370, loss: 0.002736164489760995
step: 380, loss: 0.0070495931431651115
epoch 16: dev_f1=0.6964705882352942, f1=0.689119170984456, best_f1=0.689119170984456
step: 0, loss: 0.011842076666653156
step: 10, loss: 0.026478774845600128
step: 20, loss: 0.0445689857006073
step: 30, loss: 0.0004356572462711483
step: 40, loss: 4.515855107456446e-05
step: 50, loss: 0.0077141160145401955
step: 60, loss: 0.02191564068198204
step: 70, loss: 0.04133061692118645
step: 80, loss: 0.0007617584778927267
step: 90, loss: 0.051976706832647324
step: 100, loss: 4.177376831648871e-05
step: 110, loss: 0.0261959470808506
step: 120, loss: 0.05554640293121338
step: 130, loss: 0.0548914298415184
step: 140, loss: 0.013630104251205921
step: 150, loss: 0.0007917568436823785
step: 160, loss: 3.962777554988861e-05
step: 170, loss: 0.10724984109401703
step: 180, loss: 0.010660210624337196
step: 190, loss: 0.0017002893146127462
step: 200, loss: 0.0710296630859375
step: 210, loss: 0.003672229591757059
step: 220, loss: 0.0002675079449545592
step: 230, loss: 0.03761925920844078
step: 240, loss: 0.004045264795422554
step: 250, loss: 0.06920911371707916
step: 260, loss: 0.04704924300312996
step: 270, loss: 0.015280699357390404
step: 280, loss: 0.005729256197810173
step: 290, loss: 0.05680645629763603
step: 300, loss: 0.044801611453294754
step: 310, loss: 0.004048431292176247
step: 320, loss: 0.0003276295028626919
step: 330, loss: 0.11297643929719925
step: 340, loss: 0.001534661860205233
step: 350, loss: 0.03924001008272171
step: 360, loss: 0.0008407738641835749
step: 370, loss: 0.011131503619253635
step: 380, loss: 0.00048350851284340024
epoch 17: dev_f1=0.679334916864608, f1=0.689119170984456, best_f1=0.689119170984456
step: 0, loss: 0.10317976772785187
step: 10, loss: 0.0008752127178013325
step: 20, loss: 0.030067171901464462
step: 30, loss: 0.014134660363197327
step: 40, loss: 0.00940413773059845
step: 50, loss: 0.05724139139056206
step: 60, loss: 0.004268481861799955
step: 70, loss: 5.01544309372548e-05
step: 80, loss: 0.00012731421156786382
step: 90, loss: 0.0010981436353176832
step: 100, loss: 0.025458350777626038
step: 110, loss: 3.857318370137364e-05
step: 120, loss: 0.0070608737878501415
step: 130, loss: 0.05539337918162346
step: 140, loss: 0.04677813500165939
step: 150, loss: 0.040983445942401886
step: 160, loss: 0.0017124194419011474
step: 170, loss: 0.013753066770732403
step: 180, loss: 0.024645548313856125
step: 190, loss: 0.0013319082790985703
step: 200, loss: 0.00024651866988278925
step: 210, loss: 0.008983490988612175
step: 220, loss: 0.018877224996685982
step: 230, loss: 0.02333616465330124
step: 240, loss: 0.04041359946131706
step: 250, loss: 0.0003244777617510408
step: 260, loss: 0.035108596086502075
step: 270, loss: 0.005418627057224512
step: 280, loss: 0.01658507063984871
step: 290, loss: 0.008025319315493107
step: 300, loss: 6.804006261518225e-05
step: 310, loss: 0.00034355948446318507
step: 320, loss: 0.00029114086646586657
step: 330, loss: 0.0034583203960210085
step: 340, loss: 0.023356977850198746
step: 350, loss: 0.0022722012363374233
step: 360, loss: 0.000158499286044389
step: 370, loss: 0.020138001069426537
step: 380, loss: 0.0011309529654681683
epoch 18: dev_f1=0.6683046683046683, f1=0.6898395721925134, best_f1=0.689119170984456
step: 0, loss: 0.002954798750579357
step: 10, loss: 0.0239963848143816
step: 20, loss: 0.0001331696257693693
step: 30, loss: 0.03401988372206688
step: 40, loss: 0.05347998067736626
step: 50, loss: 0.04734959825873375
step: 60, loss: 0.0018481130246073008
step: 70, loss: 0.055396873503923416
step: 80, loss: 0.0006195358582772315
step: 90, loss: 0.0849565640091896
step: 100, loss: 0.018404293805360794
step: 110, loss: 0.005885052960366011
step: 120, loss: 3.515065327519551e-05
step: 130, loss: 0.04409653693437576
step: 140, loss: 0.05791661515831947
step: 150, loss: 0.023240135982632637
step: 160, loss: 0.049256160855293274
step: 170, loss: 0.003838416188955307
step: 180, loss: 0.00021512756939046085
step: 190, loss: 0.0017411899752914906
step: 200, loss: 0.013119573704898357
step: 210, loss: 0.0500008650124073
step: 220, loss: 0.011628099717199802
step: 230, loss: 0.0008915068465285003
step: 240, loss: 0.0004649803158827126
step: 250, loss: 0.017900239676237106
step: 260, loss: 0.0001902405492728576
step: 270, loss: 0.0003623137890826911
step: 280, loss: 0.00213474384509027
step: 290, loss: 0.029218921437859535
step: 300, loss: 0.0002351921721128747
step: 310, loss: 0.04920075833797455
step: 320, loss: 0.004721092525869608
step: 330, loss: 0.040990058332681656
step: 340, loss: 0.08267134428024292
step: 350, loss: 0.008045744150876999
step: 360, loss: 0.1158650666475296
step: 370, loss: 0.003510351525619626
step: 380, loss: 0.011504530906677246
epoch 19: dev_f1=0.675, f1=0.6864864864864865, best_f1=0.689119170984456
step: 0, loss: 0.019068492576479912
step: 10, loss: 0.0006693211616948247
step: 20, loss: 0.032029446214437485
step: 30, loss: 0.019796257838606834
step: 40, loss: 0.03162536397576332
step: 50, loss: 0.005174304824322462
step: 60, loss: 0.027261942625045776
step: 70, loss: 0.04323853179812431
step: 80, loss: 0.02320779860019684
step: 90, loss: 0.005702910479158163
step: 100, loss: 0.004658270627260208
step: 110, loss: 0.018928326666355133
step: 120, loss: 0.011408036574721336
step: 130, loss: 0.04466409236192703
step: 140, loss: 0.005367770325392485
step: 150, loss: 6.175193993840367e-05
step: 160, loss: 0.0004911556025035679
step: 170, loss: 0.006116327363997698
step: 180, loss: 0.00046870613005012274
step: 190, loss: 0.0160316601395607
step: 200, loss: 0.0005960265989415348
step: 210, loss: 0.00048347588744945824
step: 220, loss: 0.00010564630792941898
step: 230, loss: 0.016689062118530273
step: 240, loss: 0.003494385164231062
step: 250, loss: 0.026284916326403618
step: 260, loss: 0.00018979926244355738
step: 270, loss: 3.868557178066112e-05
step: 280, loss: 0.04103019833564758
step: 290, loss: 0.00577840069308877
step: 300, loss: 0.01887083612382412
step: 310, loss: 0.00015680496289860457
step: 320, loss: 0.009487377479672432
step: 330, loss: 9.850528294919059e-05
step: 340, loss: 0.004475616849958897
step: 350, loss: 0.00816392246633768
step: 360, loss: 0.04721275344491005
step: 370, loss: 0.03285256400704384
step: 380, loss: 0.000751002982724458
epoch 20: dev_f1=0.6698795180722893, f1=0.6910994764397905, best_f1=0.689119170984456
