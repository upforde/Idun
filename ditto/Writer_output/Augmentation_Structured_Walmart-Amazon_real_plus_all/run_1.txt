cuda
Device: cuda
step: 0, loss: 0.7566881775856018
step: 10, loss: 0.40547728538513184
step: 20, loss: 0.29370641708374023
step: 30, loss: 0.29258543252944946
step: 40, loss: 0.3461933434009552
step: 50, loss: 0.4248999357223511
step: 60, loss: 0.482873797416687
step: 70, loss: 0.056540705263614655
step: 80, loss: 0.36734914779663086
step: 90, loss: 0.36347463726997375
step: 100, loss: 0.3587805926799774
step: 110, loss: 0.2005271315574646
step: 120, loss: 0.27911823987960815
step: 130, loss: 0.28286173939704895
step: 140, loss: 0.1017259806394577
step: 150, loss: 0.15205632150173187
step: 160, loss: 0.32851049304008484
step: 170, loss: 0.3034328520298004
step: 180, loss: 0.3019452393054962
step: 190, loss: 0.3362729847431183
step: 200, loss: 0.3341042995452881
step: 210, loss: 0.09862222522497177
step: 220, loss: 0.25027117133140564
step: 230, loss: 0.5268425345420837
step: 240, loss: 0.1044255867600441
step: 250, loss: 0.21678663790225983
step: 260, loss: 0.22945274412631989
step: 270, loss: 0.19539307057857513
step: 280, loss: 0.08032286912202835
step: 290, loss: 0.1929749995470047
step: 300, loss: 0.25294631719589233
step: 310, loss: 0.16348731517791748
step: 320, loss: 0.44088831543922424
step: 330, loss: 0.22471992671489716
step: 340, loss: 0.24023810029029846
step: 350, loss: 0.3648748993873596
step: 360, loss: 0.23077337443828583
step: 370, loss: 0.10845106095075607
step: 380, loss: 0.11141728609800339
epoch 1: dev_f1=0.6048780487804878, f1=0.6347607052896725, best_f1=0.6347607052896725
step: 0, loss: 0.39288780093193054
step: 10, loss: 0.27634814381599426
step: 20, loss: 0.12898503243923187
step: 30, loss: 0.06607957929372787
step: 40, loss: 0.11526142060756683
step: 50, loss: 0.1390848457813263
step: 60, loss: 0.05459767207503319
step: 70, loss: 0.15229026973247528
step: 80, loss: 0.15974289178848267
step: 90, loss: 0.34510838985443115
step: 100, loss: 0.22951564192771912
step: 110, loss: 0.1714220643043518
step: 120, loss: 0.2013312429189682
step: 130, loss: 0.19792486727237701
step: 140, loss: 0.22606366872787476
step: 150, loss: 0.10667978227138519
step: 160, loss: 0.29710137844085693
step: 170, loss: 0.10975541919469833
step: 180, loss: 0.19971095025539398
step: 190, loss: 0.17586585879325867
step: 200, loss: 0.15131138265132904
step: 210, loss: 0.22794118523597717
step: 220, loss: 0.09629032760858536
step: 230, loss: 0.24885614216327667
step: 240, loss: 0.12754034996032715
step: 250, loss: 0.021723326295614243
step: 260, loss: 0.12391741573810577
step: 270, loss: 0.008019695058465004
step: 280, loss: 0.19680346548557281
step: 290, loss: 0.32576265931129456
step: 300, loss: 0.08678162842988968
step: 310, loss: 0.0835464745759964
step: 320, loss: 0.08041848987340927
step: 330, loss: 0.0860084667801857
step: 340, loss: 0.2201440930366516
step: 350, loss: 0.1578899770975113
step: 360, loss: 0.02342897281050682
step: 370, loss: 0.02938557043671608
step: 380, loss: 0.030578404664993286
epoch 2: dev_f1=0.5823389021479713, f1=0.639618138424821, best_f1=0.6347607052896725
step: 0, loss: 0.05597202852368355
step: 10, loss: 0.023596106097102165
step: 20, loss: 0.10355453193187714
step: 30, loss: 0.1349858194589615
step: 40, loss: 0.04190049320459366
step: 50, loss: 0.18664111196994781
step: 60, loss: 0.0742165744304657
step: 70, loss: 0.03706551715731621
step: 80, loss: 0.29943743348121643
step: 90, loss: 0.04966964200139046
step: 100, loss: 0.14106962084770203
step: 110, loss: 0.021345563232898712
step: 120, loss: 0.06276507675647736
step: 130, loss: 0.052206046879291534
step: 140, loss: 0.07056855410337448
step: 150, loss: 0.054090410470962524
step: 160, loss: 0.06990346312522888
step: 170, loss: 0.17090383172035217
step: 180, loss: 0.06753485649824142
step: 190, loss: 0.17272303998470306
step: 200, loss: 0.020826268941164017
step: 210, loss: 0.03325493633747101
step: 220, loss: 0.06781063973903656
step: 230, loss: 0.09797892719507217
step: 240, loss: 0.02373804710805416
step: 250, loss: 0.06259246170520782
step: 260, loss: 0.13789165019989014
step: 270, loss: 0.15617676079273224
step: 280, loss: 0.39893579483032227
step: 290, loss: 0.1429412066936493
step: 300, loss: 0.09765022993087769
step: 310, loss: 0.053135234862565994
step: 320, loss: 0.0712079256772995
step: 330, loss: 0.09162671864032745
step: 340, loss: 0.1703178584575653
step: 350, loss: 0.05041830241680145
step: 360, loss: 0.06567331403493881
step: 370, loss: 0.06297007203102112
step: 380, loss: 0.09802036732435226
epoch 3: dev_f1=0.6767676767676767, f1=0.6886075949367089, best_f1=0.6886075949367089
step: 0, loss: 0.09072329103946686
step: 10, loss: 0.04370405152440071
step: 20, loss: 0.03621140867471695
step: 30, loss: 0.0803523138165474
step: 40, loss: 0.01039646565914154
step: 50, loss: 0.0942053273320198
step: 60, loss: 0.0893019586801529
step: 70, loss: 0.035685498267412186
step: 80, loss: 0.08346718549728394
step: 90, loss: 0.07464300096035004
step: 100, loss: 0.06542495638132095
step: 110, loss: 0.19548292458057404
step: 120, loss: 0.07942208647727966
step: 130, loss: 0.07132615894079208
step: 140, loss: 0.10297389328479767
step: 150, loss: 0.0529300719499588
step: 160, loss: 0.10577418655157089
step: 170, loss: 0.04945032671093941
step: 180, loss: 0.023240678012371063
step: 190, loss: 0.0413401834666729
step: 200, loss: 0.04378960654139519
step: 210, loss: 0.05033610388636589
step: 220, loss: 0.13611994683742523
step: 230, loss: 0.06118948012590408
step: 240, loss: 0.1442575305700302
step: 250, loss: 0.04811698570847511
step: 260, loss: 0.14263950288295746
step: 270, loss: 0.09028796851634979
step: 280, loss: 0.07662932574748993
step: 290, loss: 0.10572651028633118
step: 300, loss: 0.07253510504961014
step: 310, loss: 0.0024564145132899284
step: 320, loss: 0.0671556368470192
step: 330, loss: 0.15799583494663239
step: 340, loss: 0.09546030312776566
step: 350, loss: 0.050167277455329895
step: 360, loss: 0.08352974057197571
step: 370, loss: 0.011087304912507534
step: 380, loss: 0.029981397092342377
epoch 4: dev_f1=0.6832579185520362, f1=0.6651053864168618, best_f1=0.6651053864168618
step: 0, loss: 0.025057353079319
step: 10, loss: 0.1305246353149414
step: 20, loss: 0.009948831982910633
step: 30, loss: 0.08772721886634827
step: 40, loss: 0.00475119287148118
step: 50, loss: 0.09159112721681595
step: 60, loss: 0.027431517839431763
step: 70, loss: 0.05953821912407875
step: 80, loss: 0.008301456458866596
step: 90, loss: 0.021723948419094086
step: 100, loss: 0.026372011750936508
step: 110, loss: 0.02641625516116619
step: 120, loss: 0.0217349324375391
step: 130, loss: 0.028645265847444534
step: 140, loss: 0.07288419455289841
step: 150, loss: 0.07104834914207458
step: 160, loss: 0.06649747490882874
step: 170, loss: 0.05849343165755272
step: 180, loss: 0.045944713056087494
step: 190, loss: 0.052803099155426025
step: 200, loss: 0.04922383278608322
step: 210, loss: 0.021567372605204582
step: 220, loss: 0.16301287710666656
step: 230, loss: 0.06572627276182175
step: 240, loss: 0.06030495837330818
step: 250, loss: 0.10974740236997604
step: 260, loss: 0.02354310266673565
step: 270, loss: 0.006300716660916805
step: 280, loss: 0.28279271721839905
step: 290, loss: 0.004663032479584217
step: 300, loss: 0.004444332327693701
step: 310, loss: 0.0052814544178545475
step: 320, loss: 0.03031807951629162
step: 330, loss: 0.10775008797645569
step: 340, loss: 0.048492349684238434
step: 350, loss: 0.02976682223379612
step: 360, loss: 0.011825704015791416
step: 370, loss: 0.06514081358909607
step: 380, loss: 0.01829603873193264
epoch 5: dev_f1=0.6962962962962963, f1=0.6921119592875319, best_f1=0.6921119592875319
step: 0, loss: 0.021758290007710457
step: 10, loss: 0.01641053892672062
step: 20, loss: 0.062239911407232285
step: 30, loss: 0.06361722201108932
step: 40, loss: 0.01615935191512108
step: 50, loss: 0.027338305488228798
step: 60, loss: 0.02419034205377102
step: 70, loss: 0.05168330669403076
step: 80, loss: 0.08293943107128143
step: 90, loss: 0.1590764820575714
step: 100, loss: 0.3090147376060486
step: 110, loss: 0.056178972125053406
step: 120, loss: 0.015728330239653587
step: 130, loss: 0.046127378940582275
step: 140, loss: 0.19791308045387268
step: 150, loss: 0.005923024378716946
step: 160, loss: 0.06208326295018196
step: 170, loss: 0.036485835909843445
step: 180, loss: 0.08445929735898972
step: 190, loss: 0.07211528718471527
step: 200, loss: 0.031881172209978104
step: 210, loss: 0.02278515323996544
step: 220, loss: 0.0009865605970844626
step: 230, loss: 0.038177747279405594
step: 240, loss: 0.06366921216249466
step: 250, loss: 0.024522805586457253
step: 260, loss: 0.11344602704048157
step: 270, loss: 0.010858084075152874
step: 280, loss: 0.055070895701646805
step: 290, loss: 0.06060090288519859
step: 300, loss: 0.061156243085861206
step: 310, loss: 0.06837549060583115
step: 320, loss: 0.06375311315059662
step: 330, loss: 0.04210895672440529
step: 340, loss: 0.13206857442855835
step: 350, loss: 0.02307572029531002
step: 360, loss: 0.10171440988779068
step: 370, loss: 0.06154004484415054
step: 380, loss: 0.05595804750919342
epoch 6: dev_f1=0.6748166259168704, f1=0.6834170854271356, best_f1=0.6921119592875319
step: 0, loss: 0.019578736275434494
step: 10, loss: 0.08881872892379761
step: 20, loss: 0.020475182682275772
step: 30, loss: 0.10415974259376526
step: 40, loss: 0.07318251579999924
step: 50, loss: 0.022800080478191376
step: 60, loss: 0.027902405709028244
step: 70, loss: 0.06887810677289963
step: 80, loss: 0.02037201076745987
step: 90, loss: 0.0493311882019043
step: 100, loss: 0.03209546208381653
step: 110, loss: 0.06462431699037552
step: 120, loss: 0.023793267086148262
step: 130, loss: 0.01640906371176243
step: 140, loss: 0.10236892849206924
step: 150, loss: 0.014624010771512985
step: 160, loss: 0.021573910489678383
step: 170, loss: 0.012903274968266487
step: 180, loss: 0.07870586216449738
step: 190, loss: 0.13372668623924255
step: 200, loss: 0.007467405870556831
step: 210, loss: 0.09733223170042038
step: 220, loss: 0.0391479954123497
step: 230, loss: 0.10847239196300507
step: 240, loss: 0.05654405802488327
step: 250, loss: 0.17893022298812866
step: 260, loss: 0.09997628629207611
step: 270, loss: 0.02419494092464447
step: 280, loss: 0.03565150871872902
step: 290, loss: 0.04761454090476036
step: 300, loss: 0.09449028223752975
step: 310, loss: 0.08882766962051392
step: 320, loss: 0.06842421740293503
step: 330, loss: 0.027155060321092606
step: 340, loss: 0.11334311217069626
step: 350, loss: 0.021850908175110817
step: 360, loss: 0.023324135690927505
step: 370, loss: 0.03412570431828499
step: 380, loss: 0.023766813799738884
epoch 7: dev_f1=0.6950354609929078, f1=0.6526806526806527, best_f1=0.6921119592875319
step: 0, loss: 0.021472830325365067
step: 10, loss: 0.02774360403418541
step: 20, loss: 0.06418611109256744
step: 30, loss: 0.07569409906864166
step: 40, loss: 0.034402430057525635
step: 50, loss: 0.04522709548473358
step: 60, loss: 0.022497527301311493
step: 70, loss: 0.007248942274600267
step: 80, loss: 0.04153534770011902
step: 90, loss: 0.04981270805001259
step: 100, loss: 0.02652932144701481
step: 110, loss: 0.02166401408612728
step: 120, loss: 0.02786099538207054
step: 130, loss: 0.003361334325745702
step: 140, loss: 0.03298603743314743
step: 150, loss: 0.048635244369506836
step: 160, loss: 0.04215993732213974
step: 170, loss: 0.03383371978998184
step: 180, loss: 0.01064468827098608
step: 190, loss: 0.18180067837238312
step: 200, loss: 0.013417139649391174
step: 210, loss: 0.11360181868076324
step: 220, loss: 0.09684990346431732
step: 230, loss: 0.006874309852719307
step: 240, loss: 0.015097466297447681
step: 250, loss: 0.04514804482460022
step: 260, loss: 0.009619583375751972
step: 270, loss: 0.09558670222759247
step: 280, loss: 0.04671630263328552
step: 290, loss: 0.02048749476671219
step: 300, loss: 0.03013920597732067
step: 310, loss: 0.07442394644021988
step: 320, loss: 0.05676755681633949
step: 330, loss: 0.0484590046107769
step: 340, loss: 0.04582316428422928
step: 350, loss: 0.29583847522735596
step: 360, loss: 0.012662088498473167
step: 370, loss: 0.05042571574449539
step: 380, loss: 0.060632042586803436
epoch 8: dev_f1=0.72, f1=0.7035175879396985, best_f1=0.7035175879396985
step: 0, loss: 0.027496125549077988
step: 10, loss: 0.062218789011240005
step: 20, loss: 0.015486432239413261
step: 30, loss: 0.0011527041206136346
step: 40, loss: 0.001051363069564104
step: 50, loss: 0.06384646892547607
step: 60, loss: 0.04868486151099205
step: 70, loss: 0.06286998838186264
step: 80, loss: 0.0012956453720107675
step: 90, loss: 0.04574941471219063
step: 100, loss: 0.0975220799446106
step: 110, loss: 0.02102765068411827
step: 120, loss: 0.11433988064527512
step: 130, loss: 0.009603628888726234
step: 140, loss: 0.04049315303564072
step: 150, loss: 0.0002197037247242406
step: 160, loss: 0.10561393201351166
step: 170, loss: 0.020413387566804886
step: 180, loss: 0.005349881015717983
step: 190, loss: 0.11763477325439453
step: 200, loss: 0.04513397067785263
step: 210, loss: 0.013142752461135387
step: 220, loss: 0.020370598882436752
step: 230, loss: 0.050741031765937805
step: 240, loss: 0.04473423957824707
step: 250, loss: 0.06718062609434128
step: 260, loss: 0.10129568725824356
step: 270, loss: 0.00779181532561779
step: 280, loss: 0.008314831182360649
step: 290, loss: 0.037966445088386536
step: 300, loss: 0.0202841404825449
step: 310, loss: 0.008298905566334724
step: 320, loss: 0.07938847690820694
step: 330, loss: 0.043369095772504807
step: 340, loss: 0.0851220190525055
step: 350, loss: 0.05735727399587631
step: 360, loss: 0.08326079696416855
step: 370, loss: 0.033812515437603
step: 380, loss: 0.06397251784801483
epoch 9: dev_f1=0.7174447174447175, f1=0.6956521739130435, best_f1=0.7035175879396985
step: 0, loss: 0.013395185582339764
step: 10, loss: 0.02540024369955063
step: 20, loss: 0.0020391035359352827
step: 30, loss: 0.011353736743330956
step: 40, loss: 0.013566865585744381
step: 50, loss: 0.07317884266376495
step: 60, loss: 0.0025811640080064535
step: 70, loss: 0.01252493541687727
step: 80, loss: 0.005333736538887024
step: 90, loss: 0.013233141042292118
step: 100, loss: 0.042577698826789856
step: 110, loss: 0.02430998906493187
step: 120, loss: 0.08432074636220932
step: 130, loss: 0.005335142370313406
step: 140, loss: 0.0067562442272901535
step: 150, loss: 0.08255071938037872
step: 160, loss: 0.09844734519720078
step: 170, loss: 0.0017768793040886521
step: 180, loss: 0.08256801217794418
step: 190, loss: 0.03539552912116051
step: 200, loss: 0.0031966054812073708
step: 210, loss: 0.107877217233181
step: 220, loss: 0.1088137999176979
step: 230, loss: 0.019701017066836357
step: 240, loss: 0.16587257385253906
step: 250, loss: 0.028753934428095818
step: 260, loss: 0.11836306005716324
step: 270, loss: 0.04647469148039818
step: 280, loss: 0.01412065327167511
step: 290, loss: 0.020259132608771324
step: 300, loss: 0.018897490575909615
step: 310, loss: 0.009479510597884655
step: 320, loss: 0.07780718803405762
step: 330, loss: 0.0023923716507852077
step: 340, loss: 0.08399879932403564
step: 350, loss: 0.012786755338311195
step: 360, loss: 0.08824773132801056
step: 370, loss: 0.00012211706780362874
step: 380, loss: 0.038604266941547394
epoch 10: dev_f1=0.7196029776674937, f1=0.6977886977886977, best_f1=0.7035175879396985
step: 0, loss: 0.050022535026073456
step: 10, loss: 0.007020796649158001
step: 20, loss: 0.004076097160577774
step: 30, loss: 0.012616896070539951
step: 40, loss: 0.0019601797685027122
step: 50, loss: 0.0908331423997879
step: 60, loss: 0.030620494857430458
step: 70, loss: 0.01807219721376896
step: 80, loss: 0.02965330146253109
step: 90, loss: 0.0020864056423306465
step: 100, loss: 0.009969105012714863
step: 110, loss: 0.08355985581874847
step: 120, loss: 0.06825584918260574
step: 130, loss: 0.01854472979903221
step: 140, loss: 0.018850767984986305
step: 150, loss: 0.014586218632757664
step: 160, loss: 0.01689053513109684
step: 170, loss: 0.0068657309748232365
step: 180, loss: 0.1302415132522583
step: 190, loss: 0.06185892969369888
step: 200, loss: 0.11149206757545471
step: 210, loss: 0.03827919811010361
step: 220, loss: 0.03577769175171852
step: 230, loss: 0.00013994623441249132
step: 240, loss: 0.013175240717828274
step: 250, loss: 0.08632345497608185
step: 260, loss: 0.02665150724351406
step: 270, loss: 0.03209977596998215
step: 280, loss: 0.09957189112901688
step: 290, loss: 0.048014480620622635
step: 300, loss: 0.014192122966051102
step: 310, loss: 0.02806881256401539
step: 320, loss: 0.025503378361463547
step: 330, loss: 0.1374131292104721
step: 340, loss: 0.1159629225730896
step: 350, loss: 0.010161086916923523
step: 360, loss: 0.03347339481115341
step: 370, loss: 0.027238724753260612
step: 380, loss: 0.0731969028711319
epoch 11: dev_f1=0.6852791878172589, f1=0.676470588235294, best_f1=0.7035175879396985
step: 0, loss: 0.02161983959376812
step: 10, loss: 0.0653519332408905
step: 20, loss: 0.005036851856857538
step: 30, loss: 0.018413109704852104
step: 40, loss: 0.038409315049648285
step: 50, loss: 0.0117626478895545
step: 60, loss: 0.06729412078857422
step: 70, loss: 0.03604458272457123
step: 80, loss: 7.077476766426116e-05
step: 90, loss: 0.041141193360090256
step: 100, loss: 0.008523699827492237
step: 110, loss: 0.0009167836979031563
step: 120, loss: 0.05422176793217659
step: 130, loss: 0.003994144033640623
step: 140, loss: 0.07553781569004059
step: 150, loss: 0.015819480642676353
step: 160, loss: 0.015003537759184837
step: 170, loss: 0.010593539103865623
step: 180, loss: 0.08450455218553543
step: 190, loss: 0.036014605313539505
step: 200, loss: 0.08504671603441238
step: 210, loss: 0.0001124022965086624
step: 220, loss: 0.08453510701656342
step: 230, loss: 0.1302877515554428
step: 240, loss: 0.00019380822777748108
step: 250, loss: 0.0013219142565503716
step: 260, loss: 0.036590661853551865
step: 270, loss: 0.038809407502412796
step: 280, loss: 0.062247030436992645
step: 290, loss: 0.0010914902668446302
step: 300, loss: 0.037856895476579666
step: 310, loss: 0.04056015610694885
step: 320, loss: 0.0046644629910588264
step: 330, loss: 0.013789413496851921
step: 340, loss: 0.1272781491279602
step: 350, loss: 0.004447487182915211
step: 360, loss: 0.00723197590559721
step: 370, loss: 0.001720159430988133
step: 380, loss: 0.03715217486023903
epoch 12: dev_f1=0.6799999999999999, f1=0.628992628992629, best_f1=0.7035175879396985
step: 0, loss: 0.0021848436444997787
step: 10, loss: 0.008180100470781326
step: 20, loss: 0.02167421393096447
step: 30, loss: 0.22161142528057098
step: 40, loss: 0.00023929413873702288
step: 50, loss: 0.021025577560067177
step: 60, loss: 0.003011515364050865
step: 70, loss: 0.00285098934546113
step: 80, loss: 0.0033641911577433348
step: 90, loss: 0.0007885409286245704
step: 100, loss: 0.00605406891554594
step: 110, loss: 0.002427190775051713
step: 120, loss: 0.010637449100613594
step: 130, loss: 0.1486484855413437
step: 140, loss: 0.021212205290794373
step: 150, loss: 0.039962224662303925
step: 160, loss: 0.0532221756875515
step: 170, loss: 3.087796358158812e-05
step: 180, loss: 8.162172161974013e-05
step: 190, loss: 0.062465909868478775
step: 200, loss: 0.1453314870595932
step: 210, loss: 0.00041896410402841866
step: 220, loss: 0.05416456609964371
step: 230, loss: 0.03099875897169113
step: 240, loss: 0.0632053092122078
step: 250, loss: 0.008196298964321613
step: 260, loss: 0.0055562397465109825
step: 270, loss: 0.04523549973964691
step: 280, loss: 0.015028931200504303
step: 290, loss: 0.024312874302268028
step: 300, loss: 0.0007079997449181974
step: 310, loss: 0.04964420944452286
step: 320, loss: 0.007799383718520403
step: 330, loss: 0.03036656603217125
step: 340, loss: 0.008934266865253448
step: 350, loss: 0.010455993004143238
step: 360, loss: 0.0019131351727992296
step: 370, loss: 0.0011318203760311007
step: 380, loss: 0.006457917857915163
epoch 13: dev_f1=0.6851851851851851, f1=0.6666666666666666, best_f1=0.7035175879396985
step: 0, loss: 0.0002774096210487187
step: 10, loss: 0.029536671936511993
step: 20, loss: 0.060016363859176636
step: 30, loss: 0.00997235532850027
step: 40, loss: 0.0009311431786045432
step: 50, loss: 0.00036035748780705035
step: 60, loss: 0.0009515569545328617
step: 70, loss: 0.0008275158470496535
step: 80, loss: 0.0007431258563883603
step: 90, loss: 0.009230973199009895
step: 100, loss: 0.00017512110935058445
step: 110, loss: 0.09098747372627258
step: 120, loss: 0.0467505119740963
step: 130, loss: 4.0335380617761984e-05
step: 140, loss: 0.001358647714368999
step: 150, loss: 0.01360608171671629
step: 160, loss: 0.010107751004397869
step: 170, loss: 0.00028961378848180175
step: 180, loss: 0.008357098326086998
step: 190, loss: 0.07102258503437042
step: 200, loss: 0.014174402691423893
step: 210, loss: 0.0020073193591088057
step: 220, loss: 0.0005468755844049156
step: 230, loss: 0.013057212345302105
step: 240, loss: 0.04436587542295456
step: 250, loss: 0.006584288086742163
step: 260, loss: 0.000525444804225117
step: 270, loss: 7.242493302328512e-05
step: 280, loss: 9.44204002735205e-05
step: 290, loss: 0.05557439476251602
step: 300, loss: 0.026294302195310593
step: 310, loss: 0.028812918812036514
step: 320, loss: 0.053618352860212326
step: 330, loss: 0.0006890890654176474
step: 340, loss: 0.0022652253974229097
step: 350, loss: 0.0158305112272501
step: 360, loss: 0.013287678360939026
step: 370, loss: 0.08511479943990707
step: 380, loss: 0.048878204077482224
epoch 14: dev_f1=0.6929133858267716, f1=0.6611570247933883, best_f1=0.7035175879396985
step: 0, loss: 0.003156278282403946
step: 10, loss: 0.005571658257395029
step: 20, loss: 0.04570063203573227
step: 30, loss: 0.000539384491275996
step: 40, loss: 0.027589548379182816
step: 50, loss: 0.005980387795716524
step: 60, loss: 0.02553091011941433
step: 70, loss: 0.010653268545866013
step: 80, loss: 0.08695805072784424
step: 90, loss: 0.04561509191989899
step: 100, loss: 0.00017980569100473076
step: 110, loss: 0.01868622750043869
step: 120, loss: 0.03329915180802345
step: 130, loss: 0.17995114624500275
step: 140, loss: 0.04279134422540665
step: 150, loss: 0.002356522250920534
step: 160, loss: 0.00018048878700938076
step: 170, loss: 0.0028540014754980803
step: 180, loss: 0.04887565225362778
step: 190, loss: 0.01342052686959505
step: 200, loss: 0.01696152798831463
step: 210, loss: 0.0007892932626418769
step: 220, loss: 0.0007413558778353035
step: 230, loss: 0.000471724197268486
step: 240, loss: 0.028433429077267647
step: 250, loss: 0.004359487444162369
step: 260, loss: 0.0017590366769582033
step: 270, loss: 0.007246693596243858
step: 280, loss: 0.05039604380726814
step: 290, loss: 0.00021402070706244558
step: 300, loss: 0.0008213883847929537
step: 310, loss: 0.020719468593597412
step: 320, loss: 0.0044197021052241325
step: 330, loss: 0.0004252850776538253
step: 340, loss: 0.02432088367640972
step: 350, loss: 0.06520306318998337
step: 360, loss: 0.001799004152417183
step: 370, loss: 0.0030481526628136635
step: 380, loss: 0.017062818631529808
epoch 15: dev_f1=0.7043478260869565, f1=0.6609071274298057, best_f1=0.7035175879396985
step: 0, loss: 0.09374601393938065
step: 10, loss: 0.04524223506450653
step: 20, loss: 0.02658911421895027
step: 30, loss: 0.06541682779788971
step: 40, loss: 0.0051646046340465546
step: 50, loss: 0.014839252457022667
step: 60, loss: 0.0020027190912514925
step: 70, loss: 0.031442586332559586
step: 80, loss: 0.015176201239228249
step: 90, loss: 0.013565011322498322
step: 100, loss: 0.01976148597896099
step: 110, loss: 0.10299685597419739
step: 120, loss: 0.02101619355380535
step: 130, loss: 0.005556638818234205
step: 140, loss: 0.014816957525908947
step: 150, loss: 0.00023214067914523184
step: 160, loss: 0.007935134693980217
step: 170, loss: 0.00035315038985572755
step: 180, loss: 0.006862984504550695
step: 190, loss: 0.016570117324590683
step: 200, loss: 0.038866713643074036
step: 210, loss: 0.012972838245332241
step: 220, loss: 0.044314827769994736
step: 230, loss: 0.023668944835662842
step: 240, loss: 0.002047720830887556
step: 250, loss: 0.01766280271112919
step: 260, loss: 0.04908411204814911
step: 270, loss: 0.00014168850611895323
step: 280, loss: 0.1388644278049469
step: 290, loss: 3.680377994896844e-05
step: 300, loss: 0.0024174063000828028
step: 310, loss: 0.003999440930783749
step: 320, loss: 0.05234614014625549
step: 330, loss: 0.03853794187307358
step: 340, loss: 0.008032217621803284
step: 350, loss: 0.025539446622133255
step: 360, loss: 9.973926353268325e-05
step: 370, loss: 0.002758474089205265
step: 380, loss: 0.002400191267952323
epoch 16: dev_f1=0.7091836734693878, f1=0.6684350132625995, best_f1=0.7035175879396985
step: 0, loss: 0.004065966699272394
step: 10, loss: 0.023590626195073128
step: 20, loss: 0.0007859067991375923
step: 30, loss: 0.00019856958533637226
step: 40, loss: 8.369717397727072e-05
step: 50, loss: 0.021301642060279846
step: 60, loss: 0.005614842288196087
step: 70, loss: 0.0027668133843690157
step: 80, loss: 0.001583702745847404
step: 90, loss: 0.024115754291415215
step: 100, loss: 0.00843197200447321
step: 110, loss: 0.0022351534571498632
step: 120, loss: 9.787001908989623e-05
step: 130, loss: 3.902696698787622e-05
step: 140, loss: 4.81689021398779e-05
step: 150, loss: 0.04124985262751579
step: 160, loss: 0.029770003631711006
step: 170, loss: 0.002313299337401986
step: 180, loss: 9.880404832074419e-05
step: 190, loss: 0.017687030136585236
step: 200, loss: 0.01670127920806408
step: 210, loss: 0.038956549018621445
step: 220, loss: 0.00042920446139760315
step: 230, loss: 0.060400597751140594
step: 240, loss: 0.026819873601198196
step: 250, loss: 0.02330852299928665
step: 260, loss: 0.018714698031544685
step: 270, loss: 0.026208924129605293
step: 280, loss: 0.00022712153440807015
step: 290, loss: 0.006168726831674576
step: 300, loss: 3.909550650860183e-05
step: 310, loss: 0.00015870766947045922
step: 320, loss: 0.001706589013338089
step: 330, loss: 0.0004827203811146319
step: 340, loss: 0.03797474130988121
step: 350, loss: 0.0042455182410776615
step: 360, loss: 6.589771510334685e-05
step: 370, loss: 0.0001863593643065542
step: 380, loss: 0.024452069774270058
epoch 17: dev_f1=0.6947890818858561, f1=0.6751918158567773, best_f1=0.7035175879396985
step: 0, loss: 0.008786874823272228
step: 10, loss: 0.0009828078327700496
step: 20, loss: 3.3971195080084726e-05
step: 30, loss: 0.0032750191166996956
step: 40, loss: 0.06550649553537369
step: 50, loss: 0.04854244738817215
step: 60, loss: 0.016640938818454742
step: 70, loss: 0.0005146475741639733
step: 80, loss: 0.0276733860373497
step: 90, loss: 0.00014249880041461438
step: 100, loss: 0.002121737925335765
step: 110, loss: 0.0003444037865847349
step: 120, loss: 0.004967153538018465
step: 130, loss: 0.00017175512039102614
step: 140, loss: 0.026771042495965958
step: 150, loss: 0.00016350440273527056
step: 160, loss: 0.04466155543923378
step: 170, loss: 0.06665019690990448
step: 180, loss: 8.140148565871641e-05
step: 190, loss: 0.043150644749403
step: 200, loss: 8.641849126433954e-05
step: 210, loss: 0.02095416560769081
step: 220, loss: 2.063768988591619e-05
step: 230, loss: 0.030780049040913582
step: 240, loss: 0.06418163329362869
step: 250, loss: 0.04024044796824455
step: 260, loss: 0.0005775890313088894
step: 270, loss: 0.0005046453443355858
step: 280, loss: 0.0009900861186906695
step: 290, loss: 5.8750978496391326e-05
step: 300, loss: 0.019713634625077248
step: 310, loss: 0.031199999153614044
step: 320, loss: 0.0006366007728502154
step: 330, loss: 0.0001245264575118199
step: 340, loss: 0.006946443580091
step: 350, loss: 0.018751898780465126
step: 360, loss: 0.008169062435626984
step: 370, loss: 0.009232409298419952
step: 380, loss: 0.02321634255349636
epoch 18: dev_f1=0.6812652068126521, f1=0.6683804627249357, best_f1=0.7035175879396985
step: 0, loss: 0.022484369575977325
step: 10, loss: 0.0063832844607532024
step: 20, loss: 0.042693257331848145
step: 30, loss: 0.0006327893352136016
step: 40, loss: 0.000866913003847003
step: 50, loss: 0.001393236336298287
step: 60, loss: 0.01600479893386364
step: 70, loss: 0.00017279121675528586
step: 80, loss: 8.086393063422292e-05
step: 90, loss: 6.347024464048445e-05
step: 100, loss: 0.003674156963825226
step: 110, loss: 0.016820697113871574
step: 120, loss: 0.014756398275494576
step: 130, loss: 0.0023313327692449093
step: 140, loss: 0.0003378716064617038
step: 150, loss: 9.685511759016663e-05
step: 160, loss: 0.001162938540801406
step: 170, loss: 0.006628594361245632
step: 180, loss: 4.745821206597611e-05
step: 190, loss: 0.014696052297949791
step: 200, loss: 3.968259261455387e-05
step: 210, loss: 2.7896874598809518e-05
step: 220, loss: 0.0006208637496456504
step: 230, loss: 0.01002487912774086
step: 240, loss: 0.0002837195643223822
step: 250, loss: 9.501844033366069e-05
step: 260, loss: 0.003534127725288272
step: 270, loss: 0.0481577105820179
step: 280, loss: 1.772836003510747e-05
step: 290, loss: 0.05092288553714752
step: 300, loss: 0.02371874824166298
step: 310, loss: 0.0025743115693330765
step: 320, loss: 0.027197768911719322
step: 330, loss: 2.4739025320741348e-05
step: 340, loss: 0.049278710037469864
step: 350, loss: 4.7612043999833986e-05
step: 360, loss: 3.7171164876781404e-05
step: 370, loss: 2.334556120331399e-05
step: 380, loss: 0.08317387849092484
epoch 19: dev_f1=0.6969696969696969, f1=0.6790450928381963, best_f1=0.7035175879396985
step: 0, loss: 0.046778466552495956
step: 10, loss: 0.033841054886579514
step: 20, loss: 0.0052420757710933685
step: 30, loss: 0.05695754289627075
step: 40, loss: 3.3417396480217576e-05
step: 50, loss: 0.015368354506790638
step: 60, loss: 0.0006067434442229569
step: 70, loss: 0.0003426269395276904
step: 80, loss: 1.9710012566065416e-05
step: 90, loss: 0.015582696534693241
step: 100, loss: 3.0341405363287777e-05
step: 110, loss: 0.0006296636420302093
step: 120, loss: 0.002260911278426647
step: 130, loss: 0.014425239525735378
step: 140, loss: 0.0005826899432577193
step: 150, loss: 0.008383531123399734
step: 160, loss: 0.02660473808646202
step: 170, loss: 0.00014955877850297838
step: 180, loss: 0.048932936042547226
step: 190, loss: 0.0024865595623850822
step: 200, loss: 5.220832099439576e-05
step: 210, loss: 0.0070980871096253395
step: 220, loss: 0.00015654831076972187
step: 230, loss: 0.0010725850006565452
step: 240, loss: 0.02284141816198826
step: 250, loss: 0.004967458546161652
step: 260, loss: 0.001405227230861783
step: 270, loss: 0.0003050730738323182
step: 280, loss: 4.4252989027881995e-05
step: 290, loss: 0.00604666443541646
step: 300, loss: 0.0002329937560716644
step: 310, loss: 5.895074355066754e-05
step: 320, loss: 0.0003358407411724329
step: 330, loss: 0.007155741564929485
step: 340, loss: 3.5248805943410844e-05
step: 350, loss: 0.004579337779432535
step: 360, loss: 0.0001266553153982386
step: 370, loss: 0.0076785157434642315
step: 380, loss: 0.0033880891278386116
epoch 20: dev_f1=0.6940874035989718, f1=0.6939890710382514, best_f1=0.7035175879396985
