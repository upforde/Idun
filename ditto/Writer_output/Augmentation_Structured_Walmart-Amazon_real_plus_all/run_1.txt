cuda
Device: cuda
step: 0, loss: 0.635771632194519
step: 10, loss: 0.32157382369041443
step: 20, loss: 0.08679553866386414
step: 30, loss: 0.44719499349594116
step: 40, loss: 0.2888506352901459
step: 50, loss: 0.32706671953201294
step: 60, loss: 0.3170357048511505
step: 70, loss: 0.28870072960853577
step: 80, loss: 0.2666526734828949
step: 90, loss: 0.32002267241477966
step: 100, loss: 0.4212644696235657
step: 110, loss: 0.1633504033088684
step: 120, loss: 0.27351927757263184
step: 130, loss: 0.3797917366027832
step: 140, loss: 0.1458950787782669
step: 150, loss: 0.13585405051708221
step: 160, loss: 0.38044679164886475
step: 170, loss: 0.2132553905248642
step: 180, loss: 0.3343643844127655
step: 190, loss: 0.2885536551475525
step: 200, loss: 0.2427661269903183
step: 210, loss: 0.12243159860372543
step: 220, loss: 0.2660045027732849
step: 230, loss: 0.39815741777420044
step: 240, loss: 0.24245727062225342
step: 250, loss: 0.30916523933410645
step: 260, loss: 0.18129965662956238
step: 270, loss: 0.3389545977115631
step: 280, loss: 0.18067464232444763
step: 290, loss: 0.23678193986415863
step: 300, loss: 0.17132924497127533
step: 310, loss: 0.16314323246479034
step: 320, loss: 0.20334553718566895
step: 330, loss: 0.5209776759147644
step: 340, loss: 0.3387739658355713
step: 350, loss: 0.20461219549179077
step: 360, loss: 0.13878092169761658
step: 370, loss: 0.1814444661140442
step: 380, loss: 0.24816392362117767
epoch 1: dev_f1=0.5492424242424242, f1=0.5137614678899083, best_f1=0.5137614678899083
step: 0, loss: 0.20229671895503998
step: 10, loss: 0.28488096594810486
step: 20, loss: 0.042075756937265396
step: 30, loss: 0.0682215765118599
step: 40, loss: 0.027102168649435043
step: 50, loss: 0.49122247099876404
step: 60, loss: 0.19898590445518494
step: 70, loss: 0.12765385210514069
step: 80, loss: 0.22854718565940857
step: 90, loss: 0.23892496526241302
step: 100, loss: 0.14910995960235596
step: 110, loss: 0.1093728169798851
step: 120, loss: 0.22718890011310577
step: 130, loss: 0.08065785467624664
step: 140, loss: 0.3733120858669281
step: 150, loss: 0.09521495550870895
step: 160, loss: 0.13682356476783752
step: 170, loss: 0.16807065904140472
step: 180, loss: 0.17589281499385834
step: 190, loss: 0.10308224707841873
step: 200, loss: 0.2674674689769745
step: 210, loss: 0.24068805575370789
step: 220, loss: 0.049124155193567276
step: 230, loss: 0.16635762155056
step: 240, loss: 0.030281348153948784
step: 250, loss: 0.10155466198921204
step: 260, loss: 0.22094844281673431
step: 270, loss: 0.11552029848098755
step: 280, loss: 0.13297484815120697
step: 290, loss: 0.3172553777694702
step: 300, loss: 0.17630109190940857
step: 310, loss: 0.07517896592617035
step: 320, loss: 0.268960565328598
step: 330, loss: 0.07580121606588364
step: 340, loss: 0.10756227374076843
step: 350, loss: 0.1680288165807724
step: 360, loss: 0.08706377446651459
step: 370, loss: 0.13719260692596436
step: 380, loss: 0.06910821050405502
epoch 2: dev_f1=0.676470588235294, f1=0.668354430379747, best_f1=0.668354430379747
step: 0, loss: 0.1478785276412964
step: 10, loss: 0.07157021760940552
step: 20, loss: 0.05694584548473358
step: 30, loss: 0.16432704031467438
step: 40, loss: 0.21684861183166504
step: 50, loss: 0.1578795462846756
step: 60, loss: 0.02077479474246502
step: 70, loss: 0.1513276994228363
step: 80, loss: 0.04324508085846901
step: 90, loss: 0.01826905645430088
step: 100, loss: 0.22596579790115356
step: 110, loss: 0.0662597268819809
step: 120, loss: 0.06749262660741806
step: 130, loss: 0.028082387521862984
step: 140, loss: 0.04912398010492325
step: 150, loss: 0.04426871985197067
step: 160, loss: 0.0027856009546667337
step: 170, loss: 0.025731921195983887
step: 180, loss: 0.03284323588013649
step: 190, loss: 0.03512785583734512
step: 200, loss: 0.059732235968112946
step: 210, loss: 0.10051023215055466
step: 220, loss: 0.08533057570457458
step: 230, loss: 0.03409755602478981
step: 240, loss: 0.01655430719256401
step: 250, loss: 0.014359799213707447
step: 260, loss: 0.11502674967050552
step: 270, loss: 0.04259501397609711
step: 280, loss: 0.11054782569408417
step: 290, loss: 0.14036990702152252
step: 300, loss: 0.03989739343523979
step: 310, loss: 0.06477934122085571
step: 320, loss: 0.12097526341676712
step: 330, loss: 0.07088317722082138
step: 340, loss: 0.08333507180213928
step: 350, loss: 0.4028548002243042
step: 360, loss: 0.18971103429794312
step: 370, loss: 0.0376783050596714
step: 380, loss: 0.008059476502239704
epoch 3: dev_f1=0.6462264150943395, f1=0.6730310262529833, best_f1=0.668354430379747
step: 0, loss: 0.03961392492055893
step: 10, loss: 0.042294733226299286
step: 20, loss: 0.07511947304010391
step: 30, loss: 0.07519938796758652
step: 40, loss: 0.13934870064258575
step: 50, loss: 0.04680667817592621
step: 60, loss: 0.029742449522018433
step: 70, loss: 0.07363676279783249
step: 80, loss: 0.07766540348529816
step: 90, loss: 0.03309043496847153
step: 100, loss: 0.11533155292272568
step: 110, loss: 0.0197853222489357
step: 120, loss: 0.03528552129864693
step: 130, loss: 0.10402075201272964
step: 140, loss: 0.12756411731243134
step: 150, loss: 0.043178535997867584
step: 160, loss: 0.03081193007528782
step: 170, loss: 0.04091853275895119
step: 180, loss: 0.08436039090156555
step: 190, loss: 0.01138691883534193
step: 200, loss: 0.10339401662349701
step: 210, loss: 0.13972827792167664
step: 220, loss: 0.14793848991394043
step: 230, loss: 0.15930680930614471
step: 240, loss: 0.03356383368372917
step: 250, loss: 0.015328814275562763
step: 260, loss: 0.08001471310853958
step: 270, loss: 0.11226886510848999
step: 280, loss: 0.03255234658718109
step: 290, loss: 0.026307016611099243
step: 300, loss: 0.07155340909957886
step: 310, loss: 0.024031972512602806
step: 320, loss: 0.01779402792453766
step: 330, loss: 0.05663435533642769
step: 340, loss: 0.059290915727615356
step: 350, loss: 0.14603883028030396
step: 360, loss: 0.039103079587221146
step: 370, loss: 0.11422918736934662
step: 380, loss: 0.14647182822227478
epoch 4: dev_f1=0.6962616822429907, f1=0.7080459770114941, best_f1=0.7080459770114941
step: 0, loss: 0.07515232264995575
step: 10, loss: 0.07771275192499161
step: 20, loss: 0.024042220786213875
step: 30, loss: 0.04870632290840149
step: 40, loss: 0.020615538582205772
step: 50, loss: 0.074583038687706
step: 60, loss: 0.026471346616744995
step: 70, loss: 0.0448911115527153
step: 80, loss: 0.14980539679527283
step: 90, loss: 0.25989967584609985
step: 100, loss: 0.10317429155111313
step: 110, loss: 0.0704101175069809
step: 120, loss: 0.08662005513906479
step: 130, loss: 0.008137013763189316
step: 140, loss: 0.04948996379971504
step: 150, loss: 0.1678985357284546
step: 160, loss: 0.05451114475727081
step: 170, loss: 0.11564560234546661
step: 180, loss: 0.08492863923311234
step: 190, loss: 0.09744235128164291
step: 200, loss: 0.07619106024503708
step: 210, loss: 0.0044284178875386715
step: 220, loss: 0.04364392161369324
step: 230, loss: 0.10003341734409332
step: 240, loss: 0.07477720081806183
step: 250, loss: 0.020406875759363174
step: 260, loss: 0.005795476958155632
step: 270, loss: 0.050529610365629196
step: 280, loss: 0.09822914004325867
step: 290, loss: 0.0751681700348854
step: 300, loss: 0.0010305375326424837
step: 310, loss: 0.011003440245985985
step: 320, loss: 0.04495573416352272
step: 330, loss: 0.0453236922621727
step: 340, loss: 0.03484506905078888
step: 350, loss: 0.02918052300810814
step: 360, loss: 0.004875484388321638
step: 370, loss: 0.013214505277574062
step: 380, loss: 0.09546279162168503
epoch 5: dev_f1=0.7023255813953487, f1=0.7180722891566265, best_f1=0.7180722891566265
step: 0, loss: 0.06120172515511513
step: 10, loss: 0.08719435334205627
step: 20, loss: 0.05046599358320236
step: 30, loss: 0.0782303735613823
step: 40, loss: 0.06346782296895981
step: 50, loss: 0.04715140536427498
step: 60, loss: 0.0461009219288826
step: 70, loss: 0.08847194164991379
step: 80, loss: 0.025968436151742935
step: 90, loss: 0.03692898899316788
step: 100, loss: 0.06415386497974396
step: 110, loss: 0.08644898980855942
step: 120, loss: 0.025568027049303055
step: 130, loss: 0.016635609790682793
step: 140, loss: 0.06834399700164795
step: 150, loss: 0.05274040624499321
step: 160, loss: 0.08586474508047104
step: 170, loss: 0.0734163150191307
step: 180, loss: 0.13059352338314056
step: 190, loss: 0.06748132407665253
step: 200, loss: 0.03738856315612793
step: 210, loss: 0.05225616320967674
step: 220, loss: 0.08605636656284332
step: 230, loss: 0.07398895174264908
step: 240, loss: 0.08318623155355453
step: 250, loss: 0.08100711554288864
step: 260, loss: 0.0008093705400824547
step: 270, loss: 0.04070333391427994
step: 280, loss: 0.1146669015288353
step: 290, loss: 0.09888223558664322
step: 300, loss: 0.06425269693136215
step: 310, loss: 0.014083446003496647
step: 320, loss: 0.058802906423807144
step: 330, loss: 0.037526242434978485
step: 340, loss: 0.053635381162166595
step: 350, loss: 0.017742358148097992
step: 360, loss: 0.05031823366880417
step: 370, loss: 0.1657707393169403
step: 380, loss: 0.2070743888616562
epoch 6: dev_f1=0.6868686868686869, f1=0.722077922077922, best_f1=0.7180722891566265
step: 0, loss: 0.030865496024489403
step: 10, loss: 0.020671285688877106
step: 20, loss: 0.009189476259052753
step: 30, loss: 0.030792128294706345
step: 40, loss: 0.005069483071565628
step: 50, loss: 0.054793328046798706
step: 60, loss: 0.0091667789965868
step: 70, loss: 0.08761895447969437
step: 80, loss: 0.005669714417308569
step: 90, loss: 0.07223103940486908
step: 100, loss: 0.07134442776441574
step: 110, loss: 0.00734680937603116
step: 120, loss: 0.013685362413525581
step: 130, loss: 0.05736623331904411
step: 140, loss: 0.016942258924245834
step: 150, loss: 0.01886831410229206
step: 160, loss: 0.08156285434961319
step: 170, loss: 0.07677002996206284
step: 180, loss: 0.04801610857248306
step: 190, loss: 0.1387910097837448
step: 200, loss: 0.11883054673671722
step: 210, loss: 0.037106528878211975
step: 220, loss: 0.024797584861516953
step: 230, loss: 0.027614351361989975
step: 240, loss: 0.054144229739904404
step: 250, loss: 0.11558949202299118
step: 260, loss: 0.07828958332538605
step: 270, loss: 0.030864790081977844
step: 280, loss: 0.035724151879549026
step: 290, loss: 0.006059823092073202
step: 300, loss: 0.019677720963954926
step: 310, loss: 0.0010485127568244934
step: 320, loss: 0.027231886982917786
step: 330, loss: 0.030210603028535843
step: 340, loss: 0.09729637205600739
step: 350, loss: 0.07601068168878555
step: 360, loss: 0.054715532809495926
step: 370, loss: 0.039601728320121765
step: 380, loss: 0.18016751110553741
epoch 7: dev_f1=0.6770025839793281, f1=0.6718346253229973, best_f1=0.7180722891566265
step: 0, loss: 0.025624344125390053
step: 10, loss: 0.03832437843084335
step: 20, loss: 0.005452356301248074
step: 30, loss: 0.0007874439470469952
step: 40, loss: 0.13362076878547668
step: 50, loss: 0.04868418723344803
step: 60, loss: 0.026098228991031647
step: 70, loss: 0.04031943529844284
step: 80, loss: 0.07875395566225052
step: 90, loss: 0.030543729662895203
step: 100, loss: 0.1014731377363205
step: 110, loss: 0.03133277967572212
step: 120, loss: 0.002560777124017477
step: 130, loss: 0.019821958616375923
step: 140, loss: 0.005267464555799961
step: 150, loss: 0.02307985909283161
step: 160, loss: 0.14237453043460846
step: 170, loss: 0.0219466183334589
step: 180, loss: 0.013895757496356964
step: 190, loss: 0.05451570078730583
step: 200, loss: 0.01840127259492874
step: 210, loss: 0.02389025315642357
step: 220, loss: 0.040917325764894485
step: 230, loss: 0.05459238961338997
step: 240, loss: 0.024708572775125504
step: 250, loss: 0.04412596672773361
step: 260, loss: 0.06780943274497986
step: 270, loss: 0.05322637781500816
step: 280, loss: 0.029202938079833984
step: 290, loss: 0.028940735384821892
step: 300, loss: 0.12674182653427124
step: 310, loss: 0.005606238264590502
step: 320, loss: 0.028611531481146812
step: 330, loss: 0.0188604723662138
step: 340, loss: 0.0011503504356369376
step: 350, loss: 0.0013240552507340908
step: 360, loss: 0.034424252808094025
step: 370, loss: 0.027705064043402672
step: 380, loss: 0.09170817583799362
epoch 8: dev_f1=0.6900269541778975, f1=0.7027027027027027, best_f1=0.7180722891566265
step: 0, loss: 0.11509467661380768
step: 10, loss: 0.029206151142716408
step: 20, loss: 0.06291748583316803
step: 30, loss: 0.10121813416481018
step: 40, loss: 0.09156730026006699
step: 50, loss: 0.060239508748054504
step: 60, loss: 0.00046379512059502304
step: 70, loss: 0.02312450297176838
step: 80, loss: 0.02671806886792183
step: 90, loss: 0.0001478447811678052
step: 100, loss: 0.06550895422697067
step: 110, loss: 0.027005635201931
step: 120, loss: 0.05408560484647751
step: 130, loss: 0.05296700447797775
step: 140, loss: 0.02477957494556904
step: 150, loss: 0.06621479243040085
step: 160, loss: 0.015277168713510036
step: 170, loss: 0.24122193455696106
step: 180, loss: 0.04638811573386192
step: 190, loss: 0.0164018627256155
step: 200, loss: 0.0851440355181694
step: 210, loss: 0.04223532974720001
step: 220, loss: 0.061639849096536636
step: 230, loss: 0.05830409377813339
step: 240, loss: 0.050074875354766846
step: 250, loss: 0.08074028789997101
step: 260, loss: 0.0016799947479739785
step: 270, loss: 0.06861628592014313
step: 280, loss: 0.007062735967338085
step: 290, loss: 0.0677705630660057
step: 300, loss: 0.022423695772886276
step: 310, loss: 0.06768279522657394
step: 320, loss: 0.009537328034639359
step: 330, loss: 0.04882119596004486
step: 340, loss: 0.0616912804543972
step: 350, loss: 0.010123812593519688
step: 360, loss: 0.09943757206201553
step: 370, loss: 0.03760185465216637
step: 380, loss: 0.05711881443858147
epoch 9: dev_f1=0.6851385390428211, f1=0.6921119592875319, best_f1=0.7180722891566265
step: 0, loss: 0.0481407456099987
step: 10, loss: 0.0002742293872870505
step: 20, loss: 0.011587361805140972
step: 30, loss: 0.007721108850091696
step: 40, loss: 0.0003142693603876978
step: 50, loss: 0.08198559284210205
step: 60, loss: 0.011221355758607388
step: 70, loss: 0.060381773859262466
step: 80, loss: 0.0020452397875487804
step: 90, loss: 0.4481971263885498
step: 100, loss: 0.00708585511893034
step: 110, loss: 0.01361021026968956
step: 120, loss: 0.00016081197827588767
step: 130, loss: 0.018972644582390785
step: 140, loss: 0.03176859766244888
step: 150, loss: 0.15230301022529602
step: 160, loss: 0.0682579055428505
step: 170, loss: 0.007743827998638153
step: 180, loss: 0.02690056897699833
step: 190, loss: 0.051386281847953796
step: 200, loss: 0.0038196872919797897
step: 210, loss: 0.03146903216838837
step: 220, loss: 0.01915264129638672
step: 230, loss: 0.00019134528702124953
step: 240, loss: 0.026953965425491333
step: 250, loss: 0.02204250916838646
step: 260, loss: 0.011215196922421455
step: 270, loss: 0.035921432077884674
step: 280, loss: 0.03070932812988758
step: 290, loss: 0.027755938470363617
step: 300, loss: 0.06961558014154434
step: 310, loss: 0.07160663604736328
step: 320, loss: 0.03398386761546135
step: 330, loss: 0.04480355232954025
step: 340, loss: 0.03612200543284416
step: 350, loss: 0.09168370813131332
step: 360, loss: 0.06924982368946075
step: 370, loss: 0.0045064715668559074
step: 380, loss: 0.05786707624793053
epoch 10: dev_f1=0.7043701799485862, f1=0.7083333333333333, best_f1=0.7083333333333333
step: 0, loss: 0.03470010310411453
step: 10, loss: 0.015054061077535152
step: 20, loss: 0.004129901062697172
step: 30, loss: 0.018244439736008644
step: 40, loss: 0.01978941075503826
step: 50, loss: 0.05274515226483345
step: 60, loss: 0.019338974729180336
step: 70, loss: 0.01874774880707264
step: 80, loss: 0.07280983030796051
step: 90, loss: 0.08081518858671188
step: 100, loss: 0.04144878685474396
step: 110, loss: 0.0003726314753293991
step: 120, loss: 0.03664028272032738
step: 130, loss: 0.027452118694782257
step: 140, loss: 0.009576923213899136
step: 150, loss: 0.019535278901457787
step: 160, loss: 0.12483533471822739
step: 170, loss: 0.004576845560222864
step: 180, loss: 0.013929378241300583
step: 190, loss: 0.00021766973077319562
step: 200, loss: 0.017368149012327194
step: 210, loss: 0.05705408751964569
step: 220, loss: 0.03565044701099396
step: 230, loss: 0.027596058323979378
step: 240, loss: 0.04379890486598015
step: 250, loss: 0.029066795483231544
step: 260, loss: 0.029120836406946182
step: 270, loss: 0.0025571947917342186
step: 280, loss: 0.02985471487045288
step: 290, loss: 0.043410737067461014
step: 300, loss: 0.04582107439637184
step: 310, loss: 0.053618423640728
step: 320, loss: 0.015092018991708755
step: 330, loss: 0.0030111235100775957
step: 340, loss: 0.03667234256863594
step: 350, loss: 0.02457253262400627
step: 360, loss: 0.009689638391137123
step: 370, loss: 0.13976958394050598
step: 380, loss: 0.009943932294845581
epoch 11: dev_f1=0.6846473029045643, f1=0.6753812636165577, best_f1=0.7083333333333333
step: 0, loss: 0.048446670174598694
step: 10, loss: 0.034726738929748535
step: 20, loss: 0.07309670746326447
step: 30, loss: 0.00033996228012256324
step: 40, loss: 0.004699041601270437
step: 50, loss: 0.02987481839954853
step: 60, loss: 7.093819294823334e-05
step: 70, loss: 0.00033941565197892487
step: 80, loss: 0.07774075120687485
step: 90, loss: 0.025579677894711494
step: 100, loss: 0.03993643447756767
step: 110, loss: 0.04795293137431145
step: 120, loss: 0.0548936128616333
step: 130, loss: 0.00014830779400654137
step: 140, loss: 0.02862311340868473
step: 150, loss: 0.01921161822974682
step: 160, loss: 0.009621313773095608
step: 170, loss: 0.00459601916372776
step: 180, loss: 0.02272750250995159
step: 190, loss: 0.046515822410583496
step: 200, loss: 0.015782851725816727
step: 210, loss: 0.03967634215950966
step: 220, loss: 0.004695338662713766
step: 230, loss: 0.07513362914323807
step: 240, loss: 0.06209968775510788
step: 250, loss: 0.00043281816761009395
step: 260, loss: 0.16141556203365326
step: 270, loss: 0.054607030004262924
step: 280, loss: 0.021549489349126816
step: 290, loss: 0.0005493045318871737
step: 300, loss: 0.024796627461910248
step: 310, loss: 0.025945913046598434
step: 320, loss: 0.00015630669076927006
step: 330, loss: 0.06743603944778442
step: 340, loss: 0.010246210731565952
step: 350, loss: 0.019833095371723175
step: 360, loss: 0.036553919315338135
step: 370, loss: 0.0377933569252491
step: 380, loss: 0.0823511928319931
epoch 12: dev_f1=0.7085427135678392, f1=0.6929133858267716, best_f1=0.6929133858267716
step: 0, loss: 0.018969323486089706
step: 10, loss: 0.002241201465949416
step: 20, loss: 0.01459402684122324
step: 30, loss: 0.013525217771530151
step: 40, loss: 0.0251479409635067
step: 50, loss: 7.671277126064524e-05
step: 60, loss: 0.0008551161154173315
step: 70, loss: 0.17899829149246216
step: 80, loss: 0.06671399623155594
step: 90, loss: 0.038125280290842056
step: 100, loss: 0.06385960429906845
step: 110, loss: 0.05355826020240784
step: 120, loss: 0.04667866230010986
step: 130, loss: 0.0006099199526943266
step: 140, loss: 0.031329985707998276
step: 150, loss: 0.005163894966244698
step: 160, loss: 0.0419454351067543
step: 170, loss: 0.024365615099668503
step: 180, loss: 0.08602536469697952
step: 190, loss: 0.0016331501537933946
step: 200, loss: 0.012726213783025742
step: 210, loss: 0.06881505250930786
step: 220, loss: 0.11672565340995789
step: 230, loss: 0.06575818359851837
step: 240, loss: 0.06617087125778198
step: 250, loss: 0.0013328641653060913
step: 260, loss: 0.0030015187803655863
step: 270, loss: 0.0019039214821532369
step: 280, loss: 0.021667396649718285
step: 290, loss: 0.051009029150009155
step: 300, loss: 0.0256190225481987
step: 310, loss: 0.051085807383060455
step: 320, loss: 0.06789325177669525
step: 330, loss: 0.018540913239121437
step: 340, loss: 0.005354288034141064
step: 350, loss: 0.17840151488780975
step: 360, loss: 0.002137187635526061
step: 370, loss: 0.023430712521076202
step: 380, loss: 0.000190280974493362
epoch 13: dev_f1=0.7201946472019465, f1=0.7204030226700252, best_f1=0.7204030226700252
step: 0, loss: 0.1297033578157425
step: 10, loss: 0.05704276263713837
step: 20, loss: 0.012534381821751595
step: 30, loss: 0.006013368256390095
step: 40, loss: 0.00015296725905500352
step: 50, loss: 4.987884312868118e-05
step: 60, loss: 0.0077244979329407215
step: 70, loss: 0.01586332358419895
step: 80, loss: 0.0050293863750994205
step: 90, loss: 0.06172870472073555
step: 100, loss: 0.01942015253007412
step: 110, loss: 0.008217434398829937
step: 120, loss: 0.01693739742040634
step: 130, loss: 0.28807228803634644
step: 140, loss: 0.18419302999973297
step: 150, loss: 0.042987871915102005
step: 160, loss: 0.07485491782426834
step: 170, loss: 0.058926187455654144
step: 180, loss: 0.00493987649679184
step: 190, loss: 0.023741912096738815
step: 200, loss: 0.10495281219482422
step: 210, loss: 0.0006742228870280087
step: 220, loss: 0.013812963850796223
step: 230, loss: 0.057935237884521484
step: 240, loss: 0.024276787415146828
step: 250, loss: 0.005600448232144117
step: 260, loss: 0.024273665621876717
step: 270, loss: 0.033940013498067856
step: 280, loss: 0.022264918312430382
step: 290, loss: 0.00015875241660978645
step: 300, loss: 0.10820826143026352
step: 310, loss: 0.03644993156194687
step: 320, loss: 0.003969708923250437
step: 330, loss: 0.016182055696845055
step: 340, loss: 0.031294144690036774
step: 350, loss: 0.036128755658864975
step: 360, loss: 0.018391108140349388
step: 370, loss: 0.041982486844062805
step: 380, loss: 0.03566514328122139
epoch 14: dev_f1=0.7239583333333334, f1=0.6978021978021979, best_f1=0.6978021978021979
step: 0, loss: 0.0006469847867265344
step: 10, loss: 0.02574576437473297
step: 20, loss: 0.028437955304980278
step: 30, loss: 0.05861636623740196
step: 40, loss: 0.017531871795654297
step: 50, loss: 0.04903624206781387
step: 60, loss: 0.00021174286666791886
step: 70, loss: 0.00023813227016944438
step: 80, loss: 0.015765629708766937
step: 90, loss: 0.0143003910779953
step: 100, loss: 0.0021066642366349697
step: 110, loss: 0.03451604023575783
step: 120, loss: 0.012312651611864567
step: 130, loss: 2.9127249945304357e-05
step: 140, loss: 5.162081652088091e-05
step: 150, loss: 0.014395589008927345
step: 160, loss: 0.05301011726260185
step: 170, loss: 0.010776340961456299
step: 180, loss: 0.12096454203128815
step: 190, loss: 0.00016177541692741215
step: 200, loss: 0.019020967185497284
step: 210, loss: 0.002203877316787839
step: 220, loss: 0.017400914803147316
step: 230, loss: 0.007215534802526236
step: 240, loss: 0.00014147160982247442
step: 250, loss: 0.13868899643421173
step: 260, loss: 0.0007766254129819572
step: 270, loss: 0.004715580027550459
step: 280, loss: 0.07118155062198639
step: 290, loss: 0.03194404020905495
step: 300, loss: 0.026555487886071205
step: 310, loss: 0.025797102600336075
step: 320, loss: 0.04194321483373642
step: 330, loss: 0.0158219151198864
step: 340, loss: 0.06021830439567566
step: 350, loss: 0.00633900286629796
step: 360, loss: 5.3689320338889956e-05
step: 370, loss: 0.03190700709819794
step: 380, loss: 0.05522641912102699
epoch 15: dev_f1=0.7139479905437351, f1=0.7241379310344828, best_f1=0.6978021978021979
step: 0, loss: 0.029714087024331093
step: 10, loss: 0.0003443716559559107
step: 20, loss: 0.06460346281528473
step: 30, loss: 0.0837739035487175
step: 40, loss: 0.011292662471532822
step: 50, loss: 0.005816464778035879
step: 60, loss: 0.0228120144456625
step: 70, loss: 4.1836625314317644e-05
step: 80, loss: 0.034121736884117126
step: 90, loss: 0.0016892540734261274
step: 100, loss: 0.0006886848132126033
step: 110, loss: 0.00032882310915738344
step: 120, loss: 0.033306509256362915
step: 130, loss: 5.1924300350947306e-05
step: 140, loss: 0.027167487889528275
step: 150, loss: 0.0007663321448490024
step: 160, loss: 0.016383584588766098
step: 170, loss: 0.009523405693471432
step: 180, loss: 0.02446991205215454
step: 190, loss: 0.025306712836027145
step: 200, loss: 0.018218912184238434
step: 210, loss: 0.0010340119479224086
step: 220, loss: 0.01175103709101677
step: 230, loss: 0.00013107019185554236
step: 240, loss: 6.653274613199756e-05
step: 250, loss: 0.00030760973459109664
step: 260, loss: 5.112640792503953e-05
step: 270, loss: 6.188198312884197e-05
step: 280, loss: 0.013138553127646446
step: 290, loss: 3.690426456159912e-05
step: 300, loss: 0.031164441257715225
step: 310, loss: 4.515214459388517e-05
step: 320, loss: 0.09985482692718506
step: 330, loss: 0.0018690647557377815
step: 340, loss: 0.02650490775704384
step: 350, loss: 0.0388975627720356
step: 360, loss: 0.018959417939186096
step: 370, loss: 0.029544221237301826
step: 380, loss: 0.0027707607951015234
epoch 16: dev_f1=0.7160493827160493, f1=0.7064935064935065, best_f1=0.6978021978021979
step: 0, loss: 0.03686738386750221
step: 10, loss: 0.00017645246407482773
step: 20, loss: 4.5807231799699366e-05
step: 30, loss: 0.03816797956824303
step: 40, loss: 0.0004606155271176249
step: 50, loss: 0.0006499465089291334
step: 60, loss: 0.011297992430627346
step: 70, loss: 0.059372782707214355
step: 80, loss: 0.03994440287351608
step: 90, loss: 0.0022575657349079847
step: 100, loss: 3.341471528983675e-05
step: 110, loss: 0.0005490214680321515
step: 120, loss: 0.00029250147053971887
step: 130, loss: 4.2217874579364434e-05
step: 140, loss: 0.0015111962566152215
step: 150, loss: 0.029554732143878937
step: 160, loss: 6.183191726449877e-05
step: 170, loss: 0.018930643796920776
step: 180, loss: 5.2325078286230564e-05
step: 190, loss: 0.03824467584490776
step: 200, loss: 0.00012171145499451086
step: 210, loss: 0.00018534819537308067
step: 220, loss: 0.02249179035425186
step: 230, loss: 0.00020233979739714414
step: 240, loss: 0.017536919564008713
step: 250, loss: 0.0001090284131350927
step: 260, loss: 0.0345175601541996
step: 270, loss: 0.04689127951860428
step: 280, loss: 0.0004342000465840101
step: 290, loss: 0.0028912557754665613
step: 300, loss: 0.002855713712051511
step: 310, loss: 0.019864730536937714
step: 320, loss: 0.0027126690838485956
step: 330, loss: 0.0003344806900713593
step: 340, loss: 0.0022031820844858885
step: 350, loss: 0.051658954471349716
step: 360, loss: 0.0003229368885513395
step: 370, loss: 0.03796282410621643
step: 380, loss: 0.00019836603314615786
epoch 17: dev_f1=0.7055555555555556, f1=0.709141274238227, best_f1=0.6978021978021979
step: 0, loss: 0.013483799062669277
step: 10, loss: 0.028757452964782715
step: 20, loss: 0.011041451245546341
step: 30, loss: 0.00016733793017920107
step: 40, loss: 0.028915168717503548
step: 50, loss: 0.0010090831201523542
step: 60, loss: 5.726477684220299e-05
step: 70, loss: 0.014192484319210052
step: 80, loss: 0.08382123708724976
step: 90, loss: 0.06681714206933975
step: 100, loss: 0.00877884216606617
step: 110, loss: 6.38568599242717e-05
step: 120, loss: 0.004812710452824831
step: 130, loss: 0.00040930876275524497
step: 140, loss: 0.01935046911239624
step: 150, loss: 0.03521524369716644
step: 160, loss: 0.00022080268536228687
step: 170, loss: 0.03031003475189209
step: 180, loss: 0.03465152904391289
step: 190, loss: 0.0008784995297901332
step: 200, loss: 0.05851063132286072
step: 210, loss: 0.0002190388331655413
step: 220, loss: 0.015500370413064957
step: 230, loss: 0.03606412932276726
step: 240, loss: 0.0005159465363249183
step: 250, loss: 0.02765514887869358
step: 260, loss: 0.032648395746946335
step: 270, loss: 0.001401820802129805
step: 280, loss: 0.0002009323361562565
step: 290, loss: 0.06803998351097107
step: 300, loss: 0.022253550589084625
step: 310, loss: 0.018508555367588997
step: 320, loss: 0.0012488758657127619
step: 330, loss: 0.00023370585404336452
step: 340, loss: 0.02157530002295971
step: 350, loss: 0.0074428049847483635
step: 360, loss: 0.042191386222839355
step: 370, loss: 0.013319953344762325
step: 380, loss: 2.1632355128531344e-05
epoch 18: dev_f1=0.7167919799498748, f1=0.7146529562982005, best_f1=0.6978021978021979
step: 0, loss: 0.04494202136993408
step: 10, loss: 0.018163146451115608
step: 20, loss: 0.0013124176766723394
step: 30, loss: 0.18298694491386414
step: 40, loss: 6.335599027806893e-05
step: 50, loss: 0.03227158263325691
step: 60, loss: 0.004267948679625988
step: 70, loss: 0.03180326521396637
step: 80, loss: 2.3409102141158655e-05
step: 90, loss: 0.018061084672808647
step: 100, loss: 0.018318643793463707
step: 110, loss: 0.0004377866571303457
step: 120, loss: 0.001225244370289147
step: 130, loss: 4.067631016368978e-05
step: 140, loss: 0.07554417848587036
step: 150, loss: 0.0007773977122269571
step: 160, loss: 0.0019867094233632088
step: 170, loss: 7.458830077666789e-05
step: 180, loss: 0.014227799139916897
step: 190, loss: 0.0008594114915467799
step: 200, loss: 0.08570141345262527
step: 210, loss: 0.014472327195107937
step: 220, loss: 0.01562558300793171
step: 230, loss: 0.007850384339690208
step: 240, loss: 2.5644409106462263e-05
step: 250, loss: 0.002756864530965686
step: 260, loss: 0.032271407544612885
step: 270, loss: 0.02126150391995907
step: 280, loss: 0.036675628274679184
step: 290, loss: 0.0001135955099016428
step: 300, loss: 0.020691286772489548
step: 310, loss: 7.249262125696987e-05
step: 320, loss: 6.95265262038447e-05
step: 330, loss: 0.008723337203264236
step: 340, loss: 0.0002534983213990927
step: 350, loss: 0.0006324694259092212
step: 360, loss: 8.002961112651974e-05
step: 370, loss: 0.009011276066303253
step: 380, loss: 0.00010574369662208483
epoch 19: dev_f1=0.7093333333333335, f1=0.7058823529411764, best_f1=0.6978021978021979
step: 0, loss: 0.03877156227827072
step: 10, loss: 2.8367096092551947e-05
step: 20, loss: 0.009134112857282162
step: 30, loss: 0.01722228154540062
step: 40, loss: 0.0004112801398150623
step: 50, loss: 0.04952017217874527
step: 60, loss: 0.027863511815667152
step: 70, loss: 0.002203822135925293
step: 80, loss: 0.017820153385400772
step: 90, loss: 2.917941856139805e-05
step: 100, loss: 0.024474121630191803
step: 110, loss: 0.01690111681818962
step: 120, loss: 0.004898919723927975
step: 130, loss: 0.023304812610149384
step: 140, loss: 0.014630235731601715
step: 150, loss: 0.06887734681367874
step: 160, loss: 0.0001424067741027102
step: 170, loss: 0.015960223972797394
step: 180, loss: 0.08489098399877548
step: 190, loss: 0.012369474396109581
step: 200, loss: 3.375674714334309e-05
step: 210, loss: 8.359602361451834e-05
step: 220, loss: 0.01423236820846796
step: 230, loss: 0.00035748217487707734
step: 240, loss: 0.00033418077509850264
step: 250, loss: 0.030961429700255394
step: 260, loss: 0.008037598803639412
step: 270, loss: 0.006991812493652105
step: 280, loss: 0.048244375735521317
step: 290, loss: 0.03278997913002968
step: 300, loss: 0.022501632571220398
step: 310, loss: 0.05778561532497406
step: 320, loss: 0.0005245268112048507
step: 330, loss: 0.0317230224609375
step: 340, loss: 5.426888674264774e-05
step: 350, loss: 2.7387633963371627e-05
step: 360, loss: 0.03388427570462227
step: 370, loss: 0.000663903309032321
step: 380, loss: 0.0010101274820044637
epoch 20: dev_f1=0.7088607594936709, f1=0.7028423772609819, best_f1=0.6978021978021979
