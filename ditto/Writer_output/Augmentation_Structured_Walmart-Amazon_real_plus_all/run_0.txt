cuda
Device: cuda
step: 0, loss: 0.6174411773681641
step: 10, loss: 0.2419501692056656
step: 20, loss: 0.44901159405708313
step: 30, loss: 0.2692437469959259
step: 40, loss: 0.30839282274246216
step: 50, loss: 0.0792611688375473
step: 60, loss: 0.2994843125343323
step: 70, loss: 0.4822903275489807
step: 80, loss: 0.3138745427131653
step: 90, loss: 0.2399212270975113
step: 100, loss: 0.4779305160045624
step: 110, loss: 0.3889561593532562
step: 120, loss: 0.1865869164466858
step: 130, loss: 0.4303804636001587
step: 140, loss: 0.227799654006958
step: 150, loss: 0.3809509575366974
step: 160, loss: 0.3126319348812103
step: 170, loss: 0.27163076400756836
step: 180, loss: 0.25445568561553955
step: 190, loss: 0.23541979491710663
step: 200, loss: 0.2995496094226837
step: 210, loss: 0.18233810365200043
step: 220, loss: 0.20498529076576233
step: 230, loss: 0.30137214064598083
step: 240, loss: 0.22989597916603088
step: 250, loss: 0.1816617101430893
step: 260, loss: 0.15794624388217926
step: 270, loss: 0.12342241406440735
step: 280, loss: 0.25293025374412537
step: 290, loss: 0.19491346180438995
step: 300, loss: 0.2473316490650177
step: 310, loss: 0.2868592143058777
step: 320, loss: 0.15245886147022247
step: 330, loss: 0.2462301105260849
step: 340, loss: 0.15106509625911713
step: 350, loss: 0.13238336145877838
step: 360, loss: 0.2666845917701721
step: 370, loss: 0.16529324650764465
step: 380, loss: 0.2659332752227783
epoch 1: dev_f1=0.5441860465116279, f1=0.5372460496613995, best_f1=0.5372460496613995
step: 0, loss: 0.12686723470687866
step: 10, loss: 0.17378884553909302
step: 20, loss: 0.19459562003612518
step: 30, loss: 0.07558714598417282
step: 40, loss: 0.34627553820610046
step: 50, loss: 0.10569991916418076
step: 60, loss: 0.0985209122300148
step: 70, loss: 0.0755755603313446
step: 80, loss: 0.09483209252357483
step: 90, loss: 0.10427437722682953
step: 100, loss: 0.061404503881931305
step: 110, loss: 0.09739857167005539
step: 120, loss: 0.1274672895669937
step: 130, loss: 0.13951611518859863
step: 140, loss: 0.027561822906136513
step: 150, loss: 0.05459568277001381
step: 160, loss: 0.10650921612977982
step: 170, loss: 0.20947480201721191
step: 180, loss: 0.1823015958070755
step: 190, loss: 0.1104528158903122
step: 200, loss: 0.04933682829141617
step: 210, loss: 0.10054769366979599
step: 220, loss: 0.05026116967201233
step: 230, loss: 0.09639019519090652
step: 240, loss: 0.1518785059452057
step: 250, loss: 0.1214650496840477
step: 260, loss: 0.1680787354707718
step: 270, loss: 0.11061270534992218
step: 280, loss: 0.12095224112272263
step: 290, loss: 0.3911206126213074
step: 300, loss: 0.13844390213489532
step: 310, loss: 0.13816985487937927
step: 320, loss: 0.1685943305492401
step: 330, loss: 0.10056498646736145
step: 340, loss: 0.08265553414821625
step: 350, loss: 0.18510113656520844
step: 360, loss: 0.27155378460884094
step: 370, loss: 0.07969524711370468
step: 380, loss: 0.3727344572544098
epoch 2: dev_f1=0.6145833333333334, f1=0.64, best_f1=0.64
step: 0, loss: 0.1159515529870987
step: 10, loss: 0.1328081339597702
step: 20, loss: 0.035064395517110825
step: 30, loss: 0.09001632779836655
step: 40, loss: 0.09365785866975784
step: 50, loss: 0.0792628675699234
step: 60, loss: 0.10156147181987762
step: 70, loss: 0.013713566586375237
step: 80, loss: 0.0504157654941082
step: 90, loss: 0.07559073716402054
step: 100, loss: 0.08845357596874237
step: 110, loss: 0.3076187074184418
step: 120, loss: 0.009583288803696632
step: 130, loss: 0.19680166244506836
step: 140, loss: 0.1978800743818283
step: 150, loss: 0.08793415129184723
step: 160, loss: 0.0988529846072197
step: 170, loss: 0.08283841609954834
step: 180, loss: 0.0928681418299675
step: 190, loss: 0.13279277086257935
step: 200, loss: 0.12599129974842072
step: 210, loss: 0.017908133566379547
step: 220, loss: 0.10355965793132782
step: 230, loss: 0.05960893630981445
step: 240, loss: 0.1361086517572403
step: 250, loss: 0.15484371781349182
step: 260, loss: 0.05018031224608421
step: 270, loss: 0.09084585309028625
step: 280, loss: 0.16663992404937744
step: 290, loss: 0.1601879745721817
step: 300, loss: 0.09296847134828568
step: 310, loss: 0.06977346539497375
step: 320, loss: 0.10853930562734604
step: 330, loss: 0.05771574750542641
step: 340, loss: 0.05626893416047096
step: 350, loss: 0.01832244172692299
step: 360, loss: 0.09332825243473053
step: 370, loss: 0.015473147854208946
step: 380, loss: 0.09472375363111496
epoch 3: dev_f1=0.6309012875536482, f1=0.6681415929203539, best_f1=0.6681415929203539
step: 0, loss: 0.10701295733451843
step: 10, loss: 0.1745317578315735
step: 20, loss: 0.1228361427783966
step: 30, loss: 0.032114144414663315
step: 40, loss: 0.07797826081514359
step: 50, loss: 0.08431467413902283
step: 60, loss: 0.057933222502470016
step: 70, loss: 0.10422400385141373
step: 80, loss: 0.12803922593593597
step: 90, loss: 0.07342060655355453
step: 100, loss: 0.049816377460956573
step: 110, loss: 0.06392345577478409
step: 120, loss: 0.09612999856472015
step: 130, loss: 0.28364765644073486
step: 140, loss: 0.13822074234485626
step: 150, loss: 0.015580070205032825
step: 160, loss: 0.10876517742872238
step: 170, loss: 0.09992275387048721
step: 180, loss: 0.10222876071929932
step: 190, loss: 0.09088127315044403
step: 200, loss: 0.096036896109581
step: 210, loss: 0.20797789096832275
step: 220, loss: 0.02186565287411213
step: 230, loss: 0.10161188244819641
step: 240, loss: 0.07547196000814438
step: 250, loss: 0.0008069447940215468
step: 260, loss: 0.03606269508600235
step: 270, loss: 0.10662725567817688
step: 280, loss: 0.012741688638925552
step: 290, loss: 0.02894498035311699
step: 300, loss: 0.3529767394065857
step: 310, loss: 0.024202674627304077
step: 320, loss: 0.04512409865856171
step: 330, loss: 0.011563465930521488
step: 340, loss: 0.11484888195991516
step: 350, loss: 0.061934396624565125
step: 360, loss: 0.027880294248461723
step: 370, loss: 0.13789023458957672
step: 380, loss: 0.02443605847656727
epoch 4: dev_f1=0.6666666666666667, f1=0.6987341772151898, best_f1=0.6987341772151898
step: 0, loss: 0.1864476203918457
step: 10, loss: 0.051085665822029114
step: 20, loss: 0.05583273991942406
step: 30, loss: 0.03339112177491188
step: 40, loss: 0.09163879603147507
step: 50, loss: 0.09131712466478348
step: 60, loss: 0.045276712626218796
step: 70, loss: 0.02462884411215782
step: 80, loss: 0.1713414490222931
step: 90, loss: 0.10691259801387787
step: 100, loss: 0.03355729207396507
step: 110, loss: 0.16263070702552795
step: 120, loss: 0.08936449885368347
step: 130, loss: 0.05011846125125885
step: 140, loss: 0.16511492431163788
step: 150, loss: 0.049641452729701996
step: 160, loss: 0.03972385451197624
step: 170, loss: 0.15787483751773834
step: 180, loss: 0.05026540905237198
step: 190, loss: 0.027446355670690536
step: 200, loss: 0.10259733349084854
step: 210, loss: 0.00838832650333643
step: 220, loss: 0.0785118043422699
step: 230, loss: 0.033251821994781494
step: 240, loss: 0.03574218600988388
step: 250, loss: 0.1079782247543335
step: 260, loss: 0.21488219499588013
step: 270, loss: 0.06303172558546066
step: 280, loss: 0.09586357325315475
step: 290, loss: 0.014462548308074474
step: 300, loss: 0.044733405113220215
step: 310, loss: 0.1646348088979721
step: 320, loss: 0.09593670070171356
step: 330, loss: 0.03691837936639786
step: 340, loss: 0.25385868549346924
step: 350, loss: 0.0010825702920556068
step: 360, loss: 0.10131461918354034
step: 370, loss: 0.029885530471801758
step: 380, loss: 0.0751001313328743
epoch 5: dev_f1=0.7129186602870814, f1=0.7317073170731708, best_f1=0.7317073170731708
step: 0, loss: 0.024359874427318573
step: 10, loss: 0.009899172931909561
step: 20, loss: 0.11821863055229187
step: 30, loss: 0.04715780168771744
step: 40, loss: 0.07034429907798767
step: 50, loss: 0.05582543835043907
step: 60, loss: 0.0415324829518795
step: 70, loss: 0.0734100416302681
step: 80, loss: 0.12585845589637756
step: 90, loss: 0.01118497271090746
step: 100, loss: 0.07858599722385406
step: 110, loss: 0.018980499356985092
step: 120, loss: 0.03879978880286217
step: 130, loss: 0.07552006095647812
step: 140, loss: 0.10999516397714615
step: 150, loss: 0.049230292439460754
step: 160, loss: 0.05149485543370247
step: 170, loss: 0.004003904294222593
step: 180, loss: 0.005955989472568035
step: 190, loss: 0.05991201475262642
step: 200, loss: 0.02356666512787342
step: 210, loss: 0.07181115448474884
step: 220, loss: 0.08500541746616364
step: 230, loss: 0.05520622432231903
step: 240, loss: 0.12870576977729797
step: 250, loss: 0.05136199668049812
step: 260, loss: 0.04761066660284996
step: 270, loss: 0.029873359948396683
step: 280, loss: 0.1825818121433258
step: 290, loss: 0.014379872009158134
step: 300, loss: 0.008573383092880249
step: 310, loss: 0.08895398676395416
step: 320, loss: 0.01090832706540823
step: 330, loss: 0.06130417063832283
step: 340, loss: 0.02315218187868595
step: 350, loss: 0.0065361023880541325
step: 360, loss: 0.04866456240415573
step: 370, loss: 0.07451460510492325
step: 380, loss: 0.04177292063832283
epoch 6: dev_f1=0.6712643678160919, f1=0.6896551724137931, best_f1=0.7317073170731708
step: 0, loss: 0.1011020839214325
step: 10, loss: 0.07258881628513336
step: 20, loss: 0.07474762946367264
step: 30, loss: 0.037681881338357925
step: 40, loss: 0.012193351052701473
step: 50, loss: 0.0012929015792906284
step: 60, loss: 0.029447076842188835
step: 70, loss: 0.06297428905963898
step: 80, loss: 0.012884249910712242
step: 90, loss: 0.03295356407761574
step: 100, loss: 0.05309988930821419
step: 110, loss: 0.03515224903821945
step: 120, loss: 0.043764349073171616
step: 130, loss: 0.13649091124534607
step: 140, loss: 0.012285348027944565
step: 150, loss: 0.0506344698369503
step: 160, loss: 0.08581452816724777
step: 170, loss: 0.11119380593299866
step: 180, loss: 0.02156096138060093
step: 190, loss: 0.0002017266961047426
step: 200, loss: 0.02364814653992653
step: 210, loss: 0.03936437517404556
step: 220, loss: 0.0005754553712904453
step: 230, loss: 0.04240832477807999
step: 240, loss: 0.011116940528154373
step: 250, loss: 0.013174109160900116
step: 260, loss: 0.0014935112558305264
step: 270, loss: 0.25481370091438293
step: 280, loss: 0.020335061475634575
step: 290, loss: 0.038009338080883026
step: 300, loss: 0.07189872115850449
step: 310, loss: 0.07367000728845596
step: 320, loss: 0.06790030747652054
step: 330, loss: 0.008634968660771847
step: 340, loss: 0.027236346155405045
step: 350, loss: 0.07302762567996979
step: 360, loss: 0.0007396673900075257
step: 370, loss: 0.0743277370929718
step: 380, loss: 0.07638440281152725
epoch 7: dev_f1=0.7012987012987013, f1=0.7239583333333334, best_f1=0.7317073170731708
step: 0, loss: 0.025565605610609055
step: 10, loss: 0.0008485508733429015
step: 20, loss: 0.17017728090286255
step: 30, loss: 0.03186136484146118
step: 40, loss: 0.06710067391395569
step: 50, loss: 0.05188661441206932
step: 60, loss: 0.048857834190130234
step: 70, loss: 0.058700285851955414
step: 80, loss: 0.10412748157978058
step: 90, loss: 0.012212675996124744
step: 100, loss: 0.022771380841732025
step: 110, loss: 0.010450955480337143
step: 120, loss: 0.01013711653649807
step: 130, loss: 0.049842920154333115
step: 140, loss: 0.00027453142683953047
step: 150, loss: 0.0019360912265256047
step: 160, loss: 0.06318346410989761
step: 170, loss: 0.03034070134162903
step: 180, loss: 0.0018852903740480542
step: 190, loss: 0.008582787588238716
step: 200, loss: 0.008371727541089058
step: 210, loss: 0.11490052938461304
step: 220, loss: 0.053555868566036224
step: 230, loss: 0.03247876837849617
step: 240, loss: 0.000321900995913893
step: 250, loss: 0.0690532699227333
step: 260, loss: 0.0006554939318448305
step: 270, loss: 0.05761829391121864
step: 280, loss: 0.06466194987297058
step: 290, loss: 0.08485577255487442
step: 300, loss: 0.06060926616191864
step: 310, loss: 0.09992759674787521
step: 320, loss: 0.05241277813911438
step: 330, loss: 0.028552215546369553
step: 340, loss: 0.07110504806041718
step: 350, loss: 0.03208594396710396
step: 360, loss: 0.05411450192332268
step: 370, loss: 0.0006953953998163342
step: 380, loss: 0.026720333844423294
epoch 8: dev_f1=0.7044334975369458, f1=0.75, best_f1=0.7317073170731708
step: 0, loss: 0.07216566801071167
step: 10, loss: 0.026269836351275444
step: 20, loss: 0.004417017102241516
step: 30, loss: 0.0002787408302538097
step: 40, loss: 0.09896395355463028
step: 50, loss: 0.05415911227464676
step: 60, loss: 0.11912640184164047
step: 70, loss: 0.04052437096834183
step: 80, loss: 0.08235098421573639
step: 90, loss: 0.04992536082863808
step: 100, loss: 0.0072617605328559875
step: 110, loss: 0.026406699791550636
step: 120, loss: 0.01297947857528925
step: 130, loss: 0.04181232303380966
step: 140, loss: 0.09888525307178497
step: 150, loss: 0.09488574415445328
step: 160, loss: 0.013370982371270657
step: 170, loss: 0.0003990301920566708
step: 180, loss: 0.0038632466457784176
step: 190, loss: 0.013111934065818787
step: 200, loss: 0.006797333247959614
step: 210, loss: 0.004107744432985783
step: 220, loss: 0.040624815970659256
step: 230, loss: 0.010087154805660248
step: 240, loss: 0.04397423192858696
step: 250, loss: 0.0016573297325521708
step: 260, loss: 0.030415058135986328
step: 270, loss: 0.005782787222415209
step: 280, loss: 0.15242893993854523
step: 290, loss: 0.06832819432020187
step: 300, loss: 0.005164641421288252
step: 310, loss: 0.06453525274991989
step: 320, loss: 0.00953742302954197
step: 330, loss: 0.057758692651987076
step: 340, loss: 0.06123431771993637
step: 350, loss: 0.03809003531932831
step: 360, loss: 0.0019529829733073711
step: 370, loss: 0.05807069316506386
step: 380, loss: 0.030932972207665443
epoch 9: dev_f1=0.6756756756756755, f1=0.7024128686327078, best_f1=0.7317073170731708
step: 0, loss: 0.011258777230978012
step: 10, loss: 0.09958759695291519
step: 20, loss: 0.13877785205841064
step: 30, loss: 0.008095831610262394
step: 40, loss: 0.021439265459775925
step: 50, loss: 0.02921796217560768
step: 60, loss: 0.00877393875271082
step: 70, loss: 0.03600931912660599
step: 80, loss: 0.052041519433259964
step: 90, loss: 0.0025067911483347416
step: 100, loss: 0.016883233562111855
step: 110, loss: 0.10088441520929337
step: 120, loss: 0.0003339433460496366
step: 130, loss: 0.07743002474308014
step: 140, loss: 0.05040509253740311
step: 150, loss: 0.0019452422857284546
step: 160, loss: 0.038384564220905304
step: 170, loss: 0.015705270692706108
step: 180, loss: 0.0001696671824902296
step: 190, loss: 0.08007673919200897
step: 200, loss: 9.357435192214325e-05
step: 210, loss: 0.06820984929800034
step: 220, loss: 0.0734277218580246
step: 230, loss: 0.01664133183658123
step: 240, loss: 0.030955670401453972
step: 250, loss: 0.020485922694206238
step: 260, loss: 0.0758252665400505
step: 270, loss: 0.013217216357588768
step: 280, loss: 0.2023555040359497
step: 290, loss: 0.022478483617305756
step: 300, loss: 0.07852370291948318
step: 310, loss: 0.025434980168938637
step: 320, loss: 0.04692505672574043
step: 330, loss: 0.03210245817899704
step: 340, loss: 0.21722577512264252
step: 350, loss: 0.053889404982328415
step: 360, loss: 0.03320881724357605
step: 370, loss: 0.021012376993894577
step: 380, loss: 0.044924430549144745
epoch 10: dev_f1=0.7319587628865978, f1=0.7553191489361701, best_f1=0.7553191489361701
step: 0, loss: 0.03848734870553017
step: 10, loss: 0.16177931427955627
step: 20, loss: 0.05758903920650482
step: 30, loss: 0.01317694503813982
step: 40, loss: 0.01918645016849041
step: 50, loss: 0.011655161157250404
step: 60, loss: 0.008551702834665775
step: 70, loss: 0.01581050083041191
step: 80, loss: 0.04137531667947769
step: 90, loss: 0.06877949833869934
step: 100, loss: 0.040089201182127
step: 110, loss: 0.0015152624109759927
step: 120, loss: 0.07327613234519958
step: 130, loss: 0.020893583074212074
step: 140, loss: 0.023819738999009132
step: 150, loss: 0.012761839665472507
step: 160, loss: 0.017746660858392715
step: 170, loss: 0.01064616721123457
step: 180, loss: 0.009649473242461681
step: 190, loss: 0.002570164855569601
step: 200, loss: 0.02761084772646427
step: 210, loss: 0.03660020977258682
step: 220, loss: 0.0005548046319745481
step: 230, loss: 0.00592021131888032
step: 240, loss: 0.15713822841644287
step: 250, loss: 0.01744293048977852
step: 260, loss: 0.04356730729341507
step: 270, loss: 0.007220393978059292
step: 280, loss: 0.011443192139267921
step: 290, loss: 0.0001194946380564943
step: 300, loss: 0.013642520643770695
step: 310, loss: 0.04086959362030029
step: 320, loss: 0.0664486214518547
step: 330, loss: 0.038972921669483185
step: 340, loss: 0.023746613413095474
step: 350, loss: 0.07387898117303848
step: 360, loss: 0.08282171934843063
step: 370, loss: 0.011136277578771114
step: 380, loss: 0.02693128027021885
epoch 11: dev_f1=0.7317073170731708, f1=0.7365728900255755, best_f1=0.7553191489361701
step: 0, loss: 0.010248618200421333
step: 10, loss: 0.02445962466299534
step: 20, loss: 0.03949248045682907
step: 30, loss: 0.03578461706638336
step: 40, loss: 0.006887081544846296
step: 50, loss: 0.007531685288995504
step: 60, loss: 0.035412296652793884
step: 70, loss: 0.016782915219664574
step: 80, loss: 0.04162614792585373
step: 90, loss: 9.125148062594235e-05
step: 100, loss: 0.017782630398869514
step: 110, loss: 0.002790794475004077
step: 120, loss: 0.043043702840805054
step: 130, loss: 0.019601937383413315
step: 140, loss: 0.021301759406924248
step: 150, loss: 0.03517512232065201
step: 160, loss: 0.20246052742004395
step: 170, loss: 0.023062195628881454
step: 180, loss: 0.0005463763372972608
step: 190, loss: 0.029752466827630997
step: 200, loss: 0.06281279772520065
step: 210, loss: 0.00078776286682114
step: 220, loss: 0.00030694229644723237
step: 230, loss: 0.00012432376388460398
step: 240, loss: 0.05788656696677208
step: 250, loss: 0.035195041447877884
step: 260, loss: 0.05057529732584953
step: 270, loss: 0.051378343254327774
step: 280, loss: 0.008362853899598122
step: 290, loss: 0.01740400120615959
step: 300, loss: 0.02658630907535553
step: 310, loss: 0.0718935951590538
step: 320, loss: 0.020751185715198517
step: 330, loss: 0.021522976458072662
step: 340, loss: 0.0042481557466089725
step: 350, loss: 0.04016708582639694
step: 360, loss: 0.003921968396753073
step: 370, loss: 0.009065302088856697
step: 380, loss: 0.0001485739485360682
epoch 12: dev_f1=0.7231920199501246, f1=0.7296587926509187, best_f1=0.7553191489361701
step: 0, loss: 0.02593526802957058
step: 10, loss: 0.09220191836357117
step: 20, loss: 0.014392168261110783
step: 30, loss: 8.026591967791319e-05
step: 40, loss: 0.038345009088516235
step: 50, loss: 0.04667346179485321
step: 60, loss: 0.0025634958874434233
step: 70, loss: 0.08643300831317902
step: 80, loss: 0.09128398448228836
step: 90, loss: 0.03823894262313843
step: 100, loss: 0.0032797660678625107
step: 110, loss: 0.007367509882897139
step: 120, loss: 0.09588843584060669
step: 130, loss: 0.02207944169640541
step: 140, loss: 0.006349124945700169
step: 150, loss: 0.05633777007460594
step: 160, loss: 0.03640471771359444
step: 170, loss: 0.0006310749449767172
step: 180, loss: 0.053090859204530716
step: 190, loss: 0.002771100727841258
step: 200, loss: 0.03479335084557533
step: 210, loss: 0.022119984030723572
step: 220, loss: 0.05285106971859932
step: 230, loss: 0.004275025334209204
step: 240, loss: 0.0338694266974926
step: 250, loss: 0.000998413423076272
step: 260, loss: 0.028262903913855553
step: 270, loss: 0.0005057930829934776
step: 280, loss: 0.009563329629600048
step: 290, loss: 0.01866769604384899
step: 300, loss: 0.027387691661715508
step: 310, loss: 0.013469649478793144
step: 320, loss: 0.0006116306758485734
step: 330, loss: 0.01830257847905159
step: 340, loss: 0.06156578287482262
step: 350, loss: 0.024545537307858467
step: 360, loss: 0.02450677379965782
step: 370, loss: 0.07030633836984634
step: 380, loss: 0.00014296472363639623
epoch 13: dev_f1=0.733644859813084, f1=0.7304785894206549, best_f1=0.7304785894206549
step: 0, loss: 0.02505236119031906
step: 10, loss: 0.10203855484724045
step: 20, loss: 0.0004420905315782875
step: 30, loss: 0.04471395164728165
step: 40, loss: 0.011172821745276451
step: 50, loss: 0.02530287578701973
step: 60, loss: 0.0013685491867363453
step: 70, loss: 0.08124875277280807
step: 80, loss: 0.0008927862509153783
step: 90, loss: 8.124783198582008e-05
step: 100, loss: 0.0014794041635468602
step: 110, loss: 0.0012684863759204745
step: 120, loss: 0.017620712518692017
step: 130, loss: 0.0043334015645086765
step: 140, loss: 0.047429196536540985
step: 150, loss: 0.0019736243411898613
step: 160, loss: 0.00583374360576272
step: 170, loss: 0.001469676150009036
step: 180, loss: 0.17372216284275055
step: 190, loss: 0.014246667735278606
step: 200, loss: 0.011731341481208801
step: 210, loss: 0.05763856694102287
step: 220, loss: 0.009155720472335815
step: 230, loss: 0.026033926755189896
step: 240, loss: 0.08428316563367844
step: 250, loss: 0.02292442135512829
step: 260, loss: 0.08838736265897751
step: 270, loss: 0.023596765473484993
step: 280, loss: 0.008665175177156925
step: 290, loss: 0.00044739129953086376
step: 300, loss: 0.008369144052267075
step: 310, loss: 0.07199186086654663
step: 320, loss: 0.009004653431475163
step: 330, loss: 0.03781002759933472
step: 340, loss: 0.05737766996026039
step: 350, loss: 0.026241671293973923
step: 360, loss: 0.05687057226896286
step: 370, loss: 0.09975357353687286
step: 380, loss: 0.03866679593920708
epoch 14: dev_f1=0.7030878859857482, f1=0.7132169576059851, best_f1=0.7304785894206549
step: 0, loss: 0.0011752779828384519
step: 10, loss: 0.00012981280451640487
step: 20, loss: 0.09146586060523987
step: 30, loss: 0.0547591857612133
step: 40, loss: 0.023747514933347702
step: 50, loss: 0.015560157597064972
step: 60, loss: 0.00369471637532115
step: 70, loss: 0.03381025418639183
step: 80, loss: 0.0037335422821342945
step: 90, loss: 0.04165396839380264
step: 100, loss: 0.0060757906176149845
step: 110, loss: 0.03646978363394737
step: 120, loss: 0.03298385441303253
step: 130, loss: 0.0038656829856336117
step: 140, loss: 0.03133454546332359
step: 150, loss: 0.0018822719575837255
step: 160, loss: 0.023672455921769142
step: 170, loss: 0.056537069380283356
step: 180, loss: 0.015783842653036118
step: 190, loss: 0.019190730527043343
step: 200, loss: 0.00039553758688271046
step: 210, loss: 0.08479639887809753
step: 220, loss: 0.021854059770703316
step: 230, loss: 0.00039997161366045475
step: 240, loss: 0.0011705562938004732
step: 250, loss: 0.012723312713205814
step: 260, loss: 0.0024327735882252455
step: 270, loss: 0.0004602840926963836
step: 280, loss: 0.015152794308960438
step: 290, loss: 0.0212356336414814
step: 300, loss: 0.010342651978135109
step: 310, loss: 0.004028111230581999
step: 320, loss: 0.00010398450831416994
step: 330, loss: 0.02943611703813076
step: 340, loss: 0.001128820818848908
step: 350, loss: 0.0081268809735775
step: 360, loss: 0.03528324514627457
step: 370, loss: 0.00014323224604595453
step: 380, loss: 0.018977617844939232
epoch 15: dev_f1=0.6970509383378016, f1=0.7182320441988949, best_f1=0.7304785894206549
step: 0, loss: 0.03259332850575447
step: 10, loss: 9.546514775138348e-05
step: 20, loss: 0.00823100283741951
step: 30, loss: 0.0961199477314949
step: 40, loss: 0.0010509379208087921
step: 50, loss: 0.03065636195242405
step: 60, loss: 0.00012110635725548491
step: 70, loss: 0.045632604509592056
step: 80, loss: 0.00017140207637567073
step: 90, loss: 0.022842464968562126
step: 100, loss: 0.035578519105911255
step: 110, loss: 0.015377791598439217
step: 120, loss: 0.0009239653591066599
step: 130, loss: 0.035005468875169754
step: 140, loss: 0.0459149032831192
step: 150, loss: 0.026798320934176445
step: 160, loss: 0.009423349983990192
step: 170, loss: 0.03904707357287407
step: 180, loss: 0.004491818603128195
step: 190, loss: 0.005388106219470501
step: 200, loss: 0.001997309736907482
step: 210, loss: 0.05310240387916565
step: 220, loss: 0.027664542198181152
step: 230, loss: 0.01788225583732128
step: 240, loss: 0.02159719355404377
step: 250, loss: 0.005765758920460939
step: 260, loss: 0.012957257218658924
step: 270, loss: 0.09644103050231934
step: 280, loss: 0.011846083216369152
step: 290, loss: 4.64634140371345e-05
step: 300, loss: 0.001011202111840248
step: 310, loss: 0.05372963100671768
step: 320, loss: 0.006016708444803953
step: 330, loss: 0.003094511339440942
step: 340, loss: 0.004748655948787928
step: 350, loss: 0.0003946735232602805
step: 360, loss: 0.013957173563539982
step: 370, loss: 0.06315406411886215
step: 380, loss: 0.02644849196076393
epoch 16: dev_f1=0.7230769230769232, f1=0.7446808510638299, best_f1=0.7304785894206549
step: 0, loss: 0.000726880447473377
step: 10, loss: 0.015764040872454643
step: 20, loss: 0.002812206745147705
step: 30, loss: 0.00017837689665611833
step: 40, loss: 0.02805214747786522
step: 50, loss: 0.02132575958967209
step: 60, loss: 0.00016074508312158287
step: 70, loss: 0.01673850230872631
step: 80, loss: 0.02566009946167469
step: 90, loss: 0.03088463470339775
step: 100, loss: 0.0024544233456254005
step: 110, loss: 0.0730285719037056
step: 120, loss: 0.017601652070879936
step: 130, loss: 0.0016796458512544632
step: 140, loss: 0.0005861697718501091
step: 150, loss: 0.021153774112462997
step: 160, loss: 0.051846448332071304
step: 170, loss: 0.0014791392022743821
step: 180, loss: 0.00018330421880818903
step: 190, loss: 0.0451134629547596
step: 200, loss: 0.0025780098512768745
step: 210, loss: 0.07507851719856262
step: 220, loss: 0.05091254040598869
step: 230, loss: 0.06915940344333649
step: 240, loss: 0.00022218031517695636
step: 250, loss: 0.0009002687875181437
step: 260, loss: 0.02744782716035843
step: 270, loss: 0.005352851469069719
step: 280, loss: 0.0018516520503908396
step: 290, loss: 0.00030479999259114265
step: 300, loss: 0.021024955436587334
step: 310, loss: 0.03695327788591385
step: 320, loss: 0.001136859180405736
step: 330, loss: 0.06994666159152985
step: 340, loss: 0.052501872181892395
step: 350, loss: 9.221979416906834e-05
step: 360, loss: 0.0014609992504119873
step: 370, loss: 0.006917070131748915
step: 380, loss: 0.08109792321920395
epoch 17: dev_f1=0.7238605898123326, f1=0.7407407407407407, best_f1=0.7304785894206549
step: 0, loss: 0.023339439183473587
step: 10, loss: 0.04048372805118561
step: 20, loss: 0.0003878475690726191
step: 30, loss: 0.05209515243768692
step: 40, loss: 0.009542297571897507
step: 50, loss: 0.033545009791851044
step: 60, loss: 0.05521295964717865
step: 70, loss: 0.034936606884002686
step: 80, loss: 0.0018671432044357061
step: 90, loss: 0.03721049800515175
step: 100, loss: 0.0006805550074204803
step: 110, loss: 0.022769076749682426
step: 120, loss: 0.0005198170547373593
step: 130, loss: 0.012017443776130676
step: 140, loss: 0.0026879082433879375
step: 150, loss: 0.0015396738890558481
step: 160, loss: 0.0001119553271564655
step: 170, loss: 0.06247450038790703
step: 180, loss: 0.008935971185564995
step: 190, loss: 0.03268241509795189
step: 200, loss: 0.030237603932619095
step: 210, loss: 0.0003668801800813526
step: 220, loss: 0.04240981116890907
step: 230, loss: 0.005701226182281971
step: 240, loss: 0.003831879934296012
step: 250, loss: 4.622105188900605e-05
step: 260, loss: 0.020101336762309074
step: 270, loss: 0.00023262658214662224
step: 280, loss: 0.0020506505388766527
step: 290, loss: 0.018469426780939102
step: 300, loss: 0.008414411917328835
step: 310, loss: 0.002956371521577239
step: 320, loss: 0.0007532357703894377
step: 330, loss: 8.360610081581399e-05
step: 340, loss: 0.005226695444434881
step: 350, loss: 0.00016606837743893266
step: 360, loss: 0.029372090473771095
step: 370, loss: 0.0009620393975637853
step: 380, loss: 0.010920146480202675
epoch 18: dev_f1=0.7120418848167539, f1=0.7176781002638523, best_f1=0.7304785894206549
step: 0, loss: 0.01073487475514412
step: 10, loss: 0.003895105794072151
step: 20, loss: 0.0190618634223938
step: 30, loss: 0.009682267904281616
step: 40, loss: 0.0009862283477559686
step: 50, loss: 0.032263029366731644
step: 60, loss: 0.0001588985469425097
step: 70, loss: 0.03149766847491264
step: 80, loss: 5.9889072872465476e-05
step: 90, loss: 0.00010345163900637999
step: 100, loss: 0.02484099380671978
step: 110, loss: 0.00011500078835524619
step: 120, loss: 0.03528805077075958
step: 130, loss: 0.021814653649926186
step: 140, loss: 8.404949767282233e-05
step: 150, loss: 0.09344186633825302
step: 160, loss: 0.015519958920776844
step: 170, loss: 0.016595475375652313
step: 180, loss: 0.013605285435914993
step: 190, loss: 0.01135331578552723
step: 200, loss: 0.036017045378685
step: 210, loss: 0.08884534239768982
step: 220, loss: 0.00023062658146955073
step: 230, loss: 0.06477595865726471
step: 240, loss: 0.025251232087612152
step: 250, loss: 0.0018804362043738365
step: 260, loss: 6.029602445778437e-05
step: 270, loss: 0.00020515215874183923
step: 280, loss: 0.00038705780752934515
step: 290, loss: 0.06110437214374542
step: 300, loss: 0.011061280965805054
step: 310, loss: 4.8060057451948524e-05
step: 320, loss: 0.0003712828329298645
step: 330, loss: 0.004559502936899662
step: 340, loss: 0.000424901518272236
step: 350, loss: 0.0766504555940628
step: 360, loss: 0.06478750705718994
step: 370, loss: 0.016233598813414574
step: 380, loss: 0.049776677042245865
epoch 19: dev_f1=0.7098445595854923, f1=0.7142857142857143, best_f1=0.7304785894206549
step: 0, loss: 0.0001233293442055583
step: 10, loss: 0.0002462028351146728
step: 20, loss: 0.00029074790654703975
step: 30, loss: 0.00010062215005746111
step: 40, loss: 4.51854029961396e-05
step: 50, loss: 0.006903322879225016
step: 60, loss: 4.2731044231913984e-05
step: 70, loss: 0.0220777690410614
step: 80, loss: 0.017773013561964035
step: 90, loss: 0.02421991154551506
step: 100, loss: 0.010675385594367981
step: 110, loss: 0.006614957004785538
step: 120, loss: 6.283660331973806e-05
step: 130, loss: 0.01747998781502247
step: 140, loss: 0.016375059261918068
step: 150, loss: 0.05414688214659691
step: 160, loss: 0.00010980450315400958
step: 170, loss: 0.0068253627978265285
step: 180, loss: 0.0024277784395962954
step: 190, loss: 0.007508851587772369
step: 200, loss: 0.019364269450306892
step: 210, loss: 0.01010132022202015
step: 220, loss: 0.0003962968476116657
step: 230, loss: 6.301965186139569e-05
step: 240, loss: 0.04274487867951393
step: 250, loss: 5.347149999579415e-05
step: 260, loss: 0.0009517771541140974
step: 270, loss: 0.0001632868661545217
step: 280, loss: 0.002115848707035184
step: 290, loss: 0.00092047214275226
step: 300, loss: 0.008847933262586594
step: 310, loss: 0.020234234631061554
step: 320, loss: 5.109918856760487e-05
step: 330, loss: 0.00027690635761246085
step: 340, loss: 0.0030597462318837643
step: 350, loss: 8.74782563187182e-05
step: 360, loss: 0.0005947122699581087
step: 370, loss: 0.0003393508668523282
step: 380, loss: 0.0642932802438736
epoch 20: dev_f1=0.7176781002638523, f1=0.7154471544715448, best_f1=0.7304785894206549
