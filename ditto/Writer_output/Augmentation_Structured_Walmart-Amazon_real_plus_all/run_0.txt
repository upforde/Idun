cuda
Device: cuda
step: 0, loss: 0.7071710228919983
step: 10, loss: 0.23398011922836304
step: 20, loss: 0.4910453259944916
step: 30, loss: 0.4358225464820862
step: 40, loss: 0.316955029964447
step: 50, loss: 0.6326245665550232
step: 60, loss: 0.2543114125728607
step: 70, loss: 0.3825150430202484
step: 80, loss: 0.1548418253660202
step: 90, loss: 0.37275171279907227
step: 100, loss: 0.14401699602603912
step: 110, loss: 0.19446994364261627
step: 120, loss: 0.22976230084896088
step: 130, loss: 0.22254687547683716
step: 140, loss: 0.3961468040943146
step: 150, loss: 0.24476759135723114
step: 160, loss: 0.19489295780658722
step: 170, loss: 0.2026725858449936
step: 180, loss: 0.15226329863071442
step: 190, loss: 0.2755865156650543
step: 200, loss: 0.17385771870613098
step: 210, loss: 0.2151225507259369
step: 220, loss: 0.20009909570217133
step: 230, loss: 0.3346008360385895
step: 240, loss: 0.16214413940906525
step: 250, loss: 0.24519363045692444
step: 260, loss: 0.27127596735954285
step: 270, loss: 0.22466941177845
step: 280, loss: 0.16532738506793976
step: 290, loss: 0.27174001932144165
step: 300, loss: 0.31146439909935
step: 310, loss: 0.20131228864192963
step: 320, loss: 0.0529116615653038
step: 330, loss: 0.22195446491241455
step: 340, loss: 0.1353156417608261
step: 350, loss: 0.11057905852794647
step: 360, loss: 0.0179155170917511
step: 370, loss: 0.10829199105501175
step: 380, loss: 0.13559162616729736
epoch 1: dev_f1=0.5685785536159601, f1=0.5609756097560977, best_f1=0.5609756097560977
step: 0, loss: 0.16734282672405243
step: 10, loss: 0.13246305286884308
step: 20, loss: 0.19688044488430023
step: 30, loss: 0.1961582601070404
step: 40, loss: 0.16340230405330658
step: 50, loss: 0.16665764153003693
step: 60, loss: 0.21049416065216064
step: 70, loss: 0.35769587755203247
step: 80, loss: 0.09958257526159286
step: 90, loss: 0.1225959062576294
step: 100, loss: 0.17992395162582397
step: 110, loss: 0.07126840949058533
step: 120, loss: 0.17530669271945953
step: 130, loss: 0.16399595141410828
step: 140, loss: 0.10872386395931244
step: 150, loss: 0.003345229895785451
step: 160, loss: 0.11628460884094238
step: 170, loss: 0.08780619502067566
step: 180, loss: 0.247977152466774
step: 190, loss: 0.07736941426992416
step: 200, loss: 0.1055455356836319
step: 210, loss: 0.08213184028863907
step: 220, loss: 0.22317075729370117
step: 230, loss: 0.1259387731552124
step: 240, loss: 0.25253814458847046
step: 250, loss: 0.13265788555145264
step: 260, loss: 0.11219947785139084
step: 270, loss: 0.18382790684700012
step: 280, loss: 0.10305853933095932
step: 290, loss: 0.14892993867397308
step: 300, loss: 0.07574555277824402
step: 310, loss: 0.1440402865409851
step: 320, loss: 0.2264225333929062
step: 330, loss: 0.13404476642608643
step: 340, loss: 0.10273629426956177
step: 350, loss: 0.16029368340969086
step: 360, loss: 0.05403345078229904
step: 370, loss: 0.04903460294008255
step: 380, loss: 0.04462743178009987
epoch 2: dev_f1=0.5910290237467019, f1=0.6424870466321243, best_f1=0.6424870466321243
step: 0, loss: 0.12121152132749557
step: 10, loss: 0.1269891858100891
step: 20, loss: 0.15348844230175018
step: 30, loss: 0.10859033465385437
step: 40, loss: 0.09041775017976761
step: 50, loss: 0.15669067203998566
step: 60, loss: 0.06338043510913849
step: 70, loss: 0.015723612159490585
step: 80, loss: 0.12635551393032074
step: 90, loss: 0.19116351008415222
step: 100, loss: 0.20944169163703918
step: 110, loss: 0.057443514466285706
step: 120, loss: 0.08706125617027283
step: 130, loss: 0.08606450259685516
step: 140, loss: 0.08359076827764511
step: 150, loss: 0.08686110377311707
step: 160, loss: 0.17727269232273102
step: 170, loss: 0.26091820001602173
step: 180, loss: 0.04962287098169327
step: 190, loss: 0.07861584424972534
step: 200, loss: 0.05790529027581215
step: 210, loss: 0.19126884639263153
step: 220, loss: 0.14322294294834137
step: 230, loss: 0.07199624180793762
step: 240, loss: 0.08570742607116699
step: 250, loss: 0.0991409420967102
step: 260, loss: 0.023366570472717285
step: 270, loss: 0.013301468454301357
step: 280, loss: 0.17196010053157806
step: 290, loss: 0.12324538081884384
step: 300, loss: 0.11868704110383987
step: 310, loss: 0.062096480280160904
step: 320, loss: 0.04890908673405647
step: 330, loss: 0.26865530014038086
step: 340, loss: 0.05306767299771309
step: 350, loss: 0.14211077988147736
step: 360, loss: 0.05958504602313042
step: 370, loss: 0.02448318898677826
step: 380, loss: 0.04163519665598869
epoch 3: dev_f1=0.6421052631578948, f1=0.7037037037037037, best_f1=0.7037037037037037
step: 0, loss: 0.17579101026058197
step: 10, loss: 0.16737067699432373
step: 20, loss: 0.02980809286236763
step: 30, loss: 0.06435254961252213
step: 40, loss: 0.054792001843452454
step: 50, loss: 0.040890634059906006
step: 60, loss: 0.0901864767074585
step: 70, loss: 0.05883817747235298
step: 80, loss: 0.04129992425441742
step: 90, loss: 0.028661372140049934
step: 100, loss: 0.052293162792921066
step: 110, loss: 0.026277514174580574
step: 120, loss: 0.031030816957354546
step: 130, loss: 0.01399029977619648
step: 140, loss: 0.04004824906587601
step: 150, loss: 0.06551207602024078
step: 160, loss: 0.04952647536993027
step: 170, loss: 0.13631223142147064
step: 180, loss: 0.023266876116394997
step: 190, loss: 0.0996333509683609
step: 200, loss: 0.0931876003742218
step: 210, loss: 0.1525515466928482
step: 220, loss: 0.05024118348956108
step: 230, loss: 0.1319044679403305
step: 240, loss: 0.07066212594509125
step: 250, loss: 0.07205258309841156
step: 260, loss: 0.06740421056747437
step: 270, loss: 0.06810156255960464
step: 280, loss: 0.0020209585782140493
step: 290, loss: 0.1062389388680458
step: 300, loss: 0.0065271370112895966
step: 310, loss: 0.06358355283737183
step: 320, loss: 0.03250102698802948
step: 330, loss: 0.07725431025028229
step: 340, loss: 0.12479294091463089
step: 350, loss: 0.2026611715555191
step: 360, loss: 0.06248846277594566
step: 370, loss: 0.0588616244494915
step: 380, loss: 0.04756151884794235
epoch 4: dev_f1=0.6366197183098592, f1=0.6422535211267607, best_f1=0.7037037037037037
step: 0, loss: 0.00957503542304039
step: 10, loss: 0.13803815841674805
step: 20, loss: 0.058646805584430695
step: 30, loss: 0.08109410107135773
step: 40, loss: 0.011833940632641315
step: 50, loss: 0.06205609813332558
step: 60, loss: 0.06273438781499863
step: 70, loss: 0.04529140517115593
step: 80, loss: 0.03316477686166763
step: 90, loss: 0.04500262439250946
step: 100, loss: 0.01720978505909443
step: 110, loss: 0.044276077300310135
step: 120, loss: 0.05405653640627861
step: 130, loss: 0.27888980507850647
step: 140, loss: 0.0008258811431005597
step: 150, loss: 0.00113688874989748
step: 160, loss: 0.14533951878547668
step: 170, loss: 0.0412023700773716
step: 180, loss: 0.06822782754898071
step: 190, loss: 0.1034073531627655
step: 200, loss: 0.12155789136886597
step: 210, loss: 0.02809777297079563
step: 220, loss: 0.05311504378914833
step: 230, loss: 0.003342130919918418
step: 240, loss: 0.03757800906896591
step: 250, loss: 0.05816756188869476
step: 260, loss: 0.06858754903078079
step: 270, loss: 0.03858982026576996
step: 280, loss: 0.09797441214323044
step: 290, loss: 0.0948483794927597
step: 300, loss: 0.059303272515535355
step: 310, loss: 0.024096298962831497
step: 320, loss: 0.05007552355527878
step: 330, loss: 0.0025394135154783726
step: 340, loss: 0.03723923861980438
step: 350, loss: 0.07229394465684891
step: 360, loss: 0.06085933372378349
step: 370, loss: 0.11586172133684158
step: 380, loss: 0.09763575345277786
epoch 5: dev_f1=0.6511627906976744, f1=0.6588785046728972, best_f1=0.6588785046728972
step: 0, loss: 0.01669231243431568
step: 10, loss: 0.04005143791437149
step: 20, loss: 0.08874033391475677
step: 30, loss: 0.06266967207193375
step: 40, loss: 0.0038592687342315912
step: 50, loss: 0.007188653573393822
step: 60, loss: 0.043911878019571304
step: 70, loss: 0.011007946915924549
step: 80, loss: 0.0015574340941384435
step: 90, loss: 0.014600223861634731
step: 100, loss: 0.11652389913797379
step: 110, loss: 0.05232545733451843
step: 120, loss: 0.00021460317657329142
step: 130, loss: 0.026763679459691048
step: 140, loss: 0.04569002985954285
step: 150, loss: 0.04062431678175926
step: 160, loss: 0.053250111639499664
step: 170, loss: 0.054452940821647644
step: 180, loss: 0.021541863679885864
step: 190, loss: 0.0053751301020383835
step: 200, loss: 0.05351973697543144
step: 210, loss: 0.00883792620152235
step: 220, loss: 0.02981821820139885
step: 230, loss: 0.172322615981102
step: 240, loss: 0.027639318257570267
step: 250, loss: 0.05600166693329811
step: 260, loss: 0.023879509419202805
step: 270, loss: 0.037419166415929794
step: 280, loss: 0.078832246363163
step: 290, loss: 0.10606793314218521
step: 300, loss: 0.011749910190701485
step: 310, loss: 0.09964445978403091
step: 320, loss: 0.12473499029874802
step: 330, loss: 0.019843198359012604
step: 340, loss: 0.026353901252150536
step: 350, loss: 0.09163995087146759
step: 360, loss: 0.13874848186969757
step: 370, loss: 0.10669145733118057
step: 380, loss: 0.07649658620357513
epoch 6: dev_f1=0.6752577319587627, f1=0.7098445595854923, best_f1=0.7098445595854923
step: 0, loss: 0.030301691964268684
step: 10, loss: 0.0004544856783468276
step: 20, loss: 0.0374172143638134
step: 30, loss: 0.04014311358332634
step: 40, loss: 0.08744090795516968
step: 50, loss: 0.03234280273318291
step: 60, loss: 0.0001468951813876629
step: 70, loss: 0.2569466531276703
step: 80, loss: 0.0028877598233520985
step: 90, loss: 0.02140728011727333
step: 100, loss: 0.014816141687333584
step: 110, loss: 0.11175242811441422
step: 120, loss: 0.006057505030184984
step: 130, loss: 0.031365446746349335
step: 140, loss: 0.0859508365392685
step: 150, loss: 0.034064892679452896
step: 160, loss: 0.025248223915696144
step: 170, loss: 0.024042446166276932
step: 180, loss: 0.0034819329157471657
step: 190, loss: 0.024206994101405144
step: 200, loss: 0.058156389743089676
step: 210, loss: 0.055208053439855576
step: 220, loss: 0.011646476574242115
step: 230, loss: 0.018022574484348297
step: 240, loss: 0.0010437233140692115
step: 250, loss: 0.011610089801251888
step: 260, loss: 0.2462940812110901
step: 270, loss: 0.08185932040214539
step: 280, loss: 0.040992408990859985
step: 290, loss: 0.07358511537313461
step: 300, loss: 0.10057351738214493
step: 310, loss: 0.06111754849553108
step: 320, loss: 0.02640153281390667
step: 330, loss: 0.20699384808540344
step: 340, loss: 0.01584879495203495
step: 350, loss: 0.030081965029239655
step: 360, loss: 0.15327855944633484
step: 370, loss: 0.13396258652210236
step: 380, loss: 0.01118579600006342
epoch 7: dev_f1=0.689119170984456, f1=0.6790450928381963, best_f1=0.6790450928381963
step: 0, loss: 0.010743443854153156
step: 10, loss: 0.010754860006272793
step: 20, loss: 0.039961524307727814
step: 30, loss: 0.08680441975593567
step: 40, loss: 0.008515017107129097
step: 50, loss: 0.011407210491597652
step: 60, loss: 0.04663117974996567
step: 70, loss: 0.046327825635671616
step: 80, loss: 0.06146179512143135
step: 90, loss: 0.000255480787018314
step: 100, loss: 0.019775845110416412
step: 110, loss: 0.010715455748140812
step: 120, loss: 0.09593790769577026
step: 130, loss: 0.0027698390185832977
step: 140, loss: 0.011125320568680763
step: 150, loss: 0.07193952798843384
step: 160, loss: 0.02195194736123085
step: 170, loss: 0.00750460522249341
step: 180, loss: 0.03799285739660263
step: 190, loss: 0.012436971068382263
step: 200, loss: 0.04692192003130913
step: 210, loss: 0.06552378088235855
step: 220, loss: 0.06008239835500717
step: 230, loss: 0.13699588179588318
step: 240, loss: 0.056223541498184204
step: 250, loss: 0.03044094331562519
step: 260, loss: 0.02434523031115532
step: 270, loss: 0.10215863585472107
step: 280, loss: 0.01967070810496807
step: 290, loss: 0.03578926622867584
step: 300, loss: 0.04600148648023605
step: 310, loss: 0.034791719168424606
step: 320, loss: 0.012730743736028671
step: 330, loss: 0.0723893940448761
step: 340, loss: 0.05108802393078804
step: 350, loss: 0.058479052037000656
step: 360, loss: 0.0016442005289718509
step: 370, loss: 0.05421578511595726
step: 380, loss: 0.13659915328025818
epoch 8: dev_f1=0.6898263027295285, f1=0.7041564792176039, best_f1=0.7041564792176039
step: 0, loss: 0.0037327378522604704
step: 10, loss: 0.006551056634634733
step: 20, loss: 0.025482745841145515
step: 30, loss: 0.014761518687009811
step: 40, loss: 0.030379626899957657
step: 50, loss: 0.00931349117308855
step: 60, loss: 0.260376513004303
step: 70, loss: 0.006980471312999725
step: 80, loss: 0.06922835111618042
step: 90, loss: 0.010130916722118855
step: 100, loss: 0.06116662919521332
step: 110, loss: 0.006326742935925722
step: 120, loss: 0.1064080223441124
step: 130, loss: 0.019267596304416656
step: 140, loss: 0.06235772371292114
step: 150, loss: 0.09001020342111588
step: 160, loss: 0.05845958739519119
step: 170, loss: 0.002257956424728036
step: 180, loss: 0.05056888982653618
step: 190, loss: 0.03313850238919258
step: 200, loss: 0.04279700294137001
step: 210, loss: 0.004734874237328768
step: 220, loss: 0.029031598940491676
step: 230, loss: 0.04182373359799385
step: 240, loss: 0.03505539521574974
step: 250, loss: 0.028146909549832344
step: 260, loss: 0.08276413381099701
step: 270, loss: 0.038331642746925354
step: 280, loss: 0.007211168296635151
step: 290, loss: 0.06257998198270798
step: 300, loss: 0.1346927285194397
step: 310, loss: 0.003915719222277403
step: 320, loss: 0.035294920206069946
step: 330, loss: 0.00020936816872563213
step: 340, loss: 0.0015859582927078009
step: 350, loss: 0.019017711281776428
step: 360, loss: 0.23717448115348816
step: 370, loss: 0.01783815212547779
step: 380, loss: 0.03267570957541466
epoch 9: dev_f1=0.6571428571428571, f1=0.6792452830188679, best_f1=0.7041564792176039
step: 0, loss: 0.014810239896178246
step: 10, loss: 0.04064051806926727
step: 20, loss: 0.03167293965816498
step: 30, loss: 0.001430155010893941
step: 40, loss: 0.022921249270439148
step: 50, loss: 0.015266436152160168
step: 60, loss: 0.013584909960627556
step: 70, loss: 0.0005580537836067379
step: 80, loss: 0.023323731496930122
step: 90, loss: 0.014607233926653862
step: 100, loss: 7.601684774272144e-05
step: 110, loss: 0.09510154277086258
step: 120, loss: 0.09094523638486862
step: 130, loss: 0.008790044113993645
step: 140, loss: 0.02462664246559143
step: 150, loss: 0.0025603577960282564
step: 160, loss: 0.003088000463321805
step: 170, loss: 0.04985031485557556
step: 180, loss: 0.0486823171377182
step: 190, loss: 0.003476575016975403
step: 200, loss: 0.016110584139823914
step: 210, loss: 0.018611470237374306
step: 220, loss: 0.09107988327741623
step: 230, loss: 0.04637230187654495
step: 240, loss: 0.005746745970100164
step: 250, loss: 0.01929355226457119
step: 260, loss: 0.007039900869131088
step: 270, loss: 0.02849261462688446
step: 280, loss: 0.03784125670790672
step: 290, loss: 0.02965429797768593
step: 300, loss: 0.0254172645509243
step: 310, loss: 0.0415736585855484
step: 320, loss: 0.06280126422643661
step: 330, loss: 0.05129888653755188
step: 340, loss: 0.019788336008787155
step: 350, loss: 0.033422354608774185
step: 360, loss: 0.13739486038684845
step: 370, loss: 0.05866816267371178
step: 380, loss: 0.0014686075737699866
epoch 10: dev_f1=0.6798029556650247, f1=0.7005076142131978, best_f1=0.7041564792176039
step: 0, loss: 0.014061074703931808
step: 10, loss: 0.03300287202000618
step: 20, loss: 0.015005121938884258
step: 30, loss: 0.04063013941049576
step: 40, loss: 0.028540408238768578
step: 50, loss: 0.002962094498798251
step: 60, loss: 8.801667718216777e-05
step: 70, loss: 8.301741036120802e-05
step: 80, loss: 0.029692450538277626
step: 90, loss: 0.015008395537734032
step: 100, loss: 0.011446740478277206
step: 110, loss: 0.00023595291713718325
step: 120, loss: 0.02388092502951622
step: 130, loss: 0.013962822034955025
step: 140, loss: 0.005609010346233845
step: 150, loss: 0.017034543678164482
step: 160, loss: 0.004077997524291277
step: 170, loss: 0.07472361624240875
step: 180, loss: 0.153962641954422
step: 190, loss: 0.0863603726029396
step: 200, loss: 0.007491953205317259
step: 210, loss: 0.0024454749654978514
step: 220, loss: 0.007204547990113497
step: 230, loss: 0.002941262209787965
step: 240, loss: 0.059530578553676605
step: 250, loss: 0.07926075905561447
step: 260, loss: 0.05418328568339348
step: 270, loss: 0.017992869019508362
step: 280, loss: 0.01354680210351944
step: 290, loss: 0.0003993573773186654
step: 300, loss: 0.00970806647092104
step: 310, loss: 0.045907627791166306
step: 320, loss: 0.0036770026199519634
step: 330, loss: 0.06593634933233261
step: 340, loss: 0.12338237464427948
step: 350, loss: 0.00025309206102974713
step: 360, loss: 0.029229789972305298
step: 370, loss: 0.0029375648591667414
step: 380, loss: 0.021718662232160568
epoch 11: dev_f1=0.6786632390745502, f1=0.6954177897574124, best_f1=0.7041564792176039
step: 0, loss: 0.004192146006971598
step: 10, loss: 0.08122453838586807
step: 20, loss: 0.009816525503993034
step: 30, loss: 0.00986243225634098
step: 40, loss: 0.03310807794332504
step: 50, loss: 0.007733138278126717
step: 60, loss: 0.003966704476624727
step: 70, loss: 0.006824848707765341
step: 80, loss: 0.02076694183051586
step: 90, loss: 0.10095193982124329
step: 100, loss: 0.014596429653465748
step: 110, loss: 0.07798280566930771
step: 120, loss: 0.054893191903829575
step: 130, loss: 0.0020727280061692
step: 140, loss: 0.020505670458078384
step: 150, loss: 0.06138037145137787
step: 160, loss: 0.04694811627268791
step: 170, loss: 0.0173809714615345
step: 180, loss: 0.03321042284369469
step: 190, loss: 0.021530630066990852
step: 200, loss: 0.04039253294467926
step: 210, loss: 0.022767875343561172
step: 220, loss: 0.022600580006837845
step: 230, loss: 0.0009334784699603915
step: 240, loss: 0.04658235237002373
step: 250, loss: 0.015426287427544594
step: 260, loss: 0.001296746195293963
step: 270, loss: 0.035126883536577225
step: 280, loss: 0.10326279699802399
step: 290, loss: 0.00012264287215657532
step: 300, loss: 0.04036363959312439
step: 310, loss: 0.018398594111204147
step: 320, loss: 0.08235431462526321
step: 330, loss: 0.00813098344951868
step: 340, loss: 0.004176770336925983
step: 350, loss: 0.04842875525355339
step: 360, loss: 0.09459927678108215
step: 370, loss: 7.717718108324334e-05
step: 380, loss: 0.0024035584647208452
epoch 12: dev_f1=0.6889952153110047, f1=0.7250608272506084, best_f1=0.7041564792176039
step: 0, loss: 0.036043811589479446
step: 10, loss: 0.13922546803951263
step: 20, loss: 0.009289531968533993
step: 30, loss: 0.007448877673596144
step: 40, loss: 0.013503835536539555
step: 50, loss: 0.07753469049930573
step: 60, loss: 0.0005469508469104767
step: 70, loss: 0.03688104450702667
step: 80, loss: 0.015667671337723732
step: 90, loss: 0.005242510698735714
step: 100, loss: 8.643829642096534e-05
step: 110, loss: 0.00014703316264785826
step: 120, loss: 0.04486781358718872
step: 130, loss: 0.003432722296565771
step: 140, loss: 0.00015712654567323625
step: 150, loss: 0.03874678164720535
step: 160, loss: 0.020519688725471497
step: 170, loss: 0.005194667261093855
step: 180, loss: 0.008846151642501354
step: 190, loss: 0.07678408920764923
step: 200, loss: 0.010100317187607288
step: 210, loss: 6.315008795354515e-05
step: 220, loss: 0.026398032903671265
step: 230, loss: 0.022867461666464806
step: 240, loss: 0.0004934578901156783
step: 250, loss: 0.0011879104422405362
step: 260, loss: 0.011886373162269592
step: 270, loss: 0.02020987495779991
step: 280, loss: 0.006348627619445324
step: 290, loss: 0.024775676429271698
step: 300, loss: 0.0010985186090692878
step: 310, loss: 0.0022808911744505167
step: 320, loss: 0.012785461731255054
step: 330, loss: 0.0002426608552923426
step: 340, loss: 0.03597226366400719
step: 350, loss: 0.06234176456928253
step: 360, loss: 0.032889991998672485
step: 370, loss: 0.002146925777196884
step: 380, loss: 0.002946911146864295
epoch 13: dev_f1=0.6844660194174758, f1=0.6819338422391857, best_f1=0.7041564792176039
step: 0, loss: 0.05205642804503441
step: 10, loss: 0.0024563365150243044
step: 20, loss: 0.03641509264707565
step: 30, loss: 0.006487817037850618
step: 40, loss: 0.0009880972793325782
step: 50, loss: 0.00028191215824335814
step: 60, loss: 0.017445746809244156
step: 70, loss: 9.715434862300754e-05
step: 80, loss: 0.011059408076107502
step: 90, loss: 0.0003505617496557534
step: 100, loss: 0.037846341729164124
step: 110, loss: 0.0004247685137670487
step: 120, loss: 0.0004461233620531857
step: 130, loss: 0.010751299560070038
step: 140, loss: 0.015728071331977844
step: 150, loss: 0.0019204870332032442
step: 160, loss: 0.09681735187768936
step: 170, loss: 0.021255768835544586
step: 180, loss: 0.008463801816105843
step: 190, loss: 0.00264832959510386
step: 200, loss: 7.17618822818622e-05
step: 210, loss: 0.02551320753991604
step: 220, loss: 0.03474798798561096
step: 230, loss: 0.0025185225531458855
step: 240, loss: 0.028642727062106133
step: 250, loss: 0.03613370656967163
step: 260, loss: 0.0028620462398976088
step: 270, loss: 0.02950073406100273
step: 280, loss: 0.033502910286188126
step: 290, loss: 0.00408649817109108
step: 300, loss: 0.032342880964279175
step: 310, loss: 0.019342884421348572
step: 320, loss: 0.0471465177834034
step: 330, loss: 0.033064354211091995
step: 340, loss: 0.0642501562833786
step: 350, loss: 0.0034353083465248346
step: 360, loss: 0.03931874781847
step: 370, loss: 0.016054822131991386
step: 380, loss: 0.030138196423649788
epoch 14: dev_f1=0.6811989100817438, f1=0.6759002770083102, best_f1=0.7041564792176039
step: 0, loss: 5.14449602633249e-05
step: 10, loss: 0.0338386707007885
step: 20, loss: 0.0014356070896610618
step: 30, loss: 0.0006298429798334837
step: 40, loss: 0.027112357318401337
step: 50, loss: 0.00953673105686903
step: 60, loss: 0.00014463235856965184
step: 70, loss: 0.0001392170088365674
step: 80, loss: 0.0001357251894660294
step: 90, loss: 0.03481903299689293
step: 100, loss: 2.9138625905034132e-05
step: 110, loss: 0.0039388518780469894
step: 120, loss: 0.007712526246905327
step: 130, loss: 8.301177877001464e-05
step: 140, loss: 0.011742888949811459
step: 150, loss: 0.0014916107757017016
step: 160, loss: 0.006443300750106573
step: 170, loss: 0.04342144355177879
step: 180, loss: 0.0006897298735566437
step: 190, loss: 0.017631273716688156
step: 200, loss: 0.004442491568624973
step: 210, loss: 0.0003879719297401607
step: 220, loss: 0.03701712563633919
step: 230, loss: 0.04177165776491165
step: 240, loss: 0.0004773437394760549
step: 250, loss: 0.06882323324680328
step: 260, loss: 0.0020296855363994837
step: 270, loss: 0.030879361554980278
step: 280, loss: 0.010155401192605495
step: 290, loss: 0.0012447938788682222
step: 300, loss: 0.0021643773652613163
step: 310, loss: 0.0440492145717144
step: 320, loss: 0.03134163096547127
step: 330, loss: 0.046340495347976685
step: 340, loss: 0.042335573583841324
step: 350, loss: 0.16745373606681824
step: 360, loss: 0.021388763561844826
step: 370, loss: 0.0040256427600979805
step: 380, loss: 0.00017258760635741055
epoch 15: dev_f1=0.6787564766839378, f1=0.7012987012987013, best_f1=0.7041564792176039
step: 0, loss: 0.10169210284948349
step: 10, loss: 0.01983369141817093
step: 20, loss: 0.03005385585129261
step: 30, loss: 0.09320884943008423
step: 40, loss: 0.015407299622893333
step: 50, loss: 0.02833782508969307
step: 60, loss: 0.010653550736606121
step: 70, loss: 0.027736425399780273
step: 80, loss: 0.029858501628041267
step: 90, loss: 0.00037943327333778143
step: 100, loss: 0.00019458682800177485
step: 110, loss: 0.027508774772286415
step: 120, loss: 0.00040092470590025187
step: 130, loss: 0.05560465157032013
step: 140, loss: 0.0006956771831028163
step: 150, loss: 0.20610979199409485
step: 160, loss: 0.01005288865417242
step: 170, loss: 0.0004834080464206636
step: 180, loss: 0.03709287941455841
step: 190, loss: 0.004307298921048641
step: 200, loss: 0.0008025675197131932
step: 210, loss: 0.13326798379421234
step: 220, loss: 0.09873716533184052
step: 230, loss: 0.03990783914923668
step: 240, loss: 0.00014610253856517375
step: 250, loss: 4.2770494474098086e-05
step: 260, loss: 0.00012291224265936762
step: 270, loss: 3.575307346181944e-05
step: 280, loss: 9.332012268714607e-05
step: 290, loss: 0.02596537210047245
step: 300, loss: 0.057100437581539154
step: 310, loss: 0.00905347429215908
step: 320, loss: 0.004004171118140221
step: 330, loss: 0.02509201504290104
step: 340, loss: 0.0315137654542923
step: 350, loss: 0.10776696354150772
step: 360, loss: 0.011730611324310303
step: 370, loss: 8.753620932111517e-05
step: 380, loss: 0.012809235602617264
epoch 16: dev_f1=0.7021791767554478, f1=0.7093596059113301, best_f1=0.7093596059113301
step: 0, loss: 0.029978841543197632
step: 10, loss: 0.03835030272603035
step: 20, loss: 0.04582686349749565
step: 30, loss: 0.00019798995344899595
step: 40, loss: 2.2343816453940235e-05
step: 50, loss: 0.0033622439950704575
step: 60, loss: 6.41929727862589e-05
step: 70, loss: 0.016573302447795868
step: 80, loss: 0.001929688616655767
step: 90, loss: 0.0007530308212153614
step: 100, loss: 0.02677614614367485
step: 110, loss: 0.020736495032906532
step: 120, loss: 0.0021613140124827623
step: 130, loss: 0.05965229496359825
step: 140, loss: 0.021262597292661667
step: 150, loss: 0.004971949849277735
step: 160, loss: 0.016865575686097145
step: 170, loss: 5.489917384693399e-05
step: 180, loss: 0.06612095236778259
step: 190, loss: 0.05529637634754181
step: 200, loss: 7.069379353197291e-05
step: 210, loss: 0.0003833811788354069
step: 220, loss: 0.0008012813050299883
step: 230, loss: 0.01423004548996687
step: 240, loss: 0.03288188949227333
step: 250, loss: 3.268785440013744e-05
step: 260, loss: 0.018116263672709465
step: 270, loss: 0.0005725935334339738
step: 280, loss: 0.03626210615038872
step: 290, loss: 0.01648181863129139
step: 300, loss: 0.05753468722105026
step: 310, loss: 0.0037563350051641464
step: 320, loss: 0.03495629504323006
step: 330, loss: 0.003657986642792821
step: 340, loss: 0.00015406953752972186
step: 350, loss: 0.022331008687615395
step: 360, loss: 0.015067657455801964
step: 370, loss: 0.001947365002706647
step: 380, loss: 0.001598554546944797
epoch 17: dev_f1=0.6801007556675063, f1=0.7235142118863048, best_f1=0.7093596059113301
step: 0, loss: 0.00013344670878723264
step: 10, loss: 0.01372811384499073
step: 20, loss: 0.019522743299603462
step: 30, loss: 3.058736183447763e-05
step: 40, loss: 0.0012444417225196958
step: 50, loss: 2.8576021577464417e-05
step: 60, loss: 5.295698792906478e-05
step: 70, loss: 0.026050757616758347
step: 80, loss: 0.0013243753928691149
step: 90, loss: 0.005100219044834375
step: 100, loss: 4.580952736432664e-05
step: 110, loss: 0.017783217132091522
step: 120, loss: 0.015002528205513954
step: 130, loss: 0.040554411709308624
step: 140, loss: 0.016342749819159508
step: 150, loss: 0.00010492468572920188
step: 160, loss: 0.043122436851263046
step: 170, loss: 0.021945709362626076
step: 180, loss: 0.027239561080932617
step: 190, loss: 0.009340540505945683
step: 200, loss: 0.001318817026913166
step: 210, loss: 0.05222427845001221
step: 220, loss: 0.0010116881458088756
step: 230, loss: 0.014580478891730309
step: 240, loss: 0.012731273658573627
step: 250, loss: 0.00017956421652343124
step: 260, loss: 2.608014619909227e-05
step: 270, loss: 0.027226049453020096
step: 280, loss: 0.019514625892043114
step: 290, loss: 0.0005666397046297789
step: 300, loss: 0.001516022253781557
step: 310, loss: 0.0035632250364869833
step: 320, loss: 0.08761494606733322
step: 330, loss: 0.00018992117838934064
step: 340, loss: 7.748546340735629e-05
step: 350, loss: 0.04727395996451378
step: 360, loss: 0.0007536067278124392
step: 370, loss: 0.012499728240072727
step: 380, loss: 0.020649095997214317
epoch 18: dev_f1=0.6736842105263158, f1=0.6868131868131868, best_f1=0.7093596059113301
step: 0, loss: 0.020525863394141197
step: 10, loss: 0.0003336089139338583
step: 20, loss: 0.045467671006917953
step: 30, loss: 0.0029272600077092648
step: 40, loss: 0.024690423160791397
step: 50, loss: 0.011493189260363579
step: 60, loss: 0.0019159320509061217
step: 70, loss: 0.0033694300800561905
step: 80, loss: 0.00546881090849638
step: 90, loss: 0.03932195156812668
step: 100, loss: 0.0028720046393573284
step: 110, loss: 5.856405550730415e-05
step: 120, loss: 0.000108819775050506
step: 130, loss: 7.50242979847826e-05
step: 140, loss: 0.0013069419655948877
step: 150, loss: 0.025828298181295395
step: 160, loss: 0.002395572839304805
step: 170, loss: 0.00014545749581884593
step: 180, loss: 0.004540769383311272
step: 190, loss: 0.03130665794014931
step: 200, loss: 0.006996165495365858
step: 210, loss: 0.019137132912874222
step: 220, loss: 5.8542154874885455e-05
step: 230, loss: 0.00012861366849392653
step: 240, loss: 0.011414159089326859
step: 250, loss: 0.000482800678582862
step: 260, loss: 0.03018053248524666
step: 270, loss: 0.014506800100207329
step: 280, loss: 0.0051115755923092365
step: 290, loss: 0.009712004102766514
step: 300, loss: 7.042510696919635e-05
step: 310, loss: 0.010572471655905247
step: 320, loss: 0.0060962531715631485
step: 330, loss: 2.215759923274163e-05
step: 340, loss: 0.020744528621435165
step: 350, loss: 0.0002748830011114478
step: 360, loss: 0.015820015221834183
step: 370, loss: 0.036870379000902176
step: 380, loss: 0.0004927302361465991
epoch 19: dev_f1=0.6875000000000001, f1=0.6809651474530832, best_f1=0.7093596059113301
step: 0, loss: 0.012131166644394398
step: 10, loss: 0.022221622988581657
step: 20, loss: 3.4017681173281744e-05
step: 30, loss: 0.046315740793943405
step: 40, loss: 0.0158530343323946
step: 50, loss: 0.0443325936794281
step: 60, loss: 0.00641162134706974
step: 70, loss: 0.029735872521996498
step: 80, loss: 0.019242912530899048
step: 90, loss: 6.974596908548847e-05
step: 100, loss: 0.060617443174123764
step: 110, loss: 0.004429834894835949
step: 120, loss: 0.0605509877204895
step: 130, loss: 0.015508032403886318
step: 140, loss: 0.03285658732056618
step: 150, loss: 8.329985575983301e-05
step: 160, loss: 0.023361027240753174
step: 170, loss: 3.6342204111861065e-05
step: 180, loss: 0.032082539051771164
step: 190, loss: 0.09512721747159958
step: 200, loss: 0.0011272336123511195
step: 210, loss: 0.010714305564761162
step: 220, loss: 0.004143364727497101
step: 230, loss: 5.28502969245892e-05
step: 240, loss: 6.502113683382049e-05
step: 250, loss: 0.012343316338956356
step: 260, loss: 0.0005776298348791897
step: 270, loss: 0.010603567585349083
step: 280, loss: 0.027293730527162552
step: 290, loss: 0.052813123911619186
step: 300, loss: 0.08104407787322998
step: 310, loss: 0.020514199510216713
step: 320, loss: 0.0010142240207642317
step: 330, loss: 0.004046449437737465
step: 340, loss: 5.544789746636525e-05
step: 350, loss: 0.0059348177164793015
step: 360, loss: 2.7312666134093888e-05
step: 370, loss: 8.781066571827978e-05
step: 380, loss: 0.005460110027343035
epoch 20: dev_f1=0.6826666666666666, f1=0.6759776536312848, best_f1=0.7093596059113301
