cuda
Device: cuda
step: 0, loss: 0.6762936115264893
step: 10, loss: 0.06282748281955719
step: 20, loss: 0.3104149401187897
step: 30, loss: 0.30712568759918213
step: 40, loss: 0.2575792074203491
step: 50, loss: 0.2507059574127197
step: 60, loss: 0.5587039589881897
step: 70, loss: 0.2969990372657776
step: 80, loss: 0.33960241079330444
step: 90, loss: 0.24381722509860992
step: 100, loss: 0.33970239758491516
step: 110, loss: 0.32055389881134033
step: 120, loss: 0.19944895803928375
step: 130, loss: 0.5384751558303833
step: 140, loss: 0.23677141964435577
step: 150, loss: 0.1335730254650116
step: 160, loss: 0.2608145773410797
step: 170, loss: 0.16187937557697296
step: 180, loss: 0.19120407104492188
step: 190, loss: 0.33332693576812744
step: 200, loss: 0.29875314235687256
step: 210, loss: 0.534161388874054
step: 220, loss: 0.08577192574739456
step: 230, loss: 0.19418737292289734
step: 240, loss: 0.1845759153366089
step: 250, loss: 0.17242944240570068
step: 260, loss: 0.23117807507514954
step: 270, loss: 0.24928969144821167
step: 280, loss: 0.44078320264816284
step: 290, loss: 0.20452162623405457
step: 300, loss: 0.2389945685863495
step: 310, loss: 0.23289638757705688
step: 320, loss: 0.14352849125862122
step: 330, loss: 0.4240877032279968
step: 340, loss: 0.2428368777036667
step: 350, loss: 0.12056975811719894
step: 360, loss: 0.2505480945110321
step: 370, loss: 0.029028190299868584
step: 380, loss: 0.10013869404792786
epoch 1: dev_f1=0.6526806526806527, f1=0.6150234741784038, best_f1=0.6150234741784038
step: 0, loss: 0.039060790091753006
step: 10, loss: 0.1559041291475296
step: 20, loss: 0.15687045454978943
step: 30, loss: 0.08985615521669388
step: 40, loss: 0.006413075141608715
step: 50, loss: 0.07464827597141266
step: 60, loss: 0.04981936514377594
step: 70, loss: 0.09981431066989899
step: 80, loss: 0.4012824296951294
step: 90, loss: 0.13358667492866516
step: 100, loss: 0.11916240304708481
step: 110, loss: 0.14813989400863647
step: 120, loss: 0.2006295621395111
step: 130, loss: 0.24389182031154633
step: 140, loss: 0.058143310248851776
step: 150, loss: 0.189114511013031
step: 160, loss: 0.08634385466575623
step: 170, loss: 0.07114584743976593
step: 180, loss: 0.1711171716451645
step: 190, loss: 0.09530384838581085
step: 200, loss: 0.0702071338891983
step: 210, loss: 0.17533208429813385
step: 220, loss: 0.31419137120246887
step: 230, loss: 0.12235912680625916
step: 240, loss: 0.12912163138389587
step: 250, loss: 0.19146600365638733
step: 260, loss: 0.16074717044830322
step: 270, loss: 0.007139661815017462
step: 280, loss: 0.19009338319301605
step: 290, loss: 0.07196291536092758
step: 300, loss: 0.09498636424541473
step: 310, loss: 0.10035340487957001
step: 320, loss: 0.16906525194644928
step: 330, loss: 0.06790091842412949
step: 340, loss: 0.0634583905339241
step: 350, loss: 0.028982238844037056
step: 360, loss: 0.28958994150161743
step: 370, loss: 0.12309270352125168
step: 380, loss: 0.08402039855718613
epoch 2: dev_f1=0.6682027649769585, f1=0.6575963718820862, best_f1=0.6575963718820862
step: 0, loss: 0.11137080192565918
step: 10, loss: 0.11232231557369232
step: 20, loss: 0.0664992555975914
step: 30, loss: 0.05161497741937637
step: 40, loss: 0.04704957455396652
step: 50, loss: 0.1380203515291214
step: 60, loss: 0.07008121907711029
step: 70, loss: 0.019135408103466034
step: 80, loss: 0.1178881973028183
step: 90, loss: 0.1402253806591034
step: 100, loss: 0.12580706179141998
step: 110, loss: 0.024484947323799133
step: 120, loss: 0.041903819888830185
step: 130, loss: 0.051428183913230896
step: 140, loss: 0.1279153823852539
step: 150, loss: 0.05943923816084862
step: 160, loss: 0.21656447649002075
step: 170, loss: 0.11101759225130081
step: 180, loss: 0.03496949002146721
step: 190, loss: 0.11468522995710373
step: 200, loss: 0.021271685138344765
step: 210, loss: 0.08943182229995728
step: 220, loss: 0.0808335691690445
step: 230, loss: 0.07159833610057831
step: 240, loss: 0.07608115673065186
step: 250, loss: 0.07576644420623779
step: 260, loss: 0.04089977592229843
step: 270, loss: 0.1002650111913681
step: 280, loss: 0.08006415516138077
step: 290, loss: 0.08447837829589844
step: 300, loss: 0.08823078125715256
step: 310, loss: 0.023527419194579124
step: 320, loss: 0.025509782135486603
step: 330, loss: 0.024119339883327484
step: 340, loss: 0.048521533608436584
step: 350, loss: 0.010001333430409431
step: 360, loss: 0.06200060620903969
step: 370, loss: 0.09282940626144409
step: 380, loss: 0.09858446568250656
epoch 3: dev_f1=0.7183462532299743, f1=0.733509234828496, best_f1=0.733509234828496
step: 0, loss: 0.06341234594583511
step: 10, loss: 0.09660506993532181
step: 20, loss: 0.05659337341785431
step: 30, loss: 0.07307589054107666
step: 40, loss: 0.09698086231946945
step: 50, loss: 0.06590289622545242
step: 60, loss: 0.05827225744724274
step: 70, loss: 0.03492514044046402
step: 80, loss: 0.03191010653972626
step: 90, loss: 0.17199374735355377
step: 100, loss: 0.044372882694005966
step: 110, loss: 0.0010108948918059468
step: 120, loss: 0.16531898081302643
step: 130, loss: 0.21043354272842407
step: 140, loss: 0.07308602333068848
step: 150, loss: 0.016739744693040848
step: 160, loss: 0.07186122238636017
step: 170, loss: 0.15588119626045227
step: 180, loss: 0.1479083150625229
step: 190, loss: 0.03916332870721817
step: 200, loss: 0.15582801401615143
step: 210, loss: 0.01105333212763071
step: 220, loss: 0.018715474754571915
step: 230, loss: 0.04340944439172745
step: 240, loss: 0.069534070789814
step: 250, loss: 0.1579866260290146
step: 260, loss: 0.07863412797451019
step: 270, loss: 0.07831119745969772
step: 280, loss: 0.008207445032894611
step: 290, loss: 0.04383367300033569
step: 300, loss: 0.1285427212715149
step: 310, loss: 0.09533734619617462
step: 320, loss: 0.020088594406843185
step: 330, loss: 0.08179621398448944
step: 340, loss: 0.09155938774347305
step: 350, loss: 0.03135541081428528
step: 360, loss: 0.07541510462760925
step: 370, loss: 0.059152159839868546
step: 380, loss: 0.13277073204517365
epoch 4: dev_f1=0.7019230769230769, f1=0.735576923076923, best_f1=0.733509234828496
step: 0, loss: 0.044991858303546906
step: 10, loss: 0.16276568174362183
step: 20, loss: 0.032504189759492874
step: 30, loss: 0.06318701803684235
step: 40, loss: 0.00972748827189207
step: 50, loss: 0.004273556638509035
step: 60, loss: 0.04913261532783508
step: 70, loss: 0.04181244969367981
step: 80, loss: 0.08274704962968826
step: 90, loss: 0.061218444257974625
step: 100, loss: 0.10518192499876022
step: 110, loss: 0.12780041992664337
step: 120, loss: 0.32544606924057007
step: 130, loss: 0.03411535918712616
step: 140, loss: 0.006415100768208504
step: 150, loss: 0.11642701923847198
step: 160, loss: 0.013082572259008884
step: 170, loss: 0.0737486407160759
step: 180, loss: 0.08193615823984146
step: 190, loss: 0.02780180796980858
step: 200, loss: 0.1907084584236145
step: 210, loss: 0.033541541546583176
step: 220, loss: 0.03107103332877159
step: 230, loss: 0.05070044472813606
step: 240, loss: 0.03865279257297516
step: 250, loss: 0.12303933501243591
step: 260, loss: 0.04054771736264229
step: 270, loss: 0.16246414184570312
step: 280, loss: 0.06578800082206726
step: 290, loss: 0.008680729195475578
step: 300, loss: 0.021254461258649826
step: 310, loss: 0.0010862930212169886
step: 320, loss: 0.06126442924141884
step: 330, loss: 0.13079890608787537
step: 340, loss: 0.010238579474389553
step: 350, loss: 0.2399282306432724
step: 360, loss: 0.11393612623214722
step: 370, loss: 0.08826523274183273
step: 380, loss: 0.014549432322382927
epoch 5: dev_f1=0.7281553398058251, f1=0.7358024691358025, best_f1=0.7358024691358025
step: 0, loss: 0.04221548140048981
step: 10, loss: 0.018665947020053864
step: 20, loss: 0.14370188117027283
step: 30, loss: 0.0057663205079734325
step: 40, loss: 0.020028701052069664
step: 50, loss: 0.0755176767706871
step: 60, loss: 0.02215154469013214
step: 70, loss: 0.126163050532341
step: 80, loss: 0.07906383275985718
step: 90, loss: 0.07729074358940125
step: 100, loss: 0.03638322651386261
step: 110, loss: 0.0036880485713481903
step: 120, loss: 0.00021332784672267735
step: 130, loss: 0.03000691533088684
step: 140, loss: 0.02045878954231739
step: 150, loss: 0.06952965259552002
step: 160, loss: 0.0003749510506168008
step: 170, loss: 0.0434873066842556
step: 180, loss: 0.16587957739830017
step: 190, loss: 0.04222862422466278
step: 200, loss: 0.07271135598421097
step: 210, loss: 0.06864015758037567
step: 220, loss: 0.024848010390996933
step: 230, loss: 0.020275194197893143
step: 240, loss: 0.10006281733512878
step: 250, loss: 0.04932170361280441
step: 260, loss: 0.03871702030301094
step: 270, loss: 0.02247662842273712
step: 280, loss: 0.07385493069887161
step: 290, loss: 0.006438239943236113
step: 300, loss: 0.049808647483587265
step: 310, loss: 0.08056215941905975
step: 320, loss: 0.012331939302384853
step: 330, loss: 0.11469422280788422
step: 340, loss: 0.02000458911061287
step: 350, loss: 0.15525561571121216
step: 360, loss: 0.0325901061296463
step: 370, loss: 0.0392569974064827
step: 380, loss: 0.039398811757564545
epoch 6: dev_f1=0.7218390804597701, f1=0.7529411764705882, best_f1=0.7358024691358025
step: 0, loss: 0.21049700677394867
step: 10, loss: 0.02546287514269352
step: 20, loss: 0.04816390946507454
step: 30, loss: 0.2260781079530716
step: 40, loss: 0.10137239843606949
step: 50, loss: 0.0178776104003191
step: 60, loss: 0.03411460295319557
step: 70, loss: 0.14702409505844116
step: 80, loss: 0.04018079489469528
step: 90, loss: 0.06147793307900429
step: 100, loss: 0.0989660993218422
step: 110, loss: 0.03630857169628143
step: 120, loss: 0.043128326535224915
step: 130, loss: 0.056979600340127945
step: 140, loss: 0.07377782464027405
step: 150, loss: 0.04727461561560631
step: 160, loss: 0.025841567665338516
step: 170, loss: 0.06774447113275528
step: 180, loss: 0.049093153327703476
step: 190, loss: 0.045646991580724716
step: 200, loss: 0.006752033717930317
step: 210, loss: 0.05597389489412308
step: 220, loss: 0.02712806686758995
step: 230, loss: 0.0411025807261467
step: 240, loss: 0.023761702701449394
step: 250, loss: 0.026798833161592484
step: 260, loss: 0.03030998259782791
step: 270, loss: 0.06028641387820244
step: 280, loss: 0.11927235871553421
step: 290, loss: 0.0012755815405398607
step: 300, loss: 0.049464356154203415
step: 310, loss: 0.00683641666546464
step: 320, loss: 0.024069271981716156
step: 330, loss: 0.036471981555223465
step: 340, loss: 0.08555488288402557
step: 350, loss: 0.060613252222537994
step: 360, loss: 0.003758090315386653
step: 370, loss: 0.060718514025211334
step: 380, loss: 0.0569118969142437
epoch 7: dev_f1=0.7428571428571429, f1=0.7344913151364764, best_f1=0.7344913151364764
step: 0, loss: 0.08600309491157532
step: 10, loss: 0.03134607896208763
step: 20, loss: 0.03181369975209236
step: 30, loss: 0.06706554442644119
step: 40, loss: 0.06989936530590057
step: 50, loss: 0.03375793248414993
step: 60, loss: 0.00023707232321612537
step: 70, loss: 0.06737720221281052
step: 80, loss: 0.02627652883529663
step: 90, loss: 0.11087898164987564
step: 100, loss: 0.13817963004112244
step: 110, loss: 0.07216869294643402
step: 120, loss: 0.009800354018807411
step: 130, loss: 0.016384132206439972
step: 140, loss: 0.016144413501024246
step: 150, loss: 0.04585329815745354
step: 160, loss: 0.00027015464729629457
step: 170, loss: 0.055451929569244385
step: 180, loss: 0.009556896053254604
step: 190, loss: 0.01569654792547226
step: 200, loss: 0.03755640983581543
step: 210, loss: 0.00880973320454359
step: 220, loss: 0.028698060661554337
step: 230, loss: 0.001693785423412919
step: 240, loss: 0.019261401146650314
step: 250, loss: 0.00037435951526276767
step: 260, loss: 0.00414032069966197
step: 270, loss: 0.1505560278892517
step: 280, loss: 0.009648974984884262
step: 290, loss: 0.003371155820786953
step: 300, loss: 0.02945610322058201
step: 310, loss: 0.00782238133251667
step: 320, loss: 0.022258082404732704
step: 330, loss: 0.0042809429578483105
step: 340, loss: 0.15351341664791107
step: 350, loss: 0.09656170010566711
step: 360, loss: 0.03410869091749191
step: 370, loss: 0.050608307123184204
step: 380, loss: 0.08124792575836182
epoch 8: dev_f1=0.7205882352941175, f1=0.72, best_f1=0.7344913151364764
step: 0, loss: 0.030211888253688812
step: 10, loss: 0.050094276666641235
step: 20, loss: 0.031010374426841736
step: 30, loss: 0.009067422710359097
step: 40, loss: 0.1035495400428772
step: 50, loss: 0.03512418642640114
step: 60, loss: 0.007462246343493462
step: 70, loss: 0.00013782037422060966
step: 80, loss: 0.002962365746498108
step: 90, loss: 0.03261250630021095
step: 100, loss: 0.017590435221791267
step: 110, loss: 0.005504151340574026
step: 120, loss: 0.002143509453162551
step: 130, loss: 0.007677113171666861
step: 140, loss: 0.00164331728592515
step: 150, loss: 0.05646999552845955
step: 160, loss: 0.05366736277937889
step: 170, loss: 0.016756081953644753
step: 180, loss: 0.04720772057771683
step: 190, loss: 0.01353967934846878
step: 200, loss: 0.005868644453585148
step: 210, loss: 0.0012041947338730097
step: 220, loss: 0.08202352374792099
step: 230, loss: 0.04911966621875763
step: 240, loss: 0.000698974181432277
step: 250, loss: 0.03663652017712593
step: 260, loss: 0.08235468715429306
step: 270, loss: 0.01835385151207447
step: 280, loss: 0.0002483986027073115
step: 290, loss: 0.018054015934467316
step: 300, loss: 0.04549315571784973
step: 310, loss: 0.013338888064026833
step: 320, loss: 0.11028924584388733
step: 330, loss: 0.12077441811561584
step: 340, loss: 0.0121171148493886
step: 350, loss: 0.05260058864951134
step: 360, loss: 0.10610055923461914
step: 370, loss: 0.015524795278906822
step: 380, loss: 0.09317505359649658
epoch 9: dev_f1=0.7241379310344828, f1=0.7487437185929648, best_f1=0.7344913151364764
step: 0, loss: 0.00895932037383318
step: 10, loss: 0.020087504759430885
step: 20, loss: 0.05356870964169502
step: 30, loss: 0.0026881720405071974
step: 40, loss: 0.06721054762601852
step: 50, loss: 0.06251990795135498
step: 60, loss: 0.04498236998915672
step: 70, loss: 0.03684784844517708
step: 80, loss: 0.014439940452575684
step: 90, loss: 0.014702633023262024
step: 100, loss: 0.012160928919911385
step: 110, loss: 0.002252967096865177
step: 120, loss: 0.06356873363256454
step: 130, loss: 0.0729173794388771
step: 140, loss: 0.00025114259915426373
step: 150, loss: 0.1112382560968399
step: 160, loss: 0.005243240389972925
step: 170, loss: 0.15932811796665192
step: 180, loss: 0.013369121588766575
step: 190, loss: 0.00020444270921871066
step: 200, loss: 0.010097024030983448
step: 210, loss: 0.08305695652961731
step: 220, loss: 0.03933895006775856
step: 230, loss: 0.046297673135995865
step: 240, loss: 0.00431060092523694
step: 250, loss: 0.008420444093644619
step: 260, loss: 0.00015957375580910593
step: 270, loss: 0.029003113508224487
step: 280, loss: 0.11926150321960449
step: 290, loss: 0.07701615989208221
step: 300, loss: 0.0912463441491127
step: 310, loss: 0.03074372559785843
step: 320, loss: 0.026906833052635193
step: 330, loss: 0.04772390052676201
step: 340, loss: 0.024389224126935005
step: 350, loss: 0.15119998157024384
step: 360, loss: 0.06504177302122116
step: 370, loss: 0.02150656282901764
step: 380, loss: 0.003090109210461378
epoch 10: dev_f1=0.7198177676537586, f1=0.711943793911007, best_f1=0.7344913151364764
step: 0, loss: 0.015769517049193382
step: 10, loss: 0.030353710055351257
step: 20, loss: 0.021479617804288864
step: 30, loss: 0.011630523949861526
step: 40, loss: 0.00010665397712728009
step: 50, loss: 0.018334655091166496
step: 60, loss: 0.018569080159068108
step: 70, loss: 0.06409332901239395
step: 80, loss: 0.012635230086743832
step: 90, loss: 0.03707766532897949
step: 100, loss: 0.010285170748829842
step: 110, loss: 0.02259078621864319
step: 120, loss: 0.1430228054523468
step: 130, loss: 0.012185067869722843
step: 140, loss: 0.006792797707021236
step: 150, loss: 0.0007983924588188529
step: 160, loss: 0.04908553510904312
step: 170, loss: 0.09303943812847137
step: 180, loss: 0.0020101587288081646
step: 190, loss: 0.00386715866625309
step: 200, loss: 0.028278248384594917
step: 210, loss: 0.018734658136963844
step: 220, loss: 0.0038131268229335546
step: 230, loss: 0.09978947788476944
step: 240, loss: 0.03691002354025841
step: 250, loss: 0.0067380135878920555
step: 260, loss: 0.016733845695853233
step: 270, loss: 0.07541338354349136
step: 280, loss: 0.00016146802227012813
step: 290, loss: 0.04317118600010872
step: 300, loss: 0.01761433854699135
step: 310, loss: 0.024198079481720924
step: 320, loss: 0.03200685605406761
step: 330, loss: 0.015428694896399975
step: 340, loss: 0.0002053415373666212
step: 350, loss: 0.02044195868074894
step: 360, loss: 0.038688380271196365
step: 370, loss: 0.016438234597444534
step: 380, loss: 0.0024264671374112368
epoch 11: dev_f1=0.7033492822966507, f1=0.7118644067796611, best_f1=0.7344913151364764
step: 0, loss: 0.00023198564304038882
step: 10, loss: 0.04108304902911186
step: 20, loss: 0.01312225591391325
step: 30, loss: 0.0158179122954607
step: 40, loss: 0.05192692577838898
step: 50, loss: 0.028670072555541992
step: 60, loss: 0.03007843904197216
step: 70, loss: 0.04334642365574837
step: 80, loss: 0.04060092195868492
step: 90, loss: 0.01031579915434122
step: 100, loss: 0.05924180522561073
step: 110, loss: 0.0779811441898346
step: 120, loss: 0.0394379124045372
step: 130, loss: 0.005955342669039965
step: 140, loss: 0.00013595366908703
step: 150, loss: 0.013796856626868248
step: 160, loss: 0.0503116101026535
step: 170, loss: 0.0006532697007060051
step: 180, loss: 0.001139097730629146
step: 190, loss: 0.0459655225276947
step: 200, loss: 0.004237225744873285
step: 210, loss: 0.03826159983873367
step: 220, loss: 0.016793984919786453
step: 230, loss: 0.1327522248029709
step: 240, loss: 0.00617742445319891
step: 250, loss: 0.00010480308264959604
step: 260, loss: 0.04581238701939583
step: 270, loss: 0.06031463295221329
step: 280, loss: 0.03702522814273834
step: 290, loss: 0.0015843173023313284
step: 300, loss: 0.034692730754613876
step: 310, loss: 0.03643862530589104
step: 320, loss: 0.0010162955150008202
step: 330, loss: 0.01231294870376587
step: 340, loss: 0.017689043655991554
step: 350, loss: 0.01523316465318203
step: 360, loss: 0.06207772716879845
step: 370, loss: 0.10025525838136673
step: 380, loss: 0.04931756108999252
epoch 12: dev_f1=0.7095238095238094, f1=0.7475247524752476, best_f1=0.7344913151364764
step: 0, loss: 0.056831859052181244
step: 10, loss: 0.006488618906587362
step: 20, loss: 0.011526177637279034
step: 30, loss: 0.0001267903862753883
step: 40, loss: 0.006140890996903181
step: 50, loss: 0.029524043202400208
step: 60, loss: 0.005181271117180586
step: 70, loss: 0.06705984473228455
step: 80, loss: 0.01127094216644764
step: 90, loss: 0.14793431758880615
step: 100, loss: 0.009876196272671223
step: 110, loss: 0.000450220366474241
step: 120, loss: 0.0028957363683730364
step: 130, loss: 0.04567670822143555
step: 140, loss: 4.1355764551553875e-05
step: 150, loss: 0.0012118390295654535
step: 160, loss: 0.006913422606885433
step: 170, loss: 0.09198460727930069
step: 180, loss: 0.001990941585972905
step: 190, loss: 0.022904247045516968
step: 200, loss: 4.5232671254780143e-05
step: 210, loss: 0.01053533237427473
step: 220, loss: 0.011296432465314865
step: 230, loss: 0.08832962065935135
step: 240, loss: 0.0441276952624321
step: 250, loss: 0.010582913644611835
step: 260, loss: 0.05221148580312729
step: 270, loss: 0.022431718185544014
step: 280, loss: 0.04681785777211189
step: 290, loss: 0.013024802319705486
step: 300, loss: 0.03749310225248337
step: 310, loss: 0.003845477942377329
step: 320, loss: 0.16161048412322998
step: 330, loss: 0.0017190787475556135
step: 340, loss: 0.02594105713069439
step: 350, loss: 0.10161848366260529
step: 360, loss: 0.004217734560370445
step: 370, loss: 0.015395717695355415
step: 380, loss: 0.052380822598934174
epoch 13: dev_f1=0.691292875989446, f1=0.6947368421052632, best_f1=0.7344913151364764
step: 0, loss: 7.029628613963723e-05
step: 10, loss: 0.0008162845624610782
step: 20, loss: 0.0003487653157208115
step: 30, loss: 0.02507205307483673
step: 40, loss: 0.009404146112501621
step: 50, loss: 0.0011296254815533757
step: 60, loss: 0.002461503492668271
step: 70, loss: 0.003427139250561595
step: 80, loss: 0.013629681430757046
step: 90, loss: 0.0006374901277013123
step: 100, loss: 0.026716021820902824
step: 110, loss: 0.007732924539595842
step: 120, loss: 0.008896954357624054
step: 130, loss: 3.0367833460331894e-05
step: 140, loss: 0.001039838301949203
step: 150, loss: 0.059674154967069626
step: 160, loss: 0.00032631613430567086
step: 170, loss: 0.030207952484488487
step: 180, loss: 0.03546774014830589
step: 190, loss: 0.03417850658297539
step: 200, loss: 0.003908413462340832
step: 210, loss: 0.04834389314055443
step: 220, loss: 0.0011465342249721289
step: 230, loss: 0.0062824818305671215
step: 240, loss: 0.08422420918941498
step: 250, loss: 0.05420411005616188
step: 260, loss: 0.023427829146385193
step: 270, loss: 0.03106486052274704
step: 280, loss: 0.08011870831251144
step: 290, loss: 0.00012200327182654291
step: 300, loss: 0.014214401133358479
step: 310, loss: 2.8225762434885837e-05
step: 320, loss: 0.000795234926044941
step: 330, loss: 0.01930581033229828
step: 340, loss: 0.03394671157002449
step: 350, loss: 0.07739322632551193
step: 360, loss: 0.018165770918130875
step: 370, loss: 0.11720561981201172
step: 380, loss: 0.0037680407986044884
epoch 14: dev_f1=0.7295285359801489, f1=0.7185929648241205, best_f1=0.7344913151364764
step: 0, loss: 0.027027897536754608
step: 10, loss: 0.007892947643995285
step: 20, loss: 0.005752370692789555
step: 30, loss: 0.04735499620437622
step: 40, loss: 0.034439388662576675
step: 50, loss: 0.02783607877790928
step: 60, loss: 0.008758916519582272
step: 70, loss: 0.001858727540820837
step: 80, loss: 0.007217018865048885
step: 90, loss: 0.03990214690566063
step: 100, loss: 0.08782937377691269
step: 110, loss: 0.017720473930239677
step: 120, loss: 0.0015355037758126855
step: 130, loss: 0.000740138697437942
step: 140, loss: 0.00016495160525664687
step: 150, loss: 0.0006180385826155543
step: 160, loss: 0.02519685961306095
step: 170, loss: 0.00023368143592961133
step: 180, loss: 0.030998945236206055
step: 190, loss: 0.027437467128038406
step: 200, loss: 0.01178339496254921
step: 210, loss: 0.04733417183160782
step: 220, loss: 6.054334153304808e-05
step: 230, loss: 0.028892675414681435
step: 240, loss: 0.020050322636961937
step: 250, loss: 0.009034043177962303
step: 260, loss: 0.0008084996370598674
step: 270, loss: 0.00010410817776573822
step: 280, loss: 0.047208696603775024
step: 290, loss: 0.020323671400547028
step: 300, loss: 0.028557896614074707
step: 310, loss: 0.007105296943336725
step: 320, loss: 0.006708419416099787
step: 330, loss: 0.01872376911342144
step: 340, loss: 0.0018433940131217241
step: 350, loss: 0.08237864077091217
step: 360, loss: 0.0018784240819513798
step: 370, loss: 0.01895267516374588
step: 380, loss: 0.06055547669529915
epoch 15: dev_f1=0.7170731707317073, f1=0.7344913151364764, best_f1=0.7344913151364764
step: 0, loss: 0.03391497954726219
step: 10, loss: 0.023881830275058746
step: 20, loss: 0.03073715604841709
step: 30, loss: 0.0006356293451972306
step: 40, loss: 0.03416449576616287
step: 50, loss: 0.04816018417477608
step: 60, loss: 0.03080860897898674
step: 70, loss: 0.047058358788490295
step: 80, loss: 0.03881051018834114
step: 90, loss: 0.06440805643796921
step: 100, loss: 0.0009023352758958936
step: 110, loss: 0.014559858478605747
step: 120, loss: 0.054044388234615326
step: 130, loss: 0.009057781659066677
step: 140, loss: 0.047063957899808884
step: 150, loss: 0.03082355670630932
step: 160, loss: 3.2397201721323654e-05
step: 170, loss: 0.03821205720305443
step: 180, loss: 0.014249492436647415
step: 190, loss: 0.03486495092511177
step: 200, loss: 0.0910039097070694
step: 210, loss: 0.028505384922027588
step: 220, loss: 0.0659913718700409
step: 230, loss: 0.0005058260285295546
step: 240, loss: 0.02519739791750908
step: 250, loss: 0.00888354703783989
step: 260, loss: 0.018005283549427986
step: 270, loss: 0.0006502444739453495
step: 280, loss: 0.034405019134283066
step: 290, loss: 5.51725497643929e-05
step: 300, loss: 0.0015956435818225145
step: 310, loss: 0.01643243432044983
step: 320, loss: 0.08576418459415436
step: 330, loss: 0.0019166053971275687
step: 340, loss: 0.0014728973619639874
step: 350, loss: 0.037541527301073074
step: 360, loss: 0.00021533317340072244
step: 370, loss: 0.0007282301667146385
step: 380, loss: 0.00028369674691930413
epoch 16: dev_f1=0.7216981132075472, f1=0.721549636803874, best_f1=0.7344913151364764
step: 0, loss: 0.013066361658275127
step: 10, loss: 6.28790512564592e-05
step: 20, loss: 0.026349397376179695
step: 30, loss: 3.9910722989588976e-05
step: 40, loss: 0.03848638758063316
step: 50, loss: 0.005314044654369354
step: 60, loss: 0.002591476310044527
step: 70, loss: 0.03131511062383652
step: 80, loss: 0.06268854439258575
step: 90, loss: 0.0008091333438642323
step: 100, loss: 3.356672459631227e-05
step: 110, loss: 0.01673702895641327
step: 120, loss: 0.0455462671816349
step: 130, loss: 0.00037609634455293417
step: 140, loss: 2.1829682737006806e-05
step: 150, loss: 0.06638918817043304
step: 160, loss: 0.04424106329679489
step: 170, loss: 0.015000502578914165
step: 180, loss: 0.05351834371685982
step: 190, loss: 0.00024241983192041516
step: 200, loss: 0.06438522040843964
step: 210, loss: 0.00010052161815110594
step: 220, loss: 4.9025864427676424e-05
step: 230, loss: 0.024493534117937088
step: 240, loss: 0.001527468441054225
step: 250, loss: 0.02070382423698902
step: 260, loss: 0.00040024827467277646
step: 270, loss: 0.0036699154879897833
step: 280, loss: 0.0005620562587864697
step: 290, loss: 0.022748922929167747
step: 300, loss: 0.00029985871515236795
step: 310, loss: 0.0016734981909394264
step: 320, loss: 0.0461605079472065
step: 330, loss: 0.020704859867691994
step: 340, loss: 0.027365483343601227
step: 350, loss: 0.02084435522556305
step: 360, loss: 0.022786792367696762
step: 370, loss: 0.01852243021130562
step: 380, loss: 0.037011757493019104
epoch 17: dev_f1=0.6987341772151898, f1=0.7225130890052356, best_f1=0.7344913151364764
step: 0, loss: 0.030764544382691383
step: 10, loss: 0.0003798857796937227
step: 20, loss: 0.02547558769583702
step: 30, loss: 0.013206126168370247
step: 40, loss: 0.007177149411290884
step: 50, loss: 0.01547970436513424
step: 60, loss: 0.0023020971566438675
step: 70, loss: 0.01053813099861145
step: 80, loss: 0.0010590171441435814
step: 90, loss: 0.0033297452609986067
step: 100, loss: 0.00015505580813623965
step: 110, loss: 0.026515813544392586
step: 120, loss: 5.902241537114605e-05
step: 130, loss: 0.02377297915518284
step: 140, loss: 0.015005271881818771
step: 150, loss: 0.00288011459633708
step: 160, loss: 0.040071144700050354
step: 170, loss: 0.00700244540348649
step: 180, loss: 0.00343653024174273
step: 190, loss: 0.01658022776246071
step: 200, loss: 0.010242057032883167
step: 210, loss: 0.0031950408592820168
step: 220, loss: 0.0011625789338722825
step: 230, loss: 0.00930729415267706
step: 240, loss: 0.0002296415186719969
step: 250, loss: 0.011903837323188782
step: 260, loss: 0.00043303542770445347
step: 270, loss: 0.07433491945266724
step: 280, loss: 0.005391428247094154
step: 290, loss: 0.0352824404835701
step: 300, loss: 8.621973393019289e-05
step: 310, loss: 3.727347211679444e-05
step: 320, loss: 6.042766472091898e-05
step: 330, loss: 0.029483921825885773
step: 340, loss: 0.09372454881668091
step: 350, loss: 0.00767448591068387
step: 360, loss: 0.026778964325785637
step: 370, loss: 0.011500492691993713
step: 380, loss: 0.0024063698947429657
epoch 18: dev_f1=0.6904761904761906, f1=0.7114427860696517, best_f1=0.7344913151364764
step: 0, loss: 0.08215178549289703
step: 10, loss: 0.017067700624465942
step: 20, loss: 0.02066653221845627
step: 30, loss: 5.8070265367859975e-05
step: 40, loss: 0.015040615573525429
step: 50, loss: 0.031108543276786804
step: 60, loss: 7.011763955233619e-05
step: 70, loss: 0.0005133265512995422
step: 80, loss: 0.032344646751880646
step: 90, loss: 0.0005473621422424912
step: 100, loss: 0.024471154436469078
step: 110, loss: 0.011686268262565136
step: 120, loss: 0.00026354871806688607
step: 130, loss: 0.0009378819959238172
step: 140, loss: 3.753675628104247e-05
step: 150, loss: 0.011865098960697651
step: 160, loss: 0.018914999440312386
step: 170, loss: 0.00013832244439981878
step: 180, loss: 0.00036021004780195653
step: 190, loss: 0.00029409912531264126
step: 200, loss: 0.021477093920111656
step: 210, loss: 0.005254887044429779
step: 220, loss: 0.014263872988522053
step: 230, loss: 0.013084713369607925
step: 240, loss: 0.10847602039575577
step: 250, loss: 0.052279647439718246
step: 260, loss: 0.0016480509657412767
step: 270, loss: 0.020480703562498093
step: 280, loss: 0.002148327650502324
step: 290, loss: 0.0012125401990488172
step: 300, loss: 0.03233389928936958
step: 310, loss: 0.0008283615461550653
step: 320, loss: 0.041686754673719406
step: 330, loss: 0.12880854308605194
step: 340, loss: 0.025357414036989212
step: 350, loss: 0.03377949818968773
step: 360, loss: 5.280112236505374e-05
step: 370, loss: 0.004202292300760746
step: 380, loss: 0.0550377257168293
epoch 19: dev_f1=0.6997518610421836, f1=0.7263427109974423, best_f1=0.7344913151364764
step: 0, loss: 0.0885428711771965
step: 10, loss: 0.024725288152694702
step: 20, loss: 0.018603084608912468
step: 30, loss: 0.008125384338200092
step: 40, loss: 0.000594294280745089
step: 50, loss: 0.01120443269610405
step: 60, loss: 0.028622597455978394
step: 70, loss: 0.0510464683175087
step: 80, loss: 0.0002792022714857012
step: 90, loss: 0.029640089720487595
step: 100, loss: 0.0010455814190208912
step: 110, loss: 0.034369222819805145
step: 120, loss: 0.13179917633533478
step: 130, loss: 0.010573508217930794
step: 140, loss: 6.854602543171495e-05
step: 150, loss: 0.0031228435691446066
step: 160, loss: 0.024894937872886658
step: 170, loss: 0.0019417176954448223
step: 180, loss: 0.07269942760467529
step: 190, loss: 0.0034550735726952553
step: 200, loss: 0.020799271762371063
step: 210, loss: 6.386177847161889e-05
step: 220, loss: 0.0009127891971729696
step: 230, loss: 2.682834747247398e-05
step: 240, loss: 0.00031788754859007895
step: 250, loss: 0.027874549850821495
step: 260, loss: 0.009752265177667141
step: 270, loss: 0.011115592904388905
step: 280, loss: 0.0004659084661398083
step: 290, loss: 0.003682968905195594
step: 300, loss: 7.42038173484616e-05
step: 310, loss: 0.03522138297557831
step: 320, loss: 0.00015847195754759014
step: 330, loss: 0.013236857019364834
step: 340, loss: 0.03309062123298645
step: 350, loss: 0.00019107993284706026
step: 360, loss: 0.00142442446667701
step: 370, loss: 9.290110756410286e-05
step: 380, loss: 0.001238134689629078
epoch 20: dev_f1=0.6972010178117048, f1=0.7154046997389033, best_f1=0.7344913151364764
