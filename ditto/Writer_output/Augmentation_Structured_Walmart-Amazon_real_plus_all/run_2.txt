cuda
Device: cuda
step: 0, loss: 0.7222966551780701
step: 10, loss: 0.329590380191803
step: 20, loss: 0.18420736491680145
step: 30, loss: 0.22700081765651703
step: 40, loss: 0.3641315996646881
step: 50, loss: 0.22330106794834137
step: 60, loss: 0.35437628626823425
step: 70, loss: 0.1462104171514511
step: 80, loss: 0.39383915066719055
step: 90, loss: 0.15947148203849792
step: 100, loss: 0.14437012374401093
step: 110, loss: 0.1523013412952423
step: 120, loss: 0.2812163233757019
step: 130, loss: 0.3710963726043701
step: 140, loss: 0.22003629803657532
step: 150, loss: 0.393926739692688
step: 160, loss: 0.18384096026420593
step: 170, loss: 0.4690108895301819
step: 180, loss: 0.27375486493110657
step: 190, loss: 0.13468477129936218
step: 200, loss: 0.25430938601493835
step: 210, loss: 0.24970409274101257
step: 220, loss: 0.4151492714881897
step: 230, loss: 0.07615084201097488
step: 240, loss: 0.19555683434009552
step: 250, loss: 0.2272927612066269
step: 260, loss: 0.1090371236205101
step: 270, loss: 0.10752013325691223
step: 280, loss: 0.4113610088825226
step: 290, loss: 0.27348148822784424
step: 300, loss: 0.34319496154785156
step: 310, loss: 0.19308333098888397
step: 320, loss: 0.2463938146829605
step: 330, loss: 0.10201376676559448
step: 340, loss: 0.1348707228899002
step: 350, loss: 0.21242381632328033
step: 360, loss: 0.07173822820186615
step: 370, loss: 0.26064035296440125
step: 380, loss: 0.1627063751220703
epoch 1: dev_f1=0.5623582766439909, f1=0.563063063063063, best_f1=0.563063063063063
step: 0, loss: 0.1126648336648941
step: 10, loss: 0.22337846457958221
step: 20, loss: 0.182590514421463
step: 30, loss: 0.0974460318684578
step: 40, loss: 0.20766521990299225
step: 50, loss: 0.17268787324428558
step: 60, loss: 0.1327117383480072
step: 70, loss: 0.4030933678150177
step: 80, loss: 0.020449938252568245
step: 90, loss: 0.08604426681995392
step: 100, loss: 0.18292869627475739
step: 110, loss: 0.0778932198882103
step: 120, loss: 0.3052436113357544
step: 130, loss: 0.3050336539745331
step: 140, loss: 0.23258428275585175
step: 150, loss: 0.008969374001026154
step: 160, loss: 0.16613519191741943
step: 170, loss: 0.3468170762062073
step: 180, loss: 0.0761893168091774
step: 190, loss: 0.08929385989904404
step: 200, loss: 0.23098593950271606
step: 210, loss: 0.2424800843000412
step: 220, loss: 0.24816541373729706
step: 230, loss: 0.03813860937952995
step: 240, loss: 0.33637911081314087
step: 250, loss: 0.10864993929862976
step: 260, loss: 0.01152842678129673
step: 270, loss: 0.06389112770557404
step: 280, loss: 0.16102798283100128
step: 290, loss: 0.10146049410104752
step: 300, loss: 0.0315837636590004
step: 310, loss: 0.04246871545910835
step: 320, loss: 0.14029952883720398
step: 330, loss: 0.2891269326210022
step: 340, loss: 0.1551593691110611
step: 350, loss: 0.12735389173030853
step: 360, loss: 0.2235977202653885
step: 370, loss: 0.24434930086135864
step: 380, loss: 0.10828229784965515
epoch 2: dev_f1=0.6121372031662269, f1=0.6233062330623306, best_f1=0.6233062330623306
step: 0, loss: 0.0909612774848938
step: 10, loss: 0.087282694876194
step: 20, loss: 0.09214978665113449
step: 30, loss: 0.12851543724536896
step: 40, loss: 0.06395547837018967
step: 50, loss: 0.06645163148641586
step: 60, loss: 0.044750917702913284
step: 70, loss: 0.07355872541666031
step: 80, loss: 0.23010197281837463
step: 90, loss: 0.06618617475032806
step: 100, loss: 0.05016273632645607
step: 110, loss: 0.05502864718437195
step: 120, loss: 0.039531148970127106
step: 130, loss: 0.022799653932452202
step: 140, loss: 0.07793612033128738
step: 150, loss: 0.11615511029958725
step: 160, loss: 0.0951189249753952
step: 170, loss: 0.11232542991638184
step: 180, loss: 0.15811190009117126
step: 190, loss: 0.18531563878059387
step: 200, loss: 0.07223590463399887
step: 210, loss: 0.007875938899815083
step: 220, loss: 0.06152193248271942
step: 230, loss: 0.07552088797092438
step: 240, loss: 0.13050279021263123
step: 250, loss: 0.08073987066745758
step: 260, loss: 0.2267012894153595
step: 270, loss: 0.093454509973526
step: 280, loss: 0.07912663370370865
step: 290, loss: 0.04822321608662605
step: 300, loss: 0.1189025342464447
step: 310, loss: 0.03662016615271568
step: 320, loss: 0.09624004364013672
step: 330, loss: 0.10281249135732651
step: 340, loss: 0.022870341315865517
step: 350, loss: 0.11539769917726517
step: 360, loss: 0.08843441307544708
step: 370, loss: 0.04093971475958824
step: 380, loss: 0.055308591574430466
epoch 3: dev_f1=0.6431924882629109, f1=0.6504854368932039, best_f1=0.6504854368932039
step: 0, loss: 0.01009331364184618
step: 10, loss: 0.05177849903702736
step: 20, loss: 0.02843702957034111
step: 30, loss: 0.002646778244525194
step: 40, loss: 0.020312491804361343
step: 50, loss: 0.022245392203330994
step: 60, loss: 0.12566626071929932
step: 70, loss: 0.09739962220191956
step: 80, loss: 0.11355719715356827
step: 90, loss: 0.05593237653374672
step: 100, loss: 0.04389386624097824
step: 110, loss: 0.20059257745742798
step: 120, loss: 0.04069381207227707
step: 130, loss: 0.011077845469117165
step: 140, loss: 0.12019407749176025
step: 150, loss: 0.0693763941526413
step: 160, loss: 0.10394351184368134
step: 170, loss: 0.052106376737356186
step: 180, loss: 0.07772056013345718
step: 190, loss: 0.02152123861014843
step: 200, loss: 0.09697719663381577
step: 210, loss: 0.0522444024682045
step: 220, loss: 0.05285397544503212
step: 230, loss: 0.11419440060853958
step: 240, loss: 0.09405560791492462
step: 250, loss: 0.17712996900081635
step: 260, loss: 0.036637384444475174
step: 270, loss: 0.15254971385002136
step: 280, loss: 0.029628288000822067
step: 290, loss: 0.03299803286790848
step: 300, loss: 0.09726656228303909
step: 310, loss: 0.04564417898654938
step: 320, loss: 0.0500626415014267
step: 330, loss: 0.021849974989891052
step: 340, loss: 0.14031711220741272
step: 350, loss: 0.10197171568870544
step: 360, loss: 0.032082702964544296
step: 370, loss: 0.029448814690113068
step: 380, loss: 0.014844107441604137
epoch 4: dev_f1=0.6869158878504674, f1=0.7047619047619048, best_f1=0.7047619047619048
step: 0, loss: 0.027874410152435303
step: 10, loss: 0.08084379136562347
step: 20, loss: 0.015117556788027287
step: 30, loss: 0.01344913151115179
step: 40, loss: 0.05129719898104668
step: 50, loss: 0.03581570088863373
step: 60, loss: 0.03145500272512436
step: 70, loss: 0.07423804700374603
step: 80, loss: 0.10663960129022598
step: 90, loss: 0.07638382166624069
step: 100, loss: 0.045802533626556396
step: 110, loss: 0.11410180479288101
step: 120, loss: 0.07731480896472931
step: 130, loss: 0.06753947585821152
step: 140, loss: 0.06902074813842773
step: 150, loss: 0.013343974016606808
step: 160, loss: 0.04307928681373596
step: 170, loss: 0.04732421413064003
step: 180, loss: 0.1034465804696083
step: 190, loss: 0.02966764010488987
step: 200, loss: 0.1311638504266739
step: 210, loss: 0.017849521711468697
step: 220, loss: 0.035005129873752594
step: 230, loss: 0.16212089359760284
step: 240, loss: 0.16343942284584045
step: 250, loss: 0.26053449511528015
step: 260, loss: 0.14315901696681976
step: 270, loss: 0.16436609625816345
step: 280, loss: 0.0534953847527504
step: 290, loss: 0.07186013460159302
step: 300, loss: 0.22751006484031677
step: 310, loss: 0.052420273423194885
step: 320, loss: 0.08479313552379608
step: 330, loss: 0.03309537097811699
step: 340, loss: 0.00413262564688921
step: 350, loss: 0.08840616792440414
step: 360, loss: 0.06520364433526993
step: 370, loss: 0.06948164850473404
step: 380, loss: 0.042819708585739136
epoch 5: dev_f1=0.663316582914573, f1=0.6683804627249357, best_f1=0.7047619047619048
step: 0, loss: 0.03378074988722801
step: 10, loss: 0.04547528177499771
step: 20, loss: 0.00032622399157844484
step: 30, loss: 0.02260993979871273
step: 40, loss: 0.0270860455930233
step: 50, loss: 0.009873103350400925
step: 60, loss: 0.10420917719602585
step: 70, loss: 0.09841841459274292
step: 80, loss: 0.07515060901641846
step: 90, loss: 0.0353756919503212
step: 100, loss: 0.04716313257813454
step: 110, loss: 0.030294353142380714
step: 120, loss: 0.02458529733121395
step: 130, loss: 0.12049441784620285
step: 140, loss: 0.004668698646128178
step: 150, loss: 0.06847475469112396
step: 160, loss: 0.053680550307035446
step: 170, loss: 0.07157237082719803
step: 180, loss: 0.03690600395202637
step: 190, loss: 0.05431825667619705
step: 200, loss: 0.04559306427836418
step: 210, loss: 0.03291323408484459
step: 220, loss: 0.041765518486499786
step: 230, loss: 0.002940230304375291
step: 240, loss: 0.05648396909236908
step: 250, loss: 0.0022484574001282454
step: 260, loss: 0.04395546764135361
step: 270, loss: 0.002473030472174287
step: 280, loss: 0.09969671815633774
step: 290, loss: 0.08993379771709442
step: 300, loss: 0.011471863836050034
step: 310, loss: 0.027288639917969704
step: 320, loss: 0.07830294221639633
step: 330, loss: 0.09181584417819977
step: 340, loss: 0.1139180064201355
step: 350, loss: 0.127352774143219
step: 360, loss: 0.06207472085952759
step: 370, loss: 0.06383021175861359
step: 380, loss: 0.07884356379508972
epoch 6: dev_f1=0.6795180722891567, f1=0.7067307692307694, best_f1=0.7047619047619048
step: 0, loss: 0.03231814131140709
step: 10, loss: 0.04865061491727829
step: 20, loss: 0.05381720885634422
step: 30, loss: 0.021157344803214073
step: 40, loss: 0.03128569573163986
step: 50, loss: 0.025469284504652023
step: 60, loss: 0.024335796013474464
step: 70, loss: 0.15498165786266327
step: 80, loss: 0.001102746813558042
step: 90, loss: 0.05381373316049576
step: 100, loss: 0.017974451184272766
step: 110, loss: 0.04124000295996666
step: 120, loss: 0.017971783876419067
step: 130, loss: 0.0387396365404129
step: 140, loss: 0.013822748325765133
step: 150, loss: 0.0248276200145483
step: 160, loss: 0.01284027099609375
step: 170, loss: 0.09026114642620087
step: 180, loss: 0.07005514949560165
step: 190, loss: 0.04048977792263031
step: 200, loss: 0.03594578430056572
step: 210, loss: 0.10404759645462036
step: 220, loss: 0.0536261722445488
step: 230, loss: 0.11957837641239166
step: 240, loss: 0.06126823648810387
step: 250, loss: 0.14358417689800262
step: 260, loss: 0.016788484528660774
step: 270, loss: 0.006077936850488186
step: 280, loss: 0.04148717224597931
step: 290, loss: 0.030202161520719528
step: 300, loss: 0.025781434029340744
step: 310, loss: 0.041450731456279755
step: 320, loss: 0.04327687621116638
step: 330, loss: 0.03478764370083809
step: 340, loss: 0.06780673563480377
step: 350, loss: 0.03943093121051788
step: 360, loss: 0.03208872303366661
step: 370, loss: 0.012492879293859005
step: 380, loss: 0.0075083207339048386
epoch 7: dev_f1=0.6975609756097562, f1=0.7002518891687657, best_f1=0.7002518891687657
step: 0, loss: 0.010833446867763996
step: 10, loss: 0.006707093212753534
step: 20, loss: 0.01660430245101452
step: 30, loss: 0.05220051109790802
step: 40, loss: 0.003722615772858262
step: 50, loss: 0.02364746853709221
step: 60, loss: 0.024220440536737442
step: 70, loss: 0.20771564543247223
step: 80, loss: 0.0084020234644413
step: 90, loss: 0.029022246599197388
step: 100, loss: 0.0806872695684433
step: 110, loss: 0.09010238945484161
step: 120, loss: 0.024143461138010025
step: 130, loss: 0.009448711760342121
step: 140, loss: 0.055621396750211716
step: 150, loss: 0.05262315645813942
step: 160, loss: 0.026000825688242912
step: 170, loss: 0.024493932723999023
step: 180, loss: 0.008668201975524426
step: 190, loss: 0.05760149285197258
step: 200, loss: 0.00195907661691308
step: 210, loss: 0.015860343351960182
step: 220, loss: 0.012618369422852993
step: 230, loss: 0.03654605522751808
step: 240, loss: 0.07922417670488358
step: 250, loss: 0.0047443886287510395
step: 260, loss: 0.023647446185350418
step: 270, loss: 0.0404781699180603
step: 280, loss: 0.08272264897823334
step: 290, loss: 0.023854166269302368
step: 300, loss: 0.1920219510793686
step: 310, loss: 0.009931495413184166
step: 320, loss: 0.20494775474071503
step: 330, loss: 0.00809959415346384
step: 340, loss: 0.0007250542985275388
step: 350, loss: 0.014926052652299404
step: 360, loss: 0.010864391922950745
step: 370, loss: 0.10569322109222412
step: 380, loss: 0.00028917344752699137
epoch 8: dev_f1=0.7161125319693094, f1=0.7277486910994764, best_f1=0.7277486910994764
step: 0, loss: 0.03265836834907532
step: 10, loss: 0.11325735598802567
step: 20, loss: 0.15062658488750458
step: 30, loss: 0.10335659235715866
step: 40, loss: 0.0020548191387206316
step: 50, loss: 0.05511914938688278
step: 60, loss: 0.008108934387564659
step: 70, loss: 0.2685554623603821
step: 80, loss: 0.04450269788503647
step: 90, loss: 0.12322536110877991
step: 100, loss: 0.06244087591767311
step: 110, loss: 0.07045605033636093
step: 120, loss: 0.007306323852390051
step: 130, loss: 0.008007197640836239
step: 140, loss: 0.03409479558467865
step: 150, loss: 0.00586731918156147
step: 160, loss: 0.07670506089925766
step: 170, loss: 0.07385550439357758
step: 180, loss: 0.06267330795526505
step: 190, loss: 0.04184552654623985
step: 200, loss: 0.028489507734775543
step: 210, loss: 0.0012940139276906848
step: 220, loss: 0.025664417073130608
step: 230, loss: 0.09125802665948868
step: 240, loss: 0.02123274840414524
step: 250, loss: 0.069827601313591
step: 260, loss: 0.009110911749303341
step: 270, loss: 0.014496302232146263
step: 280, loss: 0.014285322278738022
step: 290, loss: 0.0134859848767519
step: 300, loss: 0.06441561877727509
step: 310, loss: 0.012991555035114288
step: 320, loss: 0.12992647290229797
step: 330, loss: 0.000687764841131866
step: 340, loss: 0.0499972365796566
step: 350, loss: 0.00963407289236784
step: 360, loss: 0.017424654215574265
step: 370, loss: 0.00919970590621233
step: 380, loss: 0.011113723739981651
epoch 9: dev_f1=0.6857142857142856, f1=0.6896551724137931, best_f1=0.7277486910994764
step: 0, loss: 0.051157839596271515
step: 10, loss: 0.004848405718803406
step: 20, loss: 0.01229857187718153
step: 30, loss: 0.05980462208390236
step: 40, loss: 0.002373782219365239
step: 50, loss: 0.008837799541652203
step: 60, loss: 0.00026168450131081045
step: 70, loss: 0.07415515929460526
step: 80, loss: 0.003062628675252199
step: 90, loss: 0.004784214776009321
step: 100, loss: 0.0003257608914282173
step: 110, loss: 0.13269735872745514
step: 120, loss: 0.018658936023712158
step: 130, loss: 0.022683165967464447
step: 140, loss: 0.00605733459815383
step: 150, loss: 0.17624445259571075
step: 160, loss: 0.04927660897374153
step: 170, loss: 0.00027711139409802854
step: 180, loss: 0.0004018269246444106
step: 190, loss: 0.0017314488068223
step: 200, loss: 0.05183863639831543
step: 210, loss: 0.05959085002541542
step: 220, loss: 0.02291949838399887
step: 230, loss: 0.07244069129228592
step: 240, loss: 0.006594410631805658
step: 250, loss: 0.006055637262761593
step: 260, loss: 0.01818656735122204
step: 270, loss: 0.05412791669368744
step: 280, loss: 0.02162436582148075
step: 290, loss: 0.0687033161520958
step: 300, loss: 0.007213713601231575
step: 310, loss: 0.0641835555434227
step: 320, loss: 0.057791873812675476
step: 330, loss: 0.02967679500579834
step: 340, loss: 0.009633781388401985
step: 350, loss: 0.06781713664531708
step: 360, loss: 0.030481692403554916
step: 370, loss: 0.14825782179832458
step: 380, loss: 0.11254876852035522
epoch 10: dev_f1=0.6698795180722893, f1=0.695, best_f1=0.7277486910994764
step: 0, loss: 0.029422370716929436
step: 10, loss: 0.07165863364934921
step: 20, loss: 0.06397834420204163
step: 30, loss: 0.07960831373929977
step: 40, loss: 0.002298472449183464
step: 50, loss: 0.009811040945351124
step: 60, loss: 0.008000041358172894
step: 70, loss: 0.040567852556705475
step: 80, loss: 0.00043268236913718283
step: 90, loss: 0.022253116592764854
step: 100, loss: 0.002744583413004875
step: 110, loss: 0.019435197114944458
step: 120, loss: 0.044852618128061295
step: 130, loss: 0.03941987827420235
step: 140, loss: 0.14257869124412537
step: 150, loss: 0.0004075518809258938
step: 160, loss: 0.00010136589844478294
step: 170, loss: 0.025540495291352272
step: 180, loss: 0.02720077708363533
step: 190, loss: 0.02601262368261814
step: 200, loss: 0.025539327412843704
step: 210, loss: 0.0893564224243164
step: 220, loss: 0.009981369599699974
step: 230, loss: 0.005510998424142599
step: 240, loss: 0.04903144761919975
step: 250, loss: 0.00501527264714241
step: 260, loss: 0.005876421928405762
step: 270, loss: 0.00012662496010307223
step: 280, loss: 0.0010010418482124805
step: 290, loss: 0.02921913005411625
step: 300, loss: 0.07220792025327682
step: 310, loss: 0.019698064774274826
step: 320, loss: 0.044193487614393234
step: 330, loss: 0.007679346948862076
step: 340, loss: 0.09831661731004715
step: 350, loss: 0.004703996703028679
step: 360, loss: 0.005922507029026747
step: 370, loss: 0.0014423244865611196
step: 380, loss: 0.03417045623064041
epoch 11: dev_f1=0.7053140096618358, f1=0.6892950391644909, best_f1=0.7277486910994764
step: 0, loss: 0.007332381326705217
step: 10, loss: 0.028892645612359047
step: 20, loss: 0.01663331314921379
step: 30, loss: 0.00960873905569315
step: 40, loss: 0.052421122789382935
step: 50, loss: 0.009084489196538925
step: 60, loss: 0.009130321443080902
step: 70, loss: 0.11290659755468369
step: 80, loss: 0.00925454217940569
step: 90, loss: 0.06043391302227974
step: 100, loss: 0.0017830993747338653
step: 110, loss: 0.02541976608335972
step: 120, loss: 0.07240743935108185
step: 130, loss: 0.02806469425559044
step: 140, loss: 0.027625275775790215
step: 150, loss: 0.022809958085417747
step: 160, loss: 0.011643223464488983
step: 170, loss: 0.016187069937586784
step: 180, loss: 0.018253028392791748
step: 190, loss: 0.05732588469982147
step: 200, loss: 0.06296771764755249
step: 210, loss: 0.04356234148144722
step: 220, loss: 0.015634970739483833
step: 230, loss: 0.03526391088962555
step: 240, loss: 0.0043675871565938
step: 250, loss: 0.0008166040061041713
step: 260, loss: 0.014042670838534832
step: 270, loss: 0.013665112666785717
step: 280, loss: 0.016741394996643066
step: 290, loss: 0.007173404097557068
step: 300, loss: 0.0001176592631964013
step: 310, loss: 0.10750074684619904
step: 320, loss: 0.03479239344596863
step: 330, loss: 0.04249574616551399
step: 340, loss: 0.0511866994202137
step: 350, loss: 0.0024890799541026354
step: 360, loss: 0.0925283133983612
step: 370, loss: 0.0009223631350323558
step: 380, loss: 0.006508261431008577
epoch 12: dev_f1=0.7154046997389033, f1=0.7135135135135134, best_f1=0.7277486910994764
step: 0, loss: 0.011137465015053749
step: 10, loss: 0.001242061727680266
step: 20, loss: 0.006684458814561367
step: 30, loss: 0.03139727562665939
step: 40, loss: 0.0387083999812603
step: 50, loss: 0.0024570762179791927
step: 60, loss: 0.021614698693156242
step: 70, loss: 0.01693408377468586
step: 80, loss: 0.03589934483170509
step: 90, loss: 0.007581300102174282
step: 100, loss: 0.006109958980232477
step: 110, loss: 0.0035714400000870228
step: 120, loss: 0.00023003722890280187
step: 130, loss: 0.024890096858143806
step: 140, loss: 0.005574056878685951
step: 150, loss: 0.001371956430375576
step: 160, loss: 0.051714275032281876
step: 170, loss: 0.047744616866111755
step: 180, loss: 0.023208465427160263
step: 190, loss: 0.014834003522992134
step: 200, loss: 0.002171366009861231
step: 210, loss: 0.00034554192097857594
step: 220, loss: 0.00022669846657663584
step: 230, loss: 0.004257150925695896
step: 240, loss: 0.010310424491763115
step: 250, loss: 0.06352511793375015
step: 260, loss: 0.0011915810173377395
step: 270, loss: 0.02338240295648575
step: 280, loss: 0.06271900981664658
step: 290, loss: 0.06527239829301834
step: 300, loss: 0.038308605551719666
step: 310, loss: 0.07925742864608765
step: 320, loss: 0.0016621307004243135
step: 330, loss: 0.02172972448170185
step: 340, loss: 0.015987969934940338
step: 350, loss: 0.06247367709875107
step: 360, loss: 0.007206513546407223
step: 370, loss: 0.07765145599842072
step: 380, loss: 0.021333204582333565
epoch 13: dev_f1=0.6914153132250579, f1=0.6814814814814815, best_f1=0.7277486910994764
step: 0, loss: 0.06389538198709488
step: 10, loss: 0.019921602681279182
step: 20, loss: 0.03747652843594551
step: 30, loss: 0.05424893647432327
step: 40, loss: 0.00400456553325057
step: 50, loss: 0.019559744745492935
step: 60, loss: 9.208238043356687e-05
step: 70, loss: 0.08868756890296936
step: 80, loss: 0.02909005805850029
step: 90, loss: 0.0052588265389204025
step: 100, loss: 0.0002818321227096021
step: 110, loss: 0.04017375782132149
step: 120, loss: 0.02641451731324196
step: 130, loss: 0.008933845907449722
step: 140, loss: 0.03145771101117134
step: 150, loss: 0.0774235874414444
step: 160, loss: 0.0025846478529274464
step: 170, loss: 8.312252612086013e-05
step: 180, loss: 0.038245007395744324
step: 190, loss: 0.0011117540998384356
step: 200, loss: 0.006085183005779982
step: 210, loss: 0.0015581289771944284
step: 220, loss: 0.0031110746785998344
step: 230, loss: 0.00038412524736486375
step: 240, loss: 0.00010142269456991926
step: 250, loss: 0.005408918485045433
step: 260, loss: 0.003045979654416442
step: 270, loss: 0.0635368600487709
step: 280, loss: 0.014630760066211224
step: 290, loss: 0.01859300397336483
step: 300, loss: 0.0041523706167936325
step: 310, loss: 0.011262880638241768
step: 320, loss: 0.0064935144037008286
step: 330, loss: 0.00494394963607192
step: 340, loss: 0.02247598208487034
step: 350, loss: 0.0799633339047432
step: 360, loss: 0.0994587317109108
step: 370, loss: 0.016920173540711403
step: 380, loss: 0.005326332524418831
epoch 14: dev_f1=0.7010869565217391, f1=0.6833333333333333, best_f1=0.7277486910994764
step: 0, loss: 0.0041473074816167355
step: 10, loss: 0.0027567585930228233
step: 20, loss: 0.0005143717280589044
step: 30, loss: 0.08556145429611206
step: 40, loss: 5.973618317511864e-05
step: 50, loss: 0.005678919143974781
step: 60, loss: 0.021977920085191727
step: 70, loss: 0.006714833900332451
step: 80, loss: 0.0029041131492704153
step: 90, loss: 0.037260230630636215
step: 100, loss: 0.05018875375390053
step: 110, loss: 0.03964832425117493
step: 120, loss: 0.01421630010008812
step: 130, loss: 0.053175006061792374
step: 140, loss: 0.02033207379281521
step: 150, loss: 0.014256693422794342
step: 160, loss: 8.734849689062685e-05
step: 170, loss: 0.0013798943255096674
step: 180, loss: 0.018334021791815758
step: 190, loss: 0.028816496953368187
step: 200, loss: 0.03637514263391495
step: 210, loss: 0.055023353546857834
step: 220, loss: 0.0009066322236321867
step: 230, loss: 0.058444418013095856
step: 240, loss: 0.008314170874655247
step: 250, loss: 0.01759614422917366
step: 260, loss: 0.08639199286699295
step: 270, loss: 0.06730282306671143
step: 280, loss: 0.018494999036192894
step: 290, loss: 0.007052644621580839
step: 300, loss: 0.03281250596046448
step: 310, loss: 0.018558628857135773
step: 320, loss: 0.08305791765451431
step: 330, loss: 0.034117694944143295
step: 340, loss: 0.019967621192336082
step: 350, loss: 6.799845141358674e-05
step: 360, loss: 0.003814649535343051
step: 370, loss: 0.05445904657244682
step: 380, loss: 0.001090998062863946
epoch 15: dev_f1=0.6898148148148148, f1=0.6908212560386474, best_f1=0.7277486910994764
step: 0, loss: 0.0029854183085262775
step: 10, loss: 0.011749358847737312
step: 20, loss: 0.005184789188206196
step: 30, loss: 0.03876210004091263
step: 40, loss: 0.023550599813461304
step: 50, loss: 0.0005133296945132315
step: 60, loss: 0.030299892649054527
step: 70, loss: 0.0022251203190535307
step: 80, loss: 0.0355449877679348
step: 90, loss: 0.036842361092567444
step: 100, loss: 0.0016552372835576534
step: 110, loss: 0.036444712430238724
step: 120, loss: 0.0072272359393537045
step: 130, loss: 0.0002504786825738847
step: 140, loss: 0.00957190990447998
step: 150, loss: 0.0054684774950146675
step: 160, loss: 0.0005301290657371283
step: 170, loss: 0.08088092505931854
step: 180, loss: 0.004892147146165371
step: 190, loss: 0.0834164023399353
step: 200, loss: 0.1082487627863884
step: 210, loss: 0.11538293212652206
step: 220, loss: 0.02810988947749138
step: 230, loss: 0.0004011891724076122
step: 240, loss: 0.0003651860752142966
step: 250, loss: 0.08314566314220428
step: 260, loss: 0.006900431588292122
step: 270, loss: 0.007975148968398571
step: 280, loss: 0.003955250605940819
step: 290, loss: 0.0402224026620388
step: 300, loss: 0.08252984285354614
step: 310, loss: 0.029768189415335655
step: 320, loss: 0.00012140547187300399
step: 330, loss: 0.0027833173517137766
step: 340, loss: 0.010828717611730099
step: 350, loss: 0.004355126991868019
step: 360, loss: 0.004205374978482723
step: 370, loss: 0.03133183717727661
step: 380, loss: 0.08083858340978622
epoch 16: dev_f1=0.6928746928746928, f1=0.6921119592875319, best_f1=0.7277486910994764
step: 0, loss: 0.019491469487547874
step: 10, loss: 0.0024646869860589504
step: 20, loss: 0.037998028099536896
step: 30, loss: 0.01690734550356865
step: 40, loss: 0.04606179893016815
step: 50, loss: 0.005670393351465464
step: 60, loss: 0.005637855269014835
step: 70, loss: 0.007795678451657295
step: 80, loss: 0.03995248302817345
step: 90, loss: 0.00023748259991407394
step: 100, loss: 0.08096028864383698
step: 110, loss: 0.007228778209537268
step: 120, loss: 0.0021269062999635935
step: 130, loss: 0.023820023983716965
step: 140, loss: 0.00048548722406849265
step: 150, loss: 7.846954395063221e-05
step: 160, loss: 0.03744965046644211
step: 170, loss: 0.014977216720581055
step: 180, loss: 0.08384047448635101
step: 190, loss: 0.026551246643066406
step: 200, loss: 0.0007702532457187772
step: 210, loss: 0.0009912146488204598
step: 220, loss: 0.024383720010519028
step: 230, loss: 0.02371741458773613
step: 240, loss: 0.042971789836883545
step: 250, loss: 0.0009127084631472826
step: 260, loss: 0.005262561608105898
step: 270, loss: 0.0010760698933154345
step: 280, loss: 0.05008159205317497
step: 290, loss: 0.019104231148958206
step: 300, loss: 0.06104893237352371
step: 310, loss: 0.036145564168691635
step: 320, loss: 0.004608415067195892
step: 330, loss: 9.428882913198322e-05
step: 340, loss: 0.03994990140199661
step: 350, loss: 0.0003465866611804813
step: 360, loss: 0.00022625697602052242
step: 370, loss: 0.004137153271585703
step: 380, loss: 0.001077796914614737
epoch 17: dev_f1=0.7085427135678392, f1=0.7071240105540898, best_f1=0.7277486910994764
step: 0, loss: 0.005540806334465742
step: 10, loss: 0.023952273651957512
step: 20, loss: 0.0021339699160307646
step: 30, loss: 6.768844468751922e-05
step: 40, loss: 5.238134690443985e-05
step: 50, loss: 0.002359881065785885
step: 60, loss: 0.03429749980568886
step: 70, loss: 0.00975631084293127
step: 80, loss: 0.016282057389616966
step: 90, loss: 0.018051225692033768
step: 100, loss: 0.0001194771975860931
step: 110, loss: 0.0020968453027307987
step: 120, loss: 0.004214138258248568
step: 130, loss: 0.0024682788643985987
step: 140, loss: 0.0385727621614933
step: 150, loss: 0.03357607126235962
step: 160, loss: 4.266217729309574e-05
step: 170, loss: 0.013159970752894878
step: 180, loss: 0.021789494901895523
step: 190, loss: 0.0014123705914244056
step: 200, loss: 0.04115625470876694
step: 210, loss: 0.006195304449647665
step: 220, loss: 0.005779114086180925
step: 230, loss: 0.020035797730088234
step: 240, loss: 0.0004566655261442065
step: 250, loss: 3.6859350075246766e-05
step: 260, loss: 0.09913910925388336
step: 270, loss: 0.030048351734876633
step: 280, loss: 0.002385825151577592
step: 290, loss: 0.03535814583301544
step: 300, loss: 0.0023482907563447952
step: 310, loss: 0.003587347222492099
step: 320, loss: 0.001973371719941497
step: 330, loss: 3.439382271608338e-05
step: 340, loss: 0.03526538982987404
step: 350, loss: 0.05596242472529411
step: 360, loss: 0.033364780247211456
step: 370, loss: 0.01601695455610752
step: 380, loss: 0.013363220728933811
epoch 18: dev_f1=0.6965699208443272, f1=0.6975476839237057, best_f1=0.7277486910994764
step: 0, loss: 0.020907290279865265
step: 10, loss: 0.005610451102256775
step: 20, loss: 0.012184211052954197
step: 30, loss: 0.05845937877893448
step: 40, loss: 0.030233066529035568
step: 50, loss: 0.037842780351638794
step: 60, loss: 0.04885348305106163
step: 70, loss: 0.02474168874323368
step: 80, loss: 0.02107010781764984
step: 90, loss: 0.021169062703847885
step: 100, loss: 0.010885629802942276
step: 110, loss: 0.0006195956375449896
step: 120, loss: 0.00015672655717935413
step: 130, loss: 0.05795994773507118
step: 140, loss: 0.0010825243080034852
step: 150, loss: 3.550761903170496e-05
step: 160, loss: 5.789925126009621e-05
step: 170, loss: 0.017664894461631775
step: 180, loss: 0.004211288411170244
step: 190, loss: 0.001011377782560885
step: 200, loss: 0.054661042988300323
step: 210, loss: 0.00013119161303620785
step: 220, loss: 0.0013903833460062742
step: 230, loss: 0.013210738077759743
step: 240, loss: 0.00819555576890707
step: 250, loss: 0.025928255170583725
step: 260, loss: 0.011323532089591026
step: 270, loss: 0.006517739500850439
step: 280, loss: 0.010687709785997868
step: 290, loss: 5.2819381380686536e-05
step: 300, loss: 7.465320231858641e-05
step: 310, loss: 0.014184120111167431
step: 320, loss: 0.006381205283105373
step: 330, loss: 0.031633567065000534
step: 340, loss: 0.04070298746228218
step: 350, loss: 0.006627481896430254
step: 360, loss: 0.027074551209807396
step: 370, loss: 0.00031656905775889754
step: 380, loss: 0.0004830064426641911
epoch 19: dev_f1=0.6910994764397905, f1=0.6935483870967742, best_f1=0.7277486910994764
step: 0, loss: 0.011089136824011803
step: 10, loss: 0.07663768529891968
step: 20, loss: 0.01598873734474182
step: 30, loss: 0.039848532527685165
step: 40, loss: 0.009806402027606964
step: 50, loss: 0.004280429799109697
step: 60, loss: 0.020794754847884178
step: 70, loss: 0.03839769586920738
step: 80, loss: 0.006180079188197851
step: 90, loss: 7.654086221009493e-05
step: 100, loss: 0.00011568811169127002
step: 110, loss: 0.04063763841986656
step: 120, loss: 0.004105826374143362
step: 130, loss: 0.02063353732228279
step: 140, loss: 0.11172949522733688
step: 150, loss: 0.029989879578351974
step: 160, loss: 0.0064345914870500565
step: 170, loss: 0.0007117326022125781
step: 180, loss: 0.06137619912624359
step: 190, loss: 0.017244918271899223
step: 200, loss: 0.00037654084735549986
step: 210, loss: 2.6899731892626733e-05
step: 220, loss: 0.0008282900089398026
step: 230, loss: 0.0723380371928215
step: 240, loss: 0.00010480338096385822
step: 250, loss: 0.021073810756206512
step: 260, loss: 0.047374092042446136
step: 270, loss: 0.0002540186687838286
step: 280, loss: 0.003876729402691126
step: 290, loss: 0.023301225155591965
step: 300, loss: 0.0038635910023003817
step: 310, loss: 5.232619878370315e-05
step: 320, loss: 0.02370459772646427
step: 330, loss: 0.0044820187613368034
step: 340, loss: 0.004561957903206348
step: 350, loss: 0.0004943137755617499
step: 360, loss: 0.041211552917957306
step: 370, loss: 0.05397013574838638
step: 380, loss: 0.0006938728620298207
epoch 20: dev_f1=0.7010309278350515, f1=0.6933333333333334, best_f1=0.7277486910994764
