cuda
Device: cuda
step: 0, loss: 0.6265584826469421
step: 10, loss: 0.25787633657455444
step: 20, loss: 0.250301331281662
step: 30, loss: 0.23987165093421936
step: 40, loss: 0.6055007576942444
step: 50, loss: 0.43938589096069336
step: 60, loss: 0.3013840615749359
step: 70, loss: 0.18222327530384064
step: 80, loss: 0.22963982820510864
step: 90, loss: 0.28233587741851807
step: 100, loss: 0.3945305645465851
step: 110, loss: 0.32908257842063904
step: 120, loss: 0.04749888554215431
step: 130, loss: 0.42325615882873535
step: 140, loss: 0.22951672971248627
step: 150, loss: 0.21780511736869812
step: 160, loss: 0.2925689220428467
step: 170, loss: 0.18327073752880096
step: 180, loss: 0.2617669403553009
step: 190, loss: 0.2581838071346283
step: 200, loss: 0.22960099577903748
step: 210, loss: 0.1485670506954193
step: 220, loss: 0.19976310431957245
step: 230, loss: 0.28873196244239807
step: 240, loss: 0.33959949016571045
step: 250, loss: 0.07311893999576569
step: 260, loss: 0.16903558373451233
step: 270, loss: 0.18121708929538727
step: 280, loss: 0.1944132298231125
step: 290, loss: 0.09145790338516235
step: 300, loss: 0.13660597801208496
step: 310, loss: 0.042872004210948944
step: 320, loss: 0.11727917194366455
step: 330, loss: 0.22382551431655884
step: 340, loss: 0.2848689556121826
step: 350, loss: 0.14587126672267914
step: 360, loss: 0.3275699019432068
step: 370, loss: 0.09069667011499405
step: 380, loss: 0.17656157910823822
epoch 1: dev_f1=0.5824742268041238, f1=0.610079575596817, best_f1=0.610079575596817
step: 0, loss: 0.0284750834107399
step: 10, loss: 0.11077232658863068
step: 20, loss: 0.17668122053146362
step: 30, loss: 0.15772077441215515
step: 40, loss: 0.11135818064212799
step: 50, loss: 0.10218000411987305
step: 60, loss: 0.06879834830760956
step: 70, loss: 0.14840257167816162
step: 80, loss: 0.17233550548553467
step: 90, loss: 0.0445544570684433
step: 100, loss: 0.0688595175743103
step: 110, loss: 0.12255436182022095
step: 120, loss: 0.08022727817296982
step: 130, loss: 0.06498399376869202
step: 140, loss: 0.1149800643324852
step: 150, loss: 0.09785608947277069
step: 160, loss: 0.07999491691589355
step: 170, loss: 0.031413063406944275
step: 180, loss: 0.06955544650554657
step: 190, loss: 0.09322609752416611
step: 200, loss: 0.3533092141151428
step: 210, loss: 0.0899670347571373
step: 220, loss: 0.10316548496484756
step: 230, loss: 0.19911766052246094
step: 240, loss: 0.05933434143662453
step: 250, loss: 0.0430014468729496
step: 260, loss: 0.08030615001916885
step: 270, loss: 0.04022664949297905
step: 280, loss: 0.008119589649140835
step: 290, loss: 0.011068890802562237
step: 300, loss: 0.05836937576532364
step: 310, loss: 0.09543819725513458
step: 320, loss: 0.06699759513139725
step: 330, loss: 0.2047329992055893
step: 340, loss: 0.30755284428596497
step: 350, loss: 0.1921413242816925
step: 360, loss: 0.019335927441716194
step: 370, loss: 0.11414700746536255
step: 380, loss: 0.11143288016319275
epoch 2: dev_f1=0.7047146401985112, f1=0.7100000000000001, best_f1=0.7100000000000001
step: 0, loss: 0.08310817927122116
step: 10, loss: 0.09584446251392365
step: 20, loss: 0.2009402960538864
step: 30, loss: 0.13694235682487488
step: 40, loss: 0.057947609573602676
step: 50, loss: 0.2808895409107208
step: 60, loss: 0.07439643144607544
step: 70, loss: 0.03478487581014633
step: 80, loss: 0.08356864750385284
step: 90, loss: 0.07303328812122345
step: 100, loss: 0.03006395325064659
step: 110, loss: 0.07626331597566605
step: 120, loss: 0.09882915019989014
step: 130, loss: 0.23259834945201874
step: 140, loss: 0.02694547362625599
step: 150, loss: 0.14371375739574432
step: 160, loss: 0.05854296684265137
step: 170, loss: 0.19446317851543427
step: 180, loss: 0.06414023041725159
step: 190, loss: 0.10233844071626663
step: 200, loss: 0.01932930387556553
step: 210, loss: 0.07272452861070633
step: 220, loss: 0.07933714985847473
step: 230, loss: 0.2512768507003784
step: 240, loss: 0.0682591050863266
step: 250, loss: 0.0664462223649025
step: 260, loss: 0.0780097097158432
step: 270, loss: 0.021026719361543655
step: 280, loss: 0.15520703792572021
step: 290, loss: 0.14262798428535461
step: 300, loss: 0.0768672525882721
step: 310, loss: 0.011712035164237022
step: 320, loss: 0.15802401304244995
step: 330, loss: 0.06724239140748978
step: 340, loss: 0.04995521157979965
step: 350, loss: 0.05630325525999069
step: 360, loss: 0.33396461606025696
step: 370, loss: 0.08166902512311935
step: 380, loss: 0.09930702298879623
epoch 3: dev_f1=0.6849999999999999, f1=0.7153284671532846, best_f1=0.7100000000000001
step: 0, loss: 0.043880678713321686
step: 10, loss: 0.18204404413700104
step: 20, loss: 0.12666122615337372
step: 30, loss: 0.15174421668052673
step: 40, loss: 0.21497508883476257
step: 50, loss: 0.0009895151015371084
step: 60, loss: 0.10227061808109283
step: 70, loss: 0.058167845010757446
step: 80, loss: 0.11494482308626175
step: 90, loss: 0.08883797377347946
step: 100, loss: 0.05356848984956741
step: 110, loss: 0.1717783659696579
step: 120, loss: 0.040445636957883835
step: 130, loss: 0.08725877106189728
step: 140, loss: 0.012452037073671818
step: 150, loss: 0.06742826849222183
step: 160, loss: 0.06656543165445328
step: 170, loss: 0.01058683916926384
step: 180, loss: 0.028416818007826805
step: 190, loss: 0.06913753598928452
step: 200, loss: 0.09954442083835602
step: 210, loss: 0.07430729269981384
step: 220, loss: 0.09326047450304031
step: 230, loss: 0.05974838510155678
step: 240, loss: 0.04112362489104271
step: 250, loss: 0.028604894876480103
step: 260, loss: 0.06287556141614914
step: 270, loss: 0.03828103095293045
step: 280, loss: 0.13031987845897675
step: 290, loss: 0.12377990037202835
step: 300, loss: 0.011091365478932858
step: 310, loss: 0.1404716968536377
step: 320, loss: 0.12640726566314697
step: 330, loss: 0.10814404487609863
step: 340, loss: 0.04124276340007782
step: 350, loss: 0.009755277074873447
step: 360, loss: 0.11415013670921326
step: 370, loss: 0.03989806026220322
step: 380, loss: 0.05259086564183235
epoch 4: dev_f1=0.7598039215686274, f1=0.7766497461928934, best_f1=0.7766497461928934
step: 0, loss: 0.08951776474714279
step: 10, loss: 0.034435171633958817
step: 20, loss: 0.04296322166919708
step: 30, loss: 0.038447435945272446
step: 40, loss: 0.047388169914484024
step: 50, loss: 0.015227277763187885
step: 60, loss: 0.06034845858812332
step: 70, loss: 0.04326242953538895
step: 80, loss: 0.1049557700753212
step: 90, loss: 0.07409582287073135
step: 100, loss: 0.050661761313676834
step: 110, loss: 0.093014657497406
step: 120, loss: 0.01697295531630516
step: 130, loss: 0.011157095432281494
step: 140, loss: 0.0046593863517045975
step: 150, loss: 0.09686262905597687
step: 160, loss: 0.11565310508012772
step: 170, loss: 0.06828539073467255
step: 180, loss: 0.009089523926377296
step: 190, loss: 0.06726005673408508
step: 200, loss: 0.05951964482665062
step: 210, loss: 0.07777943462133408
step: 220, loss: 0.07318048924207687
step: 230, loss: 0.061235781759023666
step: 240, loss: 0.023520635440945625
step: 250, loss: 0.016793113201856613
step: 260, loss: 0.04261479899287224
step: 270, loss: 0.06239597871899605
step: 280, loss: 0.07094484567642212
step: 290, loss: 0.03272123262286186
step: 300, loss: 0.014038356952369213
step: 310, loss: 0.15524892508983612
step: 320, loss: 0.0823315680027008
step: 330, loss: 0.07934357225894928
step: 340, loss: 0.02939760871231556
step: 350, loss: 0.045973628759384155
step: 360, loss: 0.07930799573659897
step: 370, loss: 0.04727347567677498
step: 380, loss: 0.025152744725346565
epoch 5: dev_f1=0.7342995169082126, f1=0.7381546134663343, best_f1=0.7766497461928934
step: 0, loss: 0.03607171028852463
step: 10, loss: 0.08706052601337433
step: 20, loss: 0.09442674368619919
step: 30, loss: 0.03602093458175659
step: 40, loss: 0.034503642469644547
step: 50, loss: 0.055271685123443604
step: 60, loss: 0.08246203511953354
step: 70, loss: 0.07000002264976501
step: 80, loss: 0.04464652016758919
step: 90, loss: 0.017464539036154747
step: 100, loss: 0.045810334384441376
step: 110, loss: 0.10180331021547318
step: 120, loss: 0.025359081104397774
step: 130, loss: 0.129307359457016
step: 140, loss: 0.024417297914624214
step: 150, loss: 0.08466500043869019
step: 160, loss: 0.02297893352806568
step: 170, loss: 0.08593273907899857
step: 180, loss: 0.08524473011493683
step: 190, loss: 0.044267650693655014
step: 200, loss: 0.07428941130638123
step: 210, loss: 0.021563712507486343
step: 220, loss: 0.042068950831890106
step: 230, loss: 0.02380824275314808
step: 240, loss: 0.06058624014258385
step: 250, loss: 0.08613208681344986
step: 260, loss: 0.005529952235519886
step: 270, loss: 0.023569973185658455
step: 280, loss: 0.00939478725194931
step: 290, loss: 0.014585703611373901
step: 300, loss: 0.03294818103313446
step: 310, loss: 0.032116204500198364
step: 320, loss: 0.1827813684940338
step: 330, loss: 0.0982784628868103
step: 340, loss: 0.030338875949382782
step: 350, loss: 0.10832356661558151
step: 360, loss: 0.011278671212494373
step: 370, loss: 0.051432520151138306
step: 380, loss: 0.04632885754108429
epoch 6: dev_f1=0.7250608272506084, f1=0.7304785894206549, best_f1=0.7766497461928934
step: 0, loss: 0.009554008021950722
step: 10, loss: 0.07860981673002243
step: 20, loss: 0.037132732570171356
step: 30, loss: 0.016746845096349716
step: 40, loss: 0.0005305391969159245
step: 50, loss: 0.10382736474275589
step: 60, loss: 0.05233879014849663
step: 70, loss: 0.007056866772472858
step: 80, loss: 0.06768377125263214
step: 90, loss: 0.08254638314247131
step: 100, loss: 0.03416036069393158
step: 110, loss: 0.08705135434865952
step: 120, loss: 0.033780746161937714
step: 130, loss: 0.026411259546875954
step: 140, loss: 0.009665346704423428
step: 150, loss: 0.07395517081022263
step: 160, loss: 0.07289382070302963
step: 170, loss: 0.007008157204836607
step: 180, loss: 0.04384170100092888
step: 190, loss: 0.023462854325771332
step: 200, loss: 0.03738341107964516
step: 210, loss: 0.031537193804979324
step: 220, loss: 0.07178351283073425
step: 230, loss: 0.026999395340681076
step: 240, loss: 0.0007171964971348643
step: 250, loss: 0.05555359274148941
step: 260, loss: 0.010472008027136326
step: 270, loss: 0.16850614547729492
step: 280, loss: 0.02448434941470623
step: 290, loss: 0.07240743935108185
step: 300, loss: 0.0038003462832421064
step: 310, loss: 0.0842590183019638
step: 320, loss: 0.10724440217018127
step: 330, loss: 0.05885148048400879
step: 340, loss: 0.03029252216219902
step: 350, loss: 0.03719750791788101
step: 360, loss: 0.07815457880496979
step: 370, loss: 0.09947451949119568
step: 380, loss: 0.039663009345531464
epoch 7: dev_f1=0.7235142118863048, f1=0.7365591397849462, best_f1=0.7766497461928934
step: 0, loss: 0.09854308515787125
step: 10, loss: 0.07100966572761536
step: 20, loss: 0.03600150719285011
step: 30, loss: 0.10323818773031235
step: 40, loss: 0.018391119316220284
step: 50, loss: 0.028426822274923325
step: 60, loss: 0.05860309675335884
step: 70, loss: 0.00997138675302267
step: 80, loss: 0.013736722990870476
step: 90, loss: 0.013065755367279053
step: 100, loss: 0.04205632582306862
step: 110, loss: 0.042322710156440735
step: 120, loss: 0.02630114182829857
step: 130, loss: 0.06501348316669464
step: 140, loss: 0.023405710235238075
step: 150, loss: 0.013741878792643547
step: 160, loss: 0.006056186277419329
step: 170, loss: 0.02929164282977581
step: 180, loss: 0.019599203020334244
step: 190, loss: 0.0005477570812217891
step: 200, loss: 0.01172567531466484
step: 210, loss: 0.07318482547998428
step: 220, loss: 0.04089145362377167
step: 230, loss: 0.05144719406962395
step: 240, loss: 0.04184133931994438
step: 250, loss: 0.04236838221549988
step: 260, loss: 0.024058105424046516
step: 270, loss: 0.004908565431833267
step: 280, loss: 0.0003016804112121463
step: 290, loss: 0.00845937430858612
step: 300, loss: 0.0006030307849869132
step: 310, loss: 0.013952931389212608
step: 320, loss: 0.016278322786092758
step: 330, loss: 0.10227134823799133
step: 340, loss: 0.030734088271856308
step: 350, loss: 0.003898459952324629
step: 360, loss: 0.014994634315371513
step: 370, loss: 0.07795760780572891
step: 380, loss: 0.001821705256588757
epoch 8: dev_f1=0.7383863080684596, f1=0.7425742574257426, best_f1=0.7766497461928934
step: 0, loss: 0.03630713373422623
step: 10, loss: 0.05995924770832062
step: 20, loss: 0.004634968936443329
step: 30, loss: 0.0286738071590662
step: 40, loss: 0.006853419356048107
step: 50, loss: 0.0048131574876606464
step: 60, loss: 0.002828785218298435
step: 70, loss: 0.004066959954798222
step: 80, loss: 0.0009257515193894506
step: 90, loss: 0.1923476904630661
step: 100, loss: 0.030142929404973984
step: 110, loss: 0.051414888352155685
step: 120, loss: 0.01495154295116663
step: 130, loss: 0.01021003257483244
step: 140, loss: 0.04045375809073448
step: 150, loss: 0.10443467646837234
step: 160, loss: 0.04249197617173195
step: 170, loss: 0.034843988716602325
step: 180, loss: 0.010088600218296051
step: 190, loss: 0.04793167486786842
step: 200, loss: 0.0841183289885521
step: 210, loss: 0.05160015448927879
step: 220, loss: 0.077975332736969
step: 230, loss: 0.0010523608652874827
step: 240, loss: 0.08641301095485687
step: 250, loss: 0.024360021576285362
step: 260, loss: 0.036629218608140945
step: 270, loss: 0.042796339839696884
step: 280, loss: 0.12525877356529236
step: 290, loss: 0.0010522680822759867
step: 300, loss: 0.004474211949855089
step: 310, loss: 0.1324303150177002
step: 320, loss: 0.011124702170491219
step: 330, loss: 0.00693995738402009
step: 340, loss: 0.019219260662794113
step: 350, loss: 0.05438661575317383
step: 360, loss: 0.12469878792762756
step: 370, loss: 0.004412179812788963
step: 380, loss: 0.04810256138443947
epoch 9: dev_f1=0.7164948453608248, f1=0.7008086253369272, best_f1=0.7766497461928934
step: 0, loss: 0.08173330873250961
step: 10, loss: 0.016871340572834015
step: 20, loss: 0.058792296797037125
step: 30, loss: 0.03952945023775101
step: 40, loss: 0.01774286851286888
step: 50, loss: 0.03810392692685127
step: 60, loss: 0.002645954256877303
step: 70, loss: 0.0009278489742428064
step: 80, loss: 0.004604762885719538
step: 90, loss: 0.010974408127367496
step: 100, loss: 0.003870687447488308
step: 110, loss: 0.013712746091187
step: 120, loss: 0.054912764579057693
step: 130, loss: 0.04278293997049332
step: 140, loss: 0.0002327487018192187
step: 150, loss: 0.010078363120555878
step: 160, loss: 0.10612548142671585
step: 170, loss: 0.01534750685095787
step: 180, loss: 0.08453550189733505
step: 190, loss: 0.04886310547590256
step: 200, loss: 0.010932087898254395
step: 210, loss: 0.020482998341321945
step: 220, loss: 0.004621782340109348
step: 230, loss: 0.014637821353971958
step: 240, loss: 0.05058492720127106
step: 250, loss: 0.0048858667723834515
step: 260, loss: 0.01921561360359192
step: 270, loss: 0.09577559679746628
step: 280, loss: 0.09888279438018799
step: 290, loss: 0.08444032818078995
step: 300, loss: 0.013155514374375343
step: 310, loss: 0.0021190259139984846
step: 320, loss: 0.013064214028418064
step: 330, loss: 0.0543033666908741
step: 340, loss: 0.024465730413794518
step: 350, loss: 0.011988213285803795
step: 360, loss: 0.007904045283794403
step: 370, loss: 0.024452971294522285
step: 380, loss: 0.020774032920598984
epoch 10: dev_f1=0.7349081364829396, f1=0.7127659574468086, best_f1=0.7766497461928934
step: 0, loss: 0.03222837671637535
step: 10, loss: 0.00020256155403330922
step: 20, loss: 0.024749351665377617
step: 30, loss: 0.051059842109680176
step: 40, loss: 0.05834313482046127
step: 50, loss: 0.06609278172254562
step: 60, loss: 0.06640191376209259
step: 70, loss: 0.015348801389336586
step: 80, loss: 0.06687271595001221
step: 90, loss: 0.006622119341045618
step: 100, loss: 0.008809984661638737
step: 110, loss: 0.08205750584602356
step: 120, loss: 0.05860873684287071
step: 130, loss: 0.0008312796708196402
step: 140, loss: 9.035282710101455e-05
step: 150, loss: 0.029020749032497406
step: 160, loss: 0.10392851382493973
step: 170, loss: 0.0065842787735164165
step: 180, loss: 0.05530138686299324
step: 190, loss: 0.013461281545460224
step: 200, loss: 0.02066393569111824
step: 210, loss: 0.06414137780666351
step: 220, loss: 0.09298215806484222
step: 230, loss: 0.004433410707861185
step: 240, loss: 0.04310866445302963
step: 250, loss: 0.07329807430505753
step: 260, loss: 0.017159024253487587
step: 270, loss: 0.002015847247093916
step: 280, loss: 0.09527021646499634
step: 290, loss: 0.18787533044815063
step: 300, loss: 0.09461641311645508
step: 310, loss: 0.015512678772211075
step: 320, loss: 0.007365591358393431
step: 330, loss: 0.12332490086555481
step: 340, loss: 0.06273400038480759
step: 350, loss: 0.022140854969620705
step: 360, loss: 0.025211196392774582
step: 370, loss: 0.05233650282025337
step: 380, loss: 0.03396610915660858
epoch 11: dev_f1=0.7358024691358025, f1=0.7222222222222223, best_f1=0.7766497461928934
step: 0, loss: 0.08322784304618835
step: 10, loss: 0.0013576773926615715
step: 20, loss: 0.02751333825290203
step: 30, loss: 0.017904132604599
step: 40, loss: 0.0009056219132617116
step: 50, loss: 0.004657263867557049
step: 60, loss: 0.02987336553633213
step: 70, loss: 0.004814023617655039
step: 80, loss: 0.05256667733192444
step: 90, loss: 0.07927912473678589
step: 100, loss: 0.035499852150678635
step: 110, loss: 0.0010458662873134017
step: 120, loss: 0.004031823482364416
step: 130, loss: 0.012863939628005028
step: 140, loss: 0.04827724024653435
step: 150, loss: 0.015683112666010857
step: 160, loss: 0.014617804437875748
step: 170, loss: 0.011606215499341488
step: 180, loss: 0.0074459342285990715
step: 190, loss: 0.004321882035583258
step: 200, loss: 0.032750461250543594
step: 210, loss: 0.003071743994951248
step: 220, loss: 0.015434196218848228
step: 230, loss: 0.17162424325942993
step: 240, loss: 0.04117955267429352
step: 250, loss: 0.07650688290596008
step: 260, loss: 0.00023786944802850485
step: 270, loss: 0.025969458743929863
step: 280, loss: 0.04375475272536278
step: 290, loss: 0.05811075493693352
step: 300, loss: 0.034842297434806824
step: 310, loss: 0.12013448029756546
step: 320, loss: 0.10965147614479065
step: 330, loss: 0.03960587456822395
step: 340, loss: 0.00021083712636027485
step: 350, loss: 0.011597203090786934
step: 360, loss: 0.01539943739771843
step: 370, loss: 0.003424812341108918
step: 380, loss: 0.0978403240442276
epoch 12: dev_f1=0.7157360406091372, f1=0.7154046997389033, best_f1=0.7766497461928934
step: 0, loss: 0.04871191456913948
step: 10, loss: 0.006878901273012161
step: 20, loss: 0.022573156282305717
step: 30, loss: 0.0796104222536087
step: 40, loss: 0.022123346105217934
step: 50, loss: 0.02184099517762661
step: 60, loss: 0.0004109805158805102
step: 70, loss: 0.006933894008398056
step: 80, loss: 0.00026787814567796886
step: 90, loss: 4.018257459392771e-05
step: 100, loss: 0.020870273932814598
step: 110, loss: 0.009109853766858578
step: 120, loss: 0.004657387267798185
step: 130, loss: 0.009574180468916893
step: 140, loss: 0.005866784602403641
step: 150, loss: 0.004882078152149916
step: 160, loss: 0.007234289310872555
step: 170, loss: 0.02248859405517578
step: 180, loss: 0.002260053064674139
step: 190, loss: 0.0029045178089290857
step: 200, loss: 0.003105693031102419
step: 210, loss: 0.02054678276181221
step: 220, loss: 0.07702697068452835
step: 230, loss: 0.028765011578798294
step: 240, loss: 0.04830899089574814
step: 250, loss: 0.05201899632811546
step: 260, loss: 0.0033336204942315817
step: 270, loss: 7.012183050392196e-05
step: 280, loss: 0.004377804696559906
step: 290, loss: 0.02889060787856579
step: 300, loss: 0.012500185519456863
step: 310, loss: 0.004283033777028322
step: 320, loss: 0.05244665965437889
step: 330, loss: 0.06397224962711334
step: 340, loss: 0.00483772624284029
step: 350, loss: 0.0054902974516153336
step: 360, loss: 0.006396800745278597
step: 370, loss: 0.006815182976424694
step: 380, loss: 5.5273201724048704e-05
epoch 13: dev_f1=0.7178082191780822, f1=0.711484593837535, best_f1=0.7766497461928934
step: 0, loss: 0.01932680606842041
step: 10, loss: 0.0003695228951983154
step: 20, loss: 0.025025438517332077
step: 30, loss: 0.013051494024693966
step: 40, loss: 0.017743855714797974
step: 50, loss: 0.03615707904100418
step: 60, loss: 0.03958192840218544
step: 70, loss: 0.0015797021333128214
step: 80, loss: 0.1950392723083496
step: 90, loss: 4.9357040552422404e-05
step: 100, loss: 0.03713231906294823
step: 110, loss: 0.0014077461091801524
step: 120, loss: 0.0046342783607542515
step: 130, loss: 0.05663415417075157
step: 140, loss: 0.05293528735637665
step: 150, loss: 0.03590007871389389
step: 160, loss: 0.023395292460918427
step: 170, loss: 0.007064397446811199
step: 180, loss: 0.0808991938829422
step: 190, loss: 0.0634612888097763
step: 200, loss: 0.005808643065392971
step: 210, loss: 0.06636356562376022
step: 220, loss: 0.042973216623067856
step: 230, loss: 0.15325571596622467
step: 240, loss: 0.003244639141485095
step: 250, loss: 0.0014130697818472981
step: 260, loss: 0.026984572410583496
step: 270, loss: 0.00021502471645362675
step: 280, loss: 0.035333096981048584
step: 290, loss: 0.009425055235624313
step: 300, loss: 0.04778826981782913
step: 310, loss: 0.00030686723766848445
step: 320, loss: 0.00048636874998919666
step: 330, loss: 0.01587541401386261
step: 340, loss: 0.017579367384314537
step: 350, loss: 0.037440136075019836
step: 360, loss: 0.013981676660478115
step: 370, loss: 0.006260701920837164
step: 380, loss: 0.005879437550902367
epoch 14: dev_f1=0.7222222222222223, f1=0.7044917257683215, best_f1=0.7766497461928934
step: 0, loss: 0.00024080986622720957
step: 10, loss: 0.04601326212286949
step: 20, loss: 0.016557173803448677
step: 30, loss: 0.0009420416317880154
step: 40, loss: 0.08185847103595734
step: 50, loss: 0.0010033081052824855
step: 60, loss: 0.003685381729155779
step: 70, loss: 0.0060310992412269115
step: 80, loss: 0.00015613572031725198
step: 90, loss: 0.09127829223871231
step: 100, loss: 0.09708332270383835
step: 110, loss: 0.0006070527015253901
step: 120, loss: 0.0005395645857788622
step: 130, loss: 0.04839642718434334
step: 140, loss: 0.04169376567006111
step: 150, loss: 0.00898487213999033
step: 160, loss: 0.08338743448257446
step: 170, loss: 6.821312854299322e-05
step: 180, loss: 0.00030781482928432524
step: 190, loss: 0.03788858279585838
step: 200, loss: 0.0007719931891188025
step: 210, loss: 0.11125174909830093
step: 220, loss: 0.019504107534885406
step: 230, loss: 0.05765092372894287
step: 240, loss: 0.0006076045101508498
step: 250, loss: 0.036041684448719025
step: 260, loss: 0.012132396921515465
step: 270, loss: 0.03822645917534828
step: 280, loss: 0.02446146495640278
step: 290, loss: 0.002068527974188328
step: 300, loss: 0.01792885735630989
step: 310, loss: 0.003622692311182618
step: 320, loss: 0.033790986984968185
step: 330, loss: 0.06502934545278549
step: 340, loss: 0.06784427165985107
step: 350, loss: 0.02868686616420746
step: 360, loss: 0.027549806982278824
step: 370, loss: 0.041895393282175064
step: 380, loss: 0.11583548039197922
epoch 15: dev_f1=0.7251732101616629, f1=0.7347931873479319, best_f1=0.7766497461928934
step: 0, loss: 0.0003082458861172199
step: 10, loss: 0.03395390138030052
step: 20, loss: 0.05262357369065285
step: 30, loss: 0.00032426559482701123
step: 40, loss: 0.09332342445850372
step: 50, loss: 0.038671769201755524
step: 60, loss: 0.0073227668181061745
step: 70, loss: 0.015497607178986073
step: 80, loss: 0.03686569631099701
step: 90, loss: 0.03646813705563545
step: 100, loss: 0.00458513805642724
step: 110, loss: 0.02908720076084137
step: 120, loss: 0.006544893607497215
step: 130, loss: 0.026752877980470657
step: 140, loss: 0.022434772923588753
step: 150, loss: 0.00035932986065745354
step: 160, loss: 0.0007010711124166846
step: 170, loss: 0.0034192861057817936
step: 180, loss: 0.007329889107495546
step: 190, loss: 0.04071476683020592
step: 200, loss: 0.04679589346051216
step: 210, loss: 0.03193291649222374
step: 220, loss: 3.795863813138567e-05
step: 230, loss: 0.03894487023353577
step: 240, loss: 0.0030525927431881428
step: 250, loss: 0.0003016101545654237
step: 260, loss: 0.04810454696416855
step: 270, loss: 0.0009742408874444664
step: 280, loss: 0.001348293968476355
step: 290, loss: 0.03104904294013977
step: 300, loss: 0.03799891099333763
step: 310, loss: 0.004977132193744183
step: 320, loss: 0.03172849491238594
step: 330, loss: 0.0038648282643407583
step: 340, loss: 0.0007224943838082254
step: 350, loss: 0.00047585470019839704
step: 360, loss: 0.00504635414108634
step: 370, loss: 0.03269369900226593
step: 380, loss: 0.011873784475028515
epoch 16: dev_f1=0.731934731934732, f1=0.7216981132075472, best_f1=0.7766497461928934
step: 0, loss: 0.0031172707676887512
step: 10, loss: 0.002894689328968525
step: 20, loss: 0.007612613029778004
step: 30, loss: 0.03538837656378746
step: 40, loss: 0.01965291053056717
step: 50, loss: 0.10333172976970673
step: 60, loss: 0.061193399131298065
step: 70, loss: 0.03514822572469711
step: 80, loss: 0.007573941722512245
step: 90, loss: 0.012276837602257729
step: 100, loss: 0.06458240002393723
step: 110, loss: 0.020933663472533226
step: 120, loss: 0.008147858083248138
step: 130, loss: 2.0808980480069295e-05
step: 140, loss: 0.020762817934155464
step: 150, loss: 0.0028727694880217314
step: 160, loss: 0.010490156710147858
step: 170, loss: 3.833428490906954e-05
step: 180, loss: 0.042461127042770386
step: 190, loss: 0.08618780970573425
step: 200, loss: 0.019902318716049194
step: 210, loss: 0.0007832816918380558
step: 220, loss: 0.013062560930848122
step: 230, loss: 0.0011903290869668126
step: 240, loss: 0.028949376195669174
step: 250, loss: 0.013728022575378418
step: 260, loss: 0.05504563823342323
step: 270, loss: 0.04913489148020744
step: 280, loss: 0.04608191177248955
step: 290, loss: 0.02988128364086151
step: 300, loss: 0.006151070352643728
step: 310, loss: 0.00013054930604994297
step: 320, loss: 7.619095413247123e-05
step: 330, loss: 0.004132769536226988
step: 340, loss: 5.4025189456297085e-05
step: 350, loss: 8.090017217909917e-05
step: 360, loss: 0.009535722434520721
step: 370, loss: 9.573816350894049e-05
step: 380, loss: 0.010853547602891922
epoch 17: dev_f1=0.7233009708737864, f1=0.7213930348258706, best_f1=0.7766497461928934
step: 0, loss: 0.021908888593316078
step: 10, loss: 0.008246561512351036
step: 20, loss: 0.00013910407142248005
step: 30, loss: 0.0030185310170054436
step: 40, loss: 0.001973961479961872
step: 50, loss: 0.06455003470182419
step: 60, loss: 0.0021430125925689936
step: 70, loss: 0.07677881419658661
step: 80, loss: 4.01740035158582e-05
step: 90, loss: 0.057666998356580734
step: 100, loss: 0.005672675557434559
step: 110, loss: 0.01181380171328783
step: 120, loss: 4.020864435005933e-05
step: 130, loss: 3.3887612516991794e-05
step: 140, loss: 0.03118850849568844
step: 150, loss: 0.06926914304494858
step: 160, loss: 0.0007224238943308592
step: 170, loss: 0.0101860286667943
step: 180, loss: 0.00030802079709246755
step: 190, loss: 0.039651889353990555
step: 200, loss: 0.06358861923217773
step: 210, loss: 0.00037853949470445514
step: 220, loss: 0.003129196586087346
step: 230, loss: 0.0017472460167482495
step: 240, loss: 0.04390788450837135
step: 250, loss: 7.26272483007051e-05
step: 260, loss: 0.002878031460568309
step: 270, loss: 0.00038427094114013016
step: 280, loss: 0.033239174634218216
step: 290, loss: 0.04330264776945114
step: 300, loss: 0.00017418261268176138
step: 310, loss: 0.000718672527000308
step: 320, loss: 0.00015784775314386934
step: 330, loss: 0.008315053768455982
step: 340, loss: 0.0024399126414209604
step: 350, loss: 0.0659227967262268
step: 360, loss: 0.002187153557315469
step: 370, loss: 0.0008585973992012441
step: 380, loss: 0.054095037281513214
epoch 18: dev_f1=0.7125307125307127, f1=0.7268170426065164, best_f1=0.7766497461928934
step: 0, loss: 0.030878305435180664
step: 10, loss: 0.011559820733964443
step: 20, loss: 0.0003563496866263449
step: 30, loss: 0.021156812086701393
step: 40, loss: 0.0010078352643176913
step: 50, loss: 0.016995079815387726
step: 60, loss: 0.024286309257149696
step: 70, loss: 0.007064561825245619
step: 80, loss: 0.0370391309261322
step: 90, loss: 7.030748383840546e-05
step: 100, loss: 0.029179830104112625
step: 110, loss: 0.027608348056674004
step: 120, loss: 0.007793640252202749
step: 130, loss: 0.06740214675664902
step: 140, loss: 6.40984799247235e-05
step: 150, loss: 0.06411822885274887
step: 160, loss: 0.0011112670181319118
step: 170, loss: 0.014128535985946655
step: 180, loss: 0.00993281602859497
step: 190, loss: 0.015776533633470535
step: 200, loss: 0.029352281242609024
step: 210, loss: 0.0336630642414093
step: 220, loss: 0.013943931087851524
step: 230, loss: 0.002374067436903715
step: 240, loss: 0.035842567682266235
step: 250, loss: 0.040921226143836975
step: 260, loss: 0.00020017258066218346
step: 270, loss: 0.015922117978334427
step: 280, loss: 0.047118812799453735
step: 290, loss: 0.0463348887860775
step: 300, loss: 0.01607574336230755
step: 310, loss: 0.11685831099748611
step: 320, loss: 0.00030339485965669155
step: 330, loss: 0.04015790671110153
step: 340, loss: 0.03480088710784912
step: 350, loss: 0.0035005907993763685
step: 360, loss: 0.012163608334958553
step: 370, loss: 0.0034122206270694733
step: 380, loss: 0.0268329456448555
epoch 19: dev_f1=0.7061728395061728, f1=0.7189873417721518, best_f1=0.7766497461928934
step: 0, loss: 0.0201485063880682
step: 10, loss: 0.02131851576268673
step: 20, loss: 0.00028868758818134665
step: 30, loss: 2.5346189431729726e-05
step: 40, loss: 0.00015160208567976952
step: 50, loss: 0.03375553712248802
step: 60, loss: 0.0016365783521905541
step: 70, loss: 2.4872997528291307e-05
step: 80, loss: 0.06164787337183952
step: 90, loss: 0.00034252021578140557
step: 100, loss: 0.000196967288502492
step: 110, loss: 0.012307674624025822
step: 120, loss: 0.020755548030138016
step: 130, loss: 0.03496396169066429
step: 140, loss: 0.03544405847787857
step: 150, loss: 0.03971683979034424
step: 160, loss: 0.0010781011078506708
step: 170, loss: 0.02884483151137829
step: 180, loss: 0.01553820539265871
step: 190, loss: 0.03524705395102501
step: 200, loss: 0.025098882615566254
step: 210, loss: 0.0009728182922117412
step: 220, loss: 0.02917032688856125
step: 230, loss: 0.0005372059531509876
step: 240, loss: 0.014147359877824783
step: 250, loss: 0.07482457906007767
step: 260, loss: 0.00015785687719471753
step: 270, loss: 1.684925337031018e-05
step: 280, loss: 0.0002942827413789928
step: 290, loss: 2.6891735615208745e-05
step: 300, loss: 0.004228216130286455
step: 310, loss: 6.294099875958636e-05
step: 320, loss: 0.000168855520314537
step: 330, loss: 0.026667749509215355
step: 340, loss: 0.014077721163630486
step: 350, loss: 0.03404109925031662
step: 360, loss: 0.04187167063355446
step: 370, loss: 0.017472468316555023
step: 380, loss: 0.0018667079275473952
epoch 20: dev_f1=0.7050000000000001, f1=0.724935732647815, best_f1=0.7766497461928934
