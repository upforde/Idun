cuda
Device: cuda
step: 0, loss: 0.7322009205818176
step: 10, loss: 0.16117893159389496
step: 20, loss: 0.5983960628509521
step: 30, loss: 0.31333160400390625
step: 40, loss: 0.31503015756607056
step: 50, loss: 0.19300508499145508
step: 60, loss: 0.23767751455307007
step: 70, loss: 0.18140649795532227
step: 80, loss: 0.37362897396087646
step: 90, loss: 0.3645065724849701
step: 100, loss: 0.24013027548789978
step: 110, loss: 0.06237516179680824
step: 120, loss: 0.16283516585826874
step: 130, loss: 0.14976763725280762
step: 140, loss: 0.2731176018714905
step: 150, loss: 0.30782628059387207
step: 160, loss: 0.1829051822423935
step: 170, loss: 0.13700973987579346
step: 180, loss: 0.5544549822807312
step: 190, loss: 0.32331326603889465
step: 200, loss: 0.23416569828987122
step: 210, loss: 0.579014241695404
step: 220, loss: 0.13622760772705078
step: 230, loss: 0.25125035643577576
step: 240, loss: 0.4086882174015045
step: 250, loss: 0.06508937478065491
step: 260, loss: 0.2753012776374817
step: 270, loss: 0.1446838676929474
step: 280, loss: 0.2563951909542084
step: 290, loss: 0.3267870843410492
step: 300, loss: 0.4110957086086273
step: 310, loss: 0.2933245897293091
step: 320, loss: 0.20239606499671936
step: 330, loss: 0.045400261878967285
step: 340, loss: 0.1851959377527237
step: 350, loss: 0.09581215679645538
step: 360, loss: 0.1102147176861763
step: 370, loss: 0.11061546951532364
step: 380, loss: 0.07402200251817703
epoch 1: dev_f1=0.5970873786407768, f1=0.6078431372549019, best_f1=0.6078431372549019
step: 0, loss: 0.14878082275390625
step: 10, loss: 0.05201587826013565
step: 20, loss: 0.10332121700048447
step: 30, loss: 0.11138487607240677
step: 40, loss: 0.02439263090491295
step: 50, loss: 0.09487586468458176
step: 60, loss: 0.0727137103676796
step: 70, loss: 0.03138280659914017
step: 80, loss: 0.22497430443763733
step: 90, loss: 0.11520445346832275
step: 100, loss: 0.04461759328842163
step: 110, loss: 0.11047470569610596
step: 120, loss: 0.11752952635288239
step: 130, loss: 0.024175990372896194
step: 140, loss: 0.06829654425382614
step: 150, loss: 0.25265660881996155
step: 160, loss: 0.015235884115099907
step: 170, loss: 0.03866654634475708
step: 180, loss: 0.09724260121583939
step: 190, loss: 0.10902288556098938
step: 200, loss: 0.09923277795314789
step: 210, loss: 0.09573034942150116
step: 220, loss: 0.4232029318809509
step: 230, loss: 0.13437195122241974
step: 240, loss: 0.06342384219169617
step: 250, loss: 0.16132687032222748
step: 260, loss: 0.11683955043554306
step: 270, loss: 0.22548618912696838
step: 280, loss: 0.19120047986507416
step: 290, loss: 0.08874701708555222
step: 300, loss: 0.13815343379974365
step: 310, loss: 0.01856120675802231
step: 320, loss: 0.09790283441543579
step: 330, loss: 0.13460104167461395
step: 340, loss: 0.15926752984523773
step: 350, loss: 0.16287249326705933
step: 360, loss: 0.22986926138401031
step: 370, loss: 0.15812812745571136
step: 380, loss: 0.02309177629649639
epoch 2: dev_f1=0.6523809523809525, f1=0.6682577565632458, best_f1=0.6682577565632458
step: 0, loss: 0.08840769529342651
step: 10, loss: 0.18134601414203644
step: 20, loss: 0.17443686723709106
step: 30, loss: 0.08917061239480972
step: 40, loss: 0.037710435688495636
step: 50, loss: 0.03248679265379906
step: 60, loss: 0.09760934859514236
step: 70, loss: 0.0036193951964378357
step: 80, loss: 0.19103273749351501
step: 90, loss: 0.1630699634552002
step: 100, loss: 0.035979002714157104
step: 110, loss: 0.03298112750053406
step: 120, loss: 0.20075683295726776
step: 130, loss: 0.027988137677311897
step: 140, loss: 0.2331659346818924
step: 150, loss: 0.06212000176310539
step: 160, loss: 0.12925779819488525
step: 170, loss: 0.12392736971378326
step: 180, loss: 0.18165084719657898
step: 190, loss: 0.08326815813779831
step: 200, loss: 0.07487199455499649
step: 210, loss: 0.053710002452135086
step: 220, loss: 0.10689926892518997
step: 230, loss: 0.011487350799143314
step: 240, loss: 0.06453516334295273
step: 250, loss: 0.062354087829589844
step: 260, loss: 0.1306411772966385
step: 270, loss: 0.05954128876328468
step: 280, loss: 0.02647996135056019
step: 290, loss: 0.11814825236797333
step: 300, loss: 0.052221085876226425
step: 310, loss: 0.10951857268810272
step: 320, loss: 0.04462905600667
step: 330, loss: 0.1880788505077362
step: 340, loss: 0.04339149221777916
step: 350, loss: 0.11425663530826569
step: 360, loss: 0.21063490211963654
step: 370, loss: 0.04720745235681534
step: 380, loss: 0.1626017540693283
epoch 3: dev_f1=0.6926605504587156, f1=0.6966824644549764, best_f1=0.6966824644549764
step: 0, loss: 0.08369438350200653
step: 10, loss: 0.03017595410346985
step: 20, loss: 0.11046165972948074
step: 30, loss: 0.029743552207946777
step: 40, loss: 0.13929836452007294
step: 50, loss: 0.057814307510852814
step: 60, loss: 0.1280261129140854
step: 70, loss: 0.1481776386499405
step: 80, loss: 0.05177346244454384
step: 90, loss: 0.13886898756027222
step: 100, loss: 0.009040975011885166
step: 110, loss: 0.03177156299352646
step: 120, loss: 0.31210312247276306
step: 130, loss: 0.05331730470061302
step: 140, loss: 0.06929260492324829
step: 150, loss: 0.02291409857571125
step: 160, loss: 0.0701739639043808
step: 170, loss: 0.004852056968957186
step: 180, loss: 0.06889194995164871
step: 190, loss: 0.11875248700380325
step: 200, loss: 0.0323248915374279
step: 210, loss: 0.031724173575639725
step: 220, loss: 0.1649559587240219
step: 230, loss: 0.09318864345550537
step: 240, loss: 0.05186143517494202
step: 250, loss: 0.0650334283709526
step: 260, loss: 0.03657267242670059
step: 270, loss: 0.08460415154695511
step: 280, loss: 0.025378309190273285
step: 290, loss: 0.04162072762846947
step: 300, loss: 0.08131128549575806
step: 310, loss: 0.05091198533773422
step: 320, loss: 0.0551040843129158
step: 330, loss: 0.29680097103118896
step: 340, loss: 0.05820789560675621
step: 350, loss: 0.06548293679952621
step: 360, loss: 0.27372610569000244
step: 370, loss: 0.10199414193630219
step: 380, loss: 0.12402663379907608
epoch 4: dev_f1=0.7050000000000001, f1=0.7, best_f1=0.7
step: 0, loss: 0.061716243624687195
step: 10, loss: 0.031065452843904495
step: 20, loss: 0.026736963540315628
step: 30, loss: 0.03687634319067001
step: 40, loss: 0.1098426878452301
step: 50, loss: 0.035682108253240585
step: 60, loss: 0.037417616695165634
step: 70, loss: 0.014296934939920902
step: 80, loss: 0.05305362865328789
step: 90, loss: 0.09298800677061081
step: 100, loss: 0.0481855645775795
step: 110, loss: 0.047481123358011246
step: 120, loss: 0.027432937175035477
step: 130, loss: 0.14063511788845062
step: 140, loss: 0.12382887303829193
step: 150, loss: 0.06730611622333527
step: 160, loss: 0.3043456971645355
step: 170, loss: 0.014791215769946575
step: 180, loss: 0.011053195223212242
step: 190, loss: 0.040796272456645966
step: 200, loss: 0.03483939543366432
step: 210, loss: 0.10516317933797836
step: 220, loss: 0.020375121384859085
step: 230, loss: 0.07957608997821808
step: 240, loss: 0.11971653997898102
step: 250, loss: 0.002159383147954941
step: 260, loss: 0.06968942284584045
step: 270, loss: 0.018664423376321793
step: 280, loss: 0.07053805887699127
step: 290, loss: 0.02598888985812664
step: 300, loss: 0.05111558362841606
step: 310, loss: 0.06673791259527206
step: 320, loss: 0.1449534296989441
step: 330, loss: 0.02641601487994194
step: 340, loss: 0.14736147224903107
step: 350, loss: 0.1619570106267929
step: 360, loss: 0.055524472147226334
step: 370, loss: 0.08269045501947403
step: 380, loss: 0.10655046999454498
epoch 5: dev_f1=0.7204030226700252, f1=0.7346938775510203, best_f1=0.7346938775510203
step: 0, loss: 0.037664979696273804
step: 10, loss: 0.04521004855632782
step: 20, loss: 0.006960499566048384
step: 30, loss: 0.03782873973250389
step: 40, loss: 0.10156174749135971
step: 50, loss: 0.1079876720905304
step: 60, loss: 0.012578099966049194
step: 70, loss: 0.026409368962049484
step: 80, loss: 0.04329197108745575
step: 90, loss: 0.073982372879982
step: 100, loss: 0.07791166752576828
step: 110, loss: 0.030823616310954094
step: 120, loss: 0.01780586503446102
step: 130, loss: 0.12906962633132935
step: 140, loss: 0.07039926946163177
step: 150, loss: 0.12759903073310852
step: 160, loss: 0.06871446967124939
step: 170, loss: 0.02538229338824749
step: 180, loss: 0.00029581692069768906
step: 190, loss: 0.034363824874162674
step: 200, loss: 0.0446455180644989
step: 210, loss: 0.045933764427900314
step: 220, loss: 0.005912554915994406
step: 230, loss: 0.02304214984178543
step: 240, loss: 0.0013311601942405105
step: 250, loss: 0.3564775884151459
step: 260, loss: 0.005546783097088337
step: 270, loss: 0.013546552509069443
step: 280, loss: 0.05844901129603386
step: 290, loss: 0.005984070245176554
step: 300, loss: 0.3186880648136139
step: 310, loss: 0.007006552070379257
step: 320, loss: 0.03730000555515289
step: 330, loss: 0.0015337970107793808
step: 340, loss: 0.13501720130443573
step: 350, loss: 0.03879537805914879
step: 360, loss: 0.027800368145108223
step: 370, loss: 0.07532022893428802
step: 380, loss: 0.16309566795825958
epoch 6: dev_f1=0.7568922305764412, f1=0.7415143603133159, best_f1=0.7415143603133159
step: 0, loss: 0.09649021178483963
step: 10, loss: 0.026532454416155815
step: 20, loss: 0.023941852152347565
step: 30, loss: 0.210279181599617
step: 40, loss: 0.08033755421638489
step: 50, loss: 0.013769419863820076
step: 60, loss: 0.011764148250222206
step: 70, loss: 0.06144943833351135
step: 80, loss: 0.05517220497131348
step: 90, loss: 0.13721565902233124
step: 100, loss: 0.11385215073823929
step: 110, loss: 0.030754171311855316
step: 120, loss: 0.07406046241521835
step: 130, loss: 0.3567947745323181
step: 140, loss: 0.059491608291864395
step: 150, loss: 0.003498155390843749
step: 160, loss: 0.1474086195230484
step: 170, loss: 0.0646645650267601
step: 180, loss: 0.011477133259177208
step: 190, loss: 0.010841651819646358
step: 200, loss: 0.0075874775648117065
step: 210, loss: 0.07830838859081268
step: 220, loss: 0.1005081832408905
step: 230, loss: 0.01949450559914112
step: 240, loss: 0.03663652017712593
step: 250, loss: 0.03300606459379196
step: 260, loss: 0.09019160270690918
step: 270, loss: 0.016537955030798912
step: 280, loss: 0.038302190601825714
step: 290, loss: 0.0397513248026371
step: 300, loss: 0.04555834084749222
step: 310, loss: 0.047922756522893906
step: 320, loss: 0.05125655233860016
step: 330, loss: 0.0007298138807527721
step: 340, loss: 0.011374004185199738
step: 350, loss: 0.057441748678684235
step: 360, loss: 0.0010553277097642422
step: 370, loss: 0.13263371586799622
step: 380, loss: 0.028270868584513664
epoch 7: dev_f1=0.7263681592039801, f1=0.7291666666666667, best_f1=0.7415143603133159
step: 0, loss: 0.03095407783985138
step: 10, loss: 0.022015269845724106
step: 20, loss: 0.00032354172435589135
step: 30, loss: 0.03490768000483513
step: 40, loss: 0.0016727690817788243
step: 50, loss: 0.05977788195014
step: 60, loss: 0.03505900129675865
step: 70, loss: 0.04034189134836197
step: 80, loss: 0.015278104692697525
step: 90, loss: 0.045384589582681656
step: 100, loss: 0.01431453600525856
step: 110, loss: 0.040641672909259796
step: 120, loss: 0.08828303217887878
step: 130, loss: 0.049627095460891724
step: 140, loss: 0.09276134520769119
step: 150, loss: 0.0001569686719449237
step: 160, loss: 0.1494615375995636
step: 170, loss: 0.06989236921072006
step: 180, loss: 0.06751387566328049
step: 190, loss: 0.11084429919719696
step: 200, loss: 0.0003314568311907351
step: 210, loss: 0.013635480776429176
step: 220, loss: 0.04049080237746239
step: 230, loss: 0.011540716513991356
step: 240, loss: 0.05120909959077835
step: 250, loss: 0.03591003268957138
step: 260, loss: 0.05904882773756981
step: 270, loss: 0.061472535133361816
step: 280, loss: 0.0009700639639049768
step: 290, loss: 0.1982942819595337
step: 300, loss: 0.0016101155197247863
step: 310, loss: 0.07167811691761017
step: 320, loss: 0.04805503413081169
step: 330, loss: 0.012388910166919231
step: 340, loss: 0.08255137503147125
step: 350, loss: 0.023046210408210754
step: 360, loss: 0.010462963953614235
step: 370, loss: 0.04715476930141449
step: 380, loss: 0.005313180852681398
epoch 8: dev_f1=0.7423167848699763, f1=0.7347931873479319, best_f1=0.7415143603133159
step: 0, loss: 0.0036527588963508606
step: 10, loss: 7.092707528499886e-05
step: 20, loss: 0.033823274075984955
step: 30, loss: 0.13689155876636505
step: 40, loss: 0.0230758935213089
step: 50, loss: 0.02575947716832161
step: 60, loss: 0.12363891303539276
step: 70, loss: 0.08203239738941193
step: 80, loss: 0.00600192928686738
step: 90, loss: 0.04491090774536133
step: 100, loss: 0.12144681811332703
step: 110, loss: 0.07336020469665527
step: 120, loss: 0.00827313307672739
step: 130, loss: 0.029203731566667557
step: 140, loss: 0.043841272592544556
step: 150, loss: 0.03855736926198006
step: 160, loss: 0.00013809214578941464
step: 170, loss: 0.016036558896303177
step: 180, loss: 0.016560420393943787
step: 190, loss: 0.004059308208525181
step: 200, loss: 0.0031190456356853247
step: 210, loss: 0.04413627088069916
step: 220, loss: 0.016025565564632416
step: 230, loss: 0.00146168761420995
step: 240, loss: 0.029275203123688698
step: 250, loss: 0.014505995437502861
step: 260, loss: 0.06557552516460419
step: 270, loss: 0.09235784411430359
step: 280, loss: 0.060641344636678696
step: 290, loss: 0.059733401983976364
step: 300, loss: 0.00727710360661149
step: 310, loss: 0.01245732232928276
step: 320, loss: 0.0011499779066070914
step: 330, loss: 0.00010095442848978564
step: 340, loss: 0.04732557386159897
step: 350, loss: 0.07610607147216797
step: 360, loss: 0.003700843546539545
step: 370, loss: 0.006155990529805422
step: 380, loss: 0.04297788441181183
epoch 9: dev_f1=0.7358490566037736, f1=0.7350835322195705, best_f1=0.7415143603133159
step: 0, loss: 0.047747354954481125
step: 10, loss: 0.020799774676561356
step: 20, loss: 0.006140851881355047
step: 30, loss: 0.013477188535034657
step: 40, loss: 0.03366793319582939
step: 50, loss: 0.00011042983533116058
step: 60, loss: 0.012635129503905773
step: 70, loss: 0.06672603636980057
step: 80, loss: 0.10869432240724564
step: 90, loss: 0.0034448064398020506
step: 100, loss: 0.03767721354961395
step: 110, loss: 0.006223161239176989
step: 120, loss: 0.01566883735358715
step: 130, loss: 0.00571346003562212
step: 140, loss: 0.04030419886112213
step: 150, loss: 0.02750278078019619
step: 160, loss: 0.051681190729141235
step: 170, loss: 0.04391415789723396
step: 180, loss: 0.0492405965924263
step: 190, loss: 0.006945386994630098
step: 200, loss: 0.03236958011984825
step: 210, loss: 0.016872072592377663
step: 220, loss: 0.004835797008126974
step: 230, loss: 0.012602453120052814
step: 240, loss: 0.00010184693383052945
step: 250, loss: 0.023191368207335472
step: 260, loss: 0.03337835520505905
step: 270, loss: 0.04459904506802559
step: 280, loss: 0.04211415350437164
step: 290, loss: 0.0032795590814203024
step: 300, loss: 0.04102092981338501
step: 310, loss: 0.003926241770386696
step: 320, loss: 0.004031434655189514
step: 330, loss: 0.058346543461084366
step: 340, loss: 0.00992436520755291
step: 350, loss: 0.025493206456303596
step: 360, loss: 0.023164838552474976
step: 370, loss: 0.02720879763364792
step: 380, loss: 0.07044076919555664
epoch 10: dev_f1=0.7135678391959798, f1=0.716577540106952, best_f1=0.7415143603133159
step: 0, loss: 0.001365822390653193
step: 10, loss: 0.028196703642606735
step: 20, loss: 0.038536667823791504
step: 30, loss: 0.000596814788877964
step: 40, loss: 0.01130713988095522
step: 50, loss: 0.00824291817843914
step: 60, loss: 0.037371572107076645
step: 70, loss: 0.0054641528986394405
step: 80, loss: 0.014977827668190002
step: 90, loss: 0.010792394168674946
step: 100, loss: 0.0349554680287838
step: 110, loss: 0.03501585125923157
step: 120, loss: 0.0029342304915189743
step: 130, loss: 0.004852895624935627
step: 140, loss: 0.19622556865215302
step: 150, loss: 0.07105240225791931
step: 160, loss: 0.04641861096024513
step: 170, loss: 0.008441571146249771
step: 180, loss: 0.008177516981959343
step: 190, loss: 0.013642766512930393
step: 200, loss: 0.003005261067301035
step: 210, loss: 0.054176248610019684
step: 220, loss: 0.060934871435165405
step: 230, loss: 0.035029228776693344
step: 240, loss: 0.22560741007328033
step: 250, loss: 0.08523336052894592
step: 260, loss: 0.05993301048874855
step: 270, loss: 0.08651939034461975
step: 280, loss: 0.09565012902021408
step: 290, loss: 0.02566697634756565
step: 300, loss: 0.1002785786986351
step: 310, loss: 0.05810379609465599
step: 320, loss: 0.07859136909246445
step: 330, loss: 0.08037029206752777
step: 340, loss: 0.032745152711868286
step: 350, loss: 0.00700911320745945
step: 360, loss: 0.04412834718823433
step: 370, loss: 0.036036163568496704
step: 380, loss: 0.02996090054512024
epoch 11: dev_f1=0.7295285359801489, f1=0.7338501291989663, best_f1=0.7415143603133159
step: 0, loss: 0.028979450464248657
step: 10, loss: 0.0005108274635858834
step: 20, loss: 0.00012667205010075122
step: 30, loss: 0.004401694517582655
step: 40, loss: 0.02153867483139038
step: 50, loss: 0.020985808223485947
step: 60, loss: 0.0002948682813439518
step: 70, loss: 0.005093774758279324
step: 80, loss: 0.06300556659698486
step: 90, loss: 0.002095306757837534
step: 100, loss: 0.00019418129522819072
step: 110, loss: 0.0300326906144619
step: 120, loss: 0.0006676370976492763
step: 130, loss: 0.013698050752282143
step: 140, loss: 0.048379912972450256
step: 150, loss: 0.06476236879825592
step: 160, loss: 0.008869519457221031
step: 170, loss: 0.00018077896675094962
step: 180, loss: 0.18400198221206665
step: 190, loss: 0.025116534903645515
step: 200, loss: 0.17765310406684875
step: 210, loss: 0.008107357658445835
step: 220, loss: 0.025342563167214394
step: 230, loss: 0.00017138247494585812
step: 240, loss: 0.013446779921650887
step: 250, loss: 0.01494797132909298
step: 260, loss: 0.11829961836338043
step: 270, loss: 0.009667078033089638
step: 280, loss: 0.002573780482634902
step: 290, loss: 0.11627987772226334
step: 300, loss: 0.0049664718098938465
step: 310, loss: 0.09182823449373245
step: 320, loss: 0.005990124773234129
step: 330, loss: 0.03445141389966011
step: 340, loss: 0.05919494107365608
step: 350, loss: 0.10194330662488937
step: 360, loss: 0.06013710796833038
step: 370, loss: 0.046873681247234344
step: 380, loss: 0.00725456653162837
epoch 12: dev_f1=0.7268041237113403, f1=0.7382198952879582, best_f1=0.7415143603133159
step: 0, loss: 0.01876460760831833
step: 10, loss: 0.0347251370549202
step: 20, loss: 0.03823539987206459
step: 30, loss: 0.00788054522126913
step: 40, loss: 5.948246325715445e-05
step: 50, loss: 0.00027368689188733697
step: 60, loss: 0.0017033680342137814
step: 70, loss: 0.005037854425609112
step: 80, loss: 0.058552335947752
step: 90, loss: 7.224576256703585e-05
step: 100, loss: 0.0025018355809152126
step: 110, loss: 0.07828816771507263
step: 120, loss: 0.04275836423039436
step: 130, loss: 0.008298003114759922
step: 140, loss: 0.07004176825284958
step: 150, loss: 0.005684464238584042
step: 160, loss: 0.000663396087475121
step: 170, loss: 0.001974739134311676
step: 180, loss: 0.0005944232689216733
step: 190, loss: 0.0011772599536925554
step: 200, loss: 0.0233586635440588
step: 210, loss: 0.01058602798730135
step: 220, loss: 0.023267950862646103
step: 230, loss: 0.01583511009812355
step: 240, loss: 0.011870823800563812
step: 250, loss: 0.005347919650375843
step: 260, loss: 0.00041195537778548896
step: 270, loss: 0.010205837897956371
step: 280, loss: 0.040259577333927155
step: 290, loss: 0.00415007071569562
step: 300, loss: 0.02108929120004177
step: 310, loss: 0.0335521399974823
step: 320, loss: 0.06447523087263107
step: 330, loss: 0.045099709182977676
step: 340, loss: 0.06685221195220947
step: 350, loss: 0.0007967095007188618
step: 360, loss: 0.028751060366630554
step: 370, loss: 0.0007980970549397171
step: 380, loss: 0.010846447199583054
epoch 13: dev_f1=0.6879271070615034, f1=0.7307692307692308, best_f1=0.7415143603133159
step: 0, loss: 0.004394180607050657
step: 10, loss: 0.002517620101571083
step: 20, loss: 0.05591301620006561
step: 30, loss: 0.01367346104234457
step: 40, loss: 0.006178220268338919
step: 50, loss: 0.0008229220984503627
step: 60, loss: 0.04571185261011124
step: 70, loss: 0.005088431295007467
step: 80, loss: 0.015686780214309692
step: 90, loss: 4.0667069697519764e-05
step: 100, loss: 0.004256791435182095
step: 110, loss: 0.0645371824502945
step: 120, loss: 0.01989101804792881
step: 130, loss: 0.000359180208761245
step: 140, loss: 0.020646968856453896
step: 150, loss: 0.021786587312817574
step: 160, loss: 0.1241808831691742
step: 170, loss: 7.74226791691035e-05
step: 180, loss: 0.0729781836271286
step: 190, loss: 0.002375784097239375
step: 200, loss: 0.04785909131169319
step: 210, loss: 0.0023213860113173723
step: 220, loss: 0.007625824771821499
step: 230, loss: 0.040702469646930695
step: 240, loss: 0.026301894336938858
step: 250, loss: 0.09138645231723785
step: 260, loss: 0.0013885598164051771
step: 270, loss: 0.003550496883690357
step: 280, loss: 0.02254740707576275
step: 290, loss: 0.00016358151333406568
step: 300, loss: 0.016627592965960503
step: 310, loss: 0.010654615238308907
step: 320, loss: 0.0008082803688012064
step: 330, loss: 0.0571555458009243
step: 340, loss: 0.035592980682849884
step: 350, loss: 0.027115333825349808
step: 360, loss: 0.007250698283314705
step: 370, loss: 0.07222853600978851
step: 380, loss: 0.00040761291165836155
epoch 14: dev_f1=0.6988505747126437, f1=0.7307692307692308, best_f1=0.7415143603133159
step: 0, loss: 0.004755823872983456
step: 10, loss: 0.02942327968776226
step: 20, loss: 0.026387324556708336
step: 30, loss: 0.004131650552153587
step: 40, loss: 2.3610500647919253e-05
step: 50, loss: 0.014710454270243645
step: 60, loss: 0.010172233916819096
step: 70, loss: 0.02355271764099598
step: 80, loss: 0.1069386899471283
step: 90, loss: 0.0004555243067443371
step: 100, loss: 0.03198843076825142
step: 110, loss: 0.012776377610862255
step: 120, loss: 0.017369447275996208
step: 130, loss: 0.020935626700520515
step: 140, loss: 0.025236723944544792
step: 150, loss: 0.0011153622763231397
step: 160, loss: 0.02067118138074875
step: 170, loss: 0.05158909037709236
step: 180, loss: 0.0008295049774460495
step: 190, loss: 0.000174326662090607
step: 200, loss: 0.026452407240867615
step: 210, loss: 0.004012522753328085
step: 220, loss: 0.0013277693651616573
step: 230, loss: 0.00045077234972268343
step: 240, loss: 3.108663440798409e-05
step: 250, loss: 0.14848625659942627
step: 260, loss: 0.0002877654624171555
step: 270, loss: 0.027245990931987762
step: 280, loss: 0.002964087761938572
step: 290, loss: 0.032241202890872955
step: 300, loss: 0.0846940129995346
step: 310, loss: 0.01891268417239189
step: 320, loss: 0.0006395477103069425
step: 330, loss: 3.526102955220267e-05
step: 340, loss: 0.0031455503776669502
step: 350, loss: 0.044951725751161575
step: 360, loss: 0.028557617217302322
step: 370, loss: 0.0012342844856902957
step: 380, loss: 0.022812582552433014
epoch 15: dev_f1=0.7132169576059851, f1=0.7395833333333334, best_f1=0.7415143603133159
step: 0, loss: 0.037802085280418396
step: 10, loss: 0.0004806746437679976
step: 20, loss: 0.0003768262395169586
step: 30, loss: 0.1164431944489479
step: 40, loss: 0.018947258591651917
step: 50, loss: 0.01930387318134308
step: 60, loss: 0.004787083249539137
step: 70, loss: 0.008169522508978844
step: 80, loss: 0.08275493234395981
step: 90, loss: 6.618164479732513e-05
step: 100, loss: 5.446237628348172e-05
step: 110, loss: 0.009441696107387543
step: 120, loss: 0.020121540874242783
step: 130, loss: 0.00019076811440754682
step: 140, loss: 0.03268387168645859
step: 150, loss: 0.04183042421936989
step: 160, loss: 5.2735158533323556e-05
step: 170, loss: 0.028955375775694847
step: 180, loss: 5.190697993384674e-05
step: 190, loss: 0.001110703102312982
step: 200, loss: 0.000313342286972329
step: 210, loss: 0.1261463761329651
step: 220, loss: 0.01500843558460474
step: 230, loss: 0.040597960352897644
step: 240, loss: 0.0012229494750499725
step: 250, loss: 0.003180484753102064
step: 260, loss: 0.025239799171686172
step: 270, loss: 0.001425318536348641
step: 280, loss: 0.01770465448498726
step: 290, loss: 0.00015638989862054586
step: 300, loss: 0.00018800179532263428
step: 310, loss: 0.02020072564482689
step: 320, loss: 0.0017677478026598692
step: 330, loss: 0.010975521989166737
step: 340, loss: 0.0007272970979101956
step: 350, loss: 0.011413656175136566
step: 360, loss: 0.009909420274198055
step: 370, loss: 0.027662139385938644
step: 380, loss: 0.0012809551553800702
epoch 16: dev_f1=0.6972010178117048, f1=0.7248677248677249, best_f1=0.7415143603133159
step: 0, loss: 0.031630709767341614
step: 10, loss: 0.011671384796500206
step: 20, loss: 9.695987682789564e-05
step: 30, loss: 0.014630790799856186
step: 40, loss: 0.0002782345109153539
step: 50, loss: 0.00024756669881753623
step: 60, loss: 5.947011595708318e-05
step: 70, loss: 0.0005063792341388762
step: 80, loss: 0.012241477146744728
step: 90, loss: 0.02751586213707924
step: 100, loss: 0.005470158066600561
step: 110, loss: 0.0022440627217292786
step: 120, loss: 0.008320688270032406
step: 130, loss: 5.4921285482123494e-05
step: 140, loss: 0.04356888309121132
step: 150, loss: 0.00011566733883228153
step: 160, loss: 0.02618327923119068
step: 170, loss: 0.00020306619990151376
step: 180, loss: 0.03520386666059494
step: 190, loss: 7.237255340442061e-05
step: 200, loss: 0.03455309569835663
step: 210, loss: 3.832398942904547e-05
step: 220, loss: 0.035775020718574524
step: 230, loss: 0.001146121066994965
step: 240, loss: 0.0014953403733670712
step: 250, loss: 0.0040576462633907795
step: 260, loss: 0.0477813184261322
step: 270, loss: 0.0142774423584342
step: 280, loss: 0.019332075491547585
step: 290, loss: 0.06009521707892418
step: 300, loss: 0.0009122795308940113
step: 310, loss: 0.0027077272534370422
step: 320, loss: 2.793162639136426e-05
step: 330, loss: 0.008912257850170135
step: 340, loss: 0.039183374494314194
step: 350, loss: 0.0014616228872910142
step: 360, loss: 0.0004725304606836289
step: 370, loss: 0.034411732107400894
step: 380, loss: 0.009565263986587524
epoch 17: dev_f1=0.7158469945355191, f1=0.6936416184971099, best_f1=0.7415143603133159
step: 0, loss: 0.05246775597333908
step: 10, loss: 0.04536798596382141
step: 20, loss: 0.03563715144991875
step: 30, loss: 0.020660096779465675
step: 40, loss: 0.02629382349550724
step: 50, loss: 3.198066769982688e-05
step: 60, loss: 2.8281667255214415e-05
step: 70, loss: 2.7383624910726212e-05
step: 80, loss: 0.0024015409871935844
step: 90, loss: 0.011436108499765396
step: 100, loss: 9.253108146367595e-05
step: 110, loss: 0.07076109200716019
step: 120, loss: 0.0002812097955029458
step: 130, loss: 0.0008451332687400281
step: 140, loss: 0.05005188286304474
step: 150, loss: 0.02369980700314045
step: 160, loss: 0.04057289659976959
step: 170, loss: 0.07290582358837128
step: 180, loss: 0.0001376613072352484
step: 190, loss: 0.003784141270443797
step: 200, loss: 0.05510365590453148
step: 210, loss: 0.026077205315232277
step: 220, loss: 0.00010127870336873457
step: 230, loss: 0.011648804880678654
step: 240, loss: 0.0006390576018020511
step: 250, loss: 0.0010399131570011377
step: 260, loss: 0.011861342936754227
step: 270, loss: 0.008452963083982468
step: 280, loss: 3.2483625545864925e-05
step: 290, loss: 0.02161097526550293
step: 300, loss: 0.00017171532090287656
step: 310, loss: 0.03884683549404144
step: 320, loss: 0.011802726425230503
step: 330, loss: 0.016962070018053055
step: 340, loss: 0.0018311180174350739
step: 350, loss: 4.579869346343912e-05
step: 360, loss: 0.0002984237507916987
step: 370, loss: 0.11072580516338348
step: 380, loss: 0.00427118269726634
epoch 18: dev_f1=0.712871287128713, f1=0.7225130890052356, best_f1=0.7415143603133159
step: 0, loss: 0.027210939675569534
step: 10, loss: 0.038686323910951614
step: 20, loss: 0.006131912115961313
step: 30, loss: 7.131532038329169e-05
step: 40, loss: 0.02285560593008995
step: 50, loss: 3.931110768462531e-05
step: 60, loss: 3.127652234979905e-05
step: 70, loss: 0.00040444103069603443
step: 80, loss: 0.015672503039240837
step: 90, loss: 0.12195335328578949
step: 100, loss: 0.0008030429016798735
step: 110, loss: 0.00022656950750388205
step: 120, loss: 0.2901134192943573
step: 130, loss: 0.02720686048269272
step: 140, loss: 0.00018202154024038464
step: 150, loss: 4.192241249256767e-05
step: 160, loss: 0.0021825232543051243
step: 170, loss: 0.00024270539870485663
step: 180, loss: 0.025018325075507164
step: 190, loss: 0.013840675354003906
step: 200, loss: 0.0005783443921245635
step: 210, loss: 0.04875367134809494
step: 220, loss: 4.3483749323058873e-05
step: 230, loss: 0.011570241302251816
step: 240, loss: 0.018090199679136276
step: 250, loss: 0.0252220518887043
step: 260, loss: 0.018308643251657486
step: 270, loss: 0.014741865918040276
step: 280, loss: 0.0004705761093646288
step: 290, loss: 0.0006693510804325342
step: 300, loss: 0.034825123846530914
step: 310, loss: 0.00024357883376069367
step: 320, loss: 0.00012814303045161068
step: 330, loss: 6.064884291845374e-05
step: 340, loss: 5.26079093106091e-05
step: 350, loss: 0.02631182037293911
step: 360, loss: 8.256597357103601e-05
step: 370, loss: 0.013119065202772617
step: 380, loss: 6.008707350702025e-05
epoch 19: dev_f1=0.7088607594936709, f1=0.7024128686327078, best_f1=0.7415143603133159
step: 0, loss: 0.0015718808863312006
step: 10, loss: 0.00014671334065496922
step: 20, loss: 4.303890818846412e-05
step: 30, loss: 0.02687174081802368
step: 40, loss: 0.0005465922877192497
step: 50, loss: 0.02403685450553894
step: 60, loss: 0.00027444210718385875
step: 70, loss: 3.8525475247297436e-05
step: 80, loss: 0.07259233295917511
step: 90, loss: 0.0008138719131238759
step: 100, loss: 0.0003330515173729509
step: 110, loss: 0.00045136481639929116
step: 120, loss: 0.03082573413848877
step: 130, loss: 0.01838691160082817
step: 140, loss: 0.004032215103507042
step: 150, loss: 0.025579798966646194
step: 160, loss: 0.017514383420348167
step: 170, loss: 0.0005192338139750063
step: 180, loss: 0.0015787046868354082
step: 190, loss: 0.08084791153669357
step: 200, loss: 0.07428906857967377
step: 210, loss: 0.0011674935230985284
step: 220, loss: 0.01443797443062067
step: 230, loss: 0.002717522671446204
step: 240, loss: 0.058684200048446655
step: 250, loss: 0.02121514268219471
step: 260, loss: 3.890064908773638e-05
step: 270, loss: 0.045877061784267426
step: 280, loss: 0.07323480397462845
step: 290, loss: 0.0008304271614179015
step: 300, loss: 0.00138200877700001
step: 310, loss: 0.021092480048537254
step: 320, loss: 0.00044359208550304174
step: 330, loss: 6.423632294172421e-05
step: 340, loss: 0.0016524394741281867
step: 350, loss: 0.0801481083035469
step: 360, loss: 0.014143358916044235
step: 370, loss: 0.015247385017573833
step: 380, loss: 4.416806768858805e-05
epoch 20: dev_f1=0.7117794486215538, f1=0.7071240105540898, best_f1=0.7415143603133159
