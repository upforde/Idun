cuda
Device: cuda
step: 0, loss: 0.6421977281570435
step: 10, loss: 0.3021155595779419
step: 20, loss: 0.2572616636753082
step: 30, loss: 0.24493946135044098
step: 40, loss: 0.13826286792755127
step: 50, loss: 0.0794789120554924
step: 60, loss: 0.4940277338027954
step: 70, loss: 0.26845940947532654
step: 80, loss: 0.24859608709812164
step: 90, loss: 0.3242759704589844
step: 100, loss: 0.2552120089530945
step: 110, loss: 0.17423899471759796
step: 120, loss: 0.2369733303785324
step: 130, loss: 0.32231271266937256
step: 140, loss: 0.30854281783103943
step: 150, loss: 0.2901214361190796
step: 160, loss: 0.030921487137675285
step: 170, loss: 0.339703768491745
step: 180, loss: 0.21308475732803345
step: 190, loss: 0.39442914724349976
step: 200, loss: 0.17147718369960785
step: 210, loss: 0.1389138251543045
step: 220, loss: 0.2130793333053589
step: 230, loss: 0.1481754034757614
step: 240, loss: 0.4709659814834595
step: 250, loss: 0.15755224227905273
step: 260, loss: 0.178236186504364
step: 270, loss: 0.2988438904285431
step: 280, loss: 0.09957228600978851
step: 290, loss: 0.15359680354595184
step: 300, loss: 0.1923011839389801
step: 310, loss: 0.23555484414100647
step: 320, loss: 0.08851087093353271
step: 330, loss: 0.34924641251564026
step: 340, loss: 0.042214494198560715
step: 350, loss: 0.1336660087108612
step: 360, loss: 0.279644638299942
step: 370, loss: 0.2890211045742035
step: 380, loss: 0.10819832235574722
epoch 1: dev_f1=0.5957446808510637, f1=0.6560846560846562, best_f1=0.6560846560846562
step: 0, loss: 0.05248803645372391
step: 10, loss: 0.12127718329429626
step: 20, loss: 0.016088346019387245
step: 30, loss: 0.08268598467111588
step: 40, loss: 0.1537747085094452
step: 50, loss: 0.07228848338127136
step: 60, loss: 0.1775650680065155
step: 70, loss: 0.15623675286769867
step: 80, loss: 0.06103707104921341
step: 90, loss: 0.13059571385383606
step: 100, loss: 0.211233988404274
step: 110, loss: 0.04355442151427269
step: 120, loss: 0.10424956679344177
step: 130, loss: 0.2536056935787201
step: 140, loss: 0.0665532648563385
step: 150, loss: 0.11928263306617737
step: 160, loss: 0.09808740764856339
step: 170, loss: 0.18239730596542358
step: 180, loss: 0.28457632660865784
step: 190, loss: 0.12546488642692566
step: 200, loss: 0.08289635926485062
step: 210, loss: 0.0891650915145874
step: 220, loss: 0.10734020173549652
step: 230, loss: 0.12856750190258026
step: 240, loss: 0.16995039582252502
step: 250, loss: 0.11352549493312836
step: 260, loss: 0.08785892277956009
step: 270, loss: 0.07644914835691452
step: 280, loss: 0.052350372076034546
step: 290, loss: 0.21864718198776245
step: 300, loss: 0.032495029270648956
step: 310, loss: 0.2850974202156067
step: 320, loss: 0.10923338681459427
step: 330, loss: 0.07628866285085678
step: 340, loss: 0.05665699020028114
step: 350, loss: 0.07102391123771667
step: 360, loss: 0.3259609341621399
step: 370, loss: 0.09308478236198425
step: 380, loss: 0.1990433782339096
epoch 2: dev_f1=0.6614583333333333, f1=0.665, best_f1=0.665
step: 0, loss: 0.10899960249662399
step: 10, loss: 0.059366729110479355
step: 20, loss: 0.10057856887578964
step: 30, loss: 0.053460150957107544
step: 40, loss: 0.021203771233558655
step: 50, loss: 0.10671389102935791
step: 60, loss: 0.08265101164579391
step: 70, loss: 0.00516512431204319
step: 80, loss: 0.086201012134552
step: 90, loss: 0.08158353716135025
step: 100, loss: 0.0810663253068924
step: 110, loss: 0.01176243182271719
step: 120, loss: 0.008435103110969067
step: 130, loss: 0.06645096093416214
step: 140, loss: 0.14064273238182068
step: 150, loss: 0.15470288693904877
step: 160, loss: 0.5328302383422852
step: 170, loss: 0.031756702810525894
step: 180, loss: 0.16713164746761322
step: 190, loss: 0.08152332901954651
step: 200, loss: 0.016989514231681824
step: 210, loss: 0.06633210927248001
step: 220, loss: 0.2980174720287323
step: 230, loss: 0.09051446616649628
step: 240, loss: 0.04163023829460144
step: 250, loss: 0.17317387461662292
step: 260, loss: 0.05113809183239937
step: 270, loss: 0.17980696260929108
step: 280, loss: 0.025000005960464478
step: 290, loss: 0.13802985846996307
step: 300, loss: 0.0990460216999054
step: 310, loss: 0.18252849578857422
step: 320, loss: 0.16276828944683075
step: 330, loss: 0.1053081527352333
step: 340, loss: 0.03228544071316719
step: 350, loss: 0.09076271951198578
step: 360, loss: 0.05982256680727005
step: 370, loss: 0.006775566376745701
step: 380, loss: 0.06314390897750854
epoch 3: dev_f1=0.717557251908397, f1=0.7219251336898397, best_f1=0.7219251336898397
step: 0, loss: 0.05163801088929176
step: 10, loss: 0.029157444834709167
step: 20, loss: 0.04066897928714752
step: 30, loss: 0.05441451817750931
step: 40, loss: 0.004851349163800478
step: 50, loss: 0.2213132530450821
step: 60, loss: 0.09560978412628174
step: 70, loss: 0.08056904375553131
step: 80, loss: 0.06666217744350433
step: 90, loss: 0.044094059616327286
step: 100, loss: 0.032575156539678574
step: 110, loss: 0.0785815641283989
step: 120, loss: 0.1246127039194107
step: 130, loss: 0.09849099814891815
step: 140, loss: 0.02993728779256344
step: 150, loss: 0.06251812726259232
step: 160, loss: 0.12397094070911407
step: 170, loss: 0.12149859219789505
step: 180, loss: 0.14450228214263916
step: 190, loss: 0.02492433600127697
step: 200, loss: 0.05195199325680733
step: 210, loss: 0.11354042589664459
step: 220, loss: 0.11414386332035065
step: 230, loss: 0.07500527799129486
step: 240, loss: 0.09207001328468323
step: 250, loss: 0.01698724739253521
step: 260, loss: 0.05275744944810867
step: 270, loss: 0.11410622298717499
step: 280, loss: 0.021578144282102585
step: 290, loss: 0.044901371002197266
step: 300, loss: 0.11166394501924515
step: 310, loss: 0.008495314046740532
step: 320, loss: 0.08646292239427567
step: 330, loss: 0.06757311522960663
step: 340, loss: 0.046290572732686996
step: 350, loss: 0.11912166327238083
step: 360, loss: 0.054146114736795425
step: 370, loss: 0.0763973668217659
step: 380, loss: 0.05636626482009888
epoch 4: dev_f1=0.7138964577656676, f1=0.7183908045977011, best_f1=0.7219251336898397
step: 0, loss: 0.04749637097120285
step: 10, loss: 0.10922875255346298
step: 20, loss: 0.06252658367156982
step: 30, loss: 0.03266720846295357
step: 40, loss: 0.0374055951833725
step: 50, loss: 0.0009238190250471234
step: 60, loss: 0.023876728489995003
step: 70, loss: 0.01971847377717495
step: 80, loss: 0.031524136662483215
step: 90, loss: 0.08419958502054214
step: 100, loss: 0.12632369995117188
step: 110, loss: 0.1061580553650856
step: 120, loss: 0.16146762669086456
step: 130, loss: 0.009413186460733414
step: 140, loss: 0.10026315599679947
step: 150, loss: 0.06486305594444275
step: 160, loss: 0.14839206635951996
step: 170, loss: 0.08232097327709198
step: 180, loss: 0.02023879624903202
step: 190, loss: 0.05454804375767708
step: 200, loss: 0.01281639002263546
step: 210, loss: 0.03484845906496048
step: 220, loss: 0.057304996997117996
step: 230, loss: 0.05044584721326828
step: 240, loss: 0.0669102743268013
step: 250, loss: 0.0764985978603363
step: 260, loss: 0.15368938446044922
step: 270, loss: 0.04647166281938553
step: 280, loss: 0.03482598438858986
step: 290, loss: 0.07292580604553223
step: 300, loss: 0.15688449144363403
step: 310, loss: 0.09716003388166428
step: 320, loss: 0.03379673510789871
step: 330, loss: 0.0846804529428482
step: 340, loss: 0.10771455615758896
step: 350, loss: 0.017093492671847343
step: 360, loss: 0.019487887620925903
step: 370, loss: 0.041040826588869095
step: 380, loss: 0.06895295530557632
epoch 5: dev_f1=0.6866485013623977, f1=0.6610169491525424, best_f1=0.7219251336898397
step: 0, loss: 0.017929699271917343
step: 10, loss: 0.0292680524289608
step: 20, loss: 0.030259734019637108
step: 30, loss: 0.07643506675958633
step: 40, loss: 0.05807248130440712
step: 50, loss: 0.01590496115386486
step: 60, loss: 0.028867235407233238
step: 70, loss: 0.033897515386343
step: 80, loss: 0.052824873477220535
step: 90, loss: 0.013897270895540714
step: 100, loss: 0.05100416764616966
step: 110, loss: 0.07229448854923248
step: 120, loss: 0.060634713619947433
step: 130, loss: 0.06110453978180885
step: 140, loss: 0.043732304126024246
step: 150, loss: 0.04894450306892395
step: 160, loss: 0.07884294539690018
step: 170, loss: 0.024576686322689056
step: 180, loss: 0.09225765615701675
step: 190, loss: 0.003727699862793088
step: 200, loss: 0.08279889076948166
step: 210, loss: 0.028303872793912888
step: 220, loss: 0.09232005476951599
step: 230, loss: 0.06136995926499367
step: 240, loss: 0.08998120576143265
step: 250, loss: 0.03351892530918121
step: 260, loss: 0.06560248136520386
step: 270, loss: 0.16362594068050385
step: 280, loss: 0.16392794251441956
step: 290, loss: 0.02142512798309326
step: 300, loss: 0.07321872562170029
step: 310, loss: 0.0515078529715538
step: 320, loss: 0.035994138568639755
step: 330, loss: 0.03709190711379051
step: 340, loss: 0.12332112342119217
step: 350, loss: 0.12389475107192993
step: 360, loss: 0.06933833658695221
step: 370, loss: 0.046531837433576584
step: 380, loss: 0.05195726081728935
epoch 6: dev_f1=0.6747572815533981, f1=0.6907216494845362, best_f1=0.7219251336898397
step: 0, loss: 0.06061910092830658
step: 10, loss: 0.055429596453905106
step: 20, loss: 0.03535657376050949
step: 30, loss: 0.05590256676077843
step: 40, loss: 0.00023100692487787455
step: 50, loss: 0.00780084915459156
step: 60, loss: 0.08324191719293594
step: 70, loss: 0.11361522972583771
step: 80, loss: 0.030331382527947426
step: 90, loss: 0.05555758997797966
step: 100, loss: 0.008463301695883274
step: 110, loss: 0.028679458424448967
step: 120, loss: 0.006991253700107336
step: 130, loss: 0.05082264542579651
step: 140, loss: 0.04674682021141052
step: 150, loss: 0.13466888666152954
step: 160, loss: 0.15458279848098755
step: 170, loss: 0.19990964233875275
step: 180, loss: 0.002942585153505206
step: 190, loss: 0.03447279706597328
step: 200, loss: 0.19532574713230133
step: 210, loss: 0.030969396233558655
step: 220, loss: 0.0626191571354866
step: 230, loss: 0.06605900824069977
step: 240, loss: 0.09359405189752579
step: 250, loss: 0.023168470710515976
step: 260, loss: 0.04299682378768921
step: 270, loss: 0.023063790053129196
step: 280, loss: 0.04557971656322479
step: 290, loss: 0.03171303868293762
step: 300, loss: 0.11156266927719116
step: 310, loss: 0.07081077247858047
step: 320, loss: 0.004229618236422539
step: 330, loss: 0.07306712120771408
step: 340, loss: 0.020608430728316307
step: 350, loss: 0.05365004017949104
step: 360, loss: 0.045561470091342926
step: 370, loss: 0.03591301664710045
step: 380, loss: 0.1264650821685791
epoch 7: dev_f1=0.7225130890052356, f1=0.7166666666666668, best_f1=0.7166666666666668
step: 0, loss: 0.034658536314964294
step: 10, loss: 0.07059506326913834
step: 20, loss: 0.06575079262256622
step: 30, loss: 0.07983849197626114
step: 40, loss: 0.11941280215978622
step: 50, loss: 0.07711699604988098
step: 60, loss: 0.03108535334467888
step: 70, loss: 0.03668207675218582
step: 80, loss: 0.13295899331569672
step: 90, loss: 0.035857588052749634
step: 100, loss: 0.22848616540431976
step: 110, loss: 0.03725423663854599
step: 120, loss: 0.03577730059623718
step: 130, loss: 0.023676112294197083
step: 140, loss: 0.01193992793560028
step: 150, loss: 0.00583362951874733
step: 160, loss: 0.05766250193119049
step: 170, loss: 0.05337078869342804
step: 180, loss: 0.18761491775512695
step: 190, loss: 0.17956063151359558
step: 200, loss: 0.02121337689459324
step: 210, loss: 0.07197553664445877
step: 220, loss: 0.027601998299360275
step: 230, loss: 0.05207422748208046
step: 240, loss: 0.018971720710396767
step: 250, loss: 0.07163582742214203
step: 260, loss: 0.09607397019863129
step: 270, loss: 0.021527433767914772
step: 280, loss: 0.05097401887178421
step: 290, loss: 0.04622654989361763
step: 300, loss: 0.03606806695461273
step: 310, loss: 0.024069370701909065
step: 320, loss: 0.06055391952395439
step: 330, loss: 0.014436410740017891
step: 340, loss: 0.0516715869307518
step: 350, loss: 0.018535112962126732
step: 360, loss: 0.007079812232404947
step: 370, loss: 0.1392010599374771
step: 380, loss: 0.04466010257601738
epoch 8: dev_f1=0.6804123711340206, f1=0.7002652519893899, best_f1=0.7166666666666668
step: 0, loss: 0.0570913590490818
step: 10, loss: 0.012608460150659084
step: 20, loss: 0.10436586290597916
step: 30, loss: 0.004118658136576414
step: 40, loss: 0.0003366138553246856
step: 50, loss: 0.031361062079668045
step: 60, loss: 0.03587592765688896
step: 70, loss: 0.016482967883348465
step: 80, loss: 0.057087548077106476
step: 90, loss: 0.00018946683849208057
step: 100, loss: 0.031038163229823112
step: 110, loss: 0.011426212266087532
step: 120, loss: 0.012253159657120705
step: 130, loss: 0.03474540635943413
step: 140, loss: 0.024305181577801704
step: 150, loss: 0.07893051207065582
step: 160, loss: 0.04915611818432808
step: 170, loss: 0.056363578885793686
step: 180, loss: 0.0008526390301994979
step: 190, loss: 0.02352227084338665
step: 200, loss: 0.07629907876253128
step: 210, loss: 0.022808365523815155
step: 220, loss: 0.05437009409070015
step: 230, loss: 0.032710276544094086
step: 240, loss: 0.056839898228645325
step: 250, loss: 0.017177995294332504
step: 260, loss: 0.01767094060778618
step: 270, loss: 0.10670198500156403
step: 280, loss: 0.06776060163974762
step: 290, loss: 0.01135853212326765
step: 300, loss: 0.06209438294172287
step: 310, loss: 0.03679287061095238
step: 320, loss: 0.00020560862321872264
step: 330, loss: 0.008523460477590561
step: 340, loss: 0.0022776045370846987
step: 350, loss: 0.0649116113781929
step: 360, loss: 0.025554923340678215
step: 370, loss: 0.03697001188993454
step: 380, loss: 0.11292047798633575
epoch 9: dev_f1=0.7180722891566265, f1=0.7412935323383084, best_f1=0.7166666666666668
step: 0, loss: 0.007473288103938103
step: 10, loss: 0.06712239980697632
step: 20, loss: 0.05240785330533981
step: 30, loss: 0.04826271906495094
step: 40, loss: 0.032324571162462234
step: 50, loss: 0.005957368295639753
step: 60, loss: 0.013657680712640285
step: 70, loss: 0.004704576916992664
step: 80, loss: 0.030980978161096573
step: 90, loss: 0.08438540995121002
step: 100, loss: 0.002838284708559513
step: 110, loss: 0.020003801211714745
step: 120, loss: 0.03548198193311691
step: 130, loss: 0.07603209465742111
step: 140, loss: 0.08998886495828629
step: 150, loss: 0.004124687984585762
step: 160, loss: 0.00046933890553191304
step: 170, loss: 0.06838805228471756
step: 180, loss: 0.011164079420268536
step: 190, loss: 0.012002977542579174
step: 200, loss: 0.08518179506063461
step: 210, loss: 0.0977131798863411
step: 220, loss: 0.018600400537252426
step: 230, loss: 0.04967919737100601
step: 240, loss: 0.0007689815247431397
step: 250, loss: 0.046625617891550064
step: 260, loss: 0.2059967815876007
step: 270, loss: 0.0013548206770792603
step: 280, loss: 0.08925113081932068
step: 290, loss: 0.08689131587743759
step: 300, loss: 0.026276156306266785
step: 310, loss: 0.059204261749982834
step: 320, loss: 0.040511712431907654
step: 330, loss: 0.1497405469417572
step: 340, loss: 0.040809888392686844
step: 350, loss: 0.06769806146621704
step: 360, loss: 0.0004469927807804197
step: 370, loss: 0.04980774596333504
step: 380, loss: 0.10040208697319031
epoch 10: dev_f1=0.7085427135678392, f1=0.7376623376623376, best_f1=0.7166666666666668
step: 0, loss: 0.01777097024023533
step: 10, loss: 0.0029461176600307226
step: 20, loss: 0.0042496733367443085
step: 30, loss: 0.019689660519361496
step: 40, loss: 0.019497280940413475
step: 50, loss: 0.0610426589846611
step: 60, loss: 0.027837932109832764
step: 70, loss: 0.037271611392498016
step: 80, loss: 0.011677512899041176
step: 90, loss: 0.0011154866078868508
step: 100, loss: 0.03545370697975159
step: 110, loss: 0.12035418301820755
step: 120, loss: 0.0036356444470584393
step: 130, loss: 0.057010553777217865
step: 140, loss: 0.1185242310166359
step: 150, loss: 0.048400409519672394
step: 160, loss: 0.02739497646689415
step: 170, loss: 0.02837083861231804
step: 180, loss: 0.004334238823503256
step: 190, loss: 0.040390584617853165
step: 200, loss: 0.06663230061531067
step: 210, loss: 0.03350639343261719
step: 220, loss: 0.04763379693031311
step: 230, loss: 0.0196559876203537
step: 240, loss: 0.04516852647066116
step: 250, loss: 0.009392281994223595
step: 260, loss: 0.003912340383976698
step: 270, loss: 0.006910612806677818
step: 280, loss: 0.00017661851597949862
step: 290, loss: 0.043157972395420074
step: 300, loss: 0.0005743666552007198
step: 310, loss: 8.735139999771491e-05
step: 320, loss: 0.0039548915810883045
step: 330, loss: 0.11492224782705307
step: 340, loss: 0.020176071673631668
step: 350, loss: 0.1001317948102951
step: 360, loss: 0.04002045467495918
step: 370, loss: 0.06806934624910355
step: 380, loss: 0.03670557960867882
epoch 11: dev_f1=0.7185929648241205, f1=0.7277628032345013, best_f1=0.7166666666666668
step: 0, loss: 0.009055336937308311
step: 10, loss: 0.13122422993183136
step: 20, loss: 0.00015636630996596068
step: 30, loss: 0.0175117589533329
step: 40, loss: 0.06390253454446793
step: 50, loss: 0.053623881191015244
step: 60, loss: 0.012954246252775192
step: 70, loss: 0.04046003893017769
step: 80, loss: 0.04013936221599579
step: 90, loss: 0.025571847334504128
step: 100, loss: 0.08626271039247513
step: 110, loss: 9.854165546130389e-05
step: 120, loss: 0.016748709604144096
step: 130, loss: 0.035417087376117706
step: 140, loss: 0.019788432866334915
step: 150, loss: 0.019484862685203552
step: 160, loss: 0.034436654299497604
step: 170, loss: 0.014531027525663376
step: 180, loss: 0.00010914679296547547
step: 190, loss: 0.017623022198677063
step: 200, loss: 0.021434299647808075
step: 210, loss: 0.06637191027402878
step: 220, loss: 0.05395260080695152
step: 230, loss: 0.04403867572546005
step: 240, loss: 0.12425624579191208
step: 250, loss: 0.005315233953297138
step: 260, loss: 0.002230582060292363
step: 270, loss: 0.044044677168130875
step: 280, loss: 0.01841973140835762
step: 290, loss: 0.02238520421087742
step: 300, loss: 0.016713201999664307
step: 310, loss: 0.01016169972717762
step: 320, loss: 0.0440838597714901
step: 330, loss: 0.017871880903840065
step: 340, loss: 0.026059819385409355
step: 350, loss: 0.034303124994039536
step: 360, loss: 0.012891043908894062
step: 370, loss: 0.000688138185068965
step: 380, loss: 0.004942606668919325
epoch 12: dev_f1=0.702576112412178, f1=0.7174447174447175, best_f1=0.7166666666666668
step: 0, loss: 0.0005279586184769869
step: 10, loss: 0.016501275822520256
step: 20, loss: 0.018675748258829117
step: 30, loss: 0.028081011027097702
step: 40, loss: 0.013937690295279026
step: 50, loss: 0.08485885709524155
step: 60, loss: 0.01939733698964119
step: 70, loss: 0.005166954826563597
step: 80, loss: 0.03655804321169853
step: 90, loss: 0.020735736936330795
step: 100, loss: 0.05329480767250061
step: 110, loss: 0.0032790801487863064
step: 120, loss: 0.035379767417907715
step: 130, loss: 0.0011774473823606968
step: 140, loss: 0.0015565775102004409
step: 150, loss: 0.05401116609573364
step: 160, loss: 0.022248756140470505
step: 170, loss: 0.000509429897647351
step: 180, loss: 0.0030248172115534544
step: 190, loss: 0.09452393651008606
step: 200, loss: 0.04705921187996864
step: 210, loss: 0.0054918378591537476
step: 220, loss: 0.020436549559235573
step: 230, loss: 0.01250800583511591
step: 240, loss: 0.009220032952725887
step: 250, loss: 0.00040715650538913906
step: 260, loss: 0.001593483379110694
step: 270, loss: 0.08514770865440369
step: 280, loss: 0.06459333747625351
step: 290, loss: 0.09493041783571243
step: 300, loss: 0.07245761901140213
step: 310, loss: 0.010911683551967144
step: 320, loss: 0.08985418826341629
step: 330, loss: 0.01917489804327488
step: 340, loss: 0.015186745673418045
step: 350, loss: 0.0764625072479248
step: 360, loss: 0.10459458082914352
step: 370, loss: 0.04377790540456772
step: 380, loss: 0.004067062400281429
epoch 13: dev_f1=0.7183098591549296, f1=0.7462686567164178, best_f1=0.7166666666666668
step: 0, loss: 0.000261092180153355
step: 10, loss: 0.0351363904774189
step: 20, loss: 0.0033458720427006483
step: 30, loss: 0.024191806092858315
step: 40, loss: 9.490578668192029e-05
step: 50, loss: 0.0004887854447588325
step: 60, loss: 0.003160299500450492
step: 70, loss: 0.021725662052631378
step: 80, loss: 0.07161107659339905
step: 90, loss: 0.026407631114125252
step: 100, loss: 0.013451667502522469
step: 110, loss: 0.0010047999676316977
step: 120, loss: 0.005592342000454664
step: 130, loss: 0.02373618073761463
step: 140, loss: 0.01821659319102764
step: 150, loss: 0.021452348679304123
step: 160, loss: 0.06586793065071106
step: 170, loss: 0.010107588022947311
step: 180, loss: 0.001448642578907311
step: 190, loss: 0.04568580910563469
step: 200, loss: 0.02689305506646633
step: 210, loss: 0.005107665900141001
step: 220, loss: 0.022276869043707848
step: 230, loss: 0.020473822951316833
step: 240, loss: 0.0014983428409323096
step: 250, loss: 0.03156478330492973
step: 260, loss: 0.0005314266309142113
step: 270, loss: 0.0492016077041626
step: 280, loss: 0.015133182518184185
step: 290, loss: 0.00010016236046794802
step: 300, loss: 0.03570854663848877
step: 310, loss: 0.0004953902098350227
step: 320, loss: 0.00221610302105546
step: 330, loss: 0.01773926429450512
step: 340, loss: 0.00010113303869729862
step: 350, loss: 8.580661960877478e-05
step: 360, loss: 0.290804922580719
step: 370, loss: 0.038841281086206436
step: 380, loss: 0.02438279055058956
epoch 14: dev_f1=0.7064935064935065, f1=0.7252747252747253, best_f1=0.7166666666666668
step: 0, loss: 0.0035569281317293644
step: 10, loss: 9.440215944778174e-05
step: 20, loss: 0.03333249315619469
step: 30, loss: 0.0007110636797733605
step: 40, loss: 0.025507481768727303
step: 50, loss: 0.03692764788866043
step: 60, loss: 0.0028150032740086317
step: 70, loss: 0.0002200786693720147
step: 80, loss: 0.036845073103904724
step: 90, loss: 0.13346512615680695
step: 100, loss: 0.002260044915601611
step: 110, loss: 0.02736622467637062
step: 120, loss: 0.005789170041680336
step: 130, loss: 6.143039354356006e-05
step: 140, loss: 0.009532138705253601
step: 150, loss: 0.04861491173505783
step: 160, loss: 0.00488482927903533
step: 170, loss: 0.03729797154664993
step: 180, loss: 0.008687617257237434
step: 190, loss: 0.04488016292452812
step: 200, loss: 0.025044212117791176
step: 210, loss: 0.0391739159822464
step: 220, loss: 0.00584507267922163
step: 230, loss: 0.0022509898990392685
step: 240, loss: 0.03272513300180435
step: 250, loss: 0.04183102771639824
step: 260, loss: 4.797533983946778e-05
step: 270, loss: 0.07144740223884583
step: 280, loss: 0.029084626585245132
step: 290, loss: 0.03799368441104889
step: 300, loss: 0.3078267276287079
step: 310, loss: 0.013411972671747208
step: 320, loss: 0.08804985880851746
step: 330, loss: 0.017617451027035713
step: 340, loss: 8.300425542984158e-05
step: 350, loss: 0.01868285983800888
step: 360, loss: 0.026417896151542664
step: 370, loss: 0.04288456216454506
step: 380, loss: 0.0011282821651548147
epoch 15: dev_f1=0.7036144578313254, f1=0.7333333333333334, best_f1=0.7166666666666668
step: 0, loss: 0.00022198485385160893
step: 10, loss: 0.0010810659732669592
step: 20, loss: 0.08566872030496597
step: 30, loss: 0.06896686553955078
step: 40, loss: 0.021451206877827644
step: 50, loss: 0.030874405056238174
step: 60, loss: 0.016877034679055214
step: 70, loss: 0.0279106292873621
step: 80, loss: 0.006817328743636608
step: 90, loss: 0.033033791929483414
step: 100, loss: 0.0735609158873558
step: 110, loss: 0.0282426830381155
step: 120, loss: 0.050766877830028534
step: 130, loss: 0.05526980757713318
step: 140, loss: 0.014542141929268837
step: 150, loss: 0.011083423160016537
step: 160, loss: 0.012664376758038998
step: 170, loss: 0.006805823650211096
step: 180, loss: 0.014076326973736286
step: 190, loss: 0.12438219785690308
step: 200, loss: 0.09583360701799393
step: 210, loss: 0.022795243188738823
step: 220, loss: 0.05553608387708664
step: 230, loss: 0.014004416763782501
step: 240, loss: 0.03540973737835884
step: 250, loss: 0.00039375355117954314
step: 260, loss: 0.07262276113033295
step: 270, loss: 0.0016342285089194775
step: 280, loss: 0.0011481096735224128
step: 290, loss: 0.018740931525826454
step: 300, loss: 0.004726131912320852
step: 310, loss: 0.04339679703116417
step: 320, loss: 0.0476098470389843
step: 330, loss: 0.013709798455238342
step: 340, loss: 0.017230872064828873
step: 350, loss: 0.03623915836215019
step: 360, loss: 0.019402483478188515
step: 370, loss: 0.004985366482287645
step: 380, loss: 0.08631602674722672
epoch 16: dev_f1=0.7070217917675545, f1=0.741687979539642, best_f1=0.7166666666666668
step: 0, loss: 0.036490149796009064
step: 10, loss: 0.008276690728962421
step: 20, loss: 0.0018549252999946475
step: 30, loss: 0.06371233612298965
step: 40, loss: 0.0010469135595485568
step: 50, loss: 0.00930909812450409
step: 60, loss: 0.02232806570827961
step: 70, loss: 0.0047157839871943
step: 80, loss: 0.033356212079524994
step: 90, loss: 0.029687026515603065
step: 100, loss: 0.001642960007302463
step: 110, loss: 0.025953568518161774
step: 120, loss: 0.00029759618337266147
step: 130, loss: 0.011469454504549503
step: 140, loss: 0.019823826849460602
step: 150, loss: 0.018011700361967087
step: 160, loss: 0.02838873863220215
step: 170, loss: 0.045135099440813065
step: 180, loss: 0.00013147035497240722
step: 190, loss: 0.00035701546585187316
step: 200, loss: 0.0010734774405136704
step: 210, loss: 0.004031956195831299
step: 220, loss: 0.0027401067782193422
step: 230, loss: 0.00016056126332841814
step: 240, loss: 0.01581542007625103
step: 250, loss: 7.332735549425706e-05
step: 260, loss: 0.04778068885207176
step: 270, loss: 0.022130798548460007
step: 280, loss: 0.0006486989441327751
step: 290, loss: 0.057834673672914505
step: 300, loss: 0.0007262690924108028
step: 310, loss: 0.0032003652304410934
step: 320, loss: 0.0016819534357637167
step: 330, loss: 0.03475704789161682
step: 340, loss: 0.05284952372312546
step: 350, loss: 0.023000240325927734
step: 360, loss: 0.06103287264704704
step: 370, loss: 0.00019097296171821654
step: 380, loss: 0.024256261065602303
epoch 17: dev_f1=0.6898263027295285, f1=0.7272727272727273, best_f1=0.7166666666666668
step: 0, loss: 3.4657790820347145e-05
step: 10, loss: 0.025218229740858078
step: 20, loss: 0.020781060680747032
step: 30, loss: 0.038854267448186874
step: 40, loss: 0.00023911570315249264
step: 50, loss: 0.03442469239234924
step: 60, loss: 0.011159729212522507
step: 70, loss: 0.0006473857793025672
step: 80, loss: 0.002815274288877845
step: 90, loss: 4.7277655539801344e-05
step: 100, loss: 0.030101347714662552
step: 110, loss: 0.00015148791135288775
step: 120, loss: 0.027307728305459023
step: 130, loss: 0.04156814515590668
step: 140, loss: 0.08457353711128235
step: 150, loss: 0.0026575252413749695
step: 160, loss: 0.05608568340539932
step: 170, loss: 0.0014377220068126917
step: 180, loss: 0.0375913605093956
step: 190, loss: 0.013670877553522587
step: 200, loss: 0.09082825481891632
step: 210, loss: 0.0002877659280784428
step: 220, loss: 0.0001443972287233919
step: 230, loss: 0.0002786582917906344
step: 240, loss: 0.033178068697452545
step: 250, loss: 9.217234037350863e-05
step: 260, loss: 0.00019830431847367436
step: 270, loss: 0.09023302048444748
step: 280, loss: 0.010936214588582516
step: 290, loss: 0.048829346895217896
step: 300, loss: 0.010816159658133984
step: 310, loss: 0.022204473614692688
step: 320, loss: 0.015112094581127167
step: 330, loss: 0.04204007610678673
step: 340, loss: 0.21006383001804352
step: 350, loss: 0.016087019816040993
step: 360, loss: 0.007842976599931717
step: 370, loss: 0.0014361651847139
step: 380, loss: 0.029858926311135292
epoch 18: dev_f1=0.6967418546365916, f1=0.7214854111405835, best_f1=0.7166666666666668
step: 0, loss: 0.0006524004857055843
step: 10, loss: 0.015808960422873497
step: 20, loss: 0.01909460686147213
step: 30, loss: 0.031297728419303894
step: 40, loss: 0.056157369166612625
step: 50, loss: 0.022841941565275192
step: 60, loss: 0.04459965601563454
step: 70, loss: 0.019674072042107582
step: 80, loss: 0.0031901407055556774
step: 90, loss: 0.03467399254441261
step: 100, loss: 0.0006014028913341463
step: 110, loss: 0.027117963880300522
step: 120, loss: 0.0014446147251874208
step: 130, loss: 0.029128732159733772
step: 140, loss: 0.01832544431090355
step: 150, loss: 0.011166694574058056
step: 160, loss: 5.1475100917741656e-05
step: 170, loss: 0.07930827140808105
step: 180, loss: 2.9402919608401135e-05
step: 190, loss: 0.1321113109588623
step: 200, loss: 0.040590785443782806
step: 210, loss: 0.007179014850407839
step: 220, loss: 0.025872429832816124
step: 230, loss: 0.02387506514787674
step: 240, loss: 0.046868182718753815
step: 250, loss: 0.00020851824956480414
step: 260, loss: 0.0001768787915352732
step: 270, loss: 0.0007393438718281686
step: 280, loss: 0.023509446531534195
step: 290, loss: 0.02572551928460598
step: 300, loss: 0.050069358199834824
step: 310, loss: 0.07868141680955887
step: 320, loss: 0.00047276332043111324
step: 330, loss: 0.0010355841368436813
step: 340, loss: 0.00012300150410737842
step: 350, loss: 0.0002722720382735133
step: 360, loss: 0.042434096336364746
step: 370, loss: 0.0014822040684521198
step: 380, loss: 0.00043168917181901634
epoch 19: dev_f1=0.7035175879396985, f1=0.7356948228882835, best_f1=0.7166666666666668
step: 0, loss: 0.03468674421310425
step: 10, loss: 0.04267604649066925
step: 20, loss: 0.01606476865708828
step: 30, loss: 0.0017828589770942926
step: 40, loss: 0.03313818946480751
step: 50, loss: 0.005539495963603258
step: 60, loss: 0.036664824932813644
step: 70, loss: 0.003586841281503439
step: 80, loss: 0.002022965345531702
step: 90, loss: 0.01662757247686386
step: 100, loss: 0.029915694147348404
step: 110, loss: 0.00010084857058245689
step: 120, loss: 0.003497902536764741
step: 130, loss: 0.0032269328366965055
step: 140, loss: 0.05800791084766388
step: 150, loss: 0.01994144730269909
step: 160, loss: 0.00900687463581562
step: 170, loss: 6.597156607313082e-05
step: 180, loss: 0.0002611031522974372
step: 190, loss: 2.3856408006395213e-05
step: 200, loss: 0.013086223974823952
step: 210, loss: 0.010669647715985775
step: 220, loss: 0.0002913798962254077
step: 230, loss: 0.00011495894432300702
step: 240, loss: 0.020606432110071182
step: 250, loss: 0.025172190740704536
step: 260, loss: 0.013877090997993946
step: 270, loss: 0.00011714830179698765
step: 280, loss: 0.04763166978955269
step: 290, loss: 0.0003665540716610849
step: 300, loss: 0.018074898049235344
step: 310, loss: 0.02572055533528328
step: 320, loss: 0.04828571528196335
step: 330, loss: 0.002098896075040102
step: 340, loss: 0.020435839891433716
step: 350, loss: 0.00014606077456846833
step: 360, loss: 0.06426568329334259
step: 370, loss: 0.056803084909915924
step: 380, loss: 0.012642023153603077
epoch 20: dev_f1=0.7012987012987013, f1=0.7191011235955057, best_f1=0.7166666666666668
