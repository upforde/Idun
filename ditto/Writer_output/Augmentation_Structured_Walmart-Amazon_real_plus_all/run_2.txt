cuda
Device: cuda
step: 0, loss: 0.8509789109230042
step: 10, loss: 0.14155146479606628
step: 20, loss: 0.3093673884868622
step: 30, loss: 0.7523569464683533
step: 40, loss: 0.27067700028419495
step: 50, loss: 0.4015909433364868
step: 60, loss: 0.054782405495643616
step: 70, loss: 0.6448944807052612
step: 80, loss: 0.3821502923965454
step: 90, loss: 0.3929789960384369
step: 100, loss: 0.3150102496147156
step: 110, loss: 0.3700774312019348
step: 120, loss: 0.3090962767601013
step: 130, loss: 0.3685852885246277
step: 140, loss: 0.35226112604141235
step: 150, loss: 0.2991880774497986
step: 160, loss: 0.1923287808895111
step: 170, loss: 0.26781854033470154
step: 180, loss: 0.13198363780975342
step: 190, loss: 0.2947428226470947
step: 200, loss: 0.16093260049819946
step: 210, loss: 0.25516507029533386
step: 220, loss: 0.5451900362968445
step: 230, loss: 0.2650473415851593
step: 240, loss: 0.3188585340976715
step: 250, loss: 0.16423393785953522
step: 260, loss: 0.18690858781337738
step: 270, loss: 0.3707732558250427
step: 280, loss: 0.5618108510971069
step: 290, loss: 0.23599573969841003
step: 300, loss: 0.20781657099723816
step: 310, loss: 0.1951143443584442
step: 320, loss: 0.201434925198555
step: 330, loss: 0.12146538496017456
step: 340, loss: 0.23224714398384094
step: 350, loss: 0.0864226296544075
step: 360, loss: 0.1287647932767868
step: 370, loss: 0.1812201738357544
step: 380, loss: 0.16695527732372284
epoch 1: dev_f1=0.5938864628820961, f1=0.6030368763557483, best_f1=0.6030368763557483
step: 0, loss: 0.10184600204229355
step: 10, loss: 0.08290518075227737
step: 20, loss: 0.14950378239154816
step: 30, loss: 0.15178172290325165
step: 40, loss: 0.11895829439163208
step: 50, loss: 0.19466039538383484
step: 60, loss: 0.2451452910900116
step: 70, loss: 0.3261186182498932
step: 80, loss: 0.10856258124113083
step: 90, loss: 0.25339755415916443
step: 100, loss: 0.15812183916568756
step: 110, loss: 0.2624034881591797
step: 120, loss: 0.26076486706733704
step: 130, loss: 0.26839199662208557
step: 140, loss: 0.28616034984588623
step: 150, loss: 0.1155773475766182
step: 160, loss: 0.1199631541967392
step: 170, loss: 0.09454900026321411
step: 180, loss: 0.1890806257724762
step: 190, loss: 0.10556373745203018
step: 200, loss: 0.06647743284702301
step: 210, loss: 0.15338750183582306
step: 220, loss: 0.14106515049934387
step: 230, loss: 0.15667469799518585
step: 240, loss: 0.19449982047080994
step: 250, loss: 0.07858794927597046
step: 260, loss: 0.08420343697071075
step: 270, loss: 0.16659846901893616
step: 280, loss: 0.07538079470396042
step: 290, loss: 0.3230115473270416
step: 300, loss: 0.14750643074512482
step: 310, loss: 0.14880172908306122
step: 320, loss: 0.10535972565412521
step: 330, loss: 0.3368850350379944
step: 340, loss: 0.14668534696102142
step: 350, loss: 0.06512631475925446
step: 360, loss: 0.10108295828104019
step: 370, loss: 0.16795361042022705
step: 380, loss: 0.05289648845791817
epoch 2: dev_f1=0.6510538641686183, f1=0.6635730858468677, best_f1=0.6635730858468677
step: 0, loss: 0.11255046725273132
step: 10, loss: 0.07705531269311905
step: 20, loss: 0.06495270133018494
step: 30, loss: 0.126348078250885
step: 40, loss: 0.10635119676589966
step: 50, loss: 0.11489839106798172
step: 60, loss: 0.11435706913471222
step: 70, loss: 0.16972583532333374
step: 80, loss: 0.2172948122024536
step: 90, loss: 0.0604916475713253
step: 100, loss: 0.12915852665901184
step: 110, loss: 0.020266037434339523
step: 120, loss: 0.08375488221645355
step: 130, loss: 0.07312489300966263
step: 140, loss: 0.027113765478134155
step: 150, loss: 0.10786560922861099
step: 160, loss: 0.08674401789903641
step: 170, loss: 0.14229369163513184
step: 180, loss: 0.10448259860277176
step: 190, loss: 0.09285014867782593
step: 200, loss: 0.171305850148201
step: 210, loss: 0.2108328491449356
step: 220, loss: 0.03644251823425293
step: 230, loss: 0.0907798781991005
step: 240, loss: 0.1981968879699707
step: 250, loss: 0.06999219954013824
step: 260, loss: 0.012311583384871483
step: 270, loss: 0.07888016849756241
step: 280, loss: 0.16928261518478394
step: 290, loss: 0.06775510311126709
step: 300, loss: 0.02832060493528843
step: 310, loss: 0.08907020837068558
step: 320, loss: 0.05029197409749031
step: 330, loss: 0.1962181031703949
step: 340, loss: 0.13531288504600525
step: 350, loss: 0.12889277935028076
step: 360, loss: 0.06932956725358963
step: 370, loss: 0.08722560107707977
step: 380, loss: 0.12063521146774292
epoch 3: dev_f1=0.6904761904761906, f1=0.6896551724137931, best_f1=0.6896551724137931
step: 0, loss: 0.13404110074043274
step: 10, loss: 0.18961380422115326
step: 20, loss: 0.03618425130844116
step: 30, loss: 0.05743199586868286
step: 40, loss: 0.11441771686077118
step: 50, loss: 0.0880691409111023
step: 60, loss: 0.16228128969669342
step: 70, loss: 0.04210323840379715
step: 80, loss: 0.1983862817287445
step: 90, loss: 0.2409549355506897
step: 100, loss: 0.047297246754169464
step: 110, loss: 0.06098698824644089
step: 120, loss: 0.047938257455825806
step: 130, loss: 0.14911165833473206
step: 140, loss: 0.029209459200501442
step: 150, loss: 0.014697938226163387
step: 160, loss: 0.10860873758792877
step: 170, loss: 0.01703418605029583
step: 180, loss: 0.010895159095525742
step: 190, loss: 0.1812271773815155
step: 200, loss: 0.07305524498224258
step: 210, loss: 0.1365686058998108
step: 220, loss: 0.13536646962165833
step: 230, loss: 0.10028750449419022
step: 240, loss: 0.1656751036643982
step: 250, loss: 0.07222119718790054
step: 260, loss: 0.34653815627098083
step: 270, loss: 0.2214588224887848
step: 280, loss: 0.12146241217851639
step: 290, loss: 0.05580570548772812
step: 300, loss: 0.05813371762633324
step: 310, loss: 0.08079516887664795
step: 320, loss: 0.10045421868562698
step: 330, loss: 0.06401762366294861
step: 340, loss: 0.08189889043569565
step: 350, loss: 0.02628839574754238
step: 360, loss: 0.04828668758273125
step: 370, loss: 0.005972444079816341
step: 380, loss: 0.06823699921369553
epoch 4: dev_f1=0.6975476839237057, f1=0.6557377049180327, best_f1=0.6557377049180327
step: 0, loss: 0.159128338098526
step: 10, loss: 0.029770689085125923
step: 20, loss: 0.1045171245932579
step: 30, loss: 0.007469989359378815
step: 40, loss: 0.04244166240096092
step: 50, loss: 0.08242838829755783
step: 60, loss: 0.07314024865627289
step: 70, loss: 0.038238830864429474
step: 80, loss: 0.11044025421142578
step: 90, loss: 0.04549184441566467
step: 100, loss: 0.11214331537485123
step: 110, loss: 0.02334536798298359
step: 120, loss: 0.03055277094244957
step: 130, loss: 0.02674766257405281
step: 140, loss: 0.20691069960594177
step: 150, loss: 0.021070392802357674
step: 160, loss: 0.20756421983242035
step: 170, loss: 0.06813429296016693
step: 180, loss: 0.04906317591667175
step: 190, loss: 0.1648862212896347
step: 200, loss: 0.09976166486740112
step: 210, loss: 0.09216276556253433
step: 220, loss: 0.13820622861385345
step: 230, loss: 0.061772290617227554
step: 240, loss: 0.04072951897978783
step: 250, loss: 0.06131584197282791
step: 260, loss: 0.006396220996975899
step: 270, loss: 0.19384802877902985
step: 280, loss: 0.08981595188379288
step: 290, loss: 0.07072683423757553
step: 300, loss: 0.07768940925598145
step: 310, loss: 0.16177748143672943
step: 320, loss: 0.09363847225904465
step: 330, loss: 0.07074384391307831
step: 340, loss: 0.08693291991949081
step: 350, loss: 0.059464987367391586
step: 360, loss: 0.02316037006676197
step: 370, loss: 0.035857148468494415
step: 380, loss: 0.013567248359322548
epoch 5: dev_f1=0.672514619883041, f1=0.6804733727810651, best_f1=0.6557377049180327
step: 0, loss: 0.07778522372245789
step: 10, loss: 0.19104096293449402
step: 20, loss: 0.014835003763437271
step: 30, loss: 0.014908701181411743
step: 40, loss: 0.07946418225765228
step: 50, loss: 0.008261634036898613
step: 60, loss: 0.0060652513056993484
step: 70, loss: 0.030806012451648712
step: 80, loss: 0.040834151208400726
step: 90, loss: 0.015817131847143173
step: 100, loss: 0.03152242675423622
step: 110, loss: 0.09308543801307678
step: 120, loss: 0.024721365422010422
step: 130, loss: 0.012617327272891998
step: 140, loss: 0.05056487023830414
step: 150, loss: 0.011450675316154957
step: 160, loss: 0.02233157865703106
step: 170, loss: 0.26924678683280945
step: 180, loss: 0.06680554151535034
step: 190, loss: 0.03426024317741394
step: 200, loss: 0.08854976296424866
step: 210, loss: 0.026625357568264008
step: 220, loss: 0.013819257728755474
step: 230, loss: 0.001995522528886795
step: 240, loss: 0.017345910891890526
step: 250, loss: 0.0022176140919327736
step: 260, loss: 0.07058549672365189
step: 270, loss: 0.032565273344516754
step: 280, loss: 0.01031441893428564
step: 290, loss: 0.19610488414764404
step: 300, loss: 0.018001267686486244
step: 310, loss: 0.13640201091766357
step: 320, loss: 0.08771345019340515
step: 330, loss: 0.2621333599090576
step: 340, loss: 0.11958609521389008
step: 350, loss: 0.021573519334197044
step: 360, loss: 0.06412879377603531
step: 370, loss: 0.10469729453325272
step: 380, loss: 0.007511701434850693
epoch 6: dev_f1=0.7371134020618555, f1=0.6876640419947506, best_f1=0.6876640419947506
step: 0, loss: 0.11887799948453903
step: 10, loss: 0.036828115582466125
step: 20, loss: 0.00383318611420691
step: 30, loss: 0.014751492999494076
step: 40, loss: 0.01789751462638378
step: 50, loss: 0.01838889718055725
step: 60, loss: 0.007090088911354542
step: 70, loss: 0.02330736070871353
step: 80, loss: 0.029367825016379356
step: 90, loss: 0.03375428915023804
step: 100, loss: 0.02058575488626957
step: 110, loss: 0.05612621456384659
step: 120, loss: 0.024807149544358253
step: 130, loss: 0.0465623177587986
step: 140, loss: 0.04698101058602333
step: 150, loss: 0.05113683268427849
step: 160, loss: 0.0034602221567183733
step: 170, loss: 0.10286639630794525
step: 180, loss: 0.26669859886169434
step: 190, loss: 0.08851374685764313
step: 200, loss: 0.0641842857003212
step: 210, loss: 0.01016648206859827
step: 220, loss: 0.09013892710208893
step: 230, loss: 0.027924446389079094
step: 240, loss: 0.01322044525295496
step: 250, loss: 0.13833020627498627
step: 260, loss: 0.01863493025302887
step: 270, loss: 0.08150968700647354
step: 280, loss: 0.015777798369526863
step: 290, loss: 0.1807934045791626
step: 300, loss: 0.03964819014072418
step: 310, loss: 0.05588345602154732
step: 320, loss: 0.026643062010407448
step: 330, loss: 0.08314040303230286
step: 340, loss: 0.028404852375388145
step: 350, loss: 0.013410920277237892
step: 360, loss: 0.01646457612514496
step: 370, loss: 0.08757027983665466
step: 380, loss: 0.043274763971567154
epoch 7: dev_f1=0.711340206185567, f1=0.6684636118598383, best_f1=0.6876640419947506
step: 0, loss: 0.022875584661960602
step: 10, loss: 0.0002498005342204124
step: 20, loss: 0.0702299177646637
step: 30, loss: 0.00023995614901650697
step: 40, loss: 0.005686798598617315
step: 50, loss: 0.022060638293623924
step: 60, loss: 0.04590578004717827
step: 70, loss: 0.04489428177475929
step: 80, loss: 0.008036325685679913
step: 90, loss: 0.26908406615257263
step: 100, loss: 0.060142938047647476
step: 110, loss: 0.046180110424757004
step: 120, loss: 0.08090071380138397
step: 130, loss: 0.08116964995861053
step: 140, loss: 0.09939822554588318
step: 150, loss: 0.05890334025025368
step: 160, loss: 0.056307751685380936
step: 170, loss: 0.06662553548812866
step: 180, loss: 0.07955531775951385
step: 190, loss: 0.0006080258754082024
step: 200, loss: 0.02584013156592846
step: 210, loss: 0.007295593153685331
step: 220, loss: 0.03158135339617729
step: 230, loss: 0.07308948040008545
step: 240, loss: 0.09057871997356415
step: 250, loss: 0.011142071336507797
step: 260, loss: 0.04650804400444031
step: 270, loss: 0.12768781185150146
step: 280, loss: 0.03618619963526726
step: 290, loss: 0.09403308480978012
step: 300, loss: 0.12654221057891846
step: 310, loss: 0.03275733068585396
step: 320, loss: 0.03548262640833855
step: 330, loss: 0.058070000261068344
step: 340, loss: 0.07538814097642899
step: 350, loss: 0.03549749404191971
step: 360, loss: 0.0352373905479908
step: 370, loss: 0.06883738189935684
step: 380, loss: 0.011911991983652115
epoch 8: dev_f1=0.7211267605633802, f1=0.6744868035190615, best_f1=0.6876640419947506
step: 0, loss: 0.00416569784283638
step: 10, loss: 0.009253868833184242
step: 20, loss: 0.0006339153624139726
step: 30, loss: 0.010113363154232502
step: 40, loss: 0.005668328609317541
step: 50, loss: 0.0027464800514280796
step: 60, loss: 0.037019334733486176
step: 70, loss: 0.060420941561460495
step: 80, loss: 0.004393628798425198
step: 90, loss: 0.0001716933329589665
step: 100, loss: 0.012924669310450554
step: 110, loss: 0.08992476016283035
step: 120, loss: 0.0007243439904414117
step: 130, loss: 0.07697582989931107
step: 140, loss: 0.04170415922999382
step: 150, loss: 0.004465644713491201
step: 160, loss: 0.023740163072943687
step: 170, loss: 0.14104656875133514
step: 180, loss: 0.013195293955504894
step: 190, loss: 0.007611049804836512
step: 200, loss: 0.0896206870675087
step: 210, loss: 0.19948430359363556
step: 220, loss: 0.1268010288476944
step: 230, loss: 0.03848787769675255
step: 240, loss: 0.16018974781036377
step: 250, loss: 0.01772502437233925
step: 260, loss: 0.11356490850448608
step: 270, loss: 0.07371993362903595
step: 280, loss: 0.006813816260546446
step: 290, loss: 0.005164762493222952
step: 300, loss: 0.0810149759054184
step: 310, loss: 0.0008635835256427526
step: 320, loss: 0.07149749249219894
step: 330, loss: 0.03320253640413284
step: 340, loss: 0.0014581194845959544
step: 350, loss: 0.028717897832393646
step: 360, loss: 0.14258898794651031
step: 370, loss: 0.09312838315963745
step: 380, loss: 0.01346682757139206
epoch 9: dev_f1=0.7116279069767442, f1=0.7064439140811456, best_f1=0.6876640419947506
step: 0, loss: 0.03988955169916153
step: 10, loss: 0.002989408327266574
step: 20, loss: 0.03276686742901802
step: 30, loss: 0.012980742380023003
step: 40, loss: 0.017800431698560715
step: 50, loss: 0.01066293939948082
step: 60, loss: 0.0016919487388804555
step: 70, loss: 0.009858174249529839
step: 80, loss: 0.003568691201508045
step: 90, loss: 0.00887325033545494
step: 100, loss: 0.09911777079105377
step: 110, loss: 0.1362723857164383
step: 120, loss: 0.0006942472537048161
step: 130, loss: 0.04629924148321152
step: 140, loss: 0.031159058213233948
step: 150, loss: 0.06650454550981522
step: 160, loss: 0.0012421109713613987
step: 170, loss: 0.023262543603777885
step: 180, loss: 0.05737625062465668
step: 190, loss: 0.0006055085686966777
step: 200, loss: 0.031128384172916412
step: 210, loss: 0.0051745702512562275
step: 220, loss: 0.061056334525346756
step: 230, loss: 0.00016143126413226128
step: 240, loss: 0.07114692777395248
step: 250, loss: 0.007196088321506977
step: 260, loss: 0.048155006021261215
step: 270, loss: 0.08822906762361526
step: 280, loss: 0.025081584230065346
step: 290, loss: 0.11078579723834991
step: 300, loss: 0.006400731857866049
step: 310, loss: 0.007419030647724867
step: 320, loss: 0.13011351227760315
step: 330, loss: 0.05878255516290665
step: 340, loss: 0.00169383327011019
step: 350, loss: 0.0021384696010500193
step: 360, loss: 0.0040335203520953655
step: 370, loss: 0.001825173501856625
step: 380, loss: 0.024091321974992752
epoch 10: dev_f1=0.6971153846153847, f1=0.6945812807881775, best_f1=0.6876640419947506
step: 0, loss: 0.05589349940419197
step: 10, loss: 0.04439700394868851
step: 20, loss: 0.005839996039867401
step: 30, loss: 0.014261161908507347
step: 40, loss: 0.030400551855564117
step: 50, loss: 0.12005270272493362
step: 60, loss: 0.05044332891702652
step: 70, loss: 0.01343462336808443
step: 80, loss: 0.0005426805000752211
step: 90, loss: 0.0885128453373909
step: 100, loss: 0.13521072268486023
step: 110, loss: 0.0484560988843441
step: 120, loss: 0.051445890218019485
step: 130, loss: 0.009541870094835758
step: 140, loss: 0.02262028679251671
step: 150, loss: 0.09801420569419861
step: 160, loss: 0.1115579679608345
step: 170, loss: 0.01861458085477352
step: 180, loss: 0.003613509703427553
step: 190, loss: 0.051398422569036484
step: 200, loss: 0.03151564672589302
step: 210, loss: 0.009939003735780716
step: 220, loss: 0.023212138563394547
step: 230, loss: 0.0036721990909427404
step: 240, loss: 0.06920815259218216
step: 250, loss: 0.032806988805532455
step: 260, loss: 0.12518033385276794
step: 270, loss: 0.06457356363534927
step: 280, loss: 0.04441431164741516
step: 290, loss: 0.016687124967575073
step: 300, loss: 0.029798373579978943
step: 310, loss: 0.017348360270261765
step: 320, loss: 0.07925013452768326
step: 330, loss: 0.016013899818062782
step: 340, loss: 0.039203982800245285
step: 350, loss: 0.04284030571579933
step: 360, loss: 0.002628761576488614
step: 370, loss: 0.017952075228095055
step: 380, loss: 0.006500158458948135
epoch 11: dev_f1=0.6873385012919897, f1=0.6702127659574468, best_f1=0.6876640419947506
step: 0, loss: 0.007371257059276104
step: 10, loss: 0.017339713871479034
step: 20, loss: 0.00018241476209368557
step: 30, loss: 0.060632478445768356
step: 40, loss: 0.01842363551259041
step: 50, loss: 0.08854265511035919
step: 60, loss: 0.04157092422246933
step: 70, loss: 0.044699929654598236
step: 80, loss: 0.015675339847803116
step: 90, loss: 0.003905949415639043
step: 100, loss: 0.0056706019677221775
step: 110, loss: 0.0006938966689631343
step: 120, loss: 8.199210424209014e-05
step: 130, loss: 0.026610305532813072
step: 140, loss: 0.12856188416481018
step: 150, loss: 8.87158967088908e-05
step: 160, loss: 0.0689597949385643
step: 170, loss: 0.04441216588020325
step: 180, loss: 0.024205755442380905
step: 190, loss: 0.003780704690143466
step: 200, loss: 0.11739153414964676
step: 210, loss: 0.005423979368060827
step: 220, loss: 0.008569786325097084
step: 230, loss: 0.09979043900966644
step: 240, loss: 0.012524557299911976
step: 250, loss: 0.007149959914386272
step: 260, loss: 0.0015958889853209257
step: 270, loss: 0.04236246272921562
step: 280, loss: 0.03225019946694374
step: 290, loss: 0.008156522177159786
step: 300, loss: 0.07656572014093399
step: 310, loss: 0.009713809005916119
step: 320, loss: 0.0026514071505516768
step: 330, loss: 0.02289881557226181
step: 340, loss: 0.0008337630424648523
step: 350, loss: 0.014651520177721977
step: 360, loss: 0.031548622995615005
step: 370, loss: 0.004099556244909763
step: 380, loss: 0.0939447209239006
epoch 12: dev_f1=0.6882793017456359, f1=0.6632124352331606, best_f1=0.6876640419947506
step: 0, loss: 0.08889157325029373
step: 10, loss: 0.0008837268687784672
step: 20, loss: 0.016534171998500824
step: 30, loss: 0.03544120490550995
step: 40, loss: 0.05662592127919197
step: 50, loss: 0.06519851088523865
step: 60, loss: 0.012624766677618027
step: 70, loss: 0.027524983510375023
step: 80, loss: 0.0129392733797431
step: 90, loss: 0.07039240002632141
step: 100, loss: 0.0459459125995636
step: 110, loss: 0.0033569559454917908
step: 120, loss: 0.01992402784526348
step: 130, loss: 0.0030509689822793007
step: 140, loss: 0.035679712891578674
step: 150, loss: 0.013103153556585312
step: 160, loss: 0.0015603902284055948
step: 170, loss: 0.1544964611530304
step: 180, loss: 0.05665590986609459
step: 190, loss: 0.003956613130867481
step: 200, loss: 0.04962119832634926
step: 210, loss: 0.0031925688963383436
step: 220, loss: 0.003323608310893178
step: 230, loss: 0.009318171069025993
step: 240, loss: 0.03391730785369873
step: 250, loss: 0.02102699503302574
step: 260, loss: 0.029236389324069023
step: 270, loss: 0.018318334594368935
step: 280, loss: 0.002307767979800701
step: 290, loss: 0.023633135482668877
step: 300, loss: 0.04196403548121452
step: 310, loss: 0.021182183176279068
step: 320, loss: 0.03873896971344948
step: 330, loss: 0.035854268819093704
step: 340, loss: 0.023029882460832596
step: 350, loss: 0.03573605790734291
step: 360, loss: 0.004413603339344263
step: 370, loss: 0.040434520691633224
step: 380, loss: 0.005535876378417015
epoch 13: dev_f1=0.7146282973621103, f1=0.678132678132678, best_f1=0.6876640419947506
step: 0, loss: 0.0038714390248060226
step: 10, loss: 0.0019984100945293903
step: 20, loss: 0.0001033940352499485
step: 30, loss: 0.023867841809988022
step: 40, loss: 0.0002249478711746633
step: 50, loss: 0.0031808605417609215
step: 60, loss: 0.0061963885091245174
step: 70, loss: 0.05031777173280716
step: 80, loss: 0.0025635038036853075
step: 90, loss: 0.0025540965143591166
step: 100, loss: 0.021578015759587288
step: 110, loss: 0.06626412272453308
step: 120, loss: 0.06158638373017311
step: 130, loss: 0.0009929155930876732
step: 140, loss: 0.029710106551647186
step: 150, loss: 0.02463505044579506
step: 160, loss: 0.015538512729108334
step: 170, loss: 0.04529644921422005
step: 180, loss: 0.01764964498579502
step: 190, loss: 0.025833291932940483
step: 200, loss: 0.0024361503310501575
step: 210, loss: 0.08391149342060089
step: 220, loss: 0.009177369065582752
step: 230, loss: 0.12410276383161545
step: 240, loss: 0.14360542595386505
step: 250, loss: 0.003179033985361457
step: 260, loss: 0.02332809753715992
step: 270, loss: 0.04705803096294403
step: 280, loss: 0.06409277766942978
step: 290, loss: 0.016537629067897797
step: 300, loss: 0.01523634884506464
step: 310, loss: 0.13920126855373383
step: 320, loss: 0.020419325679540634
step: 330, loss: 0.05288399010896683
step: 340, loss: 0.0775335505604744
step: 350, loss: 0.023920446634292603
step: 360, loss: 0.0033712461590766907
step: 370, loss: 0.0008572429069317877
step: 380, loss: 0.08457564562559128
epoch 14: dev_f1=0.696078431372549, f1=0.6648793565683646, best_f1=0.6876640419947506
step: 0, loss: 0.0021467197220772505
step: 10, loss: 0.0022042356431484222
step: 20, loss: 0.0009021147852763534
step: 30, loss: 0.07045778632164001
step: 40, loss: 0.0014827954582870007
step: 50, loss: 0.00019564596004784107
step: 60, loss: 0.00013844887143932283
step: 70, loss: 0.0006148563697934151
step: 80, loss: 0.001987477531656623
step: 90, loss: 0.14549943804740906
step: 100, loss: 0.009439163841307163
step: 110, loss: 0.018573097884655
step: 120, loss: 0.001304832985624671
step: 130, loss: 0.0016868686070665717
step: 140, loss: 0.0029295531567186117
step: 150, loss: 0.059649862349033356
step: 160, loss: 0.00017899213708005846
step: 170, loss: 0.026436468586325645
step: 180, loss: 0.04218073561787605
step: 190, loss: 0.0018671205034479499
step: 200, loss: 0.003890950232744217
step: 210, loss: 0.0041121202521026134
step: 220, loss: 0.013295195065438747
step: 230, loss: 0.004984669853001833
step: 240, loss: 0.0009381360141560435
step: 250, loss: 0.01211501657962799
step: 260, loss: 7.615665526827797e-05
step: 270, loss: 0.10538265109062195
step: 280, loss: 0.08868526667356491
step: 290, loss: 0.0008705232758074999
step: 300, loss: 0.0007155031780712306
step: 310, loss: 0.00030005082953721285
step: 320, loss: 0.025468306615948677
step: 330, loss: 0.03882742300629616
step: 340, loss: 0.07224606722593307
step: 350, loss: 0.03274950012564659
step: 360, loss: 0.06949375569820404
step: 370, loss: 0.0002457914815749973
step: 380, loss: 0.01715313270688057
epoch 15: dev_f1=0.7160493827160493, f1=0.6887755102040816, best_f1=0.6876640419947506
step: 0, loss: 5.0704347813734785e-05
step: 10, loss: 0.01521345879882574
step: 20, loss: 0.03659534826874733
step: 30, loss: 0.00894114002585411
step: 40, loss: 0.02730630338191986
step: 50, loss: 0.013412121683359146
step: 60, loss: 0.02412405051290989
step: 70, loss: 0.046214740723371506
step: 80, loss: 0.03661675751209259
step: 90, loss: 0.009377130307257175
step: 100, loss: 0.015821117907762527
step: 110, loss: 0.006365074310451746
step: 120, loss: 0.00046959376777522266
step: 130, loss: 0.0019665942527353764
step: 140, loss: 0.019842956215143204
step: 150, loss: 0.011078659445047379
step: 160, loss: 0.001408801763318479
step: 170, loss: 0.06047917529940605
step: 180, loss: 0.05244012922048569
step: 190, loss: 0.0065370723605155945
step: 200, loss: 0.051838234066963196
step: 210, loss: 0.0029658128041774035
step: 220, loss: 0.014073450118303299
step: 230, loss: 0.060870930552482605
step: 240, loss: 0.025425761938095093
step: 250, loss: 0.10888537764549255
step: 260, loss: 0.01704009808599949
step: 270, loss: 0.000659577373880893
step: 280, loss: 0.07184411585330963
step: 290, loss: 0.03434381261467934
step: 300, loss: 0.0021534061525017023
step: 310, loss: 5.455879363580607e-05
step: 320, loss: 0.029658975079655647
step: 330, loss: 0.014567933045327663
step: 340, loss: 0.001215119962580502
step: 350, loss: 0.07053966820240021
step: 360, loss: 0.0015283060492947698
step: 370, loss: 0.0012098896550014615
step: 380, loss: 0.00014819749048911035
epoch 16: dev_f1=0.7196029776674937, f1=0.6910994764397905, best_f1=0.6876640419947506
step: 0, loss: 0.0003804989974014461
step: 10, loss: 0.013983702287077904
step: 20, loss: 0.00011671804531943053
step: 30, loss: 0.015886668115854263
step: 40, loss: 0.0007363815093412995
step: 50, loss: 0.0007721328875049949
step: 60, loss: 0.027923371642827988
step: 70, loss: 0.034924037754535675
step: 80, loss: 0.027660178020596504
step: 90, loss: 0.07590840011835098
step: 100, loss: 0.0003838305710814893
step: 110, loss: 0.0004897381295450032
step: 120, loss: 0.00298901810310781
step: 130, loss: 0.058868471533060074
step: 140, loss: 0.0002369241847191006
step: 150, loss: 0.008984992280602455
step: 160, loss: 0.0014456448843702674
step: 170, loss: 0.0022914367727935314
step: 180, loss: 0.0010280368151143193
step: 190, loss: 0.020168572664260864
step: 200, loss: 0.010142136365175247
step: 210, loss: 0.017285777255892754
step: 220, loss: 0.01236061379313469
step: 230, loss: 0.0001318060385528952
step: 240, loss: 8.540667477063835e-05
step: 250, loss: 0.0003891299420502037
step: 260, loss: 0.0010615914361551404
step: 270, loss: 0.029998714104294777
step: 280, loss: 0.005346602760255337
step: 290, loss: 0.07151084393262863
step: 300, loss: 0.019217893481254578
step: 310, loss: 0.027039095759391785
step: 320, loss: 0.0032348926179111004
step: 330, loss: 0.08007100969552994
step: 340, loss: 0.022108042612671852
step: 350, loss: 0.043592844158411026
step: 360, loss: 0.036758650094270706
step: 370, loss: 0.03275347873568535
step: 380, loss: 0.00047935827751643956
epoch 17: dev_f1=0.7103274559193955, f1=0.6929133858267716, best_f1=0.6876640419947506
step: 0, loss: 0.0033918311819434166
step: 10, loss: 0.0018722637323662639
step: 20, loss: 0.048719622194767
step: 30, loss: 0.0010272942017763853
step: 40, loss: 0.024132616817951202
step: 50, loss: 0.1227472648024559
step: 60, loss: 0.04848313331604004
step: 70, loss: 0.014745690859854221
step: 80, loss: 0.0006528649246320128
step: 90, loss: 0.04434521496295929
step: 100, loss: 0.00023881446395535022
step: 110, loss: 0.03208288550376892
step: 120, loss: 4.693192022386938e-05
step: 130, loss: 0.000605451816227287
step: 140, loss: 0.02752038463950157
step: 150, loss: 0.00025377728161402047
step: 160, loss: 0.04047789052128792
step: 170, loss: 0.026182997971773148
step: 180, loss: 0.010254272259771824
step: 190, loss: 0.07713354378938675
step: 200, loss: 0.00767464330419898
step: 210, loss: 0.0014826777623966336
step: 220, loss: 0.00019029252871405333
step: 230, loss: 0.02967582456767559
step: 240, loss: 3.432633457123302e-05
step: 250, loss: 0.0033625427167862654
step: 260, loss: 0.0016615603817626834
step: 270, loss: 0.0003507784567773342
step: 280, loss: 0.0021860944107174873
step: 290, loss: 8.899792010197416e-05
step: 300, loss: 0.06256669759750366
step: 310, loss: 0.00013423585915006697
step: 320, loss: 0.0017709322273731232
step: 330, loss: 0.04954517260193825
step: 340, loss: 0.0011735225562006235
step: 350, loss: 0.015667477622628212
step: 360, loss: 0.0060765487141907215
step: 370, loss: 0.0004903855733573437
step: 380, loss: 0.045070890337228775
epoch 18: dev_f1=0.7091836734693878, f1=0.6825396825396824, best_f1=0.6876640419947506
step: 0, loss: 7.50492763472721e-05
step: 10, loss: 0.00011487081064842641
step: 20, loss: 0.0014201386366039515
step: 30, loss: 0.04974019154906273
step: 40, loss: 0.0014277818845584989
step: 50, loss: 0.01734893210232258
step: 60, loss: 0.0282149575650692
step: 70, loss: 0.0008451213943772018
step: 80, loss: 0.11738379299640656
step: 90, loss: 0.03369696065783501
step: 100, loss: 0.0594017468392849
step: 110, loss: 3.526584987412207e-05
step: 120, loss: 0.013226437382400036
step: 130, loss: 0.005095007363706827
step: 140, loss: 0.0002525825402699411
step: 150, loss: 0.007221301551908255
step: 160, loss: 0.014214756898581982
step: 170, loss: 0.016250109300017357
step: 180, loss: 0.06316434592008591
step: 190, loss: 0.034971706569194794
step: 200, loss: 0.016186904162168503
step: 210, loss: 0.0695917159318924
step: 220, loss: 0.0015998778399080038
step: 230, loss: 0.01572713442146778
step: 240, loss: 0.034243591129779816
step: 250, loss: 0.00044552108738571405
step: 260, loss: 0.045215267688035965
step: 270, loss: 0.05775498226284981
step: 280, loss: 0.018533382564783096
step: 290, loss: 0.047850366681814194
step: 300, loss: 0.007278000935912132
step: 310, loss: 0.014573589898645878
step: 320, loss: 0.0018695419421419501
step: 330, loss: 5.7592820667196065e-05
step: 340, loss: 0.011852010153234005
step: 350, loss: 0.0009422929142601788
step: 360, loss: 4.9050806410377845e-05
step: 370, loss: 0.00010287297482136637
step: 380, loss: 7.856987213017419e-05
epoch 19: dev_f1=0.7093596059113301, f1=0.6871794871794872, best_f1=0.6876640419947506
step: 0, loss: 0.0003699983935803175
step: 10, loss: 9.17066281544976e-05
step: 20, loss: 0.04517000541090965
step: 30, loss: 0.0874851644039154
step: 40, loss: 0.0005104459705762565
step: 50, loss: 0.005232238210737705
step: 60, loss: 0.07156575471162796
step: 70, loss: 0.00016299115668516606
step: 80, loss: 0.0060684881173074245
step: 90, loss: 0.012819603085517883
step: 100, loss: 0.0007445521769113839
step: 110, loss: 0.0015989035600796342
step: 120, loss: 0.008760660886764526
step: 130, loss: 0.00031909593963064253
step: 140, loss: 0.024067098274827003
step: 150, loss: 0.028281785547733307
step: 160, loss: 0.008376025594770908
step: 170, loss: 4.502728188526817e-05
step: 180, loss: 0.0021224194206297398
step: 190, loss: 0.019900090992450714
step: 200, loss: 2.7186395527678542e-05
step: 210, loss: 0.010818129405379295
step: 220, loss: 0.05882497876882553
step: 230, loss: 0.0011759964982047677
step: 240, loss: 0.019104087725281715
step: 250, loss: 0.013700229115784168
step: 260, loss: 0.00043269514571875334
step: 270, loss: 0.021621178835630417
step: 280, loss: 0.005746820475906134
step: 290, loss: 0.00033940013963729143
step: 300, loss: 0.0006234091706573963
step: 310, loss: 0.0413634292781353
step: 320, loss: 0.06549211591482162
step: 330, loss: 0.002027540933340788
step: 340, loss: 0.04168425127863884
step: 350, loss: 7.824923523003235e-05
step: 360, loss: 0.003121099201962352
step: 370, loss: 0.0015725605189800262
step: 380, loss: 8.56750993989408e-05
epoch 20: dev_f1=0.7146401985111663, f1=0.6770833333333335, best_f1=0.6876640419947506
