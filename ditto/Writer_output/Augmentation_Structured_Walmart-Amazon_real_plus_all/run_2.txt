cuda
Device: cuda
step: 0, loss: 0.5617485046386719
step: 10, loss: 0.3229568302631378
step: 20, loss: 0.15030434727668762
step: 30, loss: 0.18643537163734436
step: 40, loss: 0.24340960383415222
step: 50, loss: 0.23189879953861237
step: 60, loss: 0.31116625666618347
step: 70, loss: 0.46601420640945435
step: 80, loss: 0.1025153398513794
step: 90, loss: 0.2320958822965622
step: 100, loss: 0.2116779088973999
step: 110, loss: 0.08909580856561661
step: 120, loss: 0.4913603961467743
step: 130, loss: 0.3232124149799347
step: 140, loss: 0.35539981722831726
step: 150, loss: 0.2638022303581238
step: 160, loss: 0.2720550000667572
step: 170, loss: 0.24018336832523346
step: 180, loss: 0.4249821603298187
step: 190, loss: 0.30036264657974243
step: 200, loss: 0.1846110075712204
step: 210, loss: 0.20090317726135254
step: 220, loss: 0.23382668197155
step: 230, loss: 0.1677219271659851
step: 240, loss: 0.04948245361447334
step: 250, loss: 0.2519383132457733
step: 260, loss: 0.2543843686580658
step: 270, loss: 0.08487771451473236
step: 280, loss: 0.12504126131534576
step: 290, loss: 0.38534706830978394
step: 300, loss: 0.06876283884048462
step: 310, loss: 0.29457589983940125
step: 320, loss: 0.3461163640022278
step: 330, loss: 0.3653460741043091
step: 340, loss: 0.06125466153025627
step: 350, loss: 0.12050767987966537
step: 360, loss: 0.13892169296741486
step: 370, loss: 0.12673768401145935
step: 380, loss: 0.11247085779905319
epoch 1: dev_f1=0.5237020316027088, f1=0.5506607929515418, best_f1=0.5506607929515418
step: 0, loss: 0.028321582823991776
step: 10, loss: 0.06978048384189606
step: 20, loss: 0.0282774455845356
step: 30, loss: 0.12815535068511963
step: 40, loss: 0.15247173607349396
step: 50, loss: 0.14349885284900665
step: 60, loss: 0.07972649484872818
step: 70, loss: 0.1137443259358406
step: 80, loss: 0.01678098365664482
step: 90, loss: 0.006989154499024153
step: 100, loss: 0.13784761726856232
step: 110, loss: 0.019518377259373665
step: 120, loss: 0.12274385243654251
step: 130, loss: 0.28048259019851685
step: 140, loss: 0.13530835509300232
step: 150, loss: 0.08403640985488892
step: 160, loss: 0.32470107078552246
step: 170, loss: 0.01797233708202839
step: 180, loss: 0.19064752757549286
step: 190, loss: 0.10690870881080627
step: 200, loss: 0.12971694767475128
step: 210, loss: 0.252566933631897
step: 220, loss: 0.16852638125419617
step: 230, loss: 0.1270969957113266
step: 240, loss: 0.1468392312526703
step: 250, loss: 0.07473720610141754
step: 260, loss: 0.2260257750749588
step: 270, loss: 0.13272441923618317
step: 280, loss: 0.004377444740384817
step: 290, loss: 0.2015211135149002
step: 300, loss: 0.0700363889336586
step: 310, loss: 0.12796929478645325
step: 320, loss: 0.16614645719528198
step: 330, loss: 0.16949254274368286
step: 340, loss: 0.11692381650209427
step: 350, loss: 0.15102694928646088
step: 360, loss: 0.11620195209980011
step: 370, loss: 0.3293301463127136
step: 380, loss: 0.06679098308086395
epoch 2: dev_f1=0.5659472422062349, f1=0.582089552238806, best_f1=0.582089552238806
step: 0, loss: 0.08017448335886002
step: 10, loss: 0.11626152694225311
step: 20, loss: 0.07006356120109558
step: 30, loss: 0.03209097310900688
step: 40, loss: 0.06798457354307175
step: 50, loss: 0.08440772444009781
step: 60, loss: 0.13985125720500946
step: 70, loss: 0.11597686260938644
step: 80, loss: 0.08368118107318878
step: 90, loss: 0.03617040067911148
step: 100, loss: 0.04922841116786003
step: 110, loss: 0.08303055167198181
step: 120, loss: 0.027182670310139656
step: 130, loss: 0.2089594155550003
step: 140, loss: 0.07162456214427948
step: 150, loss: 0.11311382800340652
step: 160, loss: 0.0627846047282219
step: 170, loss: 0.05310951545834541
step: 180, loss: 0.15930311381816864
step: 190, loss: 0.0904068574309349
step: 200, loss: 0.05626840144395828
step: 210, loss: 0.19633668661117554
step: 220, loss: 0.02638242579996586
step: 230, loss: 0.17594820261001587
step: 240, loss: 0.06749482452869415
step: 250, loss: 0.08681850880384445
step: 260, loss: 0.09563053399324417
step: 270, loss: 0.09020723402500153
step: 280, loss: 0.24906007945537567
step: 290, loss: 0.09044333547353745
step: 300, loss: 0.01820543222129345
step: 310, loss: 0.05870477482676506
step: 320, loss: 0.2878766655921936
step: 330, loss: 0.1684839129447937
step: 340, loss: 0.13011534512043
step: 350, loss: 0.20714350044727325
step: 360, loss: 0.09984194487333298
step: 370, loss: 0.03440510481595993
step: 380, loss: 0.0525469034910202
epoch 3: dev_f1=0.6681614349775785, f1=0.6769911504424779, best_f1=0.6769911504424779
step: 0, loss: 0.04587733745574951
step: 10, loss: 0.0065276892855763435
step: 20, loss: 0.018548093736171722
step: 30, loss: 0.11322885751724243
step: 40, loss: 0.006922758650034666
step: 50, loss: 0.07938183099031448
step: 60, loss: 0.11819068342447281
step: 70, loss: 0.04107724875211716
step: 80, loss: 0.04576542228460312
step: 90, loss: 0.20641109347343445
step: 100, loss: 0.028615858405828476
step: 110, loss: 0.13935907185077667
step: 120, loss: 0.08294205367565155
step: 130, loss: 0.010354334488511086
step: 140, loss: 0.1551673710346222
step: 150, loss: 0.03635206073522568
step: 160, loss: 0.13025085628032684
step: 170, loss: 0.017324117943644524
step: 180, loss: 0.022654129192233086
step: 190, loss: 0.07128023356199265
step: 200, loss: 0.12332546710968018
step: 210, loss: 0.07422299683094025
step: 220, loss: 0.042406369000673294
step: 230, loss: 0.07708485424518585
step: 240, loss: 0.12575674057006836
step: 250, loss: 0.1212419718503952
step: 260, loss: 0.029373258352279663
step: 270, loss: 0.025237496942281723
step: 280, loss: 0.04409148544073105
step: 290, loss: 0.027997145429253578
step: 300, loss: 0.05644357204437256
step: 310, loss: 0.10605311393737793
step: 320, loss: 0.05661281198263168
step: 330, loss: 0.10547526925802231
step: 340, loss: 0.19287987053394318
step: 350, loss: 0.04423125088214874
step: 360, loss: 0.09662839025259018
step: 370, loss: 0.002550083678215742
step: 380, loss: 0.0543128065764904
epoch 4: dev_f1=0.6567901234567901, f1=0.7020202020202021, best_f1=0.6769911504424779
step: 0, loss: 0.11468423902988434
step: 10, loss: 0.04359104111790657
step: 20, loss: 0.006692458875477314
step: 30, loss: 0.12200649827718735
step: 40, loss: 0.10157344490289688
step: 50, loss: 0.026490159332752228
step: 60, loss: 0.02323116734623909
step: 70, loss: 0.06296726316213608
step: 80, loss: 0.058654870837926865
step: 90, loss: 0.09210952371358871
step: 100, loss: 0.049877338111400604
step: 110, loss: 0.09847812354564667
step: 120, loss: 0.01133710891008377
step: 130, loss: 0.10257385671138763
step: 140, loss: 0.026019170880317688
step: 150, loss: 0.020622901618480682
step: 160, loss: 0.03178231418132782
step: 170, loss: 0.14023743569850922
step: 180, loss: 0.05828753113746643
step: 190, loss: 0.15395332872867584
step: 200, loss: 0.07248491048812866
step: 210, loss: 0.04734276235103607
step: 220, loss: 0.1076660305261612
step: 230, loss: 0.02122897282242775
step: 240, loss: 0.0886966735124588
step: 250, loss: 0.12685780227184296
step: 260, loss: 0.11971411108970642
step: 270, loss: 0.12432494759559631
step: 280, loss: 0.025081463158130646
step: 290, loss: 0.05598292499780655
step: 300, loss: 0.1315261423587799
step: 310, loss: 0.06888006627559662
step: 320, loss: 0.032045260071754456
step: 330, loss: 0.0435904823243618
step: 340, loss: 0.01934819482266903
step: 350, loss: 0.028031913563609123
step: 360, loss: 0.10627373307943344
step: 370, loss: 0.02792695350944996
step: 380, loss: 0.10270639508962631
epoch 5: dev_f1=0.6388888888888888, f1=0.6682027649769585, best_f1=0.6769911504424779
step: 0, loss: 0.001616156892850995
step: 10, loss: 0.03264937922358513
step: 20, loss: 0.04736553505063057
step: 30, loss: 0.036360964179039
step: 40, loss: 0.012729346752166748
step: 50, loss: 0.01307482086122036
step: 60, loss: 0.03469813987612724
step: 70, loss: 0.014972863718867302
step: 80, loss: 0.08619055151939392
step: 90, loss: 0.020441683009266853
step: 100, loss: 0.4539129436016083
step: 110, loss: 0.07702106982469559
step: 120, loss: 0.021457018330693245
step: 130, loss: 0.1540835201740265
step: 140, loss: 0.0230284184217453
step: 150, loss: 0.0955047607421875
step: 160, loss: 0.08102241903543472
step: 170, loss: 0.014472059905529022
step: 180, loss: 0.0023586128372699022
step: 190, loss: 0.07155284285545349
step: 200, loss: 0.11109818518161774
step: 210, loss: 0.026608292013406754
step: 220, loss: 0.16095207631587982
step: 230, loss: 0.01944074034690857
step: 240, loss: 0.18968796730041504
step: 250, loss: 0.04050617292523384
step: 260, loss: 0.07951173931360245
step: 270, loss: 0.0583188459277153
step: 280, loss: 0.07247772067785263
step: 290, loss: 0.07423070818185806
step: 300, loss: 0.03414168953895569
step: 310, loss: 0.030384045094251633
step: 320, loss: 0.1433529406785965
step: 330, loss: 0.1734572798013687
step: 340, loss: 0.13758088648319244
step: 350, loss: 0.02764716185629368
step: 360, loss: 0.02561871148645878
step: 370, loss: 0.05465994402766228
step: 380, loss: 0.0030383202247321606
epoch 6: dev_f1=0.6574074074074074, f1=0.6904761904761906, best_f1=0.6769911504424779
step: 0, loss: 0.06968623399734497
step: 10, loss: 0.09036185592412949
step: 20, loss: 0.09308305382728577
step: 30, loss: 0.1233118325471878
step: 40, loss: 0.1310373693704605
step: 50, loss: 0.07245830446481705
step: 60, loss: 0.00952863972634077
step: 70, loss: 0.05476326122879982
step: 80, loss: 0.012766119092702866
step: 90, loss: 0.010907352901995182
step: 100, loss: 0.03931755945086479
step: 110, loss: 0.12489297240972519
step: 120, loss: 0.04551802948117256
step: 130, loss: 0.09849698096513748
step: 140, loss: 0.0410776361823082
step: 150, loss: 0.057729050517082214
step: 160, loss: 0.03645237535238266
step: 170, loss: 0.02293875627219677
step: 180, loss: 0.10564646869897842
step: 190, loss: 0.04099949449300766
step: 200, loss: 0.04058205336332321
step: 210, loss: 0.0928216427564621
step: 220, loss: 0.025004196912050247
step: 230, loss: 0.011059118434786797
step: 240, loss: 0.0004876980965491384
step: 250, loss: 0.009975912980735302
step: 260, loss: 0.05902630463242531
step: 270, loss: 0.05648372322320938
step: 280, loss: 0.02517390064895153
step: 290, loss: 0.15630488097667694
step: 300, loss: 0.025647083297371864
step: 310, loss: 0.1284817010164261
step: 320, loss: 0.10235641896724701
step: 330, loss: 0.0456022210419178
step: 340, loss: 0.0012592951534315944
step: 350, loss: 0.03879348933696747
step: 360, loss: 0.005803922191262245
step: 370, loss: 0.01609029248356819
step: 380, loss: 0.020090488716959953
epoch 7: dev_f1=0.6784810126582279, f1=0.7210526315789473, best_f1=0.7210526315789473
step: 0, loss: 0.023862801492214203
step: 10, loss: 0.0679820254445076
step: 20, loss: 0.00666389474645257
step: 30, loss: 0.025696858763694763
step: 40, loss: 0.016533998772501945
step: 50, loss: 0.05412548407912254
step: 60, loss: 0.041820891201496124
step: 70, loss: 0.022900952026247978
step: 80, loss: 0.007708309683948755
step: 90, loss: 0.024406181648373604
step: 100, loss: 0.0010240759002044797
step: 110, loss: 0.023099437355995178
step: 120, loss: 0.033040259033441544
step: 130, loss: 0.04711802676320076
step: 140, loss: 0.0642232820391655
step: 150, loss: 0.0004941822262480855
step: 160, loss: 0.0615713931620121
step: 170, loss: 0.006600477732717991
step: 180, loss: 0.1517086625099182
step: 190, loss: 0.054913561791181564
step: 200, loss: 0.04546906426548958
step: 210, loss: 0.06102553382515907
step: 220, loss: 0.05989488959312439
step: 230, loss: 0.017035014927387238
step: 240, loss: 0.0719994381070137
step: 250, loss: 0.0655796080827713
step: 260, loss: 0.260148823261261
step: 270, loss: 0.05165734142065048
step: 280, loss: 0.00021628393733408302
step: 290, loss: 0.00011726694356184453
step: 300, loss: 0.03230174258351326
step: 310, loss: 0.07070627808570862
step: 320, loss: 0.027910903096199036
step: 330, loss: 0.025629142299294472
step: 340, loss: 0.036628831177949905
step: 350, loss: 0.02883979305624962
step: 360, loss: 0.08881153911352158
step: 370, loss: 0.003014232264831662
step: 380, loss: 0.044164396822452545
epoch 8: dev_f1=0.6762589928057554, f1=0.7000000000000001, best_f1=0.7210526315789473
step: 0, loss: 0.02734762616455555
step: 10, loss: 0.014279557392001152
step: 20, loss: 0.022966157644987106
step: 30, loss: 0.02203747071325779
step: 40, loss: 0.05478702485561371
step: 50, loss: 0.022608710452914238
step: 60, loss: 0.03662446513772011
step: 70, loss: 0.03784432262182236
step: 80, loss: 0.030754484236240387
step: 90, loss: 0.03420275077223778
step: 100, loss: 0.07104881852865219
step: 110, loss: 0.028381435200572014
step: 120, loss: 0.049079008400440216
step: 130, loss: 0.059492889791727066
step: 140, loss: 0.058756228536367416
step: 150, loss: 0.03527991473674774
step: 160, loss: 0.016896933317184448
step: 170, loss: 0.057782456278800964
step: 180, loss: 0.024099793285131454
step: 190, loss: 0.00023454402980860323
step: 200, loss: 0.0004158251394983381
step: 210, loss: 0.0021956274285912514
step: 220, loss: 0.009851665236055851
step: 230, loss: 0.040581535547971725
step: 240, loss: 0.027244290336966515
step: 250, loss: 0.12976719439029694
step: 260, loss: 0.053644854575395584
step: 270, loss: 0.1089150607585907
step: 280, loss: 0.06317754089832306
step: 290, loss: 0.033394571393728256
step: 300, loss: 0.025413861498236656
step: 310, loss: 0.028927594423294067
step: 320, loss: 0.0005321907228790224
step: 330, loss: 0.0014102647546678782
step: 340, loss: 0.013180840760469437
step: 350, loss: 0.023815488442778587
step: 360, loss: 0.02337096445262432
step: 370, loss: 0.19263477623462677
step: 380, loss: 0.07158221304416656
epoch 9: dev_f1=0.6778042959427207, f1=0.6778846153846154, best_f1=0.7210526315789473
step: 0, loss: 0.03241458535194397
step: 10, loss: 0.19389395415782928
step: 20, loss: 0.05570302531123161
step: 30, loss: 0.11096508055925369
step: 40, loss: 0.07272657006978989
step: 50, loss: 0.014028022065758705
step: 60, loss: 0.0002554576494731009
step: 70, loss: 0.06762000918388367
step: 80, loss: 0.030451085418462753
step: 90, loss: 0.04164019599556923
step: 100, loss: 0.016780873760581017
step: 110, loss: 0.00015210600395221263
step: 120, loss: 0.03631678596138954
step: 130, loss: 0.02305108867585659
step: 140, loss: 0.04834352433681488
step: 150, loss: 0.06141069903969765
step: 160, loss: 0.032381508499383926
step: 170, loss: 0.06529651582241058
step: 180, loss: 0.1328752189874649
step: 190, loss: 0.0003698988875839859
step: 200, loss: 0.05438118800520897
step: 210, loss: 0.04814588651061058
step: 220, loss: 0.029987335205078125
step: 230, loss: 0.07641876488924026
step: 240, loss: 0.03004325181245804
step: 250, loss: 0.07796976715326309
step: 260, loss: 0.07718660682439804
step: 270, loss: 0.05739523470401764
step: 280, loss: 0.10224184393882751
step: 290, loss: 0.08136831969022751
step: 300, loss: 0.004906618036329746
step: 310, loss: 0.017529314383864403
step: 320, loss: 0.007844342850148678
step: 330, loss: 0.025125905871391296
step: 340, loss: 0.04092343896627426
step: 350, loss: 0.029709592461586
step: 360, loss: 0.03305844962596893
step: 370, loss: 0.028520064428448677
step: 380, loss: 0.004289311822503805
epoch 10: dev_f1=0.6990291262135921, f1=0.7050000000000001, best_f1=0.7050000000000001
step: 0, loss: 0.08812031149864197
step: 10, loss: 0.016447538509964943
step: 20, loss: 0.03500170260667801
step: 30, loss: 0.05639629438519478
step: 40, loss: 0.050498757511377335
step: 50, loss: 0.010556952096521854
step: 60, loss: 0.05359281972050667
step: 70, loss: 0.0460977777838707
step: 80, loss: 0.0001562378165544942
step: 90, loss: 0.0417337566614151
step: 100, loss: 0.015447701327502728
step: 110, loss: 0.12166331708431244
step: 120, loss: 0.018910856917500496
step: 130, loss: 0.0011237242724746466
step: 140, loss: 0.043353017419576645
step: 150, loss: 0.020358217880129814
step: 160, loss: 0.03240693733096123
step: 170, loss: 0.014850342646241188
step: 180, loss: 0.09441645443439484
step: 190, loss: 0.04539114981889725
step: 200, loss: 0.11001736670732498
step: 210, loss: 0.008652634918689728
step: 220, loss: 0.10272087156772614
step: 230, loss: 0.10620003938674927
step: 240, loss: 0.0006359888939186931
step: 250, loss: 0.06049073860049248
step: 260, loss: 0.032254915684461594
step: 270, loss: 0.02228444442152977
step: 280, loss: 0.025060320273041725
step: 290, loss: 0.0012121809413656592
step: 300, loss: 0.01467737928032875
step: 310, loss: 0.03199456259608269
step: 320, loss: 0.05081140622496605
step: 330, loss: 0.003273525508120656
step: 340, loss: 0.06129923090338707
step: 350, loss: 0.019766949117183685
step: 360, loss: 0.10056620836257935
step: 370, loss: 0.007355147507041693
step: 380, loss: 0.03789903223514557
epoch 11: dev_f1=0.7044917257683215, f1=0.7033492822966507, best_f1=0.7033492822966507
step: 0, loss: 0.0022887508384883404
step: 10, loss: 0.05386870354413986
step: 20, loss: 0.004794350825250149
step: 30, loss: 0.03236517310142517
step: 40, loss: 0.025296377018094063
step: 50, loss: 0.06576957553625107
step: 60, loss: 0.0045831212773919106
step: 70, loss: 0.004677919205278158
step: 80, loss: 0.015232032164931297
step: 90, loss: 0.021692322567105293
step: 100, loss: 0.011438293382525444
step: 110, loss: 0.06293635815382004
step: 120, loss: 0.0006790072657167912
step: 130, loss: 0.07139009982347488
step: 140, loss: 0.016708143055438995
step: 150, loss: 0.02212156355381012
step: 160, loss: 0.04860710725188255
step: 170, loss: 0.02780763804912567
step: 180, loss: 0.04943722113966942
step: 190, loss: 0.06372945755720139
step: 200, loss: 0.007539080921560526
step: 210, loss: 0.006523603107780218
step: 220, loss: 0.007127237040549517
step: 230, loss: 0.04726576432585716
step: 240, loss: 0.047466788440942764
step: 250, loss: 0.03142288699746132
step: 260, loss: 0.02117365598678589
step: 270, loss: 0.043250493705272675
step: 280, loss: 0.017906833440065384
step: 290, loss: 0.024169091135263443
step: 300, loss: 0.0768192932009697
step: 310, loss: 0.0009430706268176436
step: 320, loss: 0.05492618307471275
step: 330, loss: 0.01493215374648571
step: 340, loss: 0.0029126466251909733
step: 350, loss: 0.008227668702602386
step: 360, loss: 0.011774500831961632
step: 370, loss: 0.05274288356304169
step: 380, loss: 0.033243224024772644
epoch 12: dev_f1=0.7093596059113301, f1=0.7118644067796611, best_f1=0.7118644067796611
step: 0, loss: 0.01944253034889698
step: 10, loss: 0.02198454737663269
step: 20, loss: 0.025561224669218063
step: 30, loss: 0.00012182113277958706
step: 40, loss: 0.0007622623816132545
step: 50, loss: 0.0002114958333550021
step: 60, loss: 0.09857935458421707
step: 70, loss: 0.016882559284567833
step: 80, loss: 0.011447745375335217
step: 90, loss: 0.05335249751806259
step: 100, loss: 0.04369731619954109
step: 110, loss: 0.001173957483842969
step: 120, loss: 0.04744282737374306
step: 130, loss: 0.0008560931892134249
step: 140, loss: 0.04856625199317932
step: 150, loss: 0.012051126919686794
step: 160, loss: 0.039337195456027985
step: 170, loss: 0.0011369198327884078
step: 180, loss: 0.008016708306968212
step: 190, loss: 0.00020340029732324183
step: 200, loss: 0.00019124773098155856
step: 210, loss: 0.05617491528391838
step: 220, loss: 0.0011181429727002978
step: 230, loss: 0.023764904588460922
step: 240, loss: 0.0012409614864736795
step: 250, loss: 0.03090270794928074
step: 260, loss: 0.0027640080079436302
step: 270, loss: 0.025942865759134293
step: 280, loss: 0.0052466788329184055
step: 290, loss: 0.04987676814198494
step: 300, loss: 0.04975712671875954
step: 310, loss: 0.009894788265228271
step: 320, loss: 0.020470140501856804
step: 330, loss: 0.009224487468600273
step: 340, loss: 0.07320593297481537
step: 350, loss: 0.015665166079998016
step: 360, loss: 0.01592019759118557
step: 370, loss: 0.0006178232724778354
step: 380, loss: 0.002823413582518697
epoch 13: dev_f1=0.6894977168949772, f1=0.6879271070615034, best_f1=0.7118644067796611
step: 0, loss: 0.003272758098319173
step: 10, loss: 0.017339255660772324
step: 20, loss: 0.016697421669960022
step: 30, loss: 0.006052494514733553
step: 40, loss: 0.06243263930082321
step: 50, loss: 0.0017875890480354428
step: 60, loss: 0.018025215715169907
step: 70, loss: 0.06906074285507202
step: 80, loss: 0.0025202687829732895
step: 90, loss: 4.8311547288903967e-05
step: 100, loss: 0.00029816143796779215
step: 110, loss: 0.011092152446508408
step: 120, loss: 0.00010813048720592633
step: 130, loss: 0.033319707959890366
step: 140, loss: 0.0023458926007151604
step: 150, loss: 0.02424539253115654
step: 160, loss: 0.029786448925733566
step: 170, loss: 0.027001284062862396
step: 180, loss: 0.025481844320893288
step: 190, loss: 0.018790576606988907
step: 200, loss: 0.0008807147387415171
step: 210, loss: 0.018406426534056664
step: 220, loss: 0.029512669891119003
step: 230, loss: 0.004073658026754856
step: 240, loss: 0.02167665958404541
step: 250, loss: 0.11268177628517151
step: 260, loss: 0.018414122983813286
step: 270, loss: 0.022131826728582382
step: 280, loss: 0.0018192455172538757
step: 290, loss: 0.00037666017306037247
step: 300, loss: 0.03530404716730118
step: 310, loss: 0.12503644824028015
step: 320, loss: 0.006837532855570316
step: 330, loss: 0.00043474798440001905
step: 340, loss: 0.006441319361329079
step: 350, loss: 0.0007406779332086444
step: 360, loss: 0.035468511283397675
step: 370, loss: 0.03151467815041542
step: 380, loss: 0.014663786627352238
epoch 14: dev_f1=0.6962616822429907, f1=0.7058823529411765, best_f1=0.7118644067796611
step: 0, loss: 0.0215240977704525
step: 10, loss: 0.001077989349141717
step: 20, loss: 0.02311360277235508
step: 30, loss: 0.03501050919294357
step: 40, loss: 0.00040160727803595364
step: 50, loss: 0.010607236996293068
step: 60, loss: 0.038182877004146576
step: 70, loss: 0.03347315266728401
step: 80, loss: 0.05228289216756821
step: 90, loss: 0.03413960337638855
step: 100, loss: 0.08638190478086472
step: 110, loss: 0.0013184662675485015
step: 120, loss: 0.0009266278357245028
step: 130, loss: 0.00020444541587494314
step: 140, loss: 0.060776546597480774
step: 150, loss: 0.0010946702677756548
step: 160, loss: 0.03725796937942505
step: 170, loss: 0.033580224961042404
step: 180, loss: 0.1362195611000061
step: 190, loss: 0.0002280056505696848
step: 200, loss: 0.006768799386918545
step: 210, loss: 9.484680776949972e-05
step: 220, loss: 0.10941051691770554
step: 230, loss: 0.021274223923683167
step: 240, loss: 0.00011850012378999963
step: 250, loss: 0.020727936178445816
step: 260, loss: 0.009969393722712994
step: 270, loss: 0.0038366205990314484
step: 280, loss: 0.04332736134529114
step: 290, loss: 0.040403272956609726
step: 300, loss: 0.04124828428030014
step: 310, loss: 0.022038552910089493
step: 320, loss: 0.0008190074004232883
step: 330, loss: 0.06709980964660645
step: 340, loss: 0.0021730277221649885
step: 350, loss: 0.0033495735842734575
step: 360, loss: 0.03849618136882782
step: 370, loss: 0.014192579314112663
step: 380, loss: 0.07663406431674957
epoch 15: dev_f1=0.7161803713527852, f1=0.7253333333333334, best_f1=0.7253333333333334
step: 0, loss: 0.009191050194203854
step: 10, loss: 0.0011445791460573673
step: 20, loss: 0.00017813641170505434
step: 30, loss: 0.09478648006916046
step: 40, loss: 0.031184975057840347
step: 50, loss: 0.019993199035525322
step: 60, loss: 0.0018455019453540444
step: 70, loss: 0.03247977793216705
step: 80, loss: 0.0003198619233444333
step: 90, loss: 0.02620169334113598
step: 100, loss: 0.00011749484110623598
step: 110, loss: 0.002216676715761423
step: 120, loss: 0.00019231444457545877
step: 130, loss: 0.0017497434746474028
step: 140, loss: 0.019092682749032974
step: 150, loss: 0.037686966359615326
step: 160, loss: 7.691662904107943e-05
step: 170, loss: 0.029268203303217888
step: 180, loss: 0.0004018234321847558
step: 190, loss: 0.010416911914944649
step: 200, loss: 0.08692190796136856
step: 210, loss: 0.003914958797395229
step: 220, loss: 0.027760300785303116
step: 230, loss: 0.08616046607494354
step: 240, loss: 0.017014598473906517
step: 250, loss: 0.010005395859479904
step: 260, loss: 0.01260698027908802
step: 270, loss: 0.017861828207969666
step: 280, loss: 0.04452992230653763
step: 290, loss: 0.0005063794669695199
step: 300, loss: 6.446969928219914e-05
step: 310, loss: 0.03351662680506706
step: 320, loss: 0.021253805607557297
step: 330, loss: 0.0007491810247302055
step: 340, loss: 0.008424250409007072
step: 350, loss: 0.019148733466863632
step: 360, loss: 0.005569017957895994
step: 370, loss: 0.006352728698402643
step: 380, loss: 0.031752604991197586
epoch 16: dev_f1=0.7010309278350515, f1=0.7139107611548556, best_f1=0.7253333333333334
step: 0, loss: 0.002749516163021326
step: 10, loss: 0.00019893879652954638
step: 20, loss: 0.0404764823615551
step: 30, loss: 0.00018492071831133217
step: 40, loss: 0.008869104087352753
step: 50, loss: 9.796205995371565e-05
step: 60, loss: 0.011693031527101994
step: 70, loss: 0.004794089589267969
step: 80, loss: 0.009526320733129978
step: 90, loss: 0.0008445673156529665
step: 100, loss: 0.012598971836268902
step: 110, loss: 0.02901952527463436
step: 120, loss: 0.06959692388772964
step: 130, loss: 0.003652306506410241
step: 140, loss: 0.00033822949626483023
step: 150, loss: 0.00023057278303895146
step: 160, loss: 0.0001746978232404217
step: 170, loss: 0.05037270113825798
step: 180, loss: 0.009811368770897388
step: 190, loss: 0.00111003324855119
step: 200, loss: 0.010788981802761555
step: 210, loss: 0.0024245933163911104
step: 220, loss: 0.027451837435364723
step: 230, loss: 0.022196123376488686
step: 240, loss: 4.541261660051532e-05
step: 250, loss: 0.10071379691362381
step: 260, loss: 4.586272552842274e-05
step: 270, loss: 0.005909712053835392
step: 280, loss: 0.0003039143339265138
step: 290, loss: 0.04284164309501648
step: 300, loss: 0.02071903645992279
step: 310, loss: 0.00010022964124800637
step: 320, loss: 0.039108917117118835
step: 330, loss: 0.04348767176270485
step: 340, loss: 0.0671229138970375
step: 350, loss: 0.010398048907518387
step: 360, loss: 0.004865576047450304
step: 370, loss: 0.0004350773524492979
step: 380, loss: 0.02564612776041031
epoch 17: dev_f1=0.7201946472019465, f1=0.7114427860696517, best_f1=0.7114427860696517
step: 0, loss: 0.011929572559893131
step: 10, loss: 0.022048253566026688
step: 20, loss: 0.0027731494046747684
step: 30, loss: 0.03194810822606087
step: 40, loss: 0.07778681814670563
step: 50, loss: 0.016026904806494713
step: 60, loss: 0.00022895983420312405
step: 70, loss: 0.02540997974574566
step: 80, loss: 0.00040362641448155046
step: 90, loss: 0.010648075491189957
step: 100, loss: 0.03871797397732735
step: 110, loss: 0.021516799926757812
step: 120, loss: 0.006065155379474163
step: 130, loss: 3.3902048016898334e-05
step: 140, loss: 0.014073223806917667
step: 150, loss: 0.03678162023425102
step: 160, loss: 0.0008103102445602417
step: 170, loss: 0.04868283122777939
step: 180, loss: 0.10313686728477478
step: 190, loss: 6.961088365642354e-05
step: 200, loss: 0.0001251191715709865
step: 210, loss: 5.864430931978859e-05
step: 220, loss: 0.0006734671769663692
step: 230, loss: 0.022037098184227943
step: 240, loss: 0.012739420868456364
step: 250, loss: 0.00029508143779821694
step: 260, loss: 2.631476309034042e-05
step: 270, loss: 0.031482234597206116
step: 280, loss: 0.0583728589117527
step: 290, loss: 0.025084011256694794
step: 300, loss: 0.0017052689800038934
step: 310, loss: 0.00018456581165082753
step: 320, loss: 8.807678386801854e-05
step: 330, loss: 0.0012445528991520405
step: 340, loss: 0.01695987582206726
step: 350, loss: 0.030933814123272896
step: 360, loss: 0.03335097059607506
step: 370, loss: 0.058367662131786346
step: 380, loss: 0.009331302717328072
epoch 18: dev_f1=0.7281553398058251, f1=0.7082294264339153, best_f1=0.7082294264339153
step: 0, loss: 9.321799734607339e-05
step: 10, loss: 5.9854948631254956e-05
step: 20, loss: 0.0009648160776123405
step: 30, loss: 0.0008487125160172582
step: 40, loss: 0.00507528567686677
step: 50, loss: 0.0004415006551425904
step: 60, loss: 2.8784383175661787e-05
step: 70, loss: 0.0787644013762474
step: 80, loss: 0.004667690023779869
step: 90, loss: 5.867010622750968e-05
step: 100, loss: 0.03710877150297165
step: 110, loss: 0.00043332268251106143
step: 120, loss: 0.020169924944639206
step: 130, loss: 0.03297029435634613
step: 140, loss: 0.018187392503023148
step: 150, loss: 0.03778788447380066
step: 160, loss: 0.027639828622341156
step: 170, loss: 0.04951006546616554
step: 180, loss: 0.00017494765052106231
step: 190, loss: 0.019665613770484924
step: 200, loss: 0.004724637605249882
step: 210, loss: 0.00033611434628255665
step: 220, loss: 0.033402491360902786
step: 230, loss: 0.0004012671997770667
step: 240, loss: 0.0324205681681633
step: 250, loss: 0.0074846213683485985
step: 260, loss: 0.06429361552000046
step: 270, loss: 0.046465229243040085
step: 280, loss: 0.014615497551858425
step: 290, loss: 0.023571405559778214
step: 300, loss: 0.02719121053814888
step: 310, loss: 0.028094688430428505
step: 320, loss: 0.0004460690834093839
step: 330, loss: 0.0016493377042934299
step: 340, loss: 0.018557744100689888
step: 350, loss: 0.011124477721750736
step: 360, loss: 0.05064576119184494
step: 370, loss: 0.0007297669071704149
step: 380, loss: 0.011458651162683964
epoch 19: dev_f1=0.7083333333333333, f1=0.7074468085106383, best_f1=0.7082294264339153
step: 0, loss: 0.00026086060097441077
step: 10, loss: 2.7405689252191223e-05
step: 20, loss: 0.000819483888335526
step: 30, loss: 0.021280767396092415
step: 40, loss: 0.034940969198942184
step: 50, loss: 0.008937210775911808
step: 60, loss: 0.022986024618148804
step: 70, loss: 5.0261478463653475e-05
step: 80, loss: 0.02444673515856266
step: 90, loss: 0.01238758210092783
step: 100, loss: 0.00010061589273391291
step: 110, loss: 0.027017083019018173
step: 120, loss: 0.019816873595118523
step: 130, loss: 0.007435757666826248
step: 140, loss: 0.06537169218063354
step: 150, loss: 0.00443543866276741
step: 160, loss: 0.00024115167616400868
step: 170, loss: 0.0004807061341125518
step: 180, loss: 0.007768256589770317
step: 190, loss: 3.0391673135454766e-05
step: 200, loss: 0.04140981659293175
step: 210, loss: 0.029085485264658928
step: 220, loss: 0.010750990360975266
step: 230, loss: 0.0002554168167989701
step: 240, loss: 0.0036391469184309244
step: 250, loss: 0.07226888835430145
step: 260, loss: 5.034076457377523e-05
step: 270, loss: 0.0001753523974912241
step: 280, loss: 0.029150262475013733
step: 290, loss: 2.8970467610633932e-05
step: 300, loss: 0.002243511378765106
step: 310, loss: 0.0074190013110637665
step: 320, loss: 0.00991856586188078
step: 330, loss: 0.004965536296367645
step: 340, loss: 0.0004361557657830417
step: 350, loss: 5.4177937272470444e-05
step: 360, loss: 0.00031373053207062185
step: 370, loss: 0.09212876856327057
step: 380, loss: 0.0700216293334961
epoch 20: dev_f1=0.7076923076923077, f1=0.7089947089947092, best_f1=0.7082294264339153
