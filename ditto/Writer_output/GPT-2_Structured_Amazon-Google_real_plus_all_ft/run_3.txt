cuda
Device: cuda
step: 0, loss: 0.6730182766914368
step: 10, loss: 0.2551426291465759
step: 20, loss: 1.0368759632110596
step: 30, loss: 0.3004216253757477
step: 40, loss: 0.3736477792263031
step: 50, loss: 0.250270277261734
step: 60, loss: 0.31750980019569397
step: 70, loss: 0.46207207441329956
step: 80, loss: 0.3843771815299988
step: 90, loss: 0.31346720457077026
step: 100, loss: 0.1359533816576004
step: 110, loss: 0.3752417266368866
step: 120, loss: 0.19245274364948273
step: 130, loss: 0.3429962396621704
step: 140, loss: 0.15961654484272003
step: 150, loss: 0.2892194092273712
step: 160, loss: 0.2428216189146042
step: 170, loss: 0.28949910402297974
step: 180, loss: 0.3063570261001587
step: 190, loss: 0.19478869438171387
step: 200, loss: 0.23868638277053833
step: 210, loss: 0.1842711716890335
step: 220, loss: 0.08122699707746506
step: 230, loss: 0.24462535977363586
step: 240, loss: 0.13926801085472107
step: 250, loss: 0.3180832266807556
step: 260, loss: 0.1821734756231308
step: 270, loss: 0.3280276358127594
step: 280, loss: 0.1819288730621338
step: 290, loss: 0.1607191413640976
step: 300, loss: 0.27055883407592773
step: 310, loss: 0.09857955574989319
step: 320, loss: 0.16564565896987915
step: 330, loss: 0.03356659784913063
step: 340, loss: 0.07590100169181824
step: 350, loss: 0.11082307249307632
step: 360, loss: 0.03712337464094162
step: 370, loss: 0.25617897510528564
step: 380, loss: 0.20853017270565033
step: 390, loss: 0.12627099454402924
step: 400, loss: 0.19523932039737701
step: 410, loss: 0.07896661758422852
step: 420, loss: 0.22293917834758759
epoch 1: dev_f1=0.6707566462167689, f1=0.6555323590814196, best_f1=0.6555323590814196
step: 0, loss: 0.10376647114753723
step: 10, loss: 0.038204774260520935
step: 20, loss: 0.15441492199897766
step: 30, loss: 0.01937078684568405
step: 40, loss: 0.029182584956288338
step: 50, loss: 0.07306651026010513
step: 60, loss: 0.11871563643217087
step: 70, loss: 0.145122691988945
step: 80, loss: 0.1570872813463211
step: 90, loss: 0.1384773999452591
step: 100, loss: 0.08254127204418182
step: 110, loss: 0.07038751989603043
step: 120, loss: 0.05807084962725639
step: 130, loss: 0.07790907472372055
step: 140, loss: 0.015352882444858551
step: 150, loss: 0.07089530676603317
step: 160, loss: 0.12468188256025314
step: 170, loss: 0.1392035335302353
step: 180, loss: 0.27739185094833374
step: 190, loss: 0.09486813843250275
step: 200, loss: 0.06941624730825424
step: 210, loss: 0.04491438344120979
step: 220, loss: 0.06632755696773529
step: 230, loss: 0.10467834770679474
step: 240, loss: 0.20640140771865845
step: 250, loss: 0.036380402743816376
step: 260, loss: 0.02564282901585102
step: 270, loss: 0.09881090372800827
step: 280, loss: 0.22204454243183136
step: 290, loss: 0.09285225719213486
step: 300, loss: 0.09225492924451828
step: 310, loss: 0.05938158184289932
step: 320, loss: 0.13750939071178436
step: 330, loss: 0.08731429278850555
step: 340, loss: 0.04075799882411957
step: 350, loss: 0.13843505084514618
step: 360, loss: 0.15797507762908936
step: 370, loss: 0.03527314215898514
step: 380, loss: 0.16109530627727509
step: 390, loss: 0.07880901545286179
step: 400, loss: 0.009127151221036911
step: 410, loss: 0.0800795778632164
step: 420, loss: 0.25703954696655273
epoch 2: dev_f1=0.697029702970297, f1=0.6414342629482072, best_f1=0.6414342629482072
step: 0, loss: 0.058154989033937454
step: 10, loss: 0.05715923383831978
step: 20, loss: 0.0017045243876054883
step: 30, loss: 0.036866042762994766
step: 40, loss: 0.0658448114991188
step: 50, loss: 0.21473073959350586
step: 60, loss: 0.0008246105280704796
step: 70, loss: 0.14672915637493134
step: 80, loss: 0.10913319140672684
step: 90, loss: 0.04811660945415497
step: 100, loss: 0.09446589648723602
step: 110, loss: 0.011259770020842552
step: 120, loss: 0.08966333419084549
step: 130, loss: 0.16431370377540588
step: 140, loss: 0.07309495657682419
step: 150, loss: 0.02657133713364601
step: 160, loss: 0.014874898828566074
step: 170, loss: 0.03318997472524643
step: 180, loss: 0.05659753829240799
step: 190, loss: 0.10996005684137344
step: 200, loss: 0.1837807148694992
step: 210, loss: 0.04946143180131912
step: 220, loss: 0.09486287832260132
step: 230, loss: 0.13272243738174438
step: 240, loss: 0.04688264802098274
step: 250, loss: 0.07947468012571335
step: 260, loss: 0.06890387088060379
step: 270, loss: 0.03477512672543526
step: 280, loss: 0.12334474921226501
step: 290, loss: 0.024642061442136765
step: 300, loss: 0.09784851223230362
step: 310, loss: 0.0820770114660263
step: 320, loss: 0.027989178895950317
step: 330, loss: 0.10316679626703262
step: 340, loss: 0.02712882310152054
step: 350, loss: 0.13560892641544342
step: 360, loss: 0.10344532132148743
step: 370, loss: 0.08501535654067993
step: 380, loss: 0.19910970330238342
step: 390, loss: 0.08392206579446793
step: 400, loss: 0.014542554505169392
step: 410, loss: 0.014067293144762516
step: 420, loss: 0.06570126116275787
epoch 3: dev_f1=0.686046511627907, f1=0.625, best_f1=0.6414342629482072
step: 0, loss: 0.005763374734669924
step: 10, loss: 0.02976226806640625
step: 20, loss: 0.046136051416397095
step: 30, loss: 0.07133295387029648
step: 40, loss: 0.00796896405518055
step: 50, loss: 0.09698233753442764
step: 60, loss: 0.020756317302584648
step: 70, loss: 0.02128729224205017
step: 80, loss: 0.21954773366451263
step: 90, loss: 0.0557459257543087
step: 100, loss: 0.09129232168197632
step: 110, loss: 0.029792776331305504
step: 120, loss: 0.04009368270635605
step: 130, loss: 0.11624877899885178
step: 140, loss: 0.07500498741865158
step: 150, loss: 0.039050791412591934
step: 160, loss: 0.0461890771985054
step: 170, loss: 0.08027268946170807
step: 180, loss: 0.003486484754830599
step: 190, loss: 0.028840847313404083
step: 200, loss: 0.09446031600236893
step: 210, loss: 0.08066248893737793
step: 220, loss: 0.06464431434869766
step: 230, loss: 0.006729098502546549
step: 240, loss: 0.15389332175254822
step: 250, loss: 0.1666640192270279
step: 260, loss: 0.019694911316037178
step: 270, loss: 0.021551463752985
step: 280, loss: 0.07639868557453156
step: 290, loss: 0.07766278088092804
step: 300, loss: 0.023753264918923378
step: 310, loss: 0.03280729055404663
step: 320, loss: 0.007661542855203152
step: 330, loss: 0.019443901255726814
step: 340, loss: 0.07315807044506073
step: 350, loss: 0.12058300524950027
step: 360, loss: 0.04118659719824791
step: 370, loss: 0.01636090688407421
step: 380, loss: 0.04664212837815285
step: 390, loss: 0.04599832743406296
step: 400, loss: 0.14261552691459656
step: 410, loss: 0.012259854935109615
step: 420, loss: 0.05539395287632942
epoch 4: dev_f1=0.6900826446280992, f1=0.6638830897703549, best_f1=0.6414342629482072
step: 0, loss: 0.0347762256860733
step: 10, loss: 0.014444399625062943
step: 20, loss: 0.016000067815184593
step: 30, loss: 0.03811560943722725
step: 40, loss: 0.002391170710325241
step: 50, loss: 0.001154489116743207
step: 60, loss: 0.051428504288196564
step: 70, loss: 0.009215788915753365
step: 80, loss: 0.0004041904176119715
step: 90, loss: 0.0019352891249582171
step: 100, loss: 0.0014325340744107962
step: 110, loss: 0.010813219472765923
step: 120, loss: 0.1127653568983078
step: 130, loss: 0.001346607692539692
step: 140, loss: 0.01864420622587204
step: 150, loss: 0.004622734151780605
step: 160, loss: 0.09129397571086884
step: 170, loss: 0.024060120806097984
step: 180, loss: 0.06588513404130936
step: 190, loss: 0.032365716993808746
step: 200, loss: 0.03865388035774231
step: 210, loss: 0.008712396956980228
step: 220, loss: 0.005031565669924021
step: 230, loss: 0.01800503022968769
step: 240, loss: 0.04988468438386917
step: 250, loss: 0.031508706510066986
step: 260, loss: 0.011317607015371323
step: 270, loss: 0.16497914493083954
step: 280, loss: 0.06641396880149841
step: 290, loss: 0.046389106661081314
step: 300, loss: 0.009970198385417461
step: 310, loss: 0.02179723232984543
step: 320, loss: 0.053659405559301376
step: 330, loss: 0.00959260668605566
step: 340, loss: 0.0027164267376065254
step: 350, loss: 0.17807772755622864
step: 360, loss: 0.12213271856307983
step: 370, loss: 0.0068306829780340195
step: 380, loss: 0.12476599216461182
step: 390, loss: 0.010072257369756699
step: 400, loss: 0.07543310523033142
step: 410, loss: 0.024896051734685898
step: 420, loss: 0.00781924743205309
epoch 5: dev_f1=0.7155555555555555, f1=0.6357308584686775, best_f1=0.6357308584686775
step: 0, loss: 0.011643880046904087
step: 10, loss: 0.0271194726228714
step: 20, loss: 0.026582742109894753
step: 30, loss: 0.08996222913265228
step: 40, loss: 0.0024075934197753668
step: 50, loss: 0.0018959918525069952
step: 60, loss: 0.00029478257056325674
step: 70, loss: 0.07316698879003525
step: 80, loss: 0.025417258962988853
step: 90, loss: 0.1524050235748291
step: 100, loss: 0.0036636011209338903
step: 110, loss: 0.029751431196928024
step: 120, loss: 0.07883433252573013
step: 130, loss: 0.11250793933868408
step: 140, loss: 0.05358045920729637
step: 150, loss: 0.025905098766088486
step: 160, loss: 0.014659455046057701
step: 170, loss: 0.003653214080259204
step: 180, loss: 0.010952259413897991
step: 190, loss: 0.005735285580158234
step: 200, loss: 0.01218485552817583
step: 210, loss: 0.002947290427982807
step: 220, loss: 0.0004827177617698908
step: 230, loss: 0.04469067603349686
step: 240, loss: 0.0023432800080627203
step: 250, loss: 0.004079227335751057
step: 260, loss: 0.0018779279198497534
step: 270, loss: 0.028231801465153694
step: 280, loss: 0.0978812426328659
step: 290, loss: 0.059317734092473984
step: 300, loss: 0.11746037751436234
step: 310, loss: 0.17323645949363708
step: 320, loss: 0.05108167231082916
step: 330, loss: 0.031867314130067825
step: 340, loss: 0.10806438326835632
step: 350, loss: 0.07789168506860733
step: 360, loss: 0.06305358558893204
step: 370, loss: 0.0012545207282528281
step: 380, loss: 0.019328167662024498
step: 390, loss: 0.018623478710651398
step: 400, loss: 0.05024293437600136
step: 410, loss: 0.027688950300216675
step: 420, loss: 0.052830714732408524
epoch 6: dev_f1=0.7117296222664016, f1=0.6772277227722773, best_f1=0.6357308584686775
step: 0, loss: 0.06310940533876419
step: 10, loss: 0.0005938907852396369
step: 20, loss: 0.04114312678575516
step: 30, loss: 0.0999796986579895
step: 40, loss: 0.019825918599963188
step: 50, loss: 0.0763743594288826
step: 60, loss: 0.007053295150399208
step: 70, loss: 0.03219199180603027
step: 80, loss: 0.05126677826046944
step: 90, loss: 0.0014084518188610673
step: 100, loss: 0.02321997471153736
step: 110, loss: 0.03610214218497276
step: 120, loss: 0.005531937815248966
step: 130, loss: 0.015076052397489548
step: 140, loss: 0.003760922234505415
step: 150, loss: 0.008534271270036697
step: 160, loss: 0.05265289545059204
step: 170, loss: 0.08034134656190872
step: 180, loss: 0.20069478452205658
step: 190, loss: 0.007278448436409235
step: 200, loss: 0.00036397934309206903
step: 210, loss: 0.0022884022910147905
step: 220, loss: 0.07834908366203308
step: 230, loss: 0.006252119317650795
step: 240, loss: 0.006570529192686081
step: 250, loss: 0.012306447140872478
step: 260, loss: 0.11003588885068893
step: 270, loss: 0.014528581872582436
step: 280, loss: 0.004285130184143782
step: 290, loss: 0.004037108272314072
step: 300, loss: 0.019996382296085358
step: 310, loss: 0.1264483779668808
step: 320, loss: 0.2563387155532837
step: 330, loss: 0.06511837244033813
step: 340, loss: 0.01662181131541729
step: 350, loss: 0.12107311189174652
step: 360, loss: 0.007456229068338871
step: 370, loss: 0.019739240407943726
step: 380, loss: 0.10197599977254868
step: 390, loss: 0.048107657581567764
step: 400, loss: 0.028737137094140053
step: 410, loss: 0.04869470372796059
step: 420, loss: 0.0016128727002069354
epoch 7: dev_f1=0.6847195357833656, f1=0.636015325670498, best_f1=0.6357308584686775
step: 0, loss: 0.05500312149524689
step: 10, loss: 0.0014642170863226056
step: 20, loss: 0.010532928630709648
step: 30, loss: 0.046604402363300323
step: 40, loss: 0.0014498173259198666
step: 50, loss: 0.008237514644861221
step: 60, loss: 0.0004330526280682534
step: 70, loss: 0.030057793483138084
step: 80, loss: 0.00833978783339262
step: 90, loss: 0.005564765073359013
step: 100, loss: 0.01905069872736931
step: 110, loss: 0.06555233150720596
step: 120, loss: 0.00037736192462034523
step: 130, loss: 0.0010195985669270158
step: 140, loss: 0.0800093561410904
step: 150, loss: 0.05931847169995308
step: 160, loss: 0.0002612777170725167
step: 170, loss: 0.09014926850795746
step: 180, loss: 0.06132679432630539
step: 190, loss: 0.0002668317756615579
step: 200, loss: 0.0013816634891554713
step: 210, loss: 0.003530709771439433
step: 220, loss: 0.01076233759522438
step: 230, loss: 0.11239492148160934
step: 240, loss: 0.0007298364071175456
step: 250, loss: 0.0006374438526108861
step: 260, loss: 0.0014326984528452158
step: 270, loss: 0.016571074724197388
step: 280, loss: 0.006830618716776371
step: 290, loss: 0.007071612868458033
step: 300, loss: 0.005935949739068747
step: 310, loss: 0.07363715767860413
step: 320, loss: 0.031601741909980774
step: 330, loss: 0.036256201565265656
step: 340, loss: 0.0011170882498845458
step: 350, loss: 0.00045467555173672736
step: 360, loss: 0.0037341227289289236
step: 370, loss: 0.0029250415973365307
step: 380, loss: 0.027315733954310417
step: 390, loss: 0.08310791850090027
step: 400, loss: 0.02639656513929367
step: 410, loss: 0.06651447713375092
step: 420, loss: 0.06281023472547531
epoch 8: dev_f1=0.7020408163265306, f1=0.6761133603238867, best_f1=0.6357308584686775
step: 0, loss: 0.007032708264887333
step: 10, loss: 0.00021534986444748938
step: 20, loss: 0.011789416894316673
step: 30, loss: 0.009883341379463673
step: 40, loss: 0.0015379848191514611
step: 50, loss: 0.000719446106813848
step: 60, loss: 0.1109330877661705
step: 70, loss: 0.002454412868246436
step: 80, loss: 0.017107859253883362
step: 90, loss: 0.0023583765141665936
step: 100, loss: 0.036200061440467834
step: 110, loss: 0.0030075861141085625
step: 120, loss: 0.00047498970525339246
step: 130, loss: 0.003051528474316001
step: 140, loss: 0.12804976105690002
step: 150, loss: 0.022952545434236526
step: 160, loss: 0.003284841775894165
step: 170, loss: 0.0034423379693180323
step: 180, loss: 0.00011496475781314075
step: 190, loss: 0.005875102244317532
step: 200, loss: 0.04006340354681015
step: 210, loss: 0.009229951538145542
step: 220, loss: 0.021806005388498306
step: 230, loss: 0.01292125042527914
step: 240, loss: 0.0015295990742743015
step: 250, loss: 0.00011419095244491473
step: 260, loss: 0.02815505862236023
step: 270, loss: 0.0597519613802433
step: 280, loss: 0.0006369167240336537
step: 290, loss: 0.0023773082066327333
step: 300, loss: 0.033198028802871704
step: 310, loss: 0.0026584540028125048
step: 320, loss: 0.001183115178719163
step: 330, loss: 0.0048722028732299805
step: 340, loss: 0.02111719362437725
step: 350, loss: 0.025436682626605034
step: 360, loss: 0.028384746983647346
step: 370, loss: 0.0001222534046974033
step: 380, loss: 0.0006095891585573554
step: 390, loss: 0.03997393324971199
step: 400, loss: 0.05854501202702522
step: 410, loss: 0.00036582667962647974
step: 420, loss: 0.018215645104646683
epoch 9: dev_f1=0.6936170212765959, f1=0.6535087719298245, best_f1=0.6357308584686775
step: 0, loss: 0.031451817601919174
step: 10, loss: 0.00043757990351878107
step: 20, loss: 0.004837798420339823
step: 30, loss: 0.0004632130148820579
step: 40, loss: 0.00012358689855318516
step: 50, loss: 0.041780199855566025
step: 60, loss: 0.07573144882917404
step: 70, loss: 0.0016411874676123261
step: 80, loss: 0.029023347422480583
step: 90, loss: 0.014191696420311928
step: 100, loss: 0.0020656795240938663
step: 110, loss: 0.0001531094458186999
step: 120, loss: 0.0036949305795133114
step: 130, loss: 0.04068009927868843
step: 140, loss: 0.0011874347692355514
step: 150, loss: 0.000359828001819551
step: 160, loss: 0.03245888277888298
step: 170, loss: 0.001996117876842618
step: 180, loss: 0.020305663347244263
step: 190, loss: 0.0027782979886978865
step: 200, loss: 0.001186443492770195
step: 210, loss: 0.0010598220396786928
step: 220, loss: 0.022665463387966156
step: 230, loss: 0.000483872921904549
step: 240, loss: 0.0042063891887664795
step: 250, loss: 0.00036341106169857085
step: 260, loss: 0.00025231236941181123
step: 270, loss: 0.0008755255257710814
step: 280, loss: 0.2189161628484726
step: 290, loss: 0.0034017981961369514
step: 300, loss: 0.0009171474957838655
step: 310, loss: 0.0013379023876041174
step: 320, loss: 0.004514087922871113
step: 330, loss: 0.003209091490134597
step: 340, loss: 0.014101247303187847
step: 350, loss: 0.01780431717634201
step: 360, loss: 0.006657949183136225
step: 370, loss: 0.0007435916340909898
step: 380, loss: 0.0019444817444309592
step: 390, loss: 0.04325493425130844
step: 400, loss: 0.0007164584239944816
step: 410, loss: 0.05704450234770775
step: 420, loss: 0.008687572553753853
epoch 10: dev_f1=0.6929133858267715, f1=0.6497064579256361, best_f1=0.6357308584686775
step: 0, loss: 0.004401858896017075
step: 10, loss: 0.0003817737742792815
step: 20, loss: 0.0014830712461844087
step: 30, loss: 0.012198826298117638
step: 40, loss: 0.002368615474551916
step: 50, loss: 0.04277355223894119
step: 60, loss: 0.002080080332234502
step: 70, loss: 0.011493021622300148
step: 80, loss: 0.004143505357205868
step: 90, loss: 0.00029502296820282936
step: 100, loss: 0.005785801913589239
step: 110, loss: 0.013632263988256454
step: 120, loss: 0.001173365511931479
step: 130, loss: 0.04051640257239342
step: 140, loss: 0.11074887961149216
step: 150, loss: 0.008200444281101227
step: 160, loss: 0.023269983008503914
step: 170, loss: 0.009833479300141335
step: 180, loss: 0.001743593136779964
step: 190, loss: 0.18457162380218506
step: 200, loss: 0.019746780395507812
step: 210, loss: 0.00034802136360667646
step: 220, loss: 0.07734837383031845
step: 230, loss: 0.0002247720112791285
step: 240, loss: 0.038957804441452026
step: 250, loss: 0.0017328804824501276
step: 260, loss: 0.00041306758066639304
step: 270, loss: 0.0167799424380064
step: 280, loss: 0.003995500970631838
step: 290, loss: 0.026684777811169624
step: 300, loss: 0.029587632045149803
step: 310, loss: 0.036958128213882446
step: 320, loss: 0.0027073686942458153
step: 330, loss: 0.0003281716490164399
step: 340, loss: 0.004675842821598053
step: 350, loss: 0.024897901341319084
step: 360, loss: 0.000600868312176317
step: 370, loss: 0.03283295780420303
step: 380, loss: 0.002859261352568865
step: 390, loss: 0.0008211183012463152
step: 400, loss: 0.00015812744095455855
step: 410, loss: 0.00010488700354471803
step: 420, loss: 0.004752929322421551
epoch 11: dev_f1=0.6588785046728971, f1=0.616504854368932, best_f1=0.6357308584686775
step: 0, loss: 0.00029193624504841864
step: 10, loss: 0.12043455243110657
step: 20, loss: 0.010558564215898514
step: 30, loss: 0.023978939279913902
step: 40, loss: 0.017612988129258156
step: 50, loss: 0.009937054477632046
step: 60, loss: 0.0032968339510262012
step: 70, loss: 0.003074825508520007
step: 80, loss: 0.0007088613347150385
step: 90, loss: 0.027748411521315575
step: 100, loss: 0.05732481926679611
step: 110, loss: 7.001688936725259e-05
step: 120, loss: 0.0002711885317694396
step: 130, loss: 0.0028445408679544926
step: 140, loss: 0.004886424168944359
step: 150, loss: 0.05169301480054855
step: 160, loss: 0.003060743911191821
step: 170, loss: 0.00011380481737433001
step: 180, loss: 0.0030195775907486677
step: 190, loss: 0.0018964208429679275
step: 200, loss: 0.03093048185110092
step: 210, loss: 0.0017717228038236499
step: 220, loss: 0.0019214518833905458
step: 230, loss: 0.019279178231954575
step: 240, loss: 0.011317542754113674
step: 250, loss: 0.058578312397003174
step: 260, loss: 0.006292424630373716
step: 270, loss: 0.0005413602339103818
step: 280, loss: 0.0020590804051607847
step: 290, loss: 0.013329664245247841
step: 300, loss: 0.0006026104092597961
step: 310, loss: 0.00030252663418650627
step: 320, loss: 5.275771036394872e-05
step: 330, loss: 0.000511235324665904
step: 340, loss: 0.0002938925172202289
step: 350, loss: 0.00013071022112853825
step: 360, loss: 0.00015062153397593647
step: 370, loss: 6.043189932825044e-05
step: 380, loss: 0.0002564776223152876
step: 390, loss: 0.03772879019379616
step: 400, loss: 0.0024410351179540157
step: 410, loss: 0.01111093070358038
step: 420, loss: 0.022035956382751465
epoch 12: dev_f1=0.6833333333333332, f1=0.6858316221765914, best_f1=0.6357308584686775
step: 0, loss: 8.183406316675246e-05
step: 10, loss: 0.012162095867097378
step: 20, loss: 0.0036721520591527224
step: 30, loss: 0.0022588754072785378
step: 40, loss: 0.0001987860887311399
step: 50, loss: 0.0050535607151687145
step: 60, loss: 9.925154154188931e-05
step: 70, loss: 0.0010399667080491781
step: 80, loss: 0.004161211661994457
step: 90, loss: 0.0030243457295000553
step: 100, loss: 0.0004064860986545682
step: 110, loss: 0.000550424971152097
step: 120, loss: 0.0016508272383362055
step: 130, loss: 0.0010073394514620304
step: 140, loss: 0.0015718317590653896
step: 150, loss: 0.0027442562859505415
step: 160, loss: 0.0035042627714574337
step: 170, loss: 0.013104185461997986
step: 180, loss: 0.0006392119103111327
step: 190, loss: 0.0006213405285961926
step: 200, loss: 7.091114821378142e-05
step: 210, loss: 4.020852065877989e-05
step: 220, loss: 0.006263432092964649
step: 230, loss: 0.00048650847747921944
step: 240, loss: 0.013258273713290691
step: 250, loss: 0.0017980266129598022
step: 260, loss: 0.012769297696650028
step: 270, loss: 7.613444176968187e-05
step: 280, loss: 0.0003188489645253867
step: 290, loss: 0.003018320770934224
step: 300, loss: 0.009020388126373291
step: 310, loss: 0.001887478050775826
step: 320, loss: 5.758223051088862e-05
step: 330, loss: 0.009729553014039993
step: 340, loss: 0.0010118959471583366
step: 350, loss: 0.00015914587129373103
step: 360, loss: 0.0004448439576663077
step: 370, loss: 0.1272672861814499
step: 380, loss: 0.00010485107486601919
step: 390, loss: 0.0005905943689867854
step: 400, loss: 0.02655661664903164
step: 410, loss: 6.734429916832596e-05
step: 420, loss: 0.03000197373330593
epoch 13: dev_f1=0.6831275720164609, f1=0.6369168356997972, best_f1=0.6357308584686775
step: 0, loss: 0.0002200012095272541
step: 10, loss: 0.0002825921692419797
step: 20, loss: 0.1287919282913208
step: 30, loss: 0.0014034619089215994
step: 40, loss: 7.73850260884501e-05
step: 50, loss: 0.008629299700260162
step: 60, loss: 0.0001010095002129674
step: 70, loss: 0.018340324983000755
step: 80, loss: 0.0012620839988812804
step: 90, loss: 0.00016315096581820399
step: 100, loss: 0.0004812458937522024
step: 110, loss: 0.0002752938016783446
step: 120, loss: 6.977136217756197e-05
step: 130, loss: 0.11463290452957153
step: 140, loss: 0.00025869032833725214
step: 150, loss: 0.00011243396875215694
step: 160, loss: 0.001842103200033307
step: 170, loss: 0.05301589518785477
step: 180, loss: 0.11367066949605942
step: 190, loss: 0.046113867312669754
step: 200, loss: 0.0005533121875487268
step: 210, loss: 0.002081325277686119
step: 220, loss: 0.011097176000475883
step: 230, loss: 0.0005971640348434448
step: 240, loss: 0.0005015495116822422
step: 250, loss: 8.626369526609778e-05
step: 260, loss: 5.245525608188473e-05
step: 270, loss: 0.00013955387112218887
step: 280, loss: 0.050648488104343414
step: 290, loss: 0.00022316012473311275
step: 300, loss: 0.005314257927238941
step: 310, loss: 4.304988760850392e-05
step: 320, loss: 3.244573963456787e-05
step: 330, loss: 0.006289384793490171
step: 340, loss: 0.004026379436254501
step: 350, loss: 0.0035790991969406605
step: 360, loss: 5.3121886594453827e-05
step: 370, loss: 0.05518549308180809
step: 380, loss: 0.0001855989539762959
step: 390, loss: 0.0005182191962376237
step: 400, loss: 0.0001715862745186314
step: 410, loss: 5.592068555415608e-05
step: 420, loss: 0.00031371464137919247
epoch 14: dev_f1=0.672340425531915, f1=0.6452991452991453, best_f1=0.6357308584686775
step: 0, loss: 0.01351484190672636
step: 10, loss: 6.913153629284352e-05
step: 20, loss: 0.09341368824243546
step: 30, loss: 0.0045334105379879475
step: 40, loss: 0.0012235504109412432
step: 50, loss: 2.8657770599238575e-05
step: 60, loss: 0.0012983533088117838
step: 70, loss: 0.0010501533979550004
step: 80, loss: 0.0004558550426736474
step: 90, loss: 0.00012454739771783352
step: 100, loss: 0.011380842886865139
step: 110, loss: 0.007949125953018665
step: 120, loss: 4.557929787551984e-05
step: 130, loss: 0.01175218541175127
step: 140, loss: 0.0002638094301801175
step: 150, loss: 0.11541536450386047
step: 160, loss: 7.339815783780068e-05
step: 170, loss: 0.0006657009944319725
step: 180, loss: 0.003260781290009618
step: 190, loss: 0.05968691036105156
step: 200, loss: 8.538776455679908e-05
step: 210, loss: 0.0012586923548951745
step: 220, loss: 0.0006555910222232342
step: 230, loss: 0.0008205429185181856
step: 240, loss: 0.00011925940634682775
step: 250, loss: 0.00026594765949994326
step: 260, loss: 0.01117605809122324
step: 270, loss: 8.756355236982927e-05
step: 280, loss: 0.0027053600642830133
step: 290, loss: 0.00011260434985160828
step: 300, loss: 0.00509995874017477
step: 310, loss: 0.032616838812828064
step: 320, loss: 0.0003100669418927282
step: 330, loss: 0.05267093703150749
step: 340, loss: 0.00040147601976059377
step: 350, loss: 0.0006691551534458995
step: 360, loss: 0.03186724707484245
step: 370, loss: 0.01561833918094635
step: 380, loss: 0.0014657132560387254
step: 390, loss: 0.023381540551781654
step: 400, loss: 0.000125557417050004
step: 410, loss: 0.00046398831182159483
step: 420, loss: 0.0016786010237410665
epoch 15: dev_f1=0.6776859504132232, f1=0.6419753086419754, best_f1=0.6357308584686775
step: 0, loss: 0.001100294291973114
step: 10, loss: 0.0022143563255667686
step: 20, loss: 0.008225986734032631
step: 30, loss: 4.341939347796142e-05
step: 40, loss: 6.136285810498521e-05
step: 50, loss: 0.0002922389830928296
step: 60, loss: 0.0011237312573939562
step: 70, loss: 0.0007243331056088209
step: 80, loss: 7.779855513945222e-05
step: 90, loss: 0.007518952712416649
step: 100, loss: 0.00036566867493093014
step: 110, loss: 0.000722243043128401
step: 120, loss: 0.017539605498313904
step: 130, loss: 0.00048000720562413335
step: 140, loss: 0.021121686324477196
step: 150, loss: 0.0013880946207791567
step: 160, loss: 0.0016706137685105205
step: 170, loss: 7.494194142054766e-05
step: 180, loss: 8.866356802172959e-05
step: 190, loss: 8.815778710413724e-05
step: 200, loss: 0.00011355218885000795
step: 210, loss: 8.66012487676926e-05
step: 220, loss: 0.0003689899167511612
step: 230, loss: 0.004882786422967911
step: 240, loss: 0.0005123206065036356
step: 250, loss: 0.0001406105438945815
step: 260, loss: 0.0001559753727633506
step: 270, loss: 0.03552801162004471
step: 280, loss: 0.00029799476033076644
step: 290, loss: 0.009436451829969883
step: 300, loss: 4.140482269576751e-05
step: 310, loss: 0.0011994412634521723
step: 320, loss: 6.813744403189048e-05
step: 330, loss: 0.00020832163863815367
step: 340, loss: 0.0052760886028409
step: 350, loss: 0.00039248389657586813
step: 360, loss: 0.00012759040691889822
step: 370, loss: 0.00032544255373068154
step: 380, loss: 0.0002212981489719823
step: 390, loss: 0.00036194006679579616
step: 400, loss: 0.0009733010665513575
step: 410, loss: 0.0007949834107421339
step: 420, loss: 0.0023152672220021486
epoch 16: dev_f1=0.6829268292682927, f1=0.652, best_f1=0.6357308584686775
step: 0, loss: 0.00033656341838650405
step: 10, loss: 5.8758385421242565e-05
step: 20, loss: 0.0001781721512088552
step: 30, loss: 0.017626477405428886
step: 40, loss: 0.00024319735530298203
step: 50, loss: 0.00010079427011078224
step: 60, loss: 0.014126954600214958
step: 70, loss: 0.0010052231373265386
step: 80, loss: 0.00018371424812357873
step: 90, loss: 0.00010180054960073903
step: 100, loss: 0.00011400602670619264
step: 110, loss: 0.0002590829972177744
step: 120, loss: 0.0004943363601341844
step: 130, loss: 0.00017775132437236607
step: 140, loss: 7.384851051028818e-05
step: 150, loss: 0.0017214353429153562
step: 160, loss: 4.056556281284429e-05
step: 170, loss: 0.004631919786334038
step: 180, loss: 0.030468368902802467
step: 190, loss: 0.0003782161802519113
step: 200, loss: 0.02138582244515419
step: 210, loss: 0.00010410841059638187
step: 220, loss: 2.3073980628396384e-05
step: 230, loss: 6.832450890215114e-05
step: 240, loss: 0.0015670179855078459
step: 250, loss: 0.0003309696912765503
step: 260, loss: 9.648883860791102e-05
step: 270, loss: 0.00040152479778043926
step: 280, loss: 4.416782030602917e-05
step: 290, loss: 3.441995067987591e-05
step: 300, loss: 0.00043380295392125845
step: 310, loss: 0.00025860342429950833
step: 320, loss: 0.00038150663021951914
step: 330, loss: 0.03992795944213867
step: 340, loss: 0.0007588464068248868
step: 350, loss: 5.9769186918856576e-05
step: 360, loss: 4.911078212899156e-05
step: 370, loss: 0.044343553483486176
step: 380, loss: 0.00012573828280437738
step: 390, loss: 0.007976782508194447
step: 400, loss: 0.0017609935021027923
step: 410, loss: 0.003037991002202034
step: 420, loss: 0.03012225218117237
epoch 17: dev_f1=0.6680672268907564, f1=0.6413502109704642, best_f1=0.6357308584686775
step: 0, loss: 0.0008081120904535055
step: 10, loss: 6.557413871632889e-05
step: 20, loss: 0.0005267784581519663
step: 30, loss: 2.400889752607327e-05
step: 40, loss: 0.00017696137365419418
step: 50, loss: 0.0054060062393546104
step: 60, loss: 9.902290912577882e-05
step: 70, loss: 9.666521509643644e-05
step: 80, loss: 0.0003346415178384632
step: 90, loss: 0.0004698312550317496
step: 100, loss: 5.899013558519073e-05
step: 110, loss: 3.2337869924958795e-05
step: 120, loss: 0.0009420540300197899
step: 130, loss: 3.863640085910447e-05
step: 140, loss: 0.0003148659016005695
step: 150, loss: 3.4871143725467846e-05
step: 160, loss: 0.030107036232948303
step: 170, loss: 0.000372924841940403
step: 180, loss: 0.008235810324549675
step: 190, loss: 0.00014128290058579296
step: 200, loss: 0.012095930986106396
step: 210, loss: 9.755895734997466e-05
step: 220, loss: 0.00011251783871557564
step: 230, loss: 0.00023171669454313815
step: 240, loss: 0.0007859569159336388
step: 250, loss: 0.06244157254695892
step: 260, loss: 4.9623718950897455e-05
step: 270, loss: 0.0031984655652195215
step: 280, loss: 0.004772706422954798
step: 290, loss: 4.141887984587811e-05
step: 300, loss: 0.01600315421819687
step: 310, loss: 0.01017353218048811
step: 320, loss: 0.00012050105578964576
step: 330, loss: 6.43176244921051e-05
step: 340, loss: 0.002241428242996335
step: 350, loss: 0.0023696639109402895
step: 360, loss: 6.6191321820952e-05
step: 370, loss: 0.00031431540264748037
step: 380, loss: 0.0016058982582762837
step: 390, loss: 4.705502578872256e-05
step: 400, loss: 0.05939650908112526
step: 410, loss: 6.497652066173032e-05
step: 420, loss: 9.405352466274053e-05
epoch 18: dev_f1=0.6666666666666666, f1=0.6504065040650406, best_f1=0.6357308584686775
step: 0, loss: 0.0014593234518542886
step: 10, loss: 0.0024648287799209356
step: 20, loss: 9.489423246122897e-05
step: 30, loss: 0.0001971948513528332
step: 40, loss: 5.255495852907188e-05
step: 50, loss: 7.621919212397188e-05
step: 60, loss: 0.0014961076667532325
step: 70, loss: 0.03167026489973068
step: 80, loss: 5.3714251407654956e-05
step: 90, loss: 4.160869139013812e-05
step: 100, loss: 7.401527545880526e-05
step: 110, loss: 8.248092490248382e-05
step: 120, loss: 0.002616876270622015
step: 130, loss: 5.4603304306510836e-05
step: 140, loss: 0.0001972684549400583
step: 150, loss: 0.013970881700515747
step: 160, loss: 0.00012253329623490572
step: 170, loss: 0.03826042264699936
step: 180, loss: 0.0010686502791941166
step: 190, loss: 0.0006638264749199152
step: 200, loss: 0.0005341062205843627
step: 210, loss: 0.00038532153121195734
step: 220, loss: 0.005436726380139589
step: 230, loss: 7.468542025890201e-05
step: 240, loss: 0.00010527005360927433
step: 250, loss: 0.000374769268091768
step: 260, loss: 3.5202134313294664e-05
step: 270, loss: 2.370360198256094e-05
step: 280, loss: 0.00013340002624318004
step: 290, loss: 3.0664599762531e-05
step: 300, loss: 0.0006345535512082279
step: 310, loss: 3.1105220841709524e-05
step: 320, loss: 0.00010037176252808422
step: 330, loss: 9.871814108919352e-05
step: 340, loss: 0.0005098847323097289
step: 350, loss: 0.015598969534039497
step: 360, loss: 3.696024214150384e-05
step: 370, loss: 0.004379983060061932
step: 380, loss: 0.015549082309007645
step: 390, loss: 0.10028115659952164
step: 400, loss: 3.1477538868784904e-05
step: 410, loss: 5.0224625738337636e-05
step: 420, loss: 3.814463343587704e-05
epoch 19: dev_f1=0.6709129511677282, f1=0.6295503211991433, best_f1=0.6357308584686775
step: 0, loss: 0.009781507775187492
step: 10, loss: 0.0007267564069479704
step: 20, loss: 7.051391730783507e-05
step: 30, loss: 9.929067164193839e-05
step: 40, loss: 0.00015227960830088705
step: 50, loss: 0.015650911256670952
step: 60, loss: 0.00017690620734356344
step: 70, loss: 7.23467965144664e-05
step: 80, loss: 0.00041772646363824606
step: 90, loss: 5.762625005445443e-05
step: 100, loss: 9.43225240916945e-05
step: 110, loss: 0.0069512976333498955
step: 120, loss: 5.484597204485908e-05
step: 130, loss: 7.506926340283826e-05
step: 140, loss: 0.00034675022470764816
step: 150, loss: 0.00010193850903306156
step: 160, loss: 0.006270923186093569
step: 170, loss: 0.0023516465444117785
step: 180, loss: 6.792202475480735e-05
step: 190, loss: 3.0239936677389778e-05
step: 200, loss: 7.041177741484717e-05
step: 210, loss: 7.678911060793325e-05
step: 220, loss: 0.0001835448492784053
step: 230, loss: 0.012319465167820454
step: 240, loss: 5.514929216587916e-05
step: 250, loss: 0.05976688116788864
step: 260, loss: 0.019923832267522812
step: 270, loss: 0.0016324900789186358
step: 280, loss: 0.014588690362870693
step: 290, loss: 0.004565554205328226
step: 300, loss: 0.00018222247308585793
step: 310, loss: 5.631120802718215e-05
step: 320, loss: 0.00013295625103637576
step: 330, loss: 3.9433693018509075e-05
step: 340, loss: 3.961665788665414e-05
step: 350, loss: 1.974732367671095e-05
step: 360, loss: 0.0026796595193445683
step: 370, loss: 0.00017545487207826227
step: 380, loss: 0.00029563490534201264
step: 390, loss: 0.001333572086878121
step: 400, loss: 0.00036140024894848466
step: 410, loss: 0.0005715438164770603
step: 420, loss: 4.925605026073754e-05
epoch 20: dev_f1=0.6680851063829787, f1=0.6266094420600857, best_f1=0.6357308584686775
