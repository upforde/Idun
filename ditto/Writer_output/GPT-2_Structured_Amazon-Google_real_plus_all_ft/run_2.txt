cuda
Device: cuda
step: 0, loss: 0.6538125276565552
step: 10, loss: 0.2616449296474457
step: 20, loss: 0.3132563829421997
step: 30, loss: 0.2620058059692383
step: 40, loss: 0.20242781937122345
step: 50, loss: 0.21598251163959503
step: 60, loss: 0.07672465592622757
step: 70, loss: 0.3107757866382599
step: 80, loss: 0.37762612104415894
step: 90, loss: 0.42275482416152954
step: 100, loss: 0.181387796998024
step: 110, loss: 0.34031954407691956
step: 120, loss: 0.21273303031921387
step: 130, loss: 0.23174139857292175
step: 140, loss: 0.18989023566246033
step: 150, loss: 0.1404578983783722
step: 160, loss: 0.05565416067838669
step: 170, loss: 0.21573519706726074
step: 180, loss: 0.11168234795331955
step: 190, loss: 0.10069476068019867
step: 200, loss: 0.14163650572299957
step: 210, loss: 0.1448672115802765
step: 220, loss: 0.16773094236850739
step: 230, loss: 0.0761597752571106
step: 240, loss: 0.15734261274337769
step: 250, loss: 0.18681390583515167
step: 260, loss: 0.2697688043117523
step: 270, loss: 0.1912015676498413
step: 280, loss: 0.07478392124176025
step: 290, loss: 0.11556249111890793
step: 300, loss: 0.09617704898118973
step: 310, loss: 0.10713976621627808
step: 320, loss: 0.275879830121994
step: 330, loss: 0.21196870505809784
step: 340, loss: 0.09152501076459885
step: 350, loss: 0.3808460831642151
step: 360, loss: 0.32374972105026245
step: 370, loss: 0.09762798249721527
step: 380, loss: 0.04769255220890045
step: 390, loss: 0.20027047395706177
step: 400, loss: 0.07998674362897873
step: 410, loss: 0.014727365225553513
step: 420, loss: 0.16078822314739227
epoch 1: dev_f1=0.6558704453441295, f1=0.6060606060606061, best_f1=0.6060606060606061
step: 0, loss: 0.10732073336839676
step: 10, loss: 0.10498324036598206
step: 20, loss: 0.16230285167694092
step: 30, loss: 0.07589443773031235
step: 40, loss: 0.11778023838996887
step: 50, loss: 0.053433068096637726
step: 60, loss: 0.06397587060928345
step: 70, loss: 0.010698013938963413
step: 80, loss: 0.12193426489830017
step: 90, loss: 0.12499967217445374
step: 100, loss: 0.08768800646066666
step: 110, loss: 0.10619007050991058
step: 120, loss: 0.05080254003405571
step: 130, loss: 0.1902685910463333
step: 140, loss: 0.11811337620019913
step: 150, loss: 0.0523606576025486
step: 160, loss: 0.2757180631160736
step: 170, loss: 0.06812155246734619
step: 180, loss: 0.05294269695878029
step: 190, loss: 0.02914375625550747
step: 200, loss: 0.018144188448786736
step: 210, loss: 0.008962113410234451
step: 220, loss: 0.07991622388362885
step: 230, loss: 0.1784534752368927
step: 240, loss: 0.11564961820840836
step: 250, loss: 0.2588212192058563
step: 260, loss: 0.08968809247016907
step: 270, loss: 0.2330637127161026
step: 280, loss: 0.23615995049476624
step: 290, loss: 0.0792011022567749
step: 300, loss: 0.11249168962240219
step: 310, loss: 0.03557096794247627
step: 320, loss: 0.09490250796079636
step: 330, loss: 0.3593127429485321
step: 340, loss: 0.13015541434288025
step: 350, loss: 0.030356677249073982
step: 360, loss: 0.23871348798274994
step: 370, loss: 0.1975080817937851
step: 380, loss: 0.09608954191207886
step: 390, loss: 0.12684863805770874
step: 400, loss: 0.03712037205696106
step: 410, loss: 0.1151423305273056
step: 420, loss: 0.06777477264404297
epoch 2: dev_f1=0.6869918699186993, f1=0.6747967479674798, best_f1=0.6747967479674798
step: 0, loss: 0.026679789647459984
step: 10, loss: 0.056002385914325714
step: 20, loss: 0.10493079572916031
step: 30, loss: 0.18774934113025665
step: 40, loss: 0.07108452916145325
step: 50, loss: 0.050262778997421265
step: 60, loss: 0.12545964121818542
step: 70, loss: 0.02884170226752758
step: 80, loss: 0.04493936523795128
step: 90, loss: 0.010218238458037376
step: 100, loss: 0.029998525977134705
step: 110, loss: 0.03149856999516487
step: 120, loss: 0.052841026335954666
step: 130, loss: 0.045973096042871475
step: 140, loss: 0.09093678742647171
step: 150, loss: 0.029292168095707893
step: 160, loss: 0.14646977186203003
step: 170, loss: 0.14967100322246552
step: 180, loss: 0.1360921561717987
step: 190, loss: 0.13871046900749207
step: 200, loss: 0.018669510260224342
step: 210, loss: 0.07824863493442535
step: 220, loss: 0.04792141169309616
step: 230, loss: 0.04571717232465744
step: 240, loss: 0.05209548771381378
step: 250, loss: 0.13373258709907532
step: 260, loss: 0.061353929340839386
step: 270, loss: 0.03374769166111946
step: 280, loss: 0.20892542600631714
step: 290, loss: 0.061172086745500565
step: 300, loss: 0.16583912074565887
step: 310, loss: 0.025932250544428825
step: 320, loss: 0.03663022816181183
step: 330, loss: 0.10879075527191162
step: 340, loss: 0.03769870102405548
step: 350, loss: 0.10428498685359955
step: 360, loss: 0.0849314033985138
step: 370, loss: 0.2063104510307312
step: 380, loss: 0.03929336741566658
step: 390, loss: 0.04692913964390755
step: 400, loss: 0.015771593898534775
step: 410, loss: 0.23587431013584137
step: 420, loss: 0.21877704560756683
epoch 3: dev_f1=0.6974951830443159, f1=0.6707818930041152, best_f1=0.6707818930041152
step: 0, loss: 0.08152729272842407
step: 10, loss: 0.029709098860621452
step: 20, loss: 0.03687923029065132
step: 30, loss: 0.02560598775744438
step: 40, loss: 0.06039925664663315
step: 50, loss: 0.01926719769835472
step: 60, loss: 0.024857036769390106
step: 70, loss: 0.009418909437954426
step: 80, loss: 0.08363500237464905
step: 90, loss: 0.004115762189030647
step: 100, loss: 0.15112952888011932
step: 110, loss: 0.07451101392507553
step: 120, loss: 0.04935843497514725
step: 130, loss: 0.0872545912861824
step: 140, loss: 0.2069380283355713
step: 150, loss: 0.060880690813064575
step: 160, loss: 0.08559741079807281
step: 170, loss: 0.07119420915842056
step: 180, loss: 0.05932682752609253
step: 190, loss: 0.011445488780736923
step: 200, loss: 0.022483710199594498
step: 210, loss: 0.006750983186066151
step: 220, loss: 0.23772865533828735
step: 230, loss: 0.09288288652896881
step: 240, loss: 0.038735080510377884
step: 250, loss: 0.04268098995089531
step: 260, loss: 0.1232302114367485
step: 270, loss: 0.11183654516935349
step: 280, loss: 0.016724565997719765
step: 290, loss: 0.1147553026676178
step: 300, loss: 0.20538417994976044
step: 310, loss: 0.03429106995463371
step: 320, loss: 0.1365714818239212
step: 330, loss: 0.1392851173877716
step: 340, loss: 0.02137993462383747
step: 350, loss: 0.14566583931446075
step: 360, loss: 0.12500913441181183
step: 370, loss: 0.016331350430846214
step: 380, loss: 0.16633780300617218
step: 390, loss: 0.03746505081653595
step: 400, loss: 0.04701780155301094
step: 410, loss: 0.019100142642855644
step: 420, loss: 0.03405878692865372
epoch 4: dev_f1=0.7250509164969449, f1=0.6960167714884696, best_f1=0.6960167714884696
step: 0, loss: 0.19215884804725647
step: 10, loss: 0.04236503317952156
step: 20, loss: 0.010855186730623245
step: 30, loss: 0.02241784892976284
step: 40, loss: 0.07122088223695755
step: 50, loss: 0.07170522212982178
step: 60, loss: 0.06555124372243881
step: 70, loss: 0.002477331319823861
step: 80, loss: 0.000940624566283077
step: 90, loss: 0.03653731942176819
step: 100, loss: 0.01273255329579115
step: 110, loss: 0.0031312103383243084
step: 120, loss: 0.07298725843429565
step: 130, loss: 0.03453440219163895
step: 140, loss: 0.009296625852584839
step: 150, loss: 0.0056917667388916016
step: 160, loss: 0.02954520285129547
step: 170, loss: 0.011627488769590855
step: 180, loss: 0.08174546808004379
step: 190, loss: 0.00506504625082016
step: 200, loss: 0.004160555079579353
step: 210, loss: 0.03956224396824837
step: 220, loss: 0.01929486356675625
step: 230, loss: 0.0059660375118255615
step: 240, loss: 0.046559784561395645
step: 250, loss: 0.012587888166308403
step: 260, loss: 0.014400333166122437
step: 270, loss: 0.009577630087733269
step: 280, loss: 0.01565590128302574
step: 290, loss: 0.0804930031299591
step: 300, loss: 0.03243372216820717
step: 310, loss: 0.12661351263523102
step: 320, loss: 0.04603063315153122
step: 330, loss: 0.0499565452337265
step: 340, loss: 0.06474059820175171
step: 350, loss: 0.009935101494193077
step: 360, loss: 0.011211307719349861
step: 370, loss: 0.021435268223285675
step: 380, loss: 0.0029545212164521217
step: 390, loss: 0.037950821220874786
step: 400, loss: 0.10330288857221603
step: 410, loss: 0.05582664534449577
step: 420, loss: 0.06826262921094894
epoch 5: dev_f1=0.7065868263473053, f1=0.6573146292585169, best_f1=0.6960167714884696
step: 0, loss: 0.01927793398499489
step: 10, loss: 0.015883607789874077
step: 20, loss: 0.0656985342502594
step: 30, loss: 0.018045803532004356
step: 40, loss: 0.041281163692474365
step: 50, loss: 0.007307481020689011
step: 60, loss: 0.055710189044475555
step: 70, loss: 0.04102480411529541
step: 80, loss: 0.08102336525917053
step: 90, loss: 0.01722118817269802
step: 100, loss: 0.012121769599616528
step: 110, loss: 0.03248974308371544
step: 120, loss: 0.004973601084202528
step: 130, loss: 0.029948728159070015
step: 140, loss: 0.004183302633464336
step: 150, loss: 0.005690721794962883
step: 160, loss: 0.056699488312006
step: 170, loss: 0.10896283388137817
step: 180, loss: 0.019520986825227737
step: 190, loss: 0.02966078743338585
step: 200, loss: 0.0015343173872679472
step: 210, loss: 0.003170355688780546
step: 220, loss: 0.0010886709205806255
step: 230, loss: 0.009411642327904701
step: 240, loss: 0.020965252071619034
step: 250, loss: 0.012905788607895374
step: 260, loss: 0.044030748307704926
step: 270, loss: 0.0286248866468668
step: 280, loss: 0.04216719791293144
step: 290, loss: 0.03261617571115494
step: 300, loss: 0.003383425297215581
step: 310, loss: 0.012972992844879627
step: 320, loss: 0.003963750321418047
step: 330, loss: 0.13926662504673004
step: 340, loss: 0.026475468650460243
step: 350, loss: 0.0010766781633719802
step: 360, loss: 0.01185606885701418
step: 370, loss: 0.0015209057601168752
step: 380, loss: 0.0024941759184002876
step: 390, loss: 0.01657579094171524
step: 400, loss: 0.0025268581230193377
step: 410, loss: 0.03046604059636593
step: 420, loss: 0.024437909945845604
epoch 6: dev_f1=0.7224489795918367, f1=0.679920477137177, best_f1=0.6960167714884696
step: 0, loss: 0.06067383289337158
step: 10, loss: 0.02661319635808468
step: 20, loss: 0.003747648326680064
step: 30, loss: 0.0045921956188976765
step: 40, loss: 0.0010607913136482239
step: 50, loss: 0.08481499552726746
step: 60, loss: 0.002104161772876978
step: 70, loss: 0.005816297139972448
step: 80, loss: 0.0026396336033940315
step: 90, loss: 0.019066715613007545
step: 100, loss: 0.055393435060977936
step: 110, loss: 0.010957173071801662
step: 120, loss: 0.002486138604581356
step: 130, loss: 0.0009213384473696351
step: 140, loss: 0.002786438912153244
step: 150, loss: 0.006721303332597017
step: 160, loss: 0.017938895151019096
step: 170, loss: 0.05034147948026657
step: 180, loss: 0.014943050220608711
step: 190, loss: 0.026517977938055992
step: 200, loss: 0.0362623892724514
step: 210, loss: 0.027590971440076828
step: 220, loss: 0.009741032496094704
step: 230, loss: 0.2439296990633011
step: 240, loss: 0.07234145700931549
step: 250, loss: 0.007290718145668507
step: 260, loss: 0.03582122176885605
step: 270, loss: 0.014562657102942467
step: 280, loss: 0.06916097551584244
step: 290, loss: 0.033840347081422806
step: 300, loss: 0.014200521633028984
step: 310, loss: 0.00025170197477564216
step: 320, loss: 0.00742809334769845
step: 330, loss: 0.06235789880156517
step: 340, loss: 0.017117708921432495
step: 350, loss: 0.021750155836343765
step: 360, loss: 0.10914076864719391
step: 370, loss: 0.0007319301948882639
step: 380, loss: 0.0009189642150886357
step: 390, loss: 0.060771893709897995
step: 400, loss: 0.11385472118854523
step: 410, loss: 0.01712886430323124
step: 420, loss: 0.04217590019106865
epoch 7: dev_f1=0.7261410788381742, f1=0.6977687626774849, best_f1=0.6977687626774849
step: 0, loss: 0.006383015774190426
step: 10, loss: 0.0015279813669621944
step: 20, loss: 0.0907387062907219
step: 30, loss: 0.04664372280240059
step: 40, loss: 0.0669855922460556
step: 50, loss: 0.015071302652359009
step: 60, loss: 0.0013640346005558968
step: 70, loss: 0.0010577153880149126
step: 80, loss: 0.005881056189537048
step: 90, loss: 0.03606894612312317
step: 100, loss: 0.0037696727085858583
step: 110, loss: 0.01908968761563301
step: 120, loss: 0.028331851586699486
step: 130, loss: 0.0011963439173996449
step: 140, loss: 0.0012456729309633374
step: 150, loss: 0.1595182567834854
step: 160, loss: 0.0024859325494617224
step: 170, loss: 0.01649036817252636
step: 180, loss: 0.01677987352013588
step: 190, loss: 0.009409015998244286
step: 200, loss: 0.04926830530166626
step: 210, loss: 0.001721851178444922
step: 220, loss: 0.050456978380680084
step: 230, loss: 0.13904699683189392
step: 240, loss: 0.00028527347603812814
step: 250, loss: 0.012295751832425594
step: 260, loss: 0.01697826012969017
step: 270, loss: 0.04315658658742905
step: 280, loss: 0.0010824758792296052
step: 290, loss: 0.00019683907157741487
step: 300, loss: 0.019389664754271507
step: 310, loss: 0.0007547858403995633
step: 320, loss: 0.003023739205673337
step: 330, loss: 0.07664374262094498
step: 340, loss: 0.001516883261501789
step: 350, loss: 0.03034207597374916
step: 360, loss: 0.01619655080139637
step: 370, loss: 0.030751889571547508
step: 380, loss: 0.001266509061679244
step: 390, loss: 0.11637568473815918
step: 400, loss: 0.1418941766023636
step: 410, loss: 0.030402280390262604
step: 420, loss: 0.01857893168926239
epoch 8: dev_f1=0.7280334728033474, f1=0.6905263157894737, best_f1=0.6905263157894737
step: 0, loss: 0.04713848978281021
step: 10, loss: 0.06679114699363708
step: 20, loss: 0.0865689292550087
step: 30, loss: 0.0016514826565980911
step: 40, loss: 0.0016439721221104264
step: 50, loss: 0.011558890342712402
step: 60, loss: 0.10450983047485352
step: 70, loss: 0.0017648087814450264
step: 80, loss: 0.048280928283929825
step: 90, loss: 0.07118092477321625
step: 100, loss: 0.12449035793542862
step: 110, loss: 0.031140541657805443
step: 120, loss: 0.0005620404845103621
step: 130, loss: 0.0021704237442463636
step: 140, loss: 0.04270603880286217
step: 150, loss: 0.0014990000054240227
step: 160, loss: 0.051858045160770416
step: 170, loss: 0.0013409494422376156
step: 180, loss: 0.004350308328866959
step: 190, loss: 0.015544083900749683
step: 200, loss: 0.0024338336661458015
step: 210, loss: 0.029861103743314743
step: 220, loss: 0.048728737980127335
step: 230, loss: 0.02673746645450592
step: 240, loss: 0.01699298806488514
step: 250, loss: 0.00010838986054295674
step: 260, loss: 0.00023205607431009412
step: 270, loss: 0.04845326393842697
step: 280, loss: 0.012646426446735859
step: 290, loss: 6.221945659490302e-05
step: 300, loss: 0.0018757187062874436
step: 310, loss: 0.07076362520456314
step: 320, loss: 0.0332861989736557
step: 330, loss: 0.027576562017202377
step: 340, loss: 0.007099694572389126
step: 350, loss: 0.05364372581243515
step: 360, loss: 0.0015448718331754208
step: 370, loss: 0.0034494653809815645
step: 380, loss: 0.010608135722577572
step: 390, loss: 0.0045294067822396755
step: 400, loss: 0.0008559824782423675
step: 410, loss: 0.018777117133140564
step: 420, loss: 0.010274182073771954
epoch 9: dev_f1=0.7242798353909465, f1=0.6970954356846473, best_f1=0.6905263157894737
step: 0, loss: 0.042880669236183167
step: 10, loss: 0.0012513385154306889
step: 20, loss: 0.00012638575572054833
step: 30, loss: 0.01163279078900814
step: 40, loss: 0.010153344832360744
step: 50, loss: 0.0014577091205865145
step: 60, loss: 0.003508112858980894
step: 70, loss: 0.001625637523829937
step: 80, loss: 0.01115372870117426
step: 90, loss: 0.019082559272646904
step: 100, loss: 0.031829770654439926
step: 110, loss: 0.00047855652519501746
step: 120, loss: 4.8105550376931205e-05
step: 130, loss: 0.0214373841881752
step: 140, loss: 0.052570778876543045
step: 150, loss: 0.037925660610198975
step: 160, loss: 0.020660556852817535
step: 170, loss: 0.0019347050692886114
step: 180, loss: 0.09865647554397583
step: 190, loss: 0.03140077739953995
step: 200, loss: 0.04035715013742447
step: 210, loss: 0.008862442336976528
step: 220, loss: 0.058031197637319565
step: 230, loss: 0.06378515809774399
step: 240, loss: 0.020374014973640442
step: 250, loss: 0.0024336539208889008
step: 260, loss: 0.0012187003158032894
step: 270, loss: 0.006959678139537573
step: 280, loss: 0.0015388677129521966
step: 290, loss: 0.0008855825290083885
step: 300, loss: 0.005539628677070141
step: 310, loss: 0.03145187720656395
step: 320, loss: 4.257023465470411e-05
step: 330, loss: 0.0004690114292316139
step: 340, loss: 0.0001046502948156558
step: 350, loss: 0.11358002573251724
step: 360, loss: 0.07896693795919418
step: 370, loss: 0.01042923517525196
step: 380, loss: 0.0006536026485264301
step: 390, loss: 0.0002911343181040138
step: 400, loss: 0.10803791880607605
step: 410, loss: 0.00022782772430218756
step: 420, loss: 0.0185177493840456
epoch 10: dev_f1=0.7484909456740444, f1=0.6778947368421052, best_f1=0.6778947368421052
step: 0, loss: 0.07240182161331177
step: 10, loss: 0.00899805873632431
step: 20, loss: 0.1352546513080597
step: 30, loss: 0.007122422102838755
step: 40, loss: 0.007477428764104843
step: 50, loss: 0.012678641825914383
step: 60, loss: 0.0001642871502554044
step: 70, loss: 0.0011724003124982119
step: 80, loss: 0.004108045250177383
step: 90, loss: 0.00016501324716955423
step: 100, loss: 0.0002192999527323991
step: 110, loss: 0.001466485671699047
step: 120, loss: 0.00017278347513638437
step: 130, loss: 0.021314408630132675
step: 140, loss: 0.04913196340203285
step: 150, loss: 0.0002758576883934438
step: 160, loss: 0.0005186022608540952
step: 170, loss: 0.0008479284588247538
step: 180, loss: 0.00018904077296610922
step: 190, loss: 7.374491542577744e-05
step: 200, loss: 0.011291171424090862
step: 210, loss: 0.05396178737282753
step: 220, loss: 0.03753993287682533
step: 230, loss: 0.0014332345454022288
step: 240, loss: 0.0034706960432231426
step: 250, loss: 0.011022252030670643
step: 260, loss: 0.00026621800498105586
step: 270, loss: 0.00020079509704373777
step: 280, loss: 0.00021702787489630282
step: 290, loss: 9.269052679883316e-05
step: 300, loss: 0.008540653623640537
step: 310, loss: 0.010433465242385864
step: 320, loss: 0.04140511900186539
step: 330, loss: 0.0004294942773412913
step: 340, loss: 0.0003833433729596436
step: 350, loss: 0.010790240950882435
step: 360, loss: 0.03008589893579483
step: 370, loss: 0.010508082807064056
step: 380, loss: 6.856489926576614e-05
step: 390, loss: 0.0052909948863089085
step: 400, loss: 0.07653706520795822
step: 410, loss: 0.0005759599152952433
step: 420, loss: 0.013605242595076561
epoch 11: dev_f1=0.7181628392484343, f1=0.6956521739130435, best_f1=0.6778947368421052
step: 0, loss: 6.315843347692862e-05
step: 10, loss: 0.007596442475914955
step: 20, loss: 0.013390987180173397
step: 30, loss: 0.009160533547401428
step: 40, loss: 6.899538857396692e-05
step: 50, loss: 0.02202865481376648
step: 60, loss: 0.0032571980264037848
step: 70, loss: 0.0001118242580560036
step: 80, loss: 0.003842433448880911
step: 90, loss: 0.010471032932400703
step: 100, loss: 0.000865279056597501
step: 110, loss: 0.005030517000705004
step: 120, loss: 0.0006826950702816248
step: 130, loss: 0.0021608832757920027
step: 140, loss: 0.04421965405344963
step: 150, loss: 0.0016211126931011677
step: 160, loss: 0.0009302741382271051
step: 170, loss: 0.02576959878206253
step: 180, loss: 0.101809561252594
step: 190, loss: 0.022939126938581467
step: 200, loss: 0.08790046721696854
step: 210, loss: 0.00814605038613081
step: 220, loss: 0.032506249845027924
step: 230, loss: 0.22350949048995972
step: 240, loss: 0.0405985526740551
step: 250, loss: 0.0004337239661253989
step: 260, loss: 0.0065525188110768795
step: 270, loss: 0.05098608136177063
step: 280, loss: 0.0002146822662325576
step: 290, loss: 0.0003146769304294139
step: 300, loss: 7.789325172780082e-05
step: 310, loss: 0.01567775011062622
step: 320, loss: 0.012898997403681278
step: 330, loss: 0.02426455356180668
step: 340, loss: 0.0015983950579538941
step: 350, loss: 3.950477912439965e-05
step: 360, loss: 0.0004888506955467165
step: 370, loss: 0.0013736658729612827
step: 380, loss: 0.0013569752918556333
step: 390, loss: 0.003316982416436076
step: 400, loss: 4.5803819375578314e-05
step: 410, loss: 0.006805223412811756
step: 420, loss: 0.01935962587594986
epoch 12: dev_f1=0.7183673469387755, f1=0.6799999999999999, best_f1=0.6778947368421052
step: 0, loss: 0.06708479672670364
step: 10, loss: 0.000150333609781228
step: 20, loss: 0.027386173605918884
step: 30, loss: 0.00015625727246515453
step: 40, loss: 0.025616874918341637
step: 50, loss: 0.10459741950035095
step: 60, loss: 0.0018163265194743872
step: 70, loss: 0.11071125417947769
step: 80, loss: 0.0006945943459868431
step: 90, loss: 0.0004103102255612612
step: 100, loss: 0.006626104936003685
step: 110, loss: 6.748685700586066e-05
step: 120, loss: 0.0005755149177275598
step: 130, loss: 5.7956818636739627e-05
step: 140, loss: 0.010772990062832832
step: 150, loss: 0.0010284095769748092
step: 160, loss: 8.243798220064491e-05
step: 170, loss: 0.20941278338432312
step: 180, loss: 0.09219957143068314
step: 190, loss: 0.002540940186008811
step: 200, loss: 0.0012803705176338553
step: 210, loss: 0.0019911862909793854
step: 220, loss: 0.0016051230486482382
step: 230, loss: 0.000970317458268255
step: 240, loss: 0.0002657109871506691
step: 250, loss: 0.00036359461955726147
step: 260, loss: 0.00014788030239287764
step: 270, loss: 0.00010454510629642755
step: 280, loss: 0.0013115295441821218
step: 290, loss: 0.010393486358225346
step: 300, loss: 0.00018051653751172125
step: 310, loss: 0.00027084563043899834
step: 320, loss: 0.004406082443892956
step: 330, loss: 0.01623990386724472
step: 340, loss: 0.13991178572177887
step: 350, loss: 0.14886756241321564
step: 360, loss: 0.0005385481636039913
step: 370, loss: 0.0061844042502343655
step: 380, loss: 0.005226388573646545
step: 390, loss: 0.08691074699163437
step: 400, loss: 0.006216065958142281
step: 410, loss: 0.016285285353660583
step: 420, loss: 0.0012912347447127104
epoch 13: dev_f1=0.7232323232323232, f1=0.6666666666666666, best_f1=0.6778947368421052
step: 0, loss: 0.0010741740697994828
step: 10, loss: 0.0005257117445580661
step: 20, loss: 0.043324388563632965
step: 30, loss: 0.005160562694072723
step: 40, loss: 0.004536425229161978
step: 50, loss: 0.0022407586220651865
step: 60, loss: 0.0003186825488228351
step: 70, loss: 0.000453540647868067
step: 80, loss: 0.02907317318022251
step: 90, loss: 0.05025194585323334
step: 100, loss: 0.03208234906196594
step: 110, loss: 0.0002224656054750085
step: 120, loss: 0.029495403170585632
step: 130, loss: 0.00010276463581249118
step: 140, loss: 0.03619438037276268
step: 150, loss: 0.0005078386748209596
step: 160, loss: 8.18659900687635e-05
step: 170, loss: 0.0027665686793625355
step: 180, loss: 0.00014711370749864727
step: 190, loss: 0.035789888352155685
step: 200, loss: 0.011530439369380474
step: 210, loss: 0.01213415339589119
step: 220, loss: 0.00016288610640913248
step: 230, loss: 8.757913019508123e-05
step: 240, loss: 0.022797463461756706
step: 250, loss: 0.037810903042554855
step: 260, loss: 0.0008220289601013064
step: 270, loss: 0.0007809175294823945
step: 280, loss: 0.025327980518341064
step: 290, loss: 0.001881744829006493
step: 300, loss: 8.845749835018069e-05
step: 310, loss: 0.0025537919718772173
step: 320, loss: 0.0011313922004774213
step: 330, loss: 8.15279345260933e-05
step: 340, loss: 0.000340785802109167
step: 350, loss: 0.0011601116275414824
step: 360, loss: 0.0016193741466850042
step: 370, loss: 0.05504223331809044
step: 380, loss: 0.02975662797689438
step: 390, loss: 0.0010238070972263813
step: 400, loss: 0.00012185489322291687
step: 410, loss: 0.0002577757986728102
step: 420, loss: 0.0007763032917864621
epoch 14: dev_f1=0.6940639269406393, f1=0.6352941176470589, best_f1=0.6778947368421052
step: 0, loss: 0.0003882987075485289
step: 10, loss: 0.0008868263685144484
step: 20, loss: 0.014461633749306202
step: 30, loss: 0.00045015732757747173
step: 40, loss: 0.025739189237356186
step: 50, loss: 0.10065009444952011
step: 60, loss: 0.0002550517092458904
step: 70, loss: 0.0009639029740355909
step: 80, loss: 0.00037452561082318425
step: 90, loss: 5.3046558605274186e-05
step: 100, loss: 0.009808216243982315
step: 110, loss: 4.203085700282827e-05
step: 120, loss: 0.0005047330050729215
step: 130, loss: 0.08530711382627487
step: 140, loss: 0.0050140246748924255
step: 150, loss: 0.00034500210313126445
step: 160, loss: 0.10112453252077103
step: 170, loss: 0.00018075847765430808
step: 180, loss: 0.047826267778873444
step: 190, loss: 0.006278645247220993
step: 200, loss: 0.000127991967019625
step: 210, loss: 0.002318496350198984
step: 220, loss: 0.0045374371111392975
step: 230, loss: 0.0007420119363814592
step: 240, loss: 0.000945170468185097
step: 250, loss: 0.0004046852409373969
step: 260, loss: 0.03185652196407318
step: 270, loss: 0.002651939867064357
step: 280, loss: 0.0019304454326629639
step: 290, loss: 0.001042382325977087
step: 300, loss: 0.00016158823564182967
step: 310, loss: 0.007973545230925083
step: 320, loss: 0.00013308490451890975
step: 330, loss: 3.4775952372001484e-05
step: 340, loss: 8.022844122024253e-05
step: 350, loss: 0.0009845818858593702
step: 360, loss: 0.019546600058674812
step: 370, loss: 0.0009316133218817413
step: 380, loss: 0.014603509567677975
step: 390, loss: 0.0003517399018164724
step: 400, loss: 0.000583765038754791
step: 410, loss: 0.1466997116804123
step: 420, loss: 0.010299296118319035
epoch 15: dev_f1=0.7165991902834008, f1=0.6680497925311204, best_f1=0.6778947368421052
step: 0, loss: 0.0007559729856438935
step: 10, loss: 0.008772334083914757
step: 20, loss: 0.0007857522577978671
step: 30, loss: 0.000244358234340325
step: 40, loss: 0.0005796371260657907
step: 50, loss: 0.00014026716235093772
step: 60, loss: 0.0048093171790242195
step: 70, loss: 0.0037701709661632776
step: 80, loss: 0.007521402090787888
step: 90, loss: 3.061995084863156e-05
step: 100, loss: 0.015683380886912346
step: 110, loss: 0.0004510704311542213
step: 120, loss: 0.0002873835328500718
step: 130, loss: 9.403208241565153e-05
step: 140, loss: 9.435415995540097e-05
step: 150, loss: 0.00028144370298832655
step: 160, loss: 0.03234456107020378
step: 170, loss: 0.0028736849781125784
step: 180, loss: 4.273719969205558e-05
step: 190, loss: 0.02600843459367752
step: 200, loss: 7.326096965698525e-05
step: 210, loss: 9.478316496824846e-05
step: 220, loss: 0.003931916784495115
step: 230, loss: 0.03772350773215294
step: 240, loss: 0.00020290141401346773
step: 250, loss: 7.08274164935574e-05
step: 260, loss: 7.44674980523996e-05
step: 270, loss: 0.0003357569221407175
step: 280, loss: 0.00010217521048616618
step: 290, loss: 3.164834561175667e-05
step: 300, loss: 0.0024303870741277933
step: 310, loss: 0.00011742790957214311
step: 320, loss: 8.755410817684606e-05
step: 330, loss: 5.84714871365577e-05
step: 340, loss: 0.006755946669727564
step: 350, loss: 0.0005769543931819499
step: 360, loss: 0.00291519146412611
step: 370, loss: 0.036434099078178406
step: 380, loss: 0.0005285143270157278
step: 390, loss: 0.0437701940536499
step: 400, loss: 0.02545936219394207
step: 410, loss: 2.185958146583289e-05
step: 420, loss: 0.0042061107233166695
epoch 16: dev_f1=0.6978922716627634, f1=0.6474820143884893, best_f1=0.6778947368421052
step: 0, loss: 0.0009430564241483808
step: 10, loss: 0.043365105986595154
step: 20, loss: 0.0016760868020355701
step: 30, loss: 0.005750608164817095
step: 40, loss: 0.0006359789404086769
step: 50, loss: 6.815201049903408e-05
step: 60, loss: 0.0010203937999904156
step: 70, loss: 4.8786590923555195e-05
step: 80, loss: 5.478636012412608e-05
step: 90, loss: 0.03250245377421379
step: 100, loss: 9.429967758478597e-05
step: 110, loss: 0.0008261647308245301
step: 120, loss: 0.00014880462549626827
step: 130, loss: 0.0004851020057685673
step: 140, loss: 2.803204915835522e-05
step: 150, loss: 0.0012274902546778321
step: 160, loss: 6.161630153656006e-05
step: 170, loss: 4.5794222387485206e-05
step: 180, loss: 5.392040839069523e-05
step: 190, loss: 6.911013042554259e-05
step: 200, loss: 0.0011238829465582967
step: 210, loss: 0.0003265923005528748
step: 220, loss: 0.0010970064904540777
step: 230, loss: 0.04079122841358185
step: 240, loss: 5.603261524811387e-05
step: 250, loss: 0.011916141957044601
step: 260, loss: 0.00019957529730163515
step: 270, loss: 0.0005474156350828707
step: 280, loss: 0.0005450957105495036
step: 290, loss: 0.003999135922640562
step: 300, loss: 0.0014310635160654783
step: 310, loss: 0.0013800004962831736
step: 320, loss: 0.00017287759692408144
step: 330, loss: 3.9953869418241084e-05
step: 340, loss: 0.0006800907431170344
step: 350, loss: 0.02002597786486149
step: 360, loss: 0.08519492298364639
step: 370, loss: 0.02643880806863308
step: 380, loss: 0.0006262235110625625
step: 390, loss: 8.659722516313195e-05
step: 400, loss: 0.007408604491502047
step: 410, loss: 0.00023918235092423856
step: 420, loss: 0.03340442478656769
epoch 17: dev_f1=0.698901098901099, f1=0.6651480637813212, best_f1=0.6778947368421052
step: 0, loss: 5.553041773964651e-05
step: 10, loss: 6.296948413364589e-05
step: 20, loss: 0.00023555755615234375
step: 30, loss: 0.00012549203529488295
step: 40, loss: 0.0001484531967435032
step: 50, loss: 0.00045984413009136915
step: 60, loss: 0.0007041134522296488
step: 70, loss: 0.00014166865730658174
step: 80, loss: 0.00019869151583407074
step: 90, loss: 0.0003406996256671846
step: 100, loss: 6.355505320243537e-05
step: 110, loss: 0.0005268838140182197
step: 120, loss: 9.261656668968499e-05
step: 130, loss: 8.296528540086001e-05
step: 140, loss: 0.001018290757201612
step: 150, loss: 3.506809298414737e-05
step: 160, loss: 0.0013665435835719109
step: 170, loss: 0.0001369085512124002
step: 180, loss: 0.00023246443015523255
step: 190, loss: 0.00023154843074735254
step: 200, loss: 0.044318199157714844
step: 210, loss: 0.028694873675704002
step: 220, loss: 0.023530637845396996
step: 230, loss: 0.0003364932781551033
step: 240, loss: 3.3351327147101983e-05
step: 250, loss: 0.010198989883065224
step: 260, loss: 0.0011985708260908723
step: 270, loss: 0.03414807841181755
step: 280, loss: 0.012297638691961765
step: 290, loss: 0.000982097233645618
step: 300, loss: 0.004823659081012011
step: 310, loss: 0.00023987806343939155
step: 320, loss: 0.10952837765216827
step: 330, loss: 0.005174129270017147
step: 340, loss: 2.9499798984033987e-05
step: 350, loss: 0.00608285516500473
step: 360, loss: 4.628301758202724e-05
step: 370, loss: 0.00019076235184911638
step: 380, loss: 5.759147461503744e-05
step: 390, loss: 0.031783901154994965
step: 400, loss: 0.0001616123627172783
step: 410, loss: 0.0023444558028131723
step: 420, loss: 8.905843424145132e-05
epoch 18: dev_f1=0.7071583514099783, f1=0.6608315098468271, best_f1=0.6778947368421052
step: 0, loss: 5.1231952966190875e-05
step: 10, loss: 7.440797344315797e-05
step: 20, loss: 9.70859982771799e-05
step: 30, loss: 0.0001614727807464078
step: 40, loss: 0.0020984834991395473
step: 50, loss: 0.000357196171535179
step: 60, loss: 0.0013984048273414373
step: 70, loss: 4.0763301512924954e-05
step: 80, loss: 0.011648657731711864
step: 90, loss: 4.704262755694799e-05
step: 100, loss: 0.020779764279723167
step: 110, loss: 0.007635803893208504
step: 120, loss: 0.014465962536633015
step: 130, loss: 0.00033014549990184605
step: 140, loss: 0.00017926438886206597
step: 150, loss: 0.0009204511879943311
step: 160, loss: 0.007838614284992218
step: 170, loss: 0.00013249920448288321
step: 180, loss: 0.0002785100368782878
step: 190, loss: 0.05398638918995857
step: 200, loss: 0.007851781323552132
step: 210, loss: 0.0005787668633274734
step: 220, loss: 0.0002731403219513595
step: 230, loss: 0.00010726619802881032
step: 240, loss: 9.934785339282826e-05
step: 250, loss: 4.0225790144177154e-05
step: 260, loss: 0.00011291140981484205
step: 270, loss: 7.009394175838679e-05
step: 280, loss: 0.012781561352312565
step: 290, loss: 0.00031671012402512133
step: 300, loss: 0.008779682219028473
step: 310, loss: 8.556999091524631e-05
step: 320, loss: 0.0007422820199280977
step: 330, loss: 5.3531119192484766e-05
step: 340, loss: 0.004668684210628271
step: 350, loss: 3.872987144859508e-05
step: 360, loss: 0.00013383255281951278
step: 370, loss: 4.722912854049355e-05
step: 380, loss: 0.00048172156675718725
step: 390, loss: 6.761834083590657e-05
step: 400, loss: 0.0009794550715014338
step: 410, loss: 0.00015623219951521605
step: 420, loss: 6.498069706140086e-05
epoch 19: dev_f1=0.7071583514099783, f1=0.6579520697167756, best_f1=0.6778947368421052
step: 0, loss: 0.00017687866056803614
step: 10, loss: 0.0001009972402243875
step: 20, loss: 0.00041384456562809646
step: 30, loss: 2.504454823792912e-05
step: 40, loss: 0.0006055302219465375
step: 50, loss: 0.00015553949924651533
step: 60, loss: 3.29967551806476e-05
step: 70, loss: 0.0004163466510362923
step: 80, loss: 0.00717157544568181
step: 90, loss: 5.335971218300983e-05
step: 100, loss: 0.00010449948604218662
step: 110, loss: 0.0002486086741555482
step: 120, loss: 0.00012635164603125304
step: 130, loss: 5.333152148523368e-05
step: 140, loss: 0.01235269010066986
step: 150, loss: 0.0002378320205025375
step: 160, loss: 5.731753117288463e-05
step: 170, loss: 8.515652734786272e-05
step: 180, loss: 0.003970634657889605
step: 190, loss: 0.0009573374991305172
step: 200, loss: 2.6716130378190428e-05
step: 210, loss: 0.06412213295698166
step: 220, loss: 4.136170173296705e-05
step: 230, loss: 0.0002824030234478414
step: 240, loss: 0.003867724211886525
step: 250, loss: 5.510219489224255e-05
step: 260, loss: 0.0024425312876701355
step: 270, loss: 8.191260712919757e-05
step: 280, loss: 0.03843402490019798
step: 290, loss: 0.003998306579887867
step: 300, loss: 0.0016421976033598185
step: 310, loss: 0.00313580478541553
step: 320, loss: 0.00017278715677093714
step: 330, loss: 0.01712757535278797
step: 340, loss: 0.0050808461382985115
step: 350, loss: 0.0006574989529326558
step: 360, loss: 0.00030667302780784667
step: 370, loss: 0.0001752680545905605
step: 380, loss: 0.0001913114101625979
step: 390, loss: 0.00035612125066109
step: 400, loss: 0.00015331216854974627
step: 410, loss: 0.0015906018670648336
step: 420, loss: 0.0002340841747354716
epoch 20: dev_f1=0.7012987012987013, f1=0.6607929515418502, best_f1=0.6778947368421052
