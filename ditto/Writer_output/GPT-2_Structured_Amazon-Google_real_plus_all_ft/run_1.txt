cuda
Device: cuda
step: 0, loss: 0.6190657615661621
step: 10, loss: 0.45256853103637695
step: 20, loss: 0.11998569220304489
step: 30, loss: 0.3344082534313202
step: 40, loss: 0.3588491678237915
step: 50, loss: 0.17180171608924866
step: 60, loss: 0.2884122133255005
step: 70, loss: 0.20847804844379425
step: 80, loss: 0.31979140639305115
step: 90, loss: 0.24544428288936615
step: 100, loss: 0.28096717596054077
step: 110, loss: 0.2698686718940735
step: 120, loss: 0.5080684423446655
step: 130, loss: 0.2753027677536011
step: 140, loss: 0.07534036040306091
step: 150, loss: 0.19707553088665009
step: 160, loss: 0.24507322907447815
step: 170, loss: 0.14728160202503204
step: 180, loss: 0.20292896032333374
step: 190, loss: 0.10623583197593689
step: 200, loss: 0.09900419414043427
step: 210, loss: 0.21034613251686096
step: 220, loss: 0.05052075535058975
step: 230, loss: 0.39714330434799194
step: 240, loss: 0.11408785730600357
step: 250, loss: 0.11221994459629059
step: 260, loss: 0.15314069390296936
step: 270, loss: 0.13669168949127197
step: 280, loss: 0.12261927872896194
step: 290, loss: 0.18977531790733337
step: 300, loss: 0.3561677038669586
step: 310, loss: 0.1334059238433838
step: 320, loss: 0.3155326247215271
step: 330, loss: 0.3896920382976532
step: 340, loss: 0.1649489849805832
step: 350, loss: 0.10897225141525269
step: 360, loss: 0.006301307585090399
step: 370, loss: 0.16663509607315063
step: 380, loss: 0.12735286355018616
step: 390, loss: 0.13590313494205475
step: 400, loss: 0.06925681978464127
step: 410, loss: 0.34441882371902466
step: 420, loss: 0.04518032446503639
epoch 1: dev_f1=0.6581740976645435, f1=0.5702127659574469, best_f1=0.5702127659574469
step: 0, loss: 0.02835918217897415
step: 10, loss: 0.19327685236930847
step: 20, loss: 0.2185109555721283
step: 30, loss: 0.10544092953205109
step: 40, loss: 0.0656697154045105
step: 50, loss: 0.2113952338695526
step: 60, loss: 0.10921867191791534
step: 70, loss: 0.09824515134096146
step: 80, loss: 0.053209930658340454
step: 90, loss: 0.03724003583192825
step: 100, loss: 0.15176308155059814
step: 110, loss: 0.11281807720661163
step: 120, loss: 0.08589493483304977
step: 130, loss: 0.10792586952447891
step: 140, loss: 0.2508623003959656
step: 150, loss: 0.06364868581295013
step: 160, loss: 0.03205014765262604
step: 170, loss: 0.1703643947839737
step: 180, loss: 0.21120722591876984
step: 190, loss: 0.08624961972236633
step: 200, loss: 0.04052704572677612
step: 210, loss: 0.12185952067375183
step: 220, loss: 0.24095003306865692
step: 230, loss: 0.09364385902881622
step: 240, loss: 0.07135143131017685
step: 250, loss: 0.09530346095561981
step: 260, loss: 0.2633182406425476
step: 270, loss: 0.1440170258283615
step: 280, loss: 0.08018217980861664
step: 290, loss: 0.058629803359508514
step: 300, loss: 0.18881742656230927
step: 310, loss: 0.2927916646003723
step: 320, loss: 0.11961082369089127
step: 330, loss: 0.08038715273141861
step: 340, loss: 0.13476267457008362
step: 350, loss: 0.02597540244460106
step: 360, loss: 0.2901025414466858
step: 370, loss: 0.09024509787559509
step: 380, loss: 0.09546750038862228
step: 390, loss: 0.08580713719129562
step: 400, loss: 0.040670353919267654
step: 410, loss: 0.15230485796928406
step: 420, loss: 0.22314196825027466
epoch 2: dev_f1=0.6878980891719746, f1=0.6174496644295302, best_f1=0.6174496644295302
step: 0, loss: 0.140422523021698
step: 10, loss: 0.06572829931974411
step: 20, loss: 0.0907745286822319
step: 30, loss: 0.08665196597576141
step: 40, loss: 0.04012336581945419
step: 50, loss: 0.00987932737916708
step: 60, loss: 0.02078825607895851
step: 70, loss: 0.26154035329818726
step: 80, loss: 0.003649621969088912
step: 90, loss: 0.22096890211105347
step: 100, loss: 0.08235606551170349
step: 110, loss: 0.0708354264497757
step: 120, loss: 0.01048497948795557
step: 130, loss: 0.06471867114305496
step: 140, loss: 0.015772243961691856
step: 150, loss: 0.13292011618614197
step: 160, loss: 0.3368850648403168
step: 170, loss: 0.1547151356935501
step: 180, loss: 0.0431516207754612
step: 190, loss: 0.041071828454732895
step: 200, loss: 0.0933779776096344
step: 210, loss: 0.02472119964659214
step: 220, loss: 0.01818920485675335
step: 230, loss: 0.1644836962223053
step: 240, loss: 0.04912268742918968
step: 250, loss: 0.004705330356955528
step: 260, loss: 0.11156951636075974
step: 270, loss: 0.06638681143522263
step: 280, loss: 0.07863913476467133
step: 290, loss: 0.230031818151474
step: 300, loss: 0.01791967824101448
step: 310, loss: 0.03712572902441025
step: 320, loss: 0.106804758310318
step: 330, loss: 0.05229661613702774
step: 340, loss: 0.10456914454698563
step: 350, loss: 0.16620634496212006
step: 360, loss: 0.1819201111793518
step: 370, loss: 0.04271749407052994
step: 380, loss: 0.02840747870504856
step: 390, loss: 0.0427444763481617
step: 400, loss: 0.09283329546451569
step: 410, loss: 0.04957996681332588
step: 420, loss: 0.07998234033584595
epoch 3: dev_f1=0.7029288702928871, f1=0.6272727272727273, best_f1=0.6272727272727273
step: 0, loss: 0.04960460588335991
step: 10, loss: 0.0350545197725296
step: 20, loss: 0.03015957958996296
step: 30, loss: 0.13925693929195404
step: 40, loss: 0.06342574208974838
step: 50, loss: 0.177132248878479
step: 60, loss: 0.008794710040092468
step: 70, loss: 0.03963591158390045
step: 80, loss: 0.11169715225696564
step: 90, loss: 0.10961900651454926
step: 100, loss: 0.01906784437596798
step: 110, loss: 0.027000129222869873
step: 120, loss: 0.1548788994550705
step: 130, loss: 0.08556931465864182
step: 140, loss: 0.03432488068938255
step: 150, loss: 0.068484365940094
step: 160, loss: 0.058033980429172516
step: 170, loss: 0.03204384818673134
step: 180, loss: 0.06969492137432098
step: 190, loss: 0.044746458530426025
step: 200, loss: 0.004206150304526091
step: 210, loss: 0.2506851553916931
step: 220, loss: 0.04283785820007324
step: 230, loss: 0.11089774966239929
step: 240, loss: 0.09312950819730759
step: 250, loss: 0.056122954934835434
step: 260, loss: 0.017853127792477608
step: 270, loss: 0.026379546150565147
step: 280, loss: 0.022392969578504562
step: 290, loss: 0.011227626353502274
step: 300, loss: 0.09896653890609741
step: 310, loss: 0.19768302142620087
step: 320, loss: 0.1035177931189537
step: 330, loss: 0.0788094699382782
step: 340, loss: 0.014289519749581814
step: 350, loss: 0.03373746573925018
step: 360, loss: 0.01953539252281189
step: 370, loss: 0.0021985128987580538
step: 380, loss: 0.16027623414993286
step: 390, loss: 0.013248533941805363
step: 400, loss: 0.06875614821910858
step: 410, loss: 0.08714482188224792
step: 420, loss: 0.11322792619466782
epoch 4: dev_f1=0.7329434697855752, f1=0.6626506024096386, best_f1=0.6626506024096386
step: 0, loss: 0.093355193734169
step: 10, loss: 0.05563144013285637
step: 20, loss: 0.017595339566469193
step: 30, loss: 0.09490863978862762
step: 40, loss: 0.03649759665131569
step: 50, loss: 0.01702113263309002
step: 60, loss: 0.09513334929943085
step: 70, loss: 0.1721838414669037
step: 80, loss: 0.020883584395051003
step: 90, loss: 0.029356641694903374
step: 100, loss: 0.038876455277204514
step: 110, loss: 0.0376206710934639
step: 120, loss: 0.07801269739866257
step: 130, loss: 0.16574974358081818
step: 140, loss: 0.0028845220804214478
step: 150, loss: 0.03526593744754791
step: 160, loss: 0.09645695239305496
step: 170, loss: 0.036870043724775314
step: 180, loss: 0.018597926944494247
step: 190, loss: 0.0065296487882733345
step: 200, loss: 0.005157622508704662
step: 210, loss: 0.008410283364355564
step: 220, loss: 0.027507280930876732
step: 230, loss: 0.04767313599586487
step: 240, loss: 0.15042687952518463
step: 250, loss: 0.025340808555483818
step: 260, loss: 0.0421980582177639
step: 270, loss: 0.030109809711575508
step: 280, loss: 0.0449596643447876
step: 290, loss: 0.062189262360334396
step: 300, loss: 0.1469934582710266
step: 310, loss: 0.01286481972783804
step: 320, loss: 0.04063022881746292
step: 330, loss: 0.0023349421098828316
step: 340, loss: 0.24991224706172943
step: 350, loss: 0.05026960000395775
step: 360, loss: 0.08059612661600113
step: 370, loss: 0.07936123013496399
step: 380, loss: 0.005071795079857111
step: 390, loss: 0.006130163557827473
step: 400, loss: 0.013123647309839725
step: 410, loss: 0.010399681515991688
step: 420, loss: 0.048130102455616
epoch 5: dev_f1=0.7184035476718404, f1=0.64, best_f1=0.6626506024096386
step: 0, loss: 0.027447527274489403
step: 10, loss: 0.009464861825108528
step: 20, loss: 0.004210976418107748
step: 30, loss: 0.002550477394834161
step: 40, loss: 0.0003579373296815902
step: 50, loss: 0.03704873099923134
step: 60, loss: 0.0229810643941164
step: 70, loss: 0.06206401810050011
step: 80, loss: 0.07591395825147629
step: 90, loss: 0.0481315478682518
step: 100, loss: 0.007098085712641478
step: 110, loss: 0.026135366410017014
step: 120, loss: 0.06945070624351501
step: 130, loss: 0.036749083548784256
step: 140, loss: 0.01963481307029724
step: 150, loss: 0.0012435548705980182
step: 160, loss: 0.17300015687942505
step: 170, loss: 0.022781729698181152
step: 180, loss: 0.021748866885900497
step: 190, loss: 0.10187123715877533
step: 200, loss: 0.0894818976521492
step: 210, loss: 0.0036166806239634752
step: 220, loss: 0.10881935805082321
step: 230, loss: 0.006180108059197664
step: 240, loss: 0.037730392068624496
step: 250, loss: 0.039397113025188446
step: 260, loss: 0.13033653795719147
step: 270, loss: 0.04112005606293678
step: 280, loss: 0.0031166665721684694
step: 290, loss: 0.042765308171510696
step: 300, loss: 0.03343643993139267
step: 310, loss: 0.04660480096936226
step: 320, loss: 0.0037941683549433947
step: 330, loss: 0.06127794086933136
step: 340, loss: 0.05846501141786575
step: 350, loss: 0.033218950033187866
step: 360, loss: 0.005421996116638184
step: 370, loss: 0.019319046288728714
step: 380, loss: 0.04514198750257492
step: 390, loss: 0.046327266842126846
step: 400, loss: 0.001196746015921235
step: 410, loss: 0.023074360564351082
step: 420, loss: 0.12390382587909698
epoch 6: dev_f1=0.7276422764227642, f1=0.6585858585858585, best_f1=0.6626506024096386
step: 0, loss: 0.024508865550160408
step: 10, loss: 0.002182179596275091
step: 20, loss: 0.018097659572958946
step: 30, loss: 0.014867658726871014
step: 40, loss: 0.0706321969628334
step: 50, loss: 0.004893131088465452
step: 60, loss: 0.060612406581640244
step: 70, loss: 0.0661226436495781
step: 80, loss: 0.022388553246855736
step: 90, loss: 0.0016618893714621663
step: 100, loss: 0.0867585614323616
step: 110, loss: 0.021555710583925247
step: 120, loss: 0.0286933034658432
step: 130, loss: 0.01340074185281992
step: 140, loss: 0.022114155814051628
step: 150, loss: 0.030647117644548416
step: 160, loss: 0.0009610537090338767
step: 170, loss: 0.009256703779101372
step: 180, loss: 0.0016438032034784555
step: 190, loss: 0.1404409557580948
step: 200, loss: 0.023110145702958107
step: 210, loss: 0.058619800955057144
step: 220, loss: 0.006567523814737797
step: 230, loss: 0.012094461359083652
step: 240, loss: 0.048894088715314865
step: 250, loss: 0.10176397114992142
step: 260, loss: 0.030813461169600487
step: 270, loss: 0.004985112696886063
step: 280, loss: 0.08460311591625214
step: 290, loss: 0.009492896497249603
step: 300, loss: 0.00601574219763279
step: 310, loss: 0.04454904422163963
step: 320, loss: 0.014154826290905476
step: 330, loss: 0.03972550109028816
step: 340, loss: 0.01252719759941101
step: 350, loss: 0.08456767350435257
step: 360, loss: 0.03922659903764725
step: 370, loss: 0.006869893986731768
step: 380, loss: 0.006958479061722755
step: 390, loss: 0.03309103846549988
step: 400, loss: 0.01569432206451893
step: 410, loss: 0.007307020016014576
step: 420, loss: 0.054855357855558395
epoch 7: dev_f1=0.7167630057803468, f1=0.6944971537001896, best_f1=0.6626506024096386
step: 0, loss: 0.0040123783983290195
step: 10, loss: 0.001601140364073217
step: 20, loss: 0.0028997836634516716
step: 30, loss: 0.22037988901138306
step: 40, loss: 0.0488484650850296
step: 50, loss: 0.0004560275701805949
step: 60, loss: 0.049914486706256866
step: 70, loss: 0.1477445662021637
step: 80, loss: 0.0027339996304363012
step: 90, loss: 0.04003313556313515
step: 100, loss: 0.002393989125266671
step: 110, loss: 0.014358585700392723
step: 120, loss: 0.03381042554974556
step: 130, loss: 0.00030497516854666173
step: 140, loss: 0.00829178187996149
step: 150, loss: 0.03707036375999451
step: 160, loss: 0.005788916721940041
step: 170, loss: 0.010632307268679142
step: 180, loss: 0.029720043763518333
step: 190, loss: 0.003790757618844509
step: 200, loss: 0.012218508869409561
step: 210, loss: 0.00040184237877838314
step: 220, loss: 0.0013164012925699353
step: 230, loss: 0.0018142123008146882
step: 240, loss: 0.002605746267363429
step: 250, loss: 0.14976419508457184
step: 260, loss: 0.05714447423815727
step: 270, loss: 0.08432413637638092
step: 280, loss: 0.005909429397433996
step: 290, loss: 0.04166989400982857
step: 300, loss: 0.0658465325832367
step: 310, loss: 0.04802384972572327
step: 320, loss: 0.004225867800414562
step: 330, loss: 0.012189512141048908
step: 340, loss: 0.0001961778907570988
step: 350, loss: 0.03640570119023323
step: 360, loss: 0.0039142523892223835
step: 370, loss: 0.0002799708745442331
step: 380, loss: 0.0002248291566502303
step: 390, loss: 0.00030084760510362685
step: 400, loss: 0.09987236559391022
step: 410, loss: 0.060766007751226425
step: 420, loss: 0.0040881396271288395
epoch 8: dev_f1=0.732824427480916, f1=0.66793893129771, best_f1=0.6626506024096386
step: 0, loss: 0.0012231110595166683
step: 10, loss: 0.0025938767939805984
step: 20, loss: 0.1316162794828415
step: 30, loss: 0.005844824016094208
step: 40, loss: 0.00043674110202118754
step: 50, loss: 0.0009662263328209519
step: 60, loss: 0.006405448075383902
step: 70, loss: 0.0426902212202549
step: 80, loss: 0.00599664868786931
step: 90, loss: 0.0130302794277668
step: 100, loss: 0.0010207598097622395
step: 110, loss: 0.07239707559347153
step: 120, loss: 0.003311056410893798
step: 130, loss: 0.05075034126639366
step: 140, loss: 0.0032475520856678486
step: 150, loss: 0.0032285789493471384
step: 160, loss: 0.025444919243454933
step: 170, loss: 0.004076304379850626
step: 180, loss: 0.0020047849975526333
step: 190, loss: 0.0018888962222263217
step: 200, loss: 0.04133045673370361
step: 210, loss: 0.035272881388664246
step: 220, loss: 0.0016537823248654604
step: 230, loss: 0.0006247715791687369
step: 240, loss: 0.002599327126517892
step: 250, loss: 0.026830796152353287
step: 260, loss: 0.1427263468503952
step: 270, loss: 0.0028350085485726595
step: 280, loss: 0.001422728761099279
step: 290, loss: 0.05381966754794121
step: 300, loss: 0.00022779700520914048
step: 310, loss: 0.012731412425637245
step: 320, loss: 0.02829514443874359
step: 330, loss: 0.08334030956029892
step: 340, loss: 0.01149704959243536
step: 350, loss: 0.0007972847670316696
step: 360, loss: 0.000935978488996625
step: 370, loss: 0.03969210758805275
step: 380, loss: 0.002992682857438922
step: 390, loss: 0.11736935377120972
step: 400, loss: 0.0064134313724935055
step: 410, loss: 0.00018978313892148435
step: 420, loss: 0.031206363812088966
epoch 9: dev_f1=0.72, f1=0.670611439842209, best_f1=0.6626506024096386
step: 0, loss: 0.04505457729101181
step: 10, loss: 0.0014299782924354076
step: 20, loss: 9.265483095077798e-05
step: 30, loss: 0.001955046784132719
step: 40, loss: 0.0010815993882715702
step: 50, loss: 0.0045461710542440414
step: 60, loss: 0.005230023059993982
step: 70, loss: 0.09197631478309631
step: 80, loss: 0.01142864115536213
step: 90, loss: 0.00018914321844931692
step: 100, loss: 0.04984001815319061
step: 110, loss: 0.001164303277619183
step: 120, loss: 0.00014900253154337406
step: 130, loss: 0.00015349178283941
step: 140, loss: 0.00037483411142602563
step: 150, loss: 0.0038290719967335463
step: 160, loss: 0.000157825110363774
step: 170, loss: 0.00444259587675333
step: 180, loss: 0.0008201549644581974
step: 190, loss: 7.813743286533281e-05
step: 200, loss: 0.03247668221592903
step: 210, loss: 0.00023202622833196074
step: 220, loss: 0.0015608182875439525
step: 230, loss: 0.00020827770640607923
step: 240, loss: 0.06093430146574974
step: 250, loss: 0.0001671202335273847
step: 260, loss: 0.0129414526745677
step: 270, loss: 0.011647788807749748
step: 280, loss: 0.019572023302316666
step: 290, loss: 0.07580563426017761
step: 300, loss: 0.038883328437805176
step: 310, loss: 0.006830989383161068
step: 320, loss: 0.0035401349887251854
step: 330, loss: 0.034392956644296646
step: 340, loss: 0.0076368884183466434
step: 350, loss: 0.010197510942816734
step: 360, loss: 0.01707574538886547
step: 370, loss: 0.01396896131336689
step: 380, loss: 0.00010344048496335745
step: 390, loss: 0.00830079149454832
step: 400, loss: 0.08127931505441666
step: 410, loss: 0.0001691855868557468
step: 420, loss: 0.02209962159395218
epoch 10: dev_f1=0.7157894736842106, f1=0.6623655913978495, best_f1=0.6626506024096386
step: 0, loss: 0.014787937514483929
step: 10, loss: 0.00704573467373848
step: 20, loss: 0.002476430730894208
step: 30, loss: 0.0006278295186348259
step: 40, loss: 0.03129081055521965
step: 50, loss: 0.05262937769293785
step: 60, loss: 0.06496523320674896
step: 70, loss: 0.00017700469470582902
step: 80, loss: 0.00029804877704009414
step: 90, loss: 0.0005516200908459723
step: 100, loss: 0.004057776648551226
step: 110, loss: 0.0013599895173683763
step: 120, loss: 0.0005476358928717673
step: 130, loss: 0.01172474306076765
step: 140, loss: 0.010953085497021675
step: 150, loss: 0.00035734049743041396
step: 160, loss: 0.012015048414468765
step: 170, loss: 0.0007454750593751669
step: 180, loss: 0.0160774327814579
step: 190, loss: 0.00023915155907161534
step: 200, loss: 0.009174237959086895
step: 210, loss: 0.00010617570660542697
step: 220, loss: 0.03714218735694885
step: 230, loss: 0.0016320019494742155
step: 240, loss: 0.02690167911350727
step: 250, loss: 0.01262142788618803
step: 260, loss: 0.01387370377779007
step: 270, loss: 7.533891766797751e-05
step: 280, loss: 0.007456185761839151
step: 290, loss: 0.0009130859398283064
step: 300, loss: 0.000758240232244134
step: 310, loss: 0.0002570645010564476
step: 320, loss: 0.0005333159933798015
step: 330, loss: 0.0023228581994771957
step: 340, loss: 0.007272851653397083
step: 350, loss: 0.01781289093196392
step: 360, loss: 0.002909737639129162
step: 370, loss: 0.0001481681247241795
step: 380, loss: 0.0005992052610963583
step: 390, loss: 0.0006009252974763513
step: 400, loss: 0.003684355178847909
step: 410, loss: 0.0003649699501693249
step: 420, loss: 0.006880926433950663
epoch 11: dev_f1=0.7218045112781954, f1=0.6744186046511628, best_f1=0.6626506024096386
step: 0, loss: 0.003368519013747573
step: 10, loss: 0.0004030145355500281
step: 20, loss: 0.022869938984513283
step: 30, loss: 0.0054199122823774815
step: 40, loss: 0.042086392641067505
step: 50, loss: 0.025987381115555763
step: 60, loss: 0.0010584307601675391
step: 70, loss: 0.00019866980437655002
step: 80, loss: 0.0010652800556272268
step: 90, loss: 0.012852408923208714
step: 100, loss: 0.0005005914135836065
step: 110, loss: 0.0003988875250797719
step: 120, loss: 0.078303262591362
step: 130, loss: 0.021898731589317322
step: 140, loss: 0.00014824308163952082
step: 150, loss: 0.0015661596553400159
step: 160, loss: 0.003068708349019289
step: 170, loss: 0.0365154966711998
step: 180, loss: 0.0009466710034757853
step: 190, loss: 0.0004576803185045719
step: 200, loss: 0.021979881450533867
step: 210, loss: 0.002764403587207198
step: 220, loss: 0.0011656038695946336
step: 230, loss: 0.002623757580295205
step: 240, loss: 0.00027407065499573946
step: 250, loss: 0.05707015469670296
step: 260, loss: 0.00927759613841772
step: 270, loss: 6.464249599957839e-05
step: 280, loss: 0.0001329598599113524
step: 290, loss: 0.0030292198061943054
step: 300, loss: 0.04862017184495926
step: 310, loss: 0.028855271637439728
step: 320, loss: 0.0014728381065651774
step: 330, loss: 0.0009587262175045907
step: 340, loss: 0.005857246927917004
step: 350, loss: 0.013191205449402332
step: 360, loss: 0.023472169414162636
step: 370, loss: 0.0006666036788374186
step: 380, loss: 0.05121177062392235
step: 390, loss: 0.0012407283065840602
step: 400, loss: 0.01507165189832449
step: 410, loss: 0.00022320225252769887
step: 420, loss: 0.0004554545448627323
epoch 12: dev_f1=0.6981519507186859, f1=0.6527196652719667, best_f1=0.6626506024096386
step: 0, loss: 0.0008191136294044554
step: 10, loss: 0.022674502804875374
step: 20, loss: 0.00010245074372505769
step: 30, loss: 0.00035153457429260015
step: 40, loss: 0.0018349008169025183
step: 50, loss: 0.00039288323023356497
step: 60, loss: 0.004439984913915396
step: 70, loss: 0.0037083616480231285
step: 80, loss: 0.00039147393545135856
step: 90, loss: 0.00016733689699321985
step: 100, loss: 0.018972404301166534
step: 110, loss: 0.0027479135897010565
step: 120, loss: 0.00018011181964538991
step: 130, loss: 0.0002879717794712633
step: 140, loss: 0.001583880395628512
step: 150, loss: 0.0001405105140293017
step: 160, loss: 0.012644431553781033
step: 170, loss: 0.0025848166551440954
step: 180, loss: 0.015597464516758919
step: 190, loss: 0.0011708085658028722
step: 200, loss: 0.0008849254809319973
step: 210, loss: 0.08379437774419785
step: 220, loss: 0.005553028546273708
step: 230, loss: 0.0003597617906052619
step: 240, loss: 0.0008889234741218388
step: 250, loss: 0.022253844887018204
step: 260, loss: 0.0018379486864432693
step: 270, loss: 7.67228048061952e-05
step: 280, loss: 0.006700964644551277
step: 290, loss: 0.0007079910719767213
step: 300, loss: 0.00011913043272215873
step: 310, loss: 0.0004987621214240789
step: 320, loss: 0.0033429348841309547
step: 330, loss: 0.1711394041776657
step: 340, loss: 0.0004365030908957124
step: 350, loss: 0.0015977929579094052
step: 360, loss: 5.215476267039776e-05
step: 370, loss: 0.0014820917276665568
step: 380, loss: 0.002180512761697173
step: 390, loss: 0.0002385925326962024
step: 400, loss: 0.011761089786887169
step: 410, loss: 0.01061803288757801
step: 420, loss: 0.0004807993536815047
epoch 13: dev_f1=0.721868365180467, f1=0.6565217391304349, best_f1=0.6626506024096386
step: 0, loss: 0.0011273417621850967
step: 10, loss: 0.04205148667097092
step: 20, loss: 8.622695895610377e-05
step: 30, loss: 0.000808342476375401
step: 40, loss: 0.0005768759292550385
step: 50, loss: 0.003393041668459773
step: 60, loss: 0.053663693368434906
step: 70, loss: 0.0017200126312673092
step: 80, loss: 0.0010782352183014154
step: 90, loss: 0.0001618228998268023
step: 100, loss: 0.0009361388511024415
step: 110, loss: 0.0009428196935914457
step: 120, loss: 0.02371036447584629
step: 130, loss: 0.04838157817721367
step: 140, loss: 0.013295065611600876
step: 150, loss: 0.00010395443678135052
step: 160, loss: 0.00020078782108612359
step: 170, loss: 0.034002143889665604
step: 180, loss: 0.00010692570504033938
step: 190, loss: 0.002541242865845561
step: 200, loss: 0.0005026260623708367
step: 210, loss: 0.0007742807501927018
step: 220, loss: 0.014465142041444778
step: 230, loss: 0.00017258543812204152
step: 240, loss: 0.08899207413196564
step: 250, loss: 0.00023412938753608614
step: 260, loss: 0.07340630888938904
step: 270, loss: 0.02560545690357685
step: 280, loss: 0.014411644078791142
step: 290, loss: 0.0001373757258988917
step: 300, loss: 0.04118463397026062
step: 310, loss: 0.03785880282521248
step: 320, loss: 0.0023053509648889303
step: 330, loss: 0.00011625686602201313
step: 340, loss: 0.041710611432790756
step: 350, loss: 0.0004623961867764592
step: 360, loss: 0.00014470945461653173
step: 370, loss: 0.001124221016652882
step: 380, loss: 0.03652288392186165
step: 390, loss: 0.0010219239629805088
step: 400, loss: 0.0006077304715290666
step: 410, loss: 8.912382327252999e-05
step: 420, loss: 0.0004231393395457417
epoch 14: dev_f1=0.7128712871287128, f1=0.6747474747474748, best_f1=0.6626506024096386
step: 0, loss: 0.010712849907577038
step: 10, loss: 0.0011011636815965176
step: 20, loss: 0.0170088242739439
step: 30, loss: 0.0009553624549880624
step: 40, loss: 0.0048013608902692795
step: 50, loss: 0.03231456130743027
step: 60, loss: 0.001812027650885284
step: 70, loss: 8.583737508160993e-05
step: 80, loss: 0.003788842586800456
step: 90, loss: 9.473413228988647e-05
step: 100, loss: 0.005402999930083752
step: 110, loss: 0.0011564267333596945
step: 120, loss: 0.00013584170665126294
step: 130, loss: 0.0009258376085199416
step: 140, loss: 0.0002823164686560631
step: 150, loss: 0.0012455610558390617
step: 160, loss: 0.0003225540276616812
step: 170, loss: 0.012419250793755054
step: 180, loss: 6.851085345260799e-05
step: 190, loss: 0.0012357519008219242
step: 200, loss: 0.0002793690364342183
step: 210, loss: 0.00010939963976852596
step: 220, loss: 0.00028489361284300685
step: 230, loss: 0.016756553202867508
step: 240, loss: 0.00021416701201815158
step: 250, loss: 0.017344646155834198
step: 260, loss: 0.04485980421304703
step: 270, loss: 5.913731365581043e-05
step: 280, loss: 9.522784239379689e-05
step: 290, loss: 0.0001046474208123982
step: 300, loss: 5.7701487094163895e-05
step: 310, loss: 7.346845086431131e-05
step: 320, loss: 0.00010401532199466601
step: 330, loss: 0.0006514038541354239
step: 340, loss: 0.00019654122297652066
step: 350, loss: 8.820389484753832e-05
step: 360, loss: 8.893101767171174e-05
step: 370, loss: 0.0018846223829314113
step: 380, loss: 0.0001360172900604084
step: 390, loss: 0.014368084259331226
step: 400, loss: 0.00012447504559531808
step: 410, loss: 0.046284742653369904
step: 420, loss: 0.00013012469571549445
epoch 15: dev_f1=0.7234042553191489, f1=0.6550976138828634, best_f1=0.6626506024096386
step: 0, loss: 0.044036246836185455
step: 10, loss: 0.002502821385860443
step: 20, loss: 8.664651977596804e-05
step: 30, loss: 0.00010579855006653816
step: 40, loss: 0.010471668094396591
step: 50, loss: 3.2508967706235126e-05
step: 60, loss: 0.00036602301406674087
step: 70, loss: 0.02721276506781578
step: 80, loss: 0.008045440539717674
step: 90, loss: 0.004791136831045151
step: 100, loss: 0.0006469891523011029
step: 110, loss: 0.0001249388005817309
step: 120, loss: 9.067638893611729e-05
step: 130, loss: 6.191689317347482e-05
step: 140, loss: 2.9939308660686947e-05
step: 150, loss: 2.925390981545206e-05
step: 160, loss: 0.00028403548640199006
step: 170, loss: 8.175068069249392e-05
step: 180, loss: 0.04288977384567261
step: 190, loss: 0.014182457700371742
step: 200, loss: 0.007057768292725086
step: 210, loss: 0.0004840605251956731
step: 220, loss: 0.0030011425260454416
step: 230, loss: 0.001475042663514614
step: 240, loss: 0.0053635467775166035
step: 250, loss: 0.0002506529854144901
step: 260, loss: 8.039631939027458e-05
step: 270, loss: 9.227212285622954e-05
step: 280, loss: 0.0009807597380131483
step: 290, loss: 0.01405183132737875
step: 300, loss: 3.0382576369447634e-05
step: 310, loss: 7.857999298721552e-05
step: 320, loss: 0.00013863155618309975
step: 330, loss: 0.00443446496501565
step: 340, loss: 3.920327435480431e-05
step: 350, loss: 0.0001163129709311761
step: 360, loss: 0.00010574975021881983
step: 370, loss: 0.007661172188818455
step: 380, loss: 0.08806941658258438
step: 390, loss: 0.00010178676166106015
step: 400, loss: 0.02407979778945446
step: 410, loss: 4.843969509238377e-05
step: 420, loss: 0.0004093616153113544
epoch 16: dev_f1=0.7122736418511065, f1=0.6666666666666667, best_f1=0.6626506024096386
step: 0, loss: 9.046355989994481e-05
step: 10, loss: 3.939647285733372e-05
step: 20, loss: 0.00020022857643198222
step: 30, loss: 2.7226989914197475e-05
step: 40, loss: 0.00011547536996658891
step: 50, loss: 0.02893991954624653
step: 60, loss: 0.0006112597184255719
step: 70, loss: 7.094220927683637e-05
step: 80, loss: 0.00031446406501345336
step: 90, loss: 0.01642211526632309
step: 100, loss: 3.379398549441248e-05
step: 110, loss: 0.002209436846897006
step: 120, loss: 0.0004405974177643657
step: 130, loss: 8.611472730990499e-05
step: 140, loss: 0.00276544620282948
step: 150, loss: 0.0002300324704265222
step: 160, loss: 0.00014683564950246364
step: 170, loss: 0.00011977711983490735
step: 180, loss: 0.0007300196448341012
step: 190, loss: 0.0001464451925130561
step: 200, loss: 0.001273580826818943
step: 210, loss: 3.6815268686041236e-05
step: 220, loss: 2.9242211894597858e-05
step: 230, loss: 6.874649261590093e-05
step: 240, loss: 0.0011888279113918543
step: 250, loss: 0.0022592099849134684
step: 260, loss: 7.823179475963116e-05
step: 270, loss: 5.4939133406151086e-05
step: 280, loss: 3.6480392736848444e-05
step: 290, loss: 0.0010889824479818344
step: 300, loss: 2.391563612036407e-05
step: 310, loss: 0.01025330275297165
step: 320, loss: 0.0003484060289338231
step: 330, loss: 4.591735341819003e-05
step: 340, loss: 2.4392622435698286e-05
step: 350, loss: 0.0008712601265870035
step: 360, loss: 0.010087591595947742
step: 370, loss: 9.028842760017142e-05
step: 380, loss: 0.0014801051001995802
step: 390, loss: 0.0007355515263043344
step: 400, loss: 0.0002230058453278616
step: 410, loss: 0.0673668310046196
step: 420, loss: 0.0001486864930484444
epoch 17: dev_f1=0.6714285714285715, f1=0.5952380952380952, best_f1=0.6626506024096386
step: 0, loss: 0.000652397284284234
step: 10, loss: 0.013066893443465233
step: 20, loss: 6.789075268898159e-05
step: 30, loss: 0.0003693367470987141
step: 40, loss: 7.193713827291504e-05
step: 50, loss: 0.007555641233921051
step: 60, loss: 0.00014412455493584275
step: 70, loss: 0.00400973716750741
step: 80, loss: 0.00948537141084671
step: 90, loss: 0.0008556980174034834
step: 100, loss: 0.0013755690306425095
step: 110, loss: 0.0040045687928795815
step: 120, loss: 0.00018066879420075566
step: 130, loss: 0.0005327690741978586
step: 140, loss: 0.00011579638521652669
step: 150, loss: 0.015696577727794647
step: 160, loss: 3.338147871545516e-05
step: 170, loss: 3.776835364988074e-05
step: 180, loss: 3.180853673256934e-05
step: 190, loss: 0.0014665216440334916
step: 200, loss: 0.000639673147816211
step: 210, loss: 0.009099433198571205
step: 220, loss: 0.0001478667400078848
step: 230, loss: 0.0005395927000790834
step: 240, loss: 3.8819176552351564e-05
step: 250, loss: 6.728662265231833e-05
step: 260, loss: 5.339783092495054e-05
step: 270, loss: 4.0070688555715606e-05
step: 280, loss: 2.5260447728214785e-05
step: 290, loss: 9.420581045560539e-05
step: 300, loss: 4.9655231123324484e-05
step: 310, loss: 3.8629576010862365e-05
step: 320, loss: 4.5429911551764235e-05
step: 330, loss: 0.048126280307769775
step: 340, loss: 0.00018637397442944348
step: 350, loss: 0.0002521647547837347
step: 360, loss: 0.04600035771727562
step: 370, loss: 0.00010057817416964099
step: 380, loss: 0.0012385378358885646
step: 390, loss: 6.369750917656347e-05
step: 400, loss: 5.051694461144507e-05
step: 410, loss: 3.666655538836494e-05
step: 420, loss: 0.0009019333519972861
epoch 18: dev_f1=0.7045454545454545, f1=0.608695652173913, best_f1=0.6626506024096386
step: 0, loss: 9.278845391236246e-05
step: 10, loss: 3.6856097722193226e-05
step: 20, loss: 0.032901469618082047
step: 30, loss: 0.001194123411551118
step: 40, loss: 0.00010616295912768692
step: 50, loss: 0.010548015125095844
step: 60, loss: 0.00011642277240753174
step: 70, loss: 3.020007352461107e-05
step: 80, loss: 0.0001294545509153977
step: 90, loss: 3.60179110430181e-05
step: 100, loss: 0.0035020257346332073
step: 110, loss: 0.0004109902074560523
step: 120, loss: 0.000487348937895149
step: 130, loss: 0.005903315264731646
step: 140, loss: 5.5911848903633654e-05
step: 150, loss: 4.048688424518332e-05
step: 160, loss: 0.0002065347071038559
step: 170, loss: 8.699857426108792e-05
step: 180, loss: 5.0265982281416655e-05
step: 190, loss: 0.0015423583099618554
step: 200, loss: 0.00041135482024401426
step: 210, loss: 0.009260915219783783
step: 220, loss: 5.7990106142824516e-05
step: 230, loss: 0.006642408203333616
step: 240, loss: 0.06723841279745102
step: 250, loss: 4.9383845180273056e-05
step: 260, loss: 0.00012712707393802702
step: 270, loss: 0.00010659158579073846
step: 280, loss: 0.00020424182002898306
step: 290, loss: 0.00011273362906649709
step: 300, loss: 0.00033658448955975473
step: 310, loss: 0.02252493053674698
step: 320, loss: 0.18521307408809662
step: 330, loss: 0.00020782454521395266
step: 340, loss: 0.047251567244529724
step: 350, loss: 0.0001513505121693015
step: 360, loss: 0.020712317898869514
step: 370, loss: 0.005992603953927755
step: 380, loss: 0.0001337232970399782
step: 390, loss: 3.23532112815883e-05
step: 400, loss: 3.636452674982138e-05
step: 410, loss: 4.58853792224545e-05
step: 420, loss: 0.004257759544998407
epoch 19: dev_f1=0.7139689578713969, f1=0.6216216216216216, best_f1=0.6626506024096386
step: 0, loss: 0.009895112365484238
step: 10, loss: 6.526540528284386e-05
step: 20, loss: 0.00011677489965222776
step: 30, loss: 5.213106851442717e-05
step: 40, loss: 6.0751008277293295e-05
step: 50, loss: 0.0007785074994899333
step: 60, loss: 7.074211316648871e-05
step: 70, loss: 5.948047328274697e-05
step: 80, loss: 5.2317194786155596e-05
step: 90, loss: 0.004259232897311449
step: 100, loss: 0.00013497374311555177
step: 110, loss: 0.0017732788110151887
step: 120, loss: 6.517628207802773e-05
step: 130, loss: 7.565087435068563e-05
step: 140, loss: 0.010511240921914577
step: 150, loss: 0.0011236054124310613
step: 160, loss: 0.00017521243717055768
step: 170, loss: 3.399566048756242e-05
step: 180, loss: 8.617214916739613e-05
step: 190, loss: 0.00024407129967585206
step: 200, loss: 1.9564899048418738e-05
step: 210, loss: 8.633206743979827e-05
step: 220, loss: 0.00010010308324126527
step: 230, loss: 7.136974454624578e-05
step: 240, loss: 9.853907249635085e-05
step: 250, loss: 0.00014059945533517748
step: 260, loss: 0.0002634513075463474
step: 270, loss: 7.687730249017477e-05
step: 280, loss: 4.3678362999344245e-05
step: 290, loss: 9.450173092773184e-05
step: 300, loss: 0.001255749724805355
step: 310, loss: 0.0007775579579174519
step: 320, loss: 4.7251083742594346e-05
step: 330, loss: 0.0006054796976968646
step: 340, loss: 3.7463425542227924e-05
step: 350, loss: 0.0002739196934271604
step: 360, loss: 0.002205918077379465
step: 370, loss: 0.0019535855390131474
step: 380, loss: 4.0765891753835604e-05
step: 390, loss: 0.0013602877734228969
step: 400, loss: 0.00043284683488309383
step: 410, loss: 0.001614677021279931
step: 420, loss: 0.0002660328464116901
epoch 20: dev_f1=0.7089715536105032, f1=0.6280623608017818, best_f1=0.6626506024096386
cuda
Device: cuda
step: 0, loss: 0.6042070388793945
step: 10, loss: 0.44662609696388245
step: 20, loss: 0.1069190576672554
step: 30, loss: 0.3342553973197937
step: 40, loss: 0.35233524441719055
step: 50, loss: 0.2086062878370285
step: 60, loss: 0.29708975553512573
step: 70, loss: 0.22779366374015808
step: 80, loss: 0.26509788632392883
step: 90, loss: 0.24550247192382812
step: 100, loss: 0.3095187246799469
step: 110, loss: 0.296697199344635
step: 120, loss: 0.3180263340473175
step: 130, loss: 0.2376142144203186
step: 140, loss: 0.05720769241452217
step: 150, loss: 0.216631680727005
step: 160, loss: 0.2647554278373718
step: 170, loss: 0.13583064079284668
step: 180, loss: 0.2993675470352173
step: 190, loss: 0.14492778480052948
step: 200, loss: 0.0878530740737915
step: 210, loss: 0.23685963451862335
step: 220, loss: 0.09648293256759644
step: 230, loss: 0.24726101756095886
step: 240, loss: 0.09144161641597748
step: 250, loss: 0.1313396394252777
step: 260, loss: 0.2539897859096527
step: 270, loss: 0.14876428246498108
step: 280, loss: 0.10140115022659302
step: 290, loss: 0.25543680787086487
step: 300, loss: 0.2376457154750824
step: 310, loss: 0.1836298257112503
step: 320, loss: 0.22982420027256012
step: 330, loss: 0.44767290353775024
step: 340, loss: 0.28026875853538513
step: 350, loss: 0.2222568392753601
step: 360, loss: 0.008379478007555008
step: 370, loss: 0.24175995588302612
step: 380, loss: 0.1075170561671257
step: 390, loss: 0.1292412430047989
step: 400, loss: 0.06346292048692703
step: 410, loss: 0.2133316844701767
step: 420, loss: 0.06904052942991257
epoch 1: dev_f1=0.6905263157894737, f1=0.6150442477876107, best_f1=0.6150442477876107
step: 0, loss: 0.030122285708785057
step: 10, loss: 0.13112741708755493
step: 20, loss: 0.14883363246917725
step: 30, loss: 0.06501590460538864
step: 40, loss: 0.029659748077392578
step: 50, loss: 0.13336136937141418
step: 60, loss: 0.1050410270690918
step: 70, loss: 0.13749662041664124
step: 80, loss: 0.09181482344865799
step: 90, loss: 0.04435447230935097
step: 100, loss: 0.10737335681915283
step: 110, loss: 0.15985359251499176
step: 120, loss: 0.19582752883434296
step: 130, loss: 0.05452475696802139
step: 140, loss: 0.3774389922618866
step: 150, loss: 0.07668261229991913
step: 160, loss: 0.01640123501420021
step: 170, loss: 0.1358635276556015
step: 180, loss: 0.19761672616004944
step: 190, loss: 0.10724484920501709
step: 200, loss: 0.04388944059610367
step: 210, loss: 0.1322321593761444
step: 220, loss: 0.21246036887168884
step: 230, loss: 0.07954226434230804
step: 240, loss: 0.06437470018863678
step: 250, loss: 0.06322518736124039
step: 260, loss: 0.2051524519920349
step: 270, loss: 0.1157132163643837
step: 280, loss: 0.0533977672457695
step: 290, loss: 0.051515743136405945
step: 300, loss: 0.1654425710439682
step: 310, loss: 0.1852782517671585
step: 320, loss: 0.2349126785993576
step: 330, loss: 0.0737977847456932
step: 340, loss: 0.1637369692325592
step: 350, loss: 0.020550226792693138
step: 360, loss: 0.41935786604881287
step: 370, loss: 0.12166101485490799
step: 380, loss: 0.0675591453909874
step: 390, loss: 0.11395040154457092
step: 400, loss: 0.010158881545066833
step: 410, loss: 0.17302994430065155
step: 420, loss: 0.19400379061698914
epoch 2: dev_f1=0.6873614190687362, f1=0.6325167037861915, best_f1=0.6150442477876107
step: 0, loss: 0.09899217635393143
step: 10, loss: 0.07014746963977814
step: 20, loss: 0.052760522812604904
step: 30, loss: 0.11728597432374954
step: 40, loss: 0.024504665285348892
step: 50, loss: 0.010019433684647083
step: 60, loss: 0.019580326974391937
step: 70, loss: 0.16924045979976654
step: 80, loss: 0.002407433930784464
step: 90, loss: 0.17243745923042297
step: 100, loss: 0.14964507520198822
step: 110, loss: 0.043882742524147034
step: 120, loss: 0.0022159244399517775
step: 130, loss: 0.06878568977117538
step: 140, loss: 0.034107305109500885
step: 150, loss: 0.04709286242723465
step: 160, loss: 0.2714705169200897
step: 170, loss: 0.12056773155927658
step: 180, loss: 0.014624180272221565
step: 190, loss: 0.02327381819486618
step: 200, loss: 0.041542764753103256
step: 210, loss: 0.053294479846954346
step: 220, loss: 0.01830226741731167
step: 230, loss: 0.07880539447069168
step: 240, loss: 0.2393665611743927
step: 250, loss: 0.006221438758075237
step: 260, loss: 0.16160684823989868
step: 270, loss: 0.07653253525495529
step: 280, loss: 0.11084157973527908
step: 290, loss: 0.2130846381187439
step: 300, loss: 0.011843754909932613
step: 310, loss: 0.019388588145375252
step: 320, loss: 0.23399946093559265
step: 330, loss: 0.04356259107589722
step: 340, loss: 0.136441171169281
step: 350, loss: 0.19068953394889832
step: 360, loss: 0.16932767629623413
step: 370, loss: 0.03935223072767258
step: 380, loss: 0.016259348019957542
step: 390, loss: 0.05088774859905243
step: 400, loss: 0.13208971917629242
step: 410, loss: 0.032447949051856995
step: 420, loss: 0.03670111671090126
epoch 3: dev_f1=0.6968503937007874, f1=0.640495867768595, best_f1=0.640495867768595
step: 0, loss: 0.054094430059194565
step: 10, loss: 0.04374849796295166
step: 20, loss: 0.0324089340865612
step: 30, loss: 0.09035442769527435
step: 40, loss: 0.013506066985428333
step: 50, loss: 0.06292866170406342
step: 60, loss: 0.01834484189748764
step: 70, loss: 0.08117443323135376
step: 80, loss: 0.07768171280622482
step: 90, loss: 0.06256796419620514
step: 100, loss: 0.0491580069065094
step: 110, loss: 0.1032211184501648
step: 120, loss: 0.06101404130458832
step: 130, loss: 0.06121779978275299
step: 140, loss: 0.0209104772657156
step: 150, loss: 0.03354967013001442
step: 160, loss: 0.05901433899998665
step: 170, loss: 0.030773449689149857
step: 180, loss: 0.2936611771583557
step: 190, loss: 0.023378713056445122
step: 200, loss: 0.03100738301873207
step: 210, loss: 0.07547657936811447
step: 220, loss: 0.0580451525747776
step: 230, loss: 0.1531122773885727
step: 240, loss: 0.16658316552639008
step: 250, loss: 0.02668275497853756
step: 260, loss: 0.017557580024003983
step: 270, loss: 0.034889377653598785
step: 280, loss: 0.035294655710458755
step: 290, loss: 0.014407947659492493
step: 300, loss: 0.08820819109678268
step: 310, loss: 0.22125504910945892
step: 320, loss: 0.04670443758368492
step: 330, loss: 0.01826680451631546
step: 340, loss: 0.00927152018994093
step: 350, loss: 0.011145860888063908
step: 360, loss: 0.07756884396076202
step: 370, loss: 0.0012852258514612913
step: 380, loss: 0.02592434361577034
step: 390, loss: 0.01884113810956478
step: 400, loss: 0.11647976189851761
step: 410, loss: 0.021622076630592346
step: 420, loss: 0.13502702116966248
epoch 4: dev_f1=0.7325102880658436, f1=0.6735966735966735, best_f1=0.6735966735966735
step: 0, loss: 0.11269942671060562
step: 10, loss: 0.06603419780731201
step: 20, loss: 0.0156717486679554
step: 30, loss: 0.038414668291807175
step: 40, loss: 0.029270505532622337
step: 50, loss: 0.01256662979722023
step: 60, loss: 0.08935990929603577
step: 70, loss: 0.07747013121843338
step: 80, loss: 0.019761059433221817
step: 90, loss: 0.03134331479668617
step: 100, loss: 0.12106245011091232
step: 110, loss: 0.03341999277472496
step: 120, loss: 0.04130101203918457
step: 130, loss: 0.026009606197476387
step: 140, loss: 0.009477929212152958
step: 150, loss: 0.03708895668387413
step: 160, loss: 0.014768172055482864
step: 170, loss: 0.022033272311091423
step: 180, loss: 0.0035303705371916294
step: 190, loss: 0.002701015444472432
step: 200, loss: 0.002371392445638776
step: 210, loss: 0.025103526189923286
step: 220, loss: 0.005090947728604078
step: 230, loss: 0.07648475468158722
step: 240, loss: 0.07100637257099152
step: 250, loss: 0.05535703897476196
step: 260, loss: 0.04958995431661606
step: 270, loss: 0.009688448160886765
step: 280, loss: 0.024165572598576546
step: 290, loss: 0.05244345963001251
step: 300, loss: 0.021161532029509544
step: 310, loss: 0.03705926612019539
step: 320, loss: 0.08949464559555054
step: 330, loss: 0.018031112849712372
step: 340, loss: 0.08306543529033661
step: 350, loss: 0.029503442347049713
step: 360, loss: 0.061642132699489594
step: 370, loss: 0.05025217682123184
step: 380, loss: 0.00754789961501956
step: 390, loss: 0.014565832912921906
step: 400, loss: 0.005483060143887997
step: 410, loss: 0.030443985015153885
step: 420, loss: 0.05248351767659187
epoch 5: dev_f1=0.6982248520710059, f1=0.6401673640167364, best_f1=0.6735966735966735
step: 0, loss: 0.09913493692874908
step: 10, loss: 0.03659417852759361
step: 20, loss: 0.03607320412993431
step: 30, loss: 0.007834391668438911
step: 40, loss: 0.0007511886651627719
step: 50, loss: 0.016453027725219727
step: 60, loss: 0.0015281594824045897
step: 70, loss: 0.14243559539318085
step: 80, loss: 0.18816275894641876
step: 90, loss: 0.023410577327013016
step: 100, loss: 0.09351646900177002
step: 110, loss: 0.030627459287643433
step: 120, loss: 0.05189534276723862
step: 130, loss: 0.013054056093096733
step: 140, loss: 0.011499338783323765
step: 150, loss: 0.00047290060319937766
step: 160, loss: 0.06684329360723495
step: 170, loss: 0.06753319501876831
step: 180, loss: 0.06215827167034149
step: 190, loss: 0.044288069009780884
step: 200, loss: 0.10255403816699982
step: 210, loss: 0.1027156189084053
step: 220, loss: 0.07276337593793869
step: 230, loss: 0.04780642315745354
step: 240, loss: 0.07119078189134598
step: 250, loss: 0.0038940985687077045
step: 260, loss: 0.12867604196071625
step: 270, loss: 0.0494767390191555
step: 280, loss: 0.003530038520693779
step: 290, loss: 0.09471141546964645
step: 300, loss: 0.01940697431564331
step: 310, loss: 0.04190376028418541
step: 320, loss: 0.004049042239785194
step: 330, loss: 0.03760720416903496
step: 340, loss: 0.039078086614608765
step: 350, loss: 0.21308405697345734
step: 360, loss: 0.00741259241476655
step: 370, loss: 0.014616253785789013
step: 380, loss: 0.1445683240890503
step: 390, loss: 0.026210909709334373
step: 400, loss: 0.001917603425681591
step: 410, loss: 0.0005800329381600022
step: 420, loss: 0.012331276200711727
epoch 6: dev_f1=0.7203389830508475, f1=0.6351931330472103, best_f1=0.6735966735966735
step: 0, loss: 0.007226862013339996
step: 10, loss: 0.005049427039921284
step: 20, loss: 0.015397556126117706
step: 30, loss: 0.005051237531006336
step: 40, loss: 0.003477752208709717
step: 50, loss: 0.004235550761222839
step: 60, loss: 0.0282765980809927
step: 70, loss: 0.06376679241657257
step: 80, loss: 0.001967297401279211
step: 90, loss: 0.004055996425449848
step: 100, loss: 0.039308492094278336
step: 110, loss: 0.02046714536845684
step: 120, loss: 0.03475596383213997
step: 130, loss: 0.014588600024580956
step: 140, loss: 0.01714249700307846
step: 150, loss: 0.010360863991081715
step: 160, loss: 0.00236352626234293
step: 170, loss: 0.006857771426439285
step: 180, loss: 0.01334549579769373
step: 190, loss: 0.10543041676282883
step: 200, loss: 0.0010309726931154728
step: 210, loss: 0.12902036309242249
step: 220, loss: 0.0036389196757227182
step: 230, loss: 0.0035934122279286385
step: 240, loss: 0.027191588655114174
step: 250, loss: 0.05955193564295769
step: 260, loss: 0.010518014430999756
step: 270, loss: 0.019614696502685547
step: 280, loss: 0.006202335469424725
step: 290, loss: 0.07969119399785995
step: 300, loss: 0.013190544210374355
step: 310, loss: 0.060311175882816315
step: 320, loss: 0.008530383929610252
step: 330, loss: 0.011942446231842041
step: 340, loss: 0.0008904471760615706
step: 350, loss: 0.05627167224884033
step: 360, loss: 0.15998977422714233
step: 370, loss: 0.0064077069982886314
step: 380, loss: 0.002035633660852909
step: 390, loss: 0.06547906994819641
step: 400, loss: 0.017141034826636314
step: 410, loss: 0.1424647569656372
step: 420, loss: 0.01875864714384079
epoch 7: dev_f1=0.6846153846153845, f1=0.665314401622718, best_f1=0.6735966735966735
step: 0, loss: 0.0317852608859539
step: 10, loss: 0.004822548944503069
step: 20, loss: 0.0008119359845295548
step: 30, loss: 0.05370194464921951
step: 40, loss: 0.0488649383187294
step: 50, loss: 0.016754264011979103
step: 60, loss: 0.060600847005844116
step: 70, loss: 0.01370433159172535
step: 80, loss: 0.011799702420830727
step: 90, loss: 0.08870315551757812
step: 100, loss: 0.005434479098767042
step: 110, loss: 0.0983913391828537
step: 120, loss: 0.004333829507231712
step: 130, loss: 0.018219642341136932
step: 140, loss: 0.013344324193894863
step: 150, loss: 0.012494133785367012
step: 160, loss: 0.013329423032701015
step: 170, loss: 0.02442835457623005
step: 180, loss: 0.003290019230917096
step: 190, loss: 0.0014765617670491338
step: 200, loss: 0.009205750189721584
step: 210, loss: 0.0012330985628068447
step: 220, loss: 0.0036410156171768904
step: 230, loss: 0.012757900170981884
step: 240, loss: 0.005319726187735796
step: 250, loss: 0.0868496522307396
step: 260, loss: 0.030597461387515068
step: 270, loss: 0.01994228921830654
step: 280, loss: 0.011981557123363018
step: 290, loss: 0.07893633842468262
step: 300, loss: 0.057216376066207886
step: 310, loss: 0.014763209968805313
step: 320, loss: 0.012333524413406849
step: 330, loss: 0.010888242162764072
step: 340, loss: 0.0016813930124044418
step: 350, loss: 0.05363989993929863
step: 360, loss: 0.01565934345126152
step: 370, loss: 0.0026381048373878
step: 380, loss: 0.0013332084054127336
step: 390, loss: 0.005678504705429077
step: 400, loss: 0.1396162062883377
step: 410, loss: 0.027364343404769897
step: 420, loss: 0.005489872768521309
epoch 8: dev_f1=0.6680000000000001, f1=0.6111111111111112, best_f1=0.6735966735966735
step: 0, loss: 0.07818879187107086
step: 10, loss: 0.012645131908357143
step: 20, loss: 0.019154852256178856
step: 30, loss: 0.02574867755174637
step: 40, loss: 0.005689581390470266
step: 50, loss: 0.0015809342730790377
step: 60, loss: 0.030122430995106697
step: 70, loss: 0.0025951408315449953
step: 80, loss: 0.007984684780240059
step: 90, loss: 0.02476835809648037
step: 100, loss: 0.0006814695079810917
step: 110, loss: 0.0014456900535151362
step: 120, loss: 0.005747784394770861
step: 130, loss: 0.012151072733104229
step: 140, loss: 0.000667002925183624
step: 150, loss: 0.0044732107780873775
step: 160, loss: 0.0023285511415451765
step: 170, loss: 0.0009018835262395442
step: 180, loss: 0.0003859680437017232
step: 190, loss: 0.027080539613962173
step: 200, loss: 0.001976755214855075
step: 210, loss: 0.02862681820988655
step: 220, loss: 0.007118593901395798
step: 230, loss: 0.009346439503133297
step: 240, loss: 0.005997681524604559
step: 250, loss: 0.11603619903326035
step: 260, loss: 0.020257452502846718
step: 270, loss: 0.0005599629366770387
step: 280, loss: 0.002660824451595545
step: 290, loss: 0.038897980004549026
step: 300, loss: 0.0002070043992716819
step: 310, loss: 0.005292412359267473
step: 320, loss: 0.03452499955892563
step: 330, loss: 0.014706295914947987
step: 340, loss: 0.03092435747385025
step: 350, loss: 0.0024929610081017017
step: 360, loss: 0.0012507468927651644
step: 370, loss: 0.12639908492565155
step: 380, loss: 0.0009030650835484266
step: 390, loss: 0.07655936479568481
step: 400, loss: 0.00547360721975565
step: 410, loss: 0.0011008016299456358
step: 420, loss: 0.02215857058763504
epoch 9: dev_f1=0.6954813359528488, f1=0.6378600823045267, best_f1=0.6735966735966735
step: 0, loss: 0.09587695449590683
step: 10, loss: 0.015550370328128338
step: 20, loss: 0.0005271658883430064
step: 30, loss: 0.001712627592496574
step: 40, loss: 0.04093146696686745
step: 50, loss: 0.0008686233777552843
step: 60, loss: 0.016123540699481964
step: 70, loss: 0.17453113198280334
step: 80, loss: 0.022393453866243362
step: 90, loss: 0.012857799418270588
step: 100, loss: 0.00012315576896071434
step: 110, loss: 0.0022005802020430565
step: 120, loss: 0.0011791368015110493
step: 130, loss: 0.0005988380871713161
step: 140, loss: 7.093476597219706e-05
step: 150, loss: 0.05041986331343651
step: 160, loss: 0.00030858858372084796
step: 170, loss: 0.011007128283381462
step: 180, loss: 0.007768311072140932
step: 190, loss: 9.022981248563156e-05
step: 200, loss: 0.03797537460923195
step: 210, loss: 0.0011321869678795338
step: 220, loss: 0.004335461184382439
step: 230, loss: 0.0008202363387681544
step: 240, loss: 0.045966822654008865
step: 250, loss: 0.0003387638716958463
step: 260, loss: 0.005609189160168171
step: 270, loss: 0.0006404714076779783
step: 280, loss: 0.005211377050727606
step: 290, loss: 0.013310941867530346
step: 300, loss: 0.004347548820078373
step: 310, loss: 0.0018877229886129498
step: 320, loss: 0.004003177862614393
step: 330, loss: 0.031960684806108475
step: 340, loss: 0.020937863737344742
step: 350, loss: 0.0010342495515942574
step: 360, loss: 0.01096579059958458
step: 370, loss: 0.008931662887334824
step: 380, loss: 7.687058678129688e-05
step: 390, loss: 0.0113143939524889
step: 400, loss: 0.1330675184726715
step: 410, loss: 0.00035190320340916514
step: 420, loss: 0.006038217339664698
epoch 10: dev_f1=0.7053941908713692, f1=0.6369426751592356, best_f1=0.6735966735966735
step: 0, loss: 0.011363459751009941
step: 10, loss: 0.043272633105516434
step: 20, loss: 0.00430637551471591
step: 30, loss: 0.0058530354872345924
step: 40, loss: 0.03541698679327965
step: 50, loss: 0.04757164791226387
step: 60, loss: 0.011751075275242329
step: 70, loss: 0.0006430296925827861
step: 80, loss: 0.008896981365978718
step: 90, loss: 0.0028580292128026485
step: 100, loss: 0.004691899288445711
step: 110, loss: 0.015767483040690422
step: 120, loss: 0.0002664681524038315
step: 130, loss: 0.010259967297315598
step: 140, loss: 0.013168254867196083
step: 150, loss: 0.00022895912115927786
step: 160, loss: 0.0017372207948938012
step: 170, loss: 0.00020598295668605715
step: 180, loss: 0.109718918800354
step: 190, loss: 0.014103475958108902
step: 200, loss: 0.022867802530527115
step: 210, loss: 0.0001461674546590075
step: 220, loss: 0.0178939588367939
step: 230, loss: 0.00032064938568510115
step: 240, loss: 0.09844664484262466
step: 250, loss: 0.059467386454343796
step: 260, loss: 0.0036191230174154043
step: 270, loss: 0.0010477066971361637
step: 280, loss: 0.0022923622746020555
step: 290, loss: 0.0023569902405142784
step: 300, loss: 0.0005991024081595242
step: 310, loss: 0.0010978681966662407
step: 320, loss: 0.0017895287601277232
step: 330, loss: 0.0015767914010211825
step: 340, loss: 0.0010997150093317032
step: 350, loss: 0.044383756816387177
step: 360, loss: 0.002773720072582364
step: 370, loss: 0.0005636063870042562
step: 380, loss: 0.0004745089390780777
step: 390, loss: 0.0005713238497264683
step: 400, loss: 0.0006884238682687283
step: 410, loss: 0.0001253368827747181
step: 420, loss: 0.05609606206417084
epoch 11: dev_f1=0.7154150197628458, f1=0.6693711967545638, best_f1=0.6735966735966735
step: 0, loss: 0.013332660309970379
step: 10, loss: 0.009850766509771347
step: 20, loss: 0.001393755548633635
step: 30, loss: 0.007014441769570112
step: 40, loss: 0.025104813277721405
step: 50, loss: 0.09849836677312851
step: 60, loss: 0.006011460907757282
step: 70, loss: 0.000707935425452888
step: 80, loss: 0.002089026151224971
step: 90, loss: 0.0072864447720348835
step: 100, loss: 0.0007863446953706443
step: 110, loss: 0.000242296009673737
step: 120, loss: 0.01707318052649498
step: 130, loss: 0.00018895328685175627
step: 140, loss: 0.0039659603498876095
step: 150, loss: 0.0955529510974884
step: 160, loss: 0.0014846737030893564
step: 170, loss: 0.029360590502619743
step: 180, loss: 0.0007947863778099418
step: 190, loss: 0.0006258254870772362
step: 200, loss: 0.01681727170944214
step: 210, loss: 0.013459269888699055
step: 220, loss: 0.0012955771526321769
step: 230, loss: 0.004706113133579493
step: 240, loss: 0.0018101225141435862
step: 250, loss: 0.024445904418826103
step: 260, loss: 0.0004766513593494892
step: 270, loss: 0.0003750140604097396
step: 280, loss: 0.0005789782153442502
step: 290, loss: 0.004704320337623358
step: 300, loss: 0.11306162178516388
step: 310, loss: 0.03045598417520523
step: 320, loss: 0.00021672665025107563
step: 330, loss: 0.01757098361849785
step: 340, loss: 0.001971160527318716
step: 350, loss: 0.0083445580676198
step: 360, loss: 0.013280248269438744
step: 370, loss: 0.0030323131941258907
step: 380, loss: 0.0017666448839008808
step: 390, loss: 0.0243641659617424
step: 400, loss: 0.00016544715617783368
step: 410, loss: 0.0010370026575401425
step: 420, loss: 0.00013253848010208458
epoch 12: dev_f1=0.6967213114754098, f1=0.6347826086956522, best_f1=0.6735966735966735
step: 0, loss: 0.000497128174174577
step: 10, loss: 0.029933519661426544
step: 20, loss: 0.010389784350991249
step: 30, loss: 0.006590422708541155
step: 40, loss: 0.04081686586141586
step: 50, loss: 0.000255423947237432
step: 60, loss: 0.0024371191393584013
step: 70, loss: 0.0010204329155385494
step: 80, loss: 0.07459837943315506
step: 90, loss: 0.0016801644815132022
step: 100, loss: 0.0010883697541430593
step: 110, loss: 0.00017999565170612186
step: 120, loss: 0.00010792473040055484
step: 130, loss: 0.0002260806504637003
step: 140, loss: 0.0001958216162165627
step: 150, loss: 0.00021610995463561267
step: 160, loss: 0.00307010137476027
step: 170, loss: 0.001925276592373848
step: 180, loss: 0.007630828768014908
step: 190, loss: 0.0007338087889365852
step: 200, loss: 0.037535976618528366
step: 210, loss: 0.09390643239021301
step: 220, loss: 0.0034208849538117647
step: 230, loss: 0.007021170109510422
step: 240, loss: 0.00048573233652859926
step: 250, loss: 0.00021186766389291734
step: 260, loss: 0.00417700782418251
step: 270, loss: 0.00036346394335851073
step: 280, loss: 0.012708213180303574
step: 290, loss: 0.00018602506315801293
step: 300, loss: 0.00012234803580213338
step: 310, loss: 0.001199905527755618
step: 320, loss: 0.005808178335428238
step: 330, loss: 0.014066766016185284
step: 340, loss: 0.00019503288785926998
step: 350, loss: 0.0018880347488448024
step: 360, loss: 5.1537223043851554e-05
step: 370, loss: 0.08276667445898056
step: 380, loss: 0.002654417883604765
step: 390, loss: 0.0031085850205272436
step: 400, loss: 0.004700610879808664
step: 410, loss: 0.017244549468159676
step: 420, loss: 0.0028677587397396564
epoch 13: dev_f1=0.7100840336134454, f1=0.6479481641468683, best_f1=0.6735966735966735
step: 0, loss: 9.951645915862173e-05
step: 10, loss: 0.04071978107094765
step: 20, loss: 4.389250170788728e-05
step: 30, loss: 0.0006113649578765035
step: 40, loss: 0.00019161903765052557
step: 50, loss: 0.00043171769357286394
step: 60, loss: 0.005823005456477404
step: 70, loss: 0.0025548578705638647
step: 80, loss: 0.0018410008633509278
step: 90, loss: 0.0018367348238825798
step: 100, loss: 0.0010971951996907592
step: 110, loss: 0.00029892937163822353
step: 120, loss: 0.016616802662611008
step: 130, loss: 0.028080664575099945
step: 140, loss: 0.0008439374505542219
step: 150, loss: 0.00011678296141326427
step: 160, loss: 8.619904838269576e-05
step: 170, loss: 0.12426242977380753
step: 180, loss: 0.00018470213399268687
step: 190, loss: 9.642267832532525e-05
step: 200, loss: 0.0024882410652935505
step: 210, loss: 0.00156702334061265
step: 220, loss: 0.009023687802255154
step: 230, loss: 0.00017248227959498763
step: 240, loss: 0.0005336942849680781
step: 250, loss: 0.00010066578397527337
step: 260, loss: 0.003307713195681572
step: 270, loss: 0.0007046964601613581
step: 280, loss: 0.0005584179307334125
step: 290, loss: 8.568770863348618e-05
step: 300, loss: 0.004299566149711609
step: 310, loss: 0.05091322585940361
step: 320, loss: 0.0003624505188781768
step: 330, loss: 0.003228043671697378
step: 340, loss: 0.11512791365385056
step: 350, loss: 0.002720737596973777
step: 360, loss: 0.0013173228362575173
step: 370, loss: 0.017814362421631813
step: 380, loss: 0.19107288122177124
step: 390, loss: 0.00862263236194849
step: 400, loss: 0.0004815300926566124
step: 410, loss: 0.00450326781719923
step: 420, loss: 0.014354209415614605
epoch 14: dev_f1=0.6975717439293598, f1=0.6150234741784036, best_f1=0.6735966735966735
step: 0, loss: 0.016223743557929993
step: 10, loss: 0.00034358075936324894
step: 20, loss: 0.011433087289333344
step: 30, loss: 0.00242636795155704
step: 40, loss: 0.0004336451238486916
step: 50, loss: 0.034828927367925644
step: 60, loss: 0.0031873025000095367
step: 70, loss: 0.004027615766972303
step: 80, loss: 0.0013504530070349574
step: 90, loss: 0.024290982633829117
step: 100, loss: 0.0005737505853176117
step: 110, loss: 0.0005126335308887064
step: 120, loss: 0.0004496529290918261
step: 130, loss: 0.003842670936137438
step: 140, loss: 0.0007565764244645834
step: 150, loss: 0.00014088307216297835
step: 160, loss: 0.0006425981991924345
step: 170, loss: 0.005971272010356188
step: 180, loss: 0.00024394062347710133
step: 190, loss: 0.001290423097088933
step: 200, loss: 0.0044163912534713745
step: 210, loss: 0.00043276112410239875
step: 220, loss: 0.0005548411863856018
step: 230, loss: 0.007404256146401167
step: 240, loss: 6.921788735780865e-05
step: 250, loss: 0.0002064116415567696
step: 260, loss: 0.00014174109674058855
step: 270, loss: 0.0001702276204014197
step: 280, loss: 0.00011983901640633121
step: 290, loss: 0.021136099472641945
step: 300, loss: 4.479819108382799e-05
step: 310, loss: 0.0005772364092990756
step: 320, loss: 0.041353389620780945
step: 330, loss: 0.00040364748565480113
step: 340, loss: 0.0004689407942350954
step: 350, loss: 0.0004443856014404446
step: 360, loss: 0.00016338250134140253
step: 370, loss: 0.0009721131063997746
step: 380, loss: 0.036927882581949234
step: 390, loss: 0.0004753600514959544
step: 400, loss: 0.0004118724027648568
step: 410, loss: 0.10534290224313736
step: 420, loss: 4.608237577485852e-05
epoch 15: dev_f1=0.6849894291754756, f1=0.6157303370786517, best_f1=0.6735966735966735
step: 0, loss: 0.030866708606481552
step: 10, loss: 0.00041774235432967544
step: 20, loss: 4.528955832938664e-05
step: 30, loss: 4.715519389719702e-05
step: 40, loss: 0.0003896860289387405
step: 50, loss: 4.5158703869674355e-05
step: 60, loss: 0.00047622775309719145
step: 70, loss: 0.04318726062774658
step: 80, loss: 0.001532699796371162
step: 90, loss: 0.019829947501420975
step: 100, loss: 0.1566547304391861
step: 110, loss: 0.002321535488590598
step: 120, loss: 0.0011703639756888151
step: 130, loss: 0.0001901794457808137
step: 140, loss: 6.246436532819644e-05
step: 150, loss: 0.00044371996773406863
step: 160, loss: 0.004450674168765545
step: 170, loss: 0.00402304669842124
step: 180, loss: 0.026310386136174202
step: 190, loss: 0.04958374425768852
step: 200, loss: 0.0006188121042214334
step: 210, loss: 0.002009631134569645
step: 220, loss: 0.0030985891353338957
step: 230, loss: 0.012250165455043316
step: 240, loss: 0.003136924933642149
step: 250, loss: 0.005444112233817577
step: 260, loss: 5.975937892799266e-05
step: 270, loss: 0.00011102940334239975
step: 280, loss: 0.00010118520731339231
step: 290, loss: 0.00851159356534481
step: 300, loss: 0.0002709126565605402
step: 310, loss: 0.004324300214648247
step: 320, loss: 0.00045776640763506293
step: 330, loss: 0.02316669002175331
step: 340, loss: 0.013398430310189724
step: 350, loss: 0.0003463853499852121
step: 360, loss: 7.131628080969676e-05
step: 370, loss: 0.01661689206957817
step: 380, loss: 0.0006207515252754092
step: 390, loss: 0.05477609112858772
step: 400, loss: 0.08324529230594635
step: 410, loss: 0.0005928878090344369
step: 420, loss: 0.0001806886721169576
epoch 16: dev_f1=0.6884531590413945, f1=0.6355140186915889, best_f1=0.6735966735966735
step: 0, loss: 0.0006217871559783816
step: 10, loss: 0.00013976542686577886
step: 20, loss: 0.018026137724518776
step: 30, loss: 4.560275556286797e-05
step: 40, loss: 0.0012705170083791018
step: 50, loss: 0.023732740432024002
step: 60, loss: 0.0035313137341290712
step: 70, loss: 0.0005404718685895205
step: 80, loss: 0.001158491475507617
step: 90, loss: 0.013493005186319351
step: 100, loss: 9.284011321142316e-05
step: 110, loss: 0.0002935086376965046
step: 120, loss: 0.00011377599003026262
step: 130, loss: 7.607091538375244e-05
step: 140, loss: 0.0002626506320666522
step: 150, loss: 0.000711920321919024
step: 160, loss: 0.0014566086465492845
step: 170, loss: 0.013421582989394665
step: 180, loss: 0.0003664547693915665
step: 190, loss: 0.00014804395323153585
step: 200, loss: 0.011108525097370148
step: 210, loss: 0.0009046335471794009
step: 220, loss: 3.5452489100862294e-05
step: 230, loss: 0.0005268134991638362
step: 240, loss: 0.00015831415657885373
step: 250, loss: 0.00027489083004184067
step: 260, loss: 0.04300422966480255
step: 270, loss: 0.001201772945933044
step: 280, loss: 0.00022590368462260813
step: 290, loss: 0.00016958705964498222
step: 300, loss: 5.8212081057718024e-05
step: 310, loss: 0.04784106835722923
step: 320, loss: 0.0001089795769075863
step: 330, loss: 0.0003999780456069857
step: 340, loss: 3.89730412280187e-05
step: 350, loss: 5.130574936629273e-05
step: 360, loss: 0.03911520913243294
step: 370, loss: 8.87778660398908e-05
step: 380, loss: 0.0002060645492747426
step: 390, loss: 0.002534888219088316
step: 400, loss: 0.00012699856597464532
step: 410, loss: 0.0006585285882465541
step: 420, loss: 0.00014387353439815342
epoch 17: dev_f1=0.6801801801801802, f1=0.6128266033254157, best_f1=0.6735966735966735
step: 0, loss: 0.00021187450329307467
step: 10, loss: 0.05427750572562218
step: 20, loss: 7.85487936809659e-05
step: 30, loss: 0.0003130442928522825
step: 40, loss: 5.2069080993533134e-05
step: 50, loss: 0.000151664818986319
step: 60, loss: 0.004773939028382301
step: 70, loss: 0.0003235469339415431
step: 80, loss: 0.004341600928455591
step: 90, loss: 0.00014126126188784838
step: 100, loss: 0.0023175294045358896
step: 110, loss: 0.04095074161887169
step: 120, loss: 0.00010691476927604526
step: 130, loss: 0.0005873968475498259
step: 140, loss: 0.00013343033788260072
step: 150, loss: 0.03076242469251156
step: 160, loss: 6.748420128133148e-05
step: 170, loss: 7.798279693815857e-05
step: 180, loss: 0.0001070956714102067
step: 190, loss: 0.0001629305479582399
step: 200, loss: 0.00019695037917699665
step: 210, loss: 0.00013975189358461648
step: 220, loss: 0.001587565871886909
step: 230, loss: 6.806551391491666e-05
step: 240, loss: 0.000197985878912732
step: 250, loss: 0.000132207409478724
step: 260, loss: 0.00012067332863807678
step: 270, loss: 0.0004038702172692865
step: 280, loss: 0.003743307199329138
step: 290, loss: 0.00020448831492103636
step: 300, loss: 0.00013709503400605172
step: 310, loss: 6.421786383725703e-05
step: 320, loss: 6.775391375413164e-05
step: 330, loss: 0.05038876831531525
step: 340, loss: 0.0003402786678634584
step: 350, loss: 0.0006901286542415619
step: 360, loss: 0.00021535481209866703
step: 370, loss: 0.00026748087839223444
step: 380, loss: 0.00036505641764961183
step: 390, loss: 3.7333356885937974e-05
step: 400, loss: 0.0002947792236227542
step: 410, loss: 0.002815369749441743
step: 420, loss: 0.0029467286076396704
epoch 18: dev_f1=0.6932773109243697, f1=0.6294642857142857, best_f1=0.6735966735966735
step: 0, loss: 0.00026068187435157597
step: 10, loss: 4.2961757571902126e-05
step: 20, loss: 0.017496036365628242
step: 30, loss: 4.772873580805026e-05
step: 40, loss: 0.00014243605255614966
step: 50, loss: 0.005030786618590355
step: 60, loss: 6.621642387472093e-05
step: 70, loss: 0.00022804198670201004
step: 80, loss: 0.00018648082914296538
step: 90, loss: 5.353051528800279e-05
step: 100, loss: 0.0034220258239656687
step: 110, loss: 0.00017985128215514123
step: 120, loss: 7.874456059653312e-05
step: 130, loss: 0.0012013548985123634
step: 140, loss: 8.835296466713771e-05
step: 150, loss: 9.53619455685839e-05
step: 160, loss: 0.0004174898494966328
step: 170, loss: 8.685953798703849e-05
step: 180, loss: 0.0009375513764098287
step: 190, loss: 0.003963350784033537
step: 200, loss: 4.631235424312763e-05
step: 210, loss: 0.006413733121007681
step: 220, loss: 0.00041136547224596143
step: 230, loss: 0.01714370958507061
step: 240, loss: 9.861432044999674e-05
step: 250, loss: 7.901142089394853e-05
step: 260, loss: 0.00011134901433251798
step: 270, loss: 0.0023996024392545223
step: 280, loss: 0.0026797375176101923
step: 290, loss: 0.0001825428771553561
step: 300, loss: 6.663842941634357e-05
step: 310, loss: 0.009947852231562138
step: 320, loss: 0.00893415603786707
step: 330, loss: 0.00013905363448429853
step: 340, loss: 0.034262049943208694
step: 350, loss: 7.86968957982026e-05
step: 360, loss: 0.014872669242322445
step: 370, loss: 0.0001279046991840005
step: 380, loss: 7.52930500311777e-05
step: 390, loss: 6.926635251147673e-05
step: 400, loss: 0.0005751507123932242
step: 410, loss: 6.378777470672503e-05
step: 420, loss: 0.0003886295307893306
epoch 19: dev_f1=0.6838709677419355, f1=0.6139534883720931, best_f1=0.6735966735966735
step: 0, loss: 0.002201245166361332
step: 10, loss: 0.0006618025945499539
step: 20, loss: 0.0004794212873093784
step: 30, loss: 0.00016381197201553732
step: 40, loss: 5.011302710045129e-05
step: 50, loss: 0.0001149961244664155
step: 60, loss: 0.00010860389011213556
step: 70, loss: 0.00030761410016566515
step: 80, loss: 5.9427140513435006e-05
step: 90, loss: 0.000317485595587641
step: 100, loss: 0.03343883156776428
step: 110, loss: 3.754961653612554e-05
step: 120, loss: 0.0028950192499905825
step: 130, loss: 4.736465052701533e-05
step: 140, loss: 0.01662762463092804
step: 150, loss: 0.00028617712086997926
step: 160, loss: 0.00027111422969028354
step: 170, loss: 0.00010246306919725612
step: 180, loss: 3.167896284139715e-05
step: 190, loss: 8.734501170692965e-05
step: 200, loss: 4.253673614584841e-05
step: 210, loss: 4.8593938117846847e-05
step: 220, loss: 4.712278678198345e-05
step: 230, loss: 0.00011745037045329809
step: 240, loss: 6.404976011253893e-05
step: 250, loss: 0.00040970797999762
step: 260, loss: 0.04755448177456856
step: 270, loss: 4.210185579722747e-05
step: 280, loss: 4.2343312088632956e-05
step: 290, loss: 0.0006357466918416321
step: 300, loss: 0.002068875590339303
step: 310, loss: 0.0002500074915587902
step: 320, loss: 0.0004931188304908574
step: 330, loss: 0.02396068535745144
step: 340, loss: 4.6313311031553894e-05
step: 350, loss: 0.0003236340417061001
step: 360, loss: 8.15630701254122e-05
step: 370, loss: 0.004000213462859392
step: 380, loss: 0.009655018337070942
step: 390, loss: 0.010777037590742111
step: 400, loss: 0.00012460676953196526
step: 410, loss: 0.012148837558925152
step: 420, loss: 4.948145215166733e-05
epoch 20: dev_f1=0.6811279826464208, f1=0.6093023255813953, best_f1=0.6735966735966735
