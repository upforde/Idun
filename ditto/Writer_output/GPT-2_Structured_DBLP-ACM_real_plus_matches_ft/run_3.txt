cuda
Device: cuda
step: 0, loss: 0.7248184680938721
step: 10, loss: 0.5604947209358215
step: 20, loss: 0.5891487002372742
step: 30, loss: 0.43460962176322937
step: 40, loss: 0.3358685374259949
step: 50, loss: 0.31161466240882874
step: 60, loss: 0.31655552983283997
step: 70, loss: 0.21003174781799316
step: 80, loss: 0.12075728178024292
step: 90, loss: 0.18164964020252228
step: 100, loss: 0.1666882187128067
step: 110, loss: 0.2682817578315735
step: 120, loss: 0.26558852195739746
step: 130, loss: 0.2541080713272095
step: 140, loss: 0.15942613780498505
step: 150, loss: 0.0747520849108696
step: 160, loss: 0.19023475050926208
step: 170, loss: 0.02305164933204651
step: 180, loss: 0.0577041357755661
step: 190, loss: 0.13381250202655792
step: 200, loss: 0.04258052259683609
step: 210, loss: 0.03995866701006889
step: 220, loss: 0.32116812467575073
step: 230, loss: 0.19904926419258118
step: 240, loss: 0.02701554447412491
step: 250, loss: 0.1281288117170334
step: 260, loss: 0.08173441886901855
step: 270, loss: 0.24597199261188507
epoch 1: dev_f1=0.9529276693455797, f1=0.9553264604810996, best_f1=0.9553264604810996
step: 0, loss: 0.053391698747873306
step: 10, loss: 0.2929215431213379
step: 20, loss: 0.04105000197887421
step: 30, loss: 0.29844969511032104
step: 40, loss: 0.16245844960212708
step: 50, loss: 0.04095107316970825
step: 60, loss: 0.004065872635692358
step: 70, loss: 0.014639484696090221
step: 80, loss: 0.02341555617749691
step: 90, loss: 0.00560553977265954
step: 100, loss: 0.1385926753282547
step: 110, loss: 0.07041948288679123
step: 120, loss: 0.006588395219296217
step: 130, loss: 0.008251236751675606
step: 140, loss: 0.012959737330675125
step: 150, loss: 0.013123740442097187
step: 160, loss: 0.021011194214224815
step: 170, loss: 0.005077776033431292
step: 180, loss: 0.02598433941602707
step: 190, loss: 0.007400346454232931
step: 200, loss: 0.06298082321882248
step: 210, loss: 0.051918283104896545
step: 220, loss: 0.04525668919086456
step: 230, loss: 0.03992386534810066
step: 240, loss: 0.025981230661273003
step: 250, loss: 0.014835234731435776
step: 260, loss: 0.02943269908428192
step: 270, loss: 0.0707063302397728
epoch 2: dev_f1=0.9821029082774049, f1=0.9841628959276018, best_f1=0.9841628959276018
step: 0, loss: 0.0067530362866818905
step: 10, loss: 0.01948964223265648
step: 20, loss: 0.1670682728290558
step: 30, loss: 0.09116193652153015
step: 40, loss: 0.07652304321527481
step: 50, loss: 0.006405666936188936
step: 60, loss: 0.1859583705663681
step: 70, loss: 0.008538108319044113
step: 80, loss: 0.013319098390638828
step: 90, loss: 0.06992615759372711
step: 100, loss: 0.02793208882212639
step: 110, loss: 0.0032424707897007465
step: 120, loss: 0.12420885264873505
step: 130, loss: 0.025929557159543037
step: 140, loss: 0.04675886034965515
step: 150, loss: 0.13383950293064117
step: 160, loss: 0.18025970458984375
step: 170, loss: 0.013320263475179672
step: 180, loss: 0.12141991406679153
step: 190, loss: 0.09046574681997299
step: 200, loss: 0.003423984395340085
step: 210, loss: 0.03950262814760208
step: 220, loss: 0.025030799210071564
step: 230, loss: 0.004312209784984589
step: 240, loss: 0.0027485189493745565
step: 250, loss: 0.045583438128232956
step: 260, loss: 0.00967278704047203
step: 270, loss: 0.00425616092979908
epoch 3: dev_f1=0.9831649831649831, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.0035537530202418566
step: 10, loss: 0.010243485681712627
step: 20, loss: 0.003959068562835455
step: 30, loss: 0.014889947138726711
step: 40, loss: 0.002224496565759182
step: 50, loss: 0.019346456974744797
step: 60, loss: 0.187395378947258
step: 70, loss: 0.12183381617069244
step: 80, loss: 0.12446863949298859
step: 90, loss: 0.0036622982006520033
step: 100, loss: 0.004464076831936836
step: 110, loss: 0.003357959445565939
step: 120, loss: 0.006619807332754135
step: 130, loss: 0.012284926138818264
step: 140, loss: 0.009053174406290054
step: 150, loss: 0.006414773408323526
step: 160, loss: 0.014478644356131554
step: 170, loss: 0.0020982238929718733
step: 180, loss: 0.0012055541155859828
step: 190, loss: 0.023558519780635834
step: 200, loss: 0.0016344499308615923
step: 210, loss: 0.007839873433113098
step: 220, loss: 0.0019338546553626657
step: 230, loss: 0.09111420810222626
step: 240, loss: 0.0021606043446809053
step: 250, loss: 0.04922447353601456
step: 260, loss: 0.0042550228536129
step: 270, loss: 0.024127909913659096
epoch 4: dev_f1=0.9808773903262092, f1=0.9728506787330317, best_f1=0.9831271091113611
step: 0, loss: 0.00585361709818244
step: 10, loss: 0.12055910378694534
step: 20, loss: 0.006595066748559475
step: 30, loss: 0.003520132042467594
step: 40, loss: 0.01480828132480383
step: 50, loss: 0.0760783776640892
step: 60, loss: 0.0013921427307650447
step: 70, loss: 0.002320916159078479
step: 80, loss: 0.0012762041296809912
step: 90, loss: 0.22298641502857208
step: 100, loss: 0.00121575896628201
step: 110, loss: 0.0019141577649861574
step: 120, loss: 0.008703640662133694
step: 130, loss: 0.0013699110131710768
step: 140, loss: 0.02871672995388508
step: 150, loss: 0.0010892782593145967
step: 160, loss: 0.003749686060473323
step: 170, loss: 0.0030969821382313967
step: 180, loss: 0.06056862324476242
step: 190, loss: 0.015286252833902836
step: 200, loss: 0.017072167247533798
step: 210, loss: 0.001732046715915203
step: 220, loss: 0.00876163225620985
step: 230, loss: 0.02771562896668911
step: 240, loss: 0.0029627797193825245
step: 250, loss: 0.005766655784100294
step: 260, loss: 0.023809732869267464
step: 270, loss: 0.0008808885468170047
epoch 5: dev_f1=0.9898305084745763, f1=0.9864253393665158, best_f1=0.9864253393665158
step: 0, loss: 0.008299821056425571
step: 10, loss: 0.053169988095760345
step: 20, loss: 0.001307594939135015
step: 30, loss: 0.001399123459123075
step: 40, loss: 0.007106904871761799
step: 50, loss: 0.006140104494988918
step: 60, loss: 0.002347176894545555
step: 70, loss: 0.0006110819522291422
step: 80, loss: 0.005259554833173752
step: 90, loss: 0.0006052745156921446
step: 100, loss: 0.0009492664830759168
step: 110, loss: 0.003448318224400282
step: 120, loss: 0.0035170107148587704
step: 130, loss: 0.0687834620475769
step: 140, loss: 0.05512906610965729
step: 150, loss: 0.0014545312151312828
step: 160, loss: 0.0007456878083758056
step: 170, loss: 0.03715484216809273
step: 180, loss: 0.0031496360898017883
step: 190, loss: 0.0016124213580042124
step: 200, loss: 0.0322682186961174
step: 210, loss: 0.0008586782496422529
step: 220, loss: 0.0015136422589421272
step: 230, loss: 0.0005449378513731062
step: 240, loss: 0.017286483198404312
step: 250, loss: 0.0008033491321839392
step: 260, loss: 0.0006279316148720682
step: 270, loss: 0.0010359510779380798
epoch 6: dev_f1=0.9876819708846584, f1=0.9853438556933484, best_f1=0.9864253393665158
step: 0, loss: 0.005265938583761454
step: 10, loss: 0.0014050755416974425
step: 20, loss: 0.001119373133406043
step: 30, loss: 0.005739213433116674
step: 40, loss: 0.030169252306222916
step: 50, loss: 0.0013964255340397358
step: 60, loss: 0.0015360672259703279
step: 70, loss: 0.030566079542040825
step: 80, loss: 0.011314716190099716
step: 90, loss: 0.00141524663195014
step: 100, loss: 0.0011371612781658769
step: 110, loss: 0.0023713265545666218
step: 120, loss: 0.05539867281913757
step: 130, loss: 0.0007261171704158187
step: 140, loss: 0.0005783966043964028
step: 150, loss: 0.025458401069045067
step: 160, loss: 0.007407652214169502
step: 170, loss: 0.001661455724388361
step: 180, loss: 0.002306869486346841
step: 190, loss: 0.0011674538254737854
step: 200, loss: 0.0017286587972193956
step: 210, loss: 0.0021260406356304884
step: 220, loss: 0.06986874341964722
step: 230, loss: 0.0005608468782156706
step: 240, loss: 0.0021579733584076166
step: 250, loss: 0.018001127988100052
step: 260, loss: 0.0179987121373415
step: 270, loss: 0.00032556854421272874
epoch 7: dev_f1=0.9875424688561721, f1=0.9829738933030647, best_f1=0.9864253393665158
step: 0, loss: 0.0004487218684516847
step: 10, loss: 0.016938067972660065
step: 20, loss: 0.0005297778989188373
step: 30, loss: 0.0007652650238014758
step: 40, loss: 0.0005105374148115516
step: 50, loss: 0.0014604682801291347
step: 60, loss: 0.01867230236530304
step: 70, loss: 0.0004079373902641237
step: 80, loss: 0.0012095996644347906
step: 90, loss: 0.011800543405115604
step: 100, loss: 0.01078894641250372
step: 110, loss: 0.015273944474756718
step: 120, loss: 0.005213429220020771
step: 130, loss: 0.002106798579916358
step: 140, loss: 0.0017876122146844864
step: 150, loss: 0.0036728179547935724
step: 160, loss: 0.0007534502074122429
step: 170, loss: 0.0008366976981051266
step: 180, loss: 0.0019067323300987482
step: 190, loss: 0.04426838830113411
step: 200, loss: 0.002104805549606681
step: 210, loss: 0.0013360921293497086
step: 220, loss: 0.0006730331224389374
step: 230, loss: 0.0008341921493411064
step: 240, loss: 0.0008539294940419495
step: 250, loss: 0.001431200304068625
step: 260, loss: 0.0018037214176729321
step: 270, loss: 0.00045522593427449465
epoch 8: dev_f1=0.9729119638826186, f1=0.9797752808988766, best_f1=0.9864253393665158
step: 0, loss: 0.005163822788745165
step: 10, loss: 0.0019337134435772896
step: 20, loss: 0.00024945574114099145
step: 30, loss: 0.00099328497890383
step: 40, loss: 0.06299126148223877
step: 50, loss: 0.0004888026160188019
step: 60, loss: 0.000581547268666327
step: 70, loss: 0.0037823431193828583
step: 80, loss: 0.00522613525390625
step: 90, loss: 0.0008197037968784571
step: 100, loss: 0.0010563917458057404
step: 110, loss: 0.0006354897050186992
step: 120, loss: 0.004498964641243219
step: 130, loss: 0.0021255037281662226
step: 140, loss: 0.0003785966255236417
step: 150, loss: 0.0008364149834960699
step: 160, loss: 0.00165779166854918
step: 170, loss: 0.0010999722871929407
step: 180, loss: 0.0015844333684071898
step: 190, loss: 0.0010679577244445682
step: 200, loss: 0.0002880416577681899
step: 210, loss: 0.0010152432369068265
step: 220, loss: 0.0013838323066011071
step: 230, loss: 0.00029356320737861097
step: 240, loss: 0.00027924979804083705
step: 250, loss: 0.0011299701873213053
step: 260, loss: 0.00419032946228981
step: 270, loss: 0.000375350791728124
epoch 9: dev_f1=0.988814317673378, f1=0.9799554565701558, best_f1=0.9864253393665158
step: 0, loss: 0.0007900946075096726
step: 10, loss: 0.001251567853614688
step: 20, loss: 0.0010213785571977496
step: 30, loss: 0.0014483236009255052
step: 40, loss: 0.00044897632324136794
step: 50, loss: 0.0003084517957177013
step: 60, loss: 0.0010429539252072573
step: 70, loss: 0.030595147982239723
step: 80, loss: 0.001100959605537355
step: 90, loss: 0.0029458508361130953
step: 100, loss: 0.0006063636974431574
step: 110, loss: 0.00040260847890749574
step: 120, loss: 0.0008398407371714711
step: 130, loss: 0.005010601133108139
step: 140, loss: 0.0022654319182038307
step: 150, loss: 0.09573560208082199
step: 160, loss: 0.004978597164154053
step: 170, loss: 0.07310271263122559
step: 180, loss: 0.0007916741888038814
step: 190, loss: 0.0018170246621593833
step: 200, loss: 0.00027744300314225256
step: 210, loss: 0.00014678768638987094
step: 220, loss: 0.00024780628154985607
step: 230, loss: 0.00046790449414402246
step: 240, loss: 0.0006861920119263232
step: 250, loss: 0.0016780686564743519
step: 260, loss: 0.0003764583670999855
step: 270, loss: 0.000981596065685153
epoch 10: dev_f1=0.9898989898989898, f1=0.9821428571428571, best_f1=0.9821428571428571
step: 0, loss: 0.00031082885107025504
step: 10, loss: 0.0004624406574293971
step: 20, loss: 0.00030315035837702453
step: 30, loss: 0.00026412817533127964
step: 40, loss: 0.0005282351630739868
step: 50, loss: 0.00025002920301631093
step: 60, loss: 0.0001518174249213189
step: 70, loss: 0.00019592928583733737
step: 80, loss: 0.00216110423207283
step: 90, loss: 0.00026546267326921225
step: 100, loss: 0.0006162443314678967
step: 110, loss: 0.00037200702354311943
step: 120, loss: 0.0003466987982392311
step: 130, loss: 0.002809082856401801
step: 140, loss: 0.0011521672131493688
step: 150, loss: 0.006331390701234341
step: 160, loss: 0.0014655351405963302
step: 170, loss: 0.00020579971896950155
step: 180, loss: 0.010258694179356098
step: 190, loss: 0.0002603881584946066
step: 200, loss: 0.00019511484424583614
step: 210, loss: 0.000411295797675848
step: 220, loss: 0.0002121317374985665
step: 230, loss: 0.05587496981024742
step: 240, loss: 0.0007041522185318172
step: 250, loss: 0.026932528242468834
step: 260, loss: 0.00014915131032466888
step: 270, loss: 0.04916134476661682
epoch 11: dev_f1=0.9888392857142857, f1=0.9821826280623607, best_f1=0.9821428571428571
step: 0, loss: 0.00021522720635402948
step: 10, loss: 0.00017511766054667532
step: 20, loss: 0.00018613392603583634
step: 30, loss: 0.00012705045810434967
step: 40, loss: 0.00015499818255193532
step: 50, loss: 0.00016179269005078822
step: 60, loss: 0.0005072713829576969
step: 70, loss: 0.00015602450002916157
step: 80, loss: 0.03263305500149727
step: 90, loss: 0.00043785624438896775
step: 100, loss: 0.05114922672510147
step: 110, loss: 0.03256809711456299
step: 120, loss: 0.000882314401678741
step: 130, loss: 0.0032394805457443
step: 140, loss: 0.0008746403036639094
step: 150, loss: 0.0031663894187659025
step: 160, loss: 0.0003285783459432423
step: 170, loss: 0.0012619646731764078
step: 180, loss: 0.004293837584555149
step: 190, loss: 0.021266896277666092
step: 200, loss: 0.0003123893984593451
step: 210, loss: 0.00022903000353835523
step: 220, loss: 0.00018828238535206765
step: 230, loss: 0.00026898470241576433
step: 240, loss: 0.00015822173736523837
step: 250, loss: 0.02371610887348652
step: 260, loss: 0.0013722998555749655
step: 270, loss: 0.0001179684404633008
epoch 12: dev_f1=0.9854748603351955, f1=0.9821428571428571, best_f1=0.9821428571428571
step: 0, loss: 0.001749504590407014
step: 10, loss: 0.00932674016803503
step: 20, loss: 0.002951645525172353
step: 30, loss: 0.0005653488333337009
step: 40, loss: 0.00025488476967439055
step: 50, loss: 0.00012053902173647657
step: 60, loss: 7.922104850877076e-05
step: 70, loss: 0.0003286092833150178
step: 80, loss: 0.00010771100642159581
step: 90, loss: 0.0004948582500219345
step: 100, loss: 0.00012721882376354188
step: 110, loss: 0.0002739100018516183
step: 120, loss: 0.0002636220306158066
step: 130, loss: 0.00014525730512104928
step: 140, loss: 0.00015226307732518762
step: 150, loss: 0.0001900131319416687
step: 160, loss: 0.0014461688697338104
step: 170, loss: 0.00041530808084644377
step: 180, loss: 0.0003109118260908872
step: 190, loss: 0.0034734143409878016
step: 200, loss: 0.005488284397870302
step: 210, loss: 0.0002965620078612119
step: 220, loss: 0.00041431456338614225
step: 230, loss: 0.0038849979173392057
step: 240, loss: 0.00017355855379719287
step: 250, loss: 0.03760603070259094
step: 260, loss: 0.00032572122290730476
step: 270, loss: 0.0006606272072531283
epoch 13: dev_f1=0.9875141884222476, f1=0.9841628959276018, best_f1=0.9821428571428571
step: 0, loss: 0.00026331021217629313
step: 10, loss: 0.005715701263397932
step: 20, loss: 0.00030744937248528004
step: 30, loss: 0.00022581650409847498
step: 40, loss: 0.0003082354087382555
step: 50, loss: 0.0002167743950849399
step: 60, loss: 0.0009554034913890064
step: 70, loss: 0.029834501445293427
step: 80, loss: 0.0013833215925842524
step: 90, loss: 0.0004790004750248045
step: 100, loss: 0.0003076396242249757
step: 110, loss: 0.0003180434287060052
step: 120, loss: 0.0002678820164874196
step: 130, loss: 0.0010903613874688745
step: 140, loss: 0.013323206454515457
step: 150, loss: 0.009145761840045452
step: 160, loss: 0.0003118467575404793
step: 170, loss: 0.00021699094213545322
step: 180, loss: 0.00010429148096591234
step: 190, loss: 0.0011923843994736671
step: 200, loss: 0.00016085203969851136
step: 210, loss: 0.003099358407780528
step: 220, loss: 0.0004960084334015846
step: 230, loss: 0.00023647319176234305
step: 240, loss: 0.0015500503359362483
step: 250, loss: 0.0067384555004537106
step: 260, loss: 0.00030747175333090127
step: 270, loss: 0.0013735927641391754
epoch 14: dev_f1=0.9864864864864865, f1=0.9853438556933484, best_f1=0.9821428571428571
step: 0, loss: 0.0005679336027242243
step: 10, loss: 0.00019266306480858475
step: 20, loss: 0.0004217688401695341
step: 30, loss: 0.018573984503746033
step: 40, loss: 0.00015374246868304908
step: 50, loss: 0.0003607941616792232
step: 60, loss: 0.000993629451841116
step: 70, loss: 0.0002126564650097862
step: 80, loss: 0.000818511878605932
step: 90, loss: 0.016925442963838577
step: 100, loss: 0.00011986066965619102
step: 110, loss: 8.358203922398388e-05
step: 120, loss: 8.908419113140553e-05
step: 130, loss: 0.001264466904103756
step: 140, loss: 0.00015082763275131583
step: 150, loss: 0.0003923253098037094
step: 160, loss: 0.00013197161024436355
step: 170, loss: 0.00012848575715906918
step: 180, loss: 0.0789666697382927
step: 190, loss: 9.883279562927783e-05
step: 200, loss: 0.015789857134222984
step: 210, loss: 0.0005702254711650312
step: 220, loss: 0.0004515379259828478
step: 230, loss: 0.00044367159716784954
step: 240, loss: 0.0027924617752432823
step: 250, loss: 0.0001932986342580989
step: 260, loss: 0.0005214221309870481
step: 270, loss: 0.0002998298150487244
epoch 15: dev_f1=0.987598647125141, f1=0.9853438556933484, best_f1=0.9821428571428571
step: 0, loss: 0.00011184089089510962
step: 10, loss: 0.00024525439948774874
step: 20, loss: 0.00047978406655602157
step: 30, loss: 0.00021370842296164483
step: 40, loss: 0.000684309983626008
step: 50, loss: 0.0007115456974133849
step: 60, loss: 0.0044294968247413635
step: 70, loss: 0.00012486509513109922
step: 80, loss: 0.00021251307043712586
step: 90, loss: 0.0010491226566955447
step: 100, loss: 0.00011505403381306678
step: 110, loss: 0.026666205376386642
step: 120, loss: 0.0001594241475686431
step: 130, loss: 0.00014879678201396018
step: 140, loss: 0.00020749689429067075
step: 150, loss: 9.68089880188927e-05
step: 160, loss: 0.0005190068623051047
step: 170, loss: 0.018602201715111732
step: 180, loss: 0.00013088660489302129
step: 190, loss: 0.00019860515021719038
step: 200, loss: 0.00023713927657809108
step: 210, loss: 7.634822395630181e-05
step: 220, loss: 0.00025724456645548344
step: 230, loss: 0.00010864726937143132
step: 240, loss: 0.021936455741524696
step: 250, loss: 0.0001924151583807543
step: 260, loss: 0.0026607559993863106
step: 270, loss: 0.017883218824863434
epoch 16: dev_f1=0.987709497206704, f1=0.983277591973244, best_f1=0.9821428571428571
step: 0, loss: 0.023617947474122047
step: 10, loss: 0.0002714220609050244
step: 20, loss: 9.404156298842281e-05
step: 30, loss: 0.01670878380537033
step: 40, loss: 6.126269727246836e-05
step: 50, loss: 7.783310138620436e-05
step: 60, loss: 0.0001691533107077703
step: 70, loss: 0.00016140066145453602
step: 80, loss: 0.00013807749201077968
step: 90, loss: 7.719117274973541e-05
step: 100, loss: 0.0002733013534452766
step: 110, loss: 0.00023784415679983795
step: 120, loss: 0.00012891864753328264
step: 130, loss: 0.00010821181786013767
step: 140, loss: 9.560277976561338e-05
step: 150, loss: 0.00020881043747067451
step: 160, loss: 0.00012500745651777834
step: 170, loss: 0.00013744093303103
step: 180, loss: 0.004288270603865385
step: 190, loss: 8.321726636495441e-05
step: 200, loss: 8.417874050792307e-05
step: 210, loss: 0.00012528992374427617
step: 220, loss: 0.0001641999842831865
step: 230, loss: 0.00011375172471161932
step: 240, loss: 0.01682107336819172
step: 250, loss: 0.0005828115972690284
step: 260, loss: 0.015409889630973339
step: 270, loss: 7.291722431546077e-05
epoch 17: dev_f1=0.9887387387387387, f1=0.9820627802690582, best_f1=0.9821428571428571
step: 0, loss: 0.01434032991528511
step: 10, loss: 0.000122679746709764
step: 20, loss: 0.003808377543464303
step: 30, loss: 6.979340105317533e-05
step: 40, loss: 0.00022962133516557515
step: 50, loss: 7.232985080918297e-05
step: 60, loss: 0.00013337972632143646
step: 70, loss: 0.04335805028676987
step: 80, loss: 0.00014324180665425956
step: 90, loss: 7.478115730918944e-05
step: 100, loss: 8.817846537567675e-05
step: 110, loss: 5.905790385440923e-05
step: 120, loss: 0.00014842966629657894
step: 130, loss: 9.285935084335506e-05
step: 140, loss: 5.954223524895497e-05
step: 150, loss: 0.0007930631982162595
step: 160, loss: 5.5001568398438394e-05
step: 170, loss: 8.489825995638967e-05
step: 180, loss: 8.315582817886025e-05
step: 190, loss: 6.568081880686805e-05
step: 200, loss: 6.576457963092253e-05
step: 210, loss: 7.291278598131612e-05
step: 220, loss: 0.007296126335859299
step: 230, loss: 7.12679247953929e-05
step: 240, loss: 8.696373697603121e-05
step: 250, loss: 0.0001008501130854711
step: 260, loss: 0.00046803682926110923
step: 270, loss: 0.00011065512808272615
epoch 18: dev_f1=0.9888392857142857, f1=0.9810901001112348, best_f1=0.9821428571428571
step: 0, loss: 9.676138870418072e-05
step: 10, loss: 7.147964061005041e-05
step: 20, loss: 0.00011983154399786144
step: 30, loss: 0.00013032795686740428
step: 40, loss: 6.462605961132795e-05
step: 50, loss: 4.67247336928267e-05
step: 60, loss: 6.818398833274841e-05
step: 70, loss: 0.00014998186088632792
step: 80, loss: 0.0007054036832414567
step: 90, loss: 0.000146852049510926
step: 100, loss: 0.0016121972585096955
step: 110, loss: 6.736481736879796e-05
step: 120, loss: 0.00016707675240468234
step: 130, loss: 6.297251093201339e-05
step: 140, loss: 0.00016463326755911112
step: 150, loss: 0.03384069725871086
step: 160, loss: 6.505452620331198e-05
step: 170, loss: 0.0003887951315846294
step: 180, loss: 6.424207822419703e-05
step: 190, loss: 6.983325874898583e-05
step: 200, loss: 0.0010093902237713337
step: 210, loss: 0.00010218475654255599
step: 220, loss: 8.3534287114162e-05
step: 230, loss: 5.701191184925847e-05
step: 240, loss: 6.510665116365999e-05
step: 250, loss: 0.0001505084364907816
step: 260, loss: 8.563965820940211e-05
step: 270, loss: 8.570603677071631e-05
epoch 19: dev_f1=0.9888392857142857, f1=0.9810901001112348, best_f1=0.9821428571428571
step: 0, loss: 0.000183765689143911
step: 10, loss: 6.542352639371529e-05
step: 20, loss: 8.386163972318172e-05
step: 30, loss: 6.334149657050148e-05
step: 40, loss: 6.469580694101751e-05
step: 50, loss: 7.72056810092181e-05
step: 60, loss: 0.0005721627967432141
step: 70, loss: 0.0001386663061566651
step: 80, loss: 0.00030922688893042505
step: 90, loss: 5.0997070502489805e-05
step: 100, loss: 7.58599562686868e-05
step: 110, loss: 6.97952855261974e-05
step: 120, loss: 7.719992572674528e-05
step: 130, loss: 0.00014351654681377113
step: 140, loss: 0.0005371654406189919
step: 150, loss: 0.008677072823047638
step: 160, loss: 0.016413848847150803
step: 170, loss: 9.157357999356464e-05
step: 180, loss: 0.0438731350004673
step: 190, loss: 0.00013767079508397728
step: 200, loss: 7.616508810315281e-05
step: 210, loss: 0.0004207126912660897
step: 220, loss: 8.015982166398317e-05
step: 230, loss: 6.620838394155726e-05
step: 240, loss: 6.126328662503511e-05
step: 250, loss: 7.35963840270415e-05
step: 260, loss: 8.276241715066135e-05
step: 270, loss: 0.00012211348803248256
epoch 20: dev_f1=0.9888392857142857, f1=0.9810901001112348, best_f1=0.9821428571428571
