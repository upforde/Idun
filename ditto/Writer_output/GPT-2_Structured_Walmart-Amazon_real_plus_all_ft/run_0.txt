cuda
Device: cuda
step: 0, loss: 0.6335501074790955
step: 10, loss: 0.22839686274528503
step: 20, loss: 0.2231791913509369
step: 30, loss: 0.4780063033103943
step: 40, loss: 0.24802207946777344
step: 50, loss: 0.30528178811073303
step: 60, loss: 0.34619447588920593
step: 70, loss: 0.32042360305786133
step: 80, loss: 0.26659053564071655
step: 90, loss: 0.3326267898082733
step: 100, loss: 0.28958913683891296
step: 110, loss: 0.18221086263656616
step: 120, loss: 0.3304288983345032
step: 130, loss: 0.15647286176681519
step: 140, loss: 0.38872095942497253
step: 150, loss: 0.32312461733818054
step: 160, loss: 0.3692241609096527
step: 170, loss: 0.5048781037330627
step: 180, loss: 0.3238288462162018
step: 190, loss: 0.26772183179855347
step: 200, loss: 0.34024864435195923
step: 210, loss: 0.24229691922664642
step: 220, loss: 0.11386103928089142
step: 230, loss: 0.4210106432437897
step: 240, loss: 0.34196150302886963
step: 250, loss: 0.26363229751586914
step: 260, loss: 0.2232033908367157
step: 270, loss: 0.5565070509910583
step: 280, loss: 0.27604085206985474
step: 290, loss: 0.25775212049484253
step: 300, loss: 0.15808545053005219
step: 310, loss: 0.26946720480918884
step: 320, loss: 0.21832583844661713
step: 330, loss: 0.04850439727306366
step: 340, loss: 0.14080284535884857
step: 350, loss: 0.08949582278728485
step: 360, loss: 0.3839598596096039
step: 370, loss: 0.20424257218837738
step: 380, loss: 0.23523932695388794
epoch 1: dev_f1=0.4067796610169492, f1=0.32225063938618925, best_f1=0.32225063938618925
step: 0, loss: 0.14638468623161316
step: 10, loss: 0.17768733203411102
step: 20, loss: 0.12688155472278595
step: 30, loss: 0.19512559473514557
step: 40, loss: 0.16583459079265594
step: 50, loss: 0.14726930856704712
step: 60, loss: 0.11320239305496216
step: 70, loss: 0.29823899269104004
step: 80, loss: 0.07704427093267441
step: 90, loss: 0.1626686155796051
step: 100, loss: 0.051428500562906265
step: 110, loss: 0.4364447593688965
step: 120, loss: 0.26677411794662476
step: 130, loss: 0.16980525851249695
step: 140, loss: 0.2204340100288391
step: 150, loss: 0.2964969575405121
step: 160, loss: 0.35099849104881287
step: 170, loss: 0.09736327826976776
step: 180, loss: 0.14946359395980835
step: 190, loss: 0.1674291044473648
step: 200, loss: 0.1342330425977707
step: 210, loss: 0.34823617339134216
step: 220, loss: 0.29543331265449524
step: 230, loss: 0.21848559379577637
step: 240, loss: 0.36333954334259033
step: 250, loss: 0.1656394749879837
step: 260, loss: 0.13531050086021423
step: 270, loss: 0.31255194544792175
step: 280, loss: 0.21181052923202515
step: 290, loss: 0.1499309539794922
step: 300, loss: 0.1292254775762558
step: 310, loss: 0.3280799090862274
step: 320, loss: 0.1678203046321869
step: 330, loss: 0.2860564589500427
step: 340, loss: 0.19425584375858307
step: 350, loss: 0.2732312083244324
step: 360, loss: 0.18223972618579865
step: 370, loss: 0.2693663239479065
step: 380, loss: 0.18555021286010742
epoch 2: dev_f1=0.6197916666666666, f1=0.5591397849462366, best_f1=0.5591397849462366
step: 0, loss: 0.09936904162168503
step: 10, loss: 0.13369445502758026
step: 20, loss: 0.09246979653835297
step: 30, loss: 0.08260975778102875
step: 40, loss: 0.08075381070375443
step: 50, loss: 0.016994046047329903
step: 60, loss: 0.030560385435819626
step: 70, loss: 0.1250922977924347
step: 80, loss: 0.12508921325206757
step: 90, loss: 0.09371575713157654
step: 100, loss: 0.06449742615222931
step: 110, loss: 0.05463627725839615
step: 120, loss: 0.05121154338121414
step: 130, loss: 0.11571989953517914
step: 140, loss: 0.19537213444709778
step: 150, loss: 0.05771944671869278
step: 160, loss: 0.024271192029118538
step: 170, loss: 0.06047222390770912
step: 180, loss: 0.1942661702632904
step: 190, loss: 0.17897461354732513
step: 200, loss: 0.17122767865657806
step: 210, loss: 0.24418292939662933
step: 220, loss: 0.13846276700496674
step: 230, loss: 0.08673284202814102
step: 240, loss: 0.038236360996961594
step: 250, loss: 0.12938007712364197
step: 260, loss: 0.31813153624534607
step: 270, loss: 0.03617699816823006
step: 280, loss: 0.14767324924468994
step: 290, loss: 0.10832443088293076
step: 300, loss: 0.21894074976444244
step: 310, loss: 0.19105014204978943
step: 320, loss: 0.16894976794719696
step: 330, loss: 0.19749051332473755
step: 340, loss: 0.06789939105510712
step: 350, loss: 0.13749070465564728
step: 360, loss: 0.13372258841991425
step: 370, loss: 0.160277858376503
step: 380, loss: 0.11739133298397064
epoch 3: dev_f1=0.6942148760330578, f1=0.603988603988604, best_f1=0.603988603988604
step: 0, loss: 0.08824849128723145
step: 10, loss: 0.026683205738663673
step: 20, loss: 0.09635992348194122
step: 30, loss: 0.09788445383310318
step: 40, loss: 0.05362837761640549
step: 50, loss: 0.043544963002204895
step: 60, loss: 0.03695498779416084
step: 70, loss: 0.04413643851876259
step: 80, loss: 0.026340585201978683
step: 90, loss: 0.01783483475446701
step: 100, loss: 0.0317654125392437
step: 110, loss: 0.009988108649849892
step: 120, loss: 0.10219727456569672
step: 130, loss: 0.1309136301279068
step: 140, loss: 0.07054170966148376
step: 150, loss: 0.11377110332250595
step: 160, loss: 0.0822046548128128
step: 170, loss: 0.07350107282400131
step: 180, loss: 0.09919963032007217
step: 190, loss: 0.039423029869794846
step: 200, loss: 0.24828065931797028
step: 210, loss: 0.08868475258350372
step: 220, loss: 0.10200676321983337
step: 230, loss: 0.03323543816804886
step: 240, loss: 0.07604287564754486
step: 250, loss: 0.12565232813358307
step: 260, loss: 0.03179734945297241
step: 270, loss: 0.03983060270547867
step: 280, loss: 0.05085936561226845
step: 290, loss: 0.03948244825005531
step: 300, loss: 0.20347784459590912
step: 310, loss: 0.16472937166690826
step: 320, loss: 0.005897065158933401
step: 330, loss: 0.004996106959879398
step: 340, loss: 0.06145390495657921
step: 350, loss: 0.13349109888076782
step: 360, loss: 0.09965835511684418
step: 370, loss: 0.0034585213288664818
step: 380, loss: 0.1020432859659195
epoch 4: dev_f1=0.6968838526912181, f1=0.5365853658536586, best_f1=0.5365853658536586
step: 0, loss: 0.013724981807172298
step: 10, loss: 0.03005126491189003
step: 20, loss: 0.008445740677416325
step: 30, loss: 0.0031632035970687866
step: 40, loss: 0.019212020561099052
step: 50, loss: 0.004931056872010231
step: 60, loss: 0.015483894385397434
step: 70, loss: 0.047733619809150696
step: 80, loss: 0.18240506947040558
step: 90, loss: 0.032585516571998596
step: 100, loss: 0.02033424936234951
step: 110, loss: 0.051245979964733124
step: 120, loss: 0.1420588195323944
step: 130, loss: 0.0034945618826895952
step: 140, loss: 0.07097826898097992
step: 150, loss: 0.01411418616771698
step: 160, loss: 0.03914235159754753
step: 170, loss: 0.0262564979493618
step: 180, loss: 0.028842804953455925
step: 190, loss: 0.04857680946588516
step: 200, loss: 0.046995859593153
step: 210, loss: 0.008064537309110165
step: 220, loss: 0.05894625559449196
step: 230, loss: 0.019203832373023033
step: 240, loss: 0.002566430950537324
step: 250, loss: 0.003162174252793193
step: 260, loss: 0.014676411636173725
step: 270, loss: 0.010122627019882202
step: 280, loss: 0.03981872648000717
step: 290, loss: 0.001957449596375227
step: 300, loss: 0.038552816957235336
step: 310, loss: 0.01647292822599411
step: 320, loss: 0.005496892146766186
step: 330, loss: 0.03845750167965889
step: 340, loss: 0.0424937978386879
step: 350, loss: 0.05129025876522064
step: 360, loss: 0.04439033940434456
step: 370, loss: 0.08975759148597717
step: 380, loss: 0.13787627220153809
epoch 5: dev_f1=0.7187499999999999, f1=0.6017191977077365, best_f1=0.6017191977077365
step: 0, loss: 0.013822644017636776
step: 10, loss: 0.09629151970148087
step: 20, loss: 0.0024727988056838512
step: 30, loss: 0.00867018848657608
step: 40, loss: 0.003496558405458927
step: 50, loss: 0.05914483964443207
step: 60, loss: 0.024190200492739677
step: 70, loss: 0.11559659987688065
step: 80, loss: 0.03521251305937767
step: 90, loss: 0.06440587341785431
step: 100, loss: 0.01670723594725132
step: 110, loss: 0.16766999661922455
step: 120, loss: 0.02510991133749485
step: 130, loss: 0.0014779563061892986
step: 140, loss: 0.0038842319045215845
step: 150, loss: 0.009577774442732334
step: 160, loss: 0.05628950893878937
step: 170, loss: 0.00878640916198492
step: 180, loss: 0.006126717664301395
step: 190, loss: 0.0073312316089868546
step: 200, loss: 0.029159249737858772
step: 210, loss: 0.014417897909879684
step: 220, loss: 0.0780438780784607
step: 230, loss: 0.028523782268166542
step: 240, loss: 0.09922288358211517
step: 250, loss: 0.004980733152478933
step: 260, loss: 0.007095401640981436
step: 270, loss: 0.010350087657570839
step: 280, loss: 0.011958823539316654
step: 290, loss: 0.025366157293319702
step: 300, loss: 0.03290118649601936
step: 310, loss: 0.0030307925771921873
step: 320, loss: 0.37624746561050415
step: 330, loss: 0.003253243863582611
step: 340, loss: 0.012549160048365593
step: 350, loss: 0.03661175072193146
step: 360, loss: 0.04363470897078514
step: 370, loss: 0.009859011508524418
step: 380, loss: 0.009149844758212566
epoch 6: dev_f1=0.7058823529411764, f1=0.6194225721784777, best_f1=0.6017191977077365
step: 0, loss: 0.017478957772254944
step: 10, loss: 0.007298654410988092
step: 20, loss: 0.03663019835948944
step: 30, loss: 0.031745828688144684
step: 40, loss: 0.00048341721412725747
step: 50, loss: 0.00039753943565301597
step: 60, loss: 0.0025467334780842066
step: 70, loss: 0.02202269248664379
step: 80, loss: 0.04020581766963005
step: 90, loss: 0.0029483712278306484
step: 100, loss: 0.012365210801362991
step: 110, loss: 0.006813040468841791
step: 120, loss: 0.03632495552301407
step: 130, loss: 0.20224182307720184
step: 140, loss: 0.0012043374590575695
step: 150, loss: 0.059515271335840225
step: 160, loss: 0.003281724639236927
step: 170, loss: 0.02435613051056862
step: 180, loss: 0.023507118225097656
step: 190, loss: 0.0019012396223843098
step: 200, loss: 0.03626887500286102
step: 210, loss: 0.03742299601435661
step: 220, loss: 0.004631149582564831
step: 230, loss: 0.08494693785905838
step: 240, loss: 0.0070813605561852455
step: 250, loss: 0.0010891794227063656
step: 260, loss: 0.05736813321709633
step: 270, loss: 0.0735936388373375
step: 280, loss: 0.016553567722439766
step: 290, loss: 0.0027937223203480244
step: 300, loss: 0.04439467191696167
step: 310, loss: 0.004083643201738596
step: 320, loss: 0.025073546916246414
step: 330, loss: 0.011489358730614185
step: 340, loss: 0.0011924306163564324
step: 350, loss: 0.007691662758588791
step: 360, loss: 0.0898744985461235
step: 370, loss: 0.004711648914963007
step: 380, loss: 0.0022750890348106623
epoch 7: dev_f1=0.7022900763358778, f1=0.5838150289017341, best_f1=0.6017191977077365
step: 0, loss: 0.005324223078787327
step: 10, loss: 0.002212279476225376
step: 20, loss: 0.0029040256049484015
step: 30, loss: 0.0007159331580623984
step: 40, loss: 0.0013785825576633215
step: 50, loss: 0.02372175268828869
step: 60, loss: 0.006766347214579582
step: 70, loss: 0.007583846338093281
step: 80, loss: 0.0023072187323123217
step: 90, loss: 0.0004691022331826389
step: 100, loss: 0.08701378107070923
step: 110, loss: 0.010363331064581871
step: 120, loss: 0.00066930684261024
step: 130, loss: 0.0057819741778075695
step: 140, loss: 0.005620996933430433
step: 150, loss: 0.0014419042272493243
step: 160, loss: 0.04218152537941933
step: 170, loss: 0.01256381906569004
step: 180, loss: 0.0006580693298019469
step: 190, loss: 0.0038410371635109186
step: 200, loss: 0.004395561292767525
step: 210, loss: 0.005479404237121344
step: 220, loss: 0.0031961025670170784
step: 230, loss: 0.0012500915909186006
step: 240, loss: 0.06316646933555603
step: 250, loss: 0.01869363896548748
step: 260, loss: 0.0008742713835090399
step: 270, loss: 0.16973593831062317
step: 280, loss: 0.003198862075805664
step: 290, loss: 0.07951666414737701
step: 300, loss: 0.1453404575586319
step: 310, loss: 0.002318809973075986
step: 320, loss: 0.012242327444255352
step: 330, loss: 0.004510360304266214
step: 340, loss: 0.01921314373612404
step: 350, loss: 0.0010477036703377962
step: 360, loss: 0.0008195287082344294
step: 370, loss: 0.004855882842093706
step: 380, loss: 0.0035404555965214968
epoch 8: dev_f1=0.7146282973621103, f1=0.6086956521739131, best_f1=0.6017191977077365
step: 0, loss: 0.011036179959774017
step: 10, loss: 0.0021995718125253916
step: 20, loss: 0.125413715839386
step: 30, loss: 0.12285920232534409
step: 40, loss: 0.03707753121852875
step: 50, loss: 0.006896721664816141
step: 60, loss: 0.11593315005302429
step: 70, loss: 0.012532643973827362
step: 80, loss: 0.0012445508036762476
step: 90, loss: 0.004386504180729389
step: 100, loss: 0.0007108956924639642
step: 110, loss: 0.017966270446777344
step: 120, loss: 0.08028033375740051
step: 130, loss: 0.0011251127580180764
step: 140, loss: 0.0012731964234262705
step: 150, loss: 0.001034521614201367
step: 160, loss: 0.0032543966080993414
step: 170, loss: 0.0015672635054215789
step: 180, loss: 0.00373294809833169
step: 190, loss: 0.0027028208132833242
step: 200, loss: 0.0016728974878787994
step: 210, loss: 0.00019609372247941792
step: 220, loss: 0.0007654922665096819
step: 230, loss: 0.006812937557697296
step: 240, loss: 0.04636140540242195
step: 250, loss: 0.006450291257351637
step: 260, loss: 0.0051079727709293365
step: 270, loss: 0.06673833727836609
step: 280, loss: 0.003910948522388935
step: 290, loss: 0.007691512815654278
step: 300, loss: 0.010946483351290226
step: 310, loss: 0.005394330248236656
step: 320, loss: 0.0035338043235242367
step: 330, loss: 0.0207553431391716
step: 340, loss: 0.046947140246629715
step: 350, loss: 0.014914171770215034
step: 360, loss: 0.044045526534318924
step: 370, loss: 0.001201563747599721
step: 380, loss: 0.005938158370554447
epoch 9: dev_f1=0.7142857142857142, f1=0.5492537313432836, best_f1=0.6017191977077365
step: 0, loss: 0.018561504781246185
step: 10, loss: 0.018867691978812218
step: 20, loss: 0.021999483928084373
step: 30, loss: 0.013364825397729874
step: 40, loss: 0.0037341362331062555
step: 50, loss: 0.001254803966730833
step: 60, loss: 0.009830514900386333
step: 70, loss: 0.001018800656311214
step: 80, loss: 0.0006092655821703374
step: 90, loss: 0.1083821952342987
step: 100, loss: 0.00529092364013195
step: 110, loss: 0.011549877002835274
step: 120, loss: 0.0014948169700801373
step: 130, loss: 0.0031531723216176033
step: 140, loss: 0.003665326861664653
step: 150, loss: 0.000486538716359064
step: 160, loss: 0.0003495439304970205
step: 170, loss: 0.0010008675744757056
step: 180, loss: 0.010466715320944786
step: 190, loss: 0.0006971223629079759
step: 200, loss: 0.0073379329405725
step: 210, loss: 0.00039571692468598485
step: 220, loss: 0.00016560193034820259
step: 230, loss: 0.008401787839829922
step: 240, loss: 0.0012693802127614617
step: 250, loss: 0.000396185991121456
step: 260, loss: 0.001497030956670642
step: 270, loss: 0.0005181856686249375
step: 280, loss: 0.006815620232373476
step: 290, loss: 0.002195516834035516
step: 300, loss: 0.03532738238573074
step: 310, loss: 0.002930955495685339
step: 320, loss: 0.05386308580636978
step: 330, loss: 0.0022159721702337265
step: 340, loss: 0.0009479468571953475
step: 350, loss: 0.019426872953772545
step: 360, loss: 0.0006135546718724072
step: 370, loss: 0.0011551922652870417
step: 380, loss: 0.0011765711242333055
epoch 10: dev_f1=0.7035175879396985, f1=0.5797872340425532, best_f1=0.6017191977077365
step: 0, loss: 0.000597205653320998
step: 10, loss: 0.0020361817441880703
step: 20, loss: 0.0017585515743121505
step: 30, loss: 0.00011485942377476022
step: 40, loss: 0.00628019031137228
step: 50, loss: 0.0021291193552315235
step: 60, loss: 0.00018980713502969593
step: 70, loss: 0.000279129104455933
step: 80, loss: 0.0014374502934515476
step: 90, loss: 0.00047067549894563854
step: 100, loss: 0.0043745385482907295
step: 110, loss: 0.041782692074775696
step: 120, loss: 0.0007421488407999277
step: 130, loss: 0.0018887651385739446
step: 140, loss: 0.035021714866161346
step: 150, loss: 0.00039599029696546495
step: 160, loss: 0.0008092832867987454
step: 170, loss: 0.0012016737600788474
step: 180, loss: 0.0029902877286076546
step: 190, loss: 0.0010208445601165295
step: 200, loss: 0.008690173737704754
step: 210, loss: 0.00023357324243988842
step: 220, loss: 0.001164610031992197
step: 230, loss: 0.0008623473113402724
step: 240, loss: 0.00023032678291201591
step: 250, loss: 5.322433207766153e-05
step: 260, loss: 0.0005134792882017791
step: 270, loss: 0.0019001045729964972
step: 280, loss: 4.416146839503199e-05
step: 290, loss: 0.0004251333011779934
step: 300, loss: 0.002436273265630007
step: 310, loss: 0.0139915831387043
step: 320, loss: 0.0002982425212394446
step: 330, loss: 0.00036565688787959516
step: 340, loss: 0.013868353329598904
step: 350, loss: 0.003226099768653512
step: 360, loss: 0.00048219910240732133
step: 370, loss: 0.0023476933129131794
step: 380, loss: 0.15539516508579254
epoch 11: dev_f1=0.7055837563451777, f1=0.5698630136986302, best_f1=0.6017191977077365
step: 0, loss: 0.029596608132123947
step: 10, loss: 0.0010129009606316686
step: 20, loss: 0.0003448277711868286
step: 30, loss: 0.0002610890951473266
step: 40, loss: 0.00020846528059337288
step: 50, loss: 0.004097551107406616
step: 60, loss: 0.002677262993529439
step: 70, loss: 0.00020197629055473953
step: 80, loss: 0.00014946467126719654
step: 90, loss: 0.0003243611427024007
step: 100, loss: 0.0006375120719894767
step: 110, loss: 0.0006797187379561365
step: 120, loss: 6.0668997321045026e-05
step: 130, loss: 0.002306524896994233
step: 140, loss: 0.0027638114988803864
step: 150, loss: 0.015573367476463318
step: 160, loss: 0.006805140990763903
step: 170, loss: 4.71501043648459e-05
step: 180, loss: 0.0024917591363191605
step: 190, loss: 0.0007121603703126311
step: 200, loss: 0.0009061993332579732
step: 210, loss: 0.0014593026135116816
step: 220, loss: 0.00014730940165463835
step: 230, loss: 0.01582189090549946
step: 240, loss: 0.009905464015901089
step: 250, loss: 0.0016994791803881526
step: 260, loss: 0.0002312416472705081
step: 270, loss: 0.0001394212304148823
step: 280, loss: 0.008705990388989449
step: 290, loss: 0.0004150908498559147
step: 300, loss: 0.0010159143712371588
step: 310, loss: 0.0013315682299435139
step: 320, loss: 0.0006257828208617866
step: 330, loss: 0.0012911844532936811
step: 340, loss: 0.03229561075568199
step: 350, loss: 9.296907956013456e-05
step: 360, loss: 0.0018222795333713293
step: 370, loss: 0.0008455736096948385
step: 380, loss: 0.004966207314282656
epoch 12: dev_f1=0.7080103359173127, f1=0.5552407932011332, best_f1=0.6017191977077365
step: 0, loss: 0.0026089216116815805
step: 10, loss: 0.0008600010187365115
step: 20, loss: 0.0006618964835070074
step: 30, loss: 0.013152092695236206
step: 40, loss: 0.000981259043328464
step: 50, loss: 0.00028465286595746875
step: 60, loss: 0.03359706699848175
step: 70, loss: 0.00010448703687870875
step: 80, loss: 0.00016187055734917521
step: 90, loss: 0.00020654966647271067
step: 100, loss: 0.0019609343726187944
step: 110, loss: 5.947382305748761e-05
step: 120, loss: 0.005746839568018913
step: 130, loss: 0.00035354893771000206
step: 140, loss: 0.00011873727635247633
step: 150, loss: 0.00011928957974305376
step: 160, loss: 0.003042002208530903
step: 170, loss: 0.09480204433202744
step: 180, loss: 0.0010133772157132626
step: 190, loss: 5.3156752983340994e-05
step: 200, loss: 0.002618216909468174
step: 210, loss: 8.911707845982164e-05
step: 220, loss: 0.0004343465552665293
step: 230, loss: 0.0009831604547798634
step: 240, loss: 0.00010565022967057303
step: 250, loss: 0.00392421567812562
step: 260, loss: 0.028565222397446632
step: 270, loss: 0.0019599550869315863
step: 280, loss: 0.0006328495219349861
step: 290, loss: 0.001977516571059823
step: 300, loss: 0.05754077062010765
step: 310, loss: 0.0015218178741633892
step: 320, loss: 0.011370564810931683
step: 330, loss: 0.0013648484600707889
step: 340, loss: 0.0006959578022360802
step: 350, loss: 2.9517730581574142e-05
step: 360, loss: 0.00026931226602755487
step: 370, loss: 0.000668998109176755
step: 380, loss: 0.0009122012997977436
epoch 13: dev_f1=0.717391304347826, f1=0.5808383233532934, best_f1=0.6017191977077365
step: 0, loss: 0.0014009554870426655
step: 10, loss: 0.0001626050507184118
step: 20, loss: 0.0011087240418419242
step: 30, loss: 0.00022048862592782825
step: 40, loss: 0.015084638260304928
step: 50, loss: 0.00011582026490941644
step: 60, loss: 3.845325409201905e-05
step: 70, loss: 0.00474234065040946
step: 80, loss: 0.00024411504273302853
step: 90, loss: 0.14281846582889557
step: 100, loss: 0.00012740580132231116
step: 110, loss: 7.64911892474629e-05
step: 120, loss: 0.030269382521510124
step: 130, loss: 0.0005059586837887764
step: 140, loss: 0.00021331933385226876
step: 150, loss: 8.418218203587458e-05
step: 160, loss: 0.00012464930478017777
step: 170, loss: 3.878947609337047e-05
step: 180, loss: 0.0009193524601869285
step: 190, loss: 4.289001662982628e-05
step: 200, loss: 0.00016640796093270183
step: 210, loss: 0.002478711772710085
step: 220, loss: 0.00016361534653697163
step: 230, loss: 0.00010372710676165298
step: 240, loss: 0.00010076817125082016
step: 250, loss: 0.0010947268456220627
step: 260, loss: 0.003897908143699169
step: 270, loss: 3.913872569683008e-05
step: 280, loss: 0.0001439237385056913
step: 290, loss: 0.00016309815691784024
step: 300, loss: 0.00027074170066043735
step: 310, loss: 0.00017990382912103087
step: 320, loss: 6.467633647844195e-05
step: 330, loss: 0.0011206582421436906
step: 340, loss: 0.0013249573530629277
step: 350, loss: 0.0012084809131920338
step: 360, loss: 0.0009948384249582887
step: 370, loss: 0.0001168730523204431
step: 380, loss: 0.0007133196922950447
epoch 14: dev_f1=0.6584615384615384, f1=0.49146757679180886, best_f1=0.6017191977077365
step: 0, loss: 0.00010636822116794065
step: 10, loss: 6.388196925399825e-05
step: 20, loss: 0.02825857885181904
step: 30, loss: 0.0001838514144765213
step: 40, loss: 0.0020117536187171936
step: 50, loss: 0.00022133768652565777
step: 60, loss: 0.05709998682141304
step: 70, loss: 0.001013465691357851
step: 80, loss: 0.0004822673508897424
step: 90, loss: 6.578536704182625e-05
step: 100, loss: 0.0004804599448107183
step: 110, loss: 0.0029187567997723818
step: 120, loss: 0.0001611629850231111
step: 130, loss: 9.900738950818777e-05
step: 140, loss: 0.0018688412383198738
step: 150, loss: 0.0003571243432816118
step: 160, loss: 0.0003134155413135886
step: 170, loss: 9.08269066712819e-05
step: 180, loss: 0.0012398111866787076
step: 190, loss: 0.00010074712190544233
step: 200, loss: 0.00018195746815763414
step: 210, loss: 0.005938914604485035
step: 220, loss: 0.0002789763384498656
step: 230, loss: 0.00022284171427600086
step: 240, loss: 0.0011541348649188876
step: 250, loss: 0.0013050655834376812
step: 260, loss: 0.0066147358156740665
step: 270, loss: 0.0722060352563858
step: 280, loss: 0.003660893999040127
step: 290, loss: 0.013259569182991982
step: 300, loss: 2.85640089714434e-05
step: 310, loss: 0.00030765135306864977
step: 320, loss: 4.820482718059793e-05
step: 330, loss: 0.00017521307745482773
step: 340, loss: 9.497908467892557e-05
step: 350, loss: 7.886591629358009e-05
step: 360, loss: 0.012500828132033348
step: 370, loss: 0.0702054426074028
step: 380, loss: 0.0009397054091095924
epoch 15: dev_f1=0.6908077994428968, f1=0.5377643504531721, best_f1=0.6017191977077365
step: 0, loss: 9.721583046484739e-05
step: 10, loss: 0.00012391695054247975
step: 20, loss: 0.0002229781966889277
step: 30, loss: 0.00019823844195343554
step: 40, loss: 7.88772085797973e-05
step: 50, loss: 0.00027161469915881753
step: 60, loss: 0.000682919635437429
step: 70, loss: 0.0007235949160531163
step: 80, loss: 3.371598359080963e-05
step: 90, loss: 8.351296128239483e-05
step: 100, loss: 7.792225369485095e-05
step: 110, loss: 0.00012685611727647483
step: 120, loss: 0.0011180558940395713
step: 130, loss: 0.012695354409515858
step: 140, loss: 0.0011977202957496047
step: 150, loss: 0.0004228560719639063
step: 160, loss: 0.0011165222385898232
step: 170, loss: 0.0004590838507283479
step: 180, loss: 0.0014469411689788103
step: 190, loss: 0.0004804522613994777
step: 200, loss: 0.004865813069045544
step: 210, loss: 0.00115725037176162
step: 220, loss: 0.00036144672776572406
step: 230, loss: 0.0001498555066064
step: 240, loss: 0.0008523400756530464
step: 250, loss: 0.0003627529658842832
step: 260, loss: 8.834081381792203e-05
step: 270, loss: 0.003478622529655695
step: 280, loss: 2.5703882784000598e-05
step: 290, loss: 0.0014334182487800717
step: 300, loss: 6.322081753751263e-05
step: 310, loss: 0.0008677472360432148
step: 320, loss: 0.0005066102603450418
step: 330, loss: 0.0008937976672314107
step: 340, loss: 0.0001796488941181451
step: 350, loss: 0.001659077825024724
step: 360, loss: 0.0020873728208243847
step: 370, loss: 7.469596312148497e-05
step: 380, loss: 2.5889792595990002e-05
epoch 16: dev_f1=0.6910112359550561, f1=0.5350318471337578, best_f1=0.6017191977077365
step: 0, loss: 0.00025194205227307975
step: 10, loss: 0.0016492257127538323
step: 20, loss: 4.656813325709663e-05
step: 30, loss: 0.0003750701725948602
step: 40, loss: 8.366474503418431e-05
step: 50, loss: 0.0023751745466142893
step: 60, loss: 0.00015876318502705544
step: 70, loss: 0.00016628022422082722
step: 80, loss: 0.00034926930675283074
step: 90, loss: 0.01701425015926361
step: 100, loss: 4.1038623749045655e-05
step: 110, loss: 6.810090417275205e-05
step: 120, loss: 0.00017388415290042758
step: 130, loss: 0.00012750134919770062
step: 140, loss: 0.0003452927921898663
step: 150, loss: 4.930724753648974e-05
step: 160, loss: 8.391103619942442e-05
step: 170, loss: 9.351914923172444e-05
step: 180, loss: 0.00017783248040359467
step: 190, loss: 0.0032696593552827835
step: 200, loss: 0.0026250327937304974
step: 210, loss: 0.001799316960386932
step: 220, loss: 0.0001017963804770261
step: 230, loss: 0.0006904699257574975
step: 240, loss: 3.940710303140804e-05
step: 250, loss: 0.000473398802569136
step: 260, loss: 5.358373891795054e-05
step: 270, loss: 4.8063284339150414e-05
step: 280, loss: 0.0020064087584614754
step: 290, loss: 0.00039029697654768825
step: 300, loss: 9.395908273290843e-05
step: 310, loss: 0.0006593650905415416
step: 320, loss: 0.0003100754984188825
step: 330, loss: 7.202180131571367e-05
step: 340, loss: 0.0004886266542598605
step: 350, loss: 0.0004094608302693814
step: 360, loss: 0.022724589332938194
step: 370, loss: 0.00026977923698723316
step: 380, loss: 0.0006966081564314663
epoch 17: dev_f1=0.7089337175792507, f1=0.5526315789473685, best_f1=0.6017191977077365
step: 0, loss: 0.0004360992752481252
step: 10, loss: 0.00013698470138479024
step: 20, loss: 0.00026370378327555954
step: 30, loss: 0.00021749240113422275
step: 40, loss: 0.015475929714739323
step: 50, loss: 0.015521437861025333
step: 60, loss: 0.0001293794484809041
step: 70, loss: 0.00015428237384185195
step: 80, loss: 5.38557069376111e-05
step: 90, loss: 0.00015965045895427465
step: 100, loss: 0.0007831280818209052
step: 110, loss: 0.00010113589087268338
step: 120, loss: 7.416158769046888e-05
step: 130, loss: 0.0005084667354822159
step: 140, loss: 0.00025759838172234595
step: 150, loss: 4.5096108806319535e-05
step: 160, loss: 6.625513196922839e-05
step: 170, loss: 0.00023588803014717996
step: 180, loss: 0.00029283156618475914
step: 190, loss: 0.00010725072206696495
step: 200, loss: 0.0003145500086247921
step: 210, loss: 0.0001998546504182741
step: 220, loss: 5.071549094282091e-05
step: 230, loss: 6.932522228453308e-05
step: 240, loss: 5.484541179612279e-05
step: 250, loss: 3.0496810722979717e-05
step: 260, loss: 0.000530433957464993
step: 270, loss: 4.376793003757484e-05
step: 280, loss: 0.0001021847638185136
step: 290, loss: 0.00018035751418210566
step: 300, loss: 7.094728789525107e-05
step: 310, loss: 0.0025150608271360397
step: 320, loss: 0.0012262319214642048
step: 330, loss: 6.076777208363637e-05
step: 340, loss: 0.0004749677609652281
step: 350, loss: 5.766013418906368e-05
step: 360, loss: 0.00011148721387144178
step: 370, loss: 2.195991328335367e-05
step: 380, loss: 3.991619450971484e-05
epoch 18: dev_f1=0.690909090909091, f1=0.5865921787709497, best_f1=0.6017191977077365
step: 0, loss: 0.00033276909380219877
step: 10, loss: 0.031817059963941574
step: 20, loss: 0.0010491934372112155
step: 30, loss: 4.381975668366067e-05
step: 40, loss: 0.0024262121878564358
step: 50, loss: 8.163090387824923e-05
step: 60, loss: 9.67029991443269e-05
step: 70, loss: 3.055378329008818e-05
step: 80, loss: 6.750186730641872e-05
step: 90, loss: 7.162950350902975e-05
step: 100, loss: 0.00013641097757499665
step: 110, loss: 0.00029519895906560123
step: 120, loss: 2.308134935447015e-05
step: 130, loss: 8.636457641841844e-05
step: 140, loss: 0.0014160436112433672
step: 150, loss: 3.805341475526802e-05
step: 160, loss: 0.03007766231894493
step: 170, loss: 0.00013000173203181475
step: 180, loss: 0.0049553061835467815
step: 190, loss: 5.39080319867935e-05
step: 200, loss: 0.00015808019088581204
step: 210, loss: 0.0009859392885118723
step: 220, loss: 0.000301905267406255
step: 230, loss: 0.001265552593395114
step: 240, loss: 0.0002456845832057297
step: 250, loss: 0.00041275532566942275
step: 260, loss: 0.00012937297287862748
step: 270, loss: 7.239842670969665e-05
step: 280, loss: 0.00022285612067207694
step: 290, loss: 0.00025039308820851147
step: 300, loss: 0.0021544783376157284
step: 310, loss: 0.00021832728816661984
step: 320, loss: 4.271319630788639e-05
step: 330, loss: 0.0018871519714593887
step: 340, loss: 2.2731261196895503e-05
step: 350, loss: 7.972349703777581e-05
step: 360, loss: 0.0013450420228764415
step: 370, loss: 0.0001386438379995525
step: 380, loss: 0.0002017739025177434
epoch 19: dev_f1=0.6908077994428968, f1=0.5644171779141104, best_f1=0.6017191977077365
step: 0, loss: 9.120578761212528e-05
step: 10, loss: 0.00032184674637392163
step: 20, loss: 0.0003215546894352883
step: 30, loss: 0.0027877746615558863
step: 40, loss: 0.0003376593813300133
step: 50, loss: 7.508027920266613e-05
step: 60, loss: 0.0001008557592285797
step: 70, loss: 0.0043662129901349545
step: 80, loss: 5.606845661532134e-05
step: 90, loss: 2.465291618136689e-05
step: 100, loss: 4.078176789334975e-05
step: 110, loss: 0.0005909867468290031
step: 120, loss: 0.00012453508679755032
step: 130, loss: 6.278113869484514e-05
step: 140, loss: 0.00031808699714019895
step: 150, loss: 7.413526327582076e-05
step: 160, loss: 0.00012463933671824634
step: 170, loss: 0.0003637038462329656
step: 180, loss: 0.00015233058365993202
step: 190, loss: 0.00023753913410473615
step: 200, loss: 0.0002697771997191012
step: 210, loss: 0.0034138252958655357
step: 220, loss: 0.0004974029143340886
step: 230, loss: 0.00019587212591432035
step: 240, loss: 0.0005152522935532033
step: 250, loss: 0.00019395453273318708
step: 260, loss: 0.00010055272286990657
step: 270, loss: 3.6442237615119666e-05
step: 280, loss: 0.005303671117872
step: 290, loss: 0.0001418752653989941
step: 300, loss: 8.987914043245837e-05
step: 310, loss: 0.00015149253886193037
step: 320, loss: 4.148417428950779e-05
step: 330, loss: 0.0006080204038880765
step: 340, loss: 0.00011506415467010811
step: 350, loss: 0.0009633401059545577
step: 360, loss: 4.847451418754645e-05
step: 370, loss: 0.00016216558287851512
step: 380, loss: 2.2570651708520018e-05
epoch 20: dev_f1=0.6925207756232686, f1=0.5679012345679011, best_f1=0.6017191977077365
