cuda
Device: cuda
step: 0, loss: 0.5847833752632141
step: 10, loss: 0.47596755623817444
step: 20, loss: 0.3595377802848816
step: 30, loss: 0.26007381081581116
step: 40, loss: 0.20128373801708221
step: 50, loss: 0.23078371584415436
step: 60, loss: 0.13447123765945435
step: 70, loss: 0.35306650400161743
step: 80, loss: 0.2818526327610016
step: 90, loss: 0.17161716520786285
step: 100, loss: 0.2937678396701813
step: 110, loss: 0.29350483417510986
step: 120, loss: 0.23589015007019043
step: 130, loss: 0.2464975267648697
step: 140, loss: 0.2469303011894226
step: 150, loss: 0.3431504964828491
step: 160, loss: 0.452042818069458
step: 170, loss: 0.27791884541511536
step: 180, loss: 0.3745311200618744
step: 190, loss: 0.18379616737365723
step: 200, loss: 0.28145045042037964
step: 210, loss: 0.371897429227829
step: 220, loss: 0.17072553932666779
step: 230, loss: 0.425083190202713
step: 240, loss: 0.23982274532318115
step: 250, loss: 0.15073582530021667
step: 260, loss: 0.22960509359836578
step: 270, loss: 0.1791030764579773
step: 280, loss: 0.3217035233974457
step: 290, loss: 0.21059295535087585
step: 300, loss: 0.3837926685810089
step: 310, loss: 0.2791338264942169
step: 320, loss: 0.5225567817687988
step: 330, loss: 0.24048922955989838
step: 340, loss: 0.43253666162490845
step: 350, loss: 0.3681092858314514
step: 360, loss: 0.27484971284866333
step: 370, loss: 0.2987954020500183
step: 380, loss: 0.2506580948829651
epoch 1: dev_f1=0.33035714285714285, f1=0.31067961165048547, best_f1=0.31067961165048547
step: 0, loss: 0.22102388739585876
step: 10, loss: 0.22986319661140442
step: 20, loss: 0.1929190456867218
step: 30, loss: 0.23749393224716187
step: 40, loss: 0.05306321382522583
step: 50, loss: 0.3479926884174347
step: 60, loss: 0.37014585733413696
step: 70, loss: 0.2485487461090088
step: 80, loss: 0.15393488109111786
step: 90, loss: 0.2218257188796997
step: 100, loss: 0.17593324184417725
step: 110, loss: 0.0980238988995552
step: 120, loss: 0.08202224969863892
step: 130, loss: 0.23588955402374268
step: 140, loss: 0.21264468133449554
step: 150, loss: 0.40751224756240845
step: 160, loss: 0.175879567861557
step: 170, loss: 0.34328511357307434
step: 180, loss: 0.08806274831295013
step: 190, loss: 0.1761671006679535
step: 200, loss: 0.22370614111423492
step: 210, loss: 0.20590099692344666
step: 220, loss: 0.06256144493818283
step: 230, loss: 0.23281794786453247
step: 240, loss: 0.26895007491111755
step: 250, loss: 0.12592031061649323
step: 260, loss: 0.04488949850201607
step: 270, loss: 0.1366376429796219
step: 280, loss: 0.3314780592918396
step: 290, loss: 0.1050865575671196
step: 300, loss: 0.12824569642543793
step: 310, loss: 0.075334332883358
step: 320, loss: 0.32827213406562805
step: 330, loss: 0.12674099206924438
step: 340, loss: 0.17803968489170074
step: 350, loss: 0.13695946335792542
step: 360, loss: 0.150706484913826
step: 370, loss: 0.18667010962963104
step: 380, loss: 0.09561297297477722
epoch 2: dev_f1=0.5647558386411891, f1=0.5458612975391498, best_f1=0.5458612975391498
step: 0, loss: 0.08989755064249039
step: 10, loss: 0.09747155010700226
step: 20, loss: 0.0769074410200119
step: 30, loss: 0.0396527536213398
step: 40, loss: 0.0828336849808693
step: 50, loss: 0.3967572748661041
step: 60, loss: 0.03931254893541336
step: 70, loss: 0.05779262259602547
step: 80, loss: 0.08077123016119003
step: 90, loss: 0.11458617448806763
step: 100, loss: 0.23456820845603943
step: 110, loss: 0.11906992644071579
step: 120, loss: 0.19658920168876648
step: 130, loss: 0.03562651202082634
step: 140, loss: 0.05759064853191376
step: 150, loss: 0.09607000648975372
step: 160, loss: 0.10071016848087311
step: 170, loss: 0.03316953033208847
step: 180, loss: 0.02918221801519394
step: 190, loss: 0.06285472959280014
step: 200, loss: 0.08052714169025421
step: 210, loss: 0.0874226987361908
step: 220, loss: 0.05489858239889145
step: 230, loss: 0.10047901421785355
step: 240, loss: 0.18094344437122345
step: 250, loss: 0.0414682999253273
step: 260, loss: 0.07750166207551956
step: 270, loss: 0.013696165755391121
step: 280, loss: 0.06871762871742249
step: 290, loss: 0.012814514338970184
step: 300, loss: 0.09644941240549088
step: 310, loss: 0.0966063141822815
step: 320, loss: 0.15948043763637543
step: 330, loss: 0.34730374813079834
step: 340, loss: 0.14109349250793457
step: 350, loss: 0.08350300043821335
step: 360, loss: 0.2869150936603546
step: 370, loss: 0.16549210250377655
step: 380, loss: 0.03751026466488838
epoch 3: dev_f1=0.6408268733850129, f1=0.5638297872340425, best_f1=0.5638297872340425
step: 0, loss: 0.024543840438127518
step: 10, loss: 0.02161390334367752
step: 20, loss: 0.019146209582686424
step: 30, loss: 0.33554792404174805
step: 40, loss: 0.01165564265102148
step: 50, loss: 0.04612487554550171
step: 60, loss: 0.037081364542245865
step: 70, loss: 0.08206821978092194
step: 80, loss: 0.018579907715320587
step: 90, loss: 0.09281876683235168
step: 100, loss: 0.15434695780277252
step: 110, loss: 0.054032325744628906
step: 120, loss: 0.07342803478240967
step: 130, loss: 0.040651630610227585
step: 140, loss: 0.058316875249147415
step: 150, loss: 0.0017655669944360852
step: 160, loss: 0.11924458295106888
step: 170, loss: 0.3077041804790497
step: 180, loss: 0.13110308349132538
step: 190, loss: 0.1713922917842865
step: 200, loss: 0.07073286175727844
step: 210, loss: 0.19185727834701538
step: 220, loss: 0.058378878980875015
step: 230, loss: 0.01115387212485075
step: 240, loss: 0.08624384552240372
step: 250, loss: 0.21944592893123627
step: 260, loss: 0.024755755439400673
step: 270, loss: 0.036964207887649536
step: 280, loss: 0.1854119598865509
step: 290, loss: 0.15270766615867615
step: 300, loss: 0.010712380520999432
step: 310, loss: 0.234294593334198
step: 320, loss: 0.08305313438177109
step: 330, loss: 0.2312137633562088
step: 340, loss: 0.10641264915466309
step: 350, loss: 0.19082432985305786
step: 360, loss: 0.058727703988552094
step: 370, loss: 0.10033455491065979
step: 380, loss: 0.03825273737311363
epoch 4: dev_f1=0.717948717948718, f1=0.6141304347826086, best_f1=0.6141304347826086
step: 0, loss: 0.0077396174892783165
step: 10, loss: 0.030465640127658844
step: 20, loss: 0.001282809884287417
step: 30, loss: 0.02951119653880596
step: 40, loss: 0.0864841639995575
step: 50, loss: 0.08583645522594452
step: 60, loss: 0.028538042679429054
step: 70, loss: 0.02067168988287449
step: 80, loss: 0.06034127622842789
step: 90, loss: 0.1685965657234192
step: 100, loss: 0.020660683512687683
step: 110, loss: 0.030170394107699394
step: 120, loss: 0.007602270692586899
step: 130, loss: 0.02494044229388237
step: 140, loss: 0.005215928889811039
step: 150, loss: 0.008157855831086636
step: 160, loss: 0.05175896733999252
step: 170, loss: 0.06984349340200424
step: 180, loss: 0.022137662395834923
step: 190, loss: 0.00433886144310236
step: 200, loss: 0.002680864417925477
step: 210, loss: 0.07922597229480743
step: 220, loss: 0.027163058519363403
step: 230, loss: 0.012995719909667969
step: 240, loss: 0.03916556015610695
step: 250, loss: 0.0740586519241333
step: 260, loss: 0.056594233959913254
step: 270, loss: 0.07678446173667908
step: 280, loss: 0.1315625160932541
step: 290, loss: 0.01678752899169922
step: 300, loss: 0.01838843524456024
step: 310, loss: 0.06572598963975906
step: 320, loss: 0.02364443987607956
step: 330, loss: 0.0228847898542881
step: 340, loss: 0.07050977647304535
step: 350, loss: 0.13745948672294617
step: 360, loss: 0.017053043469786644
step: 370, loss: 0.01811746321618557
step: 380, loss: 0.018992284312844276
epoch 5: dev_f1=0.6720430107526881, f1=0.5681159420289855, best_f1=0.6141304347826086
step: 0, loss: 0.01952846348285675
step: 10, loss: 0.03467746451497078
step: 20, loss: 0.058687083423137665
step: 30, loss: 0.00951707735657692
step: 40, loss: 0.002519016619771719
step: 50, loss: 0.02616565115749836
step: 60, loss: 0.02132284827530384
step: 70, loss: 0.07693973183631897
step: 80, loss: 0.1731715053319931
step: 90, loss: 0.03729063645005226
step: 100, loss: 0.0007518089842051268
step: 110, loss: 0.007847707718610764
step: 120, loss: 0.027543101459741592
step: 130, loss: 0.015643635764718056
step: 140, loss: 0.0732705220580101
step: 150, loss: 0.06491591036319733
step: 160, loss: 0.030217036604881287
step: 170, loss: 0.06209299713373184
step: 180, loss: 0.0546061173081398
step: 190, loss: 0.00844815094023943
step: 200, loss: 0.013663148507475853
step: 210, loss: 0.06864021718502045
step: 220, loss: 0.051575932651758194
step: 230, loss: 0.0005633591208606958
step: 240, loss: 0.005869066342711449
step: 250, loss: 0.0036410584580153227
step: 260, loss: 0.006102357059717178
step: 270, loss: 0.0017430116422474384
step: 280, loss: 0.149727925658226
step: 290, loss: 0.026652129366993904
step: 300, loss: 0.05244501680135727
step: 310, loss: 0.006293834652751684
step: 320, loss: 0.0064463065937161446
step: 330, loss: 0.025615599006414413
step: 340, loss: 0.0016479410696774721
step: 350, loss: 0.002399502554908395
step: 360, loss: 0.0030175892170518637
step: 370, loss: 0.009150838479399681
step: 380, loss: 0.044826358556747437
epoch 6: dev_f1=0.7272727272727272, f1=0.6354166666666666, best_f1=0.6354166666666666
step: 0, loss: 0.0006921996246092021
step: 10, loss: 0.23094651103019714
step: 20, loss: 0.05018942430615425
step: 30, loss: 0.001012429827824235
step: 40, loss: 0.026977887377142906
step: 50, loss: 0.0032317526638507843
step: 60, loss: 0.04846297577023506
step: 70, loss: 0.010309926234185696
step: 80, loss: 0.09719709306955338
step: 90, loss: 0.09262482076883316
step: 100, loss: 0.011200150474905968
step: 110, loss: 0.004121750593185425
step: 120, loss: 0.0021531106904149055
step: 130, loss: 0.07016491889953613
step: 140, loss: 0.0012636557221412659
step: 150, loss: 0.0006476633716374636
step: 160, loss: 0.011882985942065716
step: 170, loss: 0.03650732338428497
step: 180, loss: 0.014807933010160923
step: 190, loss: 0.10382428020238876
step: 200, loss: 0.0010008233366534114
step: 210, loss: 0.001132029457949102
step: 220, loss: 0.011845129542052746
step: 230, loss: 0.007387121208012104
step: 240, loss: 0.012390934862196445
step: 250, loss: 0.031655214726924896
step: 260, loss: 0.17926564812660217
step: 270, loss: 0.06259751319885254
step: 280, loss: 0.07869288325309753
step: 290, loss: 0.08212204277515411
step: 300, loss: 0.004067126661539078
step: 310, loss: 0.014052101410925388
step: 320, loss: 0.1527538001537323
step: 330, loss: 0.0020324988290667534
step: 340, loss: 0.10669685155153275
step: 350, loss: 0.02630445547401905
step: 360, loss: 0.07122986763715744
step: 370, loss: 0.062065042555332184
step: 380, loss: 0.0125027010217309
epoch 7: dev_f1=0.6722689075630252, f1=0.5875370919881306, best_f1=0.6354166666666666
step: 0, loss: 0.0005315136513672769
step: 10, loss: 0.04290052503347397
step: 20, loss: 0.0032725080382078886
step: 30, loss: 0.021951982751488686
step: 40, loss: 0.0019982755184173584
step: 50, loss: 0.0004949753638356924
step: 60, loss: 0.0007222078857012093
step: 70, loss: 0.374824196100235
step: 80, loss: 0.00979788787662983
step: 90, loss: 0.005429605953395367
step: 100, loss: 0.030209334567189217
step: 110, loss: 0.007318041753023863
step: 120, loss: 0.010764277540147305
step: 130, loss: 0.005619723815470934
step: 140, loss: 0.00046594470040872693
step: 150, loss: 0.0986889898777008
step: 160, loss: 0.02288227528333664
step: 170, loss: 0.0008213830296881497
step: 180, loss: 0.017430270090699196
step: 190, loss: 0.0043456293642520905
step: 200, loss: 0.01155721116811037
step: 210, loss: 0.003223632462322712
step: 220, loss: 0.040018584579229355
step: 230, loss: 0.0016389730153605342
step: 240, loss: 0.019142968580126762
step: 250, loss: 0.010901225730776787
step: 260, loss: 0.1588444709777832
step: 270, loss: 0.05270254984498024
step: 280, loss: 0.006083420477807522
step: 290, loss: 0.009210929274559021
step: 300, loss: 0.0022309126798063517
step: 310, loss: 0.0028042872436344624
step: 320, loss: 0.015778563916683197
step: 330, loss: 0.023146983236074448
step: 340, loss: 0.005740447901189327
step: 350, loss: 0.0002536222746130079
step: 360, loss: 0.03916815668344498
step: 370, loss: 0.00042336489423178136
step: 380, loss: 0.11254702508449554
epoch 8: dev_f1=0.6814404432132963, f1=0.575, best_f1=0.6354166666666666
step: 0, loss: 0.00011489507596706972
step: 10, loss: 0.002051092917099595
step: 20, loss: 0.09681880474090576
step: 30, loss: 0.001158635481260717
step: 40, loss: 0.00029095151694491506
step: 50, loss: 0.01799268275499344
step: 60, loss: 0.0004734956310130656
step: 70, loss: 0.0010075742611661553
step: 80, loss: 0.004279709421098232
step: 90, loss: 0.0014392381999641657
step: 100, loss: 0.01994936168193817
step: 110, loss: 0.015249170362949371
step: 120, loss: 0.00020482401305343956
step: 130, loss: 0.006913075223565102
step: 140, loss: 0.019237706437706947
step: 150, loss: 0.06087438389658928
step: 160, loss: 0.0031675274949520826
step: 170, loss: 0.0003581412020139396
step: 180, loss: 0.002364111365750432
step: 190, loss: 0.009847861714661121
step: 200, loss: 0.005764709785580635
step: 210, loss: 0.015375776216387749
step: 220, loss: 0.002353753661736846
step: 230, loss: 0.07404129207134247
step: 240, loss: 0.05183672904968262
step: 250, loss: 0.07632650434970856
step: 260, loss: 0.2396330088376999
step: 270, loss: 0.0006719758966937661
step: 280, loss: 0.14126445353031158
step: 290, loss: 0.0315866656601429
step: 300, loss: 0.10185179114341736
step: 310, loss: 0.0016066116513684392
step: 320, loss: 0.02749733440577984
step: 330, loss: 0.0036437504459172487
step: 340, loss: 0.1030038371682167
step: 350, loss: 0.002280584769323468
step: 360, loss: 0.0010751631343737245
step: 370, loss: 0.004167129751294851
step: 380, loss: 0.0008407360874116421
epoch 9: dev_f1=0.6836158192090396, f1=0.5653495440729484, best_f1=0.6354166666666666
step: 0, loss: 0.0012614253209903836
step: 10, loss: 0.011595060117542744
step: 20, loss: 0.00046801564167253673
step: 30, loss: 0.0024531343951821327
step: 40, loss: 0.018386248499155045
step: 50, loss: 0.00028120094793848693
step: 60, loss: 0.028627580031752586
step: 70, loss: 0.007865926250815392
step: 80, loss: 0.005964741110801697
step: 90, loss: 0.00018127895600628108
step: 100, loss: 0.007682204712182283
step: 110, loss: 0.00039200938772410154
step: 120, loss: 0.0027638350147753954
step: 130, loss: 0.0007186051807366312
step: 140, loss: 0.123226597905159
step: 150, loss: 0.001659862813539803
step: 160, loss: 0.009847634471952915
step: 170, loss: 0.006535527762025595
step: 180, loss: 0.0012676346814259887
step: 190, loss: 0.00865133386105299
step: 200, loss: 0.010470554232597351
step: 210, loss: 0.004868712276220322
step: 220, loss: 0.00012740670354105532
step: 230, loss: 0.0011667991057038307
step: 240, loss: 0.0015863204607740045
step: 250, loss: 0.0680987611413002
step: 260, loss: 0.0068115293979644775
step: 270, loss: 0.008866565302014351
step: 280, loss: 0.0007712575607001781
step: 290, loss: 0.023080646991729736
step: 300, loss: 0.001157463644631207
step: 310, loss: 0.007820729166269302
step: 320, loss: 0.0010529480641707778
step: 330, loss: 0.001143115689046681
step: 340, loss: 0.01700705662369728
step: 350, loss: 0.000609196606092155
step: 360, loss: 0.0011403486132621765
step: 370, loss: 0.003274607704952359
step: 380, loss: 0.017249373719096184
epoch 10: dev_f1=0.6908077994428968, f1=0.555223880597015, best_f1=0.6354166666666666
step: 0, loss: 0.0010565106058493257
step: 10, loss: 0.018070535734295845
step: 20, loss: 0.03522029519081116
step: 30, loss: 0.00010977444617310539
step: 40, loss: 0.0005916165537200868
step: 50, loss: 0.006689575966447592
step: 60, loss: 0.0002666367799974978
step: 70, loss: 0.010514145717024803
step: 80, loss: 0.00018973834812641144
step: 90, loss: 0.004068101290613413
step: 100, loss: 0.20196491479873657
step: 110, loss: 0.0046027060598134995
step: 120, loss: 0.029547126963734627
step: 130, loss: 0.0010146701242774725
step: 140, loss: 0.016252463683485985
step: 150, loss: 0.01494279783219099
step: 160, loss: 0.02052251808345318
step: 170, loss: 0.00033439326216466725
step: 180, loss: 0.005183427594602108
step: 190, loss: 0.0001997724175453186
step: 200, loss: 0.0005994361126795411
step: 210, loss: 0.001743387896567583
step: 220, loss: 0.0015034695388749242
step: 230, loss: 0.0007990896701812744
step: 240, loss: 0.0018747987924143672
step: 250, loss: 0.0010364081244915724
step: 260, loss: 0.0019949041306972504
step: 270, loss: 0.0002725555968936533
step: 280, loss: 0.00010851716797333211
step: 290, loss: 0.0015003257431089878
step: 300, loss: 0.009430250152945518
step: 310, loss: 0.002812733640894294
step: 320, loss: 0.03664964810013771
step: 330, loss: 0.016202187165617943
step: 340, loss: 0.0004261854919604957
step: 350, loss: 0.0001821002078941092
step: 360, loss: 0.016798416152596474
step: 370, loss: 0.061984069645404816
step: 380, loss: 0.0021563288755714893
epoch 11: dev_f1=0.6942148760330578, f1=0.5952380952380952, best_f1=0.6354166666666666
step: 0, loss: 0.0005408321740105748
step: 10, loss: 0.00035868017585016787
step: 20, loss: 0.00038107915315777063
step: 30, loss: 0.00038535427302122116
step: 40, loss: 0.0028772547375410795
step: 50, loss: 0.0001584352576173842
step: 60, loss: 0.0008303784416057169
step: 70, loss: 0.00031198334181681275
step: 80, loss: 0.0002055777149507776
step: 90, loss: 0.013486722484230995
step: 100, loss: 0.001145000453107059
step: 110, loss: 0.0004048685368616134
step: 120, loss: 0.001601654919795692
step: 130, loss: 0.0009601544006727636
step: 140, loss: 0.0010502878576517105
step: 150, loss: 0.05078501254320145
step: 160, loss: 0.0020851397421211004
step: 170, loss: 0.000524875707924366
step: 180, loss: 0.000603488995693624
step: 190, loss: 0.004029690753668547
step: 200, loss: 0.0006343811983242631
step: 210, loss: 0.11269500106573105
step: 220, loss: 0.0007440083427354693
step: 230, loss: 0.0006868297350592911
step: 240, loss: 0.016335589811205864
step: 250, loss: 0.08546293526887894
step: 260, loss: 0.004793624859303236
step: 270, loss: 0.004550355952233076
step: 280, loss: 0.0018027601763606071
step: 290, loss: 0.003048570826649666
step: 300, loss: 0.00018877604452427477
step: 310, loss: 0.0001502084924140945
step: 320, loss: 0.0004322549793869257
step: 330, loss: 0.0065494743175804615
step: 340, loss: 0.0001003214274533093
step: 350, loss: 0.00017615786055102944
step: 360, loss: 6.814091466367245e-05
step: 370, loss: 0.0003638140333350748
step: 380, loss: 0.00012296278146095574
epoch 12: dev_f1=0.6535211267605634, f1=0.529968454258675, best_f1=0.6354166666666666
step: 0, loss: 0.0003925275814253837
step: 10, loss: 0.0020484894048422575
step: 20, loss: 0.005783287808299065
step: 30, loss: 0.00027841090923175216
step: 40, loss: 0.00013278286496642977
step: 50, loss: 0.00033839725074358284
step: 60, loss: 0.0007695181993767619
step: 70, loss: 0.005385176278650761
step: 80, loss: 0.04674799367785454
step: 90, loss: 0.00041843956569209695
step: 100, loss: 0.004608112387359142
step: 110, loss: 8.534312655683607e-05
step: 120, loss: 0.001199935795739293
step: 130, loss: 0.0005356741603463888
step: 140, loss: 0.0022082601208239794
step: 150, loss: 0.0009055638802237809
step: 160, loss: 0.00374834006652236
step: 170, loss: 0.00011650355736492202
step: 180, loss: 0.19620081782341003
step: 190, loss: 0.027378037571907043
step: 200, loss: 0.00037525256630033255
step: 210, loss: 0.0002989118220284581
step: 220, loss: 0.09956981241703033
step: 230, loss: 0.0004981174715794623
step: 240, loss: 0.0004893713048659265
step: 250, loss: 0.014724373817443848
step: 260, loss: 0.0006432511727325618
step: 270, loss: 0.003545930376276374
step: 280, loss: 0.0034136015456169844
step: 290, loss: 0.0009334738133475184
step: 300, loss: 0.00029963013366796076
step: 310, loss: 0.0023864638060331345
step: 320, loss: 0.001203846069984138
step: 330, loss: 0.006233911495655775
step: 340, loss: 0.003102090209722519
step: 350, loss: 0.004067635163664818
step: 360, loss: 0.051790736615657806
step: 370, loss: 0.004232688341289759
step: 380, loss: 0.0008145913598127663
epoch 13: dev_f1=0.6771653543307086, f1=0.5982905982905982, best_f1=0.6354166666666666
step: 0, loss: 0.0006307288422249258
step: 10, loss: 0.0008707806700840592
step: 20, loss: 0.026792321354150772
step: 30, loss: 0.0002973107621073723
step: 40, loss: 0.001322597381658852
step: 50, loss: 0.00031444450723938644
step: 60, loss: 0.006249784957617521
step: 70, loss: 0.00010443708742968738
step: 80, loss: 0.0029560194816440344
step: 90, loss: 0.00024785660207271576
step: 100, loss: 0.0009921770542860031
step: 110, loss: 0.0002786245895549655
step: 120, loss: 0.00023700346355326474
step: 130, loss: 0.0006567614036612213
step: 140, loss: 0.00016276589303743094
step: 150, loss: 9.65815779636614e-05
step: 160, loss: 0.000815422972664237
step: 170, loss: 7.447157986462116e-05
step: 180, loss: 4.921033178106882e-05
step: 190, loss: 0.0001058747511706315
step: 200, loss: 0.0008251419640146196
step: 210, loss: 0.1737522929906845
step: 220, loss: 0.00024311149900313467
step: 230, loss: 0.00015564158093184233
step: 240, loss: 6.197091715876013e-05
step: 250, loss: 0.004962461069226265
step: 260, loss: 0.00029292580438777804
step: 270, loss: 0.0016655304934829473
step: 280, loss: 0.013989347033202648
step: 290, loss: 0.00016947869153227657
step: 300, loss: 0.004116620868444443
step: 310, loss: 0.02030101977288723
step: 320, loss: 0.0005128469783812761
step: 330, loss: 0.003401285968720913
step: 340, loss: 0.005899876356124878
step: 350, loss: 0.0001283775200136006
step: 360, loss: 0.00029555126093328
step: 370, loss: 0.0008649812079966068
step: 380, loss: 0.00011759150220314041
epoch 14: dev_f1=0.6806282722513088, f1=0.6235955056179776, best_f1=0.6354166666666666
step: 0, loss: 0.0006431496585719287
step: 10, loss: 0.0028819229919463396
step: 20, loss: 0.00020075732027180493
step: 30, loss: 0.0016276524402201176
step: 40, loss: 0.0001979359076358378
step: 50, loss: 0.0015104126650840044
step: 60, loss: 9.930712985806167e-05
step: 70, loss: 0.0004221890994813293
step: 80, loss: 0.00025717014796100557
step: 90, loss: 0.00030322663951665163
step: 100, loss: 0.00025417760480195284
step: 110, loss: 0.00013424950884655118
step: 120, loss: 0.0006039328291080892
step: 130, loss: 0.00017182339797727764
step: 140, loss: 0.00014220362936612219
step: 150, loss: 0.00016041363414842635
step: 160, loss: 0.008117095567286015
step: 170, loss: 0.00023306022922042757
step: 180, loss: 0.0002868932788260281
step: 190, loss: 0.019604263827204704
step: 200, loss: 0.00018503920000512153
step: 210, loss: 0.03254852816462517
step: 220, loss: 7.731678488198668e-05
step: 230, loss: 0.000299954874208197
step: 240, loss: 0.0016643416602164507
step: 250, loss: 4.2119550926145166e-05
step: 260, loss: 0.0033136161509901285
step: 270, loss: 0.0001276633411180228
step: 280, loss: 0.0004195115470793098
step: 290, loss: 0.00015017609985079616
step: 300, loss: 0.02614540047943592
step: 310, loss: 6.628307164646685e-05
step: 320, loss: 0.013400629162788391
step: 330, loss: 0.00013240908447187394
step: 340, loss: 0.0027258070185780525
step: 350, loss: 0.00021381508850026876
step: 360, loss: 8.726921078050509e-05
step: 370, loss: 0.001957233063876629
step: 380, loss: 0.015169237740337849
epoch 15: dev_f1=0.6859903381642513, f1=0.6318537859007832, best_f1=0.6354166666666666
step: 0, loss: 0.0004264739982318133
step: 10, loss: 0.06934503465890884
step: 20, loss: 0.05698064714670181
step: 30, loss: 0.00012114783748984337
step: 40, loss: 0.00022551591973751783
step: 50, loss: 0.003105725394561887
step: 60, loss: 4.555795021587983e-05
step: 70, loss: 0.00014903592818882316
step: 80, loss: 0.00443315738812089
step: 90, loss: 0.00015261908993124962
step: 100, loss: 0.00047365212230943143
step: 110, loss: 0.0018811802146956325
step: 120, loss: 0.0003605574311222881
step: 130, loss: 0.00023517901718150824
step: 140, loss: 0.0048719001933932304
step: 150, loss: 0.001556845847517252
step: 160, loss: 0.000226012576604262
step: 170, loss: 0.0072607132606208324
step: 180, loss: 0.0008205916383303702
step: 190, loss: 0.0006132291746325791
step: 200, loss: 0.0001973414036910981
step: 210, loss: 9.794757352210581e-05
step: 220, loss: 6.378231046255678e-05
step: 230, loss: 0.0004522578383330256
step: 240, loss: 0.0011425632983446121
step: 250, loss: 0.023463260382413864
step: 260, loss: 0.010101327672600746
step: 270, loss: 0.015189905650913715
step: 280, loss: 0.0001520496589364484
step: 290, loss: 0.001001510419882834
step: 300, loss: 2.552864134486299e-05
step: 310, loss: 0.00012689763389062136
step: 320, loss: 0.00029731192626059055
step: 330, loss: 3.8767138903494924e-05
step: 340, loss: 0.0004033068544231355
step: 350, loss: 7.491825090255588e-05
step: 360, loss: 4.333354445407167e-05
step: 370, loss: 5.685104042640887e-05
step: 380, loss: 0.00041110909660346806
epoch 16: dev_f1=0.7068062827225131, f1=0.6225895316804407, best_f1=0.6354166666666666
step: 0, loss: 0.01920430362224579
step: 10, loss: 0.00037597716436721385
step: 20, loss: 0.005948984529823065
step: 30, loss: 0.01770090125501156
step: 40, loss: 0.0007439868059009314
step: 50, loss: 0.0014654680853709579
step: 60, loss: 5.388850695453584e-05
step: 70, loss: 0.00018906377954408526
step: 80, loss: 0.00014197968994267285
step: 90, loss: 0.00024146314535755664
step: 100, loss: 0.00015696480113547295
step: 110, loss: 0.002429672284051776
step: 120, loss: 0.00025723627186380327
step: 130, loss: 0.0001373456761939451
step: 140, loss: 8.480945689370856e-05
step: 150, loss: 0.0012672069715335965
step: 160, loss: 0.0020987014286220074
step: 170, loss: 0.00015990583051461726
step: 180, loss: 0.00010308418131899089
step: 190, loss: 0.0017195586115121841
step: 200, loss: 9.887103078654036e-05
step: 210, loss: 8.303380309371278e-05
step: 220, loss: 4.102112143300474e-05
step: 230, loss: 7.695490057813004e-05
step: 240, loss: 0.000260534870903939
step: 250, loss: 0.0006541426409967244
step: 260, loss: 6.262688839342445e-05
step: 270, loss: 0.00033300448558293283
step: 280, loss: 0.03944510221481323
step: 290, loss: 7.504806853830814e-05
step: 300, loss: 4.2763491364894435e-05
step: 310, loss: 0.00016148341819643974
step: 320, loss: 3.319471579743549e-05
step: 330, loss: 0.00017230308731086552
step: 340, loss: 0.00012008492194581777
step: 350, loss: 3.4696095099207014e-05
step: 360, loss: 0.0003422727168072015
step: 370, loss: 0.0012464220635592937
step: 380, loss: 0.05230056867003441
epoch 17: dev_f1=0.69164265129683, f1=0.5696594427244582, best_f1=0.6354166666666666
step: 0, loss: 0.0003464923647698015
step: 10, loss: 0.0010795830748975277
step: 20, loss: 5.5661002988927066e-05
step: 30, loss: 0.00014629348879680037
step: 40, loss: 0.00038244659663178027
step: 50, loss: 6.314422353170812e-05
step: 60, loss: 8.29431155580096e-05
step: 70, loss: 0.001424900139681995
step: 80, loss: 5.328549013938755e-05
step: 90, loss: 0.0087075624614954
step: 100, loss: 4.216035449644551e-05
step: 110, loss: 9.96636736090295e-05
step: 120, loss: 0.00016526776016689837
step: 130, loss: 0.00016274825611617416
step: 140, loss: 0.00024146385840140283
step: 150, loss: 0.009154574014246464
step: 160, loss: 6.012276207911782e-05
step: 170, loss: 0.0003992431447841227
step: 180, loss: 0.0005193339311517775
step: 190, loss: 0.00017418243805877864
step: 200, loss: 0.00015146647638175637
step: 210, loss: 3.2691525120753795e-05
step: 220, loss: 6.400725396815687e-05
step: 230, loss: 0.001203457941301167
step: 240, loss: 5.3770192607771605e-05
step: 250, loss: 3.769333125092089e-05
step: 260, loss: 6.613149162149057e-05
step: 270, loss: 0.0005164904869161546
step: 280, loss: 0.00014860587543807924
step: 290, loss: 7.259012636495754e-05
step: 300, loss: 0.00012828994658775628
step: 310, loss: 0.00016159839287865907
step: 320, loss: 0.007008124142885208
step: 330, loss: 2.8169872166472487e-05
step: 340, loss: 4.230557169648819e-05
step: 350, loss: 7.872790592955425e-05
step: 360, loss: 0.0001647145109018311
step: 370, loss: 0.00018822707352228463
step: 380, loss: 0.00013086233229842037
epoch 18: dev_f1=0.6961651917404129, f1=0.5740740740740741, best_f1=0.6354166666666666
step: 0, loss: 9.72225607256405e-05
step: 10, loss: 0.006983562372624874
step: 20, loss: 0.0002765626413747668
step: 30, loss: 5.049960236647166e-05
step: 40, loss: 6.773113273084164e-05
step: 50, loss: 4.330426236265339e-05
step: 60, loss: 4.0566159441368654e-05
step: 70, loss: 4.3735166400438175e-05
step: 80, loss: 3.568996908143163e-05
step: 90, loss: 0.00012098229490220547
step: 100, loss: 0.0002140995056834072
step: 110, loss: 5.866007995791733e-05
step: 120, loss: 0.0012142708292230964
step: 130, loss: 3.332887717988342e-05
step: 140, loss: 0.0005378328496590257
step: 150, loss: 3.377927714609541e-05
step: 160, loss: 3.45470652973745e-05
step: 170, loss: 9.520738967694342e-05
step: 180, loss: 5.555292955250479e-05
step: 190, loss: 0.00010329642827855423
step: 200, loss: 0.00015367438027169555
step: 210, loss: 0.0006803854485042393
step: 220, loss: 5.0700033170869574e-05
step: 230, loss: 0.0003222147352062166
step: 240, loss: 0.0010069407289847732
step: 250, loss: 5.522753781406209e-05
step: 260, loss: 6.016107727191411e-05
step: 270, loss: 0.0003344115393701941
step: 280, loss: 0.0015721331583335996
step: 290, loss: 4.64027798443567e-05
step: 300, loss: 2.926826164184604e-05
step: 310, loss: 0.00029279335285536945
step: 320, loss: 6.762098928447813e-05
step: 330, loss: 7.430712139466777e-05
step: 340, loss: 2.8549879061756656e-05
step: 350, loss: 2.1218796973698772e-05
step: 360, loss: 4.037260077893734e-05
step: 370, loss: 0.0003934736887458712
step: 380, loss: 3.703820038936101e-05
epoch 19: dev_f1=0.6925373134328358, f1=0.549520766773163, best_f1=0.6354166666666666
step: 0, loss: 4.0640450606588274e-05
step: 10, loss: 0.00035369713441468775
step: 20, loss: 0.0002371303125983104
step: 30, loss: 5.8452878874959424e-05
step: 40, loss: 4.894154699286446e-05
step: 50, loss: 0.00011427364370319992
step: 60, loss: 0.0004278634150978178
step: 70, loss: 6.175469025038183e-05
step: 80, loss: 6.209542334545404e-05
step: 90, loss: 7.410610123770311e-05
step: 100, loss: 4.593290577759035e-05
step: 110, loss: 0.00030511003569699824
step: 120, loss: 0.0001484569365857169
step: 130, loss: 0.00012154387513874099
step: 140, loss: 6.456690607592463e-05
step: 150, loss: 9.28418812691234e-05
step: 160, loss: 3.379752888577059e-05
step: 170, loss: 2.6959138267557137e-05
step: 180, loss: 0.0009409282938577235
step: 190, loss: 2.5659088350948878e-05
step: 200, loss: 4.110663212486543e-05
step: 210, loss: 5.957592657068744e-05
step: 220, loss: 0.0002549068012740463
step: 230, loss: 3.133629070362076e-05
step: 240, loss: 0.0006987547385506332
step: 250, loss: 4.251276914146729e-05
step: 260, loss: 9.466981282457709e-05
step: 270, loss: 6.289204611675814e-05
step: 280, loss: 5.326409882400185e-05
step: 290, loss: 0.012516804970800877
step: 300, loss: 0.0006564012146554887
step: 310, loss: 3.7784066080348566e-05
step: 320, loss: 4.6233664761530235e-05
step: 330, loss: 0.0027914931997656822
step: 340, loss: 8.228446677094325e-05
step: 350, loss: 8.924498979467899e-05
step: 360, loss: 0.00016175930795725435
step: 370, loss: 0.005317901261150837
step: 380, loss: 0.0004720620345324278
epoch 20: dev_f1=0.6902654867256637, f1=0.5669781931464175, best_f1=0.6354166666666666
cuda
Device: cuda
step: 0, loss: 0.5826435089111328
step: 10, loss: 0.47101908922195435
step: 20, loss: 0.3777540624141693
step: 30, loss: 0.23933348059654236
step: 40, loss: 0.19738897681236267
step: 50, loss: 0.24386821687221527
step: 60, loss: 0.14791132509708405
step: 70, loss: 0.3739050328731537
step: 80, loss: 0.29958680272102356
step: 90, loss: 0.1697462499141693
step: 100, loss: 0.296556681394577
step: 110, loss: 0.29950469732284546
step: 120, loss: 0.18875092267990112
step: 130, loss: 0.24731728434562683
step: 140, loss: 0.22613048553466797
step: 150, loss: 0.3607489764690399
step: 160, loss: 0.4203234314918518
step: 170, loss: 0.2963433265686035
step: 180, loss: 0.3357050120830536
step: 190, loss: 0.10948914289474487
step: 200, loss: 0.2703591585159302
step: 210, loss: 0.3244766592979431
step: 220, loss: 0.159939706325531
step: 230, loss: 0.6389636993408203
step: 240, loss: 0.22537928819656372
step: 250, loss: 0.1167803630232811
step: 260, loss: 0.2524285912513733
step: 270, loss: 0.16382059454917908
step: 280, loss: 0.3208827078342438
step: 290, loss: 0.24218858778476715
step: 300, loss: 0.3988003134727478
step: 310, loss: 0.30179089307785034
step: 320, loss: 0.5172621607780457
step: 330, loss: 0.2552240192890167
step: 340, loss: 0.5196487307548523
step: 350, loss: 0.4139705300331116
step: 360, loss: 0.31973040103912354
step: 370, loss: 0.3054402470588684
step: 380, loss: 0.2885461151599884
epoch 1: dev_f1=0.3147699757869249, f1=0.28780487804878047, best_f1=0.28780487804878047
step: 0, loss: 0.17255628108978271
step: 10, loss: 0.1816118061542511
step: 20, loss: 0.2610466480255127
step: 30, loss: 0.27180996537208557
step: 40, loss: 0.05280527472496033
step: 50, loss: 0.3411373794078827
step: 60, loss: 0.36981865763664246
step: 70, loss: 0.2888646423816681
step: 80, loss: 0.1766054779291153
step: 90, loss: 0.27485838532447815
step: 100, loss: 0.15391609072685242
step: 110, loss: 0.13948330283164978
step: 120, loss: 0.06622019410133362
step: 130, loss: 0.28069552779197693
step: 140, loss: 0.2334395796060562
step: 150, loss: 0.38177692890167236
step: 160, loss: 0.13750022649765015
step: 170, loss: 0.2987939119338989
step: 180, loss: 0.07773338258266449
step: 190, loss: 0.16115081310272217
step: 200, loss: 0.31227177381515503
step: 210, loss: 0.12790706753730774
step: 220, loss: 0.09354175627231598
step: 230, loss: 0.22722455859184265
step: 240, loss: 0.1882064789533615
step: 250, loss: 0.16222509741783142
step: 260, loss: 0.14748847484588623
step: 270, loss: 0.14282502233982086
step: 280, loss: 0.43127313256263733
step: 290, loss: 0.10305365175008774
step: 300, loss: 0.09862220287322998
step: 310, loss: 0.0830952525138855
step: 320, loss: 0.3490084409713745
step: 330, loss: 0.1818631887435913
step: 340, loss: 0.17482954263687134
step: 350, loss: 0.15643034875392914
step: 360, loss: 0.06576709449291229
step: 370, loss: 0.17751659452915192
step: 380, loss: 0.16669964790344238
epoch 2: dev_f1=0.49142857142857144, f1=0.39871382636655955, best_f1=0.39871382636655955
step: 0, loss: 0.1013585701584816
step: 10, loss: 0.13582105934619904
step: 20, loss: 0.18994398415088654
step: 30, loss: 0.025590883567929268
step: 40, loss: 0.09716320037841797
step: 50, loss: 0.3540997803211212
step: 60, loss: 0.04271881654858589
step: 70, loss: 0.10937759280204773
step: 80, loss: 0.019919291138648987
step: 90, loss: 0.039986394345760345
step: 100, loss: 0.23962092399597168
step: 110, loss: 0.12491819262504578
step: 120, loss: 0.2868267297744751
step: 130, loss: 0.05605914071202278
step: 140, loss: 0.030863942578434944
step: 150, loss: 0.010365842841565609
step: 160, loss: 0.04531610757112503
step: 170, loss: 0.04937567189335823
step: 180, loss: 0.06318439543247223
step: 190, loss: 0.023776762187480927
step: 200, loss: 0.06098352372646332
step: 210, loss: 0.14225943386554718
step: 220, loss: 0.06155138090252876
step: 230, loss: 0.24553462862968445
step: 240, loss: 0.17616063356399536
step: 250, loss: 0.0443405918776989
step: 260, loss: 0.028836697340011597
step: 270, loss: 0.09573698043823242
step: 280, loss: 0.06649775058031082
step: 290, loss: 0.026014933362603188
step: 300, loss: 0.18747882544994354
step: 310, loss: 0.09632620215415955
step: 320, loss: 0.16611222922801971
step: 330, loss: 0.3198281228542328
step: 340, loss: 0.07991596311330795
step: 350, loss: 0.13806432485580444
step: 360, loss: 0.38020530343055725
step: 370, loss: 0.1380995661020279
step: 380, loss: 0.1099352166056633
epoch 3: dev_f1=0.6246575342465753, f1=0.5142857142857142, best_f1=0.5142857142857142
step: 0, loss: 0.024793429300189018
step: 10, loss: 0.009936616756021976
step: 20, loss: 0.03292511776089668
step: 30, loss: 0.10788285732269287
step: 40, loss: 0.10397353768348694
step: 50, loss: 0.04287087544798851
step: 60, loss: 0.021954040974378586
step: 70, loss: 0.04486443102359772
step: 80, loss: 0.02050636149942875
step: 90, loss: 0.12772217392921448
step: 100, loss: 0.10430373251438141
step: 110, loss: 0.028316697105765343
step: 120, loss: 0.10744091868400574
step: 130, loss: 0.01461043395102024
step: 140, loss: 0.0495782196521759
step: 150, loss: 0.0020302210468798876
step: 160, loss: 0.10769614577293396
step: 170, loss: 0.19004768133163452
step: 180, loss: 0.10388027131557465
step: 190, loss: 0.12771180272102356
step: 200, loss: 0.0337006077170372
step: 210, loss: 0.18970513343811035
step: 220, loss: 0.052631959319114685
step: 230, loss: 0.005655677989125252
step: 240, loss: 0.15659208595752716
step: 250, loss: 0.029594646766781807
step: 260, loss: 0.05796761065721512
step: 270, loss: 0.042366791516542435
step: 280, loss: 0.20268823206424713
step: 290, loss: 0.05977979674935341
step: 300, loss: 0.018297653645277023
step: 310, loss: 0.1712339073419571
step: 320, loss: 0.056344375014305115
step: 330, loss: 0.16041654348373413
step: 340, loss: 0.06408412754535675
step: 350, loss: 0.18959414958953857
step: 360, loss: 0.05446925014257431
step: 370, loss: 0.2379823923110962
step: 380, loss: 0.07188203185796738
epoch 4: dev_f1=0.7067669172932332, f1=0.6282722513089005, best_f1=0.6282722513089005
step: 0, loss: 0.022698543965816498
step: 10, loss: 0.047899309545755386
step: 20, loss: 0.05862531065940857
step: 30, loss: 0.05049210786819458
step: 40, loss: 0.11150877177715302
step: 50, loss: 0.15813149511814117
step: 60, loss: 0.0582086518406868
step: 70, loss: 0.20666712522506714
step: 80, loss: 0.02732444927096367
step: 90, loss: 0.143117293715477
step: 100, loss: 0.012878634966909885
step: 110, loss: 0.13699421286582947
step: 120, loss: 0.010327022522687912
step: 130, loss: 0.021236222237348557
step: 140, loss: 0.007776751648634672
step: 150, loss: 0.005150293931365013
step: 160, loss: 0.00484370905905962
step: 170, loss: 0.027742622420191765
step: 180, loss: 0.019011305645108223
step: 190, loss: 0.12485507130622864
step: 200, loss: 0.019132694229483604
step: 210, loss: 0.08940701186656952
step: 220, loss: 0.0052180541679263115
step: 230, loss: 0.016894523054361343
step: 240, loss: 0.09790468215942383
step: 250, loss: 0.008022050373256207
step: 260, loss: 0.019469821825623512
step: 270, loss: 0.12293902039527893
step: 280, loss: 0.20329004526138306
step: 290, loss: 0.019636331126093864
step: 300, loss: 0.03750822693109512
step: 310, loss: 0.1943752020597458
step: 320, loss: 0.003909937106072903
step: 330, loss: 0.06503325700759888
step: 340, loss: 0.06642785668373108
step: 350, loss: 0.1475999355316162
step: 360, loss: 0.0487942174077034
step: 370, loss: 0.07143215090036392
step: 380, loss: 0.009787888266146183
epoch 5: dev_f1=0.6810810810810811, f1=0.6391184573002755, best_f1=0.6282722513089005
step: 0, loss: 0.010322780348360538
step: 10, loss: 0.053446609526872635
step: 20, loss: 0.14064669609069824
step: 30, loss: 0.0022755791433155537
step: 40, loss: 0.002892970573157072
step: 50, loss: 0.0004458994953893125
step: 60, loss: 0.08641250431537628
step: 70, loss: 0.032057736068964005
step: 80, loss: 0.1221231147646904
step: 90, loss: 0.020772358402609825
step: 100, loss: 0.0015489245997741818
step: 110, loss: 0.006019295193254948
step: 120, loss: 0.028129374608397484
step: 130, loss: 0.021313747391104698
step: 140, loss: 0.02867693081498146
step: 150, loss: 0.1269223988056183
step: 160, loss: 0.027601733803749084
step: 170, loss: 0.019834309816360474
step: 180, loss: 0.004554392769932747
step: 190, loss: 0.003294412512332201
step: 200, loss: 0.04724861681461334
step: 210, loss: 0.038743067532777786
step: 220, loss: 0.02668602392077446
step: 230, loss: 0.0008381432271562517
step: 240, loss: 0.08637213706970215
step: 250, loss: 0.03722655400633812
step: 260, loss: 0.003853083588182926
step: 270, loss: 0.0028221956454217434
step: 280, loss: 0.07920613139867783
step: 290, loss: 0.04132549837231636
step: 300, loss: 0.035184308886528015
step: 310, loss: 0.001942158560268581
step: 320, loss: 0.0034035269636660814
step: 330, loss: 0.10247676819562912
step: 340, loss: 0.12557119131088257
step: 350, loss: 0.002709947293624282
step: 360, loss: 0.01789233274757862
step: 370, loss: 0.0313459150493145
step: 380, loss: 0.20786629617214203
epoch 6: dev_f1=0.7116883116883116, f1=0.6465753424657535, best_f1=0.6465753424657535
step: 0, loss: 0.022536449134349823
step: 10, loss: 0.15730004012584686
step: 20, loss: 0.028201187029480934
step: 30, loss: 0.003450472839176655
step: 40, loss: 0.0020125783048570156
step: 50, loss: 0.0019057566532865167
step: 60, loss: 0.020855531096458435
step: 70, loss: 0.03640667349100113
step: 80, loss: 0.22228869795799255
step: 90, loss: 0.002204644726589322
step: 100, loss: 0.0012479207944124937
step: 110, loss: 0.0490458719432354
step: 120, loss: 0.008957317098975182
step: 130, loss: 0.005587439984083176
step: 140, loss: 0.0650419220328331
step: 150, loss: 0.0018517110729590058
step: 160, loss: 0.006803170777857304
step: 170, loss: 0.007595628499984741
step: 180, loss: 0.007679868955165148
step: 190, loss: 0.0028305158484727144
step: 200, loss: 0.0007604453712701797
step: 210, loss: 0.10538257658481598
step: 220, loss: 0.1285848468542099
step: 230, loss: 0.01682129316031933
step: 240, loss: 0.0004685262683779001
step: 250, loss: 0.07545726001262665
step: 260, loss: 0.03067055530846119
step: 270, loss: 0.0274294875562191
step: 280, loss: 0.021225443109869957
step: 290, loss: 0.045776695013046265
step: 300, loss: 0.0008721525082364678
step: 310, loss: 0.2815990447998047
step: 320, loss: 0.16160370409488678
step: 330, loss: 0.0036282094661146402
step: 340, loss: 0.025656769052147865
step: 350, loss: 0.002738961949944496
step: 360, loss: 0.04041452333331108
step: 370, loss: 0.09191063791513443
step: 380, loss: 0.01046088244765997
epoch 7: dev_f1=0.6282420749279539, f1=0.5504587155963303, best_f1=0.6465753424657535
step: 0, loss: 0.00035651694633997977
step: 10, loss: 0.18371175229549408
step: 20, loss: 0.011770430020987988
step: 30, loss: 0.004474644549190998
step: 40, loss: 0.0023244782350957394
step: 50, loss: 0.00034207990393042564
step: 60, loss: 0.0007219272665679455
step: 70, loss: 0.03232242912054062
step: 80, loss: 0.005734418053179979
step: 90, loss: 0.028141669929027557
step: 100, loss: 0.032330431044101715
step: 110, loss: 0.0013349936343729496
step: 120, loss: 0.0014331855345517397
step: 130, loss: 0.00037020232412032783
step: 140, loss: 0.0013392772525548935
step: 150, loss: 0.055137306451797485
step: 160, loss: 0.0053191655315458775
step: 170, loss: 0.011409238912165165
step: 180, loss: 0.004598340485244989
step: 190, loss: 0.0006237922934815288
step: 200, loss: 0.019490063190460205
step: 210, loss: 0.00041486346162855625
step: 220, loss: 0.006447782274335623
step: 230, loss: 0.017040545120835304
step: 240, loss: 0.0029336372390389442
step: 250, loss: 0.022108104079961777
step: 260, loss: 0.004886196460574865
step: 270, loss: 0.00562203349545598
step: 280, loss: 0.06932532787322998
step: 290, loss: 0.0033971816301345825
step: 300, loss: 0.00023947315639816225
step: 310, loss: 0.0013585187261924148
step: 320, loss: 0.03953268751502037
step: 330, loss: 0.06608254462480545
step: 340, loss: 0.007651365362107754
step: 350, loss: 0.0021303410176187754
step: 360, loss: 0.018567362800240517
step: 370, loss: 0.0019954447634518147
step: 380, loss: 0.13940772414207458
epoch 8: dev_f1=0.695, f1=0.6532663316582915, best_f1=0.6465753424657535
step: 0, loss: 0.0006881002918817103
step: 10, loss: 0.047237738966941833
step: 20, loss: 0.004155648406594992
step: 30, loss: 0.004137613344937563
step: 40, loss: 0.0007080495706759393
step: 50, loss: 0.0013698951806873083
step: 60, loss: 0.0001620333787286654
step: 70, loss: 0.0062829977832734585
step: 80, loss: 0.0003500267630442977
step: 90, loss: 0.005678135901689529
step: 100, loss: 0.061577800661325455
step: 110, loss: 0.023870516568422318
step: 120, loss: 0.0010084169916808605
step: 130, loss: 0.021439770236611366
step: 140, loss: 0.0019924871157854795
step: 150, loss: 0.13982650637626648
step: 160, loss: 0.0020021640229970217
step: 170, loss: 0.00641561858355999
step: 180, loss: 0.003974133171141148
step: 190, loss: 0.05100487917661667
step: 200, loss: 0.002048828173428774
step: 210, loss: 0.03877636417746544
step: 220, loss: 0.0017074268544092774
step: 230, loss: 0.053129710257053375
step: 240, loss: 0.07517829537391663
step: 250, loss: 0.0006427587359212339
step: 260, loss: 0.08595316112041473
step: 270, loss: 0.0011144987074658275
step: 280, loss: 0.011991167441010475
step: 290, loss: 0.0008485834114253521
step: 300, loss: 0.2494601607322693
step: 310, loss: 0.003255152842029929
step: 320, loss: 0.0033839265815913677
step: 330, loss: 0.012558155693113804
step: 340, loss: 0.09315937012434006
step: 350, loss: 0.0014767198590561748
step: 360, loss: 0.0021016329992562532
step: 370, loss: 0.0009141007321886718
step: 380, loss: 0.002440388547256589
epoch 9: dev_f1=0.6888361045130642, f1=0.6231884057971014, best_f1=0.6465753424657535
step: 0, loss: 0.022699274122714996
step: 10, loss: 0.004075825680047274
step: 20, loss: 0.0003831429348792881
step: 30, loss: 0.0007782462635077536
step: 40, loss: 0.0004669134796131402
step: 50, loss: 0.00112052948679775
step: 60, loss: 0.0010743424063548446
step: 70, loss: 0.04786023497581482
step: 80, loss: 0.0041510434821248055
step: 90, loss: 8.607026393292472e-05
step: 100, loss: 0.0002819981600623578
step: 110, loss: 0.017636485397815704
step: 120, loss: 0.0012275278568267822
step: 130, loss: 0.0008968855836428702
step: 140, loss: 0.003997869789600372
step: 150, loss: 0.002135910326614976
step: 160, loss: 0.00673966109752655
step: 170, loss: 0.008860649541020393
step: 180, loss: 0.007169975433498621
step: 190, loss: 0.06527642160654068
step: 200, loss: 0.0014251299435272813
step: 210, loss: 0.0013426122022792697
step: 220, loss: 0.0013205412542447448
step: 230, loss: 0.0008200265001505613
step: 240, loss: 0.007505742833018303
step: 250, loss: 0.0014427616260945797
step: 260, loss: 0.0018102769972756505
step: 270, loss: 0.042011406272649765
step: 280, loss: 0.002781508956104517
step: 290, loss: 0.020631857216358185
step: 300, loss: 0.0009651658474467695
step: 310, loss: 0.016831308603286743
step: 320, loss: 0.00223746569827199
step: 330, loss: 0.0026705143973231316
step: 340, loss: 0.0009663120727054775
step: 350, loss: 0.24152816832065582
step: 360, loss: 0.015428641811013222
step: 370, loss: 0.011149166151881218
step: 380, loss: 0.0011201777961105108
epoch 10: dev_f1=0.6558265582655827, f1=0.5865921787709497, best_f1=0.6465753424657535
step: 0, loss: 0.013344744220376015
step: 10, loss: 0.045876771211624146
step: 20, loss: 0.000489796104375273
step: 30, loss: 0.000157663511345163
step: 40, loss: 0.00024324543483089656
step: 50, loss: 0.0696050152182579
step: 60, loss: 0.0001459016348235309
step: 70, loss: 0.0036461579147726297
step: 80, loss: 0.0002488807658664882
step: 90, loss: 0.0015523205511271954
step: 100, loss: 0.0005153862293809652
step: 110, loss: 0.05003943294286728
step: 120, loss: 0.001533251372165978
step: 130, loss: 0.007514717523008585
step: 140, loss: 0.012218317948281765
step: 150, loss: 0.010950141586363316
step: 160, loss: 0.12674827873706818
step: 170, loss: 0.0013091611908748746
step: 180, loss: 0.009420137852430344
step: 190, loss: 0.0030514956451952457
step: 200, loss: 0.0007184421992860734
step: 210, loss: 0.0006852804217487574
step: 220, loss: 0.0001678467815509066
step: 230, loss: 0.07086798548698425
step: 240, loss: 0.004068518057465553
step: 250, loss: 0.01213158667087555
step: 260, loss: 0.00026826350949704647
step: 270, loss: 0.00019100065401289612
step: 280, loss: 0.006124389823526144
step: 290, loss: 0.001438329229131341
step: 300, loss: 0.004040655680000782
step: 310, loss: 0.00017278309678658843
step: 320, loss: 0.002349712885916233
step: 330, loss: 0.0006461754674091935
step: 340, loss: 4.654109216062352e-05
step: 350, loss: 7.432023994624615e-05
step: 360, loss: 0.000380011711968109
step: 370, loss: 0.002388071734458208
step: 380, loss: 0.0007609059102833271
epoch 11: dev_f1=0.6878612716763006, f1=0.6257309941520468, best_f1=0.6465753424657535
step: 0, loss: 0.01759803667664528
step: 10, loss: 0.004545753356069326
step: 20, loss: 0.003626965917646885
step: 30, loss: 0.0006826994940638542
step: 40, loss: 0.00037122934008948505
step: 50, loss: 0.0005538109107874334
step: 60, loss: 0.012795381247997284
step: 70, loss: 0.00019540954963304102
step: 80, loss: 0.0003816684184130281
step: 90, loss: 0.0005756857572123408
step: 100, loss: 0.004870087839663029
step: 110, loss: 0.00011996883404208347
step: 120, loss: 0.0005879909149371088
step: 130, loss: 0.1268184632062912
step: 140, loss: 0.00032743578776717186
step: 150, loss: 0.0011604037135839462
step: 160, loss: 0.0005778132472187281
step: 170, loss: 0.00032890430884435773
step: 180, loss: 0.00039053004002198577
step: 190, loss: 0.0003821193240582943
step: 200, loss: 0.0014239044394344091
step: 210, loss: 0.0006794609362259507
step: 220, loss: 0.002511225175112486
step: 230, loss: 0.0009802458807826042
step: 240, loss: 0.004571881145238876
step: 250, loss: 0.007294188719242811
step: 260, loss: 0.003289883490651846
step: 270, loss: 0.0002911631599999964
step: 280, loss: 0.026614002883434296
step: 290, loss: 0.00024109508376568556
step: 300, loss: 0.1659485250711441
step: 310, loss: 3.86708379664924e-05
step: 320, loss: 0.0004971594316884875
step: 330, loss: 0.0005303420475684106
step: 340, loss: 0.00020374683663249016
step: 350, loss: 0.0013269874034449458
step: 360, loss: 8.435466588707641e-05
step: 370, loss: 8.941466512624174e-05
step: 380, loss: 0.00016469962429255247
epoch 12: dev_f1=0.650887573964497, f1=0.490566037735849, best_f1=0.6465753424657535
step: 0, loss: 0.0003546111402101815
step: 10, loss: 0.00030795237398706377
step: 20, loss: 0.00039395951898768544
step: 30, loss: 0.028163112699985504
step: 40, loss: 0.000506110314745456
step: 50, loss: 0.0007461094064638019
step: 60, loss: 0.00028647444560192525
step: 70, loss: 0.00020595396927092224
step: 80, loss: 0.002041321247816086
step: 90, loss: 0.000458967057056725
step: 100, loss: 0.0010216903174296021
step: 110, loss: 0.00019840168533846736
step: 120, loss: 9.401080751558766e-05
step: 130, loss: 0.00012091346434317529
step: 140, loss: 0.031136352568864822
step: 150, loss: 0.000223052004002966
step: 160, loss: 0.0008714271243661642
step: 170, loss: 0.0003028045757673681
step: 180, loss: 0.0006143134087324142
step: 190, loss: 0.005979507230222225
step: 200, loss: 6.979819590924308e-05
step: 210, loss: 6.731413304805756e-05
step: 220, loss: 0.00013257346290629357
step: 230, loss: 5.4906962759559974e-05
step: 240, loss: 0.0001163700653705746
step: 250, loss: 0.007246268447488546
step: 260, loss: 0.0002518992405384779
step: 270, loss: 0.0014143756125122309
step: 280, loss: 0.05386051908135414
step: 290, loss: 0.0022503628861159086
step: 300, loss: 5.758712723036297e-05
step: 310, loss: 0.04084378108382225
step: 320, loss: 0.024433042854070663
step: 330, loss: 8.118645928334445e-05
step: 340, loss: 0.0033360461238771677
step: 350, loss: 0.00012073911057086661
step: 360, loss: 0.003841196885332465
step: 370, loss: 0.00012470257934182882
step: 380, loss: 0.0003495920973364264
epoch 13: dev_f1=0.7074468085106383, f1=0.6016260162601628, best_f1=0.6465753424657535
step: 0, loss: 0.00027579450397752225
step: 10, loss: 0.00012970736133866012
step: 20, loss: 0.014061355032026768
step: 30, loss: 0.0002510824997443706
step: 40, loss: 0.00011099242692580447
step: 50, loss: 0.00013578937796410173
step: 60, loss: 0.00010674465011106804
step: 70, loss: 3.307558290543966e-05
step: 80, loss: 0.001642873277887702
step: 90, loss: 0.0010396164143458009
step: 100, loss: 0.00046131262206472456
step: 110, loss: 0.00034960141056217253
step: 120, loss: 0.0006244508549571037
step: 130, loss: 0.0023397619370371103
step: 140, loss: 0.001385885989293456
step: 150, loss: 0.0003441807930357754
step: 160, loss: 0.0002879987587220967
step: 170, loss: 5.1244187488919124e-05
step: 180, loss: 0.00024877715623006225
step: 190, loss: 0.004603988956660032
step: 200, loss: 0.0006258346838876605
step: 210, loss: 0.003016474423930049
step: 220, loss: 7.189557800302282e-05
step: 230, loss: 0.0009368956671096385
step: 240, loss: 3.436042970861308e-05
step: 250, loss: 0.0015489970101043582
step: 260, loss: 0.00014097370149102062
step: 270, loss: 0.00021726755949202925
step: 280, loss: 0.00011882973922183737
step: 290, loss: 5.765442983829416e-05
step: 300, loss: 0.0034537161700427532
step: 310, loss: 0.0012390388874337077
step: 320, loss: 5.95132187299896e-05
step: 330, loss: 8.172416710294783e-05
step: 340, loss: 0.0029874718748033047
step: 350, loss: 0.0005117689142934978
step: 360, loss: 8.68672359501943e-05
step: 370, loss: 0.007206648588180542
step: 380, loss: 0.0008782354998402297
epoch 14: dev_f1=0.620253164556962, f1=0.4931506849315069, best_f1=0.6465753424657535
step: 0, loss: 0.06275314837694168
step: 10, loss: 4.5981407311046496e-05
step: 20, loss: 5.292255445965566e-05
step: 30, loss: 0.0009401172865182161
step: 40, loss: 7.949569408083335e-05
step: 50, loss: 0.0010666786693036556
step: 60, loss: 0.0002886983857024461
step: 70, loss: 0.04035050794482231
step: 80, loss: 0.0005716063315048814
step: 90, loss: 8.5976324044168e-05
step: 100, loss: 0.004480611998587847
step: 110, loss: 4.262985385139473e-05
step: 120, loss: 0.0002226068318122998
step: 130, loss: 0.0001441808562958613
step: 140, loss: 0.001402456546202302
step: 150, loss: 0.00015644283848814666
step: 160, loss: 0.05730518326163292
step: 170, loss: 0.0002657921868376434
step: 180, loss: 0.003914779983460903
step: 190, loss: 0.019344668835401535
step: 200, loss: 0.0007001921185292304
step: 210, loss: 0.03315494582056999
step: 220, loss: 0.0001435017620678991
step: 230, loss: 0.0004915381432510912
step: 240, loss: 8.044949936447665e-05
step: 250, loss: 5.436279025161639e-05
step: 260, loss: 0.00033814343623816967
step: 270, loss: 0.00010929273412330076
step: 280, loss: 0.005758505314588547
step: 290, loss: 3.3529366191942245e-05
step: 300, loss: 0.05594206973910332
step: 310, loss: 0.00019141977827530354
step: 320, loss: 0.0004537401837296784
step: 330, loss: 4.433905633050017e-05
step: 340, loss: 3.454973557381891e-05
step: 350, loss: 0.005439367610961199
step: 360, loss: 4.5647757360711694e-05
step: 370, loss: 0.0002528007607907057
step: 380, loss: 0.010168603621423244
epoch 15: dev_f1=0.6470588235294118, f1=0.5521472392638036, best_f1=0.6465753424657535
step: 0, loss: 0.0008208849467337132
step: 10, loss: 0.025900941342115402
step: 20, loss: 4.719507342088036e-05
step: 30, loss: 0.0011585678439587355
step: 40, loss: 0.00014967865718062967
step: 50, loss: 3.402162838028744e-05
step: 60, loss: 4.4036343751940876e-05
step: 70, loss: 0.0008577144471928477
step: 80, loss: 0.0015132830012589693
step: 90, loss: 9.9622891866602e-05
step: 100, loss: 0.0001159300736617297
step: 110, loss: 0.00026753864949569106
step: 120, loss: 3.157817991450429e-05
step: 130, loss: 0.0002457487862557173
step: 140, loss: 0.0006781317642889917
step: 150, loss: 0.00014063551498111337
step: 160, loss: 0.0006426387699320912
step: 170, loss: 3.2360399927711114e-05
step: 180, loss: 0.00016045165830291808
step: 190, loss: 0.0007775097037665546
step: 200, loss: 6.765378202544525e-05
step: 210, loss: 0.00047335258568637073
step: 220, loss: 0.003484838642179966
step: 230, loss: 0.02283935621380806
step: 240, loss: 3.9406822907039896e-05
step: 250, loss: 2.4835802832967602e-05
step: 260, loss: 0.00023990074987523258
step: 270, loss: 0.00043384599848650396
step: 280, loss: 2.9510734748328105e-05
step: 290, loss: 0.0002952726499643177
step: 300, loss: 1.7583042790647596e-05
step: 310, loss: 0.0001752139942254871
step: 320, loss: 0.0001824739301810041
step: 330, loss: 5.7403947721468285e-05
step: 340, loss: 0.00043937648297287524
step: 350, loss: 0.0003031804517377168
step: 360, loss: 0.0005152099183760583
step: 370, loss: 6.263872637646273e-05
step: 380, loss: 0.0004840822075493634
epoch 16: dev_f1=0.6628242074927955, f1=0.5865102639296187, best_f1=0.6465753424657535
step: 0, loss: 8.05593590484932e-05
step: 10, loss: 0.0004294002428650856
step: 20, loss: 0.0003264389233663678
step: 30, loss: 9.645274258218706e-05
step: 40, loss: 0.00024345323618035764
step: 50, loss: 3.679460132843815e-05
step: 60, loss: 0.00014075775106903166
step: 70, loss: 3.491517054499127e-05
step: 80, loss: 0.19044476747512817
step: 90, loss: 0.0738644227385521
step: 100, loss: 0.0006619168561883271
step: 110, loss: 0.0006236983463168144
step: 120, loss: 0.012121060863137245
step: 130, loss: 0.00014049145102035254
step: 140, loss: 0.0014599516289308667
step: 150, loss: 0.0003878516727127135
step: 160, loss: 0.00016363586473744363
step: 170, loss: 7.92412756709382e-05
step: 180, loss: 6.138560274848714e-05
step: 190, loss: 0.00024529526126571
step: 200, loss: 0.0002914881915785372
step: 210, loss: 8.25837705633603e-05
step: 220, loss: 3.462420863797888e-05
step: 230, loss: 3.078702502534725e-05
step: 240, loss: 0.000309783557895571
step: 250, loss: 0.01193833164870739
step: 260, loss: 3.156221646349877e-05
step: 270, loss: 0.00012965335918124765
step: 280, loss: 0.0012814734363928437
step: 290, loss: 0.0005381189403124154
step: 300, loss: 0.000351336580934003
step: 310, loss: 0.00019347692432347685
step: 320, loss: 3.5672961530508474e-05
step: 330, loss: 0.0024035831447690725
step: 340, loss: 3.4740136470645666e-05
step: 350, loss: 2.1546620700974017e-05
step: 360, loss: 0.0010116577614098787
step: 370, loss: 5.055247311247513e-05
step: 380, loss: 7.579119119327515e-05
epoch 17: dev_f1=0.6846361185983827, f1=0.6033519553072626, best_f1=0.6465753424657535
step: 0, loss: 0.0005498495302163064
step: 10, loss: 0.0010564089752733707
step: 20, loss: 2.3092552510206588e-05
step: 30, loss: 0.00016460094775538892
step: 40, loss: 0.0010369959054514766
step: 50, loss: 0.00029419767088256776
step: 60, loss: 7.728605851298198e-05
step: 70, loss: 9.396298992214724e-05
step: 80, loss: 0.00024860844132490456
step: 90, loss: 0.006063183303922415
step: 100, loss: 0.00012335131759755313
step: 110, loss: 9.496295388089493e-05
step: 120, loss: 0.00011529679613886401
step: 130, loss: 9.617095929570496e-05
step: 140, loss: 8.869964949553832e-05
step: 150, loss: 0.006499702576547861
step: 160, loss: 6.649969873251393e-05
step: 170, loss: 0.012244327925145626
step: 180, loss: 0.001362155075185001
step: 190, loss: 0.00022575368348043412
step: 200, loss: 0.00013665125879924744
step: 210, loss: 1.986649658647366e-05
step: 220, loss: 0.00019595891353674233
step: 230, loss: 0.001117480336688459
step: 240, loss: 0.0008476667571812868
step: 250, loss: 3.558471144060604e-05
step: 260, loss: 2.543807204347104e-05
step: 270, loss: 3.5313951229909435e-05
step: 280, loss: 2.5945570087060332e-05
step: 290, loss: 3.612537693697959e-05
step: 300, loss: 0.00022880038886796683
step: 310, loss: 6.515873974421993e-05
step: 320, loss: 0.002426764229312539
step: 330, loss: 0.0001677828113315627
step: 340, loss: 3.931551691493951e-05
step: 350, loss: 3.3878066460601985e-05
step: 360, loss: 0.0004570482997223735
step: 370, loss: 3.8907037378521636e-05
step: 380, loss: 5.613267785520293e-05
epoch 18: dev_f1=0.6647887323943661, f1=0.5923753665689149, best_f1=0.6465753424657535
step: 0, loss: 8.482262637699023e-05
step: 10, loss: 0.0004181937256362289
step: 20, loss: 8.615974365966395e-05
step: 30, loss: 0.00031870038947090507
step: 40, loss: 0.000655718962661922
step: 50, loss: 6.064132685423829e-05
step: 60, loss: 2.049233989964705e-05
step: 70, loss: 0.0005242963088676333
step: 80, loss: 5.310584310791455e-05
step: 90, loss: 0.0024188568349927664
step: 100, loss: 8.537055691704154e-05
step: 110, loss: 0.00022249665926210582
step: 120, loss: 0.00023847169359214604
step: 130, loss: 5.160443106433377e-05
step: 140, loss: 0.0006977145676501095
step: 150, loss: 2.0838499040110037e-05
step: 160, loss: 7.999022636795416e-05
step: 170, loss: 3.374521475052461e-05
step: 180, loss: 0.00014492360060103238
step: 190, loss: 2.2917047317605466e-05
step: 200, loss: 2.8821359592257068e-05
step: 210, loss: 0.0002610852534417063
step: 220, loss: 0.0013350741937756538
step: 230, loss: 0.0001362627954222262
step: 240, loss: 0.001722674467600882
step: 250, loss: 0.00020053698972333223
step: 260, loss: 0.00011042247933801264
step: 270, loss: 3.6718749470310286e-05
step: 280, loss: 5.5408861953765154e-05
step: 290, loss: 2.3620797946932726e-05
step: 300, loss: 0.05131730064749718
step: 310, loss: 0.0027111670933663845
step: 320, loss: 0.00010085969552164897
step: 330, loss: 9.534708806313574e-05
step: 340, loss: 0.0005311922868713737
step: 350, loss: 5.8565707149682567e-05
step: 360, loss: 0.00014983254368416965
step: 370, loss: 0.00039657551678828895
step: 380, loss: 5.86850474064704e-05
epoch 19: dev_f1=0.6646706586826346, f1=0.5828220858895705, best_f1=0.6465753424657535
step: 0, loss: 2.59828484558966e-05
step: 10, loss: 3.273120819358155e-05
step: 20, loss: 4.910474308417179e-05
step: 30, loss: 2.240684989374131e-05
step: 40, loss: 0.0001559633092256263
step: 50, loss: 2.4816896257107146e-05
step: 60, loss: 2.0205452528898604e-05
step: 70, loss: 4.268132761353627e-05
step: 80, loss: 0.0007503411034122109
step: 90, loss: 0.0021936665289103985
step: 100, loss: 2.1787795049021952e-05
step: 110, loss: 0.00027217803290113807
step: 120, loss: 6.647477130172774e-05
step: 130, loss: 0.0002334972086828202
step: 140, loss: 0.002494585933163762
step: 150, loss: 9.089663944905624e-05
step: 160, loss: 5.761018110206351e-05
step: 170, loss: 3.408685006434098e-05
step: 180, loss: 5.515052180271596e-05
step: 190, loss: 1.9900126062566414e-05
step: 200, loss: 2.0316761947469786e-05
step: 210, loss: 0.00026023006648756564
step: 220, loss: 4.654623262467794e-05
step: 230, loss: 6.664508691756055e-05
step: 240, loss: 0.00012340499961283058
step: 250, loss: 0.00010274620581185445
step: 260, loss: 4.1332521504955366e-05
step: 270, loss: 1.8875443856813945e-05
step: 280, loss: 3.421957808313891e-05
step: 290, loss: 0.010234927758574486
step: 300, loss: 0.0009418870904482901
step: 310, loss: 4.619003084371798e-05
step: 320, loss: 0.00019152931054122746
step: 330, loss: 0.00014086731243878603
step: 340, loss: 0.0001032339787343517
step: 350, loss: 3.665433541755192e-05
step: 360, loss: 0.23139089345932007
step: 370, loss: 0.0038518980145454407
step: 380, loss: 0.011150912381708622
epoch 20: dev_f1=0.6723163841807909, f1=0.6011560693641619, best_f1=0.6465753424657535
