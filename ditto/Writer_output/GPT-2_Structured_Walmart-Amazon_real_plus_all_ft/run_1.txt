cuda
Device: cuda
step: 0, loss: 0.6047236323356628
step: 10, loss: 0.3808511197566986
step: 20, loss: 0.2706752121448517
step: 30, loss: 0.3684921860694885
step: 40, loss: 0.25600773096084595
step: 50, loss: 0.340729683637619
step: 60, loss: 0.1661093682050705
step: 70, loss: 0.3886207044124603
step: 80, loss: 0.2761020064353943
step: 90, loss: 0.14981326460838318
step: 100, loss: 0.23613782227039337
step: 110, loss: 0.41107770800590515
step: 120, loss: 0.31984174251556396
step: 130, loss: 0.2885756492614746
step: 140, loss: 0.3870837092399597
step: 150, loss: 0.09780797362327576
step: 160, loss: 0.26373419165611267
step: 170, loss: 0.40249860286712646
step: 180, loss: 0.2494124323129654
step: 190, loss: 0.27576571702957153
step: 200, loss: 0.2238006740808487
step: 210, loss: 0.4269157648086548
step: 220, loss: 0.22617602348327637
step: 230, loss: 0.13229253888130188
step: 240, loss: 0.3813627064228058
step: 250, loss: 0.22706425189971924
step: 260, loss: 0.1627093106508255
step: 270, loss: 0.1774025857448578
step: 280, loss: 0.15354257822036743
step: 290, loss: 0.1633114069700241
step: 300, loss: 0.19827130436897278
step: 310, loss: 0.21732226014137268
step: 320, loss: 0.31830260157585144
step: 330, loss: 0.30267098546028137
step: 340, loss: 0.36439651250839233
step: 350, loss: 0.33932361006736755
step: 360, loss: 0.36934489011764526
step: 370, loss: 0.33122503757476807
step: 380, loss: 0.138343945145607
epoch 1: dev_f1=0.3657142857142857, f1=0.3224489795918367, best_f1=0.3224489795918367
step: 0, loss: 0.2849717140197754
step: 10, loss: 0.27749383449554443
step: 20, loss: 0.07385408133268356
step: 30, loss: 0.15326252579689026
step: 40, loss: 0.20426250994205475
step: 50, loss: 0.0710429698228836
step: 60, loss: 0.37912970781326294
step: 70, loss: 0.09051542729139328
step: 80, loss: 0.33383598923683167
step: 90, loss: 0.41344189643859863
step: 100, loss: 0.08061981201171875
step: 110, loss: 0.126015305519104
step: 120, loss: 0.2616044580936432
step: 130, loss: 0.20390291512012482
step: 140, loss: 0.2851148843765259
step: 150, loss: 0.24361689388751984
step: 160, loss: 0.2664533853530884
step: 170, loss: 0.12176734209060669
step: 180, loss: 0.16001839935779572
step: 190, loss: 0.09734407812356949
step: 200, loss: 0.13393938541412354
step: 210, loss: 0.1149723157286644
step: 220, loss: 0.09606669098138809
step: 230, loss: 0.03168678283691406
step: 240, loss: 0.02714521810412407
step: 250, loss: 0.06432939320802689
step: 260, loss: 0.07229945063591003
step: 270, loss: 0.23174673318862915
step: 280, loss: 0.3767176568508148
step: 290, loss: 0.13173307478427887
step: 300, loss: 0.05830962583422661
step: 310, loss: 0.18582116067409515
step: 320, loss: 0.03614016994833946
step: 330, loss: 0.06385285407304764
step: 340, loss: 0.25615036487579346
step: 350, loss: 0.21223747730255127
step: 360, loss: 0.08378807455301285
step: 370, loss: 0.1713244616985321
step: 380, loss: 0.03769160434603691
epoch 2: dev_f1=0.58719646799117, f1=0.5330296127562643, best_f1=0.5330296127562643
step: 0, loss: 0.1635415405035019
step: 10, loss: 0.08030393719673157
step: 20, loss: 0.07315385341644287
step: 30, loss: 0.39410001039505005
step: 40, loss: 0.24522370100021362
step: 50, loss: 0.04151272773742676
step: 60, loss: 0.08921533823013306
step: 70, loss: 0.0195731520652771
step: 80, loss: 0.020569738000631332
step: 90, loss: 0.10216537117958069
step: 100, loss: 0.1562556028366089
step: 110, loss: 0.15056800842285156
step: 120, loss: 0.0811557024717331
step: 130, loss: 0.3895380198955536
step: 140, loss: 0.14653505384922028
step: 150, loss: 0.4657342731952667
step: 160, loss: 0.20643112063407898
step: 170, loss: 0.15817436575889587
step: 180, loss: 0.0358816422522068
step: 190, loss: 0.18249458074569702
step: 200, loss: 0.24181978404521942
step: 210, loss: 0.013293777592480183
step: 220, loss: 0.08933443576097488
step: 230, loss: 0.16405685245990753
step: 240, loss: 0.1849856674671173
step: 250, loss: 0.022563934326171875
step: 260, loss: 0.0942811444401741
step: 270, loss: 0.2496064007282257
step: 280, loss: 0.07476599514484406
step: 290, loss: 0.11231867969036102
step: 300, loss: 0.24848704040050507
step: 310, loss: 0.031279850751161575
step: 320, loss: 0.18270665407180786
step: 330, loss: 0.27099522948265076
step: 340, loss: 0.07564942538738251
step: 350, loss: 0.15854263305664062
step: 360, loss: 0.08672032505273819
step: 370, loss: 0.14262419939041138
step: 380, loss: 0.06649558991193771
epoch 3: dev_f1=0.6149732620320856, f1=0.48450704225352115, best_f1=0.48450704225352115
step: 0, loss: 0.09528322517871857
step: 10, loss: 0.016295194625854492
step: 20, loss: 0.04180200397968292
step: 30, loss: 0.09140416979789734
step: 40, loss: 0.018784549087285995
step: 50, loss: 0.11976012587547302
step: 60, loss: 0.1418975293636322
step: 70, loss: 0.1364823579788208
step: 80, loss: 0.025822333991527557
step: 90, loss: 0.04251926392316818
step: 100, loss: 0.16102850437164307
step: 110, loss: 0.08081093430519104
step: 120, loss: 0.1906321495771408
step: 130, loss: 0.010903642512857914
step: 140, loss: 0.10299567133188248
step: 150, loss: 0.023070983588695526
step: 160, loss: 0.05485575273633003
step: 170, loss: 0.14347393810749054
step: 180, loss: 0.06324805319309235
step: 190, loss: 0.03984243422746658
step: 200, loss: 0.11906250566244125
step: 210, loss: 0.12146487832069397
step: 220, loss: 0.013597987592220306
step: 230, loss: 0.19067421555519104
step: 240, loss: 0.04507913812994957
step: 250, loss: 0.16544727981090546
step: 260, loss: 0.10691431164741516
step: 270, loss: 0.010313834063708782
step: 280, loss: 0.014275584369897842
step: 290, loss: 0.05396905541419983
step: 300, loss: 0.16461744904518127
step: 310, loss: 0.042942654341459274
step: 320, loss: 0.0390753448009491
step: 330, loss: 0.032286182045936584
step: 340, loss: 0.05193387344479561
step: 350, loss: 0.08236533403396606
step: 360, loss: 0.1504496932029724
step: 370, loss: 0.01104084961116314
step: 380, loss: 0.08097118139266968
epoch 4: dev_f1=0.6376811594202899, f1=0.596401028277635, best_f1=0.596401028277635
step: 0, loss: 0.022577108815312386
step: 10, loss: 0.04590136930346489
step: 20, loss: 0.025480331853032112
step: 30, loss: 0.008245451375842094
step: 40, loss: 0.031309377402067184
step: 50, loss: 0.011702874675393105
step: 60, loss: 0.02045758068561554
step: 70, loss: 0.00828598439693451
step: 80, loss: 0.08650766313076019
step: 90, loss: 0.14534927904605865
step: 100, loss: 0.004460267256945372
step: 110, loss: 0.1490306705236435
step: 120, loss: 0.026528039947152138
step: 130, loss: 0.01279822364449501
step: 140, loss: 0.06787307560443878
step: 150, loss: 0.02389046736061573
step: 160, loss: 0.12084019184112549
step: 170, loss: 0.06831848621368408
step: 180, loss: 0.07837028056383133
step: 190, loss: 0.06418275833129883
step: 200, loss: 0.011624696664512157
step: 210, loss: 0.004826194606721401
step: 220, loss: 0.0008079697145149112
step: 230, loss: 0.006826560478657484
step: 240, loss: 0.0106654679402709
step: 250, loss: 0.002249091863632202
step: 260, loss: 0.01166599988937378
step: 270, loss: 0.0017956487135961652
step: 280, loss: 0.05384596809744835
step: 290, loss: 0.07869237661361694
step: 300, loss: 0.047090835869312286
step: 310, loss: 0.08533541113138199
step: 320, loss: 0.020108314231038094
step: 330, loss: 0.0020345705561339855
step: 340, loss: 0.14977946877479553
step: 350, loss: 0.03566619008779526
step: 360, loss: 0.01586659625172615
step: 370, loss: 0.02674303576350212
step: 380, loss: 0.12312313914299011
epoch 5: dev_f1=0.6881188118811882, f1=0.6141732283464568, best_f1=0.6141732283464568
step: 0, loss: 0.0038543061818927526
step: 10, loss: 0.021565955132246017
step: 20, loss: 0.030477290973067284
step: 30, loss: 0.002969943918287754
step: 40, loss: 0.004620460327714682
step: 50, loss: 0.014883555471897125
step: 60, loss: 0.0038612764328718185
step: 70, loss: 0.012528140097856522
step: 80, loss: 0.13399995863437653
step: 90, loss: 0.005686708725988865
step: 100, loss: 0.0817379429936409
step: 110, loss: 0.006171582732349634
step: 120, loss: 0.004472855478525162
step: 130, loss: 0.010660089552402496
step: 140, loss: 0.06740270555019379
step: 150, loss: 0.0007051973952911794
step: 160, loss: 0.061688944697380066
step: 170, loss: 0.09553655236959457
step: 180, loss: 0.0926678478717804
step: 190, loss: 0.146491140127182
step: 200, loss: 0.007932104170322418
step: 210, loss: 0.0060117607936263084
step: 220, loss: 0.039506327360868454
step: 230, loss: 0.00723959319293499
step: 240, loss: 0.0013115438632667065
step: 250, loss: 0.0005529805202968419
step: 260, loss: 0.05278652906417847
step: 270, loss: 0.017864609137177467
step: 280, loss: 0.021744806319475174
step: 290, loss: 0.011391904205083847
step: 300, loss: 0.033672887831926346
step: 310, loss: 0.06234387308359146
step: 320, loss: 0.0025343571323901415
step: 330, loss: 0.17190906405448914
step: 340, loss: 0.012812408618628979
step: 350, loss: 0.019709518179297447
step: 360, loss: 0.004565067123621702
step: 370, loss: 0.0015766548458486795
step: 380, loss: 0.00287617277354002
epoch 6: dev_f1=0.676470588235294, f1=0.5662337662337663, best_f1=0.6141732283464568
step: 0, loss: 0.0007133266190066934
step: 10, loss: 0.006395748350769281
step: 20, loss: 0.07806992530822754
step: 30, loss: 0.002339532831683755
step: 40, loss: 0.0037940526381134987
step: 50, loss: 0.037034016102552414
step: 60, loss: 0.014642634429037571
step: 70, loss: 0.06658729910850525
step: 80, loss: 0.001451185205951333
step: 90, loss: 0.002889718860387802
step: 100, loss: 0.056594718247652054
step: 110, loss: 0.0034705069847404957
step: 120, loss: 0.015119155868887901
step: 130, loss: 0.01579553820192814
step: 140, loss: 0.014210505411028862
step: 150, loss: 0.007741675246506929
step: 160, loss: 0.0838380828499794
step: 170, loss: 0.0852239578962326
step: 180, loss: 0.011194257996976376
step: 190, loss: 0.0047956532798707485
step: 200, loss: 0.03169764578342438
step: 210, loss: 0.06271666288375854
step: 220, loss: 0.0012211567955091596
step: 230, loss: 0.11313401907682419
step: 240, loss: 0.10505407303571701
step: 250, loss: 0.0020063992124050856
step: 260, loss: 0.09994436800479889
step: 270, loss: 0.014561663381755352
step: 280, loss: 0.007636990398168564
step: 290, loss: 0.0025330432690680027
step: 300, loss: 0.0010158849181607366
step: 310, loss: 0.03004337288439274
step: 320, loss: 0.002705133054405451
step: 330, loss: 0.05269302800297737
step: 340, loss: 0.003018765477463603
step: 350, loss: 0.028037885203957558
step: 360, loss: 0.017144761979579926
step: 370, loss: 0.02945440448820591
step: 380, loss: 0.06932556629180908
epoch 7: dev_f1=0.6617647058823529, f1=0.5866666666666667, best_f1=0.6141732283464568
step: 0, loss: 0.0015518025029450655
step: 10, loss: 0.010290578939020634
step: 20, loss: 0.00546023016795516
step: 30, loss: 0.017586231231689453
step: 40, loss: 0.004847660195082426
step: 50, loss: 0.0010343550238758326
step: 60, loss: 0.04254739359021187
step: 70, loss: 0.0006756920483894646
step: 80, loss: 0.001510482863523066
step: 90, loss: 0.003208589507266879
step: 100, loss: 0.00028482128982432187
step: 110, loss: 0.0036593519616872072
step: 120, loss: 0.001746396766975522
step: 130, loss: 0.0007802862673997879
step: 140, loss: 0.009824777022004128
step: 150, loss: 0.000779242254793644
step: 160, loss: 0.0016708852490410209
step: 170, loss: 0.010118930600583553
step: 180, loss: 0.0006305357674136758
step: 190, loss: 0.05015427619218826
step: 200, loss: 0.08903727680444717
step: 210, loss: 0.017232771962881088
step: 220, loss: 0.001322588068433106
step: 230, loss: 0.0013607288710772991
step: 240, loss: 0.02967843972146511
step: 250, loss: 0.022845648229122162
step: 260, loss: 0.019750723615288734
step: 270, loss: 0.0013907201355323195
step: 280, loss: 0.0006990856491029263
step: 290, loss: 0.2525746822357178
step: 300, loss: 0.03253675624728203
step: 310, loss: 0.0036221721675246954
step: 320, loss: 0.007769813295453787
step: 330, loss: 0.006362827494740486
step: 340, loss: 0.0028108074329793453
step: 350, loss: 0.0008558016270399094
step: 360, loss: 0.007110686041414738
step: 370, loss: 0.0008950396440923214
step: 380, loss: 0.05016832798719406
epoch 8: dev_f1=0.6617283950617284, f1=0.6170212765957447, best_f1=0.6141732283464568
step: 0, loss: 0.08159270137548447
step: 10, loss: 0.0006825057789683342
step: 20, loss: 0.03143760561943054
step: 30, loss: 0.0021097224671393633
step: 40, loss: 0.007515604607760906
step: 50, loss: 0.001897860667668283
step: 60, loss: 0.0018308591097593307
step: 70, loss: 0.000208502693567425
step: 80, loss: 0.00697319908067584
step: 90, loss: 0.00031793751986697316
step: 100, loss: 0.011001582257449627
step: 110, loss: 0.0004422262136358768
step: 120, loss: 0.001675653737038374
step: 130, loss: 0.0006720818928442895
step: 140, loss: 0.011026187799870968
step: 150, loss: 0.006858518347144127
step: 160, loss: 0.0019288389012217522
step: 170, loss: 0.010795162990689278
step: 180, loss: 0.00030179377063177526
step: 190, loss: 0.00040770735358819366
step: 200, loss: 0.0004159121890552342
step: 210, loss: 0.0029450026340782642
step: 220, loss: 0.0031025114003568888
step: 230, loss: 0.0002842358371708542
step: 240, loss: 0.0013012161944061518
step: 250, loss: 0.024347463622689247
step: 260, loss: 0.021557196974754333
step: 270, loss: 0.022887280210852623
step: 280, loss: 0.01743798889219761
step: 290, loss: 0.00559404818341136
step: 300, loss: 0.013804139569401741
step: 310, loss: 0.007008264306932688
step: 320, loss: 0.00026378038455732167
step: 330, loss: 0.0006511164829134941
step: 340, loss: 0.07930281013250351
step: 350, loss: 0.0009341270197182894
step: 360, loss: 0.007648359518498182
step: 370, loss: 0.007519768550992012
step: 380, loss: 0.00015107175568118691
epoch 9: dev_f1=0.6954314720812182, f1=0.5801104972375691, best_f1=0.5801104972375691
step: 0, loss: 0.0007937182090245187
step: 10, loss: 0.0024044851306825876
step: 20, loss: 0.00010863821080420166
step: 30, loss: 0.005130940582603216
step: 40, loss: 0.03445228561758995
step: 50, loss: 0.003802651772275567
step: 60, loss: 0.00017694143753033131
step: 70, loss: 0.0037771996576339006
step: 80, loss: 0.020434165373444557
step: 90, loss: 8.937927486840636e-05
step: 100, loss: 0.005929905921220779
step: 110, loss: 0.0009437089902348816
step: 120, loss: 0.00016169535228982568
step: 130, loss: 0.0017522030975669622
step: 140, loss: 0.0007068418781273067
step: 150, loss: 0.00272146868519485
step: 160, loss: 0.013677602633833885
step: 170, loss: 0.119415283203125
step: 180, loss: 0.00027831317856907845
step: 190, loss: 0.00024390227918047458
step: 200, loss: 0.016528530046343803
step: 210, loss: 0.0008514975197613239
step: 220, loss: 0.0015159185277298093
step: 230, loss: 0.003132053418084979
step: 240, loss: 0.00020343519281595945
step: 250, loss: 0.005652757827192545
step: 260, loss: 0.000868002709466964
step: 270, loss: 0.04663495719432831
step: 280, loss: 0.0009282255196012557
step: 290, loss: 0.0007627508603036404
step: 300, loss: 0.0014455579221248627
step: 310, loss: 0.0005711151752620935
step: 320, loss: 0.002074368530884385
step: 330, loss: 0.0011554078664630651
step: 340, loss: 0.0011742954375222325
step: 350, loss: 0.0008104398148134351
step: 360, loss: 0.00020322260388638824
step: 370, loss: 0.0002532258804421872
step: 380, loss: 0.0019256793893873692
epoch 10: dev_f1=0.7002518891687657, f1=0.5927977839335179, best_f1=0.5927977839335179
step: 0, loss: 0.0025326507166028023
step: 10, loss: 0.0005356302717700601
step: 20, loss: 0.00038759567542001605
step: 30, loss: 0.014747783541679382
step: 40, loss: 0.00023714608687441796
step: 50, loss: 0.0003592938301153481
step: 60, loss: 0.0015652100555598736
step: 70, loss: 0.0003477673453744501
step: 80, loss: 0.027459295466542244
step: 90, loss: 0.00014451317838393152
step: 100, loss: 0.002007724717259407
step: 110, loss: 0.00026847439585253596
step: 120, loss: 0.0002711393462959677
step: 130, loss: 0.0004501740913838148
step: 140, loss: 0.0005276937154121697
step: 150, loss: 0.04187195748090744
step: 160, loss: 0.0012105322675779462
step: 170, loss: 0.05061446130275726
step: 180, loss: 0.032844800502061844
step: 190, loss: 0.006109454203397036
step: 200, loss: 0.0020349016413092613
step: 210, loss: 0.0007968556019477546
step: 220, loss: 0.0003530223330017179
step: 230, loss: 0.00011000957601936534
step: 240, loss: 0.0026310491375625134
step: 250, loss: 0.0034882582258433104
step: 260, loss: 0.004669387359172106
step: 270, loss: 0.019644945859909058
step: 280, loss: 0.028677308931946754
step: 290, loss: 0.0004697183321695775
step: 300, loss: 0.002008431125432253
step: 310, loss: 9.075439447769895e-05
step: 320, loss: 0.06618323922157288
step: 330, loss: 0.08191123604774475
step: 340, loss: 0.00044226713362149894
step: 350, loss: 0.01053085457533598
step: 360, loss: 0.0016812068643048406
step: 370, loss: 0.0015008950140327215
step: 380, loss: 0.012645342387259007
epoch 11: dev_f1=0.6768447837150128, f1=0.5921787709497207, best_f1=0.5927977839335179
step: 0, loss: 0.0001902867661556229
step: 10, loss: 0.004008272662758827
step: 20, loss: 0.0003542099439073354
step: 30, loss: 0.00019148293358739465
step: 40, loss: 0.09694301337003708
step: 50, loss: 0.000976336479652673
step: 60, loss: 0.001110999844968319
step: 70, loss: 0.056424830108881
step: 80, loss: 8.472003537463024e-05
step: 90, loss: 0.0019001552136614919
step: 100, loss: 0.0003065341152250767
step: 110, loss: 0.00033548797364346683
step: 120, loss: 0.00011481887486297637
step: 130, loss: 0.0004334363911766559
step: 140, loss: 0.0004039517662022263
step: 150, loss: 0.0006284827250055969
step: 160, loss: 0.0015546237118542194
step: 170, loss: 0.00035284244222566485
step: 180, loss: 0.00010426943481434137
step: 190, loss: 0.0008700739708729088
step: 200, loss: 0.0016239240067079663
step: 210, loss: 0.0007542609819211066
step: 220, loss: 9.589789988240227e-05
step: 230, loss: 0.0018215322634205222
step: 240, loss: 0.0005555489915423095
step: 250, loss: 0.0006579583860002458
step: 260, loss: 0.0005062624695710838
step: 270, loss: 0.0025939836632460356
step: 280, loss: 0.0013861062470823526
step: 290, loss: 0.20261362195014954
step: 300, loss: 8.400463411817327e-05
step: 310, loss: 0.0027322040405124426
step: 320, loss: 0.0003405163006391376
step: 330, loss: 0.0004384650383144617
step: 340, loss: 0.00663366075605154
step: 350, loss: 0.0035431492142379284
step: 360, loss: 6.579650653293356e-05
step: 370, loss: 0.01761651039123535
step: 380, loss: 0.0011349059641361237
epoch 12: dev_f1=0.6588921282798833, f1=0.5163398692810457, best_f1=0.5927977839335179
step: 0, loss: 0.0025688197929412127
step: 10, loss: 0.005260698962956667
step: 20, loss: 0.00048393005272373557
step: 30, loss: 0.024448763579130173
step: 40, loss: 0.0004642800777219236
step: 50, loss: 0.018637705594301224
step: 60, loss: 0.0004955080221407115
step: 70, loss: 0.0018880466232076287
step: 80, loss: 0.002176282461732626
step: 90, loss: 0.0005035312497057021
step: 100, loss: 0.0005784984678030014
step: 110, loss: 8.064982102951035e-05
step: 120, loss: 0.0006259764777496457
step: 130, loss: 0.004197746515274048
step: 140, loss: 0.003244927618652582
step: 150, loss: 0.004813718143850565
step: 160, loss: 0.0038003879599273205
step: 170, loss: 0.005898674950003624
step: 180, loss: 0.0007994617917574942
step: 190, loss: 0.00024291065346915275
step: 200, loss: 0.00011870949674630538
step: 210, loss: 0.000503782881423831
step: 220, loss: 0.0009613269357942045
step: 230, loss: 0.03136615827679634
step: 240, loss: 0.0003200555802322924
step: 250, loss: 0.01228506863117218
step: 260, loss: 0.0022123828530311584
step: 270, loss: 0.00027387350564822555
step: 280, loss: 6.708680302836001e-05
step: 290, loss: 0.0010682175634428859
step: 300, loss: 0.000142683697049506
step: 310, loss: 0.00252793962135911
step: 320, loss: 0.0004696524702012539
step: 330, loss: 0.001912376144900918
step: 340, loss: 0.0009559537284076214
step: 350, loss: 0.0001141136817750521
step: 360, loss: 0.0001614074717508629
step: 370, loss: 0.0025333338417112827
step: 380, loss: 0.00018358281522523612
epoch 13: dev_f1=0.7045454545454547, f1=0.5919003115264797, best_f1=0.5919003115264797
step: 0, loss: 0.00011722689669113606
step: 10, loss: 0.0001887184043880552
step: 20, loss: 0.007470657583326101
step: 30, loss: 0.00026086880825459957
step: 40, loss: 0.000554236292373389
step: 50, loss: 0.00014380653738044202
step: 60, loss: 0.00010828681843122467
step: 70, loss: 0.00013523726374842227
step: 80, loss: 0.011674940586090088
step: 90, loss: 0.00039151194505393505
step: 100, loss: 0.00012868955673184246
step: 110, loss: 0.00018073045066557825
step: 120, loss: 0.00021157317678444088
step: 130, loss: 9.300343663198873e-05
step: 140, loss: 0.000155953413923271
step: 150, loss: 0.0002450699976179749
step: 160, loss: 0.00024378791567869484
step: 170, loss: 0.002045313362032175
step: 180, loss: 0.0015545185888186097
step: 190, loss: 0.0009083890472538769
step: 200, loss: 0.00035761669278144836
step: 210, loss: 0.047185953706502914
step: 220, loss: 0.00042429540189914405
step: 230, loss: 0.016405683010816574
step: 240, loss: 0.00039184984052553773
step: 250, loss: 7.218749669846147e-05
step: 260, loss: 0.00013409066013991833
step: 270, loss: 0.0009049869258888066
step: 280, loss: 0.0014027032302692533
step: 290, loss: 0.00010352489334763959
step: 300, loss: 6.800496339565143e-05
step: 310, loss: 0.0002583542373031378
step: 320, loss: 0.0009350834880024195
step: 330, loss: 0.00012066746421623975
step: 340, loss: 0.12114904075860977
step: 350, loss: 0.0001120979868574068
step: 360, loss: 0.2710599899291992
step: 370, loss: 0.004913218319416046
step: 380, loss: 0.0009257437195628881
epoch 14: dev_f1=0.660968660968661, f1=0.5015479876160991, best_f1=0.5919003115264797
step: 0, loss: 0.04575832933187485
step: 10, loss: 0.00014500967517960817
step: 20, loss: 6.259835208766162e-05
step: 30, loss: 0.0013678902760148048
step: 40, loss: 0.0004910952993668616
step: 50, loss: 0.00024097636924125254
step: 60, loss: 0.00033136020647361875
step: 70, loss: 9.554956341162324e-05
step: 80, loss: 0.00025960951461456716
step: 90, loss: 0.0007043082732707262
step: 100, loss: 5.8419940614840016e-05
step: 110, loss: 4.875804006587714e-05
step: 120, loss: 0.0012510234955698252
step: 130, loss: 0.00023115071235224605
step: 140, loss: 0.00015837489627301693
step: 150, loss: 0.0004907480906695127
step: 160, loss: 5.217861325945705e-05
step: 170, loss: 0.00010722772276494652
step: 180, loss: 0.0019350340589880943
step: 190, loss: 0.0011050811735913157
step: 200, loss: 5.96796307945624e-05
step: 210, loss: 3.97098483517766e-05
step: 220, loss: 0.0023309323005378246
step: 230, loss: 0.006379172205924988
step: 240, loss: 0.00018728245049715042
step: 250, loss: 0.017263123765587807
step: 260, loss: 0.0002181042655138299
step: 270, loss: 0.00012677157064899802
step: 280, loss: 0.00036687677493318915
step: 290, loss: 8.315156446769834e-05
step: 300, loss: 0.0008489589090459049
step: 310, loss: 0.0001615781948203221
step: 320, loss: 0.0012551893014460802
step: 330, loss: 0.00010628286690916866
step: 340, loss: 0.04778062552213669
step: 350, loss: 4.07303414249327e-05
step: 360, loss: 9.341917029814795e-05
step: 370, loss: 0.007522687315940857
step: 380, loss: 0.00035280847805552185
epoch 15: dev_f1=0.6839378238341969, f1=0.5842696629213484, best_f1=0.5919003115264797
step: 0, loss: 0.01873183064162731
step: 10, loss: 0.0003637921472545713
step: 20, loss: 0.006280776113271713
step: 30, loss: 0.0014040851965546608
step: 40, loss: 3.7021742173237726e-05
step: 50, loss: 0.10080043971538544
step: 60, loss: 0.00028976122848689556
step: 70, loss: 0.002075719181448221
step: 80, loss: 0.0037949627730995417
step: 90, loss: 0.002012006239965558
step: 100, loss: 0.009015998803079128
step: 110, loss: 0.00022584943508263677
step: 120, loss: 0.00012247668928466737
step: 130, loss: 3.565198858268559e-05
step: 140, loss: 0.000114937596663367
step: 150, loss: 0.0001893502485472709
step: 160, loss: 0.0008166899788193405
step: 170, loss: 0.0003981020417995751
step: 180, loss: 0.0001296059781452641
step: 190, loss: 0.000397543772123754
step: 200, loss: 0.013360166922211647
step: 210, loss: 0.00013771829253528267
step: 220, loss: 0.00011689464736264199
step: 230, loss: 0.00012520939344540238
step: 240, loss: 0.0005134152015671134
step: 250, loss: 0.001208473346196115
step: 260, loss: 0.00019090875866822898
step: 270, loss: 0.0044114552438259125
step: 280, loss: 5.8494308177614585e-05
step: 290, loss: 0.00031432477408088744
step: 300, loss: 0.00037000514566898346
step: 310, loss: 0.00027805555146187544
step: 320, loss: 0.00028465711511671543
step: 330, loss: 7.240669219754636e-05
step: 340, loss: 0.001870923675596714
step: 350, loss: 0.0003578650357667357
step: 360, loss: 6.434375245589763e-05
step: 370, loss: 8.214897388825193e-05
step: 380, loss: 3.53643081325572e-05
epoch 16: dev_f1=0.6685714285714286, f1=0.5431309904153355, best_f1=0.5919003115264797
step: 0, loss: 0.0016063848743215203
step: 10, loss: 0.00017656953423283994
step: 20, loss: 7.222832209663466e-05
step: 30, loss: 0.0006520812166854739
step: 40, loss: 0.008891303092241287
step: 50, loss: 6.461689918069169e-05
step: 60, loss: 7.9426979937125e-05
step: 70, loss: 0.00010041998757515103
step: 80, loss: 0.0006451682420447469
step: 90, loss: 7.208359602373093e-05
step: 100, loss: 6.927375943632796e-05
step: 110, loss: 0.00040343505679629743
step: 120, loss: 0.00029784388607367873
step: 130, loss: 9.439216228201985e-05
step: 140, loss: 4.8624126065988094e-05
step: 150, loss: 0.0005390181904658675
step: 160, loss: 0.03189320117235184
step: 170, loss: 4.544033799902536e-05
step: 180, loss: 0.011029569432139397
step: 190, loss: 0.00043906201608479023
step: 200, loss: 6.269686127780005e-05
step: 210, loss: 1.984746995731257e-05
step: 220, loss: 5.304912701831199e-05
step: 230, loss: 0.00017900060629472136
step: 240, loss: 2.7281639631837606e-05
step: 250, loss: 4.969291694578715e-05
step: 260, loss: 5.6163640692830086e-05
step: 270, loss: 0.0002758169430308044
step: 280, loss: 0.0006016360130161047
step: 290, loss: 3.69866902474314e-05
step: 300, loss: 4.780892777489498e-05
step: 310, loss: 0.00042881633271463215
step: 320, loss: 0.0002907091111410409
step: 330, loss: 0.005507244728505611
step: 340, loss: 0.00019785825861617923
step: 350, loss: 0.00022505733068101108
step: 360, loss: 0.0001543261023471132
step: 370, loss: 0.00010510584252187982
step: 380, loss: 0.00016139876970555633
epoch 17: dev_f1=0.6900269541778975, f1=0.5545722713864307, best_f1=0.5919003115264797
step: 0, loss: 7.788459333823994e-05
step: 10, loss: 7.101940718712285e-05
step: 20, loss: 0.017937617376446724
step: 30, loss: 0.014917741529643536
step: 40, loss: 8.511859050486237e-05
step: 50, loss: 4.27604973083362e-05
step: 60, loss: 5.4372238082578406e-05
step: 70, loss: 1.7232889149454422e-05
step: 80, loss: 0.0002059482503682375
step: 90, loss: 0.00034408789360895753
step: 100, loss: 0.00010620381362969056
step: 110, loss: 5.003987098461948e-05
step: 120, loss: 0.00010349736839998513
step: 130, loss: 0.0010285673197358847
step: 140, loss: 0.0009919260628521442
step: 150, loss: 2.1948655557935126e-05
step: 160, loss: 0.0001723231398500502
step: 170, loss: 4.627543967217207e-05
step: 180, loss: 0.03390420600771904
step: 190, loss: 0.00029920306405983865
step: 200, loss: 8.785590034676716e-05
step: 210, loss: 0.0010645772563293576
step: 220, loss: 0.010817456059157848
step: 230, loss: 2.493267493264284e-05
step: 240, loss: 0.00020748437964357436
step: 250, loss: 0.0002997702395077795
step: 260, loss: 2.582613888080232e-05
step: 270, loss: 0.0002358100755373016
step: 280, loss: 3.472920798230916e-05
step: 290, loss: 3.298257433925755e-05
step: 300, loss: 7.78151661506854e-05
step: 310, loss: 7.86475939094089e-05
step: 320, loss: 4.012999124825001e-05
step: 330, loss: 0.0001153766133938916
step: 340, loss: 6.078874139348045e-05
step: 350, loss: 4.02263794967439e-05
step: 360, loss: 5.686684016836807e-05
step: 370, loss: 0.0002194986882386729
step: 380, loss: 0.00046748173190280795
epoch 18: dev_f1=0.6742209631728046, f1=0.5420560747663551, best_f1=0.5919003115264797
step: 0, loss: 0.0033001387491822243
step: 10, loss: 4.2630847019609064e-05
step: 20, loss: 0.00033088968484662473
step: 30, loss: 0.0003037229471374303
step: 40, loss: 0.00015011196956038475
step: 50, loss: 2.347206464037299e-05
step: 60, loss: 2.7204880097997375e-05
step: 70, loss: 0.041352856904268265
step: 80, loss: 0.001178555190563202
step: 90, loss: 6.253507308429107e-05
step: 100, loss: 7.50552790123038e-05
step: 110, loss: 0.0010856360895559192
step: 120, loss: 0.0005523081053979695
step: 130, loss: 7.824324711691588e-05
step: 140, loss: 3.624801684054546e-05
step: 150, loss: 0.09157942235469818
step: 160, loss: 0.0008494454086758196
step: 170, loss: 0.00017707944789435714
step: 180, loss: 5.821567901875824e-05
step: 190, loss: 3.6956073017790914e-05
step: 200, loss: 0.0002843191905412823
step: 210, loss: 0.00048655204591341317
step: 220, loss: 3.182026921422221e-05
step: 230, loss: 0.0001839168689912185
step: 240, loss: 4.90879756398499e-05
step: 250, loss: 0.0005676164873875678
step: 260, loss: 0.0002651663380675018
step: 270, loss: 3.9432630728697404e-05
step: 280, loss: 0.00016767413762863725
step: 290, loss: 7.884119258960709e-05
step: 300, loss: 7.109712169039994e-05
step: 310, loss: 8.306527161039412e-05
step: 320, loss: 0.00018834492948371917
step: 330, loss: 0.00022851834364701062
step: 340, loss: 6.332107295747846e-05
step: 350, loss: 0.0014121062122285366
step: 360, loss: 6.833349470980465e-05
step: 370, loss: 9.641137876315042e-05
step: 380, loss: 3.981601548730396e-05
epoch 19: dev_f1=0.696808510638298, f1=0.5797101449275361, best_f1=0.5919003115264797
step: 0, loss: 0.0001499778445577249
step: 10, loss: 0.0029620607383549213
step: 20, loss: 9.837470861384645e-05
step: 30, loss: 4.405096115078777e-05
step: 40, loss: 0.00020253345428500324
step: 50, loss: 3.071361788897775e-05
step: 60, loss: 2.334557029826101e-05
step: 70, loss: 6.856844265712425e-05
step: 80, loss: 7.392520637949929e-05
step: 90, loss: 0.00034376548137515783
step: 100, loss: 0.0029680225998163223
step: 110, loss: 0.0001486233959440142
step: 120, loss: 6.370976188918576e-05
step: 130, loss: 0.002484649885445833
step: 140, loss: 0.005414731800556183
step: 150, loss: 0.00018060803995467722
step: 160, loss: 0.0006972447736188769
step: 170, loss: 0.00011692490079440176
step: 180, loss: 0.0007679981063120067
step: 190, loss: 0.00011546070163603872
step: 200, loss: 8.840708323987201e-05
step: 210, loss: 5.47061390534509e-05
step: 220, loss: 0.00014980488049332052
step: 230, loss: 0.00013926936662755907
step: 240, loss: 0.00013394246343523264
step: 250, loss: 4.27742961619515e-05
step: 260, loss: 0.1281363070011139
step: 270, loss: 0.00032100698444992304
step: 280, loss: 3.398782791919075e-05
step: 290, loss: 7.97436005086638e-05
step: 300, loss: 6.329012830974534e-05
step: 310, loss: 0.00022493256255984306
step: 320, loss: 4.3244948756182566e-05
step: 330, loss: 0.00015390710905194283
step: 340, loss: 0.00021591203403659165
step: 350, loss: 0.00010267362085869536
step: 360, loss: 4.4450182031141594e-05
step: 370, loss: 4.3144416849827394e-05
step: 380, loss: 4.817002627532929e-05
epoch 20: dev_f1=0.6925207756232686, f1=0.5504587155963303, best_f1=0.5919003115264797
