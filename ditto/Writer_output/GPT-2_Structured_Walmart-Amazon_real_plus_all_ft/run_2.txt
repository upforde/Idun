cuda
Device: cuda
step: 0, loss: 0.6612460613250732
step: 10, loss: 0.3144225478172302
step: 20, loss: 0.2521718740463257
step: 30, loss: 0.295728862285614
step: 40, loss: 0.5115792155265808
step: 50, loss: 0.3321802616119385
step: 60, loss: 0.2337924838066101
step: 70, loss: 0.2297368198633194
step: 80, loss: 0.141323059797287
step: 90, loss: 0.07797282189130783
step: 100, loss: 0.30171918869018555
step: 110, loss: 0.5043497085571289
step: 120, loss: 0.10258891433477402
step: 130, loss: 0.27520108222961426
step: 140, loss: 0.2730449438095093
step: 150, loss: 0.3787688910961151
step: 160, loss: 0.30540770292282104
step: 170, loss: 0.5180666446685791
step: 180, loss: 0.2656899690628052
step: 190, loss: 0.3215194046497345
step: 200, loss: 0.22666291892528534
step: 210, loss: 0.3031197786331177
step: 220, loss: 0.14814287424087524
step: 230, loss: 0.3361142575740814
step: 240, loss: 0.17233078181743622
step: 250, loss: 0.3748749792575836
step: 260, loss: 0.08603375405073166
step: 270, loss: 0.37874922156333923
step: 280, loss: 0.3532370924949646
step: 290, loss: 0.14719413220882416
step: 300, loss: 0.20045365393161774
step: 310, loss: 0.35069262981414795
step: 320, loss: 0.12943267822265625
step: 330, loss: 0.1758800894021988
step: 340, loss: 0.1746099889278412
step: 350, loss: 0.32223406434059143
step: 360, loss: 0.024375364184379578
step: 370, loss: 0.2662193477153778
step: 380, loss: 0.10875782370567322
epoch 1: dev_f1=0.39886039886039887, f1=0.33544303797468356, best_f1=0.33544303797468356
step: 0, loss: 0.18093881011009216
step: 10, loss: 0.26690730452537537
step: 20, loss: 0.19678880274295807
step: 30, loss: 0.13477201759815216
step: 40, loss: 0.16568763554096222
step: 50, loss: 0.06210986524820328
step: 60, loss: 0.43190136551856995
step: 70, loss: 0.18345040082931519
step: 80, loss: 0.13164179027080536
step: 90, loss: 0.2620076835155487
step: 100, loss: 0.37564197182655334
step: 110, loss: 0.06911119818687439
step: 120, loss: 0.17827798426151276
step: 130, loss: 0.20851124823093414
step: 140, loss: 0.26592180132865906
step: 150, loss: 0.2092903107404709
step: 160, loss: 0.06345163285732269
step: 170, loss: 0.2070939987897873
step: 180, loss: 0.11334414780139923
step: 190, loss: 0.26760998368263245
step: 200, loss: 0.25267475843429565
step: 210, loss: 0.14713546633720398
step: 220, loss: 0.18835008144378662
step: 230, loss: 0.15092244744300842
step: 240, loss: 0.17585080862045288
step: 250, loss: 0.09901722520589828
step: 260, loss: 0.10706287622451782
step: 270, loss: 0.12139976769685745
step: 280, loss: 0.05198835954070091
step: 290, loss: 0.21731221675872803
step: 300, loss: 0.12089145928621292
step: 310, loss: 0.007739086169749498
step: 320, loss: 0.25952890515327454
step: 330, loss: 0.1352033019065857
step: 340, loss: 0.15552011132240295
step: 350, loss: 0.16886335611343384
step: 360, loss: 0.10905153304338455
step: 370, loss: 0.08167091012001038
step: 380, loss: 0.09350088238716125
epoch 2: dev_f1=0.6602870813397129, f1=0.6321243523316062, best_f1=0.6321243523316062
step: 0, loss: 0.184209406375885
step: 10, loss: 0.039790187031030655
step: 20, loss: 0.22466227412223816
step: 30, loss: 0.18847636878490448
step: 40, loss: 0.07245466858148575
step: 50, loss: 0.08385887742042542
step: 60, loss: 0.0635862872004509
step: 70, loss: 0.05044625699520111
step: 80, loss: 0.1272616982460022
step: 90, loss: 0.0631817951798439
step: 100, loss: 0.10836723446846008
step: 110, loss: 0.08339563012123108
step: 120, loss: 0.0431109182536602
step: 130, loss: 0.10761035233736038
step: 140, loss: 0.04182189330458641
step: 150, loss: 0.04165584221482277
step: 160, loss: 0.02908509410917759
step: 170, loss: 0.03988414257764816
step: 180, loss: 0.1009485200047493
step: 190, loss: 0.044958218932151794
step: 200, loss: 0.04742348566651344
step: 210, loss: 0.1647397130727768
step: 220, loss: 0.06264699995517731
step: 230, loss: 0.068079873919487
step: 240, loss: 0.0764615461230278
step: 250, loss: 0.05227837711572647
step: 260, loss: 0.04563850536942482
step: 270, loss: 0.06848276406526566
step: 280, loss: 0.175466850399971
step: 290, loss: 0.08094746619462967
step: 300, loss: 0.027040604501962662
step: 310, loss: 0.31980082392692566
step: 320, loss: 0.30970683693885803
step: 330, loss: 0.1314249485731125
step: 340, loss: 0.49449315667152405
step: 350, loss: 0.031244715675711632
step: 360, loss: 0.06996724754571915
step: 370, loss: 0.04223126173019409
step: 380, loss: 0.09608926624059677
epoch 3: dev_f1=0.7068062827225131, f1=0.639344262295082, best_f1=0.639344262295082
step: 0, loss: 0.016538266092538834
step: 10, loss: 0.022588633000850677
step: 20, loss: 0.13223254680633545
step: 30, loss: 0.052634965628385544
step: 40, loss: 0.07899200171232224
step: 50, loss: 0.050497088581323624
step: 60, loss: 0.014853638596832752
step: 70, loss: 0.006565908435732126
step: 80, loss: 0.032857462763786316
step: 90, loss: 0.05529048666357994
step: 100, loss: 0.004734660964459181
step: 110, loss: 0.02477925457060337
step: 120, loss: 0.0658876821398735
step: 130, loss: 0.06146799400448799
step: 140, loss: 0.06546735018491745
step: 150, loss: 0.05815577507019043
step: 160, loss: 0.02693835273385048
step: 170, loss: 0.16974718868732452
step: 180, loss: 0.16228334605693817
step: 190, loss: 0.0943511426448822
step: 200, loss: 0.11756430566310883
step: 210, loss: 0.043272145092487335
step: 220, loss: 0.026796899735927582
step: 230, loss: 0.06715025752782822
step: 240, loss: 0.05310594663023949
step: 250, loss: 0.03661350905895233
step: 260, loss: 0.012272799387574196
step: 270, loss: 0.053256645798683167
step: 280, loss: 0.04676948860287666
step: 290, loss: 0.040314897894859314
step: 300, loss: 0.08586717396974564
step: 310, loss: 0.02554643340408802
step: 320, loss: 0.1973060965538025
step: 330, loss: 0.062410373240709305
step: 340, loss: 0.22692851722240448
step: 350, loss: 0.15877850353717804
step: 360, loss: 0.257448673248291
step: 370, loss: 0.08410399407148361
step: 380, loss: 0.13982100784778595
epoch 4: dev_f1=0.6651162790697674, f1=0.6038647342995169, best_f1=0.639344262295082
step: 0, loss: 0.24707704782485962
step: 10, loss: 0.011936558410525322
step: 20, loss: 0.018370013684034348
step: 30, loss: 0.06310949474573135
step: 40, loss: 0.0019510783022269607
step: 50, loss: 0.041026294231414795
step: 60, loss: 0.11153536289930344
step: 70, loss: 0.021494060754776
step: 80, loss: 0.12557950615882874
step: 90, loss: 0.009350261650979519
step: 100, loss: 0.02156342938542366
step: 110, loss: 0.029644452035427094
step: 120, loss: 0.05873246118426323
step: 130, loss: 0.15147314965724945
step: 140, loss: 0.005306544713675976
step: 150, loss: 0.04076976329088211
step: 160, loss: 0.029660621657967567
step: 170, loss: 0.07216238975524902
step: 180, loss: 0.04505221173167229
step: 190, loss: 0.022775933146476746
step: 200, loss: 0.056706421077251434
step: 210, loss: 0.0017846371047198772
step: 220, loss: 0.14496982097625732
step: 230, loss: 0.004174939822405577
step: 240, loss: 0.013182519003748894
step: 250, loss: 0.0046172491274774075
step: 260, loss: 0.0736583024263382
step: 270, loss: 0.022340403869748116
step: 280, loss: 0.08126281201839447
step: 290, loss: 0.0204895231872797
step: 300, loss: 0.0034930557012557983
step: 310, loss: 0.0016165522392839193
step: 320, loss: 0.014359831809997559
step: 330, loss: 0.015885038301348686
step: 340, loss: 0.07871304452419281
step: 350, loss: 0.006476273760199547
step: 360, loss: 0.01652245968580246
step: 370, loss: 0.009113818407058716
step: 380, loss: 0.02340535819530487
epoch 5: dev_f1=0.712468193384224, f1=0.6408268733850129, best_f1=0.6408268733850129
step: 0, loss: 0.035245124250650406
step: 10, loss: 0.012063547968864441
step: 20, loss: 0.000714171037543565
step: 30, loss: 0.00510774552822113
step: 40, loss: 0.006546499207615852
step: 50, loss: 0.005635252688080072
step: 60, loss: 0.0013651741901412606
step: 70, loss: 0.00942704826593399
step: 80, loss: 0.006536918692290783
step: 90, loss: 0.018213093280792236
step: 100, loss: 0.054815102368593216
step: 110, loss: 0.017682259902358055
step: 120, loss: 0.11927330493927002
step: 130, loss: 0.06144885718822479
step: 140, loss: 0.0053991577588021755
step: 150, loss: 0.09862608462572098
step: 160, loss: 0.009762976318597794
step: 170, loss: 0.04107610881328583
step: 180, loss: 0.018072083592414856
step: 190, loss: 0.10745548456907272
step: 200, loss: 0.04489276558160782
step: 210, loss: 0.03806208446621895
step: 220, loss: 0.027063924819231033
step: 230, loss: 0.0011871210299432278
step: 240, loss: 0.15657269954681396
step: 250, loss: 0.00614136504009366
step: 260, loss: 0.004046119283884764
step: 270, loss: 0.0410580150783062
step: 280, loss: 0.15394267439842224
step: 290, loss: 0.023025354370474815
step: 300, loss: 0.01291134487837553
step: 310, loss: 0.032955560833215714
step: 320, loss: 0.04484887793660164
step: 330, loss: 0.019557775929570198
step: 340, loss: 0.013045349158346653
step: 350, loss: 0.030933812260627747
step: 360, loss: 0.11199204623699188
step: 370, loss: 0.010676492005586624
step: 380, loss: 0.01689646765589714
epoch 6: dev_f1=0.6894865525672371, f1=0.5851063829787234, best_f1=0.6408268733850129
step: 0, loss: 0.007169021293520927
step: 10, loss: 0.0035140691325068474
step: 20, loss: 0.0018109272932633758
step: 30, loss: 0.002490619895979762
step: 40, loss: 0.006828110199421644
step: 50, loss: 0.002220808994024992
step: 60, loss: 0.05243852734565735
step: 70, loss: 0.012209770269691944
step: 80, loss: 0.0019823790062218904
step: 90, loss: 0.00829049851745367
step: 100, loss: 0.0011650301748886704
step: 110, loss: 0.14677923917770386
step: 120, loss: 0.008596157655119896
step: 130, loss: 0.00021601139451377094
step: 140, loss: 0.01036260835826397
step: 150, loss: 0.0021532687824219465
step: 160, loss: 0.004217606969177723
step: 170, loss: 0.005442436784505844
step: 180, loss: 0.0840362161397934
step: 190, loss: 0.010351244360208511
step: 200, loss: 0.040046051144599915
step: 210, loss: 0.008167404681444168
step: 220, loss: 0.004197193309664726
step: 230, loss: 0.0038420853670686483
step: 240, loss: 0.005031930282711983
step: 250, loss: 0.00484057329595089
step: 260, loss: 0.0022441719193011522
step: 270, loss: 0.005222660023719072
step: 280, loss: 0.00038497609784826636
step: 290, loss: 0.03953850269317627
step: 300, loss: 0.005172176752239466
step: 310, loss: 0.0014545816229656339
step: 320, loss: 0.0002349686110392213
step: 330, loss: 0.014635352417826653
step: 340, loss: 0.010471004992723465
step: 350, loss: 0.023212626576423645
step: 360, loss: 0.000619218684732914
step: 370, loss: 0.002128874883055687
step: 380, loss: 0.00041411997517570853
epoch 7: dev_f1=0.6387434554973821, f1=0.5799457994579945, best_f1=0.6408268733850129
step: 0, loss: 0.0008806579862721264
step: 10, loss: 0.0003324112622067332
step: 20, loss: 0.0008291719714179635
step: 30, loss: 0.002440531039610505
step: 40, loss: 0.002369300462305546
step: 50, loss: 0.00012566238001454622
step: 60, loss: 0.0004845306684728712
step: 70, loss: 0.010909995064139366
step: 80, loss: 0.01606268435716629
step: 90, loss: 0.028577715158462524
step: 100, loss: 0.016500484198331833
step: 110, loss: 0.017665330320596695
step: 120, loss: 0.002346196211874485
step: 130, loss: 0.001612935564480722
step: 140, loss: 0.01292145811021328
step: 150, loss: 0.0004865255032200366
step: 160, loss: 0.002858560997992754
step: 170, loss: 0.001856992137618363
step: 180, loss: 0.0034398864954710007
step: 190, loss: 0.0025315205566585064
step: 200, loss: 0.0039702728390693665
step: 210, loss: 0.001965142786502838
step: 220, loss: 0.04552510753273964
step: 230, loss: 0.0019046717789024115
step: 240, loss: 0.0075659672729671
step: 250, loss: 0.002369496738538146
step: 260, loss: 0.0209580697119236
step: 270, loss: 0.005669734440743923
step: 280, loss: 0.001996266422793269
step: 290, loss: 0.07961053401231766
step: 300, loss: 0.025782084092497826
step: 310, loss: 0.0012355156941339374
step: 320, loss: 0.007280285470187664
step: 330, loss: 0.0004027037648484111
step: 340, loss: 0.001722872257232666
step: 350, loss: 0.0019471957348287106
step: 360, loss: 0.00936699565500021
step: 370, loss: 0.010567663237452507
step: 380, loss: 0.0010402521584182978
epoch 8: dev_f1=0.7076167076167075, f1=0.6492146596858639, best_f1=0.6408268733850129
step: 0, loss: 0.0023415815085172653
step: 10, loss: 0.0015917894197627902
step: 20, loss: 0.003921515308320522
step: 30, loss: 0.0006992518319748342
step: 40, loss: 0.0017375716706737876
step: 50, loss: 0.009927858598530293
step: 60, loss: 0.07282523810863495
step: 70, loss: 0.000248967349762097
step: 80, loss: 0.014203019440174103
step: 90, loss: 0.0006817677058279514
step: 100, loss: 0.02036122977733612
step: 110, loss: 0.02858070284128189
step: 120, loss: 0.0007522882660850883
step: 130, loss: 0.0033760557416826487
step: 140, loss: 0.0003194610762875527
step: 150, loss: 0.10476710647344589
step: 160, loss: 0.029300736263394356
step: 170, loss: 0.0019476080778986216
step: 180, loss: 0.002557954518124461
step: 190, loss: 0.00013605004642158747
step: 200, loss: 0.040575604885816574
step: 210, loss: 0.007984357886016369
step: 220, loss: 0.23158010840415955
step: 230, loss: 0.0007618945091962814
step: 240, loss: 0.03440239652991295
step: 250, loss: 0.000757868867367506
step: 260, loss: 0.001228115987032652
step: 270, loss: 0.007278972305357456
step: 280, loss: 0.029039407148957253
step: 290, loss: 0.002986346371471882
step: 300, loss: 0.0082711698487401
step: 310, loss: 0.006434242241084576
step: 320, loss: 0.0007470818236470222
step: 330, loss: 0.0010121295927092433
step: 340, loss: 0.00022638206428382546
step: 350, loss: 0.013483560644090176
step: 360, loss: 0.0008718058234080672
step: 370, loss: 0.0006843453156761825
step: 380, loss: 0.018947621807456017
epoch 9: dev_f1=0.6929133858267716, f1=0.5965909090909091, best_f1=0.6408268733850129
step: 0, loss: 0.08477777987718582
step: 10, loss: 0.0034649348817765713
step: 20, loss: 0.0034302538260817528
step: 30, loss: 0.023004278540611267
step: 40, loss: 0.0003980611509177834
step: 50, loss: 0.005393608007580042
step: 60, loss: 0.00014546012971550226
step: 70, loss: 0.000940457102842629
step: 80, loss: 0.0011794104939326644
step: 90, loss: 0.00015635311137884855
step: 100, loss: 0.023434588685631752
step: 110, loss: 0.001252144225873053
step: 120, loss: 0.005636851768940687
step: 130, loss: 0.0005230597453191876
step: 140, loss: 0.004059959668666124
step: 150, loss: 0.0009015625109896064
step: 160, loss: 0.000461700139567256
step: 170, loss: 0.0018735987832769752
step: 180, loss: 0.006884852424263954
step: 190, loss: 0.10229509323835373
step: 200, loss: 0.004399782512336969
step: 210, loss: 0.0001698445266811177
step: 220, loss: 0.004282671492546797
step: 230, loss: 0.0025323613081127405
step: 240, loss: 0.0010217688977718353
step: 250, loss: 0.006122622638940811
step: 260, loss: 0.0019856798462569714
step: 270, loss: 0.0010276822140440345
step: 280, loss: 0.034026287496089935
step: 290, loss: 0.005767843686044216
step: 300, loss: 0.00016578705981373787
step: 310, loss: 0.08985436707735062
step: 320, loss: 0.0347653403878212
step: 330, loss: 0.001487997593358159
step: 340, loss: 0.02554105408489704
step: 350, loss: 0.0002920276310760528
step: 360, loss: 0.0032523844856768847
step: 370, loss: 0.019457440823316574
step: 380, loss: 0.003973822575062513
epoch 10: dev_f1=0.695, f1=0.6136986301369862, best_f1=0.6408268733850129
step: 0, loss: 0.014531318098306656
step: 10, loss: 0.0010087443515658379
step: 20, loss: 0.00036101110163144767
step: 30, loss: 0.004095662850886583
step: 40, loss: 0.0015064910985529423
step: 50, loss: 0.00555428909137845
step: 60, loss: 0.0006933701224625111
step: 70, loss: 0.001249336521141231
step: 80, loss: 0.0017292180564254522
step: 90, loss: 0.0010590098099783063
step: 100, loss: 0.00032518894295208156
step: 110, loss: 0.004004225134849548
step: 120, loss: 0.0008274574647657573
step: 130, loss: 0.00019432252156548202
step: 140, loss: 0.0001747534261085093
step: 150, loss: 0.00035949089215137064
step: 160, loss: 0.010237002745270729
step: 170, loss: 0.0009747447911649942
step: 180, loss: 0.0005983696319162846
step: 190, loss: 0.0009208483970724046
step: 200, loss: 0.001993916928768158
step: 210, loss: 0.014606098644435406
step: 220, loss: 0.00026059619267471135
step: 230, loss: 0.09957842528820038
step: 240, loss: 0.0014547567116096616
step: 250, loss: 0.008450539782643318
step: 260, loss: 0.00030718874768354
step: 270, loss: 0.0022103821393102407
step: 280, loss: 0.008824685588479042
step: 290, loss: 0.00308997998945415
step: 300, loss: 0.001616014284081757
step: 310, loss: 0.004920921288430691
step: 320, loss: 0.012018473818898201
step: 330, loss: 0.00017711386317387223
step: 340, loss: 0.01877618581056595
step: 350, loss: 0.000275612372206524
step: 360, loss: 0.0022157246712595224
step: 370, loss: 0.03879434987902641
step: 380, loss: 0.0005300951306708157
epoch 11: dev_f1=0.7037037037037037, f1=0.6114285714285714, best_f1=0.6408268733850129
step: 0, loss: 0.0003966457734350115
step: 10, loss: 0.00278859562240541
step: 20, loss: 0.003189602866768837
step: 30, loss: 0.0036133171524852514
step: 40, loss: 0.0069335647858679295
step: 50, loss: 0.0005649073864333332
step: 60, loss: 0.0026251866947859526
step: 70, loss: 0.0021819162648171186
step: 80, loss: 0.00023461735690943897
step: 90, loss: 0.00014324887888506055
step: 100, loss: 0.0014236923307180405
step: 110, loss: 0.000374776340322569
step: 120, loss: 0.026807308197021484
step: 130, loss: 0.0008137460681609809
step: 140, loss: 0.0012663956731557846
step: 150, loss: 0.003319447161629796
step: 160, loss: 0.0010385015048086643
step: 170, loss: 0.0011850922601297498
step: 180, loss: 0.0002782897208817303
step: 190, loss: 0.002696214010939002
step: 200, loss: 0.017373111099004745
step: 210, loss: 0.0017830412834882736
step: 220, loss: 0.0024554277770221233
step: 230, loss: 0.020608767867088318
step: 240, loss: 0.00024565233616158366
step: 250, loss: 0.0013648731401190162
step: 260, loss: 0.0015506214695051312
step: 270, loss: 0.0014821839286014438
step: 280, loss: 0.00015278678620234132
step: 290, loss: 0.0007418320165015757
step: 300, loss: 0.00017555621161591262
step: 310, loss: 0.017118707299232483
step: 320, loss: 0.0002906640584114939
step: 330, loss: 0.0015450716018676758
step: 340, loss: 0.00045753218000754714
step: 350, loss: 0.0011186746414750814
step: 360, loss: 0.0006173323490656912
step: 370, loss: 0.0034533545840531588
step: 380, loss: 0.004420361015945673
epoch 12: dev_f1=0.6705539358600584, f1=0.5660377358490566, best_f1=0.6408268733850129
step: 0, loss: 9.732554462971166e-05
step: 10, loss: 0.004902157932519913
step: 20, loss: 0.0011700902832672
step: 30, loss: 7.68114477978088e-05
step: 40, loss: 0.011608364060521126
step: 50, loss: 0.00012126477668061852
step: 60, loss: 0.10877910256385803
step: 70, loss: 0.0009566121734678745
step: 80, loss: 0.0006425427854992449
step: 90, loss: 0.0004222623829264194
step: 100, loss: 8.391875599045306e-05
step: 110, loss: 0.0012030554935336113
step: 120, loss: 0.0033098498824983835
step: 130, loss: 0.0036145057529211044
step: 140, loss: 0.07705917954444885
step: 150, loss: 0.00016895736916922033
step: 160, loss: 0.00030837469967082143
step: 170, loss: 0.00013107650738675147
step: 180, loss: 0.00039766181726008654
step: 190, loss: 0.0007601582910865545
step: 200, loss: 0.0006929558585397899
step: 210, loss: 0.00023623013112228364
step: 220, loss: 0.0003243141691200435
step: 230, loss: 0.0010215658694505692
step: 240, loss: 0.005488254129886627
step: 250, loss: 0.00027687876718118787
step: 260, loss: 0.00018210793496109545
step: 270, loss: 0.004201854113489389
step: 280, loss: 0.002614669967442751
step: 290, loss: 0.001608853810466826
step: 300, loss: 0.011166485957801342
step: 310, loss: 0.00018427203758619726
step: 320, loss: 0.0021043976303189993
step: 330, loss: 0.0012458947021514177
step: 340, loss: 0.0003558180178515613
step: 350, loss: 0.0009945761412382126
step: 360, loss: 0.00015023734886199236
step: 370, loss: 0.07066120207309723
step: 380, loss: 0.07683912664651871
epoch 13: dev_f1=0.7034120734908137, f1=0.5902578796561605, best_f1=0.6408268733850129
step: 0, loss: 0.0006219250499270856
step: 10, loss: 0.0003771419869735837
step: 20, loss: 6.04599408688955e-05
step: 30, loss: 0.01771053485572338
step: 40, loss: 0.0025227819569408894
step: 50, loss: 0.0035056232009083033
step: 60, loss: 0.025103114545345306
step: 70, loss: 0.00013643145211972296
step: 80, loss: 0.001432875171303749
step: 90, loss: 0.0004668192705139518
step: 100, loss: 0.0009008884662762284
step: 110, loss: 0.004524151794612408
step: 120, loss: 0.0010786157799884677
step: 130, loss: 0.010203998535871506
step: 140, loss: 0.00029125367291271687
step: 150, loss: 8.672790136188269e-05
step: 160, loss: 0.0008826004923321307
step: 170, loss: 0.0010763532482087612
step: 180, loss: 0.000311285606585443
step: 190, loss: 0.0017358158947899938
step: 200, loss: 0.00036957571865059435
step: 210, loss: 0.001284920028410852
step: 220, loss: 0.00574651500210166
step: 230, loss: 5.5701384553685784e-05
step: 240, loss: 0.0006581337656825781
step: 250, loss: 0.0003824732266366482
step: 260, loss: 0.0004655436787288636
step: 270, loss: 0.00023818969202693552
step: 280, loss: 0.00023949290334712714
step: 290, loss: 0.00032231741352006793
step: 300, loss: 0.00010033032594947144
step: 310, loss: 0.0006668824353255332
step: 320, loss: 0.006019103340804577
step: 330, loss: 0.00019099420751444995
step: 340, loss: 8.061995322350413e-05
step: 350, loss: 0.00017071484762709588
step: 360, loss: 0.00023015002079773694
step: 370, loss: 0.020050643011927605
step: 380, loss: 6.960165774216875e-05
epoch 14: dev_f1=0.6857142857142857, f1=0.55625, best_f1=0.6408268733850129
step: 0, loss: 0.0004917887854389846
step: 10, loss: 6.227406265679747e-05
step: 20, loss: 0.0006071548559702933
step: 30, loss: 0.00028426264179870486
step: 40, loss: 0.00036457236274145544
step: 50, loss: 0.0003518108860589564
step: 60, loss: 0.0008495350484736264
step: 70, loss: 5.0064300012309104e-05
step: 80, loss: 0.0004082450468558818
step: 90, loss: 0.0005297230090945959
step: 100, loss: 0.00013875978766009212
step: 110, loss: 0.00012656892067752779
step: 120, loss: 0.00018828223983291537
step: 130, loss: 0.00022007404186297208
step: 140, loss: 7.854377327021211e-05
step: 150, loss: 0.00012037355918437243
step: 160, loss: 0.02062675543129444
step: 170, loss: 0.0016861071344465017
step: 180, loss: 0.001379545428790152
step: 190, loss: 0.012482875026762486
step: 200, loss: 8.361262734979391e-05
step: 210, loss: 8.38955893414095e-05
step: 220, loss: 8.189545042114332e-05
step: 230, loss: 0.0010384219931438565
step: 240, loss: 0.024509644135832787
step: 250, loss: 4.77597423014231e-05
step: 260, loss: 0.001577273360453546
step: 270, loss: 0.022449148818850517
step: 280, loss: 0.0002123598096659407
step: 290, loss: 5.841698293806985e-05
step: 300, loss: 0.0006128196837380528
step: 310, loss: 0.00016175674682017416
step: 320, loss: 6.791666965000331e-05
step: 330, loss: 0.0001439612387912348
step: 340, loss: 4.339991937740706e-05
step: 350, loss: 0.00015964402700774372
step: 360, loss: 0.00011717512097675353
step: 370, loss: 0.0002506381133571267
step: 380, loss: 0.0015080069424584508
epoch 15: dev_f1=0.7127659574468086, f1=0.5953757225433527, best_f1=0.5953757225433527
step: 0, loss: 0.0003012091328855604
step: 10, loss: 0.0003315499925520271
step: 20, loss: 7.041160279186442e-05
step: 30, loss: 0.01814119890332222
step: 40, loss: 0.0014091773191466928
step: 50, loss: 5.800083454232663e-05
step: 60, loss: 6.212497828528285e-05
step: 70, loss: 0.0002955721574835479
step: 80, loss: 0.0006039806175976992
step: 90, loss: 0.003168482566252351
step: 100, loss: 0.00013684593432117254
step: 110, loss: 0.0008913040510378778
step: 120, loss: 0.003808289999142289
step: 130, loss: 0.014794678427278996
step: 140, loss: 5.1760671340161934e-05
step: 150, loss: 0.00014191273658070713
step: 160, loss: 0.00025202505639754236
step: 170, loss: 0.002017686143517494
step: 180, loss: 0.0002875853097066283
step: 190, loss: 5.6103559472830966e-05
step: 200, loss: 0.001072659040801227
step: 210, loss: 0.00036243838258087635
step: 220, loss: 0.00045278907055035233
step: 230, loss: 0.0016578792128711939
step: 240, loss: 0.00022995960898697376
step: 250, loss: 0.0009176826570183039
step: 260, loss: 0.017676491290330887
step: 270, loss: 0.005644591525197029
step: 280, loss: 0.00014010642189532518
step: 290, loss: 0.00010762409510789439
step: 300, loss: 0.0029799025505781174
step: 310, loss: 0.00016648980090394616
step: 320, loss: 0.0008256052969954908
step: 330, loss: 3.6266501410864294e-05
step: 340, loss: 4.124504994251765e-05
step: 350, loss: 0.0016535862814635038
step: 360, loss: 3.6126763006905094e-05
step: 370, loss: 0.002716650255024433
step: 380, loss: 0.006423141807317734
epoch 16: dev_f1=0.6947368421052632, f1=0.6017191977077365, best_f1=0.5953757225433527
step: 0, loss: 0.04214361310005188
step: 10, loss: 0.00014748296234756708
step: 20, loss: 0.0018819896504282951
step: 30, loss: 0.001409364165738225
step: 40, loss: 0.00018643199291545898
step: 50, loss: 8.024431735975668e-05
step: 60, loss: 0.00015334431373048574
step: 70, loss: 0.00014165628817863762
step: 80, loss: 0.0006161140045151114
step: 90, loss: 0.0006138181197457016
step: 100, loss: 0.00016693139332346618
step: 110, loss: 5.508269532583654e-05
step: 120, loss: 9.453449456486851e-05
step: 130, loss: 5.761897409684025e-05
step: 140, loss: 0.021261164918541908
step: 150, loss: 7.094537431839854e-05
step: 160, loss: 0.0001585311401868239
step: 170, loss: 0.00013209457392804325
step: 180, loss: 2.5592215024516918e-05
step: 190, loss: 0.00030995564884506166
step: 200, loss: 0.00010611335164867342
step: 210, loss: 0.0002150526997866109
step: 220, loss: 0.0003143651410937309
step: 230, loss: 0.00014058519445825368
step: 240, loss: 0.00012317640357650816
step: 250, loss: 9.828364272834733e-05
step: 260, loss: 0.022649191319942474
step: 270, loss: 0.00026499570230953395
step: 280, loss: 4.772218017023988e-05
step: 290, loss: 0.0037195889744907618
step: 300, loss: 0.0005798458587378263
step: 310, loss: 0.00012909082579426467
step: 320, loss: 8.936002996051684e-05
step: 330, loss: 3.053542604902759e-05
step: 340, loss: 0.0005007323925383389
step: 350, loss: 0.0025631356984376907
step: 360, loss: 7.96373569755815e-05
step: 370, loss: 8.047092705965042e-05
step: 380, loss: 0.00010175762872677296
epoch 17: dev_f1=0.6994535519125683, f1=0.5847953216374269, best_f1=0.5953757225433527
step: 0, loss: 0.00022570855799131095
step: 10, loss: 0.0002814240287989378
step: 20, loss: 0.00017380448116455227
step: 30, loss: 0.00014865523553453386
step: 40, loss: 0.00019048681133426726
step: 50, loss: 0.010587073862552643
step: 60, loss: 0.002540045417845249
step: 70, loss: 4.797915244125761e-05
step: 80, loss: 9.341449913335964e-05
step: 90, loss: 0.0001965204137377441
step: 100, loss: 7.324298348976299e-05
step: 110, loss: 0.00036160220042802393
step: 120, loss: 0.00024732184829190373
step: 130, loss: 0.0002624631451908499
step: 140, loss: 0.00870835967361927
step: 150, loss: 0.0019448554376140237
step: 160, loss: 3.360383561812341e-05
step: 170, loss: 0.1317349523305893
step: 180, loss: 0.0007596269715577364
step: 190, loss: 0.00021498763817362487
step: 200, loss: 0.00010843146446859464
step: 210, loss: 0.0012466578045859933
step: 220, loss: 0.00015359029930550605
step: 230, loss: 0.00011223175533814356
step: 240, loss: 7.411961269099265e-05
step: 250, loss: 0.0001054091626428999
step: 260, loss: 0.0007998949149623513
step: 270, loss: 0.00074586714617908
step: 280, loss: 0.00017851915617939085
step: 290, loss: 0.0023354494478553534
step: 300, loss: 0.0009035932016558945
step: 310, loss: 0.0005419115186668932
step: 320, loss: 3.38468344125431e-05
step: 330, loss: 0.0006288240547291934
step: 340, loss: 0.00021479865245055407
step: 350, loss: 5.539169069379568e-05
step: 360, loss: 5.961910210317001e-05
step: 370, loss: 3.342952550156042e-05
step: 380, loss: 0.0002586102928034961
epoch 18: dev_f1=0.6850828729281768, f1=0.5816023738872405, best_f1=0.5953757225433527
step: 0, loss: 0.00037986593088135123
step: 10, loss: 3.264278348069638e-05
step: 20, loss: 3.877771086990833e-05
step: 30, loss: 4.4448617700254545e-05
step: 40, loss: 0.00018479737627785653
step: 50, loss: 0.00013007954112254083
step: 60, loss: 0.0014547323808073997
step: 70, loss: 8.467330189887434e-05
step: 80, loss: 0.0019316010875627398
step: 90, loss: 0.0005690089892596006
step: 100, loss: 8.882628753781319e-05
step: 110, loss: 9.526018402539194e-05
step: 120, loss: 0.0020170488860458136
step: 130, loss: 0.00014388741692528129
step: 140, loss: 0.0003772383788600564
step: 150, loss: 0.00032922314130701125
step: 160, loss: 0.01646784134209156
step: 170, loss: 6.984890933381394e-05
step: 180, loss: 4.382918632472865e-05
step: 190, loss: 5.588911153608933e-05
step: 200, loss: 0.0002850905293598771
step: 210, loss: 0.00011796745093306527
step: 220, loss: 0.003011053428053856
step: 230, loss: 6.571309495484456e-05
step: 240, loss: 0.005126157775521278
step: 250, loss: 0.00014048720186110586
step: 260, loss: 2.8888527594972402e-05
step: 270, loss: 0.00013595499331131577
step: 280, loss: 8.347468246938661e-05
step: 290, loss: 0.0001179607497761026
step: 300, loss: 0.0013264087028801441
step: 310, loss: 0.00010871155245695263
step: 320, loss: 0.00035511990427039564
step: 330, loss: 3.046794699912425e-05
step: 340, loss: 0.0008710892288945615
step: 350, loss: 7.668114267289639e-05
step: 360, loss: 2.7618421881925315e-05
step: 370, loss: 0.0263026412576437
step: 380, loss: 3.69342633348424e-05
epoch 19: dev_f1=0.6890756302521008, f1=0.5818181818181818, best_f1=0.5953757225433527
step: 0, loss: 0.005731246899813414
step: 10, loss: 5.887548832106404e-05
step: 20, loss: 0.0003344956785440445
step: 30, loss: 0.0002526879252400249
step: 40, loss: 1.8026354155153967e-05
step: 50, loss: 0.00018049233767669648
step: 60, loss: 4.013856960227713e-05
step: 70, loss: 2.232899896625895e-05
step: 80, loss: 9.398241672897711e-05
step: 90, loss: 0.0003212283772882074
step: 100, loss: 0.0007056298200041056
step: 110, loss: 0.00046615087194368243
step: 120, loss: 0.00013985222904011607
step: 130, loss: 4.4992520997766405e-05
step: 140, loss: 3.231231676181778e-05
step: 150, loss: 0.00019092412549071014
step: 160, loss: 0.0013091263826936483
step: 170, loss: 3.7306286685634404e-05
step: 180, loss: 7.745199400233105e-05
step: 190, loss: 5.840891753905453e-05
step: 200, loss: 0.00024227834364864975
step: 210, loss: 0.01676025427877903
step: 220, loss: 2.91933974949643e-05
step: 230, loss: 5.4422700486611575e-05
step: 240, loss: 0.00014126193127594888
step: 250, loss: 5.945238808635622e-05
step: 260, loss: 3.065062628593296e-05
step: 270, loss: 4.2576306441333145e-05
step: 280, loss: 0.0001863456709543243
step: 290, loss: 0.005877447780221701
step: 300, loss: 0.00017579230188857764
step: 310, loss: 0.0006546753575094044
step: 320, loss: 6.547772500198334e-05
step: 330, loss: 0.00013555921032093465
step: 340, loss: 7.424997602356598e-05
step: 350, loss: 4.9914877308765426e-05
step: 360, loss: 0.0005362820229493082
step: 370, loss: 0.000701012322679162
step: 380, loss: 0.00015260459622368217
epoch 20: dev_f1=0.6871508379888268, f1=0.5818181818181818, best_f1=0.5953757225433527
