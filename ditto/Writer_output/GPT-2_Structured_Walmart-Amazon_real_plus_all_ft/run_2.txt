cuda
Device: cuda
step: 0, loss: 0.6968576312065125
step: 10, loss: 0.3592792749404907
step: 20, loss: 0.3191712498664856
step: 30, loss: 0.2433091402053833
step: 40, loss: 0.23862427473068237
step: 50, loss: 0.44690951704978943
step: 60, loss: 0.3058054745197296
step: 70, loss: 0.39771944284439087
step: 80, loss: 0.35768991708755493
step: 90, loss: 0.21197009086608887
step: 100, loss: 0.21696339547634125
step: 110, loss: 0.5390076041221619
step: 120, loss: 0.5560635328292847
step: 130, loss: 0.19754764437675476
step: 140, loss: 0.2670610547065735
step: 150, loss: 0.43595436215400696
step: 160, loss: 0.3676433563232422
step: 170, loss: 0.3957972228527069
step: 180, loss: 0.24766835570335388
step: 190, loss: 0.26599961519241333
step: 200, loss: 0.22507408261299133
step: 210, loss: 0.09259217977523804
step: 220, loss: 0.45276764035224915
step: 230, loss: 0.16029375791549683
step: 240, loss: 0.13370008766651154
step: 250, loss: 0.24588079750537872
step: 260, loss: 0.029710903763771057
step: 270, loss: 0.4118441343307495
step: 280, loss: 0.5905176997184753
step: 290, loss: 0.29797929525375366
step: 300, loss: 0.20085586607456207
step: 310, loss: 0.12706036865711212
step: 320, loss: 0.23232729732990265
step: 330, loss: 0.10670793801546097
step: 340, loss: 0.35442087054252625
step: 350, loss: 0.4968032240867615
step: 360, loss: 0.27849671244621277
step: 370, loss: 0.38140884041786194
step: 380, loss: 0.22247305512428284
epoch 1: dev_f1=0.39901477832512317, f1=0.3041237113402061, best_f1=0.3041237113402061
step: 0, loss: 0.18784061074256897
step: 10, loss: 0.34297671914100647
step: 20, loss: 0.06964993476867676
step: 30, loss: 0.28693655133247375
step: 40, loss: 0.2511342167854309
step: 50, loss: 0.4049225151538849
step: 60, loss: 0.14914216101169586
step: 70, loss: 0.5328208208084106
step: 80, loss: 0.27984917163848877
step: 90, loss: 0.08965032547712326
step: 100, loss: 0.19831204414367676
step: 110, loss: 0.09676746279001236
step: 120, loss: 0.22205466032028198
step: 130, loss: 0.29879942536354065
step: 140, loss: 0.2859739065170288
step: 150, loss: 0.28380343317985535
step: 160, loss: 0.27672332525253296
step: 170, loss: 0.15071558952331543
step: 180, loss: 0.14334101974964142
step: 190, loss: 0.13069124519824982
step: 200, loss: 0.10362942516803741
step: 210, loss: 0.21855714917182922
step: 220, loss: 0.32709813117980957
step: 230, loss: 0.23863327503204346
step: 240, loss: 0.3374500870704651
step: 250, loss: 0.31201156973838806
step: 260, loss: 0.23319999873638153
step: 270, loss: 0.13386905193328857
step: 280, loss: 0.1702534407377243
step: 290, loss: 0.17844247817993164
step: 300, loss: 0.16272713243961334
step: 310, loss: 0.1426927149295807
step: 320, loss: 0.1948016881942749
step: 330, loss: 0.21309691667556763
step: 340, loss: 0.23892444372177124
step: 350, loss: 0.1281633973121643
step: 360, loss: 0.13661643862724304
step: 370, loss: 0.04164613038301468
step: 380, loss: 0.17608068883419037
epoch 2: dev_f1=0.6066838046272495, f1=0.4861878453038674, best_f1=0.4861878453038674
step: 0, loss: 0.14580953121185303
step: 10, loss: 0.07306677848100662
step: 20, loss: 0.1140361800789833
step: 30, loss: 0.0487687774002552
step: 40, loss: 0.09667987376451492
step: 50, loss: 0.23447471857070923
step: 60, loss: 0.08040723204612732
step: 70, loss: 0.08338429778814316
step: 80, loss: 0.1483195275068283
step: 90, loss: 0.08352011442184448
step: 100, loss: 0.08544674515724182
step: 110, loss: 0.08956454694271088
step: 120, loss: 0.24933043122291565
step: 130, loss: 0.13464251160621643
step: 140, loss: 0.086906298995018
step: 150, loss: 0.012509633786976337
step: 160, loss: 0.06976421177387238
step: 170, loss: 0.427717000246048
step: 180, loss: 0.03668102249503136
step: 190, loss: 0.10809597373008728
step: 200, loss: 0.028933534398674965
step: 210, loss: 0.3315151631832123
step: 220, loss: 0.07018376886844635
step: 230, loss: 0.1146649494767189
step: 240, loss: 0.12278380990028381
step: 250, loss: 0.2456025630235672
step: 260, loss: 0.21627898514270782
step: 270, loss: 0.11363755911588669
step: 280, loss: 0.11641331762075424
step: 290, loss: 0.04979419708251953
step: 300, loss: 0.06191859766840935
step: 310, loss: 0.020446253940463066
step: 320, loss: 0.16477617621421814
step: 330, loss: 0.2990495264530182
step: 340, loss: 0.09783007949590683
step: 350, loss: 0.11809862405061722
step: 360, loss: 0.04045841470360756
step: 370, loss: 0.27276939153671265
step: 380, loss: 0.1647818237543106
epoch 3: dev_f1=0.6479591836734695, f1=0.512, best_f1=0.512
step: 0, loss: 0.1734965592622757
step: 10, loss: 0.005874880589544773
step: 20, loss: 0.16097614169120789
step: 30, loss: 0.029409339651465416
step: 40, loss: 0.04933983460068703
step: 50, loss: 0.0331147275865078
step: 60, loss: 0.14745177328586578
step: 70, loss: 0.06804683804512024
step: 80, loss: 0.2327091097831726
step: 90, loss: 0.13418284058570862
step: 100, loss: 0.08645402640104294
step: 110, loss: 0.05612510070204735
step: 120, loss: 0.15008391439914703
step: 130, loss: 0.1924118548631668
step: 140, loss: 0.11167468130588531
step: 150, loss: 0.12719763815402985
step: 160, loss: 0.03735383227467537
step: 170, loss: 0.14062151312828064
step: 180, loss: 0.04837345331907272
step: 190, loss: 0.07039795815944672
step: 200, loss: 0.06328292936086655
step: 210, loss: 0.005120687186717987
step: 220, loss: 0.07547514140605927
step: 230, loss: 0.1567116528749466
step: 240, loss: 0.04008464515209198
step: 250, loss: 0.0382261797785759
step: 260, loss: 0.026506807655096054
step: 270, loss: 0.12379799038171768
step: 280, loss: 0.01607857458293438
step: 290, loss: 0.13600440323352814
step: 300, loss: 0.23509134352207184
step: 310, loss: 0.08603482693433762
step: 320, loss: 0.14884552359580994
step: 330, loss: 0.00984681211411953
step: 340, loss: 0.0033950908109545708
step: 350, loss: 0.12180216610431671
step: 360, loss: 0.024146793410182
step: 370, loss: 0.03052816540002823
step: 380, loss: 0.025331299751996994
epoch 4: dev_f1=0.6873508353221957, f1=0.6077922077922079, best_f1=0.6077922077922079
step: 0, loss: 0.006508485414087772
step: 10, loss: 0.033120520412921906
step: 20, loss: 0.007438747677952051
step: 30, loss: 0.034745123237371445
step: 40, loss: 0.04746825620532036
step: 50, loss: 0.0948275476694107
step: 60, loss: 0.01577106863260269
step: 70, loss: 0.0469522699713707
step: 80, loss: 0.06090887635946274
step: 90, loss: 0.0191783644258976
step: 100, loss: 0.04269180819392204
step: 110, loss: 0.014724906533956528
step: 120, loss: 0.03366556391119957
step: 130, loss: 0.035729069262742996
step: 140, loss: 0.05673425644636154
step: 150, loss: 0.09622234106063843
step: 160, loss: 0.02967536449432373
step: 170, loss: 0.006102951243519783
step: 180, loss: 0.04532407224178314
step: 190, loss: 0.06662320345640182
step: 200, loss: 0.00807866733521223
step: 210, loss: 0.025402627885341644
step: 220, loss: 0.10396027565002441
step: 230, loss: 0.0031701212283223867
step: 240, loss: 0.012035137042403221
step: 250, loss: 0.03134709596633911
step: 260, loss: 0.04956178739666939
step: 270, loss: 0.06742964684963226
step: 280, loss: 0.10058237612247467
step: 290, loss: 0.11410309374332428
step: 300, loss: 0.0031736427918076515
step: 310, loss: 0.0033409164752811193
step: 320, loss: 0.00632341718301177
step: 330, loss: 0.04297046735882759
step: 340, loss: 0.058578480035066605
step: 350, loss: 0.005711065139621496
step: 360, loss: 0.0006552762934006751
step: 370, loss: 0.05166136473417282
step: 380, loss: 0.00516384094953537
epoch 5: dev_f1=0.7241379310344828, f1=0.6479591836734695, best_f1=0.6479591836734695
step: 0, loss: 0.003957766108214855
step: 10, loss: 0.006968021858483553
step: 20, loss: 0.1527482271194458
step: 30, loss: 0.011166936717927456
step: 40, loss: 0.060121454298496246
step: 50, loss: 0.0244539063423872
step: 60, loss: 0.04337400943040848
step: 70, loss: 0.039255376905202866
step: 80, loss: 0.012070467695593834
step: 90, loss: 0.005478271283209324
step: 100, loss: 0.12656241655349731
step: 110, loss: 0.07085026055574417
step: 120, loss: 0.03791160508990288
step: 130, loss: 0.02290656790137291
step: 140, loss: 0.009198673069477081
step: 150, loss: 0.009503518231213093
step: 160, loss: 0.0005419236258603632
step: 170, loss: 0.04422978684306145
step: 180, loss: 0.00043102577910758555
step: 190, loss: 0.04008713737130165
step: 200, loss: 0.014864864759147167
step: 210, loss: 0.1343868374824524
step: 220, loss: 0.005206785164773464
step: 230, loss: 0.01781478151679039
step: 240, loss: 0.00902740377932787
step: 250, loss: 0.15335489809513092
step: 260, loss: 0.07210981845855713
step: 270, loss: 0.10704204440116882
step: 280, loss: 0.03293697163462639
step: 290, loss: 0.00782203022390604
step: 300, loss: 0.00684467563405633
step: 310, loss: 0.09169980883598328
step: 320, loss: 0.10387156903743744
step: 330, loss: 0.0038792944978922606
step: 340, loss: 0.0027894710656255484
step: 350, loss: 0.03024192713201046
step: 360, loss: 0.012564913369715214
step: 370, loss: 0.002497286070138216
step: 380, loss: 0.06541751325130463
epoch 6: dev_f1=0.7081339712918661, f1=0.6564885496183206, best_f1=0.6479591836734695
step: 0, loss: 0.004740745294839144
step: 10, loss: 0.03642779961228371
step: 20, loss: 0.009210159070789814
step: 30, loss: 0.0055011240765452385
step: 40, loss: 0.004989672917872667
step: 50, loss: 0.0015924109611660242
step: 60, loss: 0.00041009666165336967
step: 70, loss: 0.01966879516839981
step: 80, loss: 0.0007694807718507946
step: 90, loss: 0.1087159514427185
step: 100, loss: 0.012311658822000027
step: 110, loss: 0.15018367767333984
step: 120, loss: 0.006573164369910955
step: 130, loss: 0.0016213644994422793
step: 140, loss: 0.00406735111027956
step: 150, loss: 0.024221271276474
step: 160, loss: 0.10943145304918289
step: 170, loss: 0.0005530203925445676
step: 180, loss: 0.003219136968255043
step: 190, loss: 0.006844459101557732
step: 200, loss: 0.00598189327865839
step: 210, loss: 0.02577073499560356
step: 220, loss: 0.008862942457199097
step: 230, loss: 0.005297064781188965
step: 240, loss: 0.003490821458399296
step: 250, loss: 0.1369287371635437
step: 260, loss: 0.05574268847703934
step: 270, loss: 0.007200608961284161
step: 280, loss: 0.005543997976928949
step: 290, loss: 0.024847673252224922
step: 300, loss: 0.01599096693098545
step: 310, loss: 0.08583853393793106
step: 320, loss: 0.12442828714847565
step: 330, loss: 0.1492718607187271
step: 340, loss: 0.0006662994273938239
step: 350, loss: 0.009982009418308735
step: 360, loss: 0.12748536467552185
step: 370, loss: 0.001987745985388756
step: 380, loss: 0.08973446488380432
epoch 7: dev_f1=0.6923076923076923, f1=0.607242339832869, best_f1=0.6479591836734695
step: 0, loss: 0.017001396045088768
step: 10, loss: 0.012132838368415833
step: 20, loss: 0.02862210012972355
step: 30, loss: 0.001026046578772366
step: 40, loss: 0.0012121545150876045
step: 50, loss: 0.002194942208006978
step: 60, loss: 0.0034179675858467817
step: 70, loss: 0.0006945240893401206
step: 80, loss: 0.0010900055058300495
step: 90, loss: 0.03433958441019058
step: 100, loss: 0.031941793859004974
step: 110, loss: 0.001704094116576016
step: 120, loss: 0.0012444942258298397
step: 130, loss: 0.20623809099197388
step: 140, loss: 0.0008130408823490143
step: 150, loss: 0.005745961796492338
step: 160, loss: 0.01240889448672533
step: 170, loss: 0.0035061263479292393
step: 180, loss: 0.03195352479815483
step: 190, loss: 0.14423778653144836
step: 200, loss: 0.007903576828539371
step: 210, loss: 0.007333265617489815
step: 220, loss: 0.003384561976417899
step: 230, loss: 0.0034827273339033127
step: 240, loss: 0.0027738725766539574
step: 250, loss: 0.006830448750406504
step: 260, loss: 0.058741841465234756
step: 270, loss: 0.003701855195686221
step: 280, loss: 0.011087528429925442
step: 290, loss: 0.002516193315386772
step: 300, loss: 0.05020906403660774
step: 310, loss: 0.007691237609833479
step: 320, loss: 0.00945416558533907
step: 330, loss: 0.00023995830269996077
step: 340, loss: 0.00035928573925048113
step: 350, loss: 0.07137539982795715
step: 360, loss: 0.017780674621462822
step: 370, loss: 0.00044640444684773684
step: 380, loss: 0.002281086752191186
epoch 8: dev_f1=0.6923076923076923, f1=0.5964912280701754, best_f1=0.6479591836734695
step: 0, loss: 0.0006971010589040816
step: 10, loss: 0.015063025057315826
step: 20, loss: 0.0005366153200156987
step: 30, loss: 0.0016132739838212729
step: 40, loss: 0.0019272778881713748
step: 50, loss: 0.08917886018753052
step: 60, loss: 0.004364086780697107
step: 70, loss: 0.01055842638015747
step: 80, loss: 0.0009866278851404786
step: 90, loss: 0.001026799320243299
step: 100, loss: 0.025860261172056198
step: 110, loss: 0.02728528529405594
step: 120, loss: 0.0008528053294867277
step: 130, loss: 0.000653547584079206
step: 140, loss: 0.007114042527973652
step: 150, loss: 0.001736727892421186
step: 160, loss: 0.0023423493839800358
step: 170, loss: 0.007475517224520445
step: 180, loss: 0.0004896404570899904
step: 190, loss: 0.04023216664791107
step: 200, loss: 0.0005576752591878176
step: 210, loss: 0.0008968875627033412
step: 220, loss: 0.07512092590332031
step: 230, loss: 0.0038095361087471247
step: 240, loss: 0.003186456160619855
step: 250, loss: 0.04113404080271721
step: 260, loss: 0.0014174666721373796
step: 270, loss: 0.0055761137045919895
step: 280, loss: 0.0010197791270911694
step: 290, loss: 0.013375583104789257
step: 300, loss: 0.19440889358520508
step: 310, loss: 0.000998420873656869
step: 320, loss: 0.0008030013414099813
step: 330, loss: 0.0009989943355321884
step: 340, loss: 0.019203847274184227
step: 350, loss: 0.010027735494077206
step: 360, loss: 0.0012738085351884365
step: 370, loss: 0.10051986575126648
step: 380, loss: 0.002139338292181492
epoch 9: dev_f1=0.7055837563451777, f1=0.5932203389830509, best_f1=0.6479591836734695
step: 0, loss: 0.0014156176475808024
step: 10, loss: 0.0005799337523058057
step: 20, loss: 0.0013742444571107626
step: 30, loss: 0.0036284984089434147
step: 40, loss: 0.001838123076595366
step: 50, loss: 0.0002831139718182385
step: 60, loss: 0.00023976566444616765
step: 70, loss: 0.0013991014566272497
step: 80, loss: 0.000393614755012095
step: 90, loss: 0.000341029983246699
step: 100, loss: 0.0005698485183529556
step: 110, loss: 0.01670888066291809
step: 120, loss: 0.20256996154785156
step: 130, loss: 0.006228754762560129
step: 140, loss: 0.00436554616317153
step: 150, loss: 0.002199379727244377
step: 160, loss: 0.0008822878589853644
step: 170, loss: 0.002533555729314685
step: 180, loss: 0.009416253305971622
step: 190, loss: 0.0005198795115575194
step: 200, loss: 0.001126249204389751
step: 210, loss: 0.0030552069656550884
step: 220, loss: 0.0006407283362932503
step: 230, loss: 0.00032054533949121833
step: 240, loss: 0.004420271143317223
step: 250, loss: 0.00047687074402347207
step: 260, loss: 8.866313874023035e-05
step: 270, loss: 0.0014172587543725967
step: 280, loss: 0.00048787580453790724
step: 290, loss: 0.0010926866671070457
step: 300, loss: 0.05735117197036743
step: 310, loss: 0.0026903508696705103
step: 320, loss: 0.018612513318657875
step: 330, loss: 0.0015233131125569344
step: 340, loss: 0.0004053993325214833
step: 350, loss: 0.006225030403584242
step: 360, loss: 0.0019639632664620876
step: 370, loss: 0.00033848913153633475
step: 380, loss: 0.0007585505954921246
epoch 10: dev_f1=0.6830466830466831, f1=0.5693069306930693, best_f1=0.6479591836734695
step: 0, loss: 0.000643832900095731
step: 10, loss: 0.00025116530014202
step: 20, loss: 0.012508492916822433
step: 30, loss: 0.001180932275019586
step: 40, loss: 0.00021657635807059705
step: 50, loss: 0.0007414930732920766
step: 60, loss: 0.002535311272367835
step: 70, loss: 0.05529564246535301
step: 80, loss: 0.0014978572726249695
step: 90, loss: 0.0004302691377233714
step: 100, loss: 0.01280877273529768
step: 110, loss: 0.002883853856474161
step: 120, loss: 0.008207184262573719
step: 130, loss: 0.0006043690955266356
step: 140, loss: 0.00020581917488016188
step: 150, loss: 0.029259197413921356
step: 160, loss: 0.21536590158939362
step: 170, loss: 0.0012250210857018828
step: 180, loss: 0.01754853129386902
step: 190, loss: 0.0012353983474895358
step: 200, loss: 0.015874531120061874
step: 210, loss: 0.0015361558180302382
step: 220, loss: 0.0164064709097147
step: 230, loss: 0.0038338638842105865
step: 240, loss: 0.0019031250849366188
step: 250, loss: 0.00030261208303272724
step: 260, loss: 0.060830019414424896
step: 270, loss: 0.0014796758769080043
step: 280, loss: 0.03163037821650505
step: 290, loss: 0.13451799750328064
step: 300, loss: 0.10489378124475479
step: 310, loss: 0.004086097236722708
step: 320, loss: 0.003296714276075363
step: 330, loss: 0.014069689437747002
step: 340, loss: 0.001027922728098929
step: 350, loss: 0.0002528493059799075
step: 360, loss: 0.0003785535227507353
step: 370, loss: 0.0011531078489497304
step: 380, loss: 0.0012337336083874106
epoch 11: dev_f1=0.7096774193548386, f1=0.5936599423631125, best_f1=0.6479591836734695
step: 0, loss: 0.006997521035373211
step: 10, loss: 0.0010498956544324756
step: 20, loss: 0.0004313256940804422
step: 30, loss: 0.0035938031505793333
step: 40, loss: 0.00473625585436821
step: 50, loss: 0.00020586333994287997
step: 60, loss: 0.18467913568019867
step: 70, loss: 0.00028955331072211266
step: 80, loss: 0.0019232035847380757
step: 90, loss: 0.0015511448727920651
step: 100, loss: 0.0027801066171377897
step: 110, loss: 0.00363052892498672
step: 120, loss: 0.0037494555581361055
step: 130, loss: 0.004463639575988054
step: 140, loss: 0.00017515239596832544
step: 150, loss: 0.00018046380137093365
step: 160, loss: 0.010031593032181263
step: 170, loss: 0.001909156097099185
step: 180, loss: 0.003091089893132448
step: 190, loss: 0.005649155005812645
step: 200, loss: 0.0002446635626256466
step: 210, loss: 0.00020218436839058995
step: 220, loss: 0.0003832989605143666
step: 230, loss: 0.0008580900612287223
step: 240, loss: 7.989248115336522e-05
step: 250, loss: 0.00012207526015117764
step: 260, loss: 0.0001459961786167696
step: 270, loss: 0.00014136354729998857
step: 280, loss: 0.0007252036593854427
step: 290, loss: 0.00041883348603732884
step: 300, loss: 0.0003668064600788057
step: 310, loss: 0.000563253415748477
step: 320, loss: 0.011775982566177845
step: 330, loss: 0.00024143127666320652
step: 340, loss: 0.0003669997095130384
step: 350, loss: 0.0015652594156563282
step: 360, loss: 0.017276134341955185
step: 370, loss: 0.0013653336791321635
step: 380, loss: 0.0001059586284100078
epoch 12: dev_f1=0.7109004739336492, f1=0.6256157635467979, best_f1=0.6479591836734695
step: 0, loss: 0.0029480603989213705
step: 10, loss: 0.0004454260633792728
step: 20, loss: 0.0005951762432232499
step: 30, loss: 0.00036290724528953433
step: 40, loss: 0.0004614953650161624
step: 50, loss: 0.002323388820514083
step: 60, loss: 0.002300440100952983
step: 70, loss: 0.08079361170530319
step: 80, loss: 0.001126445597037673
step: 90, loss: 0.0017995607340708375
step: 100, loss: 0.0028363100718706846
step: 110, loss: 5.050474646850489e-05
step: 120, loss: 0.0001836923329392448
step: 130, loss: 0.004165026359260082
step: 140, loss: 0.0002678896998986602
step: 150, loss: 0.022310039028525352
step: 160, loss: 5.94772573094815e-05
step: 170, loss: 0.0011448932345956564
step: 180, loss: 0.00043971557170152664
step: 190, loss: 5.9788628277601674e-05
step: 200, loss: 0.012566110119223595
step: 210, loss: 0.0009534197160974145
step: 220, loss: 0.02391120418906212
step: 230, loss: 0.012910103425383568
step: 240, loss: 3.407368785701692e-05
step: 250, loss: 0.00012459984282031655
step: 260, loss: 0.000513902516104281
step: 270, loss: 0.012011315673589706
step: 280, loss: 0.000837545027025044
step: 290, loss: 0.0009230389259755611
step: 300, loss: 0.001539608114399016
step: 310, loss: 0.03137385472655296
step: 320, loss: 0.0007058779010549188
step: 330, loss: 3.281513636466116e-05
step: 340, loss: 0.00028074748115614057
step: 350, loss: 0.0006320169777609408
step: 360, loss: 0.00014234807167667896
step: 370, loss: 0.0014187071938067675
step: 380, loss: 3.058007496292703e-05
epoch 13: dev_f1=0.6847826086956522, f1=0.5604719764011798, best_f1=0.6479591836734695
step: 0, loss: 0.0007756783743388951
step: 10, loss: 0.00013540119107346982
step: 20, loss: 0.0001202670464408584
step: 30, loss: 0.00014570061466656625
step: 40, loss: 0.012483630329370499
step: 50, loss: 0.0032699480652809143
step: 60, loss: 8.412748866248876e-05
step: 70, loss: 0.0001495160540798679
step: 80, loss: 9.15635100682266e-05
step: 90, loss: 0.0005150888464413583
step: 100, loss: 0.00022415137209463865
step: 110, loss: 0.0007632343913428485
step: 120, loss: 0.00015795044600963593
step: 130, loss: 0.002038442762568593
step: 140, loss: 5.8784778957488015e-05
step: 150, loss: 0.0025969063863158226
step: 160, loss: 0.00017319980543106794
step: 170, loss: 0.053071774542331696
step: 180, loss: 0.0004907838301733136
step: 190, loss: 0.00017494363419245929
step: 200, loss: 0.0003708031144924462
step: 210, loss: 0.0015134472632780671
step: 220, loss: 7.899598131189123e-05
step: 230, loss: 0.0013533452292904258
step: 240, loss: 0.0001695854589343071
step: 250, loss: 0.00021748927247244865
step: 260, loss: 0.0028686863370239735
step: 270, loss: 0.0010899113258346915
step: 280, loss: 0.00048556068213656545
step: 290, loss: 0.00013543371460400522
step: 300, loss: 0.00012771687761414796
step: 310, loss: 0.00043843057937920094
step: 320, loss: 0.07846143841743469
step: 330, loss: 3.255058254580945e-05
step: 340, loss: 0.00016727960610296577
step: 350, loss: 0.0010571388993412256
step: 360, loss: 0.0001255297102034092
step: 370, loss: 0.008281535468995571
step: 380, loss: 0.0005329866544343531
epoch 14: dev_f1=0.7118644067796611, f1=0.5989304812834224, best_f1=0.6479591836734695
step: 0, loss: 6.28189736744389e-05
step: 10, loss: 0.00034542419598437846
step: 20, loss: 3.2267456845147535e-05
step: 30, loss: 4.474677189136855e-05
step: 40, loss: 0.011991580948233604
step: 50, loss: 0.002476988360285759
step: 60, loss: 0.0016803800826892257
step: 70, loss: 0.0005526748718693852
step: 80, loss: 0.00029895821353420615
step: 90, loss: 4.858761531068012e-05
step: 100, loss: 0.00018614785221870989
step: 110, loss: 0.0016114554600790143
step: 120, loss: 0.00012986213550902903
step: 130, loss: 0.0007380887400358915
step: 140, loss: 0.0002490119368303567
step: 150, loss: 0.11805840581655502
step: 160, loss: 0.0014309568796306849
step: 170, loss: 0.00030487123876810074
step: 180, loss: 0.0002850512391887605
step: 190, loss: 0.0007586588617414236
step: 200, loss: 0.00428780447691679
step: 210, loss: 0.00013679801486432552
step: 220, loss: 0.0019362011225894094
step: 230, loss: 0.0050474293529987335
step: 240, loss: 0.004695885814726353
step: 250, loss: 0.00901806354522705
step: 260, loss: 6.757384107913822e-05
step: 270, loss: 0.0012146697845309973
step: 280, loss: 0.039994534105062485
step: 290, loss: 0.00016467625391669571
step: 300, loss: 0.00011276316945441067
step: 310, loss: 0.11504002660512924
step: 320, loss: 0.0009443115559406579
step: 330, loss: 0.0001246677420567721
step: 340, loss: 0.0004993120674043894
step: 350, loss: 0.00011614878894761205
step: 360, loss: 0.00018558168085291982
step: 370, loss: 0.0003233238821849227
step: 380, loss: 0.00044616605737246573
epoch 15: dev_f1=0.7146529562982005, f1=0.6033519553072626, best_f1=0.6479591836734695
step: 0, loss: 0.0012642128858715296
step: 10, loss: 9.475047409068793e-05
step: 20, loss: 0.0028218275401741266
step: 30, loss: 6.0859572840854526e-05
step: 40, loss: 0.00011026363063137978
step: 50, loss: 0.0015377189265564084
step: 60, loss: 0.00045983423478901386
step: 70, loss: 5.273104034131393e-05
step: 80, loss: 5.3076404583407566e-05
step: 90, loss: 0.00022481971245724708
step: 100, loss: 0.0007587988511659205
step: 110, loss: 9.997321467380971e-05
step: 120, loss: 0.0003041552845388651
step: 130, loss: 0.00011790573626058176
step: 140, loss: 0.00033718132181093097
step: 150, loss: 0.0006725374842062593
step: 160, loss: 0.0003478130674920976
step: 170, loss: 0.01375313475728035
step: 180, loss: 0.0001798602897906676
step: 190, loss: 0.0002669471432454884
step: 200, loss: 0.00014348930562846363
step: 210, loss: 9.906993363983929e-05
step: 220, loss: 0.024785198271274567
step: 230, loss: 0.0005387939745560288
step: 240, loss: 0.009976026602089405
step: 250, loss: 0.000569923606235534
step: 260, loss: 0.0001477451151004061
step: 270, loss: 0.00029721276951022446
step: 280, loss: 0.0008551768260076642
step: 290, loss: 0.0009643469238653779
step: 300, loss: 8.93557516974397e-05
step: 310, loss: 0.00012792226334568113
step: 320, loss: 7.39057213650085e-05
step: 330, loss: 5.905979924136773e-05
step: 340, loss: 4.527157943812199e-05
step: 350, loss: 0.00033859224640764296
step: 360, loss: 0.0022123914677649736
step: 370, loss: 0.0012098458828404546
step: 380, loss: 0.00038834469160065055
epoch 16: dev_f1=0.721227621483376, f1=0.5779036827195467, best_f1=0.6479591836734695
step: 0, loss: 0.20765620470046997
step: 10, loss: 0.0004369083617348224
step: 20, loss: 0.000786177406553179
step: 30, loss: 9.308420703746378e-05
step: 40, loss: 0.00034419618896208704
step: 50, loss: 0.0018786360742524266
step: 60, loss: 0.00044780163443647325
step: 70, loss: 0.0005365870310924947
step: 80, loss: 0.00019595464982558042
step: 90, loss: 0.0020348457619547844
step: 100, loss: 0.002056475030258298
step: 110, loss: 0.00010479256161488593
step: 120, loss: 0.00010568146535661072
step: 130, loss: 0.00028675884823314846
step: 140, loss: 0.00015177964814938605
step: 150, loss: 7.473515142919496e-05
step: 160, loss: 0.0025713187642395496
step: 170, loss: 0.0006719750235788524
step: 180, loss: 0.00016204580606427044
step: 190, loss: 0.0001916887704282999
step: 200, loss: 0.007109135389328003
step: 210, loss: 0.00010598711378406733
step: 220, loss: 5.636604691972025e-05
step: 230, loss: 0.002270929981023073
step: 240, loss: 0.022863680496811867
step: 250, loss: 0.00013207456504460424
step: 260, loss: 0.0011155735701322556
step: 270, loss: 0.0003444816975388676
step: 280, loss: 0.00013423323980532587
step: 290, loss: 0.0001274727110285312
step: 300, loss: 0.00019514064479153603
step: 310, loss: 0.00014471680333372205
step: 320, loss: 0.0015416223322972655
step: 330, loss: 0.00012968244845978916
step: 340, loss: 9.56272124312818e-05
step: 350, loss: 0.0013170518213883042
step: 360, loss: 0.00010037326865131035
step: 370, loss: 0.023422641679644585
step: 380, loss: 7.429692050209269e-05
epoch 17: dev_f1=0.7310704960835509, f1=0.6189111747851003, best_f1=0.6189111747851003
step: 0, loss: 0.00010045360977528617
step: 10, loss: 0.00014834399917162955
step: 20, loss: 0.00014733218995388597
step: 30, loss: 7.97152824816294e-05
step: 40, loss: 5.577884439844638e-05
step: 50, loss: 2.18186505662743e-05
step: 60, loss: 0.00016350702208001167
step: 70, loss: 7.542433013441041e-05
step: 80, loss: 0.0005835595075041056
step: 90, loss: 0.00016308308113366365
step: 100, loss: 0.010996771976351738
step: 110, loss: 5.048033926868811e-05
step: 120, loss: 0.00010134631884284317
step: 130, loss: 0.00010593358456389979
step: 140, loss: 3.731817196239717e-05
step: 150, loss: 8.910572796594352e-05
step: 160, loss: 4.7262456064345315e-05
step: 170, loss: 4.921956133330241e-05
step: 180, loss: 0.0004180946561973542
step: 190, loss: 0.00032075741910375655
step: 200, loss: 0.00016140559455379844
step: 210, loss: 0.00010023236245615408
step: 220, loss: 0.0007176696672104299
step: 230, loss: 3.7992391298757866e-05
step: 240, loss: 0.0001500192011008039
step: 250, loss: 0.002479808870702982
step: 260, loss: 0.000400463177356869
step: 270, loss: 0.0004841027839574963
step: 280, loss: 4.248900222592056e-05
step: 290, loss: 0.00032122977427206933
step: 300, loss: 0.00019209296442568302
step: 310, loss: 0.0006832524086348712
step: 320, loss: 0.00016872392734512687
step: 330, loss: 0.0002140089200111106
step: 340, loss: 0.0005673087434843183
step: 350, loss: 0.002788772340863943
step: 360, loss: 0.0005537635879591107
step: 370, loss: 7.02864199411124e-05
step: 380, loss: 0.00044708646601065993
epoch 18: dev_f1=0.7208672086720868, f1=0.5917159763313609, best_f1=0.6189111747851003
step: 0, loss: 8.397767669521272e-05
step: 10, loss: 0.021482445299625397
step: 20, loss: 0.00012162138591520488
step: 30, loss: 6.857257540104911e-05
step: 40, loss: 8.115579839795828e-05
step: 50, loss: 0.00011019196244888008
step: 60, loss: 0.000166064448421821
step: 70, loss: 0.0019251819467172027
step: 80, loss: 0.00012378305837046355
step: 90, loss: 6.618712359340861e-05
step: 100, loss: 0.00019184726988896728
step: 110, loss: 0.006762268021702766
step: 120, loss: 0.0006312254117801785
step: 130, loss: 5.52596065972466e-05
step: 140, loss: 6.277076317928731e-05
step: 150, loss: 0.0008278906461782753
step: 160, loss: 0.00016132788732647896
step: 170, loss: 5.38917702215258e-05
step: 180, loss: 0.0020663721952587366
step: 190, loss: 0.0001603979035280645
step: 200, loss: 0.0012302957475185394
step: 210, loss: 4.9688151193549857e-05
step: 220, loss: 0.00031623983522877097
step: 230, loss: 5.752192373620346e-05
step: 240, loss: 5.442362089524977e-05
step: 250, loss: 4.996367351850495e-05
step: 260, loss: 4.088641071575694e-05
step: 270, loss: 9.95762093225494e-05
step: 280, loss: 5.399807923822664e-05
step: 290, loss: 9.547579975333065e-05
step: 300, loss: 0.00013799643784295768
step: 310, loss: 0.0003022588789463043
step: 320, loss: 6.0112823121016845e-05
step: 330, loss: 6.851760554127395e-05
step: 340, loss: 5.9884383517783135e-05
step: 350, loss: 4.4611548219108954e-05
step: 360, loss: 5.8210789575241506e-05
step: 370, loss: 0.0007135958876460791
step: 380, loss: 0.00011787876428570598
epoch 19: dev_f1=0.7131367292225201, f1=0.5857988165680474, best_f1=0.6189111747851003
step: 0, loss: 4.3972911953460425e-05
step: 10, loss: 3.52321112586651e-05
step: 20, loss: 0.0009052273235283792
step: 30, loss: 4.586636714520864e-05
step: 40, loss: 6.966108048800379e-05
step: 50, loss: 0.0002582860761322081
step: 60, loss: 0.003089702455326915
step: 70, loss: 2.7145450076204725e-05
step: 80, loss: 8.71602533152327e-05
step: 90, loss: 9.742614201968536e-05
step: 100, loss: 0.00041320070158690214
step: 110, loss: 6.896773993503302e-05
step: 120, loss: 4.768040162161924e-05
step: 130, loss: 0.00010005861258832738
step: 140, loss: 0.029122132807970047
step: 150, loss: 0.0004649137263186276
step: 160, loss: 5.82958928134758e-05
step: 170, loss: 5.208688526181504e-05
step: 180, loss: 4.3091265979455784e-05
step: 190, loss: 0.0001219094920088537
step: 200, loss: 9.449935896554962e-05
step: 210, loss: 5.4067008022684604e-05
step: 220, loss: 0.00022976034961175174
step: 230, loss: 6.65653424221091e-05
step: 240, loss: 0.001261666533537209
step: 250, loss: 0.00018688563432078809
step: 260, loss: 0.028967907652258873
step: 270, loss: 0.00010736145486589521
step: 280, loss: 0.004886198788881302
step: 290, loss: 0.0001267168263439089
step: 300, loss: 0.0010000854963436723
step: 310, loss: 8.154811075655743e-05
step: 320, loss: 7.198888488346711e-05
step: 330, loss: 0.00020547397434711456
step: 340, loss: 4.0257924410980195e-05
step: 350, loss: 0.00260440306738019
step: 360, loss: 5.1856288337148726e-05
step: 370, loss: 0.00015374603390228003
step: 380, loss: 0.00025191163877025247
epoch 20: dev_f1=0.7142857142857143, f1=0.5971014492753624, best_f1=0.6189111747851003
