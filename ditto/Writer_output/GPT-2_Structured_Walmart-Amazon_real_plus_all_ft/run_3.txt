cuda
Device: cuda
step: 0, loss: 0.9761372804641724
step: 10, loss: 0.3983614444732666
step: 20, loss: 0.33216845989227295
step: 30, loss: 0.4495396614074707
step: 40, loss: 0.32272160053253174
step: 50, loss: 0.3082845211029053
step: 60, loss: 0.3143666684627533
step: 70, loss: 0.2375718057155609
step: 80, loss: 0.23362046480178833
step: 90, loss: 0.42624548077583313
step: 100, loss: 0.18311791121959686
step: 110, loss: 0.6032679677009583
step: 120, loss: 0.45677438378334045
step: 130, loss: 0.3164272606372833
step: 140, loss: 0.362033486366272
step: 150, loss: 0.2144586145877838
step: 160, loss: 0.2335001528263092
step: 170, loss: 0.38423600792884827
step: 180, loss: 0.39932218194007874
step: 190, loss: 0.21313615143299103
step: 200, loss: 0.2120240181684494
step: 210, loss: 0.21376654505729675
step: 220, loss: 0.15145380795001984
step: 230, loss: 0.3861452639102936
step: 240, loss: 0.21493259072303772
step: 250, loss: 0.20141856372356415
step: 260, loss: 0.41502562165260315
step: 270, loss: 0.2647584080696106
step: 280, loss: 0.28789541125297546
step: 290, loss: 0.26648610830307007
step: 300, loss: 0.2358793020248413
step: 310, loss: 0.3295120596885681
step: 320, loss: 0.29781827330589294
step: 330, loss: 0.2056436538696289
step: 340, loss: 0.24890124797821045
step: 350, loss: 0.15935461223125458
step: 360, loss: 0.2073044627904892
step: 370, loss: 0.18777908384799957
step: 380, loss: 0.4555000364780426
epoch 1: dev_f1=0.37749546279491836, f1=0.29795158286778395, best_f1=0.29795158286778395
step: 0, loss: 0.3483594059944153
step: 10, loss: 0.17496249079704285
step: 20, loss: 0.26630911231040955
step: 30, loss: 0.07181543856859207
step: 40, loss: 0.1811835914850235
step: 50, loss: 0.12362324446439743
step: 60, loss: 0.1222623735666275
step: 70, loss: 0.36725103855133057
step: 80, loss: 0.13856978714466095
step: 90, loss: 0.14447222650051117
step: 100, loss: 0.19010183215141296
step: 110, loss: 0.16728736460208893
step: 120, loss: 0.11971845477819443
step: 130, loss: 0.2002761960029602
step: 140, loss: 0.09405070543289185
step: 150, loss: 0.2667778432369232
step: 160, loss: 0.22705122828483582
step: 170, loss: 0.27626344561576843
step: 180, loss: 0.12017229944467545
step: 190, loss: 0.29448315501213074
step: 200, loss: 0.2008267492055893
step: 210, loss: 0.09439116716384888
step: 220, loss: 0.2003452181816101
step: 230, loss: 0.14772216975688934
step: 240, loss: 0.09227731078863144
step: 250, loss: 0.04367830604314804
step: 260, loss: 0.16988196969032288
step: 270, loss: 0.055118054151535034
step: 280, loss: 0.10895810276269913
step: 290, loss: 0.09327894449234009
step: 300, loss: 0.26262107491493225
step: 310, loss: 0.12966953217983246
step: 320, loss: 0.028236588463187218
step: 330, loss: 0.12942184507846832
step: 340, loss: 0.35037365555763245
step: 350, loss: 0.24563947319984436
step: 360, loss: 0.19871656596660614
step: 370, loss: 0.17410454154014587
step: 380, loss: 0.06663092970848083
epoch 2: dev_f1=0.5164556962025316, f1=0.3733333333333333, best_f1=0.3733333333333333
step: 0, loss: 0.1738971620798111
step: 10, loss: 0.11512848734855652
step: 20, loss: 0.1459018588066101
step: 30, loss: 0.17381025850772858
step: 40, loss: 0.1813027262687683
step: 50, loss: 0.10361810028553009
step: 60, loss: 0.06380636245012283
step: 70, loss: 0.1500083953142166
step: 80, loss: 0.12137912958860397
step: 90, loss: 0.04167521372437477
step: 100, loss: 0.20730550587177277
step: 110, loss: 0.29696813225746155
step: 120, loss: 0.10668706893920898
step: 130, loss: 0.11929333209991455
step: 140, loss: 0.18996992707252502
step: 150, loss: 0.016089076176285744
step: 160, loss: 0.015440328046679497
step: 170, loss: 0.1552383303642273
step: 180, loss: 0.06700449436903
step: 190, loss: 0.13146543502807617
step: 200, loss: 0.04007332772016525
step: 210, loss: 0.049361154437065125
step: 220, loss: 0.1944885104894638
step: 230, loss: 0.1624555140733719
step: 240, loss: 0.08851408958435059
step: 250, loss: 0.2230370044708252
step: 260, loss: 0.30215904116630554
step: 270, loss: 0.1560395509004593
step: 280, loss: 0.36751919984817505
step: 290, loss: 0.34456905722618103
step: 300, loss: 0.11345012485980988
step: 310, loss: 0.009018420241773129
step: 320, loss: 0.31097501516342163
step: 330, loss: 0.2130340337753296
step: 340, loss: 0.13104374706745148
step: 350, loss: 0.19739298522472382
step: 360, loss: 0.12516644597053528
step: 370, loss: 0.07570263743400574
step: 380, loss: 0.4135358929634094
epoch 3: dev_f1=0.5754716981132075, f1=0.4153846153846154, best_f1=0.4153846153846154
step: 0, loss: 0.15842175483703613
step: 10, loss: 0.07320471107959747
step: 20, loss: 0.06471626460552216
step: 30, loss: 0.02878357283771038
step: 40, loss: 0.035543717443943024
step: 50, loss: 0.23598317801952362
step: 60, loss: 0.20875287055969238
step: 70, loss: 0.2560768127441406
step: 80, loss: 0.07249890267848969
step: 90, loss: 0.08356232941150665
step: 100, loss: 0.09957168996334076
step: 110, loss: 0.010492508299648762
step: 120, loss: 0.18899691104888916
step: 130, loss: 0.02330758422613144
step: 140, loss: 0.007914027199149132
step: 150, loss: 0.03130704164505005
step: 160, loss: 0.06605740636587143
step: 170, loss: 0.10033606737852097
step: 180, loss: 0.055156007409095764
step: 190, loss: 0.03643809258937836
step: 200, loss: 0.05152088776230812
step: 210, loss: 0.09371287375688553
step: 220, loss: 0.06219244748353958
step: 230, loss: 0.04724384471774101
step: 240, loss: 0.023103484883904457
step: 250, loss: 0.06309287250041962
step: 260, loss: 0.05135038122534752
step: 270, loss: 0.11890511959791183
step: 280, loss: 0.0860540047287941
step: 290, loss: 0.1316380500793457
step: 300, loss: 0.06805560737848282
step: 310, loss: 0.1939290314912796
step: 320, loss: 0.18481609225273132
step: 330, loss: 0.021703898906707764
step: 340, loss: 0.008099985308945179
step: 350, loss: 0.014581261202692986
step: 360, loss: 0.09435050189495087
step: 370, loss: 0.1769920289516449
step: 380, loss: 0.1816716343164444
epoch 4: dev_f1=0.5829145728643216, f1=0.4956268221574344, best_f1=0.4956268221574344
step: 0, loss: 0.05246657878160477
step: 10, loss: 0.0270497128367424
step: 20, loss: 0.01189988013356924
step: 30, loss: 0.020650062710046768
step: 40, loss: 0.003736375365406275
step: 50, loss: 0.12031380832195282
step: 60, loss: 0.01980811171233654
step: 70, loss: 0.08202732354402542
step: 80, loss: 0.023710070177912712
step: 90, loss: 0.046500496566295624
step: 100, loss: 0.03449496999382973
step: 110, loss: 0.10395941883325577
step: 120, loss: 0.0070473868399858475
step: 130, loss: 0.10570211708545685
step: 140, loss: 0.03162139281630516
step: 150, loss: 0.31064000725746155
step: 160, loss: 0.016059208661317825
step: 170, loss: 0.023212362080812454
step: 180, loss: 0.07915469259023666
step: 190, loss: 0.010100177489221096
step: 200, loss: 0.18245147168636322
step: 210, loss: 0.10871829092502594
step: 220, loss: 0.09220115095376968
step: 230, loss: 0.006792887579649687
step: 240, loss: 0.024605803191661835
step: 250, loss: 0.020350610837340355
step: 260, loss: 0.13432937860488892
step: 270, loss: 0.02571042999625206
step: 280, loss: 0.08116767555475235
step: 290, loss: 0.08907297998666763
step: 300, loss: 0.03854866698384285
step: 310, loss: 0.06796898692846298
step: 320, loss: 0.09680281579494476
step: 330, loss: 0.07532688975334167
step: 340, loss: 0.020553523674607277
step: 350, loss: 0.15697365999221802
step: 360, loss: 0.04431651160120964
step: 370, loss: 0.15132537484169006
step: 380, loss: 0.05611128732562065
epoch 5: dev_f1=0.6284403669724771, f1=0.553921568627451, best_f1=0.553921568627451
step: 0, loss: 0.023180702701210976
step: 10, loss: 0.029132679104804993
step: 20, loss: 0.16694492101669312
step: 30, loss: 0.01040996890515089
step: 40, loss: 0.011617944575846195
step: 50, loss: 0.01919766515493393
step: 60, loss: 0.009368497878313065
step: 70, loss: 0.007598376367241144
step: 80, loss: 0.0024068395141512156
step: 90, loss: 0.009655516594648361
step: 100, loss: 0.0018505185144022107
step: 110, loss: 0.08922339975833893
step: 120, loss: 0.010776638984680176
step: 130, loss: 0.011711426079273224
step: 140, loss: 0.006015573162585497
step: 150, loss: 0.03811485320329666
step: 160, loss: 0.0036275985185056925
step: 170, loss: 0.0014471268514171243
step: 180, loss: 0.004513989202678204
step: 190, loss: 0.013674594461917877
step: 200, loss: 0.01042057666927576
step: 210, loss: 0.11413309723138809
step: 220, loss: 0.04523914307355881
step: 230, loss: 0.04338434338569641
step: 240, loss: 0.0022185281850397587
step: 250, loss: 0.005409235134720802
step: 260, loss: 0.12497840076684952
step: 270, loss: 0.023540114983916283
step: 280, loss: 0.0006874253158457577
step: 290, loss: 0.022050710394978523
step: 300, loss: 0.08569514751434326
step: 310, loss: 0.004770998377352953
step: 320, loss: 0.007730552926659584
step: 330, loss: 0.06593020260334015
step: 340, loss: 0.003716673469170928
step: 350, loss: 0.05192309990525246
step: 360, loss: 0.002211070153862238
step: 370, loss: 0.015032529830932617
step: 380, loss: 0.05498840659856796
epoch 6: dev_f1=0.6, f1=0.545, best_f1=0.553921568627451
step: 0, loss: 0.1724751889705658
step: 10, loss: 0.029857801273465157
step: 20, loss: 0.008283238857984543
step: 30, loss: 0.09972315281629562
step: 40, loss: 0.00041670433711260557
step: 50, loss: 0.011021414771676064
step: 60, loss: 0.022823516279459
step: 70, loss: 0.0009410117054358125
step: 80, loss: 0.0074980780482292175
step: 90, loss: 0.017437655478715897
step: 100, loss: 0.006415159907191992
step: 110, loss: 0.004716159775853157
step: 120, loss: 0.00279230042360723
step: 130, loss: 0.005382477305829525
step: 140, loss: 0.0042936536483466625
step: 150, loss: 0.0025070991832762957
step: 160, loss: 0.025229191407561302
step: 170, loss: 0.0032322369515895844
step: 180, loss: 0.002848760224878788
step: 190, loss: 0.0020205264445394278
step: 200, loss: 0.11791335791349411
step: 210, loss: 0.08896539360284805
step: 220, loss: 0.0010313151869922876
step: 230, loss: 0.08679456263780594
step: 240, loss: 0.000988837331533432
step: 250, loss: 0.028821924701333046
step: 260, loss: 0.0015179964248090982
step: 270, loss: 0.01164466142654419
step: 280, loss: 0.05737513303756714
step: 290, loss: 0.006358435843139887
step: 300, loss: 0.05138988420367241
step: 310, loss: 0.050436411052942276
step: 320, loss: 0.006241518072783947
step: 330, loss: 0.15861369669437408
step: 340, loss: 0.008110208436846733
step: 350, loss: 0.0026038577780127525
step: 360, loss: 0.020445985719561577
step: 370, loss: 0.007886854000389576
step: 380, loss: 0.0012809112668037415
epoch 7: dev_f1=0.6391752577319586, f1=0.5413105413105412, best_f1=0.5413105413105412
step: 0, loss: 0.03081909939646721
step: 10, loss: 0.0038559401873499155
step: 20, loss: 0.014683015644550323
step: 30, loss: 0.008530577644705772
step: 40, loss: 0.08693844079971313
step: 50, loss: 0.0008945826557464898
step: 60, loss: 0.008274865336716175
step: 70, loss: 0.0006134154391475022
step: 80, loss: 0.00031386417686007917
step: 90, loss: 0.03374992683529854
step: 100, loss: 0.017369022592902184
step: 110, loss: 0.00041466866969130933
step: 120, loss: 0.0028191450983285904
step: 130, loss: 0.08814442902803421
step: 140, loss: 0.0019944855011999607
step: 150, loss: 0.004914050456136465
step: 160, loss: 0.0005480915424413979
step: 170, loss: 0.11334468424320221
step: 180, loss: 0.04526083916425705
step: 190, loss: 0.022309843450784683
step: 200, loss: 0.10139451175928116
step: 210, loss: 0.01087181270122528
step: 220, loss: 0.011575182899832726
step: 230, loss: 0.028203818947076797
step: 240, loss: 0.003424685215577483
step: 250, loss: 0.004958311095833778
step: 260, loss: 0.0013950926950201392
step: 270, loss: 0.03229173272848129
step: 280, loss: 0.013533405028283596
step: 290, loss: 0.0034775310195982456
step: 300, loss: 0.001703576068393886
step: 310, loss: 0.019267892464995384
step: 320, loss: 0.0023544649593532085
step: 330, loss: 0.04288862273097038
step: 340, loss: 0.0005377869820222259
step: 350, loss: 0.004454700741916895
step: 360, loss: 0.00032704323530197144
step: 370, loss: 0.016309330239892006
step: 380, loss: 0.020430702716112137
epoch 8: dev_f1=0.6523809523809525, f1=0.5820105820105821, best_f1=0.5820105820105821
step: 0, loss: 0.00807045865803957
step: 10, loss: 0.004187518730759621
step: 20, loss: 0.0004952187300659716
step: 30, loss: 0.005306197330355644
step: 40, loss: 0.016862550750374794
step: 50, loss: 0.008132170885801315
step: 60, loss: 0.0003677234926726669
step: 70, loss: 0.00024619276518933475
step: 80, loss: 0.008415712974965572
step: 90, loss: 0.19639085233211517
step: 100, loss: 0.001973458332940936
step: 110, loss: 0.014970480464398861
step: 120, loss: 0.009846221655607224
step: 130, loss: 0.005245201755315065
step: 140, loss: 0.02442070282995701
step: 150, loss: 0.0031058022286742926
step: 160, loss: 0.00013809275696985424
step: 170, loss: 0.0007345949416048825
step: 180, loss: 0.005965037737041712
step: 190, loss: 0.12898299098014832
step: 200, loss: 0.0020817809272557497
step: 210, loss: 0.002930646762251854
step: 220, loss: 0.04623682051897049
step: 230, loss: 0.0023566470481455326
step: 240, loss: 0.0010060407221317291
step: 250, loss: 0.015054583549499512
step: 260, loss: 0.002284523332491517
step: 270, loss: 0.0006221875664778054
step: 280, loss: 0.000505875563248992
step: 290, loss: 0.04835307598114014
step: 300, loss: 0.02647862397134304
step: 310, loss: 0.004593681078404188
step: 320, loss: 0.08681081980466843
step: 330, loss: 0.0016947842668741941
step: 340, loss: 0.04810318350791931
step: 350, loss: 0.01577451452612877
step: 360, loss: 0.015472803264856339
step: 370, loss: 0.00527198426425457
step: 380, loss: 0.01900053769350052
epoch 9: dev_f1=0.612565445026178, f1=0.5086705202312138, best_f1=0.5820105820105821
step: 0, loss: 0.0267056692391634
step: 10, loss: 0.0016627743607386947
step: 20, loss: 0.0007804432534612715
step: 30, loss: 0.0033161977771669626
step: 40, loss: 0.010158387012779713
step: 50, loss: 0.016107235103845596
step: 60, loss: 0.004410475492477417
step: 70, loss: 0.002381446771323681
step: 80, loss: 0.0024542100727558136
step: 90, loss: 0.004518154077231884
step: 100, loss: 0.0006185608799569309
step: 110, loss: 0.051838453859090805
step: 120, loss: 0.002328893868252635
step: 130, loss: 0.0035886249970644712
step: 140, loss: 0.07170706987380981
step: 150, loss: 0.06458273530006409
step: 160, loss: 0.005939008202403784
step: 170, loss: 0.00035651333746500313
step: 180, loss: 0.0016174436314031482
step: 190, loss: 0.0005432926118373871
step: 200, loss: 0.1316932886838913
step: 210, loss: 0.0029982691630721092
step: 220, loss: 0.005619170144200325
step: 230, loss: 0.0003860834112856537
step: 240, loss: 0.0012111200485378504
step: 250, loss: 0.04846671223640442
step: 260, loss: 0.0644940733909607
step: 270, loss: 0.006396030075848103
step: 280, loss: 0.005460900254547596
step: 290, loss: 0.0022593585308641195
step: 300, loss: 0.0035563535057008266
step: 310, loss: 0.0013748215278610587
step: 320, loss: 0.0019846325740218163
step: 330, loss: 0.0001294422399951145
step: 340, loss: 0.003708480391651392
step: 350, loss: 0.0012803080026060343
step: 360, loss: 0.1351073682308197
step: 370, loss: 0.0011582811130210757
step: 380, loss: 0.0014798901975154877
epoch 10: dev_f1=0.6323185011709601, f1=0.5408163265306122, best_f1=0.5820105820105821
step: 0, loss: 0.012666186317801476
step: 10, loss: 0.0008089212933555245
step: 20, loss: 0.0015917039709165692
step: 30, loss: 0.00096230796771124
step: 40, loss: 0.0002507908211555332
step: 50, loss: 0.00130549818277359
step: 60, loss: 0.006212383043020964
step: 70, loss: 0.1275416761636734
step: 80, loss: 0.03576958179473877
step: 90, loss: 0.0013241979759186506
step: 100, loss: 0.0013255566591396928
step: 110, loss: 0.00018150301184505224
step: 120, loss: 0.000177237787283957
step: 130, loss: 0.0007009247783571482
step: 140, loss: 0.00021153484703972936
step: 150, loss: 0.0014104052679613233
step: 160, loss: 0.0006606329116038978
step: 170, loss: 0.10251278430223465
step: 180, loss: 0.0005498672253452241
step: 190, loss: 0.0004550133307930082
step: 200, loss: 0.0010132113238796592
step: 210, loss: 0.0012112592812627554
step: 220, loss: 0.0006876161205582321
step: 230, loss: 0.0007434344151988626
step: 240, loss: 0.004027171991765499
step: 250, loss: 0.0007116078631952405
step: 260, loss: 0.009051314555108547
step: 270, loss: 0.0025923526845872402
step: 280, loss: 0.030580660328269005
step: 290, loss: 0.002521704649552703
step: 300, loss: 0.0008171431836672127
step: 310, loss: 0.0011241273023188114
step: 320, loss: 0.004599626641720533
step: 330, loss: 0.0007142727263271809
step: 340, loss: 0.0011026738211512566
step: 350, loss: 0.002964313142001629
step: 360, loss: 0.00044899084605276585
step: 370, loss: 0.0008167579071596265
step: 380, loss: 0.016806256026029587
epoch 11: dev_f1=0.616822429906542, f1=0.5824742268041238, best_f1=0.5820105820105821
step: 0, loss: 0.0025813535321503878
step: 10, loss: 0.0006088794907554984
step: 20, loss: 0.00030207354575395584
step: 30, loss: 0.005265228915959597
step: 40, loss: 0.0008929363102652133
step: 50, loss: 0.002420579083263874
step: 60, loss: 0.00033662060741335154
step: 70, loss: 0.0005825134576298296
step: 80, loss: 0.0006461274460889399
step: 90, loss: 0.0004379551683086902
step: 100, loss: 0.002004349837079644
step: 110, loss: 0.0003555639705155045
step: 120, loss: 0.00042484584264457226
step: 130, loss: 0.009293676353991032
step: 140, loss: 0.0005172240198589861
step: 150, loss: 0.020784132182598114
step: 160, loss: 0.000823733804281801
step: 170, loss: 0.0001768802758306265
step: 180, loss: 0.0002841806272044778
step: 190, loss: 0.0016666387673467398
step: 200, loss: 0.00037168097333051264
step: 210, loss: 0.0013664313592016697
step: 220, loss: 0.00012651436554733664
step: 230, loss: 0.02057049237191677
step: 240, loss: 0.0012713875621557236
step: 250, loss: 0.00010240838309982792
step: 260, loss: 0.021910682320594788
step: 270, loss: 0.00030693638836964965
step: 280, loss: 0.0006905448972247541
step: 290, loss: 0.00030592616531066597
step: 300, loss: 0.0003217111516278237
step: 310, loss: 0.004122716374695301
step: 320, loss: 0.0013943103840574622
step: 330, loss: 0.035757485777139664
step: 340, loss: 0.00011281722254352644
step: 350, loss: 0.008702870458364487
step: 360, loss: 0.0028639030642807484
step: 370, loss: 0.0010697392281144857
step: 380, loss: 0.0001883037475636229
epoch 12: dev_f1=0.6243093922651933, f1=0.5391849529780565, best_f1=0.5820105820105821
step: 0, loss: 0.0008099292172119021
step: 10, loss: 0.0005408519646152854
step: 20, loss: 0.0011124450247734785
step: 30, loss: 0.0029261361341923475
step: 40, loss: 0.0004002015630248934
step: 50, loss: 0.00012137550947954878
step: 60, loss: 0.00046049561933614314
step: 70, loss: 0.0003227394772693515
step: 80, loss: 0.005728139542043209
step: 90, loss: 0.0002298673352925107
step: 100, loss: 0.00576843973249197
step: 110, loss: 0.00017875368939712644
step: 120, loss: 0.00013989991566631943
step: 130, loss: 0.0006204332457855344
step: 140, loss: 0.0024781785905361176
step: 150, loss: 4.237117536831647e-05
step: 160, loss: 0.0003436991246417165
step: 170, loss: 0.159215047955513
step: 180, loss: 0.0014379293425008655
step: 190, loss: 0.002125285565853119
step: 200, loss: 0.0022943378426134586
step: 210, loss: 0.009739178232848644
step: 220, loss: 0.00053492869483307
step: 230, loss: 0.004562412388622761
step: 240, loss: 0.00012888325727544725
step: 250, loss: 0.04017869755625725
step: 260, loss: 0.0014455632772296667
step: 270, loss: 0.0005108616896905005
step: 280, loss: 0.0003279964439570904
step: 290, loss: 0.0011448926525190473
step: 300, loss: 0.00300611462444067
step: 310, loss: 0.00042978767305612564
step: 320, loss: 0.00836506113409996
step: 330, loss: 0.0005909578176215291
step: 340, loss: 0.005980133544653654
step: 350, loss: 0.00010016359738074243
step: 360, loss: 0.0004319165600463748
step: 370, loss: 0.0015527763171121478
step: 380, loss: 0.0014318212633952498
epoch 13: dev_f1=0.6295399515738498, f1=0.5537634408602151, best_f1=0.5820105820105821
step: 0, loss: 0.010040978901088238
step: 10, loss: 0.0016645878786221147
step: 20, loss: 0.008207399398088455
step: 30, loss: 0.04745269566774368
step: 40, loss: 0.00028651132015511394
step: 50, loss: 0.0028832759708166122
step: 60, loss: 0.0012041295412927866
step: 70, loss: 0.00018331293540541083
step: 80, loss: 9.401747229276225e-05
step: 90, loss: 0.0010879524052143097
step: 100, loss: 0.0010117455385625362
step: 110, loss: 0.07554781436920166
step: 120, loss: 0.00430683046579361
step: 130, loss: 0.004874431062489748
step: 140, loss: 0.001029576058499515
step: 150, loss: 9.848066110862419e-05
step: 160, loss: 8.851218444760889e-05
step: 170, loss: 6.778162787668407e-05
step: 180, loss: 0.0012500148732215166
step: 190, loss: 0.00021625554654747248
step: 200, loss: 0.0014910848112776875
step: 210, loss: 0.0028095922898501158
step: 220, loss: 0.0006181344506330788
step: 230, loss: 0.00034499651519581676
step: 240, loss: 0.00019826395146083087
step: 250, loss: 0.0002560419379733503
step: 260, loss: 0.00042367909918539226
step: 270, loss: 0.0008468229207210243
step: 280, loss: 0.0002470437320880592
step: 290, loss: 0.0001799498131731525
step: 300, loss: 9.12537143449299e-05
step: 310, loss: 0.00012648357369471341
step: 320, loss: 0.00037660793168470263
step: 330, loss: 0.0027113542892038822
step: 340, loss: 0.00016926029638852924
step: 350, loss: 0.05006041377782822
step: 360, loss: 0.007618601433932781
step: 370, loss: 0.0008528613252565265
step: 380, loss: 0.0002956348180305213
epoch 14: dev_f1=0.6141304347826086, f1=0.5538461538461538, best_f1=0.5820105820105821
step: 0, loss: 0.00039226081571541727
step: 10, loss: 0.0003414649982005358
step: 20, loss: 0.00011670193634927273
step: 30, loss: 0.00020577156101353467
step: 40, loss: 0.0005050966283306479
step: 50, loss: 0.00018855411326512694
step: 60, loss: 0.00023835930915083736
step: 70, loss: 0.00047984736738726497
step: 80, loss: 0.0038475096225738525
step: 90, loss: 0.00045369440340436995
step: 100, loss: 0.0040836636908352375
step: 110, loss: 0.008167242631316185
step: 120, loss: 7.725068280706182e-05
step: 130, loss: 0.004356514196842909
step: 140, loss: 0.0011861068196594715
step: 150, loss: 0.0002352393785258755
step: 160, loss: 0.0004060853971168399
step: 170, loss: 0.00018889454076997936
step: 180, loss: 0.00030229659751057625
step: 190, loss: 0.0007695677923038602
step: 200, loss: 0.004376607481390238
step: 210, loss: 0.013048982247710228
step: 220, loss: 0.0012891991063952446
step: 230, loss: 0.00010370324162067845
step: 240, loss: 0.11002663522958755
step: 250, loss: 6.641582876909524e-05
step: 260, loss: 0.008977122604846954
step: 270, loss: 0.00042164503247477114
step: 280, loss: 0.0029223603196442127
step: 290, loss: 0.0001160225147032179
step: 300, loss: 0.0007436767336912453
step: 310, loss: 0.0825301930308342
step: 320, loss: 0.00048259057803079486
step: 330, loss: 0.0006011100485920906
step: 340, loss: 7.288772030733526e-05
step: 350, loss: 0.0012175495503470302
step: 360, loss: 0.135304793715477
step: 370, loss: 0.004346699919551611
step: 380, loss: 0.0002402850368525833
epoch 15: dev_f1=0.6719160104986877, f1=0.5349544072948329, best_f1=0.5349544072948329
step: 0, loss: 0.00469067320227623
step: 10, loss: 0.0012811090564355254
step: 20, loss: 0.0002579504798632115
step: 30, loss: 0.00016291439533233643
step: 40, loss: 0.0006025106995366514
step: 50, loss: 0.0012374292127788067
step: 60, loss: 0.00029116138466633856
step: 70, loss: 0.00018973922124132514
step: 80, loss: 0.0001842154306359589
step: 90, loss: 0.0001392675912939012
step: 100, loss: 0.000571369775570929
step: 110, loss: 0.000248379452386871
step: 120, loss: 0.006273672915995121
step: 130, loss: 0.00035208798362873495
step: 140, loss: 0.00015019129205029458
step: 150, loss: 0.00030517319100908935
step: 160, loss: 0.05928679555654526
step: 170, loss: 4.876527964370325e-05
step: 180, loss: 0.00011578224803088233
step: 190, loss: 0.00010862514318432659
step: 200, loss: 0.00018544566410128027
step: 210, loss: 0.008237717673182487
step: 220, loss: 0.00015733421605546027
step: 230, loss: 0.0002485357690602541
step: 240, loss: 0.006139879580587149
step: 250, loss: 0.05118142068386078
step: 260, loss: 0.0007496896432712674
step: 270, loss: 6.788728933315724e-05
step: 280, loss: 0.0003545014187693596
step: 290, loss: 9.433969535166398e-05
step: 300, loss: 0.00029244774486869574
step: 310, loss: 0.0018264129757881165
step: 320, loss: 0.0006278923247009516
step: 330, loss: 0.00020339580078143626
step: 340, loss: 0.00017349720292259008
step: 350, loss: 0.00012057300773449242
step: 360, loss: 0.00017445940466132015
step: 370, loss: 9.862033766694367e-05
step: 380, loss: 8.128055924316868e-05
epoch 16: dev_f1=0.6217616580310881, f1=0.5393939393939394, best_f1=0.5349544072948329
step: 0, loss: 0.00015891416114754975
step: 10, loss: 0.04108951985836029
step: 20, loss: 0.004167658742517233
step: 30, loss: 0.0006021560984663665
step: 40, loss: 0.00030047682230360806
step: 50, loss: 0.004094000440090895
step: 60, loss: 0.00011098715185653418
step: 70, loss: 0.0015504512703046203
step: 80, loss: 0.00012032772792736068
step: 90, loss: 0.007781017106026411
step: 100, loss: 0.0005849094595760107
step: 110, loss: 6.82738027535379e-05
step: 120, loss: 0.00011122750584036112
step: 130, loss: 0.0003137307066936046
step: 140, loss: 0.00014597363770008087
step: 150, loss: 9.801644773688167e-05
step: 160, loss: 0.0003517226141411811
step: 170, loss: 7.169009040808305e-05
step: 180, loss: 0.0003050108498428017
step: 190, loss: 9.407410107087344e-05
step: 200, loss: 4.442506906343624e-05
step: 210, loss: 0.0003481272724457085
step: 220, loss: 0.0017122308490797877
step: 230, loss: 0.0005014707567170262
step: 240, loss: 0.003948610741645098
step: 250, loss: 0.0006555699510499835
step: 260, loss: 0.00017679405573289841
step: 270, loss: 0.0016794863622635603
step: 280, loss: 0.0033679520711302757
step: 290, loss: 0.00045537843834608793
step: 300, loss: 0.00018014057422988117
step: 310, loss: 0.00624994607642293
step: 320, loss: 0.0007537119090557098
step: 330, loss: 0.00021525780903175473
step: 340, loss: 0.0002136526018148288
step: 350, loss: 0.00013030407717451453
step: 360, loss: 7.384542550425977e-05
step: 370, loss: 0.002490451792255044
step: 380, loss: 0.0002932073548436165
epoch 17: dev_f1=0.6410256410256411, f1=0.5492537313432836, best_f1=0.5349544072948329
step: 0, loss: 0.0003223112435080111
step: 10, loss: 0.00045174697879701853
step: 20, loss: 0.0002918322279583663
step: 30, loss: 0.009258299134671688
step: 40, loss: 0.00023869043798185885
step: 50, loss: 0.00222469842992723
step: 60, loss: 4.2290852434234694e-05
step: 70, loss: 6.361220584949479e-05
step: 80, loss: 8.748941036174074e-05
step: 90, loss: 0.0004977535572834313
step: 100, loss: 0.029145801439881325
step: 110, loss: 0.00025206332793459296
step: 120, loss: 0.00015906995395198464
step: 130, loss: 0.00019628005975391716
step: 140, loss: 0.00018285406986251473
step: 150, loss: 0.00012576310837175697
step: 160, loss: 0.00011767267278628424
step: 170, loss: 0.0005594791728071868
step: 180, loss: 0.00012163089559180662
step: 190, loss: 9.406214667251334e-05
step: 200, loss: 0.0001774198899511248
step: 210, loss: 0.0005996295367367566
step: 220, loss: 0.00014347047545015812
step: 230, loss: 0.0010381372412666678
step: 240, loss: 0.00038116530049592257
step: 250, loss: 0.00021400614059530199
step: 260, loss: 0.0002534795494284481
step: 270, loss: 0.0005966120515950024
step: 280, loss: 0.00034390942892059684
step: 290, loss: 0.00020536060037557036
step: 300, loss: 8.666919893585145e-05
step: 310, loss: 0.00022079811606090516
step: 320, loss: 9.374247747473419e-05
step: 330, loss: 0.00010165360436076298
step: 340, loss: 0.010096343234181404
step: 350, loss: 0.007225161883980036
step: 360, loss: 0.0007993020699359477
step: 370, loss: 0.00019658323435578495
step: 380, loss: 2.673934977792669e-05
epoch 18: dev_f1=0.6346666666666667, f1=0.5487804878048781, best_f1=0.5349544072948329
step: 0, loss: 0.00012647896073758602
step: 10, loss: 0.004780449438840151
step: 20, loss: 5.939629045315087e-05
step: 30, loss: 0.00029831851134076715
step: 40, loss: 0.00013538898201659322
step: 50, loss: 6.163830403238535e-05
step: 60, loss: 9.627643157728016e-05
step: 70, loss: 3.1611420126864687e-05
step: 80, loss: 6.77233692840673e-05
step: 90, loss: 8.152404188876972e-05
step: 100, loss: 9.219803905580193e-05
step: 110, loss: 0.019991276785731316
step: 120, loss: 0.00017571540956851095
step: 130, loss: 0.00019150420848745853
step: 140, loss: 5.303334182826802e-05
step: 150, loss: 0.00026379546034149826
step: 160, loss: 0.00023318227613344789
step: 170, loss: 0.00011011157039320096
step: 180, loss: 4.375022399472073e-05
step: 190, loss: 0.00029420494684018195
step: 200, loss: 2.9261464078444988e-05
step: 210, loss: 0.00014413578901439905
step: 220, loss: 0.0001267217448912561
step: 230, loss: 0.00021490103972610086
step: 240, loss: 5.551768481382169e-05
step: 250, loss: 0.00016073360166046768
step: 260, loss: 5.9316673286957666e-05
step: 270, loss: 0.0035702872555702925
step: 280, loss: 8.644849003758281e-05
step: 290, loss: 0.007163736503571272
step: 300, loss: 8.20589775685221e-05
step: 310, loss: 0.00036645401269197464
step: 320, loss: 0.0002501174167264253
step: 330, loss: 4.171699765720405e-05
step: 340, loss: 9.049091022461653e-05
step: 350, loss: 0.00011143071606056765
step: 360, loss: 0.00017205471522174776
step: 370, loss: 0.0010672045173123479
step: 380, loss: 6.430473149521276e-05
epoch 19: dev_f1=0.6344086021505376, f1=0.5443425076452599, best_f1=0.5349544072948329
step: 0, loss: 0.0004596968356054276
step: 10, loss: 9.669849532656372e-05
step: 20, loss: 0.00010138625657418743
step: 30, loss: 7.42907213862054e-05
step: 40, loss: 0.00012364920985419303
step: 50, loss: 0.01273230742663145
step: 60, loss: 4.950068978359923e-05
step: 70, loss: 6.871775985928252e-05
step: 80, loss: 0.00015817602979950607
step: 90, loss: 0.00020777872123289853
step: 100, loss: 0.00016460585175082088
step: 110, loss: 0.000648331013508141
step: 120, loss: 0.00014742060739081353
step: 130, loss: 0.00034369673812761903
step: 140, loss: 5.386342672863975e-05
step: 150, loss: 0.00013992491585668176
step: 160, loss: 9.359614341519773e-05
step: 170, loss: 0.0005579355056397617
step: 180, loss: 8.045887807384133e-05
step: 190, loss: 0.00011944293510168791
step: 200, loss: 6.870822107885033e-05
step: 210, loss: 9.07658104551956e-05
step: 220, loss: 8.578577399021015e-05
step: 230, loss: 0.00018947718490380794
step: 240, loss: 9.027853229781613e-05
step: 250, loss: 8.217465074267238e-05
step: 260, loss: 9.060282172868028e-05
step: 270, loss: 0.00025300748529843986
step: 280, loss: 0.00029437130433507264
step: 290, loss: 0.00012229954882059246
step: 300, loss: 5.849308945471421e-05
step: 310, loss: 8.120692655211315e-05
step: 320, loss: 0.00015621355851180851
step: 330, loss: 0.0007462569046765566
step: 340, loss: 0.00024289512657560408
step: 350, loss: 0.01693720370531082
step: 360, loss: 0.00037700298707932234
step: 370, loss: 5.993898957967758e-05
step: 380, loss: 0.0003042917523998767
epoch 20: dev_f1=0.6233766233766234, f1=0.5508982035928144, best_f1=0.5349544072948329
