cuda
Device: cuda
step: 0, loss: 0.6577054262161255
step: 10, loss: 0.25076234340667725
step: 20, loss: 0.3806709945201874
step: 30, loss: 0.2978438138961792
step: 40, loss: 0.31615185737609863
step: 50, loss: 0.19571983814239502
step: 60, loss: 0.3174290657043457
step: 70, loss: 0.2332199662923813
step: 80, loss: 0.10206064581871033
step: 90, loss: 0.1131773442029953
step: 100, loss: 0.19822287559509277
step: 110, loss: 0.1818217635154724
step: 120, loss: 0.06264379620552063
step: 130, loss: 0.15567488968372345
step: 140, loss: 0.06484309583902359
step: 150, loss: 0.32061663269996643
step: 160, loss: 0.12618452310562134
step: 170, loss: 0.0612737275660038
step: 180, loss: 0.22052441537380219
step: 190, loss: 0.11140210181474686
step: 200, loss: 0.0555131658911705
step: 210, loss: 0.07201093435287476
step: 220, loss: 0.22220057249069214
step: 230, loss: 0.09150083363056183
step: 240, loss: 0.04556965082883835
step: 250, loss: 0.10950120538473129
step: 260, loss: 0.05917820334434509
step: 270, loss: 0.09853412955999374
step: 280, loss: 0.14641602337360382
step: 290, loss: 0.06242666020989418
step: 300, loss: 0.22871603071689606
step: 310, loss: 0.10636141151189804
step: 320, loss: 0.28014203906059265
step: 330, loss: 0.11313123255968094
step: 340, loss: 0.284275621175766
step: 350, loss: 0.27620264887809753
step: 360, loss: 0.09778835624456406
step: 370, loss: 0.08186014741659164
step: 380, loss: 0.23412272334098816
step: 390, loss: 0.17821404337882996
step: 400, loss: 0.050084080547094345
step: 410, loss: 0.1699969321489334
step: 420, loss: 0.12581971287727356
step: 430, loss: 0.10265862196683884
step: 440, loss: 0.18913689255714417
step: 450, loss: 0.31478366255760193
step: 460, loss: 0.27938589453697205
step: 470, loss: 0.10047703236341476
step: 480, loss: 0.0763445720076561
step: 490, loss: 0.10459408164024353
step: 500, loss: 0.02736104466021061
step: 510, loss: 0.24571840465068817
step: 520, loss: 0.1643192619085312
step: 530, loss: 0.13544867932796478
step: 540, loss: 0.10731944441795349
step: 550, loss: 0.1374455690383911
step: 560, loss: 0.0033558285795152187
step: 570, loss: 0.11484367400407791
step: 580, loss: 0.11722227185964584
step: 590, loss: 0.10505520552396774
step: 600, loss: 0.21893683075904846
step: 610, loss: 0.18712906539440155
step: 620, loss: 0.03555447608232498
step: 630, loss: 0.0608113557100296
step: 640, loss: 0.0422753170132637
step: 650, loss: 0.3343406021595001
step: 660, loss: 0.0917915478348732
step: 670, loss: 0.09945337474346161
step: 680, loss: 0.031871259212493896
step: 690, loss: 0.07583222538232803
step: 700, loss: 0.08034302294254303
step: 710, loss: 0.06961435824632645
step: 720, loss: 0.09207630902528763
step: 730, loss: 0.13853488862514496
step: 740, loss: 0.0494377575814724
step: 750, loss: 0.12393905222415924
step: 760, loss: 0.040675316005945206
step: 770, loss: 0.21530301868915558
step: 780, loss: 0.18332089483737946
step: 790, loss: 0.05024489760398865
step: 800, loss: 0.11400501430034637
step: 810, loss: 0.07005251944065094
step: 820, loss: 0.07376467436552048
step: 830, loss: 0.06441677361726761
step: 840, loss: 0.06290522962808609
step: 850, loss: 0.15506669878959656
step: 860, loss: 0.1510971188545227
step: 870, loss: 0.0879259705543518
step: 880, loss: 0.1903150975704193
step: 890, loss: 0.06418861448764801
step: 900, loss: 0.09344210475683212
step: 910, loss: 0.1003168448805809
step: 920, loss: 0.21041171252727509
step: 930, loss: 0.1394079327583313
step: 940, loss: 0.07879050076007843
step: 950, loss: 0.10220708698034286
step: 960, loss: 0.10716370493173599
step: 970, loss: 0.13708367943763733
epoch 1: dev_f1=0.9189435336976319, f1=0.9145183175033921, best_f1=0.9145183175033921
step: 0, loss: 0.07448745518922806
step: 10, loss: 0.04559170827269554
step: 20, loss: 0.05461360141634941
step: 30, loss: 0.04383157566189766
step: 40, loss: 0.04581350460648537
step: 50, loss: 0.16515669226646423
step: 60, loss: 0.08435023576021194
step: 70, loss: 0.19412854313850403
step: 80, loss: 0.01674698106944561
step: 90, loss: 0.019019635394215584
step: 100, loss: 0.09325440227985382
step: 110, loss: 0.07081574201583862
step: 120, loss: 0.05273441970348358
step: 130, loss: 0.016226010397076607
step: 140, loss: 0.07727212458848953
step: 150, loss: 0.026919720694422722
step: 160, loss: 0.01031472533941269
step: 170, loss: 0.07670145481824875
step: 180, loss: 0.11049657315015793
step: 190, loss: 0.04830850288271904
step: 200, loss: 0.111996129155159
step: 210, loss: 0.042773544788360596
step: 220, loss: 0.08634353429079056
step: 230, loss: 0.07600881904363632
step: 240, loss: 0.11196877807378769
step: 250, loss: 0.007116868160665035
step: 260, loss: 0.036026012152433395
step: 270, loss: 0.015833592042326927
step: 280, loss: 0.14307187497615814
step: 290, loss: 0.10981070250272751
step: 300, loss: 0.08006703853607178
step: 310, loss: 0.2759552597999573
step: 320, loss: 0.09446033835411072
step: 330, loss: 0.02075185254216194
step: 340, loss: 0.10185173153877258
step: 350, loss: 0.06261403113603592
step: 360, loss: 0.11210687458515167
step: 370, loss: 0.03455729782581329
step: 380, loss: 0.09342821687459946
step: 390, loss: 0.10414253920316696
step: 400, loss: 0.006953107658773661
step: 410, loss: 0.09952260553836823
step: 420, loss: 0.016790499910712242
step: 430, loss: 0.10145803540945053
step: 440, loss: 0.03894321620464325
step: 450, loss: 0.09753169864416122
step: 460, loss: 0.09439224749803543
step: 470, loss: 0.15458734333515167
step: 480, loss: 0.16600818932056427
step: 490, loss: 0.10305720567703247
step: 500, loss: 0.058989983052015305
step: 510, loss: 0.12600953876972198
step: 520, loss: 0.14652803540229797
step: 530, loss: 0.11776609718799591
step: 540, loss: 0.2460121214389801
step: 550, loss: 0.187332421541214
step: 560, loss: 0.04582628607749939
step: 570, loss: 0.19087566435337067
step: 580, loss: 0.1483495533466339
step: 590, loss: 0.014974390156567097
step: 600, loss: 0.02199547365307808
step: 610, loss: 0.14887471497058868
step: 620, loss: 0.03373340144753456
step: 630, loss: 0.08715932071208954
step: 640, loss: 0.14629843831062317
step: 650, loss: 0.11608229577541351
step: 660, loss: 0.011473119258880615
step: 670, loss: 0.015524118207395077
step: 680, loss: 0.09973207116127014
step: 690, loss: 0.09126359224319458
step: 700, loss: 0.0891747772693634
step: 710, loss: 0.058096744120121
step: 720, loss: 0.18987688422203064
step: 730, loss: 0.056805189698934555
step: 740, loss: 0.10224677622318268
step: 750, loss: 0.1056208461523056
step: 760, loss: 0.04588925838470459
step: 770, loss: 0.08086194097995758
step: 780, loss: 0.15324880182743073
step: 790, loss: 0.09638673067092896
step: 800, loss: 0.0262112058699131
step: 810, loss: 0.13629800081253052
step: 820, loss: 0.1735880970954895
step: 830, loss: 0.06711595505475998
step: 840, loss: 0.06889256834983826
step: 850, loss: 0.07043416798114777
step: 860, loss: 0.09586828947067261
step: 870, loss: 0.12256360799074173
step: 880, loss: 0.07956016808748245
step: 890, loss: 0.08795822411775589
step: 900, loss: 0.12366626411676407
step: 910, loss: 0.02758716605603695
step: 920, loss: 0.07012395560741425
step: 930, loss: 0.030202696099877357
step: 940, loss: 0.06999208778142929
step: 950, loss: 0.02897397242486477
step: 960, loss: 0.12652339041233063
step: 970, loss: 0.0485595278441906
epoch 2: dev_f1=0.9200189304306672, f1=0.9193245778611632, best_f1=0.9193245778611632
step: 0, loss: 0.13133284449577332
step: 10, loss: 0.10527927428483963
step: 20, loss: 0.12053011357784271
step: 30, loss: 0.25471997261047363
step: 40, loss: 0.10128811001777649
step: 50, loss: 0.31598615646362305
step: 60, loss: 0.05268501117825508
step: 70, loss: 0.13773563504219055
step: 80, loss: 0.030380593612790108
step: 90, loss: 0.05850142985582352
step: 100, loss: 0.06321917474269867
step: 110, loss: 0.17181392014026642
step: 120, loss: 0.0517711341381073
step: 130, loss: 0.045141905546188354
step: 140, loss: 0.1209234744310379
step: 150, loss: 0.06122618913650513
step: 160, loss: 0.14971384406089783
step: 170, loss: 0.058215536177158356
step: 180, loss: 0.07111235707998276
step: 190, loss: 0.017394794151186943
step: 200, loss: 0.12598773837089539
step: 210, loss: 0.063430055975914
step: 220, loss: 0.06347925961017609
step: 230, loss: 0.08999432623386383
step: 240, loss: 0.036351725459098816
step: 250, loss: 0.07441195100545883
step: 260, loss: 0.05675189197063446
step: 270, loss: 0.317436158657074
step: 280, loss: 0.1305406093597412
step: 290, loss: 0.12489136308431625
step: 300, loss: 0.05388684570789337
step: 310, loss: 0.01652367413043976
step: 320, loss: 0.007094732951372862
step: 330, loss: 0.04228087514638901
step: 340, loss: 0.34586864709854126
step: 350, loss: 0.042663078755140305
step: 360, loss: 0.03517341986298561
step: 370, loss: 0.06515509635210037
step: 380, loss: 0.12355312705039978
step: 390, loss: 0.12606340646743774
step: 400, loss: 0.03809306398034096
step: 410, loss: 0.07628629356622696
step: 420, loss: 0.02229141630232334
step: 430, loss: 0.08508377522230148
step: 440, loss: 0.08828750997781754
step: 450, loss: 0.05312328413128853
step: 460, loss: 0.1127450168132782
step: 470, loss: 0.11274205148220062
step: 480, loss: 0.04580988734960556
step: 490, loss: 0.13834375143051147
step: 500, loss: 0.05793013423681259
step: 510, loss: 0.16235242784023285
step: 520, loss: 0.07219649106264114
step: 530, loss: 0.019803566858172417
step: 540, loss: 0.10008861869573593
step: 550, loss: 0.02682594582438469
step: 560, loss: 0.10740108042955399
step: 570, loss: 0.02911999262869358
step: 580, loss: 0.08041250705718994
step: 590, loss: 0.06896794587373734
step: 600, loss: 0.05010299012064934
step: 610, loss: 0.03122040070593357
step: 620, loss: 0.1782601773738861
step: 630, loss: 0.1280910074710846
step: 640, loss: 0.022868996486067772
step: 650, loss: 0.11154786497354507
step: 660, loss: 0.08362598717212677
step: 670, loss: 0.11579693108797073
step: 680, loss: 0.029978277161717415
step: 690, loss: 0.0800403356552124
step: 700, loss: 0.06796146929264069
step: 710, loss: 0.16094538569450378
step: 720, loss: 0.13574038445949554
step: 730, loss: 0.18011586368083954
step: 740, loss: 0.08285509049892426
step: 750, loss: 0.31805068254470825
step: 760, loss: 0.04156197980046272
step: 770, loss: 0.1398320496082306
step: 780, loss: 0.06634180247783661
step: 790, loss: 0.02214575931429863
step: 800, loss: 0.07495903968811035
step: 810, loss: 0.029619215056300163
step: 820, loss: 0.03169247508049011
step: 830, loss: 0.10252790153026581
step: 840, loss: 0.050779178738594055
step: 850, loss: 0.07354976236820221
step: 860, loss: 0.14008592069149017
step: 870, loss: 0.1949760764837265
step: 880, loss: 0.06245008856058121
step: 890, loss: 0.09084713459014893
step: 900, loss: 0.07825464755296707
step: 910, loss: 0.05088549107313156
step: 920, loss: 0.16810470819473267
step: 930, loss: 0.09728872776031494
step: 940, loss: 0.12845788896083832
step: 950, loss: 0.10905955731868744
step: 960, loss: 0.032443124800920486
step: 970, loss: 0.03964730352163315
epoch 3: dev_f1=0.93202062822316, f1=0.9320843091334895, best_f1=0.9320843091334895
step: 0, loss: 0.06118380278348923
step: 10, loss: 0.1667514443397522
step: 20, loss: 0.06067796051502228
step: 30, loss: 0.07633883506059647
step: 40, loss: 0.10213630646467209
step: 50, loss: 0.17872276902198792
step: 60, loss: 0.06318023055791855
step: 70, loss: 0.06822242587804794
step: 80, loss: 0.01787596195936203
step: 90, loss: 0.09243210405111313
step: 100, loss: 0.02180902101099491
step: 110, loss: 0.12452856451272964
step: 120, loss: 0.05794138088822365
step: 130, loss: 0.14535599946975708
step: 140, loss: 0.07680371403694153
step: 150, loss: 0.018067069351673126
step: 160, loss: 0.20074281096458435
step: 170, loss: 0.022576861083507538
step: 180, loss: 0.014598705805838108
step: 190, loss: 0.0837002769112587
step: 200, loss: 0.08649291843175888
step: 210, loss: 0.070833221077919
step: 220, loss: 0.11140148341655731
step: 230, loss: 0.11253711581230164
step: 240, loss: 0.1278485655784607
step: 250, loss: 0.07294972240924835
step: 260, loss: 0.07809844613075256
step: 270, loss: 0.019596165046095848
step: 280, loss: 0.11984772235155106
step: 290, loss: 0.11616355180740356
step: 300, loss: 0.013808799907565117
step: 310, loss: 0.2603287994861603
step: 320, loss: 0.16988743841648102
step: 330, loss: 0.05175822228193283
step: 340, loss: 0.07847126573324203
step: 350, loss: 0.07632313668727875
step: 360, loss: 0.0776573121547699
step: 370, loss: 0.08499075472354889
step: 380, loss: 0.061911121010780334
step: 390, loss: 0.2142016887664795
step: 400, loss: 0.062346652150154114
step: 410, loss: 0.2187948077917099
step: 420, loss: 0.16101931035518646
step: 430, loss: 0.10341773182153702
step: 440, loss: 0.16530896723270416
step: 450, loss: 0.01627429760992527
step: 460, loss: 0.06203068792819977
step: 470, loss: 0.08604611456394196
step: 480, loss: 0.12114893645048141
step: 490, loss: 0.2019229233264923
step: 500, loss: 0.03688648343086243
step: 510, loss: 0.0628344863653183
step: 520, loss: 0.06277266889810562
step: 530, loss: 0.0038889122661203146
step: 540, loss: 0.0307004451751709
step: 550, loss: 0.14924827218055725
step: 560, loss: 0.1263221800327301
step: 570, loss: 0.1116786077618599
step: 580, loss: 0.18319235742092133
step: 590, loss: 0.11827345192432404
step: 600, loss: 0.1080607995390892
step: 610, loss: 0.02769487537443638
step: 620, loss: 0.08989665657281876
step: 630, loss: 0.05090383067727089
step: 640, loss: 0.09991505742073059
step: 650, loss: 0.06251897662878036
step: 660, loss: 0.14517858624458313
step: 670, loss: 0.051849499344825745
step: 680, loss: 0.042975205928087234
step: 690, loss: 0.019714513793587685
step: 700, loss: 0.04432619363069534
step: 710, loss: 0.008571675047278404
step: 720, loss: 0.0416162833571434
step: 730, loss: 0.11121729761362076
step: 740, loss: 0.1539064198732376
step: 750, loss: 0.013333875685930252
step: 760, loss: 0.14762046933174133
step: 770, loss: 0.0782238319516182
step: 780, loss: 0.11678712069988251
step: 790, loss: 0.057004738599061966
step: 800, loss: 0.053004954010248184
step: 810, loss: 0.0677250474691391
step: 820, loss: 0.042654648423194885
step: 830, loss: 0.07955554127693176
step: 840, loss: 0.0844312533736229
step: 850, loss: 0.04397958889603615
step: 860, loss: 0.07682299613952637
step: 870, loss: 0.16165468096733093
step: 880, loss: 0.08134166896343231
step: 890, loss: 0.07443268597126007
step: 900, loss: 0.09043757617473602
step: 910, loss: 0.060321908444166183
step: 920, loss: 0.050398167222738266
step: 930, loss: 0.12873120605945587
step: 940, loss: 0.046580635011196136
step: 950, loss: 0.11346597969532013
step: 960, loss: 0.02532185986638069
step: 970, loss: 0.13675978779792786
epoch 4: dev_f1=0.9300411522633745, f1=0.9318801089918256, best_f1=0.9320843091334895
step: 0, loss: 0.06657455861568451
step: 10, loss: 0.06405221670866013
step: 20, loss: 0.04341011121869087
step: 30, loss: 0.012647859752178192
step: 40, loss: 0.04392942786216736
step: 50, loss: 0.08021283149719238
step: 60, loss: 0.055666834115982056
step: 70, loss: 0.02529667690396309
step: 80, loss: 0.0813821330666542
step: 90, loss: 0.09967142343521118
step: 100, loss: 0.2034618854522705
step: 110, loss: 0.0597463883459568
step: 120, loss: 0.04301074519753456
step: 130, loss: 0.08388792723417282
step: 140, loss: 0.1103658527135849
step: 150, loss: 0.09823232889175415
step: 160, loss: 0.07496803253889084
step: 170, loss: 0.08759650588035583
step: 180, loss: 0.06887838989496231
step: 190, loss: 0.07361279428005219
step: 200, loss: 0.005422372370958328
step: 210, loss: 0.08503838628530502
step: 220, loss: 0.09279399365186691
step: 230, loss: 0.024918876588344574
step: 240, loss: 0.09071123600006104
step: 250, loss: 0.18193058669567108
step: 260, loss: 0.012367187067866325
step: 270, loss: 0.03193356469273567
step: 280, loss: 0.07294072955846786
step: 290, loss: 0.0699363723397255
step: 300, loss: 0.1050102636218071
step: 310, loss: 0.06136719882488251
step: 320, loss: 0.07560598105192184
step: 330, loss: 0.05955324321985245
step: 340, loss: 0.06772592663764954
step: 350, loss: 0.004264154005795717
step: 360, loss: 0.016905512660741806
step: 370, loss: 0.00677903788164258
step: 380, loss: 0.025655262172222137
step: 390, loss: 0.0760035291314125
step: 400, loss: 0.05290529131889343
step: 410, loss: 0.030494268983602524
step: 420, loss: 0.11354418843984604
step: 430, loss: 0.0937279760837555
step: 440, loss: 0.052571605890989304
step: 450, loss: 0.2276657372713089
step: 460, loss: 0.015545979142189026
step: 470, loss: 0.1529635787010193
step: 480, loss: 0.05071062967181206
step: 490, loss: 0.04993017017841339
step: 500, loss: 0.03082485869526863
step: 510, loss: 0.062070269137620926
step: 520, loss: 0.029170501977205276
step: 530, loss: 0.23718802630901337
step: 540, loss: 0.1274976283311844
step: 550, loss: 0.07563010603189468
step: 560, loss: 0.022286657243967056
step: 570, loss: 0.046888530254364014
step: 580, loss: 0.06708525866270065
step: 590, loss: 0.03065207414329052
step: 600, loss: 0.03380955755710602
step: 610, loss: 0.051238562911748886
step: 620, loss: 0.07362815737724304
step: 630, loss: 0.04973169043660164
step: 640, loss: 0.01852729171514511
step: 650, loss: 0.04350891709327698
step: 660, loss: 0.10389714688062668
step: 670, loss: 0.036340467631816864
step: 680, loss: 0.09538313746452332
step: 690, loss: 0.17727231979370117
step: 700, loss: 0.03678622096776962
step: 710, loss: 0.14320114254951477
step: 720, loss: 0.07455132901668549
step: 730, loss: 0.06571148335933685
step: 740, loss: 0.04346947371959686
step: 750, loss: 0.10484016686677933
step: 760, loss: 0.02690974436700344
step: 770, loss: 0.20069192349910736
step: 780, loss: 0.16235403716564178
step: 790, loss: 0.015084232203662395
step: 800, loss: 0.009604169987142086
step: 810, loss: 0.010213187895715237
step: 820, loss: 0.13148675858974457
step: 830, loss: 0.01557252835482359
step: 840, loss: 0.16820834577083588
step: 850, loss: 0.06378132849931717
step: 860, loss: 0.027888299897313118
step: 870, loss: 0.06915324926376343
step: 880, loss: 0.1540190875530243
step: 890, loss: 0.014884507283568382
step: 900, loss: 0.15965242683887482
step: 910, loss: 0.08333232998847961
step: 920, loss: 0.015183979645371437
step: 930, loss: 0.09312519431114197
step: 940, loss: 0.00918751023709774
step: 950, loss: 0.11289148032665253
step: 960, loss: 0.02734151855111122
step: 970, loss: 0.133897066116333
epoch 5: dev_f1=0.9371011850501367, f1=0.9315192743764172, best_f1=0.9315192743764172
step: 0, loss: 0.06060653179883957
step: 10, loss: 0.11320298165082932
step: 20, loss: 0.057942070066928864
step: 30, loss: 0.035214949399232864
step: 40, loss: 0.12602545320987701
step: 50, loss: 0.03253766894340515
step: 60, loss: 0.06084304302930832
step: 70, loss: 0.058549340814352036
step: 80, loss: 0.08585137128829956
step: 90, loss: 0.054528649896383286
step: 100, loss: 0.1314428299665451
step: 110, loss: 0.05415806546807289
step: 120, loss: 0.20137692987918854
step: 130, loss: 0.06103815510869026
step: 140, loss: 0.13337963819503784
step: 150, loss: 0.09919764846563339
step: 160, loss: 0.1260208934545517
step: 170, loss: 0.03954285383224487
step: 180, loss: 0.06251141428947449
step: 190, loss: 0.004936876706779003
step: 200, loss: 0.08839549124240875
step: 210, loss: 0.10001559555530548
step: 220, loss: 0.11381987482309341
step: 230, loss: 0.038350582122802734
step: 240, loss: 0.08320697396993637
step: 250, loss: 0.014572164043784142
step: 260, loss: 0.06103489175438881
step: 270, loss: 0.14874519407749176
step: 280, loss: 0.024616654962301254
step: 290, loss: 0.021303489804267883
step: 300, loss: 0.07582136988639832
step: 310, loss: 0.10652045160531998
step: 320, loss: 0.21690033376216888
step: 330, loss: 0.08226755261421204
step: 340, loss: 0.023189032450318336
step: 350, loss: 0.014237255789339542
step: 360, loss: 0.08027154952287674
step: 370, loss: 0.07062028348445892
step: 380, loss: 0.09280258417129517
step: 390, loss: 0.14175797998905182
step: 400, loss: 0.04891341179609299
step: 410, loss: 0.11275338381528854
step: 420, loss: 0.06180451065301895
step: 430, loss: 0.08047258853912354
step: 440, loss: 0.09878586232662201
step: 450, loss: 0.06769078224897385
step: 460, loss: 0.03694813326001167
step: 470, loss: 0.16745422780513763
step: 480, loss: 0.017271030694246292
step: 490, loss: 0.07544992119073868
step: 500, loss: 0.06817881017923355
step: 510, loss: 0.19000139832496643
step: 520, loss: 0.0999566912651062
step: 530, loss: 0.11290591955184937
step: 540, loss: 0.0380728542804718
step: 550, loss: 0.0816383808851242
step: 560, loss: 0.03361736983060837
step: 570, loss: 0.23797601461410522
step: 580, loss: 0.057388827204704285
step: 590, loss: 0.08753389865159988
step: 600, loss: 0.03282127529382706
step: 610, loss: 0.1615286022424698
step: 620, loss: 0.03280675783753395
step: 630, loss: 0.05405399203300476
step: 640, loss: 0.03901124745607376
step: 650, loss: 0.10436518490314484
step: 660, loss: 0.07320885360240936
step: 670, loss: 0.0386427603662014
step: 680, loss: 0.09739658981561661
step: 690, loss: 0.08837892860174179
step: 700, loss: 0.17347794771194458
step: 710, loss: 0.022306811064481735
step: 720, loss: 0.05046693608164787
step: 730, loss: 0.055656109005212784
step: 740, loss: 0.1961655169725418
step: 750, loss: 0.07120321691036224
step: 760, loss: 0.126820370554924
step: 770, loss: 0.05329184979200363
step: 780, loss: 0.017994634807109833
step: 790, loss: 0.16611681878566742
step: 800, loss: 0.051333773881196976
step: 810, loss: 0.081790991127491
step: 820, loss: 0.02121407724916935
step: 830, loss: 0.019680052995681763
step: 840, loss: 0.05326774716377258
step: 850, loss: 0.08823292702436447
step: 860, loss: 0.03778674080967903
step: 870, loss: 0.06259121000766754
step: 880, loss: 0.03403623029589653
step: 890, loss: 0.07314784824848175
step: 900, loss: 0.057251136749982834
step: 910, loss: 0.10313168913125992
step: 920, loss: 0.11769924312829971
step: 930, loss: 0.28888794779777527
step: 940, loss: 0.08291250467300415
step: 950, loss: 0.0173116996884346
step: 960, loss: 0.10171523690223694
step: 970, loss: 0.016736892983317375
epoch 6: dev_f1=0.9459084604715674, f1=0.9388888888888889, best_f1=0.9388888888888889
step: 0, loss: 0.07715457677841187
step: 10, loss: 0.024162784218788147
step: 20, loss: 0.09323397278785706
step: 30, loss: 0.07749489694833755
step: 40, loss: 0.06673210114240646
step: 50, loss: 0.007315801922231913
step: 60, loss: 0.1305253803730011
step: 70, loss: 0.0821373388171196
step: 80, loss: 0.032573360949754715
step: 90, loss: 0.19066835939884186
step: 100, loss: 0.0689183920621872
step: 110, loss: 0.013087817467749119
step: 120, loss: 0.04066641628742218
step: 130, loss: 0.013870935887098312
step: 140, loss: 0.00897642970085144
step: 150, loss: 0.013297000899910927
step: 160, loss: 5.182765380595811e-05
step: 170, loss: 0.03267251327633858
step: 180, loss: 0.09428911656141281
step: 190, loss: 0.036611929535865784
step: 200, loss: 0.09122254699468613
step: 210, loss: 0.009629998356103897
step: 220, loss: 0.007289001252502203
step: 230, loss: 0.05753560736775398
step: 240, loss: 0.02138156071305275
step: 250, loss: 0.10395978391170502
step: 260, loss: 0.06753034144639969
step: 270, loss: 0.11058488488197327
step: 280, loss: 0.07229629904031754
step: 290, loss: 0.021752474829554558
step: 300, loss: 0.10377886146306992
step: 310, loss: 0.044925108551979065
step: 320, loss: 0.03397850692272186
step: 330, loss: 0.092250756919384
step: 340, loss: 0.0969650149345398
step: 350, loss: 0.06409868597984314
step: 360, loss: 0.053432416170835495
step: 370, loss: 0.0723976194858551
step: 380, loss: 0.07858127355575562
step: 390, loss: 0.046228282153606415
step: 400, loss: 0.11328324675559998
step: 410, loss: 0.10174224525690079
step: 420, loss: 0.03072296641767025
step: 430, loss: 0.01471552811563015
step: 440, loss: 0.018351027742028236
step: 450, loss: 0.15641579031944275
step: 460, loss: 0.051646970212459564
step: 470, loss: 0.02261367440223694
step: 480, loss: 0.031062010675668716
step: 490, loss: 0.12122450768947601
step: 500, loss: 0.05132250115275383
step: 510, loss: 0.03756348788738251
step: 520, loss: 0.08030714094638824
step: 530, loss: 0.04676903784275055
step: 540, loss: 0.012145783752202988
step: 550, loss: 0.026699526235461235
step: 560, loss: 0.002101177116855979
step: 570, loss: 0.035961851477622986
step: 580, loss: 0.019703246653079987
step: 590, loss: 0.05494268238544464
step: 600, loss: 0.09287787228822708
step: 610, loss: 0.0029366195667535067
step: 620, loss: 0.016460314393043518
step: 630, loss: 0.06582998484373093
step: 640, loss: 0.06694784760475159
step: 650, loss: 0.015221117064356804
step: 660, loss: 0.1066928431391716
step: 670, loss: 0.12582945823669434
step: 680, loss: 0.014203472062945366
step: 690, loss: 0.0626746416091919
step: 700, loss: 0.012487443163990974
step: 710, loss: 0.006060696206986904
step: 720, loss: 0.024051150307059288
step: 730, loss: 0.09269639104604721
step: 740, loss: 0.020557187497615814
step: 750, loss: 0.011835100129246712
step: 760, loss: 0.02844114415347576
step: 770, loss: 0.12828613817691803
step: 780, loss: 0.08703161031007767
step: 790, loss: 0.05223553255200386
step: 800, loss: 0.019643375650048256
step: 810, loss: 0.0630757063627243
step: 820, loss: 0.23598666489124298
step: 830, loss: 0.07257542014122009
step: 840, loss: 0.051128994673490524
step: 850, loss: 0.09169095754623413
step: 860, loss: 0.06836941093206406
step: 870, loss: 0.0004228201578371227
step: 880, loss: 0.05411280691623688
step: 890, loss: 0.08066537976264954
step: 900, loss: 0.14713382720947266
step: 910, loss: 0.007915804162621498
step: 920, loss: 0.16828835010528564
step: 930, loss: 0.05751073732972145
step: 940, loss: 0.022721752524375916
step: 950, loss: 0.06477998197078705
step: 960, loss: 0.08575508743524551
step: 970, loss: 0.03777863085269928
epoch 7: dev_f1=0.9381682938168294, f1=0.9311627906976745, best_f1=0.9388888888888889
step: 0, loss: 0.07104681432247162
step: 10, loss: 0.036144960671663284
step: 20, loss: 0.05712878704071045
step: 30, loss: 0.19110499322414398
step: 40, loss: 0.10288095474243164
step: 50, loss: 0.027554979547858238
step: 60, loss: 0.13591864705085754
step: 70, loss: 0.01819729618728161
step: 80, loss: 0.19980816543102264
step: 90, loss: 0.22302719950675964
step: 100, loss: 0.10834181308746338
step: 110, loss: 0.03707093000411987
step: 120, loss: 0.00962328165769577
step: 130, loss: 0.07807774841785431
step: 140, loss: 0.02093423157930374
step: 150, loss: 0.04796403646469116
step: 160, loss: 0.061939921230077744
step: 170, loss: 0.0474812388420105
step: 180, loss: 0.10381393879652023
step: 190, loss: 0.014467857778072357
step: 200, loss: 0.15155380964279175
step: 210, loss: 0.0018423446454107761
step: 220, loss: 0.012944447807967663
step: 230, loss: 0.05714055895805359
step: 240, loss: 0.15877309441566467
step: 250, loss: 0.13534799218177795
step: 260, loss: 0.06977953016757965
step: 270, loss: 0.03272324427962303
step: 280, loss: 0.10895520448684692
step: 290, loss: 0.08354043960571289
step: 300, loss: 0.01904536969959736
step: 310, loss: 0.010516500100493431
step: 320, loss: 0.011167889460921288
step: 330, loss: 0.14227813482284546
step: 340, loss: 0.012632732279598713
step: 350, loss: 0.0778692290186882
step: 360, loss: 0.05398218333721161
step: 370, loss: 0.07787986844778061
step: 380, loss: 0.11729919165372849
step: 390, loss: 0.007933837361633778
step: 400, loss: 0.026017695665359497
step: 410, loss: 0.013225620612502098
step: 420, loss: 0.07226192951202393
step: 430, loss: 0.13336612284183502
step: 440, loss: 0.09255335479974747
step: 450, loss: 0.1322842389345169
step: 460, loss: 0.18997812271118164
step: 470, loss: 0.09293415397405624
step: 480, loss: 0.025529341772198677
step: 490, loss: 0.061077818274497986
step: 500, loss: 0.03524486720561981
step: 510, loss: 0.08153806626796722
step: 520, loss: 0.0900101289153099
step: 530, loss: 0.07588732987642288
step: 540, loss: 0.08374861627817154
step: 550, loss: 0.015119597315788269
step: 560, loss: 0.07034267485141754
step: 570, loss: 0.12302439659833908
step: 580, loss: 0.020789731293916702
step: 590, loss: 0.07428550720214844
step: 600, loss: 0.14264008402824402
step: 610, loss: 0.08615239709615707
step: 620, loss: 0.031863659620285034
step: 630, loss: 0.07908813655376434
step: 640, loss: 0.057205069810152054
step: 650, loss: 0.08465225994586945
step: 660, loss: 0.050762418657541275
step: 670, loss: 0.01294361986219883
step: 680, loss: 0.009480617009103298
step: 690, loss: 0.018286582082509995
step: 700, loss: 0.03436822071671486
step: 710, loss: 0.11840932816267014
step: 720, loss: 0.09020309150218964
step: 730, loss: 0.14300279319286346
step: 740, loss: 0.06524316966533661
step: 750, loss: 0.04612640291452408
step: 760, loss: 0.055854666978120804
step: 770, loss: 0.052459269762039185
step: 780, loss: 0.029370790347456932
step: 790, loss: 0.0728965774178505
step: 800, loss: 0.07309326529502869
step: 810, loss: 0.043631572276353836
step: 820, loss: 0.15644395351409912
step: 830, loss: 0.021707994863390923
step: 840, loss: 0.13314470648765564
step: 850, loss: 0.060574423521757126
step: 860, loss: 0.09002026915550232
step: 870, loss: 0.0370650552213192
step: 880, loss: 0.05635365843772888
step: 890, loss: 0.12921138107776642
step: 900, loss: 0.024809464812278748
step: 910, loss: 0.0956590548157692
step: 920, loss: 0.03897017985582352
step: 930, loss: 0.02569434605538845
step: 940, loss: 0.07401653379201889
step: 950, loss: 0.07341606914997101
step: 960, loss: 0.050865136086940765
step: 970, loss: 0.03503662720322609
epoch 8: dev_f1=0.9371215649743828, f1=0.9322892676186089, best_f1=0.9388888888888889
step: 0, loss: 0.09666326642036438
step: 10, loss: 0.019426265731453896
step: 20, loss: 0.061427030712366104
step: 30, loss: 0.046038832515478134
step: 40, loss: 0.09913387149572372
step: 50, loss: 0.006513287778943777
step: 60, loss: 0.07258138805627823
step: 70, loss: 0.018472781404852867
step: 80, loss: 0.015172875486314297
step: 90, loss: 0.023574113845825195
step: 100, loss: 0.044879358261823654
step: 110, loss: 0.07959788292646408
step: 120, loss: 0.036988548934459686
step: 130, loss: 0.07391747832298279
step: 140, loss: 0.05032755807042122
step: 150, loss: 0.04656143859028816
step: 160, loss: 0.027706407010555267
step: 170, loss: 0.02727663703262806
step: 180, loss: 0.09173242747783661
step: 190, loss: 0.03216884657740593
step: 200, loss: 0.10833565145730972
step: 210, loss: 0.055771421641111374
step: 220, loss: 0.1416843980550766
step: 230, loss: 0.06203477457165718
step: 240, loss: 0.02043311856687069
step: 250, loss: 0.0655980333685875
step: 260, loss: 0.03132319822907448
step: 270, loss: 0.018699053674936295
step: 280, loss: 0.041612643748521805
step: 290, loss: 0.013146737590432167
step: 300, loss: 0.04076646268367767
step: 310, loss: 0.05159552022814751
step: 320, loss: 0.08219129592180252
step: 330, loss: 0.01670077256858349
step: 340, loss: 0.0510367713868618
step: 350, loss: 0.16162048280239105
step: 360, loss: 0.025077862665057182
step: 370, loss: 0.0002466360165271908
step: 380, loss: 0.0281950943171978
step: 390, loss: 0.07341932505369186
step: 400, loss: 0.016223274171352386
step: 410, loss: 0.04119307920336723
step: 420, loss: 0.06407797336578369
step: 430, loss: 0.07059524953365326
step: 440, loss: 0.018515625968575478
step: 450, loss: 0.21390876173973083
step: 460, loss: 0.02727348916232586
step: 470, loss: 0.03826358914375305
step: 480, loss: 1.8723099856288172e-05
step: 490, loss: 0.005248526111245155
step: 500, loss: 0.10408871620893478
step: 510, loss: 0.01976041868329048
step: 520, loss: 0.11015990376472473
step: 530, loss: 0.022290999069809914
step: 540, loss: 0.01298067718744278
step: 550, loss: 0.030718225985765457
step: 560, loss: 0.08827801793813705
step: 570, loss: 0.023555316030979156
step: 580, loss: 0.1057477667927742
step: 590, loss: 0.10543185472488403
step: 600, loss: 0.016014065593481064
step: 610, loss: 0.10836911201477051
step: 620, loss: 0.03607175126671791
step: 630, loss: 0.0318903885781765
step: 640, loss: 0.016054626554250717
step: 650, loss: 0.061632584780454636
step: 660, loss: 0.015885915607213974
step: 670, loss: 0.14442293345928192
step: 680, loss: 0.011229248717427254
step: 690, loss: 0.007928933016955853
step: 700, loss: 0.09824956208467484
step: 710, loss: 0.029471229761838913
step: 720, loss: 0.14241720736026764
step: 730, loss: 0.05430208891630173
step: 740, loss: 0.12314636260271072
step: 750, loss: 0.008869973942637444
step: 760, loss: 0.08892650902271271
step: 770, loss: 0.06788657605648041
step: 780, loss: 0.018920758739113808
step: 790, loss: 0.15828539431095123
step: 800, loss: 0.12198112905025482
step: 810, loss: 0.022536322474479675
step: 820, loss: 0.08841483294963837
step: 830, loss: 0.016066117212176323
step: 840, loss: 0.08974943310022354
step: 850, loss: 0.024034246802330017
step: 860, loss: 0.11843886226415634
step: 870, loss: 0.12773342430591583
step: 880, loss: 0.006395855452865362
step: 890, loss: 0.025992996990680695
step: 900, loss: 0.09665011614561081
step: 910, loss: 0.09142184257507324
step: 920, loss: 0.06797443330287933
step: 930, loss: 0.006914160214364529
step: 940, loss: 0.009847719222307205
step: 950, loss: 0.004561503883451223
step: 960, loss: 0.09795784950256348
step: 970, loss: 0.07200582325458527
epoch 9: dev_f1=0.9337068160597572, f1=0.929368029739777, best_f1=0.9388888888888889
step: 0, loss: 0.03636807203292847
step: 10, loss: 0.08788495510816574
step: 20, loss: 0.05160252004861832
step: 30, loss: 0.07702170312404633
step: 40, loss: 0.07755450159311295
step: 50, loss: 0.06313207745552063
step: 60, loss: 0.0766044408082962
step: 70, loss: 0.18792720139026642
step: 80, loss: 0.03379923477768898
step: 90, loss: 0.04670768231153488
step: 100, loss: 0.0720023363828659
step: 110, loss: 0.025617798790335655
step: 120, loss: 0.0318487212061882
step: 130, loss: 0.08745802938938141
step: 140, loss: 0.09392479062080383
step: 150, loss: 0.0572051927447319
step: 160, loss: 0.05612732470035553
step: 170, loss: 0.0731099396944046
step: 180, loss: 0.07810751348733902
step: 190, loss: 0.031700499355793
step: 200, loss: 0.07303501665592194
step: 210, loss: 0.06961895525455475
step: 220, loss: 0.019937187433242798
step: 230, loss: 0.01335175707936287
step: 240, loss: 0.029202427715063095
step: 250, loss: 0.08546948432922363
step: 260, loss: 0.00854158028960228
step: 270, loss: 0.04190520942211151
step: 280, loss: 0.015392648987472057
step: 290, loss: 0.03555549308657646
step: 300, loss: 0.09402726590633392
step: 310, loss: 0.022459980100393295
step: 320, loss: 0.019938863813877106
step: 330, loss: 0.10710233449935913
step: 340, loss: 0.05918227136135101
step: 350, loss: 0.012967698276042938
step: 360, loss: 0.19517503678798676
step: 370, loss: 0.06716810166835785
step: 380, loss: 0.09274979680776596
step: 390, loss: 0.05923844128847122
step: 400, loss: 0.06435853987932205
step: 410, loss: 0.08258680254220963
step: 420, loss: 0.0385759174823761
step: 430, loss: 0.052693214267492294
step: 440, loss: 0.2474701702594757
step: 450, loss: 0.08023779094219208
step: 460, loss: 0.003367363242432475
step: 470, loss: 0.044295720756053925
step: 480, loss: 0.05766010284423828
step: 490, loss: 0.02983068861067295
step: 500, loss: 0.05354207754135132
step: 510, loss: 0.13226954638957977
step: 520, loss: 0.04059774428606033
step: 530, loss: 0.03901994228363037
step: 540, loss: 0.015295105054974556
step: 550, loss: 0.006064470857381821
step: 560, loss: 0.021558061242103577
step: 570, loss: 0.08459477126598358
step: 580, loss: 0.014352133497595787
step: 590, loss: 0.07640822976827621
step: 600, loss: 0.16492295265197754
step: 610, loss: 0.02114887163043022
step: 620, loss: 0.051044415682554245
step: 630, loss: 0.039023857563734055
step: 640, loss: 0.05201246589422226
step: 650, loss: 0.06635177135467529
step: 660, loss: 0.029573233798146248
step: 670, loss: 0.011933984234929085
step: 680, loss: 0.04933710768818855
step: 690, loss: 0.01736316829919815
step: 700, loss: 0.11427684128284454
step: 710, loss: 0.06618375331163406
step: 720, loss: 0.03709045425057411
step: 730, loss: 0.19286522269248962
step: 740, loss: 0.07092496752738953
step: 750, loss: 0.04622640833258629
step: 760, loss: 0.06873977929353714
step: 770, loss: 0.005806776694953442
step: 780, loss: 0.0042151398956775665
step: 790, loss: 0.009217836894094944
step: 800, loss: 0.044253330677747726
step: 810, loss: 0.04970460385084152
step: 820, loss: 0.012613484635949135
step: 830, loss: 0.07291148602962494
step: 840, loss: 0.028580818325281143
step: 850, loss: 0.03904968500137329
step: 860, loss: 0.0020635847467929125
step: 870, loss: 0.06630223989486694
step: 880, loss: 0.05361105874180794
step: 890, loss: 0.012309404090046883
step: 900, loss: 0.1396389603614807
step: 910, loss: 0.03023078851401806
step: 920, loss: 0.05597652494907379
step: 930, loss: 0.007544039282947779
step: 940, loss: 0.06585768610239029
step: 950, loss: 0.09371597319841385
step: 960, loss: 0.0824911817908287
step: 970, loss: 0.03956357389688492
epoch 10: dev_f1=0.9393237610004631, f1=0.9321100917431193, best_f1=0.9388888888888889
step: 0, loss: 0.0018907802877947688
step: 10, loss: 0.004094978794455528
step: 20, loss: 0.03879506513476372
step: 30, loss: 0.06518111377954483
step: 40, loss: 0.0033927354961633682
step: 50, loss: 0.15878714621067047
step: 60, loss: 0.01409834623336792
step: 70, loss: 0.1360791176557541
step: 80, loss: 0.011008505709469318
step: 90, loss: 0.035769008100032806
step: 100, loss: 0.006725823972374201
step: 110, loss: 0.12596897780895233
step: 120, loss: 0.0716262012720108
step: 130, loss: 0.07757090032100677
step: 140, loss: 0.07564704120159149
step: 150, loss: 0.1746043860912323
step: 160, loss: 0.0018717453349381685
step: 170, loss: 0.01825580932199955
step: 180, loss: 0.082697294652462
step: 190, loss: 0.055283073335886
step: 200, loss: 0.03462157025933266
step: 210, loss: 0.03675315901637077
step: 220, loss: 0.053161609917879105
step: 230, loss: 0.06848650425672531
step: 240, loss: 0.11307259649038315
step: 250, loss: 0.017360897734761238
step: 260, loss: 0.15900231897830963
step: 270, loss: 0.02188911847770214
step: 280, loss: 0.07650017738342285
step: 290, loss: 0.06983736902475357
step: 300, loss: 0.03714185953140259
step: 310, loss: 0.04824135825037956
step: 320, loss: 0.08821474015712738
step: 330, loss: 0.002617419697344303
step: 340, loss: 0.08988719433546066
step: 350, loss: 0.05296655744314194
step: 360, loss: 0.061599668115377426
step: 370, loss: 0.057851918041706085
step: 380, loss: 0.07706005871295929
step: 390, loss: 0.1282162070274353
step: 400, loss: 0.006583210546523333
step: 410, loss: 0.03916902467608452
step: 420, loss: 0.033588021993637085
step: 430, loss: 0.057551220059394836
step: 440, loss: 0.028622694313526154
step: 450, loss: 0.027695240452885628
step: 460, loss: 0.005143282003700733
step: 470, loss: 0.11179182678461075
step: 480, loss: 0.07392676174640656
step: 490, loss: 0.02718687616288662
step: 500, loss: 0.15318678319454193
step: 510, loss: 0.13735149800777435
step: 520, loss: 0.1094963476061821
step: 530, loss: 0.0458800345659256
step: 540, loss: 0.07051137089729309
step: 550, loss: 0.03911074623465538
step: 560, loss: 0.03396306186914444
step: 570, loss: 0.12624651193618774
step: 580, loss: 0.01853524148464203
step: 590, loss: 0.05305665358901024
step: 600, loss: 0.04111114889383316
step: 610, loss: 0.006660690531134605
step: 620, loss: 0.10701490193605423
step: 630, loss: 0.09463527798652649
step: 640, loss: 0.07522924989461899
step: 650, loss: 0.05644851550459862
step: 660, loss: 0.038130421191453934
step: 670, loss: 0.09541758894920349
step: 680, loss: 0.12733326852321625
step: 690, loss: 0.011498134583234787
step: 700, loss: 0.06737257540225983
step: 710, loss: 0.007462630048394203
step: 720, loss: 0.05375593155622482
step: 730, loss: 0.07880283147096634
step: 740, loss: 0.014909197576344013
step: 750, loss: 0.012385311536490917
step: 760, loss: 0.1069580540060997
step: 770, loss: 0.07609211653470993
step: 780, loss: 0.01778833568096161
step: 790, loss: 2.0935711290803738e-05
step: 800, loss: 0.03343382850289345
step: 810, loss: 0.03001796081662178
step: 820, loss: 0.21658124029636383
step: 830, loss: 0.06470486521720886
step: 840, loss: 0.05786123871803284
step: 850, loss: 0.09742563962936401
step: 860, loss: 0.005961580667644739
step: 870, loss: 0.020198151469230652
step: 880, loss: 0.04844574257731438
step: 890, loss: 0.02474188804626465
step: 900, loss: 0.028448281809687614
step: 910, loss: 0.06346531212329865
step: 920, loss: 0.04669453203678131
step: 930, loss: 0.09463497251272202
step: 940, loss: 0.01868496462702751
step: 950, loss: 0.007017320953309536
step: 960, loss: 0.005579658318310976
step: 970, loss: 0.13978399336338043
epoch 11: dev_f1=0.9402501157943491, f1=0.9351127473538886, best_f1=0.9388888888888889
step: 0, loss: 0.16273179650306702
step: 10, loss: 0.07920292019844055
step: 20, loss: 0.01772635616362095
step: 30, loss: 0.0017920497339218855
step: 40, loss: 0.015030075795948505
step: 50, loss: 0.042749837040901184
step: 60, loss: 0.023773059248924255
step: 70, loss: 0.04429138824343681
step: 80, loss: 0.05196959152817726
step: 90, loss: 0.008850963786244392
step: 100, loss: 0.043724074959754944
step: 110, loss: 0.02929391898214817
step: 120, loss: 0.027102144435048103
step: 130, loss: 0.1020507887005806
step: 140, loss: 0.04429883882403374
step: 150, loss: 0.014966280199587345
step: 160, loss: 0.001863064244389534
step: 170, loss: 0.07425012439489365
step: 180, loss: 0.008146011270582676
step: 190, loss: 0.07086817920207977
step: 200, loss: 0.0011318761389702559
step: 210, loss: 0.028282612562179565
step: 220, loss: 0.12611280381679535
step: 230, loss: 0.01860010251402855
step: 240, loss: 0.044401515275239944
step: 250, loss: 0.08579161763191223
step: 260, loss: 0.045550741255283356
step: 270, loss: 0.03798186033964157
step: 280, loss: 0.009887415915727615
step: 290, loss: 0.05420713126659393
step: 300, loss: 0.01197378896176815
step: 310, loss: 0.038775861263275146
step: 320, loss: 0.026159776374697685
step: 330, loss: 0.0028206524439156055
step: 340, loss: 0.12678727507591248
step: 350, loss: 0.03628883510828018
step: 360, loss: 0.003127196803689003
step: 370, loss: 0.10044007003307343
step: 380, loss: 0.03576250746846199
step: 390, loss: 0.15627023577690125
step: 400, loss: 0.09353651106357574
step: 410, loss: 0.023228909820318222
step: 420, loss: 0.07108329236507416
step: 430, loss: 0.002715898910537362
step: 440, loss: 0.0031043817289173603
step: 450, loss: 0.0005735190352424979
step: 460, loss: 0.07127738744020462
step: 470, loss: 0.21375252306461334
step: 480, loss: 0.01117106806486845
step: 490, loss: 0.08126500248908997
step: 500, loss: 0.002204537857323885
step: 510, loss: 7.92419450590387e-05
step: 520, loss: 0.025472629815340042
step: 530, loss: 0.02441791631281376
step: 540, loss: 0.07711367309093475
step: 550, loss: 0.0710216835141182
step: 560, loss: 0.08305900543928146
step: 570, loss: 0.07757505774497986
step: 580, loss: 0.1356833130121231
step: 590, loss: 0.00029654207173734903
step: 600, loss: 0.0492267943918705
step: 610, loss: 0.025628987699747086
step: 620, loss: 0.014077939093112946
step: 630, loss: 0.05234332010149956
step: 640, loss: 0.11081131547689438
step: 650, loss: 0.08571215718984604
step: 660, loss: 0.001613966072909534
step: 670, loss: 0.01167241483926773
step: 680, loss: 0.024961665272712708
step: 690, loss: 0.0500779002904892
step: 700, loss: 0.08815250545740128
step: 710, loss: 0.07212895154953003
step: 720, loss: 0.01984269917011261
step: 730, loss: 0.016532335430383682
step: 740, loss: 0.07851128280162811
step: 750, loss: 0.004985074512660503
step: 760, loss: 0.10964874178171158
step: 770, loss: 0.04999987781047821
step: 780, loss: 0.047191496938467026
step: 790, loss: 0.11540602147579193
step: 800, loss: 0.03971460834145546
step: 810, loss: 0.03856884315609932
step: 820, loss: 0.09111181646585464
step: 830, loss: 0.014178813435137272
step: 840, loss: 0.07290516793727875
step: 850, loss: 0.060436002910137177
step: 860, loss: 0.04192303121089935
step: 870, loss: 0.005317246075719595
step: 880, loss: 0.06761250644922256
step: 890, loss: 0.03469439968466759
step: 900, loss: 0.0024127706419676542
step: 910, loss: 0.0845249742269516
step: 920, loss: 0.024930108338594437
step: 930, loss: 0.044492971152067184
step: 940, loss: 0.06648784875869751
step: 950, loss: 0.027512559667229652
step: 960, loss: 0.022189894691109657
step: 970, loss: 0.052613962441682816
epoch 12: dev_f1=0.9391143911439114, f1=0.9308291342189647, best_f1=0.9388888888888889
step: 0, loss: 0.004496690351516008
step: 10, loss: 0.01311304047703743
step: 20, loss: 0.030344631522893906
step: 30, loss: 0.020978547632694244
step: 40, loss: 0.09114405512809753
step: 50, loss: 0.05460840091109276
step: 60, loss: 0.07851935923099518
step: 70, loss: 0.11740947514772415
step: 80, loss: 0.01404991839081049
step: 90, loss: 0.04722905158996582
step: 100, loss: 0.0058459010906517506
step: 110, loss: 0.0023161601275205612
step: 120, loss: 0.0038694737013429403
step: 130, loss: 0.10274434089660645
step: 140, loss: 0.004568320699036121
step: 150, loss: 0.04503241181373596
step: 160, loss: 0.0007701823487877846
step: 170, loss: 0.07610853761434555
step: 180, loss: 0.003650456201285124
step: 190, loss: 0.03185289725661278
step: 200, loss: 0.029647069051861763
step: 210, loss: 0.017771296203136444
step: 220, loss: 0.08490151911973953
step: 230, loss: 0.06734559684991837
step: 240, loss: 0.09608924388885498
step: 250, loss: 0.08976903557777405
step: 260, loss: 0.01986711472272873
step: 270, loss: 0.10213873535394669
step: 280, loss: 0.07661709934473038
step: 290, loss: 0.037309430539608
step: 300, loss: 0.07384159415960312
step: 310, loss: 0.027229148894548416
step: 320, loss: 0.021854756399989128
step: 330, loss: 0.005984388291835785
step: 340, loss: 0.05951958894729614
step: 350, loss: 0.029557468369603157
step: 360, loss: 0.06990879774093628
step: 370, loss: 0.017713528126478195
step: 380, loss: 0.03557282313704491
step: 390, loss: 0.05639011785387993
step: 400, loss: 0.05079767853021622
step: 410, loss: 0.07141489535570145
step: 420, loss: 0.0283768642693758
step: 430, loss: 0.0004608400631695986
step: 440, loss: 0.002399699529632926
step: 450, loss: 0.021522823721170425
step: 460, loss: 0.03022993542253971
step: 470, loss: 0.012039854191243649
step: 480, loss: 0.049840036779642105
step: 490, loss: 0.0009742486290633678
step: 500, loss: 0.040121451020240784
step: 510, loss: 0.03670043125748634
step: 520, loss: 0.07814018428325653
step: 530, loss: 0.06275109946727753
step: 540, loss: 0.04051171615719795
step: 550, loss: 0.008699123747646809
step: 560, loss: 0.0052166772074997425
step: 570, loss: 0.06608032435178757
step: 580, loss: 0.1890292912721634
step: 590, loss: 0.12309958785772324
step: 600, loss: 0.05528663843870163
step: 610, loss: 0.09377946704626083
step: 620, loss: 0.09721708297729492
step: 630, loss: 0.040054988116025925
step: 640, loss: 0.09426477551460266
step: 650, loss: 0.04401350021362305
step: 660, loss: 0.017462804913520813
step: 670, loss: 0.04978036880493164
step: 680, loss: 0.0050496445037424564
step: 690, loss: 0.00033349599107168615
step: 700, loss: 0.031063508242368698
step: 710, loss: 0.04206682741641998
step: 720, loss: 0.0490909144282341
step: 730, loss: 0.023569917306303978
step: 740, loss: 0.04226258024573326
step: 750, loss: 0.01104646548628807
step: 760, loss: 0.0074585964903235435
step: 770, loss: 0.006006091833114624
step: 780, loss: 0.014243055135011673
step: 790, loss: 0.03439118713140488
step: 800, loss: 0.1228279173374176
step: 810, loss: 0.09518910944461823
step: 820, loss: 0.04746747389435768
step: 830, loss: 0.03385290876030922
step: 840, loss: 0.052120063453912735
step: 850, loss: 0.0626811683177948
step: 860, loss: 0.07120543718338013
step: 870, loss: 0.04241026192903519
step: 880, loss: 0.039932653307914734
step: 890, loss: 0.004159489180892706
step: 900, loss: 0.0033300144132226706
step: 910, loss: 0.13430292904376984
step: 920, loss: 0.03357421234250069
step: 930, loss: 0.01779010333120823
step: 940, loss: 0.005417680833488703
step: 950, loss: 0.045210812240839005
step: 960, loss: 0.04502662271261215
step: 970, loss: 0.004750533495098352
epoch 13: dev_f1=0.938568129330254, f1=0.93646408839779, best_f1=0.9388888888888889
step: 0, loss: 0.060280196368694305
step: 10, loss: 0.0002109463675878942
step: 20, loss: 0.0880957767367363
step: 30, loss: 0.0009155269945040345
step: 40, loss: 0.049379367381334305
step: 50, loss: 0.019676826894283295
step: 60, loss: 0.027769822627305984
step: 70, loss: 0.030525919049978256
step: 80, loss: 0.05779331922531128
step: 90, loss: 0.028555113822221756
step: 100, loss: 0.002725492464378476
step: 110, loss: 0.0223781056702137
step: 120, loss: 0.013833998702466488
step: 130, loss: 0.034990593791007996
step: 140, loss: 0.0003116446314379573
step: 150, loss: 0.000388152344385162
step: 160, loss: 0.006551806349307299
step: 170, loss: 0.022120032459497452
step: 180, loss: 0.00023992120986804366
step: 190, loss: 0.04277469962835312
step: 200, loss: 0.04762760549783707
step: 210, loss: 0.05545060336589813
step: 220, loss: 0.018059175461530685
step: 230, loss: 0.030419304966926575
step: 240, loss: 0.04652298241853714
step: 250, loss: 0.004885893315076828
step: 260, loss: 0.05379408970475197
step: 270, loss: 0.05443469434976578
step: 280, loss: 0.06856545805931091
step: 290, loss: 0.02553122118115425
step: 300, loss: 0.20671606063842773
step: 310, loss: 0.0005522300489246845
step: 320, loss: 0.03121306002140045
step: 330, loss: 0.06623882055282593
step: 340, loss: 0.002656431868672371
step: 350, loss: 0.015854481607675552
step: 360, loss: 0.02250274457037449
step: 370, loss: 0.0010637755040079355
step: 380, loss: 0.06082192063331604
step: 390, loss: 0.04828380420804024
step: 400, loss: 0.07515005022287369
step: 410, loss: 0.04122842848300934
step: 420, loss: 0.00021211817511357367
step: 430, loss: 0.007017297670245171
step: 440, loss: 0.04144300892949104
step: 450, loss: 0.03929205611348152
step: 460, loss: 0.026910152286291122
step: 470, loss: 0.06483285129070282
step: 480, loss: 0.11855373531579971
step: 490, loss: 0.02764679491519928
step: 500, loss: 0.0040756287053227425
step: 510, loss: 0.029496213421225548
step: 520, loss: 0.0571470744907856
step: 530, loss: 0.026296552270650864
step: 540, loss: 0.00014523511345032603
step: 550, loss: 0.01718953438103199
step: 560, loss: 0.0359126441180706
step: 570, loss: 0.00022335565881803632
step: 580, loss: 1.2952737051818985e-05
step: 590, loss: 0.019305966794490814
step: 600, loss: 0.007915344089269638
step: 610, loss: 0.07351239025592804
step: 620, loss: 0.07812660187482834
step: 630, loss: 0.02651493065059185
step: 640, loss: 0.0027601695619523525
step: 650, loss: 0.05125194042921066
step: 660, loss: 0.01507543958723545
step: 670, loss: 0.08747904002666473
step: 680, loss: 0.12323637306690216
step: 690, loss: 0.019388098269701004
step: 700, loss: 0.014687851071357727
step: 710, loss: 0.06284603476524353
step: 720, loss: 0.016931824386119843
step: 730, loss: 0.006705218460410833
step: 740, loss: 0.023869486525654793
step: 750, loss: 0.05690497159957886
step: 760, loss: 0.0021209283731877804
step: 770, loss: 0.07334526628255844
step: 780, loss: 0.02487686648964882
step: 790, loss: 0.25762680172920227
step: 800, loss: 0.05937815085053444
step: 810, loss: 0.04282638430595398
step: 820, loss: 0.025124460458755493
step: 830, loss: 0.024790167808532715
step: 840, loss: 0.09849332273006439
step: 850, loss: 0.011427818797528744
step: 860, loss: 0.023345956578850746
step: 870, loss: 0.05152954161167145
step: 880, loss: 0.06671734154224396
step: 890, loss: 0.004997416399419308
step: 900, loss: 0.09094400703907013
step: 910, loss: 0.012721057049930096
step: 920, loss: 0.03506561741232872
step: 930, loss: 0.03272182494401932
step: 940, loss: 0.003927602432668209
step: 950, loss: 0.09647372364997864
step: 960, loss: 0.015170799568295479
step: 970, loss: 0.09201163798570633
epoch 14: dev_f1=0.9310018903591682, f1=0.9304063521718824, best_f1=0.9388888888888889
step: 0, loss: 0.016344355419278145
step: 10, loss: 0.017001768574118614
step: 20, loss: 0.022294901311397552
step: 30, loss: 0.001432769000530243
step: 40, loss: 0.027476752176880836
step: 50, loss: 0.029982034116983414
step: 60, loss: 0.024271272122859955
step: 70, loss: 0.03817487508058548
step: 80, loss: 0.09872639179229736
step: 90, loss: 0.0011303647188469768
step: 100, loss: 0.006697438657283783
step: 110, loss: 0.036835674196481705
step: 120, loss: 0.06021759659051895
step: 130, loss: 0.023073699325323105
step: 140, loss: 6.871360528748482e-05
step: 150, loss: 0.11477646231651306
step: 160, loss: 0.046501439064741135
step: 170, loss: 0.008737028576433659
step: 180, loss: 0.01001068763434887
step: 190, loss: 0.0035359368193894625
step: 200, loss: 0.035457875579595566
step: 210, loss: 0.01979941502213478
step: 220, loss: 0.028585124760866165
step: 230, loss: 0.021324945613741875
step: 240, loss: 0.05103864148259163
step: 250, loss: 0.00010201121040154248
step: 260, loss: 0.1055668443441391
step: 270, loss: 0.03860342130064964
step: 280, loss: 0.05838118866086006
step: 290, loss: 0.03826877474784851
step: 300, loss: 0.03519181162118912
step: 310, loss: 0.0004385237698443234
step: 320, loss: 0.0030505324248224497
step: 330, loss: 0.0003107164811808616
step: 340, loss: 0.02768399380147457
step: 350, loss: 0.00016424797649960965
step: 360, loss: 0.07999446243047714
step: 370, loss: 0.0033650039695203304
step: 380, loss: 0.07792981714010239
step: 390, loss: 0.06173543259501457
step: 400, loss: 0.02227007783949375
step: 410, loss: 0.006065237335860729
step: 420, loss: 0.03424450755119324
step: 430, loss: 0.010368765331804752
step: 440, loss: 0.058327287435531616
step: 450, loss: 0.03591938316822052
step: 460, loss: 0.0007536131888628006
step: 470, loss: 0.004402444697916508
step: 480, loss: 0.002016801619902253
step: 490, loss: 0.06814410537481308
step: 500, loss: 0.056552331894636154
step: 510, loss: 0.04868675768375397
step: 520, loss: 0.015389037318527699
step: 530, loss: 0.014142387546598911
step: 540, loss: 0.04407116770744324
step: 550, loss: 0.07590257376432419
step: 560, loss: 0.15881280601024628
step: 570, loss: 0.03468157723546028
step: 580, loss: 0.03860270231962204
step: 590, loss: 0.0026953089982271194
step: 600, loss: 0.0006181937060318887
step: 610, loss: 0.010351317003369331
step: 620, loss: 0.04977269098162651
step: 630, loss: 0.03161973878741264
step: 640, loss: 0.043969154357910156
step: 650, loss: 0.001456857775337994
step: 660, loss: 0.02635573223233223
step: 670, loss: 0.005110588856041431
step: 680, loss: 0.09261288493871689
step: 690, loss: 0.012683957815170288
step: 700, loss: 0.005825011059641838
step: 710, loss: 0.030443266034126282
step: 720, loss: 0.00017893766926135868
step: 730, loss: 0.06275338679552078
step: 740, loss: 0.04031296819448471
step: 750, loss: 0.03302616998553276
step: 760, loss: 0.030871108174324036
step: 770, loss: 0.02244441583752632
step: 780, loss: 0.058885060250759125
step: 790, loss: 0.013090194202959538
step: 800, loss: 0.12433888018131256
step: 810, loss: 0.04853072762489319
step: 820, loss: 0.0060108983889222145
step: 830, loss: 0.04226236045360565
step: 840, loss: 0.012360261753201485
step: 850, loss: 0.004466074053198099
step: 860, loss: 0.0255584679543972
step: 870, loss: 0.0002264103532070294
step: 880, loss: 0.06961576640605927
step: 890, loss: 0.014379329048097134
step: 900, loss: 0.041252799332141876
step: 910, loss: 0.06332281976938248
step: 920, loss: 0.028770439326763153
step: 930, loss: 0.003566617611795664
step: 940, loss: 0.01627097651362419
step: 950, loss: 0.05586094781756401
step: 960, loss: 0.02271810919046402
step: 970, loss: 0.009975002147257328
epoch 15: dev_f1=0.9387008234217749, f1=0.9321100917431193, best_f1=0.9388888888888889
step: 0, loss: 0.07219649851322174
step: 10, loss: 0.021887099370360374
step: 20, loss: 0.024421170353889465
step: 30, loss: 9.615114686312154e-05
step: 40, loss: 0.000745490484405309
step: 50, loss: 0.027142951264977455
step: 60, loss: 0.008555835112929344
step: 70, loss: 0.12286312878131866
step: 80, loss: 0.00014965176524128765
step: 90, loss: 0.019066639244556427
step: 100, loss: 0.050901446491479874
step: 110, loss: 0.029045214876532555
step: 120, loss: 0.0004822337650693953
step: 130, loss: 0.01668131723999977
step: 140, loss: 0.07472007721662521
step: 150, loss: 0.027172567322850227
step: 160, loss: 3.434802056290209e-05
step: 170, loss: 0.009564558044075966
step: 180, loss: 0.03646976500749588
step: 190, loss: 0.00012494753173086792
step: 200, loss: 0.07155655324459076
step: 210, loss: 0.018237508833408356
step: 220, loss: 0.023489978164434433
step: 230, loss: 0.04172074422240257
step: 240, loss: 0.056343067437410355
step: 250, loss: 0.005305401515215635
step: 260, loss: 0.03120032325387001
step: 270, loss: 0.023357797414064407
step: 280, loss: 0.029420293867588043
step: 290, loss: 0.02852007932960987
step: 300, loss: 0.08956395089626312
step: 310, loss: 0.05301004648208618
step: 320, loss: 0.010471842251718044
step: 330, loss: 0.06753535568714142
step: 340, loss: 0.04409625753760338
step: 350, loss: 0.008334359154105186
step: 360, loss: 0.028389081358909607
step: 370, loss: 0.025081686675548553
step: 380, loss: 0.022405285388231277
step: 390, loss: 0.019049668684601784
step: 400, loss: 0.0007222119020298123
step: 410, loss: 0.0465865358710289
step: 420, loss: 0.01826322451233864
step: 430, loss: 0.00772609980776906
step: 440, loss: 0.0002657062141224742
step: 450, loss: 0.059814952313899994
step: 460, loss: 0.021848181262612343
step: 470, loss: 0.11697911471128464
step: 480, loss: 0.053647756576538086
step: 490, loss: 0.0028731778729707003
step: 500, loss: 0.0020150295458734035
step: 510, loss: 0.036916058510541916
step: 520, loss: 0.00032030761940404773
step: 530, loss: 0.040182288736104965
step: 540, loss: 0.0678507536649704
step: 550, loss: 0.03522596135735512
step: 560, loss: 0.05310235917568207
step: 570, loss: 1.7060952814063057e-05
step: 580, loss: 0.023275848478078842
step: 590, loss: 0.06535253673791885
step: 600, loss: 0.14766913652420044
step: 610, loss: 0.023618848994374275
step: 620, loss: 0.003268279368057847
step: 630, loss: 0.023121695965528488
step: 640, loss: 0.06314578652381897
step: 650, loss: 0.04743952304124832
step: 660, loss: 0.031120991334319115
step: 670, loss: 0.02090497687458992
step: 680, loss: 0.06951867789030075
step: 690, loss: 0.041649896651506424
step: 700, loss: 0.10882098972797394
step: 710, loss: 0.06718402355909348
step: 720, loss: 0.0049383509904146194
step: 730, loss: 2.3975924705155194e-05
step: 740, loss: 0.015044738538563251
step: 750, loss: 0.029607506468892097
step: 760, loss: 0.030232669785618782
step: 770, loss: 0.036677177995443344
step: 780, loss: 0.00011654637637548149
step: 790, loss: 0.00117467378731817
step: 800, loss: 0.02024979144334793
step: 810, loss: 0.00023607449838891625
step: 820, loss: 0.02507675625383854
step: 830, loss: 0.023207273334264755
step: 840, loss: 0.0523548349738121
step: 850, loss: 0.019441578537225723
step: 860, loss: 0.020879022777080536
step: 870, loss: 0.09800637513399124
step: 880, loss: 0.02334672585129738
step: 890, loss: 0.026328211650252342
step: 900, loss: 0.0001073946405085735
step: 910, loss: 0.0004856414161622524
step: 920, loss: 0.0737372413277626
step: 930, loss: 0.05897258222103119
step: 940, loss: 0.027545811608433723
step: 950, loss: 0.03553079441189766
step: 960, loss: 0.0013563332613557577
step: 970, loss: 0.07878617197275162
epoch 16: dev_f1=0.9349930843706776, f1=0.9302752293577982, best_f1=0.9388888888888889
step: 0, loss: 0.04144936427474022
step: 10, loss: 0.007479758467525244
step: 20, loss: 0.020768404006958008
step: 30, loss: 4.7812914999667555e-05
step: 40, loss: 9.902598685584962e-05
step: 50, loss: 0.06017163768410683
step: 60, loss: 0.024128267541527748
step: 70, loss: 0.06172971427440643
step: 80, loss: 0.027213023975491524
step: 90, loss: 0.042573243379592896
step: 100, loss: 3.093010309385136e-05
step: 110, loss: 0.004201565403491259
step: 120, loss: 0.00037725374568253756
step: 130, loss: 0.021600723266601562
step: 140, loss: 0.06613253057003021
step: 150, loss: 2.2133574020699598e-05
step: 160, loss: 0.019810546189546585
step: 170, loss: 0.017946656793355942
step: 180, loss: 0.015214808285236359
step: 190, loss: 0.022549446672201157
step: 200, loss: 0.035953667014837265
step: 210, loss: 0.01952155865728855
step: 220, loss: 0.004325443413108587
step: 230, loss: 0.019351202994585037
step: 240, loss: 0.04204355552792549
step: 250, loss: 0.05564906820654869
step: 260, loss: 0.048591602593660355
step: 270, loss: 0.06300769746303558
step: 280, loss: 0.02641909196972847
step: 290, loss: 0.05635349079966545
step: 300, loss: 0.019271161407232285
step: 310, loss: 0.031736720353364944
step: 320, loss: 0.0006755173671990633
step: 330, loss: 0.020602324977517128
step: 340, loss: 0.14554458856582642
step: 350, loss: 0.013985907658934593
step: 360, loss: 0.023881204426288605
step: 370, loss: 0.04624548181891441
step: 380, loss: 0.03463102877140045
step: 390, loss: 0.05269649252295494
step: 400, loss: 0.030855689197778702
step: 410, loss: 0.013104518875479698
step: 420, loss: 0.05175381526350975
step: 430, loss: 0.02155163884162903
step: 440, loss: 0.00017779004701878875
step: 450, loss: 0.0825008898973465
step: 460, loss: 0.041496641933918
step: 470, loss: 0.00166064384393394
step: 480, loss: 0.019842790439724922
step: 490, loss: 0.0015404080040752888
step: 500, loss: 0.018959831446409225
step: 510, loss: 0.060933202505111694
step: 520, loss: 0.13002951443195343
step: 530, loss: 0.02009626105427742
step: 540, loss: 0.021105090156197548
step: 550, loss: 0.06491681188344955
step: 560, loss: 0.0009653478628024459
step: 570, loss: 0.013526201248168945
step: 580, loss: 0.02793281339108944
step: 590, loss: 0.00016809582302812487
step: 600, loss: 0.03879090026021004
step: 610, loss: 0.05666561797261238
step: 620, loss: 0.014383765868842602
step: 630, loss: 0.04696231707930565
step: 640, loss: 0.026645034551620483
step: 650, loss: 0.025557707995176315
step: 660, loss: 0.004009322728961706
step: 670, loss: 5.8275374613003805e-05
step: 680, loss: 0.03979063406586647
step: 690, loss: 5.431505269370973e-05
step: 700, loss: 0.044751595705747604
step: 710, loss: 0.019812023267149925
step: 720, loss: 2.786123877740465e-05
step: 730, loss: 0.04118582233786583
step: 740, loss: 0.047331441193819046
step: 750, loss: 0.07340104877948761
step: 760, loss: 0.02707488089799881
step: 770, loss: 0.032807040959596634
step: 780, loss: 7.267759065143764e-05
step: 790, loss: 0.02402828074991703
step: 800, loss: 0.08841854333877563
step: 810, loss: 0.09583127498626709
step: 820, loss: 7.28784580132924e-05
step: 830, loss: 0.024356823414564133
step: 840, loss: 0.035959597676992416
step: 850, loss: 0.020485486835241318
step: 860, loss: 0.023128533735871315
step: 870, loss: 0.006087791174650192
step: 880, loss: 3.105357609456405e-05
step: 890, loss: 0.03814835101366043
step: 900, loss: 0.03781348466873169
step: 910, loss: 0.018025854602456093
step: 920, loss: 0.06746523082256317
step: 930, loss: 0.05738339200615883
step: 940, loss: 0.030689124017953873
step: 950, loss: 0.10693326592445374
step: 960, loss: 8.240308488893788e-06
step: 970, loss: 0.021321002393960953
epoch 17: dev_f1=0.9330232558139535, f1=0.9335180055401663, best_f1=0.9388888888888889
step: 0, loss: 0.05126628652215004
step: 10, loss: 1.056855580827687e-05
step: 20, loss: 0.07984264194965363
step: 30, loss: 5.246413638815284e-05
step: 40, loss: 0.030706683173775673
step: 50, loss: 0.055911920964717865
step: 60, loss: 8.096156670944765e-05
step: 70, loss: 2.8467760785133578e-05
step: 80, loss: 0.01692936010658741
step: 90, loss: 0.018544768914580345
step: 100, loss: 0.04346022754907608
step: 110, loss: 0.016439052298665047
step: 120, loss: 0.00026144375442527235
step: 130, loss: 0.016223281621932983
step: 140, loss: 0.055789586156606674
step: 150, loss: 0.01757754012942314
step: 160, loss: 0.020312778651714325
step: 170, loss: 2.519469489925541e-05
step: 180, loss: 0.02299189381301403
step: 190, loss: 0.023090068250894547
step: 200, loss: 0.0018055972177535295
step: 210, loss: 6.756135553587228e-05
step: 220, loss: 0.024080876260995865
step: 230, loss: 0.029582854360342026
step: 240, loss: 0.02101385034620762
step: 250, loss: 0.04392054304480553
step: 260, loss: 0.012537585571408272
step: 270, loss: 0.03490104526281357
step: 280, loss: 0.02329408749938011
step: 290, loss: 4.436183735379018e-05
step: 300, loss: 0.02676781825721264
step: 310, loss: 0.02194567769765854
step: 320, loss: 2.3977801902219653e-05
step: 330, loss: 0.031821027398109436
step: 340, loss: 0.024314409121870995
step: 350, loss: 0.005119286943227053
step: 360, loss: 0.05078169330954552
step: 370, loss: 0.026985423639416695
step: 380, loss: 0.017259884625673294
step: 390, loss: 0.000884593406226486
step: 400, loss: 0.0008115359814837575
step: 410, loss: 0.05154109746217728
step: 420, loss: 6.003698581480421e-05
step: 430, loss: 0.000321966566843912
step: 440, loss: 0.029818406328558922
step: 450, loss: 0.028883187100291252
step: 460, loss: 2.7404823413235135e-05
step: 470, loss: 0.011242274194955826
step: 480, loss: 0.06185592710971832
step: 490, loss: 0.0503593273460865
step: 500, loss: 5.8942416217178106e-05
step: 510, loss: 0.001103117479942739
step: 520, loss: 0.0742039605975151
step: 530, loss: 0.027684293687343597
step: 540, loss: 0.0336630716919899
step: 550, loss: 0.0020460954401642084
step: 560, loss: 0.01907573826611042
step: 570, loss: 0.003517796518281102
step: 580, loss: 0.06090548262000084
step: 590, loss: 0.04370691254734993
step: 600, loss: 9.670794497651514e-06
step: 610, loss: 0.001934416824951768
step: 620, loss: 0.03497835248708725
step: 630, loss: 0.0003950097889173776
step: 640, loss: 0.037788983434438705
step: 650, loss: 0.02789214998483658
step: 660, loss: 0.018438003957271576
step: 670, loss: 0.015716293826699257
step: 680, loss: 0.027289699763059616
step: 690, loss: 0.001792740891687572
step: 700, loss: 0.014629537239670753
step: 710, loss: 0.03679318726062775
step: 720, loss: 0.06025661155581474
step: 730, loss: 0.03186355158686638
step: 740, loss: 0.016578972339630127
step: 750, loss: 0.11668367683887482
step: 760, loss: 0.025093553587794304
step: 770, loss: 0.03785531967878342
step: 780, loss: 0.07812974601984024
step: 790, loss: 0.05245726555585861
step: 800, loss: 9.701302042230964e-05
step: 810, loss: 0.027560584247112274
step: 820, loss: 0.06665506213903427
step: 830, loss: 0.016209660097956657
step: 840, loss: 0.05244708061218262
step: 850, loss: 0.02413128688931465
step: 860, loss: 0.0012617799220606685
step: 870, loss: 0.04859449714422226
step: 880, loss: 0.05459804832935333
step: 890, loss: 0.003394434228539467
step: 900, loss: 0.00016249755572061986
step: 910, loss: 0.01717539131641388
step: 920, loss: 0.03903746232390404
step: 930, loss: 0.07280927896499634
step: 940, loss: 0.0006133270217105746
step: 950, loss: 0.03839453309774399
step: 960, loss: 0.027110235765576363
step: 970, loss: 0.03712433576583862
epoch 18: dev_f1=0.9347111319868483, f1=0.9332096474953617, best_f1=0.9388888888888889
step: 0, loss: 0.08783906698226929
step: 10, loss: 0.03705587238073349
step: 20, loss: 0.1312260925769806
step: 30, loss: 0.01968294009566307
step: 40, loss: 0.04583771154284477
step: 50, loss: 0.0626540333032608
step: 60, loss: 0.06575152277946472
step: 70, loss: 0.00014602545707020909
step: 80, loss: 0.030299706384539604
step: 90, loss: 0.029751650989055634
step: 100, loss: 0.03872820362448692
step: 110, loss: 0.07699574530124664
step: 120, loss: 0.05782695859670639
step: 130, loss: 2.6212253942503594e-05
step: 140, loss: 0.0257231704890728
step: 150, loss: 0.023076802492141724
step: 160, loss: 2.8804084649891593e-05
step: 170, loss: 0.03132733702659607
step: 180, loss: 0.01938096061348915
step: 190, loss: 0.00016164290718734264
step: 200, loss: 0.0001278738782275468
step: 210, loss: 0.02940002642571926
step: 220, loss: 0.04303932934999466
step: 230, loss: 0.04918164387345314
step: 240, loss: 0.061458420008420944
step: 250, loss: 0.028429469093680382
step: 260, loss: 8.761844583204947e-06
step: 270, loss: 0.023032978177070618
step: 280, loss: 0.03017484024167061
step: 290, loss: 0.022890832275152206
step: 300, loss: 0.0031654376070946455
step: 310, loss: 0.0006596317398361862
step: 320, loss: 0.029254194349050522
step: 330, loss: 0.002084193518385291
step: 340, loss: 7.68455138313584e-05
step: 350, loss: 0.021381601691246033
step: 360, loss: 2.750728526734747e-05
step: 370, loss: 0.06629504263401031
step: 380, loss: 0.018677903339266777
step: 390, loss: 0.025912882760167122
step: 400, loss: 0.10405283421278
step: 410, loss: 0.03064877912402153
step: 420, loss: 2.497207788110245e-05
step: 430, loss: 0.09499425441026688
step: 440, loss: 0.0719844400882721
step: 450, loss: 0.024358827620744705
step: 460, loss: 0.002242388902232051
step: 470, loss: 0.0002296840975759551
step: 480, loss: 0.03945230320096016
step: 490, loss: 1.1335930139466655e-05
step: 500, loss: 0.05318383872509003
step: 510, loss: 3.630105493357405e-05
step: 520, loss: 0.02551303431391716
step: 530, loss: 0.053184639662504196
step: 540, loss: 0.08985652774572372
step: 550, loss: 0.08750348538160324
step: 560, loss: 0.001274641021154821
step: 570, loss: 2.8665215722867288e-05
step: 580, loss: 0.032862525433301926
step: 590, loss: 0.02752302587032318
step: 600, loss: 0.000778541958425194
step: 610, loss: 5.869984670425765e-05
step: 620, loss: 0.07593265175819397
step: 630, loss: 0.06261970847845078
step: 640, loss: 0.017253242433071136
step: 650, loss: 0.0273651871830225
step: 660, loss: 0.034966763108968735
step: 670, loss: 0.052548784762620926
step: 680, loss: 0.04170597344636917
step: 690, loss: 0.03291209042072296
step: 700, loss: 0.008941315114498138
step: 710, loss: 0.0249604694545269
step: 720, loss: 0.06741738319396973
step: 730, loss: 0.049953609704971313
step: 740, loss: 0.04602693021297455
step: 750, loss: 0.0017567496979609132
step: 760, loss: 0.023486506193876266
step: 770, loss: 0.04097810760140419
step: 780, loss: 0.0007510539726354182
step: 790, loss: 0.03217067942023277
step: 800, loss: 0.03867579251527786
step: 810, loss: 0.050633423030376434
step: 820, loss: 5.1291957788635045e-05
step: 830, loss: 0.0016600453527644277
step: 840, loss: 0.020493105053901672
step: 850, loss: 0.09308626502752304
step: 860, loss: 0.00024738290812820196
step: 870, loss: 0.038658492267131805
step: 880, loss: 0.026677602902054787
step: 890, loss: 0.04065443202853203
step: 900, loss: 0.07384389638900757
step: 910, loss: 0.03495479375123978
step: 920, loss: 0.0325116403400898
step: 930, loss: 0.03947097063064575
step: 940, loss: 0.0671973004937172
step: 950, loss: 0.001769617316313088
step: 960, loss: 1.1756903404602781e-05
step: 970, loss: 0.057980991899967194
epoch 19: dev_f1=0.9357109338338808, f1=0.9345707656612529, best_f1=0.9388888888888889
step: 0, loss: 9.551148832542822e-05
step: 10, loss: 0.022272445261478424
step: 20, loss: 2.299353582202457e-05
step: 30, loss: 0.05566466599702835
step: 40, loss: 0.025009844452142715
step: 50, loss: 0.1764615774154663
step: 60, loss: 0.05888255313038826
step: 70, loss: 0.0408865325152874
step: 80, loss: 3.790837217820808e-05
step: 90, loss: 0.03669022023677826
step: 100, loss: 0.0321337953209877
step: 110, loss: 0.09210141003131866
step: 120, loss: 0.017686769366264343
step: 130, loss: 0.029485201463103294
step: 140, loss: 0.00042976118857041
step: 150, loss: 0.0194076094776392
step: 160, loss: 0.0005339147173799574
step: 170, loss: 6.927266804268584e-05
step: 180, loss: 0.06604665517807007
step: 190, loss: 0.031379759311676025
step: 200, loss: 0.044920407235622406
step: 210, loss: 3.199644561391324e-05
step: 220, loss: 0.024210751056671143
step: 230, loss: 0.04413948208093643
step: 240, loss: 0.020707348361611366
step: 250, loss: 0.026874516159296036
step: 260, loss: 0.019297149032354355
step: 270, loss: 0.039213404059410095
step: 280, loss: 0.018725519999861717
step: 290, loss: 0.03719392418861389
step: 300, loss: 0.042545169591903687
step: 310, loss: 0.035374514758586884
step: 320, loss: 0.024181311950087547
step: 330, loss: 0.00043281877879053354
step: 340, loss: 0.0791073590517044
step: 350, loss: 0.04743202403187752
step: 360, loss: 0.031248776242136955
step: 370, loss: 0.06200117617845535
step: 380, loss: 0.0004369350499473512
step: 390, loss: 4.6596989704994485e-05
step: 400, loss: 0.016031144186854362
step: 410, loss: 0.026349011808633804
step: 420, loss: 0.0003178324841428548
step: 430, loss: 0.02850443683564663
step: 440, loss: 0.01353291142731905
step: 450, loss: 0.027365196496248245
step: 460, loss: 0.044573307037353516
step: 470, loss: 0.011604594998061657
step: 480, loss: 0.08228868991136551
step: 490, loss: 0.04117152467370033
step: 500, loss: 0.0426856204867363
step: 510, loss: 0.017581159248948097
step: 520, loss: 0.028275392949581146
step: 530, loss: 6.239805952645838e-05
step: 540, loss: 0.010118147358298302
step: 550, loss: 0.017501255497336388
step: 560, loss: 0.022523539140820503
step: 570, loss: 0.00018577452283352613
step: 580, loss: 0.02146594226360321
step: 590, loss: 0.024160156026482582
step: 600, loss: 0.0007119262008927763
step: 610, loss: 0.02182324044406414
step: 620, loss: 0.06683798879384995
step: 630, loss: 0.0009322240948677063
step: 640, loss: 0.025739893317222595
step: 650, loss: 0.0005959430709481239
step: 660, loss: 5.264159699436277e-05
step: 670, loss: 0.009584198705852032
step: 680, loss: 0.0001277815899811685
step: 690, loss: 1.559359225211665e-05
step: 700, loss: 0.05620266869664192
step: 710, loss: 0.026038803160190582
step: 720, loss: 6.000718713039532e-05
step: 730, loss: 5.2213559683877975e-05
step: 740, loss: 0.05097991228103638
step: 750, loss: 6.080308958189562e-05
step: 760, loss: 0.00944899208843708
step: 770, loss: 0.00018761801766231656
step: 780, loss: 0.006104514468461275
step: 790, loss: 0.014023570343852043
step: 800, loss: 0.03850899264216423
step: 810, loss: 0.08661238849163055
step: 820, loss: 0.042820367962121964
step: 830, loss: 1.9091434296569787e-05
step: 840, loss: 4.909491690341383e-05
step: 850, loss: 0.002736148424446583
step: 860, loss: 0.016166096553206444
step: 870, loss: 0.012565766461193562
step: 880, loss: 0.00225340249016881
step: 890, loss: 0.027978183701634407
step: 900, loss: 0.02573419362306595
step: 910, loss: 0.03783879801630974
step: 920, loss: 0.0603177510201931
step: 930, loss: 0.12301507592201233
step: 940, loss: 0.051863230764865875
step: 950, loss: 0.07194999605417252
step: 960, loss: 0.020841948688030243
step: 970, loss: 0.0032839816994965076
epoch 20: dev_f1=0.936269915651359, f1=0.9353788935378894, best_f1=0.9388888888888889
