cuda
Device: cuda
step: 0, loss: 0.6161190271377563
step: 10, loss: 0.23898674547672272
step: 20, loss: 0.23579876124858856
step: 30, loss: 0.43349188566207886
step: 40, loss: 0.22556693851947784
step: 50, loss: 0.21851982176303864
step: 60, loss: 0.10771216452121735
step: 70, loss: 0.19304557144641876
step: 80, loss: 0.23686982691287994
step: 90, loss: 0.09723423421382904
step: 100, loss: 0.42824122309684753
step: 110, loss: 0.16434942185878754
step: 120, loss: 0.20968785881996155
step: 130, loss: 0.1166754886507988
step: 140, loss: 0.15246334671974182
step: 150, loss: 0.0953013077378273
step: 160, loss: 0.09334967285394669
step: 170, loss: 0.03563812002539635
step: 180, loss: 0.15624785423278809
step: 190, loss: 0.17551985383033752
step: 200, loss: 0.12802644073963165
step: 210, loss: 0.12920960783958435
step: 220, loss: 0.1527433544397354
step: 230, loss: 0.09893795847892761
step: 240, loss: 0.1808982789516449
step: 250, loss: 0.4007762670516968
step: 260, loss: 0.1130388081073761
step: 270, loss: 0.1675264537334442
step: 280, loss: 0.15568013489246368
step: 290, loss: 0.15372729301452637
step: 300, loss: 0.2793494164943695
step: 310, loss: 0.23828724026679993
step: 320, loss: 0.14304347336292267
step: 330, loss: 0.1504794955253601
step: 340, loss: 0.1181093156337738
step: 350, loss: 0.12249688804149628
step: 360, loss: 0.055299680680036545
step: 370, loss: 0.13096177577972412
step: 380, loss: 0.09232810884714127
step: 390, loss: 0.0010604846756905317
step: 400, loss: 0.1280992031097412
step: 410, loss: 0.21045105159282684
step: 420, loss: 0.08204209804534912
step: 430, loss: 0.27355825901031494
step: 440, loss: 0.01817895844578743
step: 450, loss: 0.11181535571813583
step: 460, loss: 0.08765040338039398
step: 470, loss: 0.0709570050239563
step: 480, loss: 0.09639056771993637
step: 490, loss: 0.18930260837078094
step: 500, loss: 0.17739392817020416
step: 510, loss: 0.08462928235530853
step: 520, loss: 0.06264770776033401
step: 530, loss: 0.020657887682318687
step: 540, loss: 0.12572970986366272
step: 550, loss: 0.10303647071123123
step: 560, loss: 0.18046842515468597
step: 570, loss: 0.13556969165802002
step: 580, loss: 0.15800057351589203
step: 590, loss: 0.07111185789108276
step: 600, loss: 0.07581525295972824
step: 610, loss: 0.06566217541694641
step: 620, loss: 0.10598098486661911
step: 630, loss: 0.12499110400676727
step: 640, loss: 0.10643820464611053
step: 650, loss: 0.15153586864471436
step: 660, loss: 0.2633648216724396
step: 670, loss: 0.0821518525481224
step: 680, loss: 0.11061818897724152
step: 690, loss: 0.05822936072945595
step: 700, loss: 0.13754217326641083
step: 710, loss: 0.20957137644290924
step: 720, loss: 0.17962293326854706
step: 730, loss: 0.08127041906118393
step: 740, loss: 0.08436720818281174
step: 750, loss: 0.09234051406383514
step: 760, loss: 0.07022731006145477
step: 770, loss: 0.24670423567295074
step: 780, loss: 0.23524369299411774
step: 790, loss: 0.03987859934568405
step: 800, loss: 0.05015866085886955
step: 810, loss: 0.09169094264507294
step: 820, loss: 0.16367042064666748
step: 830, loss: 0.1950874626636505
step: 840, loss: 0.13141468167304993
step: 850, loss: 0.39384427666664124
step: 860, loss: 0.1919848620891571
step: 870, loss: 0.06896843761205673
step: 880, loss: 0.14891022443771362
step: 890, loss: 0.05595756322145462
step: 900, loss: 0.06625959277153015
step: 910, loss: 0.022078199312090874
step: 920, loss: 0.08006075769662857
step: 930, loss: 0.18732228875160217
step: 940, loss: 0.10469668358564377
step: 950, loss: 0.052678294479846954
step: 960, loss: 0.09978558868169785
step: 970, loss: 0.10367786884307861
epoch 1: dev_f1=0.925536774783006, f1=0.9290263876251137, best_f1=0.9290263876251137
step: 0, loss: 0.0786442756652832
step: 10, loss: 0.04823632538318634
step: 20, loss: 0.01787768304347992
step: 30, loss: 0.2634675204753876
step: 40, loss: 0.06871122866868973
step: 50, loss: 0.36073940992355347
step: 60, loss: 0.07315357774496078
step: 70, loss: 0.05622022598981857
step: 80, loss: 0.15009386837482452
step: 90, loss: 0.32663434743881226
step: 100, loss: 0.10642191767692566
step: 110, loss: 0.0651441439986229
step: 120, loss: 0.09882420301437378
step: 130, loss: 0.03185131773352623
step: 140, loss: 0.08524780720472336
step: 150, loss: 0.19364048540592194
step: 160, loss: 0.43904486298561096
step: 170, loss: 0.031045671552419662
step: 180, loss: 0.12467443197965622
step: 190, loss: 0.02489776350557804
step: 200, loss: 0.1420230269432068
step: 210, loss: 0.04338781163096428
step: 220, loss: 0.1279069185256958
step: 230, loss: 0.04828681796789169
step: 240, loss: 0.02974604442715645
step: 250, loss: 0.022610969841480255
step: 260, loss: 0.05156181380152702
step: 270, loss: 0.13127925992012024
step: 280, loss: 0.2978821396827698
step: 290, loss: 0.03739373758435249
step: 300, loss: 0.056371089071035385
step: 310, loss: 0.0734454095363617
step: 320, loss: 0.0842251405119896
step: 330, loss: 0.09847686439752579
step: 340, loss: 0.1097223162651062
step: 350, loss: 0.05369846150279045
step: 360, loss: 0.05939722806215286
step: 370, loss: 0.106987863779068
step: 380, loss: 0.03601623326539993
step: 390, loss: 0.14494246244430542
step: 400, loss: 0.019827306270599365
step: 410, loss: 0.020334236323833466
step: 420, loss: 0.1387440413236618
step: 430, loss: 0.05409051105380058
step: 440, loss: 0.03159095719456673
step: 450, loss: 0.1760595589876175
step: 460, loss: 0.016256878152489662
step: 470, loss: 0.016415443271398544
step: 480, loss: 0.07147698104381561
step: 490, loss: 0.10335074365139008
step: 500, loss: 0.059373266994953156
step: 510, loss: 0.10477298498153687
step: 520, loss: 0.0738803818821907
step: 530, loss: 0.07918674498796463
step: 540, loss: 0.06652304530143738
step: 550, loss: 0.18774782121181488
step: 560, loss: 0.09249015152454376
step: 570, loss: 0.17993877828121185
step: 580, loss: 0.1768881380558014
step: 590, loss: 0.19642749428749084
step: 600, loss: 0.18875053524971008
step: 610, loss: 0.06926267594099045
step: 620, loss: 0.07423070073127747
step: 630, loss: 0.15626470744609833
step: 640, loss: 0.05908432602882385
step: 650, loss: 0.02316867932677269
step: 660, loss: 0.11125379800796509
step: 670, loss: 0.05622154101729393
step: 680, loss: 0.11043630540370941
step: 690, loss: 0.20356152951717377
step: 700, loss: 0.09472090005874634
step: 710, loss: 0.10678932815790176
step: 720, loss: 0.13976901769638062
step: 730, loss: 0.0834348127245903
step: 740, loss: 0.09046861529350281
step: 750, loss: 0.03005041740834713
step: 760, loss: 0.020654160529375076
step: 770, loss: 0.1684214323759079
step: 780, loss: 0.06329545378684998
step: 790, loss: 0.09347044676542282
step: 800, loss: 0.0576508566737175
step: 810, loss: 0.02194041945040226
step: 820, loss: 0.07936621457338333
step: 830, loss: 0.18854978680610657
step: 840, loss: 0.06516236066818237
step: 850, loss: 0.01096999179571867
step: 860, loss: 0.05703617259860039
step: 870, loss: 0.0821438878774643
step: 880, loss: 0.2357024997472763
step: 890, loss: 0.03732761740684509
step: 900, loss: 0.05439555272459984
step: 910, loss: 0.10955353081226349
step: 920, loss: 0.10100537538528442
step: 930, loss: 0.05938998982310295
step: 940, loss: 0.0440550372004509
step: 950, loss: 0.05812985077500343
step: 960, loss: 0.0337924100458622
step: 970, loss: 0.055672865360975266
epoch 2: dev_f1=0.9443938012762079, f1=0.9423513390830685, best_f1=0.9423513390830685
step: 0, loss: 0.04586266726255417
step: 10, loss: 0.07998339831829071
step: 20, loss: 0.09596972912549973
step: 30, loss: 0.26984691619873047
step: 40, loss: 0.08282396197319031
step: 50, loss: 0.0904025211930275
step: 60, loss: 0.1527445912361145
step: 70, loss: 0.10738059133291245
step: 80, loss: 0.2877763509750366
step: 90, loss: 0.05493282899260521
step: 100, loss: 0.04212960973381996
step: 110, loss: 0.03665495663881302
step: 120, loss: 0.07652400434017181
step: 130, loss: 0.028007477521896362
step: 140, loss: 0.07326625287532806
step: 150, loss: 0.08672326803207397
step: 160, loss: 0.0896507054567337
step: 170, loss: 0.18551692366600037
step: 180, loss: 0.047245439141988754
step: 190, loss: 0.0314759686589241
step: 200, loss: 0.03226393833756447
step: 210, loss: 0.02964993566274643
step: 220, loss: 0.06367495656013489
step: 230, loss: 0.06556061655282974
step: 240, loss: 0.1265132874250412
step: 250, loss: 0.09351158142089844
step: 260, loss: 0.05067269876599312
step: 270, loss: 0.0147048719227314
step: 280, loss: 0.1376030594110489
step: 290, loss: 0.06371315568685532
step: 300, loss: 0.018579790368676186
step: 310, loss: 0.09648562222719193
step: 320, loss: 0.1150091215968132
step: 330, loss: 0.07378557324409485
step: 340, loss: 0.03467411547899246
step: 350, loss: 0.2769434154033661
step: 360, loss: 0.05111027508974075
step: 370, loss: 0.0778127983212471
step: 380, loss: 0.10117395967245102
step: 390, loss: 0.16495084762573242
step: 400, loss: 0.08122889697551727
step: 410, loss: 0.12066623568534851
step: 420, loss: 0.07094122469425201
step: 430, loss: 0.07557830959558487
step: 440, loss: 0.15042352676391602
step: 450, loss: 0.0504932776093483
step: 460, loss: 0.0055289482697844505
step: 470, loss: 0.013169619254767895
step: 480, loss: 0.006052600219845772
step: 490, loss: 0.09068020433187485
step: 500, loss: 0.10769373923540115
step: 510, loss: 0.027621792629361153
step: 520, loss: 0.04050418362021446
step: 530, loss: 0.03611801564693451
step: 540, loss: 0.18891218304634094
step: 550, loss: 0.1300469934940338
step: 560, loss: 0.07137826085090637
step: 570, loss: 0.024532021954655647
step: 580, loss: 0.0721384584903717
step: 590, loss: 0.09388154000043869
step: 600, loss: 0.16066958010196686
step: 610, loss: 0.06733821332454681
step: 620, loss: 0.07115939259529114
step: 630, loss: 0.07261716574430466
step: 640, loss: 0.1391238421201706
step: 650, loss: 0.10431528091430664
step: 660, loss: 0.1498124748468399
step: 670, loss: 0.12668831646442413
step: 680, loss: 0.020324941724538803
step: 690, loss: 0.012385498732328415
step: 700, loss: 0.09721258282661438
step: 710, loss: 0.023111464455723763
step: 720, loss: 0.03063293918967247
step: 730, loss: 0.03549791872501373
step: 740, loss: 0.1505667269229889
step: 750, loss: 0.08177810162305832
step: 760, loss: 0.0801197811961174
step: 770, loss: 0.11516395956277847
step: 780, loss: 0.09282569587230682
step: 790, loss: 0.09364765137434006
step: 800, loss: 0.0844634473323822
step: 810, loss: 0.026051241904497147
step: 820, loss: 0.011876082047820091
step: 830, loss: 0.04327335208654404
step: 840, loss: 0.07986997067928314
step: 850, loss: 0.08216076344251633
step: 860, loss: 0.09988152235746384
step: 870, loss: 0.1252848207950592
step: 880, loss: 0.02541523240506649
step: 890, loss: 0.18172243237495422
step: 900, loss: 0.2863749563694
step: 910, loss: 0.04061020910739899
step: 920, loss: 0.028568997979164124
step: 930, loss: 0.019481251016259193
step: 940, loss: 0.08858855068683624
step: 950, loss: 0.0343862809240818
step: 960, loss: 0.31655827164649963
step: 970, loss: 0.07323271036148071
epoch 3: dev_f1=0.9371069182389937, f1=0.9355565570076612, best_f1=0.9423513390830685
step: 0, loss: 0.06485529243946075
step: 10, loss: 0.04404182359576225
step: 20, loss: 0.04817863553762436
step: 30, loss: 0.08832772821187973
step: 40, loss: 0.08792290836572647
step: 50, loss: 0.061228081583976746
step: 60, loss: 0.08565087616443634
step: 70, loss: 0.03246147930622101
step: 80, loss: 0.09145375341176987
step: 90, loss: 0.017979515716433525
step: 100, loss: 0.005452531389892101
step: 110, loss: 0.01863163709640503
step: 120, loss: 0.13360823690891266
step: 130, loss: 0.13181445002555847
step: 140, loss: 0.09026332199573517
step: 150, loss: 0.026863746345043182
step: 160, loss: 0.11812747269868851
step: 170, loss: 0.005166796036064625
step: 180, loss: 0.06434057652950287
step: 190, loss: 0.021055977791547775
step: 200, loss: 0.03190736845135689
step: 210, loss: 0.06705982983112335
step: 220, loss: 0.08158478885889053
step: 230, loss: 0.03121970221400261
step: 240, loss: 0.014204168692231178
step: 250, loss: 0.038359541445970535
step: 260, loss: 0.051066406071186066
step: 270, loss: 0.011601868085563183
step: 280, loss: 0.3128221035003662
step: 290, loss: 0.0353742353618145
step: 300, loss: 0.1958152949810028
step: 310, loss: 0.030918387696146965
step: 320, loss: 0.08518608659505844
step: 330, loss: 0.06843400001525879
step: 340, loss: 0.06979259848594666
step: 350, loss: 0.023140422999858856
step: 360, loss: 0.1214190125465393
step: 370, loss: 0.04860062152147293
step: 380, loss: 0.028312508016824722
step: 390, loss: 0.024879880249500275
step: 400, loss: 0.01657664217054844
step: 410, loss: 0.01269066147506237
step: 420, loss: 0.15184009075164795
step: 430, loss: 0.28232812881469727
step: 440, loss: 0.1020171046257019
step: 450, loss: 0.12791647017002106
step: 460, loss: 0.011465482413768768
step: 470, loss: 0.07941364496946335
step: 480, loss: 0.048753418028354645
step: 490, loss: 0.04762206971645355
step: 500, loss: 0.0825013518333435
step: 510, loss: 0.0449356734752655
step: 520, loss: 0.08509346097707748
step: 530, loss: 0.054138462990522385
step: 540, loss: 0.026893332600593567
step: 550, loss: 0.014701747335493565
step: 560, loss: 0.09843659400939941
step: 570, loss: 0.10873451083898544
step: 580, loss: 0.04393204674124718
step: 590, loss: 0.08439546823501587
step: 600, loss: 0.10229861736297607
step: 610, loss: 0.036638278514146805
step: 620, loss: 0.06922347843647003
step: 630, loss: 0.09088478982448578
step: 640, loss: 0.03466477990150452
step: 650, loss: 0.025620583444833755
step: 660, loss: 0.03935857489705086
step: 670, loss: 0.14103664457798004
step: 680, loss: 0.05677684396505356
step: 690, loss: 0.05639259144663811
step: 700, loss: 0.0648779347538948
step: 710, loss: 0.15752878785133362
step: 720, loss: 0.21490079164505005
step: 730, loss: 0.02792980894446373
step: 740, loss: 0.036341216415166855
step: 750, loss: 0.07475630193948746
step: 760, loss: 0.03705797344446182
step: 770, loss: 0.02814589999616146
step: 780, loss: 0.13717377185821533
step: 790, loss: 0.08213219046592712
step: 800, loss: 0.1513870358467102
step: 810, loss: 0.16101911664009094
step: 820, loss: 0.0665585994720459
step: 830, loss: 0.0365058071911335
step: 840, loss: 0.04419803246855736
step: 850, loss: 0.08492731302976608
step: 860, loss: 0.00019134554895572364
step: 870, loss: 0.028206413611769676
step: 880, loss: 0.06106449291110039
step: 890, loss: 0.10296376794576645
step: 900, loss: 0.04039539769291878
step: 910, loss: 0.05857410281896591
step: 920, loss: 0.12370894849300385
step: 930, loss: 0.04567720368504524
step: 940, loss: 0.08806732296943665
step: 950, loss: 0.1628737449645996
step: 960, loss: 0.043617404997348785
step: 970, loss: 0.02911033108830452
epoch 4: dev_f1=0.9338235294117647, f1=0.9291628334866605, best_f1=0.9423513390830685
step: 0, loss: 0.09673058241605759
step: 10, loss: 0.0510178878903389
step: 20, loss: 0.1355138123035431
step: 30, loss: 0.10210563987493515
step: 40, loss: 0.03801804035902023
step: 50, loss: 0.03259598836302757
step: 60, loss: 0.027788108214735985
step: 70, loss: 0.1732417196035385
step: 80, loss: 0.021817591041326523
step: 90, loss: 0.017949644476175308
step: 100, loss: 0.022019684314727783
step: 110, loss: 0.05356059595942497
step: 120, loss: 0.1173522025346756
step: 130, loss: 0.03465801477432251
step: 140, loss: 0.08486087620258331
step: 150, loss: 0.15544594824314117
step: 160, loss: 0.09212556481361389
step: 170, loss: 0.09785871207714081
step: 180, loss: 0.10384780168533325
step: 190, loss: 0.02761632762849331
step: 200, loss: 0.018051661550998688
step: 210, loss: 0.11912180483341217
step: 220, loss: 0.018259044736623764
step: 230, loss: 0.021963289007544518
step: 240, loss: 0.09842515736818314
step: 250, loss: 0.014215760864317417
step: 260, loss: 0.0010139381047338247
step: 270, loss: 0.07950141280889511
step: 280, loss: 0.06792928278446198
step: 290, loss: 0.11332359164953232
step: 300, loss: 0.13477404415607452
step: 310, loss: 0.07268071919679642
step: 320, loss: 0.08002270758152008
step: 330, loss: 0.10198583453893661
step: 340, loss: 0.029142145067453384
step: 350, loss: 0.09783566743135452
step: 360, loss: 0.05576642230153084
step: 370, loss: 0.08371029794216156
step: 380, loss: 0.03237117826938629
step: 390, loss: 0.08972162753343582
step: 400, loss: 0.06408865004777908
step: 410, loss: 0.2154342532157898
step: 420, loss: 0.1393551379442215
step: 430, loss: 0.03714940696954727
step: 440, loss: 0.1027761921286583
step: 450, loss: 0.05638884752988815
step: 460, loss: 0.02911706082522869
step: 470, loss: 0.09602921456098557
step: 480, loss: 0.117598757147789
step: 490, loss: 0.07504121959209442
step: 500, loss: 0.060254573822021484
step: 510, loss: 0.07601004838943481
step: 520, loss: 0.08429508656263351
step: 530, loss: 0.13316279649734497
step: 540, loss: 0.17196926474571228
step: 550, loss: 0.1423862874507904
step: 560, loss: 0.18004417419433594
step: 570, loss: 0.0986071228981018
step: 580, loss: 0.13724379241466522
step: 590, loss: 0.028448456898331642
step: 600, loss: 0.0803242102265358
step: 610, loss: 0.04788341745734215
step: 620, loss: 0.03940068557858467
step: 630, loss: 0.07981661707162857
step: 640, loss: 0.07995651662349701
step: 650, loss: 0.07231399416923523
step: 660, loss: 0.3438085615634918
step: 670, loss: 0.019958242774009705
step: 680, loss: 0.026154203340411186
step: 690, loss: 0.007764612790197134
step: 700, loss: 0.03413991630077362
step: 710, loss: 0.046124428510665894
step: 720, loss: 0.04671107977628708
step: 730, loss: 0.00759448017925024
step: 740, loss: 0.11627744883298874
step: 750, loss: 0.006819901522248983
step: 760, loss: 0.08459001779556274
step: 770, loss: 0.06571204215288162
step: 780, loss: 0.09307156503200531
step: 790, loss: 0.09785804897546768
step: 800, loss: 0.12636852264404297
step: 810, loss: 0.12117153406143188
step: 820, loss: 0.04462004825472832
step: 830, loss: 0.09689375013113022
step: 840, loss: 0.06163310259580612
step: 850, loss: 0.1310039460659027
step: 860, loss: 0.15527209639549255
step: 870, loss: 0.03351777419447899
step: 880, loss: 0.06817398220300674
step: 890, loss: 0.03878549486398697
step: 900, loss: 0.1542496383190155
step: 910, loss: 0.10555002838373184
step: 920, loss: 0.03393954038619995
step: 930, loss: 0.010223722085356712
step: 940, loss: 0.053343553096055984
step: 950, loss: 0.06218566372990608
step: 960, loss: 0.028295394033193588
step: 970, loss: 0.1653931438922882
epoch 5: dev_f1=0.9407474931631724, f1=0.9330296127562643, best_f1=0.9423513390830685
step: 0, loss: 0.020956898108124733
step: 10, loss: 0.1488504409790039
step: 20, loss: 0.09025481343269348
step: 30, loss: 0.08545893430709839
step: 40, loss: 0.07744915783405304
step: 50, loss: 0.025147538632154465
step: 60, loss: 0.06791695207357407
step: 70, loss: 0.003723612055182457
step: 80, loss: 0.027805062010884285
step: 90, loss: 0.03046366386115551
step: 100, loss: 0.05802076309919357
step: 110, loss: 0.08421287685632706
step: 120, loss: 0.04301973059773445
step: 130, loss: 0.02170749008655548
step: 140, loss: 0.00041807832894846797
step: 150, loss: 0.11129536479711533
step: 160, loss: 0.03908649832010269
step: 170, loss: 0.005191745702177286
step: 180, loss: 0.08474035561084747
step: 190, loss: 0.06887359917163849
step: 200, loss: 0.04840991646051407
step: 210, loss: 0.03484613075852394
step: 220, loss: 0.041334617882966995
step: 230, loss: 0.06530589610338211
step: 240, loss: 0.10238409042358398
step: 250, loss: 0.010790811851620674
step: 260, loss: 0.0992182120680809
step: 270, loss: 0.039170827716588974
step: 280, loss: 0.04391144588589668
step: 290, loss: 0.07153947651386261
step: 300, loss: 0.08274585008621216
step: 310, loss: 0.10962191224098206
step: 320, loss: 0.01966579258441925
step: 330, loss: 0.1212003231048584
step: 340, loss: 0.18009203672409058
step: 350, loss: 0.013921767473220825
step: 360, loss: 0.020256320014595985
step: 370, loss: 0.1432637870311737
step: 380, loss: 0.01887403428554535
step: 390, loss: 0.06867587566375732
step: 400, loss: 0.0803101435303688
step: 410, loss: 0.062070053070783615
step: 420, loss: 0.08956773579120636
step: 430, loss: 0.04298319295048714
step: 440, loss: 0.1512332260608673
step: 450, loss: 0.04251695051789284
step: 460, loss: 0.01371496357023716
step: 470, loss: 0.1258053183555603
step: 480, loss: 0.02090935967862606
step: 490, loss: 0.10121582448482513
step: 500, loss: 0.09958438575267792
step: 510, loss: 0.024708658456802368
step: 520, loss: 0.015631821006536484
step: 530, loss: 0.05190733075141907
step: 540, loss: 0.043913401663303375
step: 550, loss: 0.18539415299892426
step: 560, loss: 0.02248900942504406
step: 570, loss: 0.10726980865001678
step: 580, loss: 0.05144206061959267
step: 590, loss: 0.04099123179912567
step: 600, loss: 0.16293957829475403
step: 610, loss: 0.2146543264389038
step: 620, loss: 0.010082683525979519
step: 630, loss: 0.01826910302042961
step: 640, loss: 0.11898838728666306
step: 650, loss: 0.0060469950549304485
step: 660, loss: 0.1026282086968422
step: 670, loss: 0.06664303690195084
step: 680, loss: 0.05047949030995369
step: 690, loss: 0.15074750781059265
step: 700, loss: 0.0947987288236618
step: 710, loss: 0.01046882662922144
step: 720, loss: 0.009866857901215553
step: 730, loss: 0.1872301548719406
step: 740, loss: 0.059050045907497406
step: 750, loss: 0.035518497228622437
step: 760, loss: 0.158417746424675
step: 770, loss: 0.06330729275941849
step: 780, loss: 0.1115480288863182
step: 790, loss: 0.17314985394477844
step: 800, loss: 0.049430519342422485
step: 810, loss: 0.020332619547843933
step: 820, loss: 0.031037157401442528
step: 830, loss: 0.09006490558385849
step: 840, loss: 0.052878472954034805
step: 850, loss: 0.08047380298376083
step: 860, loss: 0.013547527603805065
step: 870, loss: 0.0772855281829834
step: 880, loss: 0.04454803466796875
step: 890, loss: 0.02384033054113388
step: 900, loss: 0.014106456190347672
step: 910, loss: 0.054452717304229736
step: 920, loss: 0.010362677276134491
step: 930, loss: 0.00016601690731476992
step: 940, loss: 0.1286369115114212
step: 950, loss: 0.05171501636505127
step: 960, loss: 0.15969043970108032
step: 970, loss: 0.04771985486149788
epoch 6: dev_f1=0.9333950046253469, f1=0.9356779268857011, best_f1=0.9423513390830685
step: 0, loss: 0.006258755456656218
step: 10, loss: 0.0038178609684109688
step: 20, loss: 0.05668359994888306
step: 30, loss: 0.06448398530483246
step: 40, loss: 0.07686781883239746
step: 50, loss: 0.009589469991624355
step: 60, loss: 0.09775570034980774
step: 70, loss: 0.16036120057106018
step: 80, loss: 0.04529153183102608
step: 90, loss: 0.0160771906375885
step: 100, loss: 0.0791967585682869
step: 110, loss: 0.03657392039895058
step: 120, loss: 0.06872541457414627
step: 130, loss: 0.15746092796325684
step: 140, loss: 0.022120308130979538
step: 150, loss: 0.041978660970926285
step: 160, loss: 0.006452556699514389
step: 170, loss: 0.04326729476451874
step: 180, loss: 0.16225063800811768
step: 190, loss: 0.013360547833144665
step: 200, loss: 0.0931658148765564
step: 210, loss: 0.11849621683359146
step: 220, loss: 0.08272221684455872
step: 230, loss: 0.01904386840760708
step: 240, loss: 0.09621270000934601
step: 250, loss: 0.02575567364692688
step: 260, loss: 0.03557266294956207
step: 270, loss: 0.08960150927305222
step: 280, loss: 0.08894088119268417
step: 290, loss: 0.042935941368341446
step: 300, loss: 0.09841877967119217
step: 310, loss: 0.014834892004728317
step: 320, loss: 0.038316987454891205
step: 330, loss: 0.024828581139445305
step: 340, loss: 0.10094588994979858
step: 350, loss: 0.05379434674978256
step: 360, loss: 0.1591419130563736
step: 370, loss: 0.030415404587984085
step: 380, loss: 0.1097058653831482
step: 390, loss: 0.08402969688177109
step: 400, loss: 0.021568015217781067
step: 410, loss: 0.21539053320884705
step: 420, loss: 0.07885055989027023
step: 430, loss: 0.10748546570539474
step: 440, loss: 0.014078265056014061
step: 450, loss: 0.07208456844091415
step: 460, loss: 0.04984411597251892
step: 470, loss: 0.08005266636610031
step: 480, loss: 0.006209653802216053
step: 490, loss: 0.012549035251140594
step: 500, loss: 0.08046003431081772
step: 510, loss: 0.030572431161999702
step: 520, loss: 0.05833905562758446
step: 530, loss: 0.01556974183768034
step: 540, loss: 0.2675725519657135
step: 550, loss: 0.015928324311971664
step: 560, loss: 0.026966499164700508
step: 570, loss: 0.09417413175106049
step: 580, loss: 0.0380336157977581
step: 590, loss: 0.15683609247207642
step: 600, loss: 0.04318380728363991
step: 610, loss: 0.01820121705532074
step: 620, loss: 0.026644902303814888
step: 630, loss: 0.026774432510137558
step: 640, loss: 0.09513837844133377
step: 650, loss: 0.20639148354530334
step: 660, loss: 0.08882354199886322
step: 670, loss: 0.022415168583393097
step: 680, loss: 0.034037161618471146
step: 690, loss: 0.031571753323078156
step: 700, loss: 0.18482883274555206
step: 710, loss: 0.08034726232290268
step: 720, loss: 0.08478021621704102
step: 730, loss: 0.042933523654937744
step: 740, loss: 0.06935561448335648
step: 750, loss: 0.04476679116487503
step: 760, loss: 0.08443032950162888
step: 770, loss: 0.037475209683179855
step: 780, loss: 0.011936147697269917
step: 790, loss: 0.01287327241152525
step: 800, loss: 0.19554908573627472
step: 810, loss: 0.05908545106649399
step: 820, loss: 0.08528926223516464
step: 830, loss: 0.023074936121702194
step: 840, loss: 0.013236522674560547
step: 850, loss: 0.06259188801050186
step: 860, loss: 0.06045692041516304
step: 870, loss: 3.155221929773688e-05
step: 880, loss: 0.10646263509988785
step: 890, loss: 0.13848893344402313
step: 900, loss: 0.051856838166713715
step: 910, loss: 0.19451016187667847
step: 920, loss: 0.08310741931200027
step: 930, loss: 0.029468288645148277
step: 940, loss: 0.02452615648508072
step: 950, loss: 0.11072137206792831
step: 960, loss: 0.03130451962351799
step: 970, loss: 0.009293382056057453
epoch 7: dev_f1=0.9351632749645054, f1=0.9272898961284232, best_f1=0.9423513390830685
step: 0, loss: 0.07044441998004913
step: 10, loss: 0.036389078944921494
step: 20, loss: 0.028402552008628845
step: 30, loss: 0.018433578312397003
step: 40, loss: 0.10457806289196014
step: 50, loss: 0.04674392193555832
step: 60, loss: 0.12205306440591812
step: 70, loss: 0.03657080605626106
step: 80, loss: 0.03556755930185318
step: 90, loss: 0.027414420619606972
step: 100, loss: 0.02068670466542244
step: 110, loss: 0.15670232474803925
step: 120, loss: 0.01019447110593319
step: 130, loss: 0.002995454240590334
step: 140, loss: 0.04490211233496666
step: 150, loss: 0.018430637195706367
step: 160, loss: 0.09513556957244873
step: 170, loss: 0.060362257063388824
step: 180, loss: 0.08126407861709595
step: 190, loss: 0.026477018371224403
step: 200, loss: 0.020792417228221893
step: 210, loss: 0.08731140196323395
step: 220, loss: 0.08576740324497223
step: 230, loss: 0.05759144201874733
step: 240, loss: 0.02883201651275158
step: 250, loss: 0.0005177867133170366
step: 260, loss: 0.10281281173229218
step: 270, loss: 0.030143653973937035
step: 280, loss: 0.014449783600866795
step: 290, loss: 0.17969158291816711
step: 300, loss: 0.018172254785895348
step: 310, loss: 0.1165429875254631
step: 320, loss: 0.08097393810749054
step: 330, loss: 0.09498730301856995
step: 340, loss: 0.036474309861660004
step: 350, loss: 0.09060634672641754
step: 360, loss: 0.13160498440265656
step: 370, loss: 0.026564566418528557
step: 380, loss: 0.10587280988693237
step: 390, loss: 0.11398143321275711
step: 400, loss: 0.060876499861478806
step: 410, loss: 0.10607621818780899
step: 420, loss: 0.004366596695035696
step: 430, loss: 0.12884695827960968
step: 440, loss: 0.024527300149202347
step: 450, loss: 0.2431231588125229
step: 460, loss: 0.01956556923687458
step: 470, loss: 0.004350545350462198
step: 480, loss: 0.015126742422580719
step: 490, loss: 0.13080209493637085
step: 500, loss: 0.01948726177215576
step: 510, loss: 0.11610332876443863
step: 520, loss: 0.053929004818201065
step: 530, loss: 0.10128359496593475
step: 540, loss: 0.05756666883826256
step: 550, loss: 0.009898041374981403
step: 560, loss: 0.11418229341506958
step: 570, loss: 0.034765880554914474
step: 580, loss: 0.0378832072019577
step: 590, loss: 0.026350971311330795
step: 600, loss: 0.0046493131667375565
step: 610, loss: 0.01715696230530739
step: 620, loss: 0.010355168022215366
step: 630, loss: 0.07674507051706314
step: 640, loss: 0.0446150042116642
step: 650, loss: 0.0913076177239418
step: 660, loss: 0.06654340773820877
step: 670, loss: 0.0724932998418808
step: 680, loss: 0.00614792900159955
step: 690, loss: 0.10871155560016632
step: 700, loss: 0.02979239448904991
step: 710, loss: 0.11469505727291107
step: 720, loss: 0.025757133960723877
step: 730, loss: 0.12824003398418427
step: 740, loss: 0.08652905374765396
step: 750, loss: 0.11745139956474304
step: 760, loss: 0.05036812275648117
step: 770, loss: 0.07988639175891876
step: 780, loss: 0.03606930002570152
step: 790, loss: 0.0277111679315567
step: 800, loss: 0.040941234678030014
step: 810, loss: 0.02414163388311863
step: 820, loss: 0.058816589415073395
step: 830, loss: 0.18945281207561493
step: 840, loss: 0.03262776508927345
step: 850, loss: 0.07799792289733887
step: 860, loss: 0.02079416997730732
step: 870, loss: 0.04998096078634262
step: 880, loss: 0.017281971871852875
step: 890, loss: 0.028581880033016205
step: 900, loss: 0.044672440737485886
step: 910, loss: 0.1280750334262848
step: 920, loss: 0.04904007911682129
step: 930, loss: 0.15487831830978394
step: 940, loss: 0.02627805806696415
step: 950, loss: 0.083609938621521
step: 960, loss: 0.04926063492894173
step: 970, loss: 0.16075271368026733
epoch 8: dev_f1=0.9389277389277391, f1=0.9349442379182156, best_f1=0.9423513390830685
step: 0, loss: 0.008344092406332493
step: 10, loss: 0.009170863777399063
step: 20, loss: 0.017616942524909973
step: 30, loss: 0.013074973598122597
step: 40, loss: 0.012992529198527336
step: 50, loss: 0.06063970550894737
step: 60, loss: 0.07236849516630173
step: 70, loss: 0.015255708247423172
step: 80, loss: 0.15149272978305817
step: 90, loss: 0.00587866036221385
step: 100, loss: 0.01676027663052082
step: 110, loss: 0.12521037459373474
step: 120, loss: 0.05210747569799423
step: 130, loss: 0.021823275834321976
step: 140, loss: 0.04206292703747749
step: 150, loss: 0.01572437770664692
step: 160, loss: 0.031670164316892624
step: 170, loss: 0.05219697952270508
step: 180, loss: 0.01608486846089363
step: 190, loss: 0.07993808388710022
step: 200, loss: 0.0268864668905735
step: 210, loss: 0.02683105878531933
step: 220, loss: 0.11290133744478226
step: 230, loss: 0.019331207498908043
step: 240, loss: 0.03392999991774559
step: 250, loss: 0.03683152049779892
step: 260, loss: 0.014524826779961586
step: 270, loss: 0.09783455729484558
step: 280, loss: 0.07646143436431885
step: 290, loss: 0.04287177324295044
step: 300, loss: 0.029975030571222305
step: 310, loss: 0.13539810478687286
step: 320, loss: 0.06138293072581291
step: 330, loss: 0.16178177297115326
step: 340, loss: 0.022246448323130608
step: 350, loss: 0.09812584519386292
step: 360, loss: 0.010781505145132542
step: 370, loss: 0.017819533124566078
step: 380, loss: 0.06572957336902618
step: 390, loss: 0.009008832275867462
step: 400, loss: 0.09275512397289276
step: 410, loss: 0.013294435106217861
step: 420, loss: 0.004573275335133076
step: 430, loss: 1.5567833543173037e-05
step: 440, loss: 0.003511143149808049
step: 450, loss: 0.2729552984237671
step: 460, loss: 0.10763794183731079
step: 470, loss: 0.01018854696303606
step: 480, loss: 0.14723314344882965
step: 490, loss: 0.01691538654267788
step: 500, loss: 0.12195492535829544
step: 510, loss: 0.012008221819996834
step: 520, loss: 2.8794313038815744e-05
step: 530, loss: 0.01229254249483347
step: 540, loss: 0.00276560359634459
step: 550, loss: 0.01454567164182663
step: 560, loss: 0.021045567467808723
step: 570, loss: 0.011529427953064442
step: 580, loss: 0.06448982656002045
step: 590, loss: 0.08012454211711884
step: 600, loss: 0.06846126914024353
step: 610, loss: 0.01893235184252262
step: 620, loss: 0.006138173397630453
step: 630, loss: 0.04242095351219177
step: 640, loss: 0.12964636087417603
step: 650, loss: 0.16429857909679413
step: 660, loss: 0.1075291559100151
step: 670, loss: 0.033253222703933716
step: 680, loss: 0.05136873945593834
step: 690, loss: 0.022584283724427223
step: 700, loss: 0.03324563801288605
step: 710, loss: 0.06976617872714996
step: 720, loss: 0.04023871570825577
step: 730, loss: 0.06094419211149216
step: 740, loss: 0.055483873933553696
step: 750, loss: 0.020897725597023964
step: 760, loss: 0.061289265751838684
step: 770, loss: 0.06766030192375183
step: 780, loss: 0.07579008489847183
step: 790, loss: 0.0491374209523201
step: 800, loss: 0.15667076408863068
step: 810, loss: 0.23882003128528595
step: 820, loss: 0.1373470574617386
step: 830, loss: 0.13507217168807983
step: 840, loss: 0.03589640185236931
step: 850, loss: 0.016863945871591568
step: 860, loss: 0.05275705084204674
step: 870, loss: 0.05630970001220703
step: 880, loss: 0.026951223611831665
step: 890, loss: 0.02519230730831623
step: 900, loss: 0.11877996474504471
step: 910, loss: 0.03212912008166313
step: 920, loss: 0.03730933368206024
step: 930, loss: 0.017034459859132767
step: 940, loss: 0.10455263406038284
step: 950, loss: 0.11595973372459412
step: 960, loss: 0.06290716677904129
step: 970, loss: 0.027014510706067085
epoch 9: dev_f1=0.9378794955628212, f1=0.9323378441437238, best_f1=0.9423513390830685
step: 0, loss: 0.02911732718348503
step: 10, loss: 0.1076953113079071
step: 20, loss: 0.06378515064716339
step: 30, loss: 0.05397501215338707
step: 40, loss: 0.0010532233864068985
step: 50, loss: 0.04386643320322037
step: 60, loss: 0.019808530807495117
step: 70, loss: 0.05490412190556526
step: 80, loss: 0.05776776000857353
step: 90, loss: 0.009521720930933952
step: 100, loss: 0.05211598053574562
step: 110, loss: 0.006537548266351223
step: 120, loss: 0.04502120986580849
step: 130, loss: 0.05251951888203621
step: 140, loss: 0.1451270580291748
step: 150, loss: 0.05994928628206253
step: 160, loss: 0.1062283143401146
step: 170, loss: 0.144634410738945
step: 180, loss: 0.01775246113538742
step: 190, loss: 0.1224997490644455
step: 200, loss: 0.022005071863532066
step: 210, loss: 0.08612874150276184
step: 220, loss: 0.0015074334805831313
step: 230, loss: 0.03281098231673241
step: 240, loss: 0.08234165608882904
step: 250, loss: 0.06927500665187836
step: 260, loss: 0.053340233862400055
step: 270, loss: 0.05921800807118416
step: 280, loss: 0.042192474007606506
step: 290, loss: 0.06749919056892395
step: 300, loss: 0.0698532909154892
step: 310, loss: 0.038271062076091766
step: 320, loss: 0.028447069227695465
step: 330, loss: 0.09487471729516983
step: 340, loss: 0.10550326108932495
step: 350, loss: 0.029365744441747665
step: 360, loss: 0.11572936177253723
step: 370, loss: 0.01571507565677166
step: 380, loss: 0.012695764191448689
step: 390, loss: 0.19445058703422546
step: 400, loss: 0.04775051027536392
step: 410, loss: 0.03529359772801399
step: 420, loss: 0.012976882979273796
step: 430, loss: 0.0035843243822455406
step: 440, loss: 0.006851127836853266
step: 450, loss: 0.03768119588494301
step: 460, loss: 0.03542229160666466
step: 470, loss: 0.051589012145996094
step: 480, loss: 0.06075010821223259
step: 490, loss: 0.06017998978495598
step: 500, loss: 0.0028049349784851074
step: 510, loss: 0.05224168300628662
step: 520, loss: 0.03735003247857094
step: 530, loss: 0.038897719234228134
step: 540, loss: 0.03374777361750603
step: 550, loss: 0.035299163311719894
step: 560, loss: 0.0627577155828476
step: 570, loss: 0.09384189546108246
step: 580, loss: 0.12102354317903519
step: 590, loss: 0.03680235147476196
step: 600, loss: 0.014121036045253277
step: 610, loss: 0.01815318875014782
step: 620, loss: 0.00782007072120905
step: 630, loss: 0.15310059487819672
step: 640, loss: 0.08874122053384781
step: 650, loss: 0.021627001464366913
step: 660, loss: 0.0721421167254448
step: 670, loss: 0.007026089355349541
step: 680, loss: 0.01175814401358366
step: 690, loss: 0.028394917026162148
step: 700, loss: 0.03564249724149704
step: 710, loss: 0.07639552652835846
step: 720, loss: 0.021254152059555054
step: 730, loss: 0.005755798891186714
step: 740, loss: 0.08951781690120697
step: 750, loss: 0.003710099495947361
step: 760, loss: 0.012783677317202091
step: 770, loss: 0.0568474680185318
step: 780, loss: 0.014014839194715023
step: 790, loss: 0.1104845255613327
step: 800, loss: 0.004401048645377159
step: 810, loss: 0.016800785437226295
step: 820, loss: 0.033610228449106216
step: 830, loss: 0.002402970101684332
step: 840, loss: 0.044630419462919235
step: 850, loss: 0.06118452548980713
step: 860, loss: 0.06136231869459152
step: 870, loss: 0.07143082469701767
step: 880, loss: 0.17455148696899414
step: 890, loss: 0.08221278339624405
step: 900, loss: 0.05628792569041252
step: 910, loss: 0.07140428572893143
step: 920, loss: 0.04932224377989769
step: 930, loss: 0.13371586799621582
step: 940, loss: 0.029078880324959755
step: 950, loss: 0.11117701232433319
step: 960, loss: 0.0772625207901001
step: 970, loss: 0.014482876285910606
epoch 10: dev_f1=0.937207122774133, f1=0.9340196537201684, best_f1=0.9423513390830685
step: 0, loss: 0.12925542891025543
step: 10, loss: 0.016474619507789612
step: 20, loss: 0.03649898245930672
step: 30, loss: 0.03289395570755005
step: 40, loss: 0.05875151976943016
step: 50, loss: 0.04629874601960182
step: 60, loss: 0.04659275710582733
step: 70, loss: 0.014485593885183334
step: 80, loss: 0.22091780602931976
step: 90, loss: 0.04939330369234085
step: 100, loss: 0.039727311581373215
step: 110, loss: 0.017928769811987877
step: 120, loss: 0.004490396473556757
step: 130, loss: 0.07609005272388458
step: 140, loss: 0.007569876033812761
step: 150, loss: 0.037737227976322174
step: 160, loss: 0.013368234969675541
step: 170, loss: 0.06568402796983719
step: 180, loss: 0.003909307066351175
step: 190, loss: 0.07720291614532471
step: 200, loss: 0.06696129590272903
step: 210, loss: 0.021095087751746178
step: 220, loss: 0.03543338552117348
step: 230, loss: 0.05067744106054306
step: 240, loss: 0.015502113848924637
step: 250, loss: 0.0007347278879024088
step: 260, loss: 0.005864367820322514
step: 270, loss: 0.025943484157323837
step: 280, loss: 0.0018656544853001833
step: 290, loss: 0.06409363448619843
step: 300, loss: 0.0683404728770256
step: 310, loss: 0.015861133113503456
step: 320, loss: 0.07747925817966461
step: 330, loss: 0.0065131536684930325
step: 340, loss: 0.013973217457532883
step: 350, loss: 0.010242772288620472
step: 360, loss: 0.04650372266769409
step: 370, loss: 0.09828542917966843
step: 380, loss: 0.006475365255028009
step: 390, loss: 0.21148252487182617
step: 400, loss: 0.07428435236215591
step: 410, loss: 0.059747591614723206
step: 420, loss: 0.10348287969827652
step: 430, loss: 0.042862847447395325
step: 440, loss: 0.09725334495306015
step: 450, loss: 0.006955752149224281
step: 460, loss: 0.022384541109204292
step: 470, loss: 0.0610705129802227
step: 480, loss: 0.06676244735717773
step: 490, loss: 0.07293760031461716
step: 500, loss: 0.008034170605242252
step: 510, loss: 0.015549800358712673
step: 520, loss: 0.00568379694595933
step: 530, loss: 0.008017097599804401
step: 540, loss: 0.007807760965079069
step: 550, loss: 0.13735035061836243
step: 560, loss: 0.007479257415980101
step: 570, loss: 0.0062621766701340675
step: 580, loss: 0.05252283066511154
step: 590, loss: 0.08391191065311432
step: 600, loss: 0.06034751608967781
step: 610, loss: 0.06356240063905716
step: 620, loss: 0.027638809755444527
step: 630, loss: 0.0167243592441082
step: 640, loss: 0.16480451822280884
step: 650, loss: 0.07189739495515823
step: 660, loss: 0.020966241136193275
step: 670, loss: 0.07671135663986206
step: 680, loss: 0.013834631070494652
step: 690, loss: 0.011899693869054317
step: 700, loss: 0.08757482469081879
step: 710, loss: 0.009700050577521324
step: 720, loss: 0.15289120376110077
step: 730, loss: 0.041165634989738464
step: 740, loss: 0.057274430990219116
step: 750, loss: 0.04121251404285431
step: 760, loss: 0.0005878645461052656
step: 770, loss: 0.02939232438802719
step: 780, loss: 0.10461157560348511
step: 790, loss: 0.005417163483798504
step: 800, loss: 0.05710489675402641
step: 810, loss: 0.13897787034511566
step: 820, loss: 0.04412396252155304
step: 830, loss: 0.011915944516658783
step: 840, loss: 0.040916234254837036
step: 850, loss: 0.07464063167572021
step: 860, loss: 0.011214394122362137
step: 870, loss: 0.016741985455155373
step: 880, loss: 0.03241816163063049
step: 890, loss: 0.08510041236877441
step: 900, loss: 0.11502660065889359
step: 910, loss: 0.10278794169425964
step: 920, loss: 0.016376694664359093
step: 930, loss: 0.01759997196495533
step: 940, loss: 0.009897394105792046
step: 950, loss: 0.08097533136606216
step: 960, loss: 0.05243726447224617
step: 970, loss: 0.1571245938539505
epoch 11: dev_f1=0.9340761374187557, f1=0.9311778290993071, best_f1=0.9423513390830685
step: 0, loss: 0.00139127136208117
step: 10, loss: 0.05823991820216179
step: 20, loss: 0.008833610452711582
step: 30, loss: 0.05492335557937622
step: 40, loss: 0.025867190212011337
step: 50, loss: 0.041139550507068634
step: 60, loss: 0.054731063544750214
step: 70, loss: 0.01433118712157011
step: 80, loss: 0.009028329513967037
step: 90, loss: 0.0003707478754222393
step: 100, loss: 0.010655093006789684
step: 110, loss: 0.02492743730545044
step: 120, loss: 0.0064590550027787685
step: 130, loss: 0.030897557735443115
step: 140, loss: 0.00838934350758791
step: 150, loss: 0.04021620377898216
step: 160, loss: 0.06943892687559128
step: 170, loss: 0.00046120479237288237
step: 180, loss: 0.02474517747759819
step: 190, loss: 0.030008038505911827
step: 200, loss: 0.009836452081799507
step: 210, loss: 0.048873431980609894
step: 220, loss: 0.10459146648645401
step: 230, loss: 0.047373317182064056
step: 240, loss: 0.019266139715909958
step: 250, loss: 0.07995417714118958
step: 260, loss: 0.03178763762116432
step: 270, loss: 0.05252919718623161
step: 280, loss: 0.13205163180828094
step: 290, loss: 0.010091470554471016
step: 300, loss: 0.00799686647951603
step: 310, loss: 0.00021314152400009334
step: 320, loss: 0.039891425520181656
step: 330, loss: 0.2541695237159729
step: 340, loss: 0.07424336671829224
step: 350, loss: 0.05826627463102341
step: 360, loss: 0.058551378548145294
step: 370, loss: 0.11134173721075058
step: 380, loss: 0.05900851637125015
step: 390, loss: 0.013924622908234596
step: 400, loss: 0.11597886681556702
step: 410, loss: 0.227466881275177
step: 420, loss: 0.05485787242650986
step: 430, loss: 0.043999962508678436
step: 440, loss: 0.006754979491233826
step: 450, loss: 0.11128257215023041
step: 460, loss: 0.06000257283449173
step: 470, loss: 0.06192541867494583
step: 480, loss: 0.06197682395577431
step: 490, loss: 0.03117429092526436
step: 500, loss: 0.026063155382871628
step: 510, loss: 0.07296336442232132
step: 520, loss: 0.017906641587615013
step: 530, loss: 0.04631582275032997
step: 540, loss: 0.10868795216083527
step: 550, loss: 0.013271983712911606
step: 560, loss: 0.006871332414448261
step: 570, loss: 0.017351804301142693
step: 580, loss: 0.09660413861274719
step: 590, loss: 0.010370321571826935
step: 600, loss: 0.03227102383971214
step: 610, loss: 0.013598160818219185
step: 620, loss: 0.06828644871711731
step: 630, loss: 0.012423179112374783
step: 640, loss: 0.0069089625030756
step: 650, loss: 0.047687750309705734
step: 660, loss: 0.05659866705536842
step: 670, loss: 0.09292247146368027
step: 680, loss: 0.005690230056643486
step: 690, loss: 0.1928199976682663
step: 700, loss: 0.0241363737732172
step: 710, loss: 0.11080565303564072
step: 720, loss: 0.011712497100234032
step: 730, loss: 0.02627500519156456
step: 740, loss: 0.15370510518550873
step: 750, loss: 0.03846859559416771
step: 760, loss: 0.025967897847294807
step: 770, loss: 0.012497514486312866
step: 780, loss: 5.275111834635027e-05
step: 790, loss: 0.03183572366833687
step: 800, loss: 0.052677616477012634
step: 810, loss: 0.07404214888811111
step: 820, loss: 0.004409997723996639
step: 830, loss: 0.03782324865460396
step: 840, loss: 0.03849080950021744
step: 850, loss: 0.1187911406159401
step: 860, loss: 0.07699073106050491
step: 870, loss: 0.001088353805243969
step: 880, loss: 0.08088317513465881
step: 890, loss: 0.027052683755755424
step: 900, loss: 0.006176280789077282
step: 910, loss: 0.007570240180939436
step: 920, loss: 0.03231799229979515
step: 930, loss: 0.029758401215076447
step: 940, loss: 0.02169979363679886
step: 950, loss: 0.02055373601615429
step: 960, loss: 0.05900588631629944
step: 970, loss: 0.0006555480067618191
epoch 12: dev_f1=0.9400278940027894, f1=0.9296296296296297, best_f1=0.9423513390830685
step: 0, loss: 0.00652268435806036
step: 10, loss: 0.0024930997751653194
step: 20, loss: 0.02480127662420273
step: 30, loss: 0.043755363672971725
step: 40, loss: 0.02331007458269596
step: 50, loss: 0.014085819013416767
step: 60, loss: 0.013532997108995914
step: 70, loss: 0.04819495603442192
step: 80, loss: 0.03901521489024162
step: 90, loss: 0.001880017458461225
step: 100, loss: 0.0546085424721241
step: 110, loss: 0.08505450189113617
step: 120, loss: 0.08537091314792633
step: 130, loss: 0.00017259534797631204
step: 140, loss: 0.10670334845781326
step: 150, loss: 0.001076754298992455
step: 160, loss: 0.031307417899370193
step: 170, loss: 0.03774653747677803
step: 180, loss: 0.01827702671289444
step: 190, loss: 0.0010854699648916721
step: 200, loss: 0.1447731852531433
step: 210, loss: 0.13407398760318756
step: 220, loss: 0.002648676047101617
step: 230, loss: 0.021072814241051674
step: 240, loss: 0.013880748301744461
step: 250, loss: 0.019290555268526077
step: 260, loss: 0.032683052122592926
step: 270, loss: 0.0458175465464592
step: 280, loss: 0.039852920919656754
step: 290, loss: 0.014483019709587097
step: 300, loss: 0.00113958481233567
step: 310, loss: 0.13235923647880554
step: 320, loss: 0.034781135618686676
step: 330, loss: 0.01153075322508812
step: 340, loss: 0.06298936903476715
step: 350, loss: 0.054682061076164246
step: 360, loss: 0.055902738124132156
step: 370, loss: 0.003407534910365939
step: 380, loss: 0.013601037673652172
step: 390, loss: 0.042478371411561966
step: 400, loss: 0.10452613234519958
step: 410, loss: 0.005131554789841175
step: 420, loss: 0.019973812624812126
step: 430, loss: 0.1928851157426834
step: 440, loss: 0.02043035440146923
step: 450, loss: 0.0019568740390241146
step: 460, loss: 1.8968930817209184e-05
step: 470, loss: 0.0777263343334198
step: 480, loss: 0.08390533179044724
step: 490, loss: 0.1734185367822647
step: 500, loss: 0.05488504469394684
step: 510, loss: 0.00546258082613349
step: 520, loss: 0.17285804450511932
step: 530, loss: 0.1640973538160324
step: 540, loss: 0.0028835770208388567
step: 550, loss: 0.015288099646568298
step: 560, loss: 0.004336773417890072
step: 570, loss: 0.02443336695432663
step: 580, loss: 0.10265980660915375
step: 590, loss: 0.0031355414539575577
step: 600, loss: 0.0029858241323381662
step: 610, loss: 0.033462926745414734
step: 620, loss: 0.013097207061946392
step: 630, loss: 0.07066065073013306
step: 640, loss: 0.05422505736351013
step: 650, loss: 0.0018064065370708704
step: 660, loss: 0.07901131361722946
step: 670, loss: 0.015217941254377365
step: 680, loss: 0.0012844204902648926
step: 690, loss: 0.010080456733703613
step: 700, loss: 0.08548559248447418
step: 710, loss: 0.05113400146365166
step: 720, loss: 0.0526791550219059
step: 730, loss: 0.010381323285400867
step: 740, loss: 0.030150236561894417
step: 750, loss: 0.03249751403927803
step: 760, loss: 0.007012944668531418
step: 770, loss: 0.01126486249268055
step: 780, loss: 0.05737912654876709
step: 790, loss: 0.09163045883178711
step: 800, loss: 0.03060763329267502
step: 810, loss: 0.01936856098473072
step: 820, loss: 0.05427752062678337
step: 830, loss: 0.004755157977342606
step: 840, loss: 0.04791140928864479
step: 850, loss: 0.04382286220788956
step: 860, loss: 0.046943314373493195
step: 870, loss: 0.08046594262123108
step: 880, loss: 0.04885638505220413
step: 890, loss: 0.016200711950659752
step: 900, loss: 0.09028518199920654
step: 910, loss: 0.060620371252298355
step: 920, loss: 0.0557115375995636
step: 930, loss: 0.07643795013427734
step: 940, loss: 0.05092910677194595
step: 950, loss: 0.009173929691314697
step: 960, loss: 0.09271714091300964
step: 970, loss: 0.00011839211219921708
epoch 13: dev_f1=0.9339578454332552, f1=0.9316596931659693, best_f1=0.9423513390830685
step: 0, loss: 0.04963144287467003
step: 10, loss: 0.020014848560094833
step: 20, loss: 0.04385728761553764
step: 30, loss: 0.015414901077747345
step: 40, loss: 0.14897982776165009
step: 50, loss: 0.02576102875173092
step: 60, loss: 0.013024291954934597
step: 70, loss: 0.0905870646238327
step: 80, loss: 0.024337168782949448
step: 90, loss: 0.0007002284401096404
step: 100, loss: 0.007183235604315996
step: 110, loss: 0.09845063835382462
step: 120, loss: 0.008366761729121208
step: 130, loss: 0.04154795780777931
step: 140, loss: 0.000988399493508041
step: 150, loss: 0.037839412689208984
step: 160, loss: 0.05063023790717125
step: 170, loss: 0.05588749423623085
step: 180, loss: 0.06134830042719841
step: 190, loss: 0.058626700192689896
step: 200, loss: 0.0799805074930191
step: 210, loss: 0.01229929830878973
step: 220, loss: 0.07960276305675507
step: 230, loss: 0.07773520797491074
step: 240, loss: 0.0005010408931411803
step: 250, loss: 0.04646964743733406
step: 260, loss: 0.08349812030792236
step: 270, loss: 0.04128890857100487
step: 280, loss: 0.07217101007699966
step: 290, loss: 0.10074339807033539
step: 300, loss: 0.016213497146964073
step: 310, loss: 0.05305295065045357
step: 320, loss: 0.02478855289518833
step: 330, loss: 0.03752516955137253
step: 340, loss: 0.002035966143012047
step: 350, loss: 0.04094385355710983
step: 360, loss: 0.054757554084062576
step: 370, loss: 0.026627684012055397
step: 380, loss: 0.03446931391954422
step: 390, loss: 0.052119217813014984
step: 400, loss: 0.04260407015681267
step: 410, loss: 0.002350990194827318
step: 420, loss: 0.08917008340358734
step: 430, loss: 0.05380750820040703
step: 440, loss: 0.0068174125626683235
step: 450, loss: 0.020926939323544502
step: 460, loss: 0.04917805269360542
step: 470, loss: 0.004694303963333368
step: 480, loss: 0.007566069718450308
step: 490, loss: 0.09352786839008331
step: 500, loss: 0.0007471101707778871
step: 510, loss: 0.022205276414752007
step: 520, loss: 0.007133812643587589
step: 530, loss: 0.04402294382452965
step: 540, loss: 0.08029086142778397
step: 550, loss: 0.00011799666390288621
step: 560, loss: 0.06554246693849564
step: 570, loss: 0.06271550804376602
step: 580, loss: 0.10141696035861969
step: 590, loss: 0.05405794829130173
step: 600, loss: 0.010403458960354328
step: 610, loss: 0.01648183912038803
step: 620, loss: 0.011080675758421421
step: 630, loss: 0.004018460866063833
step: 640, loss: 0.005491126794368029
step: 650, loss: 0.14736197888851166
step: 660, loss: 0.0036916278768330812
step: 670, loss: 0.04710075259208679
step: 680, loss: 0.047790076583623886
step: 690, loss: 0.0624617338180542
step: 700, loss: 0.005043809302151203
step: 710, loss: 0.11644736677408218
step: 720, loss: 0.09240808337926865
step: 730, loss: 0.01995689421892166
step: 740, loss: 0.002591184340417385
step: 750, loss: 0.022359047085046768
step: 760, loss: 0.01061851903796196
step: 770, loss: 0.040704019367694855
step: 780, loss: 0.05655182898044586
step: 790, loss: 0.011924396269023418
step: 800, loss: 0.01836090348660946
step: 810, loss: 0.10137312859296799
step: 820, loss: 0.020865051075816154
step: 830, loss: 0.03138997405767441
step: 840, loss: 0.005173705983906984
step: 850, loss: 0.015636377036571503
step: 860, loss: 0.056532181799411774
step: 870, loss: 0.046727053821086884
step: 880, loss: 0.019171833992004395
step: 890, loss: 0.0006952224648557603
step: 900, loss: 0.03123314306139946
step: 910, loss: 0.08533845841884613
step: 920, loss: 0.02181125432252884
step: 930, loss: 0.028907785192131996
step: 940, loss: 0.03628026321530342
step: 950, loss: 0.041445836424827576
step: 960, loss: 0.020263316109776497
step: 970, loss: 0.04385305941104889
epoch 14: dev_f1=0.9255014326647565, f1=0.9240265906932574, best_f1=0.9423513390830685
step: 0, loss: 1.1078949682996608e-05
step: 10, loss: 0.06743896007537842
step: 20, loss: 0.12695729732513428
step: 30, loss: 0.05056411772966385
step: 40, loss: 0.02608836442232132
step: 50, loss: 0.018361054360866547
step: 60, loss: 0.02436325140297413
step: 70, loss: 0.040174100548028946
step: 80, loss: 0.01587561145424843
step: 90, loss: 0.02737310342490673
step: 100, loss: 0.04500516131520271
step: 110, loss: 0.010700639337301254
step: 120, loss: 0.001950595062226057
step: 130, loss: 0.0051911068148911
step: 140, loss: 0.004320773296058178
step: 150, loss: 0.04890918359160423
step: 160, loss: 0.0004722349112853408
step: 170, loss: 0.0003317650407552719
step: 180, loss: 0.03189867362380028
step: 190, loss: 0.000740574614610523
step: 200, loss: 0.017252154648303986
step: 210, loss: 0.011965514160692692
step: 220, loss: 0.1832139492034912
step: 230, loss: 7.823738997103646e-05
step: 240, loss: 0.0032331757247447968
step: 250, loss: 7.011640991549939e-05
step: 260, loss: 0.0009602741338312626
step: 270, loss: 0.07976989448070526
step: 280, loss: 0.0173257514834404
step: 290, loss: 0.02241714671254158
step: 300, loss: 9.659430361352861e-05
step: 310, loss: 0.020163511857390404
step: 320, loss: 0.00040226319106295705
step: 330, loss: 0.00282102613709867
step: 340, loss: 0.028552260249853134
step: 350, loss: 0.022458743304014206
step: 360, loss: 0.008315841667354107
step: 370, loss: 0.03479517996311188
step: 380, loss: 0.00011987929610768333
step: 390, loss: 0.017396822571754456
step: 400, loss: 0.1782590001821518
step: 410, loss: 0.09795723855495453
step: 420, loss: 0.0496661551296711
step: 430, loss: 0.08289044350385666
step: 440, loss: 0.03564544767141342
step: 450, loss: 1.1905924111488275e-05
step: 460, loss: 0.04089152440428734
step: 470, loss: 0.03625474125146866
step: 480, loss: 0.061431705951690674
step: 490, loss: 0.02820613607764244
step: 500, loss: 0.06731213629245758
step: 510, loss: 0.0055216518230736256
step: 520, loss: 0.03176898881793022
step: 530, loss: 0.048745859414339066
step: 540, loss: 0.07332101464271545
step: 550, loss: 0.05165769159793854
step: 560, loss: 0.024056538939476013
step: 570, loss: 0.0038119812961667776
step: 580, loss: 0.05363119766116142
step: 590, loss: 0.08354400098323822
step: 600, loss: 0.021124662831425667
step: 610, loss: 0.0616147480905056
step: 620, loss: 0.06862741708755493
step: 630, loss: 0.15657934546470642
step: 640, loss: 0.01657996140420437
step: 650, loss: 0.00040085497312247753
step: 660, loss: 0.03182246536016464
step: 670, loss: 5.3959953220328316e-05
step: 680, loss: 9.810564370127395e-05
step: 690, loss: 0.014231260865926743
step: 700, loss: 0.04538622498512268
step: 710, loss: 0.001027586287818849
step: 720, loss: 0.042876895517110825
step: 730, loss: 0.03282611444592476
step: 740, loss: 3.718154039233923e-05
step: 750, loss: 0.06926995515823364
step: 760, loss: 0.000996566261164844
step: 770, loss: 0.04131719842553139
step: 780, loss: 0.00010401294275652617
step: 790, loss: 0.016843009740114212
step: 800, loss: 0.008230699226260185
step: 810, loss: 0.020024416968226433
step: 820, loss: 0.02793450467288494
step: 830, loss: 0.08414026349782944
step: 840, loss: 0.034801993519067764
step: 850, loss: 0.034728437662124634
step: 860, loss: 0.022485801950097084
step: 870, loss: 0.002524654846638441
step: 880, loss: 0.001239759149029851
step: 890, loss: 0.1024288684129715
step: 900, loss: 0.03126445412635803
step: 910, loss: 0.01768558658659458
step: 920, loss: 0.0024000632110983133
step: 930, loss: 0.0015986114740371704
step: 940, loss: 0.10410383343696594
step: 950, loss: 0.009001530706882477
step: 960, loss: 0.00026585633167997
step: 970, loss: 0.05574063956737518
epoch 15: dev_f1=0.9390243902439025, f1=0.9310344827586207, best_f1=0.9423513390830685
step: 0, loss: 0.032822318375110626
step: 10, loss: 0.005901696160435677
step: 20, loss: 2.918242353189271e-05
step: 30, loss: 0.03488089516758919
step: 40, loss: 0.0188884437084198
step: 50, loss: 0.009844272397458553
step: 60, loss: 0.04380315542221069
step: 70, loss: 0.09469882398843765
step: 80, loss: 0.03014259971678257
step: 90, loss: 0.04195736348628998
step: 100, loss: 0.00016007132944650948
step: 110, loss: 0.010548867285251617
step: 120, loss: 0.0006596252787858248
step: 130, loss: 0.07923417538404465
step: 140, loss: 0.052313584834337234
step: 150, loss: 0.03434956446290016
step: 160, loss: 0.05293256416916847
step: 170, loss: 0.0004458665498532355
step: 180, loss: 0.0013868340756744146
step: 190, loss: 0.0035436907783150673
step: 200, loss: 0.08516666293144226
step: 210, loss: 0.06160682812333107
step: 220, loss: 0.08839035779237747
step: 230, loss: 0.02378739044070244
step: 240, loss: 0.016469556838274002
step: 250, loss: 0.04454021528363228
step: 260, loss: 0.049657516181468964
step: 270, loss: 0.07694710791110992
step: 280, loss: 0.022344093769788742
step: 290, loss: 0.007116147316992283
step: 300, loss: 0.022583331912755966
step: 310, loss: 0.008927809074521065
step: 320, loss: 0.10736274719238281
step: 330, loss: 0.0004658658872358501
step: 340, loss: 0.024133846163749695
step: 350, loss: 0.025165196508169174
step: 360, loss: 0.1305726021528244
step: 370, loss: 0.005255997180938721
step: 380, loss: 0.03569743037223816
step: 390, loss: 9.320629033027217e-06
step: 400, loss: 0.02197980135679245
step: 410, loss: 0.0012292617466300726
step: 420, loss: 0.025700025260448456
step: 430, loss: 0.06141280382871628
step: 440, loss: 0.008214440196752548
step: 450, loss: 0.035062775015830994
step: 460, loss: 0.022288339212536812
step: 470, loss: 0.04530414938926697
step: 480, loss: 0.02903992310166359
step: 490, loss: 0.021091517060995102
step: 500, loss: 0.02555692568421364
step: 510, loss: 0.001433841185644269
step: 520, loss: 0.060115378350019455
step: 530, loss: 5.519637488760054e-05
step: 540, loss: 0.04791311174631119
step: 550, loss: 0.026140382513403893
step: 560, loss: 0.001696604653261602
step: 570, loss: 0.05260447785258293
step: 580, loss: 0.020110324025154114
step: 590, loss: 0.04004546254873276
step: 600, loss: 0.05662959814071655
step: 610, loss: 0.013093595393002033
step: 620, loss: 0.04495580494403839
step: 630, loss: 0.02018686756491661
step: 640, loss: 0.025595461949706078
step: 650, loss: 0.0013593557523563504
step: 660, loss: 0.03369700536131859
step: 670, loss: 0.0001357765431748703
step: 680, loss: 0.00023421536025125533
step: 690, loss: 0.0034793163649737835
step: 700, loss: 1.3481610949384049e-05
step: 710, loss: 0.05273893103003502
step: 720, loss: 0.04241017624735832
step: 730, loss: 0.028467565774917603
step: 740, loss: 0.019641032442450523
step: 750, loss: 0.05856576934456825
step: 760, loss: 0.009627101942896843
step: 770, loss: 0.0002842938993126154
step: 780, loss: 0.049233246594667435
step: 790, loss: 0.0006003588205203414
step: 800, loss: 0.0245352815836668
step: 810, loss: 0.020062608644366264
step: 820, loss: 0.024214060977101326
step: 830, loss: 0.03895900771021843
step: 840, loss: 0.026269862428307533
step: 850, loss: 0.03369024395942688
step: 860, loss: 0.039097268134355545
step: 870, loss: 0.01815721206367016
step: 880, loss: 0.060882095247507095
step: 890, loss: 0.050835590809583664
step: 900, loss: 0.05060143396258354
step: 910, loss: 0.02630668692290783
step: 920, loss: 0.008969672955572605
step: 930, loss: 0.016099626198410988
step: 940, loss: 5.460509055410512e-05
step: 950, loss: 0.10148853063583374
step: 960, loss: 0.00181092310231179
step: 970, loss: 0.028900252655148506
epoch 16: dev_f1=0.9370300751879698, f1=0.926463700234192, best_f1=0.9423513390830685
step: 0, loss: 0.0469171367585659
step: 10, loss: 0.00012559893366415054
step: 20, loss: 5.5302847613347694e-05
step: 30, loss: 0.08010616898536682
step: 40, loss: 0.010555113665759563
step: 50, loss: 0.00016956048784777522
step: 60, loss: 0.06148156896233559
step: 70, loss: 0.00046321447007358074
step: 80, loss: 0.015185198746621609
step: 90, loss: 0.027268191799521446
step: 100, loss: 0.0007713362574577332
step: 110, loss: 0.001047360128723085
step: 120, loss: 0.02208801358938217
step: 130, loss: 1.438674189557787e-05
step: 140, loss: 0.023406758904457092
step: 150, loss: 0.00012741281534545124
step: 160, loss: 0.020324241369962692
step: 170, loss: 0.03845415264368057
step: 180, loss: 7.071851723594591e-05
step: 190, loss: 0.026343345642089844
step: 200, loss: 0.03947613388299942
step: 210, loss: 0.01062091812491417
step: 220, loss: 0.018886348232626915
step: 230, loss: 0.037739988416433334
step: 240, loss: 0.0017209354555234313
step: 250, loss: 0.032008055597543716
step: 260, loss: 0.027695439755916595
step: 270, loss: 0.015765737742185593
step: 280, loss: 0.07464826107025146
step: 290, loss: 0.023659786209464073
step: 300, loss: 0.042793430387973785
step: 310, loss: 0.021995387971401215
step: 320, loss: 0.041399162262678146
step: 330, loss: 0.04599137604236603
step: 340, loss: 0.012816332280635834
step: 350, loss: 0.021988438442349434
step: 360, loss: 0.01511654257774353
step: 370, loss: 0.0003393386723473668
step: 380, loss: 0.03763469681143761
step: 390, loss: 0.01192465890198946
step: 400, loss: 0.047699086368083954
step: 410, loss: 0.12419980019330978
step: 420, loss: 0.002522336784750223
step: 430, loss: 0.01620578207075596
step: 440, loss: 0.08475887030363083
step: 450, loss: 0.010523460805416107
step: 460, loss: 0.0037003252655267715
step: 470, loss: 0.03925785422325134
step: 480, loss: 0.029517343267798424
step: 490, loss: 0.024430282413959503
step: 500, loss: 0.016759147867560387
step: 510, loss: 0.020480340346693993
step: 520, loss: 0.03534872084856033
step: 530, loss: 0.06715064495801926
step: 540, loss: 9.399190457770601e-05
step: 550, loss: 0.020157597959041595
step: 560, loss: 0.0006659376085735857
step: 570, loss: 0.04605136439204216
step: 580, loss: 0.08311258256435394
step: 590, loss: 0.02987941913306713
step: 600, loss: 0.034205302596092224
step: 610, loss: 0.0007147264550440013
step: 620, loss: 0.05476722866296768
step: 630, loss: 0.011368293315172195
step: 640, loss: 0.054106008261442184
step: 650, loss: 0.026813283562660217
step: 660, loss: 0.050483766943216324
step: 670, loss: 0.029641347005963326
step: 680, loss: 0.03549044579267502
step: 690, loss: 0.040955834090709686
step: 700, loss: 0.0029384754598140717
step: 710, loss: 0.01748538762331009
step: 720, loss: 0.0224409569054842
step: 730, loss: 0.031486816704273224
step: 740, loss: 0.0867566242814064
step: 750, loss: 0.04719926416873932
step: 760, loss: 0.029849158599972725
step: 770, loss: 0.021021157503128052
step: 780, loss: 0.05232412368059158
step: 790, loss: 0.024815166369080544
step: 800, loss: 0.01940731145441532
step: 810, loss: 0.023926090449094772
step: 820, loss: 0.04930570349097252
step: 830, loss: 0.028653450310230255
step: 840, loss: 0.05638283118605614
step: 850, loss: 0.002181819174438715
step: 860, loss: 0.0389505997300148
step: 870, loss: 0.05217605084180832
step: 880, loss: 0.014238509349524975
step: 890, loss: 0.03603953495621681
step: 900, loss: 6.943657353986055e-05
step: 910, loss: 0.04273432865738869
step: 920, loss: 0.047757428139448166
step: 930, loss: 0.016866400837898254
step: 940, loss: 0.012621031142771244
step: 950, loss: 0.05007781833410263
step: 960, loss: 0.021595830097794533
step: 970, loss: 0.015154952183365822
epoch 17: dev_f1=0.9400278940027894, f1=0.9283720930232557, best_f1=0.9423513390830685
step: 0, loss: 0.07775222510099411
step: 10, loss: 0.03338273987174034
step: 20, loss: 0.0909564197063446
step: 30, loss: 0.0717553049325943
step: 40, loss: 9.788858005777001e-05
step: 50, loss: 6.451531953644007e-05
step: 60, loss: 0.0007310302462428808
step: 70, loss: 0.019627276808023453
step: 80, loss: 9.780319669516757e-05
step: 90, loss: 0.03609815612435341
step: 100, loss: 4.521759910858236e-05
step: 110, loss: 0.03786979243159294
step: 120, loss: 0.0025123117957264185
step: 130, loss: 0.024649525061249733
step: 140, loss: 0.022848064079880714
step: 150, loss: 0.027815992012619972
step: 160, loss: 0.003343509742990136
step: 170, loss: 0.06181429699063301
step: 180, loss: 0.05410243198275566
step: 190, loss: 0.03979261592030525
step: 200, loss: 0.027320541441440582
step: 210, loss: 0.03588191792368889
step: 220, loss: 0.00020569450862240046
step: 230, loss: 0.00032377723255194724
step: 240, loss: 0.0007054798770695925
step: 250, loss: 0.0162938442081213
step: 260, loss: 0.04044482111930847
step: 270, loss: 0.029509540647268295
step: 280, loss: 0.015549457632005215
step: 290, loss: 0.0928744301199913
step: 300, loss: 0.01841006428003311
step: 310, loss: 0.04611645266413689
step: 320, loss: 0.12271898239850998
step: 330, loss: 0.053717195987701416
step: 340, loss: 0.09863029420375824
step: 350, loss: 0.03807282820343971
step: 360, loss: 7.439115870511159e-05
step: 370, loss: 0.0004425365768838674
step: 380, loss: 0.036407485604286194
step: 390, loss: 0.03904357925057411
step: 400, loss: 0.0003341599367558956
step: 410, loss: 0.07232344895601273
step: 420, loss: 0.053850796073675156
step: 430, loss: 0.0004144929989706725
step: 440, loss: 3.196720717824064e-05
step: 450, loss: 0.0890955924987793
step: 460, loss: 0.036842431873083115
step: 470, loss: 0.0031540500931441784
step: 480, loss: 0.033588603138923645
step: 490, loss: 0.01515224389731884
step: 500, loss: 0.0005218489677645266
step: 510, loss: 0.021865151822566986
step: 520, loss: 0.04274517297744751
step: 530, loss: 0.00011935149814235047
step: 540, loss: 0.03171171247959137
step: 550, loss: 0.0016430141404271126
step: 560, loss: 0.09797754138708115
step: 570, loss: 0.05275491625070572
step: 580, loss: 0.08323436230421066
step: 590, loss: 0.03522220626473427
step: 600, loss: 0.03756314516067505
step: 610, loss: 0.0031829753424972296
step: 620, loss: 0.03154005482792854
step: 630, loss: 0.019156303256750107
step: 640, loss: 0.033066533505916595
step: 650, loss: 0.0005269564571790397
step: 660, loss: 0.02555108815431595
step: 670, loss: 0.04313431307673454
step: 680, loss: 0.011938408017158508
step: 690, loss: 0.01609197072684765
step: 700, loss: 0.0006842004950158298
step: 710, loss: 0.00011504482245072722
step: 720, loss: 0.05492750182747841
step: 730, loss: 0.030318766832351685
step: 740, loss: 0.08366119861602783
step: 750, loss: 0.027864908799529076
step: 760, loss: 0.1251489520072937
step: 770, loss: 0.03344464674592018
step: 780, loss: 0.01994096301496029
step: 790, loss: 6.930940435267985e-05
step: 800, loss: 0.03198107331991196
step: 810, loss: 0.020647060126066208
step: 820, loss: 0.05854176729917526
step: 830, loss: 0.05657724663615227
step: 840, loss: 0.07999750226736069
step: 850, loss: 0.01342011708766222
step: 860, loss: 0.004254269413650036
step: 870, loss: 0.0001217999160871841
step: 880, loss: 0.0037121144123375416
step: 890, loss: 0.024132220074534416
step: 900, loss: 0.00023855194740463048
step: 910, loss: 0.007121018599718809
step: 920, loss: 0.021523715928196907
step: 930, loss: 1.4148131413094234e-05
step: 940, loss: 0.010488166473805904
step: 950, loss: 0.0021121897734701633
step: 960, loss: 0.0002942898136097938
step: 970, loss: 0.021144291386008263
epoch 18: dev_f1=0.9370892018779343, f1=0.9272641952135147, best_f1=0.9423513390830685
step: 0, loss: 0.013385375030338764
step: 10, loss: 0.019141746684908867
step: 20, loss: 0.03991926461458206
step: 30, loss: 0.009713348932564259
step: 40, loss: 0.027399882674217224
step: 50, loss: 5.740812775911763e-05
step: 60, loss: 0.014127545990049839
step: 70, loss: 0.04045134410262108
step: 80, loss: 0.00011590390931814909
step: 90, loss: 0.018257608637213707
step: 100, loss: 0.02441861853003502
step: 110, loss: 0.00011034322233172134
step: 120, loss: 0.01937977410852909
step: 130, loss: 0.02838064730167389
step: 140, loss: 0.06532931327819824
step: 150, loss: 0.016978520900011063
step: 160, loss: 0.00013637356460094452
step: 170, loss: 0.05354911834001541
step: 180, loss: 0.038578592240810394
step: 190, loss: 0.09118537604808807
step: 200, loss: 0.10958781838417053
step: 210, loss: 0.0015807199524715543
step: 220, loss: 0.0508883111178875
step: 230, loss: 0.10071024298667908
step: 240, loss: 4.234797597746365e-05
step: 250, loss: 0.03765711560845375
step: 260, loss: 0.06959560513496399
step: 270, loss: 0.08759670704603195
step: 280, loss: 0.03706417977809906
step: 290, loss: 0.03331909701228142
step: 300, loss: 0.0005535059608519077
step: 310, loss: 0.04049263894557953
step: 320, loss: 0.11733508855104446
step: 330, loss: 0.04628608003258705
step: 340, loss: 0.00040400613215751946
step: 350, loss: 0.04613139107823372
step: 360, loss: 0.01041873823851347
step: 370, loss: 2.5779138013604097e-05
step: 380, loss: 0.059334442019462585
step: 390, loss: 0.03561534360051155
step: 400, loss: 0.0005304823280312121
step: 410, loss: 0.020461423322558403
step: 420, loss: 0.031229427084326744
step: 430, loss: 0.001228069537319243
step: 440, loss: 0.044139210134744644
step: 450, loss: 0.027707092463970184
step: 460, loss: 0.04669090732932091
step: 470, loss: 0.03901933506131172
step: 480, loss: 0.018448511138558388
step: 490, loss: 0.022994553670287132
step: 500, loss: 0.07944164425134659
step: 510, loss: 0.036238089203834534
step: 520, loss: 0.02894304133951664
step: 530, loss: 0.007984212599694729
step: 540, loss: 0.007982990704476833
step: 550, loss: 0.0013083942467346787
step: 560, loss: 0.002786582335829735
step: 570, loss: 0.02296723984181881
step: 580, loss: 0.03729463368654251
step: 590, loss: 2.5767716579139233e-05
step: 600, loss: 0.07175326347351074
step: 610, loss: 0.06681593507528305
step: 620, loss: 0.020396729931235313
step: 630, loss: 0.04162906855344772
step: 640, loss: 0.04365058243274689
step: 650, loss: 0.025046907365322113
step: 660, loss: 0.03019855171442032
step: 670, loss: 0.05678090453147888
step: 680, loss: 0.016727525740861893
step: 690, loss: 1.2229882486280985e-05
step: 700, loss: 0.0581616535782814
step: 710, loss: 0.03503253683447838
step: 720, loss: 0.023758945986628532
step: 730, loss: 8.717135642655194e-06
step: 740, loss: 5.912036431254819e-05
step: 750, loss: 0.030105318874120712
step: 760, loss: 0.02946539595723152
step: 770, loss: 0.0026157177053391933
step: 780, loss: 0.017145365476608276
step: 790, loss: 0.014573351480066776
step: 800, loss: 0.04357701539993286
step: 810, loss: 0.01663690060377121
step: 820, loss: 0.01470242254436016
step: 830, loss: 0.01695762574672699
step: 840, loss: 0.09173253178596497
step: 850, loss: 0.011594830080866814
step: 860, loss: 0.044142190366983414
step: 870, loss: 0.027454383671283722
step: 880, loss: 0.00015576173609588295
step: 890, loss: 0.06013423204421997
step: 900, loss: 0.0029174997471272945
step: 910, loss: 0.0017656477866694331
step: 920, loss: 0.015628347173333168
step: 930, loss: 0.041642483323812485
step: 940, loss: 0.03873760998249054
step: 950, loss: 0.03134451434016228
step: 960, loss: 0.03905313462018967
step: 970, loss: 0.08214858174324036
epoch 19: dev_f1=0.9349056603773584, f1=0.9269901083372586, best_f1=0.9423513390830685
step: 0, loss: 0.012563258409500122
step: 10, loss: 3.17082267429214e-05
step: 20, loss: 0.08175921440124512
step: 30, loss: 0.019497796893119812
step: 40, loss: 0.025516360998153687
step: 50, loss: 0.016340695321559906
step: 60, loss: 0.00030781253008171916
step: 70, loss: 0.06203524023294449
step: 80, loss: 0.023382745683193207
step: 90, loss: 0.001461069448851049
step: 100, loss: 0.017070047557353973
step: 110, loss: 0.000623608473688364
step: 120, loss: 0.0345798134803772
step: 130, loss: 0.021352695301175117
step: 140, loss: 7.369418744929135e-05
step: 150, loss: 0.06917781382799149
step: 160, loss: 0.022410191595554352
step: 170, loss: 5.595583934336901e-05
step: 180, loss: 0.00011074899521190673
step: 190, loss: 0.03103369101881981
step: 200, loss: 0.04667004942893982
step: 210, loss: 0.021728456020355225
step: 220, loss: 0.03919876739382744
step: 230, loss: 0.04373113811016083
step: 240, loss: 0.01960928924381733
step: 250, loss: 0.02692301571369171
step: 260, loss: 6.0105743614258245e-05
step: 270, loss: 0.014171618968248367
step: 280, loss: 0.11756452172994614
step: 290, loss: 0.04624505341053009
step: 300, loss: 0.03606757894158363
step: 310, loss: 0.04886673390865326
step: 320, loss: 0.019023964181542397
step: 330, loss: 0.07776478677988052
step: 340, loss: 0.0665004551410675
step: 350, loss: 6.624399247812107e-05
step: 360, loss: 2.842425055860076e-05
step: 370, loss: 0.016362611204385757
step: 380, loss: 0.01397748850286007
step: 390, loss: 0.021769622340798378
step: 400, loss: 0.03078373335301876
step: 410, loss: 0.00019169398001395166
step: 420, loss: 0.05913211405277252
step: 430, loss: 0.021856145933270454
step: 440, loss: 0.029709577560424805
step: 450, loss: 0.024006182327866554
step: 460, loss: 0.0013069062260910869
step: 470, loss: 0.006387622095644474
step: 480, loss: 0.08174879103899002
step: 490, loss: 1.2311790669627953e-05
step: 500, loss: 0.03431409224867821
step: 510, loss: 5.806772969663143e-05
step: 520, loss: 0.08670675754547119
step: 530, loss: 0.03713904321193695
step: 540, loss: 0.00012092460383428261
step: 550, loss: 0.03143775463104248
step: 560, loss: 0.00023368789697997272
step: 570, loss: 0.01963234134018421
step: 580, loss: 3.8659964047838e-05
step: 590, loss: 0.1013593003153801
step: 600, loss: 0.037034858018159866
step: 610, loss: 0.0369742326438427
step: 620, loss: 3.575900700525381e-05
step: 630, loss: 0.0442473329603672
step: 640, loss: 0.00026961605180986226
step: 650, loss: 4.397906377562322e-05
step: 660, loss: 0.04823434725403786
step: 670, loss: 0.017040520906448364
step: 680, loss: 0.0013038805918768048
step: 690, loss: 0.0025610721204429865
step: 700, loss: 0.02965969406068325
step: 710, loss: 0.04690093174576759
step: 720, loss: 0.03192581236362457
step: 730, loss: 0.0006669779540970922
step: 740, loss: 0.025203609839081764
step: 750, loss: 0.001548966160044074
step: 760, loss: 0.06320463120937347
step: 770, loss: 2.005882743105758e-05
step: 780, loss: 0.0019144619582220912
step: 790, loss: 0.00011690076644299552
step: 800, loss: 0.06510406732559204
step: 810, loss: 0.017418723553419113
step: 820, loss: 0.004737853072583675
step: 830, loss: 0.02265147678554058
step: 840, loss: 0.0005649939994327724
step: 850, loss: 0.07376476377248764
step: 860, loss: 3.0887098546372727e-05
step: 870, loss: 0.0001458085753256455
step: 880, loss: 0.033812131732702255
step: 890, loss: 0.04083681106567383
step: 900, loss: 0.044141609221696854
step: 910, loss: 0.0544571653008461
step: 920, loss: 0.019019292667508125
step: 930, loss: 0.047638095915317535
step: 940, loss: 0.0044036200270056725
step: 950, loss: 0.0001800439495127648
step: 960, loss: 0.0027513676322996616
step: 970, loss: 0.015198661014437675
epoch 20: dev_f1=0.9362907031618688, f1=0.926921263554927, best_f1=0.9423513390830685
