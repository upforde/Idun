cuda
Device: cuda
step: 0, loss: 0.6964612007141113
step: 10, loss: 0.2450638711452484
step: 20, loss: 0.17718668282032013
step: 30, loss: 0.6514121890068054
step: 40, loss: 0.12294851243495941
step: 50, loss: 0.10352206975221634
step: 60, loss: 0.297750860452652
step: 70, loss: 0.14899900555610657
step: 80, loss: 0.10716511309146881
step: 90, loss: 0.28904929757118225
step: 100, loss: 0.32507479190826416
step: 110, loss: 0.20142675936222076
step: 120, loss: 0.19949078559875488
step: 130, loss: 0.11423717439174652
step: 140, loss: 0.14088839292526245
step: 150, loss: 0.1377967894077301
step: 160, loss: 0.06161320209503174
step: 170, loss: 0.07746022939682007
step: 180, loss: 0.11184260994195938
step: 190, loss: 0.17300748825073242
step: 200, loss: 0.12107959389686584
step: 210, loss: 0.13512127101421356
step: 220, loss: 0.14563071727752686
step: 230, loss: 0.12458089739084244
step: 240, loss: 0.03514186665415764
step: 250, loss: 0.07678665220737457
step: 260, loss: 0.09253817796707153
step: 270, loss: 0.11723514646291733
step: 280, loss: 0.09925120323896408
step: 290, loss: 0.09788887202739716
step: 300, loss: 0.15130114555358887
step: 310, loss: 0.08575168251991272
step: 320, loss: 0.05888914316892624
step: 330, loss: 0.29525262117385864
step: 340, loss: 0.14393945038318634
step: 350, loss: 0.09691513329744339
step: 360, loss: 0.17388834059238434
step: 370, loss: 0.15084829926490784
step: 380, loss: 0.035652000457048416
step: 390, loss: 0.07691159099340439
step: 400, loss: 0.21006691455841064
step: 410, loss: 0.3222420811653137
step: 420, loss: 0.1716202348470688
step: 430, loss: 0.2200392782688141
step: 440, loss: 0.133097842335701
step: 450, loss: 0.1708800494670868
step: 460, loss: 0.1217343658208847
step: 470, loss: 0.08158877491950989
step: 480, loss: 0.08960656076669693
step: 490, loss: 0.054120022803545
step: 500, loss: 0.1052408218383789
step: 510, loss: 0.10810942202806473
step: 520, loss: 0.08447973430156708
step: 530, loss: 0.1333950161933899
step: 540, loss: 0.07678437232971191
step: 550, loss: 0.060878925025463104
step: 560, loss: 0.17524942755699158
step: 570, loss: 0.012588639743626118
step: 580, loss: 0.15377171337604523
step: 590, loss: 0.06793854385614395
step: 600, loss: 0.11214973777532578
step: 610, loss: 0.15376651287078857
step: 620, loss: 0.040423713624477386
step: 630, loss: 0.17516519129276276
step: 640, loss: 0.11557266861200333
step: 650, loss: 0.05632075294852257
step: 660, loss: 0.11965359002351761
step: 670, loss: 0.09146886318922043
step: 680, loss: 0.11827678978443146
step: 690, loss: 0.08236363530158997
step: 700, loss: 0.10117967426776886
step: 710, loss: 0.15813326835632324
step: 720, loss: 0.18873751163482666
step: 730, loss: 0.09904218465089798
step: 740, loss: 0.09496793895959854
step: 750, loss: 0.03868184983730316
step: 760, loss: 0.09842979162931442
step: 770, loss: 0.16310805082321167
step: 780, loss: 0.08108969777822495
step: 790, loss: 0.03599927946925163
step: 800, loss: 0.06510517001152039
step: 810, loss: 0.01724146492779255
step: 820, loss: 0.11766362190246582
step: 830, loss: 0.061615239828825
step: 840, loss: 0.025214482098817825
step: 850, loss: 0.15712745487689972
step: 860, loss: 0.18306849896907806
step: 870, loss: 0.050011441111564636
step: 880, loss: 0.10181170701980591
step: 890, loss: 0.13978169858455658
step: 900, loss: 0.15336544811725616
step: 910, loss: 0.06520742177963257
step: 920, loss: 0.04212898015975952
step: 930, loss: 0.07093726843595505
step: 940, loss: 0.14186309278011322
step: 950, loss: 0.12554419040679932
step: 960, loss: 0.08660556375980377
step: 970, loss: 0.08584629744291306
epoch 1: dev_f1=0.9354838709677419, f1=0.928212162780064, best_f1=0.928212162780064
step: 0, loss: 0.1211378201842308
step: 10, loss: 0.16524964570999146
step: 20, loss: 0.22304660081863403
step: 30, loss: 0.09401854127645493
step: 40, loss: 0.05207355320453644
step: 50, loss: 0.01614837907254696
step: 60, loss: 0.07652357220649719
step: 70, loss: 0.11870910972356796
step: 80, loss: 0.12652818858623505
step: 90, loss: 0.08403891324996948
step: 100, loss: 0.09657876193523407
step: 110, loss: 0.06508362293243408
step: 120, loss: 0.07160421460866928
step: 130, loss: 0.03266127407550812
step: 140, loss: 0.039619628340005875
step: 150, loss: 0.0893622562289238
step: 160, loss: 0.02380526438355446
step: 170, loss: 0.10588623583316803
step: 180, loss: 0.05813455581665039
step: 190, loss: 0.10809609293937683
step: 200, loss: 0.04469352960586548
step: 210, loss: 0.070655956864357
step: 220, loss: 0.08539950847625732
step: 230, loss: 0.12843887507915497
step: 240, loss: 0.04107874631881714
step: 250, loss: 0.10073421895503998
step: 260, loss: 0.0968862771987915
step: 270, loss: 0.07539546489715576
step: 280, loss: 0.12479247152805328
step: 290, loss: 0.15268929302692413
step: 300, loss: 0.1679326444864273
step: 310, loss: 0.06624913960695267
step: 320, loss: 0.10648973286151886
step: 330, loss: 0.20279164612293243
step: 340, loss: 0.05917787924408913
step: 350, loss: 0.15425989031791687
step: 360, loss: 0.16280701756477356
step: 370, loss: 0.10195643454790115
step: 380, loss: 0.1597958207130432
step: 390, loss: 0.08287708461284637
step: 400, loss: 0.1044728234410286
step: 410, loss: 0.12099061161279678
step: 420, loss: 0.11426958441734314
step: 430, loss: 0.06807461380958557
step: 440, loss: 0.07624007761478424
step: 450, loss: 0.053223852068185806
step: 460, loss: 0.07885554432868958
step: 470, loss: 0.05259426683187485
step: 480, loss: 0.05198395252227783
step: 490, loss: 0.16556866466999054
step: 500, loss: 0.060710497200489044
step: 510, loss: 0.1914556324481964
step: 520, loss: 0.2224983274936676
step: 530, loss: 0.08417478948831558
step: 540, loss: 0.1845836192369461
step: 550, loss: 0.0910705104470253
step: 560, loss: 0.08143146336078644
step: 570, loss: 0.04278650879859924
step: 580, loss: 0.10244223475456238
step: 590, loss: 0.1872379630804062
step: 600, loss: 0.03171366825699806
step: 610, loss: 0.08824516832828522
step: 620, loss: 0.03610895946621895
step: 630, loss: 0.06935194879770279
step: 640, loss: 0.013152876868844032
step: 650, loss: 0.10644552111625671
step: 660, loss: 0.12227942049503326
step: 670, loss: 0.12452266365289688
step: 680, loss: 0.14921371638774872
step: 690, loss: 0.01228050235658884
step: 700, loss: 0.06564170867204666
step: 710, loss: 0.026020405814051628
step: 720, loss: 0.07187429070472717
step: 730, loss: 0.18197254836559296
step: 740, loss: 0.11603352427482605
step: 750, loss: 0.11184998601675034
step: 760, loss: 0.10582920163869858
step: 770, loss: 0.344710111618042
step: 780, loss: 0.015321660786867142
step: 790, loss: 0.09903384000062943
step: 800, loss: 0.030201289802789688
step: 810, loss: 0.3283059597015381
step: 820, loss: 0.1300991177558899
step: 830, loss: 0.10109349340200424
step: 840, loss: 0.054394833743572235
step: 850, loss: 0.050098977982997894
step: 860, loss: 0.16820645332336426
step: 870, loss: 0.09003021568059921
step: 880, loss: 0.0656280592083931
step: 890, loss: 0.10268215090036392
step: 900, loss: 0.0765376091003418
step: 910, loss: 0.07340671122074127
step: 920, loss: 0.13359257578849792
step: 930, loss: 0.08322527259588242
step: 940, loss: 0.1545109897851944
step: 950, loss: 0.07274136692285538
step: 960, loss: 0.024530872702598572
step: 970, loss: 0.09050669521093369
epoch 2: dev_f1=0.9377817853922452, f1=0.935903182429404, best_f1=0.935903182429404
step: 0, loss: 0.08007489889860153
step: 10, loss: 0.01763167604804039
step: 20, loss: 0.01812114007771015
step: 30, loss: 0.15789808332920074
step: 40, loss: 0.07187519967556
step: 50, loss: 0.034439802169799805
step: 60, loss: 0.08530456572771072
step: 70, loss: 0.03922320529818535
step: 80, loss: 0.1477973759174347
step: 90, loss: 0.03187961503863335
step: 100, loss: 0.022316161543130875
step: 110, loss: 0.05901069566607475
step: 120, loss: 0.07087478041648865
step: 130, loss: 0.029152464121580124
step: 140, loss: 0.19820375740528107
step: 150, loss: 0.11724693328142166
step: 160, loss: 0.10604225099086761
step: 170, loss: 0.03529531881213188
step: 180, loss: 0.15626166760921478
step: 190, loss: 0.14292429387569427
step: 200, loss: 0.07085126638412476
step: 210, loss: 0.06202920526266098
step: 220, loss: 0.07342985272407532
step: 230, loss: 0.08873562514781952
step: 240, loss: 0.05878577381372452
step: 250, loss: 0.1476168930530548
step: 260, loss: 0.20044006407260895
step: 270, loss: 0.08153235912322998
step: 280, loss: 0.06322711706161499
step: 290, loss: 0.11768224835395813
step: 300, loss: 0.029265088960528374
step: 310, loss: 0.19494180381298065
step: 320, loss: 0.12320595979690552
step: 330, loss: 0.16624906659126282
step: 340, loss: 0.0885356143116951
step: 350, loss: 0.03693493455648422
step: 360, loss: 0.0767284706234932
step: 370, loss: 0.11256590485572815
step: 380, loss: 0.11289174854755402
step: 390, loss: 0.09173113107681274
step: 400, loss: 0.23705707490444183
step: 410, loss: 0.0733831375837326
step: 420, loss: 0.12726640701293945
step: 430, loss: 0.0161436814814806
step: 440, loss: 0.11443575471639633
step: 450, loss: 0.10642974078655243
step: 460, loss: 0.07544799894094467
step: 470, loss: 0.11541607230901718
step: 480, loss: 0.009154769591987133
step: 490, loss: 0.05963395908474922
step: 500, loss: 0.09247899800539017
step: 510, loss: 0.11233115941286087
step: 520, loss: 0.06341087073087692
step: 530, loss: 0.014151928015053272
step: 540, loss: 0.0375998429954052
step: 550, loss: 0.11125857383012772
step: 560, loss: 0.19132637977600098
step: 570, loss: 0.0464945062994957
step: 580, loss: 0.10464640706777573
step: 590, loss: 0.09687405824661255
step: 600, loss: 0.019550012424588203
step: 610, loss: 0.3496999740600586
step: 620, loss: 0.02677212841808796
step: 630, loss: 0.07391229271888733
step: 640, loss: 0.12286466360092163
step: 650, loss: 0.18665115535259247
step: 660, loss: 0.02107156626880169
step: 670, loss: 0.00939065683633089
step: 680, loss: 0.05111060291528702
step: 690, loss: 0.1536875218153
step: 700, loss: 0.06166457757353783
step: 710, loss: 0.07721353322267532
step: 720, loss: 0.026622094213962555
step: 730, loss: 0.20848935842514038
step: 740, loss: 0.10877617448568344
step: 750, loss: 0.033678166568279266
step: 760, loss: 0.08805103600025177
step: 770, loss: 0.06549894064664841
step: 780, loss: 0.0871696025133133
step: 790, loss: 0.052205976098775864
step: 800, loss: 0.11064864695072174
step: 810, loss: 0.07601145654916763
step: 820, loss: 0.15589310228824615
step: 830, loss: 0.17654690146446228
step: 840, loss: 0.09514033049345016
step: 850, loss: 0.015592904761433601
step: 860, loss: 0.016152897849678993
step: 870, loss: 0.08417132496833801
step: 880, loss: 0.05110594257712364
step: 890, loss: 0.045658744871616364
step: 900, loss: 0.07533859461545944
step: 910, loss: 0.09075859189033508
step: 920, loss: 0.12399284541606903
step: 930, loss: 0.019914165139198303
step: 940, loss: 0.12855851650238037
step: 950, loss: 0.0722200870513916
step: 960, loss: 0.05099320784211159
step: 970, loss: 0.33380284905433655
epoch 3: dev_f1=0.9289772727272728, f1=0.9171793658305726, best_f1=0.935903182429404
step: 0, loss: 0.04278707504272461
step: 10, loss: 0.04327290505170822
step: 20, loss: 0.08711665123701096
step: 30, loss: 0.04104362428188324
step: 40, loss: 0.14170844852924347
step: 50, loss: 0.038552578538656235
step: 60, loss: 0.021108444780111313
step: 70, loss: 0.04792163148522377
step: 80, loss: 0.10359703004360199
step: 90, loss: 0.1809515804052353
step: 100, loss: 0.07551192492246628
step: 110, loss: 0.11931239068508148
step: 120, loss: 0.03636444732546806
step: 130, loss: 0.028374552726745605
step: 140, loss: 0.015096436254680157
step: 150, loss: 0.01282731257379055
step: 160, loss: 0.09586073458194733
step: 170, loss: 0.07017171382904053
step: 180, loss: 0.040455352514982224
step: 190, loss: 0.01555562112480402
step: 200, loss: 0.0517919585108757
step: 210, loss: 0.039865873754024506
step: 220, loss: 0.017971741035580635
step: 230, loss: 0.14347131550312042
step: 240, loss: 0.062255218625068665
step: 250, loss: 0.05253099650144577
step: 260, loss: 0.17721600830554962
step: 270, loss: 0.07793298363685608
step: 280, loss: 5.167724521015771e-05
step: 290, loss: 0.06389652192592621
step: 300, loss: 0.05208856984972954
step: 310, loss: 0.01419852301478386
step: 320, loss: 0.15557725727558136
step: 330, loss: 0.02304142899811268
step: 340, loss: 0.14099843800067902
step: 350, loss: 0.08386754989624023
step: 360, loss: 0.06375455856323242
step: 370, loss: 0.04428683593869209
step: 380, loss: 0.02509489469230175
step: 390, loss: 0.04493344947695732
step: 400, loss: 0.020567499101161957
step: 410, loss: 0.07489839941263199
step: 420, loss: 0.12119389325380325
step: 430, loss: 0.06397779285907745
step: 440, loss: 0.07831543684005737
step: 450, loss: 0.04483513534069061
step: 460, loss: 0.12114112079143524
step: 470, loss: 0.08427993953227997
step: 480, loss: 0.029002808034420013
step: 490, loss: 0.037761662155389786
step: 500, loss: 0.1516481190919876
step: 510, loss: 0.2354779839515686
step: 520, loss: 0.05601319670677185
step: 530, loss: 0.08814510703086853
step: 540, loss: 0.07047752290964127
step: 550, loss: 0.11245564371347427
step: 560, loss: 0.07304175943136215
step: 570, loss: 0.05476498603820801
step: 580, loss: 0.06735719740390778
step: 590, loss: 0.04445328563451767
step: 600, loss: 0.20346926152706146
step: 610, loss: 0.13746021687984467
step: 620, loss: 0.053562864661216736
step: 630, loss: 0.057949796319007874
step: 640, loss: 0.058234069496393204
step: 650, loss: 0.013539092615246773
step: 660, loss: 0.11677885800600052
step: 670, loss: 0.21068750321865082
step: 680, loss: 0.052155498415231705
step: 690, loss: 0.07016690075397491
step: 700, loss: 0.06872326135635376
step: 710, loss: 0.09260018914937973
step: 720, loss: 0.1280897557735443
step: 730, loss: 0.0671360194683075
step: 740, loss: 0.02073204703629017
step: 750, loss: 0.10792313516139984
step: 760, loss: 0.0993930995464325
step: 770, loss: 0.045762643218040466
step: 780, loss: 0.1513984501361847
step: 790, loss: 0.059918712824583054
step: 800, loss: 0.010663819499313831
step: 810, loss: 0.07502415031194687
step: 820, loss: 0.06766689568758011
step: 830, loss: 0.042360592633485794
step: 840, loss: 0.07177312672138214
step: 850, loss: 0.056004494428634644
step: 860, loss: 0.08903586864471436
step: 870, loss: 0.023259639739990234
step: 880, loss: 0.0386209674179554
step: 890, loss: 0.060653381049633026
step: 900, loss: 0.07931297272443771
step: 910, loss: 0.11516284942626953
step: 920, loss: 0.13076499104499817
step: 930, loss: 0.06857089698314667
step: 940, loss: 0.1104280948638916
step: 950, loss: 0.07642345875501633
step: 960, loss: 0.07818147540092468
step: 970, loss: 0.19772577285766602
epoch 4: dev_f1=0.9410698096101541, f1=0.9371893357433347, best_f1=0.9371893357433347
step: 0, loss: 0.051534440368413925
step: 10, loss: 0.12516747415065765
step: 20, loss: 0.028160160407423973
step: 30, loss: 0.021897414699196815
step: 40, loss: 0.0396374873816967
step: 50, loss: 0.028567932546138763
step: 60, loss: 0.06536822021007538
step: 70, loss: 0.20406222343444824
step: 80, loss: 0.02302583120763302
step: 90, loss: 0.1976700723171234
step: 100, loss: 0.05815863981842995
step: 110, loss: 0.08588992059230804
step: 120, loss: 0.0782625675201416
step: 130, loss: 0.0005797990597784519
step: 140, loss: 0.08046603947877884
step: 150, loss: 0.061504632234573364
step: 160, loss: 0.060313932597637177
step: 170, loss: 0.05506517365574837
step: 180, loss: 0.047420941293239594
step: 190, loss: 0.017327183857560158
step: 200, loss: 0.06962728500366211
step: 210, loss: 0.1067095398902893
step: 220, loss: 0.08116161078214645
step: 230, loss: 0.010431604459881783
step: 240, loss: 0.08625894784927368
step: 250, loss: 0.07891403138637543
step: 260, loss: 0.07108739018440247
step: 270, loss: 0.12771449983119965
step: 280, loss: 0.03378581255674362
step: 290, loss: 0.026627592742443085
step: 300, loss: 0.09917062520980835
step: 310, loss: 0.007900240831077099
step: 320, loss: 0.030303362756967545
step: 330, loss: 0.21617412567138672
step: 340, loss: 0.027800846844911575
step: 350, loss: 0.14402364194393158
step: 360, loss: 0.009599931538105011
step: 370, loss: 0.04525977000594139
step: 380, loss: 0.017677394673228264
step: 390, loss: 0.09067877382040024
step: 400, loss: 0.011107174679636955
step: 410, loss: 0.05322806164622307
step: 420, loss: 0.02888277918100357
step: 430, loss: 0.07120248675346375
step: 440, loss: 0.08578100055456161
step: 450, loss: 0.013808327727019787
step: 460, loss: 0.00047390657709911466
step: 470, loss: 0.06159817799925804
step: 480, loss: 0.010050194337964058
step: 490, loss: 0.05768736079335213
step: 500, loss: 0.12093838304281235
step: 510, loss: 0.02825682982802391
step: 520, loss: 0.0662568062543869
step: 530, loss: 0.03995586559176445
step: 540, loss: 0.02357914112508297
step: 550, loss: 0.20010140538215637
step: 560, loss: 0.15089960396289825
step: 570, loss: 0.08951088786125183
step: 580, loss: 0.028672538697719574
step: 590, loss: 0.07003714889287949
step: 600, loss: 0.05621891841292381
step: 610, loss: 0.11176256090402603
step: 620, loss: 0.02352818287909031
step: 630, loss: 0.13988149166107178
step: 640, loss: 0.07901675254106522
step: 650, loss: 0.023552579805254936
step: 660, loss: 0.1080978587269783
step: 670, loss: 0.07684268802404404
step: 680, loss: 0.10106071084737778
step: 690, loss: 0.01729239523410797
step: 700, loss: 0.04767957329750061
step: 710, loss: 0.0839269757270813
step: 720, loss: 0.07084386050701141
step: 730, loss: 0.05318296328186989
step: 740, loss: 0.10389465093612671
step: 750, loss: 0.023341719061136246
step: 760, loss: 0.02189776673913002
step: 770, loss: 0.0032822464127093554
step: 780, loss: 0.0786147341132164
step: 790, loss: 0.02193780243396759
step: 800, loss: 0.04324192926287651
step: 810, loss: 0.01842864230275154
step: 820, loss: 0.05945305898785591
step: 830, loss: 0.04054192826151848
step: 840, loss: 0.1014767736196518
step: 850, loss: 0.10107901692390442
step: 860, loss: 0.12833967804908752
step: 870, loss: 0.12658146023750305
step: 880, loss: 0.1292884200811386
step: 890, loss: 0.05851387977600098
step: 900, loss: 0.01382092572748661
step: 910, loss: 0.06699983775615692
step: 920, loss: 0.10492342710494995
step: 930, loss: 0.014899217523634434
step: 940, loss: 0.08212919533252716
step: 950, loss: 0.04278939217329025
step: 960, loss: 0.17504532635211945
step: 970, loss: 0.03587811812758446
epoch 5: dev_f1=0.9441340782122905, f1=0.9409048938134812, best_f1=0.9409048938134812
step: 0, loss: 0.041507650166749954
step: 10, loss: 0.09759953618049622
step: 20, loss: 0.0629931315779686
step: 30, loss: 0.0444071963429451
step: 40, loss: 0.020850230008363724
step: 50, loss: 0.036670904606580734
step: 60, loss: 0.020639032125473022
step: 70, loss: 0.08789332956075668
step: 80, loss: 0.022984612733125687
step: 90, loss: 0.018394628539681435
step: 100, loss: 0.08208133280277252
step: 110, loss: 0.06417381763458252
step: 120, loss: 0.07742324471473694
step: 130, loss: 0.059875454753637314
step: 140, loss: 0.08838709443807602
step: 150, loss: 0.10566719621419907
step: 160, loss: 0.07649300992488861
step: 170, loss: 0.01805475726723671
step: 180, loss: 0.06488759070634842
step: 190, loss: 0.06325986236333847
step: 200, loss: 0.024106789380311966
step: 210, loss: 0.06018304079771042
step: 220, loss: 0.10210071504116058
step: 230, loss: 0.10557147115468979
step: 240, loss: 0.008139808662235737
step: 250, loss: 0.05146973580121994
step: 260, loss: 0.05967777222394943
step: 270, loss: 0.02117626555263996
step: 280, loss: 0.16715718805789948
step: 290, loss: 0.08135023713111877
step: 300, loss: 0.012719455175101757
step: 310, loss: 0.10717777907848358
step: 320, loss: 0.005154058337211609
step: 330, loss: 0.0840790867805481
step: 340, loss: 0.0676642507314682
step: 350, loss: 0.042675722390413284
step: 360, loss: 0.020807240158319473
step: 370, loss: 0.06916883587837219
step: 380, loss: 0.051330000162124634
step: 390, loss: 0.034937962889671326
step: 400, loss: 0.11719558387994766
step: 410, loss: 0.07559444010257721
step: 420, loss: 0.0403510145843029
step: 430, loss: 0.06033269688487053
step: 440, loss: 0.16136987507343292
step: 450, loss: 0.06756578385829926
step: 460, loss: 0.018502581864595413
step: 470, loss: 0.01582306995987892
step: 480, loss: 0.27169641852378845
step: 490, loss: 0.18124842643737793
step: 500, loss: 0.08848251402378082
step: 510, loss: 0.0886317789554596
step: 520, loss: 0.014735236763954163
step: 530, loss: 0.007915010675787926
step: 540, loss: 0.05419999733567238
step: 550, loss: 0.03186091408133507
step: 560, loss: 0.09300128370523453
step: 570, loss: 0.07351801544427872
step: 580, loss: 0.07834558933973312
step: 590, loss: 0.03198150917887688
step: 600, loss: 0.07914946973323822
step: 610, loss: 0.06637053936719894
step: 620, loss: 0.027075519785284996
step: 630, loss: 0.0103767029941082
step: 640, loss: 0.027362415567040443
step: 650, loss: 0.021919971331954002
step: 660, loss: 0.09226185083389282
step: 670, loss: 0.03234603628516197
step: 680, loss: 0.05669713392853737
step: 690, loss: 0.14487500488758087
step: 700, loss: 0.032296810299158096
step: 710, loss: 0.021961677819490433
step: 720, loss: 0.07416204363107681
step: 730, loss: 0.1236792653799057
step: 740, loss: 8.402467210544273e-05
step: 750, loss: 0.06644179672002792
step: 760, loss: 0.03696770593523979
step: 770, loss: 0.03349200636148453
step: 780, loss: 0.014140206389129162
step: 790, loss: 0.18074838817119598
step: 800, loss: 0.05035409331321716
step: 810, loss: 0.03147699311375618
step: 820, loss: 0.05657840520143509
step: 830, loss: 0.01871168240904808
step: 840, loss: 0.005288558080792427
step: 850, loss: 0.11578329652547836
step: 860, loss: 0.17063894867897034
step: 870, loss: 0.03320329636335373
step: 880, loss: 0.07237762212753296
step: 890, loss: 0.06768835335969925
step: 900, loss: 0.08471023291349411
step: 910, loss: 0.014222383499145508
step: 920, loss: 0.06231353431940079
step: 930, loss: 0.03515150398015976
step: 940, loss: 0.08116031438112259
step: 950, loss: 0.06571603566408157
step: 960, loss: 0.1326349675655365
step: 970, loss: 0.35322701930999756
epoch 6: dev_f1=0.9398806792106471, f1=0.9347329986307622, best_f1=0.9409048938134812
step: 0, loss: 0.020850157365202904
step: 10, loss: 0.008908494375646114
step: 20, loss: 0.055351320654153824
step: 30, loss: 0.06458169221878052
step: 40, loss: 0.016156084835529327
step: 50, loss: 0.02149895392358303
step: 60, loss: 0.015817251056432724
step: 70, loss: 0.03690100461244583
step: 80, loss: 0.03124528005719185
step: 90, loss: 0.010390518233180046
step: 100, loss: 0.026446662843227386
step: 110, loss: 0.08155879378318787
step: 120, loss: 0.0240666214376688
step: 130, loss: 0.013635453768074512
step: 140, loss: 0.07105186581611633
step: 150, loss: 0.029249684885144234
step: 160, loss: 0.04392367601394653
step: 170, loss: 0.11038810759782791
step: 180, loss: 0.12605808675289154
step: 190, loss: 0.05900941416621208
step: 200, loss: 0.07121466845273972
step: 210, loss: 0.03961750119924545
step: 220, loss: 0.31020236015319824
step: 230, loss: 0.061777882277965546
step: 240, loss: 0.012569400481879711
step: 250, loss: 0.11292528361082077
step: 260, loss: 0.03842686489224434
step: 270, loss: 0.08529685437679291
step: 280, loss: 0.010837079957127571
step: 290, loss: 0.07110701501369476
step: 300, loss: 0.015243210829794407
step: 310, loss: 0.05504528060555458
step: 320, loss: 0.06015012785792351
step: 330, loss: 0.016149140894412994
step: 340, loss: 0.026163961738348007
step: 350, loss: 0.015803644433617592
step: 360, loss: 0.09298762679100037
step: 370, loss: 0.222724050283432
step: 380, loss: 0.011565477587282658
step: 390, loss: 0.023992173373699188
step: 400, loss: 0.16283273696899414
step: 410, loss: 0.045990776270627975
step: 420, loss: 0.07103530317544937
step: 430, loss: 0.02346206083893776
step: 440, loss: 0.06111413612961769
step: 450, loss: 0.04342012479901314
step: 460, loss: 0.03084263578057289
step: 470, loss: 0.06667572259902954
step: 480, loss: 0.07222659885883331
step: 490, loss: 0.03761526197195053
step: 500, loss: 0.04992593452334404
step: 510, loss: 0.14630703628063202
step: 520, loss: 0.09078921377658844
step: 530, loss: 0.01856679469347
step: 540, loss: 0.026755541563034058
step: 550, loss: 0.06761359423398972
step: 560, loss: 2.5781964723137207e-05
step: 570, loss: 0.005672293249517679
step: 580, loss: 0.009541566483676434
step: 590, loss: 0.06937896460294724
step: 600, loss: 0.03186628967523575
step: 610, loss: 0.11339568346738815
step: 620, loss: 0.02885858714580536
step: 630, loss: 0.02929559163749218
step: 640, loss: 0.07845233380794525
step: 650, loss: 0.14856374263763428
step: 660, loss: 0.03279665857553482
step: 670, loss: 0.08412683010101318
step: 680, loss: 0.07558825612068176
step: 690, loss: 0.11019840836524963
step: 700, loss: 0.06358939409255981
step: 710, loss: 0.10179899632930756
step: 720, loss: 0.07938236743211746
step: 730, loss: 0.1699102818965912
step: 740, loss: 0.05136552080512047
step: 750, loss: 0.03640434145927429
step: 760, loss: 0.040742818266153336
step: 770, loss: 0.10605932772159576
step: 780, loss: 0.012540388852357864
step: 790, loss: 0.08083802461624146
step: 800, loss: 0.018525870516896248
step: 810, loss: 0.13029296696186066
step: 820, loss: 0.015854492783546448
step: 830, loss: 0.08586420863866806
step: 840, loss: 0.015153760090470314
step: 850, loss: 0.1567782461643219
step: 860, loss: 0.014004077762365341
step: 870, loss: 0.06390891224145889
step: 880, loss: 0.019502580165863037
step: 890, loss: 0.015476803295314312
step: 900, loss: 0.04352625459432602
step: 910, loss: 0.06653659045696259
step: 920, loss: 0.216240793466568
step: 930, loss: 0.12686379253864288
step: 940, loss: 0.033948227763175964
step: 950, loss: 0.10490560531616211
step: 960, loss: 0.022433793172240257
step: 970, loss: 0.021759146824479103
epoch 7: dev_f1=0.9386416861826699, f1=0.9365671641791044, best_f1=0.9409048938134812
step: 0, loss: 0.03283367305994034
step: 10, loss: 0.10861919820308685
step: 20, loss: 0.007031439803540707
step: 30, loss: 0.029534824192523956
step: 40, loss: 0.053817152976989746
step: 50, loss: 0.09097591042518616
step: 60, loss: 0.06734468042850494
step: 70, loss: 0.18790656328201294
step: 80, loss: 0.092815101146698
step: 90, loss: 0.10929117351770401
step: 100, loss: 0.05456084385514259
step: 110, loss: 0.06687323749065399
step: 120, loss: 0.04157042130827904
step: 130, loss: 0.02305074781179428
step: 140, loss: 0.08949350565671921
step: 150, loss: 0.11471662670373917
step: 160, loss: 0.024138236418366432
step: 170, loss: 0.017611665651202202
step: 180, loss: 0.026308275759220123
step: 190, loss: 0.03781444951891899
step: 200, loss: 0.03132661059498787
step: 210, loss: 0.12117081880569458
step: 220, loss: 0.10807150602340698
step: 230, loss: 0.018023353070020676
step: 240, loss: 0.03367554396390915
step: 250, loss: 0.028889594599604607
step: 260, loss: 0.08501993119716644
step: 270, loss: 0.016724254935979843
step: 280, loss: 0.05080772191286087
step: 290, loss: 0.07829245924949646
step: 300, loss: 0.22103272378444672
step: 310, loss: 0.011908535845577717
step: 320, loss: 0.16510003805160522
step: 330, loss: 0.009682049974799156
step: 340, loss: 0.018779342994093895
step: 350, loss: 0.02576359547674656
step: 360, loss: 0.04581642523407936
step: 370, loss: 0.02382512576878071
step: 380, loss: 0.1375732570886612
step: 390, loss: 0.05403581261634827
step: 400, loss: 0.04919256642460823
step: 410, loss: 0.10565263032913208
step: 420, loss: 0.0065827942453324795
step: 430, loss: 0.20207753777503967
step: 440, loss: 0.005566836800426245
step: 450, loss: 0.04055030643939972
step: 460, loss: 0.04505014047026634
step: 470, loss: 0.2250446230173111
step: 480, loss: 0.06172843649983406
step: 490, loss: 0.1370449960231781
step: 500, loss: 0.026546664535999298
step: 510, loss: 0.07405950129032135
step: 520, loss: 0.014189680106937885
step: 530, loss: 0.1417505145072937
step: 540, loss: 0.054465774446725845
step: 550, loss: 0.08951698988676071
step: 560, loss: 0.049104928970336914
step: 570, loss: 0.009191906079649925
step: 580, loss: 0.0510292686522007
step: 590, loss: 0.1299804300069809
step: 600, loss: 0.09961478412151337
step: 610, loss: 0.05928808078169823
step: 620, loss: 0.004141881596297026
step: 630, loss: 0.09202033281326294
step: 640, loss: 0.021615993231534958
step: 650, loss: 0.02364058420062065
step: 660, loss: 0.005171564407646656
step: 670, loss: 0.14286527037620544
step: 680, loss: 0.03538673743605614
step: 690, loss: 0.021994970738887787
step: 700, loss: 0.09489615261554718
step: 710, loss: 0.029642324894666672
step: 720, loss: 0.007856674492359161
step: 730, loss: 0.06330834329128265
step: 740, loss: 0.055048562586307526
step: 750, loss: 0.024687523022294044
step: 760, loss: 0.018169986084103584
step: 770, loss: 0.112686388194561
step: 780, loss: 0.03432125598192215
step: 790, loss: 0.043909765779972076
step: 800, loss: 0.043612897396087646
step: 810, loss: 0.010717308148741722
step: 820, loss: 0.10960082709789276
step: 830, loss: 0.16245649755001068
step: 840, loss: 0.02129152975976467
step: 850, loss: 0.08065957576036453
step: 860, loss: 0.05876413732767105
step: 870, loss: 0.049765925854444504
step: 880, loss: 0.008998394943773746
step: 890, loss: 0.0475141778588295
step: 900, loss: 0.017014721408486366
step: 910, loss: 0.04156674072146416
step: 920, loss: 0.06725401431322098
step: 930, loss: 0.03829560428857803
step: 940, loss: 0.1246703714132309
step: 950, loss: 0.005951012950390577
step: 960, loss: 0.022221781313419342
step: 970, loss: 0.013044902123510838
epoch 8: dev_f1=0.9426229508196722, f1=0.935862691960253, best_f1=0.9409048938134812
step: 0, loss: 0.04479098692536354
step: 10, loss: 0.004378447309136391
step: 20, loss: 0.006807141005992889
step: 30, loss: 0.04400727525353432
step: 40, loss: 0.0561165027320385
step: 50, loss: 0.010557997971773148
step: 60, loss: 0.03412449732422829
step: 70, loss: 0.009627390652894974
step: 80, loss: 0.07906985282897949
step: 90, loss: 0.050532467663288116
step: 100, loss: 0.05928485095500946
step: 110, loss: 0.040378425270318985
step: 120, loss: 0.07738319784402847
step: 130, loss: 0.08557158708572388
step: 140, loss: 0.03782413527369499
step: 150, loss: 0.1063007041811943
step: 160, loss: 0.014635864645242691
step: 170, loss: 0.08878345787525177
step: 180, loss: 0.07201429456472397
step: 190, loss: 0.10828792303800583
step: 200, loss: 0.07645890861749649
step: 210, loss: 0.027218107134103775
step: 220, loss: 0.01420464925467968
step: 230, loss: 0.046689074486494064
step: 240, loss: 0.07966990023851395
step: 250, loss: 0.006620654370635748
step: 260, loss: 0.017198672518134117
step: 270, loss: 0.010240436531603336
step: 280, loss: 0.05791188403964043
step: 290, loss: 0.013220492750406265
step: 300, loss: 0.09011952579021454
step: 310, loss: 0.040598031133413315
step: 320, loss: 0.054614435881376266
step: 330, loss: 0.009154971688985825
step: 340, loss: 0.12757711112499237
step: 350, loss: 0.017525892704725266
step: 360, loss: 0.06759824603796005
step: 370, loss: 0.018536459654569626
step: 380, loss: 0.1425468772649765
step: 390, loss: 0.0851396769285202
step: 400, loss: 0.1557542383670807
step: 410, loss: 0.1566367745399475
step: 420, loss: 0.032497648149728775
step: 430, loss: 0.18684598803520203
step: 440, loss: 0.05080265924334526
step: 450, loss: 0.03501471132040024
step: 460, loss: 0.09254886955022812
step: 470, loss: 0.03361735865473747
step: 480, loss: 0.07591243833303452
step: 490, loss: 0.05404628813266754
step: 500, loss: 0.07508690655231476
step: 510, loss: 0.025642335414886475
step: 520, loss: 0.054866306483745575
step: 530, loss: 0.06522659212350845
step: 540, loss: 0.024276601150631905
step: 550, loss: 0.0943036898970604
step: 560, loss: 0.07525423169136047
step: 570, loss: 0.05942560359835625
step: 580, loss: 0.09112442284822464
step: 590, loss: 0.04324352368712425
step: 600, loss: 0.042037561535835266
step: 610, loss: 0.07431378960609436
step: 620, loss: 0.1267448514699936
step: 630, loss: 0.058598458766937256
step: 640, loss: 0.0378868393599987
step: 650, loss: 0.07748541980981827
step: 660, loss: 0.020162606611847878
step: 670, loss: 0.12766951322555542
step: 680, loss: 0.059695202857255936
step: 690, loss: 0.026453522965312004
step: 700, loss: 0.07657890021800995
step: 710, loss: 0.04795202612876892
step: 720, loss: 0.13240976631641388
step: 730, loss: 0.01409224420785904
step: 740, loss: 0.07106290012598038
step: 750, loss: 0.0205304604023695
step: 760, loss: 0.11998715251684189
step: 770, loss: 0.05984578654170036
step: 780, loss: 0.028416389599442482
step: 790, loss: 0.09461314976215363
step: 800, loss: 0.009621652774512768
step: 810, loss: 0.02492557093501091
step: 820, loss: 0.01601395569741726
step: 830, loss: 0.0008311599376611412
step: 840, loss: 0.11222967505455017
step: 850, loss: 0.19132094085216522
step: 860, loss: 0.032869964838027954
step: 870, loss: 0.012527409940958023
step: 880, loss: 0.05654199793934822
step: 890, loss: 0.04916847124695778
step: 900, loss: 0.026925312355160713
step: 910, loss: 0.10076971352100372
step: 920, loss: 0.03331549093127251
step: 930, loss: 0.12899895012378693
step: 940, loss: 0.11041992157697678
step: 950, loss: 0.025498908013105392
step: 960, loss: 0.08524393290281296
step: 970, loss: 0.02390425093472004
epoch 9: dev_f1=0.9422632794457274, f1=0.9333333333333335, best_f1=0.9409048938134812
step: 0, loss: 0.017541367560625076
step: 10, loss: 0.10033070296049118
step: 20, loss: 0.09152399003505707
step: 30, loss: 0.10420294106006622
step: 40, loss: 0.1193416640162468
step: 50, loss: 0.012644484639167786
step: 60, loss: 0.07211487740278244
step: 70, loss: 0.06364382058382034
step: 80, loss: 0.09004617482423782
step: 90, loss: 0.03513842821121216
step: 100, loss: 0.029516886919736862
step: 110, loss: 0.014514351263642311
step: 120, loss: 0.029435355216264725
step: 130, loss: 0.019446680322289467
step: 140, loss: 0.13454554975032806
step: 150, loss: 0.030716709792613983
step: 160, loss: 0.018212176859378815
step: 170, loss: 0.005875029601156712
step: 180, loss: 0.019657162949442863
step: 190, loss: 0.08509796857833862
step: 200, loss: 0.008538967929780483
step: 210, loss: 0.04987858608365059
step: 220, loss: 0.03766601160168648
step: 230, loss: 0.08854138851165771
step: 240, loss: 0.05213606357574463
step: 250, loss: 0.07143068313598633
step: 260, loss: 0.0001283497258555144
step: 270, loss: 0.04791900888085365
step: 280, loss: 0.05631307512521744
step: 290, loss: 0.15041470527648926
step: 300, loss: 0.08551188558340073
step: 310, loss: 0.010687570087611675
step: 320, loss: 0.08480389416217804
step: 330, loss: 0.09583606570959091
step: 340, loss: 0.032496482133865356
step: 350, loss: 0.03858320787549019
step: 360, loss: 0.01905314438045025
step: 370, loss: 0.15287178754806519
step: 380, loss: 0.014458918944001198
step: 390, loss: 0.06747713685035706
step: 400, loss: 0.04805809259414673
step: 410, loss: 0.0388602688908577
step: 420, loss: 0.08192872256040573
step: 430, loss: 0.007459720596671104
step: 440, loss: 0.06718771159648895
step: 450, loss: 0.07904687523841858
step: 460, loss: 7.91737693361938e-05
step: 470, loss: 0.04367893189191818
step: 480, loss: 0.10103416442871094
step: 490, loss: 0.0486530065536499
step: 500, loss: 0.10760632157325745
step: 510, loss: 0.07729446142911911
step: 520, loss: 0.07845815271139145
step: 530, loss: 0.062288932502269745
step: 540, loss: 0.024696195498108864
step: 550, loss: 0.06837362051010132
step: 560, loss: 0.002278521191328764
step: 570, loss: 0.09678205102682114
step: 580, loss: 0.07497883588075638
step: 590, loss: 0.056196004152297974
step: 600, loss: 0.00846129935234785
step: 610, loss: 0.07626614719629288
step: 620, loss: 0.017077988013625145
step: 630, loss: 0.008510387502610683
step: 640, loss: 0.07942529767751694
step: 650, loss: 0.048539504408836365
step: 660, loss: 0.0006081457249820232
step: 670, loss: 0.08649398386478424
step: 680, loss: 0.09100747108459473
step: 690, loss: 0.15633639693260193
step: 700, loss: 0.09152033179998398
step: 710, loss: 0.029495399445295334
step: 720, loss: 0.06939397752285004
step: 730, loss: 0.08202212303876877
step: 740, loss: 0.07768040150403976
step: 750, loss: 0.07495803385972977
step: 760, loss: 0.02618051879107952
step: 770, loss: 0.06304136663675308
step: 780, loss: 0.011599021963775158
step: 790, loss: 0.0883869007229805
step: 800, loss: 0.024485277011990547
step: 810, loss: 0.021041862666606903
step: 820, loss: 0.06220714747905731
step: 830, loss: 0.06594301760196686
step: 840, loss: 0.010277066379785538
step: 850, loss: 3.0918599804863334e-05
step: 860, loss: 0.08953303843736649
step: 870, loss: 0.07412552088499069
step: 880, loss: 0.026395590975880623
step: 890, loss: 0.07349303364753723
step: 900, loss: 0.023193728178739548
step: 910, loss: 0.04038328304886818
step: 920, loss: 0.029923150315880775
step: 930, loss: 0.007312691304832697
step: 940, loss: 0.08910279721021652
step: 950, loss: 0.07484924048185349
step: 960, loss: 0.01566781848669052
step: 970, loss: 0.01766660250723362
epoch 10: dev_f1=0.937763219466542, f1=0.9327146171693736, best_f1=0.9409048938134812
step: 0, loss: 0.0269828662276268
step: 10, loss: 0.014788039028644562
step: 20, loss: 0.04569428414106369
step: 30, loss: 0.038109149783849716
step: 40, loss: 0.021849753335118294
step: 50, loss: 0.04599877819418907
step: 60, loss: 0.0005421415553428233
step: 70, loss: 0.09178609400987625
step: 80, loss: 0.09697028994560242
step: 90, loss: 0.02698853425681591
step: 100, loss: 0.021411370486021042
step: 110, loss: 0.06669694930315018
step: 120, loss: 0.17107515037059784
step: 130, loss: 0.020288784056901932
step: 140, loss: 0.06266804039478302
step: 150, loss: 0.05571020394563675
step: 160, loss: 0.005521896295249462
step: 170, loss: 0.10265733301639557
step: 180, loss: 0.1026083379983902
step: 190, loss: 0.06280642002820969
step: 200, loss: 0.014315095730125904
step: 210, loss: 0.0036479192785918713
step: 220, loss: 0.13202758133411407
step: 230, loss: 0.08600609749555588
step: 240, loss: 0.08916141837835312
step: 250, loss: 0.030009478330612183
step: 260, loss: 0.015201718546450138
step: 270, loss: 0.007435159757733345
step: 280, loss: 0.051018934696912766
step: 290, loss: 0.04626363143324852
step: 300, loss: 0.010469503700733185
step: 310, loss: 0.024737119674682617
step: 320, loss: 0.0598500519990921
step: 330, loss: 0.1226058155298233
step: 340, loss: 0.02435150183737278
step: 350, loss: 0.1806052029132843
step: 360, loss: 0.12555153667926788
step: 370, loss: 0.13733026385307312
step: 380, loss: 0.009825495071709156
step: 390, loss: 0.009391361847519875
step: 400, loss: 0.013922127895057201
step: 410, loss: 0.11195667833089828
step: 420, loss: 0.05588243156671524
step: 430, loss: 0.0658072829246521
step: 440, loss: 0.05811794474720955
step: 450, loss: 0.019316572695970535
step: 460, loss: 0.0035340627655386925
step: 470, loss: 0.0029570285696536303
step: 480, loss: 0.0050262100994586945
step: 490, loss: 0.022686228156089783
step: 500, loss: 0.033248450607061386
step: 510, loss: 0.027388429269194603
step: 520, loss: 0.09354101866483688
step: 530, loss: 0.01392770279198885
step: 540, loss: 0.012341160327196121
step: 550, loss: 0.03893202543258667
step: 560, loss: 0.03375023230910301
step: 570, loss: 0.02049202471971512
step: 580, loss: 0.04594811424612999
step: 590, loss: 0.08703233301639557
step: 600, loss: 0.033440962433815
step: 610, loss: 0.052771784365177155
step: 620, loss: 0.13863694667816162
step: 630, loss: 0.08191154897212982
step: 640, loss: 0.006867432035505772
step: 650, loss: 0.07447229325771332
step: 660, loss: 0.020343538373708725
step: 670, loss: 0.01272524707019329
step: 680, loss: 0.0014114592922851443
step: 690, loss: 0.031809549778699875
step: 700, loss: 0.03948800265789032
step: 710, loss: 0.07411843538284302
step: 720, loss: 0.016689371317625046
step: 730, loss: 0.0896662250161171
step: 740, loss: 0.05490763857960701
step: 750, loss: 0.07861663401126862
step: 760, loss: 0.07476820051670074
step: 770, loss: 0.02140524610877037
step: 780, loss: 0.18936094641685486
step: 790, loss: 0.04771994799375534
step: 800, loss: 0.0391964428126812
step: 810, loss: 0.08819685876369476
step: 820, loss: 0.08788691461086273
step: 830, loss: 0.10931351780891418
step: 840, loss: 0.00755767896771431
step: 850, loss: 0.02859944850206375
step: 860, loss: 0.14773964881896973
step: 870, loss: 0.045982297509908676
step: 880, loss: 0.04751697927713394
step: 890, loss: 0.0064285267144441605
step: 900, loss: 0.003175242803990841
step: 910, loss: 0.052442118525505066
step: 920, loss: 0.01156068965792656
step: 930, loss: 0.07114672660827637
step: 940, loss: 0.02844175696372986
step: 950, loss: 0.009671172127127647
step: 960, loss: 0.13244563341140747
step: 970, loss: 0.15189343690872192
epoch 11: dev_f1=0.9374714742126883, f1=0.9313324238290132, best_f1=0.9409048938134812
step: 0, loss: 0.013355780392885208
step: 10, loss: 0.05651063099503517
step: 20, loss: 0.04818599298596382
step: 30, loss: 0.012256196700036526
step: 40, loss: 0.07514256238937378
step: 50, loss: 0.04408615455031395
step: 60, loss: 0.08651553094387054
step: 70, loss: 0.033689532428979874
step: 80, loss: 0.05492882430553436
step: 90, loss: 0.10071485489606857
step: 100, loss: 0.012997700832784176
step: 110, loss: 0.04078439250588417
step: 120, loss: 0.043075233697891235
step: 130, loss: 0.031047062948346138
step: 140, loss: 0.031767528504133224
step: 150, loss: 0.028035910800099373
step: 160, loss: 0.018976885825395584
step: 170, loss: 0.0495748370885849
step: 180, loss: 0.06553981453180313
step: 190, loss: 0.08266402781009674
step: 200, loss: 0.010809590108692646
step: 210, loss: 0.017264120280742645
step: 220, loss: 0.016300754621624947
step: 230, loss: 0.017211778089404106
step: 240, loss: 0.011731589213013649
step: 250, loss: 0.02058529481291771
step: 260, loss: 0.04431740939617157
step: 270, loss: 0.04137798771262169
step: 280, loss: 0.006760942284017801
step: 290, loss: 0.04781591519713402
step: 300, loss: 0.134988933801651
step: 310, loss: 0.0132033322006464
step: 320, loss: 0.00510787358507514
step: 330, loss: 0.07925786823034286
step: 340, loss: 0.02658100053668022
step: 350, loss: 0.010743711143732071
step: 360, loss: 0.029170013964176178
step: 370, loss: 0.01090577058494091
step: 380, loss: 0.04650645703077316
step: 390, loss: 0.0006256362539716065
step: 400, loss: 0.0361626073718071
step: 410, loss: 0.020700301975011826
step: 420, loss: 0.010961303487420082
step: 430, loss: 0.028908265754580498
step: 440, loss: 0.02060364931821823
step: 450, loss: 0.008590562269091606
step: 460, loss: 0.11446375399827957
step: 470, loss: 0.07617717236280441
step: 480, loss: 0.017482813447713852
step: 490, loss: 0.10044784098863602
step: 500, loss: 0.07944540679454803
step: 510, loss: 0.0868164673447609
step: 520, loss: 0.06359720230102539
step: 530, loss: 0.07219115644693375
step: 540, loss: 0.005423275288194418
step: 550, loss: 0.0025753523223102093
step: 560, loss: 0.10328784584999084
step: 570, loss: 0.09869302064180374
step: 580, loss: 0.10007134824991226
step: 590, loss: 0.061554595828056335
step: 600, loss: 0.03612270951271057
step: 610, loss: 0.07284615188837051
step: 620, loss: 0.025504058226943016
step: 630, loss: 0.04051223769783974
step: 640, loss: 0.045080240815877914
step: 650, loss: 0.02524908073246479
step: 660, loss: 0.03966404125094414
step: 670, loss: 0.03627627342939377
step: 680, loss: 0.14875918626785278
step: 690, loss: 0.02936374768614769
step: 700, loss: 0.018105626106262207
step: 710, loss: 0.029531555250287056
step: 720, loss: 0.011218146421015263
step: 730, loss: 0.015321346931159496
step: 740, loss: 0.00025142155936919153
step: 750, loss: 0.03972849249839783
step: 760, loss: 0.03655747324228287
step: 770, loss: 0.021592628210783005
step: 780, loss: 0.011516276746988297
step: 790, loss: 0.03905986621975899
step: 800, loss: 0.011433576233685017
step: 810, loss: 0.0017733293352648616
step: 820, loss: 0.1092895120382309
step: 830, loss: 0.00020500074606388807
step: 840, loss: 0.01620299741625786
step: 850, loss: 0.0431857705116272
step: 860, loss: 0.005598047748208046
step: 870, loss: 0.023238487541675568
step: 880, loss: 0.08594026416540146
step: 890, loss: 0.009500589221715927
step: 900, loss: 0.10710716247558594
step: 910, loss: 0.048675958067178726
step: 920, loss: 0.0062431092374026775
step: 930, loss: 0.042674995958805084
step: 940, loss: 0.07675786316394806
step: 950, loss: 0.009813185781240463
step: 960, loss: 0.0381847508251667
step: 970, loss: 0.1375964730978012
epoch 12: dev_f1=0.9396471680594244, f1=0.9319227230910764, best_f1=0.9409048938134812
step: 0, loss: 0.06824591010808945
step: 10, loss: 0.011850359849631786
step: 20, loss: 0.05112550035119057
step: 30, loss: 0.07810422033071518
step: 40, loss: 0.032019708305597305
step: 50, loss: 0.008778396993875504
step: 60, loss: 0.00999387726187706
step: 70, loss: 0.04655113071203232
step: 80, loss: 0.07612323760986328
step: 90, loss: 0.06582453101873398
step: 100, loss: 0.044952210038900375
step: 110, loss: 0.028930049389600754
step: 120, loss: 0.006391285918653011
step: 130, loss: 0.003114927327260375
step: 140, loss: 0.03306970000267029
step: 150, loss: 0.056777603924274445
step: 160, loss: 0.002277508843690157
step: 170, loss: 0.0008295151637867093
step: 180, loss: 0.013469474390149117
step: 190, loss: 0.05336528643965721
step: 200, loss: 0.0013148484285920858
step: 210, loss: 0.05140697583556175
step: 220, loss: 0.028658876195549965
step: 230, loss: 0.056115955114364624
step: 240, loss: 0.020233092829585075
step: 250, loss: 0.009195500053465366
step: 260, loss: 0.00028287156601436436
step: 270, loss: 0.03570931404829025
step: 280, loss: 0.16116571426391602
step: 290, loss: 0.006288178730756044
step: 300, loss: 0.026677295565605164
step: 310, loss: 0.019396204501390457
step: 320, loss: 0.03458249568939209
step: 330, loss: 0.05596400052309036
step: 340, loss: 0.008110543712973595
step: 350, loss: 8.887187868822366e-05
step: 360, loss: 0.0006003230810165405
step: 370, loss: 0.03262342885136604
step: 380, loss: 0.24502769112586975
step: 390, loss: 0.04038581997156143
step: 400, loss: 0.03405638039112091
step: 410, loss: 0.021490957587957382
step: 420, loss: 0.016591833904385567
step: 430, loss: 0.14904101192951202
step: 440, loss: 0.07881507277488708
step: 450, loss: 0.0330759733915329
step: 460, loss: 0.024102235212922096
step: 470, loss: 0.12882845103740692
step: 480, loss: 0.003647392615675926
step: 490, loss: 0.031016629189252853
step: 500, loss: 0.016967063769698143
step: 510, loss: 0.07444211095571518
step: 520, loss: 0.055715110152959824
step: 530, loss: 0.04353146255016327
step: 540, loss: 0.04607073590159416
step: 550, loss: 0.012348304502665997
step: 560, loss: 0.048955921083688736
step: 570, loss: 0.019046146422624588
step: 580, loss: 0.0033239820040762424
step: 590, loss: 0.021512258797883987
step: 600, loss: 0.046622082591056824
step: 610, loss: 0.04726165905594826
step: 620, loss: 0.10826818645000458
step: 630, loss: 0.045139119029045105
step: 640, loss: 0.025005783885717392
step: 650, loss: 0.011791341006755829
step: 660, loss: 0.016291404142975807
step: 670, loss: 0.19227701425552368
step: 680, loss: 0.12740634381771088
step: 690, loss: 0.015636790543794632
step: 700, loss: 0.037264708429574966
step: 710, loss: 0.006252743769437075
step: 720, loss: 0.11441667377948761
step: 730, loss: 0.0002492807398084551
step: 740, loss: 0.02355092391371727
step: 750, loss: 0.002747565507888794
step: 760, loss: 0.1623549908399582
step: 770, loss: 0.0319860614836216
step: 780, loss: 0.001071373699232936
step: 790, loss: 0.013240404427051544
step: 800, loss: 0.08252904564142227
step: 810, loss: 0.041869957000017166
step: 820, loss: 0.0033433237113058567
step: 830, loss: 0.12297210842370987
step: 840, loss: 0.017910651862621307
step: 850, loss: 0.06149899587035179
step: 860, loss: 0.05000033974647522
step: 870, loss: 0.018124913796782494
step: 880, loss: 0.06738509237766266
step: 890, loss: 0.01669924706220627
step: 900, loss: 0.008190525695681572
step: 910, loss: 0.02929943986237049
step: 920, loss: 0.11787209659814835
step: 930, loss: 0.04753105342388153
step: 940, loss: 0.006652905605733395
step: 950, loss: 0.003629170125350356
step: 960, loss: 0.00568196689710021
step: 970, loss: 0.02565554529428482
epoch 13: dev_f1=0.9396471680594244, f1=0.9316081330868762, best_f1=0.9409048938134812
step: 0, loss: 0.060218892991542816
step: 10, loss: 0.09417351335287094
step: 20, loss: 0.046604953706264496
step: 30, loss: 0.08251972496509552
step: 40, loss: 0.03970874100923538
step: 50, loss: 0.0013319309800863266
step: 60, loss: 0.017222793772816658
step: 70, loss: 0.0014628544449806213
step: 80, loss: 0.004407916218042374
step: 90, loss: 0.04944445565342903
step: 100, loss: 0.008968852460384369
step: 110, loss: 0.04442644119262695
step: 120, loss: 0.030896833166480064
step: 130, loss: 0.030230965465307236
step: 140, loss: 0.04982377216219902
step: 150, loss: 0.055373501032590866
step: 160, loss: 0.06870672851800919
step: 170, loss: 0.07142394036054611
step: 180, loss: 0.090670645236969
step: 190, loss: 0.03833802789449692
step: 200, loss: 0.04044591262936592
step: 210, loss: 0.0020079724490642548
step: 220, loss: 0.0293134655803442
step: 230, loss: 0.040184564888477325
step: 240, loss: 0.10355789214372635
step: 250, loss: 0.009527073241770267
step: 260, loss: 1.7922186088981107e-05
step: 270, loss: 0.0003448119095992297
step: 280, loss: 0.10161231458187103
step: 290, loss: 0.013229597359895706
step: 300, loss: 0.05411669984459877
step: 310, loss: 0.06246306374669075
step: 320, loss: 0.04297393932938576
step: 330, loss: 0.03962681442499161
step: 340, loss: 0.04450568929314613
step: 350, loss: 0.0033894760999828577
step: 360, loss: 0.0621895007789135
step: 370, loss: 0.0624842643737793
step: 380, loss: 0.032131604850292206
step: 390, loss: 0.01840153895318508
step: 400, loss: 0.04011242836713791
step: 410, loss: 0.06302984803915024
step: 420, loss: 0.03822245076298714
step: 430, loss: 0.016584329307079315
step: 440, loss: 0.016140826046466827
step: 450, loss: 0.06301417201757431
step: 460, loss: 0.09982462972402573
step: 470, loss: 0.025599393993616104
step: 480, loss: 0.07935776561498642
step: 490, loss: 0.11144136637449265
step: 500, loss: 0.026665490120649338
step: 510, loss: 0.01672128029167652
step: 520, loss: 0.005895153619349003
step: 530, loss: 0.06201375648379326
step: 540, loss: 0.014527552761137486
step: 550, loss: 0.058719538152217865
step: 560, loss: 0.0017008320428431034
step: 570, loss: 0.0016167666763067245
step: 580, loss: 0.0036962830927222967
step: 590, loss: 0.046342089772224426
step: 600, loss: 0.0418173186480999
step: 610, loss: 0.03811660036444664
step: 620, loss: 0.0040904199704527855
step: 630, loss: 0.007604503538459539
step: 640, loss: 0.048675648868083954
step: 650, loss: 0.0588005930185318
step: 660, loss: 0.02504941262304783
step: 670, loss: 0.10542194545269012
step: 680, loss: 0.030061738565564156
step: 690, loss: 0.007119897753000259
step: 700, loss: 0.10499975085258484
step: 710, loss: 0.0768752247095108
step: 720, loss: 0.014439788646996021
step: 730, loss: 0.0034215187188237906
step: 740, loss: 0.0012041860027238727
step: 750, loss: 0.033344920724630356
step: 760, loss: 0.02129819430410862
step: 770, loss: 0.029493914917111397
step: 780, loss: 0.05012267827987671
step: 790, loss: 0.06704607605934143
step: 800, loss: 0.08755171298980713
step: 810, loss: 0.020586447790265083
step: 820, loss: 0.0003353862266521901
step: 830, loss: 0.03460007160902023
step: 840, loss: 0.045007046312093735
step: 850, loss: 0.059298478066921234
step: 860, loss: 0.09197001159191132
step: 870, loss: 0.021890759468078613
step: 880, loss: 0.027828700840473175
step: 890, loss: 0.10349756479263306
step: 900, loss: 0.03843342512845993
step: 910, loss: 0.024337153881788254
step: 920, loss: 0.0010675991652533412
step: 930, loss: 0.03451282158493996
step: 940, loss: 0.01291270088404417
step: 950, loss: 0.039311669766902924
step: 960, loss: 0.000181325594894588
step: 970, loss: 0.011022829450666904
epoch 14: dev_f1=0.9356943150046597, f1=0.9284386617100371, best_f1=0.9409048938134812
step: 0, loss: 0.05755491182208061
step: 10, loss: 1.5325675121857785e-05
step: 20, loss: 0.019760746508836746
step: 30, loss: 0.019613798707723618
step: 40, loss: 0.0062794447876513
step: 50, loss: 0.0009666171972639859
step: 60, loss: 0.036277566105127335
step: 70, loss: 0.03233053535223007
step: 80, loss: 0.006870361510664225
step: 90, loss: 0.01668607071042061
step: 100, loss: 0.08754982799291611
step: 110, loss: 0.0009152222773991525
step: 120, loss: 0.010640494525432587
step: 130, loss: 0.07463091611862183
step: 140, loss: 0.13940490782260895
step: 150, loss: 0.014133923687040806
step: 160, loss: 0.08126797527074814
step: 170, loss: 0.04155002161860466
step: 180, loss: 0.020782770588994026
step: 190, loss: 0.001401639194227755
step: 200, loss: 0.03372332453727722
step: 210, loss: 0.025015773251652718
step: 220, loss: 0.005736083257943392
step: 230, loss: 0.007459091488271952
step: 240, loss: 0.13149310648441315
step: 250, loss: 0.037565529346466064
step: 260, loss: 0.0012836749665439129
step: 270, loss: 0.00019780317961703986
step: 280, loss: 0.019722800701856613
step: 290, loss: 0.028206177055835724
step: 300, loss: 0.04973255470395088
step: 310, loss: 0.06035087630152702
step: 320, loss: 0.039541155099868774
step: 330, loss: 0.037331171333789825
step: 340, loss: 0.004886007867753506
step: 350, loss: 0.013483196496963501
step: 360, loss: 0.025676114484667778
step: 370, loss: 0.003207299392670393
step: 380, loss: 0.08024436980485916
step: 390, loss: 0.03437278792262077
step: 400, loss: 0.06830532103776932
step: 410, loss: 0.014729665592312813
step: 420, loss: 0.00936208013445139
step: 430, loss: 0.0008578030974604189
step: 440, loss: 0.017279990017414093
step: 450, loss: 0.0035944227129220963
step: 460, loss: 0.08155791461467743
step: 470, loss: 0.021044261753559113
step: 480, loss: 0.026648571714758873
step: 490, loss: 0.02503495290875435
step: 500, loss: 0.09687352180480957
step: 510, loss: 0.03005695529282093
step: 520, loss: 0.04377121105790138
step: 530, loss: 0.01133562158793211
step: 540, loss: 0.04021281376481056
step: 550, loss: 0.00044581672409549356
step: 560, loss: 0.03881247341632843
step: 570, loss: 0.029771996662020683
step: 580, loss: 0.16653352975845337
step: 590, loss: 0.03062865324318409
step: 600, loss: 0.0418526716530323
step: 610, loss: 0.045482974499464035
step: 620, loss: 0.00400680722668767
step: 630, loss: 0.051975615322589874
step: 640, loss: 0.06644213944673538
step: 650, loss: 0.0024126486387103796
step: 660, loss: 0.024744128808379173
step: 670, loss: 0.01849411055445671
step: 680, loss: 0.015064990147948265
step: 690, loss: 0.060926564037799835
step: 700, loss: 0.11874224990606308
step: 710, loss: 0.004771897569298744
step: 720, loss: 0.02506575547158718
step: 730, loss: 0.04047397896647453
step: 740, loss: 0.04575018212199211
step: 750, loss: 0.003710691351443529
step: 760, loss: 0.05492795258760452
step: 770, loss: 1.0114106771652587e-05
step: 780, loss: 0.0021209530532360077
step: 790, loss: 0.08898405730724335
step: 800, loss: 0.09726385772228241
step: 810, loss: 0.008529526181519032
step: 820, loss: 0.010657969862222672
step: 830, loss: 0.02722284384071827
step: 840, loss: 0.018212387338280678
step: 850, loss: 0.00017032923642545938
step: 860, loss: 0.12040957063436508
step: 870, loss: 0.0005643464392051101
step: 880, loss: 0.003263169201090932
step: 890, loss: 0.0008458569645881653
step: 900, loss: 0.027945810928940773
step: 910, loss: 0.01168946735560894
step: 920, loss: 0.0001383450726279989
step: 930, loss: 0.0633355900645256
step: 940, loss: 0.13895878195762634
step: 950, loss: 0.02637292444705963
step: 960, loss: 0.046221256256103516
step: 970, loss: 0.00635102903470397
epoch 15: dev_f1=0.935813953488372, f1=0.9305555555555556, best_f1=0.9409048938134812
step: 0, loss: 0.025802748277783394
step: 10, loss: 0.03337375074625015
step: 20, loss: 0.0071691847406327724
step: 30, loss: 0.12354370206594467
step: 40, loss: 0.02010159008204937
step: 50, loss: 0.024403542280197144
step: 60, loss: 0.00112181156873703
step: 70, loss: 0.00013636043877340853
step: 80, loss: 0.018171988427639008
step: 90, loss: 0.023042477667331696
step: 100, loss: 0.027523059397935867
step: 110, loss: 0.008973466232419014
step: 120, loss: 0.047719843685626984
step: 130, loss: 0.019820427522063255
step: 140, loss: 0.0057476116344332695
step: 150, loss: 0.00040102729690261185
step: 160, loss: 0.08301839977502823
step: 170, loss: 0.0058503844775259495
step: 180, loss: 0.008946318179368973
step: 190, loss: 0.036945294588804245
step: 200, loss: 0.017437441274523735
step: 210, loss: 0.0003766659356188029
step: 220, loss: 0.024520253762602806
step: 230, loss: 0.02790779434144497
step: 240, loss: 0.025702621787786484
step: 250, loss: 0.016719574108719826
step: 260, loss: 0.04954163357615471
step: 270, loss: 0.062366001307964325
step: 280, loss: 0.002469839295372367
step: 290, loss: 0.04416466876864433
step: 300, loss: 0.011875328607857227
step: 310, loss: 0.010968167334794998
step: 320, loss: 0.0002324373199371621
step: 330, loss: 0.014521503821015358
step: 340, loss: 0.020515959709882736
step: 350, loss: 0.0009890568908303976
step: 360, loss: 0.05837126076221466
step: 370, loss: 0.01477531436830759
step: 380, loss: 0.03301292657852173
step: 390, loss: 0.0001700723369140178
step: 400, loss: 0.04994064196944237
step: 410, loss: 0.0023819117341190577
step: 420, loss: 0.007369601167738438
step: 430, loss: 0.0018760839011520147
step: 440, loss: 0.0691898763179779
step: 450, loss: 0.0432506687939167
step: 460, loss: 0.05698790028691292
step: 470, loss: 0.07254507392644882
step: 480, loss: 0.07373747229576111
step: 490, loss: 0.027651576325297356
step: 500, loss: 0.027876093983650208
step: 510, loss: 0.025107700377702713
step: 520, loss: 0.07356622815132141
step: 530, loss: 0.03875984251499176
step: 540, loss: 0.023102976381778717
step: 550, loss: 0.00012380398402456194
step: 560, loss: 0.06527695804834366
step: 570, loss: 0.056958217173814774
step: 580, loss: 0.02782336249947548
step: 590, loss: 0.03913641348481178
step: 600, loss: 0.00458191242069006
step: 610, loss: 0.019440362229943275
step: 620, loss: 0.00048428840818814933
step: 630, loss: 0.03752509877085686
step: 640, loss: 0.05439500883221626
step: 650, loss: 0.0012916454579681158
step: 660, loss: 0.25810185074806213
step: 670, loss: 0.0611155740916729
step: 680, loss: 0.03910614177584648
step: 690, loss: 0.009832040406763554
step: 700, loss: 0.009982067160308361
step: 710, loss: 0.05606534332036972
step: 720, loss: 0.02584494836628437
step: 730, loss: 0.017343228682875633
step: 740, loss: 0.019641738384962082
step: 750, loss: 0.02230757847428322
step: 760, loss: 0.020583519712090492
step: 770, loss: 0.000138058268930763
step: 780, loss: 0.01653469167649746
step: 790, loss: 0.024099715054035187
step: 800, loss: 0.012443562038242817
step: 810, loss: 0.005387097131460905
step: 820, loss: 0.019654851406812668
step: 830, loss: 0.045211128890514374
step: 840, loss: 0.03931770473718643
step: 850, loss: 0.05978689342737198
step: 860, loss: 0.053601428866386414
step: 870, loss: 0.03234647586941719
step: 880, loss: 0.00019393175898585469
step: 890, loss: 0.051050327718257904
step: 900, loss: 4.1851973946904764e-05
step: 910, loss: 0.046067897230386734
step: 920, loss: 0.020833734422922134
step: 930, loss: 0.061431270092725754
step: 940, loss: 0.04460801184177399
step: 950, loss: 0.060382913798093796
step: 960, loss: 0.020479895174503326
step: 970, loss: 0.04269946366548538
epoch 16: dev_f1=0.9332096474953617, f1=0.9272137227630968, best_f1=0.9409048938134812
step: 0, loss: 0.09791675209999084
step: 10, loss: 0.10129394382238388
step: 20, loss: 0.11361417174339294
step: 30, loss: 0.011519462801516056
step: 40, loss: 0.00208512251265347
step: 50, loss: 0.060318537056446075
step: 60, loss: 0.07091540843248367
step: 70, loss: 0.01031672116369009
step: 80, loss: 0.045845046639442444
step: 90, loss: 0.038417160511016846
step: 100, loss: 0.00014883575204294175
step: 110, loss: 0.06630953401327133
step: 120, loss: 0.010906574316322803
step: 130, loss: 0.03565461188554764
step: 140, loss: 0.020896635949611664
step: 150, loss: 0.0632568821310997
step: 160, loss: 0.012267048470675945
step: 170, loss: 0.0002933252544607967
step: 180, loss: 0.012681623920798302
step: 190, loss: 0.0003762845299206674
step: 200, loss: 0.02141754887998104
step: 210, loss: 0.02102879248559475
step: 220, loss: 0.08102082461118698
step: 230, loss: 0.0012539512244984508
step: 240, loss: 0.014895373955368996
step: 250, loss: 0.04160675033926964
step: 260, loss: 0.07390331476926804
step: 270, loss: 0.0007642676937393844
step: 280, loss: 0.04157118871808052
step: 290, loss: 0.03567422553896904
step: 300, loss: 1.8640370399225503e-05
step: 310, loss: 0.04379316419363022
step: 320, loss: 0.05184702202677727
step: 330, loss: 0.03992879390716553
step: 340, loss: 0.01466923113912344
step: 350, loss: 0.08669184148311615
step: 360, loss: 0.018859995529055595
step: 370, loss: 0.05144043639302254
step: 380, loss: 0.01827673800289631
step: 390, loss: 0.015148095786571503
step: 400, loss: 0.04260120913386345
step: 410, loss: 0.010845468379557133
step: 420, loss: 0.02798101305961609
step: 430, loss: 0.02086269110441208
step: 440, loss: 0.02089979127049446
step: 450, loss: 0.05216989666223526
step: 460, loss: 0.002395838499069214
step: 470, loss: 0.03959982097148895
step: 480, loss: 0.03546628728508949
step: 490, loss: 0.01613839901983738
step: 500, loss: 0.0003507436776999384
step: 510, loss: 0.07962022721767426
step: 520, loss: 0.0008155625546351075
step: 530, loss: 0.04956351965665817
step: 540, loss: 0.00017818360356613994
step: 550, loss: 0.0015880482969805598
step: 560, loss: 0.044490449130535126
step: 570, loss: 0.08491409569978714
step: 580, loss: 0.06488623470067978
step: 590, loss: 0.07097551971673965
step: 600, loss: 0.004318965598940849
step: 610, loss: 4.757268834509887e-05
step: 620, loss: 0.03317702189087868
step: 630, loss: 0.05819685384631157
step: 640, loss: 0.020682331174612045
step: 650, loss: 0.057414520531892776
step: 660, loss: 0.00014520491822622716
step: 670, loss: 0.026801198720932007
step: 680, loss: 0.035018905997276306
step: 690, loss: 3.4241053072037175e-05
step: 700, loss: 0.028311986476182938
step: 710, loss: 0.0034802912268787622
step: 720, loss: 0.01037193089723587
step: 730, loss: 0.03009132668375969
step: 740, loss: 0.04292554780840874
step: 750, loss: 0.09583315253257751
step: 760, loss: 0.02568923309445381
step: 770, loss: 0.07726742327213287
step: 780, loss: 0.038432687520980835
step: 790, loss: 0.0011603583116084337
step: 800, loss: 0.006402760744094849
step: 810, loss: 0.03877975791692734
step: 820, loss: 0.02626081183552742
step: 830, loss: 0.03800917789340019
step: 840, loss: 0.00020082801347598433
step: 850, loss: 0.04950185492634773
step: 860, loss: 0.002902114298194647
step: 870, loss: 0.0228371974080801
step: 880, loss: 0.018591873347759247
step: 890, loss: 0.05917340889573097
step: 900, loss: 0.009050960652530193
step: 910, loss: 0.03115057945251465
step: 920, loss: 0.10719622671604156
step: 930, loss: 0.01448080874979496
step: 940, loss: 0.028702832758426666
step: 950, loss: 0.005530865862965584
step: 960, loss: 0.0025063680950552225
step: 970, loss: 6.615329766646028e-05
epoch 17: dev_f1=0.9356943150046597, f1=0.9277777777777779, best_f1=0.9409048938134812
step: 0, loss: 0.030178509652614594
step: 10, loss: 0.050823960453271866
step: 20, loss: 0.04355277121067047
step: 30, loss: 0.0410822369158268
step: 40, loss: 0.0001782054314389825
step: 50, loss: 0.0005328935221768916
step: 60, loss: 0.007129155099391937
step: 70, loss: 0.04882539063692093
step: 80, loss: 0.0480920784175396
step: 90, loss: 0.0015310717280954123
step: 100, loss: 0.06913634389638901
step: 110, loss: 0.015598848462104797
step: 120, loss: 0.05860544368624687
step: 130, loss: 0.003679105779156089
step: 140, loss: 0.047332312911748886
step: 150, loss: 0.04742781072854996
step: 160, loss: 0.014006759971380234
step: 170, loss: 0.03904343396425247
step: 180, loss: 0.0332043319940567
step: 190, loss: 0.019001930952072144
step: 200, loss: 0.010254696942865849
step: 210, loss: 0.21246258914470673
step: 220, loss: 0.001214642426930368
step: 230, loss: 0.0765940472483635
step: 240, loss: 0.00034237621002830565
step: 250, loss: 0.06391838192939758
step: 260, loss: 0.03234248608350754
step: 270, loss: 0.02020351216197014
step: 280, loss: 0.03801416978240013
step: 290, loss: 0.00011962803546339273
step: 300, loss: 0.00813963171094656
step: 310, loss: 3.3034521038644016e-05
step: 320, loss: 0.03484712913632393
step: 330, loss: 0.0002709304098971188
step: 340, loss: 0.00010223436402156949
step: 350, loss: 0.012765713967382908
step: 360, loss: 0.02132389135658741
step: 370, loss: 0.09902096539735794
step: 380, loss: 0.01266801543533802
step: 390, loss: 0.017208848148584366
step: 400, loss: 0.00022549956338480115
step: 410, loss: 0.03334956243634224
step: 420, loss: 0.028679609298706055
step: 430, loss: 0.00012168203829787672
step: 440, loss: 0.0409310944378376
step: 450, loss: 0.023066071793437004
step: 460, loss: 0.1165182814002037
step: 470, loss: 0.0012380529660731554
step: 480, loss: 0.017509756609797478
step: 490, loss: 0.013785118237137794
step: 500, loss: 0.009915817528963089
step: 510, loss: 0.013932432979345322
step: 520, loss: 0.018317796289920807
step: 530, loss: 0.06890766322612762
step: 540, loss: 0.0478769913315773
step: 550, loss: 0.0697527751326561
step: 560, loss: 0.017305079847574234
step: 570, loss: 0.09158370643854141
step: 580, loss: 0.0021885428577661514
step: 590, loss: 0.04029626399278641
step: 600, loss: 0.0004936559707857668
step: 610, loss: 0.04900360479950905
step: 620, loss: 3.5172775824321434e-05
step: 630, loss: 0.03093123994767666
step: 640, loss: 0.0022390992380678654
step: 650, loss: 0.15633343160152435
step: 660, loss: 0.07520078867673874
step: 670, loss: 0.02195775881409645
step: 680, loss: 0.053552769124507904
step: 690, loss: 0.03394263982772827
step: 700, loss: 0.05375212803483009
step: 710, loss: 0.005616616457700729
step: 720, loss: 0.0454227551817894
step: 730, loss: 1.5694144167355262e-05
step: 740, loss: 0.0001357328874291852
step: 750, loss: 0.07352571934461594
step: 760, loss: 0.0293999295681715
step: 770, loss: 5.083137875772081e-05
step: 780, loss: 0.019229905679821968
step: 790, loss: 0.03995642438530922
step: 800, loss: 9.552045230520889e-05
step: 810, loss: 0.03023805096745491
step: 820, loss: 0.0701267197728157
step: 830, loss: 0.04553766921162605
step: 840, loss: 0.027536068111658096
step: 850, loss: 0.03599642589688301
step: 860, loss: 6.24460299150087e-05
step: 870, loss: 0.04938498139381409
step: 880, loss: 0.05556487292051315
step: 890, loss: 0.03628659248352051
step: 900, loss: 0.04526874050498009
step: 910, loss: 0.043427616357803345
step: 920, loss: 0.10926254093647003
step: 930, loss: 0.06821119785308838
step: 940, loss: 0.00010970630683004856
step: 950, loss: 0.013789154589176178
step: 960, loss: 0.025350628420710564
step: 970, loss: 1.1004431144101545e-05
epoch 18: dev_f1=0.9366262814538677, f1=0.9299303944315545, best_f1=0.9409048938134812
step: 0, loss: 0.0007391319377347827
step: 10, loss: 0.05278898403048515
step: 20, loss: 0.0018610985716804862
step: 30, loss: 0.029899071902036667
step: 40, loss: 0.06886280328035355
step: 50, loss: 0.03694487363100052
step: 60, loss: 0.0011056362418457866
step: 70, loss: 5.178280844120309e-05
step: 80, loss: 0.08931667357683182
step: 90, loss: 0.038793712854385376
step: 100, loss: 5.475998477777466e-05
step: 110, loss: 0.004723486490547657
step: 120, loss: 0.0360579639673233
step: 130, loss: 0.06671922653913498
step: 140, loss: 0.01634170301258564
step: 150, loss: 0.10791589319705963
step: 160, loss: 0.02919306792318821
step: 170, loss: 0.01703677512705326
step: 180, loss: 0.002051741350442171
step: 190, loss: 0.032215237617492676
step: 200, loss: 0.0175749734044075
step: 210, loss: 6.044555630069226e-05
step: 220, loss: 2.8578402634593658e-05
step: 230, loss: 0.012440203689038754
step: 240, loss: 0.06271378695964813
step: 250, loss: 0.024182498455047607
step: 260, loss: 0.05463670566678047
step: 270, loss: 0.004351979121565819
step: 280, loss: 0.047498513013124466
step: 290, loss: 0.001401793211698532
step: 300, loss: 0.03725828230381012
step: 310, loss: 0.04464944079518318
step: 320, loss: 0.030675197020173073
step: 330, loss: 0.008427875116467476
step: 340, loss: 0.01681913249194622
step: 350, loss: 3.3462143619544804e-05
step: 360, loss: 0.02810230664908886
step: 370, loss: 0.03721197322010994
step: 380, loss: 0.019702160730957985
step: 390, loss: 0.07364553213119507
step: 400, loss: 0.0372387170791626
step: 410, loss: 0.06363434344530106
step: 420, loss: 0.048617538064718246
step: 430, loss: 0.08091937750577927
step: 440, loss: 0.000696374976541847
step: 450, loss: 0.02625221014022827
step: 460, loss: 0.004888024181127548
step: 470, loss: 0.02694462612271309
step: 480, loss: 0.06978252530097961
step: 490, loss: 0.04320189356803894
step: 500, loss: 0.018353290855884552
step: 510, loss: 0.03755234181880951
step: 520, loss: 2.4315129849128425e-05
step: 530, loss: 0.1313588172197342
step: 540, loss: 0.051837798207998276
step: 550, loss: 0.031045228242874146
step: 560, loss: 0.05732203647494316
step: 570, loss: 0.024607768282294273
step: 580, loss: 0.021766297519207
step: 590, loss: 0.04304047301411629
step: 600, loss: 0.04448557645082474
step: 610, loss: 3.434947575442493e-05
step: 620, loss: 0.01708938367664814
step: 630, loss: 0.0009521800093352795
step: 640, loss: 9.642585064284503e-05
step: 650, loss: 0.04724176973104477
step: 660, loss: 0.027256637811660767
step: 670, loss: 0.11260379105806351
step: 680, loss: 0.0042849644087255
step: 690, loss: 0.08133743703365326
step: 700, loss: 0.0002813288592733443
step: 710, loss: 0.020940333604812622
step: 720, loss: 0.03042774274945259
step: 730, loss: 0.029842384159564972
step: 740, loss: 0.0013595628552138805
step: 750, loss: 0.02931990474462509
step: 760, loss: 0.05888810381293297
step: 770, loss: 0.060562871396541595
step: 780, loss: 0.04626559466123581
step: 790, loss: 0.0004909449489787221
step: 800, loss: 0.02954496629536152
step: 810, loss: 0.04720499739050865
step: 820, loss: 0.022382592782378197
step: 830, loss: 0.00019310612697154284
step: 840, loss: 9.42119731917046e-06
step: 850, loss: 0.00021907812333665788
step: 860, loss: 0.017953641712665558
step: 870, loss: 0.00021455014939419925
step: 880, loss: 0.04011540487408638
step: 890, loss: 0.002751234220340848
step: 900, loss: 0.04609078913927078
step: 910, loss: 0.04952995106577873
step: 920, loss: 0.10047424584627151
step: 930, loss: 0.009349685162305832
step: 940, loss: 0.00529166404157877
step: 950, loss: 0.020959820598363876
step: 960, loss: 0.0530245378613472
step: 970, loss: 0.00023194799723569304
epoch 19: dev_f1=0.9344569288389513, f1=0.9263746505125815, best_f1=0.9409048938134812
step: 0, loss: 0.04749983921647072
step: 10, loss: 0.019191812723875046
step: 20, loss: 4.710618668468669e-05
step: 30, loss: 0.056855954229831696
step: 40, loss: 0.021060755476355553
step: 50, loss: 0.042987722903490067
step: 60, loss: 0.023683909326791763
step: 70, loss: 0.020206209272146225
step: 80, loss: 0.0044267126359045506
step: 90, loss: 0.03303320333361626
step: 100, loss: 0.0011860709637403488
step: 110, loss: 0.026185959577560425
step: 120, loss: 0.09396550804376602
step: 130, loss: 0.03372836485505104
step: 140, loss: 0.026920035481452942
step: 150, loss: 0.052564579993486404
step: 160, loss: 0.0004915572353638709
step: 170, loss: 0.025487225502729416
step: 180, loss: 0.060801710933446884
step: 190, loss: 0.01784156635403633
step: 200, loss: 0.0005668623489327729
step: 210, loss: 0.05933067575097084
step: 220, loss: 0.04943133890628815
step: 230, loss: 0.062385737895965576
step: 240, loss: 0.00021312659373506904
step: 250, loss: 0.011156507767736912
step: 260, loss: 0.05885472521185875
step: 270, loss: 0.024719737470149994
step: 280, loss: 8.939077088143677e-05
step: 290, loss: 0.01372690498828888
step: 300, loss: 4.118953802390024e-05
step: 310, loss: 0.014316733926534653
step: 320, loss: 0.03179653361439705
step: 330, loss: 0.00011838441423606128
step: 340, loss: 0.049854543060064316
step: 350, loss: 0.014405344612896442
step: 360, loss: 0.040309738367795944
step: 370, loss: 0.04723178595304489
step: 380, loss: 0.00021269485296215862
step: 390, loss: 0.020635182037949562
step: 400, loss: 0.023809103295207024
step: 410, loss: 4.449833068065345e-05
step: 420, loss: 8.729919500183314e-05
step: 430, loss: 0.004952578339725733
step: 440, loss: 0.004570933058857918
step: 450, loss: 0.037929125130176544
step: 460, loss: 0.05154987424612045
step: 470, loss: 0.06173904240131378
step: 480, loss: 0.06066267564892769
step: 490, loss: 0.04577680677175522
step: 500, loss: 0.01427406258881092
step: 510, loss: 0.02642674371600151
step: 520, loss: 0.019643574953079224
step: 530, loss: 0.018690092489123344
step: 540, loss: 1.2025108844682109e-05
step: 550, loss: 0.022765206173062325
step: 560, loss: 0.020590659230947495
step: 570, loss: 0.04220623895525932
step: 580, loss: 0.05321405082941055
step: 590, loss: 0.0270191952586174
step: 600, loss: 0.15757283568382263
step: 610, loss: 0.04061968997120857
step: 620, loss: 0.04069261997938156
step: 630, loss: 6.615534948650748e-05
step: 640, loss: 0.026744244620203972
step: 650, loss: 0.0005226112552918494
step: 660, loss: 0.04979132488369942
step: 670, loss: 0.029311493039131165
step: 680, loss: 8.164341124938801e-05
step: 690, loss: 0.07737046480178833
step: 700, loss: 0.0594932921230793
step: 710, loss: 0.013702284544706345
step: 720, loss: 0.0001780666207196191
step: 730, loss: 0.0003097847511526197
step: 740, loss: 0.0587930791079998
step: 750, loss: 0.018727613613009453
step: 760, loss: 0.05039054900407791
step: 770, loss: 0.00028779261629097164
step: 780, loss: 0.00034476167638786137
step: 790, loss: 0.010821528732776642
step: 800, loss: 0.025066157802939415
step: 810, loss: 0.034751277416944504
step: 820, loss: 0.00027430063346400857
step: 830, loss: 0.000497451750561595
step: 840, loss: 0.017970824614167213
step: 850, loss: 0.03205220773816109
step: 860, loss: 0.0023901774547994137
step: 870, loss: 6.468160427175462e-05
step: 880, loss: 0.03032168745994568
step: 890, loss: 0.018371036276221275
step: 900, loss: 9.571983537171036e-05
step: 910, loss: 0.01782851107418537
step: 920, loss: 0.0008038130472414196
step: 930, loss: 0.005180125590413809
step: 940, loss: 0.1675155609846115
step: 950, loss: 0.00018413527868688107
step: 960, loss: 0.03343696892261505
step: 970, loss: 0.04951607435941696
epoch 20: dev_f1=0.9344648750589346, f1=0.9272641952135147, best_f1=0.9409048938134812
