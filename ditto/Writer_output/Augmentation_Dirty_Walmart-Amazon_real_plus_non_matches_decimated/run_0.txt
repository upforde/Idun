cuda
Device: cuda
step: 0, loss: 0.7518516778945923
step: 10, loss: 0.15054191648960114
step: 20, loss: 0.13767917454242706
step: 30, loss: 0.23633240163326263
step: 40, loss: 0.14096029102802277
step: 50, loss: 0.02586788684129715
step: 60, loss: 0.15334555506706238
step: 70, loss: 0.2267048954963684
step: 80, loss: 0.06495923548936844
step: 90, loss: 0.13692018389701843
step: 100, loss: 0.11921433359384537
step: 110, loss: 0.3388497531414032
step: 120, loss: 0.21857790648937225
step: 130, loss: 0.12590835988521576
step: 140, loss: 0.12070699781179428
step: 150, loss: 0.13774587213993073
step: 160, loss: 0.4265373647212982
step: 170, loss: 0.11586996912956238
step: 180, loss: 0.21818938851356506
step: 190, loss: 0.014207899570465088
step: 200, loss: 0.055896393954753876
step: 210, loss: 0.1538899540901184
step: 220, loss: 0.04458223283290863
step: 230, loss: 0.14480502903461456
step: 240, loss: 0.1531120091676712
step: 250, loss: 0.07862537354230881
step: 260, loss: 0.13248220086097717
step: 270, loss: 0.24361638724803925
step: 280, loss: 0.08405324816703796
step: 290, loss: 0.21269646286964417
step: 300, loss: 0.18216438591480255
step: 310, loss: 0.29156097769737244
step: 320, loss: 0.17476509511470795
step: 330, loss: 0.26133304834365845
step: 340, loss: 0.2140209823846817
step: 350, loss: 0.23322667181491852
step: 360, loss: 0.7623406052589417
epoch 1: dev_f1=0.6227848101265823, f1=0.631578947368421, best_f1=0.631578947368421
step: 0, loss: 0.10603037476539612
step: 10, loss: 0.4024644196033478
step: 20, loss: 0.11980974674224854
step: 30, loss: 0.022474762052297592
step: 40, loss: 0.09229276329278946
step: 50, loss: 0.33407458662986755
step: 60, loss: 0.19327640533447266
step: 70, loss: 0.14045467972755432
step: 80, loss: 0.1453973650932312
step: 90, loss: 0.15880481898784637
step: 100, loss: 0.027824582532048225
step: 110, loss: 0.3446265161037445
step: 120, loss: 0.10253974795341492
step: 130, loss: 0.014187098480761051
step: 140, loss: 0.04012889042496681
step: 150, loss: 0.28241831064224243
step: 160, loss: 0.06862771511077881
step: 170, loss: 0.15751782059669495
step: 180, loss: 0.04959767311811447
step: 190, loss: 0.10299085825681686
step: 200, loss: 0.04808887466788292
step: 210, loss: 0.046362411230802536
step: 220, loss: 0.12693603336811066
step: 230, loss: 0.28218844532966614
step: 240, loss: 0.07321198284626007
step: 250, loss: 0.16156667470932007
step: 260, loss: 0.07897485047578812
step: 270, loss: 0.3146084249019623
step: 280, loss: 0.1028226688504219
step: 290, loss: 0.0675114318728447
step: 300, loss: 0.08404257893562317
step: 310, loss: 0.19964708387851715
step: 320, loss: 0.06153731420636177
step: 330, loss: 0.0696883350610733
step: 340, loss: 0.11370259523391724
step: 350, loss: 0.14302249252796173
step: 360, loss: 0.19840240478515625
epoch 2: dev_f1=0.7268041237113403, f1=0.7350000000000001, best_f1=0.7350000000000001
step: 0, loss: 0.10677101463079453
step: 10, loss: 0.046687837690114975
step: 20, loss: 0.06062426418066025
step: 30, loss: 0.04850859194993973
step: 40, loss: 0.2135026454925537
step: 50, loss: 0.16247360408306122
step: 60, loss: 0.013445491902530193
step: 70, loss: 0.23544494807720184
step: 80, loss: 0.1586684286594391
step: 90, loss: 0.09092109650373459
step: 100, loss: 0.03695660084486008
step: 110, loss: 0.11457213759422302
step: 120, loss: 0.05853510648012161
step: 130, loss: 0.17642557621002197
step: 140, loss: 0.04868775233626366
step: 150, loss: 0.0663691833615303
step: 160, loss: 0.08979532122612
step: 170, loss: 0.019966164603829384
step: 180, loss: 0.03970831632614136
step: 190, loss: 0.03660332411527634
step: 200, loss: 0.03760306164622307
step: 210, loss: 0.02722184732556343
step: 220, loss: 0.39316776394844055
step: 230, loss: 0.054161421954631805
step: 240, loss: 0.07734306901693344
step: 250, loss: 0.0776079073548317
step: 260, loss: 0.12752048671245575
step: 270, loss: 0.07925961911678314
step: 280, loss: 0.0762571170926094
step: 290, loss: 0.12285735458135605
step: 300, loss: 0.11155363917350769
step: 310, loss: 0.06381306797266006
step: 320, loss: 0.05156317725777626
step: 330, loss: 0.20733533799648285
step: 340, loss: 0.060760267078876495
step: 350, loss: 0.08424261212348938
step: 360, loss: 0.19845585525035858
epoch 3: dev_f1=0.7365439093484418, f1=0.705539358600583, best_f1=0.705539358600583
step: 0, loss: 0.1277829110622406
step: 10, loss: 0.060676224529743195
step: 20, loss: 0.08413705229759216
step: 30, loss: 0.12553808093070984
step: 40, loss: 0.06658124178647995
step: 50, loss: 0.07784896343946457
step: 60, loss: 0.061014555394649506
step: 70, loss: 0.04849584773182869
step: 80, loss: 0.06784410029649734
step: 90, loss: 0.4452283978462219
step: 100, loss: 0.0638747438788414
step: 110, loss: 0.06780758500099182
step: 120, loss: 0.0678870901465416
step: 130, loss: 0.04167201370000839
step: 140, loss: 0.08577224612236023
step: 150, loss: 0.11313445121049881
step: 160, loss: 0.15543782711029053
step: 170, loss: 0.07481130957603455
step: 180, loss: 0.08393257856369019
step: 190, loss: 0.06964607536792755
step: 200, loss: 0.08926510810852051
step: 210, loss: 0.07801199704408646
step: 220, loss: 0.17553633451461792
step: 230, loss: 0.12646937370300293
step: 240, loss: 0.1487267166376114
step: 250, loss: 0.24885717034339905
step: 260, loss: 0.20046032965183258
step: 270, loss: 0.0571468323469162
step: 280, loss: 0.1226034089922905
step: 290, loss: 0.08260129392147064
step: 300, loss: 0.07666494697332382
step: 310, loss: 0.03342687711119652
step: 320, loss: 0.12998642027378082
step: 330, loss: 0.12907247245311737
step: 340, loss: 0.054602570831775665
step: 350, loss: 0.1996450573205948
step: 360, loss: 0.08933427929878235
epoch 4: dev_f1=0.7002398081534772, f1=0.6682692307692307, best_f1=0.705539358600583
step: 0, loss: 0.09177529811859131
step: 10, loss: 0.04384990781545639
step: 20, loss: 0.028382597491145134
step: 30, loss: 0.1282060295343399
step: 40, loss: 0.02162010781466961
step: 50, loss: 0.07441608607769012
step: 60, loss: 0.13551901280879974
step: 70, loss: 0.1376354843378067
step: 80, loss: 0.10641839355230331
step: 90, loss: 0.05412578210234642
step: 100, loss: 0.058400824666023254
step: 110, loss: 0.005040486343204975
step: 120, loss: 0.12426517903804779
step: 130, loss: 0.04258399456739426
step: 140, loss: 0.11874810606241226
step: 150, loss: 0.06353609263896942
step: 160, loss: 0.07401375472545624
step: 170, loss: 0.03209806606173515
step: 180, loss: 0.10666069388389587
step: 190, loss: 0.12597760558128357
step: 200, loss: 0.013176651671528816
step: 210, loss: 0.1664796769618988
step: 220, loss: 0.04776574298739433
step: 230, loss: 0.06057269126176834
step: 240, loss: 0.02355445735156536
step: 250, loss: 0.12336135655641556
step: 260, loss: 0.05840432643890381
step: 270, loss: 0.11804581433534622
step: 280, loss: 0.1014968529343605
step: 290, loss: 0.059261903166770935
step: 300, loss: 0.047604553401470184
step: 310, loss: 0.15275396406650543
step: 320, loss: 0.05979420989751816
step: 330, loss: 0.06439418345689774
step: 340, loss: 0.11111016571521759
step: 350, loss: 0.09918127954006195
step: 360, loss: 0.07853692770004272
epoch 5: dev_f1=0.7306666666666668, f1=0.6892950391644909, best_f1=0.705539358600583
step: 0, loss: 0.041010890156030655
step: 10, loss: 0.12710565328598022
step: 20, loss: 0.15439707040786743
step: 30, loss: 0.0713362991809845
step: 40, loss: 0.03372259438037872
step: 50, loss: 0.05338176712393761
step: 60, loss: 0.14674212038516998
step: 70, loss: 0.04113008826971054
step: 80, loss: 0.02017783187329769
step: 90, loss: 0.03139342740178108
step: 100, loss: 0.05200619623064995
step: 110, loss: 0.07873506844043732
step: 120, loss: 0.0423492006957531
step: 130, loss: 0.12823078036308289
step: 140, loss: 0.05089955776929855
step: 150, loss: 0.0004970476147718728
step: 160, loss: 0.1914837509393692
step: 170, loss: 0.07825475186109543
step: 180, loss: 0.018839271739125252
step: 190, loss: 0.05979379266500473
step: 200, loss: 0.1495910882949829
step: 210, loss: 0.07632048428058624
step: 220, loss: 0.07833177596330643
step: 230, loss: 0.0875268280506134
step: 240, loss: 0.05359218642115593
step: 250, loss: 0.029925281181931496
step: 260, loss: 0.14544427394866943
step: 270, loss: 0.024116864427924156
step: 280, loss: 0.028512537479400635
step: 290, loss: 0.11253047734498978
step: 300, loss: 0.03793475776910782
step: 310, loss: 0.042687878012657166
step: 320, loss: 0.027417486533522606
step: 330, loss: 0.06884578615427017
step: 340, loss: 0.008403745479881763
step: 350, loss: 0.04019705578684807
step: 360, loss: 0.16795524954795837
epoch 6: dev_f1=0.7356948228882835, f1=0.7244094488188976, best_f1=0.705539358600583
step: 0, loss: 0.047249194234609604
step: 10, loss: 0.054958097636699677
step: 20, loss: 0.20906618237495422
step: 30, loss: 0.10107223689556122
step: 40, loss: 0.07548350840806961
step: 50, loss: 0.11607781797647476
step: 60, loss: 0.1320878118276596
step: 70, loss: 0.03162817656993866
step: 80, loss: 0.09205304086208344
step: 90, loss: 0.08222505450248718
step: 100, loss: 0.17863620817661285
step: 110, loss: 0.09087023138999939
step: 120, loss: 0.05992431566119194
step: 130, loss: 0.03434060141444206
step: 140, loss: 0.007007501553744078
step: 150, loss: 0.09099216014146805
step: 160, loss: 0.009438266977667809
step: 170, loss: 0.11581730842590332
step: 180, loss: 0.05517278239130974
step: 190, loss: 0.1168360784649849
step: 200, loss: 0.07654710859060287
step: 210, loss: 0.09597910195589066
step: 220, loss: 0.02434670180082321
step: 230, loss: 0.0712638720870018
step: 240, loss: 0.03511863946914673
step: 250, loss: 0.08964566886425018
step: 260, loss: 0.12882362306118011
step: 270, loss: 0.10132723301649094
step: 280, loss: 0.053437814116477966
step: 290, loss: 0.06622892618179321
step: 300, loss: 0.08503612130880356
step: 310, loss: 0.0614100806415081
step: 320, loss: 0.13943974673748016
step: 330, loss: 0.14224785566329956
step: 340, loss: 0.06387845426797867
step: 350, loss: 0.1503247618675232
step: 360, loss: 0.03071017563343048
epoch 7: dev_f1=0.7551020408163265, f1=0.7114427860696517, best_f1=0.7114427860696517
step: 0, loss: 0.01669601909816265
step: 10, loss: 0.006724444683641195
step: 20, loss: 0.06183374673128128
step: 30, loss: 0.08218184858560562
step: 40, loss: 0.020717952400445938
step: 50, loss: 0.028253868222236633
step: 60, loss: 0.048895787447690964
step: 70, loss: 0.00516150239855051
step: 80, loss: 0.07880495488643646
step: 90, loss: 0.12309280782938004
step: 100, loss: 0.1580096185207367
step: 110, loss: 0.06720330566167831
step: 120, loss: 0.09242120385169983
step: 130, loss: 0.033328622579574585
step: 140, loss: 0.026248449459671974
step: 150, loss: 0.05263259634375572
step: 160, loss: 0.0496247261762619
step: 170, loss: 0.08359375596046448
step: 180, loss: 0.12862223386764526
step: 190, loss: 0.06952035427093506
step: 200, loss: 0.123400017619133
step: 210, loss: 0.12984859943389893
step: 220, loss: 0.07769082486629486
step: 230, loss: 0.12322298437356949
step: 240, loss: 0.09038757532835007
step: 250, loss: 0.06353116035461426
step: 260, loss: 0.07134244590997696
step: 270, loss: 0.2385343313217163
step: 280, loss: 0.12403104454278946
step: 290, loss: 0.006046912167221308
step: 300, loss: 0.07729340344667435
step: 310, loss: 0.08714034408330917
step: 320, loss: 0.07477660477161407
step: 330, loss: 0.10125482082366943
step: 340, loss: 0.18611867725849152
step: 350, loss: 0.03772860765457153
step: 360, loss: 0.08333192020654678
epoch 8: dev_f1=0.779220779220779, f1=0.7172774869109948, best_f1=0.7172774869109948
step: 0, loss: 0.05369405448436737
step: 10, loss: 0.07951811701059341
step: 20, loss: 0.06478535383939743
step: 30, loss: 0.0574512779712677
step: 40, loss: 0.12397481501102448
step: 50, loss: 0.04661545902490616
step: 60, loss: 0.1305491328239441
step: 70, loss: 0.06489848345518112
step: 80, loss: 0.05146195739507675
step: 90, loss: 0.056669194251298904
step: 100, loss: 0.04422912001609802
step: 110, loss: 0.019834911450743675
step: 120, loss: 0.09099247306585312
step: 130, loss: 0.088749460875988
step: 140, loss: 0.06443953514099121
step: 150, loss: 0.07256533950567245
step: 160, loss: 0.05214754864573479
step: 170, loss: 0.07165592163801193
step: 180, loss: 0.060282815247774124
step: 190, loss: 0.04507230594754219
step: 200, loss: 0.09359590709209442
step: 210, loss: 0.000972128938883543
step: 220, loss: 0.12052085250616074
step: 230, loss: 0.06864050030708313
step: 240, loss: 0.022777613252401352
step: 250, loss: 0.029419047757983208
step: 260, loss: 0.038553833961486816
step: 270, loss: 0.07992331683635712
step: 280, loss: 0.1535181701183319
step: 290, loss: 0.12052206695079803
step: 300, loss: 0.08124559372663498
step: 310, loss: 0.10342326015233994
step: 320, loss: 0.2681732773780823
step: 330, loss: 0.04316142573952675
step: 340, loss: 0.029243143275380135
step: 350, loss: 0.12462779134511948
step: 360, loss: 0.0684204176068306
epoch 9: dev_f1=0.7493917274939174, f1=0.6968973747016707, best_f1=0.7172774869109948
step: 0, loss: 0.005782009568065405
step: 10, loss: 0.023843713104724884
step: 20, loss: 0.05014585331082344
step: 30, loss: 0.06412531435489655
step: 40, loss: 0.09387689083814621
step: 50, loss: 0.1469143182039261
step: 60, loss: 0.16929776966571808
step: 70, loss: 0.19231373071670532
step: 80, loss: 0.017522722482681274
step: 90, loss: 0.08624134957790375
step: 100, loss: 0.04131891578435898
step: 110, loss: 0.05529908463358879
step: 120, loss: 0.022808006033301353
step: 130, loss: 0.01212199404835701
step: 140, loss: 0.07906597852706909
step: 150, loss: 0.04855893924832344
step: 160, loss: 0.0219754409044981
step: 170, loss: 0.08784814178943634
step: 180, loss: 0.12672553956508636
step: 190, loss: 0.06256656348705292
step: 200, loss: 0.02507617138326168
step: 210, loss: 0.09625271707773209
step: 220, loss: 0.13018640875816345
step: 230, loss: 0.09351954609155655
step: 240, loss: 0.06987417489290237
step: 250, loss: 0.02530151791870594
step: 260, loss: 0.11020668596029282
step: 270, loss: 0.004848867189139128
step: 280, loss: 0.048370636999607086
step: 290, loss: 0.10716713219881058
step: 300, loss: 0.15856517851352692
step: 310, loss: 0.045884959399700165
step: 320, loss: 0.11657142639160156
step: 330, loss: 0.053727805614471436
step: 340, loss: 0.09927807003259659
step: 350, loss: 0.14278973639011383
step: 360, loss: 0.07750440388917923
epoch 10: dev_f1=0.7600950118764845, f1=0.7072599531615926, best_f1=0.7172774869109948
step: 0, loss: 0.06348685920238495
step: 10, loss: 0.15273836255073547
step: 20, loss: 0.05759122967720032
step: 30, loss: 0.07655398547649384
step: 40, loss: 0.0876583606004715
step: 50, loss: 0.0400080606341362
step: 60, loss: 0.028245525434613228
step: 70, loss: 0.11530347168445587
step: 80, loss: 0.07401741296052933
step: 90, loss: 0.0072837816551327705
step: 100, loss: 0.11573189496994019
step: 110, loss: 0.02296236716210842
step: 120, loss: 0.0008883788832463324
step: 130, loss: 0.05251121148467064
step: 140, loss: 0.012875646352767944
step: 150, loss: 0.051171958446502686
step: 160, loss: 0.03520752862095833
step: 170, loss: 0.001444761990569532
step: 180, loss: 0.057877667248249054
step: 190, loss: 0.05190792679786682
step: 200, loss: 0.12170946598052979
step: 210, loss: 0.06610281765460968
step: 220, loss: 0.08846084028482437
step: 230, loss: 0.05266136676073074
step: 240, loss: 0.0661776140332222
step: 250, loss: 0.04904002696275711
step: 260, loss: 0.03429131954908371
step: 270, loss: 0.133754163980484
step: 280, loss: 0.08984650671482086
step: 290, loss: 0.11923117190599442
step: 300, loss: 0.20956026017665863
step: 310, loss: 0.09394168853759766
step: 320, loss: 0.01596849411725998
step: 330, loss: 0.0668857991695404
step: 340, loss: 0.03118424490094185
step: 350, loss: 0.017156755551695824
step: 360, loss: 0.042458925396203995
epoch 11: dev_f1=0.760204081632653, f1=0.7037974683544304, best_f1=0.7172774869109948
step: 0, loss: 0.06053079664707184
step: 10, loss: 0.05245315656065941
step: 20, loss: 0.08620242774486542
step: 30, loss: 0.06726521253585815
step: 40, loss: 0.054992299526929855
step: 50, loss: 0.04862230271100998
step: 60, loss: 0.06962470710277557
step: 70, loss: 0.0325164757668972
step: 80, loss: 0.03332693129777908
step: 90, loss: 0.2528969943523407
step: 100, loss: 0.04218708723783493
step: 110, loss: 0.12808343768119812
step: 120, loss: 0.14062590897083282
step: 130, loss: 0.0877639576792717
step: 140, loss: 0.04689202085137367
step: 150, loss: 0.014800474978983402
step: 160, loss: 0.1540832221508026
step: 170, loss: 0.052655939012765884
step: 180, loss: 0.01619095169007778
step: 190, loss: 0.04160038009285927
step: 200, loss: 0.04192938283085823
step: 210, loss: 0.12370140850543976
step: 220, loss: 0.021095098927617073
step: 230, loss: 0.056784965097904205
step: 240, loss: 0.04892954230308533
step: 250, loss: 0.08893207460641861
step: 260, loss: 0.05493846535682678
step: 270, loss: 0.11917705088853836
step: 280, loss: 0.013659643940627575
step: 290, loss: 0.00027251409483142197
step: 300, loss: 0.024036617949604988
step: 310, loss: 0.062287647277116776
step: 320, loss: 0.16476914286613464
step: 330, loss: 0.07162483781576157
step: 340, loss: 0.10919980704784393
step: 350, loss: 0.0133566465228796
step: 360, loss: 0.1196020320057869
epoch 12: dev_f1=0.7720207253886011, f1=0.7139107611548556, best_f1=0.7172774869109948
step: 0, loss: 0.019590236246585846
step: 10, loss: 0.16817143559455872
step: 20, loss: 0.034963466227054596
step: 30, loss: 0.10120096802711487
step: 40, loss: 0.04305069148540497
step: 50, loss: 0.08094722777605057
step: 60, loss: 0.012525273486971855
step: 70, loss: 0.06382875889539719
step: 80, loss: 0.031614240258932114
step: 90, loss: 0.043159566819667816
step: 100, loss: 0.020556626841425896
step: 110, loss: 0.032874736934900284
step: 120, loss: 0.009981970302760601
step: 130, loss: 0.044572968035936356
step: 140, loss: 0.09746666252613068
step: 150, loss: 0.00842059776186943
step: 160, loss: 0.0701042041182518
step: 170, loss: 0.11937524378299713
step: 180, loss: 0.0743638277053833
step: 190, loss: 0.04035197198390961
step: 200, loss: 0.11261061578989029
step: 210, loss: 0.06417135894298553
step: 220, loss: 0.024118943139910698
step: 230, loss: 0.06131695210933685
step: 240, loss: 0.014876981265842915
step: 250, loss: 0.0172526054084301
step: 260, loss: 0.022487204521894455
step: 270, loss: 0.01158920954912901
step: 280, loss: 0.0059304810129106045
step: 290, loss: 0.06809864193201065
step: 300, loss: 0.06629802286624908
step: 310, loss: 0.03935844451189041
step: 320, loss: 0.06659770011901855
step: 330, loss: 0.07140685617923737
step: 340, loss: 0.07712092250585556
step: 350, loss: 0.031889162957668304
step: 360, loss: 0.2769180238246918
epoch 13: dev_f1=0.7506702412868632, f1=0.670360110803324, best_f1=0.7172774869109948
step: 0, loss: 0.15197527408599854
step: 10, loss: 0.036673955619335175
step: 20, loss: 0.01998106762766838
step: 30, loss: 0.010064197704195976
step: 40, loss: 0.0175855103880167
step: 50, loss: 0.024295803159475327
step: 60, loss: 0.09327805787324905
step: 70, loss: 0.014415341429412365
step: 80, loss: 0.0752711072564125
step: 90, loss: 0.02733214572072029
step: 100, loss: 0.025593919679522514
step: 110, loss: 0.020233631134033203
step: 120, loss: 0.01842276193201542
step: 130, loss: 0.18032993376255035
step: 140, loss: 0.1049102246761322
step: 150, loss: 0.11192307621240616
step: 160, loss: 0.0012773502385243773
step: 170, loss: 0.05435632914304733
step: 180, loss: 0.024869563058018684
step: 190, loss: 0.05058791860938072
step: 200, loss: 0.10483473539352417
step: 210, loss: 0.0934039056301117
step: 220, loss: 0.06576959788799286
step: 230, loss: 0.0694904625415802
step: 240, loss: 0.050247494131326675
step: 250, loss: 0.05469955503940582
step: 260, loss: 0.10494246333837509
step: 270, loss: 0.06388583779335022
step: 280, loss: 0.025879571214318275
step: 290, loss: 0.0008391441660933197
step: 300, loss: 0.02686731144785881
step: 310, loss: 0.03466489538550377
step: 320, loss: 0.10833694040775299
step: 330, loss: 0.05485493317246437
step: 340, loss: 0.06332578510046005
step: 350, loss: 0.08215441554784775
step: 360, loss: 0.03571644797921181
epoch 14: dev_f1=0.7699757869249394, f1=0.7122641509433962, best_f1=0.7172774869109948
step: 0, loss: 0.007040879223495722
step: 10, loss: 0.016193680465221405
step: 20, loss: 0.05190311372280121
step: 30, loss: 0.02316991239786148
step: 40, loss: 0.05408117547631264
step: 50, loss: 0.00869967881590128
step: 60, loss: 0.03972931206226349
step: 70, loss: 0.023776153102517128
step: 80, loss: 0.0448729582130909
step: 90, loss: 0.13549759984016418
step: 100, loss: 0.04333844408392906
step: 110, loss: 0.11805938929319382
step: 120, loss: 0.03888201341032982
step: 130, loss: 0.05061466246843338
step: 140, loss: 0.07566772401332855
step: 150, loss: 0.15027672052383423
step: 160, loss: 0.020435575395822525
step: 170, loss: 0.03911035880446434
step: 180, loss: 0.013568374328315258
step: 190, loss: 0.06029132753610611
step: 200, loss: 0.009746506810188293
step: 210, loss: 0.10092853009700775
step: 220, loss: 0.06724325567483902
step: 230, loss: 0.052386000752449036
step: 240, loss: 0.013443036004900932
step: 250, loss: 0.039678219705820084
step: 260, loss: 0.044849693775177
step: 270, loss: 0.06937332451343536
step: 280, loss: 0.0575810968875885
step: 290, loss: 0.1457166224718094
step: 300, loss: 0.1312025934457779
step: 310, loss: 0.006322203669697046
step: 320, loss: 0.04874623194336891
step: 330, loss: 0.01787276193499565
step: 340, loss: 0.07032451778650284
step: 350, loss: 0.02871551550924778
step: 360, loss: 0.03158020228147507
epoch 15: dev_f1=0.7526315789473683, f1=0.7139107611548556, best_f1=0.7172774869109948
step: 0, loss: 0.004633632954210043
step: 10, loss: 0.1013103574514389
step: 20, loss: 0.015624192543327808
step: 30, loss: 0.0857720598578453
step: 40, loss: 0.032139867544174194
step: 50, loss: 0.00795908086001873
step: 60, loss: 0.03707775101065636
step: 70, loss: 0.00799962691962719
step: 80, loss: 0.012574918568134308
step: 90, loss: 0.10325472056865692
step: 100, loss: 0.030868975445628166
step: 110, loss: 0.11737877130508423
step: 120, loss: 0.03651485964655876
step: 130, loss: 0.07184868305921555
step: 140, loss: 0.06895291060209274
step: 150, loss: 0.040613263845443726
step: 160, loss: 0.08695821464061737
step: 170, loss: 0.06741825491189957
step: 180, loss: 0.025031326338648796
step: 190, loss: 0.02762262150645256
step: 200, loss: 0.02786046639084816
step: 210, loss: 0.003114206250756979
step: 220, loss: 0.02741386368870735
step: 230, loss: 0.07808442413806915
step: 240, loss: 0.08873765170574188
step: 250, loss: 0.04684385657310486
step: 260, loss: 0.050399843603372574
step: 270, loss: 0.07718947529792786
step: 280, loss: 0.056178558617830276
step: 290, loss: 0.007254908327013254
step: 300, loss: 0.0915711373090744
step: 310, loss: 0.029428942129015923
step: 320, loss: 0.046039413660764694
step: 330, loss: 0.014529752545058727
step: 340, loss: 0.09957572817802429
step: 350, loss: 0.06618896126747131
step: 360, loss: 0.049634624272584915
epoch 16: dev_f1=0.7683923705722071, f1=0.7138964577656676, best_f1=0.7172774869109948
step: 0, loss: 0.03667949512600899
step: 10, loss: 0.07599204033613205
step: 20, loss: 0.060658179223537445
step: 30, loss: 0.06484431773424149
step: 40, loss: 0.05072017014026642
step: 50, loss: 0.014758313074707985
step: 60, loss: 0.1117677241563797
step: 70, loss: 0.02043158933520317
step: 80, loss: 0.09637459367513657
step: 90, loss: 0.01967710815370083
step: 100, loss: 0.0022475761361420155
step: 110, loss: 0.007217814214527607
step: 120, loss: 0.10173238813877106
step: 130, loss: 0.02167876437306404
step: 140, loss: 0.0851663127541542
step: 150, loss: 0.03326832875609398
step: 160, loss: 0.05514945462346077
step: 170, loss: 0.050376325845718384
step: 180, loss: 0.024246705695986748
step: 190, loss: 0.03014316037297249
step: 200, loss: 0.03851958364248276
step: 210, loss: 0.022809244692325592
step: 220, loss: 0.11109238117933273
step: 230, loss: 0.013292389921844006
step: 240, loss: 0.035583220422267914
step: 250, loss: 0.07517870515584946
step: 260, loss: 0.07940947264432907
step: 270, loss: 0.058348190039396286
step: 280, loss: 0.09303699433803558
step: 290, loss: 0.10456656664609909
step: 300, loss: 0.0258470568805933
step: 310, loss: 0.010398594662547112
step: 320, loss: 0.049396440386772156
step: 330, loss: 0.004220146685838699
step: 340, loss: 0.04778297618031502
step: 350, loss: 0.0854070633649826
step: 360, loss: 0.10727476328611374
epoch 17: dev_f1=0.7564766839378239, f1=0.7098445595854923, best_f1=0.7172774869109948
step: 0, loss: 0.05788090080022812
step: 10, loss: 0.07091832160949707
step: 20, loss: 5.938904723734595e-05
step: 30, loss: 0.018186863511800766
step: 40, loss: 0.03451292961835861
step: 50, loss: 0.00631078751757741
step: 60, loss: 0.030566776171326637
step: 70, loss: 0.06660418957471848
step: 80, loss: 0.002354217227548361
step: 90, loss: 0.11768525838851929
step: 100, loss: 0.03751549497246742
step: 110, loss: 0.0036897161044180393
step: 120, loss: 0.01933855377137661
step: 130, loss: 0.13615630567073822
step: 140, loss: 0.16374541819095612
step: 150, loss: 0.09436416625976562
step: 160, loss: 0.05686317756772041
step: 170, loss: 6.863386079203337e-05
step: 180, loss: 0.04903007671236992
step: 190, loss: 0.04943003132939339
step: 200, loss: 0.0516270287334919
step: 210, loss: 0.05974629521369934
step: 220, loss: 0.07649310678243637
step: 230, loss: 0.0879286453127861
step: 240, loss: 0.017846157774329185
step: 250, loss: 0.061241522431373596
step: 260, loss: 0.05610661953687668
step: 270, loss: 0.09128908067941666
step: 280, loss: 0.004753251560032368
step: 290, loss: 0.041402533650398254
step: 300, loss: 0.004239093977957964
step: 310, loss: 0.00020037412468809634
step: 320, loss: 0.0867593064904213
step: 330, loss: 0.052392445504665375
step: 340, loss: 0.037196241319179535
step: 350, loss: 0.05360995978116989
step: 360, loss: 2.536856300139334e-05
epoch 18: dev_f1=0.760204081632653, f1=0.7095115681233932, best_f1=0.7172774869109948
step: 0, loss: 0.01139950379729271
step: 10, loss: 0.04177666828036308
step: 20, loss: 4.666647146223113e-05
step: 30, loss: 0.03033233806490898
step: 40, loss: 0.08013249933719635
step: 50, loss: 8.855936903273687e-05
step: 60, loss: 0.00013277395919431
step: 70, loss: 0.0737486258149147
step: 80, loss: 0.011310497298836708
step: 90, loss: 0.07383357733488083
step: 100, loss: 0.0560634545981884
step: 110, loss: 0.0009812266798689961
step: 120, loss: 0.030494360253214836
step: 130, loss: 0.03395986184477806
step: 140, loss: 0.01963146962225437
step: 150, loss: 4.173911293037236e-05
step: 160, loss: 0.03810745105147362
step: 170, loss: 0.01442031655460596
step: 180, loss: 0.1063297837972641
step: 190, loss: 0.04028528928756714
step: 200, loss: 0.059981606900691986
step: 210, loss: 0.015918485820293427
step: 220, loss: 0.028340034186840057
step: 230, loss: 0.007019397336989641
step: 240, loss: 0.0613386407494545
step: 250, loss: 0.038731351494789124
step: 260, loss: 0.11177512258291245
step: 270, loss: 0.026073066517710686
step: 280, loss: 0.07663041353225708
step: 290, loss: 0.012784378603100777
step: 300, loss: 0.0001374499552184716
step: 310, loss: 0.07760223746299744
step: 320, loss: 0.00043962831841781735
step: 330, loss: 0.05938858166337013
step: 340, loss: 0.0283979382365942
step: 350, loss: 0.015932725742459297
step: 360, loss: 0.0717659667134285
epoch 19: dev_f1=0.7493403693931397, f1=0.702127659574468, best_f1=0.7172774869109948
step: 0, loss: 0.01160295121371746
step: 10, loss: 0.03586471453309059
step: 20, loss: 0.03733792155981064
step: 30, loss: 0.00026392893050797284
step: 40, loss: 0.003440536092966795
step: 50, loss: 0.04705406352877617
step: 60, loss: 0.0038057698402553797
step: 70, loss: 0.03415361046791077
step: 80, loss: 0.08426637947559357
step: 90, loss: 0.05520612746477127
step: 100, loss: 0.05521101504564285
step: 110, loss: 0.06252428889274597
step: 120, loss: 0.009661059826612473
step: 130, loss: 0.021814484149217606
step: 140, loss: 0.03632176294922829
step: 150, loss: 0.009159177541732788
step: 160, loss: 0.06031731888651848
step: 170, loss: 0.13083110749721527
step: 180, loss: 0.08027200400829315
step: 190, loss: 0.08636350929737091
step: 200, loss: 0.06993883103132248
step: 210, loss: 0.05791951343417168
step: 220, loss: 0.00800790823996067
step: 230, loss: 0.09355908632278442
step: 240, loss: 0.05211316794157028
step: 250, loss: 0.015855126082897186
step: 260, loss: 0.023801999166607857
step: 270, loss: 0.0840410366654396
step: 280, loss: 0.009100651368498802
step: 290, loss: 0.018130633980035782
step: 300, loss: 0.0440802238881588
step: 310, loss: 0.017625773325562477
step: 320, loss: 0.02210339345037937
step: 330, loss: 0.010782692581415176
step: 340, loss: 0.03452076017856598
step: 350, loss: 0.00013781894813291728
step: 360, loss: 0.01171042025089264
epoch 20: dev_f1=0.7493261455525607, f1=0.6975476839237057, best_f1=0.7172774869109948
