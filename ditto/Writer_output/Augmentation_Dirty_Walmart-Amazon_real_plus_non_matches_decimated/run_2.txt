cuda
Device: cuda
step: 0, loss: 0.7480749487876892
step: 10, loss: 0.2802315652370453
step: 20, loss: 0.3158953785896301
step: 30, loss: 0.14508822560310364
step: 40, loss: 0.03429853543639183
step: 50, loss: 0.23538738489151
step: 60, loss: 0.13842907547950745
step: 70, loss: 0.14145250618457794
step: 80, loss: 0.1356051117181778
step: 90, loss: 0.22992923855781555
step: 100, loss: 0.49684953689575195
step: 110, loss: 0.13564878702163696
step: 120, loss: 0.1323314607143402
step: 130, loss: 0.14344152808189392
step: 140, loss: 0.6691421270370483
step: 150, loss: 0.04580603539943695
step: 160, loss: 0.12223471701145172
step: 170, loss: 0.4638011157512665
step: 180, loss: 0.4129604995250702
step: 190, loss: 0.21990621089935303
step: 200, loss: 0.28083106875419617
step: 210, loss: 0.18896566331386566
step: 220, loss: 0.2249108850955963
step: 230, loss: 0.2857447564601898
step: 240, loss: 0.05530010163784027
step: 250, loss: 0.007323930040001869
step: 260, loss: 0.12541437149047852
step: 270, loss: 0.21691733598709106
step: 280, loss: 0.19567006826400757
step: 290, loss: 0.22503861784934998
step: 300, loss: 0.1374613642692566
step: 310, loss: 0.33924126625061035
step: 320, loss: 0.0396202988922596
step: 330, loss: 0.10544808208942413
step: 340, loss: 0.08496898412704468
step: 350, loss: 0.019659820944070816
step: 360, loss: 0.18721488118171692
epoch 1: dev_f1=0.712871287128713, f1=0.6967418546365916, best_f1=0.6967418546365916
step: 0, loss: 0.08106351643800735
step: 10, loss: 0.10504709184169769
step: 20, loss: 0.07416339218616486
step: 30, loss: 0.11372291296720505
step: 40, loss: 0.14895279705524445
step: 50, loss: 0.03556855767965317
step: 60, loss: 0.10983017832040787
step: 70, loss: 0.20652437210083008
step: 80, loss: 0.08389388024806976
step: 90, loss: 0.23471903800964355
step: 100, loss: 0.18971140682697296
step: 110, loss: 0.10219020396471024
step: 120, loss: 0.061816416680812836
step: 130, loss: 0.12071481347084045
step: 140, loss: 0.3273962438106537
step: 150, loss: 0.13285201787948608
step: 160, loss: 0.216202974319458
step: 170, loss: 0.05217024311423302
step: 180, loss: 0.2508096992969513
step: 190, loss: 0.18927547335624695
step: 200, loss: 0.05030883476138115
step: 210, loss: 0.12945125997066498
step: 220, loss: 0.2264333814382553
step: 230, loss: 0.013993409462273121
step: 240, loss: 0.08662179112434387
step: 250, loss: 0.15853351354599
step: 260, loss: 0.0783257707953453
step: 270, loss: 0.11898265033960342
step: 280, loss: 0.1274370551109314
step: 290, loss: 0.023310037329792976
step: 300, loss: 0.1612052321434021
step: 310, loss: 0.2480025738477707
step: 320, loss: 0.15010502934455872
step: 330, loss: 0.15422816574573517
step: 340, loss: 0.2880784571170807
step: 350, loss: 0.027825070545077324
step: 360, loss: 0.1228814348578453
epoch 2: dev_f1=0.7228915662650602, f1=0.711217183770883, best_f1=0.711217183770883
step: 0, loss: 0.1802719235420227
step: 10, loss: 0.06548639386892319
step: 20, loss: 0.008664368651807308
step: 30, loss: 0.11861452460289001
step: 40, loss: 0.2037932127714157
step: 50, loss: 0.10672502219676971
step: 60, loss: 0.12128175050020218
step: 70, loss: 0.18750084936618805
step: 80, loss: 0.05083296820521355
step: 90, loss: 0.02774009294807911
step: 100, loss: 0.16888119280338287
step: 110, loss: 0.05401031672954559
step: 120, loss: 0.11540308594703674
step: 130, loss: 0.019912684336304665
step: 140, loss: 0.11277444660663605
step: 150, loss: 0.054354798048734665
step: 160, loss: 0.30617719888687134
step: 170, loss: 0.06359847635030746
step: 180, loss: 0.16331912577152252
step: 190, loss: 0.10510300099849701
step: 200, loss: 0.05213756114244461
step: 210, loss: 0.044946491718292236
step: 220, loss: 0.008686029352247715
step: 230, loss: 0.06618301570415497
step: 240, loss: 0.060992076992988586
step: 250, loss: 0.1343388557434082
step: 260, loss: 0.07369042187929153
step: 270, loss: 0.008191259577870369
step: 280, loss: 0.05717354267835617
step: 290, loss: 0.10703428834676743
step: 300, loss: 0.12445855885744095
step: 310, loss: 0.033452171832323074
step: 320, loss: 0.04415585473179817
step: 330, loss: 0.1689276248216629
step: 340, loss: 0.14251109957695007
step: 350, loss: 0.03749649599194527
step: 360, loss: 0.11431662738323212
epoch 3: dev_f1=0.7525252525252525, f1=0.722077922077922, best_f1=0.722077922077922
step: 0, loss: 0.2558134198188782
step: 10, loss: 0.06296069920063019
step: 20, loss: 0.1252957433462143
step: 30, loss: 0.014856887981295586
step: 40, loss: 0.02614624984562397
step: 50, loss: 0.11488308012485504
step: 60, loss: 0.16865020990371704
step: 70, loss: 0.10890177637338638
step: 80, loss: 0.07105252146720886
step: 90, loss: 0.03942489996552467
step: 100, loss: 0.07842536270618439
step: 110, loss: 0.001971365185454488
step: 120, loss: 0.07334572076797485
step: 130, loss: 0.4956369698047638
step: 140, loss: 0.00410048384219408
step: 150, loss: 0.08955562114715576
step: 160, loss: 0.04876042529940605
step: 170, loss: 0.15546835958957672
step: 180, loss: 0.12811608612537384
step: 190, loss: 0.07769150286912918
step: 200, loss: 0.10478436946868896
step: 210, loss: 0.0496952161192894
step: 220, loss: 0.16362138092517853
step: 230, loss: 0.20222274959087372
step: 240, loss: 0.03242931887507439
step: 250, loss: 0.019757064059376717
step: 260, loss: 0.08742634952068329
step: 270, loss: 0.10679379850625992
step: 280, loss: 0.1231151595711708
step: 290, loss: 0.09941082447767258
step: 300, loss: 0.00839251559227705
step: 310, loss: 0.017817243933677673
step: 320, loss: 0.3700965642929077
step: 330, loss: 0.24180211126804352
step: 340, loss: 0.2232421487569809
step: 350, loss: 0.09313944727182388
step: 360, loss: 0.09146793931722641
epoch 4: dev_f1=0.743801652892562, f1=0.7123287671232876, best_f1=0.722077922077922
step: 0, loss: 0.08630137890577316
step: 10, loss: 0.0751788392663002
step: 20, loss: 0.07126729935407639
step: 30, loss: 0.09873741120100021
step: 40, loss: 0.021226389333605766
step: 50, loss: 0.10118827223777771
step: 60, loss: 0.07003530114889145
step: 70, loss: 0.08526548743247986
step: 80, loss: 0.04219847917556763
step: 90, loss: 0.07837877422571182
step: 100, loss: 0.057508569210767746
step: 110, loss: 0.16603589057922363
step: 120, loss: 0.11077594012022018
step: 130, loss: 0.2958587110042572
step: 140, loss: 0.12632766366004944
step: 150, loss: 0.034731801599264145
step: 160, loss: 0.08928259462118149
step: 170, loss: 0.07760247588157654
step: 180, loss: 0.05389149487018585
step: 190, loss: 0.018393199890851974
step: 200, loss: 0.12780073285102844
step: 210, loss: 0.07102944701910019
step: 220, loss: 0.10880555212497711
step: 230, loss: 0.0782586932182312
step: 240, loss: 0.04785691946744919
step: 250, loss: 0.03133196756243706
step: 260, loss: 0.13153478503227234
step: 270, loss: 0.13003592193126678
step: 280, loss: 0.0040227193385362625
step: 290, loss: 0.03385419771075249
step: 300, loss: 0.03384176269173622
step: 310, loss: 0.15209047496318817
step: 320, loss: 0.10084294527769089
step: 330, loss: 0.014162161387503147
step: 340, loss: 0.22819267213344574
step: 350, loss: 0.13427358865737915
step: 360, loss: 0.04994458705186844
epoch 5: dev_f1=0.7554479418886199, f1=0.7255369928400954, best_f1=0.7255369928400954
step: 0, loss: 0.10340092331171036
step: 10, loss: 0.029732173308730125
step: 20, loss: 0.07339693605899811
step: 30, loss: 0.057177845388650894
step: 40, loss: 0.04030793905258179
step: 50, loss: 0.13025958836078644
step: 60, loss: 0.07019027322530746
step: 70, loss: 0.09208953380584717
step: 80, loss: 0.02600223384797573
step: 90, loss: 0.1489449441432953
step: 100, loss: 0.09146598726511002
step: 110, loss: 0.17720304429531097
step: 120, loss: 0.05022832378745079
step: 130, loss: 0.08658037334680557
step: 140, loss: 0.06519481539726257
step: 150, loss: 0.16670836508274078
step: 160, loss: 0.08835072070360184
step: 170, loss: 0.048490386456251144
step: 180, loss: 0.2449321299791336
step: 190, loss: 0.048618827015161514
step: 200, loss: 0.06612008064985275
step: 210, loss: 0.10296909511089325
step: 220, loss: 0.11360380798578262
step: 230, loss: 0.09887558966875076
step: 240, loss: 0.057900454849004745
step: 250, loss: 0.04069148376584053
step: 260, loss: 0.11818451434373856
step: 270, loss: 0.04085937514901161
step: 280, loss: 0.06656108051538467
step: 290, loss: 0.049344196915626526
step: 300, loss: 0.09113845229148865
step: 310, loss: 0.12530113756656647
step: 320, loss: 0.10588423907756805
step: 330, loss: 0.05432745814323425
step: 340, loss: 0.1374024599790573
step: 350, loss: 0.04642263054847717
step: 360, loss: 0.08636811375617981
epoch 6: dev_f1=0.7138810198300283, f1=0.7535410764872521, best_f1=0.7255369928400954
step: 0, loss: 0.07458657026290894
step: 10, loss: 0.046488214284181595
step: 20, loss: 0.12228726595640182
step: 30, loss: 0.05199258029460907
step: 40, loss: 0.014319747686386108
step: 50, loss: 0.06527785956859589
step: 60, loss: 0.0802406594157219
step: 70, loss: 0.09106405824422836
step: 80, loss: 0.04119042307138443
step: 90, loss: 0.04636181890964508
step: 100, loss: 0.1603490263223648
step: 110, loss: 0.1627904772758484
step: 120, loss: 0.07857295125722885
step: 130, loss: 0.03666650503873825
step: 140, loss: 0.021687911823391914
step: 150, loss: 0.12210395932197571
step: 160, loss: 0.1337243765592575
step: 170, loss: 0.003350864863023162
step: 180, loss: 0.12382952123880386
step: 190, loss: 0.07886014878749847
step: 200, loss: 0.05408361554145813
step: 210, loss: 0.10534973442554474
step: 220, loss: 0.052400603890419006
step: 230, loss: 0.12804092466831207
step: 240, loss: 0.15957197546958923
step: 250, loss: 0.09063306450843811
step: 260, loss: 0.04860168322920799
step: 270, loss: 0.03039180301129818
step: 280, loss: 0.10476118326187134
step: 290, loss: 0.03286264091730118
step: 300, loss: 0.08773220330476761
step: 310, loss: 0.044133447110652924
step: 320, loss: 0.03871968016028404
step: 330, loss: 0.10483404248952866
step: 340, loss: 0.10058830678462982
step: 350, loss: 0.018216419965028763
step: 360, loss: 0.11938362568616867
epoch 7: dev_f1=0.7531172069825437, f1=0.7631578947368421, best_f1=0.7255369928400954
step: 0, loss: 0.09879789501428604
step: 10, loss: 0.2334800511598587
step: 20, loss: 0.07867273688316345
step: 30, loss: 0.09734334796667099
step: 40, loss: 0.08238404244184494
step: 50, loss: 0.04600074887275696
step: 60, loss: 0.08597525954246521
step: 70, loss: 0.04217282310128212
step: 80, loss: 0.0344848707318306
step: 90, loss: 0.05684720724821091
step: 100, loss: 0.10713706165552139
step: 110, loss: 0.0299155805259943
step: 120, loss: 0.0225785281509161
step: 130, loss: 0.06866000592708588
step: 140, loss: 0.060582514852285385
step: 150, loss: 0.1424190104007721
step: 160, loss: 0.03363391011953354
step: 170, loss: 0.08931981027126312
step: 180, loss: 0.1557665765285492
step: 190, loss: 0.10703092813491821
step: 200, loss: 0.07950497418642044
step: 210, loss: 0.13731415569782257
step: 220, loss: 0.060735464096069336
step: 230, loss: 0.0855560377240181
step: 240, loss: 0.05680442601442337
step: 250, loss: 0.07680174708366394
step: 260, loss: 0.041637953370809555
step: 270, loss: 0.06611531972885132
step: 280, loss: 0.03756355866789818
step: 290, loss: 0.027888799086213112
step: 300, loss: 0.11026354134082794
step: 310, loss: 0.08091883361339569
step: 320, loss: 0.0623948872089386
step: 330, loss: 0.13496971130371094
step: 340, loss: 0.04425916448235512
step: 350, loss: 0.07814152538776398
step: 360, loss: 0.09222707897424698
epoch 8: dev_f1=0.734375, f1=0.7068493150684931, best_f1=0.7255369928400954
step: 0, loss: 0.047833867371082306
step: 10, loss: 0.08690560609102249
step: 20, loss: 0.05051174387335777
step: 30, loss: 0.0766705870628357
step: 40, loss: 0.07442838698625565
step: 50, loss: 0.05574508011341095
step: 60, loss: 0.05425795167684555
step: 70, loss: 0.05339033901691437
step: 80, loss: 0.057193923741579056
step: 90, loss: 0.0005306579987518489
step: 100, loss: 0.06896110624074936
step: 110, loss: 0.046778690069913864
step: 120, loss: 0.03661389648914337
step: 130, loss: 0.07852846384048462
step: 140, loss: 0.04680861160159111
step: 150, loss: 0.03822535276412964
step: 160, loss: 0.046810999512672424
step: 170, loss: 0.04996528849005699
step: 180, loss: 0.07376832515001297
step: 190, loss: 0.03988555446267128
step: 200, loss: 0.045947104692459106
step: 210, loss: 0.062403567135334015
step: 220, loss: 0.000669045839458704
step: 230, loss: 0.018038447946310043
step: 240, loss: 0.040951844304800034
step: 250, loss: 0.1704695224761963
step: 260, loss: 0.0383291020989418
step: 270, loss: 0.03836853429675102
step: 280, loss: 0.05364007502794266
step: 290, loss: 0.002868560841307044
step: 300, loss: 0.038388434797525406
step: 310, loss: 0.04448441043496132
step: 320, loss: 0.12444257736206055
step: 330, loss: 0.10069349408149719
step: 340, loss: 0.19414663314819336
step: 350, loss: 0.03989117592573166
step: 360, loss: 0.11002684384584427
epoch 9: dev_f1=0.7272727272727272, f1=0.7472527472527473, best_f1=0.7255369928400954
step: 0, loss: 0.051300790160894394
step: 10, loss: 0.017464211210608482
step: 20, loss: 0.033083878457546234
step: 30, loss: 0.021864380687475204
step: 40, loss: 0.037812069058418274
step: 50, loss: 0.0509304441511631
step: 60, loss: 0.18998168408870697
step: 70, loss: 0.08260150253772736
step: 80, loss: 0.16765165328979492
step: 90, loss: 0.10781705379486084
step: 100, loss: 0.021005773916840553
step: 110, loss: 0.09150125086307526
step: 120, loss: 0.04224053770303726
step: 130, loss: 0.0004175736103206873
step: 140, loss: 0.10147728770971298
step: 150, loss: 0.2930803894996643
step: 160, loss: 0.05467623472213745
step: 170, loss: 0.03934086859226227
step: 180, loss: 0.03094419836997986
step: 190, loss: 0.09274064749479294
step: 200, loss: 0.026618018746376038
step: 210, loss: 0.06991295516490936
step: 220, loss: 0.03461552411317825
step: 230, loss: 0.14064058661460876
step: 240, loss: 0.044940035790205
step: 250, loss: 0.08123274892568588
step: 260, loss: 0.025592923164367676
step: 270, loss: 0.03542381897568703
step: 280, loss: 0.08585545420646667
step: 290, loss: 0.023351533338427544
step: 300, loss: 0.11294777691364288
step: 310, loss: 0.06442952156066895
step: 320, loss: 0.08134660869836807
step: 330, loss: 0.023942235857248306
step: 340, loss: 0.014155284501612186
step: 350, loss: 0.019949477165937424
step: 360, loss: 0.1329479217529297
epoch 10: dev_f1=0.7537688442211056, f1=0.7176781002638523, best_f1=0.7255369928400954
step: 0, loss: 0.09357278048992157
step: 10, loss: 0.0926051214337349
step: 20, loss: 0.07296129316091537
step: 30, loss: 0.11316565424203873
step: 40, loss: 0.006058344617486
step: 50, loss: 0.08369984477758408
step: 60, loss: 0.06073532626032829
step: 70, loss: 0.018545137718319893
step: 80, loss: 0.04177607595920563
step: 90, loss: 0.09657114744186401
step: 100, loss: 0.04742371290922165
step: 110, loss: 0.1305692195892334
step: 120, loss: 0.07134363800287247
step: 130, loss: 0.13937881588935852
step: 140, loss: 0.06433196365833282
step: 150, loss: 0.00030036867246963084
step: 160, loss: 0.07466643303632736
step: 170, loss: 0.04123975709080696
step: 180, loss: 0.004136021714657545
step: 190, loss: 0.08345413953065872
step: 200, loss: 0.14285598695278168
step: 210, loss: 0.08110646903514862
step: 220, loss: 0.09737677872180939
step: 230, loss: 0.02428518421947956
step: 240, loss: 4.919341881759465e-05
step: 250, loss: 0.13451839983463287
step: 260, loss: 0.07923364639282227
step: 270, loss: 0.18418195843696594
step: 280, loss: 0.1423846185207367
step: 290, loss: 0.05161614343523979
step: 300, loss: 0.014221218414604664
step: 310, loss: 0.002769707003608346
step: 320, loss: 0.07721716910600662
step: 330, loss: 0.047337856143713
step: 340, loss: 0.0811430960893631
step: 350, loss: 0.09976392239332199
step: 360, loss: 0.039699751883745193
epoch 11: dev_f1=0.7360406091370559, f1=0.7282321899736147, best_f1=0.7255369928400954
step: 0, loss: 0.04250027611851692
step: 10, loss: 0.07040237635374069
step: 20, loss: 0.038576316088438034
step: 30, loss: 0.10711342841386795
step: 40, loss: 0.04300938546657562
step: 50, loss: 0.010078639723360538
step: 60, loss: 0.07716616243124008
step: 70, loss: 0.03262702748179436
step: 80, loss: 0.08032991737127304
step: 90, loss: 0.06781566143035889
step: 100, loss: 0.060183875262737274
step: 110, loss: 0.05348947271704674
step: 120, loss: 0.018497778102755547
step: 130, loss: 0.07112839072942734
step: 140, loss: 0.04387371242046356
step: 150, loss: 0.050028711557388306
step: 160, loss: 0.03645746409893036
step: 170, loss: 0.07172034680843353
step: 180, loss: 0.12937836349010468
step: 190, loss: 0.08644852042198181
step: 200, loss: 0.022912075743079185
step: 210, loss: 0.04730920121073723
step: 220, loss: 0.014570505358278751
step: 230, loss: 0.05332585796713829
step: 240, loss: 0.14838331937789917
step: 250, loss: 0.07298289239406586
step: 260, loss: 0.10488966107368469
step: 270, loss: 0.08381159603595734
step: 280, loss: 0.07353059947490692
step: 290, loss: 0.08275263756513596
step: 300, loss: 0.09292890876531601
step: 310, loss: 0.03240970894694328
step: 320, loss: 0.03208151459693909
step: 330, loss: 0.027221472933888435
step: 340, loss: 0.0669964849948883
step: 350, loss: 0.12441153824329376
step: 360, loss: 0.11538998782634735
epoch 12: dev_f1=0.7430025445292621, f1=0.7204301075268816, best_f1=0.7255369928400954
step: 0, loss: 0.011841407977044582
step: 10, loss: 0.02047736942768097
step: 20, loss: 0.034927207976579666
step: 30, loss: 0.04283399507403374
step: 40, loss: 0.045843690633773804
step: 50, loss: 0.05688324198126793
step: 60, loss: 0.10157247632741928
step: 70, loss: 0.038803521543741226
step: 80, loss: 0.057359203696250916
step: 90, loss: 0.08267973363399506
step: 100, loss: 0.08810149878263474
step: 110, loss: 0.00872130785137415
step: 120, loss: 0.3781885504722595
step: 130, loss: 0.01660209335386753
step: 140, loss: 0.0017580516869202256
step: 150, loss: 0.062217436730861664
step: 160, loss: 0.022519659250974655
step: 170, loss: 0.010194865986704826
step: 180, loss: 0.027355670928955078
step: 190, loss: 0.06756623834371567
step: 200, loss: 0.12014935165643692
step: 210, loss: 0.06134792044758797
step: 220, loss: 0.1339612752199173
step: 230, loss: 0.06712386012077332
step: 240, loss: 0.052317555993795395
step: 250, loss: 0.054750122129917145
step: 260, loss: 0.04002278298139572
step: 270, loss: 0.00964712630957365
step: 280, loss: 0.03769142925739288
step: 290, loss: 0.06349082291126251
step: 300, loss: 0.0020922368858009577
step: 310, loss: 0.03925390541553497
step: 320, loss: 0.03948817402124405
step: 330, loss: 0.01970759592950344
step: 340, loss: 0.026489729061722755
step: 350, loss: 0.09681461751461029
step: 360, loss: 0.04539717361330986
epoch 13: dev_f1=0.7559055118110236, f1=0.7345844504021448, best_f1=0.7345844504021448
step: 0, loss: 0.0844799354672432
step: 10, loss: 0.055133156478405
step: 20, loss: 0.02518961764872074
step: 30, loss: 0.0032351729460060596
step: 40, loss: 0.038033757358789444
step: 50, loss: 0.03952927887439728
step: 60, loss: 0.03235014155507088
step: 70, loss: 0.04954983666539192
step: 80, loss: 0.027841322124004364
step: 90, loss: 0.026982761919498444
step: 100, loss: 0.001640964299440384
step: 110, loss: 0.03863883391022682
step: 120, loss: 0.18390418589115143
step: 130, loss: 0.07252029329538345
step: 140, loss: 0.06751006096601486
step: 150, loss: 0.022258475422859192
step: 160, loss: 0.058688852936029434
step: 170, loss: 0.2071508914232254
step: 180, loss: 0.08007767051458359
step: 190, loss: 0.13653312623500824
step: 200, loss: 0.1244978979229927
step: 210, loss: 0.07750078290700912
step: 220, loss: 0.06245056167244911
step: 230, loss: 0.025171199813485146
step: 240, loss: 0.01960713230073452
step: 250, loss: 0.037767473608255386
step: 260, loss: 0.048487722873687744
step: 270, loss: 0.060989491641521454
step: 280, loss: 0.005815573036670685
step: 290, loss: 0.05720127373933792
step: 300, loss: 0.005000576376914978
step: 310, loss: 0.02829025685787201
step: 320, loss: 0.009427351877093315
step: 330, loss: 0.009733916260302067
step: 340, loss: 0.04069771245121956
step: 350, loss: 0.003853659611195326
step: 360, loss: 5.0228969485033303e-05
epoch 14: dev_f1=0.7214854111405835, f1=0.7166666666666668, best_f1=0.7345844504021448
step: 0, loss: 0.025317532941699028
step: 10, loss: 0.059986479580402374
step: 20, loss: 0.026875602081418037
step: 30, loss: 0.00427429610863328
step: 40, loss: 0.1518566906452179
step: 50, loss: 0.060770321637392044
step: 60, loss: 0.007839461788535118
step: 70, loss: 0.1288716048002243
step: 80, loss: 0.06888489425182343
step: 90, loss: 0.04263372719287872
step: 100, loss: 0.06583130359649658
step: 110, loss: 0.10052655637264252
step: 120, loss: 0.04983088746666908
step: 130, loss: 0.05792922526597977
step: 140, loss: 0.016028055921196938
step: 150, loss: 0.10347875207662582
step: 160, loss: 0.011793545447289944
step: 170, loss: 0.15507692098617554
step: 180, loss: 0.0695623829960823
step: 190, loss: 0.06347805261611938
step: 200, loss: 0.05439659208059311
step: 210, loss: 0.005364535376429558
step: 220, loss: 0.038840923458337784
step: 230, loss: 0.00458257831633091
step: 240, loss: 0.08354630321264267
step: 250, loss: 0.01251225546002388
step: 260, loss: 0.05519185960292816
step: 270, loss: 0.12436535954475403
step: 280, loss: 0.06869783997535706
step: 290, loss: 0.07284761220216751
step: 300, loss: 0.01816871389746666
step: 310, loss: 0.006311304867267609
step: 320, loss: 0.006045292131602764
step: 330, loss: 0.0651976466178894
step: 340, loss: 0.05667336657643318
step: 350, loss: 0.04112055152654648
step: 360, loss: 0.07031819224357605
epoch 15: dev_f1=0.7374005305039788, f1=0.6892655367231638, best_f1=0.7345844504021448
step: 0, loss: 0.05597684532403946
step: 10, loss: 0.015315625816583633
step: 20, loss: 0.019642740488052368
step: 30, loss: 0.07808742672204971
step: 40, loss: 0.03905121982097626
step: 50, loss: 0.017011184245347977
step: 60, loss: 0.0004184027493465692
step: 70, loss: 0.022265370935201645
step: 80, loss: 0.01342430617660284
step: 90, loss: 0.011335344985127449
step: 100, loss: 0.02496284991502762
step: 110, loss: 0.002126476028934121
step: 120, loss: 0.08264395594596863
step: 130, loss: 0.00013728818157687783
step: 140, loss: 0.0023092078045010567
step: 150, loss: 0.0482984222471714
step: 160, loss: 0.02775399386882782
step: 170, loss: 0.07813867926597595
step: 180, loss: 0.1023280993103981
step: 190, loss: 0.01531476341187954
step: 200, loss: 0.061299633234739304
step: 210, loss: 0.027945108711719513
step: 220, loss: 0.023248489946126938
step: 230, loss: 0.006164070218801498
step: 240, loss: 0.03175130859017372
step: 250, loss: 0.03941711410880089
step: 260, loss: 0.0006737944204360247
step: 270, loss: 0.04898332059383392
step: 280, loss: 0.05608746409416199
step: 290, loss: 0.07046118378639221
step: 300, loss: 0.034904032945632935
step: 310, loss: 0.03368517383933067
step: 320, loss: 0.006758993957191706
step: 330, loss: 0.11653322726488113
step: 340, loss: 0.060290489345788956
step: 350, loss: 0.022004734724760056
step: 360, loss: 0.12362238019704819
epoch 16: dev_f1=0.7320954907161804, f1=0.7302452316076293, best_f1=0.7345844504021448
step: 0, loss: 0.02108921855688095
step: 10, loss: 0.04098384082317352
step: 20, loss: 0.05571918562054634
step: 30, loss: 0.0021418146789073944
step: 40, loss: 2.2075721062719822e-05
step: 50, loss: 0.0013583488762378693
step: 60, loss: 0.050742000341415405
step: 70, loss: 0.023090669885277748
step: 80, loss: 0.014412512071430683
step: 90, loss: 0.08015991002321243
step: 100, loss: 0.027287859469652176
step: 110, loss: 0.07108936458826065
step: 120, loss: 0.030180513858795166
step: 130, loss: 0.10311982035636902
step: 140, loss: 0.04554620012640953
step: 150, loss: 0.03424922004342079
step: 160, loss: 0.02812226489186287
step: 170, loss: 0.0059278979897499084
step: 180, loss: 0.09361240267753601
step: 190, loss: 0.19266708195209503
step: 200, loss: 0.0004963150713592768
step: 210, loss: 0.014358924701809883
step: 220, loss: 0.014833679422736168
step: 230, loss: 0.006813345942646265
step: 240, loss: 0.08586804568767548
step: 250, loss: 0.06728164106607437
step: 260, loss: 0.0677608996629715
step: 270, loss: 0.061166685074567795
step: 280, loss: 0.06863855570554733
step: 290, loss: 0.023996278643608093
step: 300, loss: 0.002953005488961935
step: 310, loss: 0.06759411841630936
step: 320, loss: 0.021978937089443207
step: 330, loss: 0.008314194157719612
step: 340, loss: 0.06345697492361069
step: 350, loss: 0.12021646648645401
step: 360, loss: 0.041136179119348526
epoch 17: dev_f1=0.7409326424870466, f1=0.7046070460704608, best_f1=0.7345844504021448
step: 0, loss: 0.02155628800392151
step: 10, loss: 0.049256667494773865
step: 20, loss: 0.0657380223274231
step: 30, loss: 0.06048670411109924
step: 40, loss: 0.02546144276857376
step: 50, loss: 0.00901719368994236
step: 60, loss: 0.01126184593886137
step: 70, loss: 0.00212513143196702
step: 80, loss: 0.08484626561403275
step: 90, loss: 0.0012621647911146283
step: 100, loss: 0.06675785779953003
step: 110, loss: 0.08369949460029602
step: 120, loss: 0.01604926772415638
step: 130, loss: 0.0007767389761283994
step: 140, loss: 0.03285850211977959
step: 150, loss: 0.01595253311097622
step: 160, loss: 0.03194630518555641
step: 170, loss: 0.08610448241233826
step: 180, loss: 0.025112435221672058
step: 190, loss: 0.02221064269542694
step: 200, loss: 0.041453927755355835
step: 210, loss: 0.06627386808395386
step: 220, loss: 0.032284900546073914
step: 230, loss: 0.07393331080675125
step: 240, loss: 0.06952700763940811
step: 250, loss: 0.054711777716875076
step: 260, loss: 0.023668061941862106
step: 270, loss: 0.07281649857759476
step: 280, loss: 3.453340468695387e-05
step: 290, loss: 0.10297597199678421
step: 300, loss: 0.07470857352018356
step: 310, loss: 0.10927170515060425
step: 320, loss: 0.04408474639058113
step: 330, loss: 0.034037474542856216
step: 340, loss: 0.07365559786558151
step: 350, loss: 0.05121589079499245
step: 360, loss: 0.01644046977162361
epoch 18: dev_f1=0.7229551451187335, f1=0.717391304347826, best_f1=0.7345844504021448
step: 0, loss: 0.03216058388352394
step: 10, loss: 0.13572551310062408
step: 20, loss: 0.006104283034801483
step: 30, loss: 0.05133400112390518
step: 40, loss: 0.0680261105298996
step: 50, loss: 0.037232279777526855
step: 60, loss: 0.030487865209579468
step: 70, loss: 0.09071729332208633
step: 80, loss: 0.08305714279413223
step: 90, loss: 0.06431769579648972
step: 100, loss: 0.016758158802986145
step: 110, loss: 0.016174783930182457
step: 120, loss: 0.041565556079149246
step: 130, loss: 0.048998795449733734
step: 140, loss: 0.05053594335913658
step: 150, loss: 0.007133123930543661
step: 160, loss: 0.01602199301123619
step: 170, loss: 0.09254805743694305
step: 180, loss: 0.05317746475338936
step: 190, loss: 0.05176752433180809
step: 200, loss: 0.013220027089118958
step: 210, loss: 0.015166656114161015
step: 220, loss: 0.020824404433369637
step: 230, loss: 0.075693279504776
step: 240, loss: 0.03923996910452843
step: 250, loss: 0.011156325228512287
step: 260, loss: 0.03568124771118164
step: 270, loss: 0.0005504566943272948
step: 280, loss: 0.001455102232284844
step: 290, loss: 0.05059788003563881
step: 300, loss: 0.07285840809345245
step: 310, loss: 0.09772361814975739
step: 320, loss: 0.005893907975405455
step: 330, loss: 0.016846872866153717
step: 340, loss: 0.014037653803825378
step: 350, loss: 0.006082894746214151
step: 360, loss: 0.028645558282732964
epoch 19: dev_f1=0.7204301075268816, f1=0.7022471910112359, best_f1=0.7345844504021448
step: 0, loss: 0.018336253240704536
step: 10, loss: 0.01997353322803974
step: 20, loss: 0.03592011332511902
step: 30, loss: 0.028681673109531403
step: 40, loss: 0.016409389674663544
step: 50, loss: 0.14766930043697357
step: 60, loss: 0.0027871467173099518
step: 70, loss: 0.0439680851995945
step: 80, loss: 0.029658742249011993
step: 90, loss: 0.04873675853013992
step: 100, loss: 0.005008189007639885
step: 110, loss: 0.07107924669981003
step: 120, loss: 0.06455794721841812
step: 130, loss: 0.09799398481845856
step: 140, loss: 0.09862537682056427
step: 150, loss: 0.00020498990488704294
step: 160, loss: 4.860110493609682e-05
step: 170, loss: 0.12257739901542664
step: 180, loss: 0.021313993260264397
step: 190, loss: 0.04180625453591347
step: 200, loss: 0.019291188567876816
step: 210, loss: 0.015609052032232285
step: 220, loss: 0.030750831589102745
step: 230, loss: 0.015360696241259575
step: 240, loss: 0.0014520310796797276
step: 250, loss: 0.039961837232112885
step: 260, loss: 0.07031160593032837
step: 270, loss: 0.03106151521205902
step: 280, loss: 0.032486654818058014
step: 290, loss: 0.017153628170490265
step: 300, loss: 0.04897591099143028
step: 310, loss: 0.0106984106823802
step: 320, loss: 0.05114196985960007
step: 330, loss: 0.08055277168750763
step: 340, loss: 0.037380803376436234
step: 350, loss: 0.018771501258015633
step: 360, loss: 0.04657130315899849
epoch 20: dev_f1=0.7253333333333334, f1=0.7019498607242339, best_f1=0.7345844504021448
