cuda
Device: cuda
step: 0, loss: 0.561951756477356
step: 10, loss: 0.3066653609275818
step: 20, loss: 0.21590396761894226
step: 30, loss: 0.09217139333486557
step: 40, loss: 0.2283843606710434
step: 50, loss: 0.046480871737003326
step: 60, loss: 0.2462158054113388
step: 70, loss: 0.21101562678813934
step: 80, loss: 0.12843801081180573
step: 90, loss: 0.13214927911758423
step: 100, loss: 0.2093014419078827
step: 110, loss: 0.12002242356538773
step: 120, loss: 0.22364431619644165
step: 130, loss: 0.14875619113445282
step: 140, loss: 0.0923239141702652
step: 150, loss: 0.27555057406425476
step: 160, loss: 0.2695103883743286
step: 170, loss: 0.14840134978294373
step: 180, loss: 0.17735476791858673
step: 190, loss: 0.21348117291927338
step: 200, loss: 0.057476453483104706
step: 210, loss: 0.10834938287734985
step: 220, loss: 0.220648393034935
step: 230, loss: 0.06879391521215439
step: 240, loss: 0.3256113827228546
step: 250, loss: 0.21580806374549866
step: 260, loss: 0.01751791313290596
step: 270, loss: 0.11319928616285324
step: 280, loss: 0.3137359321117401
step: 290, loss: 0.14110401272773743
step: 300, loss: 0.10525476187467575
step: 310, loss: 0.1331479549407959
step: 320, loss: 0.021406274288892746
step: 330, loss: 0.1200159415602684
step: 340, loss: 0.04676495119929314
step: 350, loss: 0.19967402517795563
step: 360, loss: 0.07348205894231796
epoch 1: dev_f1=0.5885885885885886, f1=0.629737609329446, best_f1=0.629737609329446
step: 0, loss: 0.1916024535894394
step: 10, loss: 0.17450346052646637
step: 20, loss: 0.08626703172922134
step: 30, loss: 0.13040095567703247
step: 40, loss: 0.1139560341835022
step: 50, loss: 0.11488200724124908
step: 60, loss: 0.18741561472415924
step: 70, loss: 0.12171849608421326
step: 80, loss: 0.05271311476826668
step: 90, loss: 0.13855485618114471
step: 100, loss: 0.29978322982788086
step: 110, loss: 0.04660258814692497
step: 120, loss: 0.06959248334169388
step: 130, loss: 0.16403546929359436
step: 140, loss: 0.1962745636701584
step: 150, loss: 0.160544753074646
step: 160, loss: 0.22039839625358582
step: 170, loss: 0.09037734568119049
step: 180, loss: 0.13628177344799042
step: 190, loss: 0.07115814089775085
step: 200, loss: 0.02065415307879448
step: 210, loss: 0.15686911344528198
step: 220, loss: 0.05151495710015297
step: 230, loss: 0.1490737497806549
step: 240, loss: 0.0512358583509922
step: 250, loss: 0.09444616734981537
step: 260, loss: 0.2830345630645752
step: 270, loss: 0.05420200154185295
step: 280, loss: 0.032520681619644165
step: 290, loss: 0.24550211429595947
step: 300, loss: 0.019769204780459404
step: 310, loss: 0.12653014063835144
step: 320, loss: 0.08585698902606964
step: 330, loss: 0.13392247259616852
step: 340, loss: 0.11880898475646973
step: 350, loss: 0.07267458736896515
step: 360, loss: 0.13560271263122559
epoch 2: dev_f1=0.7166666666666668, f1=0.6876790830945559, best_f1=0.6876790830945559
step: 0, loss: 0.266408771276474
step: 10, loss: 0.08548812568187714
step: 20, loss: 0.1213560551404953
step: 30, loss: 0.07854696363210678
step: 40, loss: 0.0829097181558609
step: 50, loss: 0.04096457362174988
step: 60, loss: 0.08951537311077118
step: 70, loss: 0.2310568243265152
step: 80, loss: 0.06673260778188705
step: 90, loss: 0.1955716907978058
step: 100, loss: 0.19766588509082794
step: 110, loss: 0.0912686139345169
step: 120, loss: 0.06968788057565689
step: 130, loss: 0.06056187301874161
step: 140, loss: 0.10912487655878067
step: 150, loss: 0.08448118716478348
step: 160, loss: 0.2592456638813019
step: 170, loss: 0.11240722984075546
step: 180, loss: 0.067336305975914
step: 190, loss: 0.12083718925714493
step: 200, loss: 0.15057291090488434
step: 210, loss: 0.1078629270195961
step: 220, loss: 0.057495176792144775
step: 230, loss: 0.1772347390651703
step: 240, loss: 0.05768684670329094
step: 250, loss: 0.06451123207807541
step: 260, loss: 0.16081248223781586
step: 270, loss: 0.1566074639558792
step: 280, loss: 0.13284802436828613
step: 290, loss: 0.1694350242614746
step: 300, loss: 0.06746801733970642
step: 310, loss: 0.211131751537323
step: 320, loss: 0.06180286034941673
step: 330, loss: 0.05943197384476662
step: 340, loss: 0.20476670563220978
step: 350, loss: 0.07841211557388306
step: 360, loss: 0.034122150391340256
epoch 3: dev_f1=0.7590027700831025, f1=0.724233983286908, best_f1=0.724233983286908
step: 0, loss: 0.006054270546883345
step: 10, loss: 0.07679548114538193
step: 20, loss: 0.15983235836029053
step: 30, loss: 0.21641480922698975
step: 40, loss: 0.03635002300143242
step: 50, loss: 0.06040125712752342
step: 60, loss: 0.05410246551036835
step: 70, loss: 0.17289821803569794
step: 80, loss: 0.0615118108689785
step: 90, loss: 0.01993776671588421
step: 100, loss: 0.09388173371553421
step: 110, loss: 0.07836048305034637
step: 120, loss: 0.17824789881706238
step: 130, loss: 0.08189069479703903
step: 140, loss: 0.15129289031028748
step: 150, loss: 0.0007933382294140756
step: 160, loss: 0.16565118730068207
step: 170, loss: 0.08923344314098358
step: 180, loss: 0.08049121499061584
step: 190, loss: 0.0761604979634285
step: 200, loss: 0.052487920969724655
step: 210, loss: 0.0631522461771965
step: 220, loss: 0.22334249317646027
step: 230, loss: 0.0987144261598587
step: 240, loss: 0.07657559961080551
step: 250, loss: 0.03909625485539436
step: 260, loss: 0.14275816082954407
step: 270, loss: 0.1453317105770111
step: 280, loss: 0.06947925686836243
step: 290, loss: 0.1912790685892105
step: 300, loss: 0.054714612662792206
step: 310, loss: 0.04555702582001686
step: 320, loss: 0.21268537640571594
step: 330, loss: 0.03958366438746452
step: 340, loss: 0.14643457531929016
step: 350, loss: 0.05415494367480278
step: 360, loss: 0.12622569501399994
epoch 4: dev_f1=0.7336683417085428, f1=0.7085427135678392, best_f1=0.724233983286908
step: 0, loss: 0.04341898858547211
step: 10, loss: 0.039636071771383286
step: 20, loss: 0.057369034737348557
step: 30, loss: 0.10088716447353363
step: 40, loss: 0.10222260653972626
step: 50, loss: 0.09181280434131622
step: 60, loss: 0.029866866767406464
step: 70, loss: 0.1698853075504303
step: 80, loss: 0.04746106266975403
step: 90, loss: 0.052108243107795715
step: 100, loss: 0.07101229578256607
step: 110, loss: 0.17198072373867035
step: 120, loss: 0.0826343297958374
step: 130, loss: 0.05513636767864227
step: 140, loss: 0.1125156432390213
step: 150, loss: 0.09624699503183365
step: 160, loss: 0.04160009324550629
step: 170, loss: 0.0011750495759770274
step: 180, loss: 0.08812513947486877
step: 190, loss: 0.10123254358768463
step: 200, loss: 0.048887453973293304
step: 210, loss: 0.19865012168884277
step: 220, loss: 0.027648279443383217
step: 230, loss: 0.087517149746418
step: 240, loss: 0.12790408730506897
step: 250, loss: 0.1677936613559723
step: 260, loss: 0.08864990621805191
step: 270, loss: 0.05491670221090317
step: 280, loss: 0.003616697620600462
step: 290, loss: 0.04063698649406433
step: 300, loss: 0.045372676104307175
step: 310, loss: 0.04659334197640419
step: 320, loss: 0.09341652691364288
step: 330, loss: 0.04735580086708069
step: 340, loss: 0.10455542802810669
step: 350, loss: 0.15398293733596802
step: 360, loss: 0.02613278664648533
epoch 5: dev_f1=0.691358024691358, f1=0.6921119592875319, best_f1=0.724233983286908
step: 0, loss: 0.023345595225691795
step: 10, loss: 0.01325941737741232
step: 20, loss: 0.06799952685832977
step: 30, loss: 0.04757540673017502
step: 40, loss: 0.23577286303043365
step: 50, loss: 0.18702924251556396
step: 60, loss: 0.0817049965262413
step: 70, loss: 0.06450091302394867
step: 80, loss: 0.0031716313678771257
step: 90, loss: 0.0003179939230903983
step: 100, loss: 0.026169368997216225
step: 110, loss: 0.052707329392433167
step: 120, loss: 0.03904881328344345
step: 130, loss: 0.08270985633134842
step: 140, loss: 0.34648996591567993
step: 150, loss: 0.13523584604263306
step: 160, loss: 0.04588412865996361
step: 170, loss: 0.08454498648643494
step: 180, loss: 0.07175615429878235
step: 190, loss: 0.02630978636443615
step: 200, loss: 0.06048958748579025
step: 210, loss: 0.06130747124552727
step: 220, loss: 0.03511203080415726
step: 230, loss: 0.1527225822210312
step: 240, loss: 0.17806875705718994
step: 250, loss: 0.14378012716770172
step: 260, loss: 0.14390528202056885
step: 270, loss: 0.08110849559307098
step: 280, loss: 0.08032982051372528
step: 290, loss: 0.12917381525039673
step: 300, loss: 0.06154264137148857
step: 310, loss: 0.04891665652394295
step: 320, loss: 0.11194886267185211
step: 330, loss: 0.033280737698078156
step: 340, loss: 0.02900194562971592
step: 350, loss: 0.10099267959594727
step: 360, loss: 0.039145149290561676
epoch 6: dev_f1=0.6997518610421836, f1=0.7281795511221945, best_f1=0.724233983286908
step: 0, loss: 0.02795163169503212
step: 10, loss: 0.10974963009357452
step: 20, loss: 0.06798682361841202
step: 30, loss: 0.0242044348269701
step: 40, loss: 0.042976975440979004
step: 50, loss: 0.05431253835558891
step: 60, loss: 0.076936736702919
step: 70, loss: 0.10016351193189621
step: 80, loss: 0.06901809573173523
step: 90, loss: 0.08260760456323624
step: 100, loss: 0.07649862766265869
step: 110, loss: 0.07477331906557083
step: 120, loss: 0.0867968499660492
step: 130, loss: 0.04378017038106918
step: 140, loss: 0.07515010982751846
step: 150, loss: 0.14898927509784698
step: 160, loss: 0.13060793280601501
step: 170, loss: 0.14841093122959137
step: 180, loss: 0.13924607634544373
step: 190, loss: 0.049967698752880096
step: 200, loss: 0.03480752557516098
step: 210, loss: 0.06929478049278259
step: 220, loss: 0.10232473164796829
step: 230, loss: 0.2008698582649231
step: 240, loss: 0.022503845393657684
step: 250, loss: 0.16805978119373322
step: 260, loss: 0.08557488769292831
step: 270, loss: 0.019510313868522644
step: 280, loss: 0.07881380617618561
step: 290, loss: 0.17035798728466034
step: 300, loss: 0.03382799029350281
step: 310, loss: 0.061928823590278625
step: 320, loss: 0.09123849868774414
step: 330, loss: 0.07374159246683121
step: 340, loss: 0.025020824745297432
step: 350, loss: 0.07932546734809875
step: 360, loss: 0.0745086669921875
epoch 7: dev_f1=0.7295285359801489, f1=0.7346938775510203, best_f1=0.724233983286908
step: 0, loss: 0.021162087097764015
step: 10, loss: 0.0428537093102932
step: 20, loss: 0.1389770805835724
step: 30, loss: 0.17167343199253082
step: 40, loss: 0.025071702897548676
step: 50, loss: 0.12585541605949402
step: 60, loss: 0.10837910324335098
step: 70, loss: 0.002127389656379819
step: 80, loss: 0.03734845668077469
step: 90, loss: 0.06507427245378494
step: 100, loss: 0.03012884221971035
step: 110, loss: 0.11223197728395462
step: 120, loss: 0.07353362441062927
step: 130, loss: 0.08938027918338776
step: 140, loss: 0.1338459849357605
step: 150, loss: 0.0664675161242485
step: 160, loss: 0.07528116554021835
step: 170, loss: 0.12546348571777344
step: 180, loss: 0.010944939218461514
step: 190, loss: 0.09359409660100937
step: 200, loss: 0.031932685524225235
step: 210, loss: 0.026547320187091827
step: 220, loss: 0.0898791030049324
step: 230, loss: 0.03911476954817772
step: 240, loss: 0.0012998448219150305
step: 250, loss: 0.00035386031959205866
step: 260, loss: 0.042047590017318726
step: 270, loss: 0.010121526196599007
step: 280, loss: 0.13958652317523956
step: 290, loss: 0.04569631069898605
step: 300, loss: 0.16934682428836823
step: 310, loss: 0.08832991868257523
step: 320, loss: 0.03462104871869087
step: 330, loss: 0.15393415093421936
step: 340, loss: 0.05687067657709122
step: 350, loss: 0.14741425216197968
step: 360, loss: 0.01701311580836773
epoch 8: dev_f1=0.7526315789473683, f1=0.7158469945355191, best_f1=0.724233983286908
step: 0, loss: 0.02809574082493782
step: 10, loss: 0.06932366639375687
step: 20, loss: 0.16306370496749878
step: 30, loss: 0.047084078192710876
step: 40, loss: 0.0518663115799427
step: 50, loss: 0.07395751029253006
step: 60, loss: 0.0605955608189106
step: 70, loss: 0.06329437345266342
step: 80, loss: 0.11831111460924149
step: 90, loss: 0.008950977586209774
step: 100, loss: 0.0721847265958786
step: 110, loss: 0.04433983564376831
step: 120, loss: 0.11577394604682922
step: 130, loss: 0.042390238493680954
step: 140, loss: 0.03919326514005661
step: 150, loss: 0.08687342703342438
step: 160, loss: 0.013169527053833008
step: 170, loss: 0.07626572251319885
step: 180, loss: 0.15639208257198334
step: 190, loss: 0.047838374972343445
step: 200, loss: 0.07988874614238739
step: 210, loss: 0.00015766432625241578
step: 220, loss: 0.017247993499040604
step: 230, loss: 0.08349547535181046
step: 240, loss: 0.1518157422542572
step: 250, loss: 0.060797449201345444
step: 260, loss: 0.07790299504995346
step: 270, loss: 0.03245653212070465
step: 280, loss: 0.15814433991909027
step: 290, loss: 0.03869236633181572
step: 300, loss: 0.0963435098528862
step: 310, loss: 0.1537703275680542
step: 320, loss: 0.10803280025720596
step: 330, loss: 0.06962884962558746
step: 340, loss: 0.04902276396751404
step: 350, loss: 0.13792236149311066
step: 360, loss: 0.015049910172820091
epoch 9: dev_f1=0.7526315789473683, f1=0.7440633245382585, best_f1=0.724233983286908
step: 0, loss: 0.05576527863740921
step: 10, loss: 0.06406833231449127
step: 20, loss: 0.023069601505994797
step: 30, loss: 0.040601715445518494
step: 40, loss: 0.04380613937973976
step: 50, loss: 0.03288096934556961
step: 60, loss: 0.13295049965381622
step: 70, loss: 0.1504022479057312
step: 80, loss: 0.03981833532452583
step: 90, loss: 0.05850138142704964
step: 100, loss: 0.012416504323482513
step: 110, loss: 0.1043819934129715
step: 120, loss: 0.03390113636851311
step: 130, loss: 0.03337028622627258
step: 140, loss: 0.10707789659500122
step: 150, loss: 0.13683676719665527
step: 160, loss: 0.06575756520032883
step: 170, loss: 0.08340281993150711
step: 180, loss: 0.07604585587978363
step: 190, loss: 0.021876554936170578
step: 200, loss: 0.08116960525512695
step: 210, loss: 0.09026151150465012
step: 220, loss: 0.08272901922464371
step: 230, loss: 0.10568807274103165
step: 240, loss: 0.05462874472141266
step: 250, loss: 0.089814193546772
step: 260, loss: 0.049723245203495026
step: 270, loss: 0.06894215941429138
step: 280, loss: 0.09630051255226135
step: 290, loss: 0.06289540231227875
step: 300, loss: 0.11704081296920776
step: 310, loss: 0.10410109907388687
step: 320, loss: 0.018878011032938957
step: 330, loss: 0.00901886448264122
step: 340, loss: 0.08181941509246826
step: 350, loss: 0.18768896162509918
step: 360, loss: 0.038802292197942734
epoch 10: dev_f1=0.7380410022779044, f1=0.695067264573991, best_f1=0.724233983286908
step: 0, loss: 0.049973491579294205
step: 10, loss: 0.0953434631228447
step: 20, loss: 0.08097486197948456
step: 30, loss: 0.053809888660907745
step: 40, loss: 0.029992587864398956
step: 50, loss: 0.15853911638259888
step: 60, loss: 0.08976272493600845
step: 70, loss: 0.0874873474240303
step: 80, loss: 0.01655222661793232
step: 90, loss: 0.12300378084182739
step: 100, loss: 0.08345037698745728
step: 110, loss: 0.053697798401117325
step: 120, loss: 0.06587876379489899
step: 130, loss: 0.08473960310220718
step: 140, loss: 0.10664866119623184
step: 150, loss: 0.024015355855226517
step: 160, loss: 0.08884897083044052
step: 170, loss: 0.15455305576324463
step: 180, loss: 0.07579617947340012
step: 190, loss: 0.07241126894950867
step: 200, loss: 0.007239970378577709
step: 210, loss: 0.10711373388767242
step: 220, loss: 0.06955515593290329
step: 230, loss: 0.04374875873327255
step: 240, loss: 0.07510672509670258
step: 250, loss: 0.1560514271259308
step: 260, loss: 0.028071235865354538
step: 270, loss: 0.07203595340251923
step: 280, loss: 0.13054677844047546
step: 290, loss: 0.02024233527481556
step: 300, loss: 0.0011022664839401841
step: 310, loss: 0.035989437252283096
step: 320, loss: 0.15439563989639282
step: 330, loss: 0.08823869377374649
step: 340, loss: 6.699396908516064e-05
step: 350, loss: 0.04235312342643738
step: 360, loss: 0.057787928730249405
epoch 11: dev_f1=0.73, f1=0.6972010178117048, best_f1=0.724233983286908
step: 0, loss: 0.12826019525527954
step: 10, loss: 0.02476251870393753
step: 20, loss: 0.08843861520290375
step: 30, loss: 0.03442683815956116
step: 40, loss: 0.040024057030677795
step: 50, loss: 0.03020845726132393
step: 60, loss: 0.006065798923373222
step: 70, loss: 0.060865480452775955
step: 80, loss: 0.011362362653017044
step: 90, loss: 0.027030065655708313
step: 100, loss: 0.019300149753689766
step: 110, loss: 0.12622632086277008
step: 120, loss: 0.021600624546408653
step: 130, loss: 0.12445136159658432
step: 140, loss: 0.016006141901016235
step: 150, loss: 0.06772710382938385
step: 160, loss: 0.08014846593141556
step: 170, loss: 0.056175000965595245
step: 180, loss: 0.030946524813771248
step: 190, loss: 0.02654450573027134
step: 200, loss: 0.046904731541872025
step: 210, loss: 0.10811158269643784
step: 220, loss: 0.05153670534491539
step: 230, loss: 0.07943220436573029
step: 240, loss: 0.056265152990818024
step: 250, loss: 0.05314981937408447
step: 260, loss: 0.03439589962363243
step: 270, loss: 0.11278517544269562
step: 280, loss: 0.15178969502449036
step: 290, loss: 0.06110219657421112
step: 300, loss: 0.022852737456560135
step: 310, loss: 0.05722370371222496
step: 320, loss: 0.19278106093406677
step: 330, loss: 0.057250648736953735
step: 340, loss: 0.038820646703243256
step: 350, loss: 0.15377432107925415
step: 360, loss: 0.07630928605794907
epoch 12: dev_f1=0.7355163727959698, f1=0.7329842931937172, best_f1=0.724233983286908
step: 0, loss: 0.018319176509976387
step: 10, loss: 0.0455545149743557
step: 20, loss: 7.047454710118473e-05
step: 30, loss: 0.04102659970521927
step: 40, loss: 0.021153250709176064
step: 50, loss: 0.026019223034381866
step: 60, loss: 0.08349844813346863
step: 70, loss: 0.06856705248355865
step: 80, loss: 0.052449941635131836
step: 90, loss: 0.09603868424892426
step: 100, loss: 0.0289303008466959
step: 110, loss: 0.05707308650016785
step: 120, loss: 0.03010874055325985
step: 130, loss: 0.09647147357463837
step: 140, loss: 0.07681713253259659
step: 150, loss: 0.21088455617427826
step: 160, loss: 0.02244650572538376
step: 170, loss: 0.02377501130104065
step: 180, loss: 0.10129952430725098
step: 190, loss: 0.03125656768679619
step: 200, loss: 0.04418548569083214
step: 210, loss: 0.06646813452243805
step: 220, loss: 0.06447570770978928
step: 230, loss: 0.03845464810729027
step: 240, loss: 0.012539823539555073
step: 250, loss: 0.15152214467525482
step: 260, loss: 0.12040683627128601
step: 270, loss: 0.012779716402292252
step: 280, loss: 0.017177434638142586
step: 290, loss: 0.05400686711072922
step: 300, loss: 0.11042673140764236
step: 310, loss: 0.039666712284088135
step: 320, loss: 0.07550061494112015
step: 330, loss: 0.0011547047179192305
step: 340, loss: 0.05115910619497299
step: 350, loss: 0.10854316502809525
step: 360, loss: 0.08369095623493195
epoch 13: dev_f1=0.7407407407407408, f1=0.6950354609929078, best_f1=0.724233983286908
step: 0, loss: 0.017087824642658234
step: 10, loss: 0.01769149862229824
step: 20, loss: 0.03541635721921921
step: 30, loss: 0.051468368619680405
step: 40, loss: 0.010368713177740574
step: 50, loss: 0.061850130558013916
step: 60, loss: 0.03218384459614754
step: 70, loss: 0.01615201309323311
step: 80, loss: 0.07708806544542313
step: 90, loss: 0.009759088046848774
step: 100, loss: 0.06601440906524658
step: 110, loss: 0.04038449749350548
step: 120, loss: 0.05810948833823204
step: 130, loss: 0.04812389612197876
step: 140, loss: 0.053956713527441025
step: 150, loss: 0.03471902012825012
step: 160, loss: 0.04161386936903
step: 170, loss: 0.09396345913410187
step: 180, loss: 0.10132139176130295
step: 190, loss: 0.05921759456396103
step: 200, loss: 0.06690225005149841
step: 210, loss: 0.055159784853458405
step: 220, loss: 0.03054996021091938
step: 230, loss: 0.03895479440689087
step: 240, loss: 0.02918146178126335
step: 250, loss: 0.08337800949811935
step: 260, loss: 0.04257846623659134
step: 270, loss: 0.0227722879499197
step: 280, loss: 0.00014572542568203062
step: 290, loss: 0.22824017703533173
step: 300, loss: 0.04156659170985222
step: 310, loss: 0.04143054410815239
step: 320, loss: 0.012090802192687988
step: 330, loss: 7.15443748049438e-05
step: 340, loss: 0.035447292029857635
step: 350, loss: 0.03699791058897972
step: 360, loss: 0.05422259122133255
epoch 14: dev_f1=0.7609756097560976, f1=0.7076167076167075, best_f1=0.7076167076167075
step: 0, loss: 0.03706463426351547
step: 10, loss: 0.02221602573990822
step: 20, loss: 0.034136947244405746
step: 30, loss: 0.08306071907281876
step: 40, loss: 0.0521308034658432
step: 50, loss: 0.014599934220314026
step: 60, loss: 0.07886404544115067
step: 70, loss: 0.025909997522830963
step: 80, loss: 0.0567958764731884
step: 90, loss: 0.06089943274855614
step: 100, loss: 0.013867820613086224
step: 110, loss: 0.03128678351640701
step: 120, loss: 0.004710059147328138
step: 130, loss: 0.03793375566601753
step: 140, loss: 0.0013373801484704018
step: 150, loss: 0.09298212826251984
step: 160, loss: 0.0471767783164978
step: 170, loss: 0.014840747229754925
step: 180, loss: 0.03395400568842888
step: 190, loss: 0.03303753212094307
step: 200, loss: 0.12875470519065857
step: 210, loss: 0.0657334253191948
step: 220, loss: 0.0864005833864212
step: 230, loss: 0.0809832364320755
step: 240, loss: 0.07690161466598511
step: 250, loss: 0.004360951017588377
step: 260, loss: 0.037624843418598175
step: 270, loss: 0.02355368062853813
step: 280, loss: 0.092814140021801
step: 290, loss: 0.03585166111588478
step: 300, loss: 0.018122369423508644
step: 310, loss: 0.08432129770517349
step: 320, loss: 0.018031828105449677
step: 330, loss: 0.05179808288812637
step: 340, loss: 0.11054603010416031
step: 350, loss: 0.010382035747170448
step: 360, loss: 0.051139429211616516
epoch 15: dev_f1=0.7219512195121951, f1=0.6962962962962963, best_f1=0.7076167076167075
step: 0, loss: 0.01715065911412239
step: 10, loss: 0.0287155918776989
step: 20, loss: 0.016125261783599854
step: 30, loss: 0.0016971436562016606
step: 40, loss: 0.0902535542845726
step: 50, loss: 0.03381063789129257
step: 60, loss: 0.045218851417303085
step: 70, loss: 0.03126831352710724
step: 80, loss: 0.06716403365135193
step: 90, loss: 0.005856769159436226
step: 100, loss: 4.242651993990876e-05
step: 110, loss: 0.014313647523522377
step: 120, loss: 0.15714327991008759
step: 130, loss: 0.05789370834827423
step: 140, loss: 0.007298266515135765
step: 150, loss: 0.04032614454627037
step: 160, loss: 0.05637185275554657
step: 170, loss: 0.035261355340480804
step: 180, loss: 0.0016523645026609302
step: 190, loss: 0.026410600170493126
step: 200, loss: 0.09914185106754303
step: 210, loss: 0.04436929151415825
step: 220, loss: 0.056651994585990906
step: 230, loss: 0.01713363453745842
step: 240, loss: 0.05464540049433708
step: 250, loss: 0.01127675361931324
step: 260, loss: 0.028334224596619606
step: 270, loss: 0.03066423535346985
step: 280, loss: 0.014203761704266071
step: 290, loss: 0.04363003373146057
step: 300, loss: 0.0463077537715435
step: 310, loss: 0.011188484728336334
step: 320, loss: 0.038365595042705536
step: 330, loss: 0.04250354692339897
step: 340, loss: 0.07264670729637146
step: 350, loss: 0.00930701568722725
step: 360, loss: 0.04568146541714668
epoch 16: dev_f1=0.7346938775510203, f1=0.717557251908397, best_f1=0.7076167076167075
step: 0, loss: 0.01950039155781269
step: 10, loss: 0.09189856797456741
step: 20, loss: 0.02472173422574997
step: 30, loss: 0.035042449831962585
step: 40, loss: 0.022123394533991814
step: 50, loss: 0.02289111539721489
step: 60, loss: 0.024264216423034668
step: 70, loss: 0.01881680265069008
step: 80, loss: 0.028988920152187347
step: 90, loss: 0.017038360238075256
step: 100, loss: 0.09892460703849792
step: 110, loss: 0.058210406452417374
step: 120, loss: 0.033645208925008774
step: 130, loss: 0.05327533930540085
step: 140, loss: 0.07672175019979477
step: 150, loss: 0.0468895398080349
step: 160, loss: 5.809855792904273e-05
step: 170, loss: 0.054476670920848846
step: 180, loss: 0.0835355892777443
step: 190, loss: 0.05476139858365059
step: 200, loss: 0.10004714131355286
step: 210, loss: 0.020081322640180588
step: 220, loss: 0.06339923292398453
step: 230, loss: 0.07331115007400513
step: 240, loss: 0.001168572693131864
step: 250, loss: 0.0008924435824155807
step: 260, loss: 0.052509527653455734
step: 270, loss: 0.05551731958985329
step: 280, loss: 0.026522373780608177
step: 290, loss: 0.1072666198015213
step: 300, loss: 0.011697964742779732
step: 310, loss: 0.08849482238292694
step: 320, loss: 0.09405060857534409
step: 330, loss: 0.009378781542181969
step: 340, loss: 0.06124621257185936
step: 350, loss: 0.025835873559117317
step: 360, loss: 0.05537278577685356
epoch 17: dev_f1=0.7560975609756098, f1=0.6982543640897756, best_f1=0.7076167076167075
step: 0, loss: 0.01890370063483715
step: 10, loss: 0.018671805039048195
step: 20, loss: 0.0038814900908619165
step: 30, loss: 0.007511226925998926
step: 40, loss: 0.0008275112486444414
step: 50, loss: 0.05762948468327522
step: 60, loss: 0.02520626224577427
step: 70, loss: 0.08953982591629028
step: 80, loss: 0.03269477188587189
step: 90, loss: 0.03389216214418411
step: 100, loss: 0.02345479466021061
step: 110, loss: 0.05308615416288376
step: 120, loss: 0.0025526259560137987
step: 130, loss: 0.07135546952486038
step: 140, loss: 0.0059174345806241035
step: 150, loss: 0.010472503490746021
step: 160, loss: 0.08440997451543808
step: 170, loss: 0.03137180209159851
step: 180, loss: 0.014236344955861568
step: 190, loss: 0.0001971880701603368
step: 200, loss: 0.004622165113687515
step: 210, loss: 0.00026954227359965444
step: 220, loss: 0.06539743393659592
step: 230, loss: 0.05799972638487816
step: 240, loss: 0.07519090175628662
step: 250, loss: 2.5610259399400093e-05
step: 260, loss: 0.08548454195261002
step: 270, loss: 0.0043883416801691055
step: 280, loss: 0.03554746136069298
step: 290, loss: 0.1516137719154358
step: 300, loss: 0.010524673387408257
step: 310, loss: 0.1325114667415619
step: 320, loss: 0.019595090299844742
step: 330, loss: 0.028628230094909668
step: 340, loss: 0.000107001636934001
step: 350, loss: 0.039790231734514236
step: 360, loss: 0.02128257229924202
epoch 18: dev_f1=0.741687979539642, f1=0.6940874035989718, best_f1=0.7076167076167075
step: 0, loss: 0.03482915088534355
step: 10, loss: 0.03081156313419342
step: 20, loss: 0.033404942601919174
step: 30, loss: 0.023779669776558876
step: 40, loss: 0.03719770163297653
step: 50, loss: 0.02476721629500389
step: 60, loss: 0.04091489687561989
step: 70, loss: 0.10265946388244629
step: 80, loss: 0.045268356800079346
step: 90, loss: 0.00929386168718338
step: 100, loss: 0.02309359237551689
step: 110, loss: 0.0719151571393013
step: 120, loss: 0.0325491726398468
step: 130, loss: 0.05205423757433891
step: 140, loss: 0.14482009410858154
step: 150, loss: 0.00521126901730895
step: 160, loss: 0.0515575185418129
step: 170, loss: 0.06291379779577255
step: 180, loss: 0.04066013544797897
step: 190, loss: 0.008486602455377579
step: 200, loss: 0.038022976368665695
step: 210, loss: 0.12587620317935944
step: 220, loss: 0.033833105117082596
step: 230, loss: 0.0221836119890213
step: 240, loss: 0.04156482592225075
step: 250, loss: 0.09895510971546173
step: 260, loss: 0.0591602697968483
step: 270, loss: 0.01899472251534462
step: 280, loss: 0.12013059109449387
step: 290, loss: 0.0010820371098816395
step: 300, loss: 0.027973057702183723
step: 310, loss: 0.07088717073202133
step: 320, loss: 0.006562215741723776
step: 330, loss: 0.01780976541340351
step: 340, loss: 0.004101471975445747
step: 350, loss: 0.009564107283949852
step: 360, loss: 0.027514873072504997
epoch 19: dev_f1=0.7384615384615385, f1=0.6876640419947506, best_f1=0.7076167076167075
step: 0, loss: 0.03790394589304924
step: 10, loss: 0.01375469658523798
step: 20, loss: 0.016657887026667595
step: 30, loss: 0.03251195698976517
step: 40, loss: 0.09040336310863495
step: 50, loss: 0.00954260490834713
step: 60, loss: 0.06802330911159515
step: 70, loss: 0.0627942830324173
step: 80, loss: 0.0012203238438814878
step: 90, loss: 0.011475413106381893
step: 100, loss: 0.11578106880187988
step: 110, loss: 0.011360601522028446
step: 120, loss: 0.005416227970272303
step: 130, loss: 0.0005353105370886624
step: 140, loss: 0.07851921766996384
step: 150, loss: 0.08974889665842056
step: 160, loss: 0.019495943561196327
step: 170, loss: 0.0008496857481077313
step: 180, loss: 0.019608179107308388
step: 190, loss: 0.037584636360406876
step: 200, loss: 0.014775529503822327
step: 210, loss: 0.016119586303830147
step: 220, loss: 0.03062497079372406
step: 230, loss: 0.006728924810886383
step: 240, loss: 0.027515508234500885
step: 250, loss: 0.02904674783349037
step: 260, loss: 0.13899649679660797
step: 270, loss: 0.02967091277241707
step: 280, loss: 0.12546519935131073
step: 290, loss: 0.027671776711940765
step: 300, loss: 0.011376476846635342
step: 310, loss: 0.0024681477807462215
step: 320, loss: 0.053114403039216995
step: 330, loss: 0.12856557965278625
step: 340, loss: 0.004051268566399813
step: 350, loss: 0.006787724792957306
step: 360, loss: 0.052102185785770416
epoch 20: dev_f1=0.733509234828496, f1=0.6920980926430518, best_f1=0.7076167076167075
