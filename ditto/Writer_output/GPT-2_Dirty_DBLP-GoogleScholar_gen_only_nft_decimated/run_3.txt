cuda
Device: cuda
step: 0, loss: 0.8000572323799133
step: 10, loss: 0.5735753178596497
step: 20, loss: 0.604974091053009
step: 30, loss: 0.38660117983818054
step: 40, loss: 0.4358157515525818
step: 50, loss: 0.26708006858825684
step: 60, loss: 0.3058079183101654
step: 70, loss: 0.31518226861953735
step: 80, loss: 0.30198752880096436
step: 90, loss: 0.3603977859020233
step: 100, loss: 0.32069146633148193
step: 110, loss: 0.3101296126842499
step: 120, loss: 0.3387444019317627
step: 130, loss: 0.21338288486003876
step: 140, loss: 0.17899906635284424
step: 150, loss: 0.09769246727228165
step: 160, loss: 0.20023062825202942
step: 170, loss: 0.10321883857250214
step: 180, loss: 0.11393199115991592
step: 190, loss: 0.161916121840477
step: 200, loss: 0.1511273831129074
step: 210, loss: 0.2709575593471527
step: 220, loss: 0.08340203762054443
step: 230, loss: 0.13651880621910095
step: 240, loss: 0.07736272364854813
step: 250, loss: 0.05012013390660286
step: 260, loss: 0.03520121052861214
step: 270, loss: 0.10769380629062653
step: 280, loss: 0.14762337505817413
step: 290, loss: 0.0734013170003891
step: 300, loss: 0.18663640320301056
step: 310, loss: 0.11254581809043884
step: 320, loss: 0.10278887301683426
step: 330, loss: 0.14991581439971924
step: 340, loss: 0.0817069262266159
step: 350, loss: 0.058577101677656174
step: 360, loss: 0.10937069356441498
step: 370, loss: 0.04026048630475998
step: 380, loss: 0.03789965808391571
step: 390, loss: 0.1493791788816452
step: 400, loss: 0.10424341261386871
epoch 1: dev_f1=0.5538585209003215, f1=0.5155131264916468, best_f1=0.5155131264916468
step: 0, loss: 0.02453802525997162
step: 10, loss: 0.07717595994472504
step: 20, loss: 0.012642835266888142
step: 30, loss: 0.21613562107086182
step: 40, loss: 0.08761126548051834
step: 50, loss: 0.044086236506700516
step: 60, loss: 0.09821616858243942
step: 70, loss: 0.008624005131423473
step: 80, loss: 0.08913550525903702
step: 90, loss: 0.04867308959364891
step: 100, loss: 0.022860025987029076
step: 110, loss: 0.08638925850391388
step: 120, loss: 0.054777078330516815
step: 130, loss: 0.10421838611364365
step: 140, loss: 0.11615035682916641
step: 150, loss: 0.07734373956918716
step: 160, loss: 0.05535987764596939
step: 170, loss: 0.1230543851852417
step: 180, loss: 0.12904012203216553
step: 190, loss: 0.08020564913749695
step: 200, loss: 0.0250800009816885
step: 210, loss: 0.05613214150071144
step: 220, loss: 0.09065864235162735
step: 230, loss: 0.06122741103172302
step: 240, loss: 0.09565185755491257
step: 250, loss: 0.1451856791973114
step: 260, loss: 0.042769938707351685
step: 270, loss: 0.049519848078489304
step: 280, loss: 0.21402786672115326
step: 290, loss: 0.06775660067796707
step: 300, loss: 0.056866418570280075
step: 310, loss: 0.021237650886178017
step: 320, loss: 0.10708293318748474
step: 330, loss: 0.07129369676113129
step: 340, loss: 0.0018000039272010326
step: 350, loss: 0.08321639895439148
step: 360, loss: 0.11673144996166229
step: 370, loss: 0.08586660027503967
step: 380, loss: 0.003138116793707013
step: 390, loss: 0.10517045110464096
step: 400, loss: 0.12631797790527344
epoch 2: dev_f1=0.542038515735087, f1=0.4966634890371782, best_f1=0.5155131264916468
step: 0, loss: 0.1631467491388321
step: 10, loss: 0.03317178413271904
step: 20, loss: 0.007777381222695112
step: 30, loss: 0.023748891428112984
step: 40, loss: 0.008470078930258751
step: 50, loss: 0.057144951075315475
step: 60, loss: 0.02504359744489193
step: 70, loss: 0.04722778871655464
step: 80, loss: 0.09402628242969513
step: 90, loss: 0.06868626922369003
step: 100, loss: 0.12663814425468445
step: 110, loss: 0.04751782864332199
step: 120, loss: 0.0155006879940629
step: 130, loss: 0.01815979927778244
step: 140, loss: 0.03341720625758171
step: 150, loss: 0.11939429491758347
step: 160, loss: 0.003659910522401333
step: 170, loss: 0.04257044941186905
step: 180, loss: 0.01641661301255226
step: 190, loss: 0.13469943404197693
step: 200, loss: 0.08210267871618271
step: 210, loss: 0.02719816006720066
step: 220, loss: 0.05936424061655998
step: 230, loss: 0.036985233426094055
step: 240, loss: 0.09091074764728546
step: 250, loss: 0.06592600047588348
step: 260, loss: 0.0486297532916069
step: 270, loss: 0.023754427209496498
step: 280, loss: 0.025381391867995262
step: 290, loss: 0.05374910309910774
step: 300, loss: 0.10693567991256714
step: 310, loss: 0.02492634952068329
step: 320, loss: 0.08421823382377625
step: 330, loss: 0.030278552323579788
step: 340, loss: 0.13706664741039276
step: 350, loss: 0.02718188427388668
step: 360, loss: 0.03658071905374527
step: 370, loss: 0.08304113894701004
step: 380, loss: 0.015447196550667286
step: 390, loss: 0.1252586394548416
step: 400, loss: 0.05361742153763771
epoch 3: dev_f1=0.5012456402590931, f1=0.4539007092198582, best_f1=0.5155131264916468
step: 0, loss: 0.017315108329057693
step: 10, loss: 0.052562274038791656
step: 20, loss: 0.04204593971371651
step: 30, loss: 0.015635721385478973
step: 40, loss: 0.045082639902830124
step: 50, loss: 0.05321662127971649
step: 60, loss: 0.07983339577913284
step: 70, loss: 0.026126446202397346
step: 80, loss: 0.034986600279808044
step: 90, loss: 0.02441224455833435
step: 100, loss: 0.07245425134897232
step: 110, loss: 0.007453290279954672
step: 120, loss: 0.02358664944767952
step: 130, loss: 0.08675553649663925
step: 140, loss: 0.062331732362508774
step: 150, loss: 0.061849892139434814
step: 160, loss: 0.036949727684259415
step: 170, loss: 0.23351705074310303
step: 180, loss: 0.11628830432891846
step: 190, loss: 0.11902868002653122
step: 200, loss: 0.062451377511024475
step: 210, loss: 0.11879086494445801
step: 220, loss: 0.014499478042125702
step: 230, loss: 0.0014762573409825563
step: 240, loss: 0.03199651837348938
step: 250, loss: 0.028489205986261368
step: 260, loss: 0.024609386920928955
step: 270, loss: 0.17171993851661682
step: 280, loss: 0.015278629958629608
step: 290, loss: 0.07339359074831009
step: 300, loss: 0.12811094522476196
step: 310, loss: 0.08758919686079025
step: 320, loss: 0.021266059949994087
step: 330, loss: 0.11834198236465454
step: 340, loss: 0.0353124737739563
step: 350, loss: 0.03481585532426834
step: 360, loss: 0.009432021528482437
step: 370, loss: 0.1893184930086136
step: 380, loss: 0.03202398493885994
step: 390, loss: 0.04138144850730896
step: 400, loss: 0.12906765937805176
epoch 4: dev_f1=0.4541307653319817, f1=0.4298780487804878, best_f1=0.5155131264916468
step: 0, loss: 0.016348250210285187
step: 10, loss: 0.02943091094493866
step: 20, loss: 0.07081911712884903
step: 30, loss: 0.04470530524849892
step: 40, loss: 0.06972596049308777
step: 50, loss: 0.00482608238235116
step: 60, loss: 0.0013761591399088502
step: 70, loss: 0.07839196175336838
step: 80, loss: 0.001891862484626472
step: 90, loss: 0.004650430288165808
step: 100, loss: 0.024500669911503792
step: 110, loss: 0.01741793565452099
step: 120, loss: 0.03765690326690674
step: 130, loss: 0.03841087222099304
step: 140, loss: 0.07284898310899734
step: 150, loss: 0.04040175676345825
step: 160, loss: 0.08064944297075272
step: 170, loss: 0.0030498781707137823
step: 180, loss: 0.12708181142807007
step: 190, loss: 0.046446025371551514
step: 200, loss: 0.011330396868288517
step: 210, loss: 0.029314367100596428
step: 220, loss: 0.03114018589258194
step: 230, loss: 0.07581105083227158
step: 240, loss: 0.09371784329414368
step: 250, loss: 0.11575965583324432
step: 260, loss: 0.02588619291782379
step: 270, loss: 0.05949629470705986
step: 280, loss: 0.014093504287302494
step: 290, loss: 0.006499400828033686
step: 300, loss: 0.006325687747448683
step: 310, loss: 0.0562870167195797
step: 320, loss: 0.009646383114159107
step: 330, loss: 0.011189432814717293
step: 340, loss: 0.06664812564849854
step: 350, loss: 0.014945696108043194
step: 360, loss: 0.07539048790931702
step: 370, loss: 0.008917758241295815
step: 380, loss: 0.07290251553058624
step: 390, loss: 0.005936457309871912
step: 400, loss: 0.04861302301287651
epoch 5: dev_f1=0.44256756756756754, f1=0.3921113689095128, best_f1=0.5155131264916468
step: 0, loss: 0.017208388075232506
step: 10, loss: 0.036894261837005615
step: 20, loss: 0.023866137489676476
step: 30, loss: 0.00930557120591402
step: 40, loss: 0.01445604208856821
step: 50, loss: 0.010244229808449745
step: 60, loss: 0.030487913638353348
step: 70, loss: 0.007659682538360357
step: 80, loss: 0.04178254306316376
step: 90, loss: 0.005364635493606329
step: 100, loss: 0.09918688237667084
step: 110, loss: 0.05612698569893837
step: 120, loss: 0.09469856321811676
step: 130, loss: 0.12254693359136581
step: 140, loss: 0.020852113142609596
step: 150, loss: 0.01981535367667675
step: 160, loss: 0.0037751486524939537
step: 170, loss: 0.01973838359117508
step: 180, loss: 0.07034135609865189
step: 190, loss: 0.10344932973384857
step: 200, loss: 0.025501945987343788
step: 210, loss: 0.03300066664814949
step: 220, loss: 0.020529866218566895
step: 230, loss: 0.06174222752451897
step: 240, loss: 0.005961236078292131
step: 250, loss: 0.0046410332433879375
step: 260, loss: 0.014025779440999031
step: 270, loss: 0.030836008489131927
step: 280, loss: 0.0047058165073394775
step: 290, loss: 0.0400693342089653
step: 300, loss: 0.05764540284872055
step: 310, loss: 0.003294662106782198
step: 320, loss: 0.056826427578926086
step: 330, loss: 0.009825002402067184
step: 340, loss: 0.10041763633489609
step: 350, loss: 5.922087075305171e-05
step: 360, loss: 0.03410467132925987
step: 370, loss: 0.007330321706831455
step: 380, loss: 0.0007821301696822047
step: 390, loss: 0.016910701990127563
step: 400, loss: 0.02020450495183468
epoch 6: dev_f1=0.48478260869565215, f1=0.4473829201101928, best_f1=0.5155131264916468
step: 0, loss: 0.06786090135574341
step: 10, loss: 0.11599893122911453
step: 20, loss: 0.012011682614684105
step: 30, loss: 0.035309575498104095
step: 40, loss: 0.14277435839176178
step: 50, loss: 0.008640465326607227
step: 60, loss: 0.04300661012530327
step: 70, loss: 0.00011604178143898025
step: 80, loss: 0.010438037104904652
step: 90, loss: 0.016177870333194733
step: 100, loss: 0.0003258905780967325
step: 110, loss: 0.017393270507454872
step: 120, loss: 0.01326748076826334
step: 130, loss: 0.0784599706530571
step: 140, loss: 0.007736053317785263
step: 150, loss: 0.012322084978222847
step: 160, loss: 0.002910824492573738
step: 170, loss: 0.006704819854348898
step: 180, loss: 0.01722201518714428
step: 190, loss: 0.01321993675082922
step: 200, loss: 0.040774863213300705
step: 210, loss: 0.0017170554492622614
step: 220, loss: 0.046834561973810196
step: 230, loss: 0.0019139554351568222
step: 240, loss: 0.004659967962652445
step: 250, loss: 0.0052460962906479836
step: 260, loss: 0.08769271522760391
step: 270, loss: 0.03875571861863136
step: 280, loss: 0.0038246489129960537
step: 290, loss: 0.07038585096597672
step: 300, loss: 0.033743664622306824
step: 310, loss: 0.06292466074228287
step: 320, loss: 0.012259571813046932
step: 330, loss: 0.000906855973880738
step: 340, loss: 0.06512158364057541
step: 350, loss: 0.006170934997498989
step: 360, loss: 0.01607692800462246
step: 370, loss: 0.001553197274915874
step: 380, loss: 0.09425061196088791
step: 390, loss: 0.022720709443092346
step: 400, loss: 0.02574417181313038
epoch 7: dev_f1=0.5298142717497557, f1=0.49455984174085066, best_f1=0.5155131264916468
step: 0, loss: 0.02899739146232605
step: 10, loss: 0.03518303111195564
step: 20, loss: 0.023735251277685165
step: 30, loss: 0.02872536890208721
step: 40, loss: 0.010931749828159809
step: 50, loss: 0.11589298397302628
step: 60, loss: 0.014388347044587135
step: 70, loss: 0.007204460445791483
step: 80, loss: 0.04187775403261185
step: 90, loss: 0.002791581442579627
step: 100, loss: 0.04576689749956131
step: 110, loss: 0.009239133447408676
step: 120, loss: 0.002632490359246731
step: 130, loss: 0.04383482784032822
step: 140, loss: 0.027549980208277702
step: 150, loss: 0.001139552565291524
step: 160, loss: 0.006872942205518484
step: 170, loss: 0.013482930138707161
step: 180, loss: 0.046211790293455124
step: 190, loss: 0.0016590849263593554
step: 200, loss: 0.0016607122961431742
step: 210, loss: 0.014868669211864471
step: 220, loss: 0.001179609796963632
step: 230, loss: 0.03015744313597679
step: 240, loss: 0.03088826686143875
step: 250, loss: 0.06616510450839996
step: 260, loss: 0.05232711136341095
step: 270, loss: 0.0247531458735466
step: 280, loss: 0.05466945469379425
step: 290, loss: 0.043620817363262177
step: 300, loss: 0.11973241716623306
step: 310, loss: 0.01323769148439169
step: 320, loss: 0.06913990527391434
step: 330, loss: 0.04589986801147461
step: 340, loss: 0.037649642676115036
step: 350, loss: 0.028550419956445694
step: 360, loss: 0.01749209500849247
step: 370, loss: 0.02072492428123951
step: 380, loss: 0.0037627185229212046
step: 390, loss: 0.00878119096159935
step: 400, loss: 0.0011642671888694167
epoch 8: dev_f1=0.5157292659675882, f1=0.4675324675324675, best_f1=0.5155131264916468
step: 0, loss: 0.028658481314778328
step: 10, loss: 0.038897592574357986
step: 20, loss: 0.0039362721145153046
step: 30, loss: 0.004028660710901022
step: 40, loss: 0.015394022688269615
step: 50, loss: 0.008772028610110283
step: 60, loss: 0.17566335201263428
step: 70, loss: 0.0026933096814900637
step: 80, loss: 0.037440478801727295
step: 90, loss: 0.000773988023865968
step: 100, loss: 0.0005946506280452013
step: 110, loss: 0.020064963027834892
step: 120, loss: 0.002983660902827978
step: 130, loss: 0.018281282857060432
step: 140, loss: 0.0437493734061718
step: 150, loss: 0.04962076246738434
step: 160, loss: 0.0017456287750974298
step: 170, loss: 0.0016441490733996034
step: 180, loss: 0.07700955122709274
step: 190, loss: 0.002091911854222417
step: 200, loss: 0.05248258635401726
step: 210, loss: 0.027723899111151695
step: 220, loss: 0.017565591260790825
step: 230, loss: 0.004819489549845457
step: 240, loss: 0.01374689768999815
step: 250, loss: 0.00021302078675944358
step: 260, loss: 0.00016226893058046699
step: 270, loss: 0.0014021737733855844
step: 280, loss: 0.0001041531068040058
step: 290, loss: 0.00255460012704134
step: 300, loss: 0.00331666087731719
step: 310, loss: 0.057734280824661255
step: 320, loss: 0.0007783048786222935
step: 330, loss: 0.00014379844651557505
step: 340, loss: 0.004036587197333574
step: 350, loss: 0.02326526865363121
step: 360, loss: 0.01688997447490692
step: 370, loss: 0.017226262018084526
step: 380, loss: 0.021565038710832596
step: 390, loss: 0.005744303576648235
step: 400, loss: 0.001702244975604117
epoch 9: dev_f1=0.453074433656958, f1=0.39144736842105265, best_f1=0.5155131264916468
step: 0, loss: 0.020213760435581207
step: 10, loss: 0.0008177140261977911
step: 20, loss: 0.018217245116829872
step: 30, loss: 0.0031158621422946453
step: 40, loss: 0.1174057349562645
step: 50, loss: 0.011500281281769276
step: 60, loss: 0.02212938293814659
step: 70, loss: 0.02981879934668541
step: 80, loss: 0.01829451695084572
step: 90, loss: 0.012425047345459461
step: 100, loss: 0.004403568804264069
step: 110, loss: 0.02900123968720436
step: 120, loss: 0.0009538762969896197
step: 130, loss: 0.00029443294624798
step: 140, loss: 0.006756240036338568
step: 150, loss: 0.0017486396245658398
step: 160, loss: 0.0009657608461566269
step: 170, loss: 0.019120940938591957
step: 180, loss: 0.00016354952822439373
step: 190, loss: 0.0009596861782483757
step: 200, loss: 0.05916569009423256
step: 210, loss: 0.004944528918713331
step: 220, loss: 0.0005596863338723779
step: 230, loss: 0.00036672159330919385
step: 240, loss: 0.0011887613218277693
step: 250, loss: 0.004780864343047142
step: 260, loss: 0.028751105070114136
step: 270, loss: 0.019275696948170662
step: 280, loss: 0.0022291766945272684
step: 290, loss: 0.018741222098469734
step: 300, loss: 0.038262687623500824
step: 310, loss: 0.0005422356771305203
step: 320, loss: 0.0010938940104097128
step: 330, loss: 0.001428489456884563
step: 340, loss: 0.00781308300793171
step: 350, loss: 0.0006306911236606538
step: 360, loss: 0.00583324208855629
step: 370, loss: 0.0017908274894580245
step: 380, loss: 0.01587022840976715
step: 390, loss: 0.007284295279532671
step: 400, loss: 0.01653030514717102
epoch 10: dev_f1=0.45807540799099605, f1=0.42390078917700114, best_f1=0.5155131264916468
step: 0, loss: 0.003561838995665312
step: 10, loss: 0.0055433656089007854
step: 20, loss: 0.003272696165367961
step: 30, loss: 0.0008776297909207642
step: 40, loss: 0.00017575194942764938
step: 50, loss: 0.009597008116543293
step: 60, loss: 0.035330139100551605
step: 70, loss: 0.0002418219082755968
step: 80, loss: 0.033696770668029785
step: 90, loss: 0.0015191101701930165
step: 100, loss: 0.001775008742697537
step: 110, loss: 2.9406342946458608e-05
step: 120, loss: 0.0924934521317482
step: 130, loss: 0.001335487817414105
step: 140, loss: 6.46474800305441e-05
step: 150, loss: 5.042543853051029e-05
step: 160, loss: 0.005505776964128017
step: 170, loss: 0.049291063100099564
step: 180, loss: 0.0005773510201834142
step: 190, loss: 0.11625704169273376
step: 200, loss: 0.0004216294619254768
step: 210, loss: 0.005865888204425573
step: 220, loss: 7.403987547149882e-05
step: 230, loss: 0.0007358512957580388
step: 240, loss: 0.004709235392510891
step: 250, loss: 8.993757364805788e-05
step: 260, loss: 0.0005200498853810132
step: 270, loss: 0.007296936586499214
step: 280, loss: 0.013583701103925705
step: 290, loss: 0.0003670860023703426
step: 300, loss: 0.11992119997739792
step: 310, loss: 0.0042910026386380196
step: 320, loss: 3.3163651096401736e-05
step: 330, loss: 0.041644349694252014
step: 340, loss: 0.000703697616700083
step: 350, loss: 0.006767741870135069
step: 360, loss: 0.002419663593173027
step: 370, loss: 0.008160019293427467
step: 380, loss: 0.015179088339209557
step: 390, loss: 0.0002460297546349466
step: 400, loss: 0.000508143741171807
epoch 11: dev_f1=0.4453081621321488, f1=0.40135287485907556, best_f1=0.5155131264916468
step: 0, loss: 0.003842114470899105
step: 10, loss: 0.00035450837458483875
step: 20, loss: 4.719795470009558e-05
step: 30, loss: 0.01126271765679121
step: 40, loss: 0.0031750609632581472
step: 50, loss: 5.199094448471442e-05
step: 60, loss: 0.053507596254348755
step: 70, loss: 0.00010106118861585855
step: 80, loss: 0.0024481951259076595
step: 90, loss: 0.0003560233162716031
step: 100, loss: 0.0035759112797677517
step: 110, loss: 0.0003790752380155027
step: 120, loss: 0.00011976130190305412
step: 130, loss: 3.609220584621653e-05
step: 140, loss: 0.0018654661253094673
step: 150, loss: 0.003924540709704161
step: 160, loss: 0.027257272973656654
step: 170, loss: 0.0004229399492032826
step: 180, loss: 0.013825482688844204
step: 190, loss: 0.10075809806585312
step: 200, loss: 0.0009404753800481558
step: 210, loss: 0.003501924453303218
step: 220, loss: 0.0001623123825993389
step: 230, loss: 0.028772497549653053
step: 240, loss: 0.009913724847137928
step: 250, loss: 0.0013204445131123066
step: 260, loss: 0.004118004813790321
step: 270, loss: 0.08060012012720108
step: 280, loss: 0.03158682957291603
step: 290, loss: 0.0007094122120179236
step: 300, loss: 0.0001328382350038737
step: 310, loss: 0.0002328390401089564
step: 320, loss: 0.09701906889677048
step: 330, loss: 0.12324921041727066
step: 340, loss: 0.053266748785972595
step: 350, loss: 0.0007770056836307049
step: 360, loss: 0.00937679037451744
step: 370, loss: 0.0009709959267638624
step: 380, loss: 0.0036028940230607986
step: 390, loss: 0.08643501251935959
step: 400, loss: 0.0038665528409183025
epoch 12: dev_f1=0.48592283628779975, f1=0.4436130411544629, best_f1=0.5155131264916468
step: 0, loss: 0.015900561586022377
step: 10, loss: 0.0007326794438995421
step: 20, loss: 0.036517102271318436
step: 30, loss: 0.002644777065142989
step: 40, loss: 0.0011857699137181044
step: 50, loss: 0.01396991778165102
step: 60, loss: 0.005052958615124226
step: 70, loss: 0.1796298623085022
step: 80, loss: 0.01181002613157034
step: 90, loss: 0.011212579905986786
step: 100, loss: 0.005265887826681137
step: 110, loss: 0.0034801848232746124
step: 120, loss: 0.06417398899793625
step: 130, loss: 0.0005112814251333475
step: 140, loss: 0.000267254828941077
step: 150, loss: 0.0008255189750343561
step: 160, loss: 0.007324320264160633
step: 170, loss: 0.003611008869484067
step: 180, loss: 6.924058106960729e-05
step: 190, loss: 0.004775669891387224
step: 200, loss: 0.056536588817834854
step: 210, loss: 5.86061978538055e-05
step: 220, loss: 0.020654955878853798
step: 230, loss: 0.00024097118875943124
step: 240, loss: 0.007711544632911682
step: 250, loss: 0.00010392660624347627
step: 260, loss: 0.0010054344311356544
step: 270, loss: 9.330048487754539e-05
step: 280, loss: 0.015236525796353817
step: 290, loss: 2.8828208087361418e-05
step: 300, loss: 0.0003557135642040521
step: 310, loss: 0.01831917092204094
step: 320, loss: 0.0010379388695582747
step: 330, loss: 0.0056771887466311455
step: 340, loss: 0.00018138709128834307
step: 350, loss: 0.0078081064857542515
step: 360, loss: 0.0034248994197696447
step: 370, loss: 3.3992535463767126e-05
step: 380, loss: 0.0009586748201400042
step: 390, loss: 2.3945136490510777e-05
step: 400, loss: 0.003377990797162056
epoch 13: dev_f1=0.41874619598295804, f1=0.371007371007371, best_f1=0.5155131264916468
step: 0, loss: 1.53553337440826e-05
step: 10, loss: 0.0017849324503913522
step: 20, loss: 0.0005329601699486375
step: 30, loss: 0.002233766717836261
step: 40, loss: 0.047784462571144104
step: 50, loss: 0.001645100535824895
step: 60, loss: 0.007988542318344116
step: 70, loss: 0.00430436572059989
step: 80, loss: 6.204081000760198e-05
step: 90, loss: 0.0001694540260359645
step: 100, loss: 2.4798095182632096e-05
step: 110, loss: 0.00031876255525276065
step: 120, loss: 0.020959364250302315
step: 130, loss: 2.3360644263448194e-05
step: 140, loss: 0.0009507471695542336
step: 150, loss: 0.00989138800650835
step: 160, loss: 2.341153049201239e-05
step: 170, loss: 2.2038118913769722e-05
step: 180, loss: 0.00020356732420623302
step: 190, loss: 9.645926184020936e-05
step: 200, loss: 0.0003397176042199135
step: 210, loss: 0.0009189479169435799
step: 220, loss: 5.694608262274414e-05
step: 230, loss: 0.004719638731330633
step: 240, loss: 1.9441742551862262e-05
step: 250, loss: 4.1024650272447616e-05
step: 260, loss: 2.4273027520393953e-05
step: 270, loss: 0.0002389767614658922
step: 280, loss: 5.8955185522791e-05
step: 290, loss: 0.02315238118171692
step: 300, loss: 0.022224053740501404
step: 310, loss: 0.0007205785950645804
step: 320, loss: 0.0013205877039581537
step: 330, loss: 5.046516525908373e-05
step: 340, loss: 0.0024449715856462717
step: 350, loss: 0.000713854911737144
step: 360, loss: 0.013338249176740646
step: 370, loss: 0.00893846619874239
step: 380, loss: 0.023509975522756577
step: 390, loss: 0.020636506378650665
step: 400, loss: 0.0015807650052011013
epoch 14: dev_f1=0.39713541666666663, f1=0.33819628647214856, best_f1=0.5155131264916468
step: 0, loss: 6.622725777560845e-05
step: 10, loss: 0.00023107437300495803
step: 20, loss: 0.00010824568016687408
step: 30, loss: 0.021554676815867424
step: 40, loss: 0.028153840452432632
step: 50, loss: 0.01892968825995922
step: 60, loss: 0.0019325268222019076
step: 70, loss: 9.978301386581734e-05
step: 80, loss: 0.0020892354659736156
step: 90, loss: 0.000859406660310924
step: 100, loss: 0.0001243969745701179
step: 110, loss: 0.00029860285576432943
step: 120, loss: 8.777369657764211e-05
step: 130, loss: 0.00014871032908558846
step: 140, loss: 0.011731946840882301
step: 150, loss: 0.0020460993982851505
step: 160, loss: 0.0016413459088653326
step: 170, loss: 1.9035598597838543e-05
step: 180, loss: 4.921676008962095e-05
step: 190, loss: 0.0229419507086277
step: 200, loss: 3.480920713627711e-05
step: 210, loss: 0.00029064042610116303
step: 220, loss: 0.0015139528550207615
step: 230, loss: 6.712276808684692e-05
step: 240, loss: 0.0003405669704079628
step: 250, loss: 0.00512970145791769
step: 260, loss: 0.00982713233679533
step: 270, loss: 0.00024801332619972527
step: 280, loss: 1.2438633348210715e-05
step: 290, loss: 0.00039567064959555864
step: 300, loss: 9.250345465261489e-05
step: 310, loss: 0.271543025970459
step: 320, loss: 0.00016490533016622066
step: 330, loss: 0.0004048036353196949
step: 340, loss: 0.04662279039621353
step: 350, loss: 0.00038326819776557386
step: 360, loss: 0.0002461198891978711
step: 370, loss: 1.553056063130498e-05
step: 380, loss: 4.565999552141875e-05
step: 390, loss: 6.275646592257544e-05
step: 400, loss: 0.00013835504068993032
epoch 15: dev_f1=0.4456824512534819, f1=0.41826381059751966, best_f1=0.5155131264916468
step: 0, loss: 0.002317660255357623
step: 10, loss: 0.002355559729039669
step: 20, loss: 0.006662148516625166
step: 30, loss: 0.009209992364048958
step: 40, loss: 2.6377369067631662e-05
step: 50, loss: 4.0901239117374644e-05
step: 60, loss: 0.00017096841474995017
step: 70, loss: 4.595489735947922e-05
step: 80, loss: 0.00048414902994409204
step: 90, loss: 0.0001131593162426725
step: 100, loss: 0.0010992060415446758
step: 110, loss: 2.965717067127116e-05
step: 120, loss: 2.9579809051938355e-05
step: 130, loss: 2.1643170839524828e-05
step: 140, loss: 0.002370288595557213
step: 150, loss: 2.612339631014038e-05
step: 160, loss: 1.988875555980485e-05
step: 170, loss: 6.224997923709452e-05
step: 180, loss: 0.009955419227480888
step: 190, loss: 0.00011251032265136018
step: 200, loss: 0.029551228508353233
step: 210, loss: 0.0005231122486293316
step: 220, loss: 0.0011059133103117347
step: 230, loss: 0.0001488062844146043
step: 240, loss: 0.00030391375184990466
step: 250, loss: 0.004436167422682047
step: 260, loss: 0.004179324954748154
step: 270, loss: 2.5121185899479315e-05
step: 280, loss: 2.9158993129385635e-05
step: 290, loss: 0.026152396574616432
step: 300, loss: 3.2414638553746045e-05
step: 310, loss: 1.1905919564014766e-05
step: 320, loss: 9.651967411627993e-05
step: 330, loss: 1.5076025192684028e-05
step: 340, loss: 2.9439126592478715e-05
step: 350, loss: 0.03998101130127907
step: 360, loss: 0.0064541432075202465
step: 370, loss: 0.006917599122971296
step: 380, loss: 0.0009955429704859853
step: 390, loss: 0.0030750147998332977
step: 400, loss: 0.01645543985068798
epoch 16: dev_f1=0.44431349440188567, f1=0.3987987987987988, best_f1=0.5155131264916468
step: 0, loss: 6.312724144663662e-05
step: 10, loss: 0.0030370308086276054
step: 20, loss: 0.00020194391254335642
step: 30, loss: 0.0009461628505960107
step: 40, loss: 0.00013869607937522233
step: 50, loss: 0.0006909026997163892
step: 60, loss: 2.5166402338072658e-05
step: 70, loss: 6.661612133029848e-05
step: 80, loss: 0.0026171698700636625
step: 90, loss: 0.005754613783210516
step: 100, loss: 1.4655089216830675e-05
step: 110, loss: 0.0006496293935924768
step: 120, loss: 0.013542836531996727
step: 130, loss: 0.00028272593044675887
step: 140, loss: 2.9059292501187883e-05
step: 150, loss: 0.002687557600438595
step: 160, loss: 0.0005313747096806765
step: 170, loss: 0.0005087138270027936
step: 180, loss: 6.250866135815158e-05
step: 190, loss: 0.006061881314963102
step: 200, loss: 0.0009968733647838235
step: 210, loss: 0.0026996817905455828
step: 220, loss: 1.3716228750126902e-05
step: 230, loss: 0.0009679790236987174
step: 240, loss: 0.000253352802246809
step: 250, loss: 0.0003070515231229365
step: 260, loss: 0.0004168780578766018
step: 270, loss: 2.982764817716088e-05
step: 280, loss: 4.6551107516279444e-05
step: 290, loss: 0.0012017005356028676
step: 300, loss: 0.0001334215048700571
step: 310, loss: 0.0020980637054890394
step: 320, loss: 0.0005182703025639057
step: 330, loss: 0.00019218619854655117
step: 340, loss: 0.0011524277506396174
step: 350, loss: 0.0032138333190232515
step: 360, loss: 0.0006440143915824592
step: 370, loss: 1.2758959201164544e-05
step: 380, loss: 0.0002668871602509171
step: 390, loss: 6.667208799626678e-05
step: 400, loss: 3.6266301322029904e-05
epoch 17: dev_f1=0.4682274247491638, f1=0.427765237020316, best_f1=0.5155131264916468
step: 0, loss: 0.0016165324486792088
step: 10, loss: 4.277679181541316e-05
step: 20, loss: 1.4804003512836061e-05
step: 30, loss: 0.002081804210320115
step: 40, loss: 2.513311119400896e-05
step: 50, loss: 0.01856885477900505
step: 60, loss: 0.0003615027235355228
step: 70, loss: 4.1494065953884274e-05
step: 80, loss: 0.0018052111845463514
step: 90, loss: 1.5474442989216186e-05
step: 100, loss: 0.007860500365495682
step: 110, loss: 1.4964234651415609e-05
step: 120, loss: 5.7888872106559575e-05
step: 130, loss: 3.399315755814314e-05
step: 140, loss: 0.000285738380625844
step: 150, loss: 0.0002709092223085463
step: 160, loss: 6.498761649709195e-05
step: 170, loss: 7.459336484316736e-05
step: 180, loss: 9.354126632388216e-06
step: 190, loss: 2.7333635443937965e-05
step: 200, loss: 0.000654965580906719
step: 210, loss: 1.2669545867538545e-05
step: 220, loss: 0.00016216543735936284
step: 230, loss: 3.524084604578093e-05
step: 240, loss: 1.6741067156544887e-05
step: 250, loss: 0.00032279553124681115
step: 260, loss: 0.0008574209059588611
step: 270, loss: 3.1097151804715395e-05
step: 280, loss: 0.0005602329038083553
step: 290, loss: 3.9566151826875284e-05
step: 300, loss: 0.0007973372703418136
step: 310, loss: 0.010675876401364803
step: 320, loss: 2.111037065333221e-05
step: 330, loss: 6.847042823210359e-05
step: 340, loss: 0.0008704639039933681
step: 350, loss: 0.005569583270698786
step: 360, loss: 1.674120721872896e-05
step: 370, loss: 1.8506461856304668e-05
step: 380, loss: 1.8227357941213995e-05
step: 390, loss: 0.010735106654465199
step: 400, loss: 0.0020560133270919323
epoch 18: dev_f1=0.4231003039513678, f1=0.3711980136561142, best_f1=0.5155131264916468
step: 0, loss: 5.750943091697991e-05
step: 10, loss: 2.270482582389377e-05
step: 20, loss: 7.524894317612052e-05
step: 30, loss: 4.90759703097865e-05
step: 40, loss: 6.650001159869134e-05
step: 50, loss: 1.4375626051332802e-05
step: 60, loss: 2.6351084670750424e-05
step: 70, loss: 0.0002702582278288901
step: 80, loss: 0.07040874660015106
step: 90, loss: 6.386730819940567e-05
step: 100, loss: 2.8983569791307673e-05
step: 110, loss: 0.0004776945570483804
step: 120, loss: 1.2613670151040424e-05
step: 130, loss: 0.0010526698315516114
step: 140, loss: 0.000204643263714388
step: 150, loss: 3.903443575836718e-05
step: 160, loss: 2.8814523830078542e-05
step: 170, loss: 0.0015192576684057713
step: 180, loss: 0.0010617964435368776
step: 190, loss: 2.8246682632016018e-05
step: 200, loss: 8.076035010162741e-05
step: 210, loss: 4.1152507037622854e-05
step: 220, loss: 1.1660039490379859e-05
step: 230, loss: 3.871599255944602e-05
step: 240, loss: 8.196922863135114e-05
step: 250, loss: 7.04066624166444e-05
step: 260, loss: 0.000786523858550936
step: 270, loss: 0.00021744582045357674
step: 280, loss: 0.000272350967861712
step: 290, loss: 0.0001672286307439208
step: 300, loss: 0.0003221615043003112
step: 310, loss: 3.643015952548012e-05
step: 320, loss: 2.608235263323877e-05
step: 330, loss: 3.37094024871476e-05
step: 340, loss: 5.6811695685610175e-05
step: 350, loss: 3.106355870841071e-05
step: 360, loss: 1.0948529052257072e-05
step: 370, loss: 0.00018838784308172762
step: 380, loss: 0.0005890876636840403
step: 390, loss: 7.834644202375785e-05
step: 400, loss: 1.9761568182730116e-05
epoch 19: dev_f1=0.43861740166865315, f1=0.3975975975975976, best_f1=0.5155131264916468
step: 0, loss: 0.004674934316426516
step: 10, loss: 8.396815974265337e-05
step: 20, loss: 0.000787585973739624
step: 30, loss: 0.003030954161658883
step: 40, loss: 9.912910172715783e-06
step: 50, loss: 6.235919863684103e-05
step: 60, loss: 0.0007429645047523081
step: 70, loss: 0.00010823257616721094
step: 80, loss: 0.00016217937809415162
step: 90, loss: 0.0001542249956401065
step: 100, loss: 0.00030374154448509216
step: 110, loss: 3.5099244996672496e-05
step: 120, loss: 0.0002511596539989114
step: 130, loss: 9.283357940148562e-06
step: 140, loss: 0.00016274029621854424
step: 150, loss: 0.00024407210003118962
step: 160, loss: 5.517634053830989e-05
step: 170, loss: 0.00021142233163118362
step: 180, loss: 0.00025095458840951324
step: 190, loss: 3.196223042323254e-05
step: 200, loss: 1.5191434613370802e-05
step: 210, loss: 2.5977875338867307e-05
step: 220, loss: 0.0002226205397164449
step: 230, loss: 7.20786047168076e-05
step: 240, loss: 0.009968302212655544
step: 250, loss: 5.152409357833676e-05
step: 260, loss: 0.0011315556475892663
step: 270, loss: 0.0011614753166213632
step: 280, loss: 3.969858880736865e-05
step: 290, loss: 1.7333230061922222e-05
step: 300, loss: 0.0001604682911420241
step: 310, loss: 0.0012330536264926195
step: 320, loss: 0.06088956445455551
step: 330, loss: 0.00039208121597766876
step: 340, loss: 1.4934404134692159e-05
step: 350, loss: 5.8345034631202e-05
step: 360, loss: 0.0010518257040530443
step: 370, loss: 5.7425786508247256e-05
step: 380, loss: 0.0010772129753604531
step: 390, loss: 2.1236584871076047e-05
step: 400, loss: 4.152055407757871e-05
epoch 20: dev_f1=0.43047158403869407, f1=0.3832923832923833, best_f1=0.5155131264916468
