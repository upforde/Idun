cuda
Device: cuda
step: 0, loss: 0.6340528726577759
step: 10, loss: 0.45522671937942505
step: 20, loss: 0.4678484797477722
step: 30, loss: 0.48438239097595215
step: 40, loss: 0.48390233516693115
step: 50, loss: 0.3972027003765106
step: 60, loss: 0.5182059407234192
step: 70, loss: 0.553490400314331
step: 80, loss: 0.3072364926338196
step: 90, loss: 0.3088531196117401
step: 100, loss: 0.3220362961292267
step: 110, loss: 0.5004530549049377
step: 120, loss: 0.44132915139198303
step: 130, loss: 0.4423176944255829
step: 140, loss: 0.2954500913619995
step: 150, loss: 0.299129456281662
step: 160, loss: 0.2662089765071869
step: 170, loss: 0.3803483843803406
step: 180, loss: 0.20010115206241608
step: 190, loss: 0.27022457122802734
step: 200, loss: 0.4478609561920166
step: 210, loss: 0.29119056463241577
step: 220, loss: 0.25623413920402527
step: 230, loss: 0.20622146129608154
step: 240, loss: 0.9759951829910278
step: 250, loss: 0.2749076187610626
step: 260, loss: 0.23892322182655334
step: 270, loss: 0.33787646889686584
step: 280, loss: 0.12361913174390793
step: 290, loss: 0.21094049513339996
step: 300, loss: 0.31583714485168457
step: 310, loss: 0.20346513390541077
step: 320, loss: 0.2234513908624649
step: 330, loss: 0.3121664226055145
step: 340, loss: 0.41665902733802795
step: 350, loss: 0.2379225194454193
step: 360, loss: 0.36151018738746643
step: 370, loss: 0.25396037101745605
step: 380, loss: 0.27693331241607666
step: 390, loss: 0.2720404267311096
step: 400, loss: 0.14888280630111694
step: 410, loss: 0.2976667284965515
step: 420, loss: 0.224043607711792
step: 430, loss: 0.20571038126945496
step: 440, loss: 0.26375702023506165
step: 450, loss: 0.26248109340667725
step: 460, loss: 0.3448224365711212
step: 470, loss: 0.22585313022136688
step: 480, loss: 0.35305219888687134
step: 490, loss: 0.31031665205955505
step: 500, loss: 0.1748850792646408
step: 510, loss: 0.2610858976840973
step: 520, loss: 0.28544801473617554
step: 530, loss: 0.37785911560058594
epoch 1: dev_f1=0.6714542190305206, f1=0.605866177818515, best_f1=0.605866177818515
step: 0, loss: 0.1043291911482811
step: 10, loss: 0.24658624827861786
step: 20, loss: 0.19171977043151855
step: 30, loss: 0.2567945122718811
step: 40, loss: 0.3091428577899933
step: 50, loss: 0.18731717765331268
step: 60, loss: 0.15011964738368988
step: 70, loss: 0.2181035280227661
step: 80, loss: 0.208879292011261
step: 90, loss: 0.041025664657354355
step: 100, loss: 0.18594498932361603
step: 110, loss: 0.20145533978939056
step: 120, loss: 0.036236222833395004
step: 130, loss: 0.3303292989730835
step: 140, loss: 0.07852961868047714
step: 150, loss: 0.1583147495985031
step: 160, loss: 0.17228177189826965
step: 170, loss: 0.17355823516845703
step: 180, loss: 0.17763611674308777
step: 190, loss: 0.19816090166568756
step: 200, loss: 0.274455189704895
step: 210, loss: 0.04738454893231392
step: 220, loss: 0.16582073271274567
step: 230, loss: 0.09198048710823059
step: 240, loss: 0.49391990900039673
step: 250, loss: 0.24046966433525085
step: 260, loss: 0.15650156140327454
step: 270, loss: 0.271559476852417
step: 280, loss: 0.2535261809825897
step: 290, loss: 0.11429358273744583
step: 300, loss: 0.11646664887666702
step: 310, loss: 0.2641264796257019
step: 320, loss: 0.0888020396232605
step: 330, loss: 0.034841086715459824
step: 340, loss: 0.0473996177315712
step: 350, loss: 0.14416302740573883
step: 360, loss: 0.16208693385124207
step: 370, loss: 0.09066341072320938
step: 380, loss: 0.45092132687568665
step: 390, loss: 0.06089107319712639
step: 400, loss: 0.196968674659729
step: 410, loss: 0.21218720078468323
step: 420, loss: 0.28857651352882385
step: 430, loss: 0.17440743744373322
step: 440, loss: 0.1799798458814621
step: 450, loss: 0.03601284697651863
step: 460, loss: 0.1769561469554901
step: 470, loss: 0.19489231705665588
step: 480, loss: 0.10778145492076874
step: 490, loss: 0.3732702136039734
step: 500, loss: 0.1278247982263565
step: 510, loss: 0.22310079634189606
step: 520, loss: 0.24120081961154938
step: 530, loss: 0.07822474092245102
epoch 2: dev_f1=0.7391688770999117, f1=0.6451033243486074, best_f1=0.6451033243486074
step: 0, loss: 0.05506977438926697
step: 10, loss: 0.05102528631687164
step: 20, loss: 0.01654423400759697
step: 30, loss: 0.13200421631336212
step: 40, loss: 0.1502993255853653
step: 50, loss: 0.3162945806980133
step: 60, loss: 0.06317842751741409
step: 70, loss: 0.06988941133022308
step: 80, loss: 0.08503249287605286
step: 90, loss: 0.0957556813955307
step: 100, loss: 0.02186407521367073
step: 110, loss: 0.03546437248587608
step: 120, loss: 0.06640730053186417
step: 130, loss: 0.07040898501873016
step: 140, loss: 0.10373116284608841
step: 150, loss: 0.015003606677055359
step: 160, loss: 0.027586642652750015
step: 170, loss: 0.05879150703549385
step: 180, loss: 0.08837005496025085
step: 190, loss: 0.12830859422683716
step: 200, loss: 0.19216424226760864
step: 210, loss: 0.15161220729351044
step: 220, loss: 0.08314646780490875
step: 230, loss: 0.031688664108514786
step: 240, loss: 0.11414381116628647
step: 250, loss: 0.11337359994649887
step: 260, loss: 0.10670889914035797
step: 270, loss: 0.2484317272901535
step: 280, loss: 0.14988093078136444
step: 290, loss: 0.025363285094499588
step: 300, loss: 0.05488438159227371
step: 310, loss: 0.1657753586769104
step: 320, loss: 0.23056860268115997
step: 330, loss: 0.11025384813547134
step: 340, loss: 0.01002528890967369
step: 350, loss: 0.06726399809122086
step: 360, loss: 0.13537414371967316
step: 370, loss: 0.06273581832647324
step: 380, loss: 0.04315122589468956
step: 390, loss: 0.08360341936349869
step: 400, loss: 0.06781000643968582
step: 410, loss: 0.2643057405948639
step: 420, loss: 0.14517717063426971
step: 430, loss: 0.23899315297603607
step: 440, loss: 0.09508232027292252
step: 450, loss: 0.20947526395320892
step: 460, loss: 0.1132330447435379
step: 470, loss: 0.19745196402072906
step: 480, loss: 0.05074770748615265
step: 490, loss: 0.04295053705573082
step: 500, loss: 0.127419114112854
step: 510, loss: 0.21170134842395782
step: 520, loss: 0.07207351177930832
step: 530, loss: 0.02008078619837761
epoch 3: dev_f1=0.7379531895364846, f1=0.6230769230769232, best_f1=0.6451033243486074
step: 0, loss: 0.065677709877491
step: 10, loss: 0.026699088513851166
step: 20, loss: 0.06988171488046646
step: 30, loss: 0.002525466727092862
step: 40, loss: 0.2355826497077942
step: 50, loss: 0.010946732014417648
step: 60, loss: 0.01068861410021782
step: 70, loss: 0.04947643727064133
step: 80, loss: 0.015258039347827435
step: 90, loss: 0.014687636867165565
step: 100, loss: 0.06321024894714355
step: 110, loss: 0.05471573770046234
step: 120, loss: 0.010007965378463268
step: 130, loss: 0.012644272297620773
step: 140, loss: 0.0062282029539346695
step: 150, loss: 0.07512374222278595
step: 160, loss: 0.10539506375789642
step: 170, loss: 0.017806431278586388
step: 180, loss: 0.030302543193101883
step: 190, loss: 0.15536168217658997
step: 200, loss: 0.10322723537683487
step: 210, loss: 0.041339848190546036
step: 220, loss: 0.020546816289424896
step: 230, loss: 0.08418074995279312
step: 240, loss: 0.005601346027106047
step: 250, loss: 0.01788288541138172
step: 260, loss: 0.33122771978378296
step: 270, loss: 0.17931121587753296
step: 280, loss: 0.020380940288305283
step: 290, loss: 0.022787267342209816
step: 300, loss: 0.057036492973566055
step: 310, loss: 0.002566813724115491
step: 320, loss: 0.02214915305376053
step: 330, loss: 0.018933862447738647
step: 340, loss: 0.02710128203034401
step: 350, loss: 0.0167721975594759
step: 360, loss: 0.07649078965187073
step: 370, loss: 0.018041718751192093
step: 380, loss: 0.014928633347153664
step: 390, loss: 0.019083041697740555
step: 400, loss: 0.03486684337258339
step: 410, loss: 0.06484521925449371
step: 420, loss: 0.030480848625302315
step: 430, loss: 0.09322410821914673
step: 440, loss: 0.06492197513580322
step: 450, loss: 0.01654142513871193
step: 460, loss: 0.1556311547756195
step: 470, loss: 0.012119406834244728
step: 480, loss: 0.06054893136024475
step: 490, loss: 0.01244516670703888
step: 500, loss: 0.06785610318183899
step: 510, loss: 0.1847246289253235
step: 520, loss: 0.10274854302406311
step: 530, loss: 0.04776747524738312
epoch 4: dev_f1=0.7430167597765364, f1=0.6258570029382958, best_f1=0.6258570029382958
step: 0, loss: 0.002903769025579095
step: 10, loss: 0.016899045556783676
step: 20, loss: 0.012324735522270203
step: 30, loss: 0.002225576899945736
step: 40, loss: 0.013451800681650639
step: 50, loss: 0.046447958797216415
step: 60, loss: 0.010524352081120014
step: 70, loss: 0.12659306824207306
step: 80, loss: 0.005493382457643747
step: 90, loss: 0.0007314222166314721
step: 100, loss: 0.03050660341978073
step: 110, loss: 0.0031801320146769285
step: 120, loss: 0.02148049883544445
step: 130, loss: 0.004236514214426279
step: 140, loss: 0.0017234842525795102
step: 150, loss: 0.02033063769340515
step: 160, loss: 0.0028153324965387583
step: 170, loss: 0.012835295870900154
step: 180, loss: 0.011522679589688778
step: 190, loss: 0.0018849255284294486
step: 200, loss: 0.15525662899017334
step: 210, loss: 0.1296120584011078
step: 220, loss: 0.015835123136639595
step: 230, loss: 0.009105773642659187
step: 240, loss: 0.000555704755242914
step: 250, loss: 0.016674451529979706
step: 260, loss: 0.04210323840379715
step: 270, loss: 0.0031595085747539997
step: 280, loss: 0.0019067503744736314
step: 290, loss: 0.12074127793312073
step: 300, loss: 0.10470238327980042
step: 310, loss: 0.003966684453189373
step: 320, loss: 0.19914408028125763
step: 330, loss: 0.011746115982532501
step: 340, loss: 0.09696158766746521
step: 350, loss: 0.003326400648802519
step: 360, loss: 0.010473604314029217
step: 370, loss: 0.021533304825425148
step: 380, loss: 0.00332327070645988
step: 390, loss: 0.00402842927724123
step: 400, loss: 0.007547902408987284
step: 410, loss: 0.04140344634652138
step: 420, loss: 0.011580422520637512
step: 430, loss: 0.010690225288271904
step: 440, loss: 0.03267539665102959
step: 450, loss: 0.00766171608120203
step: 460, loss: 0.012347238138318062
step: 470, loss: 0.1087549552321434
step: 480, loss: 0.05896560102701187
step: 490, loss: 0.020816383883357048
step: 500, loss: 0.012204469181597233
step: 510, loss: 0.03637479245662689
step: 520, loss: 0.20009207725524902
step: 530, loss: 0.03070109896361828
epoch 5: dev_f1=0.7377736376339078, f1=0.61423593827775, best_f1=0.6258570029382958
step: 0, loss: 0.12856315076351166
step: 10, loss: 0.0034672727342694998
step: 20, loss: 0.010077402926981449
step: 30, loss: 0.0032648646738380194
step: 40, loss: 0.08356184512376785
step: 50, loss: 0.006030644755810499
step: 60, loss: 0.017831632867455482
step: 70, loss: 0.0015353303169831634
step: 80, loss: 0.08456088602542877
step: 90, loss: 0.0029523123521357775
step: 100, loss: 0.0023207450285553932
step: 110, loss: 0.001553498674184084
step: 120, loss: 0.0011382426600903273
step: 130, loss: 0.005340796895325184
step: 140, loss: 0.02546137198805809
step: 150, loss: 0.05558452010154724
step: 160, loss: 0.0012022715527564287
step: 170, loss: 0.002496791770681739
step: 180, loss: 0.0103071890771389
step: 190, loss: 0.0012805369915440679
step: 200, loss: 0.0003759033279493451
step: 210, loss: 0.005023849196732044
step: 220, loss: 0.00961890909820795
step: 230, loss: 0.0026863606180995703
step: 240, loss: 0.0017492285696789622
step: 250, loss: 0.0008595921681262553
step: 260, loss: 0.036561254411935806
step: 270, loss: 0.017802288755774498
step: 280, loss: 0.09513765573501587
step: 290, loss: 0.031832434237003326
step: 300, loss: 0.03863982483744621
step: 310, loss: 0.0490121953189373
step: 320, loss: 0.000839176878798753
step: 330, loss: 0.017236927524209023
step: 340, loss: 0.02396143227815628
step: 350, loss: 0.15670432150363922
step: 360, loss: 0.014583893120288849
step: 370, loss: 0.04114201292395592
step: 380, loss: 0.004551501478999853
step: 390, loss: 0.002950223395600915
step: 400, loss: 0.0023690881207585335
step: 410, loss: 0.00032083873520605266
step: 420, loss: 0.014492781832814217
step: 430, loss: 0.0003227693377994001
step: 440, loss: 0.1132422685623169
step: 450, loss: 0.001850976375862956
step: 460, loss: 0.01617022603750229
step: 470, loss: 0.0006921748863533139
step: 480, loss: 0.10588008165359497
step: 490, loss: 0.017453540116548538
step: 500, loss: 0.03135852888226509
step: 510, loss: 0.0015406542224809527
step: 520, loss: 0.012486925348639488
step: 530, loss: 0.019788440316915512
epoch 6: dev_f1=0.7766051011433597, f1=0.6797445255474452, best_f1=0.6797445255474452
step: 0, loss: 0.01641387678682804
step: 10, loss: 0.00223090429790318
step: 20, loss: 0.007028159685432911
step: 30, loss: 0.001207262510433793
step: 40, loss: 0.027574190869927406
step: 50, loss: 0.019690141081809998
step: 60, loss: 0.004158223979175091
step: 70, loss: 0.005575912538915873
step: 80, loss: 0.007938639260828495
step: 90, loss: 0.0014411578886210918
step: 100, loss: 0.021814841777086258
step: 110, loss: 0.004605793859809637
step: 120, loss: 0.004972241353243589
step: 130, loss: 0.010805392637848854
step: 140, loss: 0.0025963883381336927
step: 150, loss: 0.0013970116851851344
step: 160, loss: 0.0006184757803566754
step: 170, loss: 0.0038551464676856995
step: 180, loss: 0.05240590497851372
step: 190, loss: 0.00016699283150956035
step: 200, loss: 0.0008209670195356011
step: 210, loss: 0.0007878776523284614
step: 220, loss: 0.0012247379636391997
step: 230, loss: 0.0008843817049637437
step: 240, loss: 0.0009036317933350801
step: 250, loss: 0.0019168118014931679
step: 260, loss: 0.0007069170824252069
step: 270, loss: 0.18255148828029633
step: 280, loss: 0.028177615255117416
step: 290, loss: 0.03410249203443527
step: 300, loss: 0.002729215892031789
step: 310, loss: 0.005725665017962456
step: 320, loss: 0.0024372965563088655
step: 330, loss: 0.004726623650640249
step: 340, loss: 0.0030459349509328604
step: 350, loss: 0.0025490776170045137
step: 360, loss: 0.00039605959318578243
step: 370, loss: 0.0011113833170384169
step: 380, loss: 0.02843325398862362
step: 390, loss: 0.0018157210433855653
step: 400, loss: 0.0005038646631874144
step: 410, loss: 0.004407232627272606
step: 420, loss: 0.0006493230466730893
step: 430, loss: 0.0018924488686025143
step: 440, loss: 0.0070570847019553185
step: 450, loss: 0.07098010182380676
step: 460, loss: 0.004678154829889536
step: 470, loss: 0.012833411805331707
step: 480, loss: 0.15607160329818726
step: 490, loss: 0.0042806463316082954
step: 500, loss: 0.02881712093949318
step: 510, loss: 0.016404347494244576
step: 520, loss: 0.0021924390457570553
step: 530, loss: 0.015361848287284374
epoch 7: dev_f1=0.7625531914893617, f1=0.6642920747996438, best_f1=0.6797445255474452
step: 0, loss: 0.0038377013988792896
step: 10, loss: 0.01548544317483902
step: 20, loss: 0.05746879056096077
step: 30, loss: 0.0030680298805236816
step: 40, loss: 0.05223232880234718
step: 50, loss: 0.0011497378582134843
step: 60, loss: 0.004156612791121006
step: 70, loss: 0.0005574894021265209
step: 80, loss: 0.08434543013572693
step: 90, loss: 9.035968105308712e-05
step: 100, loss: 0.0001677009859122336
step: 110, loss: 0.0020705033093690872
step: 120, loss: 0.11215125024318695
step: 130, loss: 0.01134854182600975
step: 140, loss: 0.12672293186187744
step: 150, loss: 0.0007124215480871499
step: 160, loss: 0.0005580072174780071
step: 170, loss: 0.0022141619119793177
step: 180, loss: 0.0004664162115659565
step: 190, loss: 0.0005967039614915848
step: 200, loss: 0.0001547941647004336
step: 210, loss: 0.004821411333978176
step: 220, loss: 0.005855261348187923
step: 230, loss: 0.00019136106129735708
step: 240, loss: 0.00023507890000473708
step: 250, loss: 0.007587940897792578
step: 260, loss: 0.0003036637499462813
step: 270, loss: 0.0021651550196111202
step: 280, loss: 0.0016102908411994576
step: 290, loss: 0.0625106543302536
step: 300, loss: 0.02176712639629841
step: 310, loss: 0.0012963613262400031
step: 320, loss: 0.0009832554496824741
step: 330, loss: 0.0005374908214434981
step: 340, loss: 0.0017762971110641956
step: 350, loss: 0.005288804415613413
step: 360, loss: 0.004180531948804855
step: 370, loss: 0.07298903912305832
step: 380, loss: 0.019050240516662598
step: 390, loss: 0.0017931085312739015
step: 400, loss: 0.001145260175690055
step: 410, loss: 0.012282796204090118
step: 420, loss: 0.0029108449816703796
step: 430, loss: 0.00028035842115059495
step: 440, loss: 0.0004408947716001421
step: 450, loss: 0.0003540879988577217
step: 460, loss: 0.045116085559129715
step: 470, loss: 0.10350685566663742
step: 480, loss: 0.0005382738308981061
step: 490, loss: 0.0004766708007082343
step: 500, loss: 0.0008179291617125273
step: 510, loss: 0.00028518843464553356
step: 520, loss: 0.000254809798207134
step: 530, loss: 0.03217538818717003
epoch 8: dev_f1=0.7492957746478873, f1=0.6196901549225386, best_f1=0.6797445255474452
step: 0, loss: 0.0025975441094487906
step: 10, loss: 0.030961651355028152
step: 20, loss: 0.055640291422605515
step: 30, loss: 0.055099088698625565
step: 40, loss: 0.0008244833443313837
step: 50, loss: 0.0227980799973011
step: 60, loss: 0.005134791135787964
step: 70, loss: 0.0007656183443032205
step: 80, loss: 0.0007089903810992837
step: 90, loss: 0.00653201574459672
step: 100, loss: 0.011366297490894794
step: 110, loss: 0.00021709175780415535
step: 120, loss: 0.0007866742089390755
step: 130, loss: 0.0011915563372895122
step: 140, loss: 0.002600486623123288
step: 150, loss: 0.00011795548925874755
step: 160, loss: 0.011900770477950573
step: 170, loss: 0.1110750138759613
step: 180, loss: 0.020540205761790276
step: 190, loss: 0.055063117295503616
step: 200, loss: 0.09872996807098389
step: 210, loss: 0.0006855489336885512
step: 220, loss: 0.0004902930231764913
step: 230, loss: 0.0010975813493132591
step: 240, loss: 0.0006641284562647343
step: 250, loss: 0.04175737872719765
step: 260, loss: 0.06698866933584213
step: 270, loss: 0.0014706200454384089
step: 280, loss: 0.0022814739495515823
step: 290, loss: 0.0682632252573967
step: 300, loss: 0.05669882893562317
step: 310, loss: 0.000143070486956276
step: 320, loss: 0.0016202895203605294
step: 330, loss: 0.0010890818666666746
step: 340, loss: 0.00033870796323753893
step: 350, loss: 0.008656250312924385
step: 360, loss: 0.02030269429087639
step: 370, loss: 0.051266830414533615
step: 380, loss: 0.00031448283698409796
step: 390, loss: 0.020666321739554405
step: 400, loss: 0.0005096931708976626
step: 410, loss: 0.0006796615780331194
step: 420, loss: 0.01849542185664177
step: 430, loss: 0.004160058684647083
step: 440, loss: 7.335084228543565e-05
step: 450, loss: 0.0005291157285682857
step: 460, loss: 0.002104019047692418
step: 470, loss: 0.0019486058736220002
step: 480, loss: 0.001602334319613874
step: 490, loss: 0.023066336289048195
step: 500, loss: 0.0004801571776624769
step: 510, loss: 0.002005728194490075
step: 520, loss: 0.0023562568239867687
step: 530, loss: 0.0011591057991608977
epoch 9: dev_f1=0.7599486521181, f1=0.6454789615040287, best_f1=0.6797445255474452
step: 0, loss: 0.0010709670605137944
step: 10, loss: 0.00020279399177525192
step: 20, loss: 0.001757133868522942
step: 30, loss: 0.00131732237059623
step: 40, loss: 0.00010249705519527197
step: 50, loss: 0.002814061474055052
step: 60, loss: 0.0002396630443399772
step: 70, loss: 0.00015837702085264027
step: 80, loss: 0.00022499900660477579
step: 90, loss: 0.0047321380116045475
step: 100, loss: 7.231080962810665e-05
step: 110, loss: 0.003171682357788086
step: 120, loss: 0.0008031855686567724
step: 130, loss: 7.764735346427187e-05
step: 140, loss: 0.011985941790044308
step: 150, loss: 0.002398757729679346
step: 160, loss: 0.0006939963204786181
step: 170, loss: 6.70149820507504e-05
step: 180, loss: 0.00012403095024637878
step: 190, loss: 8.780920325079933e-05
step: 200, loss: 0.00010882518836297095
step: 210, loss: 0.00048370397416874766
step: 220, loss: 0.0006151049165055156
step: 230, loss: 0.0037125658709555864
step: 240, loss: 0.0002974921662826091
step: 250, loss: 4.7635574446758255e-05
step: 260, loss: 0.0004860305634792894
step: 270, loss: 0.07141289114952087
step: 280, loss: 8.456917566945776e-05
step: 290, loss: 0.0005221408791840076
step: 300, loss: 0.0011495229555293918
step: 310, loss: 0.0038367323577404022
step: 320, loss: 0.11012284457683563
step: 330, loss: 0.06958598643541336
step: 340, loss: 0.0020086129661649466
step: 350, loss: 0.0004098323988728225
step: 360, loss: 0.000296297250315547
step: 370, loss: 0.002066057175397873
step: 380, loss: 0.0028709571342915297
step: 390, loss: 0.11184535175561905
step: 400, loss: 0.0003659308422356844
step: 410, loss: 0.0003386799362488091
step: 420, loss: 0.01925971359014511
step: 430, loss: 0.0008247565128840506
step: 440, loss: 0.00089291762560606
step: 450, loss: 0.00017048993322532624
step: 460, loss: 5.99704981141258e-05
step: 470, loss: 0.0027367935981601477
step: 480, loss: 0.0004694356466643512
step: 490, loss: 0.004932438023388386
step: 500, loss: 0.0005708497483283281
step: 510, loss: 0.0005436583887785673
step: 520, loss: 7.578475924674422e-05
step: 530, loss: 0.0010712671792134643
epoch 10: dev_f1=0.7359307359307359, f1=0.612354521038496, best_f1=0.6797445255474452
step: 0, loss: 0.0106036476790905
step: 10, loss: 4.4079151848563924e-05
step: 20, loss: 4.387009175843559e-05
step: 30, loss: 0.00021828555327374488
step: 40, loss: 0.0005416570929810405
step: 50, loss: 0.0006005685427226126
step: 60, loss: 0.009479491971433163
step: 70, loss: 0.00010918133921222761
step: 80, loss: 0.00020851026056334376
step: 90, loss: 0.0005223940825089812
step: 100, loss: 0.06741280853748322
step: 110, loss: 0.039109230041503906
step: 120, loss: 0.009511499665677547
step: 130, loss: 0.004181517753750086
step: 140, loss: 0.09244458377361298
step: 150, loss: 0.0021120079327374697
step: 160, loss: 0.006568032782524824
step: 170, loss: 0.0012029691133648157
step: 180, loss: 0.0011945117730647326
step: 190, loss: 0.00023157136456575245
step: 200, loss: 0.006077582016587257
step: 210, loss: 8.012440957827494e-05
step: 220, loss: 0.0014082180568948388
step: 230, loss: 0.00015692818851675838
step: 240, loss: 0.0003413961676415056
step: 250, loss: 7.316180563066155e-05
step: 260, loss: 0.00013551313895732164
step: 270, loss: 0.00012929581862408668
step: 280, loss: 5.073969441582449e-05
step: 290, loss: 0.0006255010957829654
step: 300, loss: 0.019377712160348892
step: 310, loss: 0.0003025745681952685
step: 320, loss: 0.0016242482233792543
step: 330, loss: 0.0016402621986344457
step: 340, loss: 0.021846067160367966
step: 350, loss: 0.002865354297682643
step: 360, loss: 0.0001394475984852761
step: 370, loss: 0.0025240785907953978
step: 380, loss: 2.8207145078340545e-05
step: 390, loss: 0.010237131267786026
step: 400, loss: 0.00011876041389768943
step: 410, loss: 0.006045868154615164
step: 420, loss: 5.77091341256164e-05
step: 430, loss: 0.0009768229210749269
step: 440, loss: 0.002973704133182764
step: 450, loss: 3.602611104724929e-05
step: 460, loss: 0.008725566789507866
step: 470, loss: 0.11560102552175522
step: 480, loss: 4.630179319065064e-05
step: 490, loss: 0.000550862227100879
step: 500, loss: 0.11837035417556763
step: 510, loss: 0.003150543663650751
step: 520, loss: 0.006043349392712116
step: 530, loss: 0.002955252304673195
epoch 11: dev_f1=0.7745234774523477, f1=0.6593951412989589, best_f1=0.6797445255474452
step: 0, loss: 0.04471806064248085
step: 10, loss: 9.080065501620993e-05
step: 20, loss: 5.454191705211997e-05
step: 30, loss: 6.32356241112575e-05
step: 40, loss: 0.0006888205534778535
step: 50, loss: 0.04024779796600342
step: 60, loss: 0.00016677597886882722
step: 70, loss: 0.0012997566955164075
step: 80, loss: 8.108519978122786e-05
step: 90, loss: 0.00019527664699126035
step: 100, loss: 0.0009248961578123271
step: 110, loss: 5.0537164497654885e-05
step: 120, loss: 0.000643385574221611
step: 130, loss: 6.098666926845908e-05
step: 140, loss: 8.616066770628095e-05
step: 150, loss: 0.0002808620629366487
step: 160, loss: 7.122121314750984e-05
step: 170, loss: 0.0005929969483986497
step: 180, loss: 0.00021009700139984488
step: 190, loss: 0.00013824233610648662
step: 200, loss: 0.0007239587139338255
step: 210, loss: 0.00015226939285639673
step: 220, loss: 0.0022865936625748873
step: 230, loss: 5.58085557713639e-05
step: 240, loss: 0.002092610811814666
step: 250, loss: 0.0013771533267572522
step: 260, loss: 2.9328321033972315e-05
step: 270, loss: 2.8445581847336143e-05
step: 280, loss: 0.00015886347682680935
step: 290, loss: 5.395922198658809e-05
step: 300, loss: 0.00018402498972136527
step: 310, loss: 0.00013277643301989883
step: 320, loss: 9.361455158796161e-05
step: 330, loss: 6.496431888081133e-05
step: 340, loss: 4.09750864491798e-05
step: 350, loss: 9.469687938690186e-05
step: 360, loss: 0.08815423399209976
step: 370, loss: 4.13184825447388e-05
step: 380, loss: 0.001554299145936966
step: 390, loss: 0.011359977535903454
step: 400, loss: 5.267380038276315e-05
step: 410, loss: 0.0005557042895816267
step: 420, loss: 0.00026451071607880294
step: 430, loss: 4.535272455541417e-05
step: 440, loss: 4.7099678340600803e-05
step: 450, loss: 0.0003402959555387497
step: 460, loss: 0.02797366864979267
step: 470, loss: 3.6969278880860656e-05
step: 480, loss: 3.0259290724643506e-05
step: 490, loss: 1.8331911633140408e-05
step: 500, loss: 7.229560287669301e-05
step: 510, loss: 0.0005939832772128284
step: 520, loss: 6.963211490074173e-05
step: 530, loss: 0.0010261365678161383
epoch 12: dev_f1=0.757932910244787, f1=0.6260201632261162, best_f1=0.6797445255474452
step: 0, loss: 8.566727046854794e-05
step: 10, loss: 3.430416836636141e-05
step: 20, loss: 0.0008900315733626485
step: 30, loss: 0.0005035888170823455
step: 40, loss: 0.020241884514689445
step: 50, loss: 0.0005674881977029145
step: 60, loss: 0.0001409555261489004
step: 70, loss: 0.015099707990884781
step: 80, loss: 0.005306737031787634
step: 90, loss: 0.00013455370208248496
step: 100, loss: 0.0001554644841235131
step: 110, loss: 9.804430737858638e-05
step: 120, loss: 0.0011585524771362543
step: 130, loss: 0.012875553220510483
step: 140, loss: 0.003185833804309368
step: 150, loss: 0.00023275245621334761
step: 160, loss: 0.0006658073398284614
step: 170, loss: 0.13895219564437866
step: 180, loss: 0.0023247015196830034
step: 190, loss: 0.0016251112101599574
step: 200, loss: 0.001337047666311264
step: 210, loss: 0.04756053164601326
step: 220, loss: 0.0014264616183936596
step: 230, loss: 0.0022172715980559587
step: 240, loss: 5.340131974662654e-05
step: 250, loss: 0.004599830601364374
step: 260, loss: 0.003244023537263274
step: 270, loss: 5.536384924198501e-05
step: 280, loss: 3.561484845704399e-05
step: 290, loss: 0.00012536732538137585
step: 300, loss: 2.857563413272146e-05
step: 310, loss: 0.0002471446932759136
step: 320, loss: 0.01627342961728573
step: 330, loss: 4.210503539070487e-05
step: 340, loss: 0.0002254364371765405
step: 350, loss: 8.144012099364772e-05
step: 360, loss: 3.950031896238215e-05
step: 370, loss: 2.2690332116326317e-05
step: 380, loss: 0.00015899178106337786
step: 390, loss: 9.402137948200107e-05
step: 400, loss: 5.3509542340179905e-05
step: 410, loss: 7.906225800979882e-05
step: 420, loss: 2.723781653912738e-05
step: 430, loss: 0.0005993500235490501
step: 440, loss: 0.0008144368184730411
step: 450, loss: 0.0069907475262880325
step: 460, loss: 0.0010519353672862053
step: 470, loss: 0.00016204839630518109
step: 480, loss: 0.008995858952403069
step: 490, loss: 4.692949732998386e-05
step: 500, loss: 0.0004106721899006516
step: 510, loss: 0.0017933943308889866
step: 520, loss: 4.089378489879891e-05
step: 530, loss: 4.736347182188183e-05
epoch 13: dev_f1=0.7313630348478165, f1=0.6049723756906077, best_f1=0.6797445255474452
step: 0, loss: 0.002968462649732828
step: 10, loss: 0.010415645316243172
step: 20, loss: 2.5599718355806544e-05
step: 30, loss: 0.0008402927778661251
step: 40, loss: 2.279063846799545e-05
step: 50, loss: 0.0001867383107310161
step: 60, loss: 3.377238681423478e-05
step: 70, loss: 0.00017068478337023407
step: 80, loss: 6.095308344811201e-05
step: 90, loss: 0.000754095206502825
step: 100, loss: 4.6184504753910005e-05
step: 110, loss: 0.0005278988974168897
step: 120, loss: 0.036920443177223206
step: 130, loss: 3.331391781102866e-05
step: 140, loss: 0.0019719547126442194
step: 150, loss: 0.00019445843645371497
step: 160, loss: 0.0010709842899814248
step: 170, loss: 0.0001274946698686108
step: 180, loss: 0.0018662220099940896
step: 190, loss: 2.5606794224586338e-05
step: 200, loss: 6.185587699292228e-05
step: 210, loss: 0.00034175149630755186
step: 220, loss: 4.494535824051127e-05
step: 230, loss: 1.777687793946825e-05
step: 240, loss: 0.0003073754196520895
step: 250, loss: 0.00035855566966347396
step: 260, loss: 0.0001160708416136913
step: 270, loss: 0.0001661928981775418
step: 280, loss: 0.04060634970664978
step: 290, loss: 0.0004982349928468466
step: 300, loss: 6.173197471071035e-05
step: 310, loss: 4.3184394598938525e-05
step: 320, loss: 2.9819922929164022e-05
step: 330, loss: 0.00021350522001739591
step: 340, loss: 4.374566924525425e-05
step: 350, loss: 0.0016485886881127954
step: 360, loss: 0.0003473220276646316
step: 370, loss: 8.86487468960695e-05
step: 380, loss: 2.250776014989242e-05
step: 390, loss: 2.0417970517883077e-05
step: 400, loss: 7.736146653769538e-05
step: 410, loss: 0.00012229518324602395
step: 420, loss: 0.001605970086529851
step: 430, loss: 0.0011155690299347043
step: 440, loss: 0.0007193023920990527
step: 450, loss: 2.6280667952960357e-05
step: 460, loss: 3.688131255330518e-05
step: 470, loss: 3.867967097903602e-05
step: 480, loss: 4.238692781655118e-05
step: 490, loss: 6.938746810192242e-05
step: 500, loss: 6.86410057824105e-05
step: 510, loss: 0.00012093859550077468
step: 520, loss: 0.005981601774692535
step: 530, loss: 0.00039605487836524844
epoch 14: dev_f1=0.7622504537205083, f1=0.6209213051823416, best_f1=0.6797445255474452
step: 0, loss: 0.0001782799809006974
step: 10, loss: 5.231017348705791e-05
step: 20, loss: 0.013243375346064568
step: 30, loss: 0.0003131492994725704
step: 40, loss: 4.790993261849508e-05
step: 50, loss: 1.2937834071635734e-05
step: 60, loss: 2.9398506740108132e-05
step: 70, loss: 0.0007643498247489333
step: 80, loss: 0.000785737531259656
step: 90, loss: 1.651401908020489e-05
step: 100, loss: 0.0014281263574957848
step: 110, loss: 1.2952740689797793e-05
step: 120, loss: 3.47575951309409e-05
step: 130, loss: 0.003065041732043028
step: 140, loss: 1.5646059182472527e-05
step: 150, loss: 4.888066905550659e-05
step: 160, loss: 1.774703196133487e-05
step: 170, loss: 6.759980897186324e-05
step: 180, loss: 0.00038408261025324464
step: 190, loss: 2.3155680537456647e-05
step: 200, loss: 0.0005208273069001734
step: 210, loss: 0.00019687721214722842
step: 220, loss: 1.842491838033311e-05
step: 230, loss: 2.9613758670166135e-05
step: 240, loss: 0.00017841518274508417
step: 250, loss: 5.4020172683522105e-05
step: 260, loss: 1.476314355386421e-05
step: 270, loss: 2.386727101111319e-05
step: 280, loss: 3.063462281716056e-05
step: 290, loss: 0.00010346002090955153
step: 300, loss: 3.054941407754086e-05
step: 310, loss: 0.00016594849876128137
step: 320, loss: 2.8165275580249727e-05
step: 330, loss: 7.546211418230087e-05
step: 340, loss: 2.4068544007604942e-05
step: 350, loss: 0.0001868506515165791
step: 360, loss: 8.662445179652423e-05
step: 370, loss: 5.939308903180063e-05
step: 380, loss: 4.820057802135125e-05
step: 390, loss: 0.006415935233235359
step: 400, loss: 0.023962251842021942
step: 410, loss: 2.15800591831794e-05
step: 420, loss: 6.439294520532712e-05
step: 430, loss: 6.317615043371916e-05
step: 440, loss: 0.004444291349500418
step: 450, loss: 0.00024260564532596618
step: 460, loss: 0.0006145754014141858
step: 470, loss: 0.0030905974563211203
step: 480, loss: 0.00021850806660950184
step: 490, loss: 0.0003037948627024889
step: 500, loss: 2.6537090889178216e-05
step: 510, loss: 0.0002554464736022055
step: 520, loss: 0.00017734318680595607
step: 530, loss: 9.79289470706135e-05
epoch 15: dev_f1=0.7594339622641509, f1=0.6256983240223463, best_f1=0.6797445255474452
step: 0, loss: 0.00033946760231629014
step: 10, loss: 0.0005932881031185389
step: 20, loss: 2.095420131809078e-05
step: 30, loss: 4.870927659794688e-05
step: 40, loss: 8.376963523915038e-05
step: 50, loss: 0.00015319552039727569
step: 60, loss: 0.004652706906199455
step: 70, loss: 0.00020911690080538392
step: 80, loss: 0.0002714271831791848
step: 90, loss: 4.9614649469731376e-05
step: 100, loss: 0.00024842817219905555
step: 110, loss: 0.0009304229170084
step: 120, loss: 0.00020347705867607147
step: 130, loss: 2.0439438230823725e-05
step: 140, loss: 3.0403136406675912e-05
step: 150, loss: 0.004414770752191544
step: 160, loss: 0.00027683976804837584
step: 170, loss: 0.0006884394679218531
step: 180, loss: 0.00010813931294251233
step: 190, loss: 0.012714405544102192
step: 200, loss: 5.2629984566010535e-05
step: 210, loss: 3.8689307984896004e-05
step: 220, loss: 0.00026176151004619896
step: 230, loss: 5.686073563992977e-05
step: 240, loss: 4.378554876893759e-05
step: 250, loss: 2.7863272407557815e-05
step: 260, loss: 0.011584598571062088
step: 270, loss: 3.32793642883189e-05
step: 280, loss: 0.0005233645788393915
step: 290, loss: 1.598873859620653e-05
step: 300, loss: 2.384103208896704e-05
step: 310, loss: 3.278657095506787e-05
step: 320, loss: 5.7708792155608535e-05
step: 330, loss: 0.0006182867800816894
step: 340, loss: 0.00011154809908475727
step: 350, loss: 0.00018627717508934438
step: 360, loss: 0.0002865319838747382
step: 370, loss: 0.0002719213080126792
step: 380, loss: 1.7117432435043156e-05
step: 390, loss: 1.5150566468946636e-05
step: 400, loss: 0.00027626121300272644
step: 410, loss: 0.0021357606165111065
step: 420, loss: 4.000961780548096e-05
step: 430, loss: 4.389067544252612e-05
step: 440, loss: 0.00018249457934871316
step: 450, loss: 2.7019861590815708e-05
step: 460, loss: 0.029232311993837357
step: 470, loss: 4.439334225025959e-05
step: 480, loss: 0.0013520244974642992
step: 490, loss: 6.325916183413938e-05
step: 500, loss: 6.214720633579418e-05
step: 510, loss: 0.0004927178961224854
step: 520, loss: 0.004157181829214096
step: 530, loss: 0.001024216297082603
epoch 16: dev_f1=0.7460389316432775, f1=0.6100872938894277, best_f1=0.6797445255474452
step: 0, loss: 1.92145071196137e-05
step: 10, loss: 2.067484092549421e-05
step: 20, loss: 1.4986546375439502e-05
step: 30, loss: 2.203076110163238e-05
step: 40, loss: 0.0008435673080384731
step: 50, loss: 2.4634282453916967e-05
step: 60, loss: 2.112538459186908e-05
step: 70, loss: 2.4640832634759136e-05
step: 80, loss: 3.186338290106505e-05
step: 90, loss: 2.7326899726176634e-05
step: 100, loss: 0.004667532164603472
step: 110, loss: 1.309799790760735e-05
step: 120, loss: 0.0005599237629212439
step: 130, loss: 2.131063047272619e-05
step: 140, loss: 2.10213092941558e-05
step: 150, loss: 6.418882549041882e-05
step: 160, loss: 0.0014820696087554097
step: 170, loss: 0.0005632536485791206
step: 180, loss: 0.0006587061798200011
step: 190, loss: 1.335126580670476e-05
step: 200, loss: 2.4860662961145863e-05
step: 210, loss: 1.390632678521797e-05
step: 220, loss: 0.0017558214021846652
step: 230, loss: 1.8938935681944713e-05
step: 240, loss: 1.7322041458101012e-05
step: 250, loss: 1.2572663763421588e-05
step: 260, loss: 0.0027698748745024204
step: 270, loss: 8.265560609288514e-05
step: 280, loss: 0.00037577649345621467
step: 290, loss: 1.342928680969635e-05
step: 300, loss: 1.3511438737623394e-05
step: 310, loss: 2.0097369997529313e-05
step: 320, loss: 8.284928480861709e-05
step: 330, loss: 2.8060361728421412e-05
step: 340, loss: 1.0989508155034855e-05
step: 350, loss: 0.0016592637402936816
step: 360, loss: 0.00040204485412687063
step: 370, loss: 0.00047427721437998116
step: 380, loss: 0.0001033734661177732
step: 390, loss: 7.056565664242953e-05
step: 400, loss: 2.3155773305916227e-05
step: 410, loss: 3.6782272218260914e-05
step: 420, loss: 0.00027572011458687484
step: 430, loss: 0.0006292410544119775
step: 440, loss: 0.0006164568476378918
step: 450, loss: 2.771787330857478e-05
step: 460, loss: 0.00013904640218243003
step: 470, loss: 3.0519611755153164e-05
step: 480, loss: 1.3317720913619269e-05
step: 490, loss: 0.011800667271018028
step: 500, loss: 8.487034210702404e-05
step: 510, loss: 0.00011205342161701992
step: 520, loss: 4.868462201557122e-05
step: 530, loss: 4.1212973883375525e-05
epoch 17: dev_f1=0.7535587188612098, f1=0.6215704824976347, best_f1=0.6797445255474452
step: 0, loss: 2.4448216208838858e-05
step: 10, loss: 3.1674830097472295e-05
step: 20, loss: 7.792763790348545e-05
step: 30, loss: 0.00016262150893453509
step: 40, loss: 3.322101474623196e-05
step: 50, loss: 3.429459684411995e-05
step: 60, loss: 0.00010451326670590788
step: 70, loss: 1.368280663882615e-05
step: 80, loss: 0.00030509274802170694
step: 90, loss: 1.2788793355866801e-05
step: 100, loss: 1.8051960068987682e-05
step: 110, loss: 2.650037822604645e-05
step: 120, loss: 1.9605577108450234e-05
step: 130, loss: 1.2021369002468418e-05
step: 140, loss: 1.1727101082215086e-05
step: 150, loss: 1.2375214282656088e-05
step: 160, loss: 3.1010389648145065e-05
step: 170, loss: 0.00014801599900238216
step: 180, loss: 2.9185903258621693e-05
step: 190, loss: 2.866443173843436e-05
step: 200, loss: 0.00019816965505015105
step: 210, loss: 3.772702984861098e-05
step: 220, loss: 3.14004864776507e-05
step: 230, loss: 7.696211105212569e-05
step: 240, loss: 1.9310906282044016e-05
step: 250, loss: 0.0006033959216438234
step: 260, loss: 1.0989524525939487e-05
step: 270, loss: 0.0006946111097931862
step: 280, loss: 0.002183143049478531
step: 290, loss: 1.615627479623072e-05
step: 300, loss: 0.001461885287426412
step: 310, loss: 1.3474071238306351e-05
step: 320, loss: 2.5642921173130162e-05
step: 330, loss: 0.00019110013090539724
step: 340, loss: 3.327798913232982e-05
step: 350, loss: 1.2494497241277713e-05
step: 360, loss: 1.1581820217543282e-05
step: 370, loss: 1.4707203263242263e-05
step: 380, loss: 1.429003805242246e-05
step: 390, loss: 2.695513830985874e-05
step: 400, loss: 3.057345384149812e-05
step: 410, loss: 0.014401938766241074
step: 420, loss: 7.239831029437482e-05
step: 430, loss: 0.001517011085525155
step: 440, loss: 3.7334768421715125e-05
step: 450, loss: 1.505735326645663e-05
step: 460, loss: 0.00013804525951854885
step: 470, loss: 0.0004694228118751198
step: 480, loss: 1.4703508895763662e-05
step: 490, loss: 2.9625289243995212e-05
step: 500, loss: 6.678958015982062e-05
step: 510, loss: 0.002063055755570531
step: 520, loss: 2.6291603717254475e-05
step: 530, loss: 1.3660507647728082e-05
epoch 18: dev_f1=0.7600542250338906, f1=0.6349663784822286, best_f1=0.6797445255474452
step: 0, loss: 2.6003745006164536e-05
step: 10, loss: 3.15889083140064e-05
step: 20, loss: 2.0339241018518806e-05
step: 30, loss: 5.172901728656143e-05
step: 40, loss: 3.940570240956731e-05
step: 50, loss: 2.6936386348097585e-05
step: 60, loss: 1.8063488823827356e-05
step: 70, loss: 3.0093999157543294e-05
step: 80, loss: 1.7866106645669788e-05
step: 90, loss: 1.400689779984532e-05
step: 100, loss: 5.374788452172652e-05
step: 110, loss: 1.998555126192514e-05
step: 120, loss: 8.499601244693622e-05
step: 130, loss: 1.4424081200559158e-05
step: 140, loss: 5.554146628128365e-05
step: 150, loss: 2.4052827939158306e-05
step: 160, loss: 0.00012468335626181215
step: 170, loss: 1.8905402612290345e-05
step: 180, loss: 0.00010694235243136063
step: 190, loss: 3.6613026168197393e-05
step: 200, loss: 1.1425367119954899e-05
step: 210, loss: 4.242261638864875e-05
step: 220, loss: 1.9768483980442397e-05
step: 230, loss: 3.682922397274524e-05
step: 240, loss: 0.0005444110720418394
step: 250, loss: 1.0624449714669026e-05
step: 260, loss: 3.893033499480225e-05
step: 270, loss: 2.3688131477683783e-05
step: 280, loss: 4.3239597289357334e-05
step: 290, loss: 2.268936441396363e-05
step: 300, loss: 1.260995395568898e-05
step: 310, loss: 6.21585568296723e-05
step: 320, loss: 3.715408456628211e-05
step: 330, loss: 0.060603585094213486
step: 340, loss: 1.4755680240341462e-05
step: 350, loss: 1.9210112441214733e-05
step: 360, loss: 1.6510175555595197e-05
step: 370, loss: 1.7813903468777426e-05
step: 380, loss: 1.94939839275321e-05
step: 390, loss: 6.738898809999228e-05
step: 400, loss: 0.00019860856991726905
step: 410, loss: 1.3902564205636736e-05
step: 420, loss: 4.816523505724035e-05
step: 430, loss: 0.00020543066784739494
step: 440, loss: 0.0018543909536674619
step: 450, loss: 3.0821429390925914e-05
step: 460, loss: 0.0008945557055994868
step: 470, loss: 7.067469414323568e-05
step: 480, loss: 3.348456812091172e-05
step: 490, loss: 1.5671945220674388e-05
step: 500, loss: 5.101252827444114e-05
step: 510, loss: 1.1242833352298476e-05
step: 520, loss: 3.345554068800993e-05
step: 530, loss: 1.4234180525818374e-05
epoch 19: dev_f1=0.7673992673992673, f1=0.6463952918097107, best_f1=0.6797445255474452
step: 0, loss: 1.782509934855625e-05
step: 10, loss: 2.4372580810450017e-05
step: 20, loss: 2.0562914869515225e-05
step: 30, loss: 3.0942752346163616e-05
step: 40, loss: 7.983238174347207e-05
step: 50, loss: 0.0011472769547253847
step: 60, loss: 1.7210268197231926e-05
step: 70, loss: 1.0982063940900844e-05
step: 80, loss: 0.00019709613115992397
step: 90, loss: 1.546330349810887e-05
step: 100, loss: 2.9282864488777705e-05
step: 110, loss: 9.898040843836498e-06
step: 120, loss: 1.581737342348788e-05
step: 130, loss: 3.074214328080416e-05
step: 140, loss: 0.00043146382085978985
step: 150, loss: 2.7126394343213178e-05
step: 160, loss: 0.0001797994482330978
step: 170, loss: 1.2799969226762187e-05
step: 180, loss: 1.3854135431756731e-05
step: 190, loss: 0.0001269857311854139
step: 200, loss: 1.7951744666788727e-05
step: 210, loss: 7.686385652050376e-05
step: 220, loss: 2.1710244254791178e-05
step: 230, loss: 1.3820632375427522e-05
step: 240, loss: 1.3612052498501725e-05
step: 250, loss: 2.5236455257982016e-05
step: 260, loss: 2.286054404976312e-05
step: 270, loss: 7.409400132019073e-05
step: 280, loss: 1.7783349903766066e-05
step: 290, loss: 1.2717995559796691e-05
step: 300, loss: 2.5221834221156314e-05
step: 310, loss: 0.00015706854173913598
step: 320, loss: 0.0015648780390620232
step: 330, loss: 0.0001620685070520267
step: 340, loss: 1.6148860595421866e-05
step: 350, loss: 1.8763432308332995e-05
step: 360, loss: 1.4338440450956114e-05
step: 370, loss: 1.2215118658787105e-05
step: 380, loss: 5.2302337280707434e-05
step: 390, loss: 1.7467398720327765e-05
step: 400, loss: 1.4401753105630632e-05
step: 410, loss: 2.462648080836516e-05
step: 420, loss: 1.4208055290509947e-05
step: 430, loss: 3.4363180020591244e-05
step: 440, loss: 0.006316172890365124
step: 450, loss: 3.5338707675691694e-05
step: 460, loss: 1.7136031601694413e-05
step: 470, loss: 1.7918046069098637e-05
step: 480, loss: 4.555228224489838e-05
step: 490, loss: 3.1327119359048083e-05
step: 500, loss: 1.8741307940217666e-05
step: 510, loss: 2.8331412977422588e-05
step: 520, loss: 1.7460017261328176e-05
step: 530, loss: 1.366789911116939e-05
epoch 20: dev_f1=0.7659955257270693, f1=0.6467236467236467, best_f1=0.6797445255474452
