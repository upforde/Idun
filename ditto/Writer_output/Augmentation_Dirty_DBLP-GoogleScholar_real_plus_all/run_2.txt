cuda
Device: cuda
step: 0, loss: 1.0159804821014404
step: 10, loss: 0.42869433760643005
step: 20, loss: 0.3767278492450714
step: 30, loss: 0.35061582922935486
step: 40, loss: 0.435325562953949
step: 50, loss: 0.24178819358348846
step: 60, loss: 0.21279141306877136
step: 70, loss: 0.14932018518447876
step: 80, loss: 0.19148613512516022
step: 90, loss: 0.2332272082567215
step: 100, loss: 0.1873970627784729
step: 110, loss: 0.1172257587313652
step: 120, loss: 0.07350925356149673
step: 130, loss: 0.28126102685928345
step: 140, loss: 0.1770721971988678
step: 150, loss: 0.12293536216020584
step: 160, loss: 0.07718195021152496
step: 170, loss: 0.16465727984905243
step: 180, loss: 0.1668805330991745
step: 190, loss: 0.1632167398929596
step: 200, loss: 0.22626149654388428
step: 210, loss: 0.26281705498695374
step: 220, loss: 0.18075598776340485
step: 230, loss: 0.1564439833164215
step: 240, loss: 0.09969839453697205
step: 250, loss: 0.05360604450106621
step: 260, loss: 0.10575427114963531
step: 270, loss: 0.09878190606832504
step: 280, loss: 0.2856043875217438
step: 290, loss: 0.05650009587407112
step: 300, loss: 0.09257074445486069
step: 310, loss: 0.18367257714271545
step: 320, loss: 0.13456206023693085
step: 330, loss: 0.15898223221302032
step: 340, loss: 0.24179208278656006
step: 350, loss: 0.23427428305149078
step: 360, loss: 0.2087823450565338
step: 370, loss: 0.24565918743610382
step: 380, loss: 0.17113971710205078
step: 390, loss: 0.06875743716955185
step: 400, loss: 0.13794593513011932
step: 410, loss: 0.18900099396705627
step: 420, loss: 0.04693734645843506
step: 430, loss: 0.16697894036769867
step: 440, loss: 0.16191381216049194
step: 450, loss: 0.24870456755161285
step: 460, loss: 0.22230298817157745
step: 470, loss: 0.09357614815235138
step: 480, loss: 0.1305811107158661
step: 490, loss: 0.2205614447593689
step: 500, loss: 0.1561433970928192
step: 510, loss: 0.15082740783691406
step: 520, loss: 0.08573567867279053
step: 530, loss: 0.09120139479637146
step: 540, loss: 0.06671567261219025
step: 550, loss: 0.15605276823043823
step: 560, loss: 0.1415201723575592
step: 570, loss: 0.14636002480983734
step: 580, loss: 0.30122441053390503
step: 590, loss: 0.09516643732786179
step: 600, loss: 0.15526847541332245
step: 610, loss: 0.21230000257492065
step: 620, loss: 0.13058894872665405
step: 630, loss: 0.11565642058849335
step: 640, loss: 0.059018976986408234
step: 650, loss: 0.1486297994852066
step: 660, loss: 0.24909591674804688
step: 670, loss: 0.07524517923593521
step: 680, loss: 0.04036937281489372
step: 690, loss: 0.1021837368607521
step: 700, loss: 0.15560896694660187
step: 710, loss: 0.23308251798152924
step: 720, loss: 0.06964867562055588
step: 730, loss: 0.27063286304473877
step: 740, loss: 0.17457441985607147
step: 750, loss: 0.058646734803915024
step: 760, loss: 0.24423423409461975
step: 770, loss: 0.11518854647874832
step: 780, loss: 0.1391187161207199
step: 790, loss: 0.22873707115650177
step: 800, loss: 0.11444386839866638
step: 810, loss: 0.21758770942687988
step: 820, loss: 0.18882626295089722
step: 830, loss: 0.0663643553853035
step: 840, loss: 0.15718236565589905
step: 850, loss: 0.0843319445848465
step: 860, loss: 0.12646910548210144
step: 870, loss: 0.25740328431129456
step: 880, loss: 0.13600173592567444
step: 890, loss: 0.19532953202724457
step: 900, loss: 0.30838820338249207
step: 910, loss: 0.14015595614910126
step: 920, loss: 0.08591986447572708
step: 930, loss: 0.06823195517063141
step: 940, loss: 0.08483761548995972
step: 950, loss: 0.19936814904212952
step: 960, loss: 0.08225135505199432
step: 970, loss: 0.21363013982772827
step: 980, loss: 0.12369391322135925
step: 990, loss: 0.12086009234189987
step: 1000, loss: 0.14245735108852386
step: 1010, loss: 0.061152879148721695
step: 1020, loss: 0.2706683874130249
step: 1030, loss: 0.13119745254516602
step: 1040, loss: 0.08149199932813644
step: 1050, loss: 0.08273366093635559
step: 1060, loss: 0.09830860048532486
step: 1070, loss: 0.05800705403089523
epoch 1: dev_f1=0.9123451124368976, f1=0.9137380191693291, best_f1=0.9137380191693291
step: 0, loss: 0.12240513414144516
step: 10, loss: 0.2570982277393341
step: 20, loss: 0.07357025891542435
step: 30, loss: 0.12117434293031693
step: 40, loss: 0.2821394205093384
step: 50, loss: 0.17948976159095764
step: 60, loss: 0.2049751877784729
step: 70, loss: 0.00802435539662838
step: 80, loss: 0.14313672482967377
step: 90, loss: 0.16491904854774475
step: 100, loss: 0.08106279373168945
step: 110, loss: 0.13869266211986542
step: 120, loss: 0.09041823446750641
step: 130, loss: 0.24609002470970154
step: 140, loss: 0.2780756652355194
step: 150, loss: 0.03386692702770233
step: 160, loss: 0.09063379466533661
step: 170, loss: 0.1082141324877739
step: 180, loss: 0.19524510204792023
step: 190, loss: 0.09137330949306488
step: 200, loss: 0.03614039719104767
step: 210, loss: 0.09646507352590561
step: 220, loss: 0.0957973301410675
step: 230, loss: 0.12472166121006012
step: 240, loss: 0.11675161868333817
step: 250, loss: 0.1609494984149933
step: 260, loss: 0.15411463379859924
step: 270, loss: 0.04554600268602371
step: 280, loss: 0.06788970530033112
step: 290, loss: 0.0003340047551319003
step: 300, loss: 0.13350485265254974
step: 310, loss: 0.13894982635974884
step: 320, loss: 0.19376704096794128
step: 330, loss: 0.16677013039588928
step: 340, loss: 0.02202143333852291
step: 350, loss: 0.13062836229801178
step: 360, loss: 0.05733264237642288
step: 370, loss: 0.07623559236526489
step: 380, loss: 0.3521248698234558
step: 390, loss: 0.08882781118154526
step: 400, loss: 0.15775083005428314
step: 410, loss: 0.10854808986186981
step: 420, loss: 0.04593166708946228
step: 430, loss: 0.18487931787967682
step: 440, loss: 0.09412983804941177
step: 450, loss: 0.14984595775604248
step: 460, loss: 0.12354040145874023
step: 470, loss: 0.1789000779390335
step: 480, loss: 0.1947336196899414
step: 490, loss: 0.05615455284714699
step: 500, loss: 0.1288224756717682
step: 510, loss: 0.1185632273554802
step: 520, loss: 0.16997340321540833
step: 530, loss: 0.1267315000295639
step: 540, loss: 0.12753808498382568
step: 550, loss: 0.12112928926944733
step: 560, loss: 0.13273215293884277
step: 570, loss: 0.14965222775936127
step: 580, loss: 0.11143449693918228
step: 590, loss: 0.14129722118377686
step: 600, loss: 0.11733025312423706
step: 610, loss: 0.0512128584086895
step: 620, loss: 0.25955578684806824
step: 630, loss: 0.10593545436859131
step: 640, loss: 0.12923361361026764
step: 650, loss: 0.03192566707730293
step: 660, loss: 0.14425206184387207
step: 670, loss: 0.09671224653720856
step: 680, loss: 0.014936086721718311
step: 690, loss: 0.045521292835474014
step: 700, loss: 0.11173219233751297
step: 710, loss: 0.15803468227386475
step: 720, loss: 0.046377018094062805
step: 730, loss: 0.01950819045305252
step: 740, loss: 0.056287843734025955
step: 750, loss: 0.03749017417430878
step: 760, loss: 0.12592865526676178
step: 770, loss: 0.1070103645324707
step: 780, loss: 0.11411929875612259
step: 790, loss: 0.14101286232471466
step: 800, loss: 0.1659623086452484
step: 810, loss: 0.08844427019357681
step: 820, loss: 0.06698369979858398
step: 830, loss: 0.18186268210411072
step: 840, loss: 0.05994422361254692
step: 850, loss: 0.09468014538288116
step: 860, loss: 0.1999279409646988
step: 870, loss: 0.08913079649209976
step: 880, loss: 0.10610485076904297
step: 890, loss: 0.07122693955898285
step: 900, loss: 0.11842779815196991
step: 910, loss: 0.03188611939549446
step: 920, loss: 0.07447777688503265
step: 930, loss: 0.12202461808919907
step: 940, loss: 0.07350233197212219
step: 950, loss: 0.1155206635594368
step: 960, loss: 0.06300464272499084
step: 970, loss: 0.2836900055408478
step: 980, loss: 0.16749845445156097
step: 990, loss: 0.21062013506889343
step: 1000, loss: 0.19615687429904938
step: 1010, loss: 0.11395799368619919
step: 1020, loss: 0.11105027794837952
step: 1030, loss: 0.0753040611743927
step: 1040, loss: 0.18238036334514618
step: 1050, loss: 0.06221477687358856
step: 1060, loss: 0.2125261127948761
step: 1070, loss: 0.14919792115688324
epoch 2: dev_f1=0.9257918552036198, f1=0.9249547920433996, best_f1=0.9249547920433996
step: 0, loss: 0.2034764289855957
step: 10, loss: 0.07346709817647934
step: 20, loss: 0.13512523472309113
step: 30, loss: 0.16358214616775513
step: 40, loss: 0.05330755189061165
step: 50, loss: 0.1106591671705246
step: 60, loss: 0.23293179273605347
step: 70, loss: 0.14734672009944916
step: 80, loss: 0.028555193915963173
step: 90, loss: 0.05426284298300743
step: 100, loss: 0.18677574396133423
step: 110, loss: 0.19891595840454102
step: 120, loss: 0.040833260864019394
step: 130, loss: 0.067406564950943
step: 140, loss: 0.0541742704808712
step: 150, loss: 0.11853893101215363
step: 160, loss: 0.044458210468292236
step: 170, loss: 0.019901959225535393
step: 180, loss: 0.0621383860707283
step: 190, loss: 0.12968862056732178
step: 200, loss: 0.03137831762433052
step: 210, loss: 0.4012641906738281
step: 220, loss: 0.06758067011833191
step: 230, loss: 0.08139031380414963
step: 240, loss: 0.10695755481719971
step: 250, loss: 0.22764506936073303
step: 260, loss: 0.14286519587039948
step: 270, loss: 0.15143777430057526
step: 280, loss: 0.1635173261165619
step: 290, loss: 0.04142161086201668
step: 300, loss: 0.12428257614374161
step: 310, loss: 0.03670920431613922
step: 320, loss: 0.027790458872914314
step: 330, loss: 0.25203758478164673
step: 340, loss: 0.04264146089553833
step: 350, loss: 0.055995773524045944
step: 360, loss: 0.1697852462530136
step: 370, loss: 0.07133181393146515
step: 380, loss: 0.1113506630063057
step: 390, loss: 0.10450467467308044
step: 400, loss: 0.03569616749882698
step: 410, loss: 0.12613877654075623
step: 420, loss: 0.09986335784196854
step: 430, loss: 0.04611560329794884
step: 440, loss: 0.04646072909235954
step: 450, loss: 0.11444373428821564
step: 460, loss: 0.17781531810760498
step: 470, loss: 0.04991903901100159
step: 480, loss: 0.20257894694805145
step: 490, loss: 0.12371112406253815
step: 500, loss: 0.04489193856716156
step: 510, loss: 0.06681603193283081
step: 520, loss: 0.11304119974374771
step: 530, loss: 0.1888301819562912
step: 540, loss: 0.141678586602211
step: 550, loss: 0.06766773015260696
step: 560, loss: 0.10734771192073822
step: 570, loss: 0.1441754400730133
step: 580, loss: 0.11102456599473953
step: 590, loss: 0.055107396095991135
step: 600, loss: 0.14220508933067322
step: 610, loss: 0.10694153606891632
step: 620, loss: 0.03659313544631004
step: 630, loss: 0.13227415084838867
step: 640, loss: 0.18053534626960754
step: 650, loss: 0.11809912323951721
step: 660, loss: 0.0967060923576355
step: 670, loss: 0.12675616145133972
step: 680, loss: 0.06896133720874786
step: 690, loss: 0.20480144023895264
step: 700, loss: 0.13883092999458313
step: 710, loss: 0.06364746391773224
step: 720, loss: 0.1532318890094757
step: 730, loss: 0.06410668790340424
step: 740, loss: 0.010468358173966408
step: 750, loss: 0.03177766129374504
step: 760, loss: 0.06115984544157982
step: 770, loss: 0.16937752068042755
step: 780, loss: 0.0369175560772419
step: 790, loss: 0.1695566028356552
step: 800, loss: 0.18693751096725464
step: 810, loss: 0.03832953795790672
step: 820, loss: 0.14207082986831665
step: 830, loss: 0.11049668490886688
step: 840, loss: 0.2029791921377182
step: 850, loss: 0.14204081892967224
step: 860, loss: 0.23062722384929657
step: 870, loss: 0.051194410771131516
step: 880, loss: 0.05390218645334244
step: 890, loss: 0.07285558432340622
step: 900, loss: 0.14101417362689972
step: 910, loss: 0.1798507273197174
step: 920, loss: 0.20015086233615875
step: 930, loss: 0.10429955273866653
step: 940, loss: 0.09970144182443619
step: 950, loss: 0.10687057673931122
step: 960, loss: 0.06460296362638474
step: 970, loss: 0.17198115587234497
step: 980, loss: 0.12110070884227753
step: 990, loss: 0.10015887022018433
step: 1000, loss: 0.17671990394592285
step: 1010, loss: 0.12086576223373413
step: 1020, loss: 0.19042912125587463
step: 1030, loss: 0.05639959126710892
step: 1040, loss: 0.13610023260116577
step: 1050, loss: 0.14800986647605896
step: 1060, loss: 0.11387746781110764
step: 1070, loss: 0.09625065326690674
epoch 3: dev_f1=0.9387564282374942, f1=0.9341983317886932, best_f1=0.9341983317886932
step: 0, loss: 0.0450422503054142
step: 10, loss: 0.146468386054039
step: 20, loss: 0.12448929995298386
step: 30, loss: 0.10315598547458649
step: 40, loss: 0.05361847206950188
step: 50, loss: 0.07637802511453629
step: 60, loss: 0.03548424318432808
step: 70, loss: 0.07599493116140366
step: 80, loss: 0.08078351616859436
step: 90, loss: 0.13754205405712128
step: 100, loss: 0.1487494260072708
step: 110, loss: 0.0638897716999054
step: 120, loss: 0.14793342351913452
step: 130, loss: 0.13793566823005676
step: 140, loss: 0.22697512805461884
step: 150, loss: 0.01562244351953268
step: 160, loss: 0.12049172073602676
step: 170, loss: 0.1854676753282547
step: 180, loss: 0.12461254000663757
step: 190, loss: 0.24786363542079926
step: 200, loss: 0.09605954587459564
step: 210, loss: 0.14447200298309326
step: 220, loss: 0.06916611641645432
step: 230, loss: 0.08135724067687988
step: 240, loss: 0.12771086394786835
step: 250, loss: 0.049793630838394165
step: 260, loss: 0.25185638666152954
step: 270, loss: 0.09258832037448883
step: 280, loss: 0.14749257266521454
step: 290, loss: 0.05942220613360405
step: 300, loss: 0.0750744491815567
step: 310, loss: 0.057079117745161057
step: 320, loss: 0.08942686766386032
step: 330, loss: 0.115776427090168
step: 340, loss: 0.04269840195775032
step: 350, loss: 0.05830257013440132
step: 360, loss: 0.06532340496778488
step: 370, loss: 0.10162973403930664
step: 380, loss: 0.0657225251197815
step: 390, loss: 0.09010044485330582
step: 400, loss: 0.023525899276137352
step: 410, loss: 0.02485092356801033
step: 420, loss: 0.1910272240638733
step: 430, loss: 0.08253508061170578
step: 440, loss: 0.046307675540447235
step: 450, loss: 0.19501346349716187
step: 460, loss: 0.13405723869800568
step: 470, loss: 0.10038302093744278
step: 480, loss: 0.01353558711707592
step: 490, loss: 0.06086333468556404
step: 500, loss: 0.028360731899738312
step: 510, loss: 0.10447923094034195
step: 520, loss: 0.0008599637076258659
step: 530, loss: 0.04693678766489029
step: 540, loss: 0.1430305540561676
step: 550, loss: 0.039171814918518066
step: 560, loss: 0.11998090147972107
step: 570, loss: 0.09611712396144867
step: 580, loss: 0.11484508961439133
step: 590, loss: 0.09384534507989883
step: 600, loss: 0.06359036266803741
step: 610, loss: 0.07210464030504227
step: 620, loss: 0.13046520948410034
step: 630, loss: 0.33754754066467285
step: 640, loss: 0.06141047179698944
step: 650, loss: 0.19567552208900452
step: 660, loss: 0.13231295347213745
step: 670, loss: 0.05684267356991768
step: 680, loss: 0.1098986342549324
step: 690, loss: 0.1440766602754593
step: 700, loss: 0.10244763642549515
step: 710, loss: 0.10991635918617249
step: 720, loss: 0.1108027771115303
step: 730, loss: 0.07749821245670319
step: 740, loss: 0.0911303162574768
step: 750, loss: 0.08511245995759964
step: 760, loss: 0.10218136757612228
step: 770, loss: 0.13823004066944122
step: 780, loss: 0.14762744307518005
step: 790, loss: 0.17211121320724487
step: 800, loss: 0.12720410525798798
step: 810, loss: 0.16263724863529205
step: 820, loss: 0.01683237962424755
step: 830, loss: 0.06432486325502396
step: 840, loss: 0.1491273194551468
step: 850, loss: 0.16373777389526367
step: 860, loss: 0.13402239978313446
step: 870, loss: 0.04106844961643219
step: 880, loss: 0.06722473353147507
step: 890, loss: 0.28492093086242676
step: 900, loss: 0.14464206993579865
step: 910, loss: 0.19079357385635376
step: 920, loss: 0.16508737206459045
step: 930, loss: 0.05477932095527649
step: 940, loss: 0.09195935726165771
step: 950, loss: 0.07521557062864304
step: 960, loss: 0.04630601033568382
step: 970, loss: 0.01565290056169033
step: 980, loss: 0.008505661971867085
step: 990, loss: 0.374051958322525
step: 1000, loss: 0.07721002399921417
step: 1010, loss: 0.16928598284721375
step: 1020, loss: 0.18635956943035126
step: 1030, loss: 0.09745383262634277
step: 1040, loss: 0.09970150142908096
step: 1050, loss: 0.282196581363678
step: 1060, loss: 0.03921303525567055
step: 1070, loss: 0.1401420533657074
epoch 4: dev_f1=0.9277777777777779, f1=0.9252767527675276, best_f1=0.9341983317886932
step: 0, loss: 0.0969121903181076
step: 10, loss: 0.06860662996768951
step: 20, loss: 0.06507278233766556
step: 30, loss: 0.09286564588546753
step: 40, loss: 0.13849079608917236
step: 50, loss: 0.11029596626758575
step: 60, loss: 0.10425232350826263
step: 70, loss: 0.038915764540433884
step: 80, loss: 0.13623692095279694
step: 90, loss: 0.11777280271053314
step: 100, loss: 0.02557314932346344
step: 110, loss: 0.010146938264369965
step: 120, loss: 0.04865081608295441
step: 130, loss: 0.09255252778530121
step: 140, loss: 0.12048837542533875
step: 150, loss: 0.07966847717761993
step: 160, loss: 0.05793863907456398
step: 170, loss: 0.0642259493470192
step: 180, loss: 0.017775744199752808
step: 190, loss: 0.0920952558517456
step: 200, loss: 0.08081549406051636
step: 210, loss: 0.09234941750764847
step: 220, loss: 0.08419504016637802
step: 230, loss: 0.24593226611614227
step: 240, loss: 0.014595568180084229
step: 250, loss: 0.055638499557971954
step: 260, loss: 0.06249912828207016
step: 270, loss: 0.05103335902094841
step: 280, loss: 0.015072536654770374
step: 290, loss: 0.04958537966012955
step: 300, loss: 0.06880596280097961
step: 310, loss: 0.06775643676519394
step: 320, loss: 0.1369589865207672
step: 330, loss: 0.12999755144119263
step: 340, loss: 0.0828220546245575
step: 350, loss: 0.1473245918750763
step: 360, loss: 0.218997985124588
step: 370, loss: 0.20994724333286285
step: 380, loss: 0.041640885174274445
step: 390, loss: 0.15278340876102448
step: 400, loss: 0.07027158886194229
step: 410, loss: 0.07525957375764847
step: 420, loss: 0.1391512006521225
step: 430, loss: 0.06349547952413559
step: 440, loss: 0.10745207220315933
step: 450, loss: 0.039827290922403336
step: 460, loss: 0.0738098993897438
step: 470, loss: 0.08338570594787598
step: 480, loss: 0.07152385264635086
step: 490, loss: 0.055283840745687485
step: 500, loss: 0.12117483466863632
step: 510, loss: 0.013916445896029472
step: 520, loss: 0.09220843017101288
step: 530, loss: 0.11567235738039017
step: 540, loss: 0.07328199595212936
step: 550, loss: 0.05680844187736511
step: 560, loss: 0.06585098057985306
step: 570, loss: 0.10731999576091766
step: 580, loss: 0.05815935879945755
step: 590, loss: 0.10266221314668655
step: 600, loss: 0.09210145473480225
step: 610, loss: 0.08426489681005478
step: 620, loss: 0.061201177537441254
step: 630, loss: 0.12198592722415924
step: 640, loss: 0.04803766682744026
step: 650, loss: 0.13309401273727417
step: 660, loss: 0.10444845259189606
step: 670, loss: 0.08030153810977936
step: 680, loss: 0.07886192202568054
step: 690, loss: 0.17069318890571594
step: 700, loss: 0.06332306563854218
step: 710, loss: 0.0344606414437294
step: 720, loss: 0.05718115717172623
step: 730, loss: 0.06547905504703522
step: 740, loss: 0.11039207130670547
step: 750, loss: 0.07171257585287094
step: 760, loss: 0.14327819645404816
step: 770, loss: 0.11028320342302322
step: 780, loss: 0.02551901340484619
step: 790, loss: 0.10661402344703674
step: 800, loss: 0.10605533421039581
step: 810, loss: 0.04958697035908699
step: 820, loss: 0.00010358443250879645
step: 830, loss: 0.09297602623701096
step: 840, loss: 0.10770080238580704
step: 850, loss: 0.05612598732113838
step: 860, loss: 0.19779060781002045
step: 870, loss: 0.11702734231948853
step: 880, loss: 0.12328769266605377
step: 890, loss: 0.08444036543369293
step: 900, loss: 0.08435986936092377
step: 910, loss: 0.15772756934165955
step: 920, loss: 0.10850120335817337
step: 930, loss: 0.1686716079711914
step: 940, loss: 0.05087560415267944
step: 950, loss: 0.15189707279205322
step: 960, loss: 0.04612541198730469
step: 970, loss: 0.043151628226041794
step: 980, loss: 0.10046403855085373
step: 990, loss: 0.10725788027048111
step: 1000, loss: 0.07703091949224472
step: 1010, loss: 0.11806710809469223
step: 1020, loss: 0.053766533732414246
step: 1030, loss: 0.16235452890396118
step: 1040, loss: 0.06273787468671799
step: 1050, loss: 0.08156076073646545
step: 1060, loss: 0.12031350284814835
step: 1070, loss: 0.07911503314971924
epoch 5: dev_f1=0.9310661764705882, f1=0.9155963302752294, best_f1=0.9341983317886932
step: 0, loss: 0.19856327772140503
step: 10, loss: 0.04549902305006981
step: 20, loss: 0.09279339760541916
step: 30, loss: 0.06861649453639984
step: 40, loss: 0.04277578741312027
step: 50, loss: 0.1261068731546402
step: 60, loss: 0.03608783707022667
step: 70, loss: 0.11698944866657257
step: 80, loss: 0.09422037750482559
step: 90, loss: 0.10290420800447464
step: 100, loss: 0.041569896042346954
step: 110, loss: 0.11358438432216644
step: 120, loss: 0.007353002205491066
step: 130, loss: 0.07555556297302246
step: 140, loss: 0.04331257566809654
step: 150, loss: 0.022337133064866066
step: 160, loss: 0.05068974196910858
step: 170, loss: 0.13285072147846222
step: 180, loss: 0.09646124392747879
step: 190, loss: 0.034107670187950134
step: 200, loss: 0.1022609993815422
step: 210, loss: 0.044037021696567535
step: 220, loss: 0.0682922825217247
step: 230, loss: 0.09392497688531876
step: 240, loss: 0.02849690057337284
step: 250, loss: 0.11621714383363724
step: 260, loss: 0.12120546400547028
step: 270, loss: 0.09263937920331955
step: 280, loss: 0.06921564042568207
step: 290, loss: 0.0459192618727684
step: 300, loss: 0.08111711591482162
step: 310, loss: 0.1638694554567337
step: 320, loss: 0.08116760849952698
step: 330, loss: 0.1748620569705963
step: 340, loss: 0.012787330895662308
step: 350, loss: 0.07416832447052002
step: 360, loss: 0.05607069656252861
step: 370, loss: 0.0416669026017189
step: 380, loss: 0.111297108232975
step: 390, loss: 0.04353874921798706
step: 400, loss: 0.06411832571029663
step: 410, loss: 0.055406901985406876
step: 420, loss: 0.0793023407459259
step: 430, loss: 0.07771749794483185
step: 440, loss: 0.02038099244236946
step: 450, loss: 0.14481323957443237
step: 460, loss: 0.054516855627298355
step: 470, loss: 0.0690048485994339
step: 480, loss: 0.06543759256601334
step: 490, loss: 0.008348910138010979
step: 500, loss: 0.012247765436768532
step: 510, loss: 0.09404604136943817
step: 520, loss: 0.026538364589214325
step: 530, loss: 0.06535026431083679
step: 540, loss: 0.02689126878976822
step: 550, loss: 0.12948089838027954
step: 560, loss: 0.0916445180773735
step: 570, loss: 0.08735313266515732
step: 580, loss: 0.18767708539962769
step: 590, loss: 0.13883273303508759
step: 600, loss: 0.17533470690250397
step: 610, loss: 0.11485494673252106
step: 620, loss: 0.0629323199391365
step: 630, loss: 0.061255913227796555
step: 640, loss: 0.1964818835258484
step: 650, loss: 0.10467040538787842
step: 660, loss: 0.1007598415017128
step: 670, loss: 0.05496861785650253
step: 680, loss: 0.03798215836286545
step: 690, loss: 0.1680891513824463
step: 700, loss: 0.046488843858242035
step: 710, loss: 0.163786843419075
step: 720, loss: 0.041867807507514954
step: 730, loss: 0.12330883741378784
step: 740, loss: 0.15992474555969238
step: 750, loss: 0.2654584050178528
step: 760, loss: 0.1575108766555786
step: 770, loss: 0.0816798284649849
step: 780, loss: 0.12978875637054443
step: 790, loss: 0.13198010623455048
step: 800, loss: 0.02591293677687645
step: 810, loss: 0.08566277474164963
step: 820, loss: 0.09700839966535568
step: 830, loss: 0.08457822352647781
step: 840, loss: 0.06269770115613937
step: 850, loss: 0.06892025470733643
step: 860, loss: 0.08732685446739197
step: 870, loss: 0.08284524083137512
step: 880, loss: 0.06266713887453079
step: 890, loss: 0.14997218549251556
step: 900, loss: 0.119962677359581
step: 910, loss: 0.19302843511104584
step: 920, loss: 0.08527850359678268
step: 930, loss: 0.10947393625974655
step: 940, loss: 0.014522857032716274
step: 950, loss: 0.08813358098268509
step: 960, loss: 0.029020801186561584
step: 970, loss: 0.10697852075099945
step: 980, loss: 0.050263188779354095
step: 990, loss: 0.15434879064559937
step: 1000, loss: 0.0491177923977375
step: 1010, loss: 0.019803421571850777
step: 1020, loss: 0.09570588916540146
step: 1030, loss: 0.06149083003401756
step: 1040, loss: 0.12214086949825287
step: 1050, loss: 0.13508445024490356
step: 1060, loss: 0.10380887240171432
step: 1070, loss: 0.13020648062229156
epoch 6: dev_f1=0.9251950435979808, f1=0.9182736455463728, best_f1=0.9341983317886932
step: 0, loss: 0.1271529346704483
step: 10, loss: 0.12644127011299133
step: 20, loss: 0.049234673380851746
step: 30, loss: 0.0622839517891407
step: 40, loss: 0.1099182665348053
step: 50, loss: 0.11101681739091873
step: 60, loss: 0.12088775634765625
step: 70, loss: 0.04732871800661087
step: 80, loss: 0.06493259221315384
step: 90, loss: 0.08220311254262924
step: 100, loss: 0.04103872552514076
step: 110, loss: 0.13580268621444702
step: 120, loss: 0.01780496910214424
step: 130, loss: 0.10040032118558884
step: 140, loss: 0.12141381949186325
step: 150, loss: 0.17359347641468048
step: 160, loss: 0.059413615614175797
step: 170, loss: 0.08679310232400894
step: 180, loss: 0.15424323081970215
step: 190, loss: 0.018593043088912964
step: 200, loss: 9.452806989429519e-05
step: 210, loss: 0.13232100009918213
step: 220, loss: 0.04391076788306236
step: 230, loss: 0.08418702334165573
step: 240, loss: 0.015220805071294308
step: 250, loss: 0.07466607540845871
step: 260, loss: 0.14712750911712646
step: 270, loss: 0.06576735526323318
step: 280, loss: 0.16577334702014923
step: 290, loss: 0.15671220421791077
step: 300, loss: 0.032643817365169525
step: 310, loss: 0.05827745795249939
step: 320, loss: 0.008859852328896523
step: 330, loss: 0.2397060990333557
step: 340, loss: 0.10765109956264496
step: 350, loss: 0.093857541680336
step: 360, loss: 0.04588595777750015
step: 370, loss: 0.03600868955254555
step: 380, loss: 0.07254122942686081
step: 390, loss: 0.14394354820251465
step: 400, loss: 0.09146759659051895
step: 410, loss: 0.12539449334144592
step: 420, loss: 0.15105266869068146
step: 430, loss: 0.04935136064887047
step: 440, loss: 0.05996914580464363
step: 450, loss: 0.09598168730735779
step: 460, loss: 0.10377079248428345
step: 470, loss: 0.09156230837106705
step: 480, loss: 0.061539147049188614
step: 490, loss: 0.04516928270459175
step: 500, loss: 0.1486874669790268
step: 510, loss: 0.18322564661502838
step: 520, loss: 0.18520072102546692
step: 530, loss: 0.0972864031791687
step: 540, loss: 0.09269993007183075
step: 550, loss: 0.1315309852361679
step: 560, loss: 0.05948002263903618
step: 570, loss: 0.1070435419678688
step: 580, loss: 0.079792819917202
step: 590, loss: 0.09108322113752365
step: 600, loss: 0.06226182356476784
step: 610, loss: 0.09824743121862411
step: 620, loss: 0.008637599647045135
step: 630, loss: 0.10045557469129562
step: 640, loss: 0.07373746484518051
step: 650, loss: 0.11388958990573883
step: 660, loss: 0.11394179612398148
step: 670, loss: 0.20304933190345764
step: 680, loss: 0.09883525967597961
step: 690, loss: 0.11252020299434662
step: 700, loss: 0.1765226274728775
step: 710, loss: 0.061274487525224686
step: 720, loss: 0.04894356057047844
step: 730, loss: 0.07804117351770401
step: 740, loss: 0.09041386842727661
step: 750, loss: 0.04229634255170822
step: 760, loss: 0.048206329345703125
step: 770, loss: 0.03950023651123047
step: 780, loss: 0.13684484362602234
step: 790, loss: 0.0891013965010643
step: 800, loss: 0.10084318369626999
step: 810, loss: 0.10825679451227188
step: 820, loss: 0.11987026035785675
step: 830, loss: 0.14387086033821106
step: 840, loss: 0.11314117908477783
step: 850, loss: 0.11219765245914459
step: 860, loss: 0.10007129609584808
step: 870, loss: 0.13027343153953552
step: 880, loss: 0.0628601685166359
step: 890, loss: 0.06657455116510391
step: 900, loss: 0.009257436729967594
step: 910, loss: 0.0863063707947731
step: 920, loss: 0.09514536708593369
step: 930, loss: 0.14938804507255554
step: 940, loss: 0.025284122675657272
step: 950, loss: 0.031108995899558067
step: 960, loss: 0.16730251908302307
step: 970, loss: 0.04942846670746803
step: 980, loss: 0.11936265975236893
step: 990, loss: 0.04598930850625038
step: 1000, loss: 0.0489753820002079
step: 1010, loss: 0.08662596344947815
step: 1020, loss: 0.14052172005176544
step: 1030, loss: 0.07095427066087723
step: 1040, loss: 0.055609382688999176
step: 1050, loss: 0.04783787950873375
step: 1060, loss: 0.09843030571937561
step: 1070, loss: 0.04010673612356186
epoch 7: dev_f1=0.9303184125519152, f1=0.925925925925926, best_f1=0.9341983317886932
step: 0, loss: 0.09861397743225098
step: 10, loss: 0.06931948661804199
step: 20, loss: 0.08124527335166931
step: 30, loss: 0.04366665706038475
step: 40, loss: 0.0640619695186615
step: 50, loss: 0.060065459460020065
step: 60, loss: 0.04843198135495186
step: 70, loss: 0.0914912298321724
step: 80, loss: 0.07990759611129761
step: 90, loss: 0.07174217700958252
step: 100, loss: 0.13198837637901306
step: 110, loss: 0.06788355112075806
step: 120, loss: 0.18132692575454712
step: 130, loss: 0.012238468043506145
step: 140, loss: 0.005635411012917757
step: 150, loss: 0.010371172800660133
step: 160, loss: 0.06736747920513153
step: 170, loss: 0.08661945164203644
step: 180, loss: 0.056543733924627304
step: 190, loss: 0.057365961372852325
step: 200, loss: 0.09371969103813171
step: 210, loss: 0.07456793636083603
step: 220, loss: 0.1796114146709442
step: 230, loss: 0.05255341902375221
step: 240, loss: 0.05257972702383995
step: 250, loss: 0.042148903012275696
step: 260, loss: 0.042151812463998795
step: 270, loss: 0.1812545657157898
step: 280, loss: 0.09886908531188965
step: 290, loss: 0.00954064168035984
step: 300, loss: 0.07153704017400742
step: 310, loss: 0.1499353051185608
step: 320, loss: 0.04249272868037224
step: 330, loss: 0.11117713153362274
step: 340, loss: 0.06693687289953232
step: 350, loss: 0.0834631472826004
step: 360, loss: 0.05729113519191742
step: 370, loss: 0.02331586182117462
step: 380, loss: 0.07432588934898376
step: 390, loss: 0.24064040184020996
step: 400, loss: 0.08568312972784042
step: 410, loss: 0.031977925449609756
step: 420, loss: 0.14220978319644928
step: 430, loss: 0.020161354914307594
step: 440, loss: 0.08049356192350388
step: 450, loss: 0.16243654489517212
step: 460, loss: 0.08397255092859268
step: 470, loss: 0.07106750458478928
step: 480, loss: 0.10078940540552139
step: 490, loss: 0.13766203820705414
step: 500, loss: 0.01715926267206669
step: 510, loss: 0.04715242609381676
step: 520, loss: 0.14534570276737213
step: 530, loss: 0.06090756133198738
step: 540, loss: 0.08925582468509674
step: 550, loss: 0.14818185567855835
step: 560, loss: 0.10967858880758286
step: 570, loss: 0.09686031192541122
step: 580, loss: 0.07681389153003693
step: 590, loss: 0.05214647948741913
step: 600, loss: 0.06891290098428726
step: 610, loss: 0.11382210999727249
step: 620, loss: 0.05760693550109863
step: 630, loss: 0.1952383816242218
step: 640, loss: 0.07591604441404343
step: 650, loss: 0.08527390658855438
step: 660, loss: 0.12878385186195374
step: 670, loss: 0.11092057824134827
step: 680, loss: 0.03408055379986763
step: 690, loss: 0.10386966168880463
step: 700, loss: 0.23508509993553162
step: 710, loss: 0.02735929936170578
step: 720, loss: 0.01176910474896431
step: 730, loss: 0.06635984778404236
step: 740, loss: 0.01705794781446457
step: 750, loss: 0.10623795539140701
step: 760, loss: 0.11688622087240219
step: 770, loss: 0.04344809427857399
step: 780, loss: 0.10738184303045273
step: 790, loss: 0.11554288119077682
step: 800, loss: 0.07481778413057327
step: 810, loss: 0.007090071216225624
step: 820, loss: 0.05250682681798935
step: 830, loss: 0.14835821092128754
step: 840, loss: 0.06037937477231026
step: 850, loss: 0.03634844720363617
step: 860, loss: 0.09699225425720215
step: 870, loss: 0.1380116194486618
step: 880, loss: 0.11784239858388901
step: 890, loss: 0.03657202050089836
step: 900, loss: 0.08908648788928986
step: 910, loss: 0.07890059798955917
step: 920, loss: 0.11419820040464401
step: 930, loss: 0.14269670844078064
step: 940, loss: 0.017961082980036736
step: 950, loss: 0.05648656189441681
step: 960, loss: 0.04672228917479515
step: 970, loss: 0.05761655792593956
step: 980, loss: 0.046397607773542404
step: 990, loss: 0.16407853364944458
step: 1000, loss: 0.13435238599777222
step: 1010, loss: 0.11697912961244583
step: 1020, loss: 0.1335584670305252
step: 1030, loss: 0.046428315341472626
step: 1040, loss: 0.08382014185190201
step: 1050, loss: 0.08399444818496704
step: 1060, loss: 0.06275531649589539
step: 1070, loss: 0.2124498039484024
epoch 8: dev_f1=0.9243316719528771, f1=0.9186733303044072, best_f1=0.9341983317886932
step: 0, loss: 0.032633449882268906
step: 10, loss: 0.10403189063072205
step: 20, loss: 0.10127867758274078
step: 30, loss: 0.04893060401082039
step: 40, loss: 0.008460856974124908
step: 50, loss: 0.026834478601813316
step: 60, loss: 0.04209160432219505
step: 70, loss: 0.18643982708454132
step: 80, loss: 0.12560606002807617
step: 90, loss: 0.08192668855190277
step: 100, loss: 0.0013731399085372686
step: 110, loss: 0.08078873157501221
step: 120, loss: 0.0022014256101101637
step: 130, loss: 0.1030321791768074
step: 140, loss: 0.05814889818429947
step: 150, loss: 0.0759720429778099
step: 160, loss: 0.1056913360953331
step: 170, loss: 0.03770521283149719
step: 180, loss: 0.11966455727815628
step: 190, loss: 0.20304174721240997
step: 200, loss: 0.09870406985282898
step: 210, loss: 0.02760949917137623
step: 220, loss: 0.06907720118761063
step: 230, loss: 0.26162925362586975
step: 240, loss: 0.03588918596506119
step: 250, loss: 0.10966131836175919
step: 260, loss: 0.06068606302142143
step: 270, loss: 0.08855003863573074
step: 280, loss: 0.19826056063175201
step: 290, loss: 0.16365300118923187
step: 300, loss: 0.08483386784791946
step: 310, loss: 0.06908997893333435
step: 320, loss: 0.08286973088979721
step: 330, loss: 0.06786290556192398
step: 340, loss: 0.06408236175775528
step: 350, loss: 0.08654151856899261
step: 360, loss: 0.051067374646663666
step: 370, loss: 0.06965906172990799
step: 380, loss: 0.14791002869606018
step: 390, loss: 0.11214558780193329
step: 400, loss: 0.06130978837609291
step: 410, loss: 0.06417743861675262
step: 420, loss: 0.09953846782445908
step: 430, loss: 0.08904679864645004
step: 440, loss: 0.09202621132135391
step: 450, loss: 0.10383559763431549
step: 460, loss: 0.09495257586240768
step: 470, loss: 0.011251695454120636
step: 480, loss: 0.092487633228302
step: 490, loss: 0.1145087480545044
step: 500, loss: 0.06593326479196548
step: 510, loss: 0.11929045617580414
step: 520, loss: 0.06401701271533966
step: 530, loss: 0.10334369540214539
step: 540, loss: 0.06535173952579498
step: 550, loss: 0.30832019448280334
step: 560, loss: 0.03308596834540367
step: 570, loss: 0.050281018018722534
step: 580, loss: 0.06650777906179428
step: 590, loss: 0.08801363408565521
step: 600, loss: 0.165957510471344
step: 610, loss: 0.08146177232265472
step: 620, loss: 0.1513364315032959
step: 630, loss: 0.048171356320381165
step: 640, loss: 0.04926038905978203
step: 650, loss: 0.031556304544210434
step: 660, loss: 0.0647338405251503
step: 670, loss: 0.028034351766109467
step: 680, loss: 0.09045722335577011
step: 690, loss: 0.060437098145484924
step: 700, loss: 0.14850333333015442
step: 710, loss: 0.018386052921414375
step: 720, loss: 0.06069427728652954
step: 730, loss: 0.12491792440414429
step: 740, loss: 0.16143420338630676
step: 750, loss: 0.13839706778526306
step: 760, loss: 0.10634398460388184
step: 770, loss: 0.053275302052497864
step: 780, loss: 0.05823124200105667
step: 790, loss: 0.02879946306347847
step: 800, loss: 0.09075676649808884
step: 810, loss: 0.024512453004717827
step: 820, loss: 0.018888240680098534
step: 830, loss: 0.0412319153547287
step: 840, loss: 0.18317070603370667
step: 850, loss: 0.05964980646967888
step: 860, loss: 0.07767195254564285
step: 870, loss: 0.17734722793102264
step: 880, loss: 0.22335678339004517
step: 890, loss: 0.05459991469979286
step: 900, loss: 0.08669241517782211
step: 910, loss: 0.09444990009069443
step: 920, loss: 0.04160726070404053
step: 930, loss: 0.07624263316392899
step: 940, loss: 0.028246860951185226
step: 950, loss: 0.0645134225487709
step: 960, loss: 0.10893194377422333
step: 970, loss: 0.03405565395951271
step: 980, loss: 0.2086869180202484
step: 990, loss: 0.05813266336917877
step: 1000, loss: 0.17043401300907135
step: 1010, loss: 0.029933899641036987
step: 1020, loss: 0.05139204114675522
step: 1030, loss: 0.02677147090435028
step: 1040, loss: 0.07020038366317749
step: 1050, loss: 0.07466917484998703
step: 1060, loss: 0.029574215412139893
step: 1070, loss: 0.0836820900440216
epoch 9: dev_f1=0.9308584686774942, f1=0.9238625812441968, best_f1=0.9341983317886932
step: 0, loss: 0.06829249858856201
step: 10, loss: 0.04595508798956871
step: 20, loss: 0.031332552433013916
step: 30, loss: 0.004740182310342789
step: 40, loss: 0.0483253039419651
step: 50, loss: 0.0524664968252182
step: 60, loss: 0.02976067364215851
step: 70, loss: 0.09886849671602249
step: 80, loss: 0.03137044608592987
step: 90, loss: 0.04365704581141472
step: 100, loss: 0.11079859733581543
step: 110, loss: 0.0016257606912404299
step: 120, loss: 0.13112866878509521
step: 130, loss: 0.03348645195364952
step: 140, loss: 0.030442921444773674
step: 150, loss: 0.09871503710746765
step: 160, loss: 0.002354058437049389
step: 170, loss: 0.08839617669582367
step: 180, loss: 0.008740792982280254
step: 190, loss: 0.09486859291791916
step: 200, loss: 0.09293565899133682
step: 210, loss: 0.06915063410997391
step: 220, loss: 0.10414845496416092
step: 230, loss: 0.03965267166495323
step: 240, loss: 0.2306196242570877
step: 250, loss: 0.13709446787834167
step: 260, loss: 0.026834992691874504
step: 270, loss: 0.03609283268451691
step: 280, loss: 0.05455625429749489
step: 290, loss: 0.09582405537366867
step: 300, loss: 0.055273592472076416
step: 310, loss: 0.08718865364789963
step: 320, loss: 0.14628084003925323
step: 330, loss: 0.00550451036542654
step: 340, loss: 0.007461615838110447
step: 350, loss: 0.07303464412689209
step: 360, loss: 0.014485843479633331
step: 370, loss: 0.07958255708217621
step: 380, loss: 0.08774961531162262
step: 390, loss: 0.0674615427851677
step: 400, loss: 0.03811994194984436
step: 410, loss: 0.1026468500494957
step: 420, loss: 0.13259421288967133
step: 430, loss: 0.09447366744279861
step: 440, loss: 0.13817979395389557
step: 450, loss: 0.03658924624323845
step: 460, loss: 0.021417174488306046
step: 470, loss: 0.06791041791439056
step: 480, loss: 0.1227220743894577
step: 490, loss: 0.18903879821300507
step: 500, loss: 0.0729571282863617
step: 510, loss: 0.01585744135081768
step: 520, loss: 0.028966132551431656
step: 530, loss: 0.04534609243273735
step: 540, loss: 0.0983145609498024
step: 550, loss: 0.08925220370292664
step: 560, loss: 0.1402219980955124
step: 570, loss: 0.047181375324726105
step: 580, loss: 0.01638992875814438
step: 590, loss: 0.2254398614168167
step: 600, loss: 0.10482807457447052
step: 610, loss: 0.12518955767154694
step: 620, loss: 0.08737880736589432
step: 630, loss: 0.06172472611069679
step: 640, loss: 0.04893019422888756
step: 650, loss: 0.06340061128139496
step: 660, loss: 0.055074118077754974
step: 670, loss: 0.042515844106674194
step: 680, loss: 0.1020173653960228
step: 690, loss: 0.011932077817618847
step: 700, loss: 0.14222678542137146
step: 710, loss: 0.11194425076246262
step: 720, loss: 0.07943709194660187
step: 730, loss: 0.1191364973783493
step: 740, loss: 0.06016181409358978
step: 750, loss: 0.0858675017952919
step: 760, loss: 0.01972227171063423
step: 770, loss: 0.171824648976326
step: 780, loss: 0.0330255888402462
step: 790, loss: 0.07305090129375458
step: 800, loss: 0.16345934569835663
step: 810, loss: 0.051056936383247375
step: 820, loss: 0.1779305338859558
step: 830, loss: 0.0068077100440859795
step: 840, loss: 0.08755093812942505
step: 850, loss: 0.10751635581254959
step: 860, loss: 0.11414996534585953
step: 870, loss: 0.06627339869737625
step: 880, loss: 0.05687154084444046
step: 890, loss: 0.11004789918661118
step: 900, loss: 0.113906629383564
step: 910, loss: 0.025210529565811157
step: 920, loss: 0.04480714350938797
step: 930, loss: 0.07779500633478165
step: 940, loss: 0.02197355031967163
step: 950, loss: 0.09204816073179245
step: 960, loss: 0.05529558286070824
step: 970, loss: 0.09318692982196808
step: 980, loss: 0.045985057950019836
step: 990, loss: 0.08011925965547562
step: 1000, loss: 0.027508573606610298
step: 1010, loss: 0.1580059975385666
step: 1020, loss: 0.09720217436552048
step: 1030, loss: 0.018382029607892036
step: 1040, loss: 0.02616172283887863
step: 1050, loss: 0.05751814693212509
step: 1060, loss: 0.04789289832115173
step: 1070, loss: 0.0405600368976593
epoch 10: dev_f1=0.9271644525881814, f1=0.9272559852670351, best_f1=0.9341983317886932
step: 0, loss: 0.13307732343673706
step: 10, loss: 0.007987942546606064
step: 20, loss: 0.06399158388376236
step: 30, loss: 0.1080373004078865
step: 40, loss: 0.008053879253566265
step: 50, loss: 0.0831017941236496
step: 60, loss: 0.10517869144678116
step: 70, loss: 0.026862002909183502
step: 80, loss: 0.038879502564668655
step: 90, loss: 0.08588176220655441
step: 100, loss: 0.04262816160917282
step: 110, loss: 0.024114567786455154
step: 120, loss: 0.07974190264940262
step: 130, loss: 0.041301749646663666
step: 140, loss: 0.05267331004142761
step: 150, loss: 0.000415738788433373
step: 160, loss: 0.1019853800535202
step: 170, loss: 0.0425189845263958
step: 180, loss: 0.02196916565299034
step: 190, loss: 0.04679550603032112
step: 200, loss: 0.014943879097700119
step: 210, loss: 0.11516382545232773
step: 220, loss: 0.00033173951669596136
step: 230, loss: 0.14675207436084747
step: 240, loss: 0.05583348125219345
step: 250, loss: 0.17060668766498566
step: 260, loss: 0.03734666481614113
step: 270, loss: 0.04668952152132988
step: 280, loss: 0.003405514173209667
step: 290, loss: 0.034775592386722565
step: 300, loss: 0.08538908511400223
step: 310, loss: 0.11899029463529587
step: 320, loss: 0.06022944673895836
step: 330, loss: 0.04498729854822159
step: 340, loss: 0.02506101503968239
step: 350, loss: 0.1008044183254242
step: 360, loss: 0.053116053342819214
step: 370, loss: 0.15595325827598572
step: 380, loss: 0.027510574087500572
step: 390, loss: 0.037281110882759094
step: 400, loss: 0.05541760474443436
step: 410, loss: 0.058711085468530655
step: 420, loss: 0.08323438465595245
step: 430, loss: 0.06238938495516777
step: 440, loss: 0.13958428800106049
step: 450, loss: 0.04613690450787544
step: 460, loss: 0.04031383618712425
step: 470, loss: 0.020150914788246155
step: 480, loss: 0.1435699164867401
step: 490, loss: 0.11517618596553802
step: 500, loss: 0.09275757521390915
step: 510, loss: 0.10222204774618149
step: 520, loss: 0.055178310722112656
step: 530, loss: 0.07704424858093262
step: 540, loss: 0.13703078031539917
step: 550, loss: 0.1362212896347046
step: 560, loss: 0.09702776372432709
step: 570, loss: 0.12721681594848633
step: 580, loss: 0.11565573513507843
step: 590, loss: 0.08637215197086334
step: 600, loss: 0.049272939562797546
step: 610, loss: 0.0370202362537384
step: 620, loss: 0.0986563041806221
step: 630, loss: 0.040706567466259
step: 640, loss: 0.062205273658037186
step: 650, loss: 0.05383559316396713
step: 660, loss: 0.03746823966503143
step: 670, loss: 0.025973111391067505
step: 680, loss: 0.04398786649107933
step: 690, loss: 0.03658563271164894
step: 700, loss: 0.042008932679891586
step: 710, loss: 0.038258492946624756
step: 720, loss: 0.1301220804452896
step: 730, loss: 0.18194977939128876
step: 740, loss: 0.033663444221019745
step: 750, loss: 0.03199431672692299
step: 760, loss: 0.04284389317035675
step: 770, loss: 0.06573868542909622
step: 780, loss: 0.04679771140217781
step: 790, loss: 0.1621064841747284
step: 800, loss: 0.10177075862884521
step: 810, loss: 0.13265591859817505
step: 820, loss: 0.027564637362957
step: 830, loss: 0.08974018692970276
step: 840, loss: 0.10934554040431976
step: 850, loss: 0.034787870943546295
step: 860, loss: 0.0760854035615921
step: 870, loss: 0.062254127115011215
step: 880, loss: 0.11638985574245453
step: 890, loss: 0.18991796672344208
step: 900, loss: 0.1432877779006958
step: 910, loss: 0.12730859220027924
step: 920, loss: 0.1027250587940216
step: 930, loss: 0.11476864665746689
step: 940, loss: 0.04207002371549606
step: 950, loss: 0.16847077012062073
step: 960, loss: 0.07088102400302887
step: 970, loss: 0.09941753000020981
step: 980, loss: 0.04215654730796814
step: 990, loss: 0.12351382523775101
step: 1000, loss: 0.1171875
step: 1010, loss: 0.0075236037373542786
step: 1020, loss: 0.22754409909248352
step: 1030, loss: 0.16832385957241058
step: 1040, loss: 0.05497357249259949
step: 1050, loss: 0.02596675045788288
step: 1060, loss: 0.02230803854763508
step: 1070, loss: 0.10639715939760208
epoch 11: dev_f1=0.9289667896678966, f1=0.9260628465804066, best_f1=0.9341983317886932
step: 0, loss: 0.04002974182367325
step: 10, loss: 0.14814530313014984
step: 20, loss: 0.03756840527057648
step: 30, loss: 0.07144777476787567
step: 40, loss: 0.10656443238258362
step: 50, loss: 0.02889738604426384
step: 60, loss: 0.04488694667816162
step: 70, loss: 0.08089110255241394
step: 80, loss: 0.09020773321390152
step: 90, loss: 0.04140264540910721
step: 100, loss: 0.04893430322408676
step: 110, loss: 0.0982154905796051
step: 120, loss: 0.0911223441362381
step: 130, loss: 0.10435501486063004
step: 140, loss: 0.12052460759878159
step: 150, loss: 0.04842136427760124
step: 160, loss: 0.03712606430053711
step: 170, loss: 0.00045502244029194117
step: 180, loss: 0.013118019327521324
step: 190, loss: 0.03799799829721451
step: 200, loss: 0.03853272274136543
step: 210, loss: 0.090504489839077
step: 220, loss: 0.057168424129486084
step: 230, loss: 0.08156534284353256
step: 240, loss: 0.08906122297048569
step: 250, loss: 0.013523247092962265
step: 260, loss: 0.10779762268066406
step: 270, loss: 0.0716153085231781
step: 280, loss: 0.0601147823035717
step: 290, loss: 0.07683335989713669
step: 300, loss: 0.046933744102716446
step: 310, loss: 0.09461930394172668
step: 320, loss: 0.07136013358831406
step: 330, loss: 0.030058126896619797
step: 340, loss: 0.03085150383412838
step: 350, loss: 0.058471519500017166
step: 360, loss: 0.08823171257972717
step: 370, loss: 0.08636274933815002
step: 380, loss: 0.018461357802152634
step: 390, loss: 0.017142925411462784
step: 400, loss: 0.039521291851997375
step: 410, loss: 0.01633392833173275
step: 420, loss: 0.03390560671687126
step: 430, loss: 0.05171990022063255
step: 440, loss: 0.0482025071978569
step: 450, loss: 0.07013021409511566
step: 460, loss: 0.09588861465454102
step: 470, loss: 0.03556806221604347
step: 480, loss: 0.04536005109548569
step: 490, loss: 0.03447316214442253
step: 500, loss: 0.26919257640838623
step: 510, loss: 0.11211517453193665
step: 520, loss: 0.01814485341310501
step: 530, loss: 0.0001356269494863227
step: 540, loss: 0.06627070903778076
step: 550, loss: 0.027665678411722183
step: 560, loss: 0.07537616789340973
step: 570, loss: 0.16030821204185486
step: 580, loss: 2.3805785531294532e-05
step: 590, loss: 0.07443499565124512
step: 600, loss: 0.03490417078137398
step: 610, loss: 0.011689161881804466
step: 620, loss: 0.09316112846136093
step: 630, loss: 0.07025579363107681
step: 640, loss: 0.14041408896446228
step: 650, loss: 0.05522459000349045
step: 660, loss: 0.0651126503944397
step: 670, loss: 0.08507579565048218
step: 680, loss: 0.03776409104466438
step: 690, loss: 0.07707183808088303
step: 700, loss: 0.027385346591472626
step: 710, loss: 0.0707656517624855
step: 720, loss: 0.11481870710849762
step: 730, loss: 0.03583703562617302
step: 740, loss: 0.040337175130844116
step: 750, loss: 0.11062535643577576
step: 760, loss: 0.004711126908659935
step: 770, loss: 0.10086660832166672
step: 780, loss: 0.11654598265886307
step: 790, loss: 0.0943785086274147
step: 800, loss: 0.09631036221981049
step: 810, loss: 0.0702972486615181
step: 820, loss: 0.00387908355332911
step: 830, loss: 0.03666600584983826
step: 840, loss: 0.1452934741973877
step: 850, loss: 0.007551230490207672
step: 860, loss: 0.02864995226264
step: 870, loss: 0.020185185596346855
step: 880, loss: 0.06002156063914299
step: 890, loss: 0.02637084573507309
step: 900, loss: 0.12608876824378967
step: 910, loss: 0.020893245935440063
step: 920, loss: 0.13647927343845367
step: 930, loss: 0.010910688899457455
step: 940, loss: 0.10710547864437103
step: 950, loss: 0.029933104291558266
step: 960, loss: 0.15321768820285797
step: 970, loss: 0.13116756081581116
step: 980, loss: 0.013265581801533699
step: 990, loss: 0.022042760625481606
step: 1000, loss: 0.041716914623975754
step: 1010, loss: 0.1190933808684349
step: 1020, loss: 0.019609825685620308
step: 1030, loss: 0.10095059126615524
step: 1040, loss: 0.34549465775489807
step: 1050, loss: 0.0504896342754364
step: 1060, loss: 0.08163249492645264
step: 1070, loss: 0.015636011958122253
epoch 12: dev_f1=0.9239384041063929, f1=0.925719591457753, best_f1=0.9341983317886932
step: 0, loss: 0.03502579405903816
step: 10, loss: 0.045431140810251236
step: 20, loss: 0.10795623064041138
step: 30, loss: 0.024652186781167984
step: 40, loss: 0.12307820469141006
step: 50, loss: 0.027671635150909424
step: 60, loss: 0.020642045885324478
step: 70, loss: 0.006580145563930273
step: 80, loss: 0.015374685637652874
step: 90, loss: 0.08770737051963806
step: 100, loss: 0.062098778784275055
step: 110, loss: 0.051207419484853745
step: 120, loss: 0.04456397145986557
step: 130, loss: 0.042135417461395264
step: 140, loss: 0.047286003828048706
step: 150, loss: 0.01932213082909584
step: 160, loss: 0.15904919803142548
step: 170, loss: 0.08476363122463226
step: 180, loss: 0.012644396163523197
step: 190, loss: 0.0777679830789566
step: 200, loss: 0.024865582585334778
step: 210, loss: 0.027988029643893242
step: 220, loss: 0.06568817794322968
step: 230, loss: 0.042961377650499344
step: 240, loss: 0.017789237201213837
step: 250, loss: 0.06638958305120468
step: 260, loss: 0.08285121619701385
step: 270, loss: 0.024588847532868385
step: 280, loss: 0.13783502578735352
step: 290, loss: 0.053113918751478195
step: 300, loss: 0.13054782152175903
step: 310, loss: 0.049050457775592804
step: 320, loss: 0.022709541022777557
step: 330, loss: 0.13239769637584686
step: 340, loss: 0.07516034692525864
step: 350, loss: 0.07943564653396606
step: 360, loss: 0.0021437956020236015
step: 370, loss: 0.018244236707687378
step: 380, loss: 0.12369140982627869
step: 390, loss: 0.05572789907455444
step: 400, loss: 0.1376333385705948
step: 410, loss: 0.03553018718957901
step: 420, loss: 0.03727291524410248
step: 430, loss: 0.00977957621216774
step: 440, loss: 0.1110181212425232
step: 450, loss: 0.03016987256705761
step: 460, loss: 0.04580884799361229
step: 470, loss: 0.01309188175946474
step: 480, loss: 0.04145484417676926
step: 490, loss: 0.06440901011228561
step: 500, loss: 0.05521441996097565
step: 510, loss: 0.10881203413009644
step: 520, loss: 0.042260847985744476
step: 530, loss: 0.08384442329406738
step: 540, loss: 0.10539156943559647
step: 550, loss: 0.02206714265048504
step: 560, loss: 0.06711754202842712
step: 570, loss: 0.12215850502252579
step: 580, loss: 0.0671062171459198
step: 590, loss: 0.0802859514951706
step: 600, loss: 0.023812999948859215
step: 610, loss: 0.0733461007475853
step: 620, loss: 0.01653739996254444
step: 630, loss: 0.08705399185419083
step: 640, loss: 0.026845453307032585
step: 650, loss: 0.07872970402240753
step: 660, loss: 0.12234903126955032
step: 670, loss: 0.024845952168107033
step: 680, loss: 0.24693448841571808
step: 690, loss: 0.07890072464942932
step: 700, loss: 0.10641699284315109
step: 710, loss: 0.0984564945101738
step: 720, loss: 0.0714908018708229
step: 730, loss: 0.04069393873214722
step: 740, loss: 0.030143795534968376
step: 750, loss: 0.10735737532377243
step: 760, loss: 0.02129129320383072
step: 770, loss: 0.0485481433570385
step: 780, loss: 0.07614536583423615
step: 790, loss: 0.042800627648830414
step: 800, loss: 0.06662890315055847
step: 810, loss: 0.05205275118350983
step: 820, loss: 0.17587527632713318
step: 830, loss: 0.027289384976029396
step: 840, loss: 0.07343145459890366
step: 850, loss: 0.0005347435362637043
step: 860, loss: 0.09427527338266373
step: 870, loss: 0.03311266005039215
step: 880, loss: 0.08325619250535965
step: 890, loss: 0.04269750043749809
step: 900, loss: 0.10222671926021576
step: 910, loss: 0.03680506721138954
step: 920, loss: 0.05966728925704956
step: 930, loss: 0.03074922040104866
step: 940, loss: 0.04309428110718727
step: 950, loss: 0.0373808853328228
step: 960, loss: 0.0011838879436254501
step: 970, loss: 0.08074364066123962
step: 980, loss: 0.06058526411652565
step: 990, loss: 0.10558729618787766
step: 1000, loss: 0.010599283501505852
step: 1010, loss: 0.15039382874965668
step: 1020, loss: 0.050079017877578735
step: 1030, loss: 0.08541633188724518
step: 1040, loss: 0.005991376005113125
step: 1050, loss: 0.10768727213144302
step: 1060, loss: 0.05688329413533211
step: 1070, loss: 0.08095433562994003
epoch 13: dev_f1=0.9296693060083837, f1=0.9292364990689013, best_f1=0.9341983317886932
step: 0, loss: 0.0735892578959465
step: 10, loss: 0.02823689766228199
step: 20, loss: 0.09819735586643219
step: 30, loss: 0.03371306136250496
step: 40, loss: 0.09763903170824051
step: 50, loss: 0.07076595723628998
step: 60, loss: 0.02754710242152214
step: 70, loss: 0.02219022996723652
step: 80, loss: 0.05494127795100212
step: 90, loss: 0.027733825147151947
step: 100, loss: 0.15213018655776978
step: 110, loss: 0.016377728432416916
step: 120, loss: 0.0743153914809227
step: 130, loss: 0.03857257589697838
step: 140, loss: 0.04372166842222214
step: 150, loss: 0.06127551943063736
step: 160, loss: 0.03039626032114029
step: 170, loss: 0.29777616262435913
step: 180, loss: 0.09280623495578766
step: 190, loss: 0.04571006819605827
step: 200, loss: 0.08097859472036362
step: 210, loss: 0.02004910446703434
step: 220, loss: 0.057495418936014175
step: 230, loss: 0.03212497755885124
step: 240, loss: 0.042597800493240356
step: 250, loss: 0.003912767861038446
step: 260, loss: 0.0008799602510407567
step: 270, loss: 0.023426230996847153
step: 280, loss: 0.02095496840775013
step: 290, loss: 0.09743890166282654
step: 300, loss: 0.03129153698682785
step: 310, loss: 0.022571558132767677
step: 320, loss: 0.06958641111850739
step: 330, loss: 0.1261032670736313
step: 340, loss: 0.13691572844982147
step: 350, loss: 0.06247766315937042
step: 360, loss: 0.057635076344013214
step: 370, loss: 0.029486868530511856
step: 380, loss: 0.012634220533072948
step: 390, loss: 0.0586208738386631
step: 400, loss: 0.00016064585361164063
step: 410, loss: 0.0006968099041841924
step: 420, loss: 0.050295211374759674
step: 430, loss: 0.006803631316870451
step: 440, loss: 0.01837444305419922
step: 450, loss: 0.04802652820944786
step: 460, loss: 0.04651593416929245
step: 470, loss: 0.06076747924089432
step: 480, loss: 0.017850497737526894
step: 490, loss: 0.0158206969499588
step: 500, loss: 0.08290410041809082
step: 510, loss: 0.1139039471745491
step: 520, loss: 0.06645479798316956
step: 530, loss: 0.14630605280399323
step: 540, loss: 0.017589015886187553
step: 550, loss: 0.10433726012706757
step: 560, loss: 0.08028095215559006
step: 570, loss: 0.0035238643176853657
step: 580, loss: 0.013243918307125568
step: 590, loss: 0.032703302800655365
step: 600, loss: 0.03957560658454895
step: 610, loss: 0.0802956223487854
step: 620, loss: 0.05955294519662857
step: 630, loss: 0.11434946954250336
step: 640, loss: 0.05243866890668869
step: 650, loss: 0.045399606227874756
step: 660, loss: 0.07462524622678757
step: 670, loss: 0.028967075049877167
step: 680, loss: 0.04598914459347725
step: 690, loss: 0.042967021465301514
step: 700, loss: 0.016421683132648468
step: 710, loss: 0.02873842976987362
step: 720, loss: 0.06949817389249802
step: 730, loss: 0.01613003760576248
step: 740, loss: 0.015916381031274796
step: 750, loss: 0.04766245186328888
step: 760, loss: 0.010091958567500114
step: 770, loss: 0.010245618410408497
step: 780, loss: 0.07425180822610855
step: 790, loss: 0.02223055623471737
step: 800, loss: 0.08666884899139404
step: 810, loss: 0.06529156863689423
step: 820, loss: 0.06748264282941818
step: 830, loss: 3.281480530858971e-05
step: 840, loss: 0.14304859936237335
step: 850, loss: 0.024735592305660248
step: 860, loss: 0.0687815248966217
step: 870, loss: 0.045179348438978195
step: 880, loss: 0.02789168432354927
step: 890, loss: 0.03792104870080948
step: 900, loss: 0.06420622020959854
step: 910, loss: 0.05420970171689987
step: 920, loss: 0.07691888511180878
step: 930, loss: 0.06615333259105682
step: 940, loss: 0.030603589490056038
step: 950, loss: 0.05812724679708481
step: 960, loss: 0.01495778001844883
step: 970, loss: 0.0657748132944107
step: 980, loss: 0.10028135031461716
step: 990, loss: 0.048766203224658966
step: 1000, loss: 0.12041373550891876
step: 1010, loss: 0.0459078885614872
step: 1020, loss: 0.011669239029288292
step: 1030, loss: 0.02815002016723156
step: 1040, loss: 0.06201041489839554
step: 1050, loss: 0.03810456395149231
step: 1060, loss: 0.04749278724193573
step: 1070, loss: 0.0028470586985349655
epoch 14: dev_f1=0.9229349330872173, f1=0.9223659889094269, best_f1=0.9341983317886932
step: 0, loss: 0.05044430121779442
step: 10, loss: 0.08035285025835037
step: 20, loss: 0.04521923512220383
step: 30, loss: 0.013905567117035389
step: 40, loss: 0.05937165766954422
step: 50, loss: 0.09512993693351746
step: 60, loss: 0.016861306503415108
step: 70, loss: 0.08688151836395264
step: 80, loss: 0.05242634564638138
step: 90, loss: 0.006622595712542534
step: 100, loss: 0.00029353448189795017
step: 110, loss: 0.09460844844579697
step: 120, loss: 0.07157258689403534
step: 130, loss: 0.049412086606025696
step: 140, loss: 0.015671581029891968
step: 150, loss: 0.09039720892906189
step: 160, loss: 0.03912917152047157
step: 170, loss: 0.027522874996066093
step: 180, loss: 0.036635927855968475
step: 190, loss: 0.046528562903404236
step: 200, loss: 3.5309174563735723e-05
step: 210, loss: 0.04209250211715698
step: 220, loss: 0.08071374893188477
step: 230, loss: 0.005476782098412514
step: 240, loss: 0.054978929460048676
step: 250, loss: 0.006587496027350426
step: 260, loss: 0.015380293130874634
step: 270, loss: 0.00017987597675528377
step: 280, loss: 0.045434288680553436
step: 290, loss: 4.278477354091592e-05
step: 300, loss: 0.043384965509176254
step: 310, loss: 0.03180535137653351
step: 320, loss: 0.06303223967552185
step: 330, loss: 0.04974652826786041
step: 340, loss: 0.04215838387608528
step: 350, loss: 0.08511156588792801
step: 360, loss: 0.06609508395195007
step: 370, loss: 0.08809229731559753
step: 380, loss: 0.11132066696882248
step: 390, loss: 0.049248140305280685
step: 400, loss: 0.004884198773652315
step: 410, loss: 0.02790302038192749
step: 420, loss: 0.07399432361125946
step: 430, loss: 0.10572609305381775
step: 440, loss: 0.03499247133731842
step: 450, loss: 0.029097910970449448
step: 460, loss: 0.10833178460597992
step: 470, loss: 0.03417341038584709
step: 480, loss: 0.030008742585778236
step: 490, loss: 0.05852256715297699
step: 500, loss: 0.06578260660171509
step: 510, loss: 0.032213903963565826
step: 520, loss: 0.06387559324502945
step: 530, loss: 0.10432277619838715
step: 540, loss: 0.10633346438407898
step: 550, loss: 0.04912608116865158
step: 560, loss: 0.19145910441875458
step: 570, loss: 0.08067228645086288
step: 580, loss: 0.04453783854842186
step: 590, loss: 0.061095938086509705
step: 600, loss: 0.1740589439868927
step: 610, loss: 0.02248508483171463
step: 620, loss: 0.0062194098718464375
step: 630, loss: 0.03082570619881153
step: 640, loss: 0.02574065513908863
step: 650, loss: 0.05653328076004982
step: 660, loss: 0.0364183709025383
step: 670, loss: 0.09949932247400284
step: 680, loss: 0.04236874356865883
step: 690, loss: 0.18998126685619354
step: 700, loss: 0.04468759894371033
step: 710, loss: 0.06833392381668091
step: 720, loss: 0.01637163758277893
step: 730, loss: 0.09162305295467377
step: 740, loss: 0.10312120616436005
step: 750, loss: 0.04120098426938057
step: 760, loss: 0.0410008430480957
step: 770, loss: 0.03485402092337608
step: 780, loss: 0.08123204112052917
step: 790, loss: 0.0023608573246747255
step: 800, loss: 0.03629382327198982
step: 810, loss: 0.03279981389641762
step: 820, loss: 0.012204657308757305
step: 830, loss: 0.12958721816539764
step: 840, loss: 0.16736316680908203
step: 850, loss: 0.0675630196928978
step: 860, loss: 0.14372190833091736
step: 870, loss: 0.09872306883335114
step: 880, loss: 0.04585456848144531
step: 890, loss: 0.010663295164704323
step: 900, loss: 0.028015315532684326
step: 910, loss: 4.688411354436539e-05
step: 920, loss: 0.05471483990550041
step: 930, loss: 0.0934738889336586
step: 940, loss: 0.03909189999103546
step: 950, loss: 0.0776393786072731
step: 960, loss: 0.03902771323919296
step: 970, loss: 0.03637244924902916
step: 980, loss: 0.016670115292072296
step: 990, loss: 0.01686260476708412
step: 1000, loss: 0.06553564965724945
step: 1010, loss: 0.0224942434579134
step: 1020, loss: 0.07922345399856567
step: 1030, loss: 0.001988281961530447
step: 1040, loss: 0.11165335774421692
step: 1050, loss: 0.02796105481684208
step: 1060, loss: 0.0023913171608000994
step: 1070, loss: 0.0949394479393959
epoch 15: dev_f1=0.9253170502583373, f1=0.9236569274269557, best_f1=0.9341983317886932
step: 0, loss: 0.052188027650117874
step: 10, loss: 0.06292613595724106
step: 20, loss: 6.657178892055526e-05
step: 30, loss: 0.1061519980430603
step: 40, loss: 0.0445115864276886
step: 50, loss: 0.07072356343269348
step: 60, loss: 0.03754199668765068
step: 70, loss: 0.06996750086545944
step: 80, loss: 0.10268749296665192
step: 90, loss: 0.03119705803692341
step: 100, loss: 0.059806257486343384
step: 110, loss: 0.03075125627219677
step: 120, loss: 0.08354531228542328
step: 130, loss: 0.018382040783762932
step: 140, loss: 0.048913054168224335
step: 150, loss: 0.02506585791707039
step: 160, loss: 0.03907877206802368
step: 170, loss: 0.09819380193948746
step: 180, loss: 0.030186457559466362
step: 190, loss: 0.03468530625104904
step: 200, loss: 0.08501528203487396
step: 210, loss: 0.13174419105052948
step: 220, loss: 0.01096465066075325
step: 230, loss: 0.08570291846990585
step: 240, loss: 0.018919136375188828
step: 250, loss: 0.04764789342880249
step: 260, loss: 0.03974362462759018
step: 270, loss: 0.050783392041921616
step: 280, loss: 0.03912777826189995
step: 290, loss: 0.09893489629030228
step: 300, loss: 0.015827851369976997
step: 310, loss: 0.03836749866604805
step: 320, loss: 0.06579550355672836
step: 330, loss: 0.08090835064649582
step: 340, loss: 0.04592550918459892
step: 350, loss: 0.05669182538986206
step: 360, loss: 0.004254773259162903
step: 370, loss: 0.06771153211593628
step: 380, loss: 0.13790147006511688
step: 390, loss: 0.0603058785200119
step: 400, loss: 0.00015156183508224785
step: 410, loss: 0.041889578104019165
step: 420, loss: 0.010816412046551704
step: 430, loss: 0.028267204761505127
step: 440, loss: 0.0011535617522895336
step: 450, loss: 0.08758293837308884
step: 460, loss: 0.013274558819830418
step: 470, loss: 0.036149896681308746
step: 480, loss: 0.10136809945106506
step: 490, loss: 0.05379181355237961
step: 500, loss: 0.06158100441098213
step: 510, loss: 0.04721161350607872
step: 520, loss: 0.019336501136422157
step: 530, loss: 0.01091296412050724
step: 540, loss: 0.009985759854316711
step: 550, loss: 0.05325934663414955
step: 560, loss: 0.015493206679821014
step: 570, loss: 0.00192812061868608
step: 580, loss: 0.14421577751636505
step: 590, loss: 0.11646968871355057
step: 600, loss: 0.042889729142189026
step: 610, loss: 0.059673700481653214
step: 620, loss: 0.09614554792642593
step: 630, loss: 0.02074444852769375
step: 640, loss: 0.03197082504630089
step: 650, loss: 0.06257784366607666
step: 660, loss: 0.11064061522483826
step: 670, loss: 0.0010291551006957889
step: 680, loss: 0.1270618587732315
step: 690, loss: 0.05923159047961235
step: 700, loss: 0.0021410698536783457
step: 710, loss: 0.039885278791189194
step: 720, loss: 0.06863170862197876
step: 730, loss: 0.01362915150821209
step: 740, loss: 0.07133617252111435
step: 750, loss: 0.07363946735858917
step: 760, loss: 0.0004236875392962247
step: 770, loss: 0.030520815402269363
step: 780, loss: 0.012977899052202702
step: 790, loss: 0.043278031051158905
step: 800, loss: 0.045510876923799515
step: 810, loss: 0.055854037404060364
step: 820, loss: 0.02411593310534954
step: 830, loss: 0.00025821063900366426
step: 840, loss: 0.04204483702778816
step: 850, loss: 0.0032850150018930435
step: 860, loss: 0.02922157198190689
step: 870, loss: 0.1354282647371292
step: 880, loss: 0.0715121403336525
step: 890, loss: 0.06030043214559555
step: 900, loss: 0.05574739724397659
step: 910, loss: 0.07011007517576218
step: 920, loss: 0.06440016627311707
step: 930, loss: 0.01915375329554081
step: 940, loss: 0.06176834926009178
step: 950, loss: 0.09611228108406067
step: 960, loss: 0.0441664382815361
step: 970, loss: 0.016972528770565987
step: 980, loss: 0.035314466804265976
step: 990, loss: 0.0492338091135025
step: 1000, loss: 0.06369074434041977
step: 1010, loss: 0.03802233189344406
step: 1020, loss: 0.05244985222816467
step: 1030, loss: 0.006777942180633545
step: 1040, loss: 0.04982685297727585
step: 1050, loss: 0.1187262013554573
step: 1060, loss: 0.05272381007671356
step: 1070, loss: 0.026275619864463806
epoch 16: dev_f1=0.9246607393542348, f1=0.9231490159325211, best_f1=0.9341983317886932
step: 0, loss: 0.1285811960697174
step: 10, loss: 0.04859616607427597
step: 20, loss: 0.02137284353375435
step: 30, loss: 0.06646179407835007
step: 40, loss: 0.062496379017829895
step: 50, loss: 0.03458908945322037
step: 60, loss: 0.0021267917472869158
step: 70, loss: 0.039845775812864304
step: 80, loss: 0.05893637239933014
step: 90, loss: 0.015323993749916553
step: 100, loss: 0.06634348630905151
step: 110, loss: 0.009755638428032398
step: 120, loss: 0.018548058345913887
step: 130, loss: 0.07548114657402039
step: 140, loss: 0.0409206822514534
step: 150, loss: 0.00019469312974251807
step: 160, loss: 0.03634878620505333
step: 170, loss: 0.062151551246643066
step: 180, loss: 0.06763406097888947
step: 190, loss: 0.07181298732757568
step: 200, loss: 0.04985932633280754
step: 210, loss: 0.021359793841838837
step: 220, loss: 0.045868270099163055
step: 230, loss: 0.02640143409371376
step: 240, loss: 0.08748401701450348
step: 250, loss: 0.04924332723021507
step: 260, loss: 0.019401418045163155
step: 270, loss: 0.07022367417812347
step: 280, loss: 0.05261186510324478
step: 290, loss: 0.024555157870054245
step: 300, loss: 0.1457543969154358
step: 310, loss: 0.026936881244182587
step: 320, loss: 0.051015704870224
step: 330, loss: 0.053619034588336945
step: 340, loss: 0.03876996412873268
step: 350, loss: 0.0013931076973676682
step: 360, loss: 0.030351193621754646
step: 370, loss: 0.054793909192085266
step: 380, loss: 0.11129043996334076
step: 390, loss: 0.12359057366847992
step: 400, loss: 0.05927085876464844
step: 410, loss: 0.0250505693256855
step: 420, loss: 0.1449224203824997
step: 430, loss: 0.04385196417570114
step: 440, loss: 0.03307439014315605
step: 450, loss: 0.06688228249549866
step: 460, loss: 0.008832572028040886
step: 470, loss: 0.026916980743408203
step: 480, loss: 0.041550565510988235
step: 490, loss: 0.009729068726301193
step: 500, loss: 0.018089275807142258
step: 510, loss: 0.024740353226661682
step: 520, loss: 0.03159787878394127
step: 530, loss: 0.03373017534613609
step: 540, loss: 0.04904799908399582
step: 550, loss: 0.0700576975941658
step: 560, loss: 0.03158444166183472
step: 570, loss: 0.04732341691851616
step: 580, loss: 0.06118091568350792
step: 590, loss: 0.061212267726659775
step: 600, loss: 0.06153062358498573
step: 610, loss: 0.06898611038923264
step: 620, loss: 0.0036777241621166468
step: 630, loss: 0.005893142893910408
step: 640, loss: 0.05241181701421738
step: 650, loss: 0.14739719033241272
step: 660, loss: 0.025859516113996506
step: 670, loss: 0.053758393973112106
step: 680, loss: 0.10521502792835236
step: 690, loss: 0.05986751616001129
step: 700, loss: 0.06216900423169136
step: 710, loss: 0.01492767222225666
step: 720, loss: 0.031386278569698334
step: 730, loss: 0.1075645461678505
step: 740, loss: 0.14099378883838654
step: 750, loss: 0.1507049798965454
step: 760, loss: 0.00853581540286541
step: 770, loss: 0.01888219639658928
step: 780, loss: 0.08136795461177826
step: 790, loss: 0.14680996537208557
step: 800, loss: 0.06873591244220734
step: 810, loss: 0.05150717496871948
step: 820, loss: 0.023989535868167877
step: 830, loss: 0.102323979139328
step: 840, loss: 5.3383177146315575e-05
step: 850, loss: 0.04268380254507065
step: 860, loss: 0.0490209199488163
step: 870, loss: 0.0792355090379715
step: 880, loss: 0.02487514540553093
step: 890, loss: 0.04909364879131317
step: 900, loss: 0.00909530557692051
step: 910, loss: 0.023690275847911835
step: 920, loss: 0.048676569014787674
step: 930, loss: 0.0038220968563109636
step: 940, loss: 0.023241128772497177
step: 950, loss: 0.1209387332201004
step: 960, loss: 0.05194095894694328
step: 970, loss: 0.018547464162111282
step: 980, loss: 0.06443332880735397
step: 990, loss: 0.014234052039682865
step: 1000, loss: 0.04250457137823105
step: 1010, loss: 0.08439668267965317
step: 1020, loss: 0.03202640265226364
step: 1030, loss: 0.0022368920035660267
step: 1040, loss: 0.03050345554947853
step: 1050, loss: 0.033149879425764084
step: 1060, loss: 0.02289261296391487
step: 1070, loss: 0.0255290400236845
epoch 17: dev_f1=0.9235849056603773, f1=0.9185115402731983, best_f1=0.9341983317886932
step: 0, loss: 0.0988701805472374
step: 10, loss: 0.048035141080617905
step: 20, loss: 0.0012737774522975087
step: 30, loss: 0.046150337904691696
step: 40, loss: 0.009455785155296326
step: 50, loss: 0.028260961174964905
step: 60, loss: 0.09150971472263336
step: 70, loss: 0.03992842882871628
step: 80, loss: 0.015491437166929245
step: 90, loss: 0.08271104097366333
step: 100, loss: 0.05569490045309067
step: 110, loss: 0.046548452228307724
step: 120, loss: 0.08619817346334457
step: 130, loss: 0.0691445842385292
step: 140, loss: 0.0004101188969798386
step: 150, loss: 0.06142766773700714
step: 160, loss: 0.01462695561349392
step: 170, loss: 0.04542549327015877
step: 180, loss: 0.020264344289898872
step: 190, loss: 0.03409434109926224
step: 200, loss: 0.03281662240624428
step: 210, loss: 0.011453657411038876
step: 220, loss: 0.05820554494857788
step: 230, loss: 0.060254599899053574
step: 240, loss: 0.07004391402006149
step: 250, loss: 0.10313544422388077
step: 260, loss: 0.01177221443504095
step: 270, loss: 0.11040322482585907
step: 280, loss: 0.10617976635694504
step: 290, loss: 0.03734114393591881
step: 300, loss: 0.04840925708413124
step: 310, loss: 0.0003085305797867477
step: 320, loss: 0.025142017751932144
step: 330, loss: 0.0320865772664547
step: 340, loss: 0.06465821713209152
step: 350, loss: 0.016054807230830193
step: 360, loss: 0.042951133102178574
step: 370, loss: 0.1550346463918686
step: 380, loss: 0.03397374600172043
step: 390, loss: 0.03462381288409233
step: 400, loss: 0.016120068728923798
step: 410, loss: 0.021513773128390312
step: 420, loss: 0.005465487949550152
step: 430, loss: 1.3924887753091753e-05
step: 440, loss: 0.12541626393795013
step: 450, loss: 0.08840325474739075
step: 460, loss: 0.004551324527710676
step: 470, loss: 0.03093945048749447
step: 480, loss: 0.05385560542345047
step: 490, loss: 0.03590185195207596
step: 500, loss: 0.07759373635053635
step: 510, loss: 0.03549681603908539
step: 520, loss: 0.06154663860797882
step: 530, loss: 0.05198245123028755
step: 540, loss: 0.05133587867021561
step: 550, loss: 0.076767198741436
step: 560, loss: 0.11133459210395813
step: 570, loss: 0.02418157458305359
step: 580, loss: 0.042965278029441833
step: 590, loss: 0.04863717779517174
step: 600, loss: 0.06574708223342896
step: 610, loss: 0.024605203419923782
step: 620, loss: 0.08798052370548248
step: 630, loss: 0.09317384660243988
step: 640, loss: 2.538982153055258e-05
step: 650, loss: 0.07584550231695175
step: 660, loss: 0.05366617813706398
step: 670, loss: 0.09583942592144012
step: 680, loss: 0.06509816646575928
step: 690, loss: 0.03021794930100441
step: 700, loss: 0.02560308948159218
step: 710, loss: 0.037016503512859344
step: 720, loss: 0.040496230125427246
step: 730, loss: 0.01595340110361576
step: 740, loss: 0.0020585283637046814
step: 750, loss: 0.048684362322092056
step: 760, loss: 0.0888572707772255
step: 770, loss: 0.04478175565600395
step: 780, loss: 0.08644910156726837
step: 790, loss: 0.03569331765174866
step: 800, loss: 0.06631279736757278
step: 810, loss: 0.04506567493081093
step: 820, loss: 0.029221495613455772
step: 830, loss: 0.0006521852919831872
step: 840, loss: 0.023686861619353294
step: 850, loss: 0.026471689343452454
step: 860, loss: 0.05188428610563278
step: 870, loss: 0.0460992231965065
step: 880, loss: 0.030402619391679764
step: 890, loss: 0.04542681202292442
step: 900, loss: 0.10612139105796814
step: 910, loss: 0.08313930034637451
step: 920, loss: 0.0889601930975914
step: 930, loss: 0.02355705015361309
step: 940, loss: 0.06767846643924713
step: 950, loss: 0.1082940548658371
step: 960, loss: 0.04439454525709152
step: 970, loss: 0.050481654703617096
step: 980, loss: 0.019056901335716248
step: 990, loss: 0.023924075067043304
step: 1000, loss: 0.07761130481958389
step: 1010, loss: 0.06539958715438843
step: 1020, loss: 0.05021662637591362
step: 1030, loss: 0.0327770933508873
step: 1040, loss: 0.06904668360948563
step: 1050, loss: 0.05660348758101463
step: 1060, loss: 0.00016896426677703857
step: 1070, loss: 0.08128608763217926
epoch 18: dev_f1=0.922498825739784, f1=0.9205453690644099, best_f1=0.9341983317886932
step: 0, loss: 0.06656816601753235
step: 10, loss: 0.06813670694828033
step: 20, loss: 0.03193916380405426
step: 30, loss: 0.06679439544677734
step: 40, loss: 0.013106100261211395
step: 50, loss: 0.0012541655451059341
step: 60, loss: 0.057652268558740616
step: 70, loss: 0.04665249586105347
step: 80, loss: 0.03482713922858238
step: 90, loss: 0.04388042539358139
step: 100, loss: 0.07175243645906448
step: 110, loss: 0.03822850435972214
step: 120, loss: 0.07841312885284424
step: 130, loss: 0.0019923856016248465
step: 140, loss: 0.11269842833280563
step: 150, loss: 0.07333314418792725
step: 160, loss: 0.002123024081811309
step: 170, loss: 0.10205087810754776
step: 180, loss: 0.044170886278152466
step: 190, loss: 0.037480708211660385
step: 200, loss: 0.01760243810713291
step: 210, loss: 0.00654236227273941
step: 220, loss: 0.00039762072265148163
step: 230, loss: 0.05207324028015137
step: 240, loss: 0.021466825157403946
step: 250, loss: 0.05139106512069702
step: 260, loss: 0.03952927887439728
step: 270, loss: 0.052609868347644806
step: 280, loss: 0.018735768273472786
step: 290, loss: 0.10610806941986084
step: 300, loss: 0.019236842170357704
step: 310, loss: 0.0035777846351265907
step: 320, loss: 0.01862149126827717
step: 330, loss: 0.03456059843301773
step: 340, loss: 0.07202519476413727
step: 350, loss: 0.11702272295951843
step: 360, loss: 0.041975297033786774
step: 370, loss: 0.01793801039457321
step: 380, loss: 0.01937687397003174
step: 390, loss: 0.00924798846244812
step: 400, loss: 0.17762915790081024
step: 410, loss: 0.04041409119963646
step: 420, loss: 0.12593011558055878
step: 430, loss: 0.0006875841645523906
step: 440, loss: 0.04780280590057373
step: 450, loss: 0.018993427976965904
step: 460, loss: 0.12246796488761902
step: 470, loss: 0.02003348246216774
step: 480, loss: 0.03094995953142643
step: 490, loss: 0.0003196010657120496
step: 500, loss: 0.02642248012125492
step: 510, loss: 2.5192208340740763e-05
step: 520, loss: 0.0063520013354718685
step: 530, loss: 0.026686914265155792
step: 540, loss: 0.0176923256367445
step: 550, loss: 0.05191356688737869
step: 560, loss: 0.07279176265001297
step: 570, loss: 0.04916677623987198
step: 580, loss: 2.1497418856597506e-05
step: 590, loss: 0.04423016682267189
step: 600, loss: 0.028570814058184624
step: 610, loss: 0.021156352013349533
step: 620, loss: 0.05683533847332001
step: 630, loss: 0.08519899845123291
step: 640, loss: 6.390991620719433e-05
step: 650, loss: 0.06534861028194427
step: 660, loss: 0.01238393597304821
step: 670, loss: 0.06329899281263351
step: 680, loss: 0.05274844914674759
step: 690, loss: 0.10241304337978363
step: 700, loss: 0.0927291214466095
step: 710, loss: 0.05177875608205795
step: 720, loss: 0.06730380654335022
step: 730, loss: 0.025795821100473404
step: 740, loss: 0.002638507867231965
step: 750, loss: 0.09929537028074265
step: 760, loss: 0.007486267480999231
step: 770, loss: 0.021232033148407936
step: 780, loss: 0.040104202926158905
step: 790, loss: 0.032258760184049606
step: 800, loss: 0.037168726325035095
step: 810, loss: 0.00011785612150561064
step: 820, loss: 0.043717510998249054
step: 830, loss: 0.018159635365009308
step: 840, loss: 0.024860579520463943
step: 850, loss: 0.09737604856491089
step: 860, loss: 0.04414987936615944
step: 870, loss: 0.0005791966686956584
step: 880, loss: 0.06508657336235046
step: 890, loss: 0.060888733714818954
step: 900, loss: 0.04148007556796074
step: 910, loss: 0.009578297846019268
step: 920, loss: 0.02475409023463726
step: 930, loss: 0.02739729918539524
step: 940, loss: 0.10244770348072052
step: 950, loss: 0.0648617297410965
step: 960, loss: 0.0002875796635635197
step: 970, loss: 0.0495372973382473
step: 980, loss: 3.7244717532303184e-05
step: 990, loss: 0.022507445886731148
step: 1000, loss: 0.0179145410656929
step: 1010, loss: 0.040056705474853516
step: 1020, loss: 0.06428288668394089
step: 1030, loss: 0.070993572473526
step: 1040, loss: 0.011777501553297043
step: 1050, loss: 0.09019900113344193
step: 1060, loss: 0.11215858161449432
step: 1070, loss: 0.025195159018039703
epoch 19: dev_f1=0.9200945626477541, f1=0.91828058573453, best_f1=0.9341983317886932
step: 0, loss: 0.03776370361447334
step: 10, loss: 0.037722472101449966
step: 20, loss: 0.001606518286280334
step: 30, loss: 0.08717834204435349
step: 40, loss: 0.05074648931622505
step: 50, loss: 0.03752109408378601
step: 60, loss: 0.024516500532627106
step: 70, loss: 0.0389307364821434
step: 80, loss: 0.02748856320977211
step: 90, loss: 0.020760849118232727
step: 100, loss: 0.04936763644218445
step: 110, loss: 0.021609097719192505
step: 120, loss: 0.045078638941049576
step: 130, loss: 0.017286032438278198
step: 140, loss: 0.01750762201845646
step: 150, loss: 0.02604086510837078
step: 160, loss: 0.17926158010959625
step: 170, loss: 0.028212010860443115
step: 180, loss: 0.042898304760456085
step: 190, loss: 0.019966552034020424
step: 200, loss: 0.049282144755125046
step: 210, loss: 0.07787500321865082
step: 220, loss: 0.05346766859292984
step: 230, loss: 0.06738710403442383
step: 240, loss: 0.011593134142458439
step: 250, loss: 4.3601008655969054e-05
step: 260, loss: 2.6891175366472453e-05
step: 270, loss: 0.11388005316257477
step: 280, loss: 0.11201439052820206
step: 290, loss: 0.04897109046578407
step: 300, loss: 5.26241201441735e-05
step: 310, loss: 0.05716761574149132
step: 320, loss: 0.0253545343875885
step: 330, loss: 0.0534183606505394
step: 340, loss: 0.004532967694103718
step: 350, loss: 0.07638340443372726
step: 360, loss: 0.01814335584640503
step: 370, loss: 0.08914968371391296
step: 380, loss: 0.023753799498081207
step: 390, loss: 0.04035291448235512
step: 400, loss: 0.0993242934346199
step: 410, loss: 0.033736564218997955
step: 420, loss: 2.7196765586268157e-05
step: 430, loss: 0.04871685802936554
step: 440, loss: 0.045010387897491455
step: 450, loss: 0.00042380113154649734
step: 460, loss: 0.056233812123537064
step: 470, loss: 0.10080094635486603
step: 480, loss: 8.538251131540164e-05
step: 490, loss: 0.07570039480924606
step: 500, loss: 0.015228796750307083
step: 510, loss: 1.5001503015810158e-05
step: 520, loss: 7.858125900384039e-05
step: 530, loss: 0.06414598971605301
step: 540, loss: 0.011895588599145412
step: 550, loss: 0.028453970327973366
step: 560, loss: 2.6969288228428923e-05
step: 570, loss: 0.09412290155887604
step: 580, loss: 0.056264836341142654
step: 590, loss: 2.7736292395275086e-05
step: 600, loss: 0.06766427308320999
step: 610, loss: 0.021522291004657745
step: 620, loss: 0.003057503141462803
step: 630, loss: 0.016779661178588867
step: 640, loss: 0.04757961258292198
step: 650, loss: 0.06770013272762299
step: 660, loss: 0.0507417768239975
step: 670, loss: 0.09352868795394897
step: 680, loss: 0.025244291871786118
step: 690, loss: 0.0005013913614675403
step: 700, loss: 0.012287375517189503
step: 710, loss: 0.0851968303322792
step: 720, loss: 0.08265262842178345
step: 730, loss: 0.07783308625221252
step: 740, loss: 0.0745023712515831
step: 750, loss: 0.058259110897779465
step: 760, loss: 0.054235272109508514
step: 770, loss: 0.056327175348997116
step: 780, loss: 0.03146752715110779
step: 790, loss: 0.05416436865925789
step: 800, loss: 0.0005270153051242232
step: 810, loss: 0.04898364841938019
step: 820, loss: 0.06079106777906418
step: 830, loss: 0.025008566677570343
step: 840, loss: 0.07614640891551971
step: 850, loss: 0.021089132875204086
step: 860, loss: 0.07233790308237076
step: 870, loss: 0.05496685206890106
step: 880, loss: 0.05264604836702347
step: 890, loss: 0.0009151138365268707
step: 900, loss: 0.018007205799221992
step: 910, loss: 0.01873561181128025
step: 920, loss: 0.09170740097761154
step: 930, loss: 0.042502470314502716
step: 940, loss: 0.030056089162826538
step: 950, loss: 0.020237723365426064
step: 960, loss: 0.08055999875068665
step: 970, loss: 0.048771727830171585
step: 980, loss: 0.11087760329246521
step: 990, loss: 0.04930982366204262
step: 1000, loss: 0.027514930814504623
step: 1010, loss: 0.015073895454406738
step: 1020, loss: 0.0999254584312439
step: 1030, loss: 0.1113811656832695
step: 1040, loss: 0.014369715936481953
step: 1050, loss: 0.017441298812627792
step: 1060, loss: 0.1173909455537796
step: 1070, loss: 0.03601641580462456
epoch 20: dev_f1=0.9201307800093415, f1=0.9213483146067416, best_f1=0.9341983317886932
