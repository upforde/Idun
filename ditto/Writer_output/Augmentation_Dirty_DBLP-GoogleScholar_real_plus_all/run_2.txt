cuda
Device: cuda
step: 0, loss: 0.6997779011726379
step: 10, loss: 0.4685162603855133
step: 20, loss: 0.37416207790374756
step: 30, loss: 0.38523584604263306
step: 40, loss: 0.32025453448295593
step: 50, loss: 0.43263721466064453
step: 60, loss: 0.20988093316555023
step: 70, loss: 0.2011842578649521
step: 80, loss: 0.4659814238548279
step: 90, loss: 0.22979505360126495
step: 100, loss: 0.19247883558273315
step: 110, loss: 0.17195792496204376
step: 120, loss: 0.1999601274728775
step: 130, loss: 0.19851148128509521
step: 140, loss: 0.18159033358097076
step: 150, loss: 0.12888890504837036
step: 160, loss: 0.16411837935447693
step: 170, loss: 0.15338604152202606
step: 180, loss: 0.04281516745686531
step: 190, loss: 0.20361652970314026
step: 200, loss: 0.5037842392921448
step: 210, loss: 0.09880410879850388
step: 220, loss: 0.256786972284317
step: 230, loss: 0.13767333328723907
step: 240, loss: 0.13197359442710876
step: 250, loss: 0.1434594988822937
step: 260, loss: 0.12052460759878159
step: 270, loss: 0.1333056092262268
step: 280, loss: 0.09795615822076797
step: 290, loss: 0.07903772592544556
step: 300, loss: 0.3632485270500183
step: 310, loss: 0.0849178358912468
step: 320, loss: 0.10834811627864838
step: 330, loss: 0.2290845513343811
step: 340, loss: 0.0898764580488205
step: 350, loss: 0.16632477939128876
step: 360, loss: 0.11862111836671829
step: 370, loss: 0.22191913425922394
step: 380, loss: 0.19219064712524414
step: 390, loss: 0.09903653711080551
step: 400, loss: 0.19389896094799042
step: 410, loss: 0.2878158688545227
step: 420, loss: 0.15635128319263458
step: 430, loss: 0.1463596522808075
step: 440, loss: 0.08610381186008453
step: 450, loss: 0.10906624048948288
step: 460, loss: 0.2707586884498596
step: 470, loss: 0.15050382912158966
step: 480, loss: 0.18721593916416168
step: 490, loss: 0.21950559318065643
step: 500, loss: 0.23180000483989716
step: 510, loss: 0.12504103779792786
step: 520, loss: 0.15437187254428864
step: 530, loss: 0.1533026546239853
step: 540, loss: 0.18993604183197021
step: 550, loss: 0.14582334458827972
step: 560, loss: 0.07933339476585388
step: 570, loss: 0.07981743663549423
step: 580, loss: 0.14562922716140747
step: 590, loss: 0.2783335745334625
step: 600, loss: 0.14859947562217712
step: 610, loss: 0.2282090038061142
step: 620, loss: 0.1502457559108734
step: 630, loss: 0.20317786931991577
step: 640, loss: 0.15793246030807495
step: 650, loss: 0.02266179583966732
step: 660, loss: 0.19638961553573608
step: 670, loss: 0.018646618351340294
step: 680, loss: 0.28138646483421326
step: 690, loss: 0.0559442900121212
step: 700, loss: 0.12118807435035706
step: 710, loss: 0.08165290206670761
step: 720, loss: 0.1320957988500595
step: 730, loss: 0.11204488575458527
step: 740, loss: 0.1996624618768692
step: 750, loss: 0.07739580422639847
step: 760, loss: 0.1361132562160492
step: 770, loss: 0.09190007299184799
step: 780, loss: 0.16834507882595062
step: 790, loss: 0.19133436679840088
step: 800, loss: 0.16343645751476288
step: 810, loss: 0.125814288854599
step: 820, loss: 0.1521115005016327
step: 830, loss: 0.18904167413711548
step: 840, loss: 0.13899438083171844
step: 850, loss: 0.11206895858049393
step: 860, loss: 0.1876467913389206
step: 870, loss: 0.09945280849933624
step: 880, loss: 0.13543309271335602
step: 890, loss: 0.10433704406023026
step: 900, loss: 0.19785456359386444
step: 910, loss: 0.20439012348651886
step: 920, loss: 0.11113978922367096
step: 930, loss: 0.1948300004005432
step: 940, loss: 0.15117444097995758
step: 950, loss: 0.07490479946136475
step: 960, loss: 0.1717393398284912
step: 970, loss: 0.11020606011152267
step: 980, loss: 0.22628718614578247
step: 990, loss: 0.12248828262090683
step: 1000, loss: 0.17094336450099945
step: 1010, loss: 0.1569039225578308
step: 1020, loss: 0.1605425924062729
step: 1030, loss: 0.04308893531560898
step: 1040, loss: 0.11029192060232162
step: 1050, loss: 0.13176703453063965
step: 1060, loss: 0.09084001928567886
step: 1070, loss: 0.1615583300590515
epoch 1: dev_f1=0.9230769230769231, f1=0.9177570093457944, best_f1=0.9177570093457944
step: 0, loss: 0.0337175652384758
step: 10, loss: 0.08412208408117294
step: 20, loss: 0.053859587758779526
step: 30, loss: 0.1428004801273346
step: 40, loss: 0.1486850380897522
step: 50, loss: 0.39403340220451355
step: 60, loss: 0.054258793592453
step: 70, loss: 0.05524318665266037
step: 80, loss: 0.13286808133125305
step: 90, loss: 0.17355892062187195
step: 100, loss: 0.13293106853961945
step: 110, loss: 0.1590583324432373
step: 120, loss: 0.3634137511253357
step: 130, loss: 0.17853990197181702
step: 140, loss: 0.12976837158203125
step: 150, loss: 0.06593268364667892
step: 160, loss: 0.09067992120981216
step: 170, loss: 0.28622812032699585
step: 180, loss: 0.06076395511627197
step: 190, loss: 0.15750175714492798
step: 200, loss: 0.1118074581027031
step: 210, loss: 0.13338018953800201
step: 220, loss: 0.1585841029882431
step: 230, loss: 0.023241640999913216
step: 240, loss: 0.11329058557748795
step: 250, loss: 0.27218207716941833
step: 260, loss: 0.09938287734985352
step: 270, loss: 0.10704993456602097
step: 280, loss: 0.10215018689632416
step: 290, loss: 0.1603260040283203
step: 300, loss: 0.10859142243862152
step: 310, loss: 0.11404934525489807
step: 320, loss: 0.03984648361802101
step: 330, loss: 0.12971512973308563
step: 340, loss: 0.05743283033370972
step: 350, loss: 0.10802167654037476
step: 360, loss: 0.03757369890809059
step: 370, loss: 0.09640815109014511
step: 380, loss: 0.13402411341667175
step: 390, loss: 0.037897076457738876
step: 400, loss: 0.06682372093200684
step: 410, loss: 0.1431380659341812
step: 420, loss: 0.13989688456058502
step: 430, loss: 0.08308246731758118
step: 440, loss: 0.14416243135929108
step: 450, loss: 0.10681970417499542
step: 460, loss: 0.13805751502513885
step: 470, loss: 0.16348503530025482
step: 480, loss: 0.21194806694984436
step: 490, loss: 0.1498621553182602
step: 500, loss: 0.17398831248283386
step: 510, loss: 0.11097061634063721
step: 520, loss: 0.09601781517267227
step: 530, loss: 0.08659596741199493
step: 540, loss: 0.11059790849685669
step: 550, loss: 0.10293027013540268
step: 560, loss: 0.19063712656497955
step: 570, loss: 0.11808444559574127
step: 580, loss: 0.14276523888111115
step: 590, loss: 0.10315518081188202
step: 600, loss: 0.03998783975839615
step: 610, loss: 0.12927575409412384
step: 620, loss: 0.0810239240527153
step: 630, loss: 0.13426947593688965
step: 640, loss: 0.1031499058008194
step: 650, loss: 0.23726557195186615
step: 660, loss: 0.07045664638280869
step: 670, loss: 0.11873028427362442
step: 680, loss: 0.15152360498905182
step: 690, loss: 0.1264924257993698
step: 700, loss: 0.10466963052749634
step: 710, loss: 0.22840845584869385
step: 720, loss: 0.21812455356121063
step: 730, loss: 0.12296014279127121
step: 740, loss: 0.16067659854888916
step: 750, loss: 0.16933155059814453
step: 760, loss: 0.10917271673679352
step: 770, loss: 0.03579924628138542
step: 780, loss: 0.14139215648174286
step: 790, loss: 0.21436405181884766
step: 800, loss: 0.1105574518442154
step: 810, loss: 0.12011724710464478
step: 820, loss: 0.046501681208610535
step: 830, loss: 0.07523354887962341
step: 840, loss: 0.24183477461338043
step: 850, loss: 0.1769150346517563
step: 860, loss: 0.11598145961761475
step: 870, loss: 0.2076748013496399
step: 880, loss: 0.07988137751817703
step: 890, loss: 0.0736507773399353
step: 900, loss: 0.17965176701545715
step: 910, loss: 0.14466577768325806
step: 920, loss: 0.12237195670604706
step: 930, loss: 0.047325968742370605
step: 940, loss: 0.08003871142864227
step: 950, loss: 0.12533897161483765
step: 960, loss: 0.09035180509090424
step: 970, loss: 0.0726495310664177
step: 980, loss: 0.023855159059166908
step: 990, loss: 0.08436379581689835
step: 1000, loss: 0.21386873722076416
step: 1010, loss: 0.1700342744588852
step: 1020, loss: 0.08090760558843613
step: 1030, loss: 0.15724524855613708
step: 1040, loss: 0.16624177992343903
step: 1050, loss: 0.22352281212806702
step: 1060, loss: 0.15583348274230957
step: 1070, loss: 0.13488854467868805
epoch 2: dev_f1=0.928377153218495, f1=0.9291835814163284, best_f1=0.9291835814163284
step: 0, loss: 0.07467744499444962
step: 10, loss: 0.051434461027383804
step: 20, loss: 0.08594896644353867
step: 30, loss: 0.06825508177280426
step: 40, loss: 0.0639999732375145
step: 50, loss: 0.06587705761194229
step: 60, loss: 0.0478951595723629
step: 70, loss: 0.09102185070514679
step: 80, loss: 0.12575222551822662
step: 90, loss: 0.050806157290935516
step: 100, loss: 0.05014823377132416
step: 110, loss: 0.11222311854362488
step: 120, loss: 0.06079275906085968
step: 130, loss: 0.021003521978855133
step: 140, loss: 0.09578191488981247
step: 150, loss: 0.10841318964958191
step: 160, loss: 0.23475195467472076
step: 170, loss: 0.03898588567972183
step: 180, loss: 0.164162740111351
step: 190, loss: 0.11300797015428543
step: 200, loss: 0.10949014127254486
step: 210, loss: 0.13260485231876373
step: 220, loss: 0.1215592548251152
step: 230, loss: 0.04887571185827255
step: 240, loss: 0.0943620353937149
step: 250, loss: 0.21517319977283478
step: 260, loss: 0.005634450353682041
step: 270, loss: 0.09664248675107956
step: 280, loss: 0.17033818364143372
step: 290, loss: 0.15868566930294037
step: 300, loss: 0.15967603027820587
step: 310, loss: 0.12214288860559464
step: 320, loss: 0.04733061417937279
step: 330, loss: 0.05370120704174042
step: 340, loss: 0.09137161076068878
step: 350, loss: 0.13273020088672638
step: 360, loss: 0.05120668560266495
step: 370, loss: 0.0787886381149292
step: 380, loss: 0.07830106467008591
step: 390, loss: 0.09468807280063629
step: 400, loss: 0.06597798317670822
step: 410, loss: 0.15641875565052032
step: 420, loss: 0.17475813627243042
step: 430, loss: 0.051259808242321014
step: 440, loss: 0.1544768512248993
step: 450, loss: 0.10527506470680237
step: 460, loss: 0.034286610782146454
step: 470, loss: 0.1427072435617447
step: 480, loss: 0.16161654889583588
step: 490, loss: 0.1857876181602478
step: 500, loss: 0.1468832641839981
step: 510, loss: 0.03924557939171791
step: 520, loss: 0.12503445148468018
step: 530, loss: 0.12431909888982773
step: 540, loss: 0.14550438523292542
step: 550, loss: 0.09545671939849854
step: 560, loss: 0.09854903817176819
step: 570, loss: 0.16865244507789612
step: 580, loss: 0.12511737644672394
step: 590, loss: 0.08259856700897217
step: 600, loss: 0.039239972829818726
step: 610, loss: 0.10074285417795181
step: 620, loss: 0.07845621556043625
step: 630, loss: 0.06773608177900314
step: 640, loss: 0.01465997751802206
step: 650, loss: 0.07846835255622864
step: 660, loss: 0.16093571484088898
step: 670, loss: 0.122348353266716
step: 680, loss: 0.11686231940984726
step: 690, loss: 0.10324122756719589
step: 700, loss: 0.059465162456035614
step: 710, loss: 0.10855567455291748
step: 720, loss: 0.13347361981868744
step: 730, loss: 0.09481735527515411
step: 740, loss: 0.04602111876010895
step: 750, loss: 0.12766365706920624
step: 760, loss: 0.05177693068981171
step: 770, loss: 0.16163036227226257
step: 780, loss: 0.06676311790943146
step: 790, loss: 0.08370915800333023
step: 800, loss: 0.05016874149441719
step: 810, loss: 0.2038787305355072
step: 820, loss: 0.2627197802066803
step: 830, loss: 0.05144420638680458
step: 840, loss: 0.12388288229703903
step: 850, loss: 0.08312792330980301
step: 860, loss: 0.0559978112578392
step: 870, loss: 0.07945577800273895
step: 880, loss: 0.05056937038898468
step: 890, loss: 0.034324515610933304
step: 900, loss: 0.10937061160802841
step: 910, loss: 0.20385132730007172
step: 920, loss: 0.02098647505044937
step: 930, loss: 0.0716504454612732
step: 940, loss: 0.16495519876480103
step: 950, loss: 0.1178123876452446
step: 960, loss: 0.11299774050712585
step: 970, loss: 0.18364064395427704
step: 980, loss: 0.10787032544612885
step: 990, loss: 0.11148916929960251
step: 1000, loss: 0.09488551318645477
step: 1010, loss: 0.11604562401771545
step: 1020, loss: 0.11138097941875458
step: 1030, loss: 0.10043890029191971
step: 1040, loss: 0.07076758146286011
step: 1050, loss: 0.06656484305858612
step: 1060, loss: 0.1276308298110962
step: 1070, loss: 0.14791572093963623
epoch 3: dev_f1=0.9296551724137931, f1=0.921451538814883, best_f1=0.921451538814883
step: 0, loss: 0.10069992393255234
step: 10, loss: 0.031157074496150017
step: 20, loss: 0.08201435953378677
step: 30, loss: 0.09115783870220184
step: 40, loss: 0.03131580725312233
step: 50, loss: 0.0665539801120758
step: 60, loss: 0.13622163236141205
step: 70, loss: 0.25850704312324524
step: 80, loss: 0.20560894906520844
step: 90, loss: 0.05672886595129967
step: 100, loss: 0.10781565308570862
step: 110, loss: 0.007895221002399921
step: 120, loss: 0.04498381167650223
step: 130, loss: 0.013337263837456703
step: 140, loss: 0.06657131761312485
step: 150, loss: 0.044532645493745804
step: 160, loss: 0.11484821140766144
step: 170, loss: 0.12346849590539932
step: 180, loss: 0.12251336872577667
step: 190, loss: 0.03106173686683178
step: 200, loss: 0.05355112999677658
step: 210, loss: 0.0433625690639019
step: 220, loss: 0.08966082334518433
step: 230, loss: 0.07224418222904205
step: 240, loss: 0.08623748272657394
step: 250, loss: 0.12195894122123718
step: 260, loss: 0.10960692912340164
step: 270, loss: 0.19657102227210999
step: 280, loss: 0.060254890471696854
step: 290, loss: 0.13949310779571533
step: 300, loss: 0.09168118238449097
step: 310, loss: 0.03903559222817421
step: 320, loss: 0.12968552112579346
step: 330, loss: 0.11403483152389526
step: 340, loss: 0.06086374446749687
step: 350, loss: 0.09418745338916779
step: 360, loss: 0.14143912494182587
step: 370, loss: 0.04359728470444679
step: 380, loss: 0.037263523787260056
step: 390, loss: 0.05944633483886719
step: 400, loss: 0.14133143424987793
step: 410, loss: 0.17233730852603912
step: 420, loss: 0.08242367953062057
step: 430, loss: 0.0949539840221405
step: 440, loss: 0.15801061689853668
step: 450, loss: 0.11568287014961243
step: 460, loss: 0.111540786921978
step: 470, loss: 0.1398266851902008
step: 480, loss: 0.13922475278377533
step: 490, loss: 0.06828513741493225
step: 500, loss: 0.07031828910112381
step: 510, loss: 0.12718114256858826
step: 520, loss: 0.11801999807357788
step: 530, loss: 0.17699222266674042
step: 540, loss: 0.13819390535354614
step: 550, loss: 0.06524524092674255
step: 560, loss: 0.07384592294692993
step: 570, loss: 0.13651061058044434
step: 580, loss: 0.1114877313375473
step: 590, loss: 0.09906516969203949
step: 600, loss: 0.0672331377863884
step: 610, loss: 0.12162284553050995
step: 620, loss: 0.019440818578004837
step: 630, loss: 0.11949331313371658
step: 640, loss: 0.017099078744649887
step: 650, loss: 0.09193576872348785
step: 660, loss: 0.11453667283058167
step: 670, loss: 0.18100374937057495
step: 680, loss: 0.103432297706604
step: 690, loss: 0.06060595065355301
step: 700, loss: 0.09182576835155487
step: 710, loss: 0.04995320364832878
step: 720, loss: 0.11180204153060913
step: 730, loss: 0.14093312621116638
step: 740, loss: 0.08370044082403183
step: 750, loss: 0.09138315916061401
step: 760, loss: 0.052300699055194855
step: 770, loss: 0.10974807292222977
step: 780, loss: 0.11768648773431778
step: 790, loss: 0.07343234866857529
step: 800, loss: 0.29980000853538513
step: 810, loss: 0.13512958586215973
step: 820, loss: 0.08549164980649948
step: 830, loss: 0.21697287261486053
step: 840, loss: 0.17498740553855896
step: 850, loss: 0.122881218791008
step: 860, loss: 0.11609674990177155
step: 870, loss: 0.05094626545906067
step: 880, loss: 0.11433188617229462
step: 890, loss: 0.03193986043334007
step: 900, loss: 0.08102678507566452
step: 910, loss: 0.04194372519850731
step: 920, loss: 0.08046059310436249
step: 930, loss: 0.12990230321884155
step: 940, loss: 0.14837943017482758
step: 950, loss: 0.20277802646160126
step: 960, loss: 0.029397770762443542
step: 970, loss: 0.0651853084564209
step: 980, loss: 0.05477825924754143
step: 990, loss: 0.05722253769636154
step: 1000, loss: 0.17974106967449188
step: 1010, loss: 0.1768808662891388
step: 1020, loss: 0.03462592884898186
step: 1030, loss: 0.0721307024359703
step: 1040, loss: 0.024058151990175247
step: 1050, loss: 0.10791000723838806
step: 1060, loss: 0.15718890726566315
step: 1070, loss: 0.07969468832015991
epoch 4: dev_f1=0.9332113449222323, f1=0.9316200091785223, best_f1=0.9316200091785223
step: 0, loss: 0.1392667442560196
step: 10, loss: 0.18636620044708252
step: 20, loss: 0.05345252528786659
step: 30, loss: 0.0711761862039566
step: 40, loss: 0.19066569209098816
step: 50, loss: 0.07829858362674713
step: 60, loss: 0.07254476845264435
step: 70, loss: 0.10039584338665009
step: 80, loss: 0.08339319378137589
step: 90, loss: 0.011600429192185402
step: 100, loss: 0.09245896339416504
step: 110, loss: 0.08490365743637085
step: 120, loss: 0.06510253995656967
step: 130, loss: 0.1783193051815033
step: 140, loss: 0.08276815712451935
step: 150, loss: 0.08290126919746399
step: 160, loss: 0.12139362096786499
step: 170, loss: 0.10857213288545609
step: 180, loss: 0.038257062435150146
step: 190, loss: 0.13230843842029572
step: 200, loss: 0.006052711047232151
step: 210, loss: 0.06267238408327103
step: 220, loss: 0.034279659390449524
step: 230, loss: 0.08663098514080048
step: 240, loss: 0.0706028938293457
step: 250, loss: 0.11558212339878082
step: 260, loss: 0.18449032306671143
step: 270, loss: 0.036309342831373215
step: 280, loss: 0.10228804498910904
step: 290, loss: 0.07595746219158173
step: 300, loss: 0.11263533681631088
step: 310, loss: 0.12111806869506836
step: 320, loss: 0.07060965150594711
step: 330, loss: 0.04565601050853729
step: 340, loss: 0.08056158572435379
step: 350, loss: 0.03457578644156456
step: 360, loss: 0.16786694526672363
step: 370, loss: 0.08258025348186493
step: 380, loss: 0.04961509257555008
step: 390, loss: 0.15761272609233856
step: 400, loss: 0.08058799058198929
step: 410, loss: 0.05312706530094147
step: 420, loss: 0.17141596972942352
step: 430, loss: 0.11028104275465012
step: 440, loss: 0.10624854266643524
step: 450, loss: 0.08706723153591156
step: 460, loss: 0.0006067624199204147
step: 470, loss: 0.07925515621900558
step: 480, loss: 0.12341055274009705
step: 490, loss: 0.09201014786958694
step: 500, loss: 0.1295156478881836
step: 510, loss: 0.05561886727809906
step: 520, loss: 0.04174111783504486
step: 530, loss: 0.07537919282913208
step: 540, loss: 0.11600970476865768
step: 550, loss: 0.07752349972724915
step: 560, loss: 0.10440461337566376
step: 570, loss: 0.03585340827703476
step: 580, loss: 0.06456959247589111
step: 590, loss: 0.06977105140686035
step: 600, loss: 0.06625837832689285
step: 610, loss: 0.0658431425690651
step: 620, loss: 0.017184903845191002
step: 630, loss: 0.13695283234119415
step: 640, loss: 0.025725198909640312
step: 650, loss: 0.1776578277349472
step: 660, loss: 0.25823989510536194
step: 670, loss: 0.1575489044189453
step: 680, loss: 0.12441155314445496
step: 690, loss: 0.11442862451076508
step: 700, loss: 0.09064781665802002
step: 710, loss: 0.16065944731235504
step: 720, loss: 0.10668700188398361
step: 730, loss: 0.07118009775876999
step: 740, loss: 0.011856546625494957
step: 750, loss: 0.042658139020204544
step: 760, loss: 0.07168781757354736
step: 770, loss: 0.1035250797867775
step: 780, loss: 0.10701952874660492
step: 790, loss: 0.1663113832473755
step: 800, loss: 0.05828343704342842
step: 810, loss: 0.020563960075378418
step: 820, loss: 0.1214194968342781
step: 830, loss: 0.06822839379310608
step: 840, loss: 0.07028466463088989
step: 850, loss: 0.10507497191429138
step: 860, loss: 0.2195250540971756
step: 870, loss: 0.013448847457766533
step: 880, loss: 0.11466363072395325
step: 890, loss: 0.17121627926826477
step: 900, loss: 0.18937070667743683
step: 910, loss: 0.009021774865686893
step: 920, loss: 0.03925759717822075
step: 930, loss: 0.030946850776672363
step: 940, loss: 0.079881452023983
step: 950, loss: 0.25807327032089233
step: 960, loss: 0.08890098333358765
step: 970, loss: 0.09932328760623932
step: 980, loss: 0.060226745903491974
step: 990, loss: 0.012490743771195412
step: 1000, loss: 0.07861718535423279
step: 1010, loss: 0.1574767529964447
step: 1020, loss: 0.1089642122387886
step: 1030, loss: 0.07003548741340637
step: 1040, loss: 0.12897253036499023
step: 1050, loss: 0.10873584449291229
step: 1060, loss: 0.15229636430740356
step: 1070, loss: 0.11007706075906754
epoch 5: dev_f1=0.935933147632312, f1=0.9288040949278734, best_f1=0.9288040949278734
step: 0, loss: 0.05773131549358368
step: 10, loss: 0.13148023188114166
step: 20, loss: 0.09189087897539139
step: 30, loss: 0.059985727071762085
step: 40, loss: 0.035390835255384445
step: 50, loss: 0.012932827696204185
step: 60, loss: 0.14907671511173248
step: 70, loss: 0.09185856580734253
step: 80, loss: 0.08278048783540726
step: 90, loss: 0.1711050271987915
step: 100, loss: 0.0701899304986
step: 110, loss: 0.123384028673172
step: 120, loss: 0.025309212505817413
step: 130, loss: 0.03248148038983345
step: 140, loss: 0.10927689075469971
step: 150, loss: 0.08426983654499054
step: 160, loss: 0.060283511877059937
step: 170, loss: 0.1328805387020111
step: 180, loss: 0.06153012067079544
step: 190, loss: 0.021878289058804512
step: 200, loss: 0.059137117117643356
step: 210, loss: 0.09380824863910675
step: 220, loss: 0.07329891622066498
step: 230, loss: 0.14810141921043396
step: 240, loss: 0.24682284891605377
step: 250, loss: 0.04376320168375969
step: 260, loss: 0.05407344549894333
step: 270, loss: 0.038588669151067734
step: 280, loss: 0.03248932585120201
step: 290, loss: 0.056422896683216095
step: 300, loss: 0.1511078029870987
step: 310, loss: 0.20653337240219116
step: 320, loss: 0.11742442101240158
step: 330, loss: 0.059978045523166656
step: 340, loss: 0.055668167769908905
step: 350, loss: 0.03340351581573486
step: 360, loss: 0.03356204554438591
step: 370, loss: 0.0969962328672409
step: 380, loss: 0.14018161594867706
step: 390, loss: 0.007468612864613533
step: 400, loss: 0.03809322044253349
step: 410, loss: 0.1113668754696846
step: 420, loss: 0.08647873997688293
step: 430, loss: 0.1831384301185608
step: 440, loss: 0.11545103043317795
step: 450, loss: 0.11727658659219742
step: 460, loss: 0.07859161496162415
step: 470, loss: 0.019484160467982292
step: 480, loss: 0.04520188644528389
step: 490, loss: 0.08248943090438843
step: 500, loss: 0.022943910211324692
step: 510, loss: 0.09460650384426117
step: 520, loss: 0.02776150591671467
step: 530, loss: 0.060718655586242676
step: 540, loss: 0.017687268555164337
step: 550, loss: 0.12261008471250534
step: 560, loss: 0.12318211048841476
step: 570, loss: 0.08750463277101517
step: 580, loss: 0.03067096509039402
step: 590, loss: 0.13575774431228638
step: 600, loss: 0.10486133396625519
step: 610, loss: 0.0380081832408905
step: 620, loss: 0.14581197500228882
step: 630, loss: 0.016726046800613403
step: 640, loss: 0.10228588432073593
step: 650, loss: 0.10118081420660019
step: 660, loss: 0.16702358424663544
step: 670, loss: 0.168122336268425
step: 680, loss: 0.025064617395401
step: 690, loss: 0.13605782389640808
step: 700, loss: 0.05280057713389397
step: 710, loss: 0.10586083680391312
step: 720, loss: 0.15393047034740448
step: 730, loss: 0.0333927720785141
step: 740, loss: 0.012521354481577873
step: 750, loss: 0.043391428887844086
step: 760, loss: 0.06701532006263733
step: 770, loss: 0.050489574670791626
step: 780, loss: 0.25833359360694885
step: 790, loss: 0.16723987460136414
step: 800, loss: 0.01669517531991005
step: 810, loss: 0.04707108438014984
step: 820, loss: 0.08017770946025848
step: 830, loss: 0.1555759608745575
step: 840, loss: 0.06859160214662552
step: 850, loss: 0.028358427807688713
step: 860, loss: 0.029851846396923065
step: 870, loss: 0.10271350294351578
step: 880, loss: 0.1111862063407898
step: 890, loss: 0.07931940257549286
step: 900, loss: 0.044018302112817764
step: 910, loss: 0.10228180885314941
step: 920, loss: 0.12087804824113846
step: 930, loss: 0.09121008217334747
step: 940, loss: 0.07893241196870804
step: 950, loss: 0.17886777222156525
step: 960, loss: 0.04183609038591385
step: 970, loss: 0.08054602146148682
step: 980, loss: 0.05811777710914612
step: 990, loss: 0.10511316359043121
step: 1000, loss: 0.08239688724279404
step: 1010, loss: 0.11557447165250778
step: 1020, loss: 0.10293013602495193
step: 1030, loss: 0.10082732886075974
step: 1040, loss: 0.11736126244068146
step: 1050, loss: 0.09706760197877884
step: 1060, loss: 0.04163927584886551
step: 1070, loss: 0.18953837454319
epoch 6: dev_f1=0.9300635785649409, f1=0.9195298372513563, best_f1=0.9288040949278734
step: 0, loss: 0.049494419246912
step: 10, loss: 0.15867118537425995
step: 20, loss: 0.022134246304631233
step: 30, loss: 0.1409773975610733
step: 40, loss: 0.06378429383039474
step: 50, loss: 0.15853984653949738
step: 60, loss: 0.10972089320421219
step: 70, loss: 0.0751713439822197
step: 80, loss: 0.059118159115314484
step: 90, loss: 0.039356499910354614
step: 100, loss: 0.051389772444963455
step: 110, loss: 0.17989113926887512
step: 120, loss: 0.15320159494876862
step: 130, loss: 0.1648983657360077
step: 140, loss: 0.09837380051612854
step: 150, loss: 0.11396203190088272
step: 160, loss: 0.09846998006105423
step: 170, loss: 0.018485574051737785
step: 180, loss: 0.0229176115244627
step: 190, loss: 0.049116358160972595
step: 200, loss: 0.0852527767419815
step: 210, loss: 0.030119851231575012
step: 220, loss: 0.008106429129838943
step: 230, loss: 0.11786630749702454
step: 240, loss: 0.035152826458215714
step: 250, loss: 0.10982772707939148
step: 260, loss: 0.013494955375790596
step: 270, loss: 0.03193383663892746
step: 280, loss: 0.0994141548871994
step: 290, loss: 0.013700115494430065
step: 300, loss: 0.06341366469860077
step: 310, loss: 0.054366644471883774
step: 320, loss: 0.030533555895090103
step: 330, loss: 0.048332519829273224
step: 340, loss: 0.07581410557031631
step: 350, loss: 0.16524863243103027
step: 360, loss: 0.10348290205001831
step: 370, loss: 0.21012142300605774
step: 380, loss: 0.04763326048851013
step: 390, loss: 0.11118590831756592
step: 400, loss: 0.1356460601091385
step: 410, loss: 0.14618320763111115
step: 420, loss: 0.11427368223667145
step: 430, loss: 0.11823698878288269
step: 440, loss: 0.1966821700334549
step: 450, loss: 0.09958472847938538
step: 460, loss: 0.10401854664087296
step: 470, loss: 0.037785399705171585
step: 480, loss: 0.1853439062833786
step: 490, loss: 0.0630599856376648
step: 500, loss: 0.11228790134191513
step: 510, loss: 0.017457162961363792
step: 520, loss: 0.09333579242229462
step: 530, loss: 0.05909755453467369
step: 540, loss: 0.12312594056129456
step: 550, loss: 0.11658523976802826
step: 560, loss: 0.0742175355553627
step: 570, loss: 0.0867590382695198
step: 580, loss: 0.02526220493018627
step: 590, loss: 0.013442844152450562
step: 600, loss: 0.184812530875206
step: 610, loss: 0.029453907161951065
step: 620, loss: 0.025521691888570786
step: 630, loss: 0.04661428928375244
step: 640, loss: 0.09179778397083282
step: 650, loss: 0.13612797856330872
step: 660, loss: 0.04726016893982887
step: 670, loss: 0.07914930582046509
step: 680, loss: 0.04957130551338196
step: 690, loss: 0.011939946562051773
step: 700, loss: 0.13790780305862427
step: 710, loss: 0.05102226883172989
step: 720, loss: 0.030360212549567223
step: 730, loss: 0.04157598689198494
step: 740, loss: 0.028641443699598312
step: 750, loss: 0.054702647030353546
step: 760, loss: 0.13741940259933472
step: 770, loss: 0.025760574266314507
step: 780, loss: 0.04727098345756531
step: 790, loss: 0.19509702920913696
step: 800, loss: 0.035559773445129395
step: 810, loss: 0.10544931143522263
step: 820, loss: 0.06909293681383133
step: 830, loss: 0.0974125862121582
step: 840, loss: 0.07610853016376495
step: 850, loss: 0.05904190614819527
step: 860, loss: 0.045795369893312454
step: 870, loss: 0.061081815510988235
step: 880, loss: 0.14155139029026031
step: 890, loss: 0.03863760456442833
step: 900, loss: 0.09806137531995773
step: 910, loss: 0.1590556502342224
step: 920, loss: 0.16191601753234863
step: 930, loss: 0.0444982573390007
step: 940, loss: 0.02273368649184704
step: 950, loss: 0.022478632628917694
step: 960, loss: 0.09123460948467255
step: 970, loss: 0.0978715568780899
step: 980, loss: 0.0912659764289856
step: 990, loss: 0.11983672529459
step: 1000, loss: 0.01023902464658022
step: 1010, loss: 0.16037783026695251
step: 1020, loss: 0.02786053530871868
step: 1030, loss: 0.0838269516825676
step: 1040, loss: 0.08462542295455933
step: 1050, loss: 0.1624426543712616
step: 1060, loss: 0.07867762446403503
step: 1070, loss: 0.15838676691055298
epoch 7: dev_f1=0.9302112029384756, f1=0.927007299270073, best_f1=0.9288040949278734
step: 0, loss: 0.039218172430992126
step: 10, loss: 0.0857212170958519
step: 20, loss: 0.12860161066055298
step: 30, loss: 0.005015612579882145
step: 40, loss: 0.09905336052179337
step: 50, loss: 0.09372139722108841
step: 60, loss: 0.08849431574344635
step: 70, loss: 0.1055167093873024
step: 80, loss: 0.09450329095125198
step: 90, loss: 0.11068355292081833
step: 100, loss: 0.08200360089540482
step: 110, loss: 0.05949389562010765
step: 120, loss: 0.05629526078701019
step: 130, loss: 0.1517871469259262
step: 140, loss: 0.1187739446759224
step: 150, loss: 0.07648583501577377
step: 160, loss: 0.0853697806596756
step: 170, loss: 0.0514969527721405
step: 180, loss: 0.13159726560115814
step: 190, loss: 0.05419791117310524
step: 200, loss: 0.07553587853908539
step: 210, loss: 0.06635066866874695
step: 220, loss: 0.04503123462200165
step: 230, loss: 0.10772139579057693
step: 240, loss: 0.054149363189935684
step: 250, loss: 0.07451925426721573
step: 260, loss: 0.012382601387798786
step: 270, loss: 0.16746319830417633
step: 280, loss: 0.08182407170534134
step: 290, loss: 0.046453461050987244
step: 300, loss: 0.0065155322663486
step: 310, loss: 0.02470291033387184
step: 320, loss: 0.017988955602049828
step: 330, loss: 0.033415310084819794
step: 340, loss: 0.031564708799123764
step: 350, loss: 0.037826474756002426
step: 360, loss: 0.06247486174106598
step: 370, loss: 0.029497455805540085
step: 380, loss: 0.04926174879074097
step: 390, loss: 0.06635835766792297
step: 400, loss: 0.216072678565979
step: 410, loss: 0.05671791732311249
step: 420, loss: 0.07896176725625992
step: 430, loss: 0.020712820813059807
step: 440, loss: 0.07289734482765198
step: 450, loss: 0.05735667794942856
step: 460, loss: 0.050572264939546585
step: 470, loss: 0.1413765400648117
step: 480, loss: 0.07980475574731827
step: 490, loss: 0.05387023836374283
step: 500, loss: 0.01208050549030304
step: 510, loss: 0.010426404885947704
step: 520, loss: 0.19588755071163177
step: 530, loss: 0.03672872856259346
step: 540, loss: 0.1952078491449356
step: 550, loss: 0.0723731517791748
step: 560, loss: 0.04257163405418396
step: 570, loss: 0.01113857701420784
step: 580, loss: 0.15943287312984467
step: 590, loss: 0.06161903589963913
step: 600, loss: 0.04256167262792587
step: 610, loss: 0.1141701489686966
step: 620, loss: 0.13539397716522217
step: 630, loss: 0.09748174995183945
step: 640, loss: 0.20473788678646088
step: 650, loss: 0.13621395826339722
step: 660, loss: 0.0901443213224411
step: 670, loss: 0.08068262040615082
step: 680, loss: 0.24425724148750305
step: 690, loss: 0.05860460549592972
step: 700, loss: 0.11862527579069138
step: 710, loss: 0.04142540320754051
step: 720, loss: 0.04891662299633026
step: 730, loss: 0.0577874556183815
step: 740, loss: 0.04267894849181175
step: 750, loss: 0.0014113271608948708
step: 760, loss: 0.049273066222667694
step: 770, loss: 0.020705001428723335
step: 780, loss: 0.02258414216339588
step: 790, loss: 0.10144063830375671
step: 800, loss: 0.09482337534427643
step: 810, loss: 0.0647362470626831
step: 820, loss: 0.07980335503816605
step: 830, loss: 0.19057916104793549
step: 840, loss: 0.18642853200435638
step: 850, loss: 0.19934004545211792
step: 860, loss: 0.02315351739525795
step: 870, loss: 0.015902074053883553
step: 880, loss: 0.028904816135764122
step: 890, loss: 0.12221579998731613
step: 900, loss: 0.0982804074883461
step: 910, loss: 0.00019170124141965061
step: 920, loss: 0.12031247466802597
step: 930, loss: 0.10049637407064438
step: 940, loss: 0.031682197004556656
step: 950, loss: 0.09583730250597
step: 960, loss: 0.06687146425247192
step: 970, loss: 0.09704920649528503
step: 980, loss: 0.056607022881507874
step: 990, loss: 0.010297395288944244
step: 1000, loss: 0.08636140823364258
step: 1010, loss: 0.0953311175107956
step: 1020, loss: 0.1446772664785385
step: 1030, loss: 0.07952015846967697
step: 1040, loss: 0.1039896160364151
step: 1050, loss: 0.0845731794834137
step: 1060, loss: 0.049311619251966476
step: 1070, loss: 0.054993726313114166
epoch 8: dev_f1=0.9307201458523247, f1=0.9225894069714802, best_f1=0.9288040949278734
step: 0, loss: 0.132945716381073
step: 10, loss: 0.013142701238393784
step: 20, loss: 0.09684436023235321
step: 30, loss: 0.08665858954191208
step: 40, loss: 0.05007778853178024
step: 50, loss: 0.0225535798817873
step: 60, loss: 0.12671272456645966
step: 70, loss: 0.0342709980905056
step: 80, loss: 0.08872188627719879
step: 90, loss: 0.030249904841184616
step: 100, loss: 0.16517122089862823
step: 110, loss: 0.06934182345867157
step: 120, loss: 0.04475928470492363
step: 130, loss: 0.029141345992684364
step: 140, loss: 0.06177650764584541
step: 150, loss: 0.0019944545347243547
step: 160, loss: 0.036928270012140274
step: 170, loss: 0.0914616659283638
step: 180, loss: 0.18126562237739563
step: 190, loss: 0.10889214277267456
step: 200, loss: 0.08002112060785294
step: 210, loss: 0.08760367333889008
step: 220, loss: 0.050047751516103745
step: 230, loss: 0.06501936167478561
step: 240, loss: 0.09041589498519897
step: 250, loss: 0.1093103215098381
step: 260, loss: 0.05742527171969414
step: 270, loss: 0.015440852381289005
step: 280, loss: 0.05646808445453644
step: 290, loss: 0.20062381029129028
step: 300, loss: 0.10462522506713867
step: 310, loss: 0.07472841441631317
step: 320, loss: 0.07684076577425003
step: 330, loss: 0.047885119915008545
step: 340, loss: 0.20350614190101624
step: 350, loss: 0.02900296077132225
step: 360, loss: 0.08178617060184479
step: 370, loss: 0.14366163313388824
step: 380, loss: 0.05721089616417885
step: 390, loss: 0.060316093266010284
step: 400, loss: 0.053451329469680786
step: 410, loss: 0.11431049555540085
step: 420, loss: 0.054880864918231964
step: 430, loss: 0.15999339520931244
step: 440, loss: 0.06849242746829987
step: 450, loss: 0.1241547018289566
step: 460, loss: 0.10221187770366669
step: 470, loss: 0.07706208527088165
step: 480, loss: 0.05416928604245186
step: 490, loss: 0.1175040677189827
step: 500, loss: 0.08518823981285095
step: 510, loss: 0.12247659265995026
step: 520, loss: 0.07011324912309647
step: 530, loss: 0.11405898630619049
step: 540, loss: 0.07817336916923523
step: 550, loss: 0.03353985771536827
step: 560, loss: 0.04736729711294174
step: 570, loss: 0.09604223072528839
step: 580, loss: 0.05955231934785843
step: 590, loss: 0.06212328001856804
step: 600, loss: 0.08737492561340332
step: 610, loss: 0.20147919654846191
step: 620, loss: 0.039312880486249924
step: 630, loss: 0.11984913796186447
step: 640, loss: 0.05346532538533211
step: 650, loss: 0.04362761229276657
step: 660, loss: 0.08018088340759277
step: 670, loss: 0.06613080948591232
step: 680, loss: 0.027193862944841385
step: 690, loss: 0.017689257860183716
step: 700, loss: 0.12345178425312042
step: 710, loss: 0.07871033996343613
step: 720, loss: 0.03469335287809372
step: 730, loss: 0.08580195903778076
step: 740, loss: 0.12816447019577026
step: 750, loss: 0.12120901048183441
step: 760, loss: 0.09309043735265732
step: 770, loss: 0.1408059149980545
step: 780, loss: 0.27104032039642334
step: 790, loss: 0.10301730036735535
step: 800, loss: 0.10235745459794998
step: 810, loss: 0.08890274912118912
step: 820, loss: 0.09490204602479935
step: 830, loss: 0.11784222722053528
step: 840, loss: 0.01857910305261612
step: 850, loss: 0.035237718373537064
step: 860, loss: 0.08818695694208145
step: 870, loss: 0.04582439363002777
step: 880, loss: 0.1767670065164566
step: 890, loss: 0.04517531394958496
step: 900, loss: 0.08965421468019485
step: 910, loss: 0.02705051563680172
step: 920, loss: 0.05146016553044319
step: 930, loss: 0.12128882855176926
step: 940, loss: 0.04833584278821945
step: 950, loss: 0.052886009216308594
step: 960, loss: 0.03348340839147568
step: 970, loss: 0.038683246821165085
step: 980, loss: 0.05425696074962616
step: 990, loss: 0.03604959696531296
step: 1000, loss: 0.0454079695045948
step: 1010, loss: 0.06156284734606743
step: 1020, loss: 0.2219284027814865
step: 1030, loss: 0.06615500897169113
step: 1040, loss: 0.0753948912024498
step: 1050, loss: 0.09259628504514694
step: 1060, loss: 0.11731315404176712
step: 1070, loss: 0.05628788843750954
epoch 9: dev_f1=0.9334582942830365, f1=0.9274418604651162, best_f1=0.9288040949278734
step: 0, loss: 0.07472965866327286
step: 10, loss: 0.0515008307993412
step: 20, loss: 0.058624885976314545
step: 30, loss: 0.026949714869260788
step: 40, loss: 0.09286191314458847
step: 50, loss: 0.07933226227760315
step: 60, loss: 0.05476319044828415
step: 70, loss: 0.13915368914604187
step: 80, loss: 0.0719962865114212
step: 90, loss: 0.00879672821611166
step: 100, loss: 0.005571831949055195
step: 110, loss: 0.07648836821317673
step: 120, loss: 0.04050818458199501
step: 130, loss: 0.05278019234538078
step: 140, loss: 0.01592945121228695
step: 150, loss: 0.029583841562271118
step: 160, loss: 0.11281199008226395
step: 170, loss: 0.0354442298412323
step: 180, loss: 0.0832485482096672
step: 190, loss: 0.07833079993724823
step: 200, loss: 0.1628204882144928
step: 210, loss: 0.08079445362091064
step: 220, loss: 0.06539728492498398
step: 230, loss: 0.05169175937771797
step: 240, loss: 0.04493017494678497
step: 250, loss: 0.07136610895395279
step: 260, loss: 0.09626075625419617
step: 270, loss: 0.08772730827331543
step: 280, loss: 0.023970069363713264
step: 290, loss: 0.015062387101352215
step: 300, loss: 0.048004575073719025
step: 310, loss: 0.05388922244310379
step: 320, loss: 0.14145366847515106
step: 330, loss: 0.03834166005253792
step: 340, loss: 0.12013553828001022
step: 350, loss: 0.016776153817772865
step: 360, loss: 0.04092469438910484
step: 370, loss: 0.07094816863536835
step: 380, loss: 0.0026314398273825645
step: 390, loss: 0.0010583667317405343
step: 400, loss: 0.22055694460868835
step: 410, loss: 0.03500980883836746
step: 420, loss: 0.07316789776086807
step: 430, loss: 0.04064856097102165
step: 440, loss: 0.030675699934363365
step: 450, loss: 0.03796949237585068
step: 460, loss: 0.14662185311317444
step: 470, loss: 0.03715405985713005
step: 480, loss: 0.07645174115896225
step: 490, loss: 0.07978841662406921
step: 500, loss: 0.042239923030138016
step: 510, loss: 0.021827157586812973
step: 520, loss: 0.1517757922410965
step: 530, loss: 0.03310292214155197
step: 540, loss: 0.038503386080265045
step: 550, loss: 0.0469818152487278
step: 560, loss: 0.012647785246372223
step: 570, loss: 0.0107793053612113
step: 580, loss: 0.055531296879053116
step: 590, loss: 0.14986149966716766
step: 600, loss: 0.036452535539865494
step: 610, loss: 0.04698471352458
step: 620, loss: 0.06479889154434204
step: 630, loss: 0.04278547316789627
step: 640, loss: 0.014166144654154778
step: 650, loss: 0.09016147255897522
step: 660, loss: 0.09806341677904129
step: 670, loss: 0.005266489926725626
step: 680, loss: 0.15700973570346832
step: 690, loss: 0.055235855281353
step: 700, loss: 0.04648243263363838
step: 710, loss: 0.03434879332780838
step: 720, loss: 0.07748856395483017
step: 730, loss: 0.07035934925079346
step: 740, loss: 0.2301074117422104
step: 750, loss: 0.025633439421653748
step: 760, loss: 0.15011374652385712
step: 770, loss: 0.09225557744503021
step: 780, loss: 0.055914267897605896
step: 790, loss: 0.0011805216781795025
step: 800, loss: 0.027955662459135056
step: 810, loss: 0.07704998552799225
step: 820, loss: 0.079613097012043
step: 830, loss: 0.0661434531211853
step: 840, loss: 0.16019102931022644
step: 850, loss: 0.03338788077235222
step: 860, loss: 0.02076687105000019
step: 870, loss: 0.023450680077075958
step: 880, loss: 0.046897780150175095
step: 890, loss: 0.067535400390625
step: 900, loss: 0.1032952219247818
step: 910, loss: 0.11958817392587662
step: 920, loss: 0.04349841922521591
step: 930, loss: 0.01805884949862957
step: 940, loss: 0.05855421721935272
step: 950, loss: 0.03574112430214882
step: 960, loss: 0.08554686605930328
step: 970, loss: 0.02676645666360855
step: 980, loss: 0.20579403638839722
step: 990, loss: 0.06640175729990005
step: 1000, loss: 0.08657815307378769
step: 1010, loss: 0.05960841476917267
step: 1020, loss: 0.09487225115299225
step: 1030, loss: 0.047880761325359344
step: 1040, loss: 0.04377317801117897
step: 1050, loss: 0.06377620995044708
step: 1060, loss: 0.03280213102698326
step: 1070, loss: 0.1010814756155014
epoch 10: dev_f1=0.9324875396465792, f1=0.9216216216216216, best_f1=0.9288040949278734
step: 0, loss: 0.0011780047789216042
step: 10, loss: 0.05569331720471382
step: 20, loss: 0.09356139600276947
step: 30, loss: 0.053488701581954956
step: 40, loss: 0.006158636882901192
step: 50, loss: 0.06462253630161285
step: 60, loss: 0.10434199869632721
step: 70, loss: 0.03907103091478348
step: 80, loss: 0.06732754409313202
step: 90, loss: 0.0073145534843206406
step: 100, loss: 0.03540449216961861
step: 110, loss: 0.07226073741912842
step: 120, loss: 0.029825612902641296
step: 130, loss: 0.0616704523563385
step: 140, loss: 0.11015603691339493
step: 150, loss: 0.023615235462784767
step: 160, loss: 0.013652169145643711
step: 170, loss: 0.06902389973402023
step: 180, loss: 0.03186653554439545
step: 190, loss: 0.05148403346538544
step: 200, loss: 0.011082688346505165
step: 210, loss: 0.11119136214256287
step: 220, loss: 0.0384351909160614
step: 230, loss: 0.02884577214717865
step: 240, loss: 0.08641592413187027
step: 250, loss: 0.06378147751092911
step: 260, loss: 0.055820051580667496
step: 270, loss: 0.021809373050928116
step: 280, loss: 0.012659705244004726
step: 290, loss: 0.018309229984879494
step: 300, loss: 0.002302014734596014
step: 310, loss: 0.09090830385684967
step: 320, loss: 0.07852409780025482
step: 330, loss: 0.06569322943687439
step: 340, loss: 0.020296260714530945
step: 350, loss: 0.09482292830944061
step: 360, loss: 0.005036240443587303
step: 370, loss: 0.06799778342247009
step: 380, loss: 0.06588494777679443
step: 390, loss: 0.058416955173015594
step: 400, loss: 0.03126952052116394
step: 410, loss: 0.06396406143903732
step: 420, loss: 0.1795196384191513
step: 430, loss: 0.08962614089250565
step: 440, loss: 0.08019103854894638
step: 450, loss: 0.04251236096024513
step: 460, loss: 0.0897052064538002
step: 470, loss: 0.014195219613611698
step: 480, loss: 0.04704791307449341
step: 490, loss: 0.02902241237461567
step: 500, loss: 0.1249777153134346
step: 510, loss: 0.07492673397064209
step: 520, loss: 0.0554749071598053
step: 530, loss: 0.06757933646440506
step: 540, loss: 0.04509168863296509
step: 550, loss: 0.054207395762205124
step: 560, loss: 0.20268669724464417
step: 570, loss: 0.08514529466629028
step: 580, loss: 0.032236091792583466
step: 590, loss: 0.13141141831874847
step: 600, loss: 0.05901387706398964
step: 610, loss: 0.03178701922297478
step: 620, loss: 0.03823842108249664
step: 630, loss: 0.11360958218574524
step: 640, loss: 0.03872040659189224
step: 650, loss: 0.09646086394786835
step: 660, loss: 0.11495006829500198
step: 670, loss: 0.0952145904302597
step: 680, loss: 0.16177022457122803
step: 690, loss: 0.02755078114569187
step: 700, loss: 0.06710974127054214
step: 710, loss: 0.15983206033706665
step: 720, loss: 0.023370880633592606
step: 730, loss: 0.08123418688774109
step: 740, loss: 0.03735848516225815
step: 750, loss: 0.027741046622395515
step: 760, loss: 0.037760570645332336
step: 770, loss: 0.01637228950858116
step: 780, loss: 0.15038177371025085
step: 790, loss: 0.01399950310587883
step: 800, loss: 0.3364328444004059
step: 810, loss: 0.09098222851753235
step: 820, loss: 0.06550750881433487
step: 830, loss: 0.11835004389286041
step: 840, loss: 0.02628903090953827
step: 850, loss: 0.1646154820919037
step: 860, loss: 0.06190758943557739
step: 870, loss: 0.14668746292591095
step: 880, loss: 0.06427405774593353
step: 890, loss: 0.1005697175860405
step: 900, loss: 0.07738734781742096
step: 910, loss: 0.04496031999588013
step: 920, loss: 0.10042866319417953
step: 930, loss: 0.12845028936862946
step: 940, loss: 0.06032693386077881
step: 950, loss: 0.09412121027708054
step: 960, loss: 6.799568654969335e-05
step: 970, loss: 0.01057975459843874
step: 980, loss: 0.11600031703710556
step: 990, loss: 0.0864771157503128
step: 1000, loss: 0.10302332788705826
step: 1010, loss: 0.07500385493040085
step: 1020, loss: 0.1512601673603058
step: 1030, loss: 0.02904977835714817
step: 1040, loss: 0.028540559113025665
step: 1050, loss: 0.02205926738679409
step: 1060, loss: 0.025497199967503548
step: 1070, loss: 0.037778861820697784
epoch 11: dev_f1=0.9332079021636878, f1=0.9288389513108615, best_f1=0.9288040949278734
step: 0, loss: 0.05874928832054138
step: 10, loss: 0.017487287521362305
step: 20, loss: 0.04273417964577675
step: 30, loss: 0.03716222941875458
step: 40, loss: 0.0045995754189789295
step: 50, loss: 0.09442362934350967
step: 60, loss: 0.12195353955030441
step: 70, loss: 0.05601219832897186
step: 80, loss: 0.03267331048846245
step: 90, loss: 0.09784870594739914
step: 100, loss: 0.0889163538813591
step: 110, loss: 0.020879462361335754
step: 120, loss: 0.01136738620698452
step: 130, loss: 0.08027772605419159
step: 140, loss: 0.08565208315849304
step: 150, loss: 0.013921486213803291
step: 160, loss: 0.02692984975874424
step: 170, loss: 0.047511886805295944
step: 180, loss: 0.02205631509423256
step: 190, loss: 0.08357447385787964
step: 200, loss: 0.09261046350002289
step: 210, loss: 0.02640857920050621
step: 220, loss: 0.04177995026111603
step: 230, loss: 0.02442477084696293
step: 240, loss: 0.058047883212566376
step: 250, loss: 0.06798424571752548
step: 260, loss: 0.03458857908844948
step: 270, loss: 0.038490038365125656
step: 280, loss: 0.0005171968950890005
step: 290, loss: 0.10643129050731659
step: 300, loss: 0.10646890848875046
step: 310, loss: 0.09109163284301758
step: 320, loss: 0.0377754345536232
step: 330, loss: 0.0230574868619442
step: 340, loss: 0.0005104492302052677
step: 350, loss: 0.02914738841354847
step: 360, loss: 0.05424465239048004
step: 370, loss: 0.012942317873239517
step: 380, loss: 0.0012014484964311123
step: 390, loss: 0.04687159135937691
step: 400, loss: 0.1358281373977661
step: 410, loss: 0.030740628018975258
step: 420, loss: 0.037791188806295395
step: 430, loss: 0.07628482580184937
step: 440, loss: 0.05971181020140648
step: 450, loss: 0.04199323430657387
step: 460, loss: 0.025148238986730576
step: 470, loss: 0.0070681264623999596
step: 480, loss: 0.12197679281234741
step: 490, loss: 0.02886761538684368
step: 500, loss: 0.02974085323512554
step: 510, loss: 0.003169839736074209
step: 520, loss: 0.027581248432397842
step: 530, loss: 0.057423185557127
step: 540, loss: 0.009166368283331394
step: 550, loss: 0.028830857947468758
step: 560, loss: 0.030469650402665138
step: 570, loss: 0.08953555673360825
step: 580, loss: 0.039024822413921356
step: 590, loss: 0.1114421859383583
step: 600, loss: 0.08684347569942474
step: 610, loss: 0.07789362221956253
step: 620, loss: 0.0070665678940713406
step: 630, loss: 0.0777372419834137
step: 640, loss: 0.13894765079021454
step: 650, loss: 0.010261000134050846
step: 660, loss: 0.049638405442237854
step: 670, loss: 0.03125675022602081
step: 680, loss: 0.04568392038345337
step: 690, loss: 0.030157549306750298
step: 700, loss: 0.08283935487270355
step: 710, loss: 0.0020202379673719406
step: 720, loss: 0.11545806378126144
step: 730, loss: 0.0398959182202816
step: 740, loss: 0.058335140347480774
step: 750, loss: 0.07292699813842773
step: 760, loss: 0.051191821694374084
step: 770, loss: 0.06336042284965515
step: 780, loss: 0.08677218109369278
step: 790, loss: 0.21816091239452362
step: 800, loss: 0.007980621419847012
step: 810, loss: 0.039331238716840744
step: 820, loss: 0.05691417679190636
step: 830, loss: 0.012114961631596088
step: 840, loss: 0.07362677156925201
step: 850, loss: 0.10722364485263824
step: 860, loss: 0.029879117384552956
step: 870, loss: 0.09307888895273209
step: 880, loss: 0.10511244088411331
step: 890, loss: 0.056342706084251404
step: 900, loss: 0.18815897405147552
step: 910, loss: 0.0009502045577391982
step: 920, loss: 0.021288562566041946
step: 930, loss: 0.10364045947790146
step: 940, loss: 0.0569833442568779
step: 950, loss: 0.09629486501216888
step: 960, loss: 0.12882192432880402
step: 970, loss: 0.05176100507378578
step: 980, loss: 0.14736874401569366
step: 990, loss: 0.06839514523744583
step: 1000, loss: 0.07532545179128647
step: 1010, loss: 0.11559853702783585
step: 1020, loss: 0.10555260628461838
step: 1030, loss: 0.012903316877782345
step: 1040, loss: 0.07673932611942291
step: 1050, loss: 0.024537675082683563
step: 1060, loss: 0.011585285887122154
step: 1070, loss: 0.01360394712537527
epoch 12: dev_f1=0.9270106927010693, f1=0.9239280774550485, best_f1=0.9288040949278734
step: 0, loss: 0.08688675612211227
step: 10, loss: 0.026584386825561523
step: 20, loss: 0.06015734001994133
step: 30, loss: 0.05001681298017502
step: 40, loss: 0.04358972609043121
step: 50, loss: 0.15002360939979553
step: 60, loss: 0.020567066967487335
step: 70, loss: 0.03238023445010185
step: 80, loss: 0.024413228034973145
step: 90, loss: 0.03258568421006203
step: 100, loss: 0.023309452459216118
step: 110, loss: 0.021422328427433968
step: 120, loss: 0.008015494793653488
step: 130, loss: 0.09752632677555084
step: 140, loss: 0.02115393802523613
step: 150, loss: 0.02659403346478939
step: 160, loss: 0.08901557326316833
step: 170, loss: 0.16764473915100098
step: 180, loss: 0.07169386744499207
step: 190, loss: 0.060743752866983414
step: 200, loss: 0.008181896060705185
step: 210, loss: 0.10562023520469666
step: 220, loss: 0.03096698597073555
step: 230, loss: 0.08829149603843689
step: 240, loss: 0.011993534862995148
step: 250, loss: 0.02086205966770649
step: 260, loss: 0.2505975067615509
step: 270, loss: 0.15045836567878723
step: 280, loss: 0.06456146389245987
step: 290, loss: 0.04737390950322151
step: 300, loss: 0.10273359715938568
step: 310, loss: 0.10119417309761047
step: 320, loss: 0.011702793650329113
step: 330, loss: 0.030692487955093384
step: 340, loss: 0.08030445873737335
step: 350, loss: 0.026916176080703735
step: 360, loss: 0.06380269676446915
step: 370, loss: 0.15787240862846375
step: 380, loss: 0.009059098549187183
step: 390, loss: 0.032610587775707245
step: 400, loss: 0.015083884820342064
step: 410, loss: 0.07435528934001923
step: 420, loss: 0.045649800449609756
step: 430, loss: 0.06459368765354156
step: 440, loss: 0.05937940627336502
step: 450, loss: 0.04968763142824173
step: 460, loss: 0.07097112387418747
step: 470, loss: 0.08171193301677704
step: 480, loss: 0.07690871506929398
step: 490, loss: 0.0016766504850238562
step: 500, loss: 0.12005401402711868
step: 510, loss: 0.03692580386996269
step: 520, loss: 0.04020094498991966
step: 530, loss: 0.09936843812465668
step: 540, loss: 0.042150527238845825
step: 550, loss: 0.06288374215364456
step: 560, loss: 0.10677728801965714
step: 570, loss: 0.03080720454454422
step: 580, loss: 0.03088219463825226
step: 590, loss: 0.05906132236123085
step: 600, loss: 0.022354191169142723
step: 610, loss: 0.021460512652993202
step: 620, loss: 0.054349035024642944
step: 630, loss: 0.01678471267223358
step: 640, loss: 0.05225692316889763
step: 650, loss: 0.06592566519975662
step: 660, loss: 0.02270086668431759
step: 670, loss: 0.0033103572204709053
step: 680, loss: 0.11551900953054428
step: 690, loss: 0.00016955190221779048
step: 700, loss: 0.05787556990981102
step: 710, loss: 0.039573561400175095
step: 720, loss: 0.0037974677979946136
step: 730, loss: 0.05755026265978813
step: 740, loss: 0.07391930371522903
step: 750, loss: 0.023090513423085213
step: 760, loss: 0.00027156731812283397
step: 770, loss: 0.0114017054438591
step: 780, loss: 0.12181759625673294
step: 790, loss: 0.003136626211926341
step: 800, loss: 0.07849955558776855
step: 810, loss: 0.04094979539513588
step: 820, loss: 0.11393199861049652
step: 830, loss: 0.07600320130586624
step: 840, loss: 0.12440884113311768
step: 850, loss: 0.05127357691526413
step: 860, loss: 0.004849485587328672
step: 870, loss: 0.011525469832122326
step: 880, loss: 0.03555545583367348
step: 890, loss: 0.053023915737867355
step: 900, loss: 0.07037421315908432
step: 910, loss: 0.10768520832061768
step: 920, loss: 0.058218903839588165
step: 930, loss: 0.04502945393323898
step: 940, loss: 0.10067285597324371
step: 950, loss: 0.09293019026517868
step: 960, loss: 0.09445662796497345
step: 970, loss: 0.012653103098273277
step: 980, loss: 0.12203554064035416
step: 990, loss: 0.11267612874507904
step: 1000, loss: 0.037763677537441254
step: 1010, loss: 0.002322510816156864
step: 1020, loss: 0.09581752121448517
step: 1030, loss: 0.02350616455078125
step: 1040, loss: 0.050763536244630814
step: 1050, loss: 0.03089079074561596
step: 1060, loss: 0.0175823662430048
step: 1070, loss: 0.03913925960659981
epoch 13: dev_f1=0.930341280972417, f1=0.9235787511649579, best_f1=0.9288040949278734
step: 0, loss: 0.011587911285459995
step: 10, loss: 0.06884635239839554
step: 20, loss: 0.018350793048739433
step: 30, loss: 0.05314029008150101
step: 40, loss: 0.000980293843895197
step: 50, loss: 0.0475914366543293
step: 60, loss: 0.037173476070165634
step: 70, loss: 0.01994236186146736
step: 80, loss: 0.02451370097696781
step: 90, loss: 0.00035826279781758785
step: 100, loss: 0.049033574759960175
step: 110, loss: 0.05151531472802162
step: 120, loss: 0.03945869579911232
step: 130, loss: 0.07727012783288956
step: 140, loss: 0.07196933776140213
step: 150, loss: 0.01131253968924284
step: 160, loss: 0.10152995586395264
step: 170, loss: 0.0021020201966166496
step: 180, loss: 0.012146965600550175
step: 190, loss: 0.0266531053930521
step: 200, loss: 0.14135198295116425
step: 210, loss: 0.016986126080155373
step: 220, loss: 0.05194432660937309
step: 230, loss: 0.08511920273303986
step: 240, loss: 0.036798685789108276
step: 250, loss: 0.04299810156226158
step: 260, loss: 0.022419609129428864
step: 270, loss: 0.020582661032676697
step: 280, loss: 0.028831645846366882
step: 290, loss: 0.11384620517492294
step: 300, loss: 0.012527409940958023
step: 310, loss: 0.01765083335340023
step: 320, loss: 0.0772557407617569
step: 330, loss: 0.04924606531858444
step: 340, loss: 0.027779361233115196
step: 350, loss: 0.06553157418966293
step: 360, loss: 0.0841287150979042
step: 370, loss: 0.0013141329400241375
step: 380, loss: 0.07849223166704178
step: 390, loss: 0.055515844374895096
step: 400, loss: 0.07127417623996735
step: 410, loss: 0.01519118994474411
step: 420, loss: 0.06374591588973999
step: 430, loss: 0.04088970646262169
step: 440, loss: 0.052991222590208054
step: 450, loss: 0.0563095286488533
step: 460, loss: 0.012939253821969032
step: 470, loss: 0.07014184445142746
step: 480, loss: 0.0683639869093895
step: 490, loss: 0.0284605510532856
step: 500, loss: 0.1648295819759369
step: 510, loss: 0.03974384441971779
step: 520, loss: 0.027156291529536247
step: 530, loss: 0.03179243206977844
step: 540, loss: 0.04783803969621658
step: 550, loss: 0.09758821129798889
step: 560, loss: 0.030258018523454666
step: 570, loss: 0.0008588173077441752
step: 580, loss: 0.001970035955309868
step: 590, loss: 0.1061222180724144
step: 600, loss: 0.042736683040857315
step: 610, loss: 0.030977627262473106
step: 620, loss: 0.03165319189429283
step: 630, loss: 0.006135446485131979
step: 640, loss: 0.005647479556500912
step: 650, loss: 0.05837011709809303
step: 660, loss: 0.09482279419898987
step: 670, loss: 0.11065902560949326
step: 680, loss: 0.026697887107729912
step: 690, loss: 0.04814842343330383
step: 700, loss: 0.12265320867300034
step: 710, loss: 0.0622866153717041
step: 720, loss: 0.04260032996535301
step: 730, loss: 0.09553650766611099
step: 740, loss: 0.02294071763753891
step: 750, loss: 0.031849753111600876
step: 760, loss: 0.10719309002161026
step: 770, loss: 0.1124090850353241
step: 780, loss: 0.08592601120471954
step: 790, loss: 0.02916242927312851
step: 800, loss: 0.04580003395676613
step: 810, loss: 0.031751908361911774
step: 820, loss: 0.02073013409972191
step: 830, loss: 0.03745283558964729
step: 840, loss: 0.056425221264362335
step: 850, loss: 0.010697970166802406
step: 860, loss: 0.11617513000965118
step: 870, loss: 0.06278242915868759
step: 880, loss: 0.03346716985106468
step: 890, loss: 0.035713594406843185
step: 900, loss: 0.19667229056358337
step: 910, loss: 0.11721565574407578
step: 920, loss: 0.04865950345993042
step: 930, loss: 0.06852082163095474
step: 940, loss: 0.05505899712443352
step: 950, loss: 0.06706051528453827
step: 960, loss: 0.014131644740700722
step: 970, loss: 0.03212936967611313
step: 980, loss: 0.12452756613492966
step: 990, loss: 0.043358318507671356
step: 1000, loss: 0.02174076810479164
step: 1010, loss: 0.12679453194141388
step: 1020, loss: 0.10974570363759995
step: 1030, loss: 0.03950771316885948
step: 1040, loss: 0.05728573724627495
step: 1050, loss: 0.06187679246068001
step: 1060, loss: 0.04078703746199608
step: 1070, loss: 0.036182910203933716
epoch 14: dev_f1=0.9356779268857011, f1=0.9244239631336406, best_f1=0.9288040949278734
step: 0, loss: 0.022164391353726387
step: 10, loss: 0.0035647486802190542
step: 20, loss: 0.018705623224377632
step: 30, loss: 0.03515801206231117
step: 40, loss: 0.09301937371492386
step: 50, loss: 0.0084674172103405
step: 60, loss: 0.040966372936964035
step: 70, loss: 0.013675607740879059
step: 80, loss: 0.08432582020759583
step: 90, loss: 0.05428961291909218
step: 100, loss: 0.018566660583019257
step: 110, loss: 0.03637196868658066
step: 120, loss: 0.02420767955482006
step: 130, loss: 0.02152535505592823
step: 140, loss: 0.02202693186700344
step: 150, loss: 0.04547673836350441
step: 160, loss: 0.013215845450758934
step: 170, loss: 0.03267161548137665
step: 180, loss: 0.027911966666579247
step: 190, loss: 0.04050947725772858
step: 200, loss: 0.00021865041344426572
step: 210, loss: 0.0621313638985157
step: 220, loss: 0.06893463432788849
step: 230, loss: 0.0064833746291697025
step: 240, loss: 3.493874100968242e-05
step: 250, loss: 0.030171707272529602
step: 260, loss: 6.416638643713668e-05
step: 270, loss: 0.028996553272008896
step: 280, loss: 0.08982942253351212
step: 290, loss: 2.809549005178269e-05
step: 300, loss: 0.06585961580276489
step: 310, loss: 0.1044887974858284
step: 320, loss: 0.0014608997153118253
step: 330, loss: 0.043057575821876526
step: 340, loss: 0.035667575895786285
step: 350, loss: 0.027713418006896973
step: 360, loss: 0.008176925592124462
step: 370, loss: 0.029470467939972878
step: 380, loss: 0.14857299625873566
step: 390, loss: 0.04574462026357651
step: 400, loss: 0.10726462304592133
step: 410, loss: 0.03499874845147133
step: 420, loss: 0.011289655230939388
step: 430, loss: 0.10055992752313614
step: 440, loss: 0.05546840652823448
step: 450, loss: 0.15079575777053833
step: 460, loss: 0.11611548066139221
step: 470, loss: 0.053307849913835526
step: 480, loss: 0.019953535869717598
step: 490, loss: 0.05312884971499443
step: 500, loss: 0.08172591030597687
step: 510, loss: 0.04700446501374245
step: 520, loss: 0.05686334893107414
step: 530, loss: 0.15317055583000183
step: 540, loss: 0.1559276431798935
step: 550, loss: 0.015070063062012196
step: 560, loss: 0.07509282231330872
step: 570, loss: 0.020132701843976974
step: 580, loss: 0.04437895119190216
step: 590, loss: 4.2294515878893435e-05
step: 600, loss: 0.0021128039807081223
step: 610, loss: 0.021676817908883095
step: 620, loss: 0.07430175691843033
step: 630, loss: 0.06303957849740982
step: 640, loss: 0.014581876806914806
step: 650, loss: 0.07551167905330658
step: 660, loss: 0.0872940644621849
step: 670, loss: 0.014725765213370323
step: 680, loss: 0.05014675483107567
step: 690, loss: 0.07078142464160919
step: 700, loss: 0.09653231501579285
step: 710, loss: 0.09184877574443817
step: 720, loss: 0.0074598160572350025
step: 730, loss: 0.05188761651515961
step: 740, loss: 0.04841937497258186
step: 750, loss: 7.386905781459063e-05
step: 760, loss: 0.06716594099998474
step: 770, loss: 0.1138169914484024
step: 780, loss: 0.11168458312749863
step: 790, loss: 0.03259929642081261
step: 800, loss: 0.11749209463596344
step: 810, loss: 0.02663443051278591
step: 820, loss: 0.07199586927890778
step: 830, loss: 0.04700332507491112
step: 840, loss: 0.04068704694509506
step: 850, loss: 0.0441468209028244
step: 860, loss: 0.04394609108567238
step: 870, loss: 0.01482621394097805
step: 880, loss: 0.11260146647691727
step: 890, loss: 0.00597546249628067
step: 900, loss: 0.03851423040032387
step: 910, loss: 0.0405065193772316
step: 920, loss: 0.049238838255405426
step: 930, loss: 2.7769952794187702e-05
step: 940, loss: 0.019588828086853027
step: 950, loss: 0.07367736846208572
step: 960, loss: 0.03024640493094921
step: 970, loss: 0.029881324619054794
step: 980, loss: 0.08617167919874191
step: 990, loss: 0.052325449883937836
step: 1000, loss: 0.053609371185302734
step: 1010, loss: 0.07766951620578766
step: 1020, loss: 0.03295760601758957
step: 1030, loss: 0.14497067034244537
step: 1040, loss: 0.031075315549969673
step: 1050, loss: 0.022497298195958138
step: 1060, loss: 0.012822895310819149
step: 1070, loss: 0.05397099256515503
epoch 15: dev_f1=0.9375879868606289, f1=0.9270588235294117, best_f1=0.9270588235294117
step: 0, loss: 0.01337140891700983
step: 10, loss: 0.06288163363933563
step: 20, loss: 0.05929367244243622
step: 30, loss: 0.0036761413794010878
step: 40, loss: 0.06391162425279617
step: 50, loss: 0.09817508608102798
step: 60, loss: 0.02613784372806549
step: 70, loss: 0.10323724150657654
step: 80, loss: 0.022328849881887436
step: 90, loss: 0.053582899272441864
step: 100, loss: 0.08512779325246811
step: 110, loss: 0.0009159547043964267
step: 120, loss: 0.0425993949174881
step: 130, loss: 0.049967460334300995
step: 140, loss: 0.03362354636192322
step: 150, loss: 0.04409085214138031
step: 160, loss: 0.06480652093887329
step: 170, loss: 0.029120750725269318
step: 180, loss: 0.024617662653326988
step: 190, loss: 0.13858279585838318
step: 200, loss: 0.038350727409124374
step: 210, loss: 0.00015711167361587286
step: 220, loss: 0.007555107120424509
step: 230, loss: 0.043180812150239944
step: 240, loss: 0.08396019786596298
step: 250, loss: 4.758522845804691e-05
step: 260, loss: 0.09177654981613159
step: 270, loss: 0.02053734101355076
step: 280, loss: 0.07904420793056488
step: 290, loss: 0.05505542457103729
step: 300, loss: 0.020332692191004753
step: 310, loss: 0.04613489285111427
step: 320, loss: 0.05809826776385307
step: 330, loss: 0.03840169683098793
step: 340, loss: 0.06415235996246338
step: 350, loss: 0.01659884862601757
step: 360, loss: 0.061913300305604935
step: 370, loss: 0.013128713704645634
step: 380, loss: 0.07966484874486923
step: 390, loss: 0.04014715179800987
step: 400, loss: 0.046916358172893524
step: 410, loss: 0.04933720454573631
step: 420, loss: 0.055458102375268936
step: 430, loss: 0.029849551618099213
step: 440, loss: 0.09467984735965729
step: 450, loss: 0.025126781314611435
step: 460, loss: 0.04672812297940254
step: 470, loss: 0.004570717923343182
step: 480, loss: 0.04512947052717209
step: 490, loss: 0.09716406464576721
step: 500, loss: 0.010498590767383575
step: 510, loss: 0.04991959035396576
step: 520, loss: 0.038175519555807114
step: 530, loss: 0.045085370540618896
step: 540, loss: 0.040277231484651566
step: 550, loss: 0.014410710893571377
step: 560, loss: 0.00884268619120121
step: 570, loss: 0.11385080218315125
step: 580, loss: 0.00011731527047231793
step: 590, loss: 0.07197381556034088
step: 600, loss: 2.7666084861266427e-05
step: 610, loss: 0.03705308586359024
step: 620, loss: 0.03036215901374817
step: 630, loss: 0.12389913201332092
step: 640, loss: 0.004408472217619419
step: 650, loss: 0.08732085675001144
step: 660, loss: 0.05050535872578621
step: 670, loss: 0.06828684359788895
step: 680, loss: 0.005850654095411301
step: 690, loss: 0.10053607076406479
step: 700, loss: 0.021541642025113106
step: 710, loss: 0.0408974252641201
step: 720, loss: 0.03366329148411751
step: 730, loss: 0.05643755570054054
step: 740, loss: 0.04127885028719902
step: 750, loss: 0.006461862474679947
step: 760, loss: 0.1430404782295227
step: 770, loss: 0.02833009883761406
step: 780, loss: 0.07017644494771957
step: 790, loss: 0.026486385613679886
step: 800, loss: 0.05477941408753395
step: 810, loss: 0.036295052617788315
step: 820, loss: 0.00010961259249597788
step: 830, loss: 0.06769067794084549
step: 840, loss: 0.04724147915840149
step: 850, loss: 0.06821198761463165
step: 860, loss: 0.013368074782192707
step: 870, loss: 0.110244020819664
step: 880, loss: 0.11358759552240372
step: 890, loss: 0.017818113788962364
step: 900, loss: 0.034592870622873306
step: 910, loss: 0.035457756370306015
step: 920, loss: 0.0002860232489183545
step: 930, loss: 0.017884546890854836
step: 940, loss: 0.07703597098588943
step: 950, loss: 0.03746385499835014
step: 960, loss: 0.07743440568447113
step: 970, loss: 0.05580570921301842
step: 980, loss: 0.028420377522706985
step: 990, loss: 0.02171388640999794
step: 1000, loss: 0.001677973777987063
step: 1010, loss: 0.00486417580395937
step: 1020, loss: 0.06223184987902641
step: 1030, loss: 0.03478465601801872
step: 1040, loss: 0.061853718012571335
step: 1050, loss: 0.04889560863375664
step: 1060, loss: 0.05145717412233353
step: 1070, loss: 0.05526185780763626
epoch 16: dev_f1=0.929007992477668, f1=0.9178789300797747, best_f1=0.9270588235294117
step: 0, loss: 0.07967226207256317
step: 10, loss: 0.0739201083779335
step: 20, loss: 0.06343937665224075
step: 30, loss: 0.06083102524280548
step: 40, loss: 0.0747402235865593
step: 50, loss: 0.010765057988464832
step: 60, loss: 0.027105756103992462
step: 70, loss: 0.024309877306222916
step: 80, loss: 0.00584480119869113
step: 90, loss: 0.010851697996258736
step: 100, loss: 0.07404527068138123
step: 110, loss: 0.018918123096227646
step: 120, loss: 0.05432717129588127
step: 130, loss: 0.0309711042791605
step: 140, loss: 0.05364788696169853
step: 150, loss: 0.05602005496621132
step: 160, loss: 0.034434184432029724
step: 170, loss: 0.05428973585367203
step: 180, loss: 0.07116999477148056
step: 190, loss: 0.020252889022231102
step: 200, loss: 0.00010069415293401107
step: 210, loss: 0.015550133772194386
step: 220, loss: 0.021000923588871956
step: 230, loss: 0.04475637152791023
step: 240, loss: 0.13021595776081085
step: 250, loss: 0.05747304856777191
step: 260, loss: 0.07272934913635254
step: 270, loss: 0.051986850798130035
step: 280, loss: 0.011825049296021461
step: 290, loss: 0.0556008443236351
step: 300, loss: 0.09178631752729416
step: 310, loss: 0.10760664194822311
step: 320, loss: 0.019282076507806778
step: 330, loss: 0.09695203602313995
step: 340, loss: 0.028393300250172615
step: 350, loss: 0.015318339690566063
step: 360, loss: 0.04471047595143318
step: 370, loss: 0.011363508179783821
step: 380, loss: 0.11279470473527908
step: 390, loss: 0.02471955679357052
step: 400, loss: 0.04729747772216797
step: 410, loss: 0.026408961042761803
step: 420, loss: 0.008044946007430553
step: 430, loss: 0.09187957644462585
step: 440, loss: 0.02120736613869667
step: 450, loss: 0.02434990182518959
step: 460, loss: 0.08534388244152069
step: 470, loss: 0.06355100870132446
step: 480, loss: 0.005737167317420244
step: 490, loss: 0.048976704478263855
step: 500, loss: 0.10307241976261139
step: 510, loss: 0.06667953729629517
step: 520, loss: 0.1290159374475479
step: 530, loss: 0.0634777620434761
step: 540, loss: 0.0036602586042135954
step: 550, loss: 0.18775667250156403
step: 560, loss: 0.07440201193094254
step: 570, loss: 0.03394496813416481
step: 580, loss: 0.01715291477739811
step: 590, loss: 0.07255230844020844
step: 600, loss: 0.08832906931638718
step: 610, loss: 0.02986225113272667
step: 620, loss: 0.05432353541254997
step: 630, loss: 0.04166067764163017
step: 640, loss: 0.09840545803308487
step: 650, loss: 0.01469920389354229
step: 660, loss: 0.03894532099366188
step: 670, loss: 0.0622483566403389
step: 680, loss: 3.0113524189800955e-05
step: 690, loss: 0.13109156489372253
step: 700, loss: 0.02644399367272854
step: 710, loss: 0.0005954753723926842
step: 720, loss: 0.038262978196144104
step: 730, loss: 0.03890649601817131
step: 740, loss: 0.06094139441847801
step: 750, loss: 0.013967444188892841
step: 760, loss: 0.02273605205118656
step: 770, loss: 0.013709519058465958
step: 780, loss: 0.004754266701638699
step: 790, loss: 0.07509006559848785
step: 800, loss: 0.04329478740692139
step: 810, loss: 0.08704744279384613
step: 820, loss: 0.02258404903113842
step: 830, loss: 8.998178964247927e-05
step: 840, loss: 0.09130778163671494
step: 850, loss: 0.035689566284418106
step: 860, loss: 0.035316888242959976
step: 870, loss: 0.03349922597408295
step: 880, loss: 0.07809745520353317
step: 890, loss: 7.932326843729243e-05
step: 900, loss: 0.00043045906932093203
step: 910, loss: 0.05071035772562027
step: 920, loss: 0.022109810262918472
step: 930, loss: 0.0348261259496212
step: 940, loss: 0.06528545916080475
step: 950, loss: 0.030219752341508865
step: 960, loss: 0.04626752436161041
step: 970, loss: 0.026585064828395844
step: 980, loss: 0.0018317236099392176
step: 990, loss: 0.030272217467427254
step: 1000, loss: 0.03243342041969299
step: 1010, loss: 0.058699339628219604
step: 1020, loss: 0.00202684523537755
step: 1030, loss: 0.11988543719053268
step: 1040, loss: 0.03252900391817093
step: 1050, loss: 0.005576920695602894
step: 1060, loss: 0.05572090297937393
step: 1070, loss: 0.1000862568616867
epoch 17: dev_f1=0.9311627906976745, f1=0.9235048678720444, best_f1=0.9270588235294117
step: 0, loss: 0.019206304103136063
step: 10, loss: 0.027713323011994362
step: 20, loss: 0.04996708780527115
step: 30, loss: 0.035339292138814926
step: 40, loss: 0.00012048579810652882
step: 50, loss: 0.0702383741736412
step: 60, loss: 0.022236688062548637
step: 70, loss: 0.10174503922462463
step: 80, loss: 0.01787218637764454
step: 90, loss: 0.01980523020029068
step: 100, loss: 0.0035153981298208237
step: 110, loss: 0.057859912514686584
step: 120, loss: 0.04207490757107735
step: 130, loss: 0.021028505638241768
step: 140, loss: 0.05131681635975838
step: 150, loss: 0.067691370844841
step: 160, loss: 0.04510711878538132
step: 170, loss: 0.004948043264448643
step: 180, loss: 0.04026729241013527
step: 190, loss: 2.2831336536910385e-05
step: 200, loss: 0.059839192777872086
step: 210, loss: 0.059754353016614914
step: 220, loss: 0.0763457864522934
step: 230, loss: 0.09447471052408218
step: 240, loss: 0.06564012169837952
step: 250, loss: 0.08763077855110168
step: 260, loss: 0.01262882724404335
step: 270, loss: 0.01960127241909504
step: 280, loss: 7.749898213660344e-05
step: 290, loss: 0.08314438164234161
step: 300, loss: 0.02237733080983162
step: 310, loss: 0.049813926219940186
step: 320, loss: 0.01658150926232338
step: 330, loss: 0.026435233652591705
step: 340, loss: 0.062195029109716415
step: 350, loss: 0.10612992197275162
step: 360, loss: 0.0007143366383388638
step: 370, loss: 0.0018767061410471797
step: 380, loss: 0.028706446290016174
step: 390, loss: 0.018490200862288475
step: 400, loss: 0.0026500148233026266
step: 410, loss: 0.03826522454619408
step: 420, loss: 0.03889107331633568
step: 430, loss: 0.05268971249461174
step: 440, loss: 0.0417020320892334
step: 450, loss: 0.0697394534945488
step: 460, loss: 0.06392219662666321
step: 470, loss: 0.04048670455813408
step: 480, loss: 4.545474439510144e-05
step: 490, loss: 0.002368046436458826
step: 500, loss: 0.0020476647187024355
step: 510, loss: 0.08697932958602905
step: 520, loss: 0.01147311832755804
step: 530, loss: 0.041308365762233734
step: 540, loss: 0.03313925117254257
step: 550, loss: 0.016358286142349243
step: 560, loss: 0.025438275188207626
step: 570, loss: 0.04723503813147545
step: 580, loss: 0.062481705099344254
step: 590, loss: 0.0359080545604229
step: 600, loss: 0.10224860906600952
step: 610, loss: 0.0186487827450037
step: 620, loss: 0.0031687826849520206
step: 630, loss: 0.10485633462667465
step: 640, loss: 0.03516862913966179
step: 650, loss: 0.048001255840063095
step: 660, loss: 0.010743281804025173
step: 670, loss: 1.997825711441692e-05
step: 680, loss: 0.05381348729133606
step: 690, loss: 0.0816129818558693
step: 700, loss: 0.024455245584249496
step: 710, loss: 0.011899539269506931
step: 720, loss: 0.030940236523747444
step: 730, loss: 0.0009811792988330126
step: 740, loss: 0.02293931506574154
step: 750, loss: 0.04531502723693848
step: 760, loss: 0.09768623113632202
step: 770, loss: 0.07948675751686096
step: 780, loss: 0.047510672360658646
step: 790, loss: 0.01625918038189411
step: 800, loss: 0.023981694132089615
step: 810, loss: 0.08179500699043274
step: 820, loss: 0.05500045418739319
step: 830, loss: 0.0380982868373394
step: 840, loss: 0.013423402793705463
step: 850, loss: 0.00014788046246394515
step: 860, loss: 0.02159632369875908
step: 870, loss: 0.037729717791080475
step: 880, loss: 0.059344567358493805
step: 890, loss: 0.031985919922590256
step: 900, loss: 0.06895360350608826
step: 910, loss: 0.04298766329884529
step: 920, loss: 0.02312524989247322
step: 930, loss: 0.09269074350595474
step: 940, loss: 0.05874435976147652
step: 950, loss: 0.0012535190908238292
step: 960, loss: 0.06594160944223404
step: 970, loss: 2.579238025646191e-05
step: 980, loss: 0.06182415038347244
step: 990, loss: 0.04256786033511162
step: 1000, loss: 0.0006295879138633609
step: 1010, loss: 0.02585890144109726
step: 1020, loss: 0.032076865434646606
step: 1030, loss: 0.02198806405067444
step: 1040, loss: 0.03381050378084183
step: 1050, loss: 0.08882661163806915
step: 1060, loss: 0.07560975849628448
step: 1070, loss: 0.009276711381971836
epoch 18: dev_f1=0.9286047596826879, f1=0.9202226345083488, best_f1=0.9270588235294117
step: 0, loss: 0.030170708894729614
step: 10, loss: 0.0008039725944399834
step: 20, loss: 0.03508645296096802
step: 30, loss: 0.03933843597769737
step: 40, loss: 0.03195022791624069
step: 50, loss: 0.024935469031333923
step: 60, loss: 0.08138276636600494
step: 70, loss: 0.05439494550228119
step: 80, loss: 0.014528448693454266
step: 90, loss: 0.01645316742360592
step: 100, loss: 0.012629218399524689
step: 110, loss: 0.017343446612358093
step: 120, loss: 0.018780220299959183
step: 130, loss: 0.016510259360074997
step: 140, loss: 1.993695696000941e-05
step: 150, loss: 0.03145898878574371
step: 160, loss: 0.0046406155452132225
step: 170, loss: 0.04058326035737991
step: 180, loss: 0.06947393715381622
step: 190, loss: 0.010155421681702137
step: 200, loss: 0.033574074506759644
step: 210, loss: 0.08553373068571091
step: 220, loss: 0.06295791268348694
step: 230, loss: 0.04506850987672806
step: 240, loss: 0.06659907847642899
step: 250, loss: 0.0325503945350647
step: 260, loss: 0.03651876002550125
step: 270, loss: 0.015278667211532593
step: 280, loss: 0.06234824284911156
step: 290, loss: 3.814173396676779e-05
step: 300, loss: 0.022162199020385742
step: 310, loss: 0.08086030185222626
step: 320, loss: 0.015904268249869347
step: 330, loss: 0.020514631643891335
step: 340, loss: 0.009931393899023533
step: 350, loss: 2.456736001477111e-05
step: 360, loss: 0.13184233009815216
step: 370, loss: 0.01677868142724037
step: 380, loss: 7.829509559087455e-05
step: 390, loss: 0.055166736245155334
step: 400, loss: 0.06785069406032562
step: 410, loss: 0.1452752649784088
step: 420, loss: 0.050289858132600784
step: 430, loss: 0.09795844554901123
step: 440, loss: 0.08525734394788742
step: 450, loss: 0.0001711226796032861
step: 460, loss: 0.0027629644609987736
step: 470, loss: 0.045155856758356094
step: 480, loss: 0.08849821239709854
step: 490, loss: 0.09319382905960083
step: 500, loss: 0.016190866008400917
step: 510, loss: 0.04123781621456146
step: 520, loss: 0.0562950037419796
step: 530, loss: 0.0010097771883010864
step: 540, loss: 0.15571513772010803
step: 550, loss: 0.000825718161650002
step: 560, loss: 0.1035628691315651
step: 570, loss: 0.13113947212696075
step: 580, loss: 0.042015377432107925
step: 590, loss: 0.0388948954641819
step: 600, loss: 0.0004331350210122764
step: 610, loss: 0.02350582554936409
step: 620, loss: 0.0013615740463137627
step: 630, loss: 0.017481008544564247
step: 640, loss: 0.03178582340478897
step: 650, loss: 0.010631544515490532
step: 660, loss: 0.06971912086009979
step: 670, loss: 0.053044360131025314
step: 680, loss: 0.01999252289533615
step: 690, loss: 0.0024707431439310312
step: 700, loss: 0.0727030336856842
step: 710, loss: 0.019816560670733452
step: 720, loss: 0.09028231352567673
step: 730, loss: 0.04317803680896759
step: 740, loss: 0.057006850838661194
step: 750, loss: 0.023818494752049446
step: 760, loss: 0.0004946502158418298
step: 770, loss: 0.021856851875782013
step: 780, loss: 0.02014785073697567
step: 790, loss: 0.05653084069490433
step: 800, loss: 0.048624977469444275
step: 810, loss: 0.019170451909303665
step: 820, loss: 0.10502538084983826
step: 830, loss: 0.051479559391736984
step: 840, loss: 0.014339368790388107
step: 850, loss: 0.04772178828716278
step: 860, loss: 0.09106046706438065
step: 870, loss: 0.07800658047199249
step: 880, loss: 0.04597049951553345
step: 890, loss: 0.013957461342215538
step: 900, loss: 0.047993794083595276
step: 910, loss: 0.03735554590821266
step: 920, loss: 0.0450298972427845
step: 930, loss: 0.06955329328775406
step: 940, loss: 0.02054334245622158
step: 950, loss: 0.06434107571840286
step: 960, loss: 0.06595748662948608
step: 970, loss: 0.014661908149719238
step: 980, loss: 0.03770193085074425
step: 990, loss: 0.040010031312704086
step: 1000, loss: 0.04285118356347084
step: 1010, loss: 0.06596719473600388
step: 1020, loss: 0.05764266476035118
step: 1030, loss: 0.017742088064551353
step: 1040, loss: 0.08743423968553543
step: 1050, loss: 0.044830404222011566
step: 1060, loss: 0.00981884729117155
step: 1070, loss: 0.0099478205665946
epoch 19: dev_f1=0.9303201506591336, f1=0.9200376293508937, best_f1=0.9270588235294117
step: 0, loss: 0.0625515878200531
step: 10, loss: 0.017931155860424042
step: 20, loss: 0.02573866955935955
step: 30, loss: 0.03556074574589729
step: 40, loss: 0.019872432574629784
step: 50, loss: 0.022496480494737625
step: 60, loss: 0.030593834817409515
step: 70, loss: 0.02428751066327095
step: 80, loss: 0.040835898369550705
step: 90, loss: 0.0002526423195376992
step: 100, loss: 0.004943451378494501
step: 110, loss: 0.03443390130996704
step: 120, loss: 0.0002468324382789433
step: 130, loss: 0.027507208287715912
step: 140, loss: 3.835181632894091e-05
step: 150, loss: 0.05428214371204376
step: 160, loss: 0.0518956333398819
step: 170, loss: 0.028831403702497482
step: 180, loss: 0.01652383990585804
step: 190, loss: 0.03190409392118454
step: 200, loss: 0.00013546498666983098
step: 210, loss: 0.00022891366097610444
step: 220, loss: 3.6895715311402455e-05
step: 230, loss: 0.05895118787884712
step: 240, loss: 0.16833552718162537
step: 250, loss: 0.060293301939964294
step: 260, loss: 0.007935118861496449
step: 270, loss: 0.0627467930316925
step: 280, loss: 0.018428461626172066
step: 290, loss: 0.024436073377728462
step: 300, loss: 0.05504953861236572
step: 310, loss: 0.07251035422086716
step: 320, loss: 0.07229108363389969
step: 330, loss: 5.491653791978024e-05
step: 340, loss: 0.03557639569044113
step: 350, loss: 0.0719379186630249
step: 360, loss: 0.07969402521848679
step: 370, loss: 0.03025803342461586
step: 380, loss: 0.04588477313518524
step: 390, loss: 5.7995599490823224e-05
step: 400, loss: 0.02696617692708969
step: 410, loss: 0.0028956420719623566
step: 420, loss: 0.12317725270986557
step: 430, loss: 0.008517644368112087
step: 440, loss: 0.02604862116277218
step: 450, loss: 1.7009415387292393e-05
step: 460, loss: 0.0003825464809779078
step: 470, loss: 0.050390128046274185
step: 480, loss: 0.05323551222681999
step: 490, loss: 0.058085206896066666
step: 500, loss: 0.020585523918271065
step: 510, loss: 0.024717478081583977
step: 520, loss: 0.0007179076201282442
step: 530, loss: 0.025017600506544113
step: 540, loss: 0.04247499629855156
step: 550, loss: 0.07983548939228058
step: 560, loss: 2.107340333168395e-05
step: 570, loss: 2.468612728989683e-05
step: 580, loss: 0.03892196714878082
step: 590, loss: 2.666441105247941e-05
step: 600, loss: 0.05234592407941818
step: 610, loss: 3.922690302715637e-05
step: 620, loss: 0.05658244341611862
step: 630, loss: 0.043193791061639786
step: 640, loss: 0.08866488933563232
step: 650, loss: 0.1205148920416832
step: 660, loss: 0.026642069220542908
step: 670, loss: 0.04931199923157692
step: 680, loss: 0.07152828574180603
step: 690, loss: 0.10487005114555359
step: 700, loss: 0.008854426443576813
step: 710, loss: 0.04310622811317444
step: 720, loss: 0.08216769993305206
step: 730, loss: 0.00014553604705724865
step: 740, loss: 0.03723534569144249
step: 750, loss: 0.007233838550746441
step: 760, loss: 0.02905651554465294
step: 770, loss: 0.02342066913843155
step: 780, loss: 3.163635483360849e-05
step: 790, loss: 0.06653653085231781
step: 800, loss: 0.011735557578504086
step: 810, loss: 0.015463112853467464
step: 820, loss: 0.015515385195612907
step: 830, loss: 0.03979489579796791
step: 840, loss: 0.0544198639690876
step: 850, loss: 0.014919072389602661
step: 860, loss: 0.043999895453453064
step: 870, loss: 3.4960459743160754e-05
step: 880, loss: 0.059405043721199036
step: 890, loss: 0.022214597091078758
step: 900, loss: 0.01576523296535015
step: 910, loss: 6.550888065248728e-05
step: 920, loss: 0.018415795639157295
step: 930, loss: 0.02810307964682579
step: 940, loss: 0.04239043593406677
step: 950, loss: 0.07220549136400223
step: 960, loss: 0.0569714717566967
step: 970, loss: 0.03715062886476517
step: 980, loss: 0.038673680275678635
step: 990, loss: 0.04338604211807251
step: 1000, loss: 0.0441240556538105
step: 1010, loss: 0.062739297747612
step: 1020, loss: 0.11928269267082214
step: 1030, loss: 0.057261865586042404
step: 1040, loss: 0.05090557783842087
step: 1050, loss: 1.8622038624016568e-05
step: 1060, loss: 0.05264855548739433
step: 1070, loss: 0.07255002856254578
epoch 20: dev_f1=0.9309534992954438, f1=0.9207688701359588, best_f1=0.9270588235294117
