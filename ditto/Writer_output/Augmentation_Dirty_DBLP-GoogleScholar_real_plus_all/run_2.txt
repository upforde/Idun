cuda
Device: cuda
step: 0, loss: 0.7639434933662415
step: 10, loss: 0.3766980469226837
step: 20, loss: 0.4149358570575714
step: 30, loss: 0.3815120458602905
step: 40, loss: 0.4262341558933258
step: 50, loss: 0.4524557888507843
step: 60, loss: 0.10442192852497101
step: 70, loss: 0.28161799907684326
step: 80, loss: 0.23676563799381256
step: 90, loss: 0.16748204827308655
step: 100, loss: 0.33288586139678955
step: 110, loss: 0.35394227504730225
step: 120, loss: 0.2503439784049988
step: 130, loss: 0.15901701152324677
step: 140, loss: 0.11681614071130753
step: 150, loss: 0.2191409021615982
step: 160, loss: 0.327654093503952
step: 170, loss: 0.14023450016975403
step: 180, loss: 0.1506660431623459
step: 190, loss: 0.2666451632976532
step: 200, loss: 0.17205888032913208
step: 210, loss: 0.10861813277006149
step: 220, loss: 0.08422891050577164
step: 230, loss: 0.14987966418266296
step: 240, loss: 0.12885604798793793
step: 250, loss: 0.17053957283496857
step: 260, loss: 0.21914073824882507
step: 270, loss: 0.2637128531932831
step: 280, loss: 0.36193734407424927
step: 290, loss: 0.09700435400009155
step: 300, loss: 0.18034960329532623
step: 310, loss: 0.35945984721183777
step: 320, loss: 0.12032679468393326
step: 330, loss: 0.19813355803489685
step: 340, loss: 0.1443817913532257
step: 350, loss: 0.08020016551017761
step: 360, loss: 0.07257913053035736
step: 370, loss: 0.1817757487297058
step: 380, loss: 0.12993831932544708
step: 390, loss: 0.15467624366283417
step: 400, loss: 0.2009158879518509
step: 410, loss: 0.0981985330581665
step: 420, loss: 0.15354803204536438
step: 430, loss: 0.13858206570148468
step: 440, loss: 0.17474624514579773
step: 450, loss: 0.08465097844600677
step: 460, loss: 0.16559699177742004
step: 470, loss: 0.08767329901456833
step: 480, loss: 0.18938326835632324
step: 490, loss: 0.19348640739917755
step: 500, loss: 0.26595166325569153
step: 510, loss: 0.1199009045958519
step: 520, loss: 0.1937209963798523
step: 530, loss: 0.06607110798358917
step: 540, loss: 0.2576744556427002
step: 550, loss: 0.2872934937477112
step: 560, loss: 0.24192498624324799
step: 570, loss: 0.24130594730377197
step: 580, loss: 0.07741785794496536
step: 590, loss: 0.1256168633699417
step: 600, loss: 0.17614571750164032
step: 610, loss: 0.19116230309009552
step: 620, loss: 0.20985309779644012
step: 630, loss: 0.1740511655807495
step: 640, loss: 0.17482851445674896
step: 650, loss: 0.15360882878303528
step: 660, loss: 0.16688017547130585
step: 670, loss: 0.026308439671993256
step: 680, loss: 0.12339823693037033
step: 690, loss: 0.11390269547700882
step: 700, loss: 0.17060165107250214
step: 710, loss: 0.12094692140817642
step: 720, loss: 0.24428461492061615
step: 730, loss: 0.10438945144414902
step: 740, loss: 0.16741196811199188
step: 750, loss: 0.1837451457977295
step: 760, loss: 0.2538713216781616
step: 770, loss: 0.11438950896263123
step: 780, loss: 0.11999650299549103
step: 790, loss: 0.22646558284759521
step: 800, loss: 0.06619006395339966
step: 810, loss: 0.18336066603660583
step: 820, loss: 0.15067227184772491
step: 830, loss: 0.07326869666576385
step: 840, loss: 0.2833744287490845
step: 850, loss: 0.24172478914260864
step: 860, loss: 0.12899014353752136
step: 870, loss: 0.1431303769350052
step: 880, loss: 0.10841180384159088
step: 890, loss: 0.1728803813457489
step: 900, loss: 0.10942047834396362
step: 910, loss: 0.1261131465435028
step: 920, loss: 0.08488953858613968
step: 930, loss: 0.13041380047798157
step: 940, loss: 0.08582382649183273
step: 950, loss: 0.2034059762954712
step: 960, loss: 0.09967540949583054
step: 970, loss: 0.08846144378185272
step: 980, loss: 0.13564574718475342
step: 990, loss: 0.10165153443813324
step: 1000, loss: 0.05074707418680191
step: 1010, loss: 0.19638201594352722
step: 1020, loss: 0.14306718111038208
step: 1030, loss: 0.2447436898946762
step: 1040, loss: 0.07436003535985947
step: 1050, loss: 0.1542462259531021
step: 1060, loss: 0.2624981999397278
step: 1070, loss: 0.2156989872455597
epoch 1: dev_f1=0.9296037296037295, f1=0.926012098650535, best_f1=0.926012098650535
step: 0, loss: 0.11356150358915329
step: 10, loss: 0.16360291838645935
step: 20, loss: 0.023058757185935974
step: 30, loss: 0.03957424685359001
step: 40, loss: 0.10219491273164749
step: 50, loss: 0.11427327990531921
step: 60, loss: 0.15705518424510956
step: 70, loss: 0.05694862827658653
step: 80, loss: 0.20399907231330872
step: 90, loss: 0.08473850041627884
step: 100, loss: 0.09775283187627792
step: 110, loss: 0.19004306197166443
step: 120, loss: 0.09314227104187012
step: 130, loss: 0.07962411642074585
step: 140, loss: 0.0471501350402832
step: 150, loss: 0.011158496141433716
step: 160, loss: 0.11052319407463074
step: 170, loss: 0.12256507575511932
step: 180, loss: 0.0773591697216034
step: 190, loss: 0.19281908869743347
step: 200, loss: 0.28054481744766235
step: 210, loss: 0.12273313850164413
step: 220, loss: 0.05242380127310753
step: 230, loss: 0.07295366376638412
step: 240, loss: 0.13840259611606598
step: 250, loss: 0.14290419220924377
step: 260, loss: 0.14449277520179749
step: 270, loss: 0.11012459546327591
step: 280, loss: 0.19854232668876648
step: 290, loss: 0.09204475581645966
step: 300, loss: 0.027613407000899315
step: 310, loss: 0.10252165794372559
step: 320, loss: 0.11342304199934006
step: 330, loss: 0.09179897606372833
step: 340, loss: 0.11006354540586472
step: 350, loss: 0.09446492791175842
step: 360, loss: 0.09313198179006577
step: 370, loss: 0.10154799371957779
step: 380, loss: 0.0896865725517273
step: 390, loss: 0.2370741218328476
step: 400, loss: 0.0717393234372139
step: 410, loss: 0.1413670778274536
step: 420, loss: 0.13389696180820465
step: 430, loss: 0.13447406888008118
step: 440, loss: 0.19600160419940948
step: 450, loss: 0.11404766142368317
step: 460, loss: 0.10104165971279144
step: 470, loss: 0.07037296891212463
step: 480, loss: 0.07523378729820251
step: 490, loss: 0.19670897722244263
step: 500, loss: 0.22442102432250977
step: 510, loss: 0.2937524914741516
step: 520, loss: 0.12887676060199738
step: 530, loss: 0.16746355593204498
step: 540, loss: 0.07962780445814133
step: 550, loss: 0.12376956641674042
step: 560, loss: 0.1307772696018219
step: 570, loss: 0.14384430646896362
step: 580, loss: 0.1266563981771469
step: 590, loss: 0.11678338795900345
step: 600, loss: 0.19054514169692993
step: 610, loss: 0.17109717428684235
step: 620, loss: 0.20585888624191284
step: 630, loss: 0.09091722965240479
step: 640, loss: 0.13581497967243195
step: 650, loss: 0.03491418436169624
step: 660, loss: 0.09075316786766052
step: 670, loss: 0.1464044600725174
step: 680, loss: 0.23617078363895416
step: 690, loss: 0.1237318143248558
step: 700, loss: 0.18253839015960693
step: 710, loss: 0.18389564752578735
step: 720, loss: 0.07488055527210236
step: 730, loss: 0.16350696980953217
step: 740, loss: 0.05853870138525963
step: 750, loss: 0.043683312833309174
step: 760, loss: 0.08385109156370163
step: 770, loss: 0.12091434001922607
step: 780, loss: 0.04352467134594917
step: 790, loss: 0.034199491143226624
step: 800, loss: 0.11691273748874664
step: 810, loss: 0.12650004029273987
step: 820, loss: 0.11445793509483337
step: 830, loss: 0.13386666774749756
step: 840, loss: 0.0863756611943245
step: 850, loss: 0.2418925166130066
step: 860, loss: 0.10734807699918747
step: 870, loss: 0.07217926532030106
step: 880, loss: 0.1380309760570526
step: 890, loss: 0.27294304966926575
step: 900, loss: 0.04207591339945793
step: 910, loss: 0.09860116243362427
step: 920, loss: 0.13433869183063507
step: 930, loss: 0.271499365568161
step: 940, loss: 0.23268894851207733
step: 950, loss: 0.022835809737443924
step: 960, loss: 0.18119843304157257
step: 970, loss: 0.10061962902545929
step: 980, loss: 0.05915605649352074
step: 990, loss: 0.13993866741657257
step: 1000, loss: 0.18505774438381195
step: 1010, loss: 0.1024039089679718
step: 1020, loss: 0.2490619570016861
step: 1030, loss: 0.13355885446071625
step: 1040, loss: 0.16983014345169067
step: 1050, loss: 0.1552455872297287
step: 1060, loss: 0.20157943665981293
step: 1070, loss: 0.12311387062072754
epoch 2: dev_f1=0.9306008383791335, f1=0.9243697478991597, best_f1=0.9243697478991597
step: 0, loss: 0.05578720569610596
step: 10, loss: 0.03296256437897682
step: 20, loss: 0.1531885713338852
step: 30, loss: 0.023853030055761337
step: 40, loss: 0.08698780089616776
step: 50, loss: 0.07552026212215424
step: 60, loss: 0.1869053840637207
step: 70, loss: 0.11359542608261108
step: 80, loss: 0.09896684437990189
step: 90, loss: 0.1131616085767746
step: 100, loss: 0.07205530256032944
step: 110, loss: 0.04871227964758873
step: 120, loss: 0.042452629655599594
step: 130, loss: 0.24020026624202728
step: 140, loss: 0.08124911785125732
step: 150, loss: 0.07179876416921616
step: 160, loss: 0.1216481477022171
step: 170, loss: 0.0981736108660698
step: 180, loss: 0.1333276778459549
step: 190, loss: 0.06553177535533905
step: 200, loss: 0.06707733869552612
step: 210, loss: 0.05988137423992157
step: 220, loss: 0.14916378259658813
step: 230, loss: 0.1006769984960556
step: 240, loss: 0.06546034663915634
step: 250, loss: 0.1254824548959732
step: 260, loss: 0.09914325922727585
step: 270, loss: 0.0556931234896183
step: 280, loss: 0.057704467326402664
step: 290, loss: 0.11426158249378204
step: 300, loss: 0.13414600491523743
step: 310, loss: 0.24489350616931915
step: 320, loss: 0.06400596350431442
step: 330, loss: 0.03251579403877258
step: 340, loss: 0.15434256196022034
step: 350, loss: 0.06272763758897781
step: 360, loss: 0.2275356948375702
step: 370, loss: 0.14044848084449768
step: 380, loss: 0.13401025533676147
step: 390, loss: 0.14727972447872162
step: 400, loss: 0.09309985488653183
step: 410, loss: 0.03540044277906418
step: 420, loss: 0.05527709424495697
step: 430, loss: 0.13740739226341248
step: 440, loss: 0.08999377489089966
step: 450, loss: 0.292357861995697
step: 460, loss: 0.17480899393558502
step: 470, loss: 0.029142159968614578
step: 480, loss: 0.09583276510238647
step: 490, loss: 0.12533430755138397
step: 500, loss: 0.14965157210826874
step: 510, loss: 0.13194115459918976
step: 520, loss: 0.10374060273170471
step: 530, loss: 0.07341727614402771
step: 540, loss: 0.0304904542863369
step: 550, loss: 0.10557088255882263
step: 560, loss: 0.03573907911777496
step: 570, loss: 0.060659587383270264
step: 580, loss: 0.03892705217003822
step: 590, loss: 0.03603117913007736
step: 600, loss: 0.0824451670050621
step: 610, loss: 0.150858074426651
step: 620, loss: 0.2546018958091736
step: 630, loss: 0.09857453405857086
step: 640, loss: 0.05981535464525223
step: 650, loss: 0.2101171761751175
step: 660, loss: 0.12219899892807007
step: 670, loss: 0.10626587271690369
step: 680, loss: 0.15887963771820068
step: 690, loss: 0.28641897439956665
step: 700, loss: 0.1769670993089676
step: 710, loss: 0.048333790153265
step: 720, loss: 0.20865881443023682
step: 730, loss: 0.04334990680217743
step: 740, loss: 0.3077864646911621
step: 750, loss: 0.14140096306800842
step: 760, loss: 0.1819567084312439
step: 770, loss: 0.07098373770713806
step: 780, loss: 0.08464761823415756
step: 790, loss: 0.05533861368894577
step: 800, loss: 0.18359936773777008
step: 810, loss: 0.07726312428712845
step: 820, loss: 0.08733657747507095
step: 830, loss: 0.08744118362665176
step: 840, loss: 0.13029171526432037
step: 850, loss: 0.17536808550357819
step: 860, loss: 0.1453016996383667
step: 870, loss: 0.0857582613825798
step: 880, loss: 0.13568216562271118
step: 890, loss: 0.1322721391916275
step: 900, loss: 0.09822211414575577
step: 910, loss: 0.048188284039497375
step: 920, loss: 0.17015978693962097
step: 930, loss: 0.12136410176753998
step: 940, loss: 0.1286662220954895
step: 950, loss: 0.02534378319978714
step: 960, loss: 0.12472432106733322
step: 970, loss: 0.06678885966539383
step: 980, loss: 0.11334328353404999
step: 990, loss: 0.12230651825666428
step: 1000, loss: 0.04322999715805054
step: 1010, loss: 0.10756709426641464
step: 1020, loss: 0.19081811606884003
step: 1030, loss: 0.1109166219830513
step: 1040, loss: 0.1330500990152359
step: 1050, loss: 0.12906304001808167
step: 1060, loss: 0.05860118567943573
step: 1070, loss: 0.05700963735580444
epoch 3: dev_f1=0.9136490250696379, f1=0.9117920148560816, best_f1=0.9243697478991597
step: 0, loss: 0.07630925625562668
step: 10, loss: 0.132933109998703
step: 20, loss: 0.1425342857837677
step: 30, loss: 0.05335402116179466
step: 40, loss: 0.020305082201957703
step: 50, loss: 0.1127883568406105
step: 60, loss: 0.10891225934028625
step: 70, loss: 0.05006695166230202
step: 80, loss: 0.1048358678817749
step: 90, loss: 0.09030357748270035
step: 100, loss: 0.07153143733739853
step: 110, loss: 0.0992303192615509
step: 120, loss: 0.08674568682909012
step: 130, loss: 0.06075166538357735
step: 140, loss: 0.062150631099939346
step: 150, loss: 0.177808478474617
step: 160, loss: 0.04146004468202591
step: 170, loss: 0.020623277872800827
step: 180, loss: 0.09548330307006836
step: 190, loss: 0.0906611904501915
step: 200, loss: 0.06859096139669418
step: 210, loss: 0.11099102348089218
step: 220, loss: 0.095169298350811
step: 230, loss: 0.07432059943675995
step: 240, loss: 0.10852346569299698
step: 250, loss: 0.0967109203338623
step: 260, loss: 0.021630674600601196
step: 270, loss: 0.19470173120498657
step: 280, loss: 0.05163782835006714
step: 290, loss: 0.03476134315133095
step: 300, loss: 0.2019549161195755
step: 310, loss: 0.09446574747562408
step: 320, loss: 0.019777406007051468
step: 330, loss: 0.16360008716583252
step: 340, loss: 0.04594501852989197
step: 350, loss: 0.04338138550519943
step: 360, loss: 0.22639986872673035
step: 370, loss: 0.07171936333179474
step: 380, loss: 0.09969872236251831
step: 390, loss: 0.07874599099159241
step: 400, loss: 0.13361136615276337
step: 410, loss: 0.0910339206457138
step: 420, loss: 0.11763039231300354
step: 430, loss: 0.18834221363067627
step: 440, loss: 0.15119586884975433
step: 450, loss: 0.15053075551986694
step: 460, loss: 0.062339503318071365
step: 470, loss: 0.051191095262765884
step: 480, loss: 0.08613140881061554
step: 490, loss: 0.07230603694915771
step: 500, loss: 0.09906234592199326
step: 510, loss: 0.08258309215307236
step: 520, loss: 0.02513975463807583
step: 530, loss: 0.15351779758930206
step: 540, loss: 0.13240894675254822
step: 550, loss: 0.16498319804668427
step: 560, loss: 0.09479372203350067
step: 570, loss: 0.0493616946041584
step: 580, loss: 0.06519407033920288
step: 590, loss: 0.10806155204772949
step: 600, loss: 0.10400547087192535
step: 610, loss: 0.06200873479247093
step: 620, loss: 0.12178482860326767
step: 630, loss: 0.0648680254817009
step: 640, loss: 0.09310393035411835
step: 650, loss: 0.04230344295501709
step: 660, loss: 0.023022612556815147
step: 670, loss: 0.08701957017183304
step: 680, loss: 0.07999290525913239
step: 690, loss: 0.09422550350427628
step: 700, loss: 0.0707474872469902
step: 710, loss: 0.08722501248121262
step: 720, loss: 0.047114357352256775
step: 730, loss: 0.01918838545680046
step: 740, loss: 0.02108248881995678
step: 750, loss: 0.061102498322725296
step: 760, loss: 0.0840684324502945
step: 770, loss: 0.15094007551670074
step: 780, loss: 0.18061763048171997
step: 790, loss: 0.09701487421989441
step: 800, loss: 0.19679294526576996
step: 810, loss: 0.14147885143756866
step: 820, loss: 0.022971661761403084
step: 830, loss: 0.11226533353328705
step: 840, loss: 0.09423491358757019
step: 850, loss: 0.0844418853521347
step: 860, loss: 0.0940239205956459
step: 870, loss: 0.11998683214187622
step: 880, loss: 0.004613968078047037
step: 890, loss: 0.14449146389961243
step: 900, loss: 0.12779535353183746
step: 910, loss: 0.02524298056960106
step: 920, loss: 0.04605529457330704
step: 930, loss: 0.1856311410665512
step: 940, loss: 0.0911077931523323
step: 950, loss: 0.12148638069629669
step: 960, loss: 0.021460672840476036
step: 970, loss: 0.08264458179473877
step: 980, loss: 0.03310951590538025
step: 990, loss: 0.05672534927725792
step: 1000, loss: 0.13711902499198914
step: 1010, loss: 0.0745236948132515
step: 1020, loss: 0.10419703274965286
step: 1030, loss: 0.033626738935709
step: 1040, loss: 0.03630394488573074
step: 1050, loss: 0.1088481992483139
step: 1060, loss: 0.0889570489525795
step: 1070, loss: 0.06608543545007706
epoch 4: dev_f1=0.928505957836847, f1=0.9272976680384087, best_f1=0.9243697478991597
step: 0, loss: 0.16954080760478973
step: 10, loss: 0.08048810809850693
step: 20, loss: 0.11114456504583359
step: 30, loss: 0.0640399307012558
step: 40, loss: 0.060951944440603256
step: 50, loss: 0.06056095287203789
step: 60, loss: 0.1056523472070694
step: 70, loss: 0.06696540862321854
step: 80, loss: 0.07486948370933533
step: 90, loss: 0.04088432341814041
step: 100, loss: 0.059849776327610016
step: 110, loss: 0.057615235447883606
step: 120, loss: 0.07097926735877991
step: 130, loss: 0.10870981961488724
step: 140, loss: 0.1348840296268463
step: 150, loss: 0.040847860276699066
step: 160, loss: 0.007774562109261751
step: 170, loss: 0.04084276780486107
step: 180, loss: 0.13078589737415314
step: 190, loss: 0.09789025783538818
step: 200, loss: 0.029180016368627548
step: 210, loss: 0.1620769500732422
step: 220, loss: 0.11244262754917145
step: 230, loss: 0.06481041759252548
step: 240, loss: 0.014019258320331573
step: 250, loss: 0.08400185406208038
step: 260, loss: 0.05413927882909775
step: 270, loss: 0.09606244415044785
step: 280, loss: 0.14536020159721375
step: 290, loss: 0.11201431602239609
step: 300, loss: 0.10395415872335434
step: 310, loss: 0.10436772555112839
step: 320, loss: 0.1045268177986145
step: 330, loss: 0.00018487792112864554
step: 340, loss: 0.06378407031297684
step: 350, loss: 0.02226804941892624
step: 360, loss: 0.044149432331323624
step: 370, loss: 0.12282685935497284
step: 380, loss: 0.20199362933635712
step: 390, loss: 0.055220749229192734
step: 400, loss: 0.07034487277269363
step: 410, loss: 0.11725104600191116
step: 420, loss: 0.08883142471313477
step: 430, loss: 0.13057689368724823
step: 440, loss: 0.12030810117721558
step: 450, loss: 0.1207025945186615
step: 460, loss: 0.059457603842020035
step: 470, loss: 0.17016614973545074
step: 480, loss: 0.1325954794883728
step: 490, loss: 0.13430507481098175
step: 500, loss: 0.0583169125020504
step: 510, loss: 0.028650153428316116
step: 520, loss: 0.05591510236263275
step: 530, loss: 0.35227733850479126
step: 540, loss: 0.2372646927833557
step: 550, loss: 0.07432368397712708
step: 560, loss: 0.11155423521995544
step: 570, loss: 0.030458934605121613
step: 580, loss: 0.07125222682952881
step: 590, loss: 0.06238557770848274
step: 600, loss: 0.04913148283958435
step: 610, loss: 0.052443765103816986
step: 620, loss: 0.18618758022785187
step: 630, loss: 0.2961604595184326
step: 640, loss: 0.07131624221801758
step: 650, loss: 0.0840563178062439
step: 660, loss: 0.03696226328611374
step: 670, loss: 0.05441552773118019
step: 680, loss: 0.08784492313861847
step: 690, loss: 0.10434136539697647
step: 700, loss: 0.19059933722019196
step: 710, loss: 0.061063215136528015
step: 720, loss: 0.10911203920841217
step: 730, loss: 0.04157291725277901
step: 740, loss: 0.09008368104696274
step: 750, loss: 0.12306385487318039
step: 760, loss: 0.1323438137769699
step: 770, loss: 0.13296329975128174
step: 780, loss: 0.1429034322500229
step: 790, loss: 0.08872967958450317
step: 800, loss: 0.0877550020813942
step: 810, loss: 0.041929252445697784
step: 820, loss: 0.19888868927955627
step: 830, loss: 0.08531555533409119
step: 840, loss: 0.07801412045955658
step: 850, loss: 0.09374747425317764
step: 860, loss: 0.07851831614971161
step: 870, loss: 0.09337745606899261
step: 880, loss: 0.15879882872104645
step: 890, loss: 0.07513830810785294
step: 900, loss: 0.10741835832595825
step: 910, loss: 0.13508735597133636
step: 920, loss: 0.02263450250029564
step: 930, loss: 0.03977757692337036
step: 940, loss: 0.11586429923772812
step: 950, loss: 0.09922607243061066
step: 960, loss: 0.20963136851787567
step: 970, loss: 0.024993225932121277
step: 980, loss: 0.1183096244931221
step: 990, loss: 0.06967420876026154
step: 1000, loss: 0.06889700144529343
step: 1010, loss: 0.05139878764748573
step: 1020, loss: 0.06928980350494385
step: 1030, loss: 0.13530685007572174
step: 1040, loss: 0.07397272437810898
step: 1050, loss: 0.20960724353790283
step: 1060, loss: 0.08197340369224548
step: 1070, loss: 0.03859240561723709
epoch 5: dev_f1=0.939282428702852, f1=0.9457221711131555, best_f1=0.9457221711131555
step: 0, loss: 0.0605061911046505
step: 10, loss: 0.027566425502300262
step: 20, loss: 0.0971444621682167
step: 30, loss: 0.12475144118070602
step: 40, loss: 0.08891721069812775
step: 50, loss: 0.011099121533334255
step: 60, loss: 0.08112309128046036
step: 70, loss: 0.09429710358381271
step: 80, loss: 0.08806571364402771
step: 90, loss: 0.06902088969945908
step: 100, loss: 0.01771092228591442
step: 110, loss: 0.1111522763967514
step: 120, loss: 0.03462156653404236
step: 130, loss: 0.0886395052075386
step: 140, loss: 0.11970390379428864
step: 150, loss: 0.16832618415355682
step: 160, loss: 0.04739928990602493
step: 170, loss: 0.08189202100038528
step: 180, loss: 0.04710385575890541
step: 190, loss: 0.11303795874118805
step: 200, loss: 0.024615326896309853
step: 210, loss: 0.07326097786426544
step: 220, loss: 0.02978326752781868
step: 230, loss: 0.08139678090810776
step: 240, loss: 0.14120234549045563
step: 250, loss: 0.16850459575653076
step: 260, loss: 0.09393126517534256
step: 270, loss: 0.0665430948138237
step: 280, loss: 0.1414376050233841
step: 290, loss: 0.1162944883108139
step: 300, loss: 0.0729527696967125
step: 310, loss: 0.10531901568174362
step: 320, loss: 0.16253015398979187
step: 330, loss: 0.05813736841082573
step: 340, loss: 0.11946408450603485
step: 350, loss: 0.08081214129924774
step: 360, loss: 0.1603049486875534
step: 370, loss: 0.05385696515440941
step: 380, loss: 0.06425904482603073
step: 390, loss: 0.07465779781341553
step: 400, loss: 0.04987641051411629
step: 410, loss: 0.05356743186712265
step: 420, loss: 0.08146015554666519
step: 430, loss: 0.09016411006450653
step: 440, loss: 0.05242587998509407
step: 450, loss: 0.037487175315618515
step: 460, loss: 0.13350673019886017
step: 470, loss: 0.10462553799152374
step: 480, loss: 0.1050753965973854
step: 490, loss: 0.10449965298175812
step: 500, loss: 0.15702290832996368
step: 510, loss: 0.025272898375988007
step: 520, loss: 0.17635351419448853
step: 530, loss: 0.05837121978402138
step: 540, loss: 0.10273929685354233
step: 550, loss: 0.054699912667274475
step: 560, loss: 0.1303279548883438
step: 570, loss: 0.10670965909957886
step: 580, loss: 0.06385259330272675
step: 590, loss: 0.12124417722225189
step: 600, loss: 0.07330849021673203
step: 610, loss: 0.07039676606655121
step: 620, loss: 0.06632107496261597
step: 630, loss: 0.23141361773014069
step: 640, loss: 0.03869231790304184
step: 650, loss: 0.1522158980369568
step: 660, loss: 0.05317380651831627
step: 670, loss: 0.052402812987565994
step: 680, loss: 0.061758916825056076
step: 690, loss: 0.030298875644803047
step: 700, loss: 0.32928961515426636
step: 710, loss: 0.056261684745550156
step: 720, loss: 0.057856980711221695
step: 730, loss: 0.024176768958568573
step: 740, loss: 0.015419239178299904
step: 750, loss: 0.0768592357635498
step: 760, loss: 0.21149516105651855
step: 770, loss: 0.07835084199905396
step: 780, loss: 0.07187312096357346
step: 790, loss: 0.07693713903427124
step: 800, loss: 0.10333423316478729
step: 810, loss: 0.051307160407304764
step: 820, loss: 0.0879899337887764
step: 830, loss: 0.033704642206430435
step: 840, loss: 0.042131777852773666
step: 850, loss: 0.062418241053819656
step: 860, loss: 0.17549069225788116
step: 870, loss: 0.1322380155324936
step: 880, loss: 0.07975895702838898
step: 890, loss: 0.06503161787986755
step: 900, loss: 0.11904101073741913
step: 910, loss: 0.07241082191467285
step: 920, loss: 0.03337918221950531
step: 930, loss: 0.023429052904248238
step: 940, loss: 0.016719937324523926
step: 950, loss: 0.08289238810539246
step: 960, loss: 0.02936173975467682
step: 970, loss: 0.005590901244431734
step: 980, loss: 0.09026121348142624
step: 990, loss: 0.07078046351671219
step: 1000, loss: 0.06537870317697525
step: 1010, loss: 0.11623143404722214
step: 1020, loss: 0.12392377108335495
step: 1030, loss: 0.08765028417110443
step: 1040, loss: 0.022808533161878586
step: 1050, loss: 0.057011425495147705
step: 1060, loss: 0.06653768569231033
step: 1070, loss: 0.11077988147735596
epoch 6: dev_f1=0.9261806510774874, f1=0.9230769230769231, best_f1=0.9457221711131555
step: 0, loss: 0.08459005504846573
step: 10, loss: 0.02950538508594036
step: 20, loss: 0.12058483064174652
step: 30, loss: 0.04928642883896828
step: 40, loss: 0.06942913681268692
step: 50, loss: 0.09840985387563705
step: 60, loss: 0.023563960567116737
step: 70, loss: 0.006342689972370863
step: 80, loss: 0.041899390518665314
step: 90, loss: 0.06492334604263306
step: 100, loss: 0.09946148097515106
step: 110, loss: 0.08132904767990112
step: 120, loss: 0.11108195781707764
step: 130, loss: 0.08380308747291565
step: 140, loss: 0.07251238077878952
step: 150, loss: 2.5100405764533207e-05
step: 160, loss: 0.08511268347501755
step: 170, loss: 0.2942594885826111
step: 180, loss: 0.24913011491298676
step: 190, loss: 0.15233983099460602
step: 200, loss: 0.0833090990781784
step: 210, loss: 0.10173650830984116
step: 220, loss: 0.04302675276994705
step: 230, loss: 0.0686706006526947
step: 240, loss: 0.008533325046300888
step: 250, loss: 0.06285243481397629
step: 260, loss: 0.21161670982837677
step: 270, loss: 0.09964170306921005
step: 280, loss: 0.0009783100103959441
step: 290, loss: 0.029098747298121452
step: 300, loss: 0.10338936746120453
step: 310, loss: 0.14126752316951752
step: 320, loss: 0.0962032675743103
step: 330, loss: 0.13252438604831696
step: 340, loss: 0.035382989794015884
step: 350, loss: 0.04114452004432678
step: 360, loss: 0.0624859556555748
step: 370, loss: 0.11468756943941116
step: 380, loss: 0.2325601726770401
step: 390, loss: 0.0670723170042038
step: 400, loss: 0.08809436112642288
step: 410, loss: 0.02704080194234848
step: 420, loss: 0.025964420288801193
step: 430, loss: 0.02812766283750534
step: 440, loss: 0.08484513312578201
step: 450, loss: 0.042852483689785004
step: 460, loss: 0.1327827274799347
step: 470, loss: 0.061834752559661865
step: 480, loss: 0.03374675661325455
step: 490, loss: 0.1653381586074829
step: 500, loss: 0.14223550260066986
step: 510, loss: 0.10782275348901749
step: 520, loss: 0.15129885077476501
step: 530, loss: 0.13312382996082306
step: 540, loss: 0.08736902475357056
step: 550, loss: 0.08001448214054108
step: 560, loss: 0.04112517088651657
step: 570, loss: 0.16343414783477783
step: 580, loss: 0.14949961006641388
step: 590, loss: 0.027026604861021042
step: 600, loss: 0.021263813599944115
step: 610, loss: 0.14407546818256378
step: 620, loss: 0.034666359424591064
step: 630, loss: 0.05058244615793228
step: 640, loss: 0.06464729458093643
step: 650, loss: 0.09236963093280792
step: 660, loss: 0.040734387934207916
step: 670, loss: 0.07071525603532791
step: 680, loss: 0.1531149446964264
step: 690, loss: 0.03158044442534447
step: 700, loss: 0.1660166084766388
step: 710, loss: 0.01859769970178604
step: 720, loss: 0.02279074117541313
step: 730, loss: 0.015235970728099346
step: 740, loss: 0.09179364889860153
step: 750, loss: 0.12321140617132187
step: 760, loss: 0.0595124326646328
step: 770, loss: 0.16004471480846405
step: 780, loss: 0.3262895941734314
step: 790, loss: 0.06703759729862213
step: 800, loss: 0.06290688365697861
step: 810, loss: 0.06003430485725403
step: 820, loss: 0.07352455705404282
step: 830, loss: 0.01420647744089365
step: 840, loss: 0.08435459434986115
step: 850, loss: 0.0987713560461998
step: 860, loss: 0.0902799665927887
step: 870, loss: 0.05097104236483574
step: 880, loss: 0.09031563997268677
step: 890, loss: 0.17820249497890472
step: 900, loss: 0.18751612305641174
step: 910, loss: 0.10747929662466049
step: 920, loss: 0.0772697851061821
step: 930, loss: 0.03466162458062172
step: 940, loss: 0.017649028450250626
step: 950, loss: 0.09863337129354477
step: 960, loss: 0.05135529860854149
step: 970, loss: 0.020772632211446762
step: 980, loss: 0.07609055936336517
step: 990, loss: 0.08422771096229553
step: 1000, loss: 0.19073718786239624
step: 1010, loss: 0.03457815200090408
step: 1020, loss: 0.16562461853027344
step: 1030, loss: 0.03646355867385864
step: 1040, loss: 0.10474389046430588
step: 1050, loss: 0.035636886954307556
step: 1060, loss: 0.10394099354743958
step: 1070, loss: 0.004476714413613081
epoch 7: dev_f1=0.9296551724137931, f1=0.9323447636700649, best_f1=0.9457221711131555
step: 0, loss: 0.08675889670848846
step: 10, loss: 0.06179499626159668
step: 20, loss: 0.05191681161522865
step: 30, loss: 0.004083954729139805
step: 40, loss: 0.08809281885623932
step: 50, loss: 0.062583327293396
step: 60, loss: 0.07136306166648865
step: 70, loss: 0.002811373909935355
step: 80, loss: 0.062022481113672256
step: 90, loss: 0.04000462219119072
step: 100, loss: 0.030600782483816147
step: 110, loss: 0.06805771589279175
step: 120, loss: 0.057102445513010025
step: 130, loss: 0.03939930349588394
step: 140, loss: 0.02453042007982731
step: 150, loss: 0.055684804916381836
step: 160, loss: 0.13065369427204132
step: 170, loss: 0.06833871454000473
step: 180, loss: 0.1180352121591568
step: 190, loss: 0.06841465830802917
step: 200, loss: 0.16646383702754974
step: 210, loss: 0.0970531478524208
step: 220, loss: 0.10996949672698975
step: 230, loss: 0.14030002057552338
step: 240, loss: 0.014335168525576591
step: 250, loss: 0.03715435415506363
step: 260, loss: 0.028784342110157013
step: 270, loss: 0.11899042874574661
step: 280, loss: 0.06818727403879166
step: 290, loss: 0.11847875267267227
step: 300, loss: 0.03537586331367493
step: 310, loss: 0.04323920980095863
step: 320, loss: 0.01930253766477108
step: 330, loss: 0.05581348016858101
step: 340, loss: 0.022784410044550896
step: 350, loss: 0.10178250074386597
step: 360, loss: 0.07232372462749481
step: 370, loss: 0.13135920464992523
step: 380, loss: 0.08725765347480774
step: 390, loss: 0.018114909529685974
step: 400, loss: 0.04761529713869095
step: 410, loss: 0.059191327542066574
step: 420, loss: 0.026988040655851364
step: 430, loss: 0.05658156797289848
step: 440, loss: 0.08492635190486908
step: 450, loss: 0.08930419385433197
step: 460, loss: 0.06898853182792664
step: 470, loss: 0.1482364982366562
step: 480, loss: 0.034937743097543716
step: 490, loss: 0.10830789059400558
step: 500, loss: 0.1367640197277069
step: 510, loss: 0.057335302233695984
step: 520, loss: 0.09360602498054504
step: 530, loss: 0.05803597345948219
step: 540, loss: 0.19010388851165771
step: 550, loss: 0.11260970681905746
step: 560, loss: 0.14491096138954163
step: 570, loss: 0.044485751539468765
step: 580, loss: 0.031134340912103653
step: 590, loss: 0.18324752151966095
step: 600, loss: 0.15513542294502258
step: 610, loss: 0.09950185567140579
step: 620, loss: 0.18266957998275757
step: 630, loss: 0.08235346525907516
step: 640, loss: 0.016978802159428596
step: 650, loss: 0.08848349750041962
step: 660, loss: 0.02291332744061947
step: 670, loss: 0.12758053839206696
step: 680, loss: 0.0425371453166008
step: 690, loss: 0.1544799506664276
step: 700, loss: 0.0268722977489233
step: 710, loss: 0.010063452646136284
step: 720, loss: 0.056341107934713364
step: 730, loss: 0.07506731897592545
step: 740, loss: 0.0844474583864212
step: 750, loss: 0.01696760021150112
step: 760, loss: 0.0853717103600502
step: 770, loss: 0.08670159429311752
step: 780, loss: 0.031576648354530334
step: 790, loss: 0.1000947505235672
step: 800, loss: 0.06538589298725128
step: 810, loss: 0.024961739778518677
step: 820, loss: 0.019714010879397392
step: 830, loss: 0.07481861114501953
step: 840, loss: 0.07458017021417618
step: 850, loss: 0.13484427332878113
step: 860, loss: 0.03731367364525795
step: 870, loss: 0.018871065229177475
step: 880, loss: 0.1667230725288391
step: 890, loss: 0.007883585058152676
step: 900, loss: 0.09086686372756958
step: 910, loss: 0.08079678565263748
step: 920, loss: 0.00026978881214745343
step: 930, loss: 0.022279977798461914
step: 940, loss: 0.001519147539511323
step: 950, loss: 0.07450196146965027
step: 960, loss: 0.10827837884426117
step: 970, loss: 0.13913317024707794
step: 980, loss: 0.12437394261360168
step: 990, loss: 0.08753989636898041
step: 1000, loss: 0.04411963000893593
step: 1010, loss: 0.2502410411834717
step: 1020, loss: 0.06961169838905334
step: 1030, loss: 0.06560193747282028
step: 1040, loss: 0.010913866572082043
step: 1050, loss: 0.05293704569339752
step: 1060, loss: 0.05663622170686722
step: 1070, loss: 0.09946082532405853
epoch 8: dev_f1=0.9336426914153132, f1=0.927536231884058, best_f1=0.9457221711131555
step: 0, loss: 0.08777737617492676
step: 10, loss: 0.08042917400598526
step: 20, loss: 0.019880160689353943
step: 30, loss: 0.0375567227602005
step: 40, loss: 0.07365366071462631
step: 50, loss: 0.039046987891197205
step: 60, loss: 0.14033325016498566
step: 70, loss: 0.07436100393533707
step: 80, loss: 0.043271519243717194
step: 90, loss: 0.03367214649915695
step: 100, loss: 0.020718522369861603
step: 110, loss: 0.09576434642076492
step: 120, loss: 0.11916309595108032
step: 130, loss: 0.06865951418876648
step: 140, loss: 0.00789006520062685
step: 150, loss: 0.12120990455150604
step: 160, loss: 0.08153344690799713
step: 170, loss: 0.0338929183781147
step: 180, loss: 0.016289183869957924
step: 190, loss: 0.06661094725131989
step: 200, loss: 0.14963361620903015
step: 210, loss: 0.288143128156662
step: 220, loss: 0.0421348474919796
step: 230, loss: 0.08617100864648819
step: 240, loss: 0.004811510909348726
step: 250, loss: 0.014675810933113098
step: 260, loss: 0.12649430334568024
step: 270, loss: 0.05451672151684761
step: 280, loss: 0.06656473875045776
step: 290, loss: 0.05655626580119133
step: 300, loss: 0.05999338626861572
step: 310, loss: 0.17533166706562042
step: 320, loss: 0.0678177997469902
step: 330, loss: 0.07790014147758484
step: 340, loss: 0.10391800105571747
step: 350, loss: 0.04835641384124756
step: 360, loss: 0.058908961713314056
step: 370, loss: 0.062312494963407516
step: 380, loss: 0.019117331132292747
step: 390, loss: 0.08489090204238892
step: 400, loss: 0.022568702697753906
step: 410, loss: 0.044731199741363525
step: 420, loss: 0.08329635113477707
step: 430, loss: 0.16768193244934082
step: 440, loss: 0.07131186872720718
step: 450, loss: 0.09216836839914322
step: 460, loss: 0.12677252292633057
step: 470, loss: 0.18843282759189606
step: 480, loss: 0.05541059374809265
step: 490, loss: 0.014969706535339355
step: 500, loss: 0.044525183737277985
step: 510, loss: 0.17443199455738068
step: 520, loss: 0.08517530560493469
step: 530, loss: 0.08008885383605957
step: 540, loss: 0.046625569462776184
step: 550, loss: 0.031165331602096558
step: 560, loss: 0.0822303295135498
step: 570, loss: 0.03192857280373573
step: 580, loss: 0.05080988630652428
step: 590, loss: 0.10487736761569977
step: 600, loss: 0.09066248685121536
step: 610, loss: 0.05425182357430458
step: 620, loss: 0.10128428041934967
step: 630, loss: 0.07279493659734726
step: 640, loss: 0.026663536205887794
step: 650, loss: 0.005420680157840252
step: 660, loss: 0.029520146548748016
step: 670, loss: 0.012118108570575714
step: 680, loss: 0.2899850308895111
step: 690, loss: 0.09687285125255585
step: 700, loss: 0.06318044662475586
step: 710, loss: 0.126107320189476
step: 720, loss: 0.14121077954769135
step: 730, loss: 0.07123718410730362
step: 740, loss: 0.21330460906028748
step: 750, loss: 0.06886763870716095
step: 760, loss: 0.016327515244483948
step: 770, loss: 0.23591633141040802
step: 780, loss: 0.03664512559771538
step: 790, loss: 0.08666735142469406
step: 800, loss: 0.12451884150505066
step: 810, loss: 0.09669965505599976
step: 820, loss: 0.11493794620037079
step: 830, loss: 0.010217784903943539
step: 840, loss: 0.13702638447284698
step: 850, loss: 0.020171185955405235
step: 860, loss: 0.056997913867235184
step: 870, loss: 0.0277528315782547
step: 880, loss: 0.09119562059640884
step: 890, loss: 0.12113747745752335
step: 900, loss: 0.10811430960893631
step: 910, loss: 0.08030453324317932
step: 920, loss: 0.05198051035404205
step: 930, loss: 0.021184371784329414
step: 940, loss: 0.08974922448396683
step: 950, loss: 0.016410846263170242
step: 960, loss: 0.0778411328792572
step: 970, loss: 0.07539685815572739
step: 980, loss: 0.06473498046398163
step: 990, loss: 0.16545812785625458
step: 1000, loss: 0.07947330176830292
step: 1010, loss: 0.10205047577619553
step: 1020, loss: 0.0259087011218071
step: 1030, loss: 0.09418389201164246
step: 1040, loss: 0.007929685525596142
step: 1050, loss: 0.02397052012383938
step: 1060, loss: 0.08799496293067932
step: 1070, loss: 0.05624276027083397
epoch 9: dev_f1=0.9203132197144173, f1=0.9180176007410837, best_f1=0.9457221711131555
step: 0, loss: 0.0711498111486435
step: 10, loss: 0.009817813523113728
step: 20, loss: 0.06862832605838776
step: 30, loss: 0.06691960990428925
step: 40, loss: 0.019390568137168884
step: 50, loss: 0.0002614492259453982
step: 60, loss: 0.045568082481622696
step: 70, loss: 0.06496180593967438
step: 80, loss: 0.1202302873134613
step: 90, loss: 0.08924335241317749
step: 100, loss: 0.048495806753635406
step: 110, loss: 0.09304884076118469
step: 120, loss: 0.04246474802494049
step: 130, loss: 0.022794518619775772
step: 140, loss: 0.013019233010709286
step: 150, loss: 0.13667744398117065
step: 160, loss: 0.05104519799351692
step: 170, loss: 0.10640432685613632
step: 180, loss: 0.019129211083054543
step: 190, loss: 0.05447566881775856
step: 200, loss: 0.014870994724333286
step: 210, loss: 0.07723274827003479
step: 220, loss: 0.09878741204738617
step: 230, loss: 0.03239943087100983
step: 240, loss: 0.018529485911130905
step: 250, loss: 0.04456236958503723
step: 260, loss: 0.20755930244922638
step: 270, loss: 0.0490260012447834
step: 280, loss: 0.06807538866996765
step: 290, loss: 0.11216536909341812
step: 300, loss: 0.0013384571066126227
step: 310, loss: 0.11424668878316879
step: 320, loss: 0.07863863557577133
step: 330, loss: 0.10019174963235855
step: 340, loss: 0.08354055136442184
step: 350, loss: 0.14621935784816742
step: 360, loss: 0.10059752315282822
step: 370, loss: 0.11748829483985901
step: 380, loss: 0.06619338691234589
step: 390, loss: 0.30635198950767517
step: 400, loss: 0.04225257784128189
step: 410, loss: 0.06725825369358063
step: 420, loss: 0.09238073229789734
step: 430, loss: 0.058312494307756424
step: 440, loss: 0.03290518745779991
step: 450, loss: 0.1106346920132637
step: 460, loss: 0.09463081508874893
step: 470, loss: 0.1424240618944168
step: 480, loss: 0.04515957459807396
step: 490, loss: 0.03829949349164963
step: 500, loss: 0.12294188886880875
step: 510, loss: 0.028080955147743225
step: 520, loss: 0.07357439398765564
step: 530, loss: 0.1586342751979828
step: 540, loss: 0.008402658626437187
step: 550, loss: 0.04678340628743172
step: 560, loss: 0.02083643712103367
step: 570, loss: 0.0176582932472229
step: 580, loss: 0.1367892175912857
step: 590, loss: 0.018910955637693405
step: 600, loss: 0.0632832944393158
step: 610, loss: 0.12041893601417542
step: 620, loss: 0.13703054189682007
step: 630, loss: 0.028714114800095558
step: 640, loss: 0.045593734830617905
step: 650, loss: 0.11191914230585098
step: 660, loss: 0.03939082473516464
step: 670, loss: 0.02522142603993416
step: 680, loss: 0.04015175625681877
step: 690, loss: 0.06432299315929413
step: 700, loss: 0.07154407352209091
step: 710, loss: 0.05435924232006073
step: 720, loss: 0.014228345826268196
step: 730, loss: 0.09699247777462006
step: 740, loss: 0.21769575774669647
step: 750, loss: 0.06666417419910431
step: 760, loss: 0.04714677110314369
step: 770, loss: 0.0007918118499219418
step: 780, loss: 0.01795353554189205
step: 790, loss: 0.08534570783376694
step: 800, loss: 0.10844703018665314
step: 810, loss: 0.09180812537670135
step: 820, loss: 0.047047898173332214
step: 830, loss: 0.0346338152885437
step: 840, loss: 0.018693646416068077
step: 850, loss: 0.10208506882190704
step: 860, loss: 0.12235989421606064
step: 870, loss: 0.07613978534936905
step: 880, loss: 0.0319778136909008
step: 890, loss: 0.03388219699263573
step: 900, loss: 0.09797931462526321
step: 910, loss: 0.03629931062459946
step: 920, loss: 0.12025292962789536
step: 930, loss: 0.08291041105985641
step: 940, loss: 0.060356851667165756
step: 950, loss: 0.12292949855327606
step: 960, loss: 0.0719059556722641
step: 970, loss: 0.03508519008755684
step: 980, loss: 0.031691279262304306
step: 990, loss: 0.06287810951471329
step: 1000, loss: 0.0272185280919075
step: 1010, loss: 0.13730742037296295
step: 1020, loss: 0.1137893795967102
step: 1030, loss: 0.07416065782308578
step: 1040, loss: 0.12453500181436539
step: 1050, loss: 0.05640041455626488
step: 1060, loss: 0.06574910879135132
step: 1070, loss: 0.09424872696399689
epoch 10: dev_f1=0.9289667896678966, f1=0.9259088817303267, best_f1=0.9457221711131555
step: 0, loss: 0.02029401808977127
step: 10, loss: 0.03174824267625809
step: 20, loss: 0.04224429279565811
step: 30, loss: 0.08670517802238464
step: 40, loss: 0.028311051428318024
step: 50, loss: 0.02046617679297924
step: 60, loss: 0.0001341324532404542
step: 70, loss: 0.03664737567305565
step: 80, loss: 0.1875060796737671
step: 90, loss: 0.053749457001686096
step: 100, loss: 0.06563327461481094
step: 110, loss: 0.047142114490270615
step: 120, loss: 0.016798628494143486
step: 130, loss: 0.10252097994089127
step: 140, loss: 0.08353520184755325
step: 150, loss: 0.0523655004799366
step: 160, loss: 0.04646652191877365
step: 170, loss: 0.1383761167526245
step: 180, loss: 0.005826639011502266
step: 190, loss: 0.027872269973158836
step: 200, loss: 0.02619699202477932
step: 210, loss: 0.10193438082933426
step: 220, loss: 0.018601076677441597
step: 230, loss: 0.038099177181720734
step: 240, loss: 0.07045941054821014
step: 250, loss: 0.04067861661314964
step: 260, loss: 0.036087531596422195
step: 270, loss: 0.025204569101333618
step: 280, loss: 0.052043765783309937
step: 290, loss: 0.2619512677192688
step: 300, loss: 0.002438334049656987
step: 310, loss: 0.08915337920188904
step: 320, loss: 0.08507667481899261
step: 330, loss: 0.026554975658655167
step: 340, loss: 0.0575454980134964
step: 350, loss: 0.034715745598077774
step: 360, loss: 0.11159081757068634
step: 370, loss: 0.0596901997923851
step: 380, loss: 0.0936271995306015
step: 390, loss: 0.08441328257322311
step: 400, loss: 0.07011023908853531
step: 410, loss: 0.09306473284959793
step: 420, loss: 0.055324703454971313
step: 430, loss: 0.0356169156730175
step: 440, loss: 0.06724220514297485
step: 450, loss: 0.03514175862073898
step: 460, loss: 0.1356678009033203
step: 470, loss: 0.14526334404945374
step: 480, loss: 0.06242441013455391
step: 490, loss: 0.026883890852332115
step: 500, loss: 0.017831603065133095
step: 510, loss: 0.023866191506385803
step: 520, loss: 0.031453873962163925
step: 530, loss: 0.04938088357448578
step: 540, loss: 0.03918782249093056
step: 550, loss: 0.04397711902856827
step: 560, loss: 0.06564202159643173
step: 570, loss: 0.06309708207845688
step: 580, loss: 0.06380950659513474
step: 590, loss: 0.08459416776895523
step: 600, loss: 0.028515877202153206
step: 610, loss: 0.05079377442598343
step: 620, loss: 0.03497779369354248
step: 630, loss: 0.09192760288715363
step: 640, loss: 0.0736348107457161
step: 650, loss: 0.037008222192525864
step: 660, loss: 0.10955933481454849
step: 670, loss: 0.1086113229393959
step: 680, loss: 0.0634140893816948
step: 690, loss: 0.04880779981613159
step: 700, loss: 0.09740767627954483
step: 710, loss: 0.05835847929120064
step: 720, loss: 0.024857347831130028
step: 730, loss: 0.06406861543655396
step: 740, loss: 0.03811371326446533
step: 750, loss: 0.11110604554414749
step: 760, loss: 0.06859400123357773
step: 770, loss: 0.0006594485603272915
step: 780, loss: 0.021632490679621696
step: 790, loss: 0.0693245381116867
step: 800, loss: 0.04929841309785843
step: 810, loss: 0.10943260043859482
step: 820, loss: 0.02504809945821762
step: 830, loss: 0.004345040302723646
step: 840, loss: 0.01709083281457424
step: 850, loss: 0.031300920993089676
step: 860, loss: 0.03156433254480362
step: 870, loss: 0.04272390156984329
step: 880, loss: 0.017418047413229942
step: 890, loss: 0.00059910659911111
step: 900, loss: 0.09709317237138748
step: 910, loss: 0.10875967144966125
step: 920, loss: 0.20333990454673767
step: 930, loss: 0.058994170278310776
step: 940, loss: 0.08817405253648758
step: 950, loss: 0.06703340262174606
step: 960, loss: 0.10472568869590759
step: 970, loss: 0.03323102742433548
step: 980, loss: 0.15399479866027832
step: 990, loss: 0.08508341014385223
step: 1000, loss: 0.03859648481011391
step: 1010, loss: 0.0443989560008049
step: 1020, loss: 0.015738923102617264
step: 1030, loss: 0.14526954293251038
step: 1040, loss: 0.013599447906017303
step: 1050, loss: 0.035585060715675354
step: 1060, loss: 0.08415510505437851
step: 1070, loss: 0.04413769766688347
epoch 11: dev_f1=0.9292649098474343, f1=0.9262865090403337, best_f1=0.9457221711131555
step: 0, loss: 0.08342449367046356
step: 10, loss: 0.017869889736175537
step: 20, loss: 0.11445421725511551
step: 30, loss: 0.0023659321013838053
step: 40, loss: 0.08675968647003174
step: 50, loss: 0.02825099043548107
step: 60, loss: 0.11576244235038757
step: 70, loss: 0.03608233481645584
step: 80, loss: 0.01879938319325447
step: 90, loss: 0.06911574304103851
step: 100, loss: 0.04478450492024422
step: 110, loss: 0.037922538816928864
step: 120, loss: 0.058795999735593796
step: 130, loss: 0.06057170033454895
step: 140, loss: 0.021876491606235504
step: 150, loss: 0.07177736610174179
step: 160, loss: 0.0011151728685945272
step: 170, loss: 0.05442694202065468
step: 180, loss: 0.029823221266269684
step: 190, loss: 0.09401735663414001
step: 200, loss: 0.0013801554450765252
step: 210, loss: 0.014322199858725071
step: 220, loss: 0.06416873633861542
step: 230, loss: 0.122186079621315
step: 240, loss: 0.07455496490001678
step: 250, loss: 0.10414419323205948
step: 260, loss: 0.11055708676576614
step: 270, loss: 0.009920123033225536
step: 280, loss: 0.03594041243195534
step: 290, loss: 0.10898275673389435
step: 300, loss: 0.0312512181699276
step: 310, loss: 0.03483724221587181
step: 320, loss: 0.07856391370296478
step: 330, loss: 0.15836471319198608
step: 340, loss: 0.06503663212060928
step: 350, loss: 0.20188552141189575
step: 360, loss: 0.11658003181219101
step: 370, loss: 0.06849122792482376
step: 380, loss: 0.08148173242807388
step: 390, loss: 0.09113787114620209
step: 400, loss: 0.015804404392838478
step: 410, loss: 0.02452586218714714
step: 420, loss: 0.06648001074790955
step: 430, loss: 0.03463619947433472
step: 440, loss: 0.034808237105607986
step: 450, loss: 0.047956082969903946
step: 460, loss: 0.11354544758796692
step: 470, loss: 0.0913313701748848
step: 480, loss: 0.02908414788544178
step: 490, loss: 0.03195685148239136
step: 500, loss: 0.09768491983413696
step: 510, loss: 0.05884680151939392
step: 520, loss: 0.07096920907497406
step: 530, loss: 0.02691059559583664
step: 540, loss: 0.07846757769584656
step: 550, loss: 0.0787414163351059
step: 560, loss: 0.13370734453201294
step: 570, loss: 0.05448417738080025
step: 580, loss: 0.09007221460342407
step: 590, loss: 0.05920933559536934
step: 600, loss: 0.0529232956469059
step: 610, loss: 0.025062303990125656
step: 620, loss: 0.10844744741916656
step: 630, loss: 0.06391293555498123
step: 640, loss: 0.15508383512496948
step: 650, loss: 0.058212198317050934
step: 660, loss: 0.10704898089170456
step: 670, loss: 0.05161405727267265
step: 680, loss: 0.2300318479537964
step: 690, loss: 0.057537999004125595
step: 700, loss: 0.053489524871110916
step: 710, loss: 0.03128538280725479
step: 720, loss: 0.050774361938238144
step: 730, loss: 0.06414144486188889
step: 740, loss: 0.10818555951118469
step: 750, loss: 0.0833328515291214
step: 760, loss: 0.062037479132413864
step: 770, loss: 0.12139670550823212
step: 780, loss: 0.016583334654569626
step: 790, loss: 0.05297363921999931
step: 800, loss: 0.06117841601371765
step: 810, loss: 0.15209044516086578
step: 820, loss: 0.15944938361644745
step: 830, loss: 0.021397976204752922
step: 840, loss: 0.06924815475940704
step: 850, loss: 0.05643603205680847
step: 860, loss: 0.07098168134689331
step: 870, loss: 0.020780568942427635
step: 880, loss: 0.02250410057604313
step: 890, loss: 0.053679611533880234
step: 900, loss: 0.05605922266840935
step: 910, loss: 0.14264589548110962
step: 920, loss: 0.07082734256982803
step: 930, loss: 0.020624486729502678
step: 940, loss: 0.07640060782432556
step: 950, loss: 0.02409866452217102
step: 960, loss: 0.06135212630033493
step: 970, loss: 0.07642857730388641
step: 980, loss: 0.11227119714021683
step: 990, loss: 0.015176440589129925
step: 1000, loss: 0.03885877504944801
step: 1010, loss: 0.1182718351483345
step: 1020, loss: 0.0410601943731308
step: 1030, loss: 0.03820174187421799
step: 1040, loss: 0.06755679100751877
step: 1050, loss: 0.050959136337041855
step: 1060, loss: 0.07473290711641312
step: 1070, loss: 0.02141241915524006
epoch 12: dev_f1=0.9254284390921722, f1=0.927806241266884, best_f1=0.9457221711131555
step: 0, loss: 0.01996706984937191
step: 10, loss: 0.06693033128976822
step: 20, loss: 0.0003601782373152673
step: 30, loss: 0.014112942852079868
step: 40, loss: 0.009479215368628502
step: 50, loss: 0.08078394830226898
step: 60, loss: 0.08327558636665344
step: 70, loss: 0.11162914335727692
step: 80, loss: 0.06381438672542572
step: 90, loss: 0.07514038681983948
step: 100, loss: 0.10345586389303207
step: 110, loss: 0.010085608810186386
step: 120, loss: 0.09682383388280869
step: 130, loss: 0.06278347223997116
step: 140, loss: 0.05180460214614868
step: 150, loss: 0.10836558789014816
step: 160, loss: 0.06677618622779846
step: 170, loss: 0.08327571302652359
step: 180, loss: 0.030282480642199516
step: 190, loss: 0.024928618222475052
step: 200, loss: 0.08373946696519852
step: 210, loss: 5.697112646885216e-05
step: 220, loss: 0.004937413614243269
step: 230, loss: 0.03602481633424759
step: 240, loss: 0.14088745415210724
step: 250, loss: 0.0044628046452999115
step: 260, loss: 0.08439934253692627
step: 270, loss: 0.01818428561091423
step: 280, loss: 0.10709431022405624
step: 290, loss: 0.05240737274289131
step: 300, loss: 0.02561182901263237
step: 310, loss: 0.06274233758449554
step: 320, loss: 0.3877146244049072
step: 330, loss: 0.05988015606999397
step: 340, loss: 0.025564122945070267
step: 350, loss: 0.05913984775543213
step: 360, loss: 0.025067409500479698
step: 370, loss: 0.057819005101919174
step: 380, loss: 0.00021598068997263908
step: 390, loss: 0.09317588806152344
step: 400, loss: 0.05042881518602371
step: 410, loss: 0.03076658956706524
step: 420, loss: 0.04840745031833649
step: 430, loss: 0.035392217338085175
step: 440, loss: 0.07979816943407059
step: 450, loss: 0.12749731540679932
step: 460, loss: 0.006940340157598257
step: 470, loss: 0.008534847758710384
step: 480, loss: 0.09720242768526077
step: 490, loss: 0.05644514784216881
step: 500, loss: 0.06518836319446564
step: 510, loss: 0.0004903857479803264
step: 520, loss: 0.014417728409171104
step: 530, loss: 0.11298876255750656
step: 540, loss: 0.0007593689952045679
step: 550, loss: 0.04288139566779137
step: 560, loss: 0.09082701057195663
step: 570, loss: 0.07918528467416763
step: 580, loss: 0.09342039376497269
step: 590, loss: 0.03845769166946411
step: 600, loss: 0.0007473616860806942
step: 610, loss: 0.0041204337030649185
step: 620, loss: 0.05762465298175812
step: 630, loss: 0.06954742968082428
step: 640, loss: 0.047986503690481186
step: 650, loss: 0.033572450280189514
step: 660, loss: 0.029374057427048683
step: 670, loss: 0.09186691045761108
step: 680, loss: 0.037981875240802765
step: 690, loss: 0.03434966504573822
step: 700, loss: 0.012928755953907967
step: 710, loss: 0.037170443683862686
step: 720, loss: 0.016714684665203094
step: 730, loss: 0.0599670372903347
step: 740, loss: 0.04042106494307518
step: 750, loss: 0.1366901695728302
step: 760, loss: 0.048049282282590866
step: 770, loss: 0.030500512570142746
step: 780, loss: 5.0071430450771004e-05
step: 790, loss: 0.11763475835323334
step: 800, loss: 0.021206598728895187
step: 810, loss: 0.10671548545360565
step: 820, loss: 0.021758968010544777
step: 830, loss: 0.045971229672431946
step: 840, loss: 0.05809454992413521
step: 850, loss: 0.021163824945688248
step: 860, loss: 0.021015232428908348
step: 870, loss: 0.1010204330086708
step: 880, loss: 0.01933911442756653
step: 890, loss: 0.06840135902166367
step: 900, loss: 0.10739275813102722
step: 910, loss: 0.06401335448026657
step: 920, loss: 0.07392652332782745
step: 930, loss: 0.017021624371409416
step: 940, loss: 2.141876939276699e-05
step: 950, loss: 0.04678066447377205
step: 960, loss: 0.02039354108273983
step: 970, loss: 0.050915323197841644
step: 980, loss: 0.059380631893873215
step: 990, loss: 0.10165271162986755
step: 1000, loss: 0.06389141827821732
step: 1010, loss: 0.08472556620836258
step: 1020, loss: 0.04651108384132385
step: 1030, loss: 0.14866526424884796
step: 1040, loss: 0.035610344260931015
step: 1050, loss: 0.017167583107948303
step: 1060, loss: 0.008559261448681355
step: 1070, loss: 0.00011298105528112501
epoch 13: dev_f1=0.9270307480495641, f1=0.9244159413650939, best_f1=0.9457221711131555
step: 0, loss: 0.025817813351750374
step: 10, loss: 0.0020490491297096014
step: 20, loss: 0.0858747586607933
step: 30, loss: 0.027943521738052368
step: 40, loss: 0.03976627439260483
step: 50, loss: 0.08724218606948853
step: 60, loss: 0.14407773315906525
step: 70, loss: 0.001144944573752582
step: 80, loss: 0.0002987743355333805
step: 90, loss: 0.013422404415905476
step: 100, loss: 0.017780141904950142
step: 110, loss: 0.11250326037406921
step: 120, loss: 0.079216867685318
step: 130, loss: 0.0375681146979332
step: 140, loss: 0.0009582245256751776
step: 150, loss: 1.62340857059462e-05
step: 160, loss: 0.04028769209980965
step: 170, loss: 0.0003508781373966485
step: 180, loss: 0.08992055803537369
step: 190, loss: 0.08097287267446518
step: 200, loss: 0.10248647630214691
step: 210, loss: 0.04822063818573952
step: 220, loss: 0.11735410988330841
step: 230, loss: 0.035492073744535446
step: 240, loss: 0.023850299417972565
step: 250, loss: 0.05169743299484253
step: 260, loss: 0.05425797030329704
step: 270, loss: 0.05265289545059204
step: 280, loss: 0.05666663125157356
step: 290, loss: 0.03422895446419716
step: 300, loss: 0.13610978424549103
step: 310, loss: 0.013478019274771214
step: 320, loss: 0.05293078348040581
step: 330, loss: 0.0773792490363121
step: 340, loss: 0.0009478185093030334
step: 350, loss: 0.04001416638493538
step: 360, loss: 0.03362065926194191
step: 370, loss: 0.035202816128730774
step: 380, loss: 0.08048360049724579
step: 390, loss: 0.060486435890197754
step: 400, loss: 0.09279400110244751
step: 410, loss: 0.06958725303411484
step: 420, loss: 0.07309887558221817
step: 430, loss: 0.021924244239926338
step: 440, loss: 0.05493137985467911
step: 450, loss: 0.10605563223361969
step: 460, loss: 0.04457744210958481
step: 470, loss: 0.02683687023818493
step: 480, loss: 0.0379607155919075
step: 490, loss: 0.027441464364528656
step: 500, loss: 0.07316436618566513
step: 510, loss: 0.04314155876636505
step: 520, loss: 0.02070862613618374
step: 530, loss: 0.05187460035085678
step: 540, loss: 0.010035503655672073
step: 550, loss: 0.06325799226760864
step: 560, loss: 3.586693128454499e-05
step: 570, loss: 0.06188805773854256
step: 580, loss: 0.0314006432890892
step: 590, loss: 0.046855147927999496
step: 600, loss: 0.05833375081419945
step: 610, loss: 0.20388980209827423
step: 620, loss: 0.009508808143436909
step: 630, loss: 0.07831346988677979
step: 640, loss: 0.033229269087314606
step: 650, loss: 0.09312113374471664
step: 660, loss: 0.02747161127626896
step: 670, loss: 0.013625603169202805
step: 680, loss: 0.030141863971948624
step: 690, loss: 0.05626228451728821
step: 700, loss: 0.032847948372364044
step: 710, loss: 0.006629041861742735
step: 720, loss: 0.02781420573592186
step: 730, loss: 2.895765646826476e-05
step: 740, loss: 0.03427538648247719
step: 750, loss: 0.05362469330430031
step: 760, loss: 0.007318626157939434
step: 770, loss: 0.0695226639509201
step: 780, loss: 0.10760076344013214
step: 790, loss: 0.030453354120254517
step: 800, loss: 0.018069619312882423
step: 810, loss: 0.04984557256102562
step: 820, loss: 0.06964008510112762
step: 830, loss: 0.025352343916893005
step: 840, loss: 0.10540590435266495
step: 850, loss: 0.09540941566228867
step: 860, loss: 0.013757236301898956
step: 870, loss: 0.023035338148474693
step: 880, loss: 0.05437459424138069
step: 890, loss: 0.02527483180165291
step: 900, loss: 0.0032258606515824795
step: 910, loss: 0.024838492274284363
step: 920, loss: 0.07121676206588745
step: 930, loss: 0.11280015110969543
step: 940, loss: 0.051567766815423965
step: 950, loss: 0.031047288328409195
step: 960, loss: 0.04017195850610733
step: 970, loss: 0.08465847373008728
step: 980, loss: 0.029524758458137512
step: 990, loss: 0.15397706627845764
step: 1000, loss: 0.1277223825454712
step: 1010, loss: 0.09169501066207886
step: 1020, loss: 0.1058935821056366
step: 1030, loss: 0.10531000047922134
step: 1040, loss: 0.12832483649253845
step: 1050, loss: 0.05396652594208717
step: 1060, loss: 0.1500108391046524
step: 1070, loss: 0.133404940366745
epoch 14: dev_f1=0.9219534459151072, f1=0.9229357798165138, best_f1=0.9457221711131555
step: 0, loss: 0.14911846816539764
step: 10, loss: 0.06276889890432358
step: 20, loss: 0.026998283341526985
step: 30, loss: 0.03828362748026848
step: 40, loss: 0.026823360472917557
step: 50, loss: 1.9627308574854396e-05
step: 60, loss: 0.05974957346916199
step: 70, loss: 2.9315177016542293e-05
step: 80, loss: 0.09432226419448853
step: 90, loss: 0.07517076283693314
step: 100, loss: 0.01968616247177124
step: 110, loss: 0.062797412276268
step: 120, loss: 0.0527331605553627
step: 130, loss: 0.06478406488895416
step: 140, loss: 0.11323285847902298
step: 150, loss: 0.02251027524471283
step: 160, loss: 0.02418837696313858
step: 170, loss: 0.022699326276779175
step: 180, loss: 0.03279712423682213
step: 190, loss: 0.06905627995729446
step: 200, loss: 0.04933299496769905
step: 210, loss: 0.010754600167274475
step: 220, loss: 0.008719931356608868
step: 230, loss: 0.054879773408174515
step: 240, loss: 0.04953722283244133
step: 250, loss: 0.03497105464339256
step: 260, loss: 0.031955089420080185
step: 270, loss: 0.014965607784688473
step: 280, loss: 0.06328931450843811
step: 290, loss: 0.08002867549657822
step: 300, loss: 0.05366678163409233
step: 310, loss: 0.03708455711603165
step: 320, loss: 0.04737704247236252
step: 330, loss: 0.028297964483499527
step: 340, loss: 0.0033659678883850574
step: 350, loss: 0.08866199105978012
step: 360, loss: 0.014036093838512897
step: 370, loss: 0.0003410256467759609
step: 380, loss: 0.05441702529788017
step: 390, loss: 0.04128258675336838
step: 400, loss: 0.13739784061908722
step: 410, loss: 0.015325361862778664
step: 420, loss: 0.04848140850663185
step: 430, loss: 0.0683019608259201
step: 440, loss: 0.10620830953121185
step: 450, loss: 0.06368007510900497
step: 460, loss: 0.0548531636595726
step: 470, loss: 0.016740813851356506
step: 480, loss: 0.0001950035511981696
step: 490, loss: 0.11856435239315033
step: 500, loss: 0.06382864713668823
step: 510, loss: 0.06168030574917793
step: 520, loss: 0.045251715928316116
step: 530, loss: 0.04768236726522446
step: 540, loss: 0.06861911714076996
step: 550, loss: 0.06700029224157333
step: 560, loss: 0.03646347299218178
step: 570, loss: 0.028553098440170288
step: 580, loss: 0.06406382471323013
step: 590, loss: 0.022926222532987595
step: 600, loss: 0.009022182784974575
step: 610, loss: 0.032500166445970535
step: 620, loss: 0.03210459649562836
step: 630, loss: 0.026159368455410004
step: 640, loss: 0.03657064214348793
step: 650, loss: 0.09006710350513458
step: 660, loss: 0.022652965039014816
step: 670, loss: 0.1402328461408615
step: 680, loss: 0.021103570237755775
step: 690, loss: 0.011501152999699116
step: 700, loss: 0.05067042261362076
step: 710, loss: 0.013674709014594555
step: 720, loss: 0.10398492962121964
step: 730, loss: 0.0474923774600029
step: 740, loss: 0.04217996820807457
step: 750, loss: 0.0007989781443029642
step: 760, loss: 0.001611583400517702
step: 770, loss: 0.03236563876271248
step: 780, loss: 0.056203898042440414
step: 790, loss: 0.12620748579502106
step: 800, loss: 0.02319100871682167
step: 810, loss: 0.09004927426576614
step: 820, loss: 0.0009785625152289867
step: 830, loss: 0.07275567948818207
step: 840, loss: 0.029466843232512474
step: 850, loss: 0.019549883902072906
step: 860, loss: 0.03891664743423462
step: 870, loss: 0.031458742916584015
step: 880, loss: 0.04472724348306656
step: 890, loss: 0.10784157365560532
step: 900, loss: 0.023877430707216263
step: 910, loss: 0.027263998985290527
step: 920, loss: 0.057980652898550034
step: 930, loss: 0.10443267971277237
step: 940, loss: 0.07458820194005966
step: 950, loss: 0.07874977588653564
step: 960, loss: 0.05748249962925911
step: 970, loss: 0.05110155791044235
step: 980, loss: 0.04672164097428322
step: 990, loss: 0.003565712831914425
step: 1000, loss: 0.15695343911647797
step: 1010, loss: 0.08612238615751266
step: 1020, loss: 0.06848739087581635
step: 1030, loss: 0.0002187524369219318
step: 1040, loss: 0.028622834011912346
step: 1050, loss: 0.0005457847728393972
step: 1060, loss: 0.08084428310394287
step: 1070, loss: 0.05264778435230255
epoch 15: dev_f1=0.9265116279069768, f1=0.9234360410830998, best_f1=0.9457221711131555
step: 0, loss: 0.040479350835084915
step: 10, loss: 0.07448268681764603
step: 20, loss: 0.09745988249778748
step: 30, loss: 0.0464242585003376
step: 40, loss: 0.016039889305830002
step: 50, loss: 0.017146917060017586
step: 60, loss: 0.05838322266936302
step: 70, loss: 0.02878819964826107
step: 80, loss: 8.926002192310989e-05
step: 90, loss: 0.10001465678215027
step: 100, loss: 0.05612363666296005
step: 110, loss: 0.0006520475726574659
step: 120, loss: 0.020194921642541885
step: 130, loss: 0.006177837960422039
step: 140, loss: 0.09825000166893005
step: 150, loss: 0.03846012428402901
step: 160, loss: 0.06872160732746124
step: 170, loss: 9.565678192302585e-05
step: 180, loss: 0.08678420633077621
step: 190, loss: 0.01672189123928547
step: 200, loss: 0.023549027740955353
step: 210, loss: 3.4388984204269946e-05
step: 220, loss: 0.060902923345565796
step: 230, loss: 0.06801742315292358
step: 240, loss: 7.162739348132163e-05
step: 250, loss: 0.04597408324480057
step: 260, loss: 0.033460572361946106
step: 270, loss: 0.03176221251487732
step: 280, loss: 0.05067159980535507
step: 290, loss: 0.03775688633322716
step: 300, loss: 0.03381217271089554
step: 310, loss: 0.03785621374845505
step: 320, loss: 0.03455284610390663
step: 330, loss: 0.08516301214694977
step: 340, loss: 0.052923694252967834
step: 350, loss: 0.0034050813410431147
step: 360, loss: 0.03227446973323822
step: 370, loss: 0.05086582526564598
step: 380, loss: 0.012839006260037422
step: 390, loss: 0.01620514877140522
step: 400, loss: 0.016517270356416702
step: 410, loss: 0.07248133420944214
step: 420, loss: 0.0007829413516446948
step: 430, loss: 0.058745674788951874
step: 440, loss: 0.06231692060828209
step: 450, loss: 0.041170883923769
step: 460, loss: 0.036889877170324326
step: 470, loss: 0.07305125892162323
step: 480, loss: 0.07016394287347794
step: 490, loss: 0.0001982283138204366
step: 500, loss: 0.0042758602648973465
step: 510, loss: 0.024379216134548187
step: 520, loss: 0.07366328686475754
step: 530, loss: 0.062214747071266174
step: 540, loss: 0.0002265997463837266
step: 550, loss: 0.019060662016272545
step: 560, loss: 0.12452432513237
step: 570, loss: 0.049629081040620804
step: 580, loss: 0.03698700666427612
step: 590, loss: 0.057523179799318314
step: 600, loss: 0.016195058822631836
step: 610, loss: 0.06820432841777802
step: 620, loss: 0.09559743106365204
step: 630, loss: 0.08845175802707672
step: 640, loss: 0.1381206512451172
step: 650, loss: 0.03960942104458809
step: 660, loss: 0.026931528002023697
step: 670, loss: 0.04216885194182396
step: 680, loss: 0.033265914767980576
step: 690, loss: 0.01449388638138771
step: 700, loss: 0.09755346924066544
step: 710, loss: 0.07017094641923904
step: 720, loss: 0.016871966421604156
step: 730, loss: 0.062136657536029816
step: 740, loss: 0.03350003808736801
step: 750, loss: 0.01962757483124733
step: 760, loss: 0.017870882526040077
step: 770, loss: 0.0017429632134735584
step: 780, loss: 0.028234869241714478
step: 790, loss: 0.05552426725625992
step: 800, loss: 0.07169295102357864
step: 810, loss: 0.029554253444075584
step: 820, loss: 0.009170686826109886
step: 830, loss: 0.00031031863181851804
step: 840, loss: 0.07369360327720642
step: 850, loss: 0.03349393978714943
step: 860, loss: 0.07892117649316788
step: 870, loss: 0.07435160130262375
step: 880, loss: 0.0377737395465374
step: 890, loss: 0.043676022440195084
step: 900, loss: 8.37834959384054e-05
step: 910, loss: 0.10513154417276382
step: 920, loss: 0.0362745001912117
step: 930, loss: 0.05502021685242653
step: 940, loss: 0.025409087538719177
step: 950, loss: 0.07468226552009583
step: 960, loss: 0.000989588676020503
step: 970, loss: 0.03613517805933952
step: 980, loss: 0.07935542613267899
step: 990, loss: 0.03292686119675636
step: 1000, loss: 0.04273318871855736
step: 1010, loss: 0.08809754252433777
step: 1020, loss: 0.04703293740749359
step: 1030, loss: 0.03668564558029175
step: 1040, loss: 0.029872333630919456
step: 1050, loss: 0.037029482424259186
step: 1060, loss: 0.019852176308631897
step: 1070, loss: 0.04673483595252037
epoch 16: dev_f1=0.9245372567631704, f1=0.9168646080760096, best_f1=0.9457221711131555
step: 0, loss: 0.020736169070005417
step: 10, loss: 0.02112380787730217
step: 20, loss: 0.032807834446430206
step: 30, loss: 0.0773516371846199
step: 40, loss: 0.03730029612779617
step: 50, loss: 0.059609536081552505
step: 60, loss: 0.04202452674508095
step: 70, loss: 7.907051622169092e-05
step: 80, loss: 0.03497011959552765
step: 90, loss: 0.048603497445583344
step: 100, loss: 0.06637871265411377
step: 110, loss: 0.016210071742534637
step: 120, loss: 0.09000688791275024
step: 130, loss: 0.055138830095529556
step: 140, loss: 0.10572592169046402
step: 150, loss: 0.038461264222860336
step: 160, loss: 0.023053614422678947
step: 170, loss: 0.06430880725383759
step: 180, loss: 0.0008742589852772653
step: 190, loss: 0.026464277878403664
step: 200, loss: 8.229667582781985e-05
step: 210, loss: 0.036475520581007004
step: 220, loss: 0.08977599442005157
step: 230, loss: 0.019085904583334923
step: 240, loss: 0.009203873574733734
step: 250, loss: 0.02850424312055111
step: 260, loss: 0.045219630002975464
step: 270, loss: 0.02870304509997368
step: 280, loss: 0.021071625873446465
step: 290, loss: 7.80461632530205e-05
step: 300, loss: 0.07673953473567963
step: 310, loss: 0.051049765199422836
step: 320, loss: 0.06917756795883179
step: 330, loss: 0.029305284842848778
step: 340, loss: 0.10835457593202591
step: 350, loss: 0.00023560387489851564
step: 360, loss: 0.02269791066646576
step: 370, loss: 0.03949149325489998
step: 380, loss: 0.001838085474446416
step: 390, loss: 0.138840913772583
step: 400, loss: 0.009990902617573738
step: 410, loss: 0.0181463360786438
step: 420, loss: 0.01823042891919613
step: 430, loss: 0.04536224529147148
step: 440, loss: 0.025470277294516563
step: 450, loss: 0.015647931024432182
step: 460, loss: 0.04349704086780548
step: 470, loss: 0.01600610837340355
step: 480, loss: 0.04663745313882828
step: 490, loss: 0.10343573987483978
step: 500, loss: 0.06718015670776367
step: 510, loss: 6.402540020644665e-05
step: 520, loss: 0.15060006082057953
step: 530, loss: 0.07505950331687927
step: 540, loss: 0.022028068080544472
step: 550, loss: 0.024620208889245987
step: 560, loss: 0.02726595476269722
step: 570, loss: 0.12565286457538605
step: 580, loss: 0.0020225520711392164
step: 590, loss: 0.029527070000767708
step: 600, loss: 0.04312487691640854
step: 610, loss: 0.047361794859170914
step: 620, loss: 4.0817103581503034e-05
step: 630, loss: 0.017967280000448227
step: 640, loss: 0.021623531356453896
step: 650, loss: 0.028598176315426826
step: 660, loss: 0.07515981048345566
step: 670, loss: 0.02369866520166397
step: 680, loss: 0.0779479518532753
step: 690, loss: 0.058514125645160675
step: 700, loss: 0.09859245270490646
step: 710, loss: 0.09871864318847656
step: 720, loss: 0.03451324254274368
step: 730, loss: 0.009961884468793869
step: 740, loss: 0.09275935590267181
step: 750, loss: 0.034668177366256714
step: 760, loss: 0.05435662716627121
step: 770, loss: 0.07574381679296494
step: 780, loss: 0.019520554691553116
step: 790, loss: 0.0592055544257164
step: 800, loss: 0.06908747553825378
step: 810, loss: 0.04861889407038689
step: 820, loss: 0.011529405601322651
step: 830, loss: 0.05673655867576599
step: 840, loss: 0.02133675292134285
step: 850, loss: 0.06335252523422241
step: 860, loss: 0.06721191853284836
step: 870, loss: 0.06837048381567001
step: 880, loss: 0.020904630422592163
step: 890, loss: 1.5180058653641026e-05
step: 900, loss: 0.08072209358215332
step: 910, loss: 0.045794907957315445
step: 920, loss: 0.044933781027793884
step: 930, loss: 0.022026032209396362
step: 940, loss: 0.033855341374874115
step: 950, loss: 0.05841547250747681
step: 960, loss: 0.000178877409780398
step: 970, loss: 0.024417709559202194
step: 980, loss: 0.03430142253637314
step: 990, loss: 1.281853565160418e-05
step: 1000, loss: 0.04310242831707001
step: 1010, loss: 0.012302271090447903
step: 1020, loss: 0.01347940880805254
step: 1030, loss: 0.06469681859016418
step: 1040, loss: 0.1216244250535965
step: 1050, loss: 0.05280684679746628
step: 1060, loss: 0.02217826060950756
step: 1070, loss: 0.07667475938796997
epoch 17: dev_f1=0.9227144203581528, f1=0.9190968955785513, best_f1=0.9457221711131555
step: 0, loss: 0.0010318742133677006
step: 10, loss: 0.11179694533348083
step: 20, loss: 0.028163688257336617
step: 30, loss: 0.08967864513397217
step: 40, loss: 0.050295550376176834
step: 50, loss: 0.05966384336352348
step: 60, loss: 0.0614757314324379
step: 70, loss: 0.0716085210442543
step: 80, loss: 0.041474681347608566
step: 90, loss: 0.04919902980327606
step: 100, loss: 0.03811419755220413
step: 110, loss: 0.012237660586833954
step: 120, loss: 0.048158302903175354
step: 130, loss: 0.021734075620770454
step: 140, loss: 0.06861241161823273
step: 150, loss: 0.1076120138168335
step: 160, loss: 0.0357847698032856
step: 170, loss: 0.08054008334875107
step: 180, loss: 0.03759661689400673
step: 190, loss: 0.02285146526992321
step: 200, loss: 0.020744023844599724
step: 210, loss: 0.06906744092702866
step: 220, loss: 0.020232098177075386
step: 230, loss: 0.04186543449759483
step: 240, loss: 0.03469109535217285
step: 250, loss: 0.007316145114600658
step: 260, loss: 0.016534462571144104
step: 270, loss: 0.01759425736963749
step: 280, loss: 0.08098851889371872
step: 290, loss: 0.04057963937520981
step: 300, loss: 0.05693618580698967
step: 310, loss: 0.06341422349214554
step: 320, loss: 0.044539328664541245
step: 330, loss: 0.03775378689169884
step: 340, loss: 0.04517185688018799
step: 350, loss: 0.07425417006015778
step: 360, loss: 0.044691286981105804
step: 370, loss: 0.03259896859526634
step: 380, loss: 0.028579268604516983
step: 390, loss: 0.012812201865017414
step: 400, loss: 0.021501773968338966
step: 410, loss: 0.01849602907896042
step: 420, loss: 0.0006151131819933653
step: 430, loss: 0.04280828312039375
step: 440, loss: 0.02440960891544819
step: 450, loss: 0.004314814228564501
step: 460, loss: 0.12983059883117676
step: 470, loss: 0.038835309445858
step: 480, loss: 0.03429887071251869
step: 490, loss: 0.03060208633542061
step: 500, loss: 0.009915592148900032
step: 510, loss: 0.00025117091718129814
step: 520, loss: 0.022182747721672058
step: 530, loss: 0.042990248650312424
step: 540, loss: 0.07129499316215515
step: 550, loss: 7.443147478625178e-05
step: 560, loss: 0.19110740721225739
step: 570, loss: 0.005865787155926228
step: 580, loss: 0.023466086015105247
step: 590, loss: 0.03918546438217163
step: 600, loss: 0.0531148798763752
step: 610, loss: 0.034182485193014145
step: 620, loss: 0.11946972459554672
step: 630, loss: 0.0013381746830418706
step: 640, loss: 0.02077348530292511
step: 650, loss: 0.06729760020971298
step: 660, loss: 0.00023452730965800583
step: 670, loss: 0.04913756623864174
step: 680, loss: 0.03109276294708252
step: 690, loss: 0.04945801943540573
step: 700, loss: 0.0803876519203186
step: 710, loss: 0.03518310561776161
step: 720, loss: 0.029175110161304474
step: 730, loss: 0.006528439465910196
step: 740, loss: 0.020385708659887314
step: 750, loss: 0.13515008985996246
step: 760, loss: 0.028658965602517128
step: 770, loss: 0.01870284043252468
step: 780, loss: 0.03219103813171387
step: 790, loss: 0.020711299031972885
step: 800, loss: 0.0001509885914856568
step: 810, loss: 0.0950586274266243
step: 820, loss: 0.03940374776721001
step: 830, loss: 0.07247649133205414
step: 840, loss: 0.06489726901054382
step: 850, loss: 0.05049510672688484
step: 860, loss: 0.10235675424337387
step: 870, loss: 0.0025347936898469925
step: 880, loss: 5.188196519156918e-05
step: 890, loss: 0.03990484029054642
step: 900, loss: 0.1066705733537674
step: 910, loss: 0.02053450420498848
step: 920, loss: 0.032526373863220215
step: 930, loss: 0.001308182836510241
step: 940, loss: 0.0013978128554299474
step: 950, loss: 0.06985273212194443
step: 960, loss: 6.529232632601634e-05
step: 970, loss: 0.027225928381085396
step: 980, loss: 0.031930066645145416
step: 990, loss: 0.047700777649879456
step: 1000, loss: 0.005387515295296907
step: 1010, loss: 0.06283074617385864
step: 1020, loss: 0.0008527438621968031
step: 1030, loss: 0.02128474786877632
step: 1040, loss: 0.05589698255062103
step: 1050, loss: 0.05324530228972435
step: 1060, loss: 0.024345707148313522
step: 1070, loss: 0.10782362520694733
epoch 18: dev_f1=0.9214758751182593, f1=0.9149338374291115, best_f1=0.9457221711131555
step: 0, loss: 0.1254482865333557
step: 10, loss: 0.03845827654004097
step: 20, loss: 0.031006556004285812
step: 30, loss: 0.04499885067343712
step: 40, loss: 0.041178833693265915
step: 50, loss: 0.016470782458782196
step: 60, loss: 0.09754666686058044
step: 70, loss: 0.08590388298034668
step: 80, loss: 0.0619121678173542
step: 90, loss: 0.03760548681020737
step: 100, loss: 0.04260798916220665
step: 110, loss: 0.028118524700403214
step: 120, loss: 0.05660327523946762
step: 130, loss: 0.06833791732788086
step: 140, loss: 0.02915753796696663
step: 150, loss: 0.03094620257616043
step: 160, loss: 0.012227828614413738
step: 170, loss: 5.879370655748062e-05
step: 180, loss: 0.03395022451877594
step: 190, loss: 0.07856478542089462
step: 200, loss: 0.038822829723358154
step: 210, loss: 0.01267559826374054
step: 220, loss: 0.028264636173844337
step: 230, loss: 0.021442987024784088
step: 240, loss: 0.02993936464190483
step: 250, loss: 0.058858055621385574
step: 260, loss: 0.03954574465751648
step: 270, loss: 0.11300208419561386
step: 280, loss: 0.09780803322792053
step: 290, loss: 0.020095519721508026
step: 300, loss: 0.03835121914744377
step: 310, loss: 6.428999768104404e-05
step: 320, loss: 0.04875541850924492
step: 330, loss: 0.11336001008749008
step: 340, loss: 0.05470889434218407
step: 350, loss: 0.031040113419294357
step: 360, loss: 3.8604295696131885e-05
step: 370, loss: 0.09107787162065506
step: 380, loss: 0.054441630840301514
step: 390, loss: 0.07725312560796738
step: 400, loss: 3.0725932447239757e-05
step: 410, loss: 0.06648661196231842
step: 420, loss: 0.0015953360125422478
step: 430, loss: 0.0007839918835088611
step: 440, loss: 2.6414181775180623e-05
step: 450, loss: 0.06958384811878204
step: 460, loss: 0.053666599094867706
step: 470, loss: 0.05184568092226982
step: 480, loss: 0.07429865002632141
step: 490, loss: 0.08439411222934723
step: 500, loss: 0.036337099969387054
step: 510, loss: 0.01747433841228485
step: 520, loss: 0.015383967198431492
step: 530, loss: 0.023305445909500122
step: 540, loss: 0.07185014337301254
step: 550, loss: 0.04581868648529053
step: 560, loss: 0.1827469766139984
step: 570, loss: 0.0455930233001709
step: 580, loss: 0.07362952828407288
step: 590, loss: 0.020970741286873817
step: 600, loss: 0.04911714419722557
step: 610, loss: 0.04808051884174347
step: 620, loss: 1.655461164773442e-05
step: 630, loss: 0.032768648117780685
step: 640, loss: 0.014897547662258148
step: 650, loss: 0.12480468302965164
step: 660, loss: 2.821509951900225e-05
step: 670, loss: 0.06716670095920563
step: 680, loss: 0.008963072672486305
step: 690, loss: 0.026249155402183533
step: 700, loss: 0.042830321937799454
step: 710, loss: 0.05965385213494301
step: 720, loss: 0.08146809041500092
step: 730, loss: 0.08668795973062515
step: 740, loss: 0.016503311693668365
step: 750, loss: 0.04888375103473663
step: 760, loss: 0.03331718593835831
step: 770, loss: 0.043618347495794296
step: 780, loss: 0.06311693787574768
step: 790, loss: 0.017573939636349678
step: 800, loss: 0.031568631529808044
step: 810, loss: 4.751859523821622e-05
step: 820, loss: 0.06918173283338547
step: 830, loss: 0.03227929025888443
step: 840, loss: 0.0300807673484087
step: 850, loss: 0.021984294056892395
step: 860, loss: 0.0002703882346395403
step: 870, loss: 0.05253073573112488
step: 880, loss: 0.04513705149292946
step: 890, loss: 0.03365365043282509
step: 900, loss: 0.016468903049826622
step: 910, loss: 0.021075855940580368
step: 920, loss: 0.0731423944234848
step: 930, loss: 0.06452798843383789
step: 940, loss: 0.03909223899245262
step: 950, loss: 4.783127587870695e-05
step: 960, loss: 0.052766233682632446
step: 970, loss: 0.012077825143933296
step: 980, loss: 0.004085773602128029
step: 990, loss: 0.07107381522655487
step: 1000, loss: 0.08136061578989029
step: 1010, loss: 0.12488733977079391
step: 1020, loss: 0.016364555805921555
step: 1030, loss: 0.04833411052823067
step: 1040, loss: 0.034171391278505325
step: 1050, loss: 0.05952191352844238
step: 1060, loss: 0.03617993742227554
step: 1070, loss: 0.05425271764397621
epoch 19: dev_f1=0.9210401891252956, f1=0.9158790170132325, best_f1=0.9457221711131555
step: 0, loss: 0.03846479207277298
step: 10, loss: 0.08776602149009705
step: 20, loss: 0.10716132819652557
step: 30, loss: 0.14653263986110687
step: 40, loss: 0.05642365664243698
step: 50, loss: 0.002020718529820442
step: 60, loss: 0.056482091546058655
step: 70, loss: 0.030756892636418343
step: 80, loss: 0.08097779005765915
step: 90, loss: 0.017158521339297295
step: 100, loss: 0.09502185136079788
step: 110, loss: 0.1071770042181015
step: 120, loss: 0.04309988394379616
step: 130, loss: 0.07474439591169357
step: 140, loss: 0.05221366137266159
step: 150, loss: 0.03791126236319542
step: 160, loss: 0.04867163300514221
step: 170, loss: 0.041434984654188156
step: 180, loss: 0.031156891956925392
step: 190, loss: 0.002853851765394211
step: 200, loss: 0.011711160652339458
step: 210, loss: 0.050955504179000854
step: 220, loss: 0.06618835031986237
step: 230, loss: 0.03242876008152962
step: 240, loss: 0.04652369022369385
step: 250, loss: 0.015331730246543884
step: 260, loss: 0.12497065961360931
step: 270, loss: 0.03195055201649666
step: 280, loss: 0.08417201042175293
step: 290, loss: 0.03328191116452217
step: 300, loss: 0.06532704830169678
step: 310, loss: 0.06144258752465248
step: 320, loss: 0.11138865351676941
step: 330, loss: 0.03067849576473236
step: 340, loss: 0.01920711062848568
step: 350, loss: 0.06639335304498672
step: 360, loss: 0.021712951362133026
step: 370, loss: 0.04337063059210777
step: 380, loss: 0.03794088214635849
step: 390, loss: 0.06129878759384155
step: 400, loss: 0.059691689908504486
step: 410, loss: 0.027134349569678307
step: 420, loss: 0.03285196051001549
step: 430, loss: 0.04746396839618683
step: 440, loss: 0.05057097598910332
step: 450, loss: 0.009991341270506382
step: 460, loss: 0.03990672528743744
step: 470, loss: 0.0202597938477993
step: 480, loss: 0.07111034542322159
step: 490, loss: 0.05358608812093735
step: 500, loss: 0.19788552820682526
step: 510, loss: 0.0392606183886528
step: 520, loss: 0.05976952612400055
step: 530, loss: 0.0443696603178978
step: 540, loss: 0.07221325486898422
step: 550, loss: 0.0910239964723587
step: 560, loss: 0.018306422978639603
step: 570, loss: 0.05744028463959694
step: 580, loss: 0.04769407585263252
step: 590, loss: 0.059505872428417206
step: 600, loss: 0.02123771607875824
step: 610, loss: 0.06001650169491768
step: 620, loss: 0.04321148246526718
step: 630, loss: 0.05031943693757057
step: 640, loss: 0.023661192506551743
step: 650, loss: 8.06315874797292e-05
step: 660, loss: 0.02828974649310112
step: 670, loss: 0.06126681715250015
step: 680, loss: 0.061717960983514786
step: 690, loss: 0.0006456692353822291
step: 700, loss: 7.32684857212007e-05
step: 710, loss: 0.11527038365602493
step: 720, loss: 0.05977413430809975
step: 730, loss: 0.051209691911935806
step: 740, loss: 0.07254292070865631
step: 750, loss: 0.02088329941034317
step: 760, loss: 0.05344143509864807
step: 770, loss: 0.009882542304694653
step: 780, loss: 0.05985520780086517
step: 790, loss: 0.0601901151239872
step: 800, loss: 0.02355330064892769
step: 810, loss: 0.09616659581661224
step: 820, loss: 0.037319302558898926
step: 830, loss: 0.07396796345710754
step: 840, loss: 0.0007422725902870297
step: 850, loss: 0.042369045317173004
step: 860, loss: 0.03562624007463455
step: 870, loss: 0.018201831728219986
step: 880, loss: 2.124366073985584e-05
step: 890, loss: 0.05033036693930626
step: 900, loss: 0.013864276930689812
step: 910, loss: 0.03666497766971588
step: 920, loss: 0.04201526567339897
step: 930, loss: 0.022517841309309006
step: 940, loss: 0.0351962074637413
step: 950, loss: 0.04758357256650925
step: 960, loss: 0.01266720611602068
step: 970, loss: 0.08965049684047699
step: 980, loss: 0.01398516446352005
step: 990, loss: 0.11395671218633652
step: 1000, loss: 0.0174894817173481
step: 1010, loss: 0.06503592431545258
step: 1020, loss: 0.031349532306194305
step: 1030, loss: 0.016151679679751396
step: 1040, loss: 0.01986905187368393
step: 1050, loss: 0.0451992005109787
step: 1060, loss: 0.039300426840782166
step: 1070, loss: 0.05230678990483284
epoch 20: dev_f1=0.921189240207645, f1=0.9163533834586467, best_f1=0.9457221711131555
