cuda
Device: cuda
step: 0, loss: 0.7509017586708069
step: 10, loss: 0.5450251698493958
step: 20, loss: 0.39942607283592224
step: 30, loss: 0.45714110136032104
step: 40, loss: 0.2516663670539856
step: 50, loss: 0.31548941135406494
step: 60, loss: 0.19524376094341278
step: 70, loss: 0.2752040922641754
step: 80, loss: 0.18614377081394196
step: 90, loss: 0.20957274734973907
step: 100, loss: 0.3996320962905884
step: 110, loss: 0.3007330298423767
step: 120, loss: 0.179666206240654
step: 130, loss: 0.2527347505092621
step: 140, loss: 0.1512630581855774
step: 150, loss: 0.30672648549079895
step: 160, loss: 0.2130502164363861
step: 170, loss: 0.1305503100156784
step: 180, loss: 0.18755219876766205
step: 190, loss: 0.11243391782045364
step: 200, loss: 0.23829950392246246
step: 210, loss: 0.2387438714504242
step: 220, loss: 0.12436260282993317
step: 230, loss: 0.14028292894363403
step: 240, loss: 0.36091411113739014
step: 250, loss: 0.42133310437202454
step: 260, loss: 0.3239194452762604
step: 270, loss: 0.1716398447751999
step: 280, loss: 0.2860652506351471
step: 290, loss: 0.03926106542348862
step: 300, loss: 0.16016575694084167
step: 310, loss: 0.15092387795448303
step: 320, loss: 0.1016436442732811
step: 330, loss: 0.32433271408081055
step: 340, loss: 0.18214869499206543
step: 350, loss: 0.23347556591033936
step: 360, loss: 0.14182811975479126
step: 370, loss: 0.24828630685806274
step: 380, loss: 0.09913075715303421
step: 390, loss: 0.1947353631258011
step: 400, loss: 0.20989850163459778
step: 410, loss: 0.15143345296382904
step: 420, loss: 0.3002537786960602
step: 430, loss: 0.11836005747318268
step: 440, loss: 0.0719270259141922
step: 450, loss: 0.16519731283187866
step: 460, loss: 0.11878079921007156
step: 470, loss: 0.15046456456184387
step: 480, loss: 0.07738145440816879
step: 490, loss: 0.09667925536632538
step: 500, loss: 0.10764030367136002
step: 510, loss: 0.08577209711074829
step: 520, loss: 0.11104649305343628
step: 530, loss: 0.1826026886701584
step: 540, loss: 0.1472131758928299
step: 550, loss: 0.16150571405887604
step: 560, loss: 0.3591548204421997
step: 570, loss: 0.14971275627613068
step: 580, loss: 0.09838012605905533
step: 590, loss: 0.13763609528541565
step: 600, loss: 0.17256984114646912
step: 610, loss: 0.15409298241138458
step: 620, loss: 0.14144478738307953
step: 630, loss: 0.10568185895681381
step: 640, loss: 0.24036823213100433
step: 650, loss: 0.20547379553318024
step: 660, loss: 0.1301785558462143
step: 670, loss: 0.12593846023082733
step: 680, loss: 0.2490427941083908
step: 690, loss: 0.032789092510938644
step: 700, loss: 0.08752265572547913
step: 710, loss: 0.11578061431646347
step: 720, loss: 0.15981638431549072
step: 730, loss: 0.05967666208744049
step: 740, loss: 0.17056481540203094
step: 750, loss: 0.09669843316078186
step: 760, loss: 0.05020347610116005
step: 770, loss: 0.10540362447500229
step: 780, loss: 0.1347666233778
step: 790, loss: 0.1967904269695282
step: 800, loss: 0.18008117377758026
step: 810, loss: 0.16418620944023132
step: 820, loss: 0.1689898669719696
step: 830, loss: 0.018963506445288658
step: 840, loss: 0.10866312682628632
step: 850, loss: 0.21939153969287872
step: 860, loss: 0.15087899565696716
step: 870, loss: 0.08048897236585617
step: 880, loss: 0.23873013257980347
step: 890, loss: 0.05073805898427963
step: 900, loss: 0.2978726625442505
step: 910, loss: 0.18372488021850586
step: 920, loss: 0.10934439301490784
step: 930, loss: 0.0900266021490097
step: 940, loss: 0.066105917096138
step: 950, loss: 0.19261857867240906
step: 960, loss: 0.08108455687761307
step: 970, loss: 0.12274181097745895
step: 980, loss: 0.23650559782981873
step: 990, loss: 0.10062349587678909
step: 1000, loss: 0.15577636659145355
step: 1010, loss: 0.15693804621696472
step: 1020, loss: 0.08363845199346542
step: 1030, loss: 0.05245307460427284
step: 1040, loss: 0.12514904141426086
step: 1050, loss: 0.20110240578651428
step: 1060, loss: 0.20150528848171234
step: 1070, loss: 0.1169092059135437
epoch 1: dev_f1=0.9130832570905763, f1=0.9225192569098323, best_f1=0.9225192569098323
step: 0, loss: 0.1755041927099228
step: 10, loss: 0.04111269488930702
step: 20, loss: 0.1831134855747223
step: 30, loss: 0.0583382211625576
step: 40, loss: 0.048641473054885864
step: 50, loss: 0.1454409807920456
step: 60, loss: 0.15492352843284607
step: 70, loss: 0.15137529373168945
step: 80, loss: 0.03538151830434799
step: 90, loss: 0.22388406097888947
step: 100, loss: 0.043937813490629196
step: 110, loss: 0.1686902642250061
step: 120, loss: 0.1330638974905014
step: 130, loss: 0.14230604469776154
step: 140, loss: 0.06261656433343887
step: 150, loss: 0.10869404673576355
step: 160, loss: 0.13224628567695618
step: 170, loss: 0.04453606531023979
step: 180, loss: 0.1625567078590393
step: 190, loss: 0.13630542159080505
step: 200, loss: 0.12533217668533325
step: 210, loss: 0.15732945501804352
step: 220, loss: 0.16436156630516052
step: 230, loss: 0.10006963461637497
step: 240, loss: 0.05983854830265045
step: 250, loss: 0.08357739448547363
step: 260, loss: 0.10804279148578644
step: 270, loss: 0.05626388639211655
step: 280, loss: 0.07052787393331528
step: 290, loss: 0.08343473821878433
step: 300, loss: 0.05822787433862686
step: 310, loss: 0.06464002281427383
step: 320, loss: 0.09675044566392899
step: 330, loss: 0.08222133666276932
step: 340, loss: 0.05432726815342903
step: 350, loss: 0.15962634980678558
step: 360, loss: 0.14116017520427704
step: 370, loss: 0.13990400731563568
step: 380, loss: 0.1872519701719284
step: 390, loss: 0.1271674782037735
step: 400, loss: 0.18022902309894562
step: 410, loss: 0.03928437829017639
step: 420, loss: 0.13433068990707397
step: 430, loss: 0.09368108958005905
step: 440, loss: 0.10592764616012573
step: 450, loss: 0.10768980532884598
step: 460, loss: 0.316156268119812
step: 470, loss: 0.11275274306535721
step: 480, loss: 0.09334032237529755
step: 490, loss: 0.14560261368751526
step: 500, loss: 0.13657429814338684
step: 510, loss: 0.04001748189330101
step: 520, loss: 0.16236212849617004
step: 530, loss: 0.05183199793100357
step: 540, loss: 0.1297232061624527
step: 550, loss: 0.14794029295444489
step: 560, loss: 0.07942957431077957
step: 570, loss: 0.11115466803312302
step: 580, loss: 0.020715458318591118
step: 590, loss: 0.0490400493144989
step: 600, loss: 0.10982764512300491
step: 610, loss: 0.22268663346767426
step: 620, loss: 0.09491760283708572
step: 630, loss: 0.2656015455722809
step: 640, loss: 0.16982263326644897
step: 650, loss: 0.11905336380004883
step: 660, loss: 0.04911929741501808
step: 670, loss: 0.09660779684782028
step: 680, loss: 0.0998334065079689
step: 690, loss: 0.08700531721115112
step: 700, loss: 0.1244286447763443
step: 710, loss: 0.1985897570848465
step: 720, loss: 0.17089316248893738
step: 730, loss: 0.07610756903886795
step: 740, loss: 0.2363768219947815
step: 750, loss: 0.18718068301677704
step: 760, loss: 0.1153460144996643
step: 770, loss: 0.05184080824255943
step: 780, loss: 0.12557947635650635
step: 790, loss: 0.17939025163650513
step: 800, loss: 0.15082883834838867
step: 810, loss: 0.11858613044023514
step: 820, loss: 0.1839195340871811
step: 830, loss: 0.11580522358417511
step: 840, loss: 0.10965210199356079
step: 850, loss: 0.130940243601799
step: 860, loss: 0.09375864267349243
step: 870, loss: 0.12143250554800034
step: 880, loss: 0.14636294543743134
step: 890, loss: 0.22767552733421326
step: 900, loss: 0.17188958823680878
step: 910, loss: 0.15072961151599884
step: 920, loss: 0.057395756244659424
step: 930, loss: 0.0806201696395874
step: 940, loss: 0.10183580219745636
step: 950, loss: 0.15735948085784912
step: 960, loss: 0.12191087007522583
step: 970, loss: 0.18845659494400024
step: 980, loss: 0.10914666205644608
step: 990, loss: 0.11838342249393463
step: 1000, loss: 0.09452168643474579
step: 1010, loss: 0.18727390468120575
step: 1020, loss: 0.07204747945070267
step: 1030, loss: 0.16035506129264832
step: 1040, loss: 0.14060074090957642
step: 1050, loss: 0.05040741339325905
step: 1060, loss: 0.06573930382728577
step: 1070, loss: 0.09466823190450668
epoch 2: dev_f1=0.9204440333024977, f1=0.9174734900875979, best_f1=0.9174734900875979
step: 0, loss: 0.08095675706863403
step: 10, loss: 0.09444650262594223
step: 20, loss: 0.09033215045928955
step: 30, loss: 0.03255770727992058
step: 40, loss: 0.09578731656074524
step: 50, loss: 0.15832367539405823
step: 60, loss: 0.14582858979701996
step: 70, loss: 0.10704664140939713
step: 80, loss: 0.09621914476156235
step: 90, loss: 0.13462570309638977
step: 100, loss: 0.14238789677619934
step: 110, loss: 0.08072616904973984
step: 120, loss: 0.06181279569864273
step: 130, loss: 0.2689695954322815
step: 140, loss: 0.20556782186031342
step: 150, loss: 0.06235312670469284
step: 160, loss: 0.06189465522766113
step: 170, loss: 0.22236521542072296
step: 180, loss: 0.047381218522787094
step: 190, loss: 0.24615943431854248
step: 200, loss: 0.075938880443573
step: 210, loss: 0.13177797198295593
step: 220, loss: 0.07944588363170624
step: 230, loss: 0.0845959261059761
step: 240, loss: 0.14744193851947784
step: 250, loss: 0.12225735187530518
step: 260, loss: 0.0369064137339592
step: 270, loss: 0.1313154399394989
step: 280, loss: 0.053647223860025406
step: 290, loss: 0.11467283964157104
step: 300, loss: 0.10322283208370209
step: 310, loss: 0.05911710858345032
step: 320, loss: 0.034290049225091934
step: 330, loss: 0.16294099390506744
step: 340, loss: 0.12654443085193634
step: 350, loss: 0.1018441691994667
step: 360, loss: 0.087803415954113
step: 370, loss: 0.09971021860837936
step: 380, loss: 0.1096595823764801
step: 390, loss: 0.13014884293079376
step: 400, loss: 0.18836311995983124
step: 410, loss: 0.06408030539751053
step: 420, loss: 0.08495444059371948
step: 430, loss: 0.17677903175354004
step: 440, loss: 0.12340415269136429
step: 450, loss: 0.1473480463027954
step: 460, loss: 0.09675753116607666
step: 470, loss: 0.16147302091121674
step: 480, loss: 0.13779373466968536
step: 490, loss: 0.062292806804180145
step: 500, loss: 0.13706201314926147
step: 510, loss: 0.23457257449626923
step: 520, loss: 0.10411271452903748
step: 530, loss: 0.17645332217216492
step: 540, loss: 0.06964042037725449
step: 550, loss: 0.08799291402101517
step: 560, loss: 0.10503353178501129
step: 570, loss: 0.05174163728952408
step: 580, loss: 0.31754788756370544
step: 590, loss: 0.11158743500709534
step: 600, loss: 0.05699414759874344
step: 610, loss: 0.07295680791139603
step: 620, loss: 0.10525865107774734
step: 630, loss: 0.106776662170887
step: 640, loss: 0.10287194699048996
step: 650, loss: 0.1949726790189743
step: 660, loss: 0.024618055671453476
step: 670, loss: 0.18989253044128418
step: 680, loss: 0.11862583458423615
step: 690, loss: 0.11637334525585175
step: 700, loss: 0.05577893555164337
step: 710, loss: 0.08749818801879883
step: 720, loss: 0.15155690908432007
step: 730, loss: 0.1880268156528473
step: 740, loss: 0.10667484998703003
step: 750, loss: 0.015305624343454838
step: 760, loss: 0.10073009878396988
step: 770, loss: 0.07584020495414734
step: 780, loss: 0.09044905006885529
step: 790, loss: 0.18354706466197968
step: 800, loss: 0.11927905678749084
step: 810, loss: 0.06732385605573654
step: 820, loss: 0.08557343482971191
step: 830, loss: 0.14597219228744507
step: 840, loss: 0.16440895199775696
step: 850, loss: 0.027267353609204292
step: 860, loss: 0.19514575600624084
step: 870, loss: 0.11013428866863251
step: 880, loss: 0.08165232837200165
step: 890, loss: 0.11860545724630356
step: 900, loss: 0.038870908319950104
step: 910, loss: 0.15571004152297974
step: 920, loss: 0.060934003442525864
step: 930, loss: 0.16879093647003174
step: 940, loss: 0.08587627112865448
step: 950, loss: 0.21099071204662323
step: 960, loss: 0.023380957543849945
step: 970, loss: 0.09954903274774551
step: 980, loss: 0.07003570348024368
step: 990, loss: 0.09563322365283966
step: 1000, loss: 0.15078602731227875
step: 1010, loss: 0.04851483553647995
step: 1020, loss: 0.04729381948709488
step: 1030, loss: 0.025443872436881065
step: 1040, loss: 0.14523835480213165
step: 1050, loss: 0.15490563213825226
step: 1060, loss: 0.04584331810474396
step: 1070, loss: 0.032596930861473083
epoch 3: dev_f1=0.9313113291703836, f1=0.9307107733571749, best_f1=0.9307107733571749
step: 0, loss: 0.07639740407466888
step: 10, loss: 0.04918656125664711
step: 20, loss: 0.10875502228736877
step: 30, loss: 0.16696669161319733
step: 40, loss: 0.09093520790338516
step: 50, loss: 0.03452213108539581
step: 60, loss: 0.12256132811307907
step: 70, loss: 0.12405966222286224
step: 80, loss: 0.04878717288374901
step: 90, loss: 0.1762496680021286
step: 100, loss: 0.13905099034309387
step: 110, loss: 0.031005114316940308
step: 120, loss: 0.02243899367749691
step: 130, loss: 0.049773674458265305
step: 140, loss: 0.212993323802948
step: 150, loss: 0.05260198190808296
step: 160, loss: 0.09038852900266647
step: 170, loss: 0.1057802066206932
step: 180, loss: 0.12845657765865326
step: 190, loss: 0.1570494920015335
step: 200, loss: 0.10477198660373688
step: 210, loss: 0.08061300963163376
step: 220, loss: 0.03814205527305603
step: 230, loss: 0.06325919181108475
step: 240, loss: 0.02380199171602726
step: 250, loss: 0.0984291359782219
step: 260, loss: 0.07405813038349152
step: 270, loss: 0.12746155261993408
step: 280, loss: 0.1220066174864769
step: 290, loss: 0.16979962587356567
step: 300, loss: 0.09173497557640076
step: 310, loss: 0.04625309631228447
step: 320, loss: 0.02695799618959427
step: 330, loss: 0.16376304626464844
step: 340, loss: 0.10623575001955032
step: 350, loss: 0.19668447971343994
step: 360, loss: 0.12982450425624847
step: 370, loss: 0.12975677847862244
step: 380, loss: 0.24913543462753296
step: 390, loss: 0.06161169335246086
step: 400, loss: 0.12374167144298553
step: 410, loss: 0.09865358471870422
step: 420, loss: 0.02490994520485401
step: 430, loss: 0.12853561341762543
step: 440, loss: 0.17220807075500488
step: 450, loss: 0.05963733047246933
step: 460, loss: 0.09992887079715729
step: 470, loss: 0.06291083991527557
step: 480, loss: 0.15503115952014923
step: 490, loss: 0.19171416759490967
step: 500, loss: 0.06107610464096069
step: 510, loss: 0.15158820152282715
step: 520, loss: 0.21621248126029968
step: 530, loss: 0.06872430443763733
step: 540, loss: 0.07242684811353683
step: 550, loss: 0.042894598096609116
step: 560, loss: 0.11510645598173141
step: 570, loss: 0.14455276727676392
step: 580, loss: 0.07894343137741089
step: 590, loss: 0.1668614000082016
step: 600, loss: 0.121220164000988
step: 610, loss: 0.11803033202886581
step: 620, loss: 0.1326155662536621
step: 630, loss: 0.1791207641363144
step: 640, loss: 0.08949440717697144
step: 650, loss: 0.08700771629810333
step: 660, loss: 0.06332888454198837
step: 670, loss: 0.02036086842417717
step: 680, loss: 0.12529736757278442
step: 690, loss: 0.11439304798841476
step: 700, loss: 0.10798747837543488
step: 710, loss: 0.10675987601280212
step: 720, loss: 0.051602158695459366
step: 730, loss: 0.17107777297496796
step: 740, loss: 0.09528949111700058
step: 750, loss: 0.10975942760705948
step: 760, loss: 0.0421348474919796
step: 770, loss: 0.11083631962537766
step: 780, loss: 0.04955295845866203
step: 790, loss: 0.1106823980808258
step: 800, loss: 0.1672469675540924
step: 810, loss: 0.05966506525874138
step: 820, loss: 0.11344900727272034
step: 830, loss: 0.07678480446338654
step: 840, loss: 0.04613819718360901
step: 850, loss: 0.15271207690238953
step: 860, loss: 0.05755548179149628
step: 870, loss: 0.09100386500358582
step: 880, loss: 0.24281051754951477
step: 890, loss: 0.4306427836418152
step: 900, loss: 0.14901171624660492
step: 910, loss: 0.11007475107908249
step: 920, loss: 0.11708200722932816
step: 930, loss: 0.07261771708726883
step: 940, loss: 0.0887453630566597
step: 950, loss: 0.116390660405159
step: 960, loss: 0.07383834570646286
step: 970, loss: 0.04581329971551895
step: 980, loss: 0.03697254881262779
step: 990, loss: 0.3287446200847626
step: 1000, loss: 0.10221616178750992
step: 1010, loss: 0.3461986780166626
step: 1020, loss: 0.08585777878761292
step: 1030, loss: 0.04397064447402954
step: 1040, loss: 0.05949626863002777
step: 1050, loss: 0.12394877523183823
step: 1060, loss: 0.17656083405017853
step: 1070, loss: 0.10534579306840897
epoch 4: dev_f1=0.9278445883441258, f1=0.9274156264447527, best_f1=0.9307107733571749
step: 0, loss: 0.0917009636759758
step: 10, loss: 0.15236008167266846
step: 20, loss: 0.05542963370680809
step: 30, loss: 0.032585132867097855
step: 40, loss: 0.09490150213241577
step: 50, loss: 0.08393442630767822
step: 60, loss: 0.09516098350286484
step: 70, loss: 0.1494322568178177
step: 80, loss: 0.105158232152462
step: 90, loss: 0.04918646439909935
step: 100, loss: 0.05887729302048683
step: 110, loss: 0.10980673879384995
step: 120, loss: 0.07482775300741196
step: 130, loss: 0.17709732055664062
step: 140, loss: 0.05067683756351471
step: 150, loss: 0.18348143994808197
step: 160, loss: 0.0421779528260231
step: 170, loss: 0.023193366825580597
step: 180, loss: 0.056348156183958054
step: 190, loss: 0.08366261422634125
step: 200, loss: 0.16332609951496124
step: 210, loss: 0.07537880539894104
step: 220, loss: 0.042569998651742935
step: 230, loss: 0.08011531829833984
step: 240, loss: 0.1480204313993454
step: 250, loss: 0.14947457611560822
step: 260, loss: 0.08126074075698853
step: 270, loss: 0.07350147515535355
step: 280, loss: 0.07499849051237106
step: 290, loss: 0.11364404112100601
step: 300, loss: 0.10629241913557053
step: 310, loss: 0.11308538168668747
step: 320, loss: 0.057462215423583984
step: 330, loss: 0.061102546751499176
step: 340, loss: 0.10535857826471329
step: 350, loss: 0.03435264155268669
step: 360, loss: 0.14073652029037476
step: 370, loss: 0.10006343573331833
step: 380, loss: 0.0924958810210228
step: 390, loss: 0.2458372712135315
step: 400, loss: 0.027821194380521774
step: 410, loss: 0.013407444581389427
step: 420, loss: 0.0782942920923233
step: 430, loss: 0.1235428899526596
step: 440, loss: 0.03381401672959328
step: 450, loss: 0.08392393589019775
step: 460, loss: 0.160777747631073
step: 470, loss: 0.04339037090539932
step: 480, loss: 0.08505610376596451
step: 490, loss: 0.028550785034894943
step: 500, loss: 0.14055678248405457
step: 510, loss: 0.15587060153484344
step: 520, loss: 0.22258999943733215
step: 530, loss: 0.10159152746200562
step: 540, loss: 0.0695619210600853
step: 550, loss: 0.09619387239217758
step: 560, loss: 0.11578340083360672
step: 570, loss: 0.18040478229522705
step: 580, loss: 0.11911589652299881
step: 590, loss: 0.06446202099323273
step: 600, loss: 0.10744871944189072
step: 610, loss: 0.20610712468624115
step: 620, loss: 0.02657104842364788
step: 630, loss: 0.05772372707724571
step: 640, loss: 0.12522749602794647
step: 650, loss: 0.10142353922128677
step: 660, loss: 0.09933257848024368
step: 670, loss: 0.06397069245576859
step: 680, loss: 0.11805760860443115
step: 690, loss: 0.11094065010547638
step: 700, loss: 0.04655041918158531
step: 710, loss: 0.1417446881532669
step: 720, loss: 0.07195039838552475
step: 730, loss: 0.08102796971797943
step: 740, loss: 0.06714805215597153
step: 750, loss: 0.06395983695983887
step: 760, loss: 0.020919322967529297
step: 770, loss: 0.09464918822050095
step: 780, loss: 0.06057801842689514
step: 790, loss: 0.02708304673433304
step: 800, loss: 0.08394896984100342
step: 810, loss: 0.030870581045746803
step: 820, loss: 0.11012355238199234
step: 830, loss: 0.09722602367401123
step: 840, loss: 0.0759391039609909
step: 850, loss: 0.07444322109222412
step: 860, loss: 0.17815981805324554
step: 870, loss: 0.07762071490287781
step: 880, loss: 0.04540940001606941
step: 890, loss: 0.04818711429834366
step: 900, loss: 0.1694013923406601
step: 910, loss: 0.10836378484964371
step: 920, loss: 0.04436575621366501
step: 930, loss: 0.0786387175321579
step: 940, loss: 0.0892423689365387
step: 950, loss: 0.044771019369363785
step: 960, loss: 0.06103167682886124
step: 970, loss: 0.047561805695295334
step: 980, loss: 0.015493432991206646
step: 990, loss: 0.10439310222864151
step: 1000, loss: 0.09411916136741638
step: 1010, loss: 0.11781555414199829
step: 1020, loss: 0.14778466522693634
step: 1030, loss: 0.09602786600589752
step: 1040, loss: 0.14179272949695587
step: 1050, loss: 0.06652109324932098
step: 1060, loss: 0.17352870106697083
step: 1070, loss: 0.016152651980519295
epoch 5: dev_f1=0.9212344541685858, f1=0.9174311926605505, best_f1=0.9307107733571749
step: 0, loss: 0.16341762244701385
step: 10, loss: 0.0578363835811615
step: 20, loss: 0.10555403679609299
step: 30, loss: 0.05976774916052818
step: 40, loss: 0.03988991677761078
step: 50, loss: 0.041947416961193085
step: 60, loss: 0.08638928085565567
step: 70, loss: 0.08354202657938004
step: 80, loss: 0.06539951264858246
step: 90, loss: 0.0691860243678093
step: 100, loss: 0.07742627710103989
step: 110, loss: 0.03528657928109169
step: 120, loss: 0.05678543820977211
step: 130, loss: 0.08614234626293182
step: 140, loss: 0.14869457483291626
step: 150, loss: 0.039867840707302094
step: 160, loss: 0.08555718511343002
step: 170, loss: 0.10337880998849869
step: 180, loss: 0.14896532893180847
step: 190, loss: 0.0783994197845459
step: 200, loss: 0.10629241168498993
step: 210, loss: 0.1405254751443863
step: 220, loss: 0.061749476939439774
step: 230, loss: 0.25818246603012085
step: 240, loss: 0.016288749873638153
step: 250, loss: 0.14984749257564545
step: 260, loss: 0.11951790750026703
step: 270, loss: 0.09938769787549973
step: 280, loss: 0.05109768360853195
step: 290, loss: 0.1035933569073677
step: 300, loss: 0.04617294296622276
step: 310, loss: 0.08049716800451279
step: 320, loss: 0.05877748504281044
step: 330, loss: 0.029365571215748787
step: 340, loss: 0.08573049306869507
step: 350, loss: 0.08994349092245102
step: 360, loss: 0.13600878417491913
step: 370, loss: 0.0237815510481596
step: 380, loss: 0.14498387277126312
step: 390, loss: 0.166300967335701
step: 400, loss: 0.12112430483102798
step: 410, loss: 0.04087275639176369
step: 420, loss: 0.05003118887543678
step: 430, loss: 0.10225862264633179
step: 440, loss: 0.18642175197601318
step: 450, loss: 0.04018845036625862
step: 460, loss: 0.01433435920625925
step: 470, loss: 0.03369671106338501
step: 480, loss: 0.16570143401622772
step: 490, loss: 0.04381171241402626
step: 500, loss: 0.11908505111932755
step: 510, loss: 0.11127901822328568
step: 520, loss: 0.0870097428560257
step: 530, loss: 0.11231131851673126
step: 540, loss: 0.12546107172966003
step: 550, loss: 0.06026388332247734
step: 560, loss: 0.17307955026626587
step: 570, loss: 0.08113684505224228
step: 580, loss: 0.11998191475868225
step: 590, loss: 0.13935472071170807
step: 600, loss: 0.1033482477068901
step: 610, loss: 0.20552939176559448
step: 620, loss: 0.019469698891043663
step: 630, loss: 0.05525388568639755
step: 640, loss: 0.029344353824853897
step: 650, loss: 0.09528196603059769
step: 660, loss: 0.10360473394393921
step: 670, loss: 0.03268890455365181
step: 680, loss: 0.027798078954219818
step: 690, loss: 0.08198931813240051
step: 700, loss: 0.03280458599328995
step: 710, loss: 0.002904229098930955
step: 720, loss: 0.05261339992284775
step: 730, loss: 0.12397660315036774
step: 740, loss: 0.18317019939422607
step: 750, loss: 0.06899572908878326
step: 760, loss: 0.1963007003068924
step: 770, loss: 0.03039747104048729
step: 780, loss: 0.009937809780240059
step: 790, loss: 0.2931205630302429
step: 800, loss: 0.09678276628255844
step: 810, loss: 0.1549634039402008
step: 820, loss: 0.1906662881374359
step: 830, loss: 0.10417868196964264
step: 840, loss: 0.10275857150554657
step: 850, loss: 0.11221518367528915
step: 860, loss: 0.027396295219659805
step: 870, loss: 0.015875615179538727
step: 880, loss: 0.019825972616672516
step: 890, loss: 0.11386049538850784
step: 900, loss: 0.07619066536426544
step: 910, loss: 0.14826330542564392
step: 920, loss: 0.13059589266777039
step: 930, loss: 0.09802141785621643
step: 940, loss: 0.1474219560623169
step: 950, loss: 0.08445845544338226
step: 960, loss: 0.004758837167173624
step: 970, loss: 0.10387203842401505
step: 980, loss: 0.07405050098896027
step: 990, loss: 0.0587826743721962
step: 1000, loss: 0.15805462002754211
step: 1010, loss: 0.07926914840936661
step: 1020, loss: 0.0995510146021843
step: 1030, loss: 0.05784834176301956
step: 1040, loss: 0.13567645847797394
step: 1050, loss: 0.08134223520755768
step: 1060, loss: 0.04885828495025635
step: 1070, loss: 0.13426733016967773
epoch 6: dev_f1=0.9264504339881224, f1=0.9267182521620392, best_f1=0.9307107733571749
step: 0, loss: 0.02101157419383526
step: 10, loss: 0.04018717259168625
step: 20, loss: 0.09115181118249893
step: 30, loss: 0.11508273333311081
step: 40, loss: 0.09697362780570984
step: 50, loss: 0.030667854472994804
step: 60, loss: 0.15985599160194397
step: 70, loss: 0.22542034089565277
step: 80, loss: 0.022028837352991104
step: 90, loss: 0.06567925959825516
step: 100, loss: 0.09942024946212769
step: 110, loss: 0.019237743690609932
step: 120, loss: 0.0244792178273201
step: 130, loss: 0.12498428672552109
step: 140, loss: 0.35834044218063354
step: 150, loss: 0.033984120935201645
step: 160, loss: 0.01726555824279785
step: 170, loss: 0.12325432896614075
step: 180, loss: 0.15450288355350494
step: 190, loss: 0.08306679129600525
step: 200, loss: 0.06146703287959099
step: 210, loss: 0.08678983896970749
step: 220, loss: 0.04434807226061821
step: 230, loss: 0.05556735768914223
step: 240, loss: 0.05018053948879242
step: 250, loss: 0.014408428221940994
step: 260, loss: 0.056293755769729614
step: 270, loss: 0.12387273460626602
step: 280, loss: 0.19630871713161469
step: 290, loss: 0.09922775626182556
step: 300, loss: 0.10044007003307343
step: 310, loss: 0.21913817524909973
step: 320, loss: 0.12374607473611832
step: 330, loss: 0.06310674548149109
step: 340, loss: 0.03816559165716171
step: 350, loss: 0.20456160604953766
step: 360, loss: 0.07831939309835434
step: 370, loss: 0.032655056565999985
step: 380, loss: 0.10577140003442764
step: 390, loss: 0.01268681325018406
step: 400, loss: 0.1754162460565567
step: 410, loss: 0.1507059633731842
step: 420, loss: 0.04358451068401337
step: 430, loss: 0.07190313190221786
step: 440, loss: 0.10841101408004761
step: 450, loss: 0.09220534563064575
step: 460, loss: 0.13950173556804657
step: 470, loss: 0.08186596632003784
step: 480, loss: 0.08026526868343353
step: 490, loss: 0.07958907634019852
step: 500, loss: 0.05405821278691292
step: 510, loss: 0.10199110954999924
step: 520, loss: 0.06623762845993042
step: 530, loss: 0.014386970549821854
step: 540, loss: 0.12845557928085327
step: 550, loss: 0.21860210597515106
step: 560, loss: 0.028898393735289574
step: 570, loss: 0.0548647865653038
step: 580, loss: 0.22215536236763
step: 590, loss: 0.0369969867169857
step: 600, loss: 0.23142090439796448
step: 610, loss: 0.047699376940727234
step: 620, loss: 0.09500140696763992
step: 630, loss: 0.04149242863059044
step: 640, loss: 0.016016973182559013
step: 650, loss: 0.08045089244842529
step: 660, loss: 0.03824257850646973
step: 670, loss: 0.04374959319829941
step: 680, loss: 0.1084364727139473
step: 690, loss: 0.012725246138870716
step: 700, loss: 0.07062983512878418
step: 710, loss: 0.17286565899848938
step: 720, loss: 0.22437092661857605
step: 730, loss: 0.17790290713310242
step: 740, loss: 0.08294045925140381
step: 750, loss: 0.09741363674402237
step: 760, loss: 0.09797597676515579
step: 770, loss: 0.07922275364398956
step: 780, loss: 0.05642670392990112
step: 790, loss: 0.0746573805809021
step: 800, loss: 0.17768968641757965
step: 810, loss: 0.2732929587364197
step: 820, loss: 0.15058812499046326
step: 830, loss: 0.04915742948651314
step: 840, loss: 0.04348794370889664
step: 850, loss: 0.05935414135456085
step: 860, loss: 0.03296611085534096
step: 870, loss: 0.027237141504883766
step: 880, loss: 0.16772158443927765
step: 890, loss: 0.05371125042438507
step: 900, loss: 0.11671273410320282
step: 910, loss: 0.08283986151218414
step: 920, loss: 0.1102650836110115
step: 930, loss: 0.039192307740449905
step: 940, loss: 0.11338260024785995
step: 950, loss: 0.07288229465484619
step: 960, loss: 0.09035550057888031
step: 970, loss: 0.021809186786413193
step: 980, loss: 0.17317868769168854
step: 990, loss: 0.07729291915893555
step: 1000, loss: 0.08970039337873459
step: 1010, loss: 0.0380621962249279
step: 1020, loss: 0.11470478028059006
step: 1030, loss: 0.038047678768634796
step: 1040, loss: 0.0836993157863617
step: 1050, loss: 0.06939500570297241
step: 1060, loss: 0.01304663997143507
step: 1070, loss: 0.05194257199764252
epoch 7: dev_f1=0.9329685362517101, f1=0.9332121762835075, best_f1=0.9332121762835075
step: 0, loss: 0.05565332993865013
step: 10, loss: 0.016017891466617584
step: 20, loss: 0.12667126953601837
step: 30, loss: 0.05573617294430733
step: 40, loss: 0.0467640645802021
step: 50, loss: 0.055943604558706284
step: 60, loss: 0.0743255615234375
step: 70, loss: 0.013766408897936344
step: 80, loss: 0.13505080342292786
step: 90, loss: 0.11435690522193909
step: 100, loss: 0.08159887790679932
step: 110, loss: 0.015314007177948952
step: 120, loss: 0.010898331180214882
step: 130, loss: 0.062184207141399384
step: 140, loss: 0.10531933605670929
step: 150, loss: 0.05775519832968712
step: 160, loss: 0.05698166415095329
step: 170, loss: 0.08183379471302032
step: 180, loss: 0.07237335294485092
step: 190, loss: 0.09780916571617126
step: 200, loss: 0.13109919428825378
step: 210, loss: 0.11280176043510437
step: 220, loss: 0.07145655155181885
step: 230, loss: 0.07405336946249008
step: 240, loss: 0.05470200255513191
step: 250, loss: 0.0912567526102066
step: 260, loss: 0.07670243084430695
step: 270, loss: 0.07019951194524765
step: 280, loss: 0.09843789041042328
step: 290, loss: 0.11326028406620026
step: 300, loss: 0.09817146509885788
step: 310, loss: 0.10634662955999374
step: 320, loss: 0.04624626040458679
step: 330, loss: 0.023185765370726585
step: 340, loss: 0.05318755656480789
step: 350, loss: 0.07886252552270889
step: 360, loss: 0.04245220124721527
step: 370, loss: 0.051841143518686295
step: 380, loss: 0.06346689909696579
step: 390, loss: 0.053357988595962524
step: 400, loss: 0.02448008581995964
step: 410, loss: 0.028261728584766388
step: 420, loss: 0.11377470940351486
step: 430, loss: 0.10227679461240768
step: 440, loss: 0.09179754555225372
step: 450, loss: 0.2038145661354065
step: 460, loss: 0.25438088178634644
step: 470, loss: 0.1500501036643982
step: 480, loss: 0.21129263937473297
step: 490, loss: 0.05272969603538513
step: 500, loss: 0.0475410521030426
step: 510, loss: 0.17400220036506653
step: 520, loss: 0.05083012580871582
step: 530, loss: 0.07123403996229172
step: 540, loss: 0.1033637598156929
step: 550, loss: 0.11747132986783981
step: 560, loss: 0.08098597824573517
step: 570, loss: 0.04387808218598366
step: 580, loss: 0.05716697499155998
step: 590, loss: 0.09017334878444672
step: 600, loss: 0.16195528209209442
step: 610, loss: 0.10943812131881714
step: 620, loss: 0.07092151790857315
step: 630, loss: 0.06710721552371979
step: 640, loss: 0.12903816998004913
step: 650, loss: 0.07591242343187332
step: 660, loss: 0.024932047352194786
step: 670, loss: 0.11483947932720184
step: 680, loss: 0.036372069269418716
step: 690, loss: 0.19425439834594727
step: 700, loss: 0.21644970774650574
step: 710, loss: 0.08825864642858505
step: 720, loss: 0.032796818763017654
step: 730, loss: 0.027152840048074722
step: 740, loss: 0.05005008727312088
step: 750, loss: 0.08028794825077057
step: 760, loss: 0.011494521982967854
step: 770, loss: 0.09992340952157974
step: 780, loss: 0.08033479005098343
step: 790, loss: 0.06452114135026932
step: 800, loss: 0.04081064835190773
step: 810, loss: 0.11463433504104614
step: 820, loss: 0.04203124716877937
step: 830, loss: 0.07130985707044601
step: 840, loss: 0.0019046313827857375
step: 850, loss: 0.2098686695098877
step: 860, loss: 0.05044078454375267
step: 870, loss: 0.04887880012392998
step: 880, loss: 0.11838163435459137
step: 890, loss: 0.054242998361587524
step: 900, loss: 0.046016570180654526
step: 910, loss: 0.09292010962963104
step: 920, loss: 0.0061983163468539715
step: 930, loss: 0.05384267494082451
step: 940, loss: 0.04952828958630562
step: 950, loss: 0.08916028589010239
step: 960, loss: 0.04474284499883652
step: 970, loss: 0.11788808554410934
step: 980, loss: 0.03629392758011818
step: 990, loss: 0.06563175469636917
step: 1000, loss: 0.06296105682849884
step: 1010, loss: 0.3193424940109253
step: 1020, loss: 0.06460203230381012
step: 1030, loss: 0.06063767895102501
step: 1040, loss: 0.12000738084316254
step: 1050, loss: 0.04758581519126892
step: 1060, loss: 0.02542223036289215
step: 1070, loss: 0.07997550070285797
epoch 8: dev_f1=0.9250814332247558, f1=0.9251510925151093, best_f1=0.9332121762835075
step: 0, loss: 3.355505396029912e-05
step: 10, loss: 0.0427616611123085
step: 20, loss: 0.08565553277730942
step: 30, loss: 0.019037745893001556
step: 40, loss: 0.08337965607643127
step: 50, loss: 0.007114338222891092
step: 60, loss: 0.057988300919532776
step: 70, loss: 0.021001990884542465
step: 80, loss: 0.12545928359031677
step: 90, loss: 0.07301509380340576
step: 100, loss: 0.0716133564710617
step: 110, loss: 0.025315014645457268
step: 120, loss: 0.051327165216207504
step: 130, loss: 0.127129927277565
step: 140, loss: 0.08618597686290741
step: 150, loss: 0.00015466599143110216
step: 160, loss: 0.19679579138755798
step: 170, loss: 0.04122774675488472
step: 180, loss: 0.11149632930755615
step: 190, loss: 0.05247575789690018
step: 200, loss: 0.09765486419200897
step: 210, loss: 0.07978594303131104
step: 220, loss: 0.10318658500909805
step: 230, loss: 0.05438443273305893
step: 240, loss: 0.12087760120630264
step: 250, loss: 0.0859961286187172
step: 260, loss: 0.08325652778148651
step: 270, loss: 0.048935338854789734
step: 280, loss: 0.18347948789596558
step: 290, loss: 0.11880926042795181
step: 300, loss: 0.12619762122631073
step: 310, loss: 0.043598417192697525
step: 320, loss: 0.10795579850673676
step: 330, loss: 0.11407619714736938
step: 340, loss: 0.025606483221054077
step: 350, loss: 0.043563082814216614
step: 360, loss: 0.16083547472953796
step: 370, loss: 0.017919745296239853
step: 380, loss: 0.10866346955299377
step: 390, loss: 0.08933128416538239
step: 400, loss: 0.03731180727481842
step: 410, loss: 0.05780029296875
step: 420, loss: 0.035464197397232056
step: 430, loss: 0.13915185630321503
step: 440, loss: 0.014479147270321846
step: 450, loss: 0.10111309587955475
step: 460, loss: 0.13049611449241638
step: 470, loss: 0.03197631612420082
step: 480, loss: 0.12840360403060913
step: 490, loss: 0.046562228351831436
step: 500, loss: 0.07269845902919769
step: 510, loss: 0.09390176832675934
step: 520, loss: 0.0635669082403183
step: 530, loss: 0.05435262620449066
step: 540, loss: 0.07121318578720093
step: 550, loss: 0.03331558406352997
step: 560, loss: 0.028597306460142136
step: 570, loss: 0.05345209687948227
step: 580, loss: 0.02703401818871498
step: 590, loss: 0.02921377681195736
step: 600, loss: 0.06492222845554352
step: 610, loss: 0.09101691097021103
step: 620, loss: 0.10751530528068542
step: 630, loss: 0.04705590009689331
step: 640, loss: 0.05647911876440048
step: 650, loss: 0.05746401473879814
step: 660, loss: 0.0965387374162674
step: 670, loss: 0.11431984603404999
step: 680, loss: 0.04942356422543526
step: 690, loss: 0.014528093859553337
step: 700, loss: 0.05945625156164169
step: 710, loss: 0.04091696813702583
step: 720, loss: 0.11425924301147461
step: 730, loss: 0.07691740244626999
step: 740, loss: 0.2096989005804062
step: 750, loss: 0.08613947778940201
step: 760, loss: 0.12370600551366806
step: 770, loss: 0.1460726112127304
step: 780, loss: 0.0324559323489666
step: 790, loss: 0.03395599126815796
step: 800, loss: 0.07445349544286728
step: 810, loss: 0.04306131228804588
step: 820, loss: 0.03142589330673218
step: 830, loss: 0.05545293539762497
step: 840, loss: 0.05374181643128395
step: 850, loss: 0.14563289284706116
step: 860, loss: 0.05969337746500969
step: 870, loss: 0.07036207616329193
step: 880, loss: 0.017838630825281143
step: 890, loss: 0.05167524516582489
step: 900, loss: 0.06741176545619965
step: 910, loss: 0.04133455455303192
step: 920, loss: 0.08038529008626938
step: 930, loss: 0.23347313702106476
step: 940, loss: 0.15067507326602936
step: 950, loss: 0.07405664771795273
step: 960, loss: 0.07357360422611237
step: 970, loss: 0.14559102058410645
step: 980, loss: 0.1154240295290947
step: 990, loss: 0.1463584303855896
step: 1000, loss: 0.11835665255784988
step: 1010, loss: 0.09842262417078018
step: 1020, loss: 0.03549753129482269
step: 1030, loss: 0.0417916476726532
step: 1040, loss: 0.058119963854551315
step: 1050, loss: 0.11012794822454453
step: 1060, loss: 0.22428090870380402
step: 1070, loss: 0.0922321006655693
epoch 9: dev_f1=0.9239981575310916, f1=0.9224376731301939, best_f1=0.9332121762835075
step: 0, loss: 0.04677455127239227
step: 10, loss: 0.10464128851890564
step: 20, loss: 0.14383594691753387
step: 30, loss: 0.015350749716162682
step: 40, loss: 0.022574659436941147
step: 50, loss: 0.07495638728141785
step: 60, loss: 0.07203833758831024
step: 70, loss: 0.05632607638835907
step: 80, loss: 0.02241751179099083
step: 90, loss: 0.09024152159690857
step: 100, loss: 0.059573814272880554
step: 110, loss: 0.08026675879955292
step: 120, loss: 0.0829010009765625
step: 130, loss: 0.020103819668293
step: 140, loss: 0.04104528948664665
step: 150, loss: 0.049924734979867935
step: 160, loss: 0.00017781158385332674
step: 170, loss: 0.15012256801128387
step: 180, loss: 0.0406513437628746
step: 190, loss: 0.04856396093964577
step: 200, loss: 0.2328040450811386
step: 210, loss: 0.0980389192700386
step: 220, loss: 0.11212559789419174
step: 230, loss: 0.11539808660745621
step: 240, loss: 0.14344239234924316
step: 250, loss: 0.021740052849054337
step: 260, loss: 0.022757580503821373
step: 270, loss: 0.0913129597902298
step: 280, loss: 0.08770547807216644
step: 290, loss: 0.12270473688840866
step: 300, loss: 0.14146263897418976
step: 310, loss: 0.1426737904548645
step: 320, loss: 0.16571515798568726
step: 330, loss: 0.0533897839486599
step: 340, loss: 0.04648096114397049
step: 350, loss: 0.12144669145345688
step: 360, loss: 0.10151896625757217
step: 370, loss: 0.03849612548947334
step: 380, loss: 0.04894200339913368
step: 390, loss: 0.07872042804956436
step: 400, loss: 0.06000540032982826
step: 410, loss: 0.027590319514274597
step: 420, loss: 0.03834665194153786
step: 430, loss: 0.20883314311504364
step: 440, loss: 0.04357299581170082
step: 450, loss: 0.056400369852781296
step: 460, loss: 0.046267539262771606
step: 470, loss: 0.06916119158267975
step: 480, loss: 0.03741350769996643
step: 490, loss: 0.05375196412205696
step: 500, loss: 0.009228355251252651
step: 510, loss: 0.06692994385957718
step: 520, loss: 0.07680671662092209
step: 530, loss: 0.0693868100643158
step: 540, loss: 0.1370381861925125
step: 550, loss: 0.028755074366927147
step: 560, loss: 0.02700200304389
step: 570, loss: 0.09251957386732101
step: 580, loss: 0.14472897350788116
step: 590, loss: 0.03001417964696884
step: 600, loss: 0.047567300498485565
step: 610, loss: 0.10809576511383057
step: 620, loss: 0.061007797718048096
step: 630, loss: 0.09734189510345459
step: 640, loss: 0.09381374716758728
step: 650, loss: 0.11020012199878693
step: 660, loss: 0.06174629554152489
step: 670, loss: 0.07062018662691116
step: 680, loss: 0.08220542967319489
step: 690, loss: 0.018432535231113434
step: 700, loss: 0.04116196930408478
step: 710, loss: 0.06039122864603996
step: 720, loss: 0.08067987859249115
step: 730, loss: 0.057719532400369644
step: 740, loss: 0.1575612723827362
step: 750, loss: 0.10462932288646698
step: 760, loss: 0.0650743767619133
step: 770, loss: 0.06519445031881332
step: 780, loss: 0.05726759508252144
step: 790, loss: 0.10765590518712997
step: 800, loss: 0.08641112595796585
step: 810, loss: 0.13634859025478363
step: 820, loss: 0.07009641826152802
step: 830, loss: 0.06783644109964371
step: 840, loss: 0.07960211485624313
step: 850, loss: 0.14132308959960938
step: 860, loss: 0.10944347828626633
step: 870, loss: 0.10491876304149628
step: 880, loss: 0.06339079141616821
step: 890, loss: 0.04799315705895424
step: 900, loss: 0.09766606241464615
step: 910, loss: 0.11450906097888947
step: 920, loss: 0.0867738127708435
step: 930, loss: 0.05074574425816536
step: 940, loss: 0.06984739005565643
step: 950, loss: 0.04234180226922035
step: 960, loss: 0.14922572672367096
step: 970, loss: 0.18963505327701569
step: 980, loss: 0.03248746693134308
step: 990, loss: 0.03832994028925896
step: 1000, loss: 0.031122665852308273
step: 1010, loss: 0.05696839466691017
step: 1020, loss: 0.04679201543331146
step: 1030, loss: 0.09365493804216385
step: 1040, loss: 0.05329449474811554
step: 1050, loss: 0.16517972946166992
step: 1060, loss: 0.05468403548002243
step: 1070, loss: 0.04273463785648346
epoch 10: dev_f1=0.9276714885674288, f1=0.9310344827586207, best_f1=0.9332121762835075
step: 0, loss: 0.06896907836198807
step: 10, loss: 0.08176951855421066
step: 20, loss: 0.06426258385181427
step: 30, loss: 0.10579751431941986
step: 40, loss: 0.1247696802020073
step: 50, loss: 0.12239716202020645
step: 60, loss: 0.032553285360336304
step: 70, loss: 0.14377880096435547
step: 80, loss: 0.04227769002318382
step: 90, loss: 0.07029205560684204
step: 100, loss: 0.1314355581998825
step: 110, loss: 0.04895307123661041
step: 120, loss: 0.03540783002972603
step: 130, loss: 0.17719542980194092
step: 140, loss: 0.06015531346201897
step: 150, loss: 0.0013449707766994834
step: 160, loss: 0.03623724356293678
step: 170, loss: 0.016919473186135292
step: 180, loss: 0.04193072393536568
step: 190, loss: 0.0669931024312973
step: 200, loss: 0.11724795401096344
step: 210, loss: 0.06624495983123779
step: 220, loss: 0.02363492175936699
step: 230, loss: 0.01676873117685318
step: 240, loss: 0.04646030813455582
step: 250, loss: 0.03268308937549591
step: 260, loss: 0.07832062244415283
step: 270, loss: 0.09206823259592056
step: 280, loss: 0.05260147899389267
step: 290, loss: 0.08397926390171051
step: 300, loss: 0.05153437331318855
step: 310, loss: 0.10962497442960739
step: 320, loss: 0.05685465782880783
step: 330, loss: 0.03952082619071007
step: 340, loss: 0.022028891369700432
step: 350, loss: 0.00016100911307148635
step: 360, loss: 0.05714727193117142
step: 370, loss: 0.18490423262119293
step: 380, loss: 0.02718593366444111
step: 390, loss: 0.08981580287218094
step: 400, loss: 0.004273566883057356
step: 410, loss: 0.0942884087562561
step: 420, loss: 0.03912349417805672
step: 430, loss: 0.04073872044682503
step: 440, loss: 0.05961819738149643
step: 450, loss: 0.08287309855222702
step: 460, loss: 0.06821668893098831
step: 470, loss: 0.20605066418647766
step: 480, loss: 0.029098879545927048
step: 490, loss: 0.07265782356262207
step: 500, loss: 0.08144737780094147
step: 510, loss: 0.11987175047397614
step: 520, loss: 0.0478370301425457
step: 530, loss: 0.04661835357546806
step: 540, loss: 0.06757235527038574
step: 550, loss: 0.0926436185836792
step: 560, loss: 0.20772278308868408
step: 570, loss: 0.10257484763860703
step: 580, loss: 0.07188114523887634
step: 590, loss: 0.20929883420467377
step: 600, loss: 0.16326068341732025
step: 610, loss: 0.016254909336566925
step: 620, loss: 0.0063743493519723415
step: 630, loss: 0.02895238995552063
step: 640, loss: 0.14204511046409607
step: 650, loss: 0.06440034508705139
step: 660, loss: 0.0851839929819107
step: 670, loss: 0.042545124888420105
step: 680, loss: 0.05638414993882179
step: 690, loss: 0.05138886347413063
step: 700, loss: 0.13752484321594238
step: 710, loss: 0.01672172173857689
step: 720, loss: 0.09965261071920395
step: 730, loss: 0.01629858836531639
step: 740, loss: 0.04661337286233902
step: 750, loss: 0.14725922048091888
step: 760, loss: 0.14318332076072693
step: 770, loss: 0.1054830327630043
step: 780, loss: 2.7163629056303762e-05
step: 790, loss: 0.14709505438804626
step: 800, loss: 0.07315608859062195
step: 810, loss: 0.03073594719171524
step: 820, loss: 0.12978599965572357
step: 830, loss: 0.06130233779549599
step: 840, loss: 0.04346712306141853
step: 850, loss: 0.05574440211057663
step: 860, loss: 0.05415773391723633
step: 870, loss: 0.08853694796562195
step: 880, loss: 0.033110249787569046
step: 890, loss: 0.010460963472723961
step: 900, loss: 0.1377941071987152
step: 910, loss: 0.13793373107910156
step: 920, loss: 0.05794522538781166
step: 930, loss: 0.0466722771525383
step: 940, loss: 0.021013760939240456
step: 950, loss: 0.07405879348516464
step: 960, loss: 0.014481483958661556
step: 970, loss: 0.15113992989063263
step: 980, loss: 0.17010386288166046
step: 990, loss: 0.059572067111730576
step: 1000, loss: 0.05945834144949913
step: 1010, loss: 0.08622243255376816
step: 1020, loss: 0.10667106509208679
step: 1030, loss: 0.09155413508415222
step: 1040, loss: 0.13243886828422546
step: 1050, loss: 0.07544734328985214
step: 1060, loss: 0.21378985047340393
step: 1070, loss: 0.02064608782529831
epoch 11: dev_f1=0.9223744292237444, f1=0.9268069533394326, best_f1=0.9332121762835075
step: 0, loss: 0.09159953147172928
step: 10, loss: 0.09890351444482803
step: 20, loss: 0.022052690386772156
step: 30, loss: 0.029426883906126022
step: 40, loss: 0.0023579690605401993
step: 50, loss: 0.0641692653298378
step: 60, loss: 0.07162473350763321
step: 70, loss: 0.05193678289651871
step: 80, loss: 0.10256465524435043
step: 90, loss: 0.05905485525727272
step: 100, loss: 0.0487937368452549
step: 110, loss: 0.0890287384390831
step: 120, loss: 0.01559829618781805
step: 130, loss: 0.1446426808834076
step: 140, loss: 0.04552080109715462
step: 150, loss: 0.1307118684053421
step: 160, loss: 0.05975538492202759
step: 170, loss: 0.06279163062572479
step: 180, loss: 0.1165279969573021
step: 190, loss: 0.06832798570394516
step: 200, loss: 0.07551465183496475
step: 210, loss: 0.1670335978269577
step: 220, loss: 0.00907545443624258
step: 230, loss: 0.04022686555981636
step: 240, loss: 0.04577004164457321
step: 250, loss: 0.05330577865242958
step: 260, loss: 0.06953858584165573
step: 270, loss: 0.05065314099192619
step: 280, loss: 0.10613556206226349
step: 290, loss: 0.04268459603190422
step: 300, loss: 0.04664989188313484
step: 310, loss: 0.062477611005306244
step: 320, loss: 0.005157691892236471
step: 330, loss: 0.08401528000831604
step: 340, loss: 0.10732873529195786
step: 350, loss: 0.08346271514892578
step: 360, loss: 0.07200966775417328
step: 370, loss: 0.03134440258145332
step: 380, loss: 0.07869498431682587
step: 390, loss: 0.029870880767703056
step: 400, loss: 0.03573579341173172
step: 410, loss: 0.03951230272650719
step: 420, loss: 0.13483797013759613
step: 430, loss: 0.004502408672124147
step: 440, loss: 0.007275943644344807
step: 450, loss: 0.006508701480925083
step: 460, loss: 0.0316021554172039
step: 470, loss: 0.0812918171286583
step: 480, loss: 0.044763579964637756
step: 490, loss: 0.0038995558861643076
step: 500, loss: 0.050501782447099686
step: 510, loss: 0.08180934935808182
step: 520, loss: 0.10212685912847519
step: 530, loss: 0.08850353956222534
step: 540, loss: 0.04933875799179077
step: 550, loss: 0.05857054889202118
step: 560, loss: 0.016266770660877228
step: 570, loss: 0.088137187063694
step: 580, loss: 0.0801410898566246
step: 590, loss: 0.05084102228283882
step: 600, loss: 0.12460807710886002
step: 610, loss: 0.13807134330272675
step: 620, loss: 0.05836387351155281
step: 630, loss: 0.04985447973012924
step: 640, loss: 0.04459140822291374
step: 650, loss: 0.10434164106845856
step: 660, loss: 0.060755833983421326
step: 670, loss: 0.02319817617535591
step: 680, loss: 0.03199752792716026
step: 690, loss: 0.06679709255695343
step: 700, loss: 0.023844795301556587
step: 710, loss: 0.05980507284402847
step: 720, loss: 0.06291860342025757
step: 730, loss: 0.018906012177467346
step: 740, loss: 0.19453546404838562
step: 750, loss: 0.016221292316913605
step: 760, loss: 0.05085643008351326
step: 770, loss: 0.08936060220003128
step: 780, loss: 0.0618254654109478
step: 790, loss: 0.04186993092298508
step: 800, loss: 0.05747609585523605
step: 810, loss: 0.08906737715005875
step: 820, loss: 0.00036362363607622683
step: 830, loss: 0.11639595776796341
step: 840, loss: 0.06889627873897552
step: 850, loss: 0.020924892276525497
step: 860, loss: 0.06116633117198944
step: 870, loss: 0.04724164679646492
step: 880, loss: 0.23517175018787384
step: 890, loss: 0.05147263780236244
step: 900, loss: 0.04912526533007622
step: 910, loss: 0.08487579971551895
step: 920, loss: 0.07455246150493622
step: 930, loss: 0.03950127214193344
step: 940, loss: 0.028231795877218246
step: 950, loss: 0.009901612065732479
step: 960, loss: 0.08376963436603546
step: 970, loss: 0.055103600025177
step: 980, loss: 0.0765746459364891
step: 990, loss: 0.09082740545272827
step: 1000, loss: 0.06119049713015556
step: 1010, loss: 0.11661709100008011
step: 1020, loss: 0.007929139770567417
step: 1030, loss: 0.03087272308766842
step: 1040, loss: 0.06384274363517761
step: 1050, loss: 0.10254170745611191
step: 1060, loss: 0.0974833145737648
step: 1070, loss: 0.0965287834405899
epoch 12: dev_f1=0.9248501613646842, f1=0.9287037037037037, best_f1=0.9332121762835075
step: 0, loss: 0.04196418449282646
step: 10, loss: 0.11410035192966461
step: 20, loss: 0.02004620060324669
step: 30, loss: 0.004101480823010206
step: 40, loss: 0.0759505033493042
step: 50, loss: 0.002634264761582017
step: 60, loss: 0.046656619757413864
step: 70, loss: 0.05255800485610962
step: 80, loss: 0.04971151798963547
step: 90, loss: 0.06006156653165817
step: 100, loss: 0.14465700089931488
step: 110, loss: 0.04335309937596321
step: 120, loss: 0.10074138641357422
step: 130, loss: 0.08464951813220978
step: 140, loss: 0.05048901215195656
step: 150, loss: 0.054517846554517746
step: 160, loss: 0.06340322643518448
step: 170, loss: 0.03349738568067551
step: 180, loss: 0.07779990136623383
step: 190, loss: 0.014871655963361263
step: 200, loss: 0.07696428894996643
step: 210, loss: 0.05154556781053543
step: 220, loss: 0.144558385014534
step: 230, loss: 0.027380168437957764
step: 240, loss: 0.05104316771030426
step: 250, loss: 0.07006633281707764
step: 260, loss: 0.039423007518053055
step: 270, loss: 0.14920373260974884
step: 280, loss: 0.0912821963429451
step: 290, loss: 0.015010952949523926
step: 300, loss: 0.04127465933561325
step: 310, loss: 0.03900573030114174
step: 320, loss: 0.009520553052425385
step: 330, loss: 0.038256723433732986
step: 340, loss: 0.0807589516043663
step: 350, loss: 0.10952128469944
step: 360, loss: 0.08037929236888885
step: 370, loss: 0.09743935614824295
step: 380, loss: 0.1325731873512268
step: 390, loss: 0.06655512750148773
step: 400, loss: 0.17345544695854187
step: 410, loss: 0.07121450453996658
step: 420, loss: 0.018131520599126816
step: 430, loss: 0.06533586233854294
step: 440, loss: 0.012385854497551918
step: 450, loss: 0.023348959162831306
step: 460, loss: 0.014746613800525665
step: 470, loss: 0.06610522419214249
step: 480, loss: 0.0004304990288801491
step: 490, loss: 0.00025792629458010197
step: 500, loss: 0.028598638251423836
step: 510, loss: 0.04799801856279373
step: 520, loss: 0.033765003085136414
step: 530, loss: 0.09423404186964035
step: 540, loss: 0.018166912719607353
step: 550, loss: 0.04411381483078003
step: 560, loss: 0.016857171431183815
step: 570, loss: 0.001519524259492755
step: 580, loss: 0.03645721450448036
step: 590, loss: 0.05576904118061066
step: 600, loss: 0.16940845549106598
step: 610, loss: 0.015517469495534897
step: 620, loss: 0.0173089150339365
step: 630, loss: 0.019180478528141975
step: 640, loss: 0.06822488456964493
step: 650, loss: 0.02497825399041176
step: 660, loss: 0.08919226378202438
step: 670, loss: 0.07369964569807053
step: 680, loss: 0.07288075983524323
step: 690, loss: 0.029490239918231964
step: 700, loss: 0.11874343454837799
step: 710, loss: 0.026169082149863243
step: 720, loss: 0.05343807116150856
step: 730, loss: 0.0627085417509079
step: 740, loss: 0.023408617824316025
step: 750, loss: 0.00872622337192297
step: 760, loss: 0.03221942484378815
step: 770, loss: 0.027061298489570618
step: 780, loss: 0.021434254944324493
step: 790, loss: 0.022577831521630287
step: 800, loss: 0.026186523959040642
step: 810, loss: 0.013113868422806263
step: 820, loss: 0.09364314377307892
step: 830, loss: 0.04408109933137894
step: 840, loss: 0.03127824515104294
step: 850, loss: 0.026341592893004417
step: 860, loss: 0.0846216231584549
step: 870, loss: 0.043514806777238846
step: 880, loss: 0.056429117918014526
step: 890, loss: 2.2463093046098948e-05
step: 900, loss: 0.003606553189456463
step: 910, loss: 0.06535384804010391
step: 920, loss: 0.03543894737958908
step: 930, loss: 0.04231511428952217
step: 940, loss: 0.00045979375136084855
step: 950, loss: 0.06619088351726532
step: 960, loss: 0.0602864995598793
step: 970, loss: 0.031206728890538216
step: 980, loss: 0.024587273597717285
step: 990, loss: 0.024619750678539276
step: 1000, loss: 0.06720194965600967
step: 1010, loss: 0.09970952570438385
step: 1020, loss: 0.0779883936047554
step: 1030, loss: 0.06024599447846413
step: 1040, loss: 0.012923414818942547
step: 1050, loss: 0.0003454174438957125
step: 1060, loss: 0.030145492404699326
step: 1070, loss: 0.026258066296577454
epoch 13: dev_f1=0.9265116279069768, f1=0.9265116279069768, best_f1=0.9332121762835075
step: 0, loss: 0.03186013922095299
step: 10, loss: 0.0363478846848011
step: 20, loss: 0.0544942244887352
step: 30, loss: 0.06603434681892395
step: 40, loss: 0.017406756058335304
step: 50, loss: 0.08874405175447464
step: 60, loss: 0.03775634616613388
step: 70, loss: 0.04793553054332733
step: 80, loss: 0.016355296596884727
step: 90, loss: 0.1585203856229782
step: 100, loss: 0.013895739801228046
step: 110, loss: 0.08508353680372238
step: 120, loss: 0.02456784062087536
step: 130, loss: 0.06932418048381805
step: 140, loss: 0.00010983889660565183
step: 150, loss: 0.03565884009003639
step: 160, loss: 0.054531268775463104
step: 170, loss: 0.028365276753902435
step: 180, loss: 0.048815540969371796
step: 190, loss: 0.06736382842063904
step: 200, loss: 0.05986114591360092
step: 210, loss: 0.024274060502648354
step: 220, loss: 0.06996095180511475
step: 230, loss: 0.020909734070301056
step: 240, loss: 0.097223199903965
step: 250, loss: 0.07422039657831192
step: 260, loss: 0.08687087893486023
step: 270, loss: 0.034464940428733826
step: 280, loss: 0.09901414066553116
step: 290, loss: 0.11469991505146027
step: 300, loss: 0.08661999553442001
step: 310, loss: 0.09673549234867096
step: 320, loss: 0.06484800577163696
step: 330, loss: 0.04327847808599472
step: 340, loss: 0.07810384780168533
step: 350, loss: 0.0016542846569791436
step: 360, loss: 0.01977572962641716
step: 370, loss: 0.03442643582820892
step: 380, loss: 0.058981962502002716
step: 390, loss: 0.06320151686668396
step: 400, loss: 0.035180382430553436
step: 410, loss: 0.05682649835944176
step: 420, loss: 0.03714544698596001
step: 430, loss: 0.03736388683319092
step: 440, loss: 0.026773756369948387
step: 450, loss: 0.022104250267148018
step: 460, loss: 0.059710513800382614
step: 470, loss: 0.07384870946407318
step: 480, loss: 0.045491207391023636
step: 490, loss: 0.11640221625566483
step: 500, loss: 0.025716450065374374
step: 510, loss: 0.0523751825094223
step: 520, loss: 0.03669285401701927
step: 530, loss: 0.030151309445500374
step: 540, loss: 0.0369257852435112
step: 550, loss: 0.023621518164873123
step: 560, loss: 0.030448809266090393
step: 570, loss: 0.041228871792554855
step: 580, loss: 0.0003897245624102652
step: 590, loss: 0.036830030381679535
step: 600, loss: 0.02033613808453083
step: 610, loss: 0.03990015387535095
step: 620, loss: 0.049886785447597504
step: 630, loss: 0.13371388614177704
step: 640, loss: 0.03125130012631416
step: 650, loss: 0.03082362562417984
step: 660, loss: 0.05799146741628647
step: 670, loss: 0.022992104291915894
step: 680, loss: 0.04471706971526146
step: 690, loss: 0.033467017114162445
step: 700, loss: 0.06378733366727829
step: 710, loss: 0.05713028833270073
step: 720, loss: 0.040161602199077606
step: 730, loss: 0.0022209968883544207
step: 740, loss: 0.11891079694032669
step: 750, loss: 0.0682704821228981
step: 760, loss: 0.062602199614048
step: 770, loss: 0.048517972230911255
step: 780, loss: 0.09183686971664429
step: 790, loss: 0.01808689534664154
step: 800, loss: 0.08264540135860443
step: 810, loss: 0.048754408955574036
step: 820, loss: 0.09792438894510269
step: 830, loss: 0.026862040162086487
step: 840, loss: 0.04600678011775017
step: 850, loss: 0.010397259145975113
step: 860, loss: 0.030974632129073143
step: 870, loss: 0.1088225468993187
step: 880, loss: 0.03198057785630226
step: 890, loss: 0.09775399416685104
step: 900, loss: 0.09681687504053116
step: 910, loss: 0.039716947823762894
step: 920, loss: 0.0536310039460659
step: 930, loss: 0.05778520554304123
step: 940, loss: 0.042234454303979874
step: 950, loss: 0.044947993010282516
step: 960, loss: 0.08949469029903412
step: 970, loss: 0.1462801694869995
step: 980, loss: 0.005985851399600506
step: 990, loss: 0.025275925174355507
step: 1000, loss: 0.01833735965192318
step: 1010, loss: 0.035205379128456116
step: 1020, loss: 0.07632511854171753
step: 1030, loss: 0.026280779391527176
step: 1040, loss: 0.0004119518562220037
step: 1050, loss: 0.0540248304605484
step: 1060, loss: 0.07902093976736069
step: 1070, loss: 0.13637542724609375
epoch 14: dev_f1=0.9279700654817586, f1=0.9260299625468165, best_f1=0.9332121762835075
step: 0, loss: 0.00039725241367705166
step: 10, loss: 0.1006721556186676
step: 20, loss: 0.02265433594584465
step: 30, loss: 0.046084675937891006
step: 40, loss: 0.013849235139787197
step: 50, loss: 0.027248123660683632
step: 60, loss: 0.015704458579421043
step: 70, loss: 0.08928249776363373
step: 80, loss: 0.023707017302513123
step: 90, loss: 7.331114466069266e-05
step: 100, loss: 0.08501191437244415
step: 110, loss: 0.0442817360162735
step: 120, loss: 0.08983498066663742
step: 130, loss: 0.026824451982975006
step: 140, loss: 0.023180846124887466
step: 150, loss: 0.011438554152846336
step: 160, loss: 0.02185322903096676
step: 170, loss: 0.05059230327606201
step: 180, loss: 0.06140455603599548
step: 190, loss: 0.002903532702475786
step: 200, loss: 0.047439634799957275
step: 210, loss: 0.03513023257255554
step: 220, loss: 0.032536331564188004
step: 230, loss: 0.03706682473421097
step: 240, loss: 0.0477762296795845
step: 250, loss: 0.028850138187408447
step: 260, loss: 0.06293720752000809
step: 270, loss: 0.023271340876817703
step: 280, loss: 0.0395200252532959
step: 290, loss: 0.07214272022247314
step: 300, loss: 0.034500956535339355
step: 310, loss: 0.06201475113630295
step: 320, loss: 0.060117609798908234
step: 330, loss: 0.023821840062737465
step: 340, loss: 0.012049300596117973
step: 350, loss: 0.032407328486442566
step: 360, loss: 0.06940807402133942
step: 370, loss: 0.08557106554508209
step: 380, loss: 0.005749672185629606
step: 390, loss: 0.026399485766887665
step: 400, loss: 0.023154912516474724
step: 410, loss: 0.00044250531936995685
step: 420, loss: 0.00603294325992465
step: 430, loss: 0.0011542602442204952
step: 440, loss: 0.009186104871332645
step: 450, loss: 0.045108694583177567
step: 460, loss: 0.03358558937907219
step: 470, loss: 0.05326163396239281
step: 480, loss: 0.04066237062215805
step: 490, loss: 0.010778309777379036
step: 500, loss: 0.018898719921708107
step: 510, loss: 0.08104919642210007
step: 520, loss: 0.017574245110154152
step: 530, loss: 0.0251077339053154
step: 540, loss: 0.0559610016644001
step: 550, loss: 0.025806548073887825
step: 560, loss: 0.13066740334033966
step: 570, loss: 0.11543234437704086
step: 580, loss: 0.07261800020933151
step: 590, loss: 0.059255994856357574
step: 600, loss: 0.03879779204726219
step: 610, loss: 0.021084925159811974
step: 620, loss: 0.04057782515883446
step: 630, loss: 0.03903139382600784
step: 640, loss: 0.04128634184598923
step: 650, loss: 0.0532195121049881
step: 660, loss: 0.034952614456415176
step: 670, loss: 0.07327272742986679
step: 680, loss: 0.08832542598247528
step: 690, loss: 0.012428520247340202
step: 700, loss: 0.05389949306845665
step: 710, loss: 0.039154428988695145
step: 720, loss: 0.08506709337234497
step: 730, loss: 0.02605750598013401
step: 740, loss: 0.07615802437067032
step: 750, loss: 0.07750669866800308
step: 760, loss: 0.2558461129665375
step: 770, loss: 0.06590080261230469
step: 780, loss: 0.0345720537006855
step: 790, loss: 0.034607790410518646
step: 800, loss: 0.10420551151037216
step: 810, loss: 0.0729328915476799
step: 820, loss: 0.04145018756389618
step: 830, loss: 0.0742001086473465
step: 840, loss: 0.01544763520359993
step: 850, loss: 0.09290654212236404
step: 860, loss: 0.055875539779663086
step: 870, loss: 0.08043047785758972
step: 880, loss: 0.05665937811136246
step: 890, loss: 0.10892762988805771
step: 900, loss: 0.0016891343984752893
step: 910, loss: 0.09641232341527939
step: 920, loss: 0.015210109762847424
step: 930, loss: 0.17174775898456573
step: 940, loss: 0.034072332084178925
step: 950, loss: 0.02085581049323082
step: 960, loss: 0.023922521620988846
step: 970, loss: 0.06205788254737854
step: 980, loss: 0.0018108400981873274
step: 990, loss: 0.0051577650010585785
step: 1000, loss: 0.08966771513223648
step: 1010, loss: 0.07957533001899719
step: 1020, loss: 0.0619511716067791
step: 1030, loss: 0.04895423352718353
step: 1040, loss: 0.02678334154188633
step: 1050, loss: 0.022400284186005592
step: 1060, loss: 0.030756652355194092
step: 1070, loss: 0.037620820105075836
epoch 15: dev_f1=0.9262672811059909, f1=0.9293954776188279, best_f1=0.9332121762835075
step: 0, loss: 0.017912503331899643
step: 10, loss: 0.013340887613594532
step: 20, loss: 0.060129303485155106
step: 30, loss: 0.03310355916619301
step: 40, loss: 0.010916727595031261
step: 50, loss: 0.0335896871984005
step: 60, loss: 2.03546787815867e-05
step: 70, loss: 0.051324427127838135
step: 80, loss: 0.041220445185899734
step: 90, loss: 0.009642149321734905
step: 100, loss: 0.07027874141931534
step: 110, loss: 0.04957032576203346
step: 120, loss: 0.06363105028867722
step: 130, loss: 0.017163129523396492
step: 140, loss: 0.07783127576112747
step: 150, loss: 0.06061544269323349
step: 160, loss: 0.10624996572732925
step: 170, loss: 0.051171932369470596
step: 180, loss: 0.011808682233095169
step: 190, loss: 0.029419997707009315
step: 200, loss: 0.04339511692523956
step: 210, loss: 0.004307788331061602
step: 220, loss: 0.03633894398808479
step: 230, loss: 0.166520893573761
step: 240, loss: 0.019055945798754692
step: 250, loss: 0.09044032543897629
step: 260, loss: 2.5003511836985126e-05
step: 270, loss: 0.038119398057460785
step: 280, loss: 0.04552801698446274
step: 290, loss: 0.06085050106048584
step: 300, loss: 0.0604257807135582
step: 310, loss: 0.024364156648516655
step: 320, loss: 0.10182202607393265
step: 330, loss: 0.03742055594921112
step: 340, loss: 0.08576423674821854
step: 350, loss: 0.1084841787815094
step: 360, loss: 0.05153520032763481
step: 370, loss: 0.036348000168800354
step: 380, loss: 0.09146027266979218
step: 390, loss: 0.06900069117546082
step: 400, loss: 0.02762468531727791
step: 410, loss: 0.09214864671230316
step: 420, loss: 0.02756134420633316
step: 430, loss: 0.005225996486842632
step: 440, loss: 0.07165823131799698
step: 450, loss: 0.14416708052158356
step: 460, loss: 0.06968917697668076
step: 470, loss: 0.03569573163986206
step: 480, loss: 0.019223110750317574
step: 490, loss: 0.034806475043296814
step: 500, loss: 0.015773499384522438
step: 510, loss: 0.05584908276796341
step: 520, loss: 0.05890128016471863
step: 530, loss: 0.06663661450147629
step: 540, loss: 0.023015841841697693
step: 550, loss: 0.013879791833460331
step: 560, loss: 0.12798935174942017
step: 570, loss: 0.02665988728404045
step: 580, loss: 0.017918813973665237
step: 590, loss: 0.01887345127761364
step: 600, loss: 0.05087970197200775
step: 610, loss: 0.04824584349989891
step: 620, loss: 0.052353743463754654
step: 630, loss: 0.05379551276564598
step: 640, loss: 0.03320972993969917
step: 650, loss: 0.10091698169708252
step: 660, loss: 0.10443732142448425
step: 670, loss: 0.04146866127848625
step: 680, loss: 0.021889904513955116
step: 690, loss: 0.00020540246623568237
step: 700, loss: 0.03014926053583622
step: 710, loss: 0.021796640008687973
step: 720, loss: 0.020047714933753014
step: 730, loss: 0.039690639823675156
step: 740, loss: 0.032840363681316376
step: 750, loss: 0.04902806133031845
step: 760, loss: 0.12827670574188232
step: 770, loss: 0.054506056010723114
step: 780, loss: 0.06421737372875214
step: 790, loss: 0.04879525303840637
step: 800, loss: 0.009502889588475227
step: 810, loss: 0.04473549500107765
step: 820, loss: 0.10887707024812698
step: 830, loss: 0.050763245671987534
step: 840, loss: 0.07262220978736877
step: 850, loss: 0.0493009053170681
step: 860, loss: 0.029172904789447784
step: 870, loss: 0.022953156381845474
step: 880, loss: 0.031242024153470993
step: 890, loss: 0.05444828048348427
step: 900, loss: 0.0023152369540184736
step: 910, loss: 0.08876080065965652
step: 920, loss: 0.08814002573490143
step: 930, loss: 0.09551537036895752
step: 940, loss: 0.0017775243613868952
step: 950, loss: 0.04049164056777954
step: 960, loss: 0.031304772943258286
step: 970, loss: 0.08880435675382614
step: 980, loss: 0.05199064314365387
step: 990, loss: 0.042521242052316666
step: 1000, loss: 5.235248681856319e-05
step: 1010, loss: 0.04712109640240669
step: 1020, loss: 0.08215607702732086
step: 1030, loss: 0.05320272967219353
step: 1040, loss: 0.033642739057540894
step: 1050, loss: 0.01158155407756567
step: 1060, loss: 0.05448293313384056
step: 1070, loss: 0.02815796248614788
epoch 16: dev_f1=0.9266697804764129, f1=0.9263746505125815, best_f1=0.9332121762835075
step: 0, loss: 0.015752660110592842
step: 10, loss: 0.027914436534047127
step: 20, loss: 0.06914576888084412
step: 30, loss: 0.07340343296527863
step: 40, loss: 0.0528135672211647
step: 50, loss: 0.024909595027565956
step: 60, loss: 0.05854655057191849
step: 70, loss: 0.03774857893586159
step: 80, loss: 0.015308592468500137
step: 90, loss: 0.08423903584480286
step: 100, loss: 0.024178361520171165
step: 110, loss: 0.030135037377476692
step: 120, loss: 0.04834083467721939
step: 130, loss: 0.03953662887215614
step: 140, loss: 0.04757481440901756
step: 150, loss: 0.10124002397060394
step: 160, loss: 0.06989234685897827
step: 170, loss: 0.032124970108270645
step: 180, loss: 0.08392024040222168
step: 190, loss: 5.9086145483888686e-05
step: 200, loss: 0.07502491027116776
step: 210, loss: 0.20677654445171356
step: 220, loss: 0.011305684223771095
step: 230, loss: 0.07466954737901688
step: 240, loss: 0.051941435784101486
step: 250, loss: 0.00012542666809167713
step: 260, loss: 0.04068932682275772
step: 270, loss: 0.037882253527641296
step: 280, loss: 2.795737236738205e-05
step: 290, loss: 0.016930555924773216
step: 300, loss: 0.08171079307794571
step: 310, loss: 0.05737125501036644
step: 320, loss: 0.04604750871658325
step: 330, loss: 0.01784747838973999
step: 340, loss: 0.0045604100450873375
step: 350, loss: 0.04611297696828842
step: 360, loss: 0.033593278378248215
step: 370, loss: 0.08239249885082245
step: 380, loss: 0.14351603388786316
step: 390, loss: 0.02279609814286232
step: 400, loss: 0.0495758019387722
step: 410, loss: 0.05239444226026535
step: 420, loss: 7.822633779142052e-05
step: 430, loss: 0.010666507296264172
step: 440, loss: 0.0010029657278209925
step: 450, loss: 0.05637780949473381
step: 460, loss: 0.052167005836963654
step: 470, loss: 0.000633813557215035
step: 480, loss: 0.027561362832784653
step: 490, loss: 0.04357917979359627
step: 500, loss: 0.016193518415093422
step: 510, loss: 0.0008164993487298489
step: 520, loss: 0.0881500095129013
step: 530, loss: 0.03890436887741089
step: 540, loss: 0.03821076452732086
step: 550, loss: 0.027096103876829147
step: 560, loss: 0.0203841682523489
step: 570, loss: 0.021828945726156235
step: 580, loss: 0.03097638487815857
step: 590, loss: 0.05095823481678963
step: 600, loss: 0.027303289622068405
step: 610, loss: 0.0028787755873054266
step: 620, loss: 0.017363257706165314
step: 630, loss: 0.012379643507301807
step: 640, loss: 0.040834441781044006
step: 650, loss: 0.04331917688250542
step: 660, loss: 0.0630536898970604
step: 670, loss: 0.07895714044570923
step: 680, loss: 0.021966539323329926
step: 690, loss: 0.028240619227290154
step: 700, loss: 0.02202792465686798
step: 710, loss: 4.8710637202020735e-05
step: 720, loss: 0.1013369932770729
step: 730, loss: 0.03801310807466507
step: 740, loss: 0.020422503352165222
step: 750, loss: 0.06554915755987167
step: 760, loss: 0.0405845120549202
step: 770, loss: 0.07995930314064026
step: 780, loss: 0.01738923043012619
step: 790, loss: 0.07214067131280899
step: 800, loss: 0.04771248251199722
step: 810, loss: 0.011076921597123146
step: 820, loss: 0.10035990923643112
step: 830, loss: 0.008994621224701405
step: 840, loss: 0.019442826509475708
step: 850, loss: 0.07515940815210342
step: 860, loss: 0.030808482319116592
step: 870, loss: 0.028797470033168793
step: 880, loss: 1.5884501408436336e-05
step: 890, loss: 0.12217073887586594
step: 900, loss: 0.02713211253285408
step: 910, loss: 0.02400871552526951
step: 920, loss: 0.04217328876256943
step: 930, loss: 0.0394955575466156
step: 940, loss: 0.0643501803278923
step: 950, loss: 0.11960940062999725
step: 960, loss: 0.038186103105545044
step: 970, loss: 0.04964470490813255
step: 980, loss: 0.038621772080659866
step: 990, loss: 0.018028665333986282
step: 1000, loss: 0.034606870263814926
step: 1010, loss: 0.0021076155826449394
step: 1020, loss: 0.0003622385556809604
step: 1030, loss: 0.08585913479328156
step: 1040, loss: 0.06284525990486145
step: 1050, loss: 5.359209899324924e-05
step: 1060, loss: 0.0594978854060173
step: 1070, loss: 0.04709538444876671
epoch 17: dev_f1=0.9281045751633987, f1=0.9268065268065269, best_f1=0.9332121762835075
step: 0, loss: 0.11477649211883545
step: 10, loss: 0.07943813502788544
step: 20, loss: 0.00020283058984205127
step: 30, loss: 0.0246272012591362
step: 40, loss: 0.005166088230907917
step: 50, loss: 0.0026272714603692293
step: 60, loss: 0.0170355923473835
step: 70, loss: 0.13452699780464172
step: 80, loss: 0.04617943614721298
step: 90, loss: 0.07375279814004898
step: 100, loss: 0.001619658200070262
step: 110, loss: 0.09073329716920853
step: 120, loss: 0.033974383026361465
step: 130, loss: 0.061156172305345535
step: 140, loss: 0.021610410884022713
step: 150, loss: 0.01689276099205017
step: 160, loss: 0.08398187905550003
step: 170, loss: 0.0311843641102314
step: 180, loss: 0.020107124000787735
step: 190, loss: 0.04619086906313896
step: 200, loss: 0.08541198074817657
step: 210, loss: 0.011983898468315601
step: 220, loss: 0.08041238784790039
step: 230, loss: 0.06399714201688766
step: 240, loss: 0.0006296467618085444
step: 250, loss: 0.010276371613144875
step: 260, loss: 0.01771344244480133
step: 270, loss: 0.06155975162982941
step: 280, loss: 0.11128240823745728
step: 290, loss: 0.04036901146173477
step: 300, loss: 0.022854389622807503
step: 310, loss: 0.05027635768055916
step: 320, loss: 0.012362105771899223
step: 330, loss: 0.025837048888206482
step: 340, loss: 0.01587780751287937
step: 350, loss: 0.02125488594174385
step: 360, loss: 0.04140141233801842
step: 370, loss: 0.08822289854288101
step: 380, loss: 0.0008303152862936258
step: 390, loss: 0.0004135130438953638
step: 400, loss: 0.04795778542757034
step: 410, loss: 0.07989740371704102
step: 420, loss: 0.01903759315609932
step: 430, loss: 0.001381883048452437
step: 440, loss: 0.038482438772916794
step: 450, loss: 0.08748222887516022
step: 460, loss: 0.045859839767217636
step: 470, loss: 0.040133509784936905
step: 480, loss: 0.013105802237987518
step: 490, loss: 0.015456879511475563
step: 500, loss: 0.024263352155685425
step: 510, loss: 0.0298231802880764
step: 520, loss: 0.0029755786526948214
step: 530, loss: 0.013148898258805275
step: 540, loss: 0.0019927197135984898
step: 550, loss: 0.0906469076871872
step: 560, loss: 0.059486936777830124
step: 570, loss: 0.006515455897897482
step: 580, loss: 0.012653631158173084
step: 590, loss: 0.045367784798145294
step: 600, loss: 0.012051375582814217
step: 610, loss: 0.04909023270010948
step: 620, loss: 0.03425528481602669
step: 630, loss: 0.13563552498817444
step: 640, loss: 0.02369295433163643
step: 650, loss: 0.05049000680446625
step: 660, loss: 0.059491999447345734
step: 670, loss: 0.06253791600465775
step: 680, loss: 0.0998673066496849
step: 690, loss: 0.06761802732944489
step: 700, loss: 0.02588191255927086
step: 710, loss: 0.11200716346502304
step: 720, loss: 0.07031919807195663
step: 730, loss: 0.008752290159463882
step: 740, loss: 0.050824739038944244
step: 750, loss: 3.383049988769926e-05
step: 760, loss: 0.04491165280342102
step: 770, loss: 0.08011066913604736
step: 780, loss: 0.040143441408872604
step: 790, loss: 0.05722697824239731
step: 800, loss: 0.085189089179039
step: 810, loss: 0.030591556802392006
step: 820, loss: 0.05500495433807373
step: 830, loss: 0.047411706298589706
step: 840, loss: 0.02908729389309883
step: 850, loss: 0.03702854365110397
step: 860, loss: 0.10305152833461761
step: 870, loss: 0.07100418210029602
step: 880, loss: 0.08299265056848526
step: 890, loss: 0.03151926398277283
step: 900, loss: 0.06673093885183334
step: 910, loss: 0.00033059960696846247
step: 920, loss: 0.03273521363735199
step: 930, loss: 0.06404192000627518
step: 940, loss: 0.05759170278906822
step: 950, loss: 0.021248314529657364
step: 960, loss: 0.026650531217455864
step: 970, loss: 0.04681702330708504
step: 980, loss: 0.0023789999540895224
step: 990, loss: 0.1196422129869461
step: 1000, loss: 0.03066764771938324
step: 1010, loss: 0.029143936932086945
step: 1020, loss: 0.11153959482908249
step: 1030, loss: 0.09281473606824875
step: 1040, loss: 0.19164417684078217
step: 1050, loss: 0.049163464456796646
step: 1060, loss: 0.03147970885038376
step: 1070, loss: 0.058101411908864975
epoch 18: dev_f1=0.9266480965645311, f1=0.9255813953488372, best_f1=0.9332121762835075
step: 0, loss: 0.03539787232875824
step: 10, loss: 0.03937763348221779
step: 20, loss: 0.0485212616622448
step: 30, loss: 0.01181011088192463
step: 40, loss: 0.01577145792543888
step: 50, loss: 0.02481069229543209
step: 60, loss: 0.08506977558135986
step: 70, loss: 0.06488094478845596
step: 80, loss: 0.02107073925435543
step: 90, loss: 0.039031609892845154
step: 100, loss: 0.03691093623638153
step: 110, loss: 0.02803160436451435
step: 120, loss: 0.07919234782457352
step: 130, loss: 0.04116469994187355
step: 140, loss: 0.028637992218136787
step: 150, loss: 0.0008068557363003492
step: 160, loss: 0.02157536894083023
step: 170, loss: 0.014304198324680328
step: 180, loss: 0.09539870172739029
step: 190, loss: 0.020563138648867607
step: 200, loss: 0.09097198396921158
step: 210, loss: 0.035028357058763504
step: 220, loss: 0.05377292260527611
step: 230, loss: 0.035375919193029404
step: 240, loss: 0.02035476267337799
step: 250, loss: 0.07892801612615585
step: 260, loss: 0.019381854683160782
step: 270, loss: 0.0443929024040699
step: 280, loss: 0.054827574640512466
step: 290, loss: 0.1749010980129242
step: 300, loss: 0.07323062419891357
step: 310, loss: 0.04894513264298439
step: 320, loss: 0.04582866653800011
step: 330, loss: 0.029875723645091057
step: 340, loss: 0.08553946018218994
step: 350, loss: 0.024497801437973976
step: 360, loss: 0.012984486296772957
step: 370, loss: 0.025321314111351967
step: 380, loss: 0.0895787924528122
step: 390, loss: 0.0002634947595652193
step: 400, loss: 0.06737415492534637
step: 410, loss: 0.008406491950154305
step: 420, loss: 7.031865970930085e-05
step: 430, loss: 0.026590239256620407
step: 440, loss: 0.04685221612453461
step: 450, loss: 0.046648330986499786
step: 460, loss: 0.05204569548368454
step: 470, loss: 0.01272636465728283
step: 480, loss: 0.050967924296855927
step: 490, loss: 0.033939410001039505
step: 500, loss: 0.05630895495414734
step: 510, loss: 0.042348362505435944
step: 520, loss: 0.04269697517156601
step: 530, loss: 0.021317441016435623
step: 540, loss: 0.04760518670082092
step: 550, loss: 0.04135110229253769
step: 560, loss: 4.089294816367328e-05
step: 570, loss: 0.05308670550584793
step: 580, loss: 0.002335962373763323
step: 590, loss: 0.03969608247280121
step: 600, loss: 0.06368841230869293
step: 610, loss: 0.08415637910366058
step: 620, loss: 0.044161293655633926
step: 630, loss: 0.05928409472107887
step: 640, loss: 0.07473960518836975
step: 650, loss: 0.03979851305484772
step: 660, loss: 0.049314770847558975
step: 670, loss: 0.08027590066194534
step: 680, loss: 0.02566666528582573
step: 690, loss: 0.06365713477134705
step: 700, loss: 0.012500165961682796
step: 710, loss: 0.04535145312547684
step: 720, loss: 0.02704370766878128
step: 730, loss: 0.028522344306111336
step: 740, loss: 0.036771971732378006
step: 750, loss: 0.00033436898957006633
step: 760, loss: 0.03957981988787651
step: 770, loss: 0.10075066238641739
step: 780, loss: 0.06968403607606888
step: 790, loss: 0.020529313012957573
step: 800, loss: 0.018535956740379333
step: 810, loss: 0.014728715643286705
step: 820, loss: 0.08221784234046936
step: 830, loss: 0.026472672820091248
step: 840, loss: 0.05523618310689926
step: 850, loss: 0.12439431250095367
step: 860, loss: 0.059237025678157806
step: 870, loss: 0.05125601217150688
step: 880, loss: 0.01846117526292801
step: 890, loss: 0.029401838779449463
step: 900, loss: 0.0182663444429636
step: 910, loss: 0.05199631303548813
step: 920, loss: 0.014431452378630638
step: 930, loss: 0.014655191451311111
step: 940, loss: 0.029434381052851677
step: 950, loss: 0.000415990361943841
step: 960, loss: 0.025321688503026962
step: 970, loss: 0.07797146588563919
step: 980, loss: 0.027573097497224808
step: 990, loss: 0.07486513257026672
step: 1000, loss: 0.02784118987619877
step: 1010, loss: 0.10872499644756317
step: 1020, loss: 0.00013415163266472518
step: 1030, loss: 0.06505255401134491
step: 1040, loss: 0.0548868253827095
step: 1050, loss: 0.014850571751594543
step: 1060, loss: 0.02311565726995468
step: 1070, loss: 0.0722060427069664
epoch 19: dev_f1=0.9243065350258581, f1=0.9266917293233082, best_f1=0.9332121762835075
step: 0, loss: 0.08329597860574722
step: 10, loss: 0.0016868626698851585
step: 20, loss: 0.0363910011947155
step: 30, loss: 0.055284980684518814
step: 40, loss: 0.0004890795098617673
step: 50, loss: 0.00011448723671492189
step: 60, loss: 0.04489098861813545
step: 70, loss: 9.746952127898112e-05
step: 80, loss: 0.02903713285923004
step: 90, loss: 0.037184108048677444
step: 100, loss: 4.470070780371316e-05
step: 110, loss: 0.034004587680101395
step: 120, loss: 0.045933548361063004
step: 130, loss: 0.03838060796260834
step: 140, loss: 0.08429218083620071
step: 150, loss: 7.307105988729745e-05
step: 160, loss: 0.06911242753267288
step: 170, loss: 0.048024702817201614
step: 180, loss: 0.08592142164707184
step: 190, loss: 0.07521910965442657
step: 200, loss: 0.05354370176792145
step: 210, loss: 0.07659824192523956
step: 220, loss: 0.03726501017808914
step: 230, loss: 0.022074008360505104
step: 240, loss: 0.024769414216279984
step: 250, loss: 0.07118280977010727
step: 260, loss: 0.00011593852104851976
step: 270, loss: 0.03292922303080559
step: 280, loss: 0.035129133611917496
step: 290, loss: 0.0433860681951046
step: 300, loss: 0.04561448097229004
step: 310, loss: 0.09336227178573608
step: 320, loss: 0.007163866888731718
step: 330, loss: 0.008701960556209087
step: 340, loss: 0.010149061679840088
step: 350, loss: 0.004586309660226107
step: 360, loss: 0.03404857590794563
step: 370, loss: 0.10385970026254654
step: 380, loss: 0.053422607481479645
step: 390, loss: 0.08394403755664825
step: 400, loss: 0.04600110277533531
step: 410, loss: 0.08643148094415665
step: 420, loss: 0.02953018620610237
step: 430, loss: 0.031676311045885086
step: 440, loss: 0.02102573961019516
step: 450, loss: 0.0041358573362231255
step: 460, loss: 0.051977138966321945
step: 470, loss: 0.002349244896322489
step: 480, loss: 0.005623796954751015
step: 490, loss: 0.043904297053813934
step: 500, loss: 0.04858853667974472
step: 510, loss: 0.009940753690898418
step: 520, loss: 0.045047298073768616
step: 530, loss: 0.018304862082004547
step: 540, loss: 0.04648348316550255
step: 550, loss: 0.08911298215389252
step: 560, loss: 0.025522548705339432
step: 570, loss: 0.02398783527314663
step: 580, loss: 0.026626646518707275
step: 590, loss: 0.03512042388319969
step: 600, loss: 0.021161913871765137
step: 610, loss: 0.04951279237866402
step: 620, loss: 0.05902976915240288
step: 630, loss: 0.040960125625133514
step: 640, loss: 0.022640299052000046
step: 650, loss: 0.14184875786304474
step: 660, loss: 0.054069917649030685
step: 670, loss: 0.025720149278640747
step: 680, loss: 0.018776141107082367
step: 690, loss: 0.019503764808177948
step: 700, loss: 0.03428475931286812
step: 710, loss: 0.01876222901046276
step: 720, loss: 0.03530063480138779
step: 730, loss: 0.039383113384246826
step: 740, loss: 0.023117657750844955
step: 750, loss: 0.03398318961262703
step: 760, loss: 0.0725162923336029
step: 770, loss: 0.07744093984365463
step: 780, loss: 0.04907671734690666
step: 790, loss: 0.017069706693291664
step: 800, loss: 0.028685040771961212
step: 810, loss: 0.061854951083660126
step: 820, loss: 0.01754889450967312
step: 830, loss: 0.053332772105932236
step: 840, loss: 0.04458347707986832
step: 850, loss: 0.03593303635716438
step: 860, loss: 0.03432486578822136
step: 870, loss: 0.03491466864943504
step: 880, loss: 0.02386082522571087
step: 890, loss: 0.031652938574552536
step: 900, loss: 0.0545475035905838
step: 910, loss: 0.004828615114092827
step: 920, loss: 0.056853581219911575
step: 930, loss: 0.051268789917230606
step: 940, loss: 0.035333696752786636
step: 950, loss: 0.03079524263739586
step: 960, loss: 0.026459738612174988
step: 970, loss: 0.06346816569566727
step: 980, loss: 0.035660520195961
step: 990, loss: 0.010950936004519463
step: 1000, loss: 0.017877018079161644
step: 1010, loss: 0.01684938184916973
step: 1020, loss: 0.07748153805732727
step: 1030, loss: 0.04806261137127876
step: 1040, loss: 0.022984148934483528
step: 1050, loss: 0.06612105667591095
step: 1060, loss: 0.030694004148244858
step: 1070, loss: 0.05811344459652901
epoch 20: dev_f1=0.9243776420854861, f1=0.9276995305164318, best_f1=0.9332121762835075
