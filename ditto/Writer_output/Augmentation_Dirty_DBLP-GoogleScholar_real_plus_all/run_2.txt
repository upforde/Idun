cuda
Device: cuda
step: 0, loss: 0.7483775615692139
step: 10, loss: 0.5505946278572083
step: 20, loss: 0.4079350531101227
step: 30, loss: 0.4650111496448517
step: 40, loss: 0.2374289333820343
step: 50, loss: 0.30427655577659607
step: 60, loss: 0.22000652551651
step: 70, loss: 0.2736501097679138
step: 80, loss: 0.22666189074516296
step: 90, loss: 0.24115394055843353
step: 100, loss: 0.3885580003261566
step: 110, loss: 0.2805996537208557
step: 120, loss: 0.22417770326137543
step: 130, loss: 0.2680186629295349
step: 140, loss: 0.1609424203634262
step: 150, loss: 0.32200154662132263
step: 160, loss: 0.21659637987613678
step: 170, loss: 0.15258851647377014
step: 180, loss: 0.19326502084732056
step: 190, loss: 0.1376621127128601
step: 200, loss: 0.26950138807296753
step: 210, loss: 0.22454115748405457
step: 220, loss: 0.17708532512187958
step: 230, loss: 0.1596241444349289
step: 240, loss: 0.321540504693985
step: 250, loss: 0.34537720680236816
step: 260, loss: 0.4630623459815979
step: 270, loss: 0.1682807058095932
step: 280, loss: 0.2139161080121994
step: 290, loss: 0.05769890546798706
step: 300, loss: 0.12369003146886826
step: 310, loss: 0.1760880947113037
step: 320, loss: 0.12555165588855743
step: 330, loss: 0.3085128962993622
step: 340, loss: 0.17525726556777954
step: 350, loss: 0.20745792984962463
step: 360, loss: 0.11703140288591385
step: 370, loss: 0.18660186231136322
step: 380, loss: 0.14746980369091034
step: 390, loss: 0.1331532746553421
step: 400, loss: 0.15952806174755096
step: 410, loss: 0.15738143026828766
step: 420, loss: 0.21559594571590424
step: 430, loss: 0.12781746685504913
step: 440, loss: 0.06766270101070404
step: 450, loss: 0.14621683955192566
step: 460, loss: 0.12324584275484085
step: 470, loss: 0.1355867236852646
step: 480, loss: 0.11521214991807938
step: 490, loss: 0.07540277391672134
step: 500, loss: 0.1064707487821579
step: 510, loss: 0.07293994724750519
step: 520, loss: 0.09958331286907196
step: 530, loss: 0.15884123742580414
step: 540, loss: 0.16513517498970032
step: 550, loss: 0.17055644094944
step: 560, loss: 0.16502252221107483
step: 570, loss: 0.1259748786687851
step: 580, loss: 0.07311881333589554
step: 590, loss: 0.10955019295215607
step: 600, loss: 0.17974475026130676
step: 610, loss: 0.19912675023078918
step: 620, loss: 0.1330975443124771
step: 630, loss: 0.12145409733057022
step: 640, loss: 0.35850971937179565
step: 650, loss: 0.21249718964099884
step: 660, loss: 0.1274653822183609
step: 670, loss: 0.13181573152542114
step: 680, loss: 0.24870531260967255
step: 690, loss: 0.06043599545955658
step: 700, loss: 0.09206557273864746
step: 710, loss: 0.09687143564224243
step: 720, loss: 0.10393819212913513
step: 730, loss: 0.12284037470817566
step: 740, loss: 0.17151248455047607
step: 750, loss: 0.10995852202177048
step: 760, loss: 0.09738408029079437
step: 770, loss: 0.09537429362535477
step: 780, loss: 0.12941206991672516
step: 790, loss: 0.2158692479133606
step: 800, loss: 0.12647825479507446
step: 810, loss: 0.10928970575332642
step: 820, loss: 0.160755455493927
step: 830, loss: 0.03562477231025696
step: 840, loss: 0.15430399775505066
step: 850, loss: 0.20193269848823547
step: 860, loss: 0.10963279753923416
step: 870, loss: 0.06500548869371414
step: 880, loss: 0.19939319789409637
step: 890, loss: 0.05568502098321915
step: 900, loss: 0.2668222188949585
step: 910, loss: 0.15477274358272552
step: 920, loss: 0.07483013719320297
step: 930, loss: 0.07476197928190231
step: 940, loss: 0.04952645301818848
step: 950, loss: 0.193133145570755
step: 960, loss: 0.07627899199724197
step: 970, loss: 0.1219063401222229
step: 980, loss: 0.15835872292518616
step: 990, loss: 0.11797993630170822
step: 1000, loss: 0.1461530327796936
step: 1010, loss: 0.16143174469470978
step: 1020, loss: 0.06456612050533295
step: 1030, loss: 0.07369202375411987
step: 1040, loss: 0.1084999218583107
step: 1050, loss: 0.11832496523857117
step: 1060, loss: 0.14915771782398224
step: 1070, loss: 0.1289772242307663
epoch 1: dev_f1=0.9248291571753987, f1=0.9202733485193623, best_f1=0.9202733485193623
step: 0, loss: 0.18578918278217316
step: 10, loss: 0.053458649665117264
step: 20, loss: 0.1984211951494217
step: 30, loss: 0.046880513429641724
step: 40, loss: 0.06485632807016373
step: 50, loss: 0.16534297168254852
step: 60, loss: 0.21485118567943573
step: 70, loss: 0.18336839973926544
step: 80, loss: 0.03620925173163414
step: 90, loss: 0.19218599796295166
step: 100, loss: 0.05189967527985573
step: 110, loss: 0.16028575599193573
step: 120, loss: 0.14921945333480835
step: 130, loss: 0.1744372844696045
step: 140, loss: 0.07806945592164993
step: 150, loss: 0.22526605427265167
step: 160, loss: 0.16486653685569763
step: 170, loss: 0.04200737550854683
step: 180, loss: 0.17748630046844482
step: 190, loss: 0.16002605855464935
step: 200, loss: 0.12302368879318237
step: 210, loss: 0.17377130687236786
step: 220, loss: 0.1358332484960556
step: 230, loss: 0.11780479550361633
step: 240, loss: 0.05825786665081978
step: 250, loss: 0.06992433965206146
step: 260, loss: 0.09830264002084732
step: 270, loss: 0.08081641793251038
step: 280, loss: 0.06250105798244476
step: 290, loss: 0.07677184045314789
step: 300, loss: 0.10154995322227478
step: 310, loss: 0.08276153355836868
step: 320, loss: 0.105776347219944
step: 330, loss: 0.08048250526189804
step: 340, loss: 0.05415573716163635
step: 350, loss: 0.14411655068397522
step: 360, loss: 0.13497604429721832
step: 370, loss: 0.18972529470920563
step: 380, loss: 0.19296546280384064
step: 390, loss: 0.12654300034046173
step: 400, loss: 0.14175811409950256
step: 410, loss: 0.03466339409351349
step: 420, loss: 0.11709285527467728
step: 430, loss: 0.09432126581668854
step: 440, loss: 0.11930789798498154
step: 450, loss: 0.10491002351045609
step: 460, loss: 0.24018177390098572
step: 470, loss: 0.08699898421764374
step: 480, loss: 0.08298446983098984
step: 490, loss: 0.14065949618816376
step: 500, loss: 0.14604227244853973
step: 510, loss: 0.06102371960878372
step: 520, loss: 0.14973409473896027
step: 530, loss: 0.04536277800798416
step: 540, loss: 0.1288699507713318
step: 550, loss: 0.13747693598270416
step: 560, loss: 0.07236877828836441
step: 570, loss: 0.12179934233427048
step: 580, loss: 0.042046934366226196
step: 590, loss: 0.085436150431633
step: 600, loss: 0.20709474384784698
step: 610, loss: 0.15325431525707245
step: 620, loss: 0.0803227648139
step: 630, loss: 0.294045090675354
step: 640, loss: 0.16104784607887268
step: 650, loss: 0.08245846629142761
step: 660, loss: 0.02335135079920292
step: 670, loss: 0.09019624441862106
step: 680, loss: 0.09759122878313065
step: 690, loss: 0.0919215977191925
step: 700, loss: 0.139877587556839
step: 710, loss: 0.20807339251041412
step: 720, loss: 0.1433844268321991
step: 730, loss: 0.09682535380125046
step: 740, loss: 0.357810914516449
step: 750, loss: 0.16472549736499786
step: 760, loss: 0.1521252989768982
step: 770, loss: 0.04176933318376541
step: 780, loss: 0.1422504484653473
step: 790, loss: 0.13033849000930786
step: 800, loss: 0.19086556136608124
step: 810, loss: 0.09564609080553055
step: 820, loss: 0.15427079796791077
step: 830, loss: 0.1399550586938858
step: 840, loss: 0.0602436363697052
step: 850, loss: 0.1383676826953888
step: 860, loss: 0.11005708575248718
step: 870, loss: 0.115513876080513
step: 880, loss: 0.21389426290988922
step: 890, loss: 0.18589265644550323
step: 900, loss: 0.19443845748901367
step: 910, loss: 0.1266068071126938
step: 920, loss: 0.06663033366203308
step: 930, loss: 0.10270538181066513
step: 940, loss: 0.09719972312450409
step: 950, loss: 0.10527142882347107
step: 960, loss: 0.12042458355426788
step: 970, loss: 0.13317807018756866
step: 980, loss: 0.12322524935007095
step: 990, loss: 0.08233828097581863
step: 1000, loss: 0.10380978137254715
step: 1010, loss: 0.2616596519947052
step: 1020, loss: 0.09478677809238434
step: 1030, loss: 0.18478098511695862
step: 1040, loss: 0.11644748598337173
step: 1050, loss: 0.039023496210575104
step: 1060, loss: 0.06569432467222214
step: 1070, loss: 0.09036841243505478
epoch 2: dev_f1=0.9135577797998181, f1=0.9084315503173165, best_f1=0.9202733485193623
step: 0, loss: 0.07546282559633255
step: 10, loss: 0.08748585730791092
step: 20, loss: 0.0837380439043045
step: 30, loss: 0.054738715291023254
step: 40, loss: 0.1331438273191452
step: 50, loss: 0.12534120678901672
step: 60, loss: 0.13153474032878876
step: 70, loss: 0.09331977367401123
step: 80, loss: 0.08483246713876724
step: 90, loss: 0.12960520386695862
step: 100, loss: 0.15421712398529053
step: 110, loss: 0.08452907204627991
step: 120, loss: 0.15368081629276276
step: 130, loss: 0.3068857789039612
step: 140, loss: 0.1698767989873886
step: 150, loss: 0.06872833520174026
step: 160, loss: 0.05639522150158882
step: 170, loss: 0.2214404195547104
step: 180, loss: 0.07410918176174164
step: 190, loss: 0.06513157486915588
step: 200, loss: 0.036217737942934036
step: 210, loss: 0.09691951423883438
step: 220, loss: 0.07596433162689209
step: 230, loss: 0.21993927657604218
step: 240, loss: 0.16423457860946655
step: 250, loss: 0.10088955610990524
step: 260, loss: 0.03781384229660034
step: 270, loss: 0.1313118189573288
step: 280, loss: 0.03636841103434563
step: 290, loss: 0.1274355947971344
step: 300, loss: 0.09735524654388428
step: 310, loss: 0.05690092220902443
step: 320, loss: 0.01643659919500351
step: 330, loss: 0.1564560979604721
step: 340, loss: 0.1441245824098587
step: 350, loss: 0.09690318256616592
step: 360, loss: 0.11080523580312729
step: 370, loss: 0.09852487593889236
step: 380, loss: 0.12644019722938538
step: 390, loss: 0.11945070326328278
step: 400, loss: 0.18414248526096344
step: 410, loss: 0.07492110878229141
step: 420, loss: 0.07530969381332397
step: 430, loss: 0.16199173033237457
step: 440, loss: 0.09573622047901154
step: 450, loss: 0.12979693710803986
step: 460, loss: 0.12701085209846497
step: 470, loss: 0.1554289311170578
step: 480, loss: 0.1581142544746399
step: 490, loss: 0.05706655606627464
step: 500, loss: 0.04739638790488243
step: 510, loss: 0.28888094425201416
step: 520, loss: 0.13229316473007202
step: 530, loss: 0.1786433458328247
step: 540, loss: 0.11039600521326065
step: 550, loss: 0.09698309749364853
step: 560, loss: 0.10712236166000366
step: 570, loss: 0.045545194298028946
step: 580, loss: 0.07113765925168991
step: 590, loss: 0.11963505297899246
step: 600, loss: 0.05685637146234512
step: 610, loss: 0.09913627058267593
step: 620, loss: 0.10271191596984863
step: 630, loss: 0.09439119696617126
step: 640, loss: 0.13582508265972137
step: 650, loss: 0.2233130931854248
step: 660, loss: 0.03001582995057106
step: 670, loss: 0.24854828417301178
step: 680, loss: 0.09920362383127213
step: 690, loss: 0.18928726017475128
step: 700, loss: 0.04390542209148407
step: 710, loss: 0.0724303126335144
step: 720, loss: 0.1925467997789383
step: 730, loss: 0.16747672855854034
step: 740, loss: 0.1363309770822525
step: 750, loss: 0.012697074562311172
step: 760, loss: 0.08640755712985992
step: 770, loss: 0.06157524138689041
step: 780, loss: 0.11266108602285385
step: 790, loss: 0.09583064168691635
step: 800, loss: 0.17877697944641113
step: 810, loss: 0.06649892777204514
step: 820, loss: 0.12137903273105621
step: 830, loss: 0.18228012323379517
step: 840, loss: 0.1547330766916275
step: 850, loss: 0.2556556463241577
step: 860, loss: 0.19231277704238892
step: 870, loss: 0.10617369413375854
step: 880, loss: 0.058818262070417404
step: 890, loss: 0.12910757958889008
step: 900, loss: 0.037632957100868225
step: 910, loss: 0.13455528020858765
step: 920, loss: 0.056457649916410446
step: 930, loss: 0.1492886245250702
step: 940, loss: 0.07658524066209793
step: 950, loss: 0.13675083220005035
step: 960, loss: 0.060155417770147324
step: 970, loss: 0.094682477414608
step: 980, loss: 0.07219960540533066
step: 990, loss: 0.21137544512748718
step: 1000, loss: 0.13839870691299438
step: 1010, loss: 0.09678913652896881
step: 1020, loss: 0.09106284379959106
step: 1030, loss: 0.0516992062330246
step: 1040, loss: 0.13375882804393768
step: 1050, loss: 0.11065228283405304
step: 1060, loss: 0.03361412510275841
step: 1070, loss: 0.027170168235898018
epoch 3: dev_f1=0.9289316827143513, f1=0.9249193919852603, best_f1=0.9249193919852603
step: 0, loss: 0.062080465257167816
step: 10, loss: 0.052588656544685364
step: 20, loss: 0.08162730932235718
step: 30, loss: 0.18066170811653137
step: 40, loss: 0.10366947948932648
step: 50, loss: 0.03414945304393768
step: 60, loss: 0.15826767683029175
step: 70, loss: 0.15807217359542847
step: 80, loss: 0.0524987168610096
step: 90, loss: 0.17085738480091095
step: 100, loss: 0.12621337175369263
step: 110, loss: 0.03072568215429783
step: 120, loss: 0.04039616882801056
step: 130, loss: 0.06681279838085175
step: 140, loss: 0.22778820991516113
step: 150, loss: 0.05786123126745224
step: 160, loss: 0.06234771013259888
step: 170, loss: 0.099503293633461
step: 180, loss: 0.11931157112121582
step: 190, loss: 0.1710977554321289
step: 200, loss: 0.1689993143081665
step: 210, loss: 0.08379726856946945
step: 220, loss: 0.055425964295864105
step: 230, loss: 0.05883128196001053
step: 240, loss: 0.017779339104890823
step: 250, loss: 0.10516367852687836
step: 260, loss: 0.0686793252825737
step: 270, loss: 0.15772582590579987
step: 280, loss: 0.09213946014642715
step: 290, loss: 0.18249915540218353
step: 300, loss: 0.10218347609043121
step: 310, loss: 0.0538734570145607
step: 320, loss: 0.03677208349108696
step: 330, loss: 0.15939144790172577
step: 340, loss: 0.10445549339056015
step: 350, loss: 0.19863440096378326
step: 360, loss: 0.1499030739068985
step: 370, loss: 0.18696700036525726
step: 380, loss: 0.15040186047554016
step: 390, loss: 0.06487715989351273
step: 400, loss: 0.10922924429178238
step: 410, loss: 0.09419246762990952
step: 420, loss: 0.05348098278045654
step: 430, loss: 0.09499850124120712
step: 440, loss: 0.19933247566223145
step: 450, loss: 0.059450168162584305
step: 460, loss: 0.047665782272815704
step: 470, loss: 0.05409594252705574
step: 480, loss: 0.22390712797641754
step: 490, loss: 0.2891266345977783
step: 500, loss: 0.04970403015613556
step: 510, loss: 0.15557743608951569
step: 520, loss: 0.16676375269889832
step: 530, loss: 0.060963816940784454
step: 540, loss: 0.07240790873765945
step: 550, loss: 0.050418056547641754
step: 560, loss: 0.13090507686138153
step: 570, loss: 0.15237756073474884
step: 580, loss: 0.06376592814922333
step: 590, loss: 0.15778081119060516
step: 600, loss: 0.11778244376182556
step: 610, loss: 0.1404285877943039
step: 620, loss: 0.10632451623678207
step: 630, loss: 0.09906718134880066
step: 640, loss: 0.07867620885372162
step: 650, loss: 0.08604469895362854
step: 660, loss: 0.08950042724609375
step: 670, loss: 0.02560477703809738
step: 680, loss: 0.16110859811306
step: 690, loss: 0.14747290313243866
step: 700, loss: 0.10710471123456955
step: 710, loss: 0.15407373011112213
step: 720, loss: 0.06336556375026703
step: 730, loss: 0.20740704238414764
step: 740, loss: 0.12028364092111588
step: 750, loss: 0.09258806705474854
step: 760, loss: 0.05407639592885971
step: 770, loss: 0.08960998058319092
step: 780, loss: 0.050205331295728683
step: 790, loss: 0.11734532564878464
step: 800, loss: 0.11861953139305115
step: 810, loss: 0.10555370151996613
step: 820, loss: 0.17688213288784027
step: 830, loss: 0.07417032867670059
step: 840, loss: 0.045485422015190125
step: 850, loss: 0.15035861730575562
step: 860, loss: 0.01878504641354084
step: 870, loss: 0.08855625241994858
step: 880, loss: 0.27430200576782227
step: 890, loss: 0.25132495164871216
step: 900, loss: 0.15620717406272888
step: 910, loss: 0.10813172161579132
step: 920, loss: 0.08870544284582138
step: 930, loss: 0.0982525497674942
step: 940, loss: 0.08414700627326965
step: 950, loss: 0.13832102715969086
step: 960, loss: 0.07827640324831009
step: 970, loss: 0.056441761553287506
step: 980, loss: 0.018102122470736504
step: 990, loss: 0.337820440530777
step: 1000, loss: 0.10009686648845673
step: 1010, loss: 0.2342524230480194
step: 1020, loss: 0.2337205410003662
step: 1030, loss: 0.0447295606136322
step: 1040, loss: 0.0662575513124466
step: 1050, loss: 0.15130245685577393
step: 1060, loss: 0.17012463510036469
step: 1070, loss: 0.09904533624649048
epoch 4: dev_f1=0.9420491423273065, f1=0.9260808926080892, best_f1=0.9260808926080892
step: 0, loss: 0.0845227763056755
step: 10, loss: 0.16032259166240692
step: 20, loss: 0.05342859774827957
step: 30, loss: 0.053114861249923706
step: 40, loss: 0.12495366483926773
step: 50, loss: 0.1175278052687645
step: 60, loss: 0.06359653174877167
step: 70, loss: 0.1592545509338379
step: 80, loss: 0.07969357818365097
step: 90, loss: 0.07616850733757019
step: 100, loss: 0.06745979189872742
step: 110, loss: 0.10468406230211258
step: 120, loss: 0.08550536632537842
step: 130, loss: 0.15691518783569336
step: 140, loss: 0.05074611306190491
step: 150, loss: 0.15171627700328827
step: 160, loss: 0.03789735585451126
step: 170, loss: 0.015415147878229618
step: 180, loss: 0.10303197801113129
step: 190, loss: 0.10770903527736664
step: 200, loss: 0.1481815129518509
step: 210, loss: 0.0807957723736763
step: 220, loss: 0.047041650861501694
step: 230, loss: 0.11021038144826889
step: 240, loss: 0.15674784779548645
step: 250, loss: 0.12284260243177414
step: 260, loss: 0.11868753284215927
step: 270, loss: 0.08056122809648514
step: 280, loss: 0.0763280913233757
step: 290, loss: 0.08191400021314621
step: 300, loss: 0.10406533628702164
step: 310, loss: 0.1343090981245041
step: 320, loss: 0.050857968628406525
step: 330, loss: 0.03767108544707298
step: 340, loss: 0.2070501744747162
step: 350, loss: 0.037810906767845154
step: 360, loss: 0.056330129504203796
step: 370, loss: 0.03869720920920372
step: 380, loss: 0.06822851300239563
step: 390, loss: 0.2508319020271301
step: 400, loss: 0.016057316213846207
step: 410, loss: 0.006137182004749775
step: 420, loss: 0.10931302607059479
step: 430, loss: 0.10859104990959167
step: 440, loss: 0.026568574830889702
step: 450, loss: 0.09665801376104355
step: 460, loss: 0.1638055294752121
step: 470, loss: 0.030423559248447418
step: 480, loss: 0.10311248898506165
step: 490, loss: 0.04321921616792679
step: 500, loss: 0.129301518201828
step: 510, loss: 0.15561269223690033
step: 520, loss: 0.20163263380527496
step: 530, loss: 0.06896362453699112
step: 540, loss: 0.07797354459762573
step: 550, loss: 0.08730024099349976
step: 560, loss: 0.10641876608133316
step: 570, loss: 0.13920550048351288
step: 580, loss: 0.17021659016609192
step: 590, loss: 0.07976263761520386
step: 600, loss: 0.20662587881088257
step: 610, loss: 0.06396429985761642
step: 620, loss: 0.022183192893862724
step: 630, loss: 0.05838321894407272
step: 640, loss: 0.13938449323177338
step: 650, loss: 0.09161035716533661
step: 660, loss: 0.11639593541622162
step: 670, loss: 0.06707364320755005
step: 680, loss: 0.11130410432815552
step: 690, loss: 0.13801206648349762
step: 700, loss: 0.04693477973341942
step: 710, loss: 0.11960062384605408
step: 720, loss: 0.0869135782122612
step: 730, loss: 0.1101556271314621
step: 740, loss: 0.08161046355962753
step: 750, loss: 0.09135951846837997
step: 760, loss: 0.03388823941349983
step: 770, loss: 0.10198529064655304
step: 780, loss: 0.06865472346544266
step: 790, loss: 0.027771491557359695
step: 800, loss: 0.05465375632047653
step: 810, loss: 0.0278730820864439
step: 820, loss: 0.13794848322868347
step: 830, loss: 0.1073262020945549
step: 840, loss: 0.04492076486349106
step: 850, loss: 0.06875014305114746
step: 860, loss: 0.1670200079679489
step: 870, loss: 0.06471472978591919
step: 880, loss: 0.059944599866867065
step: 890, loss: 0.020976630970835686
step: 900, loss: 0.07563909143209457
step: 910, loss: 0.0939917266368866
step: 920, loss: 0.07719144970178604
step: 930, loss: 0.06709359586238861
step: 940, loss: 0.08478520065546036
step: 950, loss: 0.08800306916236877
step: 960, loss: 0.06685388833284378
step: 970, loss: 0.054913267493247986
step: 980, loss: 0.013139900751411915
step: 990, loss: 0.1186976283788681
step: 1000, loss: 0.07345090806484222
step: 1010, loss: 0.11332177370786667
step: 1020, loss: 0.14144159853458405
step: 1030, loss: 0.08469752967357635
step: 1040, loss: 0.13846904039382935
step: 1050, loss: 0.06544648110866547
step: 1060, loss: 0.1885603815317154
step: 1070, loss: 0.008730223402380943
epoch 5: dev_f1=0.9338881183541378, f1=0.9236430542778289, best_f1=0.9260808926080892
step: 0, loss: 0.1600559800863266
step: 10, loss: 0.05259260907769203
step: 20, loss: 0.13553953170776367
step: 30, loss: 0.053110022097826004
step: 40, loss: 0.047492265701293945
step: 50, loss: 0.05016082152724266
step: 60, loss: 0.09131208062171936
step: 70, loss: 0.08334637433290482
step: 80, loss: 0.09861018508672714
step: 90, loss: 0.06482401490211487
step: 100, loss: 0.08654040843248367
step: 110, loss: 0.08566690236330032
step: 120, loss: 0.03202131390571594
step: 130, loss: 0.09032658487558365
step: 140, loss: 0.1080818697810173
step: 150, loss: 0.12273381650447845
step: 160, loss: 0.07773315161466599
step: 170, loss: 0.09532788395881653
step: 180, loss: 0.13622552156448364
step: 190, loss: 0.042934417724609375
step: 200, loss: 0.11013206839561462
step: 210, loss: 0.13922595977783203
step: 220, loss: 0.01834883913397789
step: 230, loss: 0.15117526054382324
step: 240, loss: 0.008736927062273026
step: 250, loss: 0.1422283798456192
step: 260, loss: 0.12030612677335739
step: 270, loss: 0.09444940090179443
step: 280, loss: 0.055688779801130295
step: 290, loss: 0.0932592898607254
step: 300, loss: 0.049637626856565475
step: 310, loss: 0.05278315395116806
step: 320, loss: 0.09106426686048508
step: 330, loss: 0.017487317323684692
step: 340, loss: 0.09040383994579315
step: 350, loss: 0.0968218669295311
step: 360, loss: 0.1655050665140152
step: 370, loss: 0.02548900619149208
step: 380, loss: 0.12996479868888855
step: 390, loss: 0.12385531514883041
step: 400, loss: 0.16836173832416534
step: 410, loss: 0.05995453521609306
step: 420, loss: 0.055652860552072525
step: 430, loss: 0.10067287087440491
step: 440, loss: 0.10170935094356537
step: 450, loss: 0.024837221950292587
step: 460, loss: 0.005254070740193129
step: 470, loss: 0.03939269483089447
step: 480, loss: 0.1795777827501297
step: 490, loss: 0.023422447964549065
step: 500, loss: 0.14147698879241943
step: 510, loss: 0.12582167983055115
step: 520, loss: 0.050677936524152756
step: 530, loss: 0.13400670886039734
step: 540, loss: 0.13538497686386108
step: 550, loss: 0.05555916950106621
step: 560, loss: 0.12121804058551788
step: 570, loss: 0.054365433752536774
step: 580, loss: 0.10716214776039124
step: 590, loss: 0.1214606910943985
step: 600, loss: 0.1049090102314949
step: 610, loss: 0.15487037599086761
step: 620, loss: 0.013893473893404007
step: 630, loss: 0.05934043973684311
step: 640, loss: 0.022961920127272606
step: 650, loss: 0.09771214425563812
step: 660, loss: 0.1126144677400589
step: 670, loss: 0.026106208562850952
step: 680, loss: 0.0572485588490963
step: 690, loss: 0.10258500277996063
step: 700, loss: 0.04334160313010216
step: 710, loss: 0.0023018289357423782
step: 720, loss: 0.06338419765233994
step: 730, loss: 0.11155010759830475
step: 740, loss: 0.09758931398391724
step: 750, loss: 0.08835320919752121
step: 760, loss: 0.1302688866853714
step: 770, loss: 0.028686104342341423
step: 780, loss: 0.04267442226409912
step: 790, loss: 0.2609039545059204
step: 800, loss: 0.0679459273815155
step: 810, loss: 0.1694605052471161
step: 820, loss: 0.23133958876132965
step: 830, loss: 0.12459149211645126
step: 840, loss: 0.11359152942895889
step: 850, loss: 0.1066841334104538
step: 860, loss: 0.026310890913009644
step: 870, loss: 0.019746912643313408
step: 880, loss: 0.049152106046676636
step: 890, loss: 0.27001404762268066
step: 900, loss: 0.08348267525434494
step: 910, loss: 0.1327623873949051
step: 920, loss: 0.13660874962806702
step: 930, loss: 0.0689193606376648
step: 940, loss: 0.09814142435789108
step: 950, loss: 0.08471902459859848
step: 960, loss: 0.014575401321053505
step: 970, loss: 0.09134766459465027
step: 980, loss: 0.048857130110263824
step: 990, loss: 0.06681003421545029
step: 1000, loss: 0.1616646945476532
step: 1010, loss: 0.06808674335479736
step: 1020, loss: 0.15490075945854187
step: 1030, loss: 0.05756112188100815
step: 1040, loss: 0.12954044342041016
step: 1050, loss: 0.09952042996883392
step: 1060, loss: 0.04964204877614975
step: 1070, loss: 0.10624919831752777
epoch 6: dev_f1=0.9277673545966229, f1=0.9255269320843091, best_f1=0.9260808926080892
step: 0, loss: 0.054003726691007614
step: 10, loss: 0.056488096714019775
step: 20, loss: 0.1565108746290207
step: 30, loss: 0.13668859004974365
step: 40, loss: 0.03520971164107323
step: 50, loss: 0.024990616366267204
step: 60, loss: 0.17146530747413635
step: 70, loss: 0.13277554512023926
step: 80, loss: 0.0173563864082098
step: 90, loss: 0.07489033788442612
step: 100, loss: 0.1236635074019432
step: 110, loss: 0.042106661945581436
step: 120, loss: 0.01992548443377018
step: 130, loss: 0.10824745148420334
step: 140, loss: 0.34585732221603394
step: 150, loss: 0.035233911126852036
step: 160, loss: 0.02471759356558323
step: 170, loss: 0.1885576993227005
step: 180, loss: 0.15483400225639343
step: 190, loss: 0.0865096002817154
step: 200, loss: 0.09642341732978821
step: 210, loss: 0.1467389315366745
step: 220, loss: 0.08206944167613983
step: 230, loss: 0.06235890090465546
step: 240, loss: 0.05986449122428894
step: 250, loss: 0.021688299253582954
step: 260, loss: 0.11074600368738174
step: 270, loss: 0.14105375111103058
step: 280, loss: 0.29048922657966614
step: 290, loss: 0.08953884243965149
step: 300, loss: 0.10385759174823761
step: 310, loss: 0.14622773230075836
step: 320, loss: 0.1238040030002594
step: 330, loss: 0.08622051775455475
step: 340, loss: 0.11041208356618881
step: 350, loss: 0.08424755930900574
step: 360, loss: 0.08427722752094269
step: 370, loss: 0.03001353330910206
step: 380, loss: 0.13360938429832458
step: 390, loss: 0.03650432452559471
step: 400, loss: 0.21113713085651398
step: 410, loss: 0.26164498925209045
step: 420, loss: 0.028756309300661087
step: 430, loss: 0.04752263426780701
step: 440, loss: 0.11049260944128036
step: 450, loss: 0.0695662871003151
step: 460, loss: 0.1299230009317398
step: 470, loss: 0.06265465915203094
step: 480, loss: 0.08149358630180359
step: 490, loss: 0.11839494854211807
step: 500, loss: 0.07367061823606491
step: 510, loss: 0.09518348425626755
step: 520, loss: 0.050528910011053085
step: 530, loss: 0.020009636878967285
step: 540, loss: 0.20260846614837646
step: 550, loss: 0.16586646437644958
step: 560, loss: 0.03575510531663895
step: 570, loss: 0.04692539572715759
step: 580, loss: 0.2677764892578125
step: 590, loss: 0.06229279935359955
step: 600, loss: 0.1887875348329544
step: 610, loss: 0.04739978164434433
step: 620, loss: 0.10146035254001617
step: 630, loss: 0.039926592260599136
step: 640, loss: 0.021873950958251953
step: 650, loss: 0.08749525249004364
step: 660, loss: 0.03262459859251976
step: 670, loss: 0.03257939964532852
step: 680, loss: 0.12629882991313934
step: 690, loss: 0.04310564696788788
step: 700, loss: 0.10445747524499893
step: 710, loss: 0.12297796458005905
step: 720, loss: 0.18795108795166016
step: 730, loss: 0.14900191128253937
step: 740, loss: 0.05847621709108353
step: 750, loss: 0.0924258604645729
step: 760, loss: 0.1142057478427887
step: 770, loss: 0.10310680419206619
step: 780, loss: 0.1540749967098236
step: 790, loss: 0.08120451122522354
step: 800, loss: 0.18649670481681824
step: 810, loss: 0.30005747079849243
step: 820, loss: 0.10701797157526016
step: 830, loss: 0.06338906288146973
step: 840, loss: 0.04967193678021431
step: 850, loss: 0.08311298489570618
step: 860, loss: 0.04772140085697174
step: 870, loss: 0.05273929610848427
step: 880, loss: 0.18933561444282532
step: 890, loss: 0.05616346374154091
step: 900, loss: 0.12518280744552612
step: 910, loss: 0.07370804250240326
step: 920, loss: 0.07661032676696777
step: 930, loss: 0.028849922120571136
step: 940, loss: 0.07752493768930435
step: 950, loss: 0.0730193629860878
step: 960, loss: 0.07048553973436356
step: 970, loss: 0.036090850830078125
step: 980, loss: 0.12468703836202621
step: 990, loss: 0.07989358901977539
step: 1000, loss: 0.11403349041938782
step: 1010, loss: 0.04581655561923981
step: 1020, loss: 0.11277773231267929
step: 1030, loss: 0.02394767850637436
step: 1040, loss: 0.06780195981264114
step: 1050, loss: 0.0725690945982933
step: 1060, loss: 0.013032488524913788
step: 1070, loss: 0.04462040215730667
epoch 7: dev_f1=0.937037037037037, f1=0.9276164130935916, best_f1=0.9260808926080892
step: 0, loss: 0.0614047646522522
step: 10, loss: 0.03889455273747444
step: 20, loss: 0.12577171623706818
step: 30, loss: 0.02817617356777191
step: 40, loss: 0.04762478172779083
step: 50, loss: 0.026731744408607483
step: 60, loss: 0.0813494324684143
step: 70, loss: 0.003561820602044463
step: 80, loss: 0.17359742522239685
step: 90, loss: 0.07609111070632935
step: 100, loss: 0.12127828598022461
step: 110, loss: 0.04366974160075188
step: 120, loss: 0.01566607505083084
step: 130, loss: 0.07601658254861832
step: 140, loss: 0.11181630939245224
step: 150, loss: 0.07233567535877228
step: 160, loss: 0.06881045550107956
step: 170, loss: 0.08814015984535217
step: 180, loss: 0.07710746675729752
step: 190, loss: 0.08864377439022064
step: 200, loss: 0.17914603650569916
step: 210, loss: 0.09285209327936172
step: 220, loss: 0.06508223712444305
step: 230, loss: 0.04480288177728653
step: 240, loss: 0.09674017876386642
step: 250, loss: 0.05589967966079712
step: 260, loss: 0.10655798017978668
step: 270, loss: 0.05445393547415733
step: 280, loss: 0.08742152154445648
step: 290, loss: 0.07944828271865845
step: 300, loss: 0.0801796093583107
step: 310, loss: 0.11549820005893707
step: 320, loss: 0.02888534590601921
step: 330, loss: 0.040697287768125534
step: 340, loss: 0.1686185598373413
step: 350, loss: 0.06639618426561356
step: 360, loss: 0.08062554150819778
step: 370, loss: 0.014024915173649788
step: 380, loss: 0.05742301791906357
step: 390, loss: 0.063939668238163
step: 400, loss: 0.018886368721723557
step: 410, loss: 0.0235858503729105
step: 420, loss: 0.15631607174873352
step: 430, loss: 0.08002742379903793
step: 440, loss: 0.08659815788269043
step: 450, loss: 0.14703427255153656
step: 460, loss: 0.08177544176578522
step: 470, loss: 0.15563905239105225
step: 480, loss: 0.22365796566009521
step: 490, loss: 0.060581184923648834
step: 500, loss: 0.060269247740507126
step: 510, loss: 0.15508146584033966
step: 520, loss: 0.061574503779411316
step: 530, loss: 0.06850838661193848
step: 540, loss: 0.07228511571884155
step: 550, loss: 0.11894286423921585
step: 560, loss: 0.06056315079331398
step: 570, loss: 0.08508670330047607
step: 580, loss: 0.02926110476255417
step: 590, loss: 0.08526246249675751
step: 600, loss: 0.12356553971767426
step: 610, loss: 0.21309611201286316
step: 620, loss: 0.07638401538133621
step: 630, loss: 0.05083644390106201
step: 640, loss: 0.13638953864574432
step: 650, loss: 0.05388084426522255
step: 660, loss: 0.023267671465873718
step: 670, loss: 0.1596270650625229
step: 680, loss: 0.03645657002925873
step: 690, loss: 0.10226817429065704
step: 700, loss: 0.19770848751068115
step: 710, loss: 0.0805617943406105
step: 720, loss: 0.060809072107076645
step: 730, loss: 0.0233298409730196
step: 740, loss: 0.05854228883981705
step: 750, loss: 0.08325868844985962
step: 760, loss: 0.009678659029304981
step: 770, loss: 0.12330000847578049
step: 780, loss: 0.08173505961894989
step: 790, loss: 0.03834725171327591
step: 800, loss: 0.12290327250957489
step: 810, loss: 0.15753009915351868
step: 820, loss: 0.06314244866371155
step: 830, loss: 0.09765930473804474
step: 840, loss: 0.006205080077052116
step: 850, loss: 0.06998970359563828
step: 860, loss: 0.09530558437108994
step: 870, loss: 0.03617830201983452
step: 880, loss: 0.11577852070331573
step: 890, loss: 0.027668315917253494
step: 900, loss: 0.02769514173269272
step: 910, loss: 0.054922282695770264
step: 920, loss: 0.005921879317611456
step: 930, loss: 0.0338192880153656
step: 940, loss: 0.08750490844249725
step: 950, loss: 0.09485310316085815
step: 960, loss: 0.03574078902602196
step: 970, loss: 0.12768594920635223
step: 980, loss: 0.036615706980228424
step: 990, loss: 0.08140271157026291
step: 1000, loss: 0.058780424296855927
step: 1010, loss: 0.10524722188711166
step: 1020, loss: 0.049440041184425354
step: 1030, loss: 0.047997355461120605
step: 1040, loss: 0.11557113379240036
step: 1050, loss: 0.06234743818640709
step: 1060, loss: 0.023490633815526962
step: 1070, loss: 0.09830322116613388
epoch 8: dev_f1=0.9316712834718375, f1=0.9314814814814815, best_f1=0.9260808926080892
step: 0, loss: 9.442437294637784e-05
step: 10, loss: 0.043674059212207794
step: 20, loss: 0.07394540309906006
step: 30, loss: 0.029001932591199875
step: 40, loss: 0.0901743546128273
step: 50, loss: 0.01725492998957634
step: 60, loss: 0.06513648480176926
step: 70, loss: 0.03989611193537712
step: 80, loss: 0.19767387211322784
step: 90, loss: 0.07698998600244522
step: 100, loss: 0.05956987291574478
step: 110, loss: 0.025966918095946312
step: 120, loss: 0.0462455153465271
step: 130, loss: 0.1634192019701004
step: 140, loss: 0.16145524382591248
step: 150, loss: 0.0003420274588279426
step: 160, loss: 0.1834757924079895
step: 170, loss: 0.049518320709466934
step: 180, loss: 0.16058219969272614
step: 190, loss: 0.06644363701343536
step: 200, loss: 0.06279387325048447
step: 210, loss: 0.07222699373960495
step: 220, loss: 0.06584945321083069
step: 230, loss: 0.027886658906936646
step: 240, loss: 0.09908819943666458
step: 250, loss: 0.07190567255020142
step: 260, loss: 0.06985651701688766
step: 270, loss: 0.045191120356321335
step: 280, loss: 0.11230724304914474
step: 290, loss: 0.13718728721141815
step: 300, loss: 0.08516719192266464
step: 310, loss: 0.05283886566758156
step: 320, loss: 0.10607318580150604
step: 330, loss: 0.07695509493350983
step: 340, loss: 0.06669344753026962
step: 350, loss: 0.07063443958759308
step: 360, loss: 0.1692422479391098
step: 370, loss: 0.024088775739073753
step: 380, loss: 0.11070525646209717
step: 390, loss: 0.08770039677619934
step: 400, loss: 0.03521215170621872
step: 410, loss: 0.05566544830799103
step: 420, loss: 0.049198877066373825
step: 430, loss: 0.10683497786521912
step: 440, loss: 0.041828278452157974
step: 450, loss: 0.08003420382738113
step: 460, loss: 0.13088804483413696
step: 470, loss: 0.02983597107231617
step: 480, loss: 0.07868001610040665
step: 490, loss: 0.0538962185382843
step: 500, loss: 0.05574585869908333
step: 510, loss: 0.07661164551973343
step: 520, loss: 0.021498000249266624
step: 530, loss: 0.029390837997198105
step: 540, loss: 0.07849553227424622
step: 550, loss: 0.06099524348974228
step: 560, loss: 0.0327974371612072
step: 570, loss: 0.038378387689590454
step: 580, loss: 0.017621053382754326
step: 590, loss: 0.022641630843281746
step: 600, loss: 0.08453461527824402
step: 610, loss: 0.12408143281936646
step: 620, loss: 0.09958969801664352
step: 630, loss: 0.042575858533382416
step: 640, loss: 0.04186709597706795
step: 650, loss: 0.08120666444301605
step: 660, loss: 0.042537324130535126
step: 670, loss: 0.10140953958034515
step: 680, loss: 0.06643690168857574
step: 690, loss: 0.012759539298713207
step: 700, loss: 0.0423746183514595
step: 710, loss: 0.06103095784783363
step: 720, loss: 0.08526430279016495
step: 730, loss: 0.1322217583656311
step: 740, loss: 0.1179896667599678
step: 750, loss: 0.08388370275497437
step: 760, loss: 0.10046205669641495
step: 770, loss: 0.10903169214725494
step: 780, loss: 0.02940777689218521
step: 790, loss: 0.03723764792084694
step: 800, loss: 0.08979680389165878
step: 810, loss: 0.0756266638636589
step: 820, loss: 0.053427089005708694
step: 830, loss: 0.06775813549757004
step: 840, loss: 0.05522169917821884
step: 850, loss: 0.15484845638275146
step: 860, loss: 0.04285659268498421
step: 870, loss: 0.07554267346858978
step: 880, loss: 0.01748862862586975
step: 890, loss: 0.05379915609955788
step: 900, loss: 0.10920950025320053
step: 910, loss: 0.006422102451324463
step: 920, loss: 0.12228480726480484
step: 930, loss: 0.07582146674394608
step: 940, loss: 0.16688579320907593
step: 950, loss: 0.12840905785560608
step: 960, loss: 0.09585778415203094
step: 970, loss: 0.1258217841386795
step: 980, loss: 0.07521100342273712
step: 990, loss: 0.07042776048183441
step: 1000, loss: 0.08455565571784973
step: 1010, loss: 0.10528735816478729
step: 1020, loss: 0.025930024683475494
step: 1030, loss: 0.0393863320350647
step: 1040, loss: 0.060946229845285416
step: 1050, loss: 0.11844562739133835
step: 1060, loss: 0.17855505645275116
step: 1070, loss: 0.11138490587472916
epoch 9: dev_f1=0.9376422394173873, f1=0.925672594619243, best_f1=0.9260808926080892
step: 0, loss: 0.047596730291843414
step: 10, loss: 0.10639896988868713
step: 20, loss: 0.09012473374605179
step: 30, loss: 0.015387844294309616
step: 40, loss: 0.012587117962539196
step: 50, loss: 0.06136735528707504
step: 60, loss: 0.053392864763736725
step: 70, loss: 0.04937319457530975
step: 80, loss: 0.01705075055360794
step: 90, loss: 0.07097677141427994
step: 100, loss: 0.04942644014954567
step: 110, loss: 0.09216040372848511
step: 120, loss: 0.06066650524735451
step: 130, loss: 0.022301524877548218
step: 140, loss: 0.027497204020619392
step: 150, loss: 0.06715509295463562
step: 160, loss: 0.0011895491043105721
step: 170, loss: 0.0697028711438179
step: 180, loss: 0.01945364661514759
step: 190, loss: 0.06975127756595612
step: 200, loss: 0.1943216174840927
step: 210, loss: 0.09928983449935913
step: 220, loss: 0.12589521706104279
step: 230, loss: 0.12695640325546265
step: 240, loss: 0.12016518414020538
step: 250, loss: 0.03201451152563095
step: 260, loss: 0.05158185586333275
step: 270, loss: 0.1308165192604065
step: 280, loss: 0.06825242936611176
step: 290, loss: 0.059764571487903595
step: 300, loss: 0.13155873119831085
step: 310, loss: 0.16940374672412872
step: 320, loss: 0.16468338668346405
step: 330, loss: 0.053517766296863556
step: 340, loss: 0.04471813142299652
step: 350, loss: 0.07510342448949814
step: 360, loss: 0.10917884856462479
step: 370, loss: 0.02450246550142765
step: 380, loss: 0.025249658152461052
step: 390, loss: 0.07296183705329895
step: 400, loss: 0.04430442675948143
step: 410, loss: 0.024217769503593445
step: 420, loss: 0.06596031039953232
step: 430, loss: 0.09192652255296707
step: 440, loss: 0.038716621696949005
step: 450, loss: 0.04683954641222954
step: 460, loss: 0.10928861051797867
step: 470, loss: 0.11907142400741577
step: 480, loss: 0.0756940171122551
step: 490, loss: 0.044464174658060074
step: 500, loss: 0.004382059443742037
step: 510, loss: 0.06958852708339691
step: 520, loss: 0.0691174864768982
step: 530, loss: 0.0679975301027298
step: 540, loss: 0.10580828040838242
step: 550, loss: 0.01894919015467167
step: 560, loss: 0.022480446845293045
step: 570, loss: 0.0658755749464035
step: 580, loss: 0.09666411578655243
step: 590, loss: 0.10044477134943008
step: 600, loss: 0.05042532831430435
step: 610, loss: 0.08776278793811798
step: 620, loss: 0.012551762163639069
step: 630, loss: 0.13501034677028656
step: 640, loss: 0.05376296490430832
step: 650, loss: 0.09668682515621185
step: 660, loss: 0.06773705780506134
step: 670, loss: 0.07552246004343033
step: 680, loss: 0.10396870225667953
step: 690, loss: 0.02723999135196209
step: 700, loss: 0.07062471657991409
step: 710, loss: 0.07501988112926483
step: 720, loss: 0.06317683309316635
step: 730, loss: 0.08671453595161438
step: 740, loss: 0.16496171057224274
step: 750, loss: 0.10991684347391129
step: 760, loss: 0.05749377980828285
step: 770, loss: 0.07389380037784576
step: 780, loss: 0.04122406244277954
step: 790, loss: 0.07861435413360596
step: 800, loss: 0.0837811529636383
step: 810, loss: 0.1195254921913147
step: 820, loss: 0.06211191043257713
step: 830, loss: 0.0655643567442894
step: 840, loss: 0.12345608323812485
step: 850, loss: 0.22491033375263214
step: 860, loss: 0.08397568017244339
step: 870, loss: 0.13269241154193878
step: 880, loss: 0.07624100893735886
step: 890, loss: 0.07004372030496597
step: 900, loss: 0.09059210121631622
step: 910, loss: 0.07814931869506836
step: 920, loss: 0.08827711641788483
step: 930, loss: 0.08325066417455673
step: 940, loss: 0.04968087375164032
step: 950, loss: 0.06893482059240341
step: 960, loss: 0.1518109291791916
step: 970, loss: 0.15419062972068787
step: 980, loss: 0.03968330845236778
step: 990, loss: 0.04141268506646156
step: 1000, loss: 0.04199209064245224
step: 1010, loss: 0.0916011780500412
step: 1020, loss: 0.057565152645111084
step: 1030, loss: 0.09344301372766495
step: 1040, loss: 0.06059780716896057
step: 1050, loss: 0.18222030997276306
step: 1060, loss: 0.04437775909900665
step: 1070, loss: 0.05423343926668167
epoch 10: dev_f1=0.9320388349514563, f1=0.9296296296296297, best_f1=0.9260808926080892
step: 0, loss: 0.07109417766332626
step: 10, loss: 0.09016034752130508
step: 20, loss: 0.10641872882843018
step: 30, loss: 0.10537626594305038
step: 40, loss: 0.12083398550748825
step: 50, loss: 0.1527242362499237
step: 60, loss: 0.05789083242416382
step: 70, loss: 0.09092172980308533
step: 80, loss: 0.02803056314587593
step: 90, loss: 0.03613854944705963
step: 100, loss: 0.0506797693669796
step: 110, loss: 0.029089510440826416
step: 120, loss: 0.024516839534044266
step: 130, loss: 0.11560934036970139
step: 140, loss: 0.049292661249637604
step: 150, loss: 0.01406354084610939
step: 160, loss: 0.07910745590925217
step: 170, loss: 0.01960996352136135
step: 180, loss: 0.09671919792890549
step: 190, loss: 0.05899503827095032
step: 200, loss: 0.10366746038198471
step: 210, loss: 0.058828093111515045
step: 220, loss: 0.045843541622161865
step: 230, loss: 0.021172793582081795
step: 240, loss: 0.03311201557517052
step: 250, loss: 0.04606419429183006
step: 260, loss: 0.0753181055188179
step: 270, loss: 0.10205472260713577
step: 280, loss: 0.04780752211809158
step: 290, loss: 0.07433607429265976
step: 300, loss: 0.07188203185796738
step: 310, loss: 0.08936737477779388
step: 320, loss: 0.03053922951221466
step: 330, loss: 0.04972127825021744
step: 340, loss: 0.01735631562769413
step: 350, loss: 0.0024796936195343733
step: 360, loss: 0.0982542559504509
step: 370, loss: 0.17301581799983978
step: 380, loss: 0.05010942742228508
step: 390, loss: 0.08091989159584045
step: 400, loss: 0.004141402430832386
step: 410, loss: 0.08795445412397385
step: 420, loss: 0.04297689348459244
step: 430, loss: 0.051846180111169815
step: 440, loss: 0.04442611336708069
step: 450, loss: 0.10889556258916855
step: 460, loss: 0.05825203284621239
step: 470, loss: 0.18897472321987152
step: 480, loss: 0.03745898976922035
step: 490, loss: 0.07943129539489746
step: 500, loss: 0.07266537100076675
step: 510, loss: 0.2068154662847519
step: 520, loss: 0.03515585884451866
step: 530, loss: 0.06763948500156403
step: 540, loss: 0.08903439342975616
step: 550, loss: 0.09136288613080978
step: 560, loss: 0.18545322120189667
step: 570, loss: 0.0924544706940651
step: 580, loss: 0.0637524351477623
step: 590, loss: 0.11244240403175354
step: 600, loss: 0.17541417479515076
step: 610, loss: 0.026125960052013397
step: 620, loss: 0.009626340121030807
step: 630, loss: 0.03484182432293892
step: 640, loss: 0.13331520557403564
step: 650, loss: 0.0647997185587883
step: 660, loss: 0.0638173297047615
step: 670, loss: 0.02324162982404232
step: 680, loss: 0.039520055055618286
step: 690, loss: 0.040102649480104446
step: 700, loss: 0.1486106961965561
step: 710, loss: 0.021667316555976868
step: 720, loss: 0.09887650609016418
step: 730, loss: 0.0061791096813976765
step: 740, loss: 0.039968814700841904
step: 750, loss: 0.1317804455757141
step: 760, loss: 0.10336930304765701
step: 770, loss: 0.08894523978233337
step: 780, loss: 0.00011672073014779016
step: 790, loss: 0.1731676459312439
step: 800, loss: 0.09662646055221558
step: 810, loss: 0.02337822876870632
step: 820, loss: 0.08347907662391663
step: 830, loss: 0.019990425556898117
step: 840, loss: 0.04363612085580826
step: 850, loss: 0.07231885194778442
step: 860, loss: 0.06670849025249481
step: 870, loss: 0.07361577451229095
step: 880, loss: 0.04388834908604622
step: 890, loss: 0.019476454704999924
step: 900, loss: 0.15842634439468384
step: 910, loss: 0.07636421173810959
step: 920, loss: 0.04929227754473686
step: 930, loss: 0.06885118782520294
step: 940, loss: 0.01938854344189167
step: 950, loss: 0.08544318377971649
step: 960, loss: 0.0252689179033041
step: 970, loss: 0.154976487159729
step: 980, loss: 0.21616999804973602
step: 990, loss: 0.08045165985822678
step: 1000, loss: 0.08985216915607452
step: 1010, loss: 0.08256183564662933
step: 1020, loss: 0.06955602765083313
step: 1030, loss: 0.07060886919498444
step: 1040, loss: 0.054227862507104874
step: 1050, loss: 0.07570497691631317
step: 1060, loss: 0.20552757382392883
step: 1070, loss: 0.012014195322990417
epoch 11: dev_f1=0.9395784543325526, f1=0.9286384976525822, best_f1=0.9260808926080892
step: 0, loss: 0.08944541960954666
step: 10, loss: 0.13335587084293365
step: 20, loss: 0.04081200435757637
step: 30, loss: 0.04841892793774605
step: 40, loss: 0.002110807690769434
step: 50, loss: 0.08737339079380035
step: 60, loss: 0.11370880156755447
step: 70, loss: 0.037793196737766266
step: 80, loss: 0.04174651950597763
step: 90, loss: 0.06906978785991669
step: 100, loss: 0.06545652449131012
step: 110, loss: 0.12213702499866486
step: 120, loss: 0.15239602327346802
step: 130, loss: 0.13897551596164703
step: 140, loss: 0.05881909281015396
step: 150, loss: 0.21528489887714386
step: 160, loss: 0.090865857899189
step: 170, loss: 0.07534388452768326
step: 180, loss: 0.13293546438217163
step: 190, loss: 0.0681837648153305
step: 200, loss: 0.04716910794377327
step: 210, loss: 0.17089931666851044
step: 220, loss: 0.03390776738524437
step: 230, loss: 0.08410035818815231
step: 240, loss: 0.04757678508758545
step: 250, loss: 0.05705639719963074
step: 260, loss: 0.06293133646249771
step: 270, loss: 0.05353762209415436
step: 280, loss: 0.09868689626455307
step: 290, loss: 0.04634961113333702
step: 300, loss: 0.07384096086025238
step: 310, loss: 0.20403145253658295
step: 320, loss: 0.0007196143269538879
step: 330, loss: 0.0997781828045845
step: 340, loss: 0.08497323095798492
step: 350, loss: 0.08114539831876755
step: 360, loss: 0.14262673258781433
step: 370, loss: 0.06576260924339294
step: 380, loss: 0.0811833068728447
step: 390, loss: 0.02815883792936802
step: 400, loss: 0.030239559710025787
step: 410, loss: 0.039593953639268875
step: 420, loss: 0.11393829435110092
step: 430, loss: 0.015133384615182877
step: 440, loss: 0.0011717869201675057
step: 450, loss: 0.004306129179894924
step: 460, loss: 0.04980691522359848
step: 470, loss: 0.08292818069458008
step: 480, loss: 0.05121653899550438
step: 490, loss: 0.013255307450890541
step: 500, loss: 0.0340011827647686
step: 510, loss: 0.11159243434667587
step: 520, loss: 0.08424245566129684
step: 530, loss: 0.07490147650241852
step: 540, loss: 0.04095204919576645
step: 550, loss: 0.03178020566701889
step: 560, loss: 0.03757300227880478
step: 570, loss: 0.12621480226516724
step: 580, loss: 0.12521076202392578
step: 590, loss: 0.03183970972895622
step: 600, loss: 0.059239160269498825
step: 610, loss: 0.12135286629199982
step: 620, loss: 0.07957954704761505
step: 630, loss: 0.040826741605997086
step: 640, loss: 0.040478385984897614
step: 650, loss: 0.06263112276792526
step: 660, loss: 0.06653429567813873
step: 670, loss: 0.042247455567121506
step: 680, loss: 0.11345192790031433
step: 690, loss: 0.10059859603643417
step: 700, loss: 0.022509202361106873
step: 710, loss: 0.051401179283857346
step: 720, loss: 0.062132034450769424
step: 730, loss: 0.023602882400155067
step: 740, loss: 0.26798316836357117
step: 750, loss: 0.037761140614748
step: 760, loss: 0.05132528394460678
step: 770, loss: 0.09281699359416962
step: 780, loss: 0.03946472331881523
step: 790, loss: 0.041055746376514435
step: 800, loss: 0.08709525316953659
step: 810, loss: 0.06926710903644562
step: 820, loss: 0.0021732777822762728
step: 830, loss: 0.08303055167198181
step: 840, loss: 0.0814826488494873
step: 850, loss: 0.016123469918966293
step: 860, loss: 0.06257238239049911
step: 870, loss: 0.07330302894115448
step: 880, loss: 0.12652958929538727
step: 890, loss: 0.03214007988572121
step: 900, loss: 0.03326784446835518
step: 910, loss: 0.14972135424613953
step: 920, loss: 0.09408164024353027
step: 930, loss: 0.03180087357759476
step: 940, loss: 0.02057713083922863
step: 950, loss: 0.017841866239905357
step: 960, loss: 0.096580870449543
step: 970, loss: 0.030992167070508003
step: 980, loss: 0.044212061911821365
step: 990, loss: 0.10027151554822922
step: 1000, loss: 0.049731895327568054
step: 1010, loss: 0.09761117398738861
step: 1020, loss: 0.0011805890826508403
step: 1030, loss: 0.03322501853108406
step: 1040, loss: 0.08041573315858841
step: 1050, loss: 0.07341378182172775
step: 1060, loss: 0.14935225248336792
step: 1070, loss: 0.001574893482029438
epoch 12: dev_f1=0.9350163627863488, f1=0.9274269557021678, best_f1=0.9260808926080892
step: 0, loss: 0.024785241112113
step: 10, loss: 0.09918060898780823
step: 20, loss: 0.024471145123243332
step: 30, loss: 0.006274103187024593
step: 40, loss: 0.0704735815525055
step: 50, loss: 0.09817076474428177
step: 60, loss: 0.057718075811862946
step: 70, loss: 0.053412411361932755
step: 80, loss: 0.061563149094581604
step: 90, loss: 0.09351207315921783
step: 100, loss: 0.1294955462217331
step: 110, loss: 0.010620072484016418
step: 120, loss: 0.11692608892917633
step: 130, loss: 0.0729570984840393
step: 140, loss: 0.05136871710419655
step: 150, loss: 0.0738370269536972
step: 160, loss: 0.042161568999290466
step: 170, loss: 0.007607711479067802
step: 180, loss: 0.0555519200861454
step: 190, loss: 0.025600675493478775
step: 200, loss: 0.12309183180332184
step: 210, loss: 0.054150864481925964
step: 220, loss: 0.22207137942314148
step: 230, loss: 0.030124885961413383
step: 240, loss: 0.033262357115745544
step: 250, loss: 0.08341879397630692
step: 260, loss: 0.04066811501979828
step: 270, loss: 0.15284903347492218
step: 280, loss: 0.057913679629564285
step: 290, loss: 0.018402893096208572
step: 300, loss: 0.10833363980054855
step: 310, loss: 0.06239626556634903
step: 320, loss: 0.0072755818255245686
step: 330, loss: 0.029894372448325157
step: 340, loss: 0.05713265389204025
step: 350, loss: 0.10267389565706253
step: 360, loss: 0.05047449469566345
step: 370, loss: 0.08104091137647629
step: 380, loss: 0.14856408536434174
step: 390, loss: 0.06632808595895767
step: 400, loss: 0.13676178455352783
step: 410, loss: 0.08488450944423676
step: 420, loss: 0.020138083025813103
step: 430, loss: 0.06929328292608261
step: 440, loss: 0.019906453788280487
step: 450, loss: 0.003943469375371933
step: 460, loss: 0.009558028541505337
step: 470, loss: 0.05929071083664894
step: 480, loss: 0.0005928699974901974
step: 490, loss: 0.0018499029101803899
step: 500, loss: 0.03422293812036514
step: 510, loss: 0.04749234765768051
step: 520, loss: 0.030796900391578674
step: 530, loss: 0.14942771196365356
step: 540, loss: 0.024558499455451965
step: 550, loss: 0.035920463502407074
step: 560, loss: 0.015559720806777477
step: 570, loss: 0.00571393221616745
step: 580, loss: 0.04051000252366066
step: 590, loss: 0.1080966591835022
step: 600, loss: 0.2146216481924057
step: 610, loss: 0.04256005957722664
step: 620, loss: 0.0194694921374321
step: 630, loss: 0.013822857290506363
step: 640, loss: 0.0559028796851635
step: 650, loss: 0.03660891205072403
step: 660, loss: 0.08515579998493195
step: 670, loss: 0.13099154829978943
step: 680, loss: 0.15407536923885345
step: 690, loss: 0.028120102360844612
step: 700, loss: 0.07252322137355804
step: 710, loss: 0.03238673508167267
step: 720, loss: 0.06487028300762177
step: 730, loss: 0.054210662841796875
step: 740, loss: 0.026131441816687584
step: 750, loss: 0.00259604025632143
step: 760, loss: 0.0683111697435379
step: 770, loss: 0.03413068503141403
step: 780, loss: 0.044179171323776245
step: 790, loss: 0.02284756861627102
step: 800, loss: 0.012136003002524376
step: 810, loss: 0.014203907921910286
step: 820, loss: 0.02418607845902443
step: 830, loss: 0.03843524679541588
step: 840, loss: 0.028150271624326706
step: 850, loss: 0.034427497535943985
step: 860, loss: 0.05465442314743996
step: 870, loss: 0.06910877674818039
step: 880, loss: 0.11016128957271576
step: 890, loss: 1.3924970517109614e-05
step: 900, loss: 0.0046709878370165825
step: 910, loss: 0.05256624519824982
step: 920, loss: 0.06660054624080658
step: 930, loss: 0.05100461095571518
step: 940, loss: 2.5629899027990177e-05
step: 950, loss: 0.09408796578645706
step: 960, loss: 0.06858746707439423
step: 970, loss: 0.01175715308636427
step: 980, loss: 0.011646127328276634
step: 990, loss: 0.028956806287169456
step: 1000, loss: 0.036289721727371216
step: 1010, loss: 0.09719201177358627
step: 1020, loss: 0.08981801569461823
step: 1030, loss: 0.04515361785888672
step: 1040, loss: 0.01322203315794468
step: 1050, loss: 0.00025502400239929557
step: 1060, loss: 0.03741731867194176
step: 1070, loss: 0.00951014831662178
epoch 13: dev_f1=0.9311475409836065, f1=0.9287054409005628, best_f1=0.9260808926080892
step: 0, loss: 0.02612304501235485
step: 10, loss: 0.025198649615049362
step: 20, loss: 0.052019938826560974
step: 30, loss: 0.0740867406129837
step: 40, loss: 0.02952566370368004
step: 50, loss: 0.11608915030956268
step: 60, loss: 0.03463808074593544
step: 70, loss: 0.05083611235022545
step: 80, loss: 0.012823441997170448
step: 90, loss: 0.1195107102394104
step: 100, loss: 0.022410405799746513
step: 110, loss: 0.05927678570151329
step: 120, loss: 0.017626335844397545
step: 130, loss: 0.08333569765090942
step: 140, loss: 0.0010892836144194007
step: 150, loss: 0.017822517082095146
step: 160, loss: 0.045830413699150085
step: 170, loss: 0.022528093308210373
step: 180, loss: 0.1360814869403839
step: 190, loss: 0.05591755360364914
step: 200, loss: 0.06504974514245987
step: 210, loss: 0.015713000670075417
step: 220, loss: 0.08335786312818527
step: 230, loss: 0.018351145088672638
step: 240, loss: 0.08454395085573196
step: 250, loss: 0.07196945697069168
step: 260, loss: 0.08889120817184448
step: 270, loss: 0.022981084883213043
step: 280, loss: 0.14215075969696045
step: 290, loss: 0.17297041416168213
step: 300, loss: 0.11793258786201477
step: 310, loss: 0.10977248847484589
step: 320, loss: 0.07329758256673813
step: 330, loss: 0.037769243121147156
step: 340, loss: 0.11774730682373047
step: 350, loss: 0.002208827529102564
step: 360, loss: 0.025655418634414673
step: 370, loss: 0.041397057473659515
step: 380, loss: 0.0781993567943573
step: 390, loss: 0.033677276223897934
step: 400, loss: 0.04792732000350952
step: 410, loss: 0.20298142731189728
step: 420, loss: 0.03873402997851372
step: 430, loss: 0.038511693477630615
step: 440, loss: 0.009125683456659317
step: 450, loss: 0.023351432755589485
step: 460, loss: 0.04688076302409172
step: 470, loss: 0.06222180277109146
step: 480, loss: 0.04500265792012215
step: 490, loss: 0.12489547580480576
step: 500, loss: 0.036387547850608826
step: 510, loss: 0.05263759195804596
step: 520, loss: 0.04804196581244469
step: 530, loss: 0.03660158812999725
step: 540, loss: 0.04525647312402725
step: 550, loss: 0.03660464286804199
step: 560, loss: 0.011413754895329475
step: 570, loss: 0.035412777215242386
step: 580, loss: 0.0005795381730422378
step: 590, loss: 0.06875291466712952
step: 600, loss: 0.005795022007077932
step: 610, loss: 0.02697519212961197
step: 620, loss: 0.04818916693329811
step: 630, loss: 0.13641279935836792
step: 640, loss: 0.019692813977599144
step: 650, loss: 0.030104350298643112
step: 660, loss: 0.06526303291320801
step: 670, loss: 0.07128165662288666
step: 680, loss: 0.07306358963251114
step: 690, loss: 0.031228121370077133
step: 700, loss: 0.12087953090667725
step: 710, loss: 0.04376789554953575
step: 720, loss: 0.04513122886419296
step: 730, loss: 2.269641299790237e-05
step: 740, loss: 0.14821045100688934
step: 750, loss: 0.030753910541534424
step: 760, loss: 0.06355884671211243
step: 770, loss: 0.03959601745009422
step: 780, loss: 0.05735772103071213
step: 790, loss: 0.025448864325881004
step: 800, loss: 0.07162057608366013
step: 810, loss: 0.0277682077139616
step: 820, loss: 0.054931532591581345
step: 830, loss: 0.05743449926376343
step: 840, loss: 0.03551265597343445
step: 850, loss: 0.0019783680327236652
step: 860, loss: 0.01281751412898302
step: 870, loss: 0.03406016156077385
step: 880, loss: 0.039584528654813766
step: 890, loss: 0.09550289064645767
step: 900, loss: 0.09693625569343567
step: 910, loss: 0.06275853514671326
step: 920, loss: 0.03965374827384949
step: 930, loss: 0.05172482132911682
step: 940, loss: 0.048435285687446594
step: 950, loss: 0.03311411663889885
step: 960, loss: 0.036693643778562546
step: 970, loss: 0.14871644973754883
step: 980, loss: 0.008516218513250351
step: 990, loss: 0.03490692749619484
step: 1000, loss: 0.025622781366109848
step: 1010, loss: 0.061466045677661896
step: 1020, loss: 0.09467250108718872
step: 1030, loss: 0.021849222481250763
step: 1040, loss: 0.005967834498733282
step: 1050, loss: 0.04375521093606949
step: 1060, loss: 0.055117033421993256
step: 1070, loss: 0.08130010217428207
epoch 14: dev_f1=0.937095282146161, f1=0.9298000929800094, best_f1=0.9260808926080892
step: 0, loss: 0.0015730614541098475
step: 10, loss: 0.10140185058116913
step: 20, loss: 0.04764028638601303
step: 30, loss: 0.045743659138679504
step: 40, loss: 0.04583274573087692
step: 50, loss: 0.019523698836565018
step: 60, loss: 0.04189787805080414
step: 70, loss: 0.12190193682909012
step: 80, loss: 0.015700731426477432
step: 90, loss: 0.0046977028250694275
step: 100, loss: 0.050510652363300323
step: 110, loss: 0.02729887142777443
step: 120, loss: 0.07713962346315384
step: 130, loss: 0.010528095997869968
step: 140, loss: 0.019370853900909424
step: 150, loss: 0.060349855571985245
step: 160, loss: 0.051433295011520386
step: 170, loss: 0.04568454250693321
step: 180, loss: 0.04125504940748215
step: 190, loss: 0.002982805483043194
step: 200, loss: 0.09351008385419846
step: 210, loss: 0.03699202463030815
step: 220, loss: 0.03609403967857361
step: 230, loss: 0.039685238152742386
step: 240, loss: 0.029019124805927277
step: 250, loss: 0.08622675389051437
step: 260, loss: 0.08828753232955933
step: 270, loss: 0.04517928510904312
step: 280, loss: 0.043957967311143875
step: 290, loss: 0.043505143374204636
step: 300, loss: 0.0878622755408287
step: 310, loss: 0.057578809559345245
step: 320, loss: 0.04720862954854965
step: 330, loss: 0.022648558020591736
step: 340, loss: 0.000851196760777384
step: 350, loss: 0.029432831332087517
step: 360, loss: 0.09765329957008362
step: 370, loss: 0.08801185339689255
step: 380, loss: 0.013287043198943138
step: 390, loss: 0.02715642936527729
step: 400, loss: 0.03677130863070488
step: 410, loss: 0.001113952836021781
step: 420, loss: 0.010940058156847954
step: 430, loss: 0.015228316187858582
step: 440, loss: 0.014425879344344139
step: 450, loss: 0.037580110132694244
step: 460, loss: 0.04530844837427139
step: 470, loss: 0.10798683017492294
step: 480, loss: 0.03779565915465355
step: 490, loss: 0.01992546208202839
step: 500, loss: 0.021267535164952278
step: 510, loss: 0.135486900806427
step: 520, loss: 0.02809440717101097
step: 530, loss: 0.059638962149620056
step: 540, loss: 0.05347385257482529
step: 550, loss: 0.0998968631029129
step: 560, loss: 0.10553473979234695
step: 570, loss: 0.07388711720705032
step: 580, loss: 0.021675871685147285
step: 590, loss: 0.04667402058839798
step: 600, loss: 0.03708149120211601
step: 610, loss: 0.020740510895848274
step: 620, loss: 0.0651145949959755
step: 630, loss: 0.04977851361036301
step: 640, loss: 0.048603370785713196
step: 650, loss: 0.0663602277636528
step: 660, loss: 0.028378747403621674
step: 670, loss: 0.057825472205877304
step: 680, loss: 0.0632098987698555
step: 690, loss: 0.0025202881079167128
step: 700, loss: 0.05774768069386482
step: 710, loss: 0.015215417370200157
step: 720, loss: 0.10289894789457321
step: 730, loss: 0.016087960451841354
step: 740, loss: 0.04992981255054474
step: 750, loss: 0.04969014972448349
step: 760, loss: 0.06879473477602005
step: 770, loss: 0.04153543338179588
step: 780, loss: 0.03483721613883972
step: 790, loss: 0.041723545640707016
step: 800, loss: 0.1993418037891388
step: 810, loss: 0.05464313551783562
step: 820, loss: 0.05060271918773651
step: 830, loss: 0.07075666636228561
step: 840, loss: 0.015384967438876629
step: 850, loss: 0.058684010058641434
step: 860, loss: 0.05249771848320961
step: 870, loss: 0.08379510790109634
step: 880, loss: 0.04105756804347038
step: 890, loss: 0.0982246920466423
step: 900, loss: 0.01194929052144289
step: 910, loss: 0.08162912726402283
step: 920, loss: 0.03721947222948074
step: 930, loss: 0.02670838125050068
step: 940, loss: 0.0731169804930687
step: 950, loss: 0.029915187507867813
step: 960, loss: 0.0646926686167717
step: 970, loss: 0.04405064880847931
step: 980, loss: 0.0026369523257017136
step: 990, loss: 0.04936099424958229
step: 1000, loss: 0.08437571674585342
step: 1010, loss: 0.0676741749048233
step: 1020, loss: 0.05009344965219498
step: 1030, loss: 0.08447463065385818
step: 1040, loss: 0.026418566703796387
step: 1050, loss: 0.03550557419657707
step: 1060, loss: 0.019061068072915077
step: 1070, loss: 0.03387593850493431
epoch 15: dev_f1=0.935813953488372, f1=0.9302973977695168, best_f1=0.9260808926080892
step: 0, loss: 0.011031337082386017
step: 10, loss: 0.0007902311626821756
step: 20, loss: 0.054254867136478424
step: 30, loss: 0.03347950801253319
step: 40, loss: 0.02588418312370777
step: 50, loss: 0.029343586415052414
step: 60, loss: 9.864514140645042e-06
step: 70, loss: 0.06997832655906677
step: 80, loss: 0.023810526356101036
step: 90, loss: 0.018619010224938393
step: 100, loss: 0.07367110252380371
step: 110, loss: 0.05013404041528702
step: 120, loss: 0.046042971312999725
step: 130, loss: 0.01854477822780609
step: 140, loss: 0.141719251871109
step: 150, loss: 0.06404493004083633
step: 160, loss: 0.12896513938903809
step: 170, loss: 0.09321046620607376
step: 180, loss: 0.017230061814188957
step: 190, loss: 0.01635868288576603
step: 200, loss: 0.03428107500076294
step: 210, loss: 0.0005131352227181196
step: 220, loss: 0.037788886576890945
step: 230, loss: 0.11739622056484222
step: 240, loss: 0.018747327849268913
step: 250, loss: 0.07325826585292816
step: 260, loss: 1.4982770153437741e-05
step: 270, loss: 0.04011452943086624
step: 280, loss: 0.05750497058033943
step: 290, loss: 0.03513496741652489
step: 300, loss: 0.06510535627603531
step: 310, loss: 0.018892763182520866
step: 320, loss: 0.07345790416002274
step: 330, loss: 0.03647961467504501
step: 340, loss: 0.08564209938049316
step: 350, loss: 0.14076104760169983
step: 360, loss: 0.06762401759624481
step: 370, loss: 0.044124867767095566
step: 380, loss: 0.0831398069858551
step: 390, loss: 0.06783651560544968
step: 400, loss: 0.06778521090745926
step: 410, loss: 0.12420319765806198
step: 420, loss: 0.03862376511096954
step: 430, loss: 0.00012664476525969803
step: 440, loss: 0.10222093760967255
step: 450, loss: 0.16963376104831696
step: 460, loss: 0.059808604419231415
step: 470, loss: 0.01174825057387352
step: 480, loss: 0.012739736586809158
step: 490, loss: 0.04543352127075195
step: 500, loss: 0.016848735511302948
step: 510, loss: 0.08182749897241592
step: 520, loss: 0.052081555128097534
step: 530, loss: 0.0818190798163414
step: 540, loss: 0.08135972917079926
step: 550, loss: 0.014320535585284233
step: 560, loss: 0.06232897937297821
step: 570, loss: 0.036593131721019745
step: 580, loss: 0.015627622604370117
step: 590, loss: 0.0024279169738292694
step: 600, loss: 0.03091524727642536
step: 610, loss: 0.02768756076693535
step: 620, loss: 0.04495443403720856
step: 630, loss: 0.06427905708551407
step: 640, loss: 0.026978805661201477
step: 650, loss: 0.0792907103896141
step: 660, loss: 0.10240916907787323
step: 670, loss: 0.04854556918144226
step: 680, loss: 0.030533744022250175
step: 690, loss: 0.00010949863644782454
step: 700, loss: 0.06368554383516312
step: 710, loss: 0.029147865250706673
step: 720, loss: 0.019376104697585106
step: 730, loss: 0.05152439698576927
step: 740, loss: 0.020871300250291824
step: 750, loss: 0.03599102422595024
step: 760, loss: 0.10339957475662231
step: 770, loss: 0.06134890392422676
step: 780, loss: 0.06606568396091461
step: 790, loss: 0.019324231892824173
step: 800, loss: 0.055131033062934875
step: 810, loss: 0.018474852666258812
step: 820, loss: 0.12490088492631912
step: 830, loss: 0.05972597375512123
step: 840, loss: 0.04813374578952789
step: 850, loss: 0.04512125998735428
step: 860, loss: 0.04525573551654816
step: 870, loss: 0.03695841133594513
step: 880, loss: 0.027188962325453758
step: 890, loss: 0.03043140098452568
step: 900, loss: 6.892024248372763e-05
step: 910, loss: 0.09674517810344696
step: 920, loss: 0.1061791479587555
step: 930, loss: 0.0719418004155159
step: 940, loss: 0.0031994252931326628
step: 950, loss: 0.04771409183740616
step: 960, loss: 0.019030621275305748
step: 970, loss: 0.07147727906703949
step: 980, loss: 0.04214973747730255
step: 990, loss: 0.0388372540473938
step: 1000, loss: 0.0002397708740318194
step: 1010, loss: 0.04972393810749054
step: 1020, loss: 0.09326744079589844
step: 1030, loss: 0.05650626868009567
step: 1040, loss: 0.04435517638921738
step: 1050, loss: 0.06209028884768486
step: 1060, loss: 0.04575437307357788
step: 1070, loss: 0.07624127715826035
epoch 16: dev_f1=0.9307832422586522, f1=0.9242700729927007, best_f1=0.9260808926080892
step: 0, loss: 0.01321016438305378
step: 10, loss: 0.024480972439050674
step: 20, loss: 0.08477791398763657
step: 30, loss: 0.04197186604142189
step: 40, loss: 0.02668331377208233
step: 50, loss: 0.0356653667986393
step: 60, loss: 0.03992753475904465
step: 70, loss: 0.03997226431965828
step: 80, loss: 0.025095010176301003
step: 90, loss: 0.05991562455892563
step: 100, loss: 0.028177879750728607
step: 110, loss: 0.018463406711816788
step: 120, loss: 0.0806775614619255
step: 130, loss: 0.06520712375640869
step: 140, loss: 0.04397929459810257
step: 150, loss: 0.13260819017887115
step: 160, loss: 0.072728231549263
step: 170, loss: 0.026332074776291847
step: 180, loss: 0.09401027113199234
step: 190, loss: 2.994448550452944e-05
step: 200, loss: 0.03605284169316292
step: 210, loss: 0.16814468801021576
step: 220, loss: 0.013804876245558262
step: 230, loss: 0.08964855968952179
step: 240, loss: 0.06069040670990944
step: 250, loss: 0.0008759793126955628
step: 260, loss: 0.04382995143532753
step: 270, loss: 0.05219985172152519
step: 280, loss: 4.12291192333214e-05
step: 290, loss: 0.009691333398222923
step: 300, loss: 0.10603825747966766
step: 310, loss: 0.03935155272483826
step: 320, loss: 0.035855527967214584
step: 330, loss: 0.04615528881549835
step: 340, loss: 0.040043603628873825
step: 350, loss: 0.04288214445114136
step: 360, loss: 0.024637063965201378
step: 370, loss: 0.0936354473233223
step: 380, loss: 0.10490037500858307
step: 390, loss: 0.019270313903689384
step: 400, loss: 0.02445055916905403
step: 410, loss: 0.049275435507297516
step: 420, loss: 0.00010655702499207109
step: 430, loss: 0.015005373395979404
step: 440, loss: 0.00010001257760450244
step: 450, loss: 0.05513497814536095
step: 460, loss: 0.011555414646863937
step: 470, loss: 0.0014806106919422746
step: 480, loss: 0.026304854080080986
step: 490, loss: 0.0619862899184227
step: 500, loss: 0.008257596753537655
step: 510, loss: 1.9679175238707103e-05
step: 520, loss: 0.055828750133514404
step: 530, loss: 0.04530639946460724
step: 540, loss: 0.05990738049149513
step: 550, loss: 0.020187528803944588
step: 560, loss: 0.0020098695531487465
step: 570, loss: 0.037541113793849945
step: 580, loss: 0.03388504311442375
step: 590, loss: 0.044701721519231796
step: 600, loss: 0.014291905798017979
step: 610, loss: 0.0003398922272026539
step: 620, loss: 0.028028491884469986
step: 630, loss: 0.03200666233897209
step: 640, loss: 0.026660703122615814
step: 650, loss: 0.03884950280189514
step: 660, loss: 0.056352268904447556
step: 670, loss: 0.10642685741186142
step: 680, loss: 3.9595022826688364e-05
step: 690, loss: 0.02214517630636692
step: 700, loss: 0.01963154226541519
step: 710, loss: 3.621763244154863e-05
step: 720, loss: 0.10815475136041641
step: 730, loss: 0.04553946480154991
step: 740, loss: 0.03247235715389252
step: 750, loss: 0.06117110326886177
step: 760, loss: 0.03300047293305397
step: 770, loss: 0.063261978328228
step: 780, loss: 0.02459435909986496
step: 790, loss: 0.05788825824856758
step: 800, loss: 0.06635694950819016
step: 810, loss: 0.0023301783949136734
step: 820, loss: 0.09552177786827087
step: 830, loss: 0.049710314720869064
step: 840, loss: 0.03688514232635498
step: 850, loss: 0.06809739023447037
step: 860, loss: 0.017588729038834572
step: 870, loss: 0.03024701029062271
step: 880, loss: 2.0688603399321437e-05
step: 890, loss: 0.10920441150665283
step: 900, loss: 0.028967158868908882
step: 910, loss: 0.016884760931134224
step: 920, loss: 0.05174470320343971
step: 930, loss: 0.04396214336156845
step: 940, loss: 0.036903850734233856
step: 950, loss: 0.06962143629789352
step: 960, loss: 0.041275184601545334
step: 970, loss: 0.02148771472275257
step: 980, loss: 0.040198951959609985
step: 990, loss: 0.023930516093969345
step: 1000, loss: 0.049229174852371216
step: 1010, loss: 0.001023077522404492
step: 1020, loss: 0.002582704881206155
step: 1030, loss: 0.07982072979211807
step: 1040, loss: 0.06487816572189331
step: 1050, loss: 0.00012126483488827944
step: 1060, loss: 0.046861931681632996
step: 1070, loss: 0.030928490683436394
epoch 17: dev_f1=0.9340148698884759, f1=0.9261495587552253, best_f1=0.9260808926080892
step: 0, loss: 0.1416727602481842
step: 10, loss: 0.05933266133069992
step: 20, loss: 0.008199424482882023
step: 30, loss: 0.04217740520834923
step: 40, loss: 0.026125766336917877
step: 50, loss: 0.004795046988874674
step: 60, loss: 0.016027303412556648
step: 70, loss: 0.08068688213825226
step: 80, loss: 0.04889007285237312
step: 90, loss: 0.057438019663095474
step: 100, loss: 0.0005855849594809115
step: 110, loss: 0.13080599904060364
step: 120, loss: 0.03365078568458557
step: 130, loss: 0.043672796338796616
step: 140, loss: 0.033927612006664276
step: 150, loss: 0.029550958424806595
step: 160, loss: 0.04190322384238243
step: 170, loss: 0.02680032327771187
step: 180, loss: 0.01674615405499935
step: 190, loss: 0.01874343305826187
step: 200, loss: 0.06931629031896591
step: 210, loss: 0.00023197571863420308
step: 220, loss: 0.05033924803137779
step: 230, loss: 0.05547086149454117
step: 240, loss: 9.499225416220725e-05
step: 250, loss: 0.010434096679091454
step: 260, loss: 0.01119790319353342
step: 270, loss: 0.10412603616714478
step: 280, loss: 0.09627045691013336
step: 290, loss: 0.07303503155708313
step: 300, loss: 0.02004087157547474
step: 310, loss: 0.05431896075606346
step: 320, loss: 0.003677335334941745
step: 330, loss: 0.04518064856529236
step: 340, loss: 0.023589881137013435
step: 350, loss: 0.02070324681699276
step: 360, loss: 0.04879063367843628
step: 370, loss: 0.09045906364917755
step: 380, loss: 0.10197557508945465
step: 390, loss: 1.816356416384224e-05
step: 400, loss: 0.057500533759593964
step: 410, loss: 0.08880820870399475
step: 420, loss: 0.038465119898319244
step: 430, loss: 5.426227653515525e-05
step: 440, loss: 0.041377417743206024
step: 450, loss: 0.08802513033151627
step: 460, loss: 0.047177087515592575
step: 470, loss: 0.03738810494542122
step: 480, loss: 0.021653644740581512
step: 490, loss: 0.012775490060448647
step: 500, loss: 0.040083106607198715
step: 510, loss: 0.034046072512865067
step: 520, loss: 0.0004098679928574711
step: 530, loss: 7.767146598780528e-05
step: 540, loss: 0.013953102752566338
step: 550, loss: 0.09412422776222229
step: 560, loss: 0.08669076859951019
step: 570, loss: 0.015489979647099972
step: 580, loss: 0.017420820891857147
step: 590, loss: 0.050368648022413254
step: 600, loss: 0.009381863288581371
step: 610, loss: 0.04245609790086746
step: 620, loss: 0.01767793670296669
step: 630, loss: 0.053173039108514786
step: 640, loss: 0.01316994521766901
step: 650, loss: 0.05341019108891487
step: 660, loss: 0.04489628225564957
step: 670, loss: 0.056915536522865295
step: 680, loss: 0.07858311384916306
step: 690, loss: 0.06283518671989441
step: 700, loss: 0.05485543981194496
step: 710, loss: 0.11430491507053375
step: 720, loss: 0.28406262397766113
step: 730, loss: 0.02626720257103443
step: 740, loss: 0.06383704394102097
step: 750, loss: 5.221343963057734e-05
step: 760, loss: 0.10296119004487991
step: 770, loss: 0.0840318500995636
step: 780, loss: 0.054711949080228806
step: 790, loss: 0.06670475006103516
step: 800, loss: 0.1000770553946495
step: 810, loss: 0.04419053718447685
step: 820, loss: 0.047251444309949875
step: 830, loss: 0.06009471043944359
step: 840, loss: 0.028121884912252426
step: 850, loss: 0.043290577828884125
step: 860, loss: 0.1099260225892067
step: 870, loss: 0.07652272284030914
step: 880, loss: 0.041341036558151245
step: 890, loss: 0.05023219808936119
step: 900, loss: 0.0706346407532692
step: 910, loss: 0.01816079393029213
step: 920, loss: 0.040969785302877426
step: 930, loss: 0.03249945491552353
step: 940, loss: 0.054314278066158295
step: 950, loss: 0.019422944635152817
step: 960, loss: 0.04048784822225571
step: 970, loss: 0.03995339572429657
step: 980, loss: 0.0024205048102885485
step: 990, loss: 0.08434265106916428
step: 1000, loss: 0.08794824033975601
step: 1010, loss: 0.033489253371953964
step: 1020, loss: 0.14005224406719208
step: 1030, loss: 0.1058550626039505
step: 1040, loss: 0.0692063719034195
step: 1050, loss: 0.04978638514876366
step: 1060, loss: 0.02190694399178028
step: 1070, loss: 0.05133300647139549
epoch 18: dev_f1=0.9334574220567706, f1=0.9290382819794585, best_f1=0.9260808926080892
step: 0, loss: 0.04119197279214859
step: 10, loss: 0.05712047591805458
step: 20, loss: 0.04239358752965927
step: 30, loss: 0.014386221766471863
step: 40, loss: 0.01946219988167286
step: 50, loss: 0.0305866077542305
step: 60, loss: 0.0682067945599556
step: 70, loss: 0.04167819768190384
step: 80, loss: 0.007512352894991636
step: 90, loss: 0.037387266755104065
step: 100, loss: 0.027418138459324837
step: 110, loss: 0.020334716886281967
step: 120, loss: 0.09505237638950348
step: 130, loss: 0.045654766261577606
step: 140, loss: 0.0330355279147625
step: 150, loss: 0.0010089605348184705
step: 160, loss: 0.004798372741788626
step: 170, loss: 0.013515151105821133
step: 180, loss: 0.11613471060991287
step: 190, loss: 0.016940975561738014
step: 200, loss: 0.1103978306055069
step: 210, loss: 0.0439826063811779
step: 220, loss: 0.06865465641021729
step: 230, loss: 0.0438864640891552
step: 240, loss: 0.03176027163863182
step: 250, loss: 0.07204428315162659
step: 260, loss: 0.022284304723143578
step: 270, loss: 0.04552203789353371
step: 280, loss: 0.05491575226187706
step: 290, loss: 0.09345334023237228
step: 300, loss: 0.052800554782152176
step: 310, loss: 0.0425812229514122
step: 320, loss: 0.057024020701646805
step: 330, loss: 0.04920351877808571
step: 340, loss: 0.06044502183794975
step: 350, loss: 0.03321435675024986
step: 360, loss: 0.02163357473909855
step: 370, loss: 0.01882774569094181
step: 380, loss: 0.06900037825107574
step: 390, loss: 0.0024385987780988216
step: 400, loss: 0.09948758780956268
step: 410, loss: 0.00591245898976922
step: 420, loss: 4.424833969096653e-05
step: 430, loss: 0.03254580497741699
step: 440, loss: 0.033189497888088226
step: 450, loss: 0.04035239666700363
step: 460, loss: 0.058358628302812576
step: 470, loss: 0.0611724779009819
step: 480, loss: 0.04257429763674736
step: 490, loss: 0.03322617709636688
step: 500, loss: 0.06517547369003296
step: 510, loss: 0.04142395779490471
step: 520, loss: 0.04195412993431091
step: 530, loss: 0.019357364624738693
step: 540, loss: 0.06634441018104553
step: 550, loss: 0.03501897677779198
step: 560, loss: 1.816386247810442e-05
step: 570, loss: 0.08588451892137527
step: 580, loss: 0.018870780244469643
step: 590, loss: 0.07622944563627243
step: 600, loss: 0.06737089157104492
step: 610, loss: 0.05779959633946419
step: 620, loss: 0.04591436684131622
step: 630, loss: 0.08869631588459015
step: 640, loss: 0.10799751430749893
step: 650, loss: 0.01857760176062584
step: 660, loss: 0.05775071308016777
step: 670, loss: 0.0667123943567276
step: 680, loss: 0.025596819818019867
step: 690, loss: 0.051758699119091034
step: 700, loss: 0.0192563459277153
step: 710, loss: 0.03361184149980545
step: 720, loss: 0.04444308206439018
step: 730, loss: 0.021684832870960236
step: 740, loss: 0.04245521500706673
step: 750, loss: 0.002967445645481348
step: 760, loss: 0.06775711476802826
step: 770, loss: 0.08709090948104858
step: 780, loss: 0.0805993601679802
step: 790, loss: 0.034311335533857346
step: 800, loss: 0.026862408965826035
step: 810, loss: 0.02104870416224003
step: 820, loss: 0.07088334113359451
step: 830, loss: 0.03356518596410751
step: 840, loss: 0.06288500130176544
step: 850, loss: 0.08099053055047989
step: 860, loss: 0.037337206304073334
step: 870, loss: 0.025845732539892197
step: 880, loss: 0.0013173508923500776
step: 890, loss: 0.035434674471616745
step: 900, loss: 0.011620300821959972
step: 910, loss: 0.05478407070040703
step: 920, loss: 0.01458846963942051
step: 930, loss: 0.019272448495030403
step: 940, loss: 0.056691091507673264
step: 950, loss: 0.00021596888836938888
step: 960, loss: 0.010132094845175743
step: 970, loss: 0.058176279067993164
step: 980, loss: 0.04051198065280914
step: 990, loss: 0.08703360706567764
step: 1000, loss: 0.022373219951987267
step: 1010, loss: 0.12511911988258362
step: 1020, loss: 0.008816441521048546
step: 1030, loss: 0.11091908812522888
step: 1040, loss: 0.0806012824177742
step: 1050, loss: 0.013855762779712677
step: 1060, loss: 0.021550707519054413
step: 1070, loss: 0.06217126548290253
epoch 19: dev_f1=0.9335192933519293, f1=0.9300373134328358, best_f1=0.9260808926080892
step: 0, loss: 0.11941848695278168
step: 10, loss: 0.0013817171566188335
step: 20, loss: 0.03673112392425537
step: 30, loss: 0.05004536360502243
step: 40, loss: 0.0004178381059318781
step: 50, loss: 3.5308610677020624e-05
step: 60, loss: 0.028486644849181175
step: 70, loss: 0.0002960322017315775
step: 80, loss: 0.05091258883476257
step: 90, loss: 0.04360971227288246
step: 100, loss: 1.4166919754643459e-05
step: 110, loss: 0.0245409794151783
step: 120, loss: 0.018391508609056473
step: 130, loss: 0.032046329230070114
step: 140, loss: 0.11497849971055984
step: 150, loss: 0.0001180639592348598
step: 160, loss: 0.0542839840054512
step: 170, loss: 0.05859467014670372
step: 180, loss: 0.08249955624341965
step: 190, loss: 0.1045452430844307
step: 200, loss: 0.03787512704730034
step: 210, loss: 0.04702934995293617
step: 220, loss: 0.026616699993610382
step: 230, loss: 0.02005087397992611
step: 240, loss: 0.010713892988860607
step: 250, loss: 0.0384061224758625
step: 260, loss: 0.00020068950834684074
step: 270, loss: 0.043208248913288116
step: 280, loss: 0.05931588634848595
step: 290, loss: 0.04547441378235817
step: 300, loss: 0.03937520831823349
step: 310, loss: 0.10658825933933258
step: 320, loss: 0.030165985226631165
step: 330, loss: 0.01050455030053854
step: 340, loss: 0.013524414971470833
step: 350, loss: 0.004043215420097113
step: 360, loss: 0.034639474004507065
step: 370, loss: 0.0811321809887886
step: 380, loss: 0.043454959988594055
step: 390, loss: 0.0748247280716896
step: 400, loss: 0.02274768240749836
step: 410, loss: 0.08792948722839355
step: 420, loss: 0.028709694743156433
step: 430, loss: 0.022794952616095543
step: 440, loss: 0.01925804652273655
step: 450, loss: 0.03560856729745865
step: 460, loss: 0.05472789704799652
step: 470, loss: 0.006598459556698799
step: 480, loss: 0.016727996990084648
step: 490, loss: 0.04291258752346039
step: 500, loss: 0.034943588078022
step: 510, loss: 0.014435704797506332
step: 520, loss: 0.04493936523795128
step: 530, loss: 0.015995491296052933
step: 540, loss: 0.04643583670258522
step: 550, loss: 0.10633920133113861
step: 560, loss: 0.03329882025718689
step: 570, loss: 0.03464902937412262
step: 580, loss: 0.032478392124176025
step: 590, loss: 0.0262930728495121
step: 600, loss: 0.07492876797914505
step: 610, loss: 0.04651261866092682
step: 620, loss: 0.04856592044234276
step: 630, loss: 0.03103206679224968
step: 640, loss: 0.04112768918275833
step: 650, loss: 0.08316910266876221
step: 660, loss: 0.04608204960823059
step: 670, loss: 0.043506231158971786
step: 680, loss: 0.025269780308008194
step: 690, loss: 0.018791619688272476
step: 700, loss: 0.016609707847237587
step: 710, loss: 0.025045355781912804
step: 720, loss: 0.0647616907954216
step: 730, loss: 0.050791122019290924
step: 740, loss: 0.023929404094815254
step: 750, loss: 0.02189180999994278
step: 760, loss: 0.012207139283418655
step: 770, loss: 0.11093860119581223
step: 780, loss: 0.05022330954670906
step: 790, loss: 0.0009465380571782589
step: 800, loss: 0.02949773333966732
step: 810, loss: 0.05244056135416031
step: 820, loss: 0.022002194076776505
step: 830, loss: 0.07210414856672287
step: 840, loss: 0.03094828873872757
step: 850, loss: 0.04006940498948097
step: 860, loss: 0.02053644508123398
step: 870, loss: 0.039355695247650146
step: 880, loss: 0.017729122191667557
step: 890, loss: 0.029173770919442177
step: 900, loss: 0.060312673449516296
step: 910, loss: 0.003337639616802335
step: 920, loss: 0.08700688183307648
step: 930, loss: 0.04750717058777809
step: 940, loss: 0.08298282325267792
step: 950, loss: 0.020364101976156235
step: 960, loss: 0.0362195186316967
step: 970, loss: 0.06161034107208252
step: 980, loss: 0.028787903487682343
step: 990, loss: 0.01518124621361494
step: 1000, loss: 0.02017485722899437
step: 1010, loss: 0.0295425895601511
step: 1020, loss: 0.08298980444669724
step: 1030, loss: 0.033891815692186356
step: 1040, loss: 0.01813216134905815
step: 1050, loss: 0.06320679187774658
step: 1060, loss: 0.06119438260793686
step: 1070, loss: 0.06238061189651489
epoch 20: dev_f1=0.9329608938547487, f1=0.9300373134328358, best_f1=0.9260808926080892
