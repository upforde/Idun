cuda
Device: cuda
step: 0, loss: 0.6695940494537354
step: 10, loss: 0.6687751412391663
step: 20, loss: 0.6084815263748169
step: 30, loss: 0.4045323133468628
step: 40, loss: 0.3154122531414032
step: 50, loss: 0.31753045320510864
step: 60, loss: 0.27015551924705505
step: 70, loss: 0.3461325764656067
step: 80, loss: 0.15013578534126282
step: 90, loss: 0.20064693689346313
step: 100, loss: 0.15624606609344482
step: 110, loss: 0.33142179250717163
step: 120, loss: 0.2954752743244171
step: 130, loss: 0.19529950618743896
step: 140, loss: 0.18215492367744446
step: 150, loss: 0.18920718133449554
step: 160, loss: 0.1821136176586151
step: 170, loss: 0.2730291485786438
step: 180, loss: 0.19773858785629272
step: 190, loss: 0.0959387719631195
step: 200, loss: 0.24494439363479614
step: 210, loss: 0.24114592373371124
step: 220, loss: 0.1957448273897171
step: 230, loss: 0.1325613409280777
step: 240, loss: 0.10295918583869934
step: 250, loss: 0.20310679078102112
step: 260, loss: 0.17087873816490173
step: 270, loss: 0.16210518777370453
step: 280, loss: 0.1517811417579651
step: 290, loss: 0.13091909885406494
step: 300, loss: 0.18383538722991943
step: 310, loss: 0.07700958847999573
step: 320, loss: 0.22351455688476562
step: 330, loss: 0.0970344990491867
step: 340, loss: 0.1867845505475998
step: 350, loss: 0.10955400764942169
step: 360, loss: 0.21676120162010193
step: 370, loss: 0.10763563215732574
step: 380, loss: 0.05342784523963928
step: 390, loss: 0.08671250194311142
step: 400, loss: 0.025347551330924034
step: 410, loss: 0.2068483978509903
step: 420, loss: 0.1921839863061905
step: 430, loss: 0.15129674971103668
step: 440, loss: 0.17809058725833893
step: 450, loss: 0.2694740295410156
step: 460, loss: 0.1095680221915245
step: 470, loss: 0.2138264924287796
step: 480, loss: 0.19335711002349854
step: 490, loss: 0.18596301972866058
step: 500, loss: 0.06669839471578598
step: 510, loss: 0.07484721392393112
step: 520, loss: 0.13684093952178955
step: 530, loss: 0.30716264247894287
step: 540, loss: 0.0735618844628334
step: 550, loss: 0.13756145536899567
step: 560, loss: 0.11464875191450119
step: 570, loss: 0.10010693967342377
step: 580, loss: 0.08931195735931396
step: 590, loss: 0.17789679765701294
step: 600, loss: 0.062231071293354034
step: 610, loss: 0.06835321336984634
step: 620, loss: 0.08518920838832855
step: 630, loss: 0.1893938183784485
step: 640, loss: 0.11502991616725922
step: 650, loss: 0.10812047123908997
step: 660, loss: 0.11907582730054855
step: 670, loss: 0.188956156373024
step: 680, loss: 0.1271994411945343
step: 690, loss: 0.18515688180923462
step: 700, loss: 0.20575828850269318
step: 710, loss: 0.1295379102230072
step: 720, loss: 0.10008507966995239
step: 730, loss: 0.03849104046821594
step: 740, loss: 0.22044631838798523
step: 750, loss: 0.1200883761048317
step: 760, loss: 0.09626998752355576
step: 770, loss: 0.14177565276622772
step: 780, loss: 0.07967956364154816
step: 790, loss: 0.11347224563360214
step: 800, loss: 0.26126089692115784
step: 810, loss: 0.05906802788376808
step: 820, loss: 0.2594381272792816
step: 830, loss: 0.26859134435653687
step: 840, loss: 0.19446690380573273
step: 850, loss: 0.15260599553585052
step: 860, loss: 0.11184243112802505
step: 870, loss: 0.0755000188946724
step: 880, loss: 0.08092322200536728
step: 890, loss: 0.06412652879953384
step: 900, loss: 0.05904519557952881
step: 910, loss: 0.13240590691566467
step: 920, loss: 0.16435977816581726
step: 930, loss: 0.19480712711811066
step: 940, loss: 0.13519413769245148
step: 950, loss: 0.07596644014120102
step: 960, loss: 0.10813672840595245
step: 970, loss: 0.18648552894592285
step: 980, loss: 0.11022387444972992
step: 990, loss: 0.054031454026699066
step: 1000, loss: 0.14819782972335815
step: 1010, loss: 0.3505792021751404
step: 1020, loss: 0.09915607422590256
step: 1030, loss: 0.11926741898059845
step: 1040, loss: 0.1634104996919632
step: 1050, loss: 0.10284426808357239
step: 1060, loss: 0.06528017669916153
step: 1070, loss: 0.13271194696426392
epoch 1: dev_f1=0.929551692589204, f1=0.923286427598729, best_f1=0.923286427598729
step: 0, loss: 0.20181025564670563
step: 10, loss: 0.18818676471710205
step: 20, loss: 0.10757669061422348
step: 30, loss: 0.10485096275806427
step: 40, loss: 0.17816457152366638
step: 50, loss: 0.1032862439751625
step: 60, loss: 0.03850233182311058
step: 70, loss: 0.23206715285778046
step: 80, loss: 0.08673727512359619
step: 90, loss: 0.11457446217536926
step: 100, loss: 0.2597414553165436
step: 110, loss: 0.16562645137310028
step: 120, loss: 0.06658503413200378
step: 130, loss: 0.10987884551286697
step: 140, loss: 0.22223219275474548
step: 150, loss: 0.11066560447216034
step: 160, loss: 0.14801761507987976
step: 170, loss: 0.15484917163848877
step: 180, loss: 0.0379350446164608
step: 190, loss: 0.1545378565788269
step: 200, loss: 0.1419999599456787
step: 210, loss: 0.12027442455291748
step: 220, loss: 0.14388209581375122
step: 230, loss: 0.05952150747179985
step: 240, loss: 0.12008433043956757
step: 250, loss: 0.11255378276109695
step: 260, loss: 0.2223564088344574
step: 270, loss: 0.18604005873203278
step: 280, loss: 0.11117566376924515
step: 290, loss: 0.09601611644029617
step: 300, loss: 0.12991739809513092
step: 310, loss: 0.05211086943745613
step: 320, loss: 0.1787126213312149
step: 330, loss: 0.11283832788467407
step: 340, loss: 0.14835628867149353
step: 350, loss: 0.0321783572435379
step: 360, loss: 0.08688420057296753
step: 370, loss: 0.20385318994522095
step: 380, loss: 0.0506548136472702
step: 390, loss: 0.10653725266456604
step: 400, loss: 0.07019080221652985
step: 410, loss: 0.10792145878076553
step: 420, loss: 0.126593217253685
step: 430, loss: 0.054546039551496506
step: 440, loss: 0.09912893176078796
step: 450, loss: 0.24196484684944153
step: 460, loss: 0.10927769541740417
step: 470, loss: 0.25542330741882324
step: 480, loss: 0.1144949421286583
step: 490, loss: 0.04989146441221237
step: 500, loss: 0.13082148134708405
step: 510, loss: 0.11619483679533005
step: 520, loss: 0.03773949667811394
step: 530, loss: 0.05543064698576927
step: 540, loss: 0.1067098081111908
step: 550, loss: 0.16591015458106995
step: 560, loss: 0.14818017184734344
step: 570, loss: 0.10468783229589462
step: 580, loss: 0.21133831143379211
step: 590, loss: 0.1275525987148285
step: 600, loss: 0.19410035014152527
step: 610, loss: 0.18499180674552917
step: 620, loss: 0.1966235339641571
step: 630, loss: 0.20170481503009796
step: 640, loss: 0.20001092553138733
step: 650, loss: 0.14261740446090698
step: 660, loss: 0.0714624673128128
step: 670, loss: 0.08784119039773941
step: 680, loss: 0.1259298324584961
step: 690, loss: 0.04305626451969147
step: 700, loss: 0.18686658143997192
step: 710, loss: 0.13156522810459137
step: 720, loss: 0.05461294203996658
step: 730, loss: 0.016828201711177826
step: 740, loss: 0.11715411394834518
step: 750, loss: 0.15884174406528473
step: 760, loss: 0.07928014546632767
step: 770, loss: 0.16211016476154327
step: 780, loss: 0.11066694557666779
step: 790, loss: 0.09779400378465652
step: 800, loss: 0.03703004866838455
step: 810, loss: 0.09538310021162033
step: 820, loss: 0.11129855364561081
step: 830, loss: 0.04513155668973923
step: 840, loss: 0.17051757872104645
step: 850, loss: 0.07995044440031052
step: 860, loss: 0.06324305385351181
step: 870, loss: 0.12992282211780548
step: 880, loss: 0.1669309437274933
step: 890, loss: 0.15196090936660767
step: 900, loss: 0.14831072092056274
step: 910, loss: 0.13356952369213104
step: 920, loss: 0.15187154710292816
step: 930, loss: 0.210539311170578
step: 940, loss: 0.2084803581237793
step: 950, loss: 0.0025197588838636875
step: 960, loss: 0.14535968005657196
step: 970, loss: 0.1052919253706932
step: 980, loss: 0.0981166809797287
step: 990, loss: 0.08966408669948578
step: 1000, loss: 0.24652931094169617
step: 1010, loss: 0.21204429864883423
step: 1020, loss: 0.0626993402838707
step: 1030, loss: 0.08757510036230087
step: 1040, loss: 0.09263382852077484
step: 1050, loss: 0.12876473367214203
step: 1060, loss: 0.036751143634319305
step: 1070, loss: 0.09404825419187546
epoch 2: dev_f1=0.9130832570905763, f1=0.9101633393829401, best_f1=0.923286427598729
step: 0, loss: 0.1646285504102707
step: 10, loss: 0.12235114723443985
step: 20, loss: 0.11312972009181976
step: 30, loss: 0.08205487579107285
step: 40, loss: 0.07873550057411194
step: 50, loss: 0.06642800569534302
step: 60, loss: 0.14860519766807556
step: 70, loss: 0.04974246770143509
step: 80, loss: 0.03504948318004608
step: 90, loss: 0.05075635761022568
step: 100, loss: 0.07290754467248917
step: 110, loss: 0.07218483090400696
step: 120, loss: 0.07160575687885284
step: 130, loss: 0.135263592004776
step: 140, loss: 0.14067263901233673
step: 150, loss: 0.1929159015417099
step: 160, loss: 0.2423063963651657
step: 170, loss: 0.13531379401683807
step: 180, loss: 0.12473951280117035
step: 190, loss: 0.15486100316047668
step: 200, loss: 0.1375037580728531
step: 210, loss: 0.1250084638595581
step: 220, loss: 0.050736475735902786
step: 230, loss: 0.14372886717319489
step: 240, loss: 0.2224379926919937
step: 250, loss: 0.08613035082817078
step: 260, loss: 0.1995123028755188
step: 270, loss: 0.14857569336891174
step: 280, loss: 0.12208227068185806
step: 290, loss: 0.15938574075698853
step: 300, loss: 0.13733923435211182
step: 310, loss: 0.15387029945850372
step: 320, loss: 0.06637875735759735
step: 330, loss: 0.0781915932893753
step: 340, loss: 0.18197745084762573
step: 350, loss: 0.07351940870285034
step: 360, loss: 0.08673582226037979
step: 370, loss: 0.061851080507040024
step: 380, loss: 0.0811891183257103
step: 390, loss: 0.05022267997264862
step: 400, loss: 0.060454774647951126
step: 410, loss: 0.13817235827445984
step: 420, loss: 0.15349479019641876
step: 430, loss: 0.086155965924263
step: 440, loss: 0.10418065637350082
step: 450, loss: 0.1098390519618988
step: 460, loss: 0.09196741133928299
step: 470, loss: 0.21836039423942566
step: 480, loss: 0.11298680305480957
step: 490, loss: 0.02160797081887722
step: 500, loss: 0.07967022061347961
step: 510, loss: 0.0814838856458664
step: 520, loss: 0.0931820422410965
step: 530, loss: 0.07105826586484909
step: 540, loss: 0.25940653681755066
step: 550, loss: 0.24251095950603485
step: 560, loss: 0.12935397028923035
step: 570, loss: 0.1959632933139801
step: 580, loss: 0.14900223910808563
step: 590, loss: 0.12380080670118332
step: 600, loss: 0.013831493444740772
step: 610, loss: 0.056475747376680374
step: 620, loss: 0.041148580610752106
step: 630, loss: 0.25998950004577637
step: 640, loss: 0.13157761096954346
step: 650, loss: 0.12054072320461273
step: 660, loss: 0.06715530157089233
step: 670, loss: 0.1649153232574463
step: 680, loss: 0.1481311023235321
step: 690, loss: 0.06293914467096329
step: 700, loss: 0.05211007222533226
step: 710, loss: 0.0924796387553215
step: 720, loss: 0.03276411071419716
step: 730, loss: 0.06113233044743538
step: 740, loss: 0.12365393340587616
step: 750, loss: 0.17394423484802246
step: 760, loss: 0.025224070996046066
step: 770, loss: 0.137852281332016
step: 780, loss: 0.10850071907043457
step: 790, loss: 0.11923016607761383
step: 800, loss: 0.04353640228509903
step: 810, loss: 0.12888917326927185
step: 820, loss: 0.08052873611450195
step: 830, loss: 0.15370874106884003
step: 840, loss: 0.1330493986606598
step: 850, loss: 0.10725191980600357
step: 860, loss: 0.12213469296693802
step: 870, loss: 0.09187211841344833
step: 880, loss: 0.05953332036733627
step: 890, loss: 0.19261106848716736
step: 900, loss: 0.16523414850234985
step: 910, loss: 0.11498700827360153
step: 920, loss: 0.0820218101143837
step: 930, loss: 0.07847322523593903
step: 940, loss: 0.0636332556605339
step: 950, loss: 0.044792480766773224
step: 960, loss: 0.17900562286376953
step: 970, loss: 0.07927418500185013
step: 980, loss: 0.20562514662742615
step: 990, loss: 0.05070769414305687
step: 1000, loss: 0.06566902250051498
step: 1010, loss: 0.1710665225982666
step: 1020, loss: 0.1312382072210312
step: 1030, loss: 0.05390537157654762
step: 1040, loss: 0.05161947011947632
step: 1050, loss: 0.028874699026346207
step: 1060, loss: 0.2509571611881256
step: 1070, loss: 0.12999755144119263
epoch 3: dev_f1=0.9129827826896232, f1=0.915270018621974, best_f1=0.923286427598729
step: 0, loss: 0.031182998791337013
step: 10, loss: 0.15173541009426117
step: 20, loss: 0.10466376692056656
step: 30, loss: 0.10409887135028839
step: 40, loss: 0.06576353311538696
step: 50, loss: 0.09796913713216782
step: 60, loss: 0.13503631949424744
step: 70, loss: 0.05275418981909752
step: 80, loss: 0.10009133070707321
step: 90, loss: 0.03139108419418335
step: 100, loss: 0.08863265812397003
step: 110, loss: 0.12674270570278168
step: 120, loss: 0.06536582857370377
step: 130, loss: 0.08653008192777634
step: 140, loss: 0.07306619733572006
step: 150, loss: 0.08129001408815384
step: 160, loss: 0.11989358067512512
step: 170, loss: 0.07531533390283585
step: 180, loss: 0.02504034712910652
step: 190, loss: 0.08530157059431076
step: 200, loss: 0.11970680952072144
step: 210, loss: 0.050058331340551376
step: 220, loss: 0.06111862510442734
step: 230, loss: 0.19825641810894012
step: 240, loss: 0.1265580803155899
step: 250, loss: 0.104209765791893
step: 260, loss: 0.0005924607976339757
step: 270, loss: 0.07159347832202911
step: 280, loss: 0.12766286730766296
step: 290, loss: 0.10744182765483856
step: 300, loss: 0.11428161710500717
step: 310, loss: 0.08734805136919022
step: 320, loss: 0.12550370395183563
step: 330, loss: 0.06551896035671234
step: 340, loss: 0.015460938215255737
step: 350, loss: 0.1762978434562683
step: 360, loss: 0.1537148803472519
step: 370, loss: 0.13340850174427032
step: 380, loss: 0.1152368038892746
step: 390, loss: 0.04076410084962845
step: 400, loss: 0.0709696114063263
step: 410, loss: 0.0942579060792923
step: 420, loss: 0.09364090114831924
step: 430, loss: 0.10791196674108505
step: 440, loss: 0.05663011968135834
step: 450, loss: 0.07845686376094818
step: 460, loss: 0.04867640137672424
step: 470, loss: 0.1777009218931198
step: 480, loss: 0.2273334115743637
step: 490, loss: 0.05698447301983833
step: 500, loss: 0.14434672892093658
step: 510, loss: 0.04416285455226898
step: 520, loss: 0.15760095417499542
step: 530, loss: 0.16190442442893982
step: 540, loss: 0.08346777409315109
step: 550, loss: 0.18785564601421356
step: 560, loss: 0.09577079117298126
step: 570, loss: 0.16542713344097137
step: 580, loss: 0.1543383002281189
step: 590, loss: 0.047258298844099045
step: 600, loss: 0.08905420452356339
step: 610, loss: 0.144689679145813
step: 620, loss: 0.20060263574123383
step: 630, loss: 0.14759425818920135
step: 640, loss: 0.06378927081823349
step: 650, loss: 0.1801854819059372
step: 660, loss: 0.055025044828653336
step: 670, loss: 0.13291049003601074
step: 680, loss: 0.2927567660808563
step: 690, loss: 0.11969442665576935
step: 700, loss: 0.11990781128406525
step: 710, loss: 0.07652673870325089
step: 720, loss: 0.09458331018686295
step: 730, loss: 0.12399966269731522
step: 740, loss: 0.07594078779220581
step: 750, loss: 0.03609657660126686
step: 760, loss: 0.06564763188362122
step: 770, loss: 0.11135724931955338
step: 780, loss: 0.08171883225440979
step: 790, loss: 0.16941247880458832
step: 800, loss: 0.22621607780456543
step: 810, loss: 0.025826582685112953
step: 820, loss: 0.06249479949474335
step: 830, loss: 0.1822129189968109
step: 840, loss: 0.2531610429286957
step: 850, loss: 0.09765926003456116
step: 860, loss: 0.07591484487056732
step: 870, loss: 0.015782561153173447
step: 880, loss: 0.06412692368030548
step: 890, loss: 0.08009132742881775
step: 900, loss: 0.04419586807489395
step: 910, loss: 0.15288710594177246
step: 920, loss: 0.06155986711382866
step: 930, loss: 0.09195652604103088
step: 940, loss: 0.0822843462228775
step: 950, loss: 0.06441566348075867
step: 960, loss: 0.0788969174027443
step: 970, loss: 0.175398051738739
step: 980, loss: 0.17099963128566742
step: 990, loss: 0.15710070729255676
step: 1000, loss: 0.14005491137504578
step: 1010, loss: 0.07591833919286728
step: 1020, loss: 0.12531566619873047
step: 1030, loss: 0.0935468077659607
step: 1040, loss: 0.09678731858730316
step: 1050, loss: 0.19448688626289368
step: 1060, loss: 0.07253894954919815
step: 1070, loss: 0.06661438941955566
epoch 4: dev_f1=0.9247706422018349, f1=0.9238532110091744, best_f1=0.923286427598729
step: 0, loss: 0.013302871026098728
step: 10, loss: 0.04898526519536972
step: 20, loss: 0.06054941192269325
step: 30, loss: 0.11689785867929459
step: 40, loss: 0.22018060088157654
step: 50, loss: 0.07020650058984756
step: 60, loss: 0.061679255217313766
step: 70, loss: 0.14348812401294708
step: 80, loss: 0.03488877788186073
step: 90, loss: 0.02169550210237503
step: 100, loss: 0.0789659172296524
step: 110, loss: 0.02652805671095848
step: 120, loss: 0.17967000603675842
step: 130, loss: 0.15638840198516846
step: 140, loss: 0.01154989656060934
step: 150, loss: 0.06478750705718994
step: 160, loss: 0.030560988932847977
step: 170, loss: 0.024861006066203117
step: 180, loss: 0.04427645355463028
step: 190, loss: 0.13324832916259766
step: 200, loss: 0.05666408687829971
step: 210, loss: 0.03861677646636963
step: 220, loss: 0.045658744871616364
step: 230, loss: 0.05104850232601166
step: 240, loss: 0.0937560647726059
step: 250, loss: 0.07831259071826935
step: 260, loss: 0.1431591808795929
step: 270, loss: 0.09608610719442368
step: 280, loss: 0.04018838331103325
step: 290, loss: 0.04131584241986275
step: 300, loss: 0.13075008988380432
step: 310, loss: 0.2135067731142044
step: 320, loss: 0.10272937268018723
step: 330, loss: 0.022088514640927315
step: 340, loss: 0.029493233188986778
step: 350, loss: 0.026530934497714043
step: 360, loss: 0.06572933495044708
step: 370, loss: 0.09050948917865753
step: 380, loss: 0.0439208559691906
step: 390, loss: 0.03639068454504013
step: 400, loss: 0.17144018411636353
step: 410, loss: 0.24329982697963715
step: 420, loss: 0.14242705702781677
step: 430, loss: 0.04268725961446762
step: 440, loss: 0.09656926989555359
step: 450, loss: 0.0965401902794838
step: 460, loss: 0.09460970014333725
step: 470, loss: 0.1633206158876419
step: 480, loss: 0.14302442967891693
step: 490, loss: 0.07297195494174957
step: 500, loss: 0.04011310264468193
step: 510, loss: 0.18671491742134094
step: 520, loss: 0.05015772581100464
step: 530, loss: 0.030639341101050377
step: 540, loss: 0.1062224879860878
step: 550, loss: 0.09823355078697205
step: 560, loss: 0.22014003992080688
step: 570, loss: 0.014487192966043949
step: 580, loss: 0.19979938864707947
step: 590, loss: 0.03996290639042854
step: 600, loss: 0.04244905710220337
step: 610, loss: 0.030344869941473007
step: 620, loss: 0.11743276566267014
step: 630, loss: 0.09809019416570663
step: 640, loss: 0.095196433365345
step: 650, loss: 0.03867825120687485
step: 660, loss: 0.09929816424846649
step: 670, loss: 0.27553194761276245
step: 680, loss: 0.057751454412937164
step: 690, loss: 0.09807567298412323
step: 700, loss: 0.03538912907242775
step: 710, loss: 0.11560101807117462
step: 720, loss: 0.07973923534154892
step: 730, loss: 0.1294454038143158
step: 740, loss: 0.01872607134282589
step: 750, loss: 0.14676475524902344
step: 760, loss: 0.0886826291680336
step: 770, loss: 0.06311582028865814
step: 780, loss: 0.047906629741191864
step: 790, loss: 0.03629022091627121
step: 800, loss: 0.09656303375959396
step: 810, loss: 0.08436062186956406
step: 820, loss: 0.14893770217895508
step: 830, loss: 0.1875704526901245
step: 840, loss: 0.02518295682966709
step: 850, loss: 0.09724733233451843
step: 860, loss: 0.2503243088722229
step: 870, loss: 0.04184696823358536
step: 880, loss: 0.03836808726191521
step: 890, loss: 0.10535735636949539
step: 900, loss: 0.11016637086868286
step: 910, loss: 0.09000390768051147
step: 920, loss: 0.03113345056772232
step: 930, loss: 0.0823809951543808
step: 940, loss: 0.2047959268093109
step: 950, loss: 0.061491936445236206
step: 960, loss: 0.030928343534469604
step: 970, loss: 0.028190623968839645
step: 980, loss: 0.09358838200569153
step: 990, loss: 0.1139770895242691
step: 1000, loss: 0.03163572773337364
step: 1010, loss: 0.026381339877843857
step: 1020, loss: 0.06254542618989944
step: 1030, loss: 0.11648918688297272
step: 1040, loss: 0.09186514467000961
step: 1050, loss: 0.12132967263460159
step: 1060, loss: 0.11160978674888611
step: 1070, loss: 0.1803419589996338
epoch 5: dev_f1=0.9316596931659693, f1=0.9289667896678966, best_f1=0.9289667896678966
step: 0, loss: 0.08943647891283035
step: 10, loss: 0.08362556248903275
step: 20, loss: 0.009985776618123055
step: 30, loss: 0.008528215810656548
step: 40, loss: 0.08926825225353241
step: 50, loss: 0.0412665456533432
step: 60, loss: 0.049744490534067154
step: 70, loss: 0.0543074794113636
step: 80, loss: 0.07644515484571457
step: 90, loss: 0.06129208207130432
step: 100, loss: 0.10727571696043015
step: 110, loss: 0.07332155853509903
step: 120, loss: 0.055962543934583664
step: 130, loss: 0.035583581775426865
step: 140, loss: 0.053287338465452194
step: 150, loss: 0.04038726165890694
step: 160, loss: 0.24210718274116516
step: 170, loss: 0.08145351707935333
step: 180, loss: 0.2825809717178345
step: 190, loss: 0.023858625441789627
step: 200, loss: 0.17585240304470062
step: 210, loss: 0.08866959065198898
step: 220, loss: 0.1071317046880722
step: 230, loss: 0.04369876906275749
step: 240, loss: 0.08352415263652802
step: 250, loss: 0.1456936150789261
step: 260, loss: 0.03212805092334747
step: 270, loss: 0.027377039194107056
step: 280, loss: 0.014582880772650242
step: 290, loss: 0.08484042435884476
step: 300, loss: 0.07061890512704849
step: 310, loss: 0.1367024928331375
step: 320, loss: 0.09501442313194275
step: 330, loss: 0.023605499416589737
step: 340, loss: 0.018961884081363678
step: 350, loss: 0.05986872315406799
step: 360, loss: 0.03747439384460449
step: 370, loss: 0.21703621745109558
step: 380, loss: 0.060998912900686264
step: 390, loss: 0.03735680133104324
step: 400, loss: 0.05755478888750076
step: 410, loss: 0.06266244500875473
step: 420, loss: 0.06442070752382278
step: 430, loss: 0.26008912920951843
step: 440, loss: 0.05283241346478462
step: 450, loss: 0.04643996059894562
step: 460, loss: 0.14465537667274475
step: 470, loss: 0.05717726796865463
step: 480, loss: 0.05441175028681755
step: 490, loss: 0.1355091631412506
step: 500, loss: 0.040297284722328186
step: 510, loss: 0.1842297464609146
step: 520, loss: 0.11000987887382507
step: 530, loss: 0.06193352863192558
step: 540, loss: 0.10247251391410828
step: 550, loss: 0.14460311830043793
step: 560, loss: 0.02204343117773533
step: 570, loss: 0.0588964968919754
step: 580, loss: 0.12803883850574493
step: 590, loss: 0.08298160135746002
step: 600, loss: 0.10686257481575012
step: 610, loss: 0.04009748250246048
step: 620, loss: 0.04524708539247513
step: 630, loss: 0.13471926748752594
step: 640, loss: 0.06637133657932281
step: 650, loss: 0.06870091706514359
step: 660, loss: 0.025004196912050247
step: 670, loss: 0.055403731763362885
step: 680, loss: 0.11450458317995071
step: 690, loss: 0.1007305160164833
step: 700, loss: 0.06200379878282547
step: 710, loss: 0.0016703619621694088
step: 720, loss: 0.07684255391359329
step: 730, loss: 0.1132352277636528
step: 740, loss: 0.03508159518241882
step: 750, loss: 0.03581183776259422
step: 760, loss: 0.26178890466690063
step: 770, loss: 0.1092478334903717
step: 780, loss: 0.09821522980928421
step: 790, loss: 0.06604794412851334
step: 800, loss: 0.11823642253875732
step: 810, loss: 0.043336644768714905
step: 820, loss: 0.2078084498643875
step: 830, loss: 7.654913497390226e-05
step: 840, loss: 0.035033661872148514
step: 850, loss: 0.07660248130559921
step: 860, loss: 0.05969563126564026
step: 870, loss: 0.13528522849082947
step: 880, loss: 0.10895657539367676
step: 890, loss: 0.0529433898627758
step: 900, loss: 0.05789880082011223
step: 910, loss: 0.05569303408265114
step: 920, loss: 0.0819115936756134
step: 930, loss: 0.05727320909500122
step: 940, loss: 0.1040273979306221
step: 950, loss: 0.16521435976028442
step: 960, loss: 0.011011944152414799
step: 970, loss: 0.10862043499946594
step: 980, loss: 0.06083949655294418
step: 990, loss: 0.07341797649860382
step: 1000, loss: 0.06532939523458481
step: 1010, loss: 0.04615342244505882
step: 1020, loss: 0.12144539505243301
step: 1030, loss: 0.05730663612484932
step: 1040, loss: 0.0036164559423923492
step: 1050, loss: 0.026669085025787354
step: 1060, loss: 0.02469092421233654
step: 1070, loss: 0.08810877799987793
epoch 6: dev_f1=0.9267399267399268, f1=0.92772186642269, best_f1=0.9289667896678966
step: 0, loss: 0.11333193629980087
step: 10, loss: 0.11322159320116043
step: 20, loss: 0.1048329770565033
step: 30, loss: 0.10072179138660431
step: 40, loss: 0.07474508881568909
step: 50, loss: 0.023085838183760643
step: 60, loss: 0.09913039952516556
step: 70, loss: 0.011250357143580914
step: 80, loss: 0.024383535608649254
step: 90, loss: 0.1419830471277237
step: 100, loss: 0.04236377403140068
step: 110, loss: 0.16508431732654572
step: 120, loss: 0.10612340271472931
step: 130, loss: 0.050339680165052414
step: 140, loss: 0.10072699934244156
step: 150, loss: 0.0843372642993927
step: 160, loss: 0.09322278201580048
step: 170, loss: 0.0642911046743393
step: 180, loss: 0.062924325466156
step: 190, loss: 0.04523523896932602
step: 200, loss: 0.042496103793382645
step: 210, loss: 0.04929007962346077
step: 220, loss: 0.118214450776577
step: 230, loss: 0.011452785693109035
step: 240, loss: 0.0854828953742981
step: 250, loss: 0.05366354063153267
step: 260, loss: 0.04429979622364044
step: 270, loss: 0.012335446663200855
step: 280, loss: 0.08140837401151657
step: 290, loss: 0.10164958983659744
step: 300, loss: 0.026400461792945862
step: 310, loss: 0.20075608789920807
step: 320, loss: 0.04940594732761383
step: 330, loss: 0.03040730208158493
step: 340, loss: 0.07579939812421799
step: 350, loss: 0.08632995933294296
step: 360, loss: 0.09704918414354324
step: 370, loss: 0.020430050790309906
step: 380, loss: 0.08578334003686905
step: 390, loss: 0.03741827234625816
step: 400, loss: 0.07161600142717361
step: 410, loss: 0.03501029685139656
step: 420, loss: 0.1268417090177536
step: 430, loss: 0.0902784988284111
step: 440, loss: 0.08150734752416611
step: 450, loss: 0.06628765165805817
step: 460, loss: 0.056824419647455215
step: 470, loss: 0.07240860909223557
step: 480, loss: 0.0591532401740551
step: 490, loss: 0.20942065119743347
step: 500, loss: 0.046726617962121964
step: 510, loss: 0.12017365545034409
step: 520, loss: 0.11032245308160782
step: 530, loss: 0.03958941251039505
step: 540, loss: 0.03723843768239021
step: 550, loss: 0.06888780742883682
step: 560, loss: 0.15492220222949982
step: 570, loss: 0.019829031080007553
step: 580, loss: 0.06902460753917694
step: 590, loss: 0.08726444840431213
step: 600, loss: 0.06870950758457184
step: 610, loss: 0.01179401483386755
step: 620, loss: 0.07308317720890045
step: 630, loss: 0.08994591981172562
step: 640, loss: 0.05543072149157524
step: 650, loss: 0.07972770929336548
step: 660, loss: 0.07332334667444229
step: 670, loss: 0.08434604853391647
step: 680, loss: 0.05581999942660332
step: 690, loss: 0.11736969649791718
step: 700, loss: 0.12348221242427826
step: 710, loss: 0.12190566956996918
step: 720, loss: 0.06241656094789505
step: 730, loss: 0.029124166816473007
step: 740, loss: 0.06462865322828293
step: 750, loss: 0.14987032115459442
step: 760, loss: 0.035886041820049286
step: 770, loss: 0.1306016594171524
step: 780, loss: 0.10962709784507751
step: 790, loss: 0.011636330746114254
step: 800, loss: 0.07651527971029282
step: 810, loss: 0.10936848074197769
step: 820, loss: 0.0686212107539177
step: 830, loss: 0.08299226313829422
step: 840, loss: 0.07785473763942719
step: 850, loss: 0.0457647480070591
step: 860, loss: 0.06530322134494781
step: 870, loss: 0.163330078125
step: 880, loss: 0.07944773137569427
step: 890, loss: 0.04195723682641983
step: 900, loss: 0.12675054371356964
step: 910, loss: 0.0032320041209459305
step: 920, loss: 0.126349538564682
step: 930, loss: 0.006912515498697758
step: 940, loss: 0.0351656973361969
step: 950, loss: 0.05696044862270355
step: 960, loss: 0.14501449465751648
step: 970, loss: 0.06911472231149673
step: 980, loss: 0.030051061883568764
step: 990, loss: 0.08378735184669495
step: 1000, loss: 0.09501872956752777
step: 1010, loss: 0.11125216633081436
step: 1020, loss: 0.10299210250377655
step: 1030, loss: 0.13725177943706512
step: 1040, loss: 0.05551515519618988
step: 1050, loss: 0.1407468020915985
step: 1060, loss: 0.0592641606926918
step: 1070, loss: 4.220914706820622e-05
epoch 7: dev_f1=0.926829268292683, f1=0.9210161662817552, best_f1=0.9289667896678966
step: 0, loss: 0.08305522799491882
step: 10, loss: 0.11774681508541107
step: 20, loss: 0.08316546678543091
step: 30, loss: 0.020606093108654022
step: 40, loss: 0.10014437139034271
step: 50, loss: 0.034335698932409286
step: 60, loss: 0.054329659789800644
step: 70, loss: 0.1180787980556488
step: 80, loss: 0.191667839884758
step: 90, loss: 0.07171189039945602
step: 100, loss: 0.06364960223436356
step: 110, loss: 0.021764487028121948
step: 120, loss: 0.11711291968822479
step: 130, loss: 0.0923219844698906
step: 140, loss: 0.1451719105243683
step: 150, loss: 0.08525503426790237
step: 160, loss: 0.06224314495921135
step: 170, loss: 0.039342500269412994
step: 180, loss: 0.03679397702217102
step: 190, loss: 0.06542074680328369
step: 200, loss: 0.07122388482093811
step: 210, loss: 0.12863467633724213
step: 220, loss: 0.09253891557455063
step: 230, loss: 0.024985333904623985
step: 240, loss: 0.07204272598028183
step: 250, loss: 0.02095123566687107
step: 260, loss: 0.0939338207244873
step: 270, loss: 0.12917235493659973
step: 280, loss: 0.053538817912340164
step: 290, loss: 0.1658153086900711
step: 300, loss: 0.036257438361644745
step: 310, loss: 0.17951145768165588
step: 320, loss: 0.08817281574010849
step: 330, loss: 0.06647896021604538
step: 340, loss: 0.1603114902973175
step: 350, loss: 0.028468584641814232
step: 360, loss: 0.06520861387252808
step: 370, loss: 0.06531086564064026
step: 380, loss: 0.12926779687404633
step: 390, loss: 0.08125282824039459
step: 400, loss: 0.11692240089178085
step: 410, loss: 0.06345855444669724
step: 420, loss: 0.0031648543663322926
step: 430, loss: 0.03589167073369026
step: 440, loss: 0.09762058407068253
step: 450, loss: 0.020399950444698334
step: 460, loss: 0.030090171843767166
step: 470, loss: 0.14690329134464264
step: 480, loss: 0.18312622606754303
step: 490, loss: 0.15433292090892792
step: 500, loss: 0.05946148931980133
step: 510, loss: 0.10193034261465073
step: 520, loss: 0.02785165049135685
step: 530, loss: 0.06412341445684433
step: 540, loss: 0.06028926745057106
step: 550, loss: 0.1071871668100357
step: 560, loss: 0.04471314698457718
step: 570, loss: 0.0361185222864151
step: 580, loss: 0.022342784330248833
step: 590, loss: 0.04575064778327942
step: 600, loss: 0.04633910953998566
step: 610, loss: 0.12667548656463623
step: 620, loss: 0.08078756928443909
step: 630, loss: 0.03793618828058243
step: 640, loss: 0.1473485380411148
step: 650, loss: 0.14730848371982574
step: 660, loss: 0.0799768716096878
step: 670, loss: 0.07049085199832916
step: 680, loss: 0.14052020013332367
step: 690, loss: 0.03495737910270691
step: 700, loss: 0.017666693776845932
step: 710, loss: 0.16683898866176605
step: 720, loss: 0.19187070429325104
step: 730, loss: 0.04353028163313866
step: 740, loss: 0.07253458350896835
step: 750, loss: 0.03940560668706894
step: 760, loss: 0.10857351869344711
step: 770, loss: 0.0833153948187828
step: 780, loss: 0.09072596579790115
step: 790, loss: 0.10315161943435669
step: 800, loss: 0.11013021320104599
step: 810, loss: 0.09655240923166275
step: 820, loss: 0.02599286288022995
step: 830, loss: 0.0483110286295414
step: 840, loss: 0.09544960409402847
step: 850, loss: 0.06850533932447433
step: 860, loss: 0.06601185351610184
step: 870, loss: 0.0603114552795887
step: 880, loss: 0.1237841323018074
step: 890, loss: 0.06035084277391434
step: 900, loss: 0.11563248187303543
step: 910, loss: 0.11005423218011856
step: 920, loss: 0.0261524710804224
step: 930, loss: 0.06709109246730804
step: 940, loss: 0.04303479939699173
step: 950, loss: 0.0758984312415123
step: 960, loss: 0.06347936391830444
step: 970, loss: 0.10014674067497253
step: 980, loss: 0.02213427424430847
step: 990, loss: 0.06581202149391174
step: 1000, loss: 0.06974387168884277
step: 1010, loss: 0.08315746486186981
step: 1020, loss: 0.08062171190977097
step: 1030, loss: 0.13085924088954926
step: 1040, loss: 0.06643637269735336
step: 1050, loss: 0.03322266787290573
step: 1060, loss: 0.10220196098089218
step: 1070, loss: 0.08583579957485199
epoch 8: dev_f1=0.9367441860465117, f1=0.9305555555555556, best_f1=0.9305555555555556
step: 0, loss: 0.22278539836406708
step: 10, loss: 0.037914104759693146
step: 20, loss: 0.04670724272727966
step: 30, loss: 0.015145039185881615
step: 40, loss: 0.11584155261516571
step: 50, loss: 0.17920826375484467
step: 60, loss: 0.028074808418750763
step: 70, loss: 0.013372459448873997
step: 80, loss: 0.08774384111166
step: 90, loss: 0.024210821837186813
step: 100, loss: 0.026375317946076393
step: 110, loss: 0.031635258346796036
step: 120, loss: 0.06983589380979538
step: 130, loss: 0.08418290317058563
step: 140, loss: 0.04795081540942192
step: 150, loss: 3.0069242711761035e-05
step: 160, loss: 0.04129868745803833
step: 170, loss: 0.13862067461013794
step: 180, loss: 0.04600294679403305
step: 190, loss: 0.05610429868102074
step: 200, loss: 0.02807372249662876
step: 210, loss: 0.009146912954747677
step: 220, loss: 0.02908368781208992
step: 230, loss: 0.06291265785694122
step: 240, loss: 0.011713425628840923
step: 250, loss: 0.03918645903468132
step: 260, loss: 0.010925875045359135
step: 270, loss: 0.047108832746744156
step: 280, loss: 0.028787648305296898
step: 290, loss: 0.0436701774597168
step: 300, loss: 0.05917283892631531
step: 310, loss: 0.07655566185712814
step: 320, loss: 0.06660246849060059
step: 330, loss: 0.017398349940776825
step: 340, loss: 0.049422912299633026
step: 350, loss: 0.12882262468338013
step: 360, loss: 0.04294288903474808
step: 370, loss: 0.09332682192325592
step: 380, loss: 0.14872922003269196
step: 390, loss: 0.13778530061244965
step: 400, loss: 0.10925894230604172
step: 410, loss: 0.0510389506816864
step: 420, loss: 0.10026054829359055
step: 430, loss: 0.10281623154878616
step: 440, loss: 0.023939277976751328
step: 450, loss: 0.04835676774382591
step: 460, loss: 0.03602980449795723
step: 470, loss: 0.03688633441925049
step: 480, loss: 0.16880592703819275
step: 490, loss: 0.039629291743040085
step: 500, loss: 0.1285356730222702
step: 510, loss: 0.22198456525802612
step: 520, loss: 0.12433977425098419
step: 530, loss: 0.015561149455606937
step: 540, loss: 0.10538361966609955
step: 550, loss: 0.08615685999393463
step: 560, loss: 0.035810764878988266
step: 570, loss: 0.004470834508538246
step: 580, loss: 0.07173246890306473
step: 590, loss: 0.03192206099629402
step: 600, loss: 0.18159019947052002
step: 610, loss: 0.0701405331492424
step: 620, loss: 0.09158267080783844
step: 630, loss: 0.02444257214665413
step: 640, loss: 0.035880059003829956
step: 650, loss: 0.0661066323518753
step: 660, loss: 0.05428193137049675
step: 670, loss: 0.08235412836074829
step: 680, loss: 0.10642481595277786
step: 690, loss: 0.09682358801364899
step: 700, loss: 0.06692495942115784
step: 710, loss: 0.09690925478935242
step: 720, loss: 0.02730313129723072
step: 730, loss: 0.05456294119358063
step: 740, loss: 0.012365926057100296
step: 750, loss: 0.02104698307812214
step: 760, loss: 0.10209943354129791
step: 770, loss: 0.14177854359149933
step: 780, loss: 0.08673243224620819
step: 790, loss: 0.05733136832714081
step: 800, loss: 0.04874217510223389
step: 810, loss: 0.04278651624917984
step: 820, loss: 0.12979844212532043
step: 830, loss: 0.05493202060461044
step: 840, loss: 0.021907635033130646
step: 850, loss: 0.0697786957025528
step: 860, loss: 0.12643493711948395
step: 870, loss: 0.037287164479494095
step: 880, loss: 0.0410960353910923
step: 890, loss: 0.07237768173217773
step: 900, loss: 0.03113318607211113
step: 910, loss: 0.035508908331394196
step: 920, loss: 0.06591586023569107
step: 930, loss: 0.1223132461309433
step: 940, loss: 0.08117178827524185
step: 950, loss: 0.09320393949747086
step: 960, loss: 0.06741555780172348
step: 970, loss: 0.08756176382303238
step: 980, loss: 0.12115158885717392
step: 990, loss: 0.09359725564718246
step: 1000, loss: 0.1143103614449501
step: 1010, loss: 0.12621964514255524
step: 1020, loss: 0.09349586069583893
step: 1030, loss: 0.15030737221240997
step: 1040, loss: 0.07468455284833908
step: 1050, loss: 0.06327218562364578
step: 1060, loss: 0.15933749079704285
step: 1070, loss: 0.20496170222759247
epoch 9: dev_f1=0.929170549860205, f1=0.9241573033707865, best_f1=0.9305555555555556
step: 0, loss: 0.024696826934814453
step: 10, loss: 0.029566671699285507
step: 20, loss: 0.04718496650457382
step: 30, loss: 0.14213019609451294
step: 40, loss: 0.16869747638702393
step: 50, loss: 0.04861026629805565
step: 60, loss: 0.08855757117271423
step: 70, loss: 1.1276342775090598e-05
step: 80, loss: 0.08940247446298599
step: 90, loss: 0.11307863146066666
step: 100, loss: 0.031233742833137512
step: 110, loss: 0.0413128100335598
step: 120, loss: 0.07636672258377075
step: 130, loss: 0.09346169978380203
step: 140, loss: 0.13164640963077545
step: 150, loss: 0.07169456779956818
step: 160, loss: 0.0332663469016552
step: 170, loss: 0.031710684299468994
step: 180, loss: 0.11969956755638123
step: 190, loss: 0.03139346465468407
step: 200, loss: 0.09401112049818039
step: 210, loss: 0.04563823342323303
step: 220, loss: 0.12190349400043488
step: 230, loss: 0.09107053279876709
step: 240, loss: 0.03495399281382561
step: 250, loss: 0.056247029453516006
step: 260, loss: 0.016489416360855103
step: 270, loss: 0.09175648540258408
step: 280, loss: 0.04712361469864845
step: 290, loss: 0.12029492110013962
step: 300, loss: 0.04909929260611534
step: 310, loss: 0.0922461673617363
step: 320, loss: 0.11140242218971252
step: 330, loss: 0.0439516045153141
step: 340, loss: 0.03501756116747856
step: 350, loss: 0.07214834541082382
step: 360, loss: 0.0861763134598732
step: 370, loss: 0.03970794007182121
step: 380, loss: 0.06669522076845169
step: 390, loss: 0.13601256906986237
step: 400, loss: 0.07224244624376297
step: 410, loss: 0.0633632242679596
step: 420, loss: 0.15628737211227417
step: 430, loss: 0.10399328172206879
step: 440, loss: 0.04644504562020302
step: 450, loss: 0.09716318547725677
step: 460, loss: 0.15605764091014862
step: 470, loss: 0.045940376818180084
step: 480, loss: 0.10473258048295975
step: 490, loss: 0.04188171401619911
step: 500, loss: 0.03499926999211311
step: 510, loss: 0.2169761210680008
step: 520, loss: 0.07549125701189041
step: 530, loss: 0.2187170684337616
step: 540, loss: 0.13595479726791382
step: 550, loss: 0.013443470001220703
step: 560, loss: 0.015185593627393246
step: 570, loss: 0.10533634573221207
step: 580, loss: 0.0801435336470604
step: 590, loss: 0.08695065230131149
step: 600, loss: 0.06326139718294144
step: 610, loss: 0.1822134405374527
step: 620, loss: 0.005752967670559883
step: 630, loss: 0.030045760795474052
step: 640, loss: 0.07027535140514374
step: 650, loss: 0.06701938062906265
step: 660, loss: 0.10973283648490906
step: 670, loss: 0.14870938658714294
step: 680, loss: 0.08562777191400528
step: 690, loss: 0.09073774516582489
step: 700, loss: 0.033236730843782425
step: 710, loss: 0.02343622036278248
step: 720, loss: 0.10934377461671829
step: 730, loss: 0.08980615437030792
step: 740, loss: 0.1788294017314911
step: 750, loss: 0.06797453761100769
step: 760, loss: 0.0473732054233551
step: 770, loss: 0.0282145906239748
step: 780, loss: 0.01373214926570654
step: 790, loss: 0.10547097027301788
step: 800, loss: 0.023469500243663788
step: 810, loss: 0.09807692468166351
step: 820, loss: 0.015676384791731834
step: 830, loss: 0.04567535221576691
step: 840, loss: 0.057121340185403824
step: 850, loss: 0.021487724035978317
step: 860, loss: 0.10257693380117416
step: 870, loss: 0.0018869593041017652
step: 880, loss: 0.030608108267188072
step: 890, loss: 0.24043604731559753
step: 900, loss: 0.038187362253665924
step: 910, loss: 0.031038673594594002
step: 920, loss: 0.07244875282049179
step: 930, loss: 0.05614873394370079
step: 940, loss: 0.010023596696555614
step: 950, loss: 0.05479932576417923
step: 960, loss: 0.06917697936296463
step: 970, loss: 0.061208758503198624
step: 980, loss: 0.14863920211791992
step: 990, loss: 0.15200470387935638
step: 1000, loss: 0.08595386892557144
step: 1010, loss: 0.09970825165510178
step: 1020, loss: 0.14685982465744019
step: 1030, loss: 0.014813962392508984
step: 1040, loss: 0.025805389508605003
step: 1050, loss: 0.03614861145615578
step: 1060, loss: 0.03246843442320824
step: 1070, loss: 0.019644198939204216
epoch 10: dev_f1=0.9331501831501833, f1=0.927694406548431, best_f1=0.9305555555555556
step: 0, loss: 0.03906925022602081
step: 10, loss: 0.13830848038196564
step: 20, loss: 0.08163581788539886
step: 30, loss: 0.003447297029197216
step: 40, loss: 0.017894014716148376
step: 50, loss: 0.08068962395191193
step: 60, loss: 0.028222111985087395
step: 70, loss: 0.037130169570446014
step: 80, loss: 0.012310929596424103
step: 90, loss: 0.026503996923565865
step: 100, loss: 0.09840439260005951
step: 110, loss: 0.01850110851228237
step: 120, loss: 9.885495092021301e-05
step: 130, loss: 0.020796796306967735
step: 140, loss: 0.03114033304154873
step: 150, loss: 0.06524688750505447
step: 160, loss: 0.08682110905647278
step: 170, loss: 0.029961440712213516
step: 180, loss: 0.047214046120643616
step: 190, loss: 0.024523042142391205
step: 200, loss: 0.11497210711240768
step: 210, loss: 0.03257777541875839
step: 220, loss: 0.0561104491353035
step: 230, loss: 0.052067242562770844
step: 240, loss: 0.020679842680692673
step: 250, loss: 0.14272792637348175
step: 260, loss: 0.05155858397483826
step: 270, loss: 0.04239172115921974
step: 280, loss: 0.0949019119143486
step: 290, loss: 0.07895307242870331
step: 300, loss: 0.09038500487804413
step: 310, loss: 0.13401766121387482
step: 320, loss: 0.047772087156772614
step: 330, loss: 0.15116462111473083
step: 340, loss: 0.06058445945382118
step: 350, loss: 0.04956471547484398
step: 360, loss: 0.06307744234800339
step: 370, loss: 0.01273712981492281
step: 380, loss: 0.046550899744033813
step: 390, loss: 0.053835004568099976
step: 400, loss: 0.019883304834365845
step: 410, loss: 0.05822652578353882
step: 420, loss: 0.0798458606004715
step: 430, loss: 0.07174936681985855
step: 440, loss: 0.08834697306156158
step: 450, loss: 0.0001338958682026714
step: 460, loss: 0.20712772011756897
step: 470, loss: 0.0935063362121582
step: 480, loss: 0.0017802512738853693
step: 490, loss: 0.0667746439576149
step: 500, loss: 0.02634851261973381
step: 510, loss: 0.11242669075727463
step: 520, loss: 0.06244602054357529
step: 530, loss: 0.0705016627907753
step: 540, loss: 0.07324960082769394
step: 550, loss: 0.03330383077263832
step: 560, loss: 0.019598620012402534
step: 570, loss: 0.05191223323345184
step: 580, loss: 0.05038803815841675
step: 590, loss: 0.0902109146118164
step: 600, loss: 0.058911267668008804
step: 610, loss: 0.10479044914245605
step: 620, loss: 3.312986882519908e-05
step: 630, loss: 0.04514112323522568
step: 640, loss: 0.035873182117938995
step: 650, loss: 0.11630811542272568
step: 660, loss: 0.046443331986665726
step: 670, loss: 0.08048578351736069
step: 680, loss: 0.034717410802841187
step: 690, loss: 0.05411650240421295
step: 700, loss: 0.010359784588217735
step: 710, loss: 0.04557708650827408
step: 720, loss: 0.06560754030942917
step: 730, loss: 0.1365801841020584
step: 740, loss: 0.008919402956962585
step: 750, loss: 0.04815910384058952
step: 760, loss: 0.07232336699962616
step: 770, loss: 0.03726203739643097
step: 780, loss: 0.09756313264369965
step: 790, loss: 0.04138939827680588
step: 800, loss: 0.09425834566354752
step: 810, loss: 0.05181942135095596
step: 820, loss: 0.02504861168563366
step: 830, loss: 0.0672495886683464
step: 840, loss: 0.02751118130981922
step: 850, loss: 0.14329645037651062
step: 860, loss: 0.13427798449993134
step: 870, loss: 0.053243670612573624
step: 880, loss: 0.09626831114292145
step: 890, loss: 0.02557399496436119
step: 900, loss: 0.06577140092849731
step: 910, loss: 0.07435638457536697
step: 920, loss: 0.07826761901378632
step: 930, loss: 0.04196781665086746
step: 940, loss: 0.05639522895216942
step: 950, loss: 0.1250302940607071
step: 960, loss: 0.038844868540763855
step: 970, loss: 0.06429079920053482
step: 980, loss: 0.08227153867483139
step: 990, loss: 0.06074914708733559
step: 1000, loss: 0.0694819912314415
step: 1010, loss: 0.04743936285376549
step: 1020, loss: 0.07883948087692261
step: 1030, loss: 0.14212366938591003
step: 1040, loss: 0.049952778965234756
step: 1050, loss: 0.0236990787088871
step: 1060, loss: 0.07709341496229172
step: 1070, loss: 0.019528627395629883
epoch 11: dev_f1=0.9308924485125859, f1=0.9288664525011474, best_f1=0.9305555555555556
step: 0, loss: 0.10352636873722076
step: 10, loss: 0.06036970764398575
step: 20, loss: 0.2284528911113739
step: 30, loss: 0.013176141306757927
step: 40, loss: 0.023207025602459908
step: 50, loss: 0.03670747950673103
step: 60, loss: 0.07381608337163925
step: 70, loss: 0.06277032941579819
step: 80, loss: 0.045698702335357666
step: 90, loss: 0.05634880065917969
step: 100, loss: 0.07889857888221741
step: 110, loss: 0.0680626630783081
step: 120, loss: 0.016381029039621353
step: 130, loss: 0.0005907252198085189
step: 140, loss: 0.04358578845858574
step: 150, loss: 0.008825504221022129
step: 160, loss: 0.09810785204172134
step: 170, loss: 0.030256612226366997
step: 180, loss: 0.06763333827257156
step: 190, loss: 0.0908462330698967
step: 200, loss: 0.03844316676259041
step: 210, loss: 0.02730904147028923
step: 220, loss: 0.20228800177574158
step: 230, loss: 0.0831117331981659
step: 240, loss: 0.1024942696094513
step: 250, loss: 0.09614110738039017
step: 260, loss: 0.40966561436653137
step: 270, loss: 0.057750701904296875
step: 280, loss: 0.001895326073281467
step: 290, loss: 0.0685996413230896
step: 300, loss: 0.13789677619934082
step: 310, loss: 0.06430769711732864
step: 320, loss: 0.008215058594942093
step: 330, loss: 0.05193036422133446
step: 340, loss: 0.006040559150278568
step: 350, loss: 0.029575714841485023
step: 360, loss: 0.05300607904791832
step: 370, loss: 0.17110230028629303
step: 380, loss: 0.04930303618311882
step: 390, loss: 0.1352633684873581
step: 400, loss: 0.09009649604558945
step: 410, loss: 0.016828248277306557
step: 420, loss: 0.08955767005681992
step: 430, loss: 0.1328592151403427
step: 440, loss: 0.057783614844083786
step: 450, loss: 0.06129245087504387
step: 460, loss: 0.06279349327087402
step: 470, loss: 0.022076163440942764
step: 480, loss: 0.08173713833093643
step: 490, loss: 0.09215981513261795
step: 500, loss: 0.041754890233278275
step: 510, loss: 0.03138646483421326
step: 520, loss: 0.013314045034348965
step: 530, loss: 0.07506650686264038
step: 540, loss: 0.03805624321103096
step: 550, loss: 0.14694850146770477
step: 560, loss: 0.0005855552735738456
step: 570, loss: 0.025281785055994987
step: 580, loss: 0.0546424575150013
step: 590, loss: 0.07641692459583282
step: 600, loss: 0.056897781789302826
step: 610, loss: 0.08121687918901443
step: 620, loss: 0.06995882093906403
step: 630, loss: 0.04707736521959305
step: 640, loss: 0.046955034136772156
step: 650, loss: 0.0035047277342528105
step: 660, loss: 0.027656380087137222
step: 670, loss: 0.05247404798865318
step: 680, loss: 0.021458163857460022
step: 690, loss: 0.021448908373713493
step: 700, loss: 0.2440803050994873
step: 710, loss: 0.056382372975349426
step: 720, loss: 0.11030004918575287
step: 730, loss: 0.11054553091526031
step: 740, loss: 0.058559589087963104
step: 750, loss: 0.06510496139526367
step: 760, loss: 0.12942153215408325
step: 770, loss: 0.04748481884598732
step: 780, loss: 0.04171708971261978
step: 790, loss: 0.03584999218583107
step: 800, loss: 0.0700356736779213
step: 810, loss: 0.038223110139369965
step: 820, loss: 0.04373083636164665
step: 830, loss: 0.0569935217499733
step: 840, loss: 0.062490109354257584
step: 850, loss: 0.12456803023815155
step: 860, loss: 0.06264844536781311
step: 870, loss: 0.03764843940734863
step: 880, loss: 0.10189634561538696
step: 890, loss: 0.14912383258342743
step: 900, loss: 0.0416647344827652
step: 910, loss: 0.0441230908036232
step: 920, loss: 0.11144548654556274
step: 930, loss: 0.01984827034175396
step: 940, loss: 0.06508675962686539
step: 950, loss: 0.053834278136491776
step: 960, loss: 0.06853070110082626
step: 970, loss: 0.10660049319267273
step: 980, loss: 0.04142242670059204
step: 990, loss: 0.10303934663534164
step: 1000, loss: 0.09135806560516357
step: 1010, loss: 0.04618103429675102
step: 1020, loss: 0.044475674629211426
step: 1030, loss: 0.14055781066417694
step: 1040, loss: 0.04504380002617836
step: 1050, loss: 0.04269476979970932
step: 1060, loss: 0.030417367815971375
step: 1070, loss: 0.08467740565538406
epoch 12: dev_f1=0.920054819552307, f1=0.9149908592321755, best_f1=0.9305555555555556
step: 0, loss: 0.058095742017030716
step: 10, loss: 0.001786807319149375
step: 20, loss: 0.008828170597553253
step: 30, loss: 0.06386935710906982
step: 40, loss: 0.041760679334402084
step: 50, loss: 0.08867555856704712
step: 60, loss: 0.040697719901800156
step: 70, loss: 2.725994272623211e-05
step: 80, loss: 0.032963912934064865
step: 90, loss: 0.05093163251876831
step: 100, loss: 0.040366437286138535
step: 110, loss: 0.0015083152102306485
step: 120, loss: 0.043157003819942474
step: 130, loss: 0.012122917920351028
step: 140, loss: 0.06633036583662033
step: 150, loss: 0.021741991862654686
step: 160, loss: 0.03429221734404564
step: 170, loss: 0.04703972116112709
step: 180, loss: 0.05418699234724045
step: 190, loss: 0.07729164510965347
step: 200, loss: 0.032801371067762375
step: 210, loss: 0.02776111662387848
step: 220, loss: 0.0312880240380764
step: 230, loss: 0.018345234915614128
step: 240, loss: 0.08397325873374939
step: 250, loss: 0.05046074092388153
step: 260, loss: 0.10134513676166534
step: 270, loss: 0.09408780187368393
step: 280, loss: 0.01909026689827442
step: 290, loss: 0.03638697415590286
step: 300, loss: 0.011112590320408344
step: 310, loss: 0.13345375657081604
step: 320, loss: 0.05512138456106186
step: 330, loss: 0.059492580592632294
step: 340, loss: 0.0018350218888372183
step: 350, loss: 0.0842118039727211
step: 360, loss: 3.128189200651832e-05
step: 370, loss: 0.05114931985735893
step: 380, loss: 0.031277887523174286
step: 390, loss: 0.15201658010482788
step: 400, loss: 0.21324552595615387
step: 410, loss: 0.13505548238754272
step: 420, loss: 0.1004813015460968
step: 430, loss: 0.039935264736413956
step: 440, loss: 0.10246382653713226
step: 450, loss: 0.025747761130332947
step: 460, loss: 0.03934403136372566
step: 470, loss: 0.05319039896130562
step: 480, loss: 0.028511693701148033
step: 490, loss: 0.07793006300926208
step: 500, loss: 0.15967132151126862
step: 510, loss: 0.022470351308584213
step: 520, loss: 0.04233800619840622
step: 530, loss: 0.01999329961836338
step: 540, loss: 0.09132079780101776
step: 550, loss: 0.054228417575359344
step: 560, loss: 0.007588043808937073
step: 570, loss: 0.024974698200821877
step: 580, loss: 0.014619315043091774
step: 590, loss: 0.010646268725395203
step: 600, loss: 0.0818394273519516
step: 610, loss: 0.10779417306184769
step: 620, loss: 0.08032538741827011
step: 630, loss: 0.04414581134915352
step: 640, loss: 0.05853855982422829
step: 650, loss: 0.045830968767404556
step: 660, loss: 0.11188046634197235
step: 670, loss: 0.012132665142416954
step: 680, loss: 0.03364028036594391
step: 690, loss: 0.11152403056621552
step: 700, loss: 0.006995531730353832
step: 710, loss: 0.032576415687799454
step: 720, loss: 0.0007997366483323276
step: 730, loss: 0.08302891254425049
step: 740, loss: 0.02429179660975933
step: 750, loss: 0.03359607607126236
step: 760, loss: 0.09873057901859283
step: 770, loss: 0.03125087171792984
step: 780, loss: 0.1287727802991867
step: 790, loss: 0.04870595782995224
step: 800, loss: 0.1477021723985672
step: 810, loss: 0.030940717086195946
step: 820, loss: 0.0501466728746891
step: 830, loss: 0.03912687301635742
step: 840, loss: 0.01945341005921364
step: 850, loss: 0.0520423986017704
step: 860, loss: 0.10230160504579544
step: 870, loss: 0.047639794647693634
step: 880, loss: 0.044403985142707825
step: 890, loss: 0.05565563961863518
step: 900, loss: 0.23678554594516754
step: 910, loss: 0.06701020896434784
step: 920, loss: 0.012010529637336731
step: 930, loss: 0.06310374289751053
step: 940, loss: 0.03553631901741028
step: 950, loss: 0.012612871825695038
step: 960, loss: 0.04756302013993263
step: 970, loss: 0.04465439170598984
step: 980, loss: 0.09223394840955734
step: 990, loss: 0.15070919692516327
step: 1000, loss: 0.1733950823545456
step: 1010, loss: 0.10622894018888474
step: 1020, loss: 0.05156312882900238
step: 1030, loss: 0.023467790335416794
step: 1040, loss: 0.17711485922336578
step: 1050, loss: 0.03878792002797127
step: 1060, loss: 0.0705941915512085
step: 1070, loss: 0.01596517488360405
epoch 13: dev_f1=0.9350770667912189, f1=0.9301675977653632, best_f1=0.9305555555555556
step: 0, loss: 0.0463893823325634
step: 10, loss: 0.023622727021574974
step: 20, loss: 0.07742542028427124
step: 30, loss: 0.02562198042869568
step: 40, loss: 0.020984066650271416
step: 50, loss: 0.00424164067953825
step: 60, loss: 0.0788070410490036
step: 70, loss: 0.07687123864889145
step: 80, loss: 0.10248275101184845
step: 90, loss: 0.0454171746969223
step: 100, loss: 0.07217075675725937
step: 110, loss: 0.06017132103443146
step: 120, loss: 0.0017800952773541212
step: 130, loss: 0.05978592857718468
step: 140, loss: 0.08555100113153458
step: 150, loss: 0.062375396490097046
step: 160, loss: 0.0633019208908081
step: 170, loss: 0.08721909672021866
step: 180, loss: 0.11437281221151352
step: 190, loss: 0.01665102317929268
step: 200, loss: 0.06199078634381294
step: 210, loss: 0.1002739816904068
step: 220, loss: 0.03438398614525795
step: 230, loss: 0.020108593627810478
step: 240, loss: 0.07796970009803772
step: 250, loss: 0.011761682108044624
step: 260, loss: 0.08132763206958771
step: 270, loss: 0.0886736735701561
step: 280, loss: 0.08890589326620102
step: 290, loss: 0.08160034567117691
step: 300, loss: 0.018564026802778244
step: 310, loss: 0.06879494339227676
step: 320, loss: 0.06239629536867142
step: 330, loss: 0.009970453567802906
step: 340, loss: 0.048436086624860764
step: 350, loss: 0.026956932619214058
step: 360, loss: 0.02207436040043831
step: 370, loss: 0.02140575461089611
step: 380, loss: 0.04660547897219658
step: 390, loss: 0.07178189605474472
step: 400, loss: 0.00014619245484936982
step: 410, loss: 0.013051571324467659
step: 420, loss: 0.04677959531545639
step: 430, loss: 0.005994705017656088
step: 440, loss: 0.0009866676991805434
step: 450, loss: 0.04493798315525055
step: 460, loss: 0.046900153160095215
step: 470, loss: 0.028431538492441177
step: 480, loss: 0.0036349105648696423
step: 490, loss: 0.07066233456134796
step: 500, loss: 0.08907286822795868
step: 510, loss: 0.08186884969472885
step: 520, loss: 0.022633254528045654
step: 530, loss: 0.09056591987609863
step: 540, loss: 0.10830069333314896
step: 550, loss: 0.008409593254327774
step: 560, loss: 0.07319026440382004
step: 570, loss: 0.05102295055985451
step: 580, loss: 0.08477673679590225
step: 590, loss: 0.05326038599014282
step: 600, loss: 0.11326777935028076
step: 610, loss: 0.0673300102353096
step: 620, loss: 0.048445556312799454
step: 630, loss: 0.13015800714492798
step: 640, loss: 0.061777155846357346
step: 650, loss: 0.0312055554240942
step: 660, loss: 0.04749218747019768
step: 670, loss: 0.05428336188197136
step: 680, loss: 0.012274282053112984
step: 690, loss: 0.06643830239772797
step: 700, loss: 0.0002003391127800569
step: 710, loss: 0.03291347250342369
step: 720, loss: 0.009051714092493057
step: 730, loss: 0.06220751628279686
step: 740, loss: 0.004502096679061651
step: 750, loss: 0.04017506167292595
step: 760, loss: 0.010241826064884663
step: 770, loss: 0.05743953585624695
step: 780, loss: 0.14971435070037842
step: 790, loss: 0.08991437405347824
step: 800, loss: 0.04305478557944298
step: 810, loss: 0.029384560883045197
step: 820, loss: 0.054352883249521255
step: 830, loss: 0.15744057297706604
step: 840, loss: 0.06636442244052887
step: 850, loss: 0.02324688248336315
step: 860, loss: 0.024328645318746567
step: 870, loss: 0.08874860405921936
step: 880, loss: 0.08187311887741089
step: 890, loss: 0.013134024105966091
step: 900, loss: 0.032250937074422836
step: 910, loss: 0.009630760177969933
step: 920, loss: 0.01782178319990635
step: 930, loss: 0.08645071089267731
step: 940, loss: 0.04212471470236778
step: 950, loss: 0.07457797974348068
step: 960, loss: 0.06654582172632217
step: 970, loss: 0.004777491558343172
step: 980, loss: 0.010024037212133408
step: 990, loss: 0.06849697977304459
step: 1000, loss: 0.028083419427275658
step: 1010, loss: 0.2074730098247528
step: 1020, loss: 0.055926233530044556
step: 1030, loss: 0.013858545571565628
step: 1040, loss: 0.05314348265528679
step: 1050, loss: 0.04032596945762634
step: 1060, loss: 0.016042856499552727
step: 1070, loss: 0.05458582192659378
epoch 14: dev_f1=0.9350046425255338, f1=0.9327770050996754, best_f1=0.9305555555555556
step: 0, loss: 0.019647149369120598
step: 10, loss: 0.03198505565524101
step: 20, loss: 0.08546975255012512
step: 30, loss: 0.03386656567454338
step: 40, loss: 0.06383263319730759
step: 50, loss: 0.046560388058423996
step: 60, loss: 0.1062462255358696
step: 70, loss: 0.017943790182471275
step: 80, loss: 0.11880429834127426
step: 90, loss: 0.03961513191461563
step: 100, loss: 0.0246062520891428
step: 110, loss: 0.14089052379131317
step: 120, loss: 2.189640872529708e-05
step: 130, loss: 1.7314639990217984e-05
step: 140, loss: 0.04804161563515663
step: 150, loss: 0.12012304365634918
step: 160, loss: 0.05514499172568321
step: 170, loss: 0.08835476636886597
step: 180, loss: 0.00010033290163846686
step: 190, loss: 0.07388249039649963
step: 200, loss: 0.05270582064986229
step: 210, loss: 0.03602052107453346
step: 220, loss: 0.03523635119199753
step: 230, loss: 0.050866011530160904
step: 240, loss: 0.026377230882644653
step: 250, loss: 0.08952575922012329
step: 260, loss: 0.031953226774930954
step: 270, loss: 0.02545659802854061
step: 280, loss: 0.09852742403745651
step: 290, loss: 0.09669657796621323
step: 300, loss: 4.745771730085835e-05
step: 310, loss: 0.22218158841133118
step: 320, loss: 0.06731384247541428
step: 330, loss: 0.02667008340358734
step: 340, loss: 0.08268164098262787
step: 350, loss: 0.10751831531524658
step: 360, loss: 0.05374101176857948
step: 370, loss: 0.10103003680706024
step: 380, loss: 0.10285034030675888
step: 390, loss: 0.058742329478263855
step: 400, loss: 0.0849844217300415
step: 410, loss: 0.02068072371184826
step: 420, loss: 0.05021324381232262
step: 430, loss: 0.10802844911813736
step: 440, loss: 0.06290321797132492
step: 450, loss: 0.015200979076325893
step: 460, loss: 0.05385381728410721
step: 470, loss: 0.040604520589113235
step: 480, loss: 0.027623852714896202
step: 490, loss: 0.05551126226782799
step: 500, loss: 0.04306766390800476
step: 510, loss: 0.0741037055850029
step: 520, loss: 0.06606583297252655
step: 530, loss: 0.11097399145364761
step: 540, loss: 0.10817430913448334
step: 550, loss: 0.08596613258123398
step: 560, loss: 0.11809561401605606
step: 570, loss: 0.03286096453666687
step: 580, loss: 0.03507990762591362
step: 590, loss: 0.019341811537742615
step: 600, loss: 0.002626704052090645
step: 610, loss: 0.08146920055150986
step: 620, loss: 0.058818645775318146
step: 630, loss: 0.04779050126671791
step: 640, loss: 0.06679994612932205
step: 650, loss: 0.027739493176341057
step: 660, loss: 0.022524720057845116
step: 670, loss: 0.06591838598251343
step: 680, loss: 0.009567645378410816
step: 690, loss: 0.049347035586833954
step: 700, loss: 0.051027555018663406
step: 710, loss: 0.03071482852101326
step: 720, loss: 0.014452206902205944
step: 730, loss: 0.03806394711136818
step: 740, loss: 0.10685162991285324
step: 750, loss: 0.05055192485451698
step: 760, loss: 0.04072665795683861
step: 770, loss: 0.12789484858512878
step: 780, loss: 0.0756298378109932
step: 790, loss: 0.040759194642305374
step: 800, loss: 0.12542316317558289
step: 810, loss: 0.030463173985481262
step: 820, loss: 0.04579056426882744
step: 830, loss: 0.045390646904706955
step: 840, loss: 0.0370732881128788
step: 850, loss: 0.00012477277778089046
step: 860, loss: 0.09589054435491562
step: 870, loss: 0.07322373241186142
step: 880, loss: 0.031169468536973
step: 890, loss: 0.09401204437017441
step: 900, loss: 0.013832064345479012
step: 910, loss: 0.06982093304395676
step: 920, loss: 0.11450288444757462
step: 930, loss: 0.09849023818969727
step: 940, loss: 0.09473618865013123
step: 950, loss: 0.06507948040962219
step: 960, loss: 0.039865221828222275
step: 970, loss: 0.029931221157312393
step: 980, loss: 0.05641107261180878
step: 990, loss: 0.03929834067821503
step: 1000, loss: 0.02777164615690708
step: 1010, loss: 0.025008665397763252
step: 1020, loss: 0.059076160192489624
step: 1030, loss: 0.04570860415697098
step: 1040, loss: 0.0523822084069252
step: 1050, loss: 0.04387320578098297
step: 1060, loss: 2.9446042390190996e-05
step: 1070, loss: 0.031176744028925896
epoch 15: dev_f1=0.9316360207449317, f1=0.9307116104868914, best_f1=0.9305555555555556
step: 0, loss: 0.0003605321981012821
step: 10, loss: 0.01761111058294773
step: 20, loss: 0.032274745404720306
step: 30, loss: 0.024020984768867493
step: 40, loss: 0.04598370939493179
step: 50, loss: 0.035596493631601334
step: 60, loss: 0.04487389326095581
step: 70, loss: 0.042861249297857285
step: 80, loss: 0.09909644722938538
step: 90, loss: 0.05155075341463089
step: 100, loss: 0.03649115562438965
step: 110, loss: 0.05244412273168564
step: 120, loss: 0.24049140512943268
step: 130, loss: 0.03549803048372269
step: 140, loss: 0.015449046157300472
step: 150, loss: 0.030429380014538765
step: 160, loss: 0.06449286639690399
step: 170, loss: 0.0027349162846803665
step: 180, loss: 0.039473772048950195
step: 190, loss: 0.02895982190966606
step: 200, loss: 0.04178418591618538
step: 210, loss: 0.024820584803819656
step: 220, loss: 0.02006533183157444
step: 230, loss: 0.08384869992733002
step: 240, loss: 0.0557701401412487
step: 250, loss: 0.06546609103679657
step: 260, loss: 0.13349761068820953
step: 270, loss: 0.02794157899916172
step: 280, loss: 0.043232519179582596
step: 290, loss: 0.01614864356815815
step: 300, loss: 0.09776004403829575
step: 310, loss: 0.3494957387447357
step: 320, loss: 0.06866519153118134
step: 330, loss: 0.08320613950490952
step: 340, loss: 0.08954262733459473
step: 350, loss: 0.022880319505929947
step: 360, loss: 0.04595896601676941
step: 370, loss: 0.04690839350223541
step: 380, loss: 0.06161591783165932
step: 390, loss: 0.021744504570961
step: 400, loss: 0.025931542739272118
step: 410, loss: 0.08075177669525146
step: 420, loss: 0.0581858865916729
step: 430, loss: 0.0006157232564873993
step: 440, loss: 0.037530940026044846
step: 450, loss: 0.0015602849889546633
step: 460, loss: 0.05360409617424011
step: 470, loss: 0.030065322294831276
step: 480, loss: 0.0727781131863594
step: 490, loss: 0.10856305807828903
step: 500, loss: 0.03066626936197281
step: 510, loss: 0.11635687202215195
step: 520, loss: 0.07264255732297897
step: 530, loss: 2.753937224042602e-05
step: 540, loss: 0.09636221081018448
step: 550, loss: 0.014828349463641644
step: 560, loss: 0.0178359467536211
step: 570, loss: 0.09360901266336441
step: 580, loss: 0.04503120854496956
step: 590, loss: 0.02987445332109928
step: 600, loss: 2.5788694983930327e-05
step: 610, loss: 0.10285210609436035
step: 620, loss: 0.0676274299621582
step: 630, loss: 0.06776005774736404
step: 640, loss: 0.028046676889061928
step: 650, loss: 0.08081042766571045
step: 660, loss: 0.10812287032604218
step: 670, loss: 0.047389328479766846
step: 680, loss: 0.01879740320146084
step: 690, loss: 0.047061510384082794
step: 700, loss: 0.03161492198705673
step: 710, loss: 0.11861447244882584
step: 720, loss: 0.0867508128285408
step: 730, loss: 0.060269154608249664
step: 740, loss: 0.03708334639668465
step: 750, loss: 0.07974732667207718
step: 760, loss: 0.10043203085660934
step: 770, loss: 0.026068760082125664
step: 780, loss: 1.649160185479559e-05
step: 790, loss: 0.046924736350774765
step: 800, loss: 0.10973498970270157
step: 810, loss: 0.049664825201034546
step: 820, loss: 0.038008224219083786
step: 830, loss: 0.04212866351008415
step: 840, loss: 0.08150242269039154
step: 850, loss: 0.06914035230875015
step: 860, loss: 0.018274707719683647
step: 870, loss: 0.07851121574640274
step: 880, loss: 0.02550441585481167
step: 890, loss: 0.04099030792713165
step: 900, loss: 0.01583895832300186
step: 910, loss: 0.18910016119480133
step: 920, loss: 0.10604790598154068
step: 930, loss: 0.13372324407100677
step: 940, loss: 0.030942317098379135
step: 950, loss: 0.03581665828824043
step: 960, loss: 0.06755299121141434
step: 970, loss: 0.05005590245127678
step: 980, loss: 0.030550682917237282
step: 990, loss: 0.09011414647102356
step: 1000, loss: 0.015020806342363358
step: 1010, loss: 0.038253769278526306
step: 1020, loss: 0.08857458084821701
step: 1030, loss: 0.05659663304686546
step: 1040, loss: 0.0940094143152237
step: 1050, loss: 0.08636269718408585
step: 1060, loss: 0.0010369080118834972
step: 1070, loss: 0.037748485803604126
epoch 16: dev_f1=0.9341317365269461, f1=0.9301470588235294, best_f1=0.9305555555555556
step: 0, loss: 0.04115603491663933
step: 10, loss: 0.11435128003358841
step: 20, loss: 0.021432790905237198
step: 30, loss: 0.012099044397473335
step: 40, loss: 0.013375943526625633
step: 50, loss: 0.04614800214767456
step: 60, loss: 0.004450060427188873
step: 70, loss: 0.0788429006934166
step: 80, loss: 0.0025888129603117704
step: 90, loss: 0.07401960343122482
step: 100, loss: 0.04117966443300247
step: 110, loss: 0.04803472384810448
step: 120, loss: 0.0008690928225405514
step: 130, loss: 0.10720036178827286
step: 140, loss: 0.05467065051198006
step: 150, loss: 0.06280432641506195
step: 160, loss: 0.008176782168447971
step: 170, loss: 0.04584651440382004
step: 180, loss: 0.0928889662027359
step: 190, loss: 0.0701482892036438
step: 200, loss: 0.041778720915317535
step: 210, loss: 0.06922481954097748
step: 220, loss: 0.06960340589284897
step: 230, loss: 0.03886652737855911
step: 240, loss: 0.03912460803985596
step: 250, loss: 0.09007672965526581
step: 260, loss: 0.06971090286970139
step: 270, loss: 0.09002029895782471
step: 280, loss: 0.015309524722397327
step: 290, loss: 0.027967488393187523
step: 300, loss: 0.06969829648733139
step: 310, loss: 0.0005033975467085838
step: 320, loss: 0.05043408274650574
step: 330, loss: 0.0005044814315624535
step: 340, loss: 0.02659398689866066
step: 350, loss: 0.04252848029136658
step: 360, loss: 0.08127725124359131
step: 370, loss: 0.014906647615134716
step: 380, loss: 0.025441298261284828
step: 390, loss: 0.04412579908967018
step: 400, loss: 0.0033418629318475723
step: 410, loss: 0.03733692690730095
step: 420, loss: 0.06678051501512527
step: 430, loss: 0.004888306371867657
step: 440, loss: 0.12429481744766235
step: 450, loss: 0.012843419797718525
step: 460, loss: 0.050065796822309494
step: 470, loss: 0.02510213851928711
step: 480, loss: 0.3254920244216919
step: 490, loss: 0.012568258680403233
step: 500, loss: 0.09341946989297867
step: 510, loss: 0.061419010162353516
step: 520, loss: 0.03873006999492645
step: 530, loss: 0.026476718485355377
step: 540, loss: 0.016240833327174187
step: 550, loss: 0.0445685014128685
step: 560, loss: 0.024732166901230812
step: 570, loss: 0.016744719818234444
step: 580, loss: 0.024595744907855988
step: 590, loss: 0.020495254546403885
step: 600, loss: 0.09805768728256226
step: 610, loss: 0.0186405461281538
step: 620, loss: 0.04768941178917885
step: 630, loss: 0.06216178461909294
step: 640, loss: 0.04700550436973572
step: 650, loss: 0.0551944263279438
step: 660, loss: 0.024728041142225266
step: 670, loss: 0.11338035017251968
step: 680, loss: 0.03743236884474754
step: 690, loss: 0.025125915184617043
step: 700, loss: 0.00038861887878738344
step: 710, loss: 0.051415055990219116
step: 720, loss: 0.04483611136674881
step: 730, loss: 0.016689101234078407
step: 740, loss: 0.08456864953041077
step: 750, loss: 0.06749176234006882
step: 760, loss: 0.040366120636463165
step: 770, loss: 0.024255938827991486
step: 780, loss: 0.03063824214041233
step: 790, loss: 6.253179890336469e-05
step: 800, loss: 1.881974640127737e-05
step: 810, loss: 0.05156675726175308
step: 820, loss: 0.05475537106394768
step: 830, loss: 0.04129336029291153
step: 840, loss: 0.07503681629896164
step: 850, loss: 0.07819145917892456
step: 860, loss: 0.04724912345409393
step: 870, loss: 0.10380582511425018
step: 880, loss: 0.09286816418170929
step: 890, loss: 4.270538192940876e-05
step: 900, loss: 0.03678271546959877
step: 910, loss: 0.006656787823885679
step: 920, loss: 0.03933965787291527
step: 930, loss: 0.11656951904296875
step: 940, loss: 0.009553197771310806
step: 950, loss: 0.012278665788471699
step: 960, loss: 0.05081532523036003
step: 970, loss: 0.008814889937639236
step: 980, loss: 0.04845622926950455
step: 990, loss: 0.05995291844010353
step: 1000, loss: 0.010832393541932106
step: 1010, loss: 0.022890793159604073
step: 1020, loss: 0.06193390488624573
step: 1030, loss: 0.019297687336802483
step: 1040, loss: 0.04207991808652878
step: 1050, loss: 0.1360112428665161
step: 1060, loss: 0.09884903579950333
step: 1070, loss: 2.0354056687210687e-05
epoch 17: dev_f1=0.9292364990689013, f1=0.9267840593141797, best_f1=0.9305555555555556
step: 0, loss: 0.08066896349191666
step: 10, loss: 0.0788721814751625
step: 20, loss: 0.029720855876803398
step: 30, loss: 0.020820431411266327
step: 40, loss: 0.11180323362350464
step: 50, loss: 0.027639465406537056
step: 60, loss: 0.060985270887613297
step: 70, loss: 0.0005011112079955637
step: 80, loss: 0.07756637036800385
step: 90, loss: 0.028719909489154816
step: 100, loss: 0.05041034147143364
step: 110, loss: 0.05304105952382088
step: 120, loss: 0.03944677114486694
step: 130, loss: 0.035675495862960815
step: 140, loss: 0.09575650840997696
step: 150, loss: 0.016960255801677704
step: 160, loss: 0.04544499143958092
step: 170, loss: 0.057906508445739746
step: 180, loss: 0.011228542774915695
step: 190, loss: 0.06952247768640518
step: 200, loss: 0.08369756489992142
step: 210, loss: 0.01700815185904503
step: 220, loss: 0.051653679460287094
step: 230, loss: 0.07550005614757538
step: 240, loss: 0.1302938461303711
step: 250, loss: 0.06561987847089767
step: 260, loss: 0.03861847519874573
step: 270, loss: 0.02649638056755066
step: 280, loss: 0.04780864715576172
step: 290, loss: 0.09057565033435822
step: 300, loss: 1.3537525774154346e-05
step: 310, loss: 0.055396828800439835
step: 320, loss: 0.009248190559446812
step: 330, loss: 0.07840098440647125
step: 340, loss: 0.062222663313150406
step: 350, loss: 0.027378622442483902
step: 360, loss: 0.05437147244811058
step: 370, loss: 0.04627775028347969
step: 380, loss: 0.03516898676753044
step: 390, loss: 0.08462679386138916
step: 400, loss: 0.03372665122151375
step: 410, loss: 0.03501972183585167
step: 420, loss: 0.052968479692935944
step: 430, loss: 0.0480717234313488
step: 440, loss: 0.017403872683644295
step: 450, loss: 0.04707875847816467
step: 460, loss: 0.03935754671692848
step: 470, loss: 0.0323575884103775
step: 480, loss: 0.07497706264257431
step: 490, loss: 0.07100076228380203
step: 500, loss: 0.06326991319656372
step: 510, loss: 0.0017485368298366666
step: 520, loss: 0.08530768007040024
step: 530, loss: 0.03927942365407944
step: 540, loss: 0.09167584776878357
step: 550, loss: 0.102988600730896
step: 560, loss: 0.01296606007963419
step: 570, loss: 0.021543016657233238
step: 580, loss: 0.04323190078139305
step: 590, loss: 0.007527752313762903
step: 600, loss: 0.08362194895744324
step: 610, loss: 0.0005896943039260805
step: 620, loss: 0.03216864541172981
step: 630, loss: 0.07177411019802094
step: 640, loss: 0.058973923325538635
step: 650, loss: 0.05570807680487633
step: 660, loss: 0.05269540473818779
step: 670, loss: 0.050883699208498
step: 680, loss: 0.01242838054895401
step: 690, loss: 0.06195611506700516
step: 700, loss: 0.0270615853369236
step: 710, loss: 0.016262661665678024
step: 720, loss: 0.04732714965939522
step: 730, loss: 0.019358986988663673
step: 740, loss: 0.0670415461063385
step: 750, loss: 0.01953635737299919
step: 760, loss: 0.023869365453720093
step: 770, loss: 0.04054836183786392
step: 780, loss: 0.07090060412883759
step: 790, loss: 0.04609828442335129
step: 800, loss: 0.03750276938080788
step: 810, loss: 0.04073821380734444
step: 820, loss: 0.05872434377670288
step: 830, loss: 0.01941695809364319
step: 840, loss: 0.049372199922800064
step: 850, loss: 0.03790641948580742
step: 860, loss: 0.0569518506526947
step: 870, loss: 0.00020414686878211796
step: 880, loss: 0.19190464913845062
step: 890, loss: 0.02998918667435646
step: 900, loss: 0.03763270005583763
step: 910, loss: 0.05807862430810928
step: 920, loss: 0.08138454705476761
step: 930, loss: 0.02913452312350273
step: 940, loss: 0.05671612545847893
step: 950, loss: 0.0948108658194542
step: 960, loss: 0.0002634910342749208
step: 970, loss: 0.0449543260037899
step: 980, loss: 0.07598850876092911
step: 990, loss: 0.11541571468114853
step: 1000, loss: 0.031634971499443054
step: 1010, loss: 0.03217928856611252
step: 1020, loss: 0.022908508777618408
step: 1030, loss: 0.004339899867773056
step: 1040, loss: 0.03371133282780647
step: 1050, loss: 0.018969643861055374
step: 1060, loss: 0.028827223926782608
step: 1070, loss: 0.03124508634209633
epoch 18: dev_f1=0.9279700654817586, f1=0.9257356375525455, best_f1=0.9305555555555556
step: 0, loss: 0.0840245932340622
step: 10, loss: 0.0760243609547615
step: 20, loss: 0.027046455070376396
step: 30, loss: 0.03335561603307724
step: 40, loss: 0.03911298140883446
step: 50, loss: 0.08944123983383179
step: 60, loss: 0.017256442457437515
step: 70, loss: 0.009901459328830242
step: 80, loss: 0.0687536969780922
step: 90, loss: 0.02632015570998192
step: 100, loss: 0.004467392805963755
step: 110, loss: 0.04034394398331642
step: 120, loss: 0.09209518879652023
step: 130, loss: 0.039190586656332016
step: 140, loss: 0.03784099221229553
step: 150, loss: 0.020332204177975655
step: 160, loss: 0.11425699293613434
step: 170, loss: 0.1098286509513855
step: 180, loss: 0.017191598191857338
step: 190, loss: 0.10608663409948349
step: 200, loss: 0.047119513154029846
step: 210, loss: 0.014627930708229542
step: 220, loss: 0.02188064344227314
step: 230, loss: 0.033377524465322495
step: 240, loss: 0.01421617902815342
step: 250, loss: 0.023718470707535744
step: 260, loss: 0.04011184722185135
step: 270, loss: 0.05038997903466225
step: 280, loss: 0.05009758099913597
step: 290, loss: 0.00016897497698664665
step: 300, loss: 0.027698252350091934
step: 310, loss: 0.01441391184926033
step: 320, loss: 0.031266458332538605
step: 330, loss: 0.00019210092432331294
step: 340, loss: 0.01025822851806879
step: 350, loss: 0.030653731897473335
step: 360, loss: 0.04668346419930458
step: 370, loss: 0.007697219029068947
step: 380, loss: 0.0673057809472084
step: 390, loss: 0.01785682514309883
step: 400, loss: 0.04909641295671463
step: 410, loss: 0.03275031968951225
step: 420, loss: 0.015071283094584942
step: 430, loss: 0.05801554396748543
step: 440, loss: 0.07609738409519196
step: 450, loss: 0.03130899742245674
step: 460, loss: 0.047491058707237244
step: 470, loss: 0.07523222267627716
step: 480, loss: 0.004513707477599382
step: 490, loss: 4.186193837085739e-05
step: 500, loss: 0.024262022227048874
step: 510, loss: 0.09870758652687073
step: 520, loss: 0.07012352347373962
step: 530, loss: 0.07466578483581543
step: 540, loss: 0.03080965019762516
step: 550, loss: 0.1068967804312706
step: 560, loss: 0.015690725296735764
step: 570, loss: 0.033780090510845184
step: 580, loss: 0.022016840055584908
step: 590, loss: 0.05766219273209572
step: 600, loss: 0.1576819270849228
step: 610, loss: 0.09364351630210876
step: 620, loss: 0.01879575476050377
step: 630, loss: 0.10128745436668396
step: 640, loss: 1.5947631254675798e-05
step: 650, loss: 0.04030270874500275
step: 660, loss: 0.0868859812617302
step: 670, loss: 0.05014601722359657
step: 680, loss: 0.09404456615447998
step: 690, loss: 0.0458514541387558
step: 700, loss: 0.0964018926024437
step: 710, loss: 0.04295061528682709
step: 720, loss: 0.026121877133846283
step: 730, loss: 0.07204607129096985
step: 740, loss: 0.02062242291867733
step: 750, loss: 0.007383592892438173
step: 760, loss: 0.02342119626700878
step: 770, loss: 0.017073778435587883
step: 780, loss: 0.023580141365528107
step: 790, loss: 0.024548707529902458
step: 800, loss: 0.0388859324157238
step: 810, loss: 0.04783983528614044
step: 820, loss: 0.00901360809803009
step: 830, loss: 0.07487532496452332
step: 840, loss: 0.10158640146255493
step: 850, loss: 0.016209248453378677
step: 860, loss: 0.013692081905901432
step: 870, loss: 0.07055417448282242
step: 880, loss: 0.0003209920832887292
step: 890, loss: 0.00016718449478503317
step: 900, loss: 0.06558843702077866
step: 910, loss: 0.05171126499772072
step: 920, loss: 0.07473959028720856
step: 930, loss: 0.06323833763599396
step: 940, loss: 0.0556802973151207
step: 950, loss: 0.03672907128930092
step: 960, loss: 0.03938165679574013
step: 970, loss: 0.01661703921854496
step: 980, loss: 0.011104929260909557
step: 990, loss: 0.026799550279974937
step: 1000, loss: 0.0472925528883934
step: 1010, loss: 0.013959616422653198
step: 1020, loss: 0.04448555037379265
step: 1030, loss: 0.0509331114590168
step: 1040, loss: 0.055935297161340714
step: 1050, loss: 2.32218317250954e-05
step: 1060, loss: 0.07953318953514099
step: 1070, loss: 0.00010045807721326128
epoch 19: dev_f1=0.9293785310734464, f1=0.924953095684803, best_f1=0.9305555555555556
step: 0, loss: 0.047648895531892776
step: 10, loss: 0.08154229819774628
step: 20, loss: 0.05603973940014839
step: 30, loss: 0.05438198149204254
step: 40, loss: 0.020994096994400024
step: 50, loss: 0.050088267773389816
step: 60, loss: 0.05897644907236099
step: 70, loss: 0.02008875645697117
step: 80, loss: 0.0300038680434227
step: 90, loss: 4.4238942791707814e-05
step: 100, loss: 0.06573430448770523
step: 110, loss: 0.0005919075338169932
step: 120, loss: 5.645029523293488e-05
step: 130, loss: 0.07368536293506622
step: 140, loss: 0.02813582867383957
step: 150, loss: 0.051278699189424515
step: 160, loss: 0.00013789536023978144
step: 170, loss: 0.00023568850883748382
step: 180, loss: 0.04603852704167366
step: 190, loss: 0.022205565124750137
step: 200, loss: 0.1709776073694229
step: 210, loss: 0.09609000384807587
step: 220, loss: 0.05596001073718071
step: 230, loss: 0.05069362372159958
step: 240, loss: 0.03677455335855484
step: 250, loss: 0.060895368456840515
step: 260, loss: 0.08832898736000061
step: 270, loss: 1.892013278848026e-05
step: 280, loss: 0.011837216094136238
step: 290, loss: 0.06886686384677887
step: 300, loss: 0.038794729858636856
step: 310, loss: 0.015348868444561958
step: 320, loss: 0.01559241022914648
step: 330, loss: 0.023899149149656296
step: 340, loss: 0.015037096105515957
step: 350, loss: 0.0814986377954483
step: 360, loss: 0.032351311296224594
step: 370, loss: 0.11962170153856277
step: 380, loss: 0.04698321223258972
step: 390, loss: 0.04575138911604881
step: 400, loss: 0.05397472158074379
step: 410, loss: 5.578403943218291e-05
step: 420, loss: 0.09057724475860596
step: 430, loss: 0.01257252600044012
step: 440, loss: 0.018692495301365852
step: 450, loss: 0.07927948981523514
step: 460, loss: 0.06875985860824585
step: 470, loss: 0.040862202644348145
step: 480, loss: 0.05077118054032326
step: 490, loss: 0.025534842163324356
step: 500, loss: 0.07832270860671997
step: 510, loss: 0.03472152724862099
step: 520, loss: 0.1051013171672821
step: 530, loss: 0.03286507725715637
step: 540, loss: 0.03791327774524689
step: 550, loss: 0.009420439600944519
step: 560, loss: 0.02801336534321308
step: 570, loss: 0.06570666283369064
step: 580, loss: 0.10291726142168045
step: 590, loss: 0.10671770572662354
step: 600, loss: 0.018011366948485374
step: 610, loss: 0.07836540788412094
step: 620, loss: 0.030324667692184448
step: 630, loss: 0.0826130211353302
step: 640, loss: 0.0001337831054115668
step: 650, loss: 0.010733026079833508
step: 660, loss: 0.013847646303474903
step: 670, loss: 0.033167388290166855
step: 680, loss: 0.030265290290117264
step: 690, loss: 1.8000144336838275e-05
step: 700, loss: 0.01849648915231228
step: 710, loss: 0.03505304455757141
step: 720, loss: 0.05387149006128311
step: 730, loss: 0.08874708414077759
step: 740, loss: 4.1937946662073955e-05
step: 750, loss: 0.057884614914655685
step: 760, loss: 0.025187328457832336
step: 770, loss: 0.11805462092161179
step: 780, loss: 0.03287371248006821
step: 790, loss: 0.0965488851070404
step: 800, loss: 0.04955901950597763
step: 810, loss: 0.01269096601754427
step: 820, loss: 0.049410026520490646
step: 830, loss: 0.03194620460271835
step: 840, loss: 0.03531349077820778
step: 850, loss: 0.06162925437092781
step: 860, loss: 0.06881682574748993
step: 870, loss: 0.030840545892715454
step: 880, loss: 0.06701356917619705
step: 890, loss: 0.04593954235315323
step: 900, loss: 0.012017590925097466
step: 910, loss: 0.0001384193019475788
step: 920, loss: 0.02053007483482361
step: 930, loss: 0.00018631225975695997
step: 940, loss: 0.024435536935925484
step: 950, loss: 0.07888049632310867
step: 960, loss: 0.02292725257575512
step: 970, loss: 0.010730557143688202
step: 980, loss: 0.02393597923219204
step: 990, loss: 0.05001988261938095
step: 1000, loss: 0.10730959475040436
step: 1010, loss: 0.027988621965050697
step: 1020, loss: 0.10548081248998642
step: 1030, loss: 0.03305398300290108
step: 1040, loss: 0.018618658185005188
step: 1050, loss: 0.018534468486905098
step: 1060, loss: 0.06149488687515259
step: 1070, loss: 0.09562575817108154
epoch 20: dev_f1=0.9290746829497416, f1=0.9260299625468165, best_f1=0.9305555555555556
