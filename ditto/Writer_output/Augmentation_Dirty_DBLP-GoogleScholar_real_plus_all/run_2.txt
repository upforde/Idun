cuda
Device: cuda
step: 0, loss: 0.6394720077514648
step: 10, loss: 0.7019756436347961
step: 20, loss: 0.3323642909526825
step: 30, loss: 0.4775584042072296
step: 40, loss: 0.48625680804252625
step: 50, loss: 0.3487001657485962
step: 60, loss: 0.33771398663520813
step: 70, loss: 0.27245408296585083
step: 80, loss: 0.32760292291641235
step: 90, loss: 0.3130502700805664
step: 100, loss: 0.23880138993263245
step: 110, loss: 0.1858016550540924
step: 120, loss: 0.2120845466852188
step: 130, loss: 0.17541421949863434
step: 140, loss: 0.12860125303268433
step: 150, loss: 0.17774134874343872
step: 160, loss: 0.24174590408802032
step: 170, loss: 0.3241613805294037
step: 180, loss: 0.11896980553865433
step: 190, loss: 0.28065598011016846
step: 200, loss: 0.09882306307554245
step: 210, loss: 0.2715579569339752
step: 220, loss: 0.11190500855445862
step: 230, loss: 0.16687600314617157
step: 240, loss: 0.1029379665851593
step: 250, loss: 0.08280565589666367
step: 260, loss: 0.36628028750419617
step: 270, loss: 0.12919661402702332
step: 280, loss: 0.05348866805434227
step: 290, loss: 0.09440018981695175
step: 300, loss: 0.057254210114479065
step: 310, loss: 0.24829766154289246
step: 320, loss: 0.09553484618663788
step: 330, loss: 0.20783083140850067
step: 340, loss: 0.12583744525909424
step: 350, loss: 0.14656248688697815
step: 360, loss: 0.1058427095413208
step: 370, loss: 0.03566325828433037
step: 380, loss: 0.15292872488498688
step: 390, loss: 0.08583692461252213
step: 400, loss: 0.15284539759159088
step: 410, loss: 0.08397403359413147
step: 420, loss: 0.2706831991672516
step: 430, loss: 0.11693083494901657
step: 440, loss: 0.17917509377002716
step: 450, loss: 0.11734286695718765
step: 460, loss: 0.2402527630329132
step: 470, loss: 0.1276361644268036
step: 480, loss: 0.1073148176074028
step: 490, loss: 0.1544026881456375
step: 500, loss: 0.20427070558071136
step: 510, loss: 0.18418540060520172
step: 520, loss: 0.012440308928489685
step: 530, loss: 0.09957319498062134
step: 540, loss: 0.12972572445869446
step: 550, loss: 0.21735966205596924
step: 560, loss: 0.126418799161911
step: 570, loss: 0.3246985077857971
step: 580, loss: 0.17901746928691864
step: 590, loss: 0.13069994747638702
step: 600, loss: 0.11289982497692108
step: 610, loss: 0.07669974118471146
step: 620, loss: 0.1391322910785675
step: 630, loss: 0.10881219804286957
step: 640, loss: 0.13708019256591797
step: 650, loss: 0.18464718759059906
step: 660, loss: 0.1962217092514038
step: 670, loss: 0.1560320109128952
step: 680, loss: 0.29041463136672974
step: 690, loss: 0.169732466340065
step: 700, loss: 0.11290449649095535
step: 710, loss: 0.08312611281871796
step: 720, loss: 0.06661386787891388
step: 730, loss: 0.13798359036445618
step: 740, loss: 0.2525106370449066
step: 750, loss: 0.11461025476455688
step: 760, loss: 0.2368851751089096
step: 770, loss: 0.10124462097883224
step: 780, loss: 0.24526438117027283
step: 790, loss: 0.16993826627731323
step: 800, loss: 0.2583247125148773
step: 810, loss: 0.2260819971561432
step: 820, loss: 0.13804365694522858
step: 830, loss: 0.07079301029443741
step: 840, loss: 0.056376758962869644
step: 850, loss: 0.07424965500831604
step: 860, loss: 0.11397013068199158
step: 870, loss: 0.10349792242050171
step: 880, loss: 0.09434706717729568
step: 890, loss: 0.198710098862648
step: 900, loss: 0.0699235051870346
step: 910, loss: 0.22973684966564178
step: 920, loss: 0.14224068820476532
step: 930, loss: 0.056286636739969254
step: 940, loss: 0.11171982437372208
step: 950, loss: 0.20762944221496582
step: 960, loss: 0.2412080615758896
step: 970, loss: 0.12272610515356064
step: 980, loss: 0.17331835627555847
step: 990, loss: 0.09752918779850006
step: 1000, loss: 0.09600167721509933
step: 1010, loss: 0.1821553111076355
step: 1020, loss: 0.03817946836352348
step: 1030, loss: 0.0991683378815651
step: 1040, loss: 0.12123337388038635
step: 1050, loss: 0.08808247745037079
step: 1060, loss: 0.0746309757232666
step: 1070, loss: 0.11437638849020004
epoch 1: dev_f1=0.9179275561668959, f1=0.908344733242134, best_f1=0.908344733242134
step: 0, loss: 0.09767170995473862
step: 10, loss: 0.061628397554159164
step: 20, loss: 0.15521982312202454
step: 30, loss: 0.10819663107395172
step: 40, loss: 0.11604171246290207
step: 50, loss: 0.1134360209107399
step: 60, loss: 0.1287732571363449
step: 70, loss: 0.11567327380180359
step: 80, loss: 0.13447655737400055
step: 90, loss: 0.0360209122300148
step: 100, loss: 0.06366472691297531
step: 110, loss: 0.16263507306575775
step: 120, loss: 0.05561254918575287
step: 130, loss: 0.2442781925201416
step: 140, loss: 0.18583378195762634
step: 150, loss: 0.196401447057724
step: 160, loss: 0.07436905056238174
step: 170, loss: 0.09518912434577942
step: 180, loss: 0.12078021466732025
step: 190, loss: 0.07431861013174057
step: 200, loss: 0.08243267238140106
step: 210, loss: 0.17056244611740112
step: 220, loss: 0.18938212096691132
step: 230, loss: 0.11194528639316559
step: 240, loss: 0.12622012197971344
step: 250, loss: 0.12440993636846542
step: 260, loss: 0.06897777318954468
step: 270, loss: 0.1371532529592514
step: 280, loss: 0.16933676600456238
step: 290, loss: 0.10498945415019989
step: 300, loss: 0.10174752026796341
step: 310, loss: 0.15754206478595734
step: 320, loss: 0.0936078429222107
step: 330, loss: 0.045609474182128906
step: 340, loss: 0.07691343873739243
step: 350, loss: 0.09726185351610184
step: 360, loss: 0.06077789515256882
step: 370, loss: 0.13630111515522003
step: 380, loss: 0.10016251355409622
step: 390, loss: 0.07060606777667999
step: 400, loss: 0.1735125184059143
step: 410, loss: 0.11191215366125107
step: 420, loss: 0.1890866756439209
step: 430, loss: 0.06587846577167511
step: 440, loss: 0.25998345017433167
step: 450, loss: 0.15672235190868378
step: 460, loss: 0.3061828911304474
step: 470, loss: 0.12207446247339249
step: 480, loss: 0.12092275172472
step: 490, loss: 0.11648877710103989
step: 500, loss: 0.034036293625831604
step: 510, loss: 0.08797840029001236
step: 520, loss: 0.0425434410572052
step: 530, loss: 0.13651661574840546
step: 540, loss: 0.09794574975967407
step: 550, loss: 0.1120956689119339
step: 560, loss: 0.0903790220618248
step: 570, loss: 0.09168459475040436
step: 580, loss: 0.05855640023946762
step: 590, loss: 0.20877453684806824
step: 600, loss: 0.15606233477592468
step: 610, loss: 0.10630317032337189
step: 620, loss: 0.21005329489707947
step: 630, loss: 0.0863342359662056
step: 640, loss: 0.14993754029273987
step: 650, loss: 0.06895539164543152
step: 660, loss: 0.09646648168563843
step: 670, loss: 0.1474800854921341
step: 680, loss: 0.10502317547798157
step: 690, loss: 0.10451709479093552
step: 700, loss: 0.15383104979991913
step: 710, loss: 0.15089981257915497
step: 720, loss: 0.08097264170646667
step: 730, loss: 0.24907992780208588
step: 740, loss: 0.11490941047668457
step: 750, loss: 0.14737370610237122
step: 760, loss: 0.1170673668384552
step: 770, loss: 0.07070273905992508
step: 780, loss: 0.077313132584095
step: 790, loss: 0.06511083990335464
step: 800, loss: 0.11500327289104462
step: 810, loss: 0.15517109632492065
step: 820, loss: 0.07800128310918808
step: 830, loss: 0.08823829144239426
step: 840, loss: 0.12818512320518494
step: 850, loss: 0.2542223334312439
step: 860, loss: 0.14672459661960602
step: 870, loss: 0.20448042452335358
step: 880, loss: 0.04095356538891792
step: 890, loss: 0.1964978128671646
step: 900, loss: 0.2320307046175003
step: 910, loss: 0.14217634499073029
step: 920, loss: 0.24063269793987274
step: 930, loss: 0.10329193621873856
step: 940, loss: 0.061319369822740555
step: 950, loss: 0.16590739786624908
step: 960, loss: 0.08988000452518463
step: 970, loss: 0.08377290517091751
step: 980, loss: 0.12805558741092682
step: 990, loss: 0.11055479198694229
step: 1000, loss: 0.06327249109745026
step: 1010, loss: 0.1072343960404396
step: 1020, loss: 0.1277967095375061
step: 1030, loss: 0.07013315707445145
step: 1040, loss: 0.27742213010787964
step: 1050, loss: 0.1517256498336792
step: 1060, loss: 0.14993765950202942
step: 1070, loss: 0.0836820900440216
epoch 2: dev_f1=0.9215328467153284, f1=0.9148063781321185, best_f1=0.9148063781321185
step: 0, loss: 0.10668796300888062
step: 10, loss: 0.03307458758354187
step: 20, loss: 0.036597851663827896
step: 30, loss: 0.11655125766992569
step: 40, loss: 0.22785606980323792
step: 50, loss: 0.02272239699959755
step: 60, loss: 0.02156134694814682
step: 70, loss: 0.13662759959697723
step: 80, loss: 0.09841635078191757
step: 90, loss: 0.09851645678281784
step: 100, loss: 0.10908612608909607
step: 110, loss: 0.146639883518219
step: 120, loss: 0.15687410533428192
step: 130, loss: 0.16687655448913574
step: 140, loss: 0.17200510203838348
step: 150, loss: 0.08206453174352646
step: 160, loss: 0.05008331313729286
step: 170, loss: 0.07706490159034729
step: 180, loss: 0.11169584095478058
step: 190, loss: 0.14855486154556274
step: 200, loss: 0.303488165140152
step: 210, loss: 0.1297241747379303
step: 220, loss: 0.07061269134283066
step: 230, loss: 0.07319594919681549
step: 240, loss: 0.14079998433589935
step: 250, loss: 0.1689733862876892
step: 260, loss: 0.03694373741745949
step: 270, loss: 0.05479104071855545
step: 280, loss: 0.04685298353433609
step: 290, loss: 0.05539727956056595
step: 300, loss: 0.012167339213192463
step: 310, loss: 0.24712206423282623
step: 320, loss: 0.13269920647144318
step: 330, loss: 0.09750679135322571
step: 340, loss: 0.030945435166358948
step: 350, loss: 0.11310386657714844
step: 360, loss: 0.17563088238239288
step: 370, loss: 0.09016706794500351
step: 380, loss: 0.34854698181152344
step: 390, loss: 0.2134053260087967
step: 400, loss: 0.11454340815544128
step: 410, loss: 0.01279228925704956
step: 420, loss: 0.22601856291294098
step: 430, loss: 0.06697442382574081
step: 440, loss: 0.12587355077266693
step: 450, loss: 0.061187855899333954
step: 460, loss: 0.12615613639354706
step: 470, loss: 0.11034371703863144
step: 480, loss: 0.18426047265529633
step: 490, loss: 0.15516752004623413
step: 500, loss: 0.05946885794401169
step: 510, loss: 0.0553431399166584
step: 520, loss: 0.12832385301589966
step: 530, loss: 0.13804057240486145
step: 540, loss: 0.05377256125211716
step: 550, loss: 0.023766277357935905
step: 560, loss: 0.1737464815378189
step: 570, loss: 0.09816405177116394
step: 580, loss: 0.06229070574045181
step: 590, loss: 0.06888885796070099
step: 600, loss: 0.10670727491378784
step: 610, loss: 0.09363723546266556
step: 620, loss: 0.04952371120452881
step: 630, loss: 0.10919687896966934
step: 640, loss: 0.11000081896781921
step: 650, loss: 0.06755681335926056
step: 660, loss: 0.08640147000551224
step: 670, loss: 0.06567250937223434
step: 680, loss: 0.0755440965294838
step: 690, loss: 0.15329068899154663
step: 700, loss: 0.08790077269077301
step: 710, loss: 0.07127875834703445
step: 720, loss: 0.16007140278816223
step: 730, loss: 0.10366961359977722
step: 740, loss: 0.08838094770908356
step: 750, loss: 0.07765764743089676
step: 760, loss: 0.19766932725906372
step: 770, loss: 0.20618723332881927
step: 780, loss: 0.1217636838555336
step: 790, loss: 0.11484160274267197
step: 800, loss: 0.02892322652041912
step: 810, loss: 0.06476595997810364
step: 820, loss: 0.03857003524899483
step: 830, loss: 0.301726758480072
step: 840, loss: 0.06985021382570267
step: 850, loss: 0.06706546247005463
step: 860, loss: 0.08335800468921661
step: 870, loss: 0.1090870052576065
step: 880, loss: 0.2740854322910309
step: 890, loss: 0.1667506992816925
step: 900, loss: 0.08099552243947983
step: 910, loss: 0.1528463363647461
step: 920, loss: 0.20995713770389557
step: 930, loss: 0.14033988118171692
step: 940, loss: 0.08872949331998825
step: 950, loss: 0.21706511080265045
step: 960, loss: 0.15705178678035736
step: 970, loss: 0.06437914818525314
step: 980, loss: 0.1098601371049881
step: 990, loss: 0.08044714480638504
step: 1000, loss: 0.1276453137397766
step: 1010, loss: 0.14627540111541748
step: 1020, loss: 0.1526569128036499
step: 1030, loss: 0.0826324075460434
step: 1040, loss: 0.13687652349472046
step: 1050, loss: 0.07088080048561096
step: 1060, loss: 0.22487913072109222
step: 1070, loss: 0.08253081142902374
epoch 3: dev_f1=0.9416126042632066, f1=0.9330855018587362, best_f1=0.9330855018587362
step: 0, loss: 0.07324180752038956
step: 10, loss: 0.015977125614881516
step: 20, loss: 0.078326515853405
step: 30, loss: 0.052163004875183105
step: 40, loss: 0.1301904022693634
step: 50, loss: 0.023099560290575027
step: 60, loss: 0.08279293775558472
step: 70, loss: 0.12743441760540009
step: 80, loss: 0.058108072727918625
step: 90, loss: 0.08784668892621994
step: 100, loss: 0.015145694836974144
step: 110, loss: 0.17696768045425415
step: 120, loss: 0.08921516686677933
step: 130, loss: 0.23080939054489136
step: 140, loss: 0.09105483442544937
step: 150, loss: 0.10131188482046127
step: 160, loss: 0.08013878762722015
step: 170, loss: 0.08536762744188309
step: 180, loss: 0.042621172964572906
step: 190, loss: 0.1391058713197708
step: 200, loss: 0.24103006720542908
step: 210, loss: 0.07889924198389053
step: 220, loss: 0.20374369621276855
step: 230, loss: 0.13187383115291595
step: 240, loss: 0.1358524113893509
step: 250, loss: 0.021044492721557617
step: 260, loss: 0.03754096105694771
step: 270, loss: 0.10415434837341309
step: 280, loss: 0.0497562400996685
step: 290, loss: 0.03609723970293999
step: 300, loss: 0.006827763747423887
step: 310, loss: 0.041304975748062134
step: 320, loss: 0.12946301698684692
step: 330, loss: 0.03348951414227486
step: 340, loss: 0.05021476745605469
step: 350, loss: 0.30053091049194336
step: 360, loss: 0.14331680536270142
step: 370, loss: 0.04950839653611183
step: 380, loss: 0.1540732979774475
step: 390, loss: 0.0993807315826416
step: 400, loss: 0.06941797584295273
step: 410, loss: 0.08092079311609268
step: 420, loss: 0.09694652259349823
step: 430, loss: 0.0951552614569664
step: 440, loss: 0.1298663318157196
step: 450, loss: 0.07513812929391861
step: 460, loss: 0.060360588133335114
step: 470, loss: 0.034622032195329666
step: 480, loss: 0.10699649900197983
step: 490, loss: 0.22379550337791443
step: 500, loss: 0.13961540162563324
step: 510, loss: 0.10040924698114395
step: 520, loss: 0.15993236005306244
step: 530, loss: 0.09233908355236053
step: 540, loss: 0.11116074025630951
step: 550, loss: 0.09964892268180847
step: 560, loss: 0.02389182150363922
step: 570, loss: 0.08533214032649994
step: 580, loss: 0.1596905142068863
step: 590, loss: 0.1077711284160614
step: 600, loss: 0.056972283869981766
step: 610, loss: 0.08655044436454773
step: 620, loss: 0.04683321341872215
step: 630, loss: 0.07573242485523224
step: 640, loss: 0.07780614495277405
step: 650, loss: 0.03008309006690979
step: 660, loss: 0.0603814572095871
step: 670, loss: 0.09622316807508469
step: 680, loss: 0.029109451919794083
step: 690, loss: 0.0776664987206459
step: 700, loss: 0.13784021139144897
step: 710, loss: 0.210061177611351
step: 720, loss: 0.17956772446632385
step: 730, loss: 0.0430130735039711
step: 740, loss: 0.03192021697759628
step: 750, loss: 0.05055340752005577
step: 760, loss: 0.15688499808311462
step: 770, loss: 0.081948421895504
step: 780, loss: 0.07511372864246368
step: 790, loss: 0.07709529250860214
step: 800, loss: 0.08275138586759567
step: 810, loss: 0.03614013269543648
step: 820, loss: 0.04093239828944206
step: 830, loss: 0.1806304156780243
step: 840, loss: 0.031009819358587265
step: 850, loss: 0.07106529176235199
step: 860, loss: 0.048096850514411926
step: 870, loss: 0.23972205817699432
step: 880, loss: 0.06119625270366669
step: 890, loss: 0.039654117077589035
step: 900, loss: 0.14902262389659882
step: 910, loss: 0.050113458186388016
step: 920, loss: 0.1048283502459526
step: 930, loss: 0.1087527722120285
step: 940, loss: 0.09533686935901642
step: 950, loss: 0.04562486708164215
step: 960, loss: 0.09671565890312195
step: 970, loss: 0.1876254677772522
step: 980, loss: 0.11038122326135635
step: 990, loss: 0.08407139033079147
step: 1000, loss: 0.17572925984859467
step: 1010, loss: 0.1733461320400238
step: 1020, loss: 0.09626992791891098
step: 1030, loss: 0.04951109364628792
step: 1040, loss: 0.06829743087291718
step: 1050, loss: 0.09292154759168625
step: 1060, loss: 0.11122395098209381
step: 1070, loss: 0.1507035791873932
epoch 4: dev_f1=0.9322820037105751, f1=0.9272137227630968, best_f1=0.9330855018587362
step: 0, loss: 0.0017901626415550709
step: 10, loss: 0.06937351077795029
step: 20, loss: 0.08720450848340988
step: 30, loss: 0.09032675623893738
step: 40, loss: 0.07461855560541153
step: 50, loss: 0.07140889018774033
step: 60, loss: 0.08397870510816574
step: 70, loss: 0.025113483890891075
step: 80, loss: 0.026578817516565323
step: 90, loss: 0.11327160149812698
step: 100, loss: 0.0725969672203064
step: 110, loss: 0.08748820424079895
step: 120, loss: 0.041795141994953156
step: 130, loss: 0.07550767064094543
step: 140, loss: 0.055487021803855896
step: 150, loss: 0.16896304488182068
step: 160, loss: 0.05599202215671539
step: 170, loss: 0.03089948743581772
step: 180, loss: 0.009868092834949493
step: 190, loss: 0.06951320916414261
step: 200, loss: 0.11481276899576187
step: 210, loss: 0.018408624455332756
step: 220, loss: 0.1161479651927948
step: 230, loss: 0.11457118391990662
step: 240, loss: 0.016039682552218437
step: 250, loss: 0.27793121337890625
step: 260, loss: 0.13735412061214447
step: 270, loss: 0.06702785938978195
step: 280, loss: 0.042591363191604614
step: 290, loss: 0.0453781820833683
step: 300, loss: 0.09237857162952423
step: 310, loss: 0.11960013210773468
step: 320, loss: 0.031843576580286026
step: 330, loss: 0.07577275484800339
step: 340, loss: 0.08051534742116928
step: 350, loss: 0.019279997795820236
step: 360, loss: 0.03012610226869583
step: 370, loss: 0.046999577432870865
step: 380, loss: 0.05404199659824371
step: 390, loss: 0.11608275026082993
step: 400, loss: 0.0908653736114502
step: 410, loss: 0.01559374202042818
step: 420, loss: 0.04349055886268616
step: 430, loss: 0.05521491542458534
step: 440, loss: 0.04564656317234039
step: 450, loss: 0.11203106492757797
step: 460, loss: 0.14971473813056946
step: 470, loss: 0.04014148190617561
step: 480, loss: 0.2908612787723541
step: 490, loss: 0.03194425627589226
step: 500, loss: 0.09515202045440674
step: 510, loss: 0.07386130094528198
step: 520, loss: 0.0701034888625145
step: 530, loss: 0.12038314342498779
step: 540, loss: 0.0200483575463295
step: 550, loss: 0.029501762241125107
step: 560, loss: 0.10352225601673126
step: 570, loss: 0.07229006290435791
step: 580, loss: 0.018075836822390556
step: 590, loss: 0.05197785422205925
step: 600, loss: 0.0980294942855835
step: 610, loss: 0.10743187367916107
step: 620, loss: 0.12470290064811707
step: 630, loss: 0.09910770505666733
step: 640, loss: 0.05681915208697319
step: 650, loss: 0.05105246976017952
step: 660, loss: 0.10620539635419846
step: 670, loss: 0.09227089583873749
step: 680, loss: 0.027282921597361565
step: 690, loss: 0.046987034380435944
step: 700, loss: 0.07705308496952057
step: 710, loss: 0.10272890329360962
step: 720, loss: 0.20619702339172363
step: 730, loss: 0.10332041233778
step: 740, loss: 0.2495427280664444
step: 750, loss: 0.08031409233808517
step: 760, loss: 0.02418394945561886
step: 770, loss: 0.05160650610923767
step: 780, loss: 0.13881324231624603
step: 790, loss: 0.0733940601348877
step: 800, loss: 0.06213106960058212
step: 810, loss: 0.06098578870296478
step: 820, loss: 0.1444765031337738
step: 830, loss: 0.09018653631210327
step: 840, loss: 0.05353814363479614
step: 850, loss: 0.09668872505426407
step: 860, loss: 0.036080263555049896
step: 870, loss: 0.0694161206483841
step: 880, loss: 0.04507473483681679
step: 890, loss: 0.10446315258741379
step: 900, loss: 0.16938024759292603
step: 910, loss: 0.09037809073925018
step: 920, loss: 0.04258713126182556
step: 930, loss: 0.034236788749694824
step: 940, loss: 0.07545097917318344
step: 950, loss: 0.05423422157764435
step: 960, loss: 0.08390112966299057
step: 970, loss: 0.02690759301185608
step: 980, loss: 0.06451280415058136
step: 990, loss: 0.036728255450725555
step: 1000, loss: 0.02012404426932335
step: 1010, loss: 0.03920118510723114
step: 1020, loss: 0.13241446018218994
step: 1030, loss: 0.0618450902402401
step: 1040, loss: 0.039160821586847305
step: 1050, loss: 0.0627598986029625
step: 1060, loss: 0.06501498073339462
step: 1070, loss: 0.20983631908893585
epoch 5: dev_f1=0.9315838800374883, f1=0.921999065857076, best_f1=0.9330855018587362
step: 0, loss: 0.05650012567639351
step: 10, loss: 0.09607867151498795
step: 20, loss: 0.06554914265871048
step: 30, loss: 0.10923963040113449
step: 40, loss: 0.05314251407980919
step: 50, loss: 0.09025616943836212
step: 60, loss: 0.013861512765288353
step: 70, loss: 0.15558265149593353
step: 80, loss: 0.03743138536810875
step: 90, loss: 0.05130884051322937
step: 100, loss: 0.13726571202278137
step: 110, loss: 0.0751606673002243
step: 120, loss: 0.015401842072606087
step: 130, loss: 0.03489145264029503
step: 140, loss: 0.0906103178858757
step: 150, loss: 0.12020343542098999
step: 160, loss: 0.06604635715484619
step: 170, loss: 0.3033384680747986
step: 180, loss: 0.06861017644405365
step: 190, loss: 0.12341897189617157
step: 200, loss: 0.011442151851952076
step: 210, loss: 0.026775449514389038
step: 220, loss: 0.08627541363239288
step: 230, loss: 0.16669943928718567
step: 240, loss: 0.16511400043964386
step: 250, loss: 0.12109265476465225
step: 260, loss: 0.030576299875974655
step: 270, loss: 0.14806513488292694
step: 280, loss: 0.06111224368214607
step: 290, loss: 0.04648476839065552
step: 300, loss: 0.1546899378299713
step: 310, loss: 0.1353951394557953
step: 320, loss: 0.13718438148498535
step: 330, loss: 0.09750296175479889
step: 340, loss: 0.07382272928953171
step: 350, loss: 0.09629494696855545
step: 360, loss: 0.040267426520586014
step: 370, loss: 0.1177172139286995
step: 380, loss: 0.1001967191696167
step: 390, loss: 0.058917537331581116
step: 400, loss: 0.13169963657855988
step: 410, loss: 0.1699856072664261
step: 420, loss: 0.04624525085091591
step: 430, loss: 0.10685914009809494
step: 440, loss: 0.19579564034938812
step: 450, loss: 0.016464706510305405
step: 460, loss: 0.07045524567365646
step: 470, loss: 0.04397492855787277
step: 480, loss: 0.11391167342662811
step: 490, loss: 0.11035525053739548
step: 500, loss: 0.1418406218290329
step: 510, loss: 0.1662253588438034
step: 520, loss: 0.1462436467409134
step: 530, loss: 0.018282275646924973
step: 540, loss: 0.17127078771591187
step: 550, loss: 0.1043262854218483
step: 560, loss: 0.10525816679000854
step: 570, loss: 0.14570659399032593
step: 580, loss: 0.04949211701750755
step: 590, loss: 0.19457967579364777
step: 600, loss: 0.14210200309753418
step: 610, loss: 0.07309938222169876
step: 620, loss: 0.09317680448293686
step: 630, loss: 0.07657288759946823
step: 640, loss: 0.18838275969028473
step: 650, loss: 0.05723600462079048
step: 660, loss: 0.0540100559592247
step: 670, loss: 0.01317824237048626
step: 680, loss: 0.07233244925737381
step: 690, loss: 0.1486579179763794
step: 700, loss: 0.10981985926628113
step: 710, loss: 0.12524978816509247
step: 720, loss: 0.12364953011274338
step: 730, loss: 0.14025691151618958
step: 740, loss: 0.22209544479846954
step: 750, loss: 0.04869639873504639
step: 760, loss: 0.07650338858366013
step: 770, loss: 0.12068265676498413
step: 780, loss: 0.10181958973407745
step: 790, loss: 0.052981387823820114
step: 800, loss: 0.11968294531106949
step: 810, loss: 0.0523875392973423
step: 820, loss: 0.0713186264038086
step: 830, loss: 0.1232515498995781
step: 840, loss: 0.25865209102630615
step: 850, loss: 0.062299951910972595
step: 860, loss: 0.1644766628742218
step: 870, loss: 0.1021532490849495
step: 880, loss: 0.08381102979183197
step: 890, loss: 0.06857815384864807
step: 900, loss: 0.06422694772481918
step: 910, loss: 0.09655404090881348
step: 920, loss: 0.022406477481126785
step: 930, loss: 0.03010563924908638
step: 940, loss: 0.16459660232067108
step: 950, loss: 0.04653482511639595
step: 960, loss: 0.05268818512558937
step: 970, loss: 0.06851683557033539
step: 980, loss: 0.12540414929389954
step: 990, loss: 0.12323754280805588
step: 1000, loss: 0.0507616326212883
step: 1010, loss: 0.1306784301996231
step: 1020, loss: 0.06562591344118118
step: 1030, loss: 0.05577428266406059
step: 1040, loss: 0.10559941828250885
step: 1050, loss: 0.09028568863868713
step: 1060, loss: 0.06112513691186905
step: 1070, loss: 0.009657560847699642
epoch 6: dev_f1=0.9280677009873061, f1=0.9227871939736347, best_f1=0.9330855018587362
step: 0, loss: 0.10814332962036133
step: 10, loss: 0.04963364824652672
step: 20, loss: 0.07792668789625168
step: 30, loss: 0.0625113770365715
step: 40, loss: 0.06422196328639984
step: 50, loss: 0.15214227139949799
step: 60, loss: 0.018742268905043602
step: 70, loss: 0.08435041457414627
step: 80, loss: 0.09234428405761719
step: 90, loss: 0.10306981950998306
step: 100, loss: 0.07019706815481186
step: 110, loss: 0.16373680531978607
step: 120, loss: 0.07668620347976685
step: 130, loss: 0.08776246011257172
step: 140, loss: 0.12184327095746994
step: 150, loss: 0.0813928097486496
step: 160, loss: 0.04567519575357437
step: 170, loss: 0.08907430619001389
step: 180, loss: 0.11095184087753296
step: 190, loss: 0.10256713628768921
step: 200, loss: 0.07716942578554153
step: 210, loss: 0.046314869076013565
step: 220, loss: 0.10702448338270187
step: 230, loss: 0.1392020434141159
step: 240, loss: 0.02878473699092865
step: 250, loss: 0.1270284652709961
step: 260, loss: 0.03017646260559559
step: 270, loss: 0.09903372079133987
step: 280, loss: 0.0732702761888504
step: 290, loss: 0.12514430284500122
step: 300, loss: 0.23925475776195526
step: 310, loss: 0.05188958719372749
step: 320, loss: 0.1450275182723999
step: 330, loss: 0.015719929710030556
step: 340, loss: 0.10591373592615128
step: 350, loss: 0.058061160147190094
step: 360, loss: 0.05245576426386833
step: 370, loss: 0.041532330214977264
step: 380, loss: 0.0862615704536438
step: 390, loss: 0.09429426491260529
step: 400, loss: 0.04957709461450577
step: 410, loss: 0.0264615248888731
step: 420, loss: 0.11289124935865402
step: 430, loss: 0.05471983551979065
step: 440, loss: 0.0683325007557869
step: 450, loss: 0.07988938689231873
step: 460, loss: 0.057821378111839294
step: 470, loss: 0.06636053323745728
step: 480, loss: 0.08808908611536026
step: 490, loss: 0.07907802611589432
step: 500, loss: 0.027986934408545494
step: 510, loss: 0.10410543531179428
step: 520, loss: 0.022416209802031517
step: 530, loss: 0.006962975487112999
step: 540, loss: 0.0462297722697258
step: 550, loss: 0.06758922338485718
step: 560, loss: 0.0090800104662776
step: 570, loss: 0.11687096208333969
step: 580, loss: 0.1040690466761589
step: 590, loss: 0.061939846724271774
step: 600, loss: 0.12397336959838867
step: 610, loss: 0.11361033469438553
step: 620, loss: 0.08487193286418915
step: 630, loss: 0.10748688131570816
step: 640, loss: 0.055480219423770905
step: 650, loss: 0.07728087157011032
step: 660, loss: 0.07796651870012283
step: 670, loss: 0.187541201710701
step: 680, loss: 0.15815098583698273
step: 690, loss: 0.1324334740638733
step: 700, loss: 0.10020771622657776
step: 710, loss: 0.06723444163799286
step: 720, loss: 0.05306849628686905
step: 730, loss: 0.18334230780601501
step: 740, loss: 0.13886280357837677
step: 750, loss: 0.035561420023441315
step: 760, loss: 0.08717147260904312
step: 770, loss: 0.12197716534137726
step: 780, loss: 0.08963017910718918
step: 790, loss: 0.004506680648773909
step: 800, loss: 0.02316048927605152
step: 810, loss: 0.18951870501041412
step: 820, loss: 0.0352415032684803
step: 830, loss: 0.00409642793238163
step: 840, loss: 0.14980658888816833
step: 850, loss: 0.07096713036298752
step: 860, loss: 0.16053538024425507
step: 870, loss: 0.02681852877140045
step: 880, loss: 0.20314070582389832
step: 890, loss: 0.0039054546505212784
step: 900, loss: 0.07607591152191162
step: 910, loss: 0.054588064551353455
step: 920, loss: 0.13574053347110748
step: 930, loss: 0.06407050788402557
step: 940, loss: 0.052756741642951965
step: 950, loss: 0.07410034537315369
step: 960, loss: 0.016944078728556633
step: 970, loss: 0.04237838834524155
step: 980, loss: 0.19556450843811035
step: 990, loss: 0.06999076157808304
step: 1000, loss: 0.07423434406518936
step: 1010, loss: 0.07844717055559158
step: 1020, loss: 0.08357268571853638
step: 1030, loss: 0.07115233689546585
step: 1040, loss: 0.0900351032614708
step: 1050, loss: 0.2212965190410614
step: 1060, loss: 0.10499226301908493
step: 1070, loss: 0.18017511069774628
epoch 7: dev_f1=0.9232192414431082, f1=0.9237918215613383, best_f1=0.9330855018587362
step: 0, loss: 0.07709307223558426
step: 10, loss: 0.1892203837633133
step: 20, loss: 0.011565493419766426
step: 30, loss: 0.04291009157896042
step: 40, loss: 0.038969747722148895
step: 50, loss: 0.12181074172258377
step: 60, loss: 0.023536406457424164
step: 70, loss: 0.07175499945878983
step: 80, loss: 0.06352899968624115
step: 90, loss: 0.06359153240919113
step: 100, loss: 0.0704420730471611
step: 110, loss: 0.0417422391474247
step: 120, loss: 0.03374025970697403
step: 130, loss: 0.049307163804769516
step: 140, loss: 0.05285352095961571
step: 150, loss: 0.08670523017644882
step: 160, loss: 0.06559095531702042
step: 170, loss: 0.12804967164993286
step: 180, loss: 0.06360240280628204
step: 190, loss: 0.12245145440101624
step: 200, loss: 0.0689137876033783
step: 210, loss: 0.0824248269200325
step: 220, loss: 0.09473475813865662
step: 230, loss: 0.06163487583398819
step: 240, loss: 0.040674541145563126
step: 250, loss: 0.03678633272647858
step: 260, loss: 0.09525419771671295
step: 270, loss: 0.06500077247619629
step: 280, loss: 0.04812317341566086
step: 290, loss: 0.08959665149450302
step: 300, loss: 0.018547628074884415
step: 310, loss: 0.21241892874240875
step: 320, loss: 0.13297691941261292
step: 330, loss: 0.05999686196446419
step: 340, loss: 0.025153782218694687
step: 350, loss: 0.09469673782587051
step: 360, loss: 0.10699314624071121
step: 370, loss: 0.051311638206243515
step: 380, loss: 0.061102092266082764
step: 390, loss: 0.01692567951977253
step: 400, loss: 0.026094384491443634
step: 410, loss: 0.07708296179771423
step: 420, loss: 0.016058288514614105
step: 430, loss: 0.1608029454946518
step: 440, loss: 0.03701188415288925
step: 450, loss: 0.15061146020889282
step: 460, loss: 0.061745401471853256
step: 470, loss: 0.05165752395987511
step: 480, loss: 0.06519389897584915
step: 490, loss: 0.07010678946971893
step: 500, loss: 0.1692570000886917
step: 510, loss: 0.11909841001033783
step: 520, loss: 0.07146172225475311
step: 530, loss: 0.057610999792814255
step: 540, loss: 0.07180974632501602
step: 550, loss: 0.09615570306777954
step: 560, loss: 0.08498265594244003
step: 570, loss: 0.09166867285966873
step: 580, loss: 0.09544055163860321
step: 590, loss: 0.054694317281246185
step: 600, loss: 0.07642581313848495
step: 610, loss: 0.20432084798812866
step: 620, loss: 0.10097003728151321
step: 630, loss: 0.018476303666830063
step: 640, loss: 0.010854164138436317
step: 650, loss: 0.20716769993305206
step: 660, loss: 0.080813929438591
step: 670, loss: 0.02797020599246025
step: 680, loss: 0.17357361316680908
step: 690, loss: 0.023436512798070908
step: 700, loss: 0.057427555322647095
step: 710, loss: 0.09114918112754822
step: 720, loss: 0.09327218681573868
step: 730, loss: 0.08819404989480972
step: 740, loss: 0.07522105425596237
step: 750, loss: 0.03987743332982063
step: 760, loss: 0.08629682660102844
step: 770, loss: 0.11327474564313889
step: 780, loss: 0.08921845257282257
step: 790, loss: 0.02067454718053341
step: 800, loss: 0.1034085750579834
step: 810, loss: 0.014061487279832363
step: 820, loss: 0.03502926230430603
step: 830, loss: 0.05669109895825386
step: 840, loss: 0.09320671856403351
step: 850, loss: 0.05108177289366722
step: 860, loss: 0.004558909684419632
step: 870, loss: 0.16834686696529388
step: 880, loss: 0.07561877369880676
step: 890, loss: 0.10198493301868439
step: 900, loss: 0.026934904977679253
step: 910, loss: 0.025470230728387833
step: 920, loss: 0.1430581510066986
step: 930, loss: 0.07179979979991913
step: 940, loss: 0.10926511138677597
step: 950, loss: 5.122334187035449e-05
step: 960, loss: 0.007519744802266359
step: 970, loss: 0.10196439921855927
step: 980, loss: 0.05205700173974037
step: 990, loss: 0.036465421319007874
step: 1000, loss: 0.10957995057106018
step: 1010, loss: 0.044021572917699814
step: 1020, loss: 0.06229087710380554
step: 1030, loss: 0.11197619885206223
step: 1040, loss: 0.07540134340524673
step: 1050, loss: 0.06737777590751648
step: 1060, loss: 0.10706067830324173
step: 1070, loss: 0.05619560554623604
epoch 8: dev_f1=0.9319227230910764, f1=0.9264705882352942, best_f1=0.9330855018587362
step: 0, loss: 0.06674107164144516
step: 10, loss: 0.06546998023986816
step: 20, loss: 0.1651400923728943
step: 30, loss: 0.11296272277832031
step: 40, loss: 0.048956453800201416
step: 50, loss: 0.14275312423706055
step: 60, loss: 0.03470800444483757
step: 70, loss: 0.06460447609424591
step: 80, loss: 0.08468180894851685
step: 90, loss: 0.04262509569525719
step: 100, loss: 0.12471558898687363
step: 110, loss: 0.08758433908224106
step: 120, loss: 0.10502900183200836
step: 130, loss: 0.08676935732364655
step: 140, loss: 0.02834043651819229
step: 150, loss: 0.03642342984676361
step: 160, loss: 0.04576147347688675
step: 170, loss: 0.011861594393849373
step: 180, loss: 0.05493232607841492
step: 190, loss: 0.06530599296092987
step: 200, loss: 0.07323528081178665
step: 210, loss: 0.0001587046281201765
step: 220, loss: 0.04548963904380798
step: 230, loss: 0.02067183330655098
step: 240, loss: 0.04963797330856323
step: 250, loss: 0.12392394989728928
step: 260, loss: 0.028841961175203323
step: 270, loss: 0.05474889650940895
step: 280, loss: 0.05225373059511185
step: 290, loss: 0.17433381080627441
step: 300, loss: 0.0841585099697113
step: 310, loss: 0.030773356556892395
step: 320, loss: 0.037423573434352875
step: 330, loss: 0.04286496341228485
step: 340, loss: 0.013017741031944752
step: 350, loss: 0.0392620675265789
step: 360, loss: 0.020194491371512413
step: 370, loss: 0.011003191582858562
step: 380, loss: 0.1007637232542038
step: 390, loss: 0.023930508643388748
step: 400, loss: 0.004427957348525524
step: 410, loss: 0.03683973476290703
step: 420, loss: 0.03974257782101631
step: 430, loss: 0.1138572171330452
step: 440, loss: 0.10646059364080429
step: 450, loss: 0.14505930244922638
step: 460, loss: 0.0400921106338501
step: 470, loss: 0.013905119150876999
step: 480, loss: 0.02558285742998123
step: 490, loss: 0.01782935857772827
step: 500, loss: 0.08203987777233124
step: 510, loss: 0.025990646332502365
step: 520, loss: 0.05048733204603195
step: 530, loss: 0.039930470287799835
step: 540, loss: 0.0541226789355278
step: 550, loss: 0.023867836222052574
step: 560, loss: 0.026073478162288666
step: 570, loss: 0.08448737114667892
step: 580, loss: 0.041350170969963074
step: 590, loss: 0.0670417919754982
step: 600, loss: 0.022050756961107254
step: 610, loss: 0.059156306087970734
step: 620, loss: 0.048536740243434906
step: 630, loss: 0.09005594998598099
step: 640, loss: 0.07408192753791809
step: 650, loss: 0.030185816809535027
step: 660, loss: 0.09356076270341873
step: 670, loss: 0.034620799124240875
step: 680, loss: 0.08234813809394836
step: 690, loss: 0.05430549755692482
step: 700, loss: 0.24508920311927795
step: 710, loss: 0.06493689119815826
step: 720, loss: 0.024281835183501244
step: 730, loss: 0.003413259284570813
step: 740, loss: 0.03277462348341942
step: 750, loss: 0.07291758060455322
step: 760, loss: 0.07933647930622101
step: 770, loss: 0.08542394638061523
step: 780, loss: 0.1076524555683136
step: 790, loss: 0.1990799754858017
step: 800, loss: 0.04054669663310051
step: 810, loss: 0.0653017908334732
step: 820, loss: 0.028032246977090836
step: 830, loss: 0.09038569033145905
step: 840, loss: 0.03282514959573746
step: 850, loss: 0.032031845301389694
step: 860, loss: 0.061444077640771866
step: 870, loss: 0.2557940185070038
step: 880, loss: 0.0645320937037468
step: 890, loss: 0.030105583369731903
step: 900, loss: 0.07242079079151154
step: 910, loss: 0.12733162939548492
step: 920, loss: 0.12954401969909668
step: 930, loss: 0.09041471779346466
step: 940, loss: 0.1357351392507553
step: 950, loss: 0.09468360990285873
step: 960, loss: 0.09190281480550766
step: 970, loss: 0.07281240820884705
step: 980, loss: 0.0391683466732502
step: 990, loss: 0.09621609002351761
step: 1000, loss: 0.10031881183385849
step: 1010, loss: 0.07782743126153946
step: 1020, loss: 0.0857846662402153
step: 1030, loss: 0.08642517030239105
step: 1040, loss: 0.02434459701180458
step: 1050, loss: 0.0948319137096405
step: 1060, loss: 0.06440985947847366
step: 1070, loss: 0.0982239693403244
epoch 9: dev_f1=0.9298486932599725, f1=0.9260450160771704, best_f1=0.9330855018587362
step: 0, loss: 0.08375146985054016
step: 10, loss: 0.0361705906689167
step: 20, loss: 0.06431639939546585
step: 30, loss: 0.07617899775505066
step: 40, loss: 0.05945280194282532
step: 50, loss: 0.09427867084741592
step: 60, loss: 0.03543765842914581
step: 70, loss: 0.21182255446910858
step: 80, loss: 0.0271769892424345
step: 90, loss: 0.0591532401740551
step: 100, loss: 0.07045027613639832
step: 110, loss: 0.026417581364512444
step: 120, loss: 0.12198908627033234
step: 130, loss: 0.07349416613578796
step: 140, loss: 0.05791878327727318
step: 150, loss: 0.05927020311355591
step: 160, loss: 0.03987923264503479
step: 170, loss: 0.10758712887763977
step: 180, loss: 0.022789467126131058
step: 190, loss: 0.21705347299575806
step: 200, loss: 0.032208774238824844
step: 210, loss: 0.02302842028439045
step: 220, loss: 0.07129886746406555
step: 230, loss: 0.1073887050151825
step: 240, loss: 0.07951542735099792
step: 250, loss: 0.06151511147618294
step: 260, loss: 0.009591822512447834
step: 270, loss: 0.06490921974182129
step: 280, loss: 0.09814903885126114
step: 290, loss: 0.0003265831037424505
step: 300, loss: 0.05230147764086723
step: 310, loss: 0.05802057683467865
step: 320, loss: 0.09659280627965927
step: 330, loss: 0.04878368601202965
step: 340, loss: 0.12927201390266418
step: 350, loss: 0.05615849792957306
step: 360, loss: 0.0806194618344307
step: 370, loss: 0.056316912174224854
step: 380, loss: 0.0811210572719574
step: 390, loss: 0.12360279262065887
step: 400, loss: 0.13229887187480927
step: 410, loss: 0.04831090196967125
step: 420, loss: 0.07322850823402405
step: 430, loss: 0.04580364748835564
step: 440, loss: 0.07566699385643005
step: 450, loss: 0.09733806550502777
step: 460, loss: 0.020782794803380966
step: 470, loss: 0.0875716507434845
step: 480, loss: 0.06301646679639816
step: 490, loss: 0.14979128539562225
step: 500, loss: 0.05220312252640724
step: 510, loss: 0.051376648247241974
step: 520, loss: 0.050504039973020554
step: 530, loss: 0.1157108023762703
step: 540, loss: 0.04373799264431
step: 550, loss: 0.014741731807589531
step: 560, loss: 0.10337946563959122
step: 570, loss: 0.10453113168478012
step: 580, loss: 0.146052747964859
step: 590, loss: 0.04964127391576767
step: 600, loss: 0.11629046499729156
step: 610, loss: 0.10187284648418427
step: 620, loss: 0.07720862329006195
step: 630, loss: 0.32847586274147034
step: 640, loss: 0.09528715163469315
step: 650, loss: 0.05209247022867203
step: 660, loss: 0.04211057722568512
step: 670, loss: 0.015062903054058552
step: 680, loss: 0.04355074465274811
step: 690, loss: 0.08484932035207748
step: 700, loss: 0.06416592001914978
step: 710, loss: 0.06578753143548965
step: 720, loss: 0.0339314304292202
step: 730, loss: 0.02565416507422924
step: 740, loss: 0.1358213573694229
step: 750, loss: 0.0019987227860838175
step: 760, loss: 0.09713119268417358
step: 770, loss: 0.052836451679468155
step: 780, loss: 0.02693020924925804
step: 790, loss: 0.060310617089271545
step: 800, loss: 0.0894913375377655
step: 810, loss: 0.03141336515545845
step: 820, loss: 0.03649801015853882
step: 830, loss: 0.10178323835134506
step: 840, loss: 0.06827713549137115
step: 850, loss: 0.04808586835861206
step: 860, loss: 0.0008921648841351271
step: 870, loss: 0.025637879967689514
step: 880, loss: 0.050600092858076096
step: 890, loss: 0.13793911039829254
step: 900, loss: 0.06697812676429749
step: 910, loss: 0.17510521411895752
step: 920, loss: 0.06464265286922455
step: 930, loss: 0.04210510849952698
step: 940, loss: 0.08804395794868469
step: 950, loss: 0.014385362155735493
step: 960, loss: 0.0856156051158905
step: 970, loss: 0.059306759387254715
step: 980, loss: 0.021325519308447838
step: 990, loss: 0.051398951560258865
step: 1000, loss: 0.035012613981962204
step: 1010, loss: 0.24078616499900818
step: 1020, loss: 0.028570499271154404
step: 1030, loss: 0.08089705556631088
step: 1040, loss: 0.04779189079999924
step: 1050, loss: 0.006307127419859171
step: 1060, loss: 0.019805938005447388
step: 1070, loss: 0.10909917205572128
epoch 10: dev_f1=0.9279026217228464, f1=0.930776426566885, best_f1=0.9330855018587362
step: 0, loss: 0.005725191906094551
step: 10, loss: 0.07739370316267014
step: 20, loss: 0.054078999906778336
step: 30, loss: 0.031174901872873306
step: 40, loss: 0.05993296205997467
step: 50, loss: 0.06644751876592636
step: 60, loss: 0.0728115364909172
step: 70, loss: 0.08559806644916534
step: 80, loss: 0.028325555846095085
step: 90, loss: 0.016258370131254196
step: 100, loss: 0.04815518856048584
step: 110, loss: 0.060710564255714417
step: 120, loss: 0.04198133945465088
step: 130, loss: 0.06987212598323822
step: 140, loss: 0.06924470514059067
step: 150, loss: 0.005579816177487373
step: 160, loss: 0.07232171297073364
step: 170, loss: 0.14716008305549622
step: 180, loss: 0.045907359570264816
step: 190, loss: 0.06206829473376274
step: 200, loss: 0.07519872486591339
step: 210, loss: 0.12179174274206161
step: 220, loss: 0.018345242366194725
step: 230, loss: 0.06441716104745865
step: 240, loss: 0.0463896319270134
step: 250, loss: 0.0795876681804657
step: 260, loss: 0.11958061158657074
step: 270, loss: 0.003659118665382266
step: 280, loss: 0.024885384365916252
step: 290, loss: 0.06408540159463882
step: 300, loss: 0.0403008833527565
step: 310, loss: 0.0002805536787491292
step: 320, loss: 0.08445470780134201
step: 330, loss: 0.011591600254178047
step: 340, loss: 0.05663038045167923
step: 350, loss: 0.03151245042681694
step: 360, loss: 0.040926020592451096
step: 370, loss: 0.08459493517875671
step: 380, loss: 0.016250895336270332
step: 390, loss: 0.020057599991559982
step: 400, loss: 0.025448434054851532
step: 410, loss: 0.0453033372759819
step: 420, loss: 0.11830161511898041
step: 430, loss: 0.08747591078281403
step: 440, loss: 0.028782270848751068
step: 450, loss: 0.060203008353710175
step: 460, loss: 0.025446996092796326
step: 470, loss: 0.07813137024641037
step: 480, loss: 0.0383787676692009
step: 490, loss: 0.031677570194005966
step: 500, loss: 0.019924065098166466
step: 510, loss: 0.1188945323228836
step: 520, loss: 0.08367986977100372
step: 530, loss: 0.06808637082576752
step: 540, loss: 0.10605552047491074
step: 550, loss: 0.051931463181972504
step: 560, loss: 0.08044737577438354
step: 570, loss: 0.08446045219898224
step: 580, loss: 0.13176566362380981
step: 590, loss: 0.0027294105384498835
step: 600, loss: 0.0023386357352137566
step: 610, loss: 0.0029380989726632833
step: 620, loss: 0.04609984531998634
step: 630, loss: 0.053436171263456345
step: 640, loss: 0.1681281477212906
step: 650, loss: 0.07984700798988342
step: 660, loss: 0.026840118691325188
step: 670, loss: 0.027074486017227173
step: 680, loss: 0.026197338476777077
step: 690, loss: 0.03661111742258072
step: 700, loss: 0.038281165063381195
step: 710, loss: 0.07937370240688324
step: 720, loss: 0.09274112433195114
step: 730, loss: 0.05123375356197357
step: 740, loss: 0.051871951669454575
step: 750, loss: 0.020338963717222214
step: 760, loss: 0.03659040480852127
step: 770, loss: 0.005702658090740442
step: 780, loss: 0.04266173020005226
step: 790, loss: 0.008787759579718113
step: 800, loss: 0.0888986811041832
step: 810, loss: 0.08316128700971603
step: 820, loss: 0.06895037740468979
step: 830, loss: 0.013699029572308064
step: 840, loss: 0.115232452750206
step: 850, loss: 0.103189617395401
step: 860, loss: 0.023910149931907654
step: 870, loss: 0.0835808515548706
step: 880, loss: 0.04920197278261185
step: 890, loss: 0.01924089528620243
step: 900, loss: 0.018512364476919174
step: 910, loss: 0.07530467212200165
step: 920, loss: 0.0005007968284189701
step: 930, loss: 0.06265262514352798
step: 940, loss: 0.043762851506471634
step: 950, loss: 0.11809933185577393
step: 960, loss: 0.08043726533651352
step: 970, loss: 0.07033875584602356
step: 980, loss: 0.08561841398477554
step: 990, loss: 0.09959453344345093
step: 1000, loss: 0.08369074016809464
step: 1010, loss: 0.037930168211460114
step: 1020, loss: 0.04166511818766594
step: 1030, loss: 0.14557653665542603
step: 1040, loss: 0.027530089020729065
step: 1050, loss: 0.054452698677778244
step: 1060, loss: 0.06334350258111954
step: 1070, loss: 0.06820852309465408
epoch 11: dev_f1=0.924408014571949, f1=0.9161704076958314, best_f1=0.9330855018587362
step: 0, loss: 0.06981436163187027
step: 10, loss: 0.09489339590072632
step: 20, loss: 0.1025058776140213
step: 30, loss: 0.005913132801651955
step: 40, loss: 0.09496711194515228
step: 50, loss: 0.022409304976463318
step: 60, loss: 0.1305992603302002
step: 70, loss: 0.1026218980550766
step: 80, loss: 0.11982639133930206
step: 90, loss: 0.0613977313041687
step: 100, loss: 0.13884346187114716
step: 110, loss: 0.02930826134979725
step: 120, loss: 0.05195356160402298
step: 130, loss: 0.03498537465929985
step: 140, loss: 0.03271773084998131
step: 150, loss: 0.02735399454832077
step: 160, loss: 0.15678507089614868
step: 170, loss: 2.4876315364963375e-05
step: 180, loss: 0.008542949333786964
step: 190, loss: 0.0776812955737114
step: 200, loss: 0.016385799273848534
step: 210, loss: 0.06199824810028076
step: 220, loss: 0.0795866847038269
step: 230, loss: 0.04966578260064125
step: 240, loss: 0.00048115287791006267
step: 250, loss: 0.05844731628894806
step: 260, loss: 0.035014595836400986
step: 270, loss: 0.05765675753355026
step: 280, loss: 0.05097000673413277
step: 290, loss: 0.11312934756278992
step: 300, loss: 0.06878701597452164
step: 310, loss: 0.0859682485461235
step: 320, loss: 0.0700441300868988
step: 330, loss: 1.6845551726873964e-05
step: 340, loss: 0.0406058169901371
step: 350, loss: 0.09005477279424667
step: 360, loss: 0.029191477224230766
step: 370, loss: 0.07915229350328445
step: 380, loss: 0.036744847893714905
step: 390, loss: 0.03322497755289078
step: 400, loss: 0.0812389925122261
step: 410, loss: 0.046182356774806976
step: 420, loss: 0.16096368432044983
step: 430, loss: 0.022914577275514603
step: 440, loss: 0.03212243318557739
step: 450, loss: 0.03648114204406738
step: 460, loss: 0.00981858465820551
step: 470, loss: 0.13152354955673218
step: 480, loss: 0.032068077474832535
step: 490, loss: 0.008147915825247765
step: 500, loss: 0.12411756068468094
step: 510, loss: 0.06224917620420456
step: 520, loss: 0.02195855602622032
step: 530, loss: 0.08886763453483582
step: 540, loss: 0.14680427312850952
step: 550, loss: 0.04627389833331108
step: 560, loss: 0.0011193336686119437
step: 570, loss: 0.13016046583652496
step: 580, loss: 0.05560946837067604
step: 590, loss: 0.08249763399362564
step: 600, loss: 0.06614545732736588
step: 610, loss: 0.1060459092259407
step: 620, loss: 0.08293842524290085
step: 630, loss: 0.03851744532585144
step: 640, loss: 0.17013080418109894
step: 650, loss: 0.0265858955681324
step: 660, loss: 0.0003565580409485847
step: 670, loss: 0.04103685915470123
step: 680, loss: 0.1162862628698349
step: 690, loss: 0.12042012065649033
step: 700, loss: 0.02521424926817417
step: 710, loss: 0.0026972487103194
step: 720, loss: 0.047795820981264114
step: 730, loss: 0.00017867096175905317
step: 740, loss: 0.031000275164842606
step: 750, loss: 0.09174487739801407
step: 760, loss: 0.0003227207052987069
step: 770, loss: 0.017464080825448036
step: 780, loss: 0.10494730621576309
step: 790, loss: 0.09498901665210724
step: 800, loss: 0.0005283989594317973
step: 810, loss: 0.029546383768320084
step: 820, loss: 0.07401737570762634
step: 830, loss: 0.06193164363503456
step: 840, loss: 0.03085215762257576
step: 850, loss: 0.06103919446468353
step: 860, loss: 0.022398343309760094
step: 870, loss: 0.10633423179388046
step: 880, loss: 0.025798803195357323
step: 890, loss: 0.10656698048114777
step: 900, loss: 0.04810106009244919
step: 910, loss: 0.08668503165245056
step: 920, loss: 0.03129056468605995
step: 930, loss: 0.0032130652107298374
step: 940, loss: 0.05238749086856842
step: 950, loss: 0.10500002652406693
step: 960, loss: 0.04126381501555443
step: 970, loss: 0.12061869353055954
step: 980, loss: 0.07693419605493546
step: 990, loss: 0.017281005159020424
step: 1000, loss: 0.05493215098977089
step: 1010, loss: 0.04934510961174965
step: 1020, loss: 0.08086535334587097
step: 1030, loss: 0.010915453545749187
step: 1040, loss: 0.03845543786883354
step: 1050, loss: 0.01720036379992962
step: 1060, loss: 0.10096084326505661
step: 1070, loss: 0.048111267387866974
epoch 12: dev_f1=0.9215509467989179, f1=0.9186991869918699, best_f1=0.9330855018587362
step: 0, loss: 0.05103019252419472
step: 10, loss: 0.05062435567378998
step: 20, loss: 0.10687240213155746
step: 30, loss: 0.11575277149677277
step: 40, loss: 0.04805236682295799
step: 50, loss: 0.05576210469007492
step: 60, loss: 0.04242853447794914
step: 70, loss: 0.06391851603984833
step: 80, loss: 0.00014234689297154546
step: 90, loss: 0.044495318084955215
step: 100, loss: 0.003092715982347727
step: 110, loss: 0.20162592828273773
step: 120, loss: 0.05385115370154381
step: 130, loss: 0.04435494542121887
step: 140, loss: 0.05712760612368584
step: 150, loss: 0.06589914858341217
step: 160, loss: 0.008094933815300465
step: 170, loss: 0.04327220097184181
step: 180, loss: 0.04156666249036789
step: 190, loss: 0.000669374130666256
step: 200, loss: 0.03709451109170914
step: 210, loss: 0.02875053510069847
step: 220, loss: 0.054368387907743454
step: 230, loss: 0.07911885529756546
step: 240, loss: 0.08012832701206207
step: 250, loss: 0.048008136451244354
step: 260, loss: 0.02445881813764572
step: 270, loss: 0.0745861679315567
step: 280, loss: 0.05143967643380165
step: 290, loss: 0.026254357770085335
step: 300, loss: 0.0003717117360793054
step: 310, loss: 0.021516690030694008
step: 320, loss: 0.08905267715454102
step: 330, loss: 0.014787175692617893
step: 340, loss: 0.11674744635820389
step: 350, loss: 0.08270281553268433
step: 360, loss: 0.039999429136514664
step: 370, loss: 0.0705011859536171
step: 380, loss: 0.015119541436433792
step: 390, loss: 0.0005564423045143485
step: 400, loss: 0.08751940727233887
step: 410, loss: 0.03202439844608307
step: 420, loss: 0.061435405164957047
step: 430, loss: 0.01919732242822647
step: 440, loss: 0.05363074317574501
step: 450, loss: 0.04461217671632767
step: 460, loss: 0.06579117476940155
step: 470, loss: 0.07873522490262985
step: 480, loss: 0.08366755396127701
step: 490, loss: 0.05875955522060394
step: 500, loss: 0.04412999376654625
step: 510, loss: 7.812740659574047e-05
step: 520, loss: 0.022049555554986
step: 530, loss: 0.05410248041152954
step: 540, loss: 0.001424202462658286
step: 550, loss: 0.0880279541015625
step: 560, loss: 0.03925628215074539
step: 570, loss: 0.06396162509918213
step: 580, loss: 0.013532300479710102
step: 590, loss: 0.042433083057403564
step: 600, loss: 0.06682679802179337
step: 610, loss: 0.059400543570518494
step: 620, loss: 0.05820717662572861
step: 630, loss: 0.03271237388253212
step: 640, loss: 0.0024852887727320194
step: 650, loss: 0.20243020355701447
step: 660, loss: 0.12753042578697205
step: 670, loss: 0.11771836876869202
step: 680, loss: 0.00634530745446682
step: 690, loss: 0.0865974947810173
step: 700, loss: 0.04873448610305786
step: 710, loss: 0.056762926280498505
step: 720, loss: 0.018823495134711266
step: 730, loss: 0.07318910211324692
step: 740, loss: 0.041986726224422455
step: 750, loss: 0.10516426712274551
step: 760, loss: 0.072426937520504
step: 770, loss: 0.06513260304927826
step: 780, loss: 0.0876549556851387
step: 790, loss: 0.06038694456219673
step: 800, loss: 0.03268979862332344
step: 810, loss: 1.8402424757368863e-05
step: 820, loss: 0.04380717873573303
step: 830, loss: 0.08088845014572144
step: 840, loss: 0.004263422917574644
step: 850, loss: 0.019893735647201538
step: 860, loss: 0.01714596152305603
step: 870, loss: 0.02842068485915661
step: 880, loss: 0.020281976088881493
step: 890, loss: 0.0525791198015213
step: 900, loss: 0.040568020194768906
step: 910, loss: 0.005010208114981651
step: 920, loss: 0.10061769932508469
step: 930, loss: 0.00018140576139558107
step: 940, loss: 0.08178393542766571
step: 950, loss: 0.020821526646614075
step: 960, loss: 0.04135582968592644
step: 970, loss: 0.11598649621009827
step: 980, loss: 0.12363729625940323
step: 990, loss: 0.01756240986287594
step: 1000, loss: 0.025784790515899658
step: 1010, loss: 0.02826927788555622
step: 1020, loss: 0.06806280463933945
step: 1030, loss: 0.006227148696780205
step: 1040, loss: 0.02860383130609989
step: 1050, loss: 0.07615680247545242
step: 1060, loss: 0.01900050975382328
step: 1070, loss: 0.08877980709075928
epoch 13: dev_f1=0.9308584686774942, f1=0.9254284390921722, best_f1=0.9330855018587362
step: 0, loss: 0.08469758182764053
step: 10, loss: 0.024122584611177444
step: 20, loss: 0.07258345931768417
step: 30, loss: 0.024286847561597824
step: 40, loss: 0.04012987017631531
step: 50, loss: 0.042432792484760284
step: 60, loss: 0.10290192812681198
step: 70, loss: 0.05564400926232338
step: 80, loss: 0.051414262503385544
step: 90, loss: 0.04762262850999832
step: 100, loss: 0.037819843739271164
step: 110, loss: 0.0766371563076973
step: 120, loss: 0.013651501387357712
step: 130, loss: 0.06346557289361954
step: 140, loss: 0.019185343757271767
step: 150, loss: 0.028125861659646034
step: 160, loss: 0.06947344541549683
step: 170, loss: 0.042957618832588196
step: 180, loss: 0.05048215389251709
step: 190, loss: 0.04402157664299011
step: 200, loss: 0.09255688637495041
step: 210, loss: 0.0003710270393639803
step: 220, loss: 0.042710114270448685
step: 230, loss: 0.05099407210946083
step: 240, loss: 0.05362320318818092
step: 250, loss: 0.05508275330066681
step: 260, loss: 0.04278435930609703
step: 270, loss: 0.018889378756284714
step: 280, loss: 0.040463753044605255
step: 290, loss: 0.055383846163749695
step: 300, loss: 0.018287399783730507
step: 310, loss: 0.05787407234311104
step: 320, loss: 0.041816044598817825
step: 330, loss: 0.021732322871685028
step: 340, loss: 0.061663273721933365
step: 350, loss: 0.0849372148513794
step: 360, loss: 0.07696393132209778
step: 370, loss: 0.000979205360636115
step: 380, loss: 0.071490079164505
step: 390, loss: 0.033204492181539536
step: 400, loss: 0.00374181242659688
step: 410, loss: 0.1758744716644287
step: 420, loss: 0.015728140249848366
step: 430, loss: 0.003077163826674223
step: 440, loss: 0.011165411211550236
step: 450, loss: 0.04299400374293327
step: 460, loss: 0.04667716845870018
step: 470, loss: 0.05127672106027603
step: 480, loss: 0.052448518574237823
step: 490, loss: 0.08581409603357315
step: 500, loss: 0.028749078512191772
step: 510, loss: 0.12038435786962509
step: 520, loss: 0.07277698814868927
step: 530, loss: 0.07213803380727768
step: 540, loss: 0.11407921463251114
step: 550, loss: 0.11676616966724396
step: 560, loss: 0.05919427052140236
step: 570, loss: 0.05707995593547821
step: 580, loss: 0.025258105248212814
step: 590, loss: 0.05797737091779709
step: 600, loss: 0.0228783767670393
step: 610, loss: 0.036000389605760574
step: 620, loss: 0.07907009869813919
step: 630, loss: 0.027865136042237282
step: 640, loss: 0.04856051877140999
step: 650, loss: 0.01552848145365715
step: 660, loss: 0.05225440859794617
step: 670, loss: 0.03699330985546112
step: 680, loss: 0.01924455724656582
step: 690, loss: 0.0643303170800209
step: 700, loss: 0.2144816517829895
step: 710, loss: 0.0362456813454628
step: 720, loss: 0.07625234127044678
step: 730, loss: 0.05213914439082146
step: 740, loss: 0.129237562417984
step: 750, loss: 0.06108354777097702
step: 760, loss: 0.08866418898105621
step: 770, loss: 0.021741081029176712
step: 780, loss: 0.12424871325492859
step: 790, loss: 0.09203197062015533
step: 800, loss: 0.04703431949019432
step: 810, loss: 0.1096334233880043
step: 820, loss: 0.1393452137708664
step: 830, loss: 0.06683489680290222
step: 840, loss: 0.05907226353883743
step: 850, loss: 0.049612756818532944
step: 860, loss: 0.07053932547569275
step: 870, loss: 0.02727755531668663
step: 880, loss: 0.057694099843502045
step: 890, loss: 0.003558584488928318
step: 900, loss: 0.09217799454927444
step: 910, loss: 0.024988800287246704
step: 920, loss: 0.11819455027580261
step: 930, loss: 0.055924322456121445
step: 940, loss: 0.013264759443700314
step: 950, loss: 0.03927033394575119
step: 960, loss: 0.20276421308517456
step: 970, loss: 0.04485512897372246
step: 980, loss: 0.06180272623896599
step: 990, loss: 0.0001195495278807357
step: 1000, loss: 0.07596064358949661
step: 1010, loss: 0.0775536596775055
step: 1020, loss: 0.035722654312849045
step: 1030, loss: 0.02671060711145401
step: 1040, loss: 0.03185408562421799
step: 1050, loss: 0.028564905747771263
step: 1060, loss: 0.11616916209459305
step: 1070, loss: 0.07214643061161041
epoch 14: dev_f1=0.9243065350258581, f1=0.9226441631504922, best_f1=0.9330855018587362
step: 0, loss: 0.038281966000795364
step: 10, loss: 0.06446170806884766
step: 20, loss: 0.0721304640173912
step: 30, loss: 0.025788959115743637
step: 40, loss: 0.00977388210594654
step: 50, loss: 0.02894669771194458
step: 60, loss: 0.021078595891594887
step: 70, loss: 0.03240156173706055
step: 80, loss: 0.04700443893671036
step: 90, loss: 0.30775851011276245
step: 100, loss: 0.0462130606174469
step: 110, loss: 0.022860374301671982
step: 120, loss: 0.08844757080078125
step: 130, loss: 0.0011451750760897994
step: 140, loss: 0.17594029009342194
step: 150, loss: 0.00016318229609169066
step: 160, loss: 0.032979246228933334
step: 170, loss: 0.026820840314030647
step: 180, loss: 0.05622148886322975
step: 190, loss: 0.025319553911685944
step: 200, loss: 0.10814738273620605
step: 210, loss: 0.0291972067207098
step: 220, loss: 0.04731059819459915
step: 230, loss: 0.10096913576126099
step: 240, loss: 0.09637798368930817
step: 250, loss: 0.003948903176933527
step: 260, loss: 0.12295856326818466
step: 270, loss: 0.04721998795866966
step: 280, loss: 0.08722080290317535
step: 290, loss: 0.054677560925483704
step: 300, loss: 0.05406542867422104
step: 310, loss: 0.060044899582862854
step: 320, loss: 0.007041969336569309
step: 330, loss: 0.042340341955423355
step: 340, loss: 0.0962148979306221
step: 350, loss: 0.08117251098155975
step: 360, loss: 0.1248447522521019
step: 370, loss: 3.23736276186537e-05
step: 380, loss: 0.04007447138428688
step: 390, loss: 0.02601642534136772
step: 400, loss: 0.06400353461503983
step: 410, loss: 0.0023821245413273573
step: 420, loss: 0.05675646662712097
step: 430, loss: 0.024712957441806793
step: 440, loss: 0.0004001004563178867
step: 450, loss: 0.05446942523121834
step: 460, loss: 0.04209492355585098
step: 470, loss: 0.1320480853319168
step: 480, loss: 0.060744863003492355
step: 490, loss: 0.02386622503399849
step: 500, loss: 0.02816777676343918
step: 510, loss: 0.016916174441576004
step: 520, loss: 0.07333913445472717
step: 530, loss: 0.0387984924018383
step: 540, loss: 0.0620591826736927
step: 550, loss: 0.10513966530561447
step: 560, loss: 0.00027920183492824435
step: 570, loss: 0.005016690585762262
step: 580, loss: 0.11996789276599884
step: 590, loss: 0.0004977501812390983
step: 600, loss: 0.04514695331454277
step: 610, loss: 0.030066004022955894
step: 620, loss: 0.04339359328150749
step: 630, loss: 0.05908733606338501
step: 640, loss: 0.13764582574367523
step: 650, loss: 0.05216580256819725
step: 660, loss: 0.008239059709012508
step: 670, loss: 0.02233365923166275
step: 680, loss: 0.004451575689017773
step: 690, loss: 0.07585202902555466
step: 700, loss: 0.06722596287727356
step: 710, loss: 0.02481856942176819
step: 720, loss: 0.08033038675785065
step: 730, loss: 0.01116927433758974
step: 740, loss: 0.02256951481103897
step: 750, loss: 0.025654492899775505
step: 760, loss: 0.1603804975748062
step: 770, loss: 0.09277965128421783
step: 780, loss: 0.06907941401004791
step: 790, loss: 0.05936432629823685
step: 800, loss: 0.01773463562130928
step: 810, loss: 0.07351650297641754
step: 820, loss: 0.025568494573235512
step: 830, loss: 0.05296461656689644
step: 840, loss: 0.04237665235996246
step: 850, loss: 0.05836385115981102
step: 860, loss: 0.002798581961542368
step: 870, loss: 0.07579066604375839
step: 880, loss: 0.044608332216739655
step: 890, loss: 0.025157084688544273
step: 900, loss: 0.04147469252347946
step: 910, loss: 0.014339947141706944
step: 920, loss: 0.051979951560497284
step: 930, loss: 0.01899639703333378
step: 940, loss: 0.02396152913570404
step: 950, loss: 0.021399933844804764
step: 960, loss: 0.03861987963318825
step: 970, loss: 0.01725599355995655
step: 980, loss: 0.05903567746281624
step: 990, loss: 0.020670557394623756
step: 1000, loss: 0.05810629203915596
step: 1010, loss: 0.05704691633582115
step: 1020, loss: 0.0641254261136055
step: 1030, loss: 0.036833085119724274
step: 1040, loss: 0.0008027541334740818
step: 1050, loss: 0.05516495183110237
step: 1060, loss: 0.03813014551997185
step: 1070, loss: 0.062316566705703735
epoch 15: dev_f1=0.9288354898336414, f1=0.9203865623561897, best_f1=0.9330855018587362
step: 0, loss: 0.06401767581701279
step: 10, loss: 0.025149138644337654
step: 20, loss: 0.11775830388069153
step: 30, loss: 8.545351738575846e-05
step: 40, loss: 0.01725047454237938
step: 50, loss: 0.005154211539775133
step: 60, loss: 0.00011833294411189854
step: 70, loss: 1.4573071894119494e-05
step: 80, loss: 0.11665843427181244
step: 90, loss: 0.02043280377984047
step: 100, loss: 0.0999244898557663
step: 110, loss: 0.024581877514719963
step: 120, loss: 0.000271821889327839
step: 130, loss: 0.04515059292316437
step: 140, loss: 0.09505286067724228
step: 150, loss: 0.0626014992594719
step: 160, loss: 0.06082747131586075
step: 170, loss: 3.178074621246196e-05
step: 180, loss: 0.06513694673776627
step: 190, loss: 0.04969426617026329
step: 200, loss: 0.012299839407205582
step: 210, loss: 0.047758933156728745
step: 220, loss: 0.06392692774534225
step: 230, loss: 0.06877776235342026
step: 240, loss: 0.0004943198291584849
step: 250, loss: 0.01648721471428871
step: 260, loss: 0.019827475771307945
step: 270, loss: 0.04908224195241928
step: 280, loss: 0.015894610434770584
step: 290, loss: 0.0515802726149559
step: 300, loss: 0.05572386085987091
step: 310, loss: 0.0968678668141365
step: 320, loss: 0.040695879608392715
step: 330, loss: 0.0001113673861254938
step: 340, loss: 0.00016513811715412885
step: 350, loss: 0.04732249677181244
step: 360, loss: 0.027083083987236023
step: 370, loss: 0.03932409733533859
step: 380, loss: 0.008883031085133553
step: 390, loss: 0.08005762100219727
step: 400, loss: 0.013743411749601364
step: 410, loss: 0.0002693746646400541
step: 420, loss: 0.01138847041875124
step: 430, loss: 0.06620316207408905
step: 440, loss: 0.028230054304003716
step: 450, loss: 0.02466009557247162
step: 460, loss: 0.11376409977674484
step: 470, loss: 0.12124384939670563
step: 480, loss: 0.06520772725343704
step: 490, loss: 0.04188205301761627
step: 500, loss: 0.018107187002897263
step: 510, loss: 0.05387851595878601
step: 520, loss: 0.003005050355568528
step: 530, loss: 0.08398746699094772
step: 540, loss: 0.02827373705804348
step: 550, loss: 0.11907599866390228
step: 560, loss: 0.09144479036331177
step: 570, loss: 0.0016416935250163078
step: 580, loss: 0.06523715704679489
step: 590, loss: 0.05496008321642876
step: 600, loss: 0.05200287699699402
step: 610, loss: 0.11620109528303146
step: 620, loss: 0.07550656050443649
step: 630, loss: 0.06806228309869766
step: 640, loss: 0.039809320122003555
step: 650, loss: 0.053251028060913086
step: 660, loss: 1.5627283573849127e-05
step: 670, loss: 0.023634497076272964
step: 680, loss: 0.03438197448849678
step: 690, loss: 0.09258083254098892
step: 700, loss: 0.01947513036429882
step: 710, loss: 0.0425550676882267
step: 720, loss: 9.999098256230354e-05
step: 730, loss: 0.05043550953269005
step: 740, loss: 0.12671147286891937
step: 750, loss: 0.05823168903589249
step: 760, loss: 0.03033519722521305
step: 770, loss: 0.041354287415742874
step: 780, loss: 0.04516398161649704
step: 790, loss: 0.001977671403437853
step: 800, loss: 0.034136444330215454
step: 810, loss: 0.0035364015493541956
step: 820, loss: 0.11290071159601212
step: 830, loss: 5.670317477779463e-05
step: 840, loss: 0.08904007077217102
step: 850, loss: 0.037765584886074066
step: 860, loss: 0.0017233313992619514
step: 870, loss: 0.1045556515455246
step: 880, loss: 0.07109391689300537
step: 890, loss: 0.07643089443445206
step: 900, loss: 0.033134061843156815
step: 910, loss: 0.01669861562550068
step: 920, loss: 0.06667473167181015
step: 930, loss: 0.026234455406665802
step: 940, loss: 0.01860295981168747
step: 950, loss: 0.023494726046919823
step: 960, loss: 0.08869961649179459
step: 970, loss: 1.3965726793685462e-05
step: 980, loss: 0.029468698427081108
step: 990, loss: 0.014804668724536896
step: 1000, loss: 0.0003391065984033048
step: 1010, loss: 0.10164975374937057
step: 1020, loss: 0.034681227058172226
step: 1030, loss: 0.059805333614349365
step: 1040, loss: 0.08117637783288956
step: 1050, loss: 0.03646848723292351
step: 1060, loss: 0.06322778761386871
step: 1070, loss: 0.0011566722532734275
epoch 16: dev_f1=0.9292649098474343, f1=0.9245020842982862, best_f1=0.9330855018587362
step: 0, loss: 0.04659704491496086
step: 10, loss: 0.13200999796390533
step: 20, loss: 0.05956970900297165
step: 30, loss: 0.044265005737543106
step: 40, loss: 0.05468049272894859
step: 50, loss: 0.012545515783131123
step: 60, loss: 0.035527974367141724
step: 70, loss: 0.0680769681930542
step: 80, loss: 0.029984064400196075
step: 90, loss: 0.14678646624088287
step: 100, loss: 0.04903644695878029
step: 110, loss: 0.045556001365184784
step: 120, loss: 0.0005526554305106401
step: 130, loss: 0.09149391949176788
step: 140, loss: 0.02590039186179638
step: 150, loss: 6.167533138068393e-05
step: 160, loss: 0.11193933337926865
step: 170, loss: 0.00019442850316409022
step: 180, loss: 0.0703410655260086
step: 190, loss: 0.10200551152229309
step: 200, loss: 0.005349043756723404
step: 210, loss: 0.003021060721948743
step: 220, loss: 0.0881955698132515
step: 230, loss: 0.002651892602443695
step: 240, loss: 0.04511193186044693
step: 250, loss: 0.04255025088787079
step: 260, loss: 2.548671000113245e-05
step: 270, loss: 0.08931393176317215
step: 280, loss: 0.048090554773807526
step: 290, loss: 0.22998563945293427
step: 300, loss: 0.08650638908147812
step: 310, loss: 0.0170933548361063
step: 320, loss: 0.00021468034537974745
step: 330, loss: 0.06187709420919418
step: 340, loss: 0.048837609589099884
step: 350, loss: 0.033574674278497696
step: 360, loss: 7.774289406370372e-05
step: 370, loss: 0.013860905542969704
step: 380, loss: 0.030669815838336945
step: 390, loss: 0.07053733617067337
step: 400, loss: 0.11844043433666229
step: 410, loss: 0.021090999245643616
step: 420, loss: 0.0010360385058447719
step: 430, loss: 0.04666288197040558
step: 440, loss: 0.04836554080247879
step: 450, loss: 0.017542891204357147
step: 460, loss: 0.05870644748210907
step: 470, loss: 0.024728957563638687
step: 480, loss: 0.02722674235701561
step: 490, loss: 0.08747675269842148
step: 500, loss: 0.06798011064529419
step: 510, loss: 0.05616383254528046
step: 520, loss: 0.054431378841400146
step: 530, loss: 0.05502069741487503
step: 540, loss: 0.040031641721725464
step: 550, loss: 0.09049671143293381
step: 560, loss: 0.01821688562631607
step: 570, loss: 0.0002737939648795873
step: 580, loss: 0.018475649878382683
step: 590, loss: 0.0018954086117446423
step: 600, loss: 0.01533976849168539
step: 610, loss: 0.01457885280251503
step: 620, loss: 0.08366177976131439
step: 630, loss: 0.0007685442687943578
step: 640, loss: 0.02010541409254074
step: 650, loss: 0.035488031804561615
step: 660, loss: 0.02636350318789482
step: 670, loss: 0.15809014439582825
step: 680, loss: 0.09116757661104202
step: 690, loss: 3.858476338791661e-05
step: 700, loss: 0.04677201062440872
step: 710, loss: 0.030857114121317863
step: 720, loss: 0.07963881641626358
step: 730, loss: 0.0024137652944773436
step: 740, loss: 0.034271467477083206
step: 750, loss: 0.06482982635498047
step: 760, loss: 0.03559759259223938
step: 770, loss: 0.013564161956310272
step: 780, loss: 0.008714454248547554
step: 790, loss: 0.08026789128780365
step: 800, loss: 0.01892949268221855
step: 810, loss: 0.041948553174734116
step: 820, loss: 0.019365932792425156
step: 830, loss: 0.02671694941818714
step: 840, loss: 0.006701706442981958
step: 850, loss: 0.040945012122392654
step: 860, loss: 0.070288747549057
step: 870, loss: 0.0488186851143837
step: 880, loss: 1.7865068002720363e-05
step: 890, loss: 0.03709704056382179
step: 900, loss: 0.043766845017671585
step: 910, loss: 0.0005554104573093355
step: 920, loss: 0.036393553018569946
step: 930, loss: 0.11955005675554276
step: 940, loss: 0.0260908342897892
step: 950, loss: 0.035910625010728836
step: 960, loss: 0.07294771075248718
step: 970, loss: 0.025010742247104645
step: 980, loss: 0.06730949133634567
step: 990, loss: 0.015515588223934174
step: 1000, loss: 0.034941185265779495
step: 1010, loss: 0.05830926448106766
step: 1020, loss: 0.041678790003061295
step: 1030, loss: 0.05318096652626991
step: 1040, loss: 0.08401857316493988
step: 1050, loss: 0.0853981077671051
step: 1060, loss: 2.784761272778269e-05
step: 1070, loss: 0.0730871930718422
epoch 17: dev_f1=0.9319664492078286, f1=0.9253034547152195, best_f1=0.9330855018587362
step: 0, loss: 0.0282933060079813
step: 10, loss: 0.01172598171979189
step: 20, loss: 0.03470798209309578
step: 30, loss: 0.0001366771903121844
step: 40, loss: 0.06395494192838669
step: 50, loss: 0.03411531820893288
step: 60, loss: 0.05309051275253296
step: 70, loss: 0.02938966266810894
step: 80, loss: 2.9660921427421272e-05
step: 90, loss: 0.08343308418989182
step: 100, loss: 0.04833584651350975
step: 110, loss: 0.02490285411477089
step: 120, loss: 0.020566489547491074
step: 130, loss: 0.11955288052558899
step: 140, loss: 0.0591282993555069
step: 150, loss: 0.03686079382896423
step: 160, loss: 3.040751107619144e-05
step: 170, loss: 0.06837935745716095
step: 180, loss: 0.0640372782945633
step: 190, loss: 0.028905540704727173
step: 200, loss: 0.03483210504055023
step: 210, loss: 0.17806142568588257
step: 220, loss: 0.0007029351545497775
step: 230, loss: 0.0392487533390522
step: 240, loss: 0.0027373956982046366
step: 250, loss: 0.046903256326913834
step: 260, loss: 0.04714478924870491
step: 270, loss: 0.04090112820267677
step: 280, loss: 0.09289384633302689
step: 290, loss: 0.027575669810175896
step: 300, loss: 1.975429586309474e-05
step: 310, loss: 0.08840586245059967
step: 320, loss: 0.1469288170337677
step: 330, loss: 0.053106360137462616
step: 340, loss: 0.06519032269716263
step: 350, loss: 3.732130426215008e-05
step: 360, loss: 0.052088260650634766
step: 370, loss: 0.06748248636722565
step: 380, loss: 0.035626865923404694
step: 390, loss: 1.3552444215747528e-05
step: 400, loss: 0.037983238697052
step: 410, loss: 0.019181694835424423
step: 420, loss: 0.049489811062812805
step: 430, loss: 0.0324837788939476
step: 440, loss: 0.04441915079951286
step: 450, loss: 0.01982700638473034
step: 460, loss: 0.000715876929461956
step: 470, loss: 0.06988545507192612
step: 480, loss: 0.08073417097330093
step: 490, loss: 0.07887767255306244
step: 500, loss: 0.04862034693360329
step: 510, loss: 0.05375244468450546
step: 520, loss: 0.0579582154750824
step: 530, loss: 0.026914887130260468
step: 540, loss: 0.07083389908075333
step: 550, loss: 0.07631660252809525
step: 560, loss: 0.04213766008615494
step: 570, loss: 0.00038662724546156824
step: 580, loss: 0.06878422200679779
step: 590, loss: 0.04488855600357056
step: 600, loss: 1.5839470506762154e-05
step: 610, loss: 0.016325335949659348
step: 620, loss: 0.017062555998563766
step: 630, loss: 0.055141299962997437
step: 640, loss: 0.000526100629940629
step: 650, loss: 0.029364893212914467
step: 660, loss: 2.915044387918897e-05
step: 670, loss: 0.000558342260774225
step: 680, loss: 0.06897786259651184
step: 690, loss: 0.0004010068951174617
step: 700, loss: 0.06028570979833603
step: 710, loss: 0.02213186025619507
step: 720, loss: 0.03161878138780594
step: 730, loss: 0.013240626081824303
step: 740, loss: 0.062020666897296906
step: 750, loss: 0.040794454514980316
step: 760, loss: 0.011542442254722118
step: 770, loss: 0.0013320608995854855
step: 780, loss: 0.035774558782577515
step: 790, loss: 0.11032340675592422
step: 800, loss: 0.10408151149749756
step: 810, loss: 0.02461402863264084
step: 820, loss: 0.03203601390123367
step: 830, loss: 0.019119348376989365
step: 840, loss: 0.04756060242652893
step: 850, loss: 0.07974394410848618
step: 860, loss: 0.040942899882793427
step: 870, loss: 0.024682993069291115
step: 880, loss: 0.07638058811426163
step: 890, loss: 0.04000014811754227
step: 900, loss: 0.05610568821430206
step: 910, loss: 0.02942085824906826
step: 920, loss: 0.04436592385172844
step: 930, loss: 0.0002169611252611503
step: 940, loss: 0.027852311730384827
step: 950, loss: 0.04284445196390152
step: 960, loss: 0.046045608818531036
step: 970, loss: 1.383552898914786e-05
step: 980, loss: 0.02257312834262848
step: 990, loss: 0.02922746166586876
step: 1000, loss: 0.02154023014008999
step: 1010, loss: 0.053372327238321304
step: 1020, loss: 0.020054154098033905
step: 1030, loss: 1.0896376807068009e-05
step: 1040, loss: 0.017605628818273544
step: 1050, loss: 0.11129387468099594
step: 1060, loss: 0.049581002444028854
step: 1070, loss: 0.07633117586374283
epoch 18: dev_f1=0.9315960912052118, f1=0.9237918215613383, best_f1=0.9330855018587362
step: 0, loss: 0.020147189497947693
step: 10, loss: 0.12007583677768707
step: 20, loss: 6.512606341857463e-05
step: 30, loss: 0.06776270270347595
step: 40, loss: 0.09931380301713943
step: 50, loss: 0.04575813561677933
step: 60, loss: 0.05564301460981369
step: 70, loss: 0.07488294690847397
step: 80, loss: 0.01355395931750536
step: 90, loss: 0.05515401065349579
step: 100, loss: 8.276045991806313e-05
step: 110, loss: 0.023151367902755737
step: 120, loss: 0.057251300662755966
step: 130, loss: 0.08817402273416519
step: 140, loss: 0.0765586867928505
step: 150, loss: 0.06165332347154617
step: 160, loss: 0.0006647695554420352
step: 170, loss: 0.05779612064361572
step: 180, loss: 0.01965605653822422
step: 190, loss: 0.10243354737758636
step: 200, loss: 0.08551451563835144
step: 210, loss: 0.0250142440199852
step: 220, loss: 0.02440190315246582
step: 230, loss: 0.022730628028512
step: 240, loss: 0.07307934015989304
step: 250, loss: 0.0402841791510582
step: 260, loss: 0.08702687174081802
step: 270, loss: 0.016352547332644463
step: 280, loss: 0.02760663628578186
step: 290, loss: 0.047185707837343216
step: 300, loss: 0.08116540312767029
step: 310, loss: 0.01809067279100418
step: 320, loss: 0.03278515487909317
step: 330, loss: 0.024187199771404266
step: 340, loss: 0.03226344287395477
step: 350, loss: 0.07843764126300812
step: 360, loss: 0.048198383301496506
step: 370, loss: 0.059232525527477264
step: 380, loss: 0.05501214414834976
step: 390, loss: 0.027495771646499634
step: 400, loss: 0.08600902557373047
step: 410, loss: 0.03146658092737198
step: 420, loss: 0.0006350054172798991
step: 430, loss: 0.07143703103065491
step: 440, loss: 0.02795148268342018
step: 450, loss: 0.0004855042789131403
step: 460, loss: 0.02339898981153965
step: 470, loss: 0.049411360174417496
step: 480, loss: 0.048815589398145676
step: 490, loss: 0.022990748286247253
step: 500, loss: 0.06297725439071655
step: 510, loss: 0.03651661053299904
step: 520, loss: 0.04001341760158539
step: 530, loss: 0.09587730467319489
step: 540, loss: 0.004143475089222193
step: 550, loss: 0.03938094899058342
step: 560, loss: 0.0731135755777359
step: 570, loss: 0.06517059355974197
step: 580, loss: 0.05529175326228142
step: 590, loss: 0.059953778982162476
step: 600, loss: 0.03571825847029686
step: 610, loss: 0.03952925279736519
step: 620, loss: 0.00020486065477598459
step: 630, loss: 9.357861017633695e-06
step: 640, loss: 0.04927721619606018
step: 650, loss: 0.03730408102273941
step: 660, loss: 0.04649652540683746
step: 670, loss: 0.012351195327937603
step: 680, loss: 0.05072718486189842
step: 690, loss: 0.03879481181502342
step: 700, loss: 0.018845820799469948
step: 710, loss: 0.11155100166797638
step: 720, loss: 0.07188389450311661
step: 730, loss: 0.005355255212634802
step: 740, loss: 0.03556989133358002
step: 750, loss: 0.0519741028547287
step: 760, loss: 0.00027929729549214244
step: 770, loss: 0.07721313834190369
step: 780, loss: 0.03895087167620659
step: 790, loss: 0.015198206529021263
step: 800, loss: 0.026883354410529137
step: 810, loss: 9.683614189270884e-05
step: 820, loss: 0.020218418911099434
step: 830, loss: 0.06050942838191986
step: 840, loss: 4.706888648797758e-05
step: 850, loss: 0.1138676330447197
step: 860, loss: 0.022927898913621902
step: 870, loss: 0.07793817669153214
step: 880, loss: 0.07116980850696564
step: 890, loss: 0.06215701624751091
step: 900, loss: 0.05120246112346649
step: 910, loss: 0.028638465330004692
step: 920, loss: 1.3921050594944973e-05
step: 930, loss: 0.12378718703985214
step: 940, loss: 0.02621925249695778
step: 950, loss: 0.04170718044042587
step: 960, loss: 0.022025378420948982
step: 970, loss: 0.000829295429866761
step: 980, loss: 0.03200145065784454
step: 990, loss: 3.243879837100394e-05
step: 1000, loss: 0.07741764932870865
step: 1010, loss: 0.004741751588881016
step: 1020, loss: 0.0067671784199774265
step: 1030, loss: 0.06751583516597748
step: 1040, loss: 0.026909315958619118
step: 1050, loss: 0.018940864130854607
step: 1060, loss: 0.12693293392658234
step: 1070, loss: 0.03913738206028938
epoch 19: dev_f1=0.9336426914153132, f1=0.9242916860195076, best_f1=0.9330855018587362
step: 0, loss: 0.029739269986748695
step: 10, loss: 0.028378024697303772
step: 20, loss: 0.05479338392615318
step: 30, loss: 0.06636933982372284
step: 40, loss: 0.023733755573630333
step: 50, loss: 0.07148022204637527
step: 60, loss: 0.00013536811457015574
step: 70, loss: 0.03458046540617943
step: 80, loss: 0.03132372722029686
step: 90, loss: 0.0761258602142334
step: 100, loss: 0.0629061609506607
step: 110, loss: 0.018194714561104774
step: 120, loss: 0.042222488671541214
step: 130, loss: 0.0444854199886322
step: 140, loss: 2.3640706785954535e-05
step: 150, loss: 0.07131174951791763
step: 160, loss: 2.0507137378444895e-05
step: 170, loss: 0.03847242891788483
step: 180, loss: 0.02290460467338562
step: 190, loss: 0.05004768818616867
step: 200, loss: 0.03288824111223221
step: 210, loss: 0.09453000128269196
step: 220, loss: 0.020171387121081352
step: 230, loss: 0.03933974355459213
step: 240, loss: 0.054787527769804
step: 250, loss: 0.08746567368507385
step: 260, loss: 0.10087903589010239
step: 270, loss: 0.017677517607808113
step: 280, loss: 0.0563410185277462
step: 290, loss: 0.08354359865188599
step: 300, loss: 0.04660554975271225
step: 310, loss: 0.10086826980113983
step: 320, loss: 0.04420889914035797
step: 330, loss: 0.060980815440416336
step: 340, loss: 0.029420845210552216
step: 350, loss: 0.05081690847873688
step: 360, loss: 0.068126380443573
step: 370, loss: 0.05176221951842308
step: 380, loss: 0.014517719857394695
step: 390, loss: 0.03589800372719765
step: 400, loss: 0.0388699434697628
step: 410, loss: 0.08253464847803116
step: 420, loss: 0.027587777003645897
step: 430, loss: 0.00018041266594082117
step: 440, loss: 0.026947027072310448
step: 450, loss: 0.014572888612747192
step: 460, loss: 0.0637010708451271
step: 470, loss: 0.03925975412130356
step: 480, loss: 0.06631723046302795
step: 490, loss: 0.0036989287473261356
step: 500, loss: 0.05587372928857803
step: 510, loss: 0.00052172492723912
step: 520, loss: 0.0240035280585289
step: 530, loss: 0.0368725061416626
step: 540, loss: 0.02727918140590191
step: 550, loss: 0.031784676015377045
step: 560, loss: 0.003740553744137287
step: 570, loss: 0.00044742008321918547
step: 580, loss: 0.017832880839705467
step: 590, loss: 0.047516196966171265
step: 600, loss: 0.015343678183853626
step: 610, loss: 0.023266112431883812
step: 620, loss: 0.03788234293460846
step: 630, loss: 0.027275141328573227
step: 640, loss: 0.024540552869439125
step: 650, loss: 0.02867981791496277
step: 660, loss: 0.08170771598815918
step: 670, loss: 0.05761757865548134
step: 680, loss: 0.04768817871809006
step: 690, loss: 0.07945375889539719
step: 700, loss: 0.02228119783103466
step: 710, loss: 0.004497135989367962
step: 720, loss: 0.04152818024158478
step: 730, loss: 0.001026138779707253
step: 740, loss: 0.01903740130364895
step: 750, loss: 6.58762437524274e-05
step: 760, loss: 0.027211884036660194
step: 770, loss: 0.06727538257837296
step: 780, loss: 0.01862943544983864
step: 790, loss: 0.09343259781599045
step: 800, loss: 0.000659642624668777
step: 810, loss: 0.014075720682740211
step: 820, loss: 0.05239850655198097
step: 830, loss: 0.018601564690470695
step: 840, loss: 0.01693831756711006
step: 850, loss: 0.044989120215177536
step: 860, loss: 0.025831783190369606
step: 870, loss: 0.0573996864259243
step: 880, loss: 0.06065577641129494
step: 890, loss: 0.010105669498443604
step: 900, loss: 0.06087920069694519
step: 910, loss: 0.07258949428796768
step: 920, loss: 0.12190502882003784
step: 930, loss: 0.00018675660248845816
step: 940, loss: 0.09509777277708054
step: 950, loss: 0.031565021723508835
step: 960, loss: 0.01870565116405487
step: 970, loss: 0.04853522405028343
step: 980, loss: 0.0005818515201099217
step: 990, loss: 0.02448032796382904
step: 1000, loss: 0.06924430280923843
step: 1010, loss: 4.586229988490231e-05
step: 1020, loss: 0.03457203134894371
step: 1030, loss: 0.02575451321899891
step: 1040, loss: 0.07597650587558746
step: 1050, loss: 0.04014553874731064
step: 1060, loss: 0.06640416383743286
step: 1070, loss: 0.07242603600025177
epoch 20: dev_f1=0.9299719887955181, f1=0.9242990654205607, best_f1=0.9330855018587362
