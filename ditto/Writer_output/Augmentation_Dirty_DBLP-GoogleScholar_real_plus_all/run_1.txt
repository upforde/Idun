cuda
Device: cuda
step: 0, loss: 0.8491039872169495
step: 10, loss: 0.576343297958374
step: 20, loss: 0.47692880034446716
step: 30, loss: 0.44817155599594116
step: 40, loss: 0.3101983964443207
step: 50, loss: 0.2440546154975891
step: 60, loss: 0.2699969410896301
step: 70, loss: 0.3607053756713867
step: 80, loss: 0.14291876554489136
step: 90, loss: 0.23576216399669647
step: 100, loss: 0.15868043899536133
step: 110, loss: 0.1317138522863388
step: 120, loss: 0.10600756853818893
step: 130, loss: 0.18873420357704163
step: 140, loss: 0.12639987468719482
step: 150, loss: 0.19731393456459045
step: 160, loss: 0.21932445466518402
step: 170, loss: 0.17214517295360565
step: 180, loss: 0.2135101705789566
step: 190, loss: 0.18242967128753662
step: 200, loss: 0.16593988239765167
step: 210, loss: 0.08316896855831146
step: 220, loss: 0.3463624119758606
step: 230, loss: 0.26083311438560486
step: 240, loss: 0.2719840705394745
step: 250, loss: 0.08737191557884216
step: 260, loss: 0.19863906502723694
step: 270, loss: 0.18907876312732697
step: 280, loss: 0.09188040345907211
step: 290, loss: 0.20804078876972198
step: 300, loss: 0.13725821673870087
step: 310, loss: 0.05138286203145981
step: 320, loss: 0.16276201605796814
step: 330, loss: 0.2357747107744217
step: 340, loss: 0.11996478587388992
step: 350, loss: 0.13599802553653717
step: 360, loss: 0.014768963679671288
step: 370, loss: 0.08159379661083221
step: 380, loss: 0.20400409400463104
step: 390, loss: 0.16471019387245178
step: 400, loss: 0.15653552114963531
step: 410, loss: 0.08262136578559875
step: 420, loss: 0.08934362232685089
step: 430, loss: 0.14243674278259277
step: 440, loss: 0.13755707442760468
step: 450, loss: 0.18291836977005005
step: 460, loss: 0.13580426573753357
step: 470, loss: 0.18492722511291504
step: 480, loss: 0.1278069168329239
step: 490, loss: 0.046190131455659866
step: 500, loss: 0.35656359791755676
step: 510, loss: 0.1210697740316391
step: 520, loss: 0.16242307424545288
step: 530, loss: 0.1861199587583542
step: 540, loss: 0.2007361501455307
step: 550, loss: 0.08178465068340302
step: 560, loss: 0.09732304513454437
step: 570, loss: 0.14560824632644653
step: 580, loss: 0.18904079496860504
step: 590, loss: 0.18728455901145935
step: 600, loss: 0.10137756168842316
step: 610, loss: 0.039792828261852264
step: 620, loss: 0.25957420468330383
step: 630, loss: 0.13499292731285095
step: 640, loss: 0.037982866168022156
step: 650, loss: 0.1931552141904831
step: 660, loss: 0.08347547799348831
step: 670, loss: 0.16530796885490417
step: 680, loss: 0.25196629762649536
step: 690, loss: 0.11402767151594162
step: 700, loss: 0.10681690275669098
step: 710, loss: 0.21602259576320648
step: 720, loss: 0.18888835608959198
step: 730, loss: 0.18276207149028778
step: 740, loss: 0.23965772986412048
step: 750, loss: 0.17051741480827332
step: 760, loss: 0.15046612918376923
step: 770, loss: 0.12115427106618881
step: 780, loss: 0.08690346777439117
step: 790, loss: 0.09161558747291565
step: 800, loss: 0.08766637742519379
step: 810, loss: 0.045921824872493744
step: 820, loss: 0.2031383365392685
step: 830, loss: 0.1638815999031067
step: 840, loss: 0.072698675096035
step: 850, loss: 0.11303947865962982
step: 860, loss: 0.07432633638381958
step: 870, loss: 0.1886380910873413
step: 880, loss: 0.09628447890281677
step: 890, loss: 0.25477030873298645
step: 900, loss: 0.11610038578510284
step: 910, loss: 0.10013236850500107
step: 920, loss: 0.0634123906493187
step: 930, loss: 0.149093896150589
step: 940, loss: 0.12274955213069916
step: 950, loss: 0.31087616086006165
step: 960, loss: 0.15621697902679443
step: 970, loss: 0.10317260026931763
step: 980, loss: 0.12880614399909973
step: 990, loss: 0.10534974187612534
step: 1000, loss: 0.11880200356245041
step: 1010, loss: 0.161465123295784
step: 1020, loss: 0.14791512489318848
step: 1030, loss: 0.1861737221479416
step: 1040, loss: 0.04282452538609505
step: 1050, loss: 0.17065586149692535
step: 1060, loss: 0.13542096316814423
step: 1070, loss: 0.055465780198574066
epoch 1: dev_f1=0.9247606019151847, f1=0.9269178393100317, best_f1=0.9269178393100317
step: 0, loss: 0.06354183703660965
step: 10, loss: 0.1934358775615692
step: 20, loss: 0.09627620875835419
step: 30, loss: 0.21921120584011078
step: 40, loss: 0.10582657158374786
step: 50, loss: 0.3352647125720978
step: 60, loss: 0.10523763298988342
step: 70, loss: 0.24491582810878754
step: 80, loss: 0.1110532209277153
step: 90, loss: 0.03190070018172264
step: 100, loss: 0.13802792131900787
step: 110, loss: 0.16095013916492462
step: 120, loss: 0.17806227505207062
step: 130, loss: 0.04904823750257492
step: 140, loss: 0.23408037424087524
step: 150, loss: 0.35759562253952026
step: 160, loss: 0.10120078176259995
step: 170, loss: 0.07503850013017654
step: 180, loss: 0.15597829222679138
step: 190, loss: 0.09560882300138474
step: 200, loss: 0.17243528366088867
step: 210, loss: 0.08728679269552231
step: 220, loss: 0.1483529955148697
step: 230, loss: 0.07504995912313461
step: 240, loss: 0.06690608710050583
step: 250, loss: 0.09655289351940155
step: 260, loss: 0.24655655026435852
step: 270, loss: 0.0958016961812973
step: 280, loss: 0.15386636555194855
step: 290, loss: 0.09150324761867523
step: 300, loss: 0.17531432211399078
step: 310, loss: 0.12089028209447861
step: 320, loss: 0.11733946949243546
step: 330, loss: 0.20024576783180237
step: 340, loss: 0.14176364243030548
step: 350, loss: 0.09120427817106247
step: 360, loss: 0.22881922125816345
step: 370, loss: 0.1574089676141739
step: 380, loss: 0.15816032886505127
step: 390, loss: 0.05268433690071106
step: 400, loss: 0.029989156872034073
step: 410, loss: 0.2898588478565216
step: 420, loss: 0.12461560219526291
step: 430, loss: 0.13136820495128632
step: 440, loss: 0.2774549126625061
step: 450, loss: 0.06943925470113754
step: 460, loss: 0.1047498881816864
step: 470, loss: 0.1091427281498909
step: 480, loss: 0.1278144270181656
step: 490, loss: 0.08936825394630432
step: 500, loss: 0.1056215837597847
step: 510, loss: 0.18917730450630188
step: 520, loss: 0.2583792209625244
step: 530, loss: 0.04877997934818268
step: 540, loss: 0.12384270131587982
step: 550, loss: 0.07441096752882004
step: 560, loss: 0.1321772336959839
step: 570, loss: 0.0958804190158844
step: 580, loss: 0.10322872549295425
step: 590, loss: 0.03506733477115631
step: 600, loss: 0.09948453307151794
step: 610, loss: 0.21142823994159698
step: 620, loss: 0.18691205978393555
step: 630, loss: 0.08456162363290787
step: 640, loss: 0.08190450072288513
step: 650, loss: 0.07312574982643127
step: 660, loss: 0.10702940821647644
step: 670, loss: 0.16621458530426025
step: 680, loss: 0.12869010865688324
step: 690, loss: 0.14443442225456238
step: 700, loss: 0.10606373846530914
step: 710, loss: 0.3543986678123474
step: 720, loss: 0.1666884422302246
step: 730, loss: 0.08553098142147064
step: 740, loss: 0.20344200730323792
step: 750, loss: 0.1378534734249115
step: 760, loss: 0.12829270958900452
step: 770, loss: 0.20905007421970367
step: 780, loss: 0.07522960752248764
step: 790, loss: 0.15331831574440002
step: 800, loss: 0.3878139853477478
step: 810, loss: 0.7305953502655029
step: 820, loss: 0.21085889637470245
step: 830, loss: 0.08802568167448044
step: 840, loss: 0.08211587369441986
step: 850, loss: 0.09446785598993301
step: 860, loss: 0.022601449862122536
step: 870, loss: 0.11545321345329285
step: 880, loss: 0.050840090960264206
step: 890, loss: 0.13913466036319733
step: 900, loss: 0.11434724926948547
step: 910, loss: 0.17354489862918854
step: 920, loss: 0.14871510863304138
step: 930, loss: 0.11508788168430328
step: 940, loss: 0.06491918861865997
step: 950, loss: 0.16136668622493744
step: 960, loss: 0.12693168222904205
step: 970, loss: 0.16000157594680786
step: 980, loss: 0.1045072078704834
step: 990, loss: 0.04379374533891678
step: 1000, loss: 0.026912668719887733
step: 1010, loss: 0.08661555498838425
step: 1020, loss: 0.12456201016902924
step: 1030, loss: 0.16481532156467438
step: 1040, loss: 0.19769929349422455
step: 1050, loss: 0.14997664093971252
step: 1060, loss: 0.21644863486289978
step: 1070, loss: 0.1768275499343872
epoch 2: dev_f1=0.9239872553482021, f1=0.9153005464480876, best_f1=0.9269178393100317
step: 0, loss: 0.06009812280535698
step: 10, loss: 0.1260690987110138
step: 20, loss: 0.028264503926038742
step: 30, loss: 0.26737555861473083
step: 40, loss: 0.2138584405183792
step: 50, loss: 0.11164209246635437
step: 60, loss: 0.05777459964156151
step: 70, loss: 0.08773348480463028
step: 80, loss: 0.061780061572790146
step: 90, loss: 0.1281314194202423
step: 100, loss: 0.058927811682224274
step: 110, loss: 0.06555744260549545
step: 120, loss: 0.13936439156532288
step: 130, loss: 0.3766261637210846
step: 140, loss: 0.20581626892089844
step: 150, loss: 0.09621336311101913
step: 160, loss: 0.06975897401571274
step: 170, loss: 0.2145819365978241
step: 180, loss: 0.09691394865512848
step: 190, loss: 0.030193237587809563
step: 200, loss: 0.09502742439508438
step: 210, loss: 0.05119408667087555
step: 220, loss: 0.02880893088877201
step: 230, loss: 0.04163622856140137
step: 240, loss: 0.025208259001374245
step: 250, loss: 0.21895939111709595
step: 260, loss: 0.0743994489312172
step: 270, loss: 0.13494578003883362
step: 280, loss: 0.019853156059980392
step: 290, loss: 0.10947856307029724
step: 300, loss: 0.06587620079517365
step: 310, loss: 0.13066142797470093
step: 320, loss: 0.20762145519256592
step: 330, loss: 0.12359850853681564
step: 340, loss: 0.09589459002017975
step: 350, loss: 0.08713819086551666
step: 360, loss: 0.09335813671350479
step: 370, loss: 0.13436417281627655
step: 380, loss: 0.04636178910732269
step: 390, loss: 0.10466014593839645
step: 400, loss: 0.14224931597709656
step: 410, loss: 0.22705459594726562
step: 420, loss: 0.10948311537504196
step: 430, loss: 0.12560734152793884
step: 440, loss: 0.1061430275440216
step: 450, loss: 0.10380852222442627
step: 460, loss: 0.043595824390649796
step: 470, loss: 0.1634475737810135
step: 480, loss: 0.22046469151973724
step: 490, loss: 0.03664055094122887
step: 500, loss: 0.1173424944281578
step: 510, loss: 0.13186950981616974
step: 520, loss: 0.07942681014537811
step: 530, loss: 0.08148950338363647
step: 540, loss: 0.11242202669382095
step: 550, loss: 0.053289394825696945
step: 560, loss: 0.04774001985788345
step: 570, loss: 0.08767950534820557
step: 580, loss: 0.06028147414326668
step: 590, loss: 0.12047653645277023
step: 600, loss: 0.1587972193956375
step: 610, loss: 0.11131399869918823
step: 620, loss: 0.05158541351556778
step: 630, loss: 0.055760473012924194
step: 640, loss: 0.05737121030688286
step: 650, loss: 0.05575249344110489
step: 660, loss: 0.1118045225739479
step: 670, loss: 0.08696239441633224
step: 680, loss: 0.08796902000904083
step: 690, loss: 0.15218126773834229
step: 700, loss: 0.04069622606039047
step: 710, loss: 0.1131054013967514
step: 720, loss: 0.0930168554186821
step: 730, loss: 0.08455801755189896
step: 740, loss: 0.19244182109832764
step: 750, loss: 0.15195174515247345
step: 760, loss: 0.11899732053279877
step: 770, loss: 0.07945308834314346
step: 780, loss: 0.072270467877388
step: 790, loss: 0.15978117287158966
step: 800, loss: 0.18303397297859192
step: 810, loss: 0.16480106115341187
step: 820, loss: 0.08844100683927536
step: 830, loss: 0.10131001472473145
step: 840, loss: 0.12034015357494354
step: 850, loss: 0.03282087668776512
step: 860, loss: 0.1681353598833084
step: 870, loss: 0.024707477539777756
step: 880, loss: 0.06780683249235153
step: 890, loss: 0.10550041496753693
step: 900, loss: 0.11327192932367325
step: 910, loss: 0.07151387631893158
step: 920, loss: 0.11419758200645447
step: 930, loss: 0.1389385461807251
step: 940, loss: 0.08403506875038147
step: 950, loss: 0.2663044333457947
step: 960, loss: 0.07575828582048416
step: 970, loss: 0.16325776278972626
step: 980, loss: 0.04563647136092186
step: 990, loss: 0.07307887822389603
step: 1000, loss: 0.0547046922147274
step: 1010, loss: 0.19705776870250702
step: 1020, loss: 0.10515975207090378
step: 1030, loss: 0.10238531231880188
step: 1040, loss: 0.08587871491909027
step: 1050, loss: 0.14879408478736877
step: 1060, loss: 0.10387056320905685
step: 1070, loss: 0.1321115791797638
epoch 3: dev_f1=0.9176688251618872, f1=0.9213587715216379, best_f1=0.9269178393100317
step: 0, loss: 0.14190615713596344
step: 10, loss: 0.1193719431757927
step: 20, loss: 0.05971406027674675
step: 30, loss: 0.09109286963939667
step: 40, loss: 0.12508544325828552
step: 50, loss: 0.025909706950187683
step: 60, loss: 0.11015427112579346
step: 70, loss: 0.15419265627861023
step: 80, loss: 0.07682406157255173
step: 90, loss: 0.08328576385974884
step: 100, loss: 0.064136803150177
step: 110, loss: 0.16409832239151
step: 120, loss: 0.12554731965065002
step: 130, loss: 0.055348098278045654
step: 140, loss: 0.08211159706115723
step: 150, loss: 0.16159498691558838
step: 160, loss: 0.12170460820198059
step: 170, loss: 0.06152499094605446
step: 180, loss: 0.0590934082865715
step: 190, loss: 0.05079323798418045
step: 200, loss: 0.11308340728282928
step: 210, loss: 0.11444651335477829
step: 220, loss: 0.101589135825634
step: 230, loss: 0.06646173447370529
step: 240, loss: 0.04081016033887863
step: 250, loss: 0.197639599442482
step: 260, loss: 0.1177135556936264
step: 270, loss: 0.06596046686172485
step: 280, loss: 0.08895040303468704
step: 290, loss: 0.1263762265443802
step: 300, loss: 0.10641409456729889
step: 310, loss: 0.184368297457695
step: 320, loss: 0.057958271354436874
step: 330, loss: 0.09820756316184998
step: 340, loss: 0.18262548744678497
step: 350, loss: 0.12492992728948593
step: 360, loss: 0.07483817636966705
step: 370, loss: 0.10509106516838074
step: 380, loss: 0.040889665484428406
step: 390, loss: 0.04155951738357544
step: 400, loss: 0.02068612538278103
step: 410, loss: 0.05205098167061806
step: 420, loss: 0.04107508435845375
step: 430, loss: 0.046638958156108856
step: 440, loss: 0.1905229240655899
step: 450, loss: 0.027981750667095184
step: 460, loss: 0.12378203123807907
step: 470, loss: 0.03701760992407799
step: 480, loss: 0.1084224283695221
step: 490, loss: 0.025441383942961693
step: 500, loss: 0.10546685755252838
step: 510, loss: 0.15755513310432434
step: 520, loss: 0.09044940024614334
step: 530, loss: 0.1163768544793129
step: 540, loss: 0.06094130873680115
step: 550, loss: 0.10295607149600983
step: 560, loss: 0.31890860199928284
step: 570, loss: 0.20804564654827118
step: 580, loss: 0.07061087340116501
step: 590, loss: 0.07163122296333313
step: 600, loss: 0.103190578520298
step: 610, loss: 0.04599076136946678
step: 620, loss: 0.019930999726057053
step: 630, loss: 0.049293048679828644
step: 640, loss: 0.1188722476363182
step: 650, loss: 0.011741439811885357
step: 660, loss: 0.12924253940582275
step: 670, loss: 0.027765240520238876
step: 680, loss: 0.09700712561607361
step: 690, loss: 0.11107669770717621
step: 700, loss: 0.025042207911610603
step: 710, loss: 0.06861316412687302
step: 720, loss: 0.1339103728532791
step: 730, loss: 0.08178412169218063
step: 740, loss: 0.17850105464458466
step: 750, loss: 0.16785535216331482
step: 760, loss: 0.07809540629386902
step: 770, loss: 0.20988023281097412
step: 780, loss: 0.2343401312828064
step: 790, loss: 0.04089438170194626
step: 800, loss: 0.08661217987537384
step: 810, loss: 0.3431534767150879
step: 820, loss: 0.038210440427064896
step: 830, loss: 0.19720882177352905
step: 840, loss: 0.03451979160308838
step: 850, loss: 0.07540187984704971
step: 860, loss: 0.027602434158325195
step: 870, loss: 0.05242374166846275
step: 880, loss: 0.15116019546985626
step: 890, loss: 0.053445003926754
step: 900, loss: 0.06167636811733246
step: 910, loss: 0.11808078736066818
step: 920, loss: 0.13679884374141693
step: 930, loss: 0.025530777871608734
step: 940, loss: 0.1069117933511734
step: 950, loss: 0.19065606594085693
step: 960, loss: 0.118023581802845
step: 970, loss: 0.07813489437103271
step: 980, loss: 0.07418125867843628
step: 990, loss: 0.058599941432476044
step: 1000, loss: 0.07201694697141647
step: 1010, loss: 0.0715748518705368
step: 1020, loss: 0.05640926584601402
step: 1030, loss: 0.08616209775209427
step: 1040, loss: 0.034729599952697754
step: 1050, loss: 0.07092659920454025
step: 1060, loss: 0.2091875672340393
step: 1070, loss: 0.19878925383090973
epoch 4: dev_f1=0.9183856502242154, f1=0.9196228109564436, best_f1=0.9269178393100317
step: 0, loss: 0.13082684576511383
step: 10, loss: 0.05335770174860954
step: 20, loss: 0.02751738205552101
step: 30, loss: 0.09919516742229462
step: 40, loss: 0.09617430716753006
step: 50, loss: 0.10535761713981628
step: 60, loss: 0.05064784362912178
step: 70, loss: 0.03189493343234062
step: 80, loss: 0.061450328677892685
step: 90, loss: 0.17173941433429718
step: 100, loss: 0.02009430341422558
step: 110, loss: 0.08740527927875519
step: 120, loss: 0.10873159766197205
step: 130, loss: 0.19658173620700836
step: 140, loss: 0.07369448244571686
step: 150, loss: 0.04384250566363335
step: 160, loss: 0.052893880754709244
step: 170, loss: 0.09986910969018936
step: 180, loss: 0.07219699025154114
step: 190, loss: 0.07748492062091827
step: 200, loss: 0.15451115369796753
step: 210, loss: 0.1739116609096527
step: 220, loss: 0.12776462733745575
step: 230, loss: 0.04579239338636398
step: 240, loss: 0.08037962764501572
step: 250, loss: 0.1569409817457199
step: 260, loss: 0.10101255774497986
step: 270, loss: 0.17462114989757538
step: 280, loss: 0.031340789049863815
step: 290, loss: 0.08360990881919861
step: 300, loss: 0.14860104024410248
step: 310, loss: 0.08758397400379181
step: 320, loss: 0.07657073438167572
step: 330, loss: 0.17624697089195251
step: 340, loss: 0.0653727725148201
step: 350, loss: 0.0780898928642273
step: 360, loss: 0.04568314552307129
step: 370, loss: 0.14506134390830994
step: 380, loss: 0.12221807986497879
step: 390, loss: 0.031098131090402603
step: 400, loss: 0.14017190039157867
step: 410, loss: 0.013215799815952778
step: 420, loss: 0.13723669946193695
step: 430, loss: 0.004405226092785597
step: 440, loss: 0.18105953931808472
step: 450, loss: 0.23366889357566833
step: 460, loss: 0.0836670994758606
step: 470, loss: 0.18760904669761658
step: 480, loss: 0.032844409346580505
step: 490, loss: 0.08341307193040848
step: 500, loss: 0.059551965445280075
step: 510, loss: 0.07241924852132797
step: 520, loss: 0.07891494780778885
step: 530, loss: 0.028377071022987366
step: 540, loss: 0.17606273293495178
step: 550, loss: 0.08655080944299698
step: 560, loss: 0.051809851080179214
step: 570, loss: 0.11359056085348129
step: 580, loss: 0.07663257420063019
step: 590, loss: 0.14623354375362396
step: 600, loss: 0.12512516975402832
step: 610, loss: 0.008038438856601715
step: 620, loss: 0.11956693977117538
step: 630, loss: 0.058489274233579636
step: 640, loss: 0.11242835223674774
step: 650, loss: 0.1442069113254547
step: 660, loss: 0.13487203419208527
step: 670, loss: 0.0903530865907669
step: 680, loss: 0.0439298152923584
step: 690, loss: 0.11809705942869186
step: 700, loss: 0.13876201212406158
step: 710, loss: 0.16355770826339722
step: 720, loss: 0.05947360023856163
step: 730, loss: 0.12551409006118774
step: 740, loss: 0.16095472872257233
step: 750, loss: 0.06895755231380463
step: 760, loss: 0.10256269574165344
step: 770, loss: 0.027913225814700127
step: 780, loss: 0.08195345848798752
step: 790, loss: 0.07807684689760208
step: 800, loss: 0.06241173297166824
step: 810, loss: 0.07286979258060455
step: 820, loss: 0.09458967298269272
step: 830, loss: 0.07978390157222748
step: 840, loss: 0.14398157596588135
step: 850, loss: 0.09912436455488205
step: 860, loss: 0.028224125504493713
step: 870, loss: 0.08025272935628891
step: 880, loss: 0.025689464062452316
step: 890, loss: 0.16824501752853394
step: 900, loss: 0.06417446583509445
step: 910, loss: 0.10986027866601944
step: 920, loss: 0.06121842563152313
step: 930, loss: 0.1410006731748581
step: 940, loss: 0.0404389463365078
step: 950, loss: 0.16507333517074585
step: 960, loss: 0.06197119876742363
step: 970, loss: 0.27404165267944336
step: 980, loss: 0.10603024065494537
step: 990, loss: 0.05124984681606293
step: 1000, loss: 0.06189890578389168
step: 1010, loss: 0.050771452486515045
step: 1020, loss: 0.3125168979167938
step: 1030, loss: 0.10071644186973572
step: 1040, loss: 0.06789258867502213
step: 1050, loss: 0.14733998477458954
step: 1060, loss: 0.04498931020498276
step: 1070, loss: 0.08705075830221176
epoch 5: dev_f1=0.9260991580916744, f1=0.9209171736078615, best_f1=0.9209171736078615
step: 0, loss: 0.15017540752887726
step: 10, loss: 0.0772462859749794
step: 20, loss: 0.04914870113134384
step: 30, loss: 0.047033362090587616
step: 40, loss: 0.04056697338819504
step: 50, loss: 0.1531410813331604
step: 60, loss: 0.2064950168132782
step: 70, loss: 0.08499352633953094
step: 80, loss: 0.02135421894490719
step: 90, loss: 0.0824369266629219
step: 100, loss: 0.0776451975107193
step: 110, loss: 0.024515895172953606
step: 120, loss: 0.12585000693798065
step: 130, loss: 0.05704808235168457
step: 140, loss: 0.10716257989406586
step: 150, loss: 0.1098250150680542
step: 160, loss: 0.07818286120891571
step: 170, loss: 0.04460522159934044
step: 180, loss: 0.2248510867357254
step: 190, loss: 0.02249586023390293
step: 200, loss: 0.028616972267627716
step: 210, loss: 0.14840450882911682
step: 220, loss: 0.058391887694597244
step: 230, loss: 0.0962359756231308
step: 240, loss: 0.11086517572402954
step: 250, loss: 0.08134235441684723
step: 260, loss: 0.1446460783481598
step: 270, loss: 0.02446223422884941
step: 280, loss: 0.023298874497413635
step: 290, loss: 0.06938416510820389
step: 300, loss: 0.07788009196519852
step: 310, loss: 0.17073798179626465
step: 320, loss: 0.1357053965330124
step: 330, loss: 0.028619779273867607
step: 340, loss: 0.11780072003602982
step: 350, loss: 0.21522417664527893
step: 360, loss: 0.15241530537605286
step: 370, loss: 0.08593115210533142
step: 380, loss: 0.0974981039762497
step: 390, loss: 0.013505494222044945
step: 400, loss: 0.08016832917928696
step: 410, loss: 0.08428036421537399
step: 420, loss: 0.06532784551382065
step: 430, loss: 0.15992040932178497
step: 440, loss: 0.19936200976371765
step: 450, loss: 0.03112557902932167
step: 460, loss: 0.12048432230949402
step: 470, loss: 0.06347627192735672
step: 480, loss: 0.1263059377670288
step: 490, loss: 0.13333389163017273
step: 500, loss: 0.07435829937458038
step: 510, loss: 0.009862828068435192
step: 520, loss: 0.024541977792978287
step: 530, loss: 0.07945320010185242
step: 540, loss: 0.07910235226154327
step: 550, loss: 0.0643954873085022
step: 560, loss: 0.12687908113002777
step: 570, loss: 0.026199229061603546
step: 580, loss: 0.09358800202608109
step: 590, loss: 0.12962105870246887
step: 600, loss: 0.02465280145406723
step: 610, loss: 0.010121176019310951
step: 620, loss: 0.03364920988678932
step: 630, loss: 0.05877848342061043
step: 640, loss: 0.06549118459224701
step: 650, loss: 0.05014652758836746
step: 660, loss: 0.09232234209775925
step: 670, loss: 0.10990887880325317
step: 680, loss: 0.13261525332927704
step: 690, loss: 0.15235427021980286
step: 700, loss: 0.053787361830472946
step: 710, loss: 0.05430992692708969
step: 720, loss: 0.12429417669773102
step: 730, loss: 0.04745923727750778
step: 740, loss: 0.06927285343408585
step: 750, loss: 0.08737959712743759
step: 760, loss: 0.08401232957839966
step: 770, loss: 0.17402999103069305
step: 780, loss: 0.11175790429115295
step: 790, loss: 0.10607372969388962
step: 800, loss: 0.0867043286561966
step: 810, loss: 0.17612232267856598
step: 820, loss: 0.05779397115111351
step: 830, loss: 0.11666953563690186
step: 840, loss: 0.1336967498064041
step: 850, loss: 0.0873616635799408
step: 860, loss: 0.09647583216428757
step: 870, loss: 0.13170278072357178
step: 880, loss: 0.07748255133628845
step: 890, loss: 0.047403015196323395
step: 900, loss: 0.07966120541095734
step: 910, loss: 0.0488007478415966
step: 920, loss: 0.07568341493606567
step: 930, loss: 0.2215431183576584
step: 940, loss: 0.08930176496505737
step: 950, loss: 0.029187971726059914
step: 960, loss: 0.09541232883930206
step: 970, loss: 0.08622417598962784
step: 980, loss: 0.13998711109161377
step: 990, loss: 0.02282889187335968
step: 1000, loss: 0.05661121383309364
step: 1010, loss: 0.17003315687179565
step: 1020, loss: 0.08769487589597702
step: 1030, loss: 0.03568810224533081
step: 1040, loss: 0.09484607726335526
step: 1050, loss: 0.05290680378675461
step: 1060, loss: 0.11054113507270813
step: 1070, loss: 0.11339220404624939
epoch 6: dev_f1=0.9270976616231087, f1=0.9185457892314773, best_f1=0.9185457892314773
step: 0, loss: 0.05114413797855377
step: 10, loss: 0.11309418082237244
step: 20, loss: 0.0690176784992218
step: 30, loss: 0.10680127888917923
step: 40, loss: 0.11108924448490143
step: 50, loss: 0.1545926034450531
step: 60, loss: 0.1126655638217926
step: 70, loss: 0.042188361287117004
step: 80, loss: 0.10657984763383865
step: 90, loss: 0.051903437823057175
step: 100, loss: 0.1154341995716095
step: 110, loss: 0.0059027299284935
step: 120, loss: 0.00941454991698265
step: 130, loss: 0.07576299458742142
step: 140, loss: 0.030600886791944504
step: 150, loss: 0.05484138801693916
step: 160, loss: 0.06142229959368706
step: 170, loss: 0.07834893465042114
step: 180, loss: 0.005495110526680946
step: 190, loss: 0.0445171482861042
step: 200, loss: 0.06285139173269272
step: 210, loss: 0.10357870161533356
step: 220, loss: 0.029975170269608498
step: 230, loss: 0.135871022939682
step: 240, loss: 0.03872126713395119
step: 250, loss: 0.12313532829284668
step: 260, loss: 0.10857044905424118
step: 270, loss: 0.049793343991041183
step: 280, loss: 0.07499990612268448
step: 290, loss: 0.02565821073949337
step: 300, loss: 0.07809974253177643
step: 310, loss: 0.03841114416718483
step: 320, loss: 0.1438876837491989
step: 330, loss: 0.1386043280363083
step: 340, loss: 0.03165231645107269
step: 350, loss: 0.07364428788423538
step: 360, loss: 0.028755757957696915
step: 370, loss: 0.08326978981494904
step: 380, loss: 0.13939881324768066
step: 390, loss: 0.0896555706858635
step: 400, loss: 0.041239913552999496
step: 410, loss: 0.07967671751976013
step: 420, loss: 0.06379912048578262
step: 430, loss: 0.006474526133388281
step: 440, loss: 0.0747322291135788
step: 450, loss: 0.18177267909049988
step: 460, loss: 0.08249528706073761
step: 470, loss: 0.22137820720672607
step: 480, loss: 0.10158346593379974
step: 490, loss: 0.05008368194103241
step: 500, loss: 0.1357041746377945
step: 510, loss: 0.05615651607513428
step: 520, loss: 0.017788100987672806
step: 530, loss: 0.05407760664820671
step: 540, loss: 0.03880266472697258
step: 550, loss: 0.11775345355272293
step: 560, loss: 0.02970198169350624
step: 570, loss: 0.12871971726417542
step: 580, loss: 0.01569683849811554
step: 590, loss: 0.05330696329474449
step: 600, loss: 0.038345176726579666
step: 610, loss: 0.03798310458660126
step: 620, loss: 0.03215495124459267
step: 630, loss: 0.013401411473751068
step: 640, loss: 0.050385378301143646
step: 650, loss: 0.10534119606018066
step: 660, loss: 0.0957680493593216
step: 670, loss: 0.06038828566670418
step: 680, loss: 0.041068218648433685
step: 690, loss: 0.0722472071647644
step: 700, loss: 0.08915034681558609
step: 710, loss: 0.13735800981521606
step: 720, loss: 0.2215818166732788
step: 730, loss: 0.04345841333270073
step: 740, loss: 0.13106566667556763
step: 750, loss: 0.11923135817050934
step: 760, loss: 0.059431545436382294
step: 770, loss: 0.14581315219402313
step: 780, loss: 0.05481256544589996
step: 790, loss: 0.10058125853538513
step: 800, loss: 0.13344083726406097
step: 810, loss: 0.15519896149635315
step: 820, loss: 0.06810743361711502
step: 830, loss: 0.15443116426467896
step: 840, loss: 0.04392723739147186
step: 850, loss: 0.035019129514694214
step: 860, loss: 0.05963632091879845
step: 870, loss: 0.05222555249929428
step: 880, loss: 0.11302807182073593
step: 890, loss: 0.07713689655065536
step: 900, loss: 0.10378898680210114
step: 910, loss: 0.05941692739725113
step: 920, loss: 0.08761849999427795
step: 930, loss: 0.020679449662566185
step: 940, loss: 0.1316799372434616
step: 950, loss: 0.12494734674692154
step: 960, loss: 0.19684427976608276
step: 970, loss: 0.0624348409473896
step: 980, loss: 0.06312540173530579
step: 990, loss: 0.1099848747253418
step: 1000, loss: 0.03569379076361656
step: 1010, loss: 0.15579713881015778
step: 1020, loss: 0.05462026223540306
step: 1030, loss: 0.10772597789764404
step: 1040, loss: 0.09352525323629379
step: 1050, loss: 0.1467352658510208
step: 1060, loss: 0.10616956651210785
step: 1070, loss: 0.06892962008714676
epoch 7: dev_f1=0.9310504396112911, f1=0.9289967934035731, best_f1=0.9289967934035731
step: 0, loss: 0.09337121248245239
step: 10, loss: 0.10876545310020447
step: 20, loss: 0.11909274756908417
step: 30, loss: 0.011098804883658886
step: 40, loss: 0.018462833017110825
step: 50, loss: 0.07868973165750504
step: 60, loss: 0.011982699856162071
step: 70, loss: 0.07882412523031235
step: 80, loss: 0.03768393024802208
step: 90, loss: 0.0659506767988205
step: 100, loss: 0.059303440153598785
step: 110, loss: 0.16271154582500458
step: 120, loss: 0.08164100348949432
step: 130, loss: 0.04823556914925575
step: 140, loss: 0.014286746270954609
step: 150, loss: 0.038803406059741974
step: 160, loss: 0.019131358712911606
step: 170, loss: 0.0519707016646862
step: 180, loss: 0.06072346121072769
step: 190, loss: 0.28106406331062317
step: 200, loss: 0.09714249521493912
step: 210, loss: 0.1172533854842186
step: 220, loss: 0.10461092740297318
step: 230, loss: 0.04104526340961456
step: 240, loss: 0.05924207717180252
step: 250, loss: 0.08572009205818176
step: 260, loss: 0.08065039664506912
step: 270, loss: 0.056328184902668
step: 280, loss: 0.2443924993276596
step: 290, loss: 0.0560927614569664
step: 300, loss: 0.07906173169612885
step: 310, loss: 0.0751202180981636
step: 320, loss: 0.03296928480267525
step: 330, loss: 0.0018562183249741793
step: 340, loss: 0.018023835495114326
step: 350, loss: 0.0317559540271759
step: 360, loss: 0.03673630207777023
step: 370, loss: 0.21877945959568024
step: 380, loss: 0.011091165244579315
step: 390, loss: 0.06781169027090073
step: 400, loss: 0.12025812268257141
step: 410, loss: 0.00549613730981946
step: 420, loss: 0.021148772910237312
step: 430, loss: 0.051654037088155746
step: 440, loss: 0.08140695840120316
step: 450, loss: 0.04747370257973671
step: 460, loss: 0.040795546025037766
step: 470, loss: 0.005214788019657135
step: 480, loss: 0.09074438363313675
step: 490, loss: 0.0626855194568634
step: 500, loss: 0.15746746957302094
step: 510, loss: 0.050606273114681244
step: 520, loss: 0.2704057991504669
step: 530, loss: 0.06440110504627228
step: 540, loss: 0.1861952841281891
step: 550, loss: 0.18237026035785675
step: 560, loss: 0.0956621989607811
step: 570, loss: 0.056017760187387466
step: 580, loss: 0.05005840212106705
step: 590, loss: 0.04053112864494324
step: 600, loss: 0.15044067800045013
step: 610, loss: 0.039842117577791214
step: 620, loss: 0.0461701862514019
step: 630, loss: 0.01080904807895422
step: 640, loss: 0.06724473088979721
step: 650, loss: 0.029270244762301445
step: 660, loss: 0.06134051829576492
step: 670, loss: 0.1547984629869461
step: 680, loss: 0.15542373061180115
step: 690, loss: 0.08071132749319077
step: 700, loss: 0.01679755374789238
step: 710, loss: 0.07389431446790695
step: 720, loss: 0.022577159106731415
step: 730, loss: 0.08264998346567154
step: 740, loss: 0.038316208869218826
step: 750, loss: 0.17094114422798157
step: 760, loss: 0.013178979977965355
step: 770, loss: 0.10568805038928986
step: 780, loss: 0.08778956532478333
step: 790, loss: 0.13658466935157776
step: 800, loss: 0.04461649805307388
step: 810, loss: 0.1434290111064911
step: 820, loss: 0.1825381964445114
step: 830, loss: 0.13416853547096252
step: 840, loss: 0.030799545347690582
step: 850, loss: 0.0640501081943512
step: 860, loss: 0.07562398165464401
step: 870, loss: 0.10336378216743469
step: 880, loss: 0.12274739146232605
step: 890, loss: 0.060756538063287735
step: 900, loss: 0.06978044658899307
step: 910, loss: 0.1650570183992386
step: 920, loss: 0.07782528549432755
step: 930, loss: 0.05691936984658241
step: 940, loss: 0.023164942860603333
step: 950, loss: 0.07573161274194717
step: 960, loss: 0.10750356316566467
step: 970, loss: 0.1509295552968979
step: 980, loss: 0.06509368866682053
step: 990, loss: 0.10207078605890274
step: 1000, loss: 0.08346264809370041
step: 1010, loss: 0.06440303474664688
step: 1020, loss: 0.10680562257766724
step: 1030, loss: 0.077519990503788
step: 1040, loss: 0.11818297207355499
step: 1050, loss: 0.02259160205721855
step: 1060, loss: 0.052243493497371674
step: 1070, loss: 0.15374933183193207
epoch 8: dev_f1=0.9310187300137049, f1=0.9259770114942528, best_f1=0.9289967934035731
step: 0, loss: 0.10461080819368362
step: 10, loss: 0.031022023409605026
step: 20, loss: 0.09298503398895264
step: 30, loss: 0.07249601185321808
step: 40, loss: 0.043784648180007935
step: 50, loss: 0.03940446674823761
step: 60, loss: 0.10935714840888977
step: 70, loss: 0.14627675712108612
step: 80, loss: 0.03324883058667183
step: 90, loss: 0.10498473048210144
step: 100, loss: 0.07974807173013687
step: 110, loss: 0.020359380170702934
step: 120, loss: 0.04206818342208862
step: 130, loss: 0.014177109114825726
step: 140, loss: 0.04111562669277191
step: 150, loss: 0.12078189104795456
step: 160, loss: 0.001695009646937251
step: 170, loss: 0.028361495584249496
step: 180, loss: 0.10928904265165329
step: 190, loss: 0.13383811712265015
step: 200, loss: 0.1299796849489212
step: 210, loss: 0.09506001323461533
step: 220, loss: 0.07680391520261765
step: 230, loss: 0.17030106484889984
step: 240, loss: 0.07114163041114807
step: 250, loss: 0.08406680822372437
step: 260, loss: 0.058361660689115524
step: 270, loss: 0.023464346304535866
step: 280, loss: 0.00586635572835803
step: 290, loss: 0.13041681051254272
step: 300, loss: 0.07682853937149048
step: 310, loss: 0.0018170299008488655
step: 320, loss: 0.09155571460723877
step: 330, loss: 0.17826592922210693
step: 340, loss: 0.07355287671089172
step: 350, loss: 0.04292946681380272
step: 360, loss: 0.12323667109012604
step: 370, loss: 0.06786118447780609
step: 380, loss: 0.11286759376525879
step: 390, loss: 0.09536746889352798
step: 400, loss: 0.08993969857692719
step: 410, loss: 0.14912354946136475
step: 420, loss: 0.07542667537927628
step: 430, loss: 0.054182019084692
step: 440, loss: 0.19298771023750305
step: 450, loss: 0.06527329981327057
step: 460, loss: 0.06206734851002693
step: 470, loss: 0.07166682928800583
step: 480, loss: 0.15165384113788605
step: 490, loss: 0.08404751867055893
step: 500, loss: 0.042112693190574646
step: 510, loss: 0.09298733621835709
step: 520, loss: 0.05517539009451866
step: 530, loss: 0.04407603293657303
step: 540, loss: 0.07914809882640839
step: 550, loss: 0.08037789911031723
step: 560, loss: 0.041659165173769
step: 570, loss: 0.052991967648267746
step: 580, loss: 0.0782361701130867
step: 590, loss: 0.058479294180870056
step: 600, loss: 0.1470651477575302
step: 610, loss: 0.07845431566238403
step: 620, loss: 0.12247791141271591
step: 630, loss: 0.13715478777885437
step: 640, loss: 0.0881505161523819
step: 650, loss: 0.0739520788192749
step: 660, loss: 0.14317823946475983
step: 670, loss: 0.18359984457492828
step: 680, loss: 0.06089940667152405
step: 690, loss: 0.14264540374279022
step: 700, loss: 0.057268157601356506
step: 710, loss: 0.1047777608036995
step: 720, loss: 0.03249999135732651
step: 730, loss: 0.131785050034523
step: 740, loss: 0.04874280467629433
step: 750, loss: 0.0792732834815979
step: 760, loss: 0.04934488981962204
step: 770, loss: 0.07104538381099701
step: 780, loss: 0.1947813481092453
step: 790, loss: 0.09342782199382782
step: 800, loss: 0.0363769493997097
step: 810, loss: 0.013527910225093365
step: 820, loss: 0.10119910538196564
step: 830, loss: 0.11968117952346802
step: 840, loss: 0.10945353657007217
step: 850, loss: 0.08215606212615967
step: 860, loss: 0.07284250855445862
step: 870, loss: 0.03406554460525513
step: 880, loss: 0.11421544849872589
step: 890, loss: 0.06285116076469421
step: 900, loss: 0.03519958630204201
step: 910, loss: 0.06023196876049042
step: 920, loss: 0.03797934204339981
step: 930, loss: 0.051422469317913055
step: 940, loss: 0.16333410143852234
step: 950, loss: 0.10908651351928711
step: 960, loss: 0.03391452506184578
step: 970, loss: 0.05938272550702095
step: 980, loss: 0.159525528550148
step: 990, loss: 0.0838703140616417
step: 1000, loss: 0.1758958101272583
step: 1010, loss: 0.047964539378881454
step: 1020, loss: 0.08961191773414612
step: 1030, loss: 0.09181620180606842
step: 1040, loss: 0.12178684026002884
step: 1050, loss: 0.07972744107246399
step: 1060, loss: 0.09037429094314575
step: 1070, loss: 0.02612335979938507
epoch 9: dev_f1=0.9240037071362373, f1=0.9213587715216379, best_f1=0.9289967934035731
step: 0, loss: 0.0002628234797157347
step: 10, loss: 0.059616100043058395
step: 20, loss: 0.07652372866868973
step: 30, loss: 0.08322463929653168
step: 40, loss: 0.04750068858265877
step: 50, loss: 0.014976120553910732
step: 60, loss: 0.04465958848595619
step: 70, loss: 0.0732690617442131
step: 80, loss: 0.07541927695274353
step: 90, loss: 0.016683422029018402
step: 100, loss: 0.04066236689686775
step: 110, loss: 0.04054822772741318
step: 120, loss: 0.0817301794886589
step: 130, loss: 0.11591289192438126
step: 140, loss: 0.04833405092358589
step: 150, loss: 0.1282888650894165
step: 160, loss: 0.009684005752205849
step: 170, loss: 0.006821829359978437
step: 180, loss: 0.07870310544967651
step: 190, loss: 0.09167533367872238
step: 200, loss: 0.07689056545495987
step: 210, loss: 0.1562609225511551
step: 220, loss: 0.06349210441112518
step: 230, loss: 0.09583541005849838
step: 240, loss: 0.04341167211532593
step: 250, loss: 0.026621093973517418
step: 260, loss: 0.07766111940145493
step: 270, loss: 0.13413813710212708
step: 280, loss: 0.08922218531370163
step: 290, loss: 0.06605322659015656
step: 300, loss: 0.12007582932710648
step: 310, loss: 0.049197014421224594
step: 320, loss: 0.03680778294801712
step: 330, loss: 0.07793891429901123
step: 340, loss: 0.1792917102575302
step: 350, loss: 0.0721210390329361
step: 360, loss: 0.07810903340578079
step: 370, loss: 0.06978366523981094
step: 380, loss: 0.08795209228992462
step: 390, loss: 0.03262690082192421
step: 400, loss: 0.17279021441936493
step: 410, loss: 0.008728777058422565
step: 420, loss: 0.03647179156541824
step: 430, loss: 0.015357567928731441
step: 440, loss: 0.04810681939125061
step: 450, loss: 0.09581958502531052
step: 460, loss: 0.029456457123160362
step: 470, loss: 0.0997902899980545
step: 480, loss: 0.09468930214643478
step: 490, loss: 0.03803277015686035
step: 500, loss: 0.11904796212911606
step: 510, loss: 0.07254642248153687
step: 520, loss: 0.1900060474872589
step: 530, loss: 0.030410900712013245
step: 540, loss: 0.008128738962113857
step: 550, loss: 0.013206134550273418
step: 560, loss: 0.043261393904685974
step: 570, loss: 0.04395230486989021
step: 580, loss: 4.879606422036886e-05
step: 590, loss: 0.14597421884536743
step: 600, loss: 0.03127724304795265
step: 610, loss: 0.10009488463401794
step: 620, loss: 0.13679145276546478
step: 630, loss: 0.09105996787548065
step: 640, loss: 0.03568316996097565
step: 650, loss: 0.06632448732852936
step: 660, loss: 0.03070354089140892
step: 670, loss: 0.17098750174045563
step: 680, loss: 0.03419988974928856
step: 690, loss: 0.05579625815153122
step: 700, loss: 0.11300168931484222
step: 710, loss: 0.055310267955064774
step: 720, loss: 0.07028596103191376
step: 730, loss: 0.07953064143657684
step: 740, loss: 0.09768011420965195
step: 750, loss: 0.14721837639808655
step: 760, loss: 0.08521828055381775
step: 770, loss: 0.005318423267453909
step: 780, loss: 0.019343044608831406
step: 790, loss: 0.07276080548763275
step: 800, loss: 0.15832941234111786
step: 810, loss: 0.03659798949956894
step: 820, loss: 0.07334498316049576
step: 830, loss: 0.06682713329792023
step: 840, loss: 0.04119236022233963
step: 850, loss: 0.11683288216590881
step: 860, loss: 0.11615122109651566
step: 870, loss: 0.03258613869547844
step: 880, loss: 0.06440173089504242
step: 890, loss: 0.15291939675807953
step: 900, loss: 0.07272040098905563
step: 910, loss: 0.15486203134059906
step: 920, loss: 0.0018573550041764975
step: 930, loss: 0.050807103514671326
step: 940, loss: 0.10963025689125061
step: 950, loss: 0.07111063599586487
step: 960, loss: 0.18032264709472656
step: 970, loss: 0.07652804255485535
step: 980, loss: 0.18582852184772491
step: 990, loss: 0.0683574452996254
step: 1000, loss: 0.10557441413402557
step: 1010, loss: 0.11312641203403473
step: 1020, loss: 0.07175957411527634
step: 1030, loss: 0.0775347352027893
step: 1040, loss: 0.06128579378128052
step: 1050, loss: 0.08692476153373718
step: 1060, loss: 0.0837150439620018
step: 1070, loss: 0.1372097134590149
epoch 10: dev_f1=0.9348230912476723, f1=0.9255966307908282, best_f1=0.9255966307908282
step: 0, loss: 0.03439272940158844
step: 10, loss: 0.05788062512874603
step: 20, loss: 0.08360700309276581
step: 30, loss: 0.03244854509830475
step: 40, loss: 0.1013028621673584
step: 50, loss: 0.1290501058101654
step: 60, loss: 0.010128039866685867
step: 70, loss: 0.011113720014691353
step: 80, loss: 0.02084028348326683
step: 90, loss: 0.15726523101329803
step: 100, loss: 0.02667926996946335
step: 110, loss: 0.1087939590215683
step: 120, loss: 0.11378702521324158
step: 130, loss: 0.054563991725444794
step: 140, loss: 0.10551932454109192
step: 150, loss: 0.034756358712911606
step: 160, loss: 0.008709392510354519
step: 170, loss: 0.021500984206795692
step: 180, loss: 0.07298024743795395
step: 190, loss: 0.05291053652763367
step: 200, loss: 0.036863844841718674
step: 210, loss: 0.025521904230117798
step: 220, loss: 0.0640583485364914
step: 230, loss: 0.03282516822218895
step: 240, loss: 0.127634659409523
step: 250, loss: 0.051267269998788834
step: 260, loss: 0.1009698137640953
step: 270, loss: 0.061055541038513184
step: 280, loss: 0.11798372864723206
step: 290, loss: 0.03199005126953125
step: 300, loss: 0.1166764423251152
step: 310, loss: 0.029635578393936157
step: 320, loss: 0.17419902980327606
step: 330, loss: 0.06513656675815582
step: 340, loss: 0.10307059437036514
step: 350, loss: 0.09141568094491959
step: 360, loss: 0.031904272735118866
step: 370, loss: 0.06030569225549698
step: 380, loss: 0.1007574200630188
step: 390, loss: 0.012495053000748158
step: 400, loss: 0.13893379271030426
step: 410, loss: 0.03787538781762123
step: 420, loss: 0.12396217882633209
step: 430, loss: 0.005669327452778816
step: 440, loss: 0.08621355891227722
step: 450, loss: 0.06333207339048386
step: 460, loss: 0.0412893109023571
step: 470, loss: 0.11513102054595947
step: 480, loss: 0.04342717304825783
step: 490, loss: 0.03419986367225647
step: 500, loss: 0.11280379444360733
step: 510, loss: 0.08243723213672638
step: 520, loss: 0.05563830956816673
step: 530, loss: 0.20268864929676056
step: 540, loss: 0.06251425296068192
step: 550, loss: 0.0031866596546024084
step: 560, loss: 0.11892225593328476
step: 570, loss: 0.18281292915344238
step: 580, loss: 0.19346506893634796
step: 590, loss: 0.10275908559560776
step: 600, loss: 0.06920918077230453
step: 610, loss: 0.013454128988087177
step: 620, loss: 0.11120033264160156
step: 630, loss: 0.06889093667268753
step: 640, loss: 0.14180094003677368
step: 650, loss: 0.002216752851381898
step: 660, loss: 0.09333005547523499
step: 670, loss: 0.2583177089691162
step: 680, loss: 0.11786589026451111
step: 690, loss: 0.023171525448560715
step: 700, loss: 0.15776079893112183
step: 710, loss: 0.07198025286197662
step: 720, loss: 0.0232418030500412
step: 730, loss: 0.036709126085042953
step: 740, loss: 0.07356920838356018
step: 750, loss: 0.0831684097647667
step: 760, loss: 0.061773378401994705
step: 770, loss: 0.09418726712465286
step: 780, loss: 0.11248792707920074
step: 790, loss: 0.04546118155121803
step: 800, loss: 0.0476558655500412
step: 810, loss: 0.08762125670909882
step: 820, loss: 0.002270214958116412
step: 830, loss: 0.08628129959106445
step: 840, loss: 0.17818552255630493
step: 850, loss: 0.0583321787416935
step: 860, loss: 0.11144489794969559
step: 870, loss: 0.024418845772743225
step: 880, loss: 0.029842328280210495
step: 890, loss: 0.02304152399301529
step: 900, loss: 0.0760687068104744
step: 910, loss: 0.07914882898330688
step: 920, loss: 0.06908795237541199
step: 930, loss: 0.019327443093061447
step: 940, loss: 0.0813402310013771
step: 950, loss: 0.016230465844273567
step: 960, loss: 0.11092624813318253
step: 970, loss: 0.16846135258674622
step: 980, loss: 0.0553307943046093
step: 990, loss: 0.03914576768875122
step: 1000, loss: 0.034894611686468124
step: 1010, loss: 0.06557978689670563
step: 1020, loss: 0.03191627189517021
step: 1030, loss: 0.041467729955911636
step: 1040, loss: 0.14296892285346985
step: 1050, loss: 0.18219344317913055
step: 1060, loss: 0.027223218232393265
step: 1070, loss: 0.06551683694124222
epoch 11: dev_f1=0.9301895515487749, f1=0.9234338747099768, best_f1=0.9255966307908282
step: 0, loss: 0.03360264003276825
step: 10, loss: 0.07386492937803268
step: 20, loss: 0.02324816770851612
step: 30, loss: 0.08013749122619629
step: 40, loss: 2.3981936465133913e-05
step: 50, loss: 0.02263454906642437
step: 60, loss: 0.016464106738567352
step: 70, loss: 0.028922127559781075
step: 80, loss: 0.1362927109003067
step: 90, loss: 0.09385504573583603
step: 100, loss: 0.03741973266005516
step: 110, loss: 0.011712005361914635
step: 120, loss: 0.15230342745780945
step: 130, loss: 0.030252480879426003
step: 140, loss: 0.00681006396189332
step: 150, loss: 0.13176874816417694
step: 160, loss: 0.029515231028199196
step: 170, loss: 0.012968161143362522
step: 180, loss: 0.031206246465444565
step: 190, loss: 0.05413668975234032
step: 200, loss: 0.04861213639378548
step: 210, loss: 0.016458187252283096
step: 220, loss: 0.06612271070480347
step: 230, loss: 0.05878400057554245
step: 240, loss: 0.047299839556217194
step: 250, loss: 0.053147412836551666
step: 260, loss: 0.05167628824710846
step: 270, loss: 0.07700685411691666
step: 280, loss: 0.13693955540657043
step: 290, loss: 0.05613870918750763
step: 300, loss: 0.06826632469892502
step: 310, loss: 0.001667021424509585
step: 320, loss: 0.024726569652557373
step: 330, loss: 0.05547131225466728
step: 340, loss: 0.09614907950162888
step: 350, loss: 0.3334132432937622
step: 360, loss: 0.02782803401350975
step: 370, loss: 0.059438928961753845
step: 380, loss: 0.1500835418701172
step: 390, loss: 0.02135956846177578
step: 400, loss: 0.09377290308475494
step: 410, loss: 0.030644498765468597
step: 420, loss: 0.05728023499250412
step: 430, loss: 0.10953658819198608
step: 440, loss: 0.04118683189153671
step: 450, loss: 0.0012264688266441226
step: 460, loss: 0.0362844243645668
step: 470, loss: 0.1150713562965393
step: 480, loss: 0.06699538975954056
step: 490, loss: 0.08200602978467941
step: 500, loss: 0.03068658895790577
step: 510, loss: 0.13894638419151306
step: 520, loss: 0.08237387239933014
step: 530, loss: 0.1503719687461853
step: 540, loss: 0.03443484753370285
step: 550, loss: 0.03578612208366394
step: 560, loss: 0.07959707081317902
step: 570, loss: 0.1477939933538437
step: 580, loss: 0.06189288571476936
step: 590, loss: 0.046617355197668076
step: 600, loss: 0.1655954122543335
step: 610, loss: 0.09642582386732101
step: 620, loss: 0.04522539675235748
step: 630, loss: 0.08035890012979507
step: 640, loss: 0.016992880031466484
step: 650, loss: 0.07925838232040405
step: 660, loss: 0.10917669534683228
step: 670, loss: 0.05171759054064751
step: 680, loss: 0.12546704709529877
step: 690, loss: 0.03498043864965439
step: 700, loss: 0.09247991442680359
step: 710, loss: 0.08976610749959946
step: 720, loss: 0.08932159841060638
step: 730, loss: 0.09278562664985657
step: 740, loss: 0.04392561316490173
step: 750, loss: 0.13138116896152496
step: 760, loss: 0.0337914377450943
step: 770, loss: 0.06389832496643066
step: 780, loss: 0.09253134578466415
step: 790, loss: 0.015734782442450523
step: 800, loss: 0.07682918012142181
step: 810, loss: 0.03706667199730873
step: 820, loss: 0.3041797876358032
step: 830, loss: 0.043834008276462555
step: 840, loss: 0.08211827278137207
step: 850, loss: 0.07938691973686218
step: 860, loss: 0.08148183673620224
step: 870, loss: 0.058837853372097015
step: 880, loss: 0.020818235352635384
step: 890, loss: 0.07946181297302246
step: 900, loss: 0.06877593696117401
step: 910, loss: 0.05941661074757576
step: 920, loss: 0.028382062911987305
step: 930, loss: 0.05994356423616409
step: 940, loss: 0.028161732479929924
step: 950, loss: 0.020150160416960716
step: 960, loss: 0.1591896414756775
step: 970, loss: 0.06063779816031456
step: 980, loss: 0.0877869725227356
step: 990, loss: 0.10144126415252686
step: 1000, loss: 0.03435887396335602
step: 1010, loss: 0.11225575953722
step: 1020, loss: 0.08273784071207047
step: 1030, loss: 0.03294019773602486
step: 1040, loss: 0.14657951891422272
step: 1050, loss: 0.11683603376150131
step: 1060, loss: 0.07296334952116013
step: 1070, loss: 0.07214539498090744
epoch 12: dev_f1=0.9327188940092166, f1=0.9234317343173433, best_f1=0.9255966307908282
step: 0, loss: 0.04648945853114128
step: 10, loss: 0.0668860524892807
step: 20, loss: 0.034251030534505844
step: 30, loss: 0.05214696750044823
step: 40, loss: 0.040565211325883865
step: 50, loss: 0.035343535244464874
step: 60, loss: 0.04931548237800598
step: 70, loss: 0.05297940969467163
step: 80, loss: 0.08356914669275284
step: 90, loss: 0.11375441402196884
step: 100, loss: 0.0676453709602356
step: 110, loss: 0.1118137538433075
step: 120, loss: 0.012874295935034752
step: 130, loss: 0.08991322666406631
step: 140, loss: 0.01118207536637783
step: 150, loss: 0.0407893992960453
step: 160, loss: 0.06849005073308945
step: 170, loss: 0.06939499080181122
step: 180, loss: 0.027603834867477417
step: 190, loss: 0.09897410124540329
step: 200, loss: 0.07096927613019943
step: 210, loss: 0.021436329931020737
step: 220, loss: 0.06178588792681694
step: 230, loss: 0.06070033460855484
step: 240, loss: 0.11762368679046631
step: 250, loss: 0.03169209510087967
step: 260, loss: 0.0007091097068041563
step: 270, loss: 0.08156076818704605
step: 280, loss: 0.008768806234002113
step: 290, loss: 0.02543773502111435
step: 300, loss: 0.026164531707763672
step: 310, loss: 0.02895728498697281
step: 320, loss: 0.06532224267721176
step: 330, loss: 0.03529905900359154
step: 340, loss: 0.007601151242852211
step: 350, loss: 0.019588492810726166
step: 360, loss: 0.03440069779753685
step: 370, loss: 0.10387000441551208
step: 380, loss: 0.10334613174200058
step: 390, loss: 0.034143079072237015
step: 400, loss: 0.010139676742255688
step: 410, loss: 0.029224315658211708
step: 420, loss: 0.015534193255007267
step: 430, loss: 0.04038058966398239
step: 440, loss: 0.07063296437263489
step: 450, loss: 0.0724564865231514
step: 460, loss: 0.0016525988467037678
step: 470, loss: 0.02525695040822029
step: 480, loss: 0.07084957510232925
step: 490, loss: 0.04492848366498947
step: 500, loss: 0.16865704953670502
step: 510, loss: 0.0768570825457573
step: 520, loss: 0.005166399758309126
step: 530, loss: 0.05643978342413902
step: 540, loss: 0.025529609993100166
step: 550, loss: 0.04325936734676361
step: 560, loss: 0.08145112544298172
step: 570, loss: 0.044631458818912506
step: 580, loss: 0.03995156288146973
step: 590, loss: 0.0612034872174263
step: 600, loss: 0.06363131105899811
step: 610, loss: 0.00017593550728634
step: 620, loss: 0.06642015278339386
step: 630, loss: 0.12898997962474823
step: 640, loss: 0.10423724353313446
step: 650, loss: 0.04999811202287674
step: 660, loss: 0.046964433044195175
step: 670, loss: 0.03060298040509224
step: 680, loss: 0.02184312976896763
step: 690, loss: 0.020035430788993835
step: 700, loss: 0.1176917776465416
step: 710, loss: 0.07674171775579453
step: 720, loss: 0.09664900600910187
step: 730, loss: 0.05609823763370514
step: 740, loss: 0.0770302563905716
step: 750, loss: 0.1343357414007187
step: 760, loss: 0.008610354736447334
step: 770, loss: 0.07138017565011978
step: 780, loss: 0.06744078546762466
step: 790, loss: 0.0401952788233757
step: 800, loss: 0.02668505162000656
step: 810, loss: 0.00740102818235755
step: 820, loss: 0.0005907074082642794
step: 830, loss: 0.07612554728984833
step: 840, loss: 0.022361086681485176
step: 850, loss: 0.051405686885118484
step: 860, loss: 0.0001889790000859648
step: 870, loss: 0.05440438538789749
step: 880, loss: 0.03708191588521004
step: 890, loss: 0.04345524311065674
step: 900, loss: 0.08096359670162201
step: 910, loss: 0.06979751586914062
step: 920, loss: 0.07081721723079681
step: 930, loss: 0.033394958823919296
step: 940, loss: 0.11297553777694702
step: 950, loss: 0.08183235675096512
step: 960, loss: 0.0011715375585481524
step: 970, loss: 0.11396006494760513
step: 980, loss: 0.09667494148015976
step: 990, loss: 0.020365053787827492
step: 1000, loss: 0.08150435239076614
step: 1010, loss: 0.020822949707508087
step: 1020, loss: 0.03640163317322731
step: 1030, loss: 0.036629583686590195
step: 1040, loss: 0.03050188347697258
step: 1050, loss: 0.06902807950973511
step: 1060, loss: 0.012085412628948689
step: 1070, loss: 0.0203279759734869
epoch 13: dev_f1=0.9283054003724395, f1=0.9257356375525455, best_f1=0.9255966307908282
step: 0, loss: 0.08987513929605484
step: 10, loss: 0.07219474017620087
step: 20, loss: 0.06568209081888199
step: 30, loss: 0.18964950740337372
step: 40, loss: 0.030868979170918465
step: 50, loss: 0.028100570663809776
step: 60, loss: 0.004142383579164743
step: 70, loss: 0.045677002519369125
step: 80, loss: 0.030868278816342354
step: 90, loss: 0.03920653089880943
step: 100, loss: 0.06617355346679688
step: 110, loss: 0.0912974402308464
step: 120, loss: 0.025315603241324425
step: 130, loss: 0.062459416687488556
step: 140, loss: 0.03212936222553253
step: 150, loss: 0.042144279927015305
step: 160, loss: 0.06275235116481781
step: 170, loss: 0.1493900567293167
step: 180, loss: 0.034112490713596344
step: 190, loss: 0.07405149936676025
step: 200, loss: 0.04560930281877518
step: 210, loss: 0.03786863759160042
step: 220, loss: 0.07605063915252686
step: 230, loss: 0.08038655668497086
step: 240, loss: 0.07749699801206589
step: 250, loss: 0.12172600626945496
step: 260, loss: 0.05336518958210945
step: 270, loss: 0.04682689160108566
step: 280, loss: 0.021648438647389412
step: 290, loss: 8.144487219396979e-05
step: 300, loss: 0.06080041453242302
step: 310, loss: 0.0003928491205442697
step: 320, loss: 0.015978660434484482
step: 330, loss: 0.03637439012527466
step: 340, loss: 0.02737153321504593
step: 350, loss: 0.03554501384496689
step: 360, loss: 0.1853266805410385
step: 370, loss: 0.09300374239683151
step: 380, loss: 0.08652292937040329
step: 390, loss: 0.04237378388643265
step: 400, loss: 0.01763877086341381
step: 410, loss: 0.06295406818389893
step: 420, loss: 0.03739700838923454
step: 430, loss: 0.033417344093322754
step: 440, loss: 0.04729042574763298
step: 450, loss: 0.028718410059809685
step: 460, loss: 0.05624231696128845
step: 470, loss: 0.02466009184718132
step: 480, loss: 0.05185465142130852
step: 490, loss: 0.053579315543174744
step: 500, loss: 0.06113230437040329
step: 510, loss: 0.07878883183002472
step: 520, loss: 0.09809821844100952
step: 530, loss: 0.05112024024128914
step: 540, loss: 0.08935892581939697
step: 550, loss: 0.06065703183412552
step: 560, loss: 0.022344207391142845
step: 570, loss: 0.026700038462877274
step: 580, loss: 0.1627577543258667
step: 590, loss: 0.0437924787402153
step: 600, loss: 9.122624032897875e-05
step: 610, loss: 0.06758233159780502
step: 620, loss: 0.04269169270992279
step: 630, loss: 0.032223090529441833
step: 640, loss: 0.04867906495928764
step: 650, loss: 0.0005731787532567978
step: 660, loss: 0.019531339406967163
step: 670, loss: 0.15118300914764404
step: 680, loss: 0.0670584887266159
step: 690, loss: 0.04147471487522125
step: 700, loss: 0.06013184040784836
step: 710, loss: 0.023269619792699814
step: 720, loss: 0.058317769318819046
step: 730, loss: 0.027914633974432945
step: 740, loss: 0.05399587005376816
step: 750, loss: 0.0525185726583004
step: 760, loss: 0.10970877856016159
step: 770, loss: 0.0865839421749115
step: 780, loss: 0.009159574285149574
step: 790, loss: 0.07709041982889175
step: 800, loss: 0.09857627749443054
step: 810, loss: 0.025424186140298843
step: 820, loss: 0.0864143893122673
step: 830, loss: 0.11631175130605698
step: 840, loss: 0.029575740918517113
step: 850, loss: 0.036369387060403824
step: 860, loss: 0.0276326984167099
step: 870, loss: 0.07573259621858597
step: 880, loss: 0.032370999455451965
step: 890, loss: 0.05061306059360504
step: 900, loss: 0.07851672917604446
step: 910, loss: 0.26490792632102966
step: 920, loss: 0.12404125183820724
step: 930, loss: 0.00018012554210145026
step: 940, loss: 0.07547494769096375
step: 950, loss: 0.005173633806407452
step: 960, loss: 0.06733963638544083
step: 970, loss: 0.04697351157665253
step: 980, loss: 0.1729002296924591
step: 990, loss: 0.0009000567952170968
step: 1000, loss: 0.014428455382585526
step: 1010, loss: 0.0358671136200428
step: 1020, loss: 0.09052491188049316
step: 1030, loss: 0.027304325252771378
step: 1040, loss: 0.0652356669306755
step: 1050, loss: 0.020787183195352554
step: 1060, loss: 0.06244268640875816
step: 1070, loss: 0.06182533875107765
epoch 14: dev_f1=0.9245107176141659, f1=0.9207089552238805, best_f1=0.9255966307908282
step: 0, loss: 0.05071452260017395
step: 10, loss: 0.0668015405535698
step: 20, loss: 0.009138660505414009
step: 30, loss: 0.031507495790719986
step: 40, loss: 0.020096004009246826
step: 50, loss: 0.06507150828838348
step: 60, loss: 0.1003289669752121
step: 70, loss: 0.061708562076091766
step: 80, loss: 0.0518830232322216
step: 90, loss: 0.05384477600455284
step: 100, loss: 0.04413829743862152
step: 110, loss: 0.30192211270332336
step: 120, loss: 0.021738747134804726
step: 130, loss: 0.027338499203324318
step: 140, loss: 0.04085442051291466
step: 150, loss: 0.004267141222953796
step: 160, loss: 8.53423189255409e-05
step: 170, loss: 0.035287532955408096
step: 180, loss: 0.04422879219055176
step: 190, loss: 0.005725396331399679
step: 200, loss: 0.18547190725803375
step: 210, loss: 0.04422585666179657
step: 220, loss: 0.05144692584872246
step: 230, loss: 0.027924809604883194
step: 240, loss: 0.0845593735575676
step: 250, loss: 0.0003795041993726045
step: 260, loss: 0.05100679025053978
step: 270, loss: 0.0002382004604442045
step: 280, loss: 0.08001754432916641
step: 290, loss: 0.018488621339201927
step: 300, loss: 0.09996674954891205
step: 310, loss: 0.13413916528224945
step: 320, loss: 0.05216319113969803
step: 330, loss: 0.08872023224830627
step: 340, loss: 0.11687389016151428
step: 350, loss: 0.07038890570402145
step: 360, loss: 0.03722473606467247
step: 370, loss: 0.06876478344202042
step: 380, loss: 0.027657613158226013
step: 390, loss: 0.027504531666636467
step: 400, loss: 0.05992354825139046
step: 410, loss: 0.050685133785009384
step: 420, loss: 0.02792239561676979
step: 430, loss: 0.025408126413822174
step: 440, loss: 0.07021801918745041
step: 450, loss: 0.040028464049100876
step: 460, loss: 0.045329414308071136
step: 470, loss: 0.09438535571098328
step: 480, loss: 0.04745399206876755
step: 490, loss: 0.10214217752218246
step: 500, loss: 0.1566169112920761
step: 510, loss: 0.006610326003283262
step: 520, loss: 0.04644494503736496
step: 530, loss: 0.01850728504359722
step: 540, loss: 0.039900317788124084
step: 550, loss: 0.005294395610690117
step: 560, loss: 0.06512756645679474
step: 570, loss: 0.08186877518892288
step: 580, loss: 0.0982133001089096
step: 590, loss: 0.014320842921733856
step: 600, loss: 0.03288375958800316
step: 610, loss: 0.02359119988977909
step: 620, loss: 0.044885095208883286
step: 630, loss: 0.09305524826049805
step: 640, loss: 0.03747471049427986
step: 650, loss: 0.007644646801054478
step: 660, loss: 0.07551266252994537
step: 670, loss: 0.007132370490580797
step: 680, loss: 0.04864223301410675
step: 690, loss: 0.1751531958580017
step: 700, loss: 0.030744552612304688
step: 710, loss: 0.06299783289432526
step: 720, loss: 0.012714316137135029
step: 730, loss: 0.007404435891658068
step: 740, loss: 0.036398179829120636
step: 750, loss: 0.03229828178882599
step: 760, loss: 0.12732477486133575
step: 770, loss: 0.0922667384147644
step: 780, loss: 0.08384067565202713
step: 790, loss: 0.05053463578224182
step: 800, loss: 0.08487268537282944
step: 810, loss: 0.05011196434497833
step: 820, loss: 0.00043838575948029757
step: 830, loss: 0.043798986822366714
step: 840, loss: 0.0705772191286087
step: 850, loss: 0.059939924627542496
step: 860, loss: 0.0485963299870491
step: 870, loss: 0.06414119154214859
step: 880, loss: 0.0018622870557010174
step: 890, loss: 0.02915043570101261
step: 900, loss: 0.021751604974269867
step: 910, loss: 0.08066068589687347
step: 920, loss: 0.11930661648511887
step: 930, loss: 1.8380043911747634e-05
step: 940, loss: 0.015005973167717457
step: 950, loss: 0.0156153729185462
step: 960, loss: 0.024974435567855835
step: 970, loss: 0.1230626031756401
step: 980, loss: 0.01544229220598936
step: 990, loss: 0.03246835619211197
step: 1000, loss: 0.025810467079281807
step: 1010, loss: 0.044710949063301086
step: 1020, loss: 0.06844758987426758
step: 1030, loss: 0.04550810903310776
step: 1040, loss: 0.05223339796066284
step: 1050, loss: 0.06609740853309631
step: 1060, loss: 0.06503576785326004
step: 1070, loss: 0.0009823079453781247
epoch 15: dev_f1=0.9270784951230839, f1=0.9240801117838845, best_f1=0.9255966307908282
step: 0, loss: 0.06314456462860107
step: 10, loss: 0.02235989086329937
step: 20, loss: 0.06429508328437805
step: 30, loss: 0.046498674899339676
step: 40, loss: 0.014351150020956993
step: 50, loss: 0.13745619356632233
step: 60, loss: 0.05984515696763992
step: 70, loss: 0.10074452310800552
step: 80, loss: 0.08516886830329895
step: 90, loss: 0.026211300864815712
step: 100, loss: 0.06684865057468414
step: 110, loss: 0.06699861586093903
step: 120, loss: 0.028623711317777634
step: 130, loss: 0.027949104085564613
step: 140, loss: 0.07800959795713425
step: 150, loss: 0.015045790001749992
step: 160, loss: 0.06374826282262802
step: 170, loss: 0.005145755130797625
step: 180, loss: 0.07781144231557846
step: 190, loss: 0.0434178002178669
step: 200, loss: 0.06158091500401497
step: 210, loss: 0.02330220863223076
step: 220, loss: 0.018504977226257324
step: 230, loss: 0.06868823617696762
step: 240, loss: 0.020418036729097366
step: 250, loss: 0.03856419026851654
step: 260, loss: 0.09744859486818314
step: 270, loss: 0.0035505671985447407
step: 280, loss: 0.05030272528529167
step: 290, loss: 0.05264239385724068
step: 300, loss: 0.0426374115049839
step: 310, loss: 0.04377301409840584
step: 320, loss: 0.018075641244649887
step: 330, loss: 0.06067490950226784
step: 340, loss: 0.06264226138591766
step: 350, loss: 0.07046807557344437
step: 360, loss: 0.022157002240419388
step: 370, loss: 0.057678479701280594
step: 380, loss: 0.02092435024678707
step: 390, loss: 0.02920234203338623
step: 400, loss: 0.05106273293495178
step: 410, loss: 0.019881462678313255
step: 420, loss: 0.004350029397755861
step: 430, loss: 0.017959943041205406
step: 440, loss: 0.05164759233593941
step: 450, loss: 0.04101933166384697
step: 460, loss: 0.1296239197254181
step: 470, loss: 0.13353247940540314
step: 480, loss: 0.051379166543483734
step: 490, loss: 0.06238751858472824
step: 500, loss: 0.05363527685403824
step: 510, loss: 0.006549453362822533
step: 520, loss: 0.017992224544286728
step: 530, loss: 0.06418633460998535
step: 540, loss: 0.00568151380866766
step: 550, loss: 0.05804741755127907
step: 560, loss: 0.02757021225988865
step: 570, loss: 0.008668862283229828
step: 580, loss: 0.04402545839548111
step: 590, loss: 0.08837524801492691
step: 600, loss: 0.08176767081022263
step: 610, loss: 0.0222597848623991
step: 620, loss: 0.033405501395463943
step: 630, loss: 0.04814375191926956
step: 640, loss: 0.03424486517906189
step: 650, loss: 0.008962780237197876
step: 660, loss: 0.05129963532090187
step: 670, loss: 0.0003989067627117038
step: 680, loss: 0.05981707200407982
step: 690, loss: 0.025050241500139236
step: 700, loss: 0.06612148880958557
step: 710, loss: 0.046798888593912125
step: 720, loss: 0.03669023886322975
step: 730, loss: 0.10872906446456909
step: 740, loss: 0.054843977093696594
step: 750, loss: 0.08308768272399902
step: 760, loss: 0.10323522239923477
step: 770, loss: 0.11643898487091064
step: 780, loss: 0.00021466537145897746
step: 790, loss: 0.072625532746315
step: 800, loss: 0.04306361451745033
step: 810, loss: 0.007156477775424719
step: 820, loss: 0.05147290229797363
step: 830, loss: 0.06938707828521729
step: 840, loss: 0.06061897799372673
step: 850, loss: 0.08136393129825592
step: 860, loss: 0.004626063164323568
step: 870, loss: 0.08815301209688187
step: 880, loss: 0.06910503655672073
step: 890, loss: 0.060610007494688034
step: 900, loss: 0.10879026353359222
step: 910, loss: 0.018827423453330994
step: 920, loss: 0.08222872763872147
step: 930, loss: 0.040007926523685455
step: 940, loss: 0.029131749644875526
step: 950, loss: 0.001321895164437592
step: 960, loss: 0.02272651344537735
step: 970, loss: 0.025657981634140015
step: 980, loss: 0.016010578721761703
step: 990, loss: 5.6770943047013134e-05
step: 1000, loss: 0.02548960968852043
step: 1010, loss: 0.01987648382782936
step: 1020, loss: 0.0669703409075737
step: 1030, loss: 0.04446444660425186
step: 1040, loss: 0.07036670297384262
step: 1050, loss: 0.18668687343597412
step: 1060, loss: 0.036112863570451736
step: 1070, loss: 2.1292762539815158e-05
epoch 16: dev_f1=0.9218604651162791, f1=0.9214953271028037, best_f1=0.9255966307908282
step: 0, loss: 0.058845218271017075
step: 10, loss: 0.04714059457182884
step: 20, loss: 0.02753167599439621
step: 30, loss: 0.021486667916178703
step: 40, loss: 0.032535895705223083
step: 50, loss: 0.08666588366031647
step: 60, loss: 0.03750993311405182
step: 70, loss: 0.11592049896717072
step: 80, loss: 0.04424217715859413
step: 90, loss: 0.04439619183540344
step: 100, loss: 0.03666674718260765
step: 110, loss: 0.0638379380106926
step: 120, loss: 0.07598541676998138
step: 130, loss: 0.06488169729709625
step: 140, loss: 0.06847023218870163
step: 150, loss: 0.06900004297494888
step: 160, loss: 0.0009955692803487182
step: 170, loss: 0.00028397247660905123
step: 180, loss: 0.04419548809528351
step: 190, loss: 0.06047849357128143
step: 200, loss: 0.08804052323102951
step: 210, loss: 0.015786075964570045
step: 220, loss: 0.01696278154850006
step: 230, loss: 0.0273763258010149
step: 240, loss: 0.057669494301080704
step: 250, loss: 0.015934504568576813
step: 260, loss: 0.006644663866609335
step: 270, loss: 0.028492748737335205
step: 280, loss: 0.16587381064891815
step: 290, loss: 0.038492631167173386
step: 300, loss: 0.08300074189901352
step: 310, loss: 0.07174483686685562
step: 320, loss: 0.08530601859092712
step: 330, loss: 0.0962149053812027
step: 340, loss: 0.00013784626207780093
step: 350, loss: 0.03729250654578209
step: 360, loss: 0.05839670076966286
step: 370, loss: 0.048055291175842285
step: 380, loss: 0.12544973194599152
step: 390, loss: 0.02028222195804119
step: 400, loss: 0.01101959403604269
step: 410, loss: 0.04147956520318985
step: 420, loss: 0.09052343666553497
step: 430, loss: 0.025235772132873535
step: 440, loss: 0.019258227199316025
step: 450, loss: 0.11322513222694397
step: 460, loss: 0.0007259108242578804
step: 470, loss: 0.07520328462123871
step: 480, loss: 0.03560474142432213
step: 490, loss: 0.049737364053726196
step: 500, loss: 0.06854996830224991
step: 510, loss: 0.02467923052608967
step: 520, loss: 0.24333739280700684
step: 530, loss: 0.021202057600021362
step: 540, loss: 0.003909824416041374
step: 550, loss: 0.05459613353013992
step: 560, loss: 0.02488713152706623
step: 570, loss: 0.00930160004645586
step: 580, loss: 0.015410158783197403
step: 590, loss: 0.03621181100606918
step: 600, loss: 0.00012849477934651077
step: 610, loss: 0.0004549493023660034
step: 620, loss: 0.10184620320796967
step: 630, loss: 0.02291153371334076
step: 640, loss: 0.04221790283918381
step: 650, loss: 0.08172274380922318
step: 660, loss: 0.008252689614892006
step: 670, loss: 0.0332113653421402
step: 680, loss: 0.04186355322599411
step: 690, loss: 0.04793843254446983
step: 700, loss: 0.00039578540599904954
step: 710, loss: 0.05180828273296356
step: 720, loss: 0.04929838329553604
step: 730, loss: 0.06459292769432068
step: 740, loss: 0.0425310842692852
step: 750, loss: 0.14089831709861755
step: 760, loss: 9.59496246650815e-05
step: 770, loss: 0.036469947546720505
step: 780, loss: 0.1379692405462265
step: 790, loss: 0.05043354630470276
step: 800, loss: 0.008435430005192757
step: 810, loss: 0.020877977833151817
step: 820, loss: 0.03307368606328964
step: 830, loss: 0.0779641643166542
step: 840, loss: 0.06149259954690933
step: 850, loss: 0.07903123646974564
step: 860, loss: 0.025149796158075333
step: 870, loss: 0.08699110150337219
step: 880, loss: 0.11255154758691788
step: 890, loss: 0.08985442668199539
step: 900, loss: 0.023805858567357063
step: 910, loss: 0.01756524294614792
step: 920, loss: 0.09947817027568817
step: 930, loss: 0.07914905995130539
step: 940, loss: 2.562443114584312e-05
step: 950, loss: 0.00014784728409722447
step: 960, loss: 0.06547818332910538
step: 970, loss: 0.012885130941867828
step: 980, loss: 0.07397227734327316
step: 990, loss: 0.04110213369131088
step: 1000, loss: 0.0884869247674942
step: 1010, loss: 0.023959804326295853
step: 1020, loss: 0.04325861483812332
step: 1030, loss: 0.07326081395149231
step: 1040, loss: 0.050390664488077164
step: 1050, loss: 0.028069062158465385
step: 1060, loss: 0.08394163846969604
step: 1070, loss: 0.04467308148741722
epoch 17: dev_f1=0.9219330855018587, f1=0.9176361098185202, best_f1=0.9255966307908282
step: 0, loss: 0.0429769866168499
step: 10, loss: 0.05112901329994202
step: 20, loss: 0.0458117239177227
step: 30, loss: 0.08336088806390762
step: 40, loss: 0.03531758859753609
step: 50, loss: 0.0641896203160286
step: 60, loss: 0.039509695023298264
step: 70, loss: 0.04478286951780319
step: 80, loss: 0.00010854791617020965
step: 90, loss: 0.05147646740078926
step: 100, loss: 0.11125589162111282
step: 110, loss: 0.005316881462931633
step: 120, loss: 0.0746166780591011
step: 130, loss: 0.0533718466758728
step: 140, loss: 0.06200149282813072
step: 150, loss: 0.02019001916050911
step: 160, loss: 0.011970380321145058
step: 170, loss: 0.03686896711587906
step: 180, loss: 0.03139742463827133
step: 190, loss: 0.031515758484601974
step: 200, loss: 0.07465310394763947
step: 210, loss: 0.015274775214493275
step: 220, loss: 0.10130327939987183
step: 230, loss: 0.1333051472902298
step: 240, loss: 0.05383039638400078
step: 250, loss: 0.07544825971126556
step: 260, loss: 0.04991209879517555
step: 270, loss: 2.359476093261037e-05
step: 280, loss: 0.0026898649521172047
step: 290, loss: 0.1361776739358902
step: 300, loss: 0.0002242454793304205
step: 310, loss: 0.04097098484635353
step: 320, loss: 0.04707667976617813
step: 330, loss: 0.07427883893251419
step: 340, loss: 0.03584390878677368
step: 350, loss: 0.09933129698038101
step: 360, loss: 0.02393215149641037
step: 370, loss: 0.0657452940940857
step: 380, loss: 7.933311280794442e-05
step: 390, loss: 0.02481617033481598
step: 400, loss: 0.04522838070988655
step: 410, loss: 0.08103933185338974
step: 420, loss: 0.030404863879084587
step: 430, loss: 4.0891743992688134e-05
step: 440, loss: 0.0138355428352952
step: 450, loss: 0.00035074795596301556
step: 460, loss: 0.05052761361002922
step: 470, loss: 0.0003063808544538915
step: 480, loss: 0.01425829716026783
step: 490, loss: 0.029006637632846832
step: 500, loss: 0.06319797784090042
step: 510, loss: 0.008572247810661793
step: 520, loss: 0.08229806274175644
step: 530, loss: 0.034157101064920425
step: 540, loss: 2.252217564091552e-05
step: 550, loss: 0.0817020907998085
step: 560, loss: 0.06378963589668274
step: 570, loss: 0.16258607804775238
step: 580, loss: 0.05106408894062042
step: 590, loss: 0.025882303714752197
step: 600, loss: 0.08117800951004028
step: 610, loss: 6.55609110253863e-05
step: 620, loss: 0.033747583627700806
step: 630, loss: 0.006407228298485279
step: 640, loss: 0.05997525528073311
step: 650, loss: 0.049232009798288345
step: 660, loss: 0.03964768722653389
step: 670, loss: 0.05493193864822388
step: 680, loss: 0.03813792020082474
step: 690, loss: 4.1307128412881866e-05
step: 700, loss: 0.02079108916223049
step: 710, loss: 0.04348044469952583
step: 720, loss: 0.02287406660616398
step: 730, loss: 0.0377219058573246
step: 740, loss: 0.03520694375038147
step: 750, loss: 0.06895701587200165
step: 760, loss: 0.11200592666864395
step: 770, loss: 0.06373635679483414
step: 780, loss: 0.0197535939514637
step: 790, loss: 0.04758751764893532
step: 800, loss: 0.0633605420589447
step: 810, loss: 0.03215391933917999
step: 820, loss: 0.08971299976110458
step: 830, loss: 0.016645250841975212
step: 840, loss: 0.035815902054309845
step: 850, loss: 0.04059559106826782
step: 860, loss: 0.04143353924155235
step: 870, loss: 0.07185155153274536
step: 880, loss: 0.04592509940266609
step: 890, loss: 0.013217197731137276
step: 900, loss: 0.07725709676742554
step: 910, loss: 0.06996691972017288
step: 920, loss: 0.05511247366666794
step: 930, loss: 0.07875371724367142
step: 940, loss: 0.07392720133066177
step: 950, loss: 0.061631739139556885
step: 960, loss: 0.004755948670208454
step: 970, loss: 0.02458617277443409
step: 980, loss: 0.08596362918615341
step: 990, loss: 0.04419730603694916
step: 1000, loss: 4.112202441319823e-05
step: 1010, loss: 0.12793615460395813
step: 1020, loss: 0.03690595179796219
step: 1030, loss: 0.011367352679371834
step: 1040, loss: 0.08573183417320251
step: 1050, loss: 0.018869571387767792
step: 1060, loss: 0.0742623433470726
step: 1070, loss: 0.06433114409446716
epoch 18: dev_f1=0.9247113163972287, f1=0.9223616922361693, best_f1=0.9255966307908282
step: 0, loss: 0.05724659934639931
step: 10, loss: 0.04164261370897293
step: 20, loss: 0.033062644302845
step: 30, loss: 2.056653465842828e-05
step: 40, loss: 0.004787884186953306
step: 50, loss: 0.04466148093342781
step: 60, loss: 0.07104188203811646
step: 70, loss: 0.07305988669395447
step: 80, loss: 0.05100655555725098
step: 90, loss: 0.044360723346471786
step: 100, loss: 0.0541047640144825
step: 110, loss: 0.0016912344144657254
step: 120, loss: 0.009979788213968277
step: 130, loss: 0.11729969084262848
step: 140, loss: 0.043341830372810364
step: 150, loss: 0.09818455576896667
step: 160, loss: 0.05869108811020851
step: 170, loss: 0.07355363667011261
step: 180, loss: 0.015963541343808174
step: 190, loss: 0.029883624985814095
step: 200, loss: 0.03335140272974968
step: 210, loss: 0.05116782337427139
step: 220, loss: 0.058648426085710526
step: 230, loss: 0.026661980897188187
step: 240, loss: 0.05760527402162552
step: 250, loss: 0.044744834303855896
step: 260, loss: 0.06730855256319046
step: 270, loss: 0.0006386738386936486
step: 280, loss: 0.09561154991388321
step: 290, loss: 0.08305235952138901
step: 300, loss: 0.047425057739019394
step: 310, loss: 0.029788699001073837
step: 320, loss: 0.08687814325094223
step: 330, loss: 0.08472717553377151
step: 340, loss: 0.06409125030040741
step: 350, loss: 0.005290290806442499
step: 360, loss: 0.1276112049818039
step: 370, loss: 0.1124420315027237
step: 380, loss: 0.05356796458363533
step: 390, loss: 0.11060910671949387
step: 400, loss: 0.04379255697131157
step: 410, loss: 0.08546651154756546
step: 420, loss: 0.0484916977584362
step: 430, loss: 0.032076396048069
step: 440, loss: 0.032321374863386154
step: 450, loss: 0.0718824565410614
step: 460, loss: 0.02661207877099514
step: 470, loss: 0.04686526954174042
step: 480, loss: 0.05446842685341835
step: 490, loss: 0.04495697468519211
step: 500, loss: 0.04775717481970787
step: 510, loss: 0.07129213958978653
step: 520, loss: 0.07327786087989807
step: 530, loss: 0.025403238832950592
step: 540, loss: 0.0794525220990181
step: 550, loss: 0.08033508062362671
step: 560, loss: 0.027041245251893997
step: 570, loss: 8.633352990727872e-05
step: 580, loss: 0.09235361218452454
step: 590, loss: 0.022094372659921646
step: 600, loss: 0.01886763423681259
step: 610, loss: 0.0012125413632020354
step: 620, loss: 0.07252318412065506
step: 630, loss: 0.012229720130562782
step: 640, loss: 0.0339762382209301
step: 650, loss: 0.02954952046275139
step: 660, loss: 1.3012300769332796e-05
step: 670, loss: 0.03058462403714657
step: 680, loss: 0.0001451945281587541
step: 690, loss: 0.03671305999159813
step: 700, loss: 0.05464109778404236
step: 710, loss: 0.03798677399754524
step: 720, loss: 0.03671323135495186
step: 730, loss: 0.05574822425842285
step: 740, loss: 0.014334974810481071
step: 750, loss: 0.07389725744724274
step: 760, loss: 0.043680936098098755
step: 770, loss: 0.04480214789509773
step: 780, loss: 0.022275902330875397
step: 790, loss: 0.00018890771025326103
step: 800, loss: 0.008864508010447025
step: 810, loss: 0.0657365620136261
step: 820, loss: 0.09905243664979935
step: 830, loss: 0.11965709924697876
step: 840, loss: 0.029937168583273888
step: 850, loss: 0.0354439876973629
step: 860, loss: 0.024136455729603767
step: 870, loss: 0.07269252091646194
step: 880, loss: 0.017297759652137756
step: 890, loss: 0.0796237364411354
step: 900, loss: 0.035445429384708405
step: 910, loss: 0.09571056067943573
step: 920, loss: 0.06256351619958878
step: 930, loss: 0.0006832056678831577
step: 940, loss: 0.02976989559829235
step: 950, loss: 0.040794551372528076
step: 960, loss: 0.05558395013213158
step: 970, loss: 0.17163224518299103
step: 980, loss: 0.024313177913427353
step: 990, loss: 0.0668983981013298
step: 1000, loss: 0.042561255395412445
step: 1010, loss: 0.047498323023319244
step: 1020, loss: 0.025746796280145645
step: 1030, loss: 0.041597653180360794
step: 1040, loss: 0.0516190342605114
step: 1050, loss: 3.7462399632204324e-05
step: 1060, loss: 0.05079983174800873
step: 1070, loss: 0.050881434231996536
epoch 19: dev_f1=0.9241507677989763, f1=0.9228611500701264, best_f1=0.9255966307908282
step: 0, loss: 0.03631517291069031
step: 10, loss: 0.060357801616191864
step: 20, loss: 0.08806547522544861
step: 30, loss: 0.0912606492638588
step: 40, loss: 0.05756363272666931
step: 50, loss: 7.032586290733889e-05
step: 60, loss: 0.03563734143972397
step: 70, loss: 0.05739298835396767
step: 80, loss: 0.043857790529727936
step: 90, loss: 6.431594374589622e-05
step: 100, loss: 4.218744288664311e-05
step: 110, loss: 0.008217866532504559
step: 120, loss: 0.02910473570227623
step: 130, loss: 0.08319997787475586
step: 140, loss: 0.06420541554689407
step: 150, loss: 0.0887044221162796
step: 160, loss: 0.10518825799226761
step: 170, loss: 0.016795825213193893
step: 180, loss: 0.02660377323627472
step: 190, loss: 0.0230170339345932
step: 200, loss: 0.06388423591852188
step: 210, loss: 0.05955478549003601
step: 220, loss: 0.05116703733801842
step: 230, loss: 5.099620466353372e-05
step: 240, loss: 0.08459574729204178
step: 250, loss: 0.023503664880990982
step: 260, loss: 0.10801713913679123
step: 270, loss: 0.104953832924366
step: 280, loss: 1.3582208339357749e-05
step: 290, loss: 0.11528930068016052
step: 300, loss: 0.00028858595760539174
step: 310, loss: 0.00028577697230502963
step: 320, loss: 0.06734369695186615
step: 330, loss: 0.04097086936235428
step: 340, loss: 0.04952672868967056
step: 350, loss: 0.08906169980764389
step: 360, loss: 0.05525430291891098
step: 370, loss: 4.0007420466281474e-05
step: 380, loss: 0.023192932829260826
step: 390, loss: 0.08396881818771362
step: 400, loss: 3.6070996429771185e-05
step: 410, loss: 0.0032193725928664207
step: 420, loss: 0.07659027725458145
step: 430, loss: 0.12724065780639648
step: 440, loss: 5.862153193447739e-05
step: 450, loss: 0.02674121782183647
step: 460, loss: 0.012861715629696846
step: 470, loss: 0.03508029878139496
step: 480, loss: 0.0861031711101532
step: 490, loss: 0.026911618188023567
step: 500, loss: 0.08394697308540344
step: 510, loss: 0.037829574197530746
step: 520, loss: 0.035993363708257675
step: 530, loss: 0.04517749696969986
step: 540, loss: 0.04043562710285187
step: 550, loss: 0.012277251109480858
step: 560, loss: 0.04727353900671005
step: 570, loss: 0.0162910558283329
step: 580, loss: 0.0741368904709816
step: 590, loss: 0.04846997931599617
step: 600, loss: 0.028583956882357597
step: 610, loss: 0.007498151622712612
step: 620, loss: 0.040857426822185516
step: 630, loss: 0.02742704004049301
step: 640, loss: 2.748369843175169e-05
step: 650, loss: 0.04711252823472023
step: 660, loss: 0.012766174972057343
step: 670, loss: 0.07522423565387726
step: 680, loss: 0.07193464040756226
step: 690, loss: 0.08784762769937515
step: 700, loss: 0.002415689639747143
step: 710, loss: 0.03604090213775635
step: 720, loss: 0.043124888092279434
step: 730, loss: 0.01493035163730383
step: 740, loss: 0.06097978353500366
step: 750, loss: 0.07083053886890411
step: 760, loss: 0.034942377358675
step: 770, loss: 0.08664078265428543
step: 780, loss: 1.8871678548748605e-05
step: 790, loss: 0.07279085367918015
step: 800, loss: 0.06528843194246292
step: 810, loss: 2.0692732505267486e-05
step: 820, loss: 0.03344373404979706
step: 830, loss: 0.008023274131119251
step: 840, loss: 0.035034943372011185
step: 850, loss: 0.025027358904480934
step: 860, loss: 0.06549827754497528
step: 870, loss: 0.0502358004450798
step: 880, loss: 0.02107864059507847
step: 890, loss: 0.04705698788166046
step: 900, loss: 0.03030780702829361
step: 910, loss: 0.06726598739624023
step: 920, loss: 0.0010744098108261824
step: 930, loss: 0.0914125144481659
step: 940, loss: 0.042687058448791504
step: 950, loss: 0.01870730333030224
step: 960, loss: 0.07693823426961899
step: 970, loss: 0.015009278431534767
step: 980, loss: 0.025904595851898193
step: 990, loss: 0.0003912276588380337
step: 1000, loss: 0.036330051720142365
step: 1010, loss: 0.005100591573864222
step: 1020, loss: 0.02920340746641159
step: 1030, loss: 0.022747214883565903
step: 1040, loss: 0.01962721347808838
step: 1050, loss: 0.0638793557882309
step: 1060, loss: 0.01735793426632881
step: 1070, loss: 0.05790084972977638
epoch 20: dev_f1=0.922858495030762, f1=0.9224952741020794, best_f1=0.9255966307908282
