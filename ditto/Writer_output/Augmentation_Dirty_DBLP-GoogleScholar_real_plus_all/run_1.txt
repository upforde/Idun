cuda
Device: cuda
step: 0, loss: 0.9119086861610413
step: 10, loss: 0.4917238652706146
step: 20, loss: 0.3609817326068878
step: 30, loss: 0.5664985775947571
step: 40, loss: 0.3752468228340149
step: 50, loss: 0.5411536693572998
step: 60, loss: 0.3154076933860779
step: 70, loss: 0.2782664895057678
step: 80, loss: 0.06954922527074814
step: 90, loss: 0.309116929769516
step: 100, loss: 0.16693943738937378
step: 110, loss: 0.2586219310760498
step: 120, loss: 0.1562596559524536
step: 130, loss: 0.2101466804742813
step: 140, loss: 0.17614524066448212
step: 150, loss: 0.1718585342168808
step: 160, loss: 0.34671804308891296
step: 170, loss: 0.2988860607147217
step: 180, loss: 0.169630765914917
step: 190, loss: 0.21824964880943298
step: 200, loss: 0.2221752405166626
step: 210, loss: 0.09958021342754364
step: 220, loss: 0.13617315888404846
step: 230, loss: 0.1821007877588272
step: 240, loss: 0.1396365910768509
step: 250, loss: 0.18677882850170135
step: 260, loss: 0.17111554741859436
step: 270, loss: 0.22719193994998932
step: 280, loss: 0.19990071654319763
step: 290, loss: 0.07691840827465057
step: 300, loss: 0.2138413041830063
step: 310, loss: 0.06729649752378464
step: 320, loss: 0.12222810089588165
step: 330, loss: 0.11622271686792374
step: 340, loss: 0.12014824897050858
step: 350, loss: 0.10111137479543686
step: 360, loss: 0.23336949944496155
step: 370, loss: 0.1066267341375351
step: 380, loss: 0.22582809627056122
step: 390, loss: 0.11399073898792267
step: 400, loss: 0.13762158155441284
step: 410, loss: 0.18147538602352142
step: 420, loss: 0.1764126867055893
step: 430, loss: 0.22566136717796326
step: 440, loss: 0.11563323438167572
step: 450, loss: 0.08269526064395905
step: 460, loss: 0.16939091682434082
step: 470, loss: 0.21550577878952026
step: 480, loss: 0.20185081660747528
step: 490, loss: 0.21283511817455292
step: 500, loss: 0.12070261687040329
step: 510, loss: 0.361152708530426
step: 520, loss: 0.11835315078496933
step: 530, loss: 0.30277225375175476
step: 540, loss: 0.14658838510513306
step: 550, loss: 0.24216820299625397
step: 560, loss: 0.22692883014678955
step: 570, loss: 0.12907451391220093
step: 580, loss: 0.11263501644134521
step: 590, loss: 0.25887519121170044
step: 600, loss: 0.22875504195690155
step: 610, loss: 0.0638657659292221
step: 620, loss: 0.32432541251182556
step: 630, loss: 0.13019312918186188
step: 640, loss: 0.1490427851676941
step: 650, loss: 0.1410844922065735
step: 660, loss: 0.20414361357688904
step: 670, loss: 0.08816226571798325
step: 680, loss: 0.1272626519203186
step: 690, loss: 0.07799233496189117
step: 700, loss: 0.0963626429438591
step: 710, loss: 0.24491600692272186
step: 720, loss: 0.08211002498865128
step: 730, loss: 0.07481649518013
step: 740, loss: 0.09230096638202667
step: 750, loss: 0.04523807764053345
step: 760, loss: 0.07987509667873383
step: 770, loss: 0.14163359999656677
step: 780, loss: 0.23998896777629852
step: 790, loss: 0.06099628657102585
step: 800, loss: 0.15278854966163635
step: 810, loss: 0.22401122748851776
step: 820, loss: 0.1945367157459259
step: 830, loss: 0.23292599618434906
step: 840, loss: 0.1296195238828659
step: 850, loss: 0.14593391120433807
step: 860, loss: 0.13202306628227234
step: 870, loss: 0.22974392771720886
step: 880, loss: 0.14589202404022217
step: 890, loss: 0.15021252632141113
step: 900, loss: 0.13166148960590363
step: 910, loss: 0.10913050919771194
step: 920, loss: 0.06506349891424179
step: 930, loss: 0.16065824031829834
step: 940, loss: 0.07041995227336884
step: 950, loss: 0.1666913479566574
step: 960, loss: 0.1115351989865303
step: 970, loss: 0.15162348747253418
step: 980, loss: 0.1314999759197235
step: 990, loss: 0.04906526952981949
step: 1000, loss: 0.17698994278907776
step: 1010, loss: 0.1155039593577385
step: 1020, loss: 0.13289915025234222
step: 1030, loss: 0.09962176531553268
step: 1040, loss: 0.23808787763118744
step: 1050, loss: 0.15542341768741608
step: 1060, loss: 0.0709555521607399
step: 1070, loss: 0.1094805896282196
epoch 1: dev_f1=0.8980338363054413, f1=0.9015873015873015, best_f1=0.9015873015873015
step: 0, loss: 0.1894892305135727
step: 10, loss: 0.12143635749816895
step: 20, loss: 0.07185474783182144
step: 30, loss: 0.04315519705414772
step: 40, loss: 0.08186369389295578
step: 50, loss: 0.10467461496591568
step: 60, loss: 0.08444266766309738
step: 70, loss: 0.0896691232919693
step: 80, loss: 0.10911945253610611
step: 90, loss: 0.19603314995765686
step: 100, loss: 0.12101034820079803
step: 110, loss: 0.12400276213884354
step: 120, loss: 0.08059827983379364
step: 130, loss: 0.13682754337787628
step: 140, loss: 0.30517318844795227
step: 150, loss: 0.224724680185318
step: 160, loss: 0.25991949439048767
step: 170, loss: 0.13618595898151398
step: 180, loss: 0.031183181330561638
step: 190, loss: 0.09864544123411179
step: 200, loss: 0.27243754267692566
step: 210, loss: 0.09215988218784332
step: 220, loss: 0.05981561169028282
step: 230, loss: 0.12883275747299194
step: 240, loss: 0.35856756567955017
step: 250, loss: 0.1804819405078888
step: 260, loss: 0.033919382840394974
step: 270, loss: 0.0656452551484108
step: 280, loss: 0.10771577060222626
step: 290, loss: 0.05949999392032623
step: 300, loss: 0.09044639021158218
step: 310, loss: 0.09085839986801147
step: 320, loss: 0.13269896805286407
step: 330, loss: 0.12211712449789047
step: 340, loss: 0.11757006496191025
step: 350, loss: 0.20605698227882385
step: 360, loss: 0.07555833458900452
step: 370, loss: 0.2208932638168335
step: 380, loss: 0.09437625855207443
step: 390, loss: 0.10946663469076157
step: 400, loss: 0.0653727650642395
step: 410, loss: 0.11863362789154053
step: 420, loss: 0.08146064728498459
step: 430, loss: 0.16862058639526367
step: 440, loss: 0.3760189712047577
step: 450, loss: 0.07991956174373627
step: 460, loss: 0.113436259329319
step: 470, loss: 0.10818174481391907
step: 480, loss: 0.14387650787830353
step: 490, loss: 0.10175257921218872
step: 500, loss: 0.16294969618320465
step: 510, loss: 0.08444336801767349
step: 520, loss: 0.18269984424114227
step: 530, loss: 0.1730090230703354
step: 540, loss: 0.1166515201330185
step: 550, loss: 0.2082146555185318
step: 560, loss: 0.08880974352359772
step: 570, loss: 0.009513098746538162
step: 580, loss: 0.0789341926574707
step: 590, loss: 0.08880874514579773
step: 600, loss: 0.10446028411388397
step: 610, loss: 0.13577775657176971
step: 620, loss: 0.3997964859008789
step: 630, loss: 0.15391789376735687
step: 640, loss: 0.11346983164548874
step: 650, loss: 0.06094338744878769
step: 660, loss: 0.18431369960308075
step: 670, loss: 0.056610092520713806
step: 680, loss: 0.09315644949674606
step: 690, loss: 0.4114512503147125
step: 700, loss: 0.19149044156074524
step: 710, loss: 0.04936479032039642
step: 720, loss: 0.22431588172912598
step: 730, loss: 0.19207453727722168
step: 740, loss: 0.030613776296377182
step: 750, loss: 0.08304434269666672
step: 760, loss: 0.22411376237869263
step: 770, loss: 0.17360711097717285
step: 780, loss: 0.06135913357138634
step: 790, loss: 0.14531345665454865
step: 800, loss: 0.153132364153862
step: 810, loss: 0.13505172729492188
step: 820, loss: 0.18463034927845
step: 830, loss: 0.03453976660966873
step: 840, loss: 0.0990205779671669
step: 850, loss: 0.02704705111682415
step: 860, loss: 0.03532971814274788
step: 870, loss: 0.15022075176239014
step: 880, loss: 0.08173610270023346
step: 890, loss: 0.1912391036748886
step: 900, loss: 0.09682881832122803
step: 910, loss: 0.22155550122261047
step: 920, loss: 0.08706467598676682
step: 930, loss: 0.08949597924947739
step: 940, loss: 0.02559056505560875
step: 950, loss: 0.1618204116821289
step: 960, loss: 0.12145385891199112
step: 970, loss: 0.12910866737365723
step: 980, loss: 0.07468081265687943
step: 990, loss: 0.2029251903295517
step: 1000, loss: 0.14842410385608673
step: 1010, loss: 0.07083111256361008
step: 1020, loss: 0.1160956621170044
step: 1030, loss: 0.14931368827819824
step: 1040, loss: 0.12983852624893188
step: 1050, loss: 0.1791904717683792
step: 1060, loss: 0.19686207175254822
step: 1070, loss: 0.05451786145567894
epoch 2: dev_f1=0.9110189027201476, f1=0.9042357274401474, best_f1=0.9042357274401474
step: 0, loss: 0.05518259108066559
step: 10, loss: 0.09705259650945663
step: 20, loss: 0.15371669828891754
step: 30, loss: 0.05080656334757805
step: 40, loss: 0.17006051540374756
step: 50, loss: 0.07501194626092911
step: 60, loss: 0.09632692486047745
step: 70, loss: 0.19030813872814178
step: 80, loss: 0.08947291970252991
step: 90, loss: 0.11460387706756592
step: 100, loss: 0.05869399756193161
step: 110, loss: 0.14333921670913696
step: 120, loss: 0.17809806764125824
step: 130, loss: 0.029207590967416763
step: 140, loss: 0.03212270513176918
step: 150, loss: 0.20876896381378174
step: 160, loss: 0.09571907669305801
step: 170, loss: 0.11684423685073853
step: 180, loss: 0.05430486053228378
step: 190, loss: 0.21773754060268402
step: 200, loss: 0.13936761021614075
step: 210, loss: 0.1415693163871765
step: 220, loss: 0.07754383981227875
step: 230, loss: 0.046993061900138855
step: 240, loss: 0.11362867802381516
step: 250, loss: 0.22885136306285858
step: 260, loss: 0.021451899781823158
step: 270, loss: 0.14816714823246002
step: 280, loss: 0.07069972902536392
step: 290, loss: 0.12383868545293808
step: 300, loss: 0.07027792185544968
step: 310, loss: 0.05382130667567253
step: 320, loss: 0.1289920210838318
step: 330, loss: 0.0686606764793396
step: 340, loss: 0.18087151646614075
step: 350, loss: 0.058551643043756485
step: 360, loss: 0.1906651258468628
step: 370, loss: 0.13626670837402344
step: 380, loss: 0.027785884216427803
step: 390, loss: 0.09884633868932724
step: 400, loss: 0.13320112228393555
step: 410, loss: 0.06774143874645233
step: 420, loss: 0.03485685586929321
step: 430, loss: 0.0863121747970581
step: 440, loss: 0.03658275306224823
step: 450, loss: 0.1224403902888298
step: 460, loss: 0.02285415679216385
step: 470, loss: 0.07724449038505554
step: 480, loss: 0.08866249024868011
step: 490, loss: 0.09196442365646362
step: 500, loss: 0.10328496992588043
step: 510, loss: 0.10366865992546082
step: 520, loss: 0.102921262383461
step: 530, loss: 0.21169491112232208
step: 540, loss: 0.1453176885843277
step: 550, loss: 0.12360600382089615
step: 560, loss: 0.09156165271997452
step: 570, loss: 0.10022153705358505
step: 580, loss: 0.061257533729076385
step: 590, loss: 0.24088823795318604
step: 600, loss: 0.05041316896677017
step: 610, loss: 0.0589243620634079
step: 620, loss: 0.11954100430011749
step: 630, loss: 0.10490748286247253
step: 640, loss: 0.07612282037734985
step: 650, loss: 0.11632712930440903
step: 660, loss: 0.05312459543347359
step: 670, loss: 0.12018786370754242
step: 680, loss: 0.17349661886692047
step: 690, loss: 0.18900910019874573
step: 700, loss: 0.13817761838436127
step: 710, loss: 0.13394257426261902
step: 720, loss: 0.1414889395236969
step: 730, loss: 0.10991193354129791
step: 740, loss: 0.05972834676504135
step: 750, loss: 0.14311201870441437
step: 760, loss: 0.19515159726142883
step: 770, loss: 0.12943965196609497
step: 780, loss: 0.17642787098884583
step: 790, loss: 0.12136387825012207
step: 800, loss: 0.07149104028940201
step: 810, loss: 0.13130491971969604
step: 820, loss: 0.07869794964790344
step: 830, loss: 0.08282728493213654
step: 840, loss: 0.21960943937301636
step: 850, loss: 0.07570695132017136
step: 860, loss: 0.16924478113651276
step: 870, loss: 0.17643249034881592
step: 880, loss: 0.20185939967632294
step: 890, loss: 0.12249325960874557
step: 900, loss: 0.1380896270275116
step: 910, loss: 0.09649156033992767
step: 920, loss: 0.06777151674032211
step: 930, loss: 0.07511400431394577
step: 940, loss: 0.1828027069568634
step: 950, loss: 0.10418788343667984
step: 960, loss: 0.1215582937002182
step: 970, loss: 0.07635102421045303
step: 980, loss: 0.0930560976266861
step: 990, loss: 0.1461678296327591
step: 1000, loss: 0.192624032497406
step: 1010, loss: 0.10953968018293381
step: 1020, loss: 0.054793830960989
step: 1030, loss: 0.10585236549377441
step: 1040, loss: 0.15131551027297974
step: 1050, loss: 0.1102067306637764
step: 1060, loss: 0.21299652755260468
step: 1070, loss: 0.0788826197385788
epoch 3: dev_f1=0.9313680331644404, f1=0.9220839096357768, best_f1=0.9220839096357768
step: 0, loss: 0.08799731731414795
step: 10, loss: 0.027258245274424553
step: 20, loss: 0.07452653348445892
step: 30, loss: 0.012430448085069656
step: 40, loss: 0.06978557258844376
step: 50, loss: 0.04428764805197716
step: 60, loss: 0.09807267040014267
step: 70, loss: 0.07289466261863708
step: 80, loss: 0.1612107902765274
step: 90, loss: 0.1158403605222702
step: 100, loss: 0.07739721983671188
step: 110, loss: 0.06920606642961502
step: 120, loss: 0.03476748988032341
step: 130, loss: 0.1537451297044754
step: 140, loss: 0.04919995367527008
step: 150, loss: 0.06273964047431946
step: 160, loss: 0.12015248835086823
step: 170, loss: 0.10093256086111069
step: 180, loss: 0.09213823080062866
step: 190, loss: 0.15225458145141602
step: 200, loss: 0.025374192744493484
step: 210, loss: 0.07719437032938004
step: 220, loss: 0.12325412034988403
step: 230, loss: 0.08725237846374512
step: 240, loss: 0.05130395293235779
step: 250, loss: 0.05255720391869545
step: 260, loss: 0.17867273092269897
step: 270, loss: 0.019809942692518234
step: 280, loss: 0.1380244940519333
step: 290, loss: 0.007477462757378817
step: 300, loss: 0.09639087319374084
step: 310, loss: 0.2086469829082489
step: 320, loss: 0.105519138276577
step: 330, loss: 0.18738150596618652
step: 340, loss: 0.20070207118988037
step: 350, loss: 0.20266468822956085
step: 360, loss: 0.14861293137073517
step: 370, loss: 0.07034704089164734
step: 380, loss: 0.19246026873588562
step: 390, loss: 0.059703268110752106
step: 400, loss: 0.19496598839759827
step: 410, loss: 0.09931544959545135
step: 420, loss: 0.11185234785079956
step: 430, loss: 0.03298180550336838
step: 440, loss: 0.05536434054374695
step: 450, loss: 0.15054544806480408
step: 460, loss: 0.05251915380358696
step: 470, loss: 0.05907445028424263
step: 480, loss: 0.11025228351354599
step: 490, loss: 0.16556687653064728
step: 500, loss: 0.08360496163368225
step: 510, loss: 0.025690266862511635
step: 520, loss: 0.055838692933321
step: 530, loss: 0.1782585233449936
step: 540, loss: 0.10696905106306076
step: 550, loss: 0.24184980988502502
step: 560, loss: 0.14364326000213623
step: 570, loss: 0.07906616479158401
step: 580, loss: 0.027746275067329407
step: 590, loss: 0.14177624881267548
step: 600, loss: 0.053026121109724045
step: 610, loss: 0.08869533240795135
step: 620, loss: 0.04092895984649658
step: 630, loss: 0.09885019063949585
step: 640, loss: 0.12147810310125351
step: 650, loss: 0.161372110247612
step: 660, loss: 0.06261856108903885
step: 670, loss: 0.14820490777492523
step: 680, loss: 0.10322856903076172
step: 690, loss: 0.08069147169589996
step: 700, loss: 0.13434302806854248
step: 710, loss: 0.07041580975055695
step: 720, loss: 0.11749950051307678
step: 730, loss: 0.09196437150239944
step: 740, loss: 0.14215974509716034
step: 750, loss: 0.13005906343460083
step: 760, loss: 0.09265879541635513
step: 770, loss: 0.1783406287431717
step: 780, loss: 0.12099713832139969
step: 790, loss: 0.17221646010875702
step: 800, loss: 0.08834896236658096
step: 810, loss: 0.05599435418844223
step: 820, loss: 0.03500886261463165
step: 830, loss: 0.07654115557670593
step: 840, loss: 0.13115599751472473
step: 850, loss: 0.07772413641214371
step: 860, loss: 0.10716430842876434
step: 870, loss: 0.1018001139163971
step: 880, loss: 0.09762444347143173
step: 890, loss: 0.10680118948221207
step: 900, loss: 0.08242859691381454
step: 910, loss: 0.05027375370264053
step: 920, loss: 0.13501125574111938
step: 930, loss: 0.06870006769895554
step: 940, loss: 0.1187136173248291
step: 950, loss: 0.11827704310417175
step: 960, loss: 0.09336637705564499
step: 970, loss: 0.11955077946186066
step: 980, loss: 0.15786625444889069
step: 990, loss: 0.08066530525684357
step: 1000, loss: 0.11551985889673233
step: 1010, loss: 0.12138085812330246
step: 1020, loss: 0.20833633840084076
step: 1030, loss: 0.09675426036119461
step: 1040, loss: 0.2373863011598587
step: 1050, loss: 0.09432373195886612
step: 1060, loss: 0.06072304770350456
step: 1070, loss: 0.12479637563228607
epoch 4: dev_f1=0.9248501613646842, f1=0.9170912459471977, best_f1=0.9220839096357768
step: 0, loss: 0.03740823641419411
step: 10, loss: 0.09152847528457642
step: 20, loss: 0.06577947735786438
step: 30, loss: 0.1464853733778
step: 40, loss: 0.0394388772547245
step: 50, loss: 0.08510258793830872
step: 60, loss: 0.055032070726156235
step: 70, loss: 0.08328743278980255
step: 80, loss: 0.1279429942369461
step: 90, loss: 0.06190072372555733
step: 100, loss: 0.06908337771892548
step: 110, loss: 0.08796650171279907
step: 120, loss: 0.02430964820086956
step: 130, loss: 0.04274145886301994
step: 140, loss: 0.04564156010746956
step: 150, loss: 0.019663626328110695
step: 160, loss: 0.008031824603676796
step: 170, loss: 0.04483196511864662
step: 180, loss: 0.04735954850912094
step: 190, loss: 0.09446454048156738
step: 200, loss: 0.06867653876543045
step: 210, loss: 0.0766267329454422
step: 220, loss: 0.18092358112335205
step: 230, loss: 0.09678944200277328
step: 240, loss: 0.09628427773714066
step: 250, loss: 0.07432349026203156
step: 260, loss: 0.05877767875790596
step: 270, loss: 0.033757831901311874
step: 280, loss: 0.02207707241177559
step: 290, loss: 0.11295919120311737
step: 300, loss: 0.1063280776143074
step: 310, loss: 0.043230753391981125
step: 320, loss: 0.11740683019161224
step: 330, loss: 0.04965364933013916
step: 340, loss: 0.14982618391513824
step: 350, loss: 0.11305401474237442
step: 360, loss: 0.06408871710300446
step: 370, loss: 0.016359800472855568
step: 380, loss: 0.14507655799388885
step: 390, loss: 0.12500014901161194
step: 400, loss: 0.23767240345478058
step: 410, loss: 0.09980996698141098
step: 420, loss: 0.12800948321819305
step: 430, loss: 0.11611484736204147
step: 440, loss: 0.07047245651483536
step: 450, loss: 0.019934656098484993
step: 460, loss: 0.1655537486076355
step: 470, loss: 0.10473155230283737
step: 480, loss: 0.11321412771940231
step: 490, loss: 0.04117665812373161
step: 500, loss: 0.021413369104266167
step: 510, loss: 0.07365109771490097
step: 520, loss: 0.15382662415504456
step: 530, loss: 0.002261078217998147
step: 540, loss: 0.08276701718568802
step: 550, loss: 0.08658746629953384
step: 560, loss: 0.099777951836586
step: 570, loss: 0.10850536078214645
step: 580, loss: 0.08092454075813293
step: 590, loss: 0.19022980332374573
step: 600, loss: 0.09411446005105972
step: 610, loss: 0.19197335839271545
step: 620, loss: 0.08457928150892258
step: 630, loss: 0.13906070590019226
step: 640, loss: 0.09838393330574036
step: 650, loss: 0.06190882995724678
step: 660, loss: 0.04667629301548004
step: 670, loss: 0.09652126580476761
step: 680, loss: 0.08489520847797394
step: 690, loss: 0.14761902391910553
step: 700, loss: 0.08097224682569504
step: 710, loss: 0.1578979641199112
step: 720, loss: 0.088833287358284
step: 730, loss: 0.09224769473075867
step: 740, loss: 0.059024371206760406
step: 750, loss: 0.033192288130521774
step: 760, loss: 0.12704482674598694
step: 770, loss: 0.09454452246427536
step: 780, loss: 0.09906058013439178
step: 790, loss: 0.16313010454177856
step: 800, loss: 0.17531318962574005
step: 810, loss: 0.061500560492277145
step: 820, loss: 0.07606884092092514
step: 830, loss: 0.1012367308139801
step: 840, loss: 0.1129675880074501
step: 850, loss: 0.016308624297380447
step: 860, loss: 0.019565844908356667
step: 870, loss: 0.12788353860378265
step: 880, loss: 0.11035215854644775
step: 890, loss: 0.11695584654808044
step: 900, loss: 0.06179973483085632
step: 910, loss: 0.10380664467811584
step: 920, loss: 0.07488501816987991
step: 930, loss: 0.05844462662935257
step: 940, loss: 0.06002502515912056
step: 950, loss: 0.046283286064863205
step: 960, loss: 0.08680146932601929
step: 970, loss: 0.021259913221001625
step: 980, loss: 0.05256194621324539
step: 990, loss: 0.015733627602458
step: 1000, loss: 0.15864332020282745
step: 1010, loss: 0.1232704222202301
step: 1020, loss: 0.13482046127319336
step: 1030, loss: 0.08226262032985687
step: 1040, loss: 0.0690300315618515
step: 1050, loss: 0.023502130061388016
step: 1060, loss: 0.14409515261650085
step: 1070, loss: 0.06482338160276413
epoch 5: dev_f1=0.9286675639300135, f1=0.9155435759209345, best_f1=0.9220839096357768
step: 0, loss: 0.0490751788020134
step: 10, loss: 0.350800484418869
step: 20, loss: 0.03026386722922325
step: 30, loss: 0.04172325134277344
step: 40, loss: 0.09285163134336472
step: 50, loss: 0.14205503463745117
step: 60, loss: 0.06170443817973137
step: 70, loss: 0.0220868568867445
step: 80, loss: 0.13057264685630798
step: 90, loss: 0.012350598350167274
step: 100, loss: 0.059988923370838165
step: 110, loss: 0.06496522575616837
step: 120, loss: 0.06229386106133461
step: 130, loss: 0.14348509907722473
step: 140, loss: 0.10268095880746841
step: 150, loss: 0.05818484351038933
step: 160, loss: 0.182037353515625
step: 170, loss: 0.11632820218801498
step: 180, loss: 0.10351034253835678
step: 190, loss: 0.04404117166996002
step: 200, loss: 0.03428232669830322
step: 210, loss: 0.04968943074345589
step: 220, loss: 0.09240486472845078
step: 230, loss: 0.07461036741733551
step: 240, loss: 0.08561483770608902
step: 250, loss: 0.06355167180299759
step: 260, loss: 0.0023058734368532896
step: 270, loss: 0.1055445745587349
step: 280, loss: 0.013420267030596733
step: 290, loss: 0.17569930851459503
step: 300, loss: 0.01687176525592804
step: 310, loss: 0.08790059387683868
step: 320, loss: 0.07937030494213104
step: 330, loss: 0.09149244427680969
step: 340, loss: 0.05063735693693161
step: 350, loss: 0.013551529496908188
step: 360, loss: 0.030924152582883835
step: 370, loss: 0.13167621195316315
step: 380, loss: 0.14694346487522125
step: 390, loss: 0.05206681787967682
step: 400, loss: 0.07337391376495361
step: 410, loss: 0.07242840528488159
step: 420, loss: 0.04273836314678192
step: 430, loss: 0.11425179988145828
step: 440, loss: 0.08808039128780365
step: 450, loss: 0.10646158456802368
step: 460, loss: 0.16660068929195404
step: 470, loss: 0.2013474553823471
step: 480, loss: 0.07006284594535828
step: 490, loss: 0.13773682713508606
step: 500, loss: 0.0595066212117672
step: 510, loss: 0.08307895809412003
step: 520, loss: 0.10668119788169861
step: 530, loss: 0.10578025132417679
step: 540, loss: 0.07286014407873154
step: 550, loss: 0.1477898508310318
step: 560, loss: 0.23286037147045135
step: 570, loss: 0.04559074714779854
step: 580, loss: 0.04538608342409134
step: 590, loss: 0.024294542148709297
step: 600, loss: 0.22607453167438507
step: 610, loss: 0.06356297433376312
step: 620, loss: 0.02909473143517971
step: 630, loss: 0.0477488748729229
step: 640, loss: 0.2129150927066803
step: 650, loss: 0.12022767961025238
step: 660, loss: 0.09929399937391281
step: 670, loss: 0.06916143745183945
step: 680, loss: 0.056593701243400574
step: 690, loss: 0.06167410686612129
step: 700, loss: 0.1365697830915451
step: 710, loss: 0.17343610525131226
step: 720, loss: 0.06160080432891846
step: 730, loss: 0.14148293435573578
step: 740, loss: 0.0925094410777092
step: 750, loss: 0.23159952461719513
step: 760, loss: 0.0544147714972496
step: 770, loss: 0.20518869161605835
step: 780, loss: 0.09117358922958374
step: 790, loss: 0.14492765069007874
step: 800, loss: 0.06574705988168716
step: 810, loss: 0.14135916531085968
step: 820, loss: 0.23536592721939087
step: 830, loss: 0.18370088934898376
step: 840, loss: 0.16653801500797272
step: 850, loss: 0.05393810570240021
step: 860, loss: 0.13037002086639404
step: 870, loss: 0.08787469565868378
step: 880, loss: 0.0749669000506401
step: 890, loss: 0.05398467555642128
step: 900, loss: 0.05485783889889717
step: 910, loss: 0.18769758939743042
step: 920, loss: 0.12452331185340881
step: 930, loss: 0.10084347426891327
step: 940, loss: 0.08622350543737411
step: 950, loss: 0.15464027225971222
step: 960, loss: 0.15134987235069275
step: 970, loss: 0.0731874629855156
step: 980, loss: 0.09816977381706238
step: 990, loss: 0.12648996710777283
step: 1000, loss: 0.06476153433322906
step: 1010, loss: 0.03344146907329559
step: 1020, loss: 0.10013893246650696
step: 1030, loss: 0.02002483792603016
step: 1040, loss: 0.04170602932572365
step: 1050, loss: 0.06864635646343231
step: 1060, loss: 0.1077398806810379
step: 1070, loss: 0.21832697093486786
epoch 6: dev_f1=0.9188432835820896, f1=0.9203539823008848, best_f1=0.9220839096357768
step: 0, loss: 0.07850847393274307
step: 10, loss: 0.0636153295636177
step: 20, loss: 0.05889378860592842
step: 30, loss: 0.08780962228775024
step: 40, loss: 0.09895189851522446
step: 50, loss: 0.05225829780101776
step: 60, loss: 0.06507856398820877
step: 70, loss: 0.08509644120931625
step: 80, loss: 0.06052987650036812
step: 90, loss: 0.09608878195285797
step: 100, loss: 0.1956413835287094
step: 110, loss: 0.041659772396087646
step: 120, loss: 0.0169456098228693
step: 130, loss: 0.012704803608357906
step: 140, loss: 0.07016044110059738
step: 150, loss: 0.09855318069458008
step: 160, loss: 0.08021911978721619
step: 170, loss: 0.014321276918053627
step: 180, loss: 0.07491911202669144
step: 190, loss: 0.045757852494716644
step: 200, loss: 0.04417436197400093
step: 210, loss: 0.06624701619148254
step: 220, loss: 0.016974810510873795
step: 230, loss: 0.04580797255039215
step: 240, loss: 0.08531796932220459
step: 250, loss: 0.05958950147032738
step: 260, loss: 0.06963633745908737
step: 270, loss: 0.15542563796043396
step: 280, loss: 0.028906697407364845
step: 290, loss: 0.18823805451393127
step: 300, loss: 0.05120018124580383
step: 310, loss: 0.0851765125989914
step: 320, loss: 0.15794414281845093
step: 330, loss: 0.015535354614257812
step: 340, loss: 0.061738964170217514
step: 350, loss: 0.022160915657877922
step: 360, loss: 0.09239406883716583
step: 370, loss: 0.05045485496520996
step: 380, loss: 0.09942765533924103
step: 390, loss: 0.026537423953413963
step: 400, loss: 0.11070664972066879
step: 410, loss: 0.059900619089603424
step: 420, loss: 0.1990063339471817
step: 430, loss: 0.08692733198404312
step: 440, loss: 0.2280963957309723
step: 450, loss: 0.036102645099163055
step: 460, loss: 0.06051734462380409
step: 470, loss: 0.1328144073486328
step: 480, loss: 0.1251402050256729
step: 490, loss: 0.1466866135597229
step: 500, loss: 0.03968099132180214
step: 510, loss: 0.08025487512350082
step: 520, loss: 0.037738192826509476
step: 530, loss: 0.08955439180135727
step: 540, loss: 0.09679067879915237
step: 550, loss: 0.055179037153720856
step: 560, loss: 0.1668849140405655
step: 570, loss: 0.014887673780322075
step: 580, loss: 0.07941969484090805
step: 590, loss: 0.060175348073244095
step: 600, loss: 0.05144238844513893
step: 610, loss: 0.02308455854654312
step: 620, loss: 0.03358368203043938
step: 630, loss: 0.06308124214410782
step: 640, loss: 0.02079569548368454
step: 650, loss: 0.08050817251205444
step: 660, loss: 0.0995023250579834
step: 670, loss: 0.17518724501132965
step: 680, loss: 0.0430699922144413
step: 690, loss: 0.17897813022136688
step: 700, loss: 0.14388823509216309
step: 710, loss: 0.053355127573013306
step: 720, loss: 0.1670033484697342
step: 730, loss: 0.2130328267812729
step: 740, loss: 0.06057985872030258
step: 750, loss: 0.1015482172369957
step: 760, loss: 0.04329098016023636
step: 770, loss: 0.13990165293216705
step: 780, loss: 0.14265847206115723
step: 790, loss: 0.08689164370298386
step: 800, loss: 0.013528731651604176
step: 810, loss: 0.07954354584217072
step: 820, loss: 0.12840266525745392
step: 830, loss: 0.1375226229429245
step: 840, loss: 0.0834517553448677
step: 850, loss: 0.03263925760984421
step: 860, loss: 0.12780705094337463
step: 870, loss: 0.11480230838060379
step: 880, loss: 0.19322066009044647
step: 890, loss: 0.07633107900619507
step: 900, loss: 0.10948679596185684
step: 910, loss: 0.1314096301794052
step: 920, loss: 0.04182194918394089
step: 930, loss: 0.11481299251317978
step: 940, loss: 0.20755159854888916
step: 950, loss: 0.01030992716550827
step: 960, loss: 0.1462578922510147
step: 970, loss: 0.16056160628795624
step: 980, loss: 0.02801015041768551
step: 990, loss: 0.13861209154129028
step: 1000, loss: 0.15377864241600037
step: 1010, loss: 0.03389895334839821
step: 1020, loss: 0.005111464764922857
step: 1030, loss: 0.08331581950187683
step: 1040, loss: 0.10105522722005844
step: 1050, loss: 0.18030104041099548
step: 1060, loss: 0.025450751185417175
step: 1070, loss: 0.15646401047706604
epoch 7: dev_f1=0.9245630174793008, f1=0.9180778032036614, best_f1=0.9220839096357768
step: 0, loss: 0.06761518865823746
step: 10, loss: 0.11282236129045486
step: 20, loss: 0.14303475618362427
step: 30, loss: 0.05702371522784233
step: 40, loss: 0.03156474977731705
step: 50, loss: 0.05548420548439026
step: 60, loss: 0.006481670308858156
step: 70, loss: 0.036468297243118286
step: 80, loss: 0.03502654656767845
step: 90, loss: 0.06060921400785446
step: 100, loss: 0.07989108562469482
step: 110, loss: 0.013908534310758114
step: 120, loss: 0.10213293880224228
step: 130, loss: 0.05889304354786873
step: 140, loss: 0.19567380845546722
step: 150, loss: 0.19590575993061066
step: 160, loss: 0.05384967848658562
step: 170, loss: 0.03641168028116226
step: 180, loss: 0.0669856071472168
step: 190, loss: 0.004929096903651953
step: 200, loss: 0.062132079154253006
step: 210, loss: 0.035873766988515854
step: 220, loss: 0.07387915253639221
step: 230, loss: 0.011395856738090515
step: 240, loss: 0.033185869455337524
step: 250, loss: 0.07104960083961487
step: 260, loss: 0.09068205207586288
step: 270, loss: 0.03728104010224342
step: 280, loss: 0.0513714924454689
step: 290, loss: 0.038150057196617126
step: 300, loss: 0.01321355439722538
step: 310, loss: 0.008957860060036182
step: 320, loss: 0.018864382058382034
step: 330, loss: 0.060984887182712555
step: 340, loss: 0.05746405944228172
step: 350, loss: 0.1686798632144928
step: 360, loss: 0.0191106665879488
step: 370, loss: 0.06325268745422363
step: 380, loss: 0.10684285312891006
step: 390, loss: 0.15312474966049194
step: 400, loss: 0.08139938861131668
step: 410, loss: 0.12691783905029297
step: 420, loss: 0.08782310038805008
step: 430, loss: 0.06655813753604889
step: 440, loss: 0.08186297118663788
step: 450, loss: 0.07130630314350128
step: 460, loss: 0.11206674575805664
step: 470, loss: 0.15626318752765656
step: 480, loss: 0.07199611514806747
step: 490, loss: 0.07177899777889252
step: 500, loss: 0.08640427142381668
step: 510, loss: 0.06381280720233917
step: 520, loss: 0.07687310874462128
step: 530, loss: 0.04417736083269119
step: 540, loss: 0.05930154770612717
step: 550, loss: 0.06622625142335892
step: 560, loss: 0.10378358513116837
step: 570, loss: 0.04053787514567375
step: 580, loss: 0.010048764757812023
step: 590, loss: 0.14893902838230133
step: 600, loss: 0.0448419488966465
step: 610, loss: 0.09412254393100739
step: 620, loss: 0.03930237144231796
step: 630, loss: 0.1303868591785431
step: 640, loss: 0.06369219720363617
step: 650, loss: 0.02299496717751026
step: 660, loss: 0.04994042217731476
step: 670, loss: 0.12697887420654297
step: 680, loss: 0.062251538038253784
step: 690, loss: 0.0036050372291356325
step: 700, loss: 0.14355716109275818
step: 710, loss: 0.0827224925160408
step: 720, loss: 0.15524421632289886
step: 730, loss: 0.10404276102781296
step: 740, loss: 0.009303145110607147
step: 750, loss: 0.07139410823583603
step: 760, loss: 0.006973549257963896
step: 770, loss: 0.017346616834402084
step: 780, loss: 0.09106956422328949
step: 790, loss: 0.12325680255889893
step: 800, loss: 0.05757271498441696
step: 810, loss: 0.15303796529769897
step: 820, loss: 0.08592967689037323
step: 830, loss: 0.11198801547288895
step: 840, loss: 0.03955494612455368
step: 850, loss: 0.018247397616505623
step: 860, loss: 0.06897908449172974
step: 870, loss: 0.11246564984321594
step: 880, loss: 0.05445612967014313
step: 890, loss: 0.008985173888504505
step: 900, loss: 0.1735963374376297
step: 910, loss: 0.06131604686379433
step: 920, loss: 0.016869796440005302
step: 930, loss: 0.10827712714672089
step: 940, loss: 0.07120027393102646
step: 950, loss: 0.07198642194271088
step: 960, loss: 0.09541140496730804
step: 970, loss: 0.04705038666725159
step: 980, loss: 0.07304256409406662
step: 990, loss: 0.048873014748096466
step: 1000, loss: 0.3262694478034973
step: 1010, loss: 0.12853989005088806
step: 1020, loss: 0.07712870836257935
step: 1030, loss: 0.06536173820495605
step: 1040, loss: 0.05323227867484093
step: 1050, loss: 0.08445286005735397
step: 1060, loss: 0.18590055406093597
step: 1070, loss: 0.10458572953939438
epoch 8: dev_f1=0.9188445667125174, f1=0.9174228675136116, best_f1=0.9220839096357768
step: 0, loss: 0.0678364485502243
step: 10, loss: 0.007330619730055332
step: 20, loss: 0.04465019330382347
step: 30, loss: 0.10124839842319489
step: 40, loss: 0.1503220945596695
step: 50, loss: 0.029082797467708588
step: 60, loss: 0.046892739832401276
step: 70, loss: 0.09489645063877106
step: 80, loss: 0.10720912367105484
step: 90, loss: 0.07141178101301193
step: 100, loss: 0.04423367232084274
step: 110, loss: 0.028208527714014053
step: 120, loss: 0.021883057430386543
step: 130, loss: 0.06481584906578064
step: 140, loss: 0.08783099055290222
step: 150, loss: 0.08103258162736893
step: 160, loss: 0.06523573398590088
step: 170, loss: 0.21647463738918304
step: 180, loss: 0.08614727854728699
step: 190, loss: 0.035118356347084045
step: 200, loss: 0.0949605330824852
step: 210, loss: 0.1470712125301361
step: 220, loss: 0.05487784743309021
step: 230, loss: 0.07083272933959961
step: 240, loss: 0.025863155722618103
step: 250, loss: 0.052495185285806656
step: 260, loss: 0.024514436721801758
step: 270, loss: 0.07840722054243088
step: 280, loss: 0.02600880153477192
step: 290, loss: 0.16970126330852509
step: 300, loss: 0.05917743965983391
step: 310, loss: 0.012807928025722504
step: 320, loss: 0.0734788253903389
step: 330, loss: 0.05199181288480759
step: 340, loss: 0.012460462749004364
step: 350, loss: 0.013189885765314102
step: 360, loss: 0.12275195121765137
step: 370, loss: 0.038183752447366714
step: 380, loss: 0.07672373950481415
step: 390, loss: 0.05482868850231171
step: 400, loss: 0.00037228353903628886
step: 410, loss: 0.024446386843919754
step: 420, loss: 0.16353599727153778
step: 430, loss: 0.04393116384744644
step: 440, loss: 0.03158668801188469
step: 450, loss: 0.029306532815098763
step: 460, loss: 0.0406392365694046
step: 470, loss: 0.05492887645959854
step: 480, loss: 0.08799324184656143
step: 490, loss: 0.1245795339345932
step: 500, loss: 0.05236930400133133
step: 510, loss: 0.08264941722154617
step: 520, loss: 0.015959959477186203
step: 530, loss: 0.061793673783540726
step: 540, loss: 0.09099625796079636
step: 550, loss: 0.0861833244562149
step: 560, loss: 0.059779781848192215
step: 570, loss: 0.10354306548833847
step: 580, loss: 0.10716455429792404
step: 590, loss: 0.0469069741666317
step: 600, loss: 0.008931607939302921
step: 610, loss: 0.13302911818027496
step: 620, loss: 0.0839347243309021
step: 630, loss: 0.04630656912922859
step: 640, loss: 0.11615922302007675
step: 650, loss: 0.16107524931430817
step: 660, loss: 0.13239049911499023
step: 670, loss: 0.10930246114730835
step: 680, loss: 0.05623919889330864
step: 690, loss: 0.043168727308511734
step: 700, loss: 0.07886534929275513
step: 710, loss: 0.025573745369911194
step: 720, loss: 0.017663734033703804
step: 730, loss: 0.09766226261854172
step: 740, loss: 0.03092566505074501
step: 750, loss: 0.06600195914506912
step: 760, loss: 0.14430713653564453
step: 770, loss: 0.013585963286459446
step: 780, loss: 0.10486295819282532
step: 790, loss: 0.04637155309319496
step: 800, loss: 0.06839925795793533
step: 810, loss: 0.08394889533519745
step: 820, loss: 0.11657757312059402
step: 830, loss: 0.117113396525383
step: 840, loss: 0.1420031487941742
step: 850, loss: 0.06685397028923035
step: 860, loss: 0.06476284563541412
step: 870, loss: 0.11410976201295853
step: 880, loss: 0.06583230942487717
step: 890, loss: 0.030700094997882843
step: 900, loss: 0.2304050326347351
step: 910, loss: 0.052998632192611694
step: 920, loss: 0.08369199186563492
step: 930, loss: 0.06922744959592819
step: 940, loss: 0.08302748948335648
step: 950, loss: 0.05482408404350281
step: 960, loss: 0.020297585055232048
step: 970, loss: 0.05926317349076271
step: 980, loss: 0.017443642020225525
step: 990, loss: 0.11513315886259079
step: 1000, loss: 0.09587536752223969
step: 1010, loss: 0.12351856380701065
step: 1020, loss: 0.3393544554710388
step: 1030, loss: 0.039712246507406235
step: 1040, loss: 0.10683254897594452
step: 1050, loss: 0.039098527282476425
step: 1060, loss: 0.03632042184472084
step: 1070, loss: 0.08323301374912262
epoch 9: dev_f1=0.9260299625468165, f1=0.9207688701359588, best_f1=0.9220839096357768
step: 0, loss: 0.046941496431827545
step: 10, loss: 0.09433427453041077
step: 20, loss: 0.06433882564306259
step: 30, loss: 0.01763750985264778
step: 40, loss: 0.1269276738166809
step: 50, loss: 0.06769156455993652
step: 60, loss: 0.11313645541667938
step: 70, loss: 0.0821918249130249
step: 80, loss: 0.10942123085260391
step: 90, loss: 0.053872305899858475
step: 100, loss: 0.06319958716630936
step: 110, loss: 0.07652437686920166
step: 120, loss: 0.025886230170726776
step: 130, loss: 0.010730608366429806
step: 140, loss: 0.041319072246551514
step: 150, loss: 0.18921461701393127
step: 160, loss: 0.06812607496976852
step: 170, loss: 0.12042374163866043
step: 180, loss: 0.039049532264471054
step: 190, loss: 0.077061727643013
step: 200, loss: 0.06881584227085114
step: 210, loss: 0.11882009357213974
step: 220, loss: 0.02456325851380825
step: 230, loss: 0.04928726330399513
step: 240, loss: 0.04923388361930847
step: 250, loss: 0.10284870862960815
step: 260, loss: 0.05950886756181717
step: 270, loss: 0.08003158867359161
step: 280, loss: 0.02790786698460579
step: 290, loss: 0.014025053009390831
step: 300, loss: 0.05981484800577164
step: 310, loss: 0.06071174517273903
step: 320, loss: 0.042455725371837616
step: 330, loss: 0.09485079348087311
step: 340, loss: 0.03456372767686844
step: 350, loss: 0.020771097391843796
step: 360, loss: 0.07811318337917328
step: 370, loss: 0.026249399408698082
step: 380, loss: 0.10544177144765854
step: 390, loss: 0.0538165345788002
step: 400, loss: 0.12128923088312149
step: 410, loss: 0.03407830372452736
step: 420, loss: 0.08238643407821655
step: 430, loss: 0.09637171775102615
step: 440, loss: 0.07385557889938354
step: 450, loss: 0.026739446446299553
step: 460, loss: 0.0410844162106514
step: 470, loss: 0.04778831824660301
step: 480, loss: 0.07379618287086487
step: 490, loss: 0.010506988503038883
step: 500, loss: 0.09623140841722488
step: 510, loss: 0.11691535264253616
step: 520, loss: 0.08010987937450409
step: 530, loss: 0.03049153834581375
step: 540, loss: 0.040444571524858475
step: 550, loss: 0.08825090527534485
step: 560, loss: 0.006677759345620871
step: 570, loss: 0.060136448591947556
step: 580, loss: 0.07545550167560577
step: 590, loss: 0.13180021941661835
step: 600, loss: 0.15622872114181519
step: 610, loss: 0.2121443897485733
step: 620, loss: 0.07810503989458084
step: 630, loss: 0.11048945039510727
step: 640, loss: 0.057001933455467224
step: 650, loss: 0.08879789710044861
step: 660, loss: 0.013570744544267654
step: 670, loss: 0.02314421907067299
step: 680, loss: 0.08687693625688553
step: 690, loss: 0.10237156599760056
step: 700, loss: 0.08885006606578827
step: 710, loss: 0.16788795590400696
step: 720, loss: 0.09527231752872467
step: 730, loss: 0.08376391977071762
step: 740, loss: 0.08432834595441818
step: 750, loss: 0.20407339930534363
step: 760, loss: 0.022412016987800598
step: 770, loss: 0.07400746643543243
step: 780, loss: 0.050145555287599564
step: 790, loss: 0.008938486687839031
step: 800, loss: 0.09423688799142838
step: 810, loss: 0.020893072709441185
step: 820, loss: 0.02630612440407276
step: 830, loss: 0.00852954387664795
step: 840, loss: 0.06282277405261993
step: 850, loss: 0.0640895664691925
step: 860, loss: 0.00343904341571033
step: 870, loss: 0.029255811125040054
step: 880, loss: 0.15709345042705536
step: 890, loss: 0.06561721861362457
step: 900, loss: 0.022208085283637047
step: 910, loss: 0.05684256553649902
step: 920, loss: 0.004902607295662165
step: 930, loss: 0.0711842030286789
step: 940, loss: 0.13381335139274597
step: 950, loss: 0.10312823206186295
step: 960, loss: 0.048139505088329315
step: 970, loss: 0.07783297449350357
step: 980, loss: 0.017630020156502724
step: 990, loss: 0.061030253767967224
step: 1000, loss: 0.04807387292385101
step: 1010, loss: 0.03361782804131508
step: 1020, loss: 0.04619758576154709
step: 1030, loss: 0.08480632305145264
step: 1040, loss: 0.12488970160484314
step: 1050, loss: 0.055435944348573685
step: 1060, loss: 0.13395258784294128
step: 1070, loss: 0.14120525121688843
epoch 10: dev_f1=0.9333333333333333, f1=0.9295112781954888, best_f1=0.9295112781954888
step: 0, loss: 0.05811651796102524
step: 10, loss: 0.2084122896194458
step: 20, loss: 0.09004070609807968
step: 30, loss: 0.04293474927544594
step: 40, loss: 0.09212731570005417
step: 50, loss: 0.03250939026474953
step: 60, loss: 0.005289049353450537
step: 70, loss: 0.12916602194309235
step: 80, loss: 0.05797765776515007
step: 90, loss: 0.06777369976043701
step: 100, loss: 0.09705347567796707
step: 110, loss: 0.09595943242311478
step: 120, loss: 0.028956368565559387
step: 130, loss: 0.08647610992193222
step: 140, loss: 0.07549796998500824
step: 150, loss: 0.12931790947914124
step: 160, loss: 0.06387874484062195
step: 170, loss: 0.09215745329856873
step: 180, loss: 0.0819413959980011
step: 190, loss: 0.09372518211603165
step: 200, loss: 0.0005503778229467571
step: 210, loss: 0.03037925437092781
step: 220, loss: 0.00012242421507835388
step: 230, loss: 0.044313330203294754
step: 240, loss: 0.13384313881397247
step: 250, loss: 0.08243051171302795
step: 260, loss: 0.005638279486447573
step: 270, loss: 0.037739258259534836
step: 280, loss: 0.026192544028162956
step: 290, loss: 0.06936340779066086
step: 300, loss: 0.007861131802201271
step: 310, loss: 0.014163753017783165
step: 320, loss: 0.09336823970079422
step: 330, loss: 0.04454546421766281
step: 340, loss: 0.06619564443826675
step: 350, loss: 0.09435626864433289
step: 360, loss: 0.04275389760732651
step: 370, loss: 0.12473977357149124
step: 380, loss: 0.04892997816205025
step: 390, loss: 0.06129537895321846
step: 400, loss: 0.03419541195034981
step: 410, loss: 0.0011868454748764634
step: 420, loss: 0.044179484248161316
step: 430, loss: 0.05037849768996239
step: 440, loss: 0.12692615389823914
step: 450, loss: 0.0014208551729097962
step: 460, loss: 0.056336574256420135
step: 470, loss: 0.08203476667404175
step: 480, loss: 0.042385995388031006
step: 490, loss: 0.07862971723079681
step: 500, loss: 0.0961218774318695
step: 510, loss: 0.10527294874191284
step: 520, loss: 0.00044753076508641243
step: 530, loss: 0.06502540409564972
step: 540, loss: 0.053494974970817566
step: 550, loss: 0.09212084114551544
step: 560, loss: 0.10216034948825836
step: 570, loss: 0.09092897176742554
step: 580, loss: 0.09278438985347748
step: 590, loss: 0.024974070489406586
step: 600, loss: 0.04645303264260292
step: 610, loss: 0.06121999770402908
step: 620, loss: 0.04219707101583481
step: 630, loss: 0.06304490566253662
step: 640, loss: 0.0690462589263916
step: 650, loss: 0.09687761962413788
step: 660, loss: 0.03605661913752556
step: 670, loss: 0.14223772287368774
step: 680, loss: 0.08897870779037476
step: 690, loss: 0.10993350297212601
step: 700, loss: 0.0822133868932724
step: 710, loss: 0.04324796795845032
step: 720, loss: 0.08717986196279526
step: 730, loss: 0.12017833441495895
step: 740, loss: 0.07791683822870255
step: 750, loss: 0.067608542740345
step: 760, loss: 0.11333078145980835
step: 770, loss: 0.06358130276203156
step: 780, loss: 0.056480225175619125
step: 790, loss: 0.025987017899751663
step: 800, loss: 0.04740668833255768
step: 810, loss: 0.04987805709242821
step: 820, loss: 0.1332196593284607
step: 830, loss: 0.019488904625177383
step: 840, loss: 0.059416573494672775
step: 850, loss: 0.07699253410100937
step: 860, loss: 0.015656212344765663
step: 870, loss: 0.019343502819538116
step: 880, loss: 0.09776996821165085
step: 890, loss: 0.014881448820233345
step: 900, loss: 0.10173530876636505
step: 910, loss: 0.05176929011940956
step: 920, loss: 0.0412367545068264
step: 930, loss: 0.09978217631578445
step: 940, loss: 0.07639795541763306
step: 950, loss: 0.051442667841911316
step: 960, loss: 0.10585907101631165
step: 970, loss: 0.051894500851631165
step: 980, loss: 0.06164233013987541
step: 990, loss: 0.1685197949409485
step: 1000, loss: 0.049924831837415695
step: 1010, loss: 0.12545104324817657
step: 1020, loss: 0.04612956941127777
step: 1030, loss: 0.044225286692380905
step: 1040, loss: 0.055605221539735794
step: 1050, loss: 0.0024314874317497015
step: 1060, loss: 0.06168920919299126
step: 1070, loss: 0.08232590556144714
epoch 11: dev_f1=0.9274826789838336, f1=0.9277496548550391, best_f1=0.9295112781954888
step: 0, loss: 0.04338417947292328
step: 10, loss: 0.11502142250537872
step: 20, loss: 0.1113152876496315
step: 30, loss: 0.04814247414469719
step: 40, loss: 0.0572705939412117
step: 50, loss: 0.011661416850984097
step: 60, loss: 0.016267525032162666
step: 70, loss: 0.05287693440914154
step: 80, loss: 0.10095154494047165
step: 90, loss: 0.020734107121825218
step: 100, loss: 0.030893364921212196
step: 110, loss: 0.08199137449264526
step: 120, loss: 0.1337624490261078
step: 130, loss: 0.05821428820490837
step: 140, loss: 0.047571420669555664
step: 150, loss: 0.10547013580799103
step: 160, loss: 0.0486363060772419
step: 170, loss: 0.0001401738845743239
step: 180, loss: 0.09419688582420349
step: 190, loss: 0.07374051213264465
step: 200, loss: 0.03227997571229935
step: 210, loss: 0.057506263256073
step: 220, loss: 0.06669062376022339
step: 230, loss: 0.08740613609552383
step: 240, loss: 0.03825114667415619
step: 250, loss: 0.039797935634851456
step: 260, loss: 0.044539421796798706
step: 270, loss: 0.08219007402658463
step: 280, loss: 0.018874356523156166
step: 290, loss: 0.07970667630434036
step: 300, loss: 0.06775949150323868
step: 310, loss: 0.19581495225429535
step: 320, loss: 0.07231277227401733
step: 330, loss: 0.10411418974399567
step: 340, loss: 0.03585446625947952
step: 350, loss: 0.0893452912569046
step: 360, loss: 0.06644562631845474
step: 370, loss: 0.06952837854623795
step: 380, loss: 0.2286297082901001
step: 390, loss: 0.01598033681511879
step: 400, loss: 0.04343172162771225
step: 410, loss: 0.07465469092130661
step: 420, loss: 0.05455496534705162
step: 430, loss: 0.021372586488723755
step: 440, loss: 0.04233046621084213
step: 450, loss: 0.04046366736292839
step: 460, loss: 0.029289759695529938
step: 470, loss: 0.010713193565607071
step: 480, loss: 0.04018070548772812
step: 490, loss: 0.05052594095468521
step: 500, loss: 0.07956819236278534
step: 510, loss: 0.16208647191524506
step: 520, loss: 0.07568199932575226
step: 530, loss: 0.003911037929356098
step: 540, loss: 0.059118837118148804
step: 550, loss: 0.08108773082494736
step: 560, loss: 0.038934413343667984
step: 570, loss: 0.00842982716858387
step: 580, loss: 0.0447801910340786
step: 590, loss: 0.037521928548812866
step: 600, loss: 0.053593266755342484
step: 610, loss: 0.08996183425188065
step: 620, loss: 0.1289152055978775
step: 630, loss: 0.09129918366670609
step: 640, loss: 0.03496730327606201
step: 650, loss: 0.20196391642093658
step: 660, loss: 0.03932321071624756
step: 670, loss: 0.0670923963189125
step: 680, loss: 0.026668258011341095
step: 690, loss: 0.0047115846537053585
step: 700, loss: 0.06894746422767639
step: 710, loss: 0.05219798907637596
step: 720, loss: 0.06644798070192337
step: 730, loss: 0.04719219729304314
step: 740, loss: 0.023462675511837006
step: 750, loss: 0.19241324067115784
step: 760, loss: 0.09553094953298569
step: 770, loss: 0.07442371547222137
step: 780, loss: 0.10051362216472626
step: 790, loss: 0.1451946198940277
step: 800, loss: 0.07679608464241028
step: 810, loss: 0.06540963798761368
step: 820, loss: 0.02145540341734886
step: 830, loss: 0.07056574523448944
step: 840, loss: 0.09449781477451324
step: 850, loss: 0.05038836598396301
step: 860, loss: 0.05618642270565033
step: 870, loss: 0.13117928802967072
step: 880, loss: 0.035428550094366074
step: 890, loss: 0.09743687510490417
step: 900, loss: 0.13065195083618164
step: 910, loss: 0.03853142634034157
step: 920, loss: 0.061022453010082245
step: 930, loss: 0.042143527418375015
step: 940, loss: 0.03604928404092789
step: 950, loss: 0.047723300755023956
step: 960, loss: 0.05400094762444496
step: 970, loss: 0.1459406167268753
step: 980, loss: 0.06234182417392731
step: 990, loss: 0.03980494290590286
step: 1000, loss: 0.00025130301946774125
step: 1010, loss: 0.08693581819534302
step: 1020, loss: 0.03748137131333351
step: 1030, loss: 0.029786700382828712
step: 1040, loss: 0.011238948442041874
step: 1050, loss: 0.10198217630386353
step: 1060, loss: 0.13931027054786682
step: 1070, loss: 0.11715414375066757
epoch 12: dev_f1=0.9255419415645617, f1=0.9271028037383178, best_f1=0.9295112781954888
step: 0, loss: 0.06803803145885468
step: 10, loss: 0.07721482217311859
step: 20, loss: 0.05293137952685356
step: 30, loss: 0.027445876970887184
step: 40, loss: 0.07107891142368317
step: 50, loss: 0.0043112244457006454
step: 60, loss: 0.03792238608002663
step: 70, loss: 0.025746529921889305
step: 80, loss: 0.0665736272931099
step: 90, loss: 0.059475596994161606
step: 100, loss: 0.04699503257870674
step: 110, loss: 0.011478381231427193
step: 120, loss: 0.0848887488245964
step: 130, loss: 0.04430895671248436
step: 140, loss: 0.08934397995471954
step: 150, loss: 0.009731464087963104
step: 160, loss: 0.004445524420589209
step: 170, loss: 0.05024156719446182
step: 180, loss: 0.013024304062128067
step: 190, loss: 0.05638258159160614
step: 200, loss: 0.054852765053510666
step: 210, loss: 0.08173052221536636
step: 220, loss: 0.05895356088876724
step: 230, loss: 0.043550338596105576
step: 240, loss: 0.05059438571333885
step: 250, loss: 0.057243816554546356
step: 260, loss: 0.013387075625360012
step: 270, loss: 0.026277927681803703
step: 280, loss: 0.05924895033240318
step: 290, loss: 0.04654252156615257
step: 300, loss: 0.001179459854029119
step: 310, loss: 0.018215686082839966
step: 320, loss: 0.0361628383398056
step: 330, loss: 0.0011947969906032085
step: 340, loss: 0.05144312605261803
step: 350, loss: 0.009474880993366241
step: 360, loss: 0.013052348978817463
step: 370, loss: 0.0022556353360414505
step: 380, loss: 0.037998151034116745
step: 390, loss: 0.13217751681804657
step: 400, loss: 0.0207983311265707
step: 410, loss: 0.060135796666145325
step: 420, loss: 0.012957721017301083
step: 430, loss: 0.035484399646520615
step: 440, loss: 0.09399950504302979
step: 450, loss: 0.06143338978290558
step: 460, loss: 0.12745310366153717
step: 470, loss: 0.05811651796102524
step: 480, loss: 0.05805892497301102
step: 490, loss: 0.06359976530075073
step: 500, loss: 0.010530244559049606
step: 510, loss: 0.14783374965190887
step: 520, loss: 0.043615080416202545
step: 530, loss: 0.005045244004577398
step: 540, loss: 0.0923222228884697
step: 550, loss: 0.04062097892165184
step: 560, loss: 0.03769567608833313
step: 570, loss: 0.05283541977405548
step: 580, loss: 0.0629621371626854
step: 590, loss: 0.05983608216047287
step: 600, loss: 0.04830555245280266
step: 610, loss: 0.07417851686477661
step: 620, loss: 0.0800950899720192
step: 630, loss: 0.0436541885137558
step: 640, loss: 0.044230613857507706
step: 650, loss: 0.02416115626692772
step: 660, loss: 0.06675422936677933
step: 670, loss: 0.05279970541596413
step: 680, loss: 0.07316043227910995
step: 690, loss: 0.1105056032538414
step: 700, loss: 0.040743645280599594
step: 710, loss: 0.07002335041761398
step: 720, loss: 0.00022585992701351643
step: 730, loss: 0.07790692150592804
step: 740, loss: 0.01184262614697218
step: 750, loss: 0.06694432348012924
step: 760, loss: 0.040933214128017426
step: 770, loss: 0.08837351202964783
step: 780, loss: 0.09073764830827713
step: 790, loss: 0.0422578863799572
step: 800, loss: 0.060460470616817474
step: 810, loss: 0.02055300399661064
step: 820, loss: 0.02545718476176262
step: 830, loss: 0.10591959953308105
step: 840, loss: 0.015839723870158195
step: 850, loss: 0.005382318049669266
step: 860, loss: 0.04997212439775467
step: 870, loss: 0.011851567775011063
step: 880, loss: 0.015869591385126114
step: 890, loss: 0.01906209997832775
step: 900, loss: 0.05599989369511604
step: 910, loss: 0.06581319868564606
step: 920, loss: 0.022230079397559166
step: 930, loss: 0.0025121073704212904
step: 940, loss: 0.028420578688383102
step: 950, loss: 0.00024738151114434004
step: 960, loss: 0.08172406256198883
step: 970, loss: 0.019022749736905098
step: 980, loss: 4.952890958520584e-05
step: 990, loss: 0.07358118146657944
step: 1000, loss: 0.07142864912748337
step: 1010, loss: 0.11113010346889496
step: 1020, loss: 0.02328203245997429
step: 1030, loss: 0.07911770790815353
step: 1040, loss: 0.07002495974302292
step: 1050, loss: 0.06618648022413254
step: 1060, loss: 0.04013076052069664
step: 1070, loss: 0.04345899820327759
epoch 13: dev_f1=0.9242212924221292, f1=0.9242843951985227, best_f1=0.9295112781954888
step: 0, loss: 0.0593516007065773
step: 10, loss: 0.01705666072666645
step: 20, loss: 0.053391218185424805
step: 30, loss: 0.13579213619232178
step: 40, loss: 0.04024704173207283
step: 50, loss: 0.0806540921330452
step: 60, loss: 0.040850840508937836
step: 70, loss: 0.06209801137447357
step: 80, loss: 0.05062384903430939
step: 90, loss: 0.03783629834651947
step: 100, loss: 0.02562340721487999
step: 110, loss: 0.09661503881216049
step: 120, loss: 0.1301843822002411
step: 130, loss: 0.10080887377262115
step: 140, loss: 0.11849101632833481
step: 150, loss: 0.05109953135251999
step: 160, loss: 0.022274678573012352
step: 170, loss: 0.15244801342487335
step: 180, loss: 0.06214927136898041
step: 190, loss: 0.06674015522003174
step: 200, loss: 0.015417860820889473
step: 210, loss: 0.012493886053562164
step: 220, loss: 0.02601948007941246
step: 230, loss: 0.028593232855200768
step: 240, loss: 0.046494051814079285
step: 250, loss: 0.04364900663495064
step: 260, loss: 0.019469792023301125
step: 270, loss: 0.044754426926374435
step: 280, loss: 0.037817008793354034
step: 290, loss: 0.03198662027716637
step: 300, loss: 0.1013299748301506
step: 310, loss: 0.05195019394159317
step: 320, loss: 0.0014356236206367612
step: 330, loss: 0.0165728647261858
step: 340, loss: 0.03471070155501366
step: 350, loss: 0.08817246556282043
step: 360, loss: 0.04225010797381401
step: 370, loss: 0.025622088462114334
step: 380, loss: 0.06610989570617676
step: 390, loss: 0.048128072172403336
step: 400, loss: 0.0758502408862114
step: 410, loss: 0.09864173829555511
step: 420, loss: 0.04533838853240013
step: 430, loss: 0.01911853812634945
step: 440, loss: 0.11092989146709442
step: 450, loss: 0.040318720042705536
step: 460, loss: 0.0350768156349659
step: 470, loss: 0.011926967650651932
step: 480, loss: 0.09557978063821793
step: 490, loss: 0.047297216951847076
step: 500, loss: 0.09226084500551224
step: 510, loss: 0.05734105408191681
step: 520, loss: 0.036434996873140335
step: 530, loss: 0.07131898403167725
step: 540, loss: 0.04168926179409027
step: 550, loss: 0.11193384975194931
step: 560, loss: 0.04284968972206116
step: 570, loss: 0.000997304916381836
step: 580, loss: 0.07537627965211868
step: 590, loss: 0.06187683343887329
step: 600, loss: 0.11833962053060532
step: 610, loss: 0.023346491158008575
step: 620, loss: 0.03104332834482193
step: 630, loss: 0.01453336514532566
step: 640, loss: 0.0331621877849102
step: 650, loss: 0.06415651738643646
step: 660, loss: 0.08304604142904282
step: 670, loss: 0.10717938840389252
step: 680, loss: 0.013138827867805958
step: 690, loss: 0.010310391895473003
step: 700, loss: 0.026509560644626617
step: 710, loss: 0.034576281905174255
step: 720, loss: 0.042397819459438324
step: 730, loss: 0.058598123490810394
step: 740, loss: 0.1356429010629654
step: 750, loss: 0.03146229311823845
step: 760, loss: 0.08010076731443405
step: 770, loss: 0.06690944731235504
step: 780, loss: 0.023854674771428108
step: 790, loss: 0.06837523728609085
step: 800, loss: 0.0365748293697834
step: 810, loss: 0.0794999822974205
step: 820, loss: 0.00013573044270742685
step: 830, loss: 0.045902375131845474
step: 840, loss: 0.060221560299396515
step: 850, loss: 0.06143854185938835
step: 860, loss: 0.06781864166259766
step: 870, loss: 0.05070161074399948
step: 880, loss: 0.05812644213438034
step: 890, loss: 0.0478673093020916
step: 900, loss: 0.08966900408267975
step: 910, loss: 0.07337282598018646
step: 920, loss: 0.029548000544309616
step: 930, loss: 0.06059863418340683
step: 940, loss: 0.023840539157390594
step: 950, loss: 0.10264972597360611
step: 960, loss: 0.15173344314098358
step: 970, loss: 0.0944027453660965
step: 980, loss: 0.057457614690065384
step: 990, loss: 0.059348493814468384
step: 1000, loss: 0.10961122065782547
step: 1010, loss: 0.08989875018596649
step: 1020, loss: 0.023889662697911263
step: 1030, loss: 0.08601950854063034
step: 1040, loss: 0.1330719292163849
step: 1050, loss: 0.023775622248649597
step: 1060, loss: 0.012256056070327759
step: 1070, loss: 0.052367202937603
epoch 14: dev_f1=0.9248501613646842, f1=0.9261128958237724, best_f1=0.9295112781954888
step: 0, loss: 0.03133411332964897
step: 10, loss: 0.04457478225231171
step: 20, loss: 0.042414598166942596
step: 30, loss: 0.05538914352655411
step: 40, loss: 0.04709338769316673
step: 50, loss: 0.044448371976614
step: 60, loss: 0.002656505210325122
step: 70, loss: 0.06452146172523499
step: 80, loss: 0.0718555748462677
step: 90, loss: 0.04325689747929573
step: 100, loss: 0.06451179832220078
step: 110, loss: 0.058317430317401886
step: 120, loss: 1.0713861229305621e-05
step: 130, loss: 0.06469400972127914
step: 140, loss: 0.03667071834206581
step: 150, loss: 0.07917290180921555
step: 160, loss: 0.07519930601119995
step: 170, loss: 0.02192690409719944
step: 180, loss: 0.06806688755750656
step: 190, loss: 0.0657745972275734
step: 200, loss: 0.014206374995410442
step: 210, loss: 0.0243433378636837
step: 220, loss: 0.054967351257801056
step: 230, loss: 0.014396575279533863
step: 240, loss: 0.09515545517206192
step: 250, loss: 0.09976904839277267
step: 260, loss: 0.036762531846761703
step: 270, loss: 0.04063893482089043
step: 280, loss: 0.007654610089957714
step: 290, loss: 0.11132896691560745
step: 300, loss: 0.11650453507900238
step: 310, loss: 0.04890156164765358
step: 320, loss: 0.05113409087061882
step: 330, loss: 0.011445819400250912
step: 340, loss: 0.12959086894989014
step: 350, loss: 0.03704237565398216
step: 360, loss: 0.051671698689460754
step: 370, loss: 0.036984674632549286
step: 380, loss: 0.0703129991889
step: 390, loss: 0.07428628951311111
step: 400, loss: 0.030920272693037987
step: 410, loss: 0.016365351155400276
step: 420, loss: 0.06073739752173424
step: 430, loss: 0.07977457344532013
step: 440, loss: 0.0863942876458168
step: 450, loss: 0.14803087711334229
step: 460, loss: 0.016447339206933975
step: 470, loss: 0.019636161625385284
step: 480, loss: 0.09453051537275314
step: 490, loss: 0.015836095437407494
step: 500, loss: 0.05686844140291214
step: 510, loss: 0.10483261942863464
step: 520, loss: 0.09215662628412247
step: 530, loss: 0.05137483403086662
step: 540, loss: 0.026269201189279556
step: 550, loss: 0.00010306943295290694
step: 560, loss: 0.05460178852081299
step: 570, loss: 0.07995593547821045
step: 580, loss: 0.06941226869821548
step: 590, loss: 0.029390186071395874
step: 600, loss: 0.10056114196777344
step: 610, loss: 0.10288716107606888
step: 620, loss: 0.021760446950793266
step: 630, loss: 0.053849294781684875
step: 640, loss: 0.054039619863033295
step: 650, loss: 0.0670810341835022
step: 660, loss: 0.030614977702498436
step: 670, loss: 0.038184911012649536
step: 680, loss: 0.04463918134570122
step: 690, loss: 0.04866014048457146
step: 700, loss: 0.03687857463955879
step: 710, loss: 0.05279814451932907
step: 720, loss: 0.032488271594047546
step: 730, loss: 0.06733644008636475
step: 740, loss: 0.015138234943151474
step: 750, loss: 0.053363289684057236
step: 760, loss: 0.05998510122299194
step: 770, loss: 0.09561238437891006
step: 780, loss: 0.09781394153833389
step: 790, loss: 0.02034635841846466
step: 800, loss: 0.12944847345352173
step: 810, loss: 0.0010230415500700474
step: 820, loss: 0.09006570279598236
step: 830, loss: 0.08504690229892731
step: 840, loss: 0.05376387760043144
step: 850, loss: 0.03566977381706238
step: 860, loss: 0.10787523537874222
step: 870, loss: 0.11413633823394775
step: 880, loss: 0.16594336926937103
step: 890, loss: 0.08853047341108322
step: 900, loss: 0.01803584024310112
step: 910, loss: 0.20386463403701782
step: 920, loss: 0.0708923265337944
step: 930, loss: 0.00020117484382353723
step: 940, loss: 0.03746245801448822
step: 950, loss: 0.09660014510154724
step: 960, loss: 0.021654753014445305
step: 970, loss: 0.03584218770265579
step: 980, loss: 0.06059453636407852
step: 990, loss: 0.0067052338272333145
step: 1000, loss: 0.07743550837039948
step: 1010, loss: 0.08431530743837357
step: 1020, loss: 0.042705412954092026
step: 1030, loss: 0.025201864540576935
step: 1040, loss: 0.05848807096481323
step: 1050, loss: 0.009262507781386375
step: 1060, loss: 0.08416130393743515
step: 1070, loss: 0.017609186470508575
epoch 15: dev_f1=0.9261176470588235, f1=0.9227889564810482, best_f1=0.9295112781954888
step: 0, loss: 0.02517770789563656
step: 10, loss: 0.05417149141430855
step: 20, loss: 0.022800497710704803
step: 30, loss: 0.10074514150619507
step: 40, loss: 0.021049844101071358
step: 50, loss: 0.03766612336039543
step: 60, loss: 0.009940840303897858
step: 70, loss: 0.1061476618051529
step: 80, loss: 0.05946062505245209
step: 90, loss: 0.017740927636623383
step: 100, loss: 0.04835980013012886
step: 110, loss: 0.0720980316400528
step: 120, loss: 6.868694617878646e-05
step: 130, loss: 0.05416501313447952
step: 140, loss: 0.07333835959434509
step: 150, loss: 0.03467812389135361
step: 160, loss: 0.05268920585513115
step: 170, loss: 0.05083081126213074
step: 180, loss: 0.02946327067911625
step: 190, loss: 0.05278856307268143
step: 200, loss: 0.014078856445848942
step: 210, loss: 0.07602886110544205
step: 220, loss: 0.05648408830165863
step: 230, loss: 0.024507226422429085
step: 240, loss: 0.014145385473966599
step: 250, loss: 0.06575612723827362
step: 260, loss: 0.009987588040530682
step: 270, loss: 0.016905371099710464
step: 280, loss: 0.029409486800432205
step: 290, loss: 0.0826849713921547
step: 300, loss: 0.013419758528470993
step: 310, loss: 0.06734906882047653
step: 320, loss: 0.044759590178728104
step: 330, loss: 0.024319594725966454
step: 340, loss: 0.05079343914985657
step: 350, loss: 0.07287704199552536
step: 360, loss: 0.08954239636659622
step: 370, loss: 0.08895431458950043
step: 380, loss: 0.05953376367688179
step: 390, loss: 0.0778718963265419
step: 400, loss: 0.014662149362266064
step: 410, loss: 0.05804881826043129
step: 420, loss: 0.12110961228609085
step: 430, loss: 0.051586270332336426
step: 440, loss: 0.0020647733472287655
step: 450, loss: 0.13752058148384094
step: 460, loss: 0.06519411504268646
step: 470, loss: 0.05591204762458801
step: 480, loss: 0.015786319971084595
step: 490, loss: 0.02316555753350258
step: 500, loss: 0.07890923321247101
step: 510, loss: 8.217360300477594e-05
step: 520, loss: 0.05246274918317795
step: 530, loss: 0.0832880437374115
step: 540, loss: 0.05469482019543648
step: 550, loss: 0.022940710186958313
step: 560, loss: 0.05940072610974312
step: 570, loss: 0.045719608664512634
step: 580, loss: 0.03279946371912956
step: 590, loss: 0.020411765202879906
step: 600, loss: 0.00011306093074381351
step: 610, loss: 0.03287596255540848
step: 620, loss: 0.024640358984470367
step: 630, loss: 0.043931204825639725
step: 640, loss: 0.021878313273191452
step: 650, loss: 0.00019771356892306358
step: 660, loss: 6.538104935316369e-05
step: 670, loss: 0.01357959397137165
step: 680, loss: 0.027077246457338333
step: 690, loss: 0.08647220581769943
step: 700, loss: 0.08100327104330063
step: 710, loss: 0.036465127021074295
step: 720, loss: 0.04522334411740303
step: 730, loss: 0.07273149490356445
step: 740, loss: 0.0317474827170372
step: 750, loss: 0.029610414057970047
step: 760, loss: 0.07472243905067444
step: 770, loss: 0.04966481402516365
step: 780, loss: 0.03822110593318939
step: 790, loss: 0.039814986288547516
step: 800, loss: 1.1037933290936053e-05
step: 810, loss: 0.11514096707105637
step: 820, loss: 0.0901719406247139
step: 830, loss: 0.004073565360158682
step: 840, loss: 0.003839470911771059
step: 850, loss: 0.07203198224306107
step: 860, loss: 0.0822041928768158
step: 870, loss: 0.040123943239450455
step: 880, loss: 0.03580699861049652
step: 890, loss: 0.09104224294424057
step: 900, loss: 0.09165646135807037
step: 910, loss: 0.011826302856206894
step: 920, loss: 0.07313132286071777
step: 930, loss: 0.11704830825328827
step: 940, loss: 0.06832093745470047
step: 950, loss: 0.0005891869659535587
step: 960, loss: 0.00010966197442030534
step: 970, loss: 0.020069660618901253
step: 980, loss: 0.14751222729682922
step: 990, loss: 0.005429169628769159
step: 1000, loss: 0.08144763857126236
step: 1010, loss: 0.05718446895480156
step: 1020, loss: 0.031489890068769455
step: 1030, loss: 0.039007239043712616
step: 1040, loss: 0.15761186182498932
step: 1050, loss: 0.009481655433773994
step: 1060, loss: 0.0463968925178051
step: 1070, loss: 0.035644903779029846
epoch 16: dev_f1=0.9245719574271172, f1=0.9243542435424354, best_f1=0.9295112781954888
step: 0, loss: 0.0902160033583641
step: 10, loss: 0.08326314389705658
step: 20, loss: 0.04587249830365181
step: 30, loss: 0.03448802977800369
step: 40, loss: 0.10583005100488663
step: 50, loss: 7.661041308892891e-05
step: 60, loss: 0.04997352883219719
step: 70, loss: 0.08890485763549805
step: 80, loss: 2.3341126507148147e-05
step: 90, loss: 0.008036094717681408
step: 100, loss: 0.09536527097225189
step: 110, loss: 0.03825780004262924
step: 120, loss: 0.07421258836984634
step: 130, loss: 0.055112168192863464
step: 140, loss: 0.03617246076464653
step: 150, loss: 0.04254641756415367
step: 160, loss: 0.03888494521379471
step: 170, loss: 0.03345070779323578
step: 180, loss: 0.022414440289139748
step: 190, loss: 0.07461590319871902
step: 200, loss: 0.05301565304398537
step: 210, loss: 0.06264512985944748
step: 220, loss: 0.07662861049175262
step: 230, loss: 0.02327287197113037
step: 240, loss: 0.09038275480270386
step: 250, loss: 0.022323910146951675
step: 260, loss: 0.04245719686150551
step: 270, loss: 0.12700366973876953
step: 280, loss: 0.02062712423503399
step: 290, loss: 0.03937878832221031
step: 300, loss: 0.08840921521186829
step: 310, loss: 0.09384574741125107
step: 320, loss: 2.3637096091988496e-05
step: 330, loss: 0.03989175334572792
step: 340, loss: 0.0668133795261383
step: 350, loss: 0.0596565417945385
step: 360, loss: 0.023189064115285873
step: 370, loss: 0.02944738231599331
step: 380, loss: 0.04798096418380737
step: 390, loss: 0.008811138570308685
step: 400, loss: 0.0881267786026001
step: 410, loss: 0.05063964053988457
step: 420, loss: 0.04070107266306877
step: 430, loss: 0.025024225935339928
step: 440, loss: 2.290503471158445e-05
step: 450, loss: 0.07106959819793701
step: 460, loss: 1.9187464204151183e-05
step: 470, loss: 0.0937783494591713
step: 480, loss: 0.05635571479797363
step: 490, loss: 0.04559043049812317
step: 500, loss: 0.03905142843723297
step: 510, loss: 0.16600513458251953
step: 520, loss: 0.031507231295108795
step: 530, loss: 0.07281560450792313
step: 540, loss: 0.007016164716333151
step: 550, loss: 0.0015956433489918709
step: 560, loss: 0.04264732450246811
step: 570, loss: 0.045341622084379196
step: 580, loss: 0.04748905822634697
step: 590, loss: 0.044452667236328125
step: 600, loss: 0.008861038833856583
step: 610, loss: 0.05595053732395172
step: 620, loss: 0.027883267030119896
step: 630, loss: 0.0015602207276970148
step: 640, loss: 0.07344016432762146
step: 650, loss: 0.03934628888964653
step: 660, loss: 0.0010293072555214167
step: 670, loss: 0.04797738417983055
step: 680, loss: 0.031637854874134064
step: 690, loss: 0.09486415237188339
step: 700, loss: 0.04291262850165367
step: 710, loss: 0.0005458045634441078
step: 720, loss: 0.0893453061580658
step: 730, loss: 0.048548053950071335
step: 740, loss: 0.028406420722603798
step: 750, loss: 0.053203973919153214
step: 760, loss: 0.08184944838285446
step: 770, loss: 0.030125770717859268
step: 780, loss: 0.06545023620128632
step: 790, loss: 0.023204639554023743
step: 800, loss: 0.08384893089532852
step: 810, loss: 0.050087545067071915
step: 820, loss: 0.06026044860482216
step: 830, loss: 0.07755950093269348
step: 840, loss: 0.039458852261304855
step: 850, loss: 0.057233069092035294
step: 860, loss: 0.01819113828241825
step: 870, loss: 0.027905331924557686
step: 880, loss: 0.011581572704017162
step: 890, loss: 0.04340340569615364
step: 900, loss: 0.012428074143826962
step: 910, loss: 0.08726689219474792
step: 920, loss: 0.02543783374130726
step: 930, loss: 0.06082139164209366
step: 940, loss: 0.03360346332192421
step: 950, loss: 0.11033061146736145
step: 960, loss: 0.01796763576567173
step: 970, loss: 0.05690141022205353
step: 980, loss: 0.03533784672617912
step: 990, loss: 0.06155460700392723
step: 1000, loss: 0.062018439173698425
step: 1010, loss: 0.11094929277896881
step: 1020, loss: 0.07236254215240479
step: 1030, loss: 0.01863388903439045
step: 1040, loss: 0.04915590211749077
step: 1050, loss: 0.011294540949165821
step: 1060, loss: 0.004301018547266722
step: 1070, loss: 0.059543199837207794
epoch 17: dev_f1=0.922425952045134, f1=0.923943661971831, best_f1=0.9295112781954888
step: 0, loss: 0.03833233192563057
step: 10, loss: 0.01077646017074585
step: 20, loss: 0.04841415584087372
step: 30, loss: 0.021014895290136337
step: 40, loss: 0.03742435947060585
step: 50, loss: 0.0588686540722847
step: 60, loss: 0.009125713258981705
step: 70, loss: 0.058728139847517014
step: 80, loss: 0.013245301321148872
step: 90, loss: 0.04121924936771393
step: 100, loss: 0.09440463781356812
step: 110, loss: 5.344108649296686e-05
step: 120, loss: 0.05036541074514389
step: 130, loss: 3.376241511432454e-05
step: 140, loss: 0.04557797685265541
step: 150, loss: 0.0805608481168747
step: 160, loss: 0.05900774151086807
step: 170, loss: 0.023577777668833733
step: 180, loss: 0.029376287013292313
step: 190, loss: 0.04595022276043892
step: 200, loss: 0.06436911225318909
step: 210, loss: 0.04344695061445236
step: 220, loss: 0.04139038920402527
step: 230, loss: 0.043524764478206635
step: 240, loss: 0.02457495406270027
step: 250, loss: 0.05755171552300453
step: 260, loss: 0.10194556415081024
step: 270, loss: 0.00024239651975221932
step: 280, loss: 0.0632103756070137
step: 290, loss: 0.07173553109169006
step: 300, loss: 0.04943566024303436
step: 310, loss: 0.08020585775375366
step: 320, loss: 0.031306955963373184
step: 330, loss: 2.559303720772732e-05
step: 340, loss: 0.030915185809135437
step: 350, loss: 0.029084187000989914
step: 360, loss: 0.04608192294836044
step: 370, loss: 0.046224113553762436
step: 380, loss: 0.02537374570965767
step: 390, loss: 0.05545791983604431
step: 400, loss: 0.06418013572692871
step: 410, loss: 0.042096223682165146
step: 420, loss: 8.418894867645577e-05
step: 430, loss: 0.02090352587401867
step: 440, loss: 0.09632936865091324
step: 450, loss: 0.05371636152267456
step: 460, loss: 0.04683807119727135
step: 470, loss: 0.029054952785372734
step: 480, loss: 0.06257982552051544
step: 490, loss: 0.029939763247966766
step: 500, loss: 0.04210255295038223
step: 510, loss: 0.014718693681061268
step: 520, loss: 0.044299669563770294
step: 530, loss: 0.04293425753712654
step: 540, loss: 0.0763094499707222
step: 550, loss: 0.03957756608724594
step: 560, loss: 0.06486447155475616
step: 570, loss: 7.527832349296659e-05
step: 580, loss: 0.04669887572526932
step: 590, loss: 0.03002006560564041
step: 600, loss: 0.022551435977220535
step: 610, loss: 0.059185728430747986
step: 620, loss: 0.031490929424762726
step: 630, loss: 0.055833686143159866
step: 640, loss: 0.07629299908876419
step: 650, loss: 0.01735716499388218
step: 660, loss: 0.016774063929915428
step: 670, loss: 0.04601198062300682
step: 680, loss: 0.03935951739549637
step: 690, loss: 0.05385328829288483
step: 700, loss: 0.04459686577320099
step: 710, loss: 0.053174491971731186
step: 720, loss: 0.042828187346458435
step: 730, loss: 0.04668480157852173
step: 740, loss: 0.021723907440900803
step: 750, loss: 0.011113345623016357
step: 760, loss: 0.05019139125943184
step: 770, loss: 0.08050312846899033
step: 780, loss: 0.05698723345994949
step: 790, loss: 0.024292653426527977
step: 800, loss: 0.03689371421933174
step: 810, loss: 0.006661071442067623
step: 820, loss: 0.0012012418592348695
step: 830, loss: 0.038118522614240646
step: 840, loss: 0.04422343149781227
step: 850, loss: 0.017154235392808914
step: 860, loss: 0.08432208001613617
step: 870, loss: 0.07646355777978897
step: 880, loss: 0.004219363443553448
step: 890, loss: 0.059816427528858185
step: 900, loss: 0.03574468940496445
step: 910, loss: 0.03545431047677994
step: 920, loss: 0.027461370453238487
step: 930, loss: 0.026726892217993736
step: 940, loss: 0.07940587401390076
step: 950, loss: 0.02824024111032486
step: 960, loss: 0.03703922778367996
step: 970, loss: 0.05425138771533966
step: 980, loss: 0.016267769038677216
step: 990, loss: 0.031097397208213806
step: 1000, loss: 0.08750993013381958
step: 1010, loss: 0.030259892344474792
step: 1020, loss: 0.0018061896553263068
step: 1030, loss: 0.06427192687988281
step: 1040, loss: 0.02124292403459549
step: 1050, loss: 7.067453407216817e-05
step: 1060, loss: 0.01621759496629238
step: 1070, loss: 0.016183890402317047
epoch 18: dev_f1=0.923943661971831, f1=0.9227889564810482, best_f1=0.9295112781954888
step: 0, loss: 0.01627921871840954
step: 10, loss: 0.045716069638729095
step: 20, loss: 0.04474781081080437
step: 30, loss: 0.06219753995537758
step: 40, loss: 5.546154352487065e-05
step: 50, loss: 0.10448439419269562
step: 60, loss: 0.023979516699910164
step: 70, loss: 0.07012630999088287
step: 80, loss: 4.4854710722574964e-05
step: 90, loss: 0.041477084159851074
step: 100, loss: 0.03050478920340538
step: 110, loss: 0.10482645034790039
step: 120, loss: 1.4885636119288392e-05
step: 130, loss: 0.05638197809457779
step: 140, loss: 0.0013455867301672697
step: 150, loss: 0.01722174882888794
step: 160, loss: 0.03271991387009621
step: 170, loss: 0.071387879550457
step: 180, loss: 0.027771547436714172
step: 190, loss: 0.024136200547218323
step: 200, loss: 0.11021117866039276
step: 210, loss: 0.0682496502995491
step: 220, loss: 0.021596379578113556
step: 230, loss: 0.04580357298254967
step: 240, loss: 0.062105633318424225
step: 250, loss: 0.06725440919399261
step: 260, loss: 0.01755695976316929
step: 270, loss: 0.038830410689115524
step: 280, loss: 0.03937549144029617
step: 290, loss: 0.0456758588552475
step: 300, loss: 0.048788510262966156
step: 310, loss: 0.029211759567260742
step: 320, loss: 0.020328249782323837
step: 330, loss: 0.008302814327180386
step: 340, loss: 0.04356061667203903
step: 350, loss: 0.00015166544471867383
step: 360, loss: 0.004922671243548393
step: 370, loss: 0.06763175129890442
step: 380, loss: 0.02557733841240406
step: 390, loss: 0.04801516607403755
step: 400, loss: 0.13646267354488373
step: 410, loss: 6.923010369064286e-05
step: 420, loss: 0.006219128146767616
step: 430, loss: 0.04255014285445213
step: 440, loss: 2.9960941901663318e-05
step: 450, loss: 0.037110716104507446
step: 460, loss: 0.02020697295665741
step: 470, loss: 0.14863073825836182
step: 480, loss: 0.05197786167263985
step: 490, loss: 5.182376116863452e-05
step: 500, loss: 0.05211355909705162
step: 510, loss: 0.02187781222164631
step: 520, loss: 0.03700995072722435
step: 530, loss: 0.013231911696493626
step: 540, loss: 0.0292055681347847
step: 550, loss: 0.049646977335214615
step: 560, loss: 0.15589725971221924
step: 570, loss: 0.00777131924405694
step: 580, loss: 0.0006290340097621083
step: 590, loss: 0.00029037526110187173
step: 600, loss: 0.011163131333887577
step: 610, loss: 0.023850031197071075
step: 620, loss: 0.00024483160814270377
step: 630, loss: 0.09897809475660324
step: 640, loss: 0.07385144382715225
step: 650, loss: 0.03814882040023804
step: 660, loss: 0.13452762365341187
step: 670, loss: 0.033328186720609665
step: 680, loss: 0.0014573609223589301
step: 690, loss: 0.049695950001478195
step: 700, loss: 0.04450996592640877
step: 710, loss: 0.09807602316141129
step: 720, loss: 0.023522717878222466
step: 730, loss: 0.018732717260718346
step: 740, loss: 0.02769230492413044
step: 750, loss: 0.002091974951326847
step: 760, loss: 0.02548949420452118
step: 770, loss: 0.03614123910665512
step: 780, loss: 2.7675983801600523e-05
step: 790, loss: 0.04664243757724762
step: 800, loss: 0.05148391053080559
step: 810, loss: 0.0071499464102089405
step: 820, loss: 0.007916959933936596
step: 830, loss: 0.0033554336987435818
step: 840, loss: 0.014155206270515919
step: 850, loss: 0.08684201538562775
step: 860, loss: 0.04159523546695709
step: 870, loss: 0.056563884019851685
step: 880, loss: 0.05732697620987892
step: 890, loss: 0.04768236726522446
step: 900, loss: 0.08124908059835434
step: 910, loss: 0.014183863997459412
step: 920, loss: 0.06746501475572586
step: 930, loss: 0.03592730686068535
step: 940, loss: 0.08550383150577545
step: 950, loss: 0.034547679126262665
step: 960, loss: 0.026656445115804672
step: 970, loss: 0.05328981205821037
step: 980, loss: 0.04152115434408188
step: 990, loss: 0.05964256078004837
step: 1000, loss: 0.06919984519481659
step: 1010, loss: 0.017715128138661385
step: 1020, loss: 0.059669774025678635
step: 1030, loss: 0.019768139347434044
step: 1040, loss: 0.036526355892419815
step: 1050, loss: 0.04205514118075371
step: 1060, loss: 8.20346103864722e-05
step: 1070, loss: 0.0632406622171402
epoch 19: dev_f1=0.9245194561650257, f1=0.922138836772983, best_f1=0.9295112781954888
step: 0, loss: 9.184006921714172e-05
step: 10, loss: 0.028909999877214432
step: 20, loss: 0.019282007589936256
step: 30, loss: 0.07706502825021744
step: 40, loss: 0.04374460130929947
step: 50, loss: 0.04099039360880852
step: 60, loss: 0.03949630260467529
step: 70, loss: 0.032568782567977905
step: 80, loss: 0.07173879444599152
step: 90, loss: 0.019216414541006088
step: 100, loss: 0.09168647229671478
step: 110, loss: 0.12916652858257294
step: 120, loss: 0.09659197181463242
step: 130, loss: 0.06692314893007278
step: 140, loss: 0.06376229971647263
step: 150, loss: 0.061614055186510086
step: 160, loss: 0.07576924562454224
step: 170, loss: 0.08994532376527786
step: 180, loss: 0.07346800714731216
step: 190, loss: 0.035442668944597244
step: 200, loss: 3.711161480168812e-05
step: 210, loss: 0.047308195382356644
step: 220, loss: 0.04736277088522911
step: 230, loss: 0.057843759655952454
step: 240, loss: 0.012912977486848831
step: 250, loss: 0.0502750501036644
step: 260, loss: 0.018730008974671364
step: 270, loss: 2.4948301870608702e-05
step: 280, loss: 1.3149749975127634e-05
step: 290, loss: 0.08651438355445862
step: 300, loss: 0.031901199370622635
step: 310, loss: 0.01283770240843296
step: 320, loss: 0.10732579976320267
step: 330, loss: 0.04782550036907196
step: 340, loss: 0.014606176875531673
step: 350, loss: 0.04258057475090027
step: 360, loss: 0.049009330570697784
step: 370, loss: 0.008271533064544201
step: 380, loss: 0.04543665051460266
step: 390, loss: 0.02677777409553528
step: 400, loss: 0.10735352337360382
step: 410, loss: 0.06440220028162003
step: 420, loss: 0.05365300551056862
step: 430, loss: 0.020761433988809586
step: 440, loss: 0.05889632925391197
step: 450, loss: 0.08663085103034973
step: 460, loss: 0.060301512479782104
step: 470, loss: 0.11330399662256241
step: 480, loss: 0.0004502519150264561
step: 490, loss: 0.05115612596273422
step: 500, loss: 0.010606366209685802
step: 510, loss: 0.02638930268585682
step: 520, loss: 0.09637292474508286
step: 530, loss: 4.4074709876440465e-05
step: 540, loss: 0.08646075427532196
step: 550, loss: 0.029969627037644386
step: 560, loss: 0.05336357653141022
step: 570, loss: 0.06888437271118164
step: 580, loss: 0.055320825427770615
step: 590, loss: 1.5693449313403107e-05
step: 600, loss: 0.07059470564126968
step: 610, loss: 0.05638796463608742
step: 620, loss: 0.046941258013248444
step: 630, loss: 0.019895097240805626
step: 640, loss: 0.04814818501472473
step: 650, loss: 0.02481762133538723
step: 660, loss: 0.039544686675071716
step: 670, loss: 0.0012058757711201906
step: 680, loss: 0.043230608105659485
step: 690, loss: 0.011533553712069988
step: 700, loss: 0.074471116065979
step: 710, loss: 0.039868053048849106
step: 720, loss: 0.010801227763295174
step: 730, loss: 0.06461305171251297
step: 740, loss: 0.0743359848856926
step: 750, loss: 0.02645851857960224
step: 760, loss: 0.025740882381796837
step: 770, loss: 0.016116835176944733
step: 780, loss: 0.02464268170297146
step: 790, loss: 0.0036894145887345076
step: 800, loss: 0.03013906069099903
step: 810, loss: 0.022610120475292206
step: 820, loss: 0.019748885184526443
step: 830, loss: 0.05785374343395233
step: 840, loss: 8.273370622191578e-05
step: 850, loss: 0.057922400534152985
step: 860, loss: 0.01203866582363844
step: 870, loss: 0.010239011608064175
step: 880, loss: 0.022230420261621475
step: 890, loss: 0.02865247055888176
step: 900, loss: 0.016307838261127472
step: 910, loss: 0.018225079402327538
step: 920, loss: 0.04938120394945145
step: 930, loss: 0.10647954046726227
step: 940, loss: 0.04362642019987106
step: 950, loss: 0.00010698540427256376
step: 960, loss: 0.0508565679192543
step: 970, loss: 0.010804349556565285
step: 980, loss: 0.014083599671721458
step: 990, loss: 0.017969822511076927
step: 1000, loss: 0.025515040382742882
step: 1010, loss: 0.0182904452085495
step: 1020, loss: 0.0005443764384835958
step: 1030, loss: 0.041845548897981644
step: 1040, loss: 0.011461771093308926
step: 1050, loss: 0.08341476321220398
step: 1060, loss: 0.07244740426540375
step: 1070, loss: 0.05530116334557533
epoch 20: dev_f1=0.9251764705882354, f1=0.9211267605633803, best_f1=0.9295112781954888
