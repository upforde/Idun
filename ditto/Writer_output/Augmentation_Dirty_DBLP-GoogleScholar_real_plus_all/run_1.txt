cuda
Device: cuda
step: 0, loss: 0.8350692987442017
step: 10, loss: 0.3705959916114807
step: 20, loss: 0.4785141348838806
step: 30, loss: 0.3688628673553467
step: 40, loss: 0.35430896282196045
step: 50, loss: 0.5343631505966187
step: 60, loss: 0.21509166061878204
step: 70, loss: 0.16470777988433838
step: 80, loss: 0.30772829055786133
step: 90, loss: 0.26699987053871155
step: 100, loss: 0.10880238562822342
step: 110, loss: 0.15227213501930237
step: 120, loss: 0.22377121448516846
step: 130, loss: 0.19261480867862701
step: 140, loss: 0.2219332605600357
step: 150, loss: 0.16705630719661713
step: 160, loss: 0.11892976611852646
step: 170, loss: 0.18954145908355713
step: 180, loss: 0.24579298496246338
step: 190, loss: 0.20059195160865784
step: 200, loss: 0.24087980389595032
step: 210, loss: 0.09035985171794891
step: 220, loss: 0.1698024421930313
step: 230, loss: 0.17749282717704773
step: 240, loss: 0.17313775420188904
step: 250, loss: 0.07506312429904938
step: 260, loss: 0.10128574073314667
step: 270, loss: 0.2184404879808426
step: 280, loss: 0.18179577589035034
step: 290, loss: 0.19765475392341614
step: 300, loss: 0.18502162396907806
step: 310, loss: 0.16691796481609344
step: 320, loss: 0.19925464689731598
step: 330, loss: 0.09379731863737106
step: 340, loss: 0.16558460891246796
step: 350, loss: 0.2446337789297104
step: 360, loss: 0.2038826048374176
step: 370, loss: 0.2260674238204956
step: 380, loss: 0.2869899272918701
step: 390, loss: 0.2620598375797272
step: 400, loss: 0.19298291206359863
step: 410, loss: 0.34390801191329956
step: 420, loss: 0.27993881702423096
step: 430, loss: 0.14724913239479065
step: 440, loss: 0.10872319340705872
step: 450, loss: 0.10533537715673447
step: 460, loss: 0.10419361293315887
step: 470, loss: 0.09492243826389313
step: 480, loss: 0.28591403365135193
step: 490, loss: 0.16450193524360657
step: 500, loss: 0.10334040969610214
step: 510, loss: 0.11383672058582306
step: 520, loss: 0.39997076988220215
step: 530, loss: 0.2556217908859253
step: 540, loss: 0.16617096960544586
step: 550, loss: 0.16193199157714844
step: 560, loss: 0.21195168793201447
step: 570, loss: 0.10168655961751938
step: 580, loss: 0.15412530303001404
step: 590, loss: 0.10989855229854584
step: 600, loss: 0.10090240836143494
step: 610, loss: 0.15803755819797516
step: 620, loss: 0.2150343805551529
step: 630, loss: 0.1110788881778717
step: 640, loss: 0.1761486977338791
step: 650, loss: 0.11924503743648529
step: 660, loss: 0.11368563771247864
step: 670, loss: 0.16589677333831787
step: 680, loss: 0.15109336376190186
step: 690, loss: 0.06118427962064743
step: 700, loss: 0.13623875379562378
step: 710, loss: 0.16461703181266785
step: 720, loss: 0.1438983976840973
step: 730, loss: 0.1393885612487793
step: 740, loss: 0.24603722989559174
step: 750, loss: 0.2116967886686325
step: 760, loss: 0.11003515869379044
step: 770, loss: 0.14947497844696045
step: 780, loss: 0.36186346411705017
step: 790, loss: 0.10042043775320053
step: 800, loss: 0.13560517132282257
step: 810, loss: 0.2556477189064026
step: 820, loss: 0.06807643920183182
step: 830, loss: 0.08292710036039352
step: 840, loss: 0.13712644577026367
step: 850, loss: 0.2529054284095764
step: 860, loss: 0.11768653988838196
step: 870, loss: 0.10493066906929016
step: 880, loss: 0.04436362907290459
step: 890, loss: 0.13961146771907806
step: 900, loss: 0.06687255948781967
step: 910, loss: 0.07690335810184479
step: 920, loss: 0.21664442121982574
step: 930, loss: 0.09612435102462769
step: 940, loss: 0.12856601178646088
step: 950, loss: 0.1645943820476532
step: 960, loss: 0.09517320990562439
step: 970, loss: 0.15243300795555115
step: 980, loss: 0.1573026180267334
step: 990, loss: 0.04443160444498062
step: 1000, loss: 0.15905407071113586
step: 1010, loss: 0.2504463493824005
step: 1020, loss: 0.28264203667640686
step: 1030, loss: 0.07373744249343872
step: 1040, loss: 0.12182476371526718
step: 1050, loss: 0.17701905965805054
step: 1060, loss: 0.10268010944128036
step: 1070, loss: 0.12858529388904572
epoch 1: dev_f1=0.9217311233885819, f1=0.9173553719008264, best_f1=0.9173553719008264
step: 0, loss: 0.18247753381729126
step: 10, loss: 0.21077923476696014
step: 20, loss: 0.16728438436985016
step: 30, loss: 0.15959033370018005
step: 40, loss: 0.04619670286774635
step: 50, loss: 0.10182053595781326
step: 60, loss: 0.10707114636898041
step: 70, loss: 0.2524298131465912
step: 80, loss: 0.17894907295703888
step: 90, loss: 0.16211634874343872
step: 100, loss: 0.08140959590673447
step: 110, loss: 0.08307058364152908
step: 120, loss: 0.17727583646774292
step: 130, loss: 0.09986740350723267
step: 140, loss: 0.13775548338890076
step: 150, loss: 0.11804609000682831
step: 160, loss: 0.22699439525604248
step: 170, loss: 0.11792532354593277
step: 180, loss: 0.17950314283370972
step: 190, loss: 0.11454108357429504
step: 200, loss: 0.1407853662967682
step: 210, loss: 0.13738524913787842
step: 220, loss: 0.29205596446990967
step: 230, loss: 0.06501653790473938
step: 240, loss: 0.13740214705467224
step: 250, loss: 0.20076292753219604
step: 260, loss: 0.10388382524251938
step: 270, loss: 0.50504070520401
step: 280, loss: 0.13230055570602417
step: 290, loss: 0.2361740618944168
step: 300, loss: 0.07590986788272858
step: 310, loss: 0.12429279834032059
step: 320, loss: 0.2414531260728836
step: 330, loss: 0.0917631983757019
step: 340, loss: 0.1197696328163147
step: 350, loss: 0.08189010620117188
step: 360, loss: 0.10396670550107956
step: 370, loss: 0.1430773288011551
step: 380, loss: 0.16445642709732056
step: 390, loss: 0.1679847091436386
step: 400, loss: 0.07807061821222305
step: 410, loss: 0.04112788662314415
step: 420, loss: 0.06443627178668976
step: 430, loss: 0.10133948922157288
step: 440, loss: 0.17346283793449402
step: 450, loss: 0.2336861789226532
step: 460, loss: 0.07537383586168289
step: 470, loss: 0.2095835953950882
step: 480, loss: 0.07658474892377853
step: 490, loss: 0.16756215691566467
step: 500, loss: 0.09468089789152145
step: 510, loss: 0.09836584329605103
step: 520, loss: 0.2832967936992645
step: 530, loss: 0.029743945226073265
step: 540, loss: 0.08593305200338364
step: 550, loss: 0.11294583976268768
step: 560, loss: 0.2491045743227005
step: 570, loss: 0.10655831545591354
step: 580, loss: 0.0704602599143982
step: 590, loss: 0.11609990894794464
step: 600, loss: 0.050895050168037415
step: 610, loss: 0.07328541576862335
step: 620, loss: 0.10767226666212082
step: 630, loss: 0.23417434096336365
step: 640, loss: 0.1556929349899292
step: 650, loss: 0.08948102593421936
step: 660, loss: 0.062269341200590134
step: 670, loss: 0.009004863910377026
step: 680, loss: 0.10728324949741364
step: 690, loss: 0.26054447889328003
step: 700, loss: 0.19747886061668396
step: 710, loss: 0.15571612119674683
step: 720, loss: 0.17443178594112396
step: 730, loss: 0.10779017955064774
step: 740, loss: 0.15017101168632507
step: 750, loss: 0.15229851007461548
step: 760, loss: 0.10561349987983704
step: 770, loss: 0.21046040952205658
step: 780, loss: 0.1344466507434845
step: 790, loss: 0.07198306918144226
step: 800, loss: 0.08238508552312851
step: 810, loss: 0.06294380128383636
step: 820, loss: 0.06276512891054153
step: 830, loss: 0.1235397458076477
step: 840, loss: 0.17262795567512512
step: 850, loss: 0.08165160566568375
step: 860, loss: 0.14020997285842896
step: 870, loss: 0.15417087078094482
step: 880, loss: 0.09896378964185715
step: 890, loss: 0.135189950466156
step: 900, loss: 0.1472722887992859
step: 910, loss: 0.17623886466026306
step: 920, loss: 0.059858888387680054
step: 930, loss: 0.15009763836860657
step: 940, loss: 0.06803888827562332
step: 950, loss: 0.16068236529827118
step: 960, loss: 0.19375905394554138
step: 970, loss: 0.20293448865413666
step: 980, loss: 0.12643785774707794
step: 990, loss: 0.12400726228952408
step: 1000, loss: 0.052600402384996414
step: 1010, loss: 0.10560481995344162
step: 1020, loss: 0.1581088900566101
step: 1030, loss: 0.08631902933120728
step: 1040, loss: 0.19027364253997803
step: 1050, loss: 0.08470294624567032
step: 1060, loss: 0.12901712954044342
step: 1070, loss: 0.11504700779914856
epoch 2: dev_f1=0.9063736263736264, f1=0.911957950065703, best_f1=0.9173553719008264
step: 0, loss: 0.07513587921857834
step: 10, loss: 0.24182681739330292
step: 20, loss: 0.03852596879005432
step: 30, loss: 0.06300126016139984
step: 40, loss: 0.12896673381328583
step: 50, loss: 0.10177692025899887
step: 60, loss: 0.058268070220947266
step: 70, loss: 0.02361978031694889
step: 80, loss: 0.1568858027458191
step: 90, loss: 0.09146946668624878
step: 100, loss: 0.04878233000636101
step: 110, loss: 0.0722077414393425
step: 120, loss: 0.05865517631173134
step: 130, loss: 0.17639778554439545
step: 140, loss: 0.10142413526773453
step: 150, loss: 0.06987227499485016
step: 160, loss: 0.06337488442659378
step: 170, loss: 0.07511330395936966
step: 180, loss: 0.05262649431824684
step: 190, loss: 0.08221343159675598
step: 200, loss: 0.08177534490823746
step: 210, loss: 0.06493513286113739
step: 220, loss: 0.15198813378810883
step: 230, loss: 0.03527442365884781
step: 240, loss: 0.017274795100092888
step: 250, loss: 0.013643235899508
step: 260, loss: 0.14095039665699005
step: 270, loss: 0.23070894181728363
step: 280, loss: 0.017100907862186432
step: 290, loss: 0.10846412926912308
step: 300, loss: 0.3829026520252228
step: 310, loss: 0.08433692902326584
step: 320, loss: 0.131187304854393
step: 330, loss: 0.12423112243413925
step: 340, loss: 0.16027142107486725
step: 350, loss: 0.1381634771823883
step: 360, loss: 0.3520877957344055
step: 370, loss: 0.054013941437006
step: 380, loss: 0.2359032928943634
step: 390, loss: 0.12231285125017166
step: 400, loss: 0.20667745172977448
step: 410, loss: 0.05434950068593025
step: 420, loss: 0.07159750908613205
step: 430, loss: 0.23665599524974823
step: 440, loss: 0.06746239960193634
step: 450, loss: 0.06683005392551422
step: 460, loss: 0.06991800665855408
step: 470, loss: 0.03192887827754021
step: 480, loss: 0.12017083168029785
step: 490, loss: 0.16791057586669922
step: 500, loss: 0.07823895663022995
step: 510, loss: 0.2775038480758667
step: 520, loss: 0.3417893350124359
step: 530, loss: 0.06617201864719391
step: 540, loss: 0.1456756889820099
step: 550, loss: 0.09059465676546097
step: 560, loss: 0.18934687972068787
step: 570, loss: 0.029379824176430702
step: 580, loss: 0.14047180116176605
step: 590, loss: 0.022987615317106247
step: 600, loss: 0.14196690917015076
step: 610, loss: 0.08033955097198486
step: 620, loss: 0.1641845852136612
step: 630, loss: 0.06654337048530579
step: 640, loss: 0.09726160764694214
step: 650, loss: 0.14390285313129425
step: 660, loss: 0.03907863423228264
step: 670, loss: 0.05518641695380211
step: 680, loss: 0.09745936840772629
step: 690, loss: 0.1418296992778778
step: 700, loss: 0.030788538977503777
step: 710, loss: 0.11149626970291138
step: 720, loss: 0.10094399005174637
step: 730, loss: 0.15397503972053528
step: 740, loss: 0.04270847514271736
step: 750, loss: 0.12079421430826187
step: 760, loss: 0.10782286524772644
step: 770, loss: 0.0824493020772934
step: 780, loss: 0.09494144469499588
step: 790, loss: 0.048271626234054565
step: 800, loss: 0.0476398766040802
step: 810, loss: 0.08826138824224472
step: 820, loss: 0.09705208241939545
step: 830, loss: 0.07508765161037445
step: 840, loss: 0.1879771202802658
step: 850, loss: 0.09645096957683563
step: 860, loss: 0.11011246591806412
step: 870, loss: 0.2008541077375412
step: 880, loss: 0.08525272458791733
step: 890, loss: 0.2592529356479645
step: 900, loss: 0.1222071498632431
step: 910, loss: 0.17753012478351593
step: 920, loss: 0.031785041093826294
step: 930, loss: 0.09153018146753311
step: 940, loss: 0.04838941618800163
step: 950, loss: 0.14807038009166718
step: 960, loss: 0.16522686183452606
step: 970, loss: 0.05408720672130585
step: 980, loss: 0.2107985019683838
step: 990, loss: 0.06244198605418205
step: 1000, loss: 0.038254264742136
step: 1010, loss: 0.02348041720688343
step: 1020, loss: 0.0515504889190197
step: 1030, loss: 0.08666215091943741
step: 1040, loss: 0.026903001591563225
step: 1050, loss: 0.17777343094348907
step: 1060, loss: 0.19708165526390076
step: 1070, loss: 0.10069656372070312
epoch 3: dev_f1=0.9311969839773798, f1=0.935771214252227, best_f1=0.935771214252227
step: 0, loss: 0.08343468606472015
step: 10, loss: 0.13851477205753326
step: 20, loss: 0.12835220992565155
step: 30, loss: 0.0798516646027565
step: 40, loss: 0.016559524461627007
step: 50, loss: 0.10236241668462753
step: 60, loss: 0.0668792873620987
step: 70, loss: 0.010466004721820354
step: 80, loss: 0.16218781471252441
step: 90, loss: 0.1248103678226471
step: 100, loss: 0.09959109127521515
step: 110, loss: 0.09826453030109406
step: 120, loss: 0.1610565185546875
step: 130, loss: 0.054869867861270905
step: 140, loss: 0.18031670153141022
step: 150, loss: 0.05666431412100792
step: 160, loss: 0.08374704420566559
step: 170, loss: 0.13061264157295227
step: 180, loss: 0.05611669644713402
step: 190, loss: 0.03463936597108841
step: 200, loss: 0.1345730572938919
step: 210, loss: 0.05306079238653183
step: 220, loss: 0.10140791535377502
step: 230, loss: 0.1200658455491066
step: 240, loss: 0.14330005645751953
step: 250, loss: 0.10246215760707855
step: 260, loss: 0.14292311668395996
step: 270, loss: 0.15079960227012634
step: 280, loss: 0.08411038666963577
step: 290, loss: 0.3023802638053894
step: 300, loss: 0.18196207284927368
step: 310, loss: 0.05731845647096634
step: 320, loss: 0.05724500119686127
step: 330, loss: 0.0630965456366539
step: 340, loss: 0.10058519244194031
step: 350, loss: 0.0318160355091095
step: 360, loss: 0.09891685098409653
step: 370, loss: 0.11109662055969238
step: 380, loss: 0.011135149747133255
step: 390, loss: 0.10971862822771072
step: 400, loss: 0.1980724334716797
step: 410, loss: 0.1501760631799698
step: 420, loss: 0.07578913867473602
step: 430, loss: 0.17964525520801544
step: 440, loss: 0.10592789947986603
step: 450, loss: 0.23586219549179077
step: 460, loss: 0.09073605388402939
step: 470, loss: 0.0605219230055809
step: 480, loss: 0.04062246158719063
step: 490, loss: 0.19555015861988068
step: 500, loss: 0.07631143182516098
step: 510, loss: 0.035065121948719025
step: 520, loss: 0.043144285678863525
step: 530, loss: 0.10333660244941711
step: 540, loss: 0.05314098298549652
step: 550, loss: 0.12402812391519547
step: 560, loss: 0.022496171295642853
step: 570, loss: 0.14938561618328094
step: 580, loss: 0.2235759049654007
step: 590, loss: 0.18314838409423828
step: 600, loss: 0.17200395464897156
step: 610, loss: 0.1282682716846466
step: 620, loss: 0.04821362346410751
step: 630, loss: 0.07367473840713501
step: 640, loss: 0.07888691872358322
step: 650, loss: 0.05470072105526924
step: 660, loss: 0.003952924627810717
step: 670, loss: 0.13731522858142853
step: 680, loss: 0.14767329394817352
step: 690, loss: 0.24535009264945984
step: 700, loss: 0.06689896434545517
step: 710, loss: 0.054551832377910614
step: 720, loss: 0.1369985193014145
step: 730, loss: 0.05364641174674034
step: 740, loss: 0.14886580407619476
step: 750, loss: 0.012243727222084999
step: 760, loss: 0.07296855747699738
step: 770, loss: 0.04294222220778465
step: 780, loss: 0.060938041657209396
step: 790, loss: 0.13848841190338135
step: 800, loss: 0.0642920434474945
step: 810, loss: 0.12892919778823853
step: 820, loss: 0.10278484970331192
step: 830, loss: 0.1181664764881134
step: 840, loss: 0.08956965804100037
step: 850, loss: 0.1780911386013031
step: 860, loss: 0.028393013402819633
step: 870, loss: 0.16175858676433563
step: 880, loss: 0.1991846114397049
step: 890, loss: 0.07727058231830597
step: 900, loss: 0.07281507551670074
step: 910, loss: 0.04843410104513168
step: 920, loss: 0.15650580823421478
step: 930, loss: 0.08690797537565231
step: 940, loss: 0.1167277842760086
step: 950, loss: 0.12507376074790955
step: 960, loss: 0.1327153444290161
step: 970, loss: 0.140745148062706
step: 980, loss: 0.20773577690124512
step: 990, loss: 0.09540536254644394
step: 1000, loss: 0.1374872773885727
step: 1010, loss: 0.05324718728661537
step: 1020, loss: 0.047336477786302567
step: 1030, loss: 0.21092502772808075
step: 1040, loss: 0.13343189656734467
step: 1050, loss: 0.0841711163520813
step: 1060, loss: 0.16702495515346527
step: 1070, loss: 0.046899933367967606
epoch 4: dev_f1=0.9258753979081401, f1=0.9272976680384087, best_f1=0.935771214252227
step: 0, loss: 0.0790809765458107
step: 10, loss: 0.12430500984191895
step: 20, loss: 0.07470522075891495
step: 30, loss: 0.028595680370926857
step: 40, loss: 0.044914212077856064
step: 50, loss: 0.13244199752807617
step: 60, loss: 0.0984659269452095
step: 70, loss: 0.07784683257341385
step: 80, loss: 0.21590521931648254
step: 90, loss: 0.048575855791568756
step: 100, loss: 0.1548180729150772
step: 110, loss: 0.22473640739917755
step: 120, loss: 0.037663575261831284
step: 130, loss: 0.14074034988880157
step: 140, loss: 0.05979505926370621
step: 150, loss: 0.10965515673160553
step: 160, loss: 0.11547427624464035
step: 170, loss: 0.014323387295007706
step: 180, loss: 0.07354040443897247
step: 190, loss: 0.027350425720214844
step: 200, loss: 0.10210154205560684
step: 210, loss: 0.06463539600372314
step: 220, loss: 0.09426365047693253
step: 230, loss: 0.07300779223442078
step: 240, loss: 0.05158563703298569
step: 250, loss: 0.09652387350797653
step: 260, loss: 0.07079457491636276
step: 270, loss: 0.07530506700277328
step: 280, loss: 0.13491356372833252
step: 290, loss: 0.04129355773329735
step: 300, loss: 0.08827805519104004
step: 310, loss: 0.045619770884513855
step: 320, loss: 0.07421524822711945
step: 330, loss: 0.13844333589076996
step: 340, loss: 0.12702003121376038
step: 350, loss: 0.014046023599803448
step: 360, loss: 0.022798972204327583
step: 370, loss: 0.08842207491397858
step: 380, loss: 0.10012209415435791
step: 390, loss: 0.04826369509100914
step: 400, loss: 0.059555597603321075
step: 410, loss: 0.11996719241142273
step: 420, loss: 0.10644334554672241
step: 430, loss: 0.11297887563705444
step: 440, loss: 0.058439936488866806
step: 450, loss: 0.023348059505224228
step: 460, loss: 0.02606968954205513
step: 470, loss: 0.09699560701847076
step: 480, loss: 0.08614224195480347
step: 490, loss: 0.03321091830730438
step: 500, loss: 0.1482357233762741
step: 510, loss: 0.057149361819028854
step: 520, loss: 0.19649836421012878
step: 530, loss: 0.10857966542243958
step: 540, loss: 0.1086978167295456
step: 550, loss: 0.09525017440319061
step: 560, loss: 0.09848400950431824
step: 570, loss: 0.16882994771003723
step: 580, loss: 0.08695107698440552
step: 590, loss: 0.0568135604262352
step: 600, loss: 0.009952009655535221
step: 610, loss: 0.06539738923311234
step: 620, loss: 0.13775795698165894
step: 630, loss: 0.07834257185459137
step: 640, loss: 0.14003072679042816
step: 650, loss: 0.1317550390958786
step: 660, loss: 0.048571620136499405
step: 670, loss: 0.1891608089208603
step: 680, loss: 0.008484257385134697
step: 690, loss: 0.10169792920351028
step: 700, loss: 0.07726166397333145
step: 710, loss: 0.08430155366659164
step: 720, loss: 0.053836923092603683
step: 730, loss: 0.11927488446235657
step: 740, loss: 0.08340984582901001
step: 750, loss: 0.10674815624952316
step: 760, loss: 0.2675817310810089
step: 770, loss: 0.10787339508533478
step: 780, loss: 0.08778509497642517
step: 790, loss: 0.04693315178155899
step: 800, loss: 0.0984354168176651
step: 810, loss: 0.10812801867723465
step: 820, loss: 0.11421217024326324
step: 830, loss: 0.047131408005952835
step: 840, loss: 0.10020744055509567
step: 850, loss: 0.15638713538646698
step: 860, loss: 0.05121980607509613
step: 870, loss: 0.13337159156799316
step: 880, loss: 0.020219866186380386
step: 890, loss: 0.08996094018220901
step: 900, loss: 0.09222355484962463
step: 910, loss: 0.17556099593639374
step: 920, loss: 0.1486809253692627
step: 930, loss: 0.186189666390419
step: 940, loss: 0.07178448885679245
step: 950, loss: 0.09563057869672775
step: 960, loss: 0.11672241985797882
step: 970, loss: 0.1464632898569107
step: 980, loss: 0.13681000471115112
step: 990, loss: 0.06277041137218475
step: 1000, loss: 0.136905238032341
step: 1010, loss: 0.09047843515872955
step: 1020, loss: 0.15270905196666718
step: 1030, loss: 0.14354637265205383
step: 1040, loss: 0.08189156651496887
step: 1050, loss: 0.0816093236207962
step: 1060, loss: 0.06075244024395943
step: 1070, loss: 0.10233553498983383
epoch 5: dev_f1=0.9265799256505577, f1=0.9249999999999999, best_f1=0.935771214252227
step: 0, loss: 0.12118034809827805
step: 10, loss: 0.09000135958194733
step: 20, loss: 0.03001362644135952
step: 30, loss: 0.10515160113573074
step: 40, loss: 0.00021349676535464823
step: 50, loss: 0.07242422550916672
step: 60, loss: 0.040285151451826096
step: 70, loss: 0.07088134437799454
step: 80, loss: 0.14048737287521362
step: 90, loss: 0.07629841566085815
step: 100, loss: 0.12338376045227051
step: 110, loss: 0.0331985279917717
step: 120, loss: 0.1556084156036377
step: 130, loss: 0.16859522461891174
step: 140, loss: 0.18704964220523834
step: 150, loss: 0.07185078412294388
step: 160, loss: 0.006863071583211422
step: 170, loss: 0.10068784654140472
step: 180, loss: 0.017972279340028763
step: 190, loss: 0.18194778263568878
step: 200, loss: 0.0782415121793747
step: 210, loss: 0.08362293988466263
step: 220, loss: 0.013480180874466896
step: 230, loss: 0.15623563528060913
step: 240, loss: 0.04923146218061447
step: 250, loss: 0.22212637960910797
step: 260, loss: 0.04852328449487686
step: 270, loss: 0.0721200704574585
step: 280, loss: 0.13330939412117004
step: 290, loss: 0.07081296294927597
step: 300, loss: 0.09688954800367355
step: 310, loss: 0.2179298996925354
step: 320, loss: 0.1624113768339157
step: 330, loss: 0.20986266434192657
step: 340, loss: 0.07835278660058975
step: 350, loss: 0.13781853020191193
step: 360, loss: 0.060594357550144196
step: 370, loss: 0.023337677121162415
step: 380, loss: 0.12543641030788422
step: 390, loss: 0.09239396452903748
step: 400, loss: 0.1941979080438614
step: 410, loss: 0.041708532720804214
step: 420, loss: 0.0454426184296608
step: 430, loss: 0.041915640234947205
step: 440, loss: 0.04261333867907524
step: 450, loss: 0.10814157128334045
step: 460, loss: 0.18707063794136047
step: 470, loss: 0.10463329404592514
step: 480, loss: 0.07123114168643951
step: 490, loss: 0.04051264375448227
step: 500, loss: 0.2141081690788269
step: 510, loss: 0.09204394370317459
step: 520, loss: 0.051141172647476196
step: 530, loss: 0.035704903304576874
step: 540, loss: 0.10247822105884552
step: 550, loss: 0.09313331544399261
step: 560, loss: 0.08407049626111984
step: 570, loss: 0.10483994334936142
step: 580, loss: 0.1828751415014267
step: 590, loss: 0.044081468135118484
step: 600, loss: 0.05284364894032478
step: 610, loss: 0.13642719388008118
step: 620, loss: 0.15870726108551025
step: 630, loss: 0.09043922275304794
step: 640, loss: 0.13691094517707825
step: 650, loss: 0.09479092806577682
step: 660, loss: 0.04887095466256142
step: 670, loss: 0.04862622171640396
step: 680, loss: 0.08879479020833969
step: 690, loss: 0.03235054388642311
step: 700, loss: 0.03833628073334694
step: 710, loss: 0.0529380701482296
step: 720, loss: 0.05994021147489548
step: 730, loss: 0.0517866425216198
step: 740, loss: 0.08891822397708893
step: 750, loss: 0.11949750781059265
step: 760, loss: 0.08621670305728912
step: 770, loss: 0.11337704211473465
step: 780, loss: 0.06864288449287415
step: 790, loss: 0.07881755381822586
step: 800, loss: 0.15839684009552002
step: 810, loss: 0.16482286155223846
step: 820, loss: 0.04877565801143646
step: 830, loss: 0.0011954489164054394
step: 840, loss: 0.033193133771419525
step: 850, loss: 0.05431538075208664
step: 860, loss: 0.0898585170507431
step: 870, loss: 0.06424249708652496
step: 880, loss: 0.1031499058008194
step: 890, loss: 0.13895244896411896
step: 900, loss: 0.0734146386384964
step: 910, loss: 0.048480886965990067
step: 920, loss: 0.07288405299186707
step: 930, loss: 0.09933804720640182
step: 940, loss: 0.3094192147254944
step: 950, loss: 0.01865331083536148
step: 960, loss: 0.07101936638355255
step: 970, loss: 0.1611894965171814
step: 980, loss: 0.13189607858657837
step: 990, loss: 0.10098905861377716
step: 1000, loss: 0.05363818258047104
step: 1010, loss: 0.0407232828438282
step: 1020, loss: 0.07274267077445984
step: 1030, loss: 0.127351313829422
step: 1040, loss: 0.031582061201334
step: 1050, loss: 0.07290209084749222
step: 1060, loss: 0.07043084502220154
step: 1070, loss: 0.0908721387386322
epoch 6: dev_f1=0.9253871421867668, f1=0.9259783121169259, best_f1=0.935771214252227
step: 0, loss: 0.1533648818731308
step: 10, loss: 0.02107802778482437
step: 20, loss: 0.11418656259775162
step: 30, loss: 0.08677614480257034
step: 40, loss: 0.12194593995809555
step: 50, loss: 0.06804615259170532
step: 60, loss: 0.06647227704524994
step: 70, loss: 0.03848906606435776
step: 80, loss: 0.07654807716608047
step: 90, loss: 0.1822209358215332
step: 100, loss: 0.015720399096608162
step: 110, loss: 0.03785533830523491
step: 120, loss: 0.02190431021153927
step: 130, loss: 0.1533871293067932
step: 140, loss: 0.11742282658815384
step: 150, loss: 0.01142927072942257
step: 160, loss: 0.02345072478055954
step: 170, loss: 0.06730954349040985
step: 180, loss: 0.08514825999736786
step: 190, loss: 0.07575348764657974
step: 200, loss: 0.06094595417380333
step: 210, loss: 0.20335562527179718
step: 220, loss: 0.1266404241323471
step: 230, loss: 0.07833009213209152
step: 240, loss: 0.06965341418981552
step: 250, loss: 0.07101214677095413
step: 260, loss: 0.01635163649916649
step: 270, loss: 0.12459851801395416
step: 280, loss: 0.14342187345027924
step: 290, loss: 0.05700640752911568
step: 300, loss: 0.08982820063829422
step: 310, loss: 0.11186639964580536
step: 320, loss: 0.13780783116817474
step: 330, loss: 0.10055473446846008
step: 340, loss: 0.04183628037571907
step: 350, loss: 0.12844231724739075
step: 360, loss: 0.011998453177511692
step: 370, loss: 0.10037453472614288
step: 380, loss: 0.025658898055553436
step: 390, loss: 0.16061706840991974
step: 400, loss: 0.10901512950658798
step: 410, loss: 0.09129603952169418
step: 420, loss: 0.049209803342819214
step: 430, loss: 0.1400606632232666
step: 440, loss: 0.05313079431653023
step: 450, loss: 0.08554977178573608
step: 460, loss: 0.16274334490299225
step: 470, loss: 0.015463155694305897
step: 480, loss: 0.058406662195920944
step: 490, loss: 0.1482805460691452
step: 500, loss: 0.06540080159902573
step: 510, loss: 0.23940512537956238
step: 520, loss: 0.035444941371679306
step: 530, loss: 0.09387779235839844
step: 540, loss: 0.0826551541686058
step: 550, loss: 0.11178676038980484
step: 560, loss: 0.04724915325641632
step: 570, loss: 0.12419036775827408
step: 580, loss: 0.0974767804145813
step: 590, loss: 0.11620807647705078
step: 600, loss: 0.08100993931293488
step: 610, loss: 0.08734172582626343
step: 620, loss: 0.1630862057209015
step: 630, loss: 0.10120366513729095
step: 640, loss: 0.13562938570976257
step: 650, loss: 0.1677294671535492
step: 660, loss: 0.0615820549428463
step: 670, loss: 0.09199502319097519
step: 680, loss: 0.2352418452501297
step: 690, loss: 0.11392266303300858
step: 700, loss: 0.050959669053554535
step: 710, loss: 0.1236598789691925
step: 720, loss: 0.04690765589475632
step: 730, loss: 0.04576748609542847
step: 740, loss: 0.03342929854989052
step: 750, loss: 0.04848973825573921
step: 760, loss: 0.20367829501628876
step: 770, loss: 0.18155163526535034
step: 780, loss: 0.16745510697364807
step: 790, loss: 0.06691361218690872
step: 800, loss: 0.006550646387040615
step: 810, loss: 0.08311636000871658
step: 820, loss: 0.05499926581978798
step: 830, loss: 0.0010548437712714076
step: 840, loss: 0.13885164260864258
step: 850, loss: 0.06526849418878555
step: 860, loss: 0.09159672260284424
step: 870, loss: 0.12491966038942337
step: 880, loss: 0.11169321835041046
step: 890, loss: 0.1496717631816864
step: 900, loss: 0.20319108664989471
step: 910, loss: 0.09759797155857086
step: 920, loss: 0.16139045357704163
step: 930, loss: 0.12834030389785767
step: 940, loss: 0.15688613057136536
step: 950, loss: 0.05240489915013313
step: 960, loss: 0.08224426209926605
step: 970, loss: 0.08860044181346893
step: 980, loss: 0.07547781616449356
step: 990, loss: 0.08829879015684128
step: 1000, loss: 0.07435406744480133
step: 1010, loss: 0.10487351566553116
step: 1020, loss: 0.035535965114831924
step: 1030, loss: 0.10652022808790207
step: 1040, loss: 0.230264812707901
step: 1050, loss: 0.0047611030749976635
step: 1060, loss: 0.08392082154750824
step: 1070, loss: 0.07706291973590851
epoch 7: dev_f1=0.922488038277512, f1=0.9227099236641221, best_f1=0.935771214252227
step: 0, loss: 0.10886683315038681
step: 10, loss: 0.10133051127195358
step: 20, loss: 0.013580129481852055
step: 30, loss: 0.2576752305030823
step: 40, loss: 0.09832792729139328
step: 50, loss: 0.02391686663031578
step: 60, loss: 0.07081884145736694
step: 70, loss: 0.067179374396801
step: 80, loss: 0.07152441889047623
step: 90, loss: 0.048302292823791504
step: 100, loss: 0.03637922927737236
step: 110, loss: 0.132872074842453
step: 120, loss: 0.08348856121301651
step: 130, loss: 0.053242623805999756
step: 140, loss: 0.1188816949725151
step: 150, loss: 0.04908110946416855
step: 160, loss: 0.019411766901612282
step: 170, loss: 0.050631083548069
step: 180, loss: 0.1354837864637375
step: 190, loss: 0.09967648237943649
step: 200, loss: 0.032504595816135406
step: 210, loss: 0.02519076317548752
step: 220, loss: 0.1049661785364151
step: 230, loss: 0.006712067872285843
step: 240, loss: 0.11323388665914536
step: 250, loss: 0.06646332889795303
step: 260, loss: 0.0534115806221962
step: 270, loss: 0.18387915194034576
step: 280, loss: 0.16752216219902039
step: 290, loss: 0.13711844384670258
step: 300, loss: 0.08097495138645172
step: 310, loss: 0.0346391536295414
step: 320, loss: 0.033320795744657516
step: 330, loss: 0.03166361525654793
step: 340, loss: 0.18260681629180908
step: 350, loss: 0.09165148437023163
step: 360, loss: 0.045329414308071136
step: 370, loss: 0.06956493109464645
step: 380, loss: 0.058608610183000565
step: 390, loss: 0.046959228813648224
step: 400, loss: 0.04827886074781418
step: 410, loss: 0.09754844009876251
step: 420, loss: 0.08130994439125061
step: 430, loss: 0.04858773946762085
step: 440, loss: 0.13045518100261688
step: 450, loss: 0.14889970421791077
step: 460, loss: 0.008069031871855259
step: 470, loss: 0.04469919204711914
step: 480, loss: 0.13184526562690735
step: 490, loss: 0.0915251076221466
step: 500, loss: 0.09903443604707718
step: 510, loss: 0.1308082938194275
step: 520, loss: 0.06575343012809753
step: 530, loss: 0.0160544253885746
step: 540, loss: 0.07250063121318817
step: 550, loss: 0.052489276975393295
step: 560, loss: 0.016184639185667038
step: 570, loss: 0.022414498031139374
step: 580, loss: 0.04824686050415039
step: 590, loss: 0.023165607824921608
step: 600, loss: 0.10765011608600616
step: 610, loss: 0.2109615057706833
step: 620, loss: 0.06839706003665924
step: 630, loss: 0.00011100494884885848
step: 640, loss: 0.03385961800813675
step: 650, loss: 0.05417919158935547
step: 660, loss: 0.04418680816888809
step: 670, loss: 0.1713835597038269
step: 680, loss: 0.14548605680465698
step: 690, loss: 0.07151681184768677
step: 700, loss: 0.11978906393051147
step: 710, loss: 0.09628532081842422
step: 720, loss: 0.0805937722325325
step: 730, loss: 0.15473932027816772
step: 740, loss: 0.04026428610086441
step: 750, loss: 0.02212274819612503
step: 760, loss: 0.09634816646575928
step: 770, loss: 0.05758664384484291
step: 780, loss: 0.12809421122074127
step: 790, loss: 0.04488154128193855
step: 800, loss: 0.13067315518856049
step: 810, loss: 0.013185962103307247
step: 820, loss: 0.01710859313607216
step: 830, loss: 0.17855246365070343
step: 840, loss: 0.0509442463517189
step: 850, loss: 0.06998439133167267
step: 860, loss: 0.17413859069347382
step: 870, loss: 0.12128665298223495
step: 880, loss: 0.023751946166157722
step: 890, loss: 0.056545551866292953
step: 900, loss: 0.059376269578933716
step: 910, loss: 0.05441306531429291
step: 920, loss: 0.08131357282400131
step: 930, loss: 0.006788645870983601
step: 940, loss: 0.0875580757856369
step: 950, loss: 0.10379248857498169
step: 960, loss: 0.07142367213964462
step: 970, loss: 0.024522004649043083
step: 980, loss: 0.06993893533945084
step: 990, loss: 0.05317498371005058
step: 1000, loss: 0.1666523963212967
step: 1010, loss: 0.007685227785259485
step: 1020, loss: 0.10594430565834045
step: 1030, loss: 0.09029250591993332
step: 1040, loss: 0.02811320312321186
step: 1050, loss: 0.03971229866147041
step: 1060, loss: 0.04147074744105339
step: 1070, loss: 0.06093549355864525
epoch 8: dev_f1=0.9244829244829245, f1=0.9192846785886902, best_f1=0.935771214252227
step: 0, loss: 0.011602512560784817
step: 10, loss: 0.06966424733400345
step: 20, loss: 0.04791409149765968
step: 30, loss: 0.06647869199514389
step: 40, loss: 0.023526154458522797
step: 50, loss: 0.03014441952109337
step: 60, loss: 0.054234929382801056
step: 70, loss: 0.1429235190153122
step: 80, loss: 0.060634151101112366
step: 90, loss: 0.07050423324108124
step: 100, loss: 0.08885359019041061
step: 110, loss: 0.07428933680057526
step: 120, loss: 0.1258096545934677
step: 130, loss: 0.019152618944644928
step: 140, loss: 0.013158151879906654
step: 150, loss: 0.047210950404405594
step: 160, loss: 0.045294176787137985
step: 170, loss: 0.012402202002704144
step: 180, loss: 0.0375358909368515
step: 190, loss: 0.09218836575746536
step: 200, loss: 0.07592891156673431
step: 210, loss: 0.09808622300624847
step: 220, loss: 0.04499426111578941
step: 230, loss: 0.036803510040044785
step: 240, loss: 0.020874392241239548
step: 250, loss: 0.055761873722076416
step: 260, loss: 0.07392667979001999
step: 270, loss: 0.05156860128045082
step: 280, loss: 0.08027298003435135
step: 290, loss: 0.06297590583562851
step: 300, loss: 0.10102736949920654
step: 310, loss: 0.08730840682983398
step: 320, loss: 0.12466107308864594
step: 330, loss: 0.15404768288135529
step: 340, loss: 0.010401167906820774
step: 350, loss: 0.13443873822689056
step: 360, loss: 0.055261123925447464
step: 370, loss: 0.08145998418331146
step: 380, loss: 0.006857603322714567
step: 390, loss: 0.11279420554637909
step: 400, loss: 0.06614546477794647
step: 410, loss: 0.09240378439426422
step: 420, loss: 0.15133918821811676
step: 430, loss: 0.015082407742738724
step: 440, loss: 0.0354052409529686
step: 450, loss: 0.07530344277620316
step: 460, loss: 0.020245376974344254
step: 470, loss: 0.1393730491399765
step: 480, loss: 0.08120682090520859
step: 490, loss: 0.050020892173051834
step: 500, loss: 0.011484876275062561
step: 510, loss: 0.02427772432565689
step: 520, loss: 0.06309420615434647
step: 530, loss: 0.014443363063037395
step: 540, loss: 0.015264377929270267
step: 550, loss: 0.11511167883872986
step: 560, loss: 0.1585315614938736
step: 570, loss: 0.0963612049818039
step: 580, loss: 0.05302158743143082
step: 590, loss: 0.09926300495862961
step: 600, loss: 0.08565966039896011
step: 610, loss: 0.01745321974158287
step: 620, loss: 0.10196392238140106
step: 630, loss: 0.08225832134485245
step: 640, loss: 0.12518469989299774
step: 650, loss: 0.07718855887651443
step: 660, loss: 0.08746857941150665
step: 670, loss: 0.05164751783013344
step: 680, loss: 0.05307140201330185
step: 690, loss: 0.09483885020017624
step: 700, loss: 0.07363487035036087
step: 710, loss: 0.1781381219625473
step: 720, loss: 0.06438218057155609
step: 730, loss: 0.046402059495449066
step: 740, loss: 0.11408417671918869
step: 750, loss: 0.1458440124988556
step: 760, loss: 0.07126563787460327
step: 770, loss: 0.03997446969151497
step: 780, loss: 0.04396282881498337
step: 790, loss: 0.028693217784166336
step: 800, loss: 0.0721745491027832
step: 810, loss: 0.041044093668460846
step: 820, loss: 0.029320787638425827
step: 830, loss: 0.06991565227508545
step: 840, loss: 0.09224062412977219
step: 850, loss: 0.02272716537117958
step: 860, loss: 0.06351377815008163
step: 870, loss: 0.07293634116649628
step: 880, loss: 0.12590250372886658
step: 890, loss: 0.048033811151981354
step: 900, loss: 0.12368408590555191
step: 910, loss: 0.12229903042316437
step: 920, loss: 0.052662771195173264
step: 930, loss: 0.12208057194948196
step: 940, loss: 0.0799623355269432
step: 950, loss: 0.0008238679729402065
step: 960, loss: 0.10311873257160187
step: 970, loss: 0.062430694699287415
step: 980, loss: 0.05663922429084778
step: 990, loss: 0.039136853069067
step: 1000, loss: 0.061611615121364594
step: 1010, loss: 0.1442282795906067
step: 1020, loss: 0.011431566439568996
step: 1030, loss: 0.11225830763578415
step: 1040, loss: 0.07471813261508942
step: 1050, loss: 0.14027920365333557
step: 1060, loss: 0.11332608759403229
step: 1070, loss: 0.056895796209573746
epoch 9: dev_f1=0.9225806451612903, f1=0.9255663430420712, best_f1=0.935771214252227
step: 0, loss: 0.03481246903538704
step: 10, loss: 0.09630704671144485
step: 20, loss: 0.09819309413433075
step: 30, loss: 0.13582542538642883
step: 40, loss: 0.06799665838479996
step: 50, loss: 0.11644487828016281
step: 60, loss: 0.06837306171655655
step: 70, loss: 0.033131398260593414
step: 80, loss: 0.04099835827946663
step: 90, loss: 0.04143006354570389
step: 100, loss: 0.04269041866064072
step: 110, loss: 0.04457130655646324
step: 120, loss: 0.024943076074123383
step: 130, loss: 0.038143936544656754
step: 140, loss: 0.022044379264116287
step: 150, loss: 0.03614020720124245
step: 160, loss: 0.0354716032743454
step: 170, loss: 0.009046792052686214
step: 180, loss: 0.014689069241285324
step: 190, loss: 0.06388197094202042
step: 200, loss: 0.2465813308954239
step: 210, loss: 0.0318216010928154
step: 220, loss: 0.056008946150541306
step: 230, loss: 0.11877094954252243
step: 240, loss: 0.06000792607665062
step: 250, loss: 0.004929711576551199
step: 260, loss: 0.1401883065700531
step: 270, loss: 0.028517980128526688
step: 280, loss: 0.10029322654008865
step: 290, loss: 0.10325519740581512
step: 300, loss: 0.07865533977746964
step: 310, loss: 0.08358494192361832
step: 320, loss: 0.04555779695510864
step: 330, loss: 0.06912518292665482
step: 340, loss: 0.1595081239938736
step: 350, loss: 0.049095794558525085
step: 360, loss: 0.03556341677904129
step: 370, loss: 0.08103808760643005
step: 380, loss: 0.0878181904554367
step: 390, loss: 0.13765066862106323
step: 400, loss: 0.01218853797763586
step: 410, loss: 0.08486834913492203
step: 420, loss: 0.06216135621070862
step: 430, loss: 0.09987012296915054
step: 440, loss: 0.039095520973205566
step: 450, loss: 0.03928128257393837
step: 460, loss: 0.011239374987781048
step: 470, loss: 0.06087809428572655
step: 480, loss: 0.12034404277801514
step: 490, loss: 0.0715179368853569
step: 500, loss: 0.019319092854857445
step: 510, loss: 0.09828667342662811
step: 520, loss: 0.0674460381269455
step: 530, loss: 0.07807186990976334
step: 540, loss: 0.0919288694858551
step: 550, loss: 0.07826318591833115
step: 560, loss: 0.09124310314655304
step: 570, loss: 0.08119422942399979
step: 580, loss: 0.057522665709257126
step: 590, loss: 0.014561549760401249
step: 600, loss: 0.05405154079198837
step: 610, loss: 0.019417745992541313
step: 620, loss: 0.043916966766119
step: 630, loss: 0.04218580573797226
step: 640, loss: 0.03204217925667763
step: 650, loss: 0.04016513377428055
step: 660, loss: 0.09565583616495132
step: 670, loss: 0.12400153279304504
step: 680, loss: 0.0753648430109024
step: 690, loss: 0.06089284271001816
step: 700, loss: 0.05938759446144104
step: 710, loss: 0.06326569616794586
step: 720, loss: 0.05263794586062431
step: 730, loss: 0.18429242074489594
step: 740, loss: 0.017316043376922607
step: 750, loss: 0.07870164513587952
step: 760, loss: 0.0627092644572258
step: 770, loss: 0.08294627815485
step: 780, loss: 0.10807432979345322
step: 790, loss: 0.051143333315849304
step: 800, loss: 0.08138615638017654
step: 810, loss: 0.051669929176568985
step: 820, loss: 0.08576580882072449
step: 830, loss: 0.0811888575553894
step: 840, loss: 0.06116904318332672
step: 850, loss: 0.16989660263061523
step: 860, loss: 0.10650476068258286
step: 870, loss: 0.036922406405210495
step: 880, loss: 0.10721922665834427
step: 890, loss: 0.04712490737438202
step: 900, loss: 0.09106846153736115
step: 910, loss: 0.13556860387325287
step: 920, loss: 0.009616253897547722
step: 930, loss: 0.014094253070652485
step: 940, loss: 0.07377292215824127
step: 950, loss: 0.04985306039452553
step: 960, loss: 0.11055943369865417
step: 970, loss: 0.08495056629180908
step: 980, loss: 0.0705694779753685
step: 990, loss: 0.08655070513486862
step: 1000, loss: 0.057728882879018784
step: 1010, loss: 0.07036002725362778
step: 1020, loss: 0.05530592426657677
step: 1030, loss: 0.08580972254276276
step: 1040, loss: 0.11770585179328918
step: 1050, loss: 0.12001010775566101
step: 1060, loss: 0.1104777529835701
step: 1070, loss: 0.06315332651138306
epoch 10: dev_f1=0.9248716752216519, f1=0.9253034547152195, best_f1=0.935771214252227
step: 0, loss: 0.02709723263978958
step: 10, loss: 0.04527819901704788
step: 20, loss: 0.01077206339687109
step: 30, loss: 0.10447985678911209
step: 40, loss: 0.0005268374807201326
step: 50, loss: 0.012880226597189903
step: 60, loss: 0.20158199965953827
step: 70, loss: 0.05836370587348938
step: 80, loss: 0.028381209820508957
step: 90, loss: 0.03596701845526695
step: 100, loss: 0.05778425186872482
step: 110, loss: 0.024795623496174812
step: 120, loss: 0.0891522616147995
step: 130, loss: 0.054845765233039856
step: 140, loss: 0.027292372658848763
step: 150, loss: 0.08727133274078369
step: 160, loss: 0.03002343326807022
step: 170, loss: 0.11101367324590683
step: 180, loss: 0.03474307060241699
step: 190, loss: 0.030012143775820732
step: 200, loss: 0.004609741736203432
step: 210, loss: 0.12420094013214111
step: 220, loss: 0.05326298624277115
step: 230, loss: 0.0874544307589531
step: 240, loss: 0.025858882814645767
step: 250, loss: 0.08098156750202179
step: 260, loss: 0.11427425593137741
step: 270, loss: 0.04273655638098717
step: 280, loss: 0.05242210626602173
step: 290, loss: 0.12717032432556152
step: 300, loss: 0.056669242680072784
step: 310, loss: 0.06543484330177307
step: 320, loss: 0.17032155394554138
step: 330, loss: 0.0010389441158622503
step: 340, loss: 0.11263523250818253
step: 350, loss: 0.0674295574426651
step: 360, loss: 0.0735766589641571
step: 370, loss: 0.07978490740060806
step: 380, loss: 0.0500250980257988
step: 390, loss: 0.0014331446727737784
step: 400, loss: 0.026640787720680237
step: 410, loss: 0.13776884973049164
step: 420, loss: 0.03253783658146858
step: 430, loss: 0.011874166317284107
step: 440, loss: 0.12635022401809692
step: 450, loss: 0.004088169429451227
step: 460, loss: 0.04553251713514328
step: 470, loss: 0.03715552017092705
step: 480, loss: 0.08685094118118286
step: 490, loss: 0.04938443750143051
step: 500, loss: 0.06289873272180557
step: 510, loss: 0.02957851067185402
step: 520, loss: 0.0884811133146286
step: 530, loss: 0.020460400730371475
step: 540, loss: 0.05813603475689888
step: 550, loss: 0.04748855158686638
step: 560, loss: 0.12444796413183212
step: 570, loss: 0.043301764875650406
step: 580, loss: 0.13727867603302002
step: 590, loss: 0.11766653507947922
step: 600, loss: 0.1197926253080368
step: 610, loss: 0.08464217931032181
step: 620, loss: 0.10171177238225937
step: 630, loss: 0.006142802070826292
step: 640, loss: 0.03485958278179169
step: 650, loss: 0.07527510821819305
step: 660, loss: 0.015002655796706676
step: 670, loss: 0.05391848832368851
step: 680, loss: 0.023278266191482544
step: 690, loss: 0.1464703530073166
step: 700, loss: 0.03697841241955757
step: 710, loss: 0.005883020348846912
step: 720, loss: 0.07023046165704727
step: 730, loss: 0.09871111810207367
step: 740, loss: 0.05161430686712265
step: 750, loss: 0.11951218545436859
step: 760, loss: 0.0961804911494255
step: 770, loss: 0.03866390883922577
step: 780, loss: 0.15193134546279907
step: 790, loss: 0.08385909348726273
step: 800, loss: 0.06697528809309006
step: 810, loss: 0.0423261821269989
step: 820, loss: 0.011758384294807911
step: 830, loss: 0.024169132113456726
step: 840, loss: 0.020114989951252937
step: 850, loss: 0.10111448913812637
step: 860, loss: 0.19178546965122223
step: 870, loss: 0.03295516595244408
step: 880, loss: 0.030782368034124374
step: 890, loss: 0.06855086982250214
step: 900, loss: 0.018491627648472786
step: 910, loss: 0.11803463846445084
step: 920, loss: 0.1073017567396164
step: 930, loss: 0.012123866006731987
step: 940, loss: 0.10042262077331543
step: 950, loss: 0.018547313287854195
step: 960, loss: 0.04085792228579521
step: 970, loss: 0.01873062364757061
step: 980, loss: 0.06398683786392212
step: 990, loss: 0.04473216086626053
step: 1000, loss: 0.06878239661455154
step: 1010, loss: 0.07089019566774368
step: 1020, loss: 0.14794032275676727
step: 1030, loss: 0.04161573201417923
step: 1040, loss: 0.027951715514063835
step: 1050, loss: 0.2276829332113266
step: 1060, loss: 0.12291648983955383
step: 1070, loss: 0.08397302776575089
epoch 11: dev_f1=0.928909952606635, f1=0.9246802463287541, best_f1=0.935771214252227
step: 0, loss: 0.04295356199145317
step: 10, loss: 0.1471664160490036
step: 20, loss: 0.014262798242270947
step: 30, loss: 0.02452555112540722
step: 40, loss: 0.035477470606565475
step: 50, loss: 0.06100241094827652
step: 60, loss: 0.00015057354175951332
step: 70, loss: 0.08449699729681015
step: 80, loss: 0.03147084638476372
step: 90, loss: 0.013274972327053547
step: 100, loss: 0.016083039343357086
step: 110, loss: 0.08008202165365219
step: 120, loss: 0.04305724799633026
step: 130, loss: 0.04924098029732704
step: 140, loss: 0.019214345142245293
step: 150, loss: 0.028587324544787407
step: 160, loss: 0.0010568700963631272
step: 170, loss: 0.022069469094276428
step: 180, loss: 0.053267017006874084
step: 190, loss: 0.028649821877479553
step: 200, loss: 0.03733571618795395
step: 210, loss: 0.026381870731711388
step: 220, loss: 0.05623936280608177
step: 230, loss: 0.039031751453876495
step: 240, loss: 0.0741923376917839
step: 250, loss: 0.07211517542600632
step: 260, loss: 0.010517743416130543
step: 270, loss: 0.019776929169893265
step: 280, loss: 0.02208911068737507
step: 290, loss: 0.07400572299957275
step: 300, loss: 0.0877552330493927
step: 310, loss: 0.09087385982275009
step: 320, loss: 0.04567117244005203
step: 330, loss: 0.07196813821792603
step: 340, loss: 0.04736312851309776
step: 350, loss: 0.011682401411235332
step: 360, loss: 0.08263801038265228
step: 370, loss: 0.17374113202095032
step: 380, loss: 0.07146374881267548
step: 390, loss: 0.03858188912272453
step: 400, loss: 0.06536300480365753
step: 410, loss: 0.03782805800437927
step: 420, loss: 0.04930056631565094
step: 430, loss: 0.02272174134850502
step: 440, loss: 0.13245682418346405
step: 450, loss: 0.022819679230451584
step: 460, loss: 0.043408457189798355
step: 470, loss: 0.03270633891224861
step: 480, loss: 0.03714333474636078
step: 490, loss: 0.08315010368824005
step: 500, loss: 0.07242714613676071
step: 510, loss: 0.017967047169804573
step: 520, loss: 0.00012449795030988753
step: 530, loss: 0.08493679016828537
step: 540, loss: 0.033174484968185425
step: 550, loss: 0.014425812289118767
step: 560, loss: 0.04487411677837372
step: 570, loss: 0.0004762526659760624
step: 580, loss: 0.04883180931210518
step: 590, loss: 0.009265086613595486
step: 600, loss: 0.05590808391571045
step: 610, loss: 0.06670719385147095
step: 620, loss: 0.028014732524752617
step: 630, loss: 0.02071046642959118
step: 640, loss: 0.03452282026410103
step: 650, loss: 0.029477154836058617
step: 660, loss: 0.05769515782594681
step: 670, loss: 0.007730967365205288
step: 680, loss: 0.052994098514318466
step: 690, loss: 0.023816993460059166
step: 700, loss: 0.053314853459596634
step: 710, loss: 0.16283142566680908
step: 720, loss: 0.0061815641820430756
step: 730, loss: 0.043985795229673386
step: 740, loss: 0.0757398009300232
step: 750, loss: 0.027545608580112457
step: 760, loss: 0.028091665357351303
step: 770, loss: 0.02160482294857502
step: 780, loss: 0.10231831669807434
step: 790, loss: 0.0019559666980057955
step: 800, loss: 0.03159303963184357
step: 810, loss: 0.09058469533920288
step: 820, loss: 0.032443251460790634
step: 830, loss: 0.04537934809923172
step: 840, loss: 0.0656307116150856
step: 850, loss: 0.06754501909017563
step: 860, loss: 0.07695481181144714
step: 870, loss: 0.04215723276138306
step: 880, loss: 0.012661714106798172
step: 890, loss: 0.05494227260351181
step: 900, loss: 0.05590134486556053
step: 910, loss: 0.08126316964626312
step: 920, loss: 0.0016184200067073107
step: 930, loss: 0.022360797971487045
step: 940, loss: 0.08543503284454346
step: 950, loss: 0.08946671336889267
step: 960, loss: 0.06763485819101334
step: 970, loss: 0.06348537653684616
step: 980, loss: 0.0357384979724884
step: 990, loss: 0.06068312004208565
step: 1000, loss: 0.051225658506155014
step: 1010, loss: 0.10082177072763443
step: 1020, loss: 0.03215750679373741
step: 1030, loss: 0.04117670655250549
step: 1040, loss: 0.10659404844045639
step: 1050, loss: 0.048805296421051025
step: 1060, loss: 0.1452251523733139
step: 1070, loss: 0.08685269951820374
epoch 12: dev_f1=0.92090395480226, f1=0.9216241737488197, best_f1=0.935771214252227
step: 0, loss: 0.031718283891677856
step: 10, loss: 0.03806152567267418
step: 20, loss: 0.05562550947070122
step: 30, loss: 0.04461654648184776
step: 40, loss: 0.0437873974442482
step: 50, loss: 7.482227374566719e-05
step: 60, loss: 0.04430673271417618
step: 70, loss: 0.10540733486413956
step: 80, loss: 0.0519862100481987
step: 90, loss: 0.0245721023529768
step: 100, loss: 0.07765421271324158
step: 110, loss: 0.04093576967716217
step: 120, loss: 0.10004377365112305
step: 130, loss: 0.04078342020511627
step: 140, loss: 0.030711844563484192
step: 150, loss: 0.0006590647390112281
step: 160, loss: 0.05590525642037392
step: 170, loss: 0.04467916116118431
step: 180, loss: 0.06590393930673599
step: 190, loss: 0.01111946813762188
step: 200, loss: 0.09766220301389694
step: 210, loss: 0.004866211209446192
step: 220, loss: 0.08996240794658661
step: 230, loss: 0.029906325042247772
step: 240, loss: 0.07764363288879395
step: 250, loss: 0.07398943603038788
step: 260, loss: 0.04790819436311722
step: 270, loss: 0.021682018414139748
step: 280, loss: 0.0380079485476017
step: 290, loss: 0.015955496579408646
step: 300, loss: 0.044084738940000534
step: 310, loss: 0.0858754813671112
step: 320, loss: 0.0523221381008625
step: 330, loss: 0.09756719321012497
step: 340, loss: 0.028136827051639557
step: 350, loss: 0.009413075633347034
step: 360, loss: 0.04571079462766647
step: 370, loss: 0.050442710518836975
step: 380, loss: 0.07885236293077469
step: 390, loss: 0.1103491485118866
step: 400, loss: 0.0009723726543597877
step: 410, loss: 0.16840222477912903
step: 420, loss: 0.07525984942913055
step: 430, loss: 0.026031149551272392
step: 440, loss: 0.059614986181259155
step: 450, loss: 0.01997952163219452
step: 460, loss: 0.0919080376625061
step: 470, loss: 0.0011081388220191002
step: 480, loss: 0.09698078781366348
step: 490, loss: 0.07035021483898163
step: 500, loss: 0.02770877256989479
step: 510, loss: 0.02809443697333336
step: 520, loss: 0.11392821371555328
step: 530, loss: 0.018783800303936005
step: 540, loss: 0.06513604521751404
step: 550, loss: 0.022257469594478607
step: 560, loss: 0.06750249117612839
step: 570, loss: 0.00029365619411692023
step: 580, loss: 0.12784132361412048
step: 590, loss: 0.058250170201063156
step: 600, loss: 0.09631296992301941
step: 610, loss: 0.09492616355419159
step: 620, loss: 0.020654531195759773
step: 630, loss: 0.00018641659698914737
step: 640, loss: 0.04617326334118843
step: 650, loss: 0.05713675171136856
step: 660, loss: 0.009927053935825825
step: 670, loss: 0.03255283832550049
step: 680, loss: 0.03201225772500038
step: 690, loss: 0.10784658044576645
step: 700, loss: 0.09888263791799545
step: 710, loss: 0.032331135123968124
step: 720, loss: 0.2989218533039093
step: 730, loss: 0.0535096600651741
step: 740, loss: 0.03523215278983116
step: 750, loss: 0.04595797881484032
step: 760, loss: 0.16148614883422852
step: 770, loss: 0.020304854959249496
step: 780, loss: 0.05833983048796654
step: 790, loss: 0.08691169321537018
step: 800, loss: 0.020107336342334747
step: 810, loss: 0.1871817260980606
step: 820, loss: 4.400184843689203e-05
step: 830, loss: 0.0714934766292572
step: 840, loss: 0.02373804897069931
step: 850, loss: 0.0006487979553639889
step: 860, loss: 0.07507965713739395
step: 870, loss: 0.10123872011899948
step: 880, loss: 0.009500726126134396
step: 890, loss: 0.04521854221820831
step: 900, loss: 0.016902387142181396
step: 910, loss: 0.08548054099082947
step: 920, loss: 0.027926236391067505
step: 930, loss: 0.07657492160797119
step: 940, loss: 0.043592870235443115
step: 950, loss: 0.00015278591308742762
step: 960, loss: 0.03645040839910507
step: 970, loss: 0.030893893912434578
step: 980, loss: 0.09743665158748627
step: 990, loss: 0.06094536930322647
step: 1000, loss: 0.049089670181274414
step: 1010, loss: 0.04581056162714958
step: 1020, loss: 0.20703689754009247
step: 1030, loss: 0.017799202352762222
step: 1040, loss: 0.04838118702173233
step: 1050, loss: 0.026553651317954063
step: 1060, loss: 0.05048464238643646
step: 1070, loss: 0.054149776697158813
epoch 13: dev_f1=0.926517571884984, f1=0.9281464530892448, best_f1=0.935771214252227
step: 0, loss: 0.07330651581287384
step: 10, loss: 0.08858770877122879
step: 20, loss: 0.047770075500011444
step: 30, loss: 0.02485274337232113
step: 40, loss: 0.019275682047009468
step: 50, loss: 0.023968635126948357
step: 60, loss: 0.033937692642211914
step: 70, loss: 0.026679236441850662
step: 80, loss: 0.03409307450056076
step: 90, loss: 0.020384985953569412
step: 100, loss: 0.01453645620495081
step: 110, loss: 0.01840774528682232
step: 120, loss: 0.04640434309840202
step: 130, loss: 0.04580306261777878
step: 140, loss: 0.07042323797941208
step: 150, loss: 0.0007421642658300698
step: 160, loss: 4.2681069317040965e-05
step: 170, loss: 0.03653468191623688
step: 180, loss: 0.06016061455011368
step: 190, loss: 0.06649991869926453
step: 200, loss: 0.02732440084218979
step: 210, loss: 0.011173732578754425
step: 220, loss: 0.033757589757442474
step: 230, loss: 0.032527122646570206
step: 240, loss: 0.0017107842722907662
step: 250, loss: 0.050420746207237244
step: 260, loss: 0.0037348915357142687
step: 270, loss: 0.09522820264101028
step: 280, loss: 0.10328946262598038
step: 290, loss: 0.11845873296260834
step: 300, loss: 0.06110425293445587
step: 310, loss: 0.04430308938026428
step: 320, loss: 0.061457522213459015
step: 330, loss: 0.05840174853801727
step: 340, loss: 0.0871221199631691
step: 350, loss: 0.041413433849811554
step: 360, loss: 0.018115125596523285
step: 370, loss: 0.02861602231860161
step: 380, loss: 0.022330621257424355
step: 390, loss: 0.050996556878089905
step: 400, loss: 0.09746042639017105
step: 410, loss: 0.13952834904193878
step: 420, loss: 0.02063816413283348
step: 430, loss: 0.03453196957707405
step: 440, loss: 0.032418373972177505
step: 450, loss: 0.030035194009542465
step: 460, loss: 0.03338472172617912
step: 470, loss: 0.05185814946889877
step: 480, loss: 0.04911132529377937
step: 490, loss: 1.9563194655347615e-05
step: 500, loss: 0.06335479766130447
step: 510, loss: 0.0460536815226078
step: 520, loss: 0.08404368907213211
step: 530, loss: 0.02638707496225834
step: 540, loss: 0.002226402284577489
step: 550, loss: 0.0716792643070221
step: 560, loss: 0.08498271554708481
step: 570, loss: 0.03296392410993576
step: 580, loss: 0.03904786705970764
step: 590, loss: 0.08574751764535904
step: 600, loss: 0.08496657013893127
step: 610, loss: 0.05271706357598305
step: 620, loss: 0.11271879076957703
step: 630, loss: 0.061426613479852676
step: 640, loss: 0.11607997119426727
step: 650, loss: 0.04274379834532738
step: 660, loss: 0.08695529401302338
step: 670, loss: 0.0352485328912735
step: 680, loss: 0.08215157687664032
step: 690, loss: 0.007821598090231419
step: 700, loss: 0.046978194266557693
step: 710, loss: 0.013936619274318218
step: 720, loss: 0.0005292298155836761
step: 730, loss: 0.13027842342853546
step: 740, loss: 0.02584744803607464
step: 750, loss: 0.03828136622905731
step: 760, loss: 0.04408606141805649
step: 770, loss: 0.04111538827419281
step: 780, loss: 0.14716172218322754
step: 790, loss: 0.0573866032063961
step: 800, loss: 0.05960680544376373
step: 810, loss: 0.17739148437976837
step: 820, loss: 0.0855904221534729
step: 830, loss: 0.04987553507089615
step: 840, loss: 0.0650906190276146
step: 850, loss: 0.18264856934547424
step: 860, loss: 0.0906764417886734
step: 870, loss: 0.0001147264483734034
step: 880, loss: 0.034608546644449234
step: 890, loss: 0.05513188987970352
step: 900, loss: 0.046639155596494675
step: 910, loss: 0.06405428051948547
step: 920, loss: 0.0006701860693283379
step: 930, loss: 0.041384462267160416
step: 940, loss: 0.08636679500341415
step: 950, loss: 0.031062817201018333
step: 960, loss: 0.053225189447402954
step: 970, loss: 0.05353708565235138
step: 980, loss: 0.04032124578952789
step: 990, loss: 0.0209822915494442
step: 1000, loss: 0.019467506557703018
step: 1010, loss: 0.09438024461269379
step: 1020, loss: 0.041342783719301224
step: 1030, loss: 0.09598275274038315
step: 1040, loss: 0.02958925999701023
step: 1050, loss: 0.0012145515065640211
step: 1060, loss: 0.06887236982584
step: 1070, loss: 9.458120621275157e-05
epoch 14: dev_f1=0.928212162780064, f1=0.9296803652968036, best_f1=0.935771214252227
step: 0, loss: 0.0855102613568306
step: 10, loss: 0.00013714851229451597
step: 20, loss: 0.09190193563699722
step: 30, loss: 0.028273683041334152
step: 40, loss: 0.029042445123195648
step: 50, loss: 0.06226836517453194
step: 60, loss: 0.030121352523565292
step: 70, loss: 0.025947799906134605
step: 80, loss: 0.04846969246864319
step: 90, loss: 0.10451605916023254
step: 100, loss: 0.0695422887802124
step: 110, loss: 0.03295855224132538
step: 120, loss: 0.048711709678173065
step: 130, loss: 0.012625382281839848
step: 140, loss: 0.021420467644929886
step: 150, loss: 0.042540982365608215
step: 160, loss: 0.07393898069858551
step: 170, loss: 0.06946777552366257
step: 180, loss: 0.056195978075265884
step: 190, loss: 0.03463273122906685
step: 200, loss: 0.04560750350356102
step: 210, loss: 0.044491641223430634
step: 220, loss: 9.235405741492286e-05
step: 230, loss: 0.060470856726169586
step: 240, loss: 0.09778772294521332
step: 250, loss: 0.09665975719690323
step: 260, loss: 0.0733165591955185
step: 270, loss: 0.04607117176055908
step: 280, loss: 0.005561194848269224
step: 290, loss: 0.13025885820388794
step: 300, loss: 0.024066288024187088
step: 310, loss: 0.05994649603962898
step: 320, loss: 0.047377198934555054
step: 330, loss: 0.01616109348833561
step: 340, loss: 0.026641439646482468
step: 350, loss: 0.05982963368296623
step: 360, loss: 0.07049711793661118
step: 370, loss: 0.12214362621307373
step: 380, loss: 0.07109485566616058
step: 390, loss: 0.0926135703921318
step: 400, loss: 0.009721420705318451
step: 410, loss: 0.0723498985171318
step: 420, loss: 0.0009078196017071605
step: 430, loss: 0.058125805109739304
step: 440, loss: 0.059940408915281296
step: 450, loss: 0.0662335604429245
step: 460, loss: 0.08852802962064743
step: 470, loss: 0.01769285276532173
step: 480, loss: 0.05695497244596481
step: 490, loss: 0.029812056571245193
step: 500, loss: 0.0517691969871521
step: 510, loss: 0.1392015516757965
step: 520, loss: 0.05745264142751694
step: 530, loss: 0.06270536780357361
step: 540, loss: 0.024557553231716156
step: 550, loss: 0.03997093439102173
step: 560, loss: 0.048189226537942886
step: 570, loss: 0.029316581785678864
step: 580, loss: 0.034615110605955124
step: 590, loss: 0.05571733042597771
step: 600, loss: 0.05009559541940689
step: 610, loss: 0.12228535860776901
step: 620, loss: 0.004592180252075195
step: 630, loss: 0.10867974162101746
step: 640, loss: 0.07098236680030823
step: 650, loss: 0.047394100576639175
step: 660, loss: 0.10407208651304245
step: 670, loss: 0.0726257935166359
step: 680, loss: 0.06505496799945831
step: 690, loss: 0.05938469246029854
step: 700, loss: 0.08803421258926392
step: 710, loss: 0.041254159063100815
step: 720, loss: 0.06732228398323059
step: 730, loss: 0.02598542720079422
step: 740, loss: 0.07538925111293793
step: 750, loss: 0.03731155022978783
step: 760, loss: 0.024041762575507164
step: 770, loss: 0.04159742221236229
step: 780, loss: 0.027722744271159172
step: 790, loss: 0.05935811996459961
step: 800, loss: 0.05641905218362808
step: 810, loss: 0.030540723353624344
step: 820, loss: 0.1723266839981079
step: 830, loss: 5.4799322242615744e-05
step: 840, loss: 0.16809743642807007
step: 850, loss: 0.04090655595064163
step: 860, loss: 0.05989239364862442
step: 870, loss: 0.04132477566599846
step: 880, loss: 0.036014944314956665
step: 890, loss: 0.0461038239300251
step: 900, loss: 0.07022985816001892
step: 910, loss: 0.024939168244600296
step: 920, loss: 0.021497884765267372
step: 930, loss: 0.03743952885270119
step: 940, loss: 0.16026844084262848
step: 950, loss: 0.059955768287181854
step: 960, loss: 0.17725959420204163
step: 970, loss: 0.035878460854291916
step: 980, loss: 0.027362648397684097
step: 990, loss: 0.08464331179857254
step: 1000, loss: 0.08314485102891922
step: 1010, loss: 0.01800384372472763
step: 1020, loss: 0.027788178995251656
step: 1030, loss: 0.06887131184339523
step: 1040, loss: 0.06759046018123627
step: 1050, loss: 0.0027715431060642004
step: 1060, loss: 0.08358605951070786
step: 1070, loss: 0.04508475214242935
epoch 15: dev_f1=0.9275229357798166, f1=0.9306384933394579, best_f1=0.935771214252227
step: 0, loss: 0.020629964768886566
step: 10, loss: 0.05149659886956215
step: 20, loss: 0.06943472474813461
step: 30, loss: 0.02340814284980297
step: 40, loss: 0.00015087772044353187
step: 50, loss: 0.012883675284683704
step: 60, loss: 0.02275303564965725
step: 70, loss: 0.08364725112915039
step: 80, loss: 0.0945204570889473
step: 90, loss: 0.051787298172712326
step: 100, loss: 0.054414428770542145
step: 110, loss: 0.06779905408620834
step: 120, loss: 0.015398945659399033
step: 130, loss: 0.0015046314802020788
step: 140, loss: 0.08064079284667969
step: 150, loss: 0.03227085992693901
step: 160, loss: 0.024379653856158257
step: 170, loss: 0.06701433658599854
step: 180, loss: 0.03826187551021576
step: 190, loss: 0.13773195445537567
step: 200, loss: 0.0890137106180191
step: 210, loss: 0.033126309514045715
step: 220, loss: 0.002390004461631179
step: 230, loss: 6.368509639287367e-05
step: 240, loss: 0.02455933392047882
step: 250, loss: 0.0001179350510938093
step: 260, loss: 8.143072773236781e-05
step: 270, loss: 0.0010511246509850025
step: 280, loss: 0.06752651184797287
step: 290, loss: 0.07019487768411636
step: 300, loss: 0.017155228182673454
step: 310, loss: 0.16009840369224548
step: 320, loss: 0.04160530865192413
step: 330, loss: 0.0013626946602016687
step: 340, loss: 0.036116957664489746
step: 350, loss: 0.07153294235467911
step: 360, loss: 0.06123719736933708
step: 370, loss: 0.07984703779220581
step: 380, loss: 0.06645991653203964
step: 390, loss: 0.005099347792565823
step: 400, loss: 0.02910122089087963
step: 410, loss: 0.04220568388700485
step: 420, loss: 0.04933289811015129
step: 430, loss: 0.04202030226588249
step: 440, loss: 0.01882239803671837
step: 450, loss: 0.07316677272319794
step: 460, loss: 0.03204052522778511
step: 470, loss: 0.018176039680838585
step: 480, loss: 0.025427965447306633
step: 490, loss: 0.0018054344691336155
step: 500, loss: 0.02539028972387314
step: 510, loss: 0.07580358535051346
step: 520, loss: 0.10682079941034317
step: 530, loss: 0.05921994149684906
step: 540, loss: 0.09446350485086441
step: 550, loss: 0.018990056589245796
step: 560, loss: 0.008484882302582264
step: 570, loss: 0.05937099829316139
step: 580, loss: 0.008593522943556309
step: 590, loss: 0.10770926624536514
step: 600, loss: 0.08614230901002884
step: 610, loss: 0.023822840303182602
step: 620, loss: 0.038398031145334244
step: 630, loss: 0.05574357882142067
step: 640, loss: 0.046245720237493515
step: 650, loss: 0.09793108701705933
step: 660, loss: 0.023986900225281715
step: 670, loss: 0.05766434594988823
step: 680, loss: 0.0002711544220801443
step: 690, loss: 0.014824491925537586
step: 700, loss: 0.06409473717212677
step: 710, loss: 0.022343600168824196
step: 720, loss: 0.022769343107938766
step: 730, loss: 0.06519563496112823
step: 740, loss: 0.09231887012720108
step: 750, loss: 0.00017490518803242594
step: 760, loss: 0.0007893285946920514
step: 770, loss: 0.001252492074854672
step: 780, loss: 0.08618272095918655
step: 790, loss: 0.021458575502038002
step: 800, loss: 0.06993645429611206
step: 810, loss: 0.08762668073177338
step: 820, loss: 0.03662406653165817
step: 830, loss: 0.06424424052238464
step: 840, loss: 0.12106917798519135
step: 850, loss: 0.08470972627401352
step: 860, loss: 0.06958731263875961
step: 870, loss: 0.04158041998744011
step: 880, loss: 0.06632893532514572
step: 890, loss: 0.02948014996945858
step: 900, loss: 0.07521726191043854
step: 910, loss: 0.04560742527246475
step: 920, loss: 0.036537446081638336
step: 930, loss: 0.0296781025826931
step: 940, loss: 0.0013184997951611876
step: 950, loss: 0.1241154745221138
step: 960, loss: 0.05881712958216667
step: 970, loss: 0.037293691188097
step: 980, loss: 0.03850395977497101
step: 990, loss: 0.09258783608675003
step: 1000, loss: 0.023340309038758278
step: 1010, loss: 0.025260940194129944
step: 1020, loss: 0.043165672570466995
step: 1030, loss: 0.06917455792427063
step: 1040, loss: 0.051094938069581985
step: 1050, loss: 0.018513742834329605
step: 1060, loss: 0.0013161844108253717
step: 1070, loss: 0.022675737738609314
epoch 16: dev_f1=0.9265116279069768, f1=0.9289363678588016, best_f1=0.935771214252227
step: 0, loss: 0.015828918665647507
step: 10, loss: 0.050864409655332565
step: 20, loss: 0.07332639396190643
step: 30, loss: 0.0718032643198967
step: 40, loss: 0.0715557187795639
step: 50, loss: 0.08605366945266724
step: 60, loss: 0.000611931667663157
step: 70, loss: 0.09952834993600845
step: 80, loss: 0.05554862320423126
step: 90, loss: 0.05526191368699074
step: 100, loss: 0.08643057942390442
step: 110, loss: 0.04976232722401619
step: 120, loss: 0.01639551855623722
step: 130, loss: 0.08615467697381973
step: 140, loss: 0.04816053807735443
step: 150, loss: 0.056793272495269775
step: 160, loss: 0.013419442810118198
step: 170, loss: 0.13936297595500946
step: 180, loss: 7.428422395605594e-05
step: 190, loss: 0.04145994782447815
step: 200, loss: 0.07360628992319107
step: 210, loss: 0.09162185341119766
step: 220, loss: 0.03591757267713547
step: 230, loss: 0.07572010159492493
step: 240, loss: 0.018327444791793823
step: 250, loss: 0.024994628503918648
step: 260, loss: 0.021924776956439018
step: 270, loss: 0.07576993852853775
step: 280, loss: 0.059425245970487595
step: 290, loss: 0.0788387805223465
step: 300, loss: 0.01025538519024849
step: 310, loss: 0.017912650480866432
step: 320, loss: 0.021671218797564507
step: 330, loss: 0.016121206805109978
step: 340, loss: 0.13196130096912384
step: 350, loss: 0.022952433675527573
step: 360, loss: 0.04642694070935249
step: 370, loss: 0.074795663356781
step: 380, loss: 0.0005926343146711588
step: 390, loss: 0.04899250715970993
step: 400, loss: 0.04256104305386543
step: 410, loss: 0.03182246536016464
step: 420, loss: 0.057012028992176056
step: 430, loss: 0.08163254708051682
step: 440, loss: 0.02149035781621933
step: 450, loss: 6.214707536855713e-05
step: 460, loss: 0.15447309613227844
step: 470, loss: 0.04667219892144203
step: 480, loss: 0.10235117375850677
step: 490, loss: 0.020454173907637596
step: 500, loss: 0.04891215264797211
step: 510, loss: 0.060792338103055954
step: 520, loss: 0.02660254016518593
step: 530, loss: 0.0477733351290226
step: 540, loss: 0.04701544716954231
step: 550, loss: 0.049406904727220535
step: 560, loss: 0.06720991432666779
step: 570, loss: 0.04671189934015274
step: 580, loss: 0.03367334604263306
step: 590, loss: 0.07388386130332947
step: 600, loss: 0.03522660583257675
step: 610, loss: 0.08938410878181458
step: 620, loss: 0.05308128148317337
step: 630, loss: 0.05524328351020813
step: 640, loss: 0.03469884395599365
step: 650, loss: 0.0029137814417481422
step: 660, loss: 0.16251221299171448
step: 670, loss: 0.05960551276803017
step: 680, loss: 0.016279976814985275
step: 690, loss: 0.05166468769311905
step: 700, loss: 0.08303368836641312
step: 710, loss: 0.1203184500336647
step: 720, loss: 0.02371148392558098
step: 730, loss: 2.948729343188461e-05
step: 740, loss: 0.05014105141162872
step: 750, loss: 0.0943029373884201
step: 760, loss: 5.313077417667955e-05
step: 770, loss: 0.0002929253096226603
step: 780, loss: 0.02223009057343006
step: 790, loss: 6.922851753188297e-05
step: 800, loss: 0.06246703863143921
step: 810, loss: 0.054296426475048065
step: 820, loss: 0.06614327430725098
step: 830, loss: 0.07265578955411911
step: 840, loss: 0.0003228505956940353
step: 850, loss: 2.612275056890212e-05
step: 860, loss: 0.058477506041526794
step: 870, loss: 0.013810482807457447
step: 880, loss: 0.1285611391067505
step: 890, loss: 0.022709378972649574
step: 900, loss: 0.01985340565443039
step: 910, loss: 0.03362699970602989
step: 920, loss: 0.0019820688758045435
step: 930, loss: 0.031942930072546005
step: 940, loss: 0.09252280741930008
step: 950, loss: 0.09172740578651428
step: 960, loss: 0.028422588482499123
step: 970, loss: 0.025937125086784363
step: 980, loss: 0.00010890322300838307
step: 990, loss: 0.030613765120506287
step: 1000, loss: 0.07344163209199905
step: 1010, loss: 1.070262078428641e-05
step: 1020, loss: 0.0001326570491073653
step: 1030, loss: 0.04400161653757095
step: 1040, loss: 0.03592877462506294
step: 1050, loss: 0.05018392205238342
step: 1060, loss: 0.023016659542918205
step: 1070, loss: 0.005982228554785252
epoch 17: dev_f1=0.9263947491795592, f1=0.9261176470588235, best_f1=0.935771214252227
step: 0, loss: 0.017361294478178024
step: 10, loss: 0.03767189010977745
step: 20, loss: 0.07889838516712189
step: 30, loss: 0.03729426860809326
step: 40, loss: 0.0712391585111618
step: 50, loss: 0.06585555523633957
step: 60, loss: 4.973077375325374e-05
step: 70, loss: 0.033177562057971954
step: 80, loss: 0.04171936213970184
step: 90, loss: 0.0033125351183116436
step: 100, loss: 0.02870698645710945
step: 110, loss: 0.017015686258673668
step: 120, loss: 0.04405796900391579
step: 130, loss: 0.024027617648243904
step: 140, loss: 0.06092224270105362
step: 150, loss: 0.021859340369701385
step: 160, loss: 0.04657689109444618
step: 170, loss: 0.022833798080682755
step: 180, loss: 0.003237624652683735
step: 190, loss: 0.02225654385983944
step: 200, loss: 0.0002477922535035759
step: 210, loss: 0.029345855116844177
step: 220, loss: 0.044776659458875656
step: 230, loss: 0.10280626267194748
step: 240, loss: 0.07711943238973618
step: 250, loss: 0.016652880236506462
step: 260, loss: 0.050533514469861984
step: 270, loss: 5.971190330456011e-05
step: 280, loss: 0.01826292648911476
step: 290, loss: 0.07042631506919861
step: 300, loss: 0.1535804569721222
step: 310, loss: 0.06907091289758682
step: 320, loss: 0.06739521771669388
step: 330, loss: 0.0005177209386602044
step: 340, loss: 0.034446436911821365
step: 350, loss: 0.03262715041637421
step: 360, loss: 0.0686056837439537
step: 370, loss: 0.03340664505958557
step: 380, loss: 1.2926304407301359e-05
step: 390, loss: 0.048532817512750626
step: 400, loss: 0.03549329563975334
step: 410, loss: 0.034274157136678696
step: 420, loss: 0.02075246348977089
step: 430, loss: 0.03558360040187836
step: 440, loss: 0.028722062706947327
step: 450, loss: 0.012698570266366005
step: 460, loss: 0.021127913147211075
step: 470, loss: 0.015609135851264
step: 480, loss: 0.03220590949058533
step: 490, loss: 0.05026824399828911
step: 500, loss: 0.013633782975375652
step: 510, loss: 0.051613714545965195
step: 520, loss: 0.04961295425891876
step: 530, loss: 3.1465806387132034e-05
step: 540, loss: 0.10579441487789154
step: 550, loss: 0.027045367285609245
step: 560, loss: 0.018599046394228935
step: 570, loss: 0.05814645439386368
step: 580, loss: 0.04759353771805763
step: 590, loss: 0.031116222962737083
step: 600, loss: 0.012016385793685913
step: 610, loss: 0.051471978425979614
step: 620, loss: 0.0023667733184993267
step: 630, loss: 0.07809507846832275
step: 640, loss: 0.01562991738319397
step: 650, loss: 0.029682941734790802
step: 660, loss: 0.05458095297217369
step: 670, loss: 0.019819779321551323
step: 680, loss: 0.02274266444146633
step: 690, loss: 0.014804886654019356
step: 700, loss: 0.013208967633545399
step: 710, loss: 0.036610692739486694
step: 720, loss: 0.014725095592439175
step: 730, loss: 0.052713919430971146
step: 740, loss: 0.002452592132613063
step: 750, loss: 0.002205977216362953
step: 760, loss: 0.031889885663986206
step: 770, loss: 0.019121957942843437
step: 780, loss: 0.018333258107304573
step: 790, loss: 0.02498054690659046
step: 800, loss: 0.06529147922992706
step: 810, loss: 0.02000599168241024
step: 820, loss: 0.008177786134183407
step: 830, loss: 0.033233121037483215
step: 840, loss: 1.0799506526382174e-05
step: 850, loss: 0.012786111794412136
step: 860, loss: 0.09010221809148788
step: 870, loss: 5.157035047886893e-05
step: 880, loss: 0.027775894850492477
step: 890, loss: 0.0260352473706007
step: 900, loss: 0.10742251574993134
step: 910, loss: 0.0711955651640892
step: 920, loss: 0.011185462586581707
step: 930, loss: 0.02539655938744545
step: 940, loss: 0.08073140680789948
step: 950, loss: 0.1030697152018547
step: 960, loss: 0.0928722620010376
step: 970, loss: 0.02966422215104103
step: 980, loss: 0.040639519691467285
step: 990, loss: 0.043585795909166336
step: 1000, loss: 0.13122069835662842
step: 1010, loss: 0.01438117865473032
step: 1020, loss: 0.035940807312726974
step: 1030, loss: 0.04312897473573685
step: 1040, loss: 3.4259966923855245e-05
step: 1050, loss: 0.017679788172245026
step: 1060, loss: 0.027921803295612335
step: 1070, loss: 0.02148188091814518
epoch 18: dev_f1=0.9264432029795159, f1=0.9286713286713286, best_f1=0.935771214252227
step: 0, loss: 0.007152199745178223
step: 10, loss: 0.03598718345165253
step: 20, loss: 0.040731992572546005
step: 30, loss: 0.050200995057821274
step: 40, loss: 0.09382196515798569
step: 50, loss: 0.08440138399600983
step: 60, loss: 0.050182245671749115
step: 70, loss: 0.054904285818338394
step: 80, loss: 0.021878106519579887
step: 90, loss: 0.012352707795798779
step: 100, loss: 0.08349744975566864
step: 110, loss: 0.12112665921449661
step: 120, loss: 0.03358727693557739
step: 130, loss: 0.05856991931796074
step: 140, loss: 0.020376188680529594
step: 150, loss: 0.02532263845205307
step: 160, loss: 0.02254694141447544
step: 170, loss: 0.03546764701604843
step: 180, loss: 0.0002339209313504398
step: 190, loss: 0.03451058641076088
step: 200, loss: 0.0903136134147644
step: 210, loss: 0.0438133142888546
step: 220, loss: 0.036503296345472336
step: 230, loss: 0.059270989149808884
step: 240, loss: 0.00015448540216311812
step: 250, loss: 0.03335445001721382
step: 260, loss: 0.08227156102657318
step: 270, loss: 0.030500149354338646
step: 280, loss: 0.031564854085445404
step: 290, loss: 0.053962111473083496
step: 300, loss: 0.0012488068314269185
step: 310, loss: 0.053378041833639145
step: 320, loss: 0.027620285749435425
step: 330, loss: 0.038423649966716766
step: 340, loss: 0.0376773439347744
step: 350, loss: 0.025643162429332733
step: 360, loss: 0.052595097571611404
step: 370, loss: 0.10602395236492157
step: 380, loss: 0.0030187671072781086
step: 390, loss: 0.0005383383249863982
step: 400, loss: 0.13812339305877686
step: 410, loss: 0.025800349190831184
step: 420, loss: 0.022745057940483093
step: 430, loss: 0.00019676366355270147
step: 440, loss: 0.032276153564453125
step: 450, loss: 0.10299921780824661
step: 460, loss: 0.016504010185599327
step: 470, loss: 0.04938556253910065
step: 480, loss: 0.07178919017314911
step: 490, loss: 0.04599287360906601
step: 500, loss: 0.03818180039525032
step: 510, loss: 0.02985389530658722
step: 520, loss: 0.11081182956695557
step: 530, loss: 0.07070458680391312
step: 540, loss: 0.0014368945267051458
step: 550, loss: 0.05550758168101311
step: 560, loss: 0.030112413689494133
step: 570, loss: 0.03991357982158661
step: 580, loss: 0.03428737819194794
step: 590, loss: 0.018387481570243835
step: 600, loss: 0.000931561749894172
step: 610, loss: 0.03324716538190842
step: 620, loss: 0.020785680040717125
step: 630, loss: 0.07376963645219803
step: 640, loss: 0.03336826711893082
step: 650, loss: 0.008974473923444748
step: 660, loss: 0.10049410164356232
step: 670, loss: 0.01793549209833145
step: 680, loss: 0.024280959740281105
step: 690, loss: 0.06124575436115265
step: 700, loss: 0.17919979989528656
step: 710, loss: 0.04955506697297096
step: 720, loss: 0.021939553320407867
step: 730, loss: 0.0002677068405319005
step: 740, loss: 0.037789251655340195
step: 750, loss: 0.024503495544195175
step: 760, loss: 0.030929088592529297
step: 770, loss: 0.05624135956168175
step: 780, loss: 0.055861227214336395
step: 790, loss: 0.03892740607261658
step: 800, loss: 0.08356938511133194
step: 810, loss: 0.07228686660528183
step: 820, loss: 0.14470481872558594
step: 830, loss: 0.09656371176242828
step: 840, loss: 0.020432576537132263
step: 850, loss: 0.040938667953014374
step: 860, loss: 0.02683800645172596
step: 870, loss: 1.0110350558534265e-05
step: 880, loss: 0.05393831431865692
step: 890, loss: 0.04044545441865921
step: 900, loss: 0.03300192952156067
step: 910, loss: 0.014845569618046284
step: 920, loss: 0.06277849525213242
step: 930, loss: 0.07427387684583664
step: 940, loss: 0.014430014416575432
step: 950, loss: 0.1882646083831787
step: 960, loss: 2.721137752814684e-05
step: 970, loss: 0.03331412002444267
step: 980, loss: 0.013857032172381878
step: 990, loss: 0.037851374596357346
step: 1000, loss: 0.037865061312913895
step: 1010, loss: 0.06539828330278397
step: 1020, loss: 0.033421654254198074
step: 1030, loss: 0.03725304454565048
step: 1040, loss: 0.02813524566590786
step: 1050, loss: 0.04980824142694473
step: 1060, loss: 0.03319673240184784
step: 1070, loss: 0.08981931209564209
epoch 19: dev_f1=0.9269427640763147, f1=0.9253731343283583, best_f1=0.935771214252227
step: 0, loss: 0.05320263281464577
step: 10, loss: 0.05398834869265556
step: 20, loss: 0.01653561182320118
step: 30, loss: 0.02645350806415081
step: 40, loss: 0.042572442442178726
step: 50, loss: 0.044790372252464294
step: 60, loss: 0.0959957018494606
step: 70, loss: 0.02059042453765869
step: 80, loss: 0.024393778294324875
step: 90, loss: 0.06720177829265594
step: 100, loss: 0.01559329591691494
step: 110, loss: 0.00689280778169632
step: 120, loss: 0.04483814537525177
step: 130, loss: 0.057698238641023636
step: 140, loss: 0.03290659934282303
step: 150, loss: 0.07211592048406601
step: 160, loss: 0.04545532912015915
step: 170, loss: 0.06858030706644058
step: 180, loss: 0.049086254090070724
step: 190, loss: 0.0727875679731369
step: 200, loss: 0.03627339377999306
step: 210, loss: 0.030456556007266045
step: 220, loss: 0.03733019530773163
step: 230, loss: 0.017663678154349327
step: 240, loss: 0.03568500652909279
step: 250, loss: 0.00015938279102556407
step: 260, loss: 0.01518316101282835
step: 270, loss: 0.04457608982920647
step: 280, loss: 0.1124114841222763
step: 290, loss: 0.06844072788953781
step: 300, loss: 0.0006827295874245465
step: 310, loss: 1.4010332051839214e-05
step: 320, loss: 0.0873417928814888
step: 330, loss: 0.06931848078966141
step: 340, loss: 0.0060927607119083405
step: 350, loss: 0.058352235704660416
step: 360, loss: 0.04111826419830322
step: 370, loss: 0.0013110109139233828
step: 380, loss: 0.03772589564323425
step: 390, loss: 0.08162924647331238
step: 400, loss: 0.05549284443259239
step: 410, loss: 0.008195004425942898
step: 420, loss: 0.06992143392562866
step: 430, loss: 0.02926592156291008
step: 440, loss: 0.03824277222156525
step: 450, loss: 0.04694860056042671
step: 460, loss: 0.02080516330897808
step: 470, loss: 0.040097832679748535
step: 480, loss: 0.04936762526631355
step: 490, loss: 0.04300132766366005
step: 500, loss: 0.021292390301823616
step: 510, loss: 0.0543050579726696
step: 520, loss: 0.018413309007883072
step: 530, loss: 0.11334897577762604
step: 540, loss: 0.03699830174446106
step: 550, loss: 0.01919492334127426
step: 560, loss: 0.013737939298152924
step: 570, loss: 0.019243743270635605
step: 580, loss: 0.06483136862516403
step: 590, loss: 1.0542437848926056e-05
step: 600, loss: 0.04924462363123894
step: 610, loss: 0.016989801079034805
step: 620, loss: 0.04769623279571533
step: 630, loss: 0.014793653041124344
step: 640, loss: 0.02251499705016613
step: 650, loss: 0.033224042505025864
step: 660, loss: 0.036622148007154465
step: 670, loss: 0.039887599647045135
step: 680, loss: 1.983975562325213e-05
step: 690, loss: 0.0914902314543724
step: 700, loss: 0.009839294478297234
step: 710, loss: 0.04678884521126747
step: 720, loss: 0.0601925291121006
step: 730, loss: 2.069153924821876e-05
step: 740, loss: 0.0341380350291729
step: 750, loss: 0.030386675149202347
step: 760, loss: 0.03329518809914589
step: 770, loss: 0.03848740831017494
step: 780, loss: 0.032319821417331696
step: 790, loss: 0.010255112312734127
step: 800, loss: 0.04291331768035889
step: 810, loss: 0.03189345821738243
step: 820, loss: 0.06731197237968445
step: 830, loss: 0.0010466703679412603
step: 840, loss: 7.432467100443318e-05
step: 850, loss: 0.06523448973894119
step: 860, loss: 0.04546240717172623
step: 870, loss: 0.0801495686173439
step: 880, loss: 7.681120041524991e-05
step: 890, loss: 0.00013375113485381007
step: 900, loss: 0.0007021554629318416
step: 910, loss: 0.02327301912009716
step: 920, loss: 0.08145838230848312
step: 930, loss: 7.321452721953392e-05
step: 940, loss: 0.014722727239131927
step: 950, loss: 0.0192544125020504
step: 960, loss: 0.013740137219429016
step: 970, loss: 0.06066739559173584
step: 980, loss: 0.020177360624074936
step: 990, loss: 0.022516833618283272
step: 1000, loss: 2.337482692382764e-05
step: 1010, loss: 0.04278042912483215
step: 1020, loss: 0.03082260861992836
step: 1030, loss: 0.12895914912223816
step: 1040, loss: 0.021201755851507187
step: 1050, loss: 0.1151094064116478
step: 1060, loss: 0.017294570803642273
step: 1070, loss: 0.022594070062041283
epoch 20: dev_f1=0.9263256687001408, f1=0.9219924812030075, best_f1=0.935771214252227
