cuda
Device: cuda
step: 0, loss: 0.6975752711296082
step: 10, loss: 0.6258211135864258
step: 20, loss: 0.42699962854385376
step: 30, loss: 0.45303085446357727
step: 40, loss: 0.22140024602413177
step: 50, loss: 0.32600945234298706
step: 60, loss: 0.2456868290901184
step: 70, loss: 0.17228588461875916
step: 80, loss: 0.3277440369129181
step: 90, loss: 0.17567911744117737
step: 100, loss: 0.3001856803894043
step: 110, loss: 0.24243776500225067
step: 120, loss: 0.27535775303840637
step: 130, loss: 0.1300993263721466
step: 140, loss: 0.18624264001846313
step: 150, loss: 0.24481512606143951
step: 160, loss: 0.18510702252388
step: 170, loss: 0.17094217240810394
step: 180, loss: 0.3657483756542206
step: 190, loss: 0.2068716287612915
step: 200, loss: 0.3003472685813904
step: 210, loss: 0.15208952128887177
step: 220, loss: 0.09431838989257812
step: 230, loss: 0.16157518327236176
step: 240, loss: 0.2571190297603607
step: 250, loss: 0.13656112551689148
step: 260, loss: 0.20706145465373993
step: 270, loss: 0.1515076607465744
step: 280, loss: 0.20381180942058563
step: 290, loss: 0.1102992445230484
step: 300, loss: 0.15498222410678864
step: 310, loss: 0.12584400177001953
step: 320, loss: 0.16970115900039673
step: 330, loss: 0.20600469410419464
step: 340, loss: 0.15072022378444672
step: 350, loss: 0.20568311214447021
step: 360, loss: 0.22859632968902588
step: 370, loss: 0.1486496478319168
step: 380, loss: 0.21403367817401886
step: 390, loss: 0.09026848524808884
step: 400, loss: 0.13430242240428925
step: 410, loss: 0.10064168274402618
step: 420, loss: 0.21691781282424927
step: 430, loss: 0.19636501371860504
step: 440, loss: 0.14979617297649384
step: 450, loss: 0.2026861608028412
step: 460, loss: 0.11826770752668381
step: 470, loss: 0.1482025384902954
step: 480, loss: 0.17792809009552002
step: 490, loss: 0.3338486850261688
step: 500, loss: 0.20366136729717255
step: 510, loss: 0.06041891872882843
step: 520, loss: 0.1328113079071045
step: 530, loss: 0.15893031656742096
step: 540, loss: 0.10761082917451859
step: 550, loss: 0.10344014316797256
step: 560, loss: 0.1447533667087555
step: 570, loss: 0.12038271874189377
step: 580, loss: 0.12850360572338104
step: 590, loss: 0.08091782033443451
step: 600, loss: 0.06643830239772797
step: 610, loss: 0.12345732003450394
step: 620, loss: 0.16648806631565094
step: 630, loss: 0.08918574452400208
step: 640, loss: 0.1927109956741333
step: 650, loss: 0.10355179011821747
step: 660, loss: 0.14936798810958862
step: 670, loss: 0.23229475319385529
step: 680, loss: 0.12186606973409653
step: 690, loss: 0.11175119131803513
step: 700, loss: 0.17600148916244507
step: 710, loss: 0.05235683545470238
step: 720, loss: 0.19183367490768433
step: 730, loss: 0.3335639536380768
step: 740, loss: 0.20550423860549927
step: 750, loss: 0.17572063207626343
step: 760, loss: 0.18900154531002045
step: 770, loss: 0.13642844557762146
step: 780, loss: 0.13307136297225952
step: 790, loss: 0.09130292385816574
step: 800, loss: 0.16966310143470764
step: 810, loss: 0.16138049960136414
step: 820, loss: 0.13882280886173248
step: 830, loss: 0.077420674264431
step: 840, loss: 0.1182560846209526
step: 850, loss: 0.11571521311998367
step: 860, loss: 0.13287433981895447
step: 870, loss: 0.14484289288520813
step: 880, loss: 0.1100669875741005
step: 890, loss: 0.1779746264219284
step: 900, loss: 0.45240122079849243
step: 910, loss: 0.0993957370519638
step: 920, loss: 0.06594341993331909
step: 930, loss: 0.06669524312019348
step: 940, loss: 0.10108986496925354
step: 950, loss: 0.1624394953250885
step: 960, loss: 0.014885957352817059
step: 970, loss: 0.061204396188259125
step: 980, loss: 0.10151097178459167
step: 990, loss: 0.16361433267593384
step: 1000, loss: 0.09157736599445343
step: 1010, loss: 0.11455913633108139
step: 1020, loss: 0.15678365528583527
step: 1030, loss: 0.12083421647548676
step: 1040, loss: 0.27601689100265503
step: 1050, loss: 0.06497953832149506
step: 1060, loss: 0.26780369877815247
step: 1070, loss: 0.20993447303771973
epoch 1: dev_f1=0.9244159413650939, f1=0.9208371246587808, best_f1=0.9208371246587808
step: 0, loss: 0.21100445091724396
step: 10, loss: 0.10505850613117218
step: 20, loss: 0.14928339421749115
step: 30, loss: 0.1251652091741562
step: 40, loss: 0.12996071577072144
step: 50, loss: 0.12439756840467453
step: 60, loss: 0.146851047873497
step: 70, loss: 0.11853121966123581
step: 80, loss: 0.20386561751365662
step: 90, loss: 0.2082863599061966
step: 100, loss: 0.11250195652246475
step: 110, loss: 0.04692927375435829
step: 120, loss: 0.17068873345851898
step: 130, loss: 0.05258092284202576
step: 140, loss: 0.11594707518815994
step: 150, loss: 0.13806378841400146
step: 160, loss: 0.1157044842839241
step: 170, loss: 0.16469471156597137
step: 180, loss: 0.052728042006492615
step: 190, loss: 0.1714300513267517
step: 200, loss: 0.08002070337533951
step: 210, loss: 0.13562454283237457
step: 220, loss: 0.08510196208953857
step: 230, loss: 0.12056282162666321
step: 240, loss: 0.1169067993760109
step: 250, loss: 0.16527096927165985
step: 260, loss: 0.06426813453435898
step: 270, loss: 0.14687225222587585
step: 280, loss: 0.05566360056400299
step: 290, loss: 0.1456858217716217
step: 300, loss: 0.09079117327928543
step: 310, loss: 0.15625296533107758
step: 320, loss: 0.04650683328509331
step: 330, loss: 0.13426081836223602
step: 340, loss: 0.0910438597202301
step: 350, loss: 0.07918951660394669
step: 360, loss: 0.05753147974610329
step: 370, loss: 0.05887426808476448
step: 380, loss: 0.1587177813053131
step: 390, loss: 0.11750597506761551
step: 400, loss: 0.25759994983673096
step: 410, loss: 0.11601904779672623
step: 420, loss: 0.091678686439991
step: 430, loss: 0.06621050834655762
step: 440, loss: 0.12489856779575348
step: 450, loss: 0.214889258146286
step: 460, loss: 0.09123224020004272
step: 470, loss: 0.0784493237733841
step: 480, loss: 0.11009267717599869
step: 490, loss: 0.05154123902320862
step: 500, loss: 0.17834559082984924
step: 510, loss: 0.1451951563358307
step: 520, loss: 0.20200501382350922
step: 530, loss: 0.07886748015880585
step: 540, loss: 0.08557106554508209
step: 550, loss: 0.032040633261203766
step: 560, loss: 0.06782231479883194
step: 570, loss: 0.08933012932538986
step: 580, loss: 0.05519230663776398
step: 590, loss: 0.14277850091457367
step: 600, loss: 0.117274709045887
step: 610, loss: 0.14080810546875
step: 620, loss: 0.031626176089048386
step: 630, loss: 0.08442480117082596
step: 640, loss: 0.16069163382053375
step: 650, loss: 0.12640070915222168
step: 660, loss: 0.07844425737857819
step: 670, loss: 0.10261139273643494
step: 680, loss: 0.09598840028047562
step: 690, loss: 0.17870712280273438
step: 700, loss: 0.07322956621646881
step: 710, loss: 0.15555796027183533
step: 720, loss: 0.09613828361034393
step: 730, loss: 0.1127811148762703
step: 740, loss: 0.1665581911802292
step: 750, loss: 0.05333337187767029
step: 760, loss: 0.09166033565998077
step: 770, loss: 0.045456770807504654
step: 780, loss: 0.10270639508962631
step: 790, loss: 0.08964627981185913
step: 800, loss: 0.07916714251041412
step: 810, loss: 0.0856081023812294
step: 820, loss: 0.09574273973703384
step: 830, loss: 0.10449740290641785
step: 840, loss: 0.35265251994132996
step: 850, loss: 0.11262273043394089
step: 860, loss: 0.11543918401002884
step: 870, loss: 0.047832589596509933
step: 880, loss: 0.07979976385831833
step: 890, loss: 0.13181227445602417
step: 900, loss: 0.20206913352012634
step: 910, loss: 0.1637016385793686
step: 920, loss: 0.029428942129015923
step: 930, loss: 0.16925163567066193
step: 940, loss: 0.11260585486888885
step: 950, loss: 0.108819879591465
step: 960, loss: 0.15207938849925995
step: 970, loss: 0.24658629298210144
step: 980, loss: 0.06147737801074982
step: 990, loss: 0.021889083087444305
step: 1000, loss: 0.0653848648071289
step: 1010, loss: 0.0902228057384491
step: 1020, loss: 0.13774628937244415
step: 1030, loss: 0.12016623467206955
step: 1040, loss: 0.22056172788143158
step: 1050, loss: 0.09781458228826523
step: 1060, loss: 0.03179578855633736
step: 1070, loss: 0.07291252166032791
epoch 2: dev_f1=0.9262672811059909, f1=0.9203296703296703, best_f1=0.9203296703296703
step: 0, loss: 0.13832904398441315
step: 10, loss: 0.11130762100219727
step: 20, loss: 0.048901066184043884
step: 30, loss: 0.06755702942609787
step: 40, loss: 0.11793311685323715
step: 50, loss: 0.12018504738807678
step: 60, loss: 0.152638241648674
step: 70, loss: 0.17445123195648193
step: 80, loss: 0.09785186499357224
step: 90, loss: 0.13733185827732086
step: 100, loss: 0.11579439789056778
step: 110, loss: 0.07764264941215515
step: 120, loss: 0.1604861468076706
step: 130, loss: 0.11428540199995041
step: 140, loss: 0.28016310930252075
step: 150, loss: 0.11668114364147186
step: 160, loss: 0.04181862249970436
step: 170, loss: 0.08986732363700867
step: 180, loss: 0.05478436499834061
step: 190, loss: 0.08027025312185287
step: 200, loss: 0.129721999168396
step: 210, loss: 0.13391682505607605
step: 220, loss: 0.115684375166893
step: 230, loss: 0.017357798293232918
step: 240, loss: 0.11141112446784973
step: 250, loss: 0.11862403899431229
step: 260, loss: 0.07180660218000412
step: 270, loss: 0.11482157558202744
step: 280, loss: 0.13638824224472046
step: 290, loss: 0.09359553456306458
step: 300, loss: 0.04208027571439743
step: 310, loss: 0.16875316202640533
step: 320, loss: 0.13109040260314941
step: 330, loss: 0.02921546995639801
step: 340, loss: 0.1452474594116211
step: 350, loss: 0.11179199069738388
step: 360, loss: 0.023409653455018997
step: 370, loss: 0.06348986178636551
step: 380, loss: 0.2142585664987564
step: 390, loss: 0.09874313324689865
step: 400, loss: 0.1305045783519745
step: 410, loss: 0.06729540228843689
step: 420, loss: 0.07623923569917679
step: 430, loss: 0.08880609273910522
step: 440, loss: 0.056411582976579666
step: 450, loss: 0.07891395688056946
step: 460, loss: 0.08262284845113754
step: 470, loss: 0.08352898061275482
step: 480, loss: 0.16184981167316437
step: 490, loss: 0.054664358496665955
step: 500, loss: 0.13593044877052307
step: 510, loss: 0.1356518715620041
step: 520, loss: 0.13974732160568237
step: 530, loss: 0.06954436004161835
step: 540, loss: 0.1334449201822281
step: 550, loss: 0.08535988628864288
step: 560, loss: 0.053165413439273834
step: 570, loss: 0.1557711362838745
step: 580, loss: 0.16232790052890778
step: 590, loss: 0.14504247903823853
step: 600, loss: 0.06612612307071686
step: 610, loss: 0.08078636974096298
step: 620, loss: 0.08621779084205627
step: 630, loss: 0.12171110510826111
step: 640, loss: 0.1196482926607132
step: 650, loss: 0.0011504079448059201
step: 660, loss: 0.11919989436864853
step: 670, loss: 0.16558414697647095
step: 680, loss: 0.10347135365009308
step: 690, loss: 0.02267403155565262
step: 700, loss: 0.24413727223873138
step: 710, loss: 0.0722663402557373
step: 720, loss: 0.1002807691693306
step: 730, loss: 0.05180102214217186
step: 740, loss: 0.19776344299316406
step: 750, loss: 0.08100304752588272
step: 760, loss: 0.12242791801691055
step: 770, loss: 0.04656841978430748
step: 780, loss: 0.039804257452487946
step: 790, loss: 0.09117675572633743
step: 800, loss: 0.0946405827999115
step: 810, loss: 0.11013072729110718
step: 820, loss: 0.05015577748417854
step: 830, loss: 0.03531485050916672
step: 840, loss: 0.15962915122509003
step: 850, loss: 0.13679559528827667
step: 860, loss: 0.03722791373729706
step: 870, loss: 0.080408476293087
step: 880, loss: 0.2482002079486847
step: 890, loss: 0.16815117001533508
step: 900, loss: 0.10466168075799942
step: 910, loss: 0.13017074763774872
step: 920, loss: 0.05848362669348717
step: 930, loss: 0.093723826110363
step: 940, loss: 0.0648069754242897
step: 950, loss: 0.06342970579862595
step: 960, loss: 0.14819298684597015
step: 970, loss: 0.2709101438522339
step: 980, loss: 0.13184165954589844
step: 990, loss: 0.0849473774433136
step: 1000, loss: 0.05215868726372719
step: 1010, loss: 0.13707232475280762
step: 1020, loss: 0.0330095998942852
step: 1030, loss: 0.1174134835600853
step: 1040, loss: 0.081595279276371
step: 1050, loss: 0.10090134292840958
step: 1060, loss: 0.07924354821443558
step: 1070, loss: 0.19614003598690033
epoch 3: dev_f1=0.9148936170212766, f1=0.9144434222631096, best_f1=0.9203296703296703
step: 0, loss: 0.12081341445446014
step: 10, loss: 0.1027313768863678
step: 20, loss: 0.1448935568332672
step: 30, loss: 0.067055344581604
step: 40, loss: 0.15028348565101624
step: 50, loss: 0.13877689838409424
step: 60, loss: 0.08457095921039581
step: 70, loss: 0.0878860354423523
step: 80, loss: 0.06535031646490097
step: 90, loss: 0.07569020241498947
step: 100, loss: 0.20669116079807281
step: 110, loss: 0.038660433143377304
step: 120, loss: 0.12175079435110092
step: 130, loss: 0.13645368814468384
step: 140, loss: 0.001685243216343224
step: 150, loss: 0.043304864317178726
step: 160, loss: 0.2878663241863251
step: 170, loss: 0.027572978287935257
step: 180, loss: 0.07859449833631516
step: 190, loss: 0.07342992722988129
step: 200, loss: 0.06999976933002472
step: 210, loss: 0.05975501611828804
step: 220, loss: 0.11495796591043472
step: 230, loss: 0.11970830708742142
step: 240, loss: 0.11370927840471268
step: 250, loss: 0.10990098863840103
step: 260, loss: 0.18553966283798218
step: 270, loss: 0.05215275660157204
step: 280, loss: 0.12154999375343323
step: 290, loss: 0.18211591243743896
step: 300, loss: 0.1263296753168106
step: 310, loss: 0.33293792605400085
step: 320, loss: 0.06070442497730255
step: 330, loss: 0.14577187597751617
step: 340, loss: 0.10702677071094513
step: 350, loss: 0.09795136004686356
step: 360, loss: 0.07514096796512604
step: 370, loss: 0.020330164581537247
step: 380, loss: 0.08245908468961716
step: 390, loss: 0.08349839597940445
step: 400, loss: 0.24844399094581604
step: 410, loss: 0.023037102073431015
step: 420, loss: 0.13262373208999634
step: 430, loss: 0.10503045469522476
step: 440, loss: 0.08179552853107452
step: 450, loss: 0.04952232912182808
step: 460, loss: 0.24597817659378052
step: 470, loss: 0.12800271809101105
step: 480, loss: 0.1794029325246811
step: 490, loss: 0.13589441776275635
step: 500, loss: 0.08383972942829132
step: 510, loss: 0.03516008332371712
step: 520, loss: 0.028174113482236862
step: 530, loss: 0.0042380173690617085
step: 540, loss: 0.17918117344379425
step: 550, loss: 0.050669144839048386
step: 560, loss: 0.06930505484342575
step: 570, loss: 0.1268944889307022
step: 580, loss: 0.07418972998857498
step: 590, loss: 0.0086348382756114
step: 600, loss: 0.10001856088638306
step: 610, loss: 0.17885053157806396
step: 620, loss: 0.12447822839021683
step: 630, loss: 0.10852334648370743
step: 640, loss: 0.1372510939836502
step: 650, loss: 0.05893012508749962
step: 660, loss: 0.08041123300790787
step: 670, loss: 0.06237723305821419
step: 680, loss: 0.09970667213201523
step: 690, loss: 0.06363219022750854
step: 700, loss: 0.06386694312095642
step: 710, loss: 0.13059286773204803
step: 720, loss: 0.16345560550689697
step: 730, loss: 0.1650180071592331
step: 740, loss: 0.11072977632284164
step: 750, loss: 0.11577173322439194
step: 760, loss: 0.18893715739250183
step: 770, loss: 0.007534774485975504
step: 780, loss: 0.034337785094976425
step: 790, loss: 0.0482795350253582
step: 800, loss: 0.08464766293764114
step: 810, loss: 0.19572892785072327
step: 820, loss: 0.074142687022686
step: 830, loss: 0.08685989677906036
step: 840, loss: 0.12183338403701782
step: 850, loss: 0.06787534803152084
step: 860, loss: 0.07829248905181885
step: 870, loss: 0.15135496854782104
step: 880, loss: 0.16380445659160614
step: 890, loss: 0.10541505366563797
step: 900, loss: 0.133413627743721
step: 910, loss: 0.0665125772356987
step: 920, loss: 0.06156475841999054
step: 930, loss: 0.24441100656986237
step: 940, loss: 0.05692273750901222
step: 950, loss: 0.057721201330423355
step: 960, loss: 0.1286420226097107
step: 970, loss: 0.06142023578286171
step: 980, loss: 0.02470817044377327
step: 990, loss: 0.2854756712913513
step: 1000, loss: 0.12033393979072571
step: 1010, loss: 0.09372714906930923
step: 1020, loss: 0.06971511989831924
step: 1030, loss: 0.12164720892906189
step: 1040, loss: 0.15884515643119812
step: 1050, loss: 0.09536096453666687
step: 1060, loss: 0.18426816165447235
step: 1070, loss: 0.17583014070987701
epoch 4: dev_f1=0.926463700234192, f1=0.924791086350975, best_f1=0.924791086350975
step: 0, loss: 0.08992301672697067
step: 10, loss: 0.06211060658097267
step: 20, loss: 0.008156069554388523
step: 30, loss: 0.15348801016807556
step: 40, loss: 0.05071065574884415
step: 50, loss: 0.11994801461696625
step: 60, loss: 0.057213373482227325
step: 70, loss: 0.10873880982398987
step: 80, loss: 0.03781374543905258
step: 90, loss: 0.13071328401565552
step: 100, loss: 0.08306063711643219
step: 110, loss: 0.09020780026912689
step: 120, loss: 0.021226204931735992
step: 130, loss: 0.028437981382012367
step: 140, loss: 0.13275763392448425
step: 150, loss: 0.07300782203674316
step: 160, loss: 0.10061677545309067
step: 170, loss: 0.2078579068183899
step: 180, loss: 0.1350414752960205
step: 190, loss: 0.12755729258060455
step: 200, loss: 0.036501120775938034
step: 210, loss: 0.10386228561401367
step: 220, loss: 0.0665246918797493
step: 230, loss: 0.11383222043514252
step: 240, loss: 0.07256686687469482
step: 250, loss: 0.1331246942281723
step: 260, loss: 0.12982740998268127
step: 270, loss: 0.0413205660879612
step: 280, loss: 0.08065931499004364
step: 290, loss: 0.00808826182037592
step: 300, loss: 0.1684536188840866
step: 310, loss: 0.14167778193950653
step: 320, loss: 0.07957835495471954
step: 330, loss: 0.12476605921983719
step: 340, loss: 0.2004472315311432
step: 350, loss: 0.04730262607336044
step: 360, loss: 0.09188511222600937
step: 370, loss: 0.055199068039655685
step: 380, loss: 0.06566425412893295
step: 390, loss: 0.03160388767719269
step: 400, loss: 0.0973203182220459
step: 410, loss: 0.21465377509593964
step: 420, loss: 0.07776094228029251
step: 430, loss: 0.09498108923435211
step: 440, loss: 0.02881723828613758
step: 450, loss: 0.11605203151702881
step: 460, loss: 0.22685520350933075
step: 470, loss: 0.24468307197093964
step: 480, loss: 0.09382981061935425
step: 490, loss: 0.11008387804031372
step: 500, loss: 0.09077166020870209
step: 510, loss: 0.0882076695561409
step: 520, loss: 0.1421443372964859
step: 530, loss: 0.07510092109441757
step: 540, loss: 0.07818193733692169
step: 550, loss: 0.13591593503952026
step: 560, loss: 0.06423118710517883
step: 570, loss: 0.13839836418628693
step: 580, loss: 0.07489027082920074
step: 590, loss: 0.06478103995323181
step: 600, loss: 0.05151813104748726
step: 610, loss: 0.12004780769348145
step: 620, loss: 0.12068092823028564
step: 630, loss: 0.07916049659252167
step: 640, loss: 0.13832037150859833
step: 650, loss: 0.03198392316699028
step: 660, loss: 0.12422341853380203
step: 670, loss: 0.008972270414233208
step: 680, loss: 0.07461203634738922
step: 690, loss: 0.06589650362730026
step: 700, loss: 0.11841725558042526
step: 710, loss: 0.09524787962436676
step: 720, loss: 0.038429517298936844
step: 730, loss: 0.039789460599422455
step: 740, loss: 0.08001800626516342
step: 750, loss: 0.08737079054117203
step: 760, loss: 0.046858616173267365
step: 770, loss: 0.08959466218948364
step: 780, loss: 0.07524877041578293
step: 790, loss: 0.00658272672444582
step: 800, loss: 0.002406573388725519
step: 810, loss: 0.04393555223941803
step: 820, loss: 0.1445024013519287
step: 830, loss: 0.1042783111333847
step: 840, loss: 0.06234660744667053
step: 850, loss: 0.1402852088212967
step: 860, loss: 0.0650026947259903
step: 870, loss: 0.19829188287258148
step: 880, loss: 0.014004269614815712
step: 890, loss: 0.16025970876216888
step: 900, loss: 0.10138754546642303
step: 910, loss: 0.10698748379945755
step: 920, loss: 0.14297421276569366
step: 930, loss: 0.13447479903697968
step: 940, loss: 0.1387280821800232
step: 950, loss: 0.13677629828453064
step: 960, loss: 0.1131947860121727
step: 970, loss: 0.06355834007263184
step: 980, loss: 0.0024346867576241493
step: 990, loss: 0.10194439440965652
step: 1000, loss: 0.12892356514930725
step: 1010, loss: 0.046311136335134506
step: 1020, loss: 0.053999412804841995
step: 1030, loss: 0.10224194079637527
step: 1040, loss: 0.19356374442577362
step: 1050, loss: 0.036329012364149094
step: 1060, loss: 0.09726326912641525
step: 1070, loss: 0.07293274253606796
epoch 5: dev_f1=0.9324200913242009, f1=0.9258079198907602, best_f1=0.9258079198907602
step: 0, loss: 0.13636989891529083
step: 10, loss: 0.027956314384937286
step: 20, loss: 0.057695016264915466
step: 30, loss: 0.049998894333839417
step: 40, loss: 0.12938490509986877
step: 50, loss: 0.078520268201828
step: 60, loss: 0.11249694228172302
step: 70, loss: 0.07693154364824295
step: 80, loss: 0.06515444070100784
step: 90, loss: 0.013176252134144306
step: 100, loss: 0.15263831615447998
step: 110, loss: 0.18316128849983215
step: 120, loss: 0.026865102350711823
step: 130, loss: 0.03762790933251381
step: 140, loss: 0.05281464383006096
step: 150, loss: 0.21256443858146667
step: 160, loss: 0.06188495084643364
step: 170, loss: 0.011165227741003036
step: 180, loss: 0.05793888494372368
step: 190, loss: 0.04296070709824562
step: 200, loss: 0.05118391290307045
step: 210, loss: 0.07802103459835052
step: 220, loss: 0.06331575661897659
step: 230, loss: 0.14813566207885742
step: 240, loss: 0.09309477359056473
step: 250, loss: 0.03730423003435135
step: 260, loss: 0.06428267061710358
step: 270, loss: 0.0751040056347847
step: 280, loss: 0.08340965211391449
step: 290, loss: 0.05079173296689987
step: 300, loss: 0.06601130962371826
step: 310, loss: 0.0723419263958931
step: 320, loss: 0.09887556731700897
step: 330, loss: 0.041030675172805786
step: 340, loss: 0.09038765728473663
step: 350, loss: 0.02407456748187542
step: 360, loss: 0.07800573855638504
step: 370, loss: 0.08758679777383804
step: 380, loss: 0.013336949981749058
step: 390, loss: 0.01832844689488411
step: 400, loss: 0.012107357382774353
step: 410, loss: 0.13929396867752075
step: 420, loss: 0.06308382004499435
step: 430, loss: 0.02496357075870037
step: 440, loss: 0.078945092856884
step: 450, loss: 0.035289470106363297
step: 460, loss: 0.11768369376659393
step: 470, loss: 0.06795041263103485
step: 480, loss: 0.13104744255542755
step: 490, loss: 0.07746584713459015
step: 500, loss: 0.08773045241832733
step: 510, loss: 0.08194707334041595
step: 520, loss: 0.06573768705129623
step: 530, loss: 0.04864940047264099
step: 540, loss: 0.17596092820167542
step: 550, loss: 0.01136629469692707
step: 560, loss: 0.1581547111272812
step: 570, loss: 0.10266709327697754
step: 580, loss: 0.12522128224372864
step: 590, loss: 0.08611340820789337
step: 600, loss: 0.1309228092432022
step: 610, loss: 0.07450888305902481
step: 620, loss: 0.032713882625103
step: 630, loss: 0.09488034248352051
step: 640, loss: 0.1572272926568985
step: 650, loss: 0.042399510741233826
step: 660, loss: 0.26452967524528503
step: 670, loss: 0.07002762705087662
step: 680, loss: 0.05617404729127884
step: 690, loss: 0.12746797502040863
step: 700, loss: 0.08095838129520416
step: 710, loss: 0.06275465339422226
step: 720, loss: 0.134505957365036
step: 730, loss: 0.1773555427789688
step: 740, loss: 0.19899830222129822
step: 750, loss: 0.15658222138881683
step: 760, loss: 0.07776854187250137
step: 770, loss: 0.05003409832715988
step: 780, loss: 0.08010595291852951
step: 790, loss: 0.11577287316322327
step: 800, loss: 0.1272769570350647
step: 810, loss: 0.07726065069437027
step: 820, loss: 0.12481570988893509
step: 830, loss: 0.2127378284931183
step: 840, loss: 0.088793084025383
step: 850, loss: 0.10209350287914276
step: 860, loss: 0.12796136736869812
step: 870, loss: 0.05200706049799919
step: 880, loss: 0.09093494713306427
step: 890, loss: 0.032241951674222946
step: 900, loss: 0.028069371357560158
step: 910, loss: 0.03992414474487305
step: 920, loss: 0.09257834404706955
step: 930, loss: 0.06558317691087723
step: 940, loss: 0.03670181706547737
step: 950, loss: 0.10980004072189331
step: 960, loss: 0.014666351489722729
step: 970, loss: 0.07896687090396881
step: 980, loss: 0.06890509277582169
step: 990, loss: 0.11863201856613159
step: 1000, loss: 0.10678714513778687
step: 1010, loss: 0.02825595997273922
step: 1020, loss: 0.12348107248544693
step: 1030, loss: 0.07346078753471375
step: 1040, loss: 0.10099770873785019
step: 1050, loss: 0.07792934030294418
step: 1060, loss: 0.052505411207675934
step: 1070, loss: 0.16038382053375244
epoch 6: dev_f1=0.9247606019151847, f1=0.921747042766151, best_f1=0.9258079198907602
step: 0, loss: 0.08748418837785721
step: 10, loss: 0.07116606831550598
step: 20, loss: 0.133257657289505
step: 30, loss: 0.033656127750873566
step: 40, loss: 0.13022594153881073
step: 50, loss: 0.07367250323295593
step: 60, loss: 0.004178452305495739
step: 70, loss: 0.0824335440993309
step: 80, loss: 0.026856087148189545
step: 90, loss: 0.04520385339856148
step: 100, loss: 0.0740155577659607
step: 110, loss: 0.10330509394407272
step: 120, loss: 0.05927252024412155
step: 130, loss: 0.09429705142974854
step: 140, loss: 0.10372667759656906
step: 150, loss: 0.08253701776266098
step: 160, loss: 0.09660062938928604
step: 170, loss: 0.014658204279839993
step: 180, loss: 0.045561183243989944
step: 190, loss: 0.039412107318639755
step: 200, loss: 0.07295691221952438
step: 210, loss: 0.0946730449795723
step: 220, loss: 0.0416368693113327
step: 230, loss: 0.0957631915807724
step: 240, loss: 0.032943375408649445
step: 250, loss: 0.14486631751060486
step: 260, loss: 0.19087396562099457
step: 270, loss: 0.07567836344242096
step: 280, loss: 0.06096860393881798
step: 290, loss: 0.035094715654850006
step: 300, loss: 0.056725528091192245
step: 310, loss: 0.04962383210659027
step: 320, loss: 0.14119377732276917
step: 330, loss: 0.0006068071234039962
step: 340, loss: 0.02251117303967476
step: 350, loss: 0.15020836889743805
step: 360, loss: 0.04255394637584686
step: 370, loss: 0.08640201389789581
step: 380, loss: 0.03803878650069237
step: 390, loss: 0.03241631016135216
step: 400, loss: 0.3324761986732483
step: 410, loss: 0.036405134946107864
step: 420, loss: 0.12833626568317413
step: 430, loss: 0.07510514557361603
step: 440, loss: 0.16504409909248352
step: 450, loss: 0.027745315805077553
step: 460, loss: 0.1836748719215393
step: 470, loss: 0.05844523012638092
step: 480, loss: 0.11488034576177597
step: 490, loss: 0.026660695672035217
step: 500, loss: 0.18801505863666534
step: 510, loss: 0.033424075692892075
step: 520, loss: 0.031361088156700134
step: 530, loss: 0.005695312283933163
step: 540, loss: 0.04664359614253044
step: 550, loss: 0.05849692225456238
step: 560, loss: 0.08972662687301636
step: 570, loss: 0.06536026298999786
step: 580, loss: 0.102370485663414
step: 590, loss: 0.023213405162096024
step: 600, loss: 0.025110360234975815
step: 610, loss: 0.0042979419231414795
step: 620, loss: 0.03987174108624458
step: 630, loss: 0.1027032732963562
step: 640, loss: 0.04729996621608734
step: 650, loss: 0.04592680558562279
step: 660, loss: 0.00374600850045681
step: 670, loss: 0.01720196008682251
step: 680, loss: 0.043422676622867584
step: 690, loss: 0.139423206448555
step: 700, loss: 0.07207676023244858
step: 710, loss: 0.06497535109519958
step: 720, loss: 0.06508243083953857
step: 730, loss: 0.014183657243847847
step: 740, loss: 0.05406172573566437
step: 750, loss: 0.13965997099876404
step: 760, loss: 0.15976852178573608
step: 770, loss: 0.05102326720952988
step: 780, loss: 0.09271590411663055
step: 790, loss: 0.10063748806715012
step: 800, loss: 0.032260242849588394
step: 810, loss: 0.18618522584438324
step: 820, loss: 0.0366838239133358
step: 830, loss: 0.08667026460170746
step: 840, loss: 0.05851024016737938
step: 850, loss: 0.07325843721628189
step: 860, loss: 0.09165763854980469
step: 870, loss: 0.02663988247513771
step: 880, loss: 0.10130655765533447
step: 890, loss: 0.04298437014222145
step: 900, loss: 0.02930457890033722
step: 910, loss: 0.054372530430555344
step: 920, loss: 0.27538612484931946
step: 930, loss: 0.0021356716752052307
step: 940, loss: 0.09818156808614731
step: 950, loss: 0.05554715916514397
step: 960, loss: 0.09847644716501236
step: 970, loss: 0.059590913355350494
step: 980, loss: 0.20197096467018127
step: 990, loss: 0.1830327808856964
step: 1000, loss: 0.045191314071416855
step: 1010, loss: 0.08635251224040985
step: 1020, loss: 0.10061413049697876
step: 1030, loss: 0.11147941648960114
step: 1040, loss: 0.0929766520857811
step: 1050, loss: 0.08198913931846619
step: 1060, loss: 0.07364524155855179
step: 1070, loss: 0.07218385487794876
epoch 7: dev_f1=0.9272727272727272, f1=0.9242630385487528, best_f1=0.9258079198907602
step: 0, loss: 0.11984675377607346
step: 10, loss: 0.05322966352105141
step: 20, loss: 0.0963931456208229
step: 30, loss: 0.2148825228214264
step: 40, loss: 0.07233721762895584
step: 50, loss: 0.07857682555913925
step: 60, loss: 0.04429733753204346
step: 70, loss: 0.05307118594646454
step: 80, loss: 0.07834959775209427
step: 90, loss: 0.11430852115154266
step: 100, loss: 0.08263327926397324
step: 110, loss: 0.03403264656662941
step: 120, loss: 0.10477445274591446
step: 130, loss: 0.02849920652806759
step: 140, loss: 0.13869966566562653
step: 150, loss: 0.09669974446296692
step: 160, loss: 0.08763151615858078
step: 170, loss: 0.06602553278207779
step: 180, loss: 0.21786832809448242
step: 190, loss: 0.1678961217403412
step: 200, loss: 0.0662025511264801
step: 210, loss: 0.10279053449630737
step: 220, loss: 0.15252868831157684
step: 230, loss: 0.02147655375301838
step: 240, loss: 0.04631005600094795
step: 250, loss: 0.16326817870140076
step: 260, loss: 0.017973382025957108
step: 270, loss: 0.08397214114665985
step: 280, loss: 0.0605989471077919
step: 290, loss: 0.039307113736867905
step: 300, loss: 0.03764971345663071
step: 310, loss: 0.06954367458820343
step: 320, loss: 0.1273343563079834
step: 330, loss: 0.05564890801906586
step: 340, loss: 0.08518175780773163
step: 350, loss: 0.18087373673915863
step: 360, loss: 0.07632424682378769
step: 370, loss: 0.14062190055847168
step: 380, loss: 0.1430589258670807
step: 390, loss: 0.026368308812379837
step: 400, loss: 0.037441667169332504
step: 410, loss: 0.07434087246656418
step: 420, loss: 0.10796946287155151
step: 430, loss: 0.07452543824911118
step: 440, loss: 0.14185498654842377
step: 450, loss: 0.06272003799676895
step: 460, loss: 0.03169148042798042
step: 470, loss: 0.06028120964765549
step: 480, loss: 0.03157459944486618
step: 490, loss: 0.062250830233097076
step: 500, loss: 0.08907326310873032
step: 510, loss: 0.028746122494339943
step: 520, loss: 0.07051055133342743
step: 530, loss: 0.027678705751895905
step: 540, loss: 0.10268362611532211
step: 550, loss: 0.061224766075611115
step: 560, loss: 0.051464468240737915
step: 570, loss: 0.05547791346907616
step: 580, loss: 0.19562678039073944
step: 590, loss: 0.13307566940784454
step: 600, loss: 0.06295207887887955
step: 610, loss: 0.08859912306070328
step: 620, loss: 0.10525158047676086
step: 630, loss: 0.14348354935646057
step: 640, loss: 0.08076266199350357
step: 650, loss: 0.04644891247153282
step: 660, loss: 0.06325621902942657
step: 670, loss: 0.11708951741456985
step: 680, loss: 0.04398862645030022
step: 690, loss: 0.0774318128824234
step: 700, loss: 0.14465437829494476
step: 710, loss: 0.029324064031243324
step: 720, loss: 0.043140679597854614
step: 730, loss: 0.06314884126186371
step: 740, loss: 0.0711924359202385
step: 750, loss: 0.06868026405572891
step: 760, loss: 0.010684332810342312
step: 770, loss: 0.07572086155414581
step: 780, loss: 0.07673081010580063
step: 790, loss: 0.1784525066614151
step: 800, loss: 0.03732974827289581
step: 810, loss: 0.08088171482086182
step: 820, loss: 0.04260550066828728
step: 830, loss: 0.041031043976545334
step: 840, loss: 0.04782517999410629
step: 850, loss: 0.05294331535696983
step: 860, loss: 0.05647484213113785
step: 870, loss: 0.037738535553216934
step: 880, loss: 0.19361868500709534
step: 890, loss: 0.09032660722732544
step: 900, loss: 0.12023431807756424
step: 910, loss: 0.056911054998636246
step: 920, loss: 0.15308159589767456
step: 930, loss: 0.0721147209405899
step: 940, loss: 0.22229397296905518
step: 950, loss: 0.13530850410461426
step: 960, loss: 0.09605899453163147
step: 970, loss: 0.08629048615694046
step: 980, loss: 0.03799998387694359
step: 990, loss: 0.09332875907421112
step: 1000, loss: 0.034503936767578125
step: 1010, loss: 0.05945408344268799
step: 1020, loss: 0.11672559380531311
step: 1030, loss: 0.06318306177854538
step: 1040, loss: 0.12997297942638397
step: 1050, loss: 0.017730144783854485
step: 1060, loss: 0.10090546309947968
step: 1070, loss: 0.035182129591703415
epoch 8: dev_f1=0.9285714285714285, f1=0.9230068337129841, best_f1=0.9258079198907602
step: 0, loss: 0.0711885392665863
step: 10, loss: 0.07631208002567291
step: 20, loss: 0.0829031765460968
step: 30, loss: 0.04203292354941368
step: 40, loss: 0.022607898339629173
step: 50, loss: 0.03198723495006561
step: 60, loss: 0.07255005091428757
step: 70, loss: 0.0519099123775959
step: 80, loss: 0.12641334533691406
step: 90, loss: 0.04660787805914879
step: 100, loss: 0.059297606348991394
step: 110, loss: 0.1380448192358017
step: 120, loss: 0.05975257605314255
step: 130, loss: 0.05434505641460419
step: 140, loss: 0.07656218111515045
step: 150, loss: 0.03588153049349785
step: 160, loss: 0.0072412979789078236
step: 170, loss: 0.017069434747099876
step: 180, loss: 0.021896496415138245
step: 190, loss: 0.03308464214205742
step: 200, loss: 0.0009832971263676882
step: 210, loss: 0.03241198882460594
step: 220, loss: 0.019412122666835785
step: 230, loss: 0.0805630311369896
step: 240, loss: 0.07462069392204285
step: 250, loss: 0.0798238068819046
step: 260, loss: 0.08236108720302582
step: 270, loss: 0.10490472614765167
step: 280, loss: 0.07340510934591293
step: 290, loss: 0.05774044245481491
step: 300, loss: 0.036659952253103256
step: 310, loss: 0.02218654379248619
step: 320, loss: 0.005954642314463854
step: 330, loss: 0.01288562174886465
step: 340, loss: 0.08072096109390259
step: 350, loss: 0.10063062608242035
step: 360, loss: 0.10529781877994537
step: 370, loss: 0.0640721544623375
step: 380, loss: 0.007397780194878578
step: 390, loss: 0.04759341850876808
step: 400, loss: 0.038120392709970474
step: 410, loss: 0.03051755204796791
step: 420, loss: 0.0796053409576416
step: 430, loss: 0.05562208220362663
step: 440, loss: 0.045548006892204285
step: 450, loss: 0.07067914307117462
step: 460, loss: 0.22834227979183197
step: 470, loss: 0.11647028475999832
step: 480, loss: 0.025423448532819748
step: 490, loss: 0.19317294657230377
step: 500, loss: 0.14169800281524658
step: 510, loss: 0.04188787564635277
step: 520, loss: 0.05033405125141144
step: 530, loss: 0.0892997607588768
step: 540, loss: 0.2638338506221771
step: 550, loss: 0.052242815494537354
step: 560, loss: 0.11591144651174545
step: 570, loss: 0.10532642900943756
step: 580, loss: 0.08921164274215698
step: 590, loss: 0.006756884511560202
step: 600, loss: 0.10612241178750992
step: 610, loss: 0.09389322996139526
step: 620, loss: 0.030889209359884262
step: 630, loss: 0.09099478274583817
step: 640, loss: 0.0709770917892456
step: 650, loss: 0.02232958748936653
step: 660, loss: 0.07880408316850662
step: 670, loss: 0.18972823023796082
step: 680, loss: 0.04247443005442619
step: 690, loss: 0.030834676697850227
step: 700, loss: 0.1437898874282837
step: 710, loss: 0.019367266446352005
step: 720, loss: 0.0016239274991676211
step: 730, loss: 0.08408887684345245
step: 740, loss: 0.12199365347623825
step: 750, loss: 0.10038331896066666
step: 760, loss: 0.04461584985256195
step: 770, loss: 0.0635545626282692
step: 780, loss: 0.11624294519424438
step: 790, loss: 0.01712092198431492
step: 800, loss: 0.03880416601896286
step: 810, loss: 0.1532384157180786
step: 820, loss: 0.19707649946212769
step: 830, loss: 0.00012956743012182415
step: 840, loss: 0.0715414509177208
step: 850, loss: 0.06423124670982361
step: 860, loss: 0.045137640088796616
step: 870, loss: 0.07312837243080139
step: 880, loss: 0.02663390338420868
step: 890, loss: 0.0105671351775527
step: 900, loss: 0.04332513362169266
step: 910, loss: 0.13849779963493347
step: 920, loss: 0.02529347874224186
step: 930, loss: 0.021455038338899612
step: 940, loss: 0.158564493060112
step: 950, loss: 0.08819909393787384
step: 960, loss: 0.030396509915590286
step: 970, loss: 0.03500088304281235
step: 980, loss: 0.07219317555427551
step: 990, loss: 0.0058057671412825584
step: 1000, loss: 0.033329419791698456
step: 1010, loss: 0.19068346917629242
step: 1020, loss: 0.07035889476537704
step: 1030, loss: 0.05034149810671806
step: 1040, loss: 0.036119479686021805
step: 1050, loss: 0.17838537693023682
step: 1060, loss: 0.08645321428775787
step: 1070, loss: 0.049137361347675323
epoch 9: dev_f1=0.9195837275307474, f1=0.9245994344957589, best_f1=0.9258079198907602
step: 0, loss: 0.05785186588764191
step: 10, loss: 0.03592905402183533
step: 20, loss: 0.056464388966560364
step: 30, loss: 0.05298192799091339
step: 40, loss: 0.05070021376013756
step: 50, loss: 0.1274060159921646
step: 60, loss: 0.08319713920354843
step: 70, loss: 0.04376358538866043
step: 80, loss: 0.13923989236354828
step: 90, loss: 0.13698670268058777
step: 100, loss: 0.06110890209674835
step: 110, loss: 0.019149618223309517
step: 120, loss: 0.048513054847717285
step: 130, loss: 0.07160064578056335
step: 140, loss: 0.034521400928497314
step: 150, loss: 0.11656380444765091
step: 160, loss: 0.029710303992033005
step: 170, loss: 0.033053234219551086
step: 180, loss: 0.005523970816284418
step: 190, loss: 0.031784795224666595
step: 200, loss: 0.11808343231678009
step: 210, loss: 0.08418598026037216
step: 220, loss: 0.1225963905453682
step: 230, loss: 0.07912704348564148
step: 240, loss: 0.11367332190275192
step: 250, loss: 0.07144574820995331
step: 260, loss: 0.10484829545021057
step: 270, loss: 0.04797431081533432
step: 280, loss: 0.023640703409910202
step: 290, loss: 0.05825674161314964
step: 300, loss: 0.03146013244986534
step: 310, loss: 0.07806643843650818
step: 320, loss: 0.05950406938791275
step: 330, loss: 0.05411270260810852
step: 340, loss: 0.03778970614075661
step: 350, loss: 0.07230518013238907
step: 360, loss: 0.04382045939564705
step: 370, loss: 0.010989086702466011
step: 380, loss: 0.03607804328203201
step: 390, loss: 0.11532288789749146
step: 400, loss: 0.010959728620946407
step: 410, loss: 0.12400896847248077
step: 420, loss: 0.02854633331298828
step: 430, loss: 0.23046933114528656
step: 440, loss: 0.13544997572898865
step: 450, loss: 0.07892075181007385
step: 460, loss: 0.1612098664045334
step: 470, loss: 0.07337857037782669
step: 480, loss: 0.018213631585240364
step: 490, loss: 0.06286785751581192
step: 500, loss: 0.021991640329360962
step: 510, loss: 0.030275175347924232
step: 520, loss: 0.10972362011671066
step: 530, loss: 0.12822917103767395
step: 540, loss: 0.09293306618928909
step: 550, loss: 0.0007984373951330781
step: 560, loss: 0.07968304306268692
step: 570, loss: 0.11849980056285858
step: 580, loss: 0.04649949073791504
step: 590, loss: 0.14904922246932983
step: 600, loss: 0.13623937964439392
step: 610, loss: 0.03537056967616081
step: 620, loss: 0.0505315363407135
step: 630, loss: 0.09871455281972885
step: 640, loss: 0.06210837513208389
step: 650, loss: 0.019674722105264664
step: 660, loss: 0.18216794729232788
step: 670, loss: 0.02760981023311615
step: 680, loss: 0.04999610036611557
step: 690, loss: 0.061858393251895905
step: 700, loss: 0.011104240082204342
step: 710, loss: 0.0381089448928833
step: 720, loss: 0.09680069983005524
step: 730, loss: 0.12150223553180695
step: 740, loss: 0.10562387853860855
step: 750, loss: 0.0585133358836174
step: 760, loss: 0.0891832783818245
step: 770, loss: 0.04661617800593376
step: 780, loss: 0.015707699581980705
step: 790, loss: 0.06613723933696747
step: 800, loss: 0.02426350675523281
step: 810, loss: 0.062129903584718704
step: 820, loss: 0.03049599565565586
step: 830, loss: 0.06461244821548462
step: 840, loss: 0.034643467515707016
step: 850, loss: 0.01998625509440899
step: 860, loss: 0.07861735671758652
step: 870, loss: 0.019476573914289474
step: 880, loss: 0.04721736162900925
step: 890, loss: 0.09512759000062943
step: 900, loss: 0.15359756350517273
step: 910, loss: 0.02031796984374523
step: 920, loss: 0.1475713849067688
step: 930, loss: 0.003382727038115263
step: 940, loss: 0.046003349125385284
step: 950, loss: 0.06838241219520569
step: 960, loss: 0.028342479839920998
step: 970, loss: 0.05331912636756897
step: 980, loss: 0.07166417688131332
step: 990, loss: 0.06659036129713058
step: 1000, loss: 0.07253725081682205
step: 1010, loss: 0.16582214832305908
step: 1020, loss: 0.009526185691356659
step: 1030, loss: 0.07569447159767151
step: 1040, loss: 0.28819650411605835
step: 1050, loss: 0.13882090151309967
step: 1060, loss: 0.00834739487618208
step: 1070, loss: 0.08751114457845688
epoch 10: dev_f1=0.923646459972235, f1=0.9250814332247558, best_f1=0.9258079198907602
step: 0, loss: 0.020331528037786484
step: 10, loss: 0.02061309665441513
step: 20, loss: 0.08482978492975235
step: 30, loss: 0.09544366598129272
step: 40, loss: 0.03464813157916069
step: 50, loss: 0.10407675057649612
step: 60, loss: 0.09764303267002106
step: 70, loss: 0.14714834094047546
step: 80, loss: 0.10421102494001389
step: 90, loss: 0.0939207375049591
step: 100, loss: 0.011059684678912163
step: 110, loss: 0.10525308549404144
step: 120, loss: 0.01682879589498043
step: 130, loss: 0.05168924853205681
step: 140, loss: 0.07508910447359085
step: 150, loss: 0.03717353194952011
step: 160, loss: 0.0845404788851738
step: 170, loss: 0.001292971195653081
step: 180, loss: 0.059956349432468414
step: 190, loss: 0.05503165349364281
step: 200, loss: 0.03228868544101715
step: 210, loss: 0.048979002982378006
step: 220, loss: 0.028979698196053505
step: 230, loss: 0.01856118068099022
step: 240, loss: 0.1364094614982605
step: 250, loss: 0.19725683331489563
step: 260, loss: 0.1348240077495575
step: 270, loss: 0.0030954708345234394
step: 280, loss: 0.08944277465343475
step: 290, loss: 0.028589190915226936
step: 300, loss: 0.026739010587334633
step: 310, loss: 0.03230902552604675
step: 320, loss: 0.11444233357906342
step: 330, loss: 0.13624787330627441
step: 340, loss: 0.021040473133325577
step: 350, loss: 0.06978479772806168
step: 360, loss: 0.1232844889163971
step: 370, loss: 0.07823004573583603
step: 380, loss: 0.014812598004937172
step: 390, loss: 0.052138157188892365
step: 400, loss: 0.085312120616436
step: 410, loss: 0.07522580772638321
step: 420, loss: 0.005444021429866552
step: 430, loss: 0.05280311778187752
step: 440, loss: 0.12138070911169052
step: 450, loss: 0.018607938662171364
step: 460, loss: 0.04563954472541809
step: 470, loss: 0.08145612478256226
step: 480, loss: 0.06734064221382141
step: 490, loss: 0.09788231551647186
step: 500, loss: 0.06445758789777756
step: 510, loss: 0.048129577189683914
step: 520, loss: 0.10931017994880676
step: 530, loss: 0.172858327627182
step: 540, loss: 0.027843043208122253
step: 550, loss: 0.09607844799757004
step: 560, loss: 0.10305962711572647
step: 570, loss: 0.06895383447408676
step: 580, loss: 0.0778430849313736
step: 590, loss: 0.03742072731256485
step: 600, loss: 0.06999842077493668
step: 610, loss: 0.10849794000387192
step: 620, loss: 0.06417696923017502
step: 630, loss: 0.005493685603141785
step: 640, loss: 0.1014610305428505
step: 650, loss: 0.044661104679107666
step: 660, loss: 0.08208221942186356
step: 670, loss: 0.09411187469959259
step: 680, loss: 0.02935379184782505
step: 690, loss: 0.039914898574352264
step: 700, loss: 0.07484634965658188
step: 710, loss: 0.04528345167636871
step: 720, loss: 0.07845856994390488
step: 730, loss: 0.11708632111549377
step: 740, loss: 0.07136800140142441
step: 750, loss: 0.07465768605470657
step: 760, loss: 0.027804875746369362
step: 770, loss: 0.04797157272696495
step: 780, loss: 0.08237157762050629
step: 790, loss: 0.0429617203772068
step: 800, loss: 0.046533141285181046
step: 810, loss: 0.03625674173235893
step: 820, loss: 0.002210028702393174
step: 830, loss: 0.08887511491775513
step: 840, loss: 0.170585036277771
step: 850, loss: 0.004523396957665682
step: 860, loss: 0.13594405353069305
step: 870, loss: 0.09641532599925995
step: 880, loss: 0.018439089879393578
step: 890, loss: 0.06661635637283325
step: 900, loss: 0.043071210384368896
step: 910, loss: 0.005699331406503916
step: 920, loss: 0.006244171876460314
step: 930, loss: 0.05939466506242752
step: 940, loss: 0.033306267112493515
step: 950, loss: 0.08031918853521347
step: 960, loss: 0.10311362892389297
step: 970, loss: 0.07151054590940475
step: 980, loss: 0.022623244673013687
step: 990, loss: 0.03294198960065842
step: 1000, loss: 0.011776209808886051
step: 1010, loss: 0.0458422489464283
step: 1020, loss: 0.10064123570919037
step: 1030, loss: 0.13523705303668976
step: 1040, loss: 0.03537654131650925
step: 1050, loss: 0.1085706278681755
step: 1060, loss: 0.13635486364364624
step: 1070, loss: 0.08346632122993469
epoch 11: dev_f1=0.9315448658649398, f1=0.9201661282879556, best_f1=0.9258079198907602
step: 0, loss: 0.03074715845286846
step: 10, loss: 0.06778673082590103
step: 20, loss: 0.015028589405119419
step: 30, loss: 0.0038548866286873817
step: 40, loss: 0.13023142516613007
step: 50, loss: 0.03493354469537735
step: 60, loss: 0.02463373728096485
step: 70, loss: 0.03161344304680824
step: 80, loss: 0.06355851143598557
step: 90, loss: 0.09962943941354752
step: 100, loss: 0.00017630236106924713
step: 110, loss: 0.030102692544460297
step: 120, loss: 0.13397562503814697
step: 130, loss: 0.09326379001140594
step: 140, loss: 0.14100907742977142
step: 150, loss: 0.0006628725095652044
step: 160, loss: 0.030230091884732246
step: 170, loss: 0.007344125770032406
step: 180, loss: 0.04038253799080849
step: 190, loss: 0.033773407340049744
step: 200, loss: 0.044984716922044754
step: 210, loss: 0.056745439767837524
step: 220, loss: 0.049868520349264145
step: 230, loss: 0.10401112586259842
step: 240, loss: 0.10549233853816986
step: 250, loss: 0.08950725942850113
step: 260, loss: 0.17776724696159363
step: 270, loss: 0.04738585278391838
step: 280, loss: 0.07585160434246063
step: 290, loss: 0.09035244584083557
step: 300, loss: 0.05949299409985542
step: 310, loss: 0.050987254828214645
step: 320, loss: 0.070194311439991
step: 330, loss: 0.03946375474333763
step: 340, loss: 0.09184618294239044
step: 350, loss: 0.04361407086253166
step: 360, loss: 0.03842097148299217
step: 370, loss: 0.007240171544253826
step: 380, loss: 0.10574985295534134
step: 390, loss: 0.11487071961164474
step: 400, loss: 0.04284655675292015
step: 410, loss: 0.05581410974264145
step: 420, loss: 0.10125788301229477
step: 430, loss: 0.07216522097587585
step: 440, loss: 0.026362938806414604
step: 450, loss: 0.01831795834004879
step: 460, loss: 0.018787931650877
step: 470, loss: 0.06991670280694962
step: 480, loss: 0.04553881287574768
step: 490, loss: 0.06816253066062927
step: 500, loss: 0.05162845179438591
step: 510, loss: 0.03473583981394768
step: 520, loss: 0.07263287156820297
step: 530, loss: 0.01914043352007866
step: 540, loss: 0.14279049634933472
step: 550, loss: 0.027164874598383904
step: 560, loss: 0.012292989529669285
step: 570, loss: 0.05648273974657059
step: 580, loss: 0.05691760033369064
step: 590, loss: 0.021898332983255386
step: 600, loss: 0.08032093197107315
step: 610, loss: 0.0010659225517883897
step: 620, loss: 0.07524855434894562
step: 630, loss: 0.0601462721824646
step: 640, loss: 0.06822513043880463
step: 650, loss: 0.09539013355970383
step: 660, loss: 0.05390050262212753
step: 670, loss: 0.036337196826934814
step: 680, loss: 0.005991735029965639
step: 690, loss: 0.0623406320810318
step: 700, loss: 0.16413195431232452
step: 710, loss: 0.044654250144958496
step: 720, loss: 0.01988724246621132
step: 730, loss: 0.07492392510175705
step: 740, loss: 0.1719582974910736
step: 750, loss: 0.08970741182565689
step: 760, loss: 0.12113912403583527
step: 770, loss: 0.07453250885009766
step: 780, loss: 0.08274539560079575
step: 790, loss: 0.01634390838444233
step: 800, loss: 0.05632801353931427
step: 810, loss: 0.07320088893175125
step: 820, loss: 0.06567701697349548
step: 830, loss: 0.00012825375597458333
step: 840, loss: 0.0034451307728886604
step: 850, loss: 0.18185997009277344
step: 860, loss: 0.04328852891921997
step: 870, loss: 0.05199844017624855
step: 880, loss: 0.10996127128601074
step: 890, loss: 0.009453041478991508
step: 900, loss: 0.04625239968299866
step: 910, loss: 0.10965222865343094
step: 920, loss: 0.0395386777818203
step: 930, loss: 0.022651556879281998
step: 940, loss: 0.0018038899870589375
step: 950, loss: 0.2509009540081024
step: 960, loss: 0.07043751329183578
step: 970, loss: 0.04184436798095703
step: 980, loss: 0.10381151735782623
step: 990, loss: 0.08744142949581146
step: 1000, loss: 0.09781970828771591
step: 1010, loss: 0.04200386628508568
step: 1020, loss: 0.05737297981977463
step: 1030, loss: 0.05187375470995903
step: 1040, loss: 8.339661144418642e-05
step: 1050, loss: 0.000859081803355366
step: 1060, loss: 0.27797314524650574
step: 1070, loss: 0.010272952727973461
epoch 12: dev_f1=0.921451538814883, f1=0.9198895027624309, best_f1=0.9258079198907602
step: 0, loss: 0.06548656523227692
step: 10, loss: 0.11687704175710678
step: 20, loss: 0.044572409242391586
step: 30, loss: 0.023479677736759186
step: 40, loss: 0.04759924113750458
step: 50, loss: 0.004666480235755444
step: 60, loss: 0.04053327813744545
step: 70, loss: 0.022429708391427994
step: 80, loss: 0.06590104848146439
step: 90, loss: 0.11396804451942444
step: 100, loss: 0.0758010670542717
step: 110, loss: 0.06586892902851105
step: 120, loss: 0.016715489327907562
step: 130, loss: 0.08421594649553299
step: 140, loss: 0.014180559664964676
step: 150, loss: 0.14413227140903473
step: 160, loss: 0.10622537136077881
step: 170, loss: 0.055921316146850586
step: 180, loss: 0.003321481868624687
step: 190, loss: 0.1035933643579483
step: 200, loss: 0.00019120884826406837
step: 210, loss: 0.012109809555113316
step: 220, loss: 0.03823035955429077
step: 230, loss: 0.06441446393728256
step: 240, loss: 0.04959452152252197
step: 250, loss: 0.054199472069740295
step: 260, loss: 0.0005108168697915971
step: 270, loss: 0.13891252875328064
step: 280, loss: 0.03285088762640953
step: 290, loss: 0.07725510001182556
step: 300, loss: 0.06923701614141464
step: 310, loss: 0.07071112096309662
step: 320, loss: 0.0290250014513731
step: 330, loss: 0.007050550077110529
step: 340, loss: 0.02930038794875145
step: 350, loss: 0.017639098688960075
step: 360, loss: 0.027425140142440796
step: 370, loss: 0.12070625275373459
step: 380, loss: 0.044746316969394684
step: 390, loss: 0.032269351184368134
step: 400, loss: 0.026259785518050194
step: 410, loss: 0.018141290172934532
step: 420, loss: 0.02448112890124321
step: 430, loss: 0.03847998380661011
step: 440, loss: 0.00442648446187377
step: 450, loss: 0.1329195350408554
step: 460, loss: 0.04606219381093979
step: 470, loss: 0.02629103884100914
step: 480, loss: 0.06960717588663101
step: 490, loss: 0.036621857434511185
step: 500, loss: 0.06645043939352036
step: 510, loss: 0.03762403130531311
step: 520, loss: 0.04931781813502312
step: 530, loss: 0.10096903890371323
step: 540, loss: 0.021461229771375656
step: 550, loss: 0.058443207293748856
step: 560, loss: 0.035243839025497437
step: 570, loss: 0.0002351941220695153
step: 580, loss: 0.035257626324892044
step: 590, loss: 0.17519904673099518
step: 600, loss: 0.11105664819478989
step: 610, loss: 0.05129602551460266
step: 620, loss: 0.04237210005521774
step: 630, loss: 0.028736699372529984
step: 640, loss: 0.040739163756370544
step: 650, loss: 0.012109456583857536
step: 660, loss: 0.08170608431100845
step: 670, loss: 0.06084645539522171
step: 680, loss: 0.06183632090687752
step: 690, loss: 0.029774611815810204
step: 700, loss: 0.08945390582084656
step: 710, loss: 0.1449434757232666
step: 720, loss: 0.028733201324939728
step: 730, loss: 0.030404984951019287
step: 740, loss: 0.04257458820939064
step: 750, loss: 0.013274092227220535
step: 760, loss: 0.051011599600315094
step: 770, loss: 0.039035651832818985
step: 780, loss: 0.006600667256861925
step: 790, loss: 0.013515143655240536
step: 800, loss: 0.013243145309388638
step: 810, loss: 0.006220168434083462
step: 820, loss: 0.06003343313932419
step: 830, loss: 0.15337440371513367
step: 840, loss: 0.045036450028419495
step: 850, loss: 0.11008749902248383
step: 860, loss: 0.052495941519737244
step: 870, loss: 0.13915753364562988
step: 880, loss: 0.051398858428001404
step: 890, loss: 0.039553433656692505
step: 900, loss: 0.08178339898586273
step: 910, loss: 0.06248374283313751
step: 920, loss: 0.059869859367609024
step: 930, loss: 0.136209636926651
step: 940, loss: 0.03784560412168503
step: 950, loss: 0.040502291172742844
step: 960, loss: 0.02719341218471527
step: 970, loss: 0.05893532559275627
step: 980, loss: 0.10269581526517868
step: 990, loss: 0.0987909808754921
step: 1000, loss: 0.018691543489694595
step: 1010, loss: 0.08970631659030914
step: 1020, loss: 0.02802548184990883
step: 1030, loss: 0.017806414514780045
step: 1040, loss: 0.015687817707657814
step: 1050, loss: 0.2834218740463257
step: 1060, loss: 0.07653430104255676
step: 1070, loss: 0.32576555013656616
epoch 13: dev_f1=0.9265588914549654, f1=0.9255663430420712, best_f1=0.9258079198907602
step: 0, loss: 0.09662473201751709
step: 10, loss: 0.08179424703121185
step: 20, loss: 0.024317419156432152
step: 30, loss: 0.03631417825818062
step: 40, loss: 0.012268791906535625
step: 50, loss: 0.055327072739601135
step: 60, loss: 0.0020011619199067354
step: 70, loss: 0.10137671232223511
step: 80, loss: 0.08651910722255707
step: 90, loss: 0.0860929787158966
step: 100, loss: 0.00313193560577929
step: 110, loss: 0.14775210618972778
step: 120, loss: 0.0698646530508995
step: 130, loss: 0.14414335787296295
step: 140, loss: 0.010752699337899685
step: 150, loss: 0.01321522705256939
step: 160, loss: 0.06814203411340714
step: 170, loss: 3.1631825549993664e-05
step: 180, loss: 0.00913669727742672
step: 190, loss: 0.09389021247625351
step: 200, loss: 0.018660908564925194
step: 210, loss: 0.07601712644100189
step: 220, loss: 0.11955704540014267
step: 230, loss: 0.017945531755685806
step: 240, loss: 0.03218076750636101
step: 250, loss: 0.02256515435874462
step: 260, loss: 0.13993221521377563
step: 270, loss: 0.007033583242446184
step: 280, loss: 0.04067397117614746
step: 290, loss: 0.015859724953770638
step: 300, loss: 0.004750695079565048
step: 310, loss: 0.02708444558084011
step: 320, loss: 0.0692417249083519
step: 330, loss: 0.05092385783791542
step: 340, loss: 0.09076188504695892
step: 350, loss: 0.039482105523347855
step: 360, loss: 0.017114313319325447
step: 370, loss: 0.0279674269258976
step: 380, loss: 0.02841225638985634
step: 390, loss: 0.0522671714425087
step: 400, loss: 0.06716902554035187
step: 410, loss: 0.00714137451723218
step: 420, loss: 0.03960568457841873
step: 430, loss: 0.08058619499206543
step: 440, loss: 0.06346037238836288
step: 450, loss: 0.0042641013860702515
step: 460, loss: 0.021385395899415016
step: 470, loss: 0.1311665177345276
step: 480, loss: 0.08343818783760071
step: 490, loss: 0.07921697944402695
step: 500, loss: 0.1080646887421608
step: 510, loss: 0.00893195066601038
step: 520, loss: 0.06462905555963516
step: 530, loss: 0.07414281368255615
step: 540, loss: 0.051745567470788956
step: 550, loss: 0.17043457925319672
step: 560, loss: 0.10704745352268219
step: 570, loss: 0.06154634803533554
step: 580, loss: 0.042094744741916656
step: 590, loss: 0.019377930089831352
step: 600, loss: 0.03305831179022789
step: 610, loss: 0.034100666642189026
step: 620, loss: 0.0025714952498674393
step: 630, loss: 0.03226814046502113
step: 640, loss: 0.08650390803813934
step: 650, loss: 0.09616175293922424
step: 660, loss: 0.08749740570783615
step: 670, loss: 0.03283308446407318
step: 680, loss: 0.036639437079429626
step: 690, loss: 0.0015397982206195593
step: 700, loss: 0.06264133006334305
step: 710, loss: 0.1098962351679802
step: 720, loss: 0.0619659423828125
step: 730, loss: 0.04512280970811844
step: 740, loss: 0.023886434733867645
step: 750, loss: 0.09410464763641357
step: 760, loss: 0.07524137198925018
step: 770, loss: 0.023181583732366562
step: 780, loss: 0.07990336418151855
step: 790, loss: 0.022021539509296417
step: 800, loss: 0.06352156400680542
step: 810, loss: 0.04837431758642197
step: 820, loss: 0.03189297765493393
step: 830, loss: 0.06846614927053452
step: 840, loss: 0.013167835772037506
step: 850, loss: 0.060284536331892014
step: 860, loss: 0.015092353336513042
step: 870, loss: 0.043637216091156006
step: 880, loss: 0.0249580517411232
step: 890, loss: 0.02733752690255642
step: 900, loss: 0.07234664261341095
step: 910, loss: 0.044931575655937195
step: 920, loss: 0.08293008804321289
step: 930, loss: 0.042082831263542175
step: 940, loss: 0.02955186739563942
step: 950, loss: 0.028895368799567223
step: 960, loss: 0.004549842327833176
step: 970, loss: 0.029406795278191566
step: 980, loss: 0.08628105372190475
step: 990, loss: 0.10129906982183456
step: 1000, loss: 0.06266999244689941
step: 1010, loss: 0.08460188657045364
step: 1020, loss: 0.04708816111087799
step: 1030, loss: 0.14211539924144745
step: 1040, loss: 0.01044751051813364
step: 1050, loss: 0.015159646049141884
step: 1060, loss: 0.03367194905877113
step: 1070, loss: 0.06987210363149643
epoch 14: dev_f1=0.9286376274328081, f1=0.9214318921431893, best_f1=0.9258079198907602
step: 0, loss: 0.010833606123924255
step: 10, loss: 0.057509008795022964
step: 20, loss: 0.0036166838835924864
step: 30, loss: 7.55549845052883e-05
step: 40, loss: 0.066628098487854
step: 50, loss: 0.04263002425432205
step: 60, loss: 0.02207186631858349
step: 70, loss: 0.08381307125091553
step: 80, loss: 0.029507821425795555
step: 90, loss: 0.0650043860077858
step: 100, loss: 0.06251901388168335
step: 110, loss: 0.082367442548275
step: 120, loss: 0.05697674676775932
step: 130, loss: 0.036259330809116364
step: 140, loss: 0.06557395309209824
step: 150, loss: 0.07667314261198044
step: 160, loss: 0.051891908049583435
step: 170, loss: 0.019688045606017113
step: 180, loss: 0.09460730105638504
step: 190, loss: 0.06966841965913773
step: 200, loss: 0.10545114427804947
step: 210, loss: 0.060414183884859085
step: 220, loss: 0.11486812680959702
step: 230, loss: 0.07051070034503937
step: 240, loss: 0.0002818087814375758
step: 250, loss: 7.711456419201568e-05
step: 260, loss: 0.1256565898656845
step: 270, loss: 0.01956813596189022
step: 280, loss: 0.028380591422319412
step: 290, loss: 0.020527614280581474
step: 300, loss: 0.0017680615419521928
step: 310, loss: 0.03052655979990959
step: 320, loss: 0.007411740720272064
step: 330, loss: 0.03260277956724167
step: 340, loss: 0.073683001101017
step: 350, loss: 0.02023097313940525
step: 360, loss: 0.03403598442673683
step: 370, loss: 0.006519592832773924
step: 380, loss: 0.032964374870061874
step: 390, loss: 0.0009273374453186989
step: 400, loss: 0.07372161000967026
step: 410, loss: 0.028536224737763405
step: 420, loss: 0.017909279093146324
step: 430, loss: 0.03640118986368179
step: 440, loss: 0.02297016605734825
step: 450, loss: 0.047941360622644424
step: 460, loss: 0.07172306627035141
step: 470, loss: 0.04250197112560272
step: 480, loss: 0.04196464270353317
step: 490, loss: 0.021201688796281815
step: 500, loss: 0.0426952950656414
step: 510, loss: 0.04986787959933281
step: 520, loss: 0.07198794931173325
step: 530, loss: 0.09997310489416122
step: 540, loss: 0.015037205070257187
step: 550, loss: 0.019362496212124825
step: 560, loss: 0.06925999373197556
step: 570, loss: 0.01340076606720686
step: 580, loss: 0.08334287256002426
step: 590, loss: 0.026302507147192955
step: 600, loss: 0.010928120464086533
step: 610, loss: 0.08293671905994415
step: 620, loss: 0.06816060096025467
step: 630, loss: 0.07164599746465683
step: 640, loss: 0.05639597773551941
step: 650, loss: 0.02809838578104973
step: 660, loss: 0.07460062950849533
step: 670, loss: 0.07292861491441727
step: 680, loss: 0.07243476808071136
step: 690, loss: 0.057948797941207886
step: 700, loss: 0.06842420995235443
step: 710, loss: 0.028087865561246872
step: 720, loss: 0.07340488582849503
step: 730, loss: 0.10789231210947037
step: 740, loss: 0.00017036538338288665
step: 750, loss: 0.16120505332946777
step: 760, loss: 0.10486215353012085
step: 770, loss: 0.03725598379969597
step: 780, loss: 0.14146937429904938
step: 790, loss: 0.03320557251572609
step: 800, loss: 0.023531567305326462
step: 810, loss: 0.020609242841601372
step: 820, loss: 0.051459502428770065
step: 830, loss: 0.04091082885861397
step: 840, loss: 0.14471308887004852
step: 850, loss: 0.05781187117099762
step: 860, loss: 0.07054127752780914
step: 870, loss: 0.032275985926389694
step: 880, loss: 0.031652066856622696
step: 890, loss: 0.04824849218130112
step: 900, loss: 0.05001804977655411
step: 910, loss: 0.03734612837433815
step: 920, loss: 0.06327182799577713
step: 930, loss: 0.037394728511571884
step: 940, loss: 0.061227262020111084
step: 950, loss: 0.014650935307145119
step: 960, loss: 0.11515724658966064
step: 970, loss: 0.00992211326956749
step: 980, loss: 0.124404177069664
step: 990, loss: 0.020529167726635933
step: 1000, loss: 0.04995578154921532
step: 1010, loss: 0.03597107157111168
step: 1020, loss: 0.006507386919111013
step: 1030, loss: 0.10680646449327469
step: 1040, loss: 0.02792857028543949
step: 1050, loss: 0.0926332101225853
step: 1060, loss: 0.046784259378910065
step: 1070, loss: 0.02651839517056942
epoch 15: dev_f1=0.923581809657759, f1=0.9212855146716348, best_f1=0.9258079198907602
step: 0, loss: 0.04351870343089104
step: 10, loss: 0.0009972513653337955
step: 20, loss: 0.07810622453689575
step: 30, loss: 0.053106117993593216
step: 40, loss: 0.06370671838521957
step: 50, loss: 0.05361831933259964
step: 60, loss: 0.016557330265641212
step: 70, loss: 0.025703946128487587
step: 80, loss: 0.017408771440386772
step: 90, loss: 0.06587857753038406
step: 100, loss: 0.05929473415017128
step: 110, loss: 0.06558454036712646
step: 120, loss: 0.07277923822402954
step: 130, loss: 0.06702682375907898
step: 140, loss: 0.01624954678118229
step: 150, loss: 0.05254810303449631
step: 160, loss: 0.012798587791621685
step: 170, loss: 0.03846525400876999
step: 180, loss: 0.051512766629457474
step: 190, loss: 0.16296353936195374
step: 200, loss: 0.0487431176006794
step: 210, loss: 0.02449522539973259
step: 220, loss: 0.02455238066613674
step: 230, loss: 0.0717124193906784
step: 240, loss: 0.049608681350946426
step: 250, loss: 0.017166346311569214
step: 260, loss: 0.04182273894548416
step: 270, loss: 0.08497734367847443
step: 280, loss: 0.14838789403438568
step: 290, loss: 0.08113481849431992
step: 300, loss: 0.06290170550346375
step: 310, loss: 0.08390391618013382
step: 320, loss: 0.058144595474004745
step: 330, loss: 0.1076497882604599
step: 340, loss: 0.08568499237298965
step: 350, loss: 0.00013346299238037318
step: 360, loss: 0.11537425965070724
step: 370, loss: 0.018448613584041595
step: 380, loss: 0.026072626933455467
step: 390, loss: 0.06006352975964546
step: 400, loss: 0.0711335837841034
step: 410, loss: 0.05687067657709122
step: 420, loss: 0.0018877169350162148
step: 430, loss: 0.07238107174634933
step: 440, loss: 0.09713323414325714
step: 450, loss: 0.06755394488573074
step: 460, loss: 0.0969824492931366
step: 470, loss: 0.038026921451091766
step: 480, loss: 0.08947008848190308
step: 490, loss: 0.05959700420498848
step: 500, loss: 3.588405525078997e-05
step: 510, loss: 0.033100713044404984
step: 520, loss: 0.02696416527032852
step: 530, loss: 0.06683775037527084
step: 540, loss: 0.11892898380756378
step: 550, loss: 0.042295150458812714
step: 560, loss: 0.04249792546033859
step: 570, loss: 0.039274416863918304
step: 580, loss: 0.027548326179385185
step: 590, loss: 0.06723874062299728
step: 600, loss: 0.06581998616456985
step: 610, loss: 0.0014779985649511218
step: 620, loss: 0.03296110779047012
step: 630, loss: 0.18323872983455658
step: 640, loss: 0.025155097246170044
step: 650, loss: 0.09579727798700333
step: 660, loss: 0.01995847374200821
step: 670, loss: 0.08038757741451263
step: 680, loss: 0.04227997735142708
step: 690, loss: 0.07278521358966827
step: 700, loss: 0.1471402794122696
step: 710, loss: 0.03795287013053894
step: 720, loss: 0.00016433410928584635
step: 730, loss: 0.08469343930482864
step: 740, loss: 0.07563196867704391
step: 750, loss: 0.03973931074142456
step: 760, loss: 0.03621247783303261
step: 770, loss: 0.06490311771631241
step: 780, loss: 0.04089845344424248
step: 790, loss: 0.057135652750730515
step: 800, loss: 0.06179013475775719
step: 810, loss: 0.055769387632608414
step: 820, loss: 0.06675911694765091
step: 830, loss: 0.015993034467101097
step: 840, loss: 0.029156576842069626
step: 850, loss: 0.09684551507234573
step: 860, loss: 0.03399281203746796
step: 870, loss: 0.04170330986380577
step: 880, loss: 0.02253863587975502
step: 890, loss: 2.1895755708101206e-05
step: 900, loss: 0.08113173395395279
step: 910, loss: 0.037172287702560425
step: 920, loss: 0.11685359477996826
step: 930, loss: 0.010824482887983322
step: 940, loss: 0.021652312949299812
step: 950, loss: 0.0027382164262235165
step: 960, loss: 0.08632838726043701
step: 970, loss: 0.060488782823085785
step: 980, loss: 0.050547949969768524
step: 990, loss: 0.05213329941034317
step: 1000, loss: 0.04061763361096382
step: 1010, loss: 8.660277671879157e-05
step: 1020, loss: 0.09154697507619858
step: 1030, loss: 0.02802673727273941
step: 1040, loss: 0.09019672125577927
step: 1050, loss: 0.02173844538629055
step: 1060, loss: 0.007141794543713331
step: 1070, loss: 0.02620425634086132
epoch 16: dev_f1=0.9219261337073399, f1=0.9204281060958586, best_f1=0.9258079198907602
step: 0, loss: 0.026582419872283936
step: 10, loss: 0.001603841781616211
step: 20, loss: 0.07020711898803711
step: 30, loss: 0.023299310356378555
step: 40, loss: 0.05793134123086929
step: 50, loss: 0.0690855011343956
step: 60, loss: 0.0001221925631398335
step: 70, loss: 0.028913484886288643
step: 80, loss: 0.027743740007281303
step: 90, loss: 0.0364748053252697
step: 100, loss: 0.28618431091308594
step: 110, loss: 0.05840161815285683
step: 120, loss: 0.015098786912858486
step: 130, loss: 0.02834204025566578
step: 140, loss: 0.04692273586988449
step: 150, loss: 0.03918316960334778
step: 160, loss: 0.017634859308600426
step: 170, loss: 0.07573540508747101
step: 180, loss: 0.07769881188869476
step: 190, loss: 0.26065757870674133
step: 200, loss: 0.028335126116871834
step: 210, loss: 0.0018134531565010548
step: 220, loss: 0.02355237863957882
step: 230, loss: 0.07639588415622711
step: 240, loss: 0.02679286152124405
step: 250, loss: 0.08248606324195862
step: 260, loss: 0.054514963179826736
step: 270, loss: 0.043593425303697586
step: 280, loss: 0.0007657947135157883
step: 290, loss: 0.06413409858942032
step: 300, loss: 0.03953899070620537
step: 310, loss: 0.04972726106643677
step: 320, loss: 0.07558877021074295
step: 330, loss: 0.08428794890642166
step: 340, loss: 0.03871427848935127
step: 350, loss: 0.10110697895288467
step: 360, loss: 0.027717839926481247
step: 370, loss: 0.04772563278675079
step: 380, loss: 0.022259777411818504
step: 390, loss: 0.03228733316063881
step: 400, loss: 0.05614146590232849
step: 410, loss: 0.05406981706619263
step: 420, loss: 0.1513044387102127
step: 430, loss: 0.027549058198928833
step: 440, loss: 0.05252976343035698
step: 450, loss: 0.05070587992668152
step: 460, loss: 0.06150444224476814
step: 470, loss: 0.06894722580909729
step: 480, loss: 0.0916375070810318
step: 490, loss: 0.021969836205244064
step: 500, loss: 0.0724794939160347
step: 510, loss: 0.025238804519176483
step: 520, loss: 0.022254521027207375
step: 530, loss: 0.015923291444778442
step: 540, loss: 0.08221545070409775
step: 550, loss: 0.012715766206383705
step: 560, loss: 0.030360575765371323
step: 570, loss: 0.045452944934368134
step: 580, loss: 0.21124409139156342
step: 590, loss: 0.04577260836958885
step: 600, loss: 0.019460679963231087
step: 610, loss: 0.03461098298430443
step: 620, loss: 0.0005177386337891221
step: 630, loss: 0.09860582649707794
step: 640, loss: 0.04315376281738281
step: 650, loss: 0.01937645860016346
step: 660, loss: 0.05366897210478783
step: 670, loss: 0.0951848179101944
step: 680, loss: 0.0738278180360794
step: 690, loss: 0.00021776891662739217
step: 700, loss: 0.019308000802993774
step: 710, loss: 0.01031193695962429
step: 720, loss: 0.030001342296600342
step: 730, loss: 0.08807722479104996
step: 740, loss: 0.04463548585772514
step: 750, loss: 0.06720717996358871
step: 760, loss: 0.05387536436319351
step: 770, loss: 0.08774527907371521
step: 780, loss: 0.03700476512312889
step: 790, loss: 0.058876898139715195
step: 800, loss: 0.07193095237016678
step: 810, loss: 0.036884017288684845
step: 820, loss: 0.07318440079689026
step: 830, loss: 0.04195696488022804
step: 840, loss: 0.09610433131456375
step: 850, loss: 0.027799513190984726
step: 860, loss: 0.04878181591629982
step: 870, loss: 0.035964690148830414
step: 880, loss: 0.027581363916397095
step: 890, loss: 0.13571156561374664
step: 900, loss: 0.02439117431640625
step: 910, loss: 0.01945178024470806
step: 920, loss: 0.07460904866456985
step: 930, loss: 0.013700266368687153
step: 940, loss: 0.017265431582927704
step: 950, loss: 0.04967094957828522
step: 960, loss: 0.002703638281673193
step: 970, loss: 0.15263274312019348
step: 980, loss: 0.04226286709308624
step: 990, loss: 0.024946162477135658
step: 1000, loss: 0.05295721814036369
step: 1010, loss: 6.0443722759373486e-05
step: 1020, loss: 0.00045640082680620253
step: 1030, loss: 0.14494264125823975
step: 1040, loss: 0.10037287324666977
step: 1050, loss: 0.049675893038511276
step: 1060, loss: 0.1140318512916565
step: 1070, loss: 0.06624188274145126
epoch 17: dev_f1=0.9267840593141797, f1=0.9229340761374188, best_f1=0.9258079198907602
step: 0, loss: 0.05484719201922417
step: 10, loss: 0.041718434542417526
step: 20, loss: 0.09303318709135056
step: 30, loss: 0.0022106643300503492
step: 40, loss: 6.178344483487308e-05
step: 50, loss: 0.0015504483599215746
step: 60, loss: 0.0776393860578537
step: 70, loss: 0.040356412529945374
step: 80, loss: 0.029349414631724358
step: 90, loss: 0.049665529280900955
step: 100, loss: 7.284346065716818e-05
step: 110, loss: 0.02418188750743866
step: 120, loss: 0.05354277417063713
step: 130, loss: 0.019920216873288155
step: 140, loss: 0.03573840484023094
step: 150, loss: 0.06798092275857925
step: 160, loss: 0.02662123739719391
step: 170, loss: 0.020394539460539818
step: 180, loss: 0.019796960055828094
step: 190, loss: 0.03766863793134689
step: 200, loss: 0.07682527601718903
step: 210, loss: 0.05425262451171875
step: 220, loss: 0.07322610169649124
step: 230, loss: 0.07158995419740677
step: 240, loss: 0.07338748872280121
step: 250, loss: 0.04206418991088867
step: 260, loss: 0.019116459414362907
step: 270, loss: 0.027109336107969284
step: 280, loss: 0.044440966099500656
step: 290, loss: 0.04796561971306801
step: 300, loss: 0.008384340442717075
step: 310, loss: 0.04302039369940758
step: 320, loss: 0.04108554124832153
step: 330, loss: 0.07291064411401749
step: 340, loss: 0.03206200525164604
step: 350, loss: 0.03136368468403816
step: 360, loss: 0.02575141191482544
step: 370, loss: 0.02904076687991619
step: 380, loss: 0.049099747091531754
step: 390, loss: 0.027476632967591286
step: 400, loss: 0.09440302848815918
step: 410, loss: 0.04155983775854111
step: 420, loss: 0.13706183433532715
step: 430, loss: 0.03350586071610451
step: 440, loss: 0.05411168560385704
step: 450, loss: 0.021391427144408226
step: 460, loss: 0.04956336319446564
step: 470, loss: 0.034311242401599884
step: 480, loss: 0.11155688017606735
step: 490, loss: 0.06557071208953857
step: 500, loss: 0.056760262697935104
step: 510, loss: 0.05854925885796547
step: 520, loss: 0.026150744408369064
step: 530, loss: 0.021686486899852753
step: 540, loss: 0.05924420803785324
step: 550, loss: 0.015855390578508377
step: 560, loss: 0.07023453712463379
step: 570, loss: 0.006190237123519182
step: 580, loss: 0.04080232232809067
step: 590, loss: 0.20482055842876434
step: 600, loss: 0.11671143770217896
step: 610, loss: 6.0119578847661614e-05
step: 620, loss: 0.059438467025756836
step: 630, loss: 0.1005425974726677
step: 640, loss: 0.07482808828353882
step: 650, loss: 0.033965907990932465
step: 660, loss: 0.02258356660604477
step: 670, loss: 0.04974440485239029
step: 680, loss: 0.005021576303988695
step: 690, loss: 0.0001413103600498289
step: 700, loss: 0.06162850558757782
step: 710, loss: 0.060261134058237076
step: 720, loss: 0.032829128205776215
step: 730, loss: 0.054615020751953125
step: 740, loss: 0.05926412716507912
step: 750, loss: 0.049977876245975494
step: 760, loss: 0.030545342713594437
step: 770, loss: 0.019984032958745956
step: 780, loss: 0.020862380042672157
step: 790, loss: 0.03928147256374359
step: 800, loss: 0.02117847092449665
step: 810, loss: 1.8506900232750922e-05
step: 820, loss: 0.017640799283981323
step: 830, loss: 0.03403497114777565
step: 840, loss: 0.06950646638870239
step: 850, loss: 0.07985299080610275
step: 860, loss: 8.635731501271948e-05
step: 870, loss: 0.00011558686674106866
step: 880, loss: 0.10142949968576431
step: 890, loss: 0.021188560873270035
step: 900, loss: 0.01193160004913807
step: 910, loss: 0.019234076142311096
step: 920, loss: 0.012196870520710945
step: 930, loss: 0.0001661069254623726
step: 940, loss: 0.10967842489480972
step: 950, loss: 0.04082048684358597
step: 960, loss: 0.017867092043161392
step: 970, loss: 0.016297532245516777
step: 980, loss: 0.10813924670219421
step: 990, loss: 0.048446398228406906
step: 1000, loss: 0.09289655834436417
step: 1010, loss: 0.04157324135303497
step: 1020, loss: 0.05503277853131294
step: 1030, loss: 0.0001229539338964969
step: 1040, loss: 0.035596199333667755
step: 1050, loss: 0.07177693396806717
step: 1060, loss: 0.047261811792850494
step: 1070, loss: 0.053152188658714294
epoch 18: dev_f1=0.9203373945641987, f1=0.9204281060958586, best_f1=0.9258079198907602
step: 0, loss: 0.029554836452007294
step: 10, loss: 0.02772534266114235
step: 20, loss: 0.02022426389157772
step: 30, loss: 0.08459987491369247
step: 40, loss: 0.019095780327916145
step: 50, loss: 0.032226189970970154
step: 60, loss: 0.01915552467107773
step: 70, loss: 0.047886963933706284
step: 80, loss: 0.034059807658195496
step: 90, loss: 0.05766351893544197
step: 100, loss: 0.0090853963047266
step: 110, loss: 0.043035801500082016
step: 120, loss: 0.10553193092346191
step: 130, loss: 0.0315374881029129
step: 140, loss: 6.24900494585745e-05
step: 150, loss: 0.0236464012414217
step: 160, loss: 0.08341813087463379
step: 170, loss: 0.0002547249314375222
step: 180, loss: 0.026686567813158035
step: 190, loss: 0.04199177026748657
step: 200, loss: 0.03411347419023514
step: 210, loss: 0.001879695919342339
step: 220, loss: 0.03744111210107803
step: 230, loss: 0.018636899068951607
step: 240, loss: 0.0003119204193353653
step: 250, loss: 0.03059445135295391
step: 260, loss: 0.02780352532863617
step: 270, loss: 0.07822582125663757
step: 280, loss: 0.05553470924496651
step: 290, loss: 0.050448499619960785
step: 300, loss: 0.0682734027504921
step: 310, loss: 0.02610134333372116
step: 320, loss: 0.03146975859999657
step: 330, loss: 0.061620526015758514
step: 340, loss: 1.4751895832887385e-05
step: 350, loss: 0.01746947504580021
step: 360, loss: 0.0026168522890657187
step: 370, loss: 0.0014952414203435183
step: 380, loss: 0.07874961197376251
step: 390, loss: 0.03375862166285515
step: 400, loss: 0.018960144370794296
step: 410, loss: 0.059855833649635315
step: 420, loss: 0.00042164241313003004
step: 430, loss: 0.04097583889961243
step: 440, loss: 0.025138098746538162
step: 450, loss: 0.10872470587491989
step: 460, loss: 0.06249740719795227
step: 470, loss: 0.047674089670181274
step: 480, loss: 0.026935916393995285
step: 490, loss: 0.06275559961795807
step: 500, loss: 0.004945645108819008
step: 510, loss: 0.0497078001499176
step: 520, loss: 0.00019353006791789085
step: 530, loss: 0.04887289181351662
step: 540, loss: 0.03212514519691467
step: 550, loss: 0.0005888856248930097
step: 560, loss: 0.056522175669670105
step: 570, loss: 0.07069987803697586
step: 580, loss: 0.014206943102180958
step: 590, loss: 0.017624041065573692
step: 600, loss: 0.02199207805097103
step: 610, loss: 0.03798995167016983
step: 620, loss: 3.5248242056695744e-05
step: 630, loss: 0.00038404378574341536
step: 640, loss: 0.01736507937312126
step: 650, loss: 0.04253232106566429
step: 660, loss: 0.13919469714164734
step: 670, loss: 0.012551539577543736
step: 680, loss: 0.093726746737957
step: 690, loss: 0.04430965706706047
step: 700, loss: 0.07487405836582184
step: 710, loss: 0.07819143682718277
step: 720, loss: 0.0004991479218006134
step: 730, loss: 0.06370409578084946
step: 740, loss: 0.04911923408508301
step: 750, loss: 0.07401291280984879
step: 760, loss: 0.09991157799959183
step: 770, loss: 1.4353154256241396e-05
step: 780, loss: 0.02681736834347248
step: 790, loss: 0.02568995952606201
step: 800, loss: 0.06305953860282898
step: 810, loss: 0.05706251785159111
step: 820, loss: 0.01913038082420826
step: 830, loss: 0.055456966161727905
step: 840, loss: 0.031718894839286804
step: 850, loss: 0.037124574184417725
step: 860, loss: 0.08024083822965622
step: 870, loss: 0.0010401454055681825
step: 880, loss: 0.11668286472558975
step: 890, loss: 0.021044956520199776
step: 900, loss: 0.0113541129976511
step: 910, loss: 0.013514510355889797
step: 920, loss: 0.004516740329563618
step: 930, loss: 0.013814507983624935
step: 940, loss: 0.07277794182300568
step: 950, loss: 0.05697343498468399
step: 960, loss: 0.10377168655395508
step: 970, loss: 0.00026535120559856296
step: 980, loss: 0.07301833480596542
step: 990, loss: 0.04512069374322891
step: 1000, loss: 0.00012443854939192533
step: 1010, loss: 0.021656371653079987
step: 1020, loss: 0.0012392515782266855
step: 1030, loss: 0.06482882052659988
step: 1040, loss: 0.032626673579216
step: 1050, loss: 0.005282790400087833
step: 1060, loss: 3.255591218476184e-05
step: 1070, loss: 0.05888550728559494
epoch 19: dev_f1=0.919020715630885, f1=0.9199812821712682, best_f1=0.9258079198907602
step: 0, loss: 0.006535787135362625
step: 10, loss: 0.04219444468617439
step: 20, loss: 0.06434610486030579
step: 30, loss: 0.05342186987400055
step: 40, loss: 0.05659175664186478
step: 50, loss: 0.06036221981048584
step: 60, loss: 0.035986997187137604
step: 70, loss: 3.466701673460193e-05
step: 80, loss: 0.038160428404808044
step: 90, loss: 0.07746749371290207
step: 100, loss: 0.06332653760910034
step: 110, loss: 0.015577223151922226
step: 120, loss: 0.056574419140815735
step: 130, loss: 0.04084935039281845
step: 140, loss: 0.007662630174309015
step: 150, loss: 0.027372628450393677
step: 160, loss: 5.146957846591249e-05
step: 170, loss: 0.07541194558143616
step: 180, loss: 0.03469228371977806
step: 190, loss: 0.028856275603175163
step: 200, loss: 0.06947197765111923
step: 210, loss: 0.031085189431905746
step: 220, loss: 3.3354877814417705e-05
step: 230, loss: 0.04096342995762825
step: 240, loss: 7.387419464066625e-05
step: 250, loss: 0.04588760435581207
step: 260, loss: 0.0002732270513661206
step: 270, loss: 0.04636504873633385
step: 280, loss: 0.07722210139036179
step: 290, loss: 0.052783600986003876
step: 300, loss: 0.04165792837738991
step: 310, loss: 0.08438395708799362
step: 320, loss: 3.710452074301429e-05
step: 330, loss: 0.04187172278761864
step: 340, loss: 0.059149570763111115
step: 350, loss: 0.0035393997095525265
step: 360, loss: 0.019131982699036598
step: 370, loss: 0.018160168081521988
step: 380, loss: 0.02367565780878067
step: 390, loss: 0.08844950795173645
step: 400, loss: 0.0004835162253584713
step: 410, loss: 3.372777791810222e-05
step: 420, loss: 0.0009246768313460052
step: 430, loss: 0.024137381464242935
step: 440, loss: 0.026569640263915062
step: 450, loss: 0.000551829522009939
step: 460, loss: 0.0666709765791893
step: 470, loss: 0.000254292506724596
step: 480, loss: 0.06186279281973839
step: 490, loss: 0.04212089255452156
step: 500, loss: 0.023736270144581795
step: 510, loss: 0.03274582326412201
step: 520, loss: 0.06264536082744598
step: 530, loss: 0.1801663190126419
step: 540, loss: 0.05471159145236015
step: 550, loss: 0.07320551574230194
step: 560, loss: 0.014594604261219501
step: 570, loss: 0.00017828543786890805
step: 580, loss: 0.01396539993584156
step: 590, loss: 0.08974065631628036
step: 600, loss: 0.03823266550898552
step: 610, loss: 0.00929438229650259
step: 620, loss: 0.0526064857840538
step: 630, loss: 6.211861182237044e-05
step: 640, loss: 0.02181263081729412
step: 650, loss: 0.011816762387752533
step: 660, loss: 0.0578063540160656
step: 670, loss: 0.15751732885837555
step: 680, loss: 0.053814973682165146
step: 690, loss: 0.013393526896834373
step: 700, loss: 0.0385248176753521
step: 710, loss: 0.030575359240174294
step: 720, loss: 0.02086765505373478
step: 730, loss: 0.056909963488578796
step: 740, loss: 0.022492224350571632
step: 750, loss: 0.016164323315024376
step: 760, loss: 0.03808360919356346
step: 770, loss: 0.03145239129662514
step: 780, loss: 0.001952747697941959
step: 790, loss: 0.030258575454354286
step: 800, loss: 8.087703463388607e-05
step: 810, loss: 0.0902252346277237
step: 820, loss: 0.07206130772829056
step: 830, loss: 0.03909620642662048
step: 840, loss: 0.019554944708943367
step: 850, loss: 0.024632731452584267
step: 860, loss: 0.061417922377586365
step: 870, loss: 0.03705326467752457
step: 880, loss: 0.028744734823703766
step: 890, loss: 0.03705226257443428
step: 900, loss: 0.03884147107601166
step: 910, loss: 0.02334926836192608
step: 920, loss: 0.012631050311028957
step: 930, loss: 0.00039431825280189514
step: 940, loss: 0.0003740335814654827
step: 950, loss: 4.5859069359721616e-05
step: 960, loss: 0.046032972633838654
step: 970, loss: 0.09203069657087326
step: 980, loss: 4.1015806345967576e-05
step: 990, loss: 0.05860770866274834
step: 1000, loss: 0.045394085347652435
step: 1010, loss: 0.045960381627082825
step: 1020, loss: 0.04289070889353752
step: 1030, loss: 0.09021840989589691
step: 1040, loss: 0.059943899512290955
step: 1050, loss: 0.0325913205742836
step: 1060, loss: 8.179400174412876e-05
step: 1070, loss: 0.051427412778139114
epoch 20: dev_f1=0.91828058573453, f1=0.9167842031029619, best_f1=0.9258079198907602
