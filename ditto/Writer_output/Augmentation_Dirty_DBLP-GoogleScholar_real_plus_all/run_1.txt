cuda
Device: cuda
step: 0, loss: 0.6868848204612732
step: 10, loss: 0.4088069498538971
step: 20, loss: 0.5267658233642578
step: 30, loss: 0.6198686361312866
step: 40, loss: 0.21725742518901825
step: 50, loss: 0.25707700848579407
step: 60, loss: 0.34087511897087097
step: 70, loss: 0.21721169352531433
step: 80, loss: 0.16793128848075867
step: 90, loss: 0.15842585265636444
step: 100, loss: 0.20367906987667084
step: 110, loss: 0.13986736536026
step: 120, loss: 0.20139099657535553
step: 130, loss: 0.19542159140110016
step: 140, loss: 0.129488006234169
step: 150, loss: 0.17049504816532135
step: 160, loss: 0.09659411013126373
step: 170, loss: 0.2258937805891037
step: 180, loss: 0.08930929005146027
step: 190, loss: 0.1777733564376831
step: 200, loss: 0.1875288486480713
step: 210, loss: 0.31191039085388184
step: 220, loss: 0.11070536822080612
step: 230, loss: 0.3058542311191559
step: 240, loss: 0.1493096798658371
step: 250, loss: 0.36345404386520386
step: 260, loss: 0.10027111321687698
step: 270, loss: 0.3083899915218353
step: 280, loss: 0.11324310302734375
step: 290, loss: 0.060489118099212646
step: 300, loss: 0.17284005880355835
step: 310, loss: 0.13494020700454712
step: 320, loss: 0.07648491859436035
step: 330, loss: 0.11992267519235611
step: 340, loss: 0.13223029673099518
step: 350, loss: 0.1064925268292427
step: 360, loss: 0.1488877236843109
step: 370, loss: 0.22115974128246307
step: 380, loss: 0.0449209026992321
step: 390, loss: 0.17194712162017822
step: 400, loss: 0.08620086312294006
step: 410, loss: 0.10480663180351257
step: 420, loss: 0.19915491342544556
step: 430, loss: 0.04575329273939133
step: 440, loss: 0.13508933782577515
step: 450, loss: 0.11871346831321716
step: 460, loss: 0.21415455639362335
step: 470, loss: 0.2541283369064331
step: 480, loss: 0.17307382822036743
step: 490, loss: 0.2405400425195694
step: 500, loss: 0.16238515079021454
step: 510, loss: 0.09816798567771912
step: 520, loss: 0.1603955775499344
step: 530, loss: 0.12521915137767792
step: 540, loss: 0.20133501291275024
step: 550, loss: 0.185238316655159
step: 560, loss: 0.07591534405946732
step: 570, loss: 0.10542812198400497
step: 580, loss: 0.08714950084686279
step: 590, loss: 0.2736192047595978
step: 600, loss: 0.14479579031467438
step: 610, loss: 0.10122174024581909
step: 620, loss: 0.1643136888742447
step: 630, loss: 0.1383097767829895
step: 640, loss: 0.13724806904792786
step: 650, loss: 0.1679989993572235
step: 660, loss: 0.046117909252643585
step: 670, loss: 0.11172863095998764
step: 680, loss: 0.059115394949913025
step: 690, loss: 0.1553671807050705
step: 700, loss: 0.21180564165115356
step: 710, loss: 0.1926054060459137
step: 720, loss: 0.22676342725753784
step: 730, loss: 0.18267659842967987
step: 740, loss: 0.15087701380252838
step: 750, loss: 0.0947960913181305
step: 760, loss: 0.11793133616447449
step: 770, loss: 0.07322122901678085
step: 780, loss: 0.07859333604574203
step: 790, loss: 0.05648861452937126
step: 800, loss: 0.19422517716884613
step: 810, loss: 0.13217714428901672
step: 820, loss: 0.04600430279970169
step: 830, loss: 0.11157529056072235
step: 840, loss: 0.03590996935963631
step: 850, loss: 0.08843990415334702
step: 860, loss: 0.0636834129691124
step: 870, loss: 0.07058575749397278
step: 880, loss: 0.04873982071876526
step: 890, loss: 0.04986751079559326
step: 900, loss: 0.15963327884674072
step: 910, loss: 0.07723597437143326
step: 920, loss: 0.08138558268547058
step: 930, loss: 0.10794663429260254
step: 940, loss: 0.15051871538162231
step: 950, loss: 0.2659863531589508
step: 960, loss: 0.18141797184944153
step: 970, loss: 0.1333264410495758
step: 980, loss: 0.04639895632863045
step: 990, loss: 0.13259166479110718
step: 1000, loss: 0.12581871449947357
step: 1010, loss: 0.15966510772705078
step: 1020, loss: 0.2029881626367569
step: 1030, loss: 0.13557757437229156
step: 1040, loss: 0.06981983035802841
step: 1050, loss: 0.06850753724575043
step: 1060, loss: 0.23946605622768402
step: 1070, loss: 0.16972616314888
epoch 1: dev_f1=0.9137291280148423, f1=0.909763998149005, best_f1=0.909763998149005
step: 0, loss: 0.04778771102428436
step: 10, loss: 0.2029120922088623
step: 20, loss: 0.25254228711128235
step: 30, loss: 0.09018927812576294
step: 40, loss: 0.017059482634067535
step: 50, loss: 0.1391100138425827
step: 60, loss: 0.18297214806079865
step: 70, loss: 0.12488792091608047
step: 80, loss: 0.09600881487131119
step: 90, loss: 0.081577368080616
step: 100, loss: 0.187888503074646
step: 110, loss: 0.045023780316114426
step: 120, loss: 0.08882728964090347
step: 130, loss: 0.2280406802892685
step: 140, loss: 0.08439407497644424
step: 150, loss: 0.23422479629516602
step: 160, loss: 0.0433153435587883
step: 170, loss: 0.08834636211395264
step: 180, loss: 0.1585986316204071
step: 190, loss: 0.09400477260351181
step: 200, loss: 0.04087202623486519
step: 210, loss: 0.14480814337730408
step: 220, loss: 0.05970950052142143
step: 230, loss: 0.20030967891216278
step: 240, loss: 0.1287906914949417
step: 250, loss: 0.18044976890087128
step: 260, loss: 0.1577882170677185
step: 270, loss: 0.031181182712316513
step: 280, loss: 0.08876971900463104
step: 290, loss: 0.05491609871387482
step: 300, loss: 0.15689757466316223
step: 310, loss: 0.07203499227762222
step: 320, loss: 0.14246514439582825
step: 330, loss: 0.046840716153383255
step: 340, loss: 0.10460127145051956
step: 350, loss: 0.2751958668231964
step: 360, loss: 0.024180572479963303
step: 370, loss: 0.13507002592086792
step: 380, loss: 0.10776322335004807
step: 390, loss: 0.07648307830095291
step: 400, loss: 0.12730887532234192
step: 410, loss: 0.04750102385878563
step: 420, loss: 0.14257170259952545
step: 430, loss: 0.19605295360088348
step: 440, loss: 0.060844164341688156
step: 450, loss: 0.15232184529304504
step: 460, loss: 0.09395419806241989
step: 470, loss: 0.19174720346927643
step: 480, loss: 0.022121191024780273
step: 490, loss: 0.21528026461601257
step: 500, loss: 0.15669625997543335
step: 510, loss: 0.07543764263391495
step: 520, loss: 0.06919863820075989
step: 530, loss: 0.1361815184354782
step: 540, loss: 0.06558071821928024
step: 550, loss: 0.15096668899059296
step: 560, loss: 0.17576457560062408
step: 570, loss: 0.12059377878904343
step: 580, loss: 0.08004560321569443
step: 590, loss: 0.08768405020236969
step: 600, loss: 0.13257917761802673
step: 610, loss: 0.23110654950141907
step: 620, loss: 0.11069449037313461
step: 630, loss: 0.0743071660399437
step: 640, loss: 0.151261106133461
step: 650, loss: 0.08132748305797577
step: 660, loss: 0.031430572271347046
step: 670, loss: 0.11940106004476547
step: 680, loss: 0.07202193886041641
step: 690, loss: 0.10858012735843658
step: 700, loss: 0.21664850413799286
step: 710, loss: 0.064690500497818
step: 720, loss: 0.25012949109077454
step: 730, loss: 0.11832290142774582
step: 740, loss: 0.06689977645874023
step: 750, loss: 0.16460451483726501
step: 760, loss: 0.016894422471523285
step: 770, loss: 0.17341487109661102
step: 780, loss: 0.13727891445159912
step: 790, loss: 0.19209295511245728
step: 800, loss: 0.060083918273448944
step: 810, loss: 0.10206298530101776
step: 820, loss: 0.11432794481515884
step: 830, loss: 0.23873111605644226
step: 840, loss: 0.06263651698827744
step: 850, loss: 0.11344301700592041
step: 860, loss: 0.06678854674100876
step: 870, loss: 0.06943745911121368
step: 880, loss: 0.0694437250494957
step: 890, loss: 0.10646844655275345
step: 900, loss: 0.14289337396621704
step: 910, loss: 0.19265849888324738
step: 920, loss: 0.14226719737052917
step: 930, loss: 0.0688142478466034
step: 940, loss: 0.19961728155612946
step: 950, loss: 0.05794427543878555
step: 960, loss: 0.11364681273698807
step: 970, loss: 0.07881134748458862
step: 980, loss: 0.22970402240753174
step: 990, loss: 0.0190285537391901
step: 1000, loss: 0.024373965337872505
step: 1010, loss: 0.14132343232631683
step: 1020, loss: 0.09531671553850174
step: 1030, loss: 0.0930693969130516
step: 1040, loss: 0.03320184722542763
step: 1050, loss: 0.0955633893609047
step: 1060, loss: 0.00236325990408659
step: 1070, loss: 0.11984871327877045
epoch 2: dev_f1=0.9317453046266607, f1=0.9286367795059469, best_f1=0.9286367795059469
step: 0, loss: 0.1514291763305664
step: 10, loss: 0.16305163502693176
step: 20, loss: 0.10789401829242706
step: 30, loss: 0.10006551444530487
step: 40, loss: 0.03534028306603432
step: 50, loss: 0.08042696863412857
step: 60, loss: 0.17003124952316284
step: 70, loss: 0.08401250094175339
step: 80, loss: 0.0708216056227684
step: 90, loss: 0.08063886314630508
step: 100, loss: 0.019686613231897354
step: 110, loss: 0.13367879390716553
step: 120, loss: 0.09884538501501083
step: 130, loss: 0.12175589799880981
step: 140, loss: 0.08740066736936569
step: 150, loss: 0.05493928864598274
step: 160, loss: 0.10434621572494507
step: 170, loss: 0.06798160076141357
step: 180, loss: 0.12336242198944092
step: 190, loss: 0.057398512959480286
step: 200, loss: 0.04690628871321678
step: 210, loss: 0.07950293272733688
step: 220, loss: 0.15485672652721405
step: 230, loss: 0.1980350762605667
step: 240, loss: 0.1308034062385559
step: 250, loss: 0.08874677121639252
step: 260, loss: 0.19684211909770966
step: 270, loss: 0.14556317031383514
step: 280, loss: 0.11520389467477798
step: 290, loss: 0.09073112905025482
step: 300, loss: 0.09889675676822662
step: 310, loss: 0.022187422960996628
step: 320, loss: 0.11033254116773605
step: 330, loss: 0.13439014554023743
step: 340, loss: 0.1885444074869156
step: 350, loss: 0.10264478623867035
step: 360, loss: 0.014847842045128345
step: 370, loss: 0.14193663001060486
step: 380, loss: 0.13153943419456482
step: 390, loss: 0.18601463735103607
step: 400, loss: 0.0669161006808281
step: 410, loss: 0.09601521492004395
step: 420, loss: 0.1153838261961937
step: 430, loss: 0.10719433426856995
step: 440, loss: 0.04099743813276291
step: 450, loss: 0.13916394114494324
step: 460, loss: 0.04699243977665901
step: 470, loss: 0.04534414783120155
step: 480, loss: 0.13031810522079468
step: 490, loss: 0.18302834033966064
step: 500, loss: 0.11453744769096375
step: 510, loss: 0.123114675283432
step: 520, loss: 0.07544615119695663
step: 530, loss: 0.1759282797574997
step: 540, loss: 0.14611956477165222
step: 550, loss: 0.22392404079437256
step: 560, loss: 0.06830648332834244
step: 570, loss: 0.19329644739627838
step: 580, loss: 0.13880769908428192
step: 590, loss: 0.054466232657432556
step: 600, loss: 0.13088881969451904
step: 610, loss: 0.012924179434776306
step: 620, loss: 0.08180733770132065
step: 630, loss: 0.1131887435913086
step: 640, loss: 0.13335031270980835
step: 650, loss: 0.08915369212627411
step: 660, loss: 0.1866089254617691
step: 670, loss: 0.053956348448991776
step: 680, loss: 0.13048455119132996
step: 690, loss: 0.07722483575344086
step: 700, loss: 0.11190469563007355
step: 710, loss: 0.06843835115432739
step: 720, loss: 0.009359346702694893
step: 730, loss: 0.0679723471403122
step: 740, loss: 0.12276630848646164
step: 750, loss: 0.13512901961803436
step: 760, loss: 0.058178823441267014
step: 770, loss: 0.06300630420446396
step: 780, loss: 0.11101163923740387
step: 790, loss: 0.11410868912935257
step: 800, loss: 0.05566214397549629
step: 810, loss: 0.04622955247759819
step: 820, loss: 0.12446141988039017
step: 830, loss: 0.20177774131298065
step: 840, loss: 0.0666678324341774
step: 850, loss: 0.07091768831014633
step: 860, loss: 0.09490998089313507
step: 870, loss: 0.04830008000135422
step: 880, loss: 0.20422351360321045
step: 890, loss: 0.044428884983062744
step: 900, loss: 0.13483941555023193
step: 910, loss: 0.22755782306194305
step: 920, loss: 0.136465921998024
step: 930, loss: 0.11304395645856857
step: 940, loss: 0.06901901960372925
step: 950, loss: 0.07855396717786789
step: 960, loss: 0.07640331238508224
step: 970, loss: 0.07904388755559921
step: 980, loss: 0.10814433544874191
step: 990, loss: 0.11043322831392288
step: 1000, loss: 0.08268558233976364
step: 1010, loss: 0.07941362261772156
step: 1020, loss: 0.21026939153671265
step: 1030, loss: 0.05472882091999054
step: 1040, loss: 0.09701612591743469
step: 1050, loss: 0.07289206981658936
step: 1060, loss: 0.038946762681007385
step: 1070, loss: 0.14264513552188873
epoch 3: dev_f1=0.9288928892889289, f1=0.9232150875617423, best_f1=0.9286367795059469
step: 0, loss: 0.09600020200014114
step: 10, loss: 0.06840042769908905
step: 20, loss: 0.06731858849525452
step: 30, loss: 0.08676191419363022
step: 40, loss: 0.08744896948337555
step: 50, loss: 0.1899058222770691
step: 60, loss: 0.16521301865577698
step: 70, loss: 0.1558493822813034
step: 80, loss: 0.05693582072854042
step: 90, loss: 0.20110277831554413
step: 100, loss: 0.0854940414428711
step: 110, loss: 0.13245868682861328
step: 120, loss: 0.06428485363721848
step: 130, loss: 0.1518482267856598
step: 140, loss: 0.12462347000837326
step: 150, loss: 0.12759238481521606
step: 160, loss: 0.01949988678097725
step: 170, loss: 0.03360030800104141
step: 180, loss: 0.09988550841808319
step: 190, loss: 0.10284397751092911
step: 200, loss: 0.13763129711151123
step: 210, loss: 0.1346469521522522
step: 220, loss: 0.10540876537561417
step: 230, loss: 0.14280711114406586
step: 240, loss: 0.040678977966308594
step: 250, loss: 0.06405644118785858
step: 260, loss: 0.10626088827848434
step: 270, loss: 0.07340165227651596
step: 280, loss: 0.045474957674741745
step: 290, loss: 0.04320630803704262
step: 300, loss: 0.08701077103614807
step: 310, loss: 0.07506503909826279
step: 320, loss: 0.04223854839801788
step: 330, loss: 0.062497545033693314
step: 340, loss: 0.08238649368286133
step: 350, loss: 0.11525319516658783
step: 360, loss: 0.15467733144760132
step: 370, loss: 0.12833791971206665
step: 380, loss: 0.2116306722164154
step: 390, loss: 0.11538872122764587
step: 400, loss: 0.017841001972556114
step: 410, loss: 0.030991846695542336
step: 420, loss: 0.03907306119799614
step: 430, loss: 0.0681627169251442
step: 440, loss: 0.1619374006986618
step: 450, loss: 0.09851706773042679
step: 460, loss: 0.17156697809696198
step: 470, loss: 0.06949862092733383
step: 480, loss: 0.047124240547418594
step: 490, loss: 0.12499991804361343
step: 500, loss: 0.09224332123994827
step: 510, loss: 0.07958701252937317
step: 520, loss: 0.15951062738895416
step: 530, loss: 0.07586271315813065
step: 540, loss: 0.025417422875761986
step: 550, loss: 0.2074945867061615
step: 560, loss: 0.0992453396320343
step: 570, loss: 0.12023061513900757
step: 580, loss: 0.12074186652898788
step: 590, loss: 0.11522708088159561
step: 600, loss: 0.07729357481002808
step: 610, loss: 0.07958431541919708
step: 620, loss: 0.0912708193063736
step: 630, loss: 0.09906332194805145
step: 640, loss: 0.240825816988945
step: 650, loss: 0.10023459047079086
step: 660, loss: 0.11397872120141983
step: 670, loss: 0.14172063767910004
step: 680, loss: 0.09106665104627609
step: 690, loss: 0.14125263690948486
step: 700, loss: 0.1276479959487915
step: 710, loss: 0.03903357684612274
step: 720, loss: 0.05401524156332016
step: 730, loss: 0.03371056169271469
step: 740, loss: 0.12004045397043228
step: 750, loss: 0.019497724249958992
step: 760, loss: 0.05736582726240158
step: 770, loss: 0.1500493884086609
step: 780, loss: 0.12228772789239883
step: 790, loss: 0.1123584508895874
step: 800, loss: 0.06485651433467865
step: 810, loss: 0.11119452863931656
step: 820, loss: 0.0800945907831192
step: 830, loss: 0.11719471216201782
step: 840, loss: 0.047776054590940475
step: 850, loss: 0.08431320637464523
step: 860, loss: 0.13859711587429047
step: 870, loss: 0.17676766216754913
step: 880, loss: 0.12315943092107773
step: 890, loss: 0.10156656801700592
step: 900, loss: 0.06214394047856331
step: 910, loss: 0.05582262575626373
step: 920, loss: 0.06134883686900139
step: 930, loss: 0.01605544239282608
step: 940, loss: 0.01894063502550125
step: 950, loss: 0.03627721592783928
step: 960, loss: 0.0532553568482399
step: 970, loss: 0.05291888117790222
step: 980, loss: 0.08560948073863983
step: 990, loss: 0.0808381661772728
step: 1000, loss: 0.09846897423267365
step: 1010, loss: 0.13635437190532684
step: 1020, loss: 0.02678259089589119
step: 1030, loss: 0.048552755266427994
step: 1040, loss: 0.09966988861560822
step: 1050, loss: 0.13703227043151855
step: 1060, loss: 0.06682341545820236
step: 1070, loss: 0.1256929337978363
epoch 4: dev_f1=0.9192200557103064, f1=0.9212233549582948, best_f1=0.9286367795059469
step: 0, loss: 0.13575983047485352
step: 10, loss: 0.05345247685909271
step: 20, loss: 0.02437477745115757
step: 30, loss: 0.036088503897190094
step: 40, loss: 0.03444167599081993
step: 50, loss: 0.03908749297261238
step: 60, loss: 0.05405110865831375
step: 70, loss: 0.14552804827690125
step: 80, loss: 0.0550667978823185
step: 90, loss: 0.0638483315706253
step: 100, loss: 0.11090962588787079
step: 110, loss: 0.11021257936954498
step: 120, loss: 0.1800561398267746
step: 130, loss: 0.10602126270532608
step: 140, loss: 0.07924851030111313
step: 150, loss: 0.02262542024254799
step: 160, loss: 0.07230832427740097
step: 170, loss: 0.06728176027536392
step: 180, loss: 0.042221248149871826
step: 190, loss: 0.0385860800743103
step: 200, loss: 0.08095619082450867
step: 210, loss: 0.07910460978746414
step: 220, loss: 0.014612898230552673
step: 230, loss: 0.2517748475074768
step: 240, loss: 0.11213794350624084
step: 250, loss: 0.06014097481966019
step: 260, loss: 0.10820188373327255
step: 270, loss: 0.07838687300682068
step: 280, loss: 0.061962489038705826
step: 290, loss: 0.10753781348466873
step: 300, loss: 0.03279504179954529
step: 310, loss: 0.05220900848507881
step: 320, loss: 0.051926273852586746
step: 330, loss: 0.030001934617757797
step: 340, loss: 0.08137001842260361
step: 350, loss: 0.0415310338139534
step: 360, loss: 0.2475741058588028
step: 370, loss: 0.18721824884414673
step: 380, loss: 0.1965143382549286
step: 390, loss: 0.05519111827015877
step: 400, loss: 0.07907090336084366
step: 410, loss: 0.06169172003865242
step: 420, loss: 0.031139157712459564
step: 430, loss: 0.06165006756782532
step: 440, loss: 0.07716501504182816
step: 450, loss: 0.010917464271187782
step: 460, loss: 0.12916430830955505
step: 470, loss: 0.027018258348107338
step: 480, loss: 0.06957796216011047
step: 490, loss: 0.2906869053840637
step: 500, loss: 0.1064104363322258
step: 510, loss: 0.08791956305503845
step: 520, loss: 0.1156201958656311
step: 530, loss: 0.1494700312614441
step: 540, loss: 0.14943523705005646
step: 550, loss: 0.055381953716278076
step: 560, loss: 0.16835030913352966
step: 570, loss: 0.0369049496948719
step: 580, loss: 0.015844635665416718
step: 590, loss: 0.2061920464038849
step: 600, loss: 0.17660744488239288
step: 610, loss: 0.09649572521448135
step: 620, loss: 0.06255484372377396
step: 630, loss: 0.036726973950862885
step: 640, loss: 0.07228676229715347
step: 650, loss: 0.1067221462726593
step: 660, loss: 0.10628434270620346
step: 670, loss: 0.060855116695165634
step: 680, loss: 0.07325323671102524
step: 690, loss: 0.08205875009298325
step: 700, loss: 0.06374391168355942
step: 710, loss: 0.14002053439617157
step: 720, loss: 0.013650315813720226
step: 730, loss: 0.10590361058712006
step: 740, loss: 0.2151275873184204
step: 750, loss: 0.054784297943115234
step: 760, loss: 0.011547261849045753
step: 770, loss: 0.06492291390895844
step: 780, loss: 0.06369780749082565
step: 790, loss: 0.10746536403894424
step: 800, loss: 0.055739324539899826
step: 810, loss: 0.0678330510854721
step: 820, loss: 0.08152394741773605
step: 830, loss: 0.08114585280418396
step: 840, loss: 0.0548006035387516
step: 850, loss: 0.11540117859840393
step: 860, loss: 0.1020907461643219
step: 870, loss: 0.12529990077018738
step: 880, loss: 0.12137942016124725
step: 890, loss: 0.01800641603767872
step: 900, loss: 0.1066298708319664
step: 910, loss: 0.2564605474472046
step: 920, loss: 0.055321432650089264
step: 930, loss: 0.181229829788208
step: 940, loss: 0.1559225171804428
step: 950, loss: 0.12323536723852158
step: 960, loss: 0.10212589055299759
step: 970, loss: 0.12362928688526154
step: 980, loss: 0.012397926300764084
step: 990, loss: 0.1964680701494217
step: 1000, loss: 0.03940664231777191
step: 1010, loss: 0.08539017289876938
step: 1020, loss: 0.09176945686340332
step: 1030, loss: 0.1528984159231186
step: 1040, loss: 0.06969372928142548
step: 1050, loss: 0.09135288745164871
step: 1060, loss: 0.15290388464927673
step: 1070, loss: 0.07541176676750183
epoch 5: dev_f1=0.9304511278195489, f1=0.9280677009873061, best_f1=0.9286367795059469
step: 0, loss: 0.11253580451011658
step: 10, loss: 0.11337551474571228
step: 20, loss: 0.04229395464062691
step: 30, loss: 0.06444733589887619
step: 40, loss: 0.061506472527980804
step: 50, loss: 0.14509813487529755
step: 60, loss: 0.07944279164075851
step: 70, loss: 0.044258397072553635
step: 80, loss: 0.10644184052944183
step: 90, loss: 0.1691686064004898
step: 100, loss: 0.043696772307157516
step: 110, loss: 0.0543333925306797
step: 120, loss: 0.11048667877912521
step: 130, loss: 0.11894777417182922
step: 140, loss: 0.029488468542695045
step: 150, loss: 0.15704503655433655
step: 160, loss: 0.14414553344249725
step: 170, loss: 0.0712815597653389
step: 180, loss: 0.007744904141873121
step: 190, loss: 0.11261314153671265
step: 200, loss: 0.08162161707878113
step: 210, loss: 0.07154414057731628
step: 220, loss: 0.1501852422952652
step: 230, loss: 0.04853353649377823
step: 240, loss: 0.0908273458480835
step: 250, loss: 0.17992043495178223
step: 260, loss: 0.03666014224290848
step: 270, loss: 0.022799959406256676
step: 280, loss: 0.011888023465871811
step: 290, loss: 0.03472086042165756
step: 300, loss: 0.06058270484209061
step: 310, loss: 0.01797022484242916
step: 320, loss: 0.027083415538072586
step: 330, loss: 0.07376184314489365
step: 340, loss: 0.1518092304468155
step: 350, loss: 0.12763114273548126
step: 360, loss: 0.3013760447502136
step: 370, loss: 0.18548518419265747
step: 380, loss: 0.0593213327229023
step: 390, loss: 0.017971672117710114
step: 400, loss: 0.22074246406555176
step: 410, loss: 0.048869140446186066
step: 420, loss: 0.06339713931083679
step: 430, loss: 0.1509018838405609
step: 440, loss: 0.09522939473390579
step: 450, loss: 0.06878718733787537
step: 460, loss: 0.023330314084887505
step: 470, loss: 0.026328807696700096
step: 480, loss: 0.1052473857998848
step: 490, loss: 0.08194299787282944
step: 500, loss: 0.1307232826948166
step: 510, loss: 0.038514576852321625
step: 520, loss: 0.09559919685125351
step: 530, loss: 0.039824750274419785
step: 540, loss: 0.17313317954540253
step: 550, loss: 0.08974633365869522
step: 560, loss: 0.07268522679805756
step: 570, loss: 0.051225338131189346
step: 580, loss: 0.08051761239767075
step: 590, loss: 0.1056000143289566
step: 600, loss: 0.050739776343107224
step: 610, loss: 0.08587285131216049
step: 620, loss: 0.05443761125206947
step: 630, loss: 0.13906461000442505
step: 640, loss: 0.10462117940187454
step: 650, loss: 0.03097507730126381
step: 660, loss: 0.02333824522793293
step: 670, loss: 0.16139023005962372
step: 680, loss: 0.051894184201955795
step: 690, loss: 0.04293769598007202
step: 700, loss: 0.057858843356370926
step: 710, loss: 0.20239144563674927
step: 720, loss: 0.09599767625331879
step: 730, loss: 0.0747334212064743
step: 740, loss: 0.06424759328365326
step: 750, loss: 0.17614416778087616
step: 760, loss: 0.14475825428962708
step: 770, loss: 0.06601236015558243
step: 780, loss: 0.0304655022919178
step: 790, loss: 0.12681658565998077
step: 800, loss: 0.04123459383845329
step: 810, loss: 0.12614679336547852
step: 820, loss: 0.057925716042518616
step: 830, loss: 0.021536748856306076
step: 840, loss: 0.04289970174431801
step: 850, loss: 0.0998157262802124
step: 860, loss: 0.10755295306444168
step: 870, loss: 0.00022300329874269664
step: 880, loss: 0.14646434783935547
step: 890, loss: 0.05447525903582573
step: 900, loss: 0.052040304988622665
step: 910, loss: 0.084602490067482
step: 920, loss: 0.10121062397956848
step: 930, loss: 0.062106095254421234
step: 940, loss: 0.09386487305164337
step: 950, loss: 0.09306445717811584
step: 960, loss: 0.16141147911548615
step: 970, loss: 0.09933920949697495
step: 980, loss: 0.09499023854732513
step: 990, loss: 0.18870869278907776
step: 1000, loss: 0.16070541739463806
step: 1010, loss: 0.11209753900766373
step: 1020, loss: 0.09413862228393555
step: 1030, loss: 0.06140751764178276
step: 1040, loss: 0.06463637948036194
step: 1050, loss: 0.012438681907951832
step: 1060, loss: 0.068683922290802
step: 1070, loss: 0.10821011662483215
epoch 6: dev_f1=0.928735632183908, f1=0.9300827966881325, best_f1=0.9286367795059469
step: 0, loss: 0.095420703291893
step: 10, loss: 0.1348300725221634
step: 20, loss: 0.05738912895321846
step: 30, loss: 0.020548688247799873
step: 40, loss: 0.03717338666319847
step: 50, loss: 0.12308280915021896
step: 60, loss: 0.14019107818603516
step: 70, loss: 0.271268367767334
step: 80, loss: 0.12389536201953888
step: 90, loss: 0.05121708661317825
step: 100, loss: 0.09614891558885574
step: 110, loss: 0.04605092480778694
step: 120, loss: 0.006320916581898928
step: 130, loss: 0.10738777369260788
step: 140, loss: 0.095039002597332
step: 150, loss: 0.00507681118324399
step: 160, loss: 0.06829306483268738
step: 170, loss: 0.03523595631122589
step: 180, loss: 0.024150464683771133
step: 190, loss: 0.1108454018831253
step: 200, loss: 0.024481896311044693
step: 210, loss: 0.1561444103717804
step: 220, loss: 0.13530878722667694
step: 230, loss: 0.05718417465686798
step: 240, loss: 0.1414739340543747
step: 250, loss: 0.03340686485171318
step: 260, loss: 0.2364538162946701
step: 270, loss: 0.08742882311344147
step: 280, loss: 0.0818997174501419
step: 290, loss: 0.12419380247592926
step: 300, loss: 0.056858547031879425
step: 310, loss: 0.05864276736974716
step: 320, loss: 0.1671554148197174
step: 330, loss: 0.057259708642959595
step: 340, loss: 0.1111917644739151
step: 350, loss: 0.03090047836303711
step: 360, loss: 0.10853638499975204
step: 370, loss: 0.10090786218643188
step: 380, loss: 0.04514848813414574
step: 390, loss: 0.07604534178972244
step: 400, loss: 0.0001087886921595782
step: 410, loss: 0.09555351734161377
step: 420, loss: 0.015691999346017838
step: 430, loss: 0.09794829040765762
step: 440, loss: 0.08823461830615997
step: 450, loss: 0.08317188173532486
step: 460, loss: 0.095561183989048
step: 470, loss: 0.10572664439678192
step: 480, loss: 0.02479957975447178
step: 490, loss: 0.12628847360610962
step: 500, loss: 0.02800743281841278
step: 510, loss: 0.07047584652900696
step: 520, loss: 0.14738048613071442
step: 530, loss: 0.0914434865117073
step: 540, loss: 0.04772433638572693
step: 550, loss: 0.06489542126655579
step: 560, loss: 0.036959465593099594
step: 570, loss: 0.0791272521018982
step: 580, loss: 0.10839428752660751
step: 590, loss: 0.1709207445383072
step: 600, loss: 0.09009326249361038
step: 610, loss: 0.07631784677505493
step: 620, loss: 0.04503346234560013
step: 630, loss: 0.11216767877340317
step: 640, loss: 0.04003031179308891
step: 650, loss: 0.017700931057333946
step: 660, loss: 0.1319338083267212
step: 670, loss: 0.054748859256505966
step: 680, loss: 0.026104841381311417
step: 690, loss: 0.03154467046260834
step: 700, loss: 0.07639819383621216
step: 710, loss: 0.09067918360233307
step: 720, loss: 0.10074262320995331
step: 730, loss: 0.01601186767220497
step: 740, loss: 0.11890537291765213
step: 750, loss: 0.09160146117210388
step: 760, loss: 0.11179070919752121
step: 770, loss: 0.0558057464659214
step: 780, loss: 0.1415330469608307
step: 790, loss: 0.06158766523003578
step: 800, loss: 0.14113812148571014
step: 810, loss: 0.06973865628242493
step: 820, loss: 0.12231910973787308
step: 830, loss: 0.06276505440473557
step: 840, loss: 0.07334715127944946
step: 850, loss: 0.09273988753557205
step: 860, loss: 0.05090954154729843
step: 870, loss: 0.12912961840629578
step: 880, loss: 0.22933544218540192
step: 890, loss: 0.02149858884513378
step: 900, loss: 0.022674143314361572
step: 910, loss: 0.1993376612663269
step: 920, loss: 0.13592632114887238
step: 930, loss: 0.10619105398654938
step: 940, loss: 0.03496018797159195
step: 950, loss: 0.1316422075033188
step: 960, loss: 0.08893650770187378
step: 970, loss: 0.07886156439781189
step: 980, loss: 0.07922350615262985
step: 990, loss: 0.08506324142217636
step: 1000, loss: 0.14739641547203064
step: 1010, loss: 0.053069278597831726
step: 1020, loss: 0.12823501229286194
step: 1030, loss: 0.025950176641345024
step: 1040, loss: 0.01881682500243187
step: 1050, loss: 0.03058231621980667
step: 1060, loss: 0.03557299077510834
step: 1070, loss: 0.037516579031944275
epoch 7: dev_f1=0.9308411214953269, f1=0.924235294117647, best_f1=0.9286367795059469
step: 0, loss: 0.00569101981818676
step: 10, loss: 0.043313223868608475
step: 20, loss: 0.1511145383119583
step: 30, loss: 0.08914942294359207
step: 40, loss: 0.14284493029117584
step: 50, loss: 0.037355903536081314
step: 60, loss: 0.046663496643304825
step: 70, loss: 0.05022261664271355
step: 80, loss: 0.17573028802871704
step: 90, loss: 0.10058917105197906
step: 100, loss: 0.1310955435037613
step: 110, loss: 0.07237763702869415
step: 120, loss: 0.1267082393169403
step: 130, loss: 0.020052626729011536
step: 140, loss: 0.04475100338459015
step: 150, loss: 0.07808340340852737
step: 160, loss: 0.0795404464006424
step: 170, loss: 0.05145964026451111
step: 180, loss: 0.0472855418920517
step: 190, loss: 0.09432698786258698
step: 200, loss: 0.09380750358104706
step: 210, loss: 0.09996725618839264
step: 220, loss: 0.02225915901362896
step: 230, loss: 0.08273620158433914
step: 240, loss: 0.03411860764026642
step: 250, loss: 0.044431522488594055
step: 260, loss: 0.0453077107667923
step: 270, loss: 0.12284184992313385
step: 280, loss: 0.13847491145133972
step: 290, loss: 0.08632943034172058
step: 300, loss: 0.042486246675252914
step: 310, loss: 0.12356118857860565
step: 320, loss: 0.05974622070789337
step: 330, loss: 0.052156005054712296
step: 340, loss: 0.06372471898794174
step: 350, loss: 0.17679482698440552
step: 360, loss: 0.17577269673347473
step: 370, loss: 0.10229168832302094
step: 380, loss: 0.128152996301651
step: 390, loss: 0.1539103388786316
step: 400, loss: 0.13449281454086304
step: 410, loss: 0.02512175962328911
step: 420, loss: 0.06254264712333679
step: 430, loss: 0.163565993309021
step: 440, loss: 0.10850714892148972
step: 450, loss: 0.06510400772094727
step: 460, loss: 0.025798888877034187
step: 470, loss: 0.0733393207192421
step: 480, loss: 0.13824018836021423
step: 490, loss: 0.02362537384033203
step: 500, loss: 0.06471072882413864
step: 510, loss: 0.2578894793987274
step: 520, loss: 0.018528522923588753
step: 530, loss: 0.006433635018765926
step: 540, loss: 0.07284808903932571
step: 550, loss: 0.11067160218954086
step: 560, loss: 0.14604441821575165
step: 570, loss: 0.0937718078494072
step: 580, loss: 0.026891794055700302
step: 590, loss: 0.019229168072342873
step: 600, loss: 0.0550025999546051
step: 610, loss: 0.07194671034812927
step: 620, loss: 0.029710382223129272
step: 630, loss: 0.09480435401201248
step: 640, loss: 0.11185061186552048
step: 650, loss: 0.16347253322601318
step: 660, loss: 0.06465229392051697
step: 670, loss: 0.09064918011426926
step: 680, loss: 0.057676199823617935
step: 690, loss: 0.09413871169090271
step: 700, loss: 0.01343635655939579
step: 710, loss: 0.12832461297512054
step: 720, loss: 0.10790402442216873
step: 730, loss: 0.052176639437675476
step: 740, loss: 0.05318375676870346
step: 750, loss: 0.056421391665935516
step: 760, loss: 0.06462623178958893
step: 770, loss: 0.01863032765686512
step: 780, loss: 0.13475258648395538
step: 790, loss: 0.06813405454158783
step: 800, loss: 0.06623760610818863
step: 810, loss: 0.1088189110159874
step: 820, loss: 0.10659022629261017
step: 830, loss: 0.019253365695476532
step: 840, loss: 0.08041071146726608
step: 850, loss: 0.07416929304599762
step: 860, loss: 0.04494483023881912
step: 870, loss: 0.09672084450721741
step: 880, loss: 0.11248357594013214
step: 890, loss: 0.05552462488412857
step: 900, loss: 0.08598684519529343
step: 910, loss: 0.031972721219062805
step: 920, loss: 0.056602947413921356
step: 930, loss: 0.10012409836053848
step: 940, loss: 0.05376525595784187
step: 950, loss: 0.03909170255064964
step: 960, loss: 0.05369127541780472
step: 970, loss: 0.03874081373214722
step: 980, loss: 0.08230724185705185
step: 990, loss: 0.11467114835977554
step: 1000, loss: 0.12164653837680817
step: 1010, loss: 0.05680499225854874
step: 1020, loss: 0.02857610210776329
step: 1030, loss: 0.1303349882364273
step: 1040, loss: 0.08432430773973465
step: 1050, loss: 0.0744810402393341
step: 1060, loss: 0.04289773479104042
step: 1070, loss: 0.06422337144613266
epoch 8: dev_f1=0.9327231121281464, f1=0.9305936073059361, best_f1=0.9305936073059361
step: 0, loss: 0.02532302774488926
step: 10, loss: 0.04602448642253876
step: 20, loss: 0.06600513309240341
step: 30, loss: 0.020464111119508743
step: 40, loss: 0.04690583422780037
step: 50, loss: 0.026591530069708824
step: 60, loss: 0.08052162081003189
step: 70, loss: 0.05901530385017395
step: 80, loss: 0.047169506549835205
step: 90, loss: 0.18852238357067108
step: 100, loss: 0.03455275297164917
step: 110, loss: 0.031433045864105225
step: 120, loss: 0.028127523139119148
step: 130, loss: 0.08417107164859772
step: 140, loss: 0.016888603568077087
step: 150, loss: 0.04260664060711861
step: 160, loss: 0.07014687359333038
step: 170, loss: 0.15041831135749817
step: 180, loss: 0.007421312388032675
step: 190, loss: 0.012923317030072212
step: 200, loss: 0.08651688694953918
step: 210, loss: 0.0644068792462349
step: 220, loss: 0.1371161788702011
step: 230, loss: 0.015889957547187805
step: 240, loss: 0.0004014627484139055
step: 250, loss: 0.10327175259590149
step: 260, loss: 0.06572140008211136
step: 270, loss: 0.09235648065805435
step: 280, loss: 0.09498324990272522
step: 290, loss: 0.047875549644231796
step: 300, loss: 0.11017151176929474
step: 310, loss: 0.03671001270413399
step: 320, loss: 0.10471389442682266
step: 330, loss: 0.030408194288611412
step: 340, loss: 0.01129791047424078
step: 350, loss: 0.0560198612511158
step: 360, loss: 0.006907608825713396
step: 370, loss: 0.0549963004887104
step: 380, loss: 0.08989164978265762
step: 390, loss: 0.07780522108078003
step: 400, loss: 0.029752597212791443
step: 410, loss: 0.049937374889850616
step: 420, loss: 0.03668971359729767
step: 430, loss: 0.08158794790506363
step: 440, loss: 0.05942245200276375
step: 450, loss: 0.11750384420156479
step: 460, loss: 0.08281183987855911
step: 470, loss: 0.05293901637196541
step: 480, loss: 0.08776552230119705
step: 490, loss: 0.028477400541305542
step: 500, loss: 0.09934671968221664
step: 510, loss: 0.017499752342700958
step: 520, loss: 0.04218633845448494
step: 530, loss: 0.07825273275375366
step: 540, loss: 0.008246026001870632
step: 550, loss: 0.031782813370227814
step: 560, loss: 0.08178391307592392
step: 570, loss: 0.14093860983848572
step: 580, loss: 0.08510085940361023
step: 590, loss: 0.05194105580449104
step: 600, loss: 0.03387613594532013
step: 610, loss: 0.08116459101438522
step: 620, loss: 0.060322415083646774
step: 630, loss: 0.02129478007555008
step: 640, loss: 0.07768167555332184
step: 650, loss: 0.08028072863817215
step: 660, loss: 0.13928461074829102
step: 670, loss: 0.04463164880871773
step: 680, loss: 0.07717585563659668
step: 690, loss: 0.016952624544501305
step: 700, loss: 0.030283313244581223
step: 710, loss: 0.10565828531980515
step: 720, loss: 0.12354796379804611
step: 730, loss: 0.05683720484375954
step: 740, loss: 0.10805566608905792
step: 750, loss: 0.056825701147317886
step: 760, loss: 0.08651038259267807
step: 770, loss: 0.047166913747787476
step: 780, loss: 0.0339650996029377
step: 790, loss: 0.05107200890779495
step: 800, loss: 0.1306522935628891
step: 810, loss: 0.14392656087875366
step: 820, loss: 0.09459667652845383
step: 830, loss: 0.08791428804397583
step: 840, loss: 0.027565015479922295
step: 850, loss: 0.06317933648824692
step: 860, loss: 0.09744150191545486
step: 870, loss: 0.13750755786895752
step: 880, loss: 0.13349415361881256
step: 890, loss: 0.06665679067373276
step: 900, loss: 0.041902102530002594
step: 910, loss: 0.05759139731526375
step: 920, loss: 0.16910409927368164
step: 930, loss: 0.10417346656322479
step: 940, loss: 0.03345005214214325
step: 950, loss: 0.07635568827390671
step: 960, loss: 0.04151606559753418
step: 970, loss: 0.0001268607738893479
step: 980, loss: 0.09269147366285324
step: 990, loss: 0.01589977741241455
step: 1000, loss: 0.06897562742233276
step: 1010, loss: 0.0350712314248085
step: 1020, loss: 0.12072807550430298
step: 1030, loss: 0.04977613687515259
step: 1040, loss: 0.05024963617324829
step: 1050, loss: 0.06847793608903885
step: 1060, loss: 0.055802009999752045
step: 1070, loss: 0.019527634605765343
epoch 9: dev_f1=0.9306569343065694, f1=0.9304666056724611, best_f1=0.9305936073059361
step: 0, loss: 0.043191246688365936
step: 10, loss: 0.0675429105758667
step: 20, loss: 0.11383777856826782
step: 30, loss: 0.07361333817243576
step: 40, loss: 0.05850472301244736
step: 50, loss: 0.1007193997502327
step: 60, loss: 0.020769888535141945
step: 70, loss: 0.16057607531547546
step: 80, loss: 0.2000741809606552
step: 90, loss: 0.062086235731840134
step: 100, loss: 0.026249263435602188
step: 110, loss: 0.07976049929857254
step: 120, loss: 0.09137938171625137
step: 130, loss: 0.02548748068511486
step: 140, loss: 0.04628920182585716
step: 150, loss: 0.10731575638055801
step: 160, loss: 0.1616450995206833
step: 170, loss: 0.01931953802704811
step: 180, loss: 0.018225278705358505
step: 190, loss: 0.01931108720600605
step: 200, loss: 0.07809221744537354
step: 210, loss: 0.05173493176698685
step: 220, loss: 0.1161867305636406
step: 230, loss: 0.015008286572992802
step: 240, loss: 0.024938136339187622
step: 250, loss: 0.042769141495227814
step: 260, loss: 0.09848435968160629
step: 270, loss: 0.10480909794569016
step: 280, loss: 0.021395601332187653
step: 290, loss: 0.03714843466877937
step: 300, loss: 0.12248501926660538
step: 310, loss: 0.005604155361652374
step: 320, loss: 0.02459554746747017
step: 330, loss: 0.01876797154545784
step: 340, loss: 0.10007227212190628
step: 350, loss: 0.0379517637193203
step: 360, loss: 0.05477501079440117
step: 370, loss: 0.0678597018122673
step: 380, loss: 0.06024811416864395
step: 390, loss: 0.06937039643526077
step: 400, loss: 0.006728448439389467
step: 410, loss: 0.06858696043491364
step: 420, loss: 0.01699152961373329
step: 430, loss: 0.05239950120449066
step: 440, loss: 0.027356086298823357
step: 450, loss: 0.14506712555885315
step: 460, loss: 0.04280748963356018
step: 470, loss: 0.05758476257324219
step: 480, loss: 0.12833303213119507
step: 490, loss: 0.10961001366376877
step: 500, loss: 0.11749804019927979
step: 510, loss: 0.005147932562977076
step: 520, loss: 0.1426151692867279
step: 530, loss: 0.061634503304958344
step: 540, loss: 0.03983128443360329
step: 550, loss: 0.024438360705971718
step: 560, loss: 0.07952111959457397
step: 570, loss: 0.039508141577243805
step: 580, loss: 0.029877634719014168
step: 590, loss: 0.05765777453780174
step: 600, loss: 0.034796133637428284
step: 610, loss: 0.1373327523469925
step: 620, loss: 0.08382925391197205
step: 630, loss: 0.020325426012277603
step: 640, loss: 0.08976246416568756
step: 650, loss: 0.04829341918230057
step: 660, loss: 0.13731546700000763
step: 670, loss: 0.09253967553377151
step: 680, loss: 0.07040776312351227
step: 690, loss: 0.02765042334794998
step: 700, loss: 0.13837936520576477
step: 710, loss: 0.05581085756421089
step: 720, loss: 0.05115709453821182
step: 730, loss: 0.019311215728521347
step: 740, loss: 0.02679191716015339
step: 750, loss: 0.06631070375442505
step: 760, loss: 0.07135701179504395
step: 770, loss: 0.02761499397456646
step: 780, loss: 0.0358290895819664
step: 790, loss: 0.061427146196365356
step: 800, loss: 0.05474624037742615
step: 810, loss: 0.03980759158730507
step: 820, loss: 0.08881703019142151
step: 830, loss: 0.028171813115477562
step: 840, loss: 0.11600296199321747
step: 850, loss: 0.03878781199455261
step: 860, loss: 0.02062850072979927
step: 870, loss: 0.048639800399541855
step: 880, loss: 0.10054581612348557
step: 890, loss: 0.06278208643198013
step: 900, loss: 0.15549397468566895
step: 910, loss: 0.09617992490530014
step: 920, loss: 0.22884222865104675
step: 930, loss: 0.08133392781019211
step: 940, loss: 0.0669843927025795
step: 950, loss: 0.14287424087524414
step: 960, loss: 0.044508788734674454
step: 970, loss: 0.0968954861164093
step: 980, loss: 0.08191706985235214
step: 990, loss: 0.06042701005935669
step: 1000, loss: 0.1236015260219574
step: 1010, loss: 0.08671252429485321
step: 1020, loss: 0.09624184668064117
step: 1030, loss: 0.06788056343793869
step: 1040, loss: 0.10161334276199341
step: 1050, loss: 0.07319669425487518
step: 1060, loss: 0.044538747519254684
step: 1070, loss: 0.06820877641439438
epoch 10: dev_f1=0.9286047596826879, f1=0.9282027217268888, best_f1=0.9305936073059361
step: 0, loss: 0.06153879314661026
step: 10, loss: 0.02514643780887127
step: 20, loss: 0.10207470506429672
step: 30, loss: 0.016974840313196182
step: 40, loss: 0.09411323070526123
step: 50, loss: 0.015889359638094902
step: 60, loss: 0.03694044426083565
step: 70, loss: 0.0509304478764534
step: 80, loss: 0.006658395752310753
step: 90, loss: 0.09540620446205139
step: 100, loss: 0.01977839320898056
step: 110, loss: 0.17292910814285278
step: 120, loss: 0.06174551695585251
step: 130, loss: 0.1371387094259262
step: 140, loss: 0.07034844160079956
step: 150, loss: 0.09477511793375015
step: 160, loss: 0.08300576359033585
step: 170, loss: 0.05333523824810982
step: 180, loss: 0.0037161274813115597
step: 190, loss: 0.06800487637519836
step: 200, loss: 0.016924777999520302
step: 210, loss: 0.018748344853520393
step: 220, loss: 0.05777853727340698
step: 230, loss: 0.032867856323719025
step: 240, loss: 0.047987427562475204
step: 250, loss: 0.011589880101382732
step: 260, loss: 0.010211944580078125
step: 270, loss: 0.0016686832532286644
step: 280, loss: 0.05197307467460632
step: 290, loss: 0.06494835019111633
step: 300, loss: 0.0286864060908556
step: 310, loss: 0.03685712441802025
step: 320, loss: 0.06906816363334656
step: 330, loss: 0.00047704551252536476
step: 340, loss: 0.033258263021707535
step: 350, loss: 0.04035446420311928
step: 360, loss: 0.02362143062055111
step: 370, loss: 0.10198181122541428
step: 380, loss: 0.010443449020385742
step: 390, loss: 0.036400724202394485
step: 400, loss: 0.07284330576658249
step: 410, loss: 0.020129214972257614
step: 420, loss: 0.0026387509424239397
step: 430, loss: 0.048546213656663895
step: 440, loss: 0.051629163324832916
step: 450, loss: 0.07004600763320923
step: 460, loss: 0.049860209226608276
step: 470, loss: 0.0713847428560257
step: 480, loss: 0.10488203912973404
step: 490, loss: 0.020737722516059875
step: 500, loss: 0.09361937642097473
step: 510, loss: 0.042082369327545166
step: 520, loss: 0.098136305809021
step: 530, loss: 0.03678109124302864
step: 540, loss: 0.046621136367321014
step: 550, loss: 0.08937399089336395
step: 560, loss: 0.030037030577659607
step: 570, loss: 0.09240013360977173
step: 580, loss: 0.11192108690738678
step: 590, loss: 0.08414535969495773
step: 600, loss: 0.09872428327798843
step: 610, loss: 0.09025170654058456
step: 620, loss: 0.10226742178201675
step: 630, loss: 0.10405853390693665
step: 640, loss: 0.17686118185520172
step: 650, loss: 0.048220518976449966
step: 660, loss: 0.14188064634799957
step: 670, loss: 0.1164189875125885
step: 680, loss: 0.05856120213866234
step: 690, loss: 0.050639569759368896
step: 700, loss: 0.05542796105146408
step: 710, loss: 0.0559425987303257
step: 720, loss: 0.09593263268470764
step: 730, loss: 0.08128359168767929
step: 740, loss: 0.05388779938220978
step: 750, loss: 0.05849454179406166
step: 760, loss: 0.0173402838408947
step: 770, loss: 0.0701276883482933
step: 780, loss: 0.09384191781282425
step: 790, loss: 0.10185633599758148
step: 800, loss: 0.14544253051280975
step: 810, loss: 0.03475195914506912
step: 820, loss: 0.054861992597579956
step: 830, loss: 0.020530007779598236
step: 840, loss: 0.01742873527109623
step: 850, loss: 0.17582006752490997
step: 860, loss: 0.040190111845731735
step: 870, loss: 0.05904990807175636
step: 880, loss: 0.021362103521823883
step: 890, loss: 0.06898047775030136
step: 900, loss: 0.0464954748749733
step: 910, loss: 0.061901889741420746
step: 920, loss: 0.13349497318267822
step: 930, loss: 0.08137746155261993
step: 940, loss: 0.0716976746916771
step: 950, loss: 0.05915455520153046
step: 960, loss: 0.05246652290225029
step: 970, loss: 0.07647833973169327
step: 980, loss: 0.1074792817234993
step: 990, loss: 0.03247470036149025
step: 1000, loss: 0.12341251969337463
step: 1010, loss: 0.06230376288294792
step: 1020, loss: 0.0008073747740127146
step: 1030, loss: 0.028653211891651154
step: 1040, loss: 0.019354864954948425
step: 1050, loss: 0.011984954588115215
step: 1060, loss: 0.04705077037215233
step: 1070, loss: 0.05526057630777359
epoch 11: dev_f1=0.9219534459151072, f1=0.9244159413650939, best_f1=0.9305936073059361
step: 0, loss: 0.007094026543200016
step: 10, loss: 0.02191910147666931
step: 20, loss: 0.04941913112998009
step: 30, loss: 0.10147586464881897
step: 40, loss: 0.03934919461607933
step: 50, loss: 0.20568785071372986
step: 60, loss: 0.0790133848786354
step: 70, loss: 0.011679762974381447
step: 80, loss: 0.09023207426071167
step: 90, loss: 0.014698661863803864
step: 100, loss: 0.09988079965114594
step: 110, loss: 0.038106102496385574
step: 120, loss: 0.02484465204179287
step: 130, loss: 0.04188396409153938
step: 140, loss: 0.00855735782533884
step: 150, loss: 0.024044577032327652
step: 160, loss: 0.10264188796281815
step: 170, loss: 0.014473113231360912
step: 180, loss: 0.06842494010925293
step: 190, loss: 0.02773517742753029
step: 200, loss: 0.06675412505865097
step: 210, loss: 0.16742581129074097
step: 220, loss: 0.04186762124300003
step: 230, loss: 0.05831751599907875
step: 240, loss: 0.032443054020404816
step: 250, loss: 0.020801939070224762
step: 260, loss: 0.0680159330368042
step: 270, loss: 0.004850335884839296
step: 280, loss: 0.12757821381092072
step: 290, loss: 0.01992867887020111
step: 300, loss: 0.024999340996146202
step: 310, loss: 0.035826899111270905
step: 320, loss: 0.08998516201972961
step: 330, loss: 0.06843841820955276
step: 340, loss: 0.09574996680021286
step: 350, loss: 0.011135910637676716
step: 360, loss: 0.07677767425775528
step: 370, loss: 0.0660015419125557
step: 380, loss: 0.000133693334646523
step: 390, loss: 0.1438538283109665
step: 400, loss: 0.12994983792304993
step: 410, loss: 0.05110136792063713
step: 420, loss: 0.1606614738702774
step: 430, loss: 0.0788608193397522
step: 440, loss: 0.0776556208729744
step: 450, loss: 0.03515714034438133
step: 460, loss: 0.027909504249691963
step: 470, loss: 0.033773429691791534
step: 480, loss: 0.05429326370358467
step: 490, loss: 0.062189891934394836
step: 500, loss: 0.06467505544424057
step: 510, loss: 0.0143297603353858
step: 520, loss: 0.04827430471777916
step: 530, loss: 0.020277095958590508
step: 540, loss: 0.03966008126735687
step: 550, loss: 0.011872022412717342
step: 560, loss: 0.03279438614845276
step: 570, loss: 0.013489714823663235
step: 580, loss: 0.0028896809089928865
step: 590, loss: 0.01709168031811714
step: 600, loss: 0.07989507168531418
step: 610, loss: 0.20966191589832306
step: 620, loss: 0.016236498951911926
step: 630, loss: 0.038331449031829834
step: 640, loss: 0.04466083273291588
step: 650, loss: 0.06271370500326157
step: 660, loss: 0.05838741734623909
step: 670, loss: 0.04363083094358444
step: 680, loss: 0.2140328735113144
step: 690, loss: 0.00014574386295862496
step: 700, loss: 0.021808678284287453
step: 710, loss: 0.05612099915742874
step: 720, loss: 0.07628742605447769
step: 730, loss: 0.022719332948327065
step: 740, loss: 0.05257480964064598
step: 750, loss: 3.0192202757461928e-05
step: 760, loss: 0.023886103183031082
step: 770, loss: 0.03711054101586342
step: 780, loss: 0.023866478353738785
step: 790, loss: 0.013320360332727432
step: 800, loss: 0.056142643094062805
step: 810, loss: 0.19900840520858765
step: 820, loss: 0.007741155102849007
step: 830, loss: 0.06343469768762589
step: 840, loss: 0.03464149311184883
step: 850, loss: 0.0073880720883607864
step: 860, loss: 0.03563576936721802
step: 870, loss: 0.08027370274066925
step: 880, loss: 0.030636586248874664
step: 890, loss: 0.12425454705953598
step: 900, loss: 0.10640638321638107
step: 910, loss: 0.029970265924930573
step: 920, loss: 0.09518735855817795
step: 930, loss: 0.03744830936193466
step: 940, loss: 0.06539983302354813
step: 950, loss: 0.022632449865341187
step: 960, loss: 0.10163185000419617
step: 970, loss: 0.0383102148771286
step: 980, loss: 0.002807869575917721
step: 990, loss: 0.06653120368719101
step: 1000, loss: 0.12205268442630768
step: 1010, loss: 0.005420469678938389
step: 1020, loss: 0.121709905564785
step: 1030, loss: 0.11857561022043228
step: 1040, loss: 0.03977816179394722
step: 1050, loss: 0.023267194628715515
step: 1060, loss: 0.004638131707906723
step: 1070, loss: 0.06895222514867783
epoch 12: dev_f1=0.9305555555555556, f1=0.9348729792147806, best_f1=0.9305936073059361
step: 0, loss: 0.01824299991130829
step: 10, loss: 0.057120416313409805
step: 20, loss: 0.032065488398075104
step: 30, loss: 0.0498100146651268
step: 40, loss: 0.07289399951696396
step: 50, loss: 0.03758475184440613
step: 60, loss: 0.07169695198535919
step: 70, loss: 0.038925111293792725
step: 80, loss: 0.0001291919470531866
step: 90, loss: 0.01965934783220291
step: 100, loss: 0.15658016502857208
step: 110, loss: 0.0030976212583482265
step: 120, loss: 0.17322838306427002
step: 130, loss: 0.018840426579117775
step: 140, loss: 0.03447026386857033
step: 150, loss: 0.04765259474515915
step: 160, loss: 0.020458374172449112
step: 170, loss: 0.03381725400686264
step: 180, loss: 0.02534598857164383
step: 190, loss: 0.08829635381698608
step: 200, loss: 0.07724588364362717
step: 210, loss: 0.03676053509116173
step: 220, loss: 0.010002454742789268
step: 230, loss: 0.0500236414372921
step: 240, loss: 0.0764637365937233
step: 250, loss: 0.0007652897038497031
step: 260, loss: 0.0454341284930706
step: 270, loss: 0.02908586710691452
step: 280, loss: 0.0963784009218216
step: 290, loss: 0.027223285287618637
step: 300, loss: 0.05738816410303116
step: 310, loss: 0.04957134649157524
step: 320, loss: 0.10617964714765549
step: 330, loss: 0.00796118937432766
step: 340, loss: 0.07649461925029755
step: 350, loss: 0.08319362252950668
step: 360, loss: 0.08940951526165009
step: 370, loss: 0.03101118467748165
step: 380, loss: 0.1281636357307434
step: 390, loss: 0.017591899260878563
step: 400, loss: 0.029024507850408554
step: 410, loss: 0.08356589823961258
step: 420, loss: 0.027764249593019485
step: 430, loss: 0.08452676981687546
step: 440, loss: 0.09143853187561035
step: 450, loss: 0.07499103993177414
step: 460, loss: 0.02456941083073616
step: 470, loss: 0.11697861552238464
step: 480, loss: 0.01086502242833376
step: 490, loss: 4.1734798287507147e-05
step: 500, loss: 0.0026428010314702988
step: 510, loss: 0.08805645257234573
step: 520, loss: 0.04884924739599228
step: 530, loss: 0.0895579382777214
step: 540, loss: 0.05012316629290581
step: 550, loss: 0.044542476534843445
step: 560, loss: 0.051288243383169174
step: 570, loss: 0.04388010874390602
step: 580, loss: 0.07453806698322296
step: 590, loss: 0.008753329515457153
step: 600, loss: 0.01690572313964367
step: 610, loss: 0.014663373120129108
step: 620, loss: 0.08149096369743347
step: 630, loss: 0.056936971843242645
step: 640, loss: 0.00010425125219626352
step: 650, loss: 0.037739697843790054
step: 660, loss: 0.07873803377151489
step: 670, loss: 0.042692117393016815
step: 680, loss: 0.004638563841581345
step: 690, loss: 0.043162450194358826
step: 700, loss: 0.16504934430122375
step: 710, loss: 0.04029380530118942
step: 720, loss: 0.06631121784448624
step: 730, loss: 0.04282330721616745
step: 740, loss: 0.04935178905725479
step: 750, loss: 0.06840471923351288
step: 760, loss: 0.016050638630986214
step: 770, loss: 0.039697930216789246
step: 780, loss: 0.05211203172802925
step: 790, loss: 0.010366539470851421
step: 800, loss: 0.13923907279968262
step: 810, loss: 0.02169010043144226
step: 820, loss: 0.025564664974808693
step: 830, loss: 0.10552982985973358
step: 840, loss: 0.01795993559062481
step: 850, loss: 0.07882427424192429
step: 860, loss: 0.127386212348938
step: 870, loss: 0.0331856906414032
step: 880, loss: 0.11419601738452911
step: 890, loss: 0.08075357973575592
step: 900, loss: 0.06954049319028854
step: 910, loss: 0.022140126675367355
step: 920, loss: 0.10337872058153152
step: 930, loss: 0.06524651497602463
step: 940, loss: 0.033817093819379807
step: 950, loss: 0.00033386534778401256
step: 960, loss: 0.024878932163119316
step: 970, loss: 0.031200353056192398
step: 980, loss: 0.0462818443775177
step: 990, loss: 0.11189021915197372
step: 1000, loss: 0.0788244754076004
step: 1010, loss: 0.014975171536207199
step: 1020, loss: 0.013576822355389595
step: 1030, loss: 0.2804337739944458
step: 1040, loss: 0.01768624410033226
step: 1050, loss: 0.03253486752510071
step: 1060, loss: 0.04937053471803665
step: 1070, loss: 0.008945931680500507
epoch 13: dev_f1=0.9305816135084428, f1=0.9305164319248826, best_f1=0.9305936073059361
step: 0, loss: 0.015295327641069889
step: 10, loss: 0.10654985159635544
step: 20, loss: 0.016376519575715065
step: 30, loss: 0.020054031163454056
step: 40, loss: 0.046889785677194595
step: 50, loss: 0.04669059067964554
step: 60, loss: 0.04350000247359276
step: 70, loss: 0.019136976450681686
step: 80, loss: 0.05433087423443794
step: 90, loss: 0.04157736152410507
step: 100, loss: 0.06186605617403984
step: 110, loss: 0.10125678032636642
step: 120, loss: 0.021003032103180885
step: 130, loss: 0.02634510211646557
step: 140, loss: 0.05964197963476181
step: 150, loss: 0.07035473734140396
step: 160, loss: 0.05336609482765198
step: 170, loss: 0.07477286458015442
step: 180, loss: 0.00033322669332847
step: 190, loss: 0.06481394171714783
step: 200, loss: 0.03238799422979355
step: 210, loss: 0.015880899503827095
step: 220, loss: 0.03948567435145378
step: 230, loss: 0.07631681114435196
step: 240, loss: 0.03252027928829193
step: 250, loss: 0.009568831883370876
step: 260, loss: 0.03573579713702202
step: 270, loss: 0.08602612465620041
step: 280, loss: 0.05583822354674339
step: 290, loss: 0.08373810350894928
step: 300, loss: 0.06471996754407883
step: 310, loss: 0.09638305753469467
step: 320, loss: 0.02171643078327179
step: 330, loss: 0.02538776397705078
step: 340, loss: 0.040133558213710785
step: 350, loss: 0.0006118531455285847
step: 360, loss: 0.056780245155096054
step: 370, loss: 0.28275546431541443
step: 380, loss: 0.025602085515856743
step: 390, loss: 0.04533948004245758
step: 400, loss: 0.05113242194056511
step: 410, loss: 0.0982384979724884
step: 420, loss: 0.007606453727930784
step: 430, loss: 0.031125904992222786
step: 440, loss: 0.015680521726608276
step: 450, loss: 0.0625140592455864
step: 460, loss: 0.16251683235168457
step: 470, loss: 0.03345763310790062
step: 480, loss: 0.13962316513061523
step: 490, loss: 0.029814347624778748
step: 500, loss: 0.00844954326748848
step: 510, loss: 0.14372751116752625
step: 520, loss: 0.0770668163895607
step: 530, loss: 1.7113738067564555e-05
step: 540, loss: 0.01000533439218998
step: 550, loss: 0.023629043251276016
step: 560, loss: 0.09600584954023361
step: 570, loss: 0.042087867856025696
step: 580, loss: 0.05116579681634903
step: 590, loss: 0.028025254607200623
step: 600, loss: 0.018957626074552536
step: 610, loss: 0.12170545011758804
step: 620, loss: 0.009036686271429062
step: 630, loss: 0.06118258833885193
step: 640, loss: 0.0075787706300616264
step: 650, loss: 0.020195096731185913
step: 660, loss: 0.08554377406835556
step: 670, loss: 0.06107592582702637
step: 680, loss: 0.04224925488233566
step: 690, loss: 7.58910973672755e-05
step: 700, loss: 0.09904783964157104
step: 710, loss: 0.07005409896373749
step: 720, loss: 0.09573349356651306
step: 730, loss: 0.016323057934641838
step: 740, loss: 0.020445609465241432
step: 750, loss: 0.027974633499979973
step: 760, loss: 0.02847241424024105
step: 770, loss: 0.10013547539710999
step: 780, loss: 0.10824811458587646
step: 790, loss: 0.0018652878934517503
step: 800, loss: 0.08458512276411057
step: 810, loss: 0.0005890019820071757
step: 820, loss: 0.04441891610622406
step: 830, loss: 0.10947548598051071
step: 840, loss: 0.00014093185018282384
step: 850, loss: 0.07420849800109863
step: 860, loss: 0.04068271443247795
step: 870, loss: 0.05107554420828819
step: 880, loss: 0.024533633142709732
step: 890, loss: 0.04303961992263794
step: 900, loss: 0.06327580660581589
step: 910, loss: 0.03143583983182907
step: 920, loss: 0.10020133852958679
step: 930, loss: 0.0688057541847229
step: 940, loss: 0.003629602026194334
step: 950, loss: 0.02496764250099659
step: 960, loss: 0.058515992015600204
step: 970, loss: 0.036299481987953186
step: 980, loss: 0.10797211527824402
step: 990, loss: 0.04941362142562866
step: 1000, loss: 0.012324931100010872
step: 1010, loss: 0.03830645605921745
step: 1020, loss: 0.04023495316505432
step: 1030, loss: 0.10269425064325333
step: 1040, loss: 0.13234031200408936
step: 1050, loss: 0.012753022834658623
step: 1060, loss: 0.03620200604200363
step: 1070, loss: 0.017435001209378242
epoch 14: dev_f1=0.9227906976744187, f1=0.9220055710306406, best_f1=0.9305936073059361
step: 0, loss: 0.022642452269792557
step: 10, loss: 0.11506864428520203
step: 20, loss: 0.07850854098796844
step: 30, loss: 0.08556661009788513
step: 40, loss: 0.00042869264143519104
step: 50, loss: 0.05142916366457939
step: 60, loss: 0.053183455020189285
step: 70, loss: 0.04711227864027023
step: 80, loss: 0.02859630435705185
step: 90, loss: 0.07397088408470154
step: 100, loss: 0.05146993324160576
step: 110, loss: 0.0820896103978157
step: 120, loss: 0.08814111351966858
step: 130, loss: 0.034726981073617935
step: 140, loss: 0.017180966213345528
step: 150, loss: 0.018385352566838264
step: 160, loss: 0.07258708775043488
step: 170, loss: 0.005875726230442524
step: 180, loss: 0.006929520517587662
step: 190, loss: 0.021715300157666206
step: 200, loss: 0.005096519831568003
step: 210, loss: 0.04183698818087578
step: 220, loss: 0.025186972692608833
step: 230, loss: 0.025792578235268593
step: 240, loss: 0.047636695206165314
step: 250, loss: 0.00014391176227945834
step: 260, loss: 0.00399310328066349
step: 270, loss: 0.08390647172927856
step: 280, loss: 0.07544582337141037
step: 290, loss: 0.025279778987169266
step: 300, loss: 0.1153642013669014
step: 310, loss: 0.006628009956330061
step: 320, loss: 0.06600973010063171
step: 330, loss: 0.001378710032440722
step: 340, loss: 5.3585372370434925e-05
step: 350, loss: 0.05780214071273804
step: 360, loss: 0.05147528648376465
step: 370, loss: 0.055752918124198914
step: 380, loss: 0.0434744767844677
step: 390, loss: 0.02030099742114544
step: 400, loss: 0.06727298349142075
step: 410, loss: 0.07949464023113251
step: 420, loss: 0.06532788276672363
step: 430, loss: 0.10401499271392822
step: 440, loss: 0.04037005826830864
step: 450, loss: 0.000894926197361201
step: 460, loss: 0.03553590178489685
step: 470, loss: 0.05773273855447769
step: 480, loss: 0.04386120289564133
step: 490, loss: 0.10188673436641693
step: 500, loss: 0.01504465565085411
step: 510, loss: 5.124202652950771e-05
step: 520, loss: 0.09866850823163986
step: 530, loss: 0.03760206699371338
step: 540, loss: 0.04570085555315018
step: 550, loss: 0.021283326670527458
step: 560, loss: 0.06297135353088379
step: 570, loss: 0.13841407001018524
step: 580, loss: 0.05006518214941025
step: 590, loss: 0.04603255167603493
step: 600, loss: 0.07847699522972107
step: 610, loss: 0.0479033961892128
step: 620, loss: 0.014262035489082336
step: 630, loss: 0.027943411841988564
step: 640, loss: 0.1847139298915863
step: 650, loss: 0.06967095285654068
step: 660, loss: 0.06873998790979385
step: 670, loss: 0.00010371488315286115
step: 680, loss: 0.02443477138876915
step: 690, loss: 0.044659242033958435
step: 700, loss: 0.05080961808562279
step: 710, loss: 0.027776524424552917
step: 720, loss: 0.029543060809373856
step: 730, loss: 0.03379584476351738
step: 740, loss: 0.07197623699903488
step: 750, loss: 0.10391104221343994
step: 760, loss: 0.028191281482577324
step: 770, loss: 0.04553556069731712
step: 780, loss: 0.038194045424461365
step: 790, loss: 0.04942663013935089
step: 800, loss: 0.07318511605262756
step: 810, loss: 0.10904602706432343
step: 820, loss: 0.0002348120469832793
step: 830, loss: 0.025086957961320877
step: 840, loss: 0.022601522505283356
step: 850, loss: 0.02898111380636692
step: 860, loss: 0.11095427721738815
step: 870, loss: 0.02167859673500061
step: 880, loss: 0.029342474415898323
step: 890, loss: 0.08876022696495056
step: 900, loss: 0.04142273962497711
step: 910, loss: 0.03767520561814308
step: 920, loss: 0.008845172822475433
step: 930, loss: 0.049722712486982346
step: 940, loss: 0.016250919550657272
step: 950, loss: 0.04582119733095169
step: 960, loss: 0.019393406808376312
step: 970, loss: 0.08128631114959717
step: 980, loss: 0.0565929114818573
step: 990, loss: 0.038241904228925705
step: 1000, loss: 0.025631438940763474
step: 1010, loss: 0.01778670772910118
step: 1020, loss: 0.04209281504154205
step: 1030, loss: 0.042373742908239365
step: 1040, loss: 0.038230087608098984
step: 1050, loss: 0.03579752892255783
step: 1060, loss: 0.06168751418590546
step: 1070, loss: 0.06240922957658768
epoch 15: dev_f1=0.9254013220018885, f1=0.9248937175247992, best_f1=0.9305936073059361
step: 0, loss: 0.029182208701968193
step: 10, loss: 0.032948993146419525
step: 20, loss: 0.02502022683620453
step: 30, loss: 0.0336621068418026
step: 40, loss: 0.14738509058952332
step: 50, loss: 0.05698780342936516
step: 60, loss: 0.034012552350759506
step: 70, loss: 0.0935748741030693
step: 80, loss: 0.10218001157045364
step: 90, loss: 0.10612175613641739
step: 100, loss: 0.06278038769960403
step: 110, loss: 0.049385324120521545
step: 120, loss: 0.041469868272542953
step: 130, loss: 0.026963479816913605
step: 140, loss: 0.08558165282011032
step: 150, loss: 0.04196229949593544
step: 160, loss: 0.01120668649673462
step: 170, loss: 0.15575866401195526
step: 180, loss: 0.02755015529692173
step: 190, loss: 0.03855392709374428
step: 200, loss: 0.00025051881675608456
step: 210, loss: 0.03150780498981476
step: 220, loss: 0.04519784078001976
step: 230, loss: 0.02566535584628582
step: 240, loss: 0.05088161304593086
step: 250, loss: 0.02690509520471096
step: 260, loss: 0.00042218260932713747
step: 270, loss: 0.034356649965047836
step: 280, loss: 0.021126406267285347
step: 290, loss: 0.04759662225842476
step: 300, loss: 0.04390070214867592
step: 310, loss: 0.01985950767993927
step: 320, loss: 0.025990623980760574
step: 330, loss: 0.04211898148059845
step: 340, loss: 0.05631272867321968
step: 350, loss: 0.012788353487849236
step: 360, loss: 0.0013905784580856562
step: 370, loss: 0.0010808546794578433
step: 380, loss: 7.09578744135797e-05
step: 390, loss: 0.10257170349359512
step: 400, loss: 0.021983742713928223
step: 410, loss: 0.034827183932065964
step: 420, loss: 0.033899400383234024
step: 430, loss: 0.0516977421939373
step: 440, loss: 0.04471418634057045
step: 450, loss: 0.03295392170548439
step: 460, loss: 0.011718225665390491
step: 470, loss: 0.033574558794498444
step: 480, loss: 0.06870200484991074
step: 490, loss: 0.08105995506048203
step: 500, loss: 0.12528973817825317
step: 510, loss: 0.026576705276966095
step: 520, loss: 0.05259433388710022
step: 530, loss: 0.09504926949739456
step: 540, loss: 0.09057973325252533
step: 550, loss: 0.04600617289543152
step: 560, loss: 0.033066023141145706
step: 570, loss: 0.06413339078426361
step: 580, loss: 0.09211152046918869
step: 590, loss: 0.03661101683974266
step: 600, loss: 0.0670178160071373
step: 610, loss: 0.05515970662236214
step: 620, loss: 0.0008682149345986545
step: 630, loss: 0.047867439687252045
step: 640, loss: 0.05250469967722893
step: 650, loss: 0.10902106016874313
step: 660, loss: 0.03268677368760109
step: 670, loss: 0.05778179690241814
step: 680, loss: 0.06700079143047333
step: 690, loss: 0.06273713707923889
step: 700, loss: 0.000595670600887388
step: 710, loss: 0.0048663076013326645
step: 720, loss: 0.006862534675747156
step: 730, loss: 0.015610329806804657
step: 740, loss: 0.06582220643758774
step: 750, loss: 0.04594030976295471
step: 760, loss: 0.06666703522205353
step: 770, loss: 0.046381935477256775
step: 780, loss: 0.10946362465620041
step: 790, loss: 0.07970436662435532
step: 800, loss: 0.05432035028934479
step: 810, loss: 0.09266789257526398
step: 820, loss: 0.08668098598718643
step: 830, loss: 0.08255124092102051
step: 840, loss: 0.04854116961359978
step: 850, loss: 0.05242280662059784
step: 860, loss: 0.022487308830022812
step: 870, loss: 0.20126786828041077
step: 880, loss: 0.04828168824315071
step: 890, loss: 0.016950607299804688
step: 900, loss: 0.03604588657617569
step: 910, loss: 0.1604226529598236
step: 920, loss: 1.3988294995215256e-05
step: 930, loss: 0.10509075224399567
step: 940, loss: 0.04088801145553589
step: 950, loss: 0.01007108110934496
step: 960, loss: 0.0793602243065834
step: 970, loss: 0.003996374551206827
step: 980, loss: 0.11506687849760056
step: 990, loss: 0.029395926743745804
step: 1000, loss: 0.1657821387052536
step: 1010, loss: 0.007359783630818129
step: 1020, loss: 0.03648208826780319
step: 1030, loss: 0.025846246629953384
step: 1040, loss: 0.02080121822655201
step: 1050, loss: 0.0020823285449296236
step: 1060, loss: 0.09289970993995667
step: 1070, loss: 0.017063623294234276
epoch 16: dev_f1=0.9255121042830541, f1=0.9243619489559165, best_f1=0.9305936073059361
step: 0, loss: 0.00825915765017271
step: 10, loss: 0.04840737581253052
step: 20, loss: 0.06208323314785957
step: 30, loss: 0.019855573773384094
step: 40, loss: 0.02632366307079792
step: 50, loss: 0.04635072126984596
step: 60, loss: 0.021998386830091476
step: 70, loss: 1.6372283425880596e-05
step: 80, loss: 0.014518246054649353
step: 90, loss: 0.01531718485057354
step: 100, loss: 0.021982235834002495
step: 110, loss: 0.010155848227441311
step: 120, loss: 0.10690824687480927
step: 130, loss: 0.06924524158239365
step: 140, loss: 0.02707415632903576
step: 150, loss: 0.04183226451277733
step: 160, loss: 0.02120903506875038
step: 170, loss: 0.05478401854634285
step: 180, loss: 0.041821062564849854
step: 190, loss: 0.0778726115822792
step: 200, loss: 0.02358071133494377
step: 210, loss: 0.059253841638565063
step: 220, loss: 0.11000000685453415
step: 230, loss: 0.018367039039731026
step: 240, loss: 0.0020705389324575663
step: 250, loss: 0.050709426403045654
step: 260, loss: 0.011037874035537243
step: 270, loss: 0.04689779877662659
step: 280, loss: 0.09791803359985352
step: 290, loss: 0.02268887870013714
step: 300, loss: 0.06459153443574905
step: 310, loss: 0.01968960091471672
step: 320, loss: 0.04606440290808678
step: 330, loss: 2.5537719920976087e-05
step: 340, loss: 0.012177245691418648
step: 350, loss: 0.0960659384727478
step: 360, loss: 0.06653279066085815
step: 370, loss: 0.07387223094701767
step: 380, loss: 0.0468892902135849
step: 390, loss: 0.012857233174145222
step: 400, loss: 0.05028657987713814
step: 410, loss: 6.692835449939594e-05
step: 420, loss: 0.022571057081222534
step: 430, loss: 0.024661730974912643
step: 440, loss: 0.020456528291106224
step: 450, loss: 0.020458219572901726
step: 460, loss: 0.015734288841485977
step: 470, loss: 0.04358084872364998
step: 480, loss: 0.14526060223579407
step: 490, loss: 0.10754632204771042
step: 500, loss: 0.0707007348537445
step: 510, loss: 0.04671888053417206
step: 520, loss: 0.0026211393997073174
step: 530, loss: 0.06958307325839996
step: 540, loss: 0.020970260724425316
step: 550, loss: 0.0803300142288208
step: 560, loss: 0.05874892696738243
step: 570, loss: 0.044568806886672974
step: 580, loss: 0.02636217325925827
step: 590, loss: 0.05322067812085152
step: 600, loss: 0.040473248809576035
step: 610, loss: 0.029388824477791786
step: 620, loss: 0.0010603767586871982
step: 630, loss: 0.002747566206380725
step: 640, loss: 0.05600905045866966
step: 650, loss: 0.034595753997564316
step: 660, loss: 0.1004222109913826
step: 670, loss: 0.058812618255615234
step: 680, loss: 0.03603055700659752
step: 690, loss: 0.048349518328905106
step: 700, loss: 0.05241784825921059
step: 710, loss: 0.05874684825539589
step: 720, loss: 0.0007146268035285175
step: 730, loss: 0.10697147995233536
step: 740, loss: 0.04470338672399521
step: 750, loss: 0.06476866453886032
step: 760, loss: 0.03715483471751213
step: 770, loss: 0.023594427853822708
step: 780, loss: 0.04098231717944145
step: 790, loss: 0.04399789124727249
step: 800, loss: 0.04858360067009926
step: 810, loss: 0.06960037350654602
step: 820, loss: 0.04030190035700798
step: 830, loss: 0.1956547349691391
step: 840, loss: 0.0989794209599495
step: 850, loss: 0.10542217642068863
step: 860, loss: 0.001051918021403253
step: 870, loss: 0.0008042691624723375
step: 880, loss: 0.0004942911909893155
step: 890, loss: 0.00047467206604778767
step: 900, loss: 0.05483575165271759
step: 910, loss: 0.014396516606211662
step: 920, loss: 0.08330827206373215
step: 930, loss: 0.03954034298658371
step: 940, loss: 0.10485374182462692
step: 950, loss: 0.07433129847049713
step: 960, loss: 0.01826176606118679
step: 970, loss: 0.04436616599559784
step: 980, loss: 0.046022847294807434
step: 990, loss: 0.023499200120568275
step: 1000, loss: 0.0625678300857544
step: 1010, loss: 0.048807285726070404
step: 1020, loss: 0.12660890817642212
step: 1030, loss: 0.00013257190585136414
step: 1040, loss: 0.02821194753050804
step: 1050, loss: 0.0643758624792099
step: 1060, loss: 0.06811552494764328
step: 1070, loss: 0.046085018664598465
epoch 17: dev_f1=0.930341280972417, f1=0.927170868347339, best_f1=0.9305936073059361
step: 0, loss: 0.05351521447300911
step: 10, loss: 0.05025263503193855
step: 20, loss: 0.05159369483590126
step: 30, loss: 0.08880019187927246
step: 40, loss: 5.969949052087031e-05
step: 50, loss: 0.0609552301466465
step: 60, loss: 0.05302320420742035
step: 70, loss: 0.021037809550762177
step: 80, loss: 0.05888094753026962
step: 90, loss: 0.0586121566593647
step: 100, loss: 0.04533510282635689
step: 110, loss: 0.06088079512119293
step: 120, loss: 0.09691131860017776
step: 130, loss: 0.023541845381259918
step: 140, loss: 0.024037981405854225
step: 150, loss: 0.033579159528017044
step: 160, loss: 0.010190867818892002
step: 170, loss: 0.021373368799686432
step: 180, loss: 0.02487960085272789
step: 190, loss: 0.020047660917043686
step: 200, loss: 0.03213762119412422
step: 210, loss: 0.005870031658560038
step: 220, loss: 0.03553011640906334
step: 230, loss: 0.00045116301043890417
step: 240, loss: 0.006731381174176931
step: 250, loss: 0.057772353291511536
step: 260, loss: 0.07087266445159912
step: 270, loss: 0.07111087441444397
step: 280, loss: 0.05826631560921669
step: 290, loss: 0.04975760355591774
step: 300, loss: 0.0635487511754036
step: 310, loss: 0.08670452982187271
step: 320, loss: 0.1327201873064041
step: 330, loss: 0.047515954822301865
step: 340, loss: 0.035924281924963
step: 350, loss: 0.06614415347576141
step: 360, loss: 0.0893167033791542
step: 370, loss: 0.012012568302452564
step: 380, loss: 0.00019343776511959732
step: 390, loss: 0.0827094241976738
step: 400, loss: 0.031648408621549606
step: 410, loss: 0.023323198780417442
step: 420, loss: 0.028127500787377357
step: 430, loss: 0.14246897399425507
step: 440, loss: 0.017423683777451515
step: 450, loss: 0.020798131823539734
step: 460, loss: 0.04537001997232437
step: 470, loss: 0.1542970836162567
step: 480, loss: 0.0802110880613327
step: 490, loss: 0.06047939136624336
step: 500, loss: 0.05905517563223839
step: 510, loss: 0.03964240476489067
step: 520, loss: 0.008595974184572697
step: 530, loss: 0.027971133589744568
step: 540, loss: 0.03894122317433357
step: 550, loss: 0.021550728008151054
step: 560, loss: 0.0210700873285532
step: 570, loss: 0.03628138452768326
step: 580, loss: 0.022852975875139236
step: 590, loss: 0.05915101245045662
step: 600, loss: 0.06898264586925507
step: 610, loss: 0.027000797912478447
step: 620, loss: 0.18210142850875854
step: 630, loss: 0.016297029331326485
step: 640, loss: 0.07172892987728119
step: 650, loss: 0.059606075286865234
step: 660, loss: 0.06859651952981949
step: 670, loss: 0.08836951851844788
step: 680, loss: 0.025247225537896156
step: 690, loss: 0.04567914456129074
step: 700, loss: 0.0020022355020046234
step: 710, loss: 0.1061926782131195
step: 720, loss: 0.031403347849845886
step: 730, loss: 0.022575635462999344
step: 740, loss: 0.04995043948292732
step: 750, loss: 0.05823560804128647
step: 760, loss: 0.05587737634778023
step: 770, loss: 0.0016982125816866755
step: 780, loss: 0.02222682535648346
step: 790, loss: 0.011605304665863514
step: 800, loss: 0.03158155456185341
step: 810, loss: 0.008287180215120316
step: 820, loss: 0.026091478765010834
step: 830, loss: 0.02810158021748066
step: 840, loss: 0.04889746382832527
step: 850, loss: 0.02731526829302311
step: 860, loss: 0.021782584488391876
step: 870, loss: 0.05471435561776161
step: 880, loss: 0.05378628149628639
step: 890, loss: 0.10839227586984634
step: 900, loss: 0.04002118855714798
step: 910, loss: 0.018901266157627106
step: 920, loss: 0.02366102859377861
step: 930, loss: 0.0002691050467547029
step: 940, loss: 0.055598724633455276
step: 950, loss: 0.020310690626502037
step: 960, loss: 0.021234845742583275
step: 970, loss: 0.04395655170083046
step: 980, loss: 0.05978723242878914
step: 990, loss: 0.044546179473400116
step: 1000, loss: 0.04124440997838974
step: 1010, loss: 0.036815229803323746
step: 1020, loss: 0.07655063271522522
step: 1030, loss: 0.0433625802397728
step: 1040, loss: 0.03875785693526268
step: 1050, loss: 0.04637228325009346
step: 1060, loss: 0.040375418961048126
step: 1070, loss: 0.05391104891896248
epoch 18: dev_f1=0.9264432029795159, f1=0.9257356375525455, best_f1=0.9305936073059361
step: 0, loss: 0.07419352978467941
step: 10, loss: 0.0019314313540235162
step: 20, loss: 0.04184240102767944
step: 30, loss: 0.07028897106647491
step: 40, loss: 0.14739181101322174
step: 50, loss: 0.011399738490581512
step: 60, loss: 0.05563913658261299
step: 70, loss: 0.00016530152061022818
step: 80, loss: 7.581416139146313e-05
step: 90, loss: 0.052300747483968735
step: 100, loss: 0.021505724638700485
step: 110, loss: 0.04635234922170639
step: 120, loss: 0.04316497966647148
step: 130, loss: 0.04699002951383591
step: 140, loss: 0.0007262085564434528
step: 150, loss: 0.04002077132463455
step: 160, loss: 0.0594300702214241
step: 170, loss: 0.053922683000564575
step: 180, loss: 0.04347984120249748
step: 190, loss: 0.017371293157339096
step: 200, loss: 0.02274276316165924
step: 210, loss: 0.000140266478410922
step: 220, loss: 0.04076358675956726
step: 230, loss: 0.029804784804582596
step: 240, loss: 0.051365453749895096
step: 250, loss: 0.07783497124910355
step: 260, loss: 0.08945558220148087
step: 270, loss: 0.03711027652025223
step: 280, loss: 0.03207826614379883
step: 290, loss: 0.09841479361057281
step: 300, loss: 0.03524358570575714
step: 310, loss: 0.013706260360777378
step: 320, loss: 0.028234263882040977
step: 330, loss: 0.03568379953503609
step: 340, loss: 0.01306128315627575
step: 350, loss: 0.048562705516815186
step: 360, loss: 0.08419390022754669
step: 370, loss: 0.10928051173686981
step: 380, loss: 0.05460511893033981
step: 390, loss: 0.0431518517434597
step: 400, loss: 0.06216385215520859
step: 410, loss: 0.07172957062721252
step: 420, loss: 0.022703742608428
step: 430, loss: 0.009905125945806503
step: 440, loss: 0.00041967525612562895
step: 450, loss: 0.04902105778455734
step: 460, loss: 0.17793841660022736
step: 470, loss: 0.0009344856371171772
step: 480, loss: 0.1533336341381073
step: 490, loss: 0.04156256467103958
step: 500, loss: 0.00012896573753096163
step: 510, loss: 0.04988173767924309
step: 520, loss: 0.057095348834991455
step: 530, loss: 0.08055756986141205
step: 540, loss: 0.040259454399347305
step: 550, loss: 0.050209566950798035
step: 560, loss: 0.023416008800268173
step: 570, loss: 0.05268961936235428
step: 580, loss: 0.09897364675998688
step: 590, loss: 0.07944165170192719
step: 600, loss: 0.07153578102588654
step: 610, loss: 0.03983301669359207
step: 620, loss: 0.022369835525751114
step: 630, loss: 0.04838109016418457
step: 640, loss: 0.04137459769845009
step: 650, loss: 0.02055191807448864
step: 660, loss: 0.02514534816145897
step: 670, loss: 0.021918518468737602
step: 680, loss: 0.038307253271341324
step: 690, loss: 0.0680636465549469
step: 700, loss: 0.034364450722932816
step: 710, loss: 0.06772232800722122
step: 720, loss: 0.07279783487319946
step: 730, loss: 1.916566543513909e-05
step: 740, loss: 0.05911606550216675
step: 750, loss: 0.02314480021595955
step: 760, loss: 0.010307754389941692
step: 770, loss: 0.08317013829946518
step: 780, loss: 0.02153424173593521
step: 790, loss: 0.07055596262216568
step: 800, loss: 0.029401032254099846
step: 810, loss: 0.054222121834754944
step: 820, loss: 0.03606639429926872
step: 830, loss: 0.021939730271697044
step: 840, loss: 0.10928625613451004
step: 850, loss: 0.0476842075586319
step: 860, loss: 0.15625692903995514
step: 870, loss: 0.14538082480430603
step: 880, loss: 0.08617167174816132
step: 890, loss: 0.010604945942759514
step: 900, loss: 0.07108572125434875
step: 910, loss: 0.007250497117638588
step: 920, loss: 0.057862889021635056
step: 930, loss: 0.035200878977775574
step: 940, loss: 0.08253133296966553
step: 950, loss: 0.028054416179656982
step: 960, loss: 0.0311447661370039
step: 970, loss: 0.14744354784488678
step: 980, loss: 0.03986528515815735
step: 990, loss: 0.07283304631710052
step: 1000, loss: 0.09455715864896774
step: 1010, loss: 0.038338907063007355
step: 1020, loss: 0.052178412675857544
step: 1030, loss: 0.047437794506549835
step: 1040, loss: 0.0440613254904747
step: 1050, loss: 0.05703379958868027
step: 1060, loss: 0.04744523763656616
step: 1070, loss: 0.0994378924369812
epoch 19: dev_f1=0.9243776420854861, f1=0.9229323308270676, best_f1=0.9305936073059361
step: 0, loss: 0.05370565876364708
step: 10, loss: 1.8283006284036674e-05
step: 20, loss: 0.05645124986767769
step: 30, loss: 0.03762158378958702
step: 40, loss: 0.042588021606206894
step: 50, loss: 0.04574918374419212
step: 60, loss: 0.00010713584924815223
step: 70, loss: 3.083964475081302e-05
step: 80, loss: 0.01994468830525875
step: 90, loss: 0.07141858339309692
step: 100, loss: 0.11180192232131958
step: 110, loss: 0.06258942186832428
step: 120, loss: 0.03905083239078522
step: 130, loss: 0.028331032022833824
step: 140, loss: 0.04451562836766243
step: 150, loss: 0.021304216235876083
step: 160, loss: 0.02729111723601818
step: 170, loss: 0.04537535831332207
step: 180, loss: 0.07532871514558792
step: 190, loss: 0.0363992340862751
step: 200, loss: 0.059129662811756134
step: 210, loss: 0.038269560784101486
step: 220, loss: 0.0560186542570591
step: 230, loss: 0.042514897882938385
step: 240, loss: 0.06310619413852692
step: 250, loss: 0.035561371594667435
step: 260, loss: 0.028709493577480316
step: 270, loss: 0.05120956525206566
step: 280, loss: 0.05982878804206848
step: 290, loss: 0.06373421847820282
step: 300, loss: 0.06972689181566238
step: 310, loss: 0.04923323914408684
step: 320, loss: 0.10845300555229187
step: 330, loss: 0.021223751828074455
step: 340, loss: 0.004812880419194698
step: 350, loss: 0.021210893988609314
step: 360, loss: 0.01744578219950199
step: 370, loss: 0.06173248589038849
step: 380, loss: 0.039202626794576645
step: 390, loss: 0.015536412596702576
step: 400, loss: 0.02656044252216816
step: 410, loss: 0.04489696025848389
step: 420, loss: 0.05995330959558487
step: 430, loss: 0.0006833632360212505
step: 440, loss: 0.06667805463075638
step: 450, loss: 0.0002439458476146683
step: 460, loss: 5.6527376727899536e-05
step: 470, loss: 1.440546111552976e-05
step: 480, loss: 0.03560113534331322
step: 490, loss: 0.00019533783779479563
step: 500, loss: 0.040208619087934494
step: 510, loss: 0.06148568540811539
step: 520, loss: 5.797232734039426e-05
step: 530, loss: 0.0476934053003788
step: 540, loss: 0.015721246600151062
step: 550, loss: 0.018060624599456787
step: 560, loss: 0.06784528493881226
step: 570, loss: 0.017972778528928757
step: 580, loss: 0.07023833692073822
step: 590, loss: 0.03207115828990936
step: 600, loss: 0.00873271282762289
step: 610, loss: 0.038228463381528854
step: 620, loss: 0.032629579305648804
step: 630, loss: 0.03896157816052437
step: 640, loss: 0.0249544195830822
step: 650, loss: 0.06853699684143066
step: 660, loss: 0.027356423437595367
step: 670, loss: 0.03797754645347595
step: 680, loss: 0.029298560693860054
step: 690, loss: 0.0357799306511879
step: 700, loss: 0.028043292462825775
step: 710, loss: 0.00010210513573838398
step: 720, loss: 0.05538603663444519
step: 730, loss: 0.0008107587927952409
step: 740, loss: 0.03257039189338684
step: 750, loss: 0.011343632824718952
step: 760, loss: 0.06338917464017868
step: 770, loss: 0.06804018467664719
step: 780, loss: 0.08018238097429276
step: 790, loss: 0.05207449942827225
step: 800, loss: 0.08181487768888474
step: 810, loss: 0.0593489445745945
step: 820, loss: 0.04738406464457512
step: 830, loss: 0.02046329528093338
step: 840, loss: 0.03293633833527565
step: 850, loss: 0.038185883313417435
step: 860, loss: 0.07698477059602737
step: 870, loss: 0.019689643755555153
step: 880, loss: 0.0001840863551478833
step: 890, loss: 0.1119043156504631
step: 900, loss: 0.042999036610126495
step: 910, loss: 0.06221061572432518
step: 920, loss: 0.026389850303530693
step: 930, loss: 0.02512151002883911
step: 940, loss: 0.03710072487592697
step: 950, loss: 0.05079706013202667
step: 960, loss: 0.0013328221393749118
step: 970, loss: 0.11080622673034668
step: 980, loss: 0.07603003084659576
step: 990, loss: 0.02072882279753685
step: 1000, loss: 0.015606502071022987
step: 1010, loss: 0.036097511649131775
step: 1020, loss: 0.03537824749946594
step: 1030, loss: 0.054074231535196304
step: 1040, loss: 0.08763129264116287
step: 1050, loss: 0.044036805629730225
step: 1060, loss: 0.07621008157730103
step: 1070, loss: 0.030836623162031174
epoch 20: dev_f1=0.9265536723163843, f1=0.924741298212606, best_f1=0.9305936073059361
