cuda
Device: cuda
step: 0, loss: 0.7328150272369385
step: 10, loss: 0.4699658751487732
step: 20, loss: 0.3047204613685608
step: 30, loss: 0.2750973403453827
step: 40, loss: 0.2483438104391098
step: 50, loss: 0.26731884479522705
step: 60, loss: 0.25099489092826843
step: 70, loss: 0.21990515291690826
step: 80, loss: 0.26197201013565063
step: 90, loss: 0.07539401203393936
step: 100, loss: 0.44976550340652466
step: 110, loss: 0.45834988355636597
step: 120, loss: 0.2626626491546631
step: 130, loss: 0.14034584164619446
step: 140, loss: 0.14658844470977783
step: 150, loss: 0.09617102146148682
step: 160, loss: 0.13718250393867493
step: 170, loss: 0.12898045778274536
step: 180, loss: 0.12961271405220032
step: 190, loss: 0.22855155169963837
step: 200, loss: 0.20566031336784363
step: 210, loss: 0.08696653693914413
step: 220, loss: 0.11501771956682205
step: 230, loss: 0.4529663622379303
step: 240, loss: 0.1390548199415207
step: 250, loss: 0.16030029952526093
step: 260, loss: 0.13884851336479187
step: 270, loss: 0.13681530952453613
step: 280, loss: 0.029669493436813354
step: 290, loss: 0.3040822148323059
step: 300, loss: 0.17313829064369202
step: 310, loss: 0.15255601704120636
step: 320, loss: 0.11874666810035706
step: 330, loss: 0.22690489888191223
step: 340, loss: 0.2031582146883011
step: 350, loss: 0.06959977746009827
step: 360, loss: 0.24614936113357544
step: 370, loss: 0.10687564313411713
step: 380, loss: 0.181788370013237
step: 390, loss: 0.18963496387004852
step: 400, loss: 0.123946912586689
step: 410, loss: 0.17276085913181305
step: 420, loss: 0.18323668837547302
step: 430, loss: 0.08144110441207886
step: 440, loss: 0.17585530877113342
step: 450, loss: 0.26466187834739685
step: 460, loss: 0.03852646052837372
step: 470, loss: 0.25314223766326904
step: 480, loss: 0.06715336441993713
step: 490, loss: 0.08679992705583572
step: 500, loss: 0.12392908334732056
step: 510, loss: 0.0779409408569336
step: 520, loss: 0.0307619571685791
step: 530, loss: 0.08015910536050797
step: 540, loss: 0.14973555505275726
step: 550, loss: 0.23185434937477112
step: 560, loss: 0.131818950176239
step: 570, loss: 0.1960708498954773
step: 580, loss: 0.1507115364074707
step: 590, loss: 0.21324917674064636
step: 600, loss: 0.17142337560653687
step: 610, loss: 0.22165346145629883
step: 620, loss: 0.19987376034259796
step: 630, loss: 0.21702249348163605
step: 640, loss: 0.11955329775810242
step: 650, loss: 0.1784290224313736
step: 660, loss: 0.09223131835460663
step: 670, loss: 0.20451347529888153
step: 680, loss: 0.2786170244216919
step: 690, loss: 0.03810959309339523
step: 700, loss: 0.2161594182252884
step: 710, loss: 0.15579856932163239
step: 720, loss: 0.05484932288527489
step: 730, loss: 0.17172859609127045
step: 740, loss: 0.037712596356868744
step: 750, loss: 0.09605082124471664
step: 760, loss: 0.08730675280094147
step: 770, loss: 0.0902886614203453
step: 780, loss: 0.12917165458202362
step: 790, loss: 0.10529136657714844
step: 800, loss: 0.12222246825695038
step: 810, loss: 0.10493918508291245
step: 820, loss: 0.08981000632047653
step: 830, loss: 0.21998612582683563
step: 840, loss: 0.10226526856422424
step: 850, loss: 0.14954528212547302
step: 860, loss: 0.27970072627067566
step: 870, loss: 0.022624172270298004
step: 880, loss: 0.024633320048451424
step: 890, loss: 0.16993361711502075
step: 900, loss: 0.10822056978940964
step: 910, loss: 0.10109643638134003
step: 920, loss: 0.10854137688875198
step: 930, loss: 0.3342975378036499
step: 940, loss: 0.15557125210762024
step: 950, loss: 0.1602644920349121
step: 960, loss: 0.15031395852565765
step: 970, loss: 0.12245114892721176
step: 980, loss: 0.05532481148838997
step: 990, loss: 0.1852802336215973
step: 1000, loss: 0.17804890871047974
step: 1010, loss: 0.12866100668907166
step: 1020, loss: 0.15490421652793884
step: 1030, loss: 0.13333642482757568
step: 1040, loss: 0.1569785475730896
step: 1050, loss: 0.2067115157842636
step: 1060, loss: 0.06427108496427536
step: 1070, loss: 0.12352097034454346
epoch 1: dev_f1=0.925756186984418, f1=0.920418371987267, best_f1=0.920418371987267
step: 0, loss: 0.11117755621671677
step: 10, loss: 0.18043695390224457
step: 20, loss: 0.2236720472574234
step: 30, loss: 0.08489274978637695
step: 40, loss: 0.19018438458442688
step: 50, loss: 0.17657805979251862
step: 60, loss: 0.08093387633562088
step: 70, loss: 0.0432208888232708
step: 80, loss: 0.40258145332336426
step: 90, loss: 0.06107427924871445
step: 100, loss: 0.14855322241783142
step: 110, loss: 0.10614660382270813
step: 120, loss: 0.1471070796251297
step: 130, loss: 0.09418123215436935
step: 140, loss: 0.20858432352542877
step: 150, loss: 0.14241015911102295
step: 160, loss: 0.09349993616342545
step: 170, loss: 0.10331758111715317
step: 180, loss: 0.13469761610031128
step: 190, loss: 0.1269352287054062
step: 200, loss: 0.3300682008266449
step: 210, loss: 0.12315978854894638
step: 220, loss: 0.1786995679140091
step: 230, loss: 0.2674565315246582
step: 240, loss: 0.27192336320877075
step: 250, loss: 0.14568351209163666
step: 260, loss: 0.1447843462228775
step: 270, loss: 0.12738452851772308
step: 280, loss: 0.15746504068374634
step: 290, loss: 0.13318227231502533
step: 300, loss: 0.12445461750030518
step: 310, loss: 0.10337918996810913
step: 320, loss: 0.09424961358308792
step: 330, loss: 0.13377107679843903
step: 340, loss: 0.12176235020160675
step: 350, loss: 0.045684076845645905
step: 360, loss: 0.18691758811473846
step: 370, loss: 0.23603947460651398
step: 380, loss: 0.15133705735206604
step: 390, loss: 0.12367956340312958
step: 400, loss: 0.11497177183628082
step: 410, loss: 0.22857937216758728
step: 420, loss: 0.0807691439986229
step: 430, loss: 0.12879979610443115
step: 440, loss: 0.1964326947927475
step: 450, loss: 0.027444133535027504
step: 460, loss: 0.08980061113834381
step: 470, loss: 0.04635091498494148
step: 480, loss: 0.23179544508457184
step: 490, loss: 0.06717550754547119
step: 500, loss: 0.10409021377563477
step: 510, loss: 0.10908476263284683
step: 520, loss: 0.09998808801174164
step: 530, loss: 0.09975340217351913
step: 540, loss: 0.091284841299057
step: 550, loss: 0.23645122349262238
step: 560, loss: 0.18108823895454407
step: 570, loss: 0.18106967210769653
step: 580, loss: 0.2899746596813202
step: 590, loss: 0.19307631254196167
step: 600, loss: 0.1163194477558136
step: 610, loss: 0.15389640629291534
step: 620, loss: 0.1434231400489807
step: 630, loss: 0.06812078505754471
step: 640, loss: 0.0983501598238945
step: 650, loss: 0.13994772732257843
step: 660, loss: 0.08069522678852081
step: 670, loss: 0.16892336308956146
step: 680, loss: 0.09979648143053055
step: 690, loss: 0.06989472359418869
step: 700, loss: 0.16792437434196472
step: 710, loss: 0.16701310873031616
step: 720, loss: 0.10960348695516586
step: 730, loss: 0.05359489098191261
step: 740, loss: 0.08795682340860367
step: 750, loss: 0.06866936385631561
step: 760, loss: 0.10485454648733139
step: 770, loss: 0.18175099790096283
step: 780, loss: 0.08373070508241653
step: 790, loss: 0.1299496740102768
step: 800, loss: 0.19924673438072205
step: 810, loss: 0.016460508108139038
step: 820, loss: 0.12370654940605164
step: 830, loss: 0.196964293718338
step: 840, loss: 0.25672683119773865
step: 850, loss: 0.15839803218841553
step: 860, loss: 0.09989546984434128
step: 870, loss: 0.11969610303640366
step: 880, loss: 0.08096310496330261
step: 890, loss: 0.10798859596252441
step: 900, loss: 0.09284262359142303
step: 910, loss: 0.08165625482797623
step: 920, loss: 0.02125021442770958
step: 930, loss: 0.04253516346216202
step: 940, loss: 0.13595342636108398
step: 950, loss: 0.1215713769197464
step: 960, loss: 0.09414555132389069
step: 970, loss: 0.06312078982591629
step: 980, loss: 0.18517868220806122
step: 990, loss: 0.127782940864563
step: 1000, loss: 0.14134949445724487
step: 1010, loss: 0.11750076711177826
step: 1020, loss: 0.08836768567562103
step: 1030, loss: 0.07674279808998108
step: 1040, loss: 0.16388456523418427
step: 1050, loss: 0.10422604531049728
step: 1060, loss: 0.0478564091026783
step: 1070, loss: 0.08773043751716614
epoch 2: dev_f1=0.9332087809434843, f1=0.9263746505125815, best_f1=0.9263746505125815
step: 0, loss: 0.04920166730880737
step: 10, loss: 0.1449391394853592
step: 20, loss: 0.09472864866256714
step: 30, loss: 0.184365913271904
step: 40, loss: 0.14049214124679565
step: 50, loss: 0.06795213371515274
step: 60, loss: 0.050508446991443634
step: 70, loss: 0.1510498821735382
step: 80, loss: 0.11382680386304855
step: 90, loss: 0.12925446033477783
step: 100, loss: 0.18757662177085876
step: 110, loss: 0.10232289135456085
step: 120, loss: 0.1150563657283783
step: 130, loss: 0.09837072342634201
step: 140, loss: 0.08770609647035599
step: 150, loss: 0.16767142713069916
step: 160, loss: 0.05085042119026184
step: 170, loss: 0.1788024753332138
step: 180, loss: 0.13668635487556458
step: 190, loss: 0.10783910751342773
step: 200, loss: 0.15063464641571045
step: 210, loss: 0.016026180237531662
step: 220, loss: 0.09703999012708664
step: 230, loss: 0.1439765840768814
step: 240, loss: 0.17730362713336945
step: 250, loss: 0.1316414773464203
step: 260, loss: 0.12718234956264496
step: 270, loss: 0.09826606512069702
step: 280, loss: 0.06222425401210785
step: 290, loss: 0.10240467637777328
step: 300, loss: 0.07158253341913223
step: 310, loss: 0.1175304651260376
step: 320, loss: 0.19110417366027832
step: 330, loss: 0.13127779960632324
step: 340, loss: 0.09281992167234421
step: 350, loss: 0.2800324857234955
step: 360, loss: 0.17825421690940857
step: 370, loss: 0.09422480314970016
step: 380, loss: 0.06960927695035934
step: 390, loss: 0.06875628978013992
step: 400, loss: 0.0587928406894207
step: 410, loss: 0.03481690213084221
step: 420, loss: 0.13867785036563873
step: 430, loss: 0.09730373322963715
step: 440, loss: 0.07696453481912613
step: 450, loss: 0.11671936511993408
step: 460, loss: 0.05833640322089195
step: 470, loss: 0.14183790981769562
step: 480, loss: 0.02445884980261326
step: 490, loss: 0.153887540102005
step: 500, loss: 0.06718198210000992
step: 510, loss: 0.023307837545871735
step: 520, loss: 0.17141805589199066
step: 530, loss: 0.0921998918056488
step: 540, loss: 0.04284965991973877
step: 550, loss: 0.25396716594696045
step: 560, loss: 0.0747159793972969
step: 570, loss: 0.16022121906280518
step: 580, loss: 0.0061242906376719475
step: 590, loss: 0.1699337214231491
step: 600, loss: 0.03529532626271248
step: 610, loss: 0.07926642894744873
step: 620, loss: 0.1821824461221695
step: 630, loss: 0.10072778910398483
step: 640, loss: 0.1784382313489914
step: 650, loss: 0.14091968536376953
step: 660, loss: 0.10361160337924957
step: 670, loss: 0.05195556953549385
step: 680, loss: 0.20428264141082764
step: 690, loss: 0.1382818967103958
step: 700, loss: 0.06449567526578903
step: 710, loss: 0.14053629338741302
step: 720, loss: 0.16045650839805603
step: 730, loss: 0.1279650181531906
step: 740, loss: 0.06890017539262772
step: 750, loss: 0.14695504307746887
step: 760, loss: 0.13552680611610413
step: 770, loss: 0.2489171326160431
step: 780, loss: 0.14404019713401794
step: 790, loss: 0.09015216678380966
step: 800, loss: 0.11609048396348953
step: 810, loss: 0.14772428572177887
step: 820, loss: 0.016922904178500175
step: 830, loss: 0.09365276247262955
step: 840, loss: 0.12215770035982132
step: 850, loss: 0.07986270636320114
step: 860, loss: 0.08853068947792053
step: 870, loss: 0.14232668280601501
step: 880, loss: 0.18155984580516815
step: 890, loss: 0.15062612295150757
step: 900, loss: 0.08835943043231964
step: 910, loss: 0.12527942657470703
step: 920, loss: 0.13163109123706818
step: 930, loss: 0.11243490129709244
step: 940, loss: 0.13640113174915314
step: 950, loss: 0.08777666091918945
step: 960, loss: 0.0985572412610054
step: 970, loss: 0.0600145198404789
step: 980, loss: 0.09437477588653564
step: 990, loss: 0.08177534490823746
step: 1000, loss: 0.11014898121356964
step: 1010, loss: 0.20634983479976654
step: 1020, loss: 0.13588617742061615
step: 1030, loss: 0.06774339824914932
step: 1040, loss: 0.24184830486774445
step: 1050, loss: 0.5515381097793579
step: 1060, loss: 0.125284343957901
step: 1070, loss: 0.11520631611347198
epoch 3: dev_f1=0.9325323475046211, f1=0.9209431345353675, best_f1=0.9263746505125815
step: 0, loss: 0.05890185385942459
step: 10, loss: 0.2673383355140686
step: 20, loss: 0.1934337615966797
step: 30, loss: 0.23463940620422363
step: 40, loss: 0.041743483394384384
step: 50, loss: 0.06564189493656158
step: 60, loss: 0.233017235994339
step: 70, loss: 0.14810460805892944
step: 80, loss: 0.17711560428142548
step: 90, loss: 0.2814337909221649
step: 100, loss: 0.05665554478764534
step: 110, loss: 0.07820888608694077
step: 120, loss: 0.04288279265165329
step: 130, loss: 0.029923079535365105
step: 140, loss: 0.08102574944496155
step: 150, loss: 0.07232920825481415
step: 160, loss: 0.1084584966301918
step: 170, loss: 0.032926660031080246
step: 180, loss: 0.06782769411802292
step: 190, loss: 0.18522204458713531
step: 200, loss: 0.10033270716667175
step: 210, loss: 0.1133887842297554
step: 220, loss: 0.09695257246494293
step: 230, loss: 0.06490689516067505
step: 240, loss: 0.07808484137058258
step: 250, loss: 0.06356512755155563
step: 260, loss: 0.163364976644516
step: 270, loss: 0.17576295137405396
step: 280, loss: 0.14791537821292877
step: 290, loss: 0.12026318907737732
step: 300, loss: 0.09060061722993851
step: 310, loss: 0.3326283097267151
step: 320, loss: 0.20591281354427338
step: 330, loss: 0.15380552411079407
step: 340, loss: 0.1353924423456192
step: 350, loss: 0.10167671740055084
step: 360, loss: 0.1561695635318756
step: 370, loss: 0.06573834270238876
step: 380, loss: 0.08359013497829437
step: 390, loss: 0.12079627811908722
step: 400, loss: 0.1843450367450714
step: 410, loss: 0.0717974305152893
step: 420, loss: 0.11662815511226654
step: 430, loss: 0.038094352930784225
step: 440, loss: 0.05510745197534561
step: 450, loss: 0.07057921588420868
step: 460, loss: 0.11166365444660187
step: 470, loss: 0.08666883409023285
step: 480, loss: 0.06785747408866882
step: 490, loss: 0.08631814271211624
step: 500, loss: 0.02649809420108795
step: 510, loss: 0.026073060929775238
step: 520, loss: 0.03576396033167839
step: 530, loss: 0.09001582860946655
step: 540, loss: 0.05113484710454941
step: 550, loss: 0.05554065480828285
step: 560, loss: 0.0575789175927639
step: 570, loss: 0.07134896516799927
step: 580, loss: 0.2205231934785843
step: 590, loss: 0.03060576505959034
step: 600, loss: 0.09219259768724442
step: 610, loss: 0.08002926409244537
step: 620, loss: 0.06319360435009003
step: 630, loss: 0.10449251532554626
step: 640, loss: 0.1454160511493683
step: 650, loss: 0.20791399478912354
step: 660, loss: 0.08896977454423904
step: 670, loss: 0.017399465665221214
step: 680, loss: 0.08127797394990921
step: 690, loss: 0.049113109707832336
step: 700, loss: 0.07217725366353989
step: 710, loss: 0.05105561390519142
step: 720, loss: 0.04879621043801308
step: 730, loss: 0.06419220566749573
step: 740, loss: 0.11693564802408218
step: 750, loss: 0.1280873715877533
step: 760, loss: 0.07498210668563843
step: 770, loss: 0.24893689155578613
step: 780, loss: 0.04514487460255623
step: 790, loss: 0.03683068975806236
step: 800, loss: 0.1378919631242752
step: 810, loss: 0.13950376212596893
step: 820, loss: 0.08169525116682053
step: 830, loss: 0.02944258227944374
step: 840, loss: 0.12389736622571945
step: 850, loss: 0.1719689816236496
step: 860, loss: 0.038151439279317856
step: 870, loss: 0.1534189134836197
step: 880, loss: 0.15697842836380005
step: 890, loss: 0.062113936990499496
step: 900, loss: 0.2819305658340454
step: 910, loss: 0.0992661714553833
step: 920, loss: 0.10533332824707031
step: 930, loss: 0.08189880102872849
step: 940, loss: 0.09331077337265015
step: 950, loss: 0.07908079028129578
step: 960, loss: 0.1230873316526413
step: 970, loss: 0.09299535304307938
step: 980, loss: 0.07652521133422852
step: 990, loss: 0.2396475076675415
step: 1000, loss: 0.15938158333301544
step: 1010, loss: 0.06974915415048599
step: 1020, loss: 0.07887471467256546
step: 1030, loss: 0.19943496584892273
step: 1040, loss: 0.03263897821307182
step: 1050, loss: 0.08294578641653061
step: 1060, loss: 0.08195017278194427
step: 1070, loss: 0.1818217784166336
epoch 4: dev_f1=0.93790546802595, f1=0.9282075034738305, best_f1=0.9282075034738305
step: 0, loss: 0.12598977982997894
step: 10, loss: 0.029683521017432213
step: 20, loss: 0.06868448853492737
step: 30, loss: 0.03464196249842644
step: 40, loss: 0.09434714913368225
step: 50, loss: 0.09240937232971191
step: 60, loss: 0.10243257135152817
step: 70, loss: 0.11474790424108505
step: 80, loss: 0.031994521617889404
step: 90, loss: 0.05206254869699478
step: 100, loss: 0.13224689662456512
step: 110, loss: 0.121400848031044
step: 120, loss: 0.06811065971851349
step: 130, loss: 0.03996647894382477
step: 140, loss: 0.1325041800737381
step: 150, loss: 0.06661202013492584
step: 160, loss: 0.09135139733552933
step: 170, loss: 0.06673187762498856
step: 180, loss: 0.1064787432551384
step: 190, loss: 0.06123042851686478
step: 200, loss: 0.08448408544063568
step: 210, loss: 0.2123548686504364
step: 220, loss: 0.06945101916790009
step: 230, loss: 0.04866303503513336
step: 240, loss: 0.14335370063781738
step: 250, loss: 0.09599140286445618
step: 260, loss: 0.048382338136434555
step: 270, loss: 0.12453082203865051
step: 280, loss: 0.09090025722980499
step: 290, loss: 0.08920150995254517
step: 300, loss: 0.07401768863201141
step: 310, loss: 0.018923887982964516
step: 320, loss: 0.11635863780975342
step: 330, loss: 0.07868532836437225
step: 340, loss: 0.06045496091246605
step: 350, loss: 0.09803101420402527
step: 360, loss: 0.04189302772283554
step: 370, loss: 0.16425548493862152
step: 380, loss: 0.14467178285121918
step: 390, loss: 0.13948291540145874
step: 400, loss: 0.04686591774225235
step: 410, loss: 0.11013859510421753
step: 420, loss: 0.13870352506637573
step: 430, loss: 0.1450902372598648
step: 440, loss: 0.04572301357984543
step: 450, loss: 0.05472026765346527
step: 460, loss: 0.15769436955451965
step: 470, loss: 0.07885567843914032
step: 480, loss: 0.03976636379957199
step: 490, loss: 0.08254563808441162
step: 500, loss: 0.14440779387950897
step: 510, loss: 0.024210097268223763
step: 520, loss: 0.03549318015575409
step: 530, loss: 0.09879481047391891
step: 540, loss: 0.11784140020608902
step: 550, loss: 0.07205428183078766
step: 560, loss: 0.3335844576358795
step: 570, loss: 0.09588203579187393
step: 580, loss: 0.22891944646835327
step: 590, loss: 0.020853564143180847
step: 600, loss: 0.12937070429325104
step: 610, loss: 0.1456499695777893
step: 620, loss: 0.08504325896501541
step: 630, loss: 0.056333787739276886
step: 640, loss: 0.04242565110325813
step: 650, loss: 0.020769748836755753
step: 660, loss: 0.10595707595348358
step: 670, loss: 0.0297175794839859
step: 680, loss: 0.06367315351963043
step: 690, loss: 0.010966069996356964
step: 700, loss: 0.1178463026881218
step: 710, loss: 0.07233747094869614
step: 720, loss: 0.06090768799185753
step: 730, loss: 0.140294149518013
step: 740, loss: 0.16010259091854095
step: 750, loss: 0.08715661615133286
step: 760, loss: 0.1424030065536499
step: 770, loss: 0.13502050936222076
step: 780, loss: 0.14442536234855652
step: 790, loss: 0.033252738416194916
step: 800, loss: 0.040570445358753204
step: 810, loss: 0.16829422116279602
step: 820, loss: 0.06627154350280762
step: 830, loss: 0.16573306918144226
step: 840, loss: 0.06370685249567032
step: 850, loss: 0.08442573249340057
step: 860, loss: 0.06621933728456497
step: 870, loss: 0.17388539016246796
step: 880, loss: 0.06466884911060333
step: 890, loss: 0.09376495331525803
step: 900, loss: 0.05273297801613808
step: 910, loss: 0.07237768918275833
step: 920, loss: 0.046419043093919754
step: 930, loss: 0.1094932034611702
step: 940, loss: 0.15800319612026215
step: 950, loss: 0.1113562360405922
step: 960, loss: 0.11880050599575043
step: 970, loss: 0.0661875531077385
step: 980, loss: 0.057159360498189926
step: 990, loss: 0.027478402480483055
step: 1000, loss: 0.10860282927751541
step: 1010, loss: 0.25515034794807434
step: 1020, loss: 0.0012654330348595977
step: 1030, loss: 0.08757726103067398
step: 1040, loss: 0.3385789692401886
step: 1050, loss: 0.041277579963207245
step: 1060, loss: 0.10230191051959991
step: 1070, loss: 0.16334162652492523
epoch 5: dev_f1=0.9325210871602625, f1=0.9281352747768906, best_f1=0.9282075034738305
step: 0, loss: 0.11609029769897461
step: 10, loss: 0.1102464571595192
step: 20, loss: 0.17074447870254517
step: 30, loss: 0.03157935291528702
step: 40, loss: 0.1114543154835701
step: 50, loss: 0.04898693040013313
step: 60, loss: 0.09281840920448303
step: 70, loss: 0.03469660505652428
step: 80, loss: 0.0883588194847107
step: 90, loss: 0.10753621906042099
step: 100, loss: 0.06519833952188492
step: 110, loss: 0.09711754322052002
step: 120, loss: 0.03814612329006195
step: 130, loss: 0.12019357085227966
step: 140, loss: 0.029165251180529594
step: 150, loss: 0.10817699879407883
step: 160, loss: 0.09219737350940704
step: 170, loss: 0.13354960083961487
step: 180, loss: 0.08623756468296051
step: 190, loss: 0.21044805645942688
step: 200, loss: 0.03522830829024315
step: 210, loss: 0.08833611011505127
step: 220, loss: 0.0497121699154377
step: 230, loss: 0.037965577095746994
step: 240, loss: 0.2092411369085312
step: 250, loss: 0.13914799690246582
step: 260, loss: 0.09039919823408127
step: 270, loss: 0.1672690510749817
step: 280, loss: 0.15786831080913544
step: 290, loss: 0.03762173280119896
step: 300, loss: 0.15669815242290497
step: 310, loss: 0.18288151919841766
step: 320, loss: 0.0979483351111412
step: 330, loss: 0.09686581045389175
step: 340, loss: 0.19094955921173096
step: 350, loss: 0.13028907775878906
step: 360, loss: 0.04045107960700989
step: 370, loss: 0.11335290223360062
step: 380, loss: 0.10397505015134811
step: 390, loss: 0.08356495946645737
step: 400, loss: 0.08676525950431824
step: 410, loss: 0.03488025814294815
step: 420, loss: 0.10373514890670776
step: 430, loss: 0.07139688730239868
step: 440, loss: 0.26300355792045593
step: 450, loss: 0.09808677434921265
step: 460, loss: 0.054108429700136185
step: 470, loss: 0.04839238151907921
step: 480, loss: 0.09252538532018661
step: 490, loss: 0.07097025215625763
step: 500, loss: 0.09276529401540756
step: 510, loss: 0.01219116896390915
step: 520, loss: 0.16417931020259857
step: 530, loss: 0.11736297607421875
step: 540, loss: 0.06315027177333832
step: 550, loss: 0.0621795617043972
step: 560, loss: 0.07234794646501541
step: 570, loss: 0.043127790093421936
step: 580, loss: 0.10450839251279831
step: 590, loss: 0.11400702595710754
step: 600, loss: 0.07618436217308044
step: 610, loss: 0.039007075130939484
step: 620, loss: 0.08299767225980759
step: 630, loss: 0.05343926325440407
step: 640, loss: 0.1025242954492569
step: 650, loss: 0.10416330397129059
step: 660, loss: 0.041816409677267075
step: 670, loss: 0.04486341029405594
step: 680, loss: 0.038930494338274
step: 690, loss: 0.03205084055662155
step: 700, loss: 0.13732367753982544
step: 710, loss: 0.08930013328790665
step: 720, loss: 0.1069190502166748
step: 730, loss: 0.20715543627738953
step: 740, loss: 0.055757228285074234
step: 750, loss: 0.22528377175331116
step: 760, loss: 0.10486778616905212
step: 770, loss: 0.08718948811292648
step: 780, loss: 0.04939042031764984
step: 790, loss: 0.06273743510246277
step: 800, loss: 0.06415470689535141
step: 810, loss: 0.04856353998184204
step: 820, loss: 0.035375870764255524
step: 830, loss: 0.16422626376152039
step: 840, loss: 0.016149431467056274
step: 850, loss: 0.2196468561887741
step: 860, loss: 0.016260500997304916
step: 870, loss: 0.1725727617740631
step: 880, loss: 0.06031004711985588
step: 890, loss: 0.10627732425928116
step: 900, loss: 0.05698389559984207
step: 910, loss: 0.02535107545554638
step: 920, loss: 0.0002595791593194008
step: 930, loss: 0.056654684245586395
step: 940, loss: 0.04811873286962509
step: 950, loss: 0.05152985826134682
step: 960, loss: 0.10335719585418701
step: 970, loss: 0.11040076613426208
step: 980, loss: 0.1342771053314209
step: 990, loss: 0.03706821799278259
step: 1000, loss: 0.08333108574151993
step: 1010, loss: 0.06490594893693924
step: 1020, loss: 0.09062579274177551
step: 1030, loss: 0.07077191025018692
step: 1040, loss: 0.02778901904821396
step: 1050, loss: 0.06940541416406631
step: 1060, loss: 0.035845376551151276
step: 1070, loss: 0.059370800852775574
epoch 6: dev_f1=0.9366391184573002, f1=0.9246323529411765, best_f1=0.9282075034738305
step: 0, loss: 0.08607322722673416
step: 10, loss: 0.08469434827566147
step: 20, loss: 0.022419298067688942
step: 30, loss: 0.055085405707359314
step: 40, loss: 0.07570575922727585
step: 50, loss: 0.11935526132583618
step: 60, loss: 0.10332408547401428
step: 70, loss: 0.0711909830570221
step: 80, loss: 0.012205385603010654
step: 90, loss: 0.0692400336265564
step: 100, loss: 0.1466381847858429
step: 110, loss: 0.08069419860839844
step: 120, loss: 0.14192821085453033
step: 130, loss: 0.0571502149105072
step: 140, loss: 0.022125763818621635
step: 150, loss: 0.3478861153125763
step: 160, loss: 0.12495189160108566
step: 170, loss: 0.026707269251346588
step: 180, loss: 0.1473826766014099
step: 190, loss: 0.0974029153585434
step: 200, loss: 0.021891843527555466
step: 210, loss: 0.031106000766158104
step: 220, loss: 0.13725411891937256
step: 230, loss: 0.1560240089893341
step: 240, loss: 0.023146051913499832
step: 250, loss: 0.09309322386980057
step: 260, loss: 0.08929765969514847
step: 270, loss: 0.07156694680452347
step: 280, loss: 0.06657862663269043
step: 290, loss: 0.09415046125650406
step: 300, loss: 0.06351818889379501
step: 310, loss: 0.09923642873764038
step: 320, loss: 0.06165851652622223
step: 330, loss: 0.05266481637954712
step: 340, loss: 0.11885294318199158
step: 350, loss: 0.16559477150440216
step: 360, loss: 0.013823164626955986
step: 370, loss: 0.03348351642489433
step: 380, loss: 0.1071816235780716
step: 390, loss: 0.0849464014172554
step: 400, loss: 0.07672693580389023
step: 410, loss: 0.11245671659708023
step: 420, loss: 0.09532734006643295
step: 430, loss: 0.014555322006344795
step: 440, loss: 0.0971195250749588
step: 450, loss: 0.09958325326442719
step: 460, loss: 0.08953158557415009
step: 470, loss: 0.07853447645902634
step: 480, loss: 0.07308418303728104
step: 490, loss: 0.18487535417079926
step: 500, loss: 0.14302705228328705
step: 510, loss: 0.1921006590127945
step: 520, loss: 0.09850755333900452
step: 530, loss: 0.11918389052152634
step: 540, loss: 0.03158501163125038
step: 550, loss: 0.12899039685726166
step: 560, loss: 0.10287674516439438
step: 570, loss: 0.08904901146888733
step: 580, loss: 0.08445150405168533
step: 590, loss: 0.12331478297710419
step: 600, loss: 0.12457871437072754
step: 610, loss: 0.06507575511932373
step: 620, loss: 0.08162079006433487
step: 630, loss: 0.06019936129450798
step: 640, loss: 0.07670268416404724
step: 650, loss: 0.07874666899442673
step: 660, loss: 0.07385370880365372
step: 670, loss: 0.04591670632362366
step: 680, loss: 0.19778433442115784
step: 690, loss: 0.1445140391588211
step: 700, loss: 0.03342439606785774
step: 710, loss: 0.020752739161252975
step: 720, loss: 0.09260930120944977
step: 730, loss: 0.06669587641954422
step: 740, loss: 0.04209326580166817
step: 750, loss: 0.07389754056930542
step: 760, loss: 0.07267170399427414
step: 770, loss: 0.03341520577669144
step: 780, loss: 0.07646039873361588
step: 790, loss: 0.0038549196906387806
step: 800, loss: 0.13706009089946747
step: 810, loss: 0.1036699190735817
step: 820, loss: 0.027590136975049973
step: 830, loss: 0.09919794648885727
step: 840, loss: 0.06584741920232773
step: 850, loss: 0.08888421207666397
step: 860, loss: 0.10673165321350098
step: 870, loss: 0.15584899485111237
step: 880, loss: 0.034468237310647964
step: 890, loss: 0.15028996765613556
step: 900, loss: 0.14736412465572357
step: 910, loss: 0.030069366097450256
step: 920, loss: 0.16931195557117462
step: 930, loss: 0.010595602914690971
step: 940, loss: 0.1905936449766159
step: 950, loss: 0.08570589125156403
step: 960, loss: 0.06490262597799301
step: 970, loss: 0.09245695173740387
step: 980, loss: 0.08614378422498703
step: 990, loss: 0.10395529866218567
step: 1000, loss: 0.022068357095122337
step: 1010, loss: 0.15736126899719238
step: 1020, loss: 0.03665672987699509
step: 1030, loss: 0.05122841149568558
step: 1040, loss: 0.06854188442230225
step: 1050, loss: 0.07248162478208542
step: 1060, loss: 0.047179918736219406
step: 1070, loss: 0.1364927887916565
epoch 7: dev_f1=0.935813953488372, f1=0.9284386617100371, best_f1=0.9282075034738305
step: 0, loss: 0.1195053979754448
step: 10, loss: 0.13544712960720062
step: 20, loss: 0.12559324502944946
step: 30, loss: 0.10313153266906738
step: 40, loss: 0.04273489490151405
step: 50, loss: 0.10827875882387161
step: 60, loss: 0.07800024747848511
step: 70, loss: 0.09382165223360062
step: 80, loss: 0.030513904988765717
step: 90, loss: 0.08280331641435623
step: 100, loss: 0.042502786964178085
step: 110, loss: 0.12597978115081787
step: 120, loss: 0.08404578268527985
step: 130, loss: 0.06784432381391525
step: 140, loss: 0.006780191324651241
step: 150, loss: 0.1662100851535797
step: 160, loss: 0.10357268899679184
step: 170, loss: 0.11689628660678864
step: 180, loss: 0.020305486395955086
step: 190, loss: 0.05493837222456932
step: 200, loss: 0.11069054156541824
step: 210, loss: 0.14585751295089722
step: 220, loss: 0.06174417585134506
step: 230, loss: 0.021787911653518677
step: 240, loss: 0.01928585208952427
step: 250, loss: 0.01610921137034893
step: 260, loss: 0.09089848399162292
step: 270, loss: 0.1193486824631691
step: 280, loss: 0.10021974891424179
step: 290, loss: 0.126287043094635
step: 300, loss: 0.049746979027986526
step: 310, loss: 0.07909637689590454
step: 320, loss: 0.07119481265544891
step: 330, loss: 0.1300598531961441
step: 340, loss: 0.13631151616573334
step: 350, loss: 0.03478848189115524
step: 360, loss: 0.12260237336158752
step: 370, loss: 0.11211661249399185
step: 380, loss: 0.024498824030160904
step: 390, loss: 0.11255863308906555
step: 400, loss: 0.07961544394493103
step: 410, loss: 0.02497095614671707
step: 420, loss: 0.13656330108642578
step: 430, loss: 0.013074474409222603
step: 440, loss: 0.05217786133289337
step: 450, loss: 0.06637302041053772
step: 460, loss: 0.09302055835723877
step: 470, loss: 0.013973609544336796
step: 480, loss: 0.07489945739507675
step: 490, loss: 0.026042258366942406
step: 500, loss: 0.11849033832550049
step: 510, loss: 0.11422059684991837
step: 520, loss: 0.02672281675040722
step: 530, loss: 0.17873574793338776
step: 540, loss: 0.01320623978972435
step: 550, loss: 0.07072333246469498
step: 560, loss: 0.21100927889347076
step: 570, loss: 0.0612359493970871
step: 580, loss: 0.10688123852014542
step: 590, loss: 0.1492047756910324
step: 600, loss: 0.04468882083892822
step: 610, loss: 0.11102648079395294
step: 620, loss: 0.09765242785215378
step: 630, loss: 0.08147869259119034
step: 640, loss: 0.15394462645053864
step: 650, loss: 0.19577132165431976
step: 660, loss: 0.037268951535224915
step: 670, loss: 0.07306240499019623
step: 680, loss: 0.10218849033117294
step: 690, loss: 0.0974191427230835
step: 700, loss: 0.06743396818637848
step: 710, loss: 0.12080421298742294
step: 720, loss: 0.05694073066115379
step: 730, loss: 0.12047252058982849
step: 740, loss: 0.11945740878582001
step: 750, loss: 0.050665050745010376
step: 760, loss: 0.2310565561056137
step: 770, loss: 0.08856841176748276
step: 780, loss: 0.019418733194470406
step: 790, loss: 0.02621280774474144
step: 800, loss: 0.028904829174280167
step: 810, loss: 0.004028101451694965
step: 820, loss: 0.08770260214805603
step: 830, loss: 0.08624938130378723
step: 840, loss: 0.1360972821712494
step: 850, loss: 0.09315905719995499
step: 860, loss: 0.18478059768676758
step: 870, loss: 0.06175584718585014
step: 880, loss: 0.09948674589395523
step: 890, loss: 0.08426276594400406
step: 900, loss: 0.08972016721963882
step: 910, loss: 0.057436902076005936
step: 920, loss: 0.02589452639222145
step: 930, loss: 0.10940463095903397
step: 940, loss: 0.07845525443553925
step: 950, loss: 0.1076924279332161
step: 960, loss: 0.10016248375177383
step: 970, loss: 0.08050354570150375
step: 980, loss: 0.1293579488992691
step: 990, loss: 0.09528374671936035
step: 1000, loss: 0.20791073143482208
step: 1010, loss: 0.03533722832798958
step: 1020, loss: 0.16405238211154938
step: 1030, loss: 8.30619246698916e-05
step: 1040, loss: 0.12261462956666946
step: 1050, loss: 0.08510277420282364
step: 1060, loss: 0.08916841447353363
step: 1070, loss: 0.06117759644985199
epoch 8: dev_f1=0.9400369003690037, f1=0.9340710004610421, best_f1=0.9340710004610421
step: 0, loss: 0.0003098531742580235
step: 10, loss: 0.04533577337861061
step: 20, loss: 0.029793664813041687
step: 30, loss: 0.08239636570215225
step: 40, loss: 0.05993722751736641
step: 50, loss: 0.004470286890864372
step: 60, loss: 0.11052986979484558
step: 70, loss: 0.031030047684907913
step: 80, loss: 0.05460892617702484
step: 90, loss: 0.050306372344493866
step: 100, loss: 0.07603488117456436
step: 110, loss: 0.03050978109240532
step: 120, loss: 0.11280671507120132
step: 130, loss: 0.017590409144759178
step: 140, loss: 0.035991936922073364
step: 150, loss: 0.14424017071723938
step: 160, loss: 0.09336433559656143
step: 170, loss: 0.05391865223646164
step: 180, loss: 0.2796272039413452
step: 190, loss: 0.04818349704146385
step: 200, loss: 0.12802280485630035
step: 210, loss: 0.05641736835241318
step: 220, loss: 0.08380507677793503
step: 230, loss: 0.1385626494884491
step: 240, loss: 0.057538725435733795
step: 250, loss: 0.13748019933700562
step: 260, loss: 0.16420166194438934
step: 270, loss: 0.008805016055703163
step: 280, loss: 0.04587341099977493
step: 290, loss: 0.04467108100652695
step: 300, loss: 0.07855170965194702
step: 310, loss: 0.13546495139598846
step: 320, loss: 0.0799066573381424
step: 330, loss: 0.15824995934963226
step: 340, loss: 0.12975716590881348
step: 350, loss: 0.03219829499721527
step: 360, loss: 0.03664780408143997
step: 370, loss: 0.04830546677112579
step: 380, loss: 0.10497237741947174
step: 390, loss: 0.013294398784637451
step: 400, loss: 0.05670708045363426
step: 410, loss: 0.16664136946201324
step: 420, loss: 0.10784829407930374
step: 430, loss: 0.007781424093991518
step: 440, loss: 0.13701900839805603
step: 450, loss: 0.0033713392913341522
step: 460, loss: 0.022553006187081337
step: 470, loss: 0.04464106634259224
step: 480, loss: 0.09666939824819565
step: 490, loss: 0.1328224092721939
step: 500, loss: 0.06485429406166077
step: 510, loss: 0.1152922511100769
step: 520, loss: 0.00018194675794802606
step: 530, loss: 0.08882366865873337
step: 540, loss: 0.048223938792943954
step: 550, loss: 0.027035903185606003
step: 560, loss: 0.09992364794015884
step: 570, loss: 0.15031218528747559
step: 580, loss: 0.06336747109889984
step: 590, loss: 0.05670541897416115
step: 600, loss: 0.09237086772918701
step: 610, loss: 0.04366439953446388
step: 620, loss: 0.1476864516735077
step: 630, loss: 0.04256167635321617
step: 640, loss: 0.06956885755062103
step: 650, loss: 0.10827206075191498
step: 660, loss: 0.03179061412811279
step: 670, loss: 0.10972996056079865
step: 680, loss: 0.14806027710437775
step: 690, loss: 0.095527783036232
step: 700, loss: 0.1500309705734253
step: 710, loss: 0.15108852088451385
step: 720, loss: 0.09676063060760498
step: 730, loss: 0.11932215839624405
step: 740, loss: 0.02273181453347206
step: 750, loss: 0.07651441544294357
step: 760, loss: 0.02387874573469162
step: 770, loss: 0.06661369651556015
step: 780, loss: 0.02882690355181694
step: 790, loss: 0.06688228249549866
step: 800, loss: 0.029646117240190506
step: 810, loss: 0.24629859626293182
step: 820, loss: 0.042966872453689575
step: 830, loss: 0.06379600614309311
step: 840, loss: 0.06430608779191971
step: 850, loss: 0.013735562562942505
step: 860, loss: 0.02946648746728897
step: 870, loss: 0.03396406024694443
step: 880, loss: 0.07331947237253189
step: 890, loss: 0.005858594086021185
step: 900, loss: 0.08063805848360062
step: 910, loss: 0.030626893043518066
step: 920, loss: 0.09691828489303589
step: 930, loss: 0.06368032097816467
step: 940, loss: 0.029977455735206604
step: 950, loss: 0.12575885653495789
step: 960, loss: 0.09063363820314407
step: 970, loss: 0.05270063504576683
step: 980, loss: 0.04720982536673546
step: 990, loss: 0.27220481634140015
step: 1000, loss: 0.012944426387548447
step: 1010, loss: 0.023644346743822098
step: 1020, loss: 0.061287231743335724
step: 1030, loss: 0.13697420060634613
step: 1040, loss: 0.046905722469091415
step: 1050, loss: 0.050945062190294266
step: 1060, loss: 0.02192520722746849
step: 1070, loss: 0.00583178224042058
epoch 9: dev_f1=0.9333967649857279, f1=0.9271523178807948, best_f1=0.9340710004610421
step: 0, loss: 0.14781711995601654
step: 10, loss: 0.08917679637670517
step: 20, loss: 0.054035723209381104
step: 30, loss: 0.05896062031388283
step: 40, loss: 0.028759844601154327
step: 50, loss: 0.12386736273765564
step: 60, loss: 0.0010534388711676002
step: 70, loss: 0.058688197284936905
step: 80, loss: 0.04686099663376808
step: 90, loss: 0.07415664196014404
step: 100, loss: 0.04181385040283203
step: 110, loss: 0.041758693754673004
step: 120, loss: 0.03680185228586197
step: 130, loss: 0.02947910688817501
step: 140, loss: 0.043330661952495575
step: 150, loss: 0.06507912278175354
step: 160, loss: 0.08883194625377655
step: 170, loss: 0.10811714082956314
step: 180, loss: 0.030232585966587067
step: 190, loss: 0.03189878165721893
step: 200, loss: 0.021549692377448082
step: 210, loss: 0.004253827501088381
step: 220, loss: 0.07067448645830154
step: 230, loss: 0.026390088722109795
step: 240, loss: 0.08435682207345963
step: 250, loss: 0.10399393737316132
step: 260, loss: 0.08564464002847672
step: 270, loss: 0.05133986100554466
step: 280, loss: 0.03999947011470795
step: 290, loss: 0.04942299425601959
step: 300, loss: 0.08423830568790436
step: 310, loss: 0.05806660279631615
step: 320, loss: 0.11167151480913162
step: 330, loss: 0.06021394953131676
step: 340, loss: 0.05301316827535629
step: 350, loss: 0.058513764292001724
step: 360, loss: 0.11054746806621552
step: 370, loss: 0.03173771873116493
step: 380, loss: 0.08458530902862549
step: 390, loss: 0.07404258102178574
step: 400, loss: 0.010000000707805157
step: 410, loss: 0.09824599325656891
step: 420, loss: 0.05352732539176941
step: 430, loss: 0.07946045696735382
step: 440, loss: 0.05075337365269661
step: 450, loss: 0.034665800631046295
step: 460, loss: 0.010575518012046814
step: 470, loss: 0.06153857707977295
step: 480, loss: 0.06356354802846909
step: 490, loss: 0.07997936755418777
step: 500, loss: 0.07878925651311874
step: 510, loss: 0.10782475024461746
step: 520, loss: 0.008403386920690536
step: 530, loss: 0.08102845400571823
step: 540, loss: 0.04000549390912056
step: 550, loss: 0.14877842366695404
step: 560, loss: 0.023458242416381836
step: 570, loss: 0.020419329404830933
step: 580, loss: 0.1268562525510788
step: 590, loss: 0.0669771134853363
step: 600, loss: 0.0730825662612915
step: 610, loss: 0.052856095135211945
step: 620, loss: 0.019661471247673035
step: 630, loss: 0.017476918175816536
step: 640, loss: 0.0167254451662302
step: 650, loss: 0.054160382598638535
step: 660, loss: 0.04955253005027771
step: 670, loss: 0.003131199860945344
step: 680, loss: 0.08095136284828186
step: 690, loss: 0.0369299091398716
step: 700, loss: 0.15868957340717316
step: 710, loss: 0.12208866328001022
step: 720, loss: 0.13220512866973877
step: 730, loss: 0.0723860114812851
step: 740, loss: 0.042807284742593765
step: 750, loss: 0.04200691729784012
step: 760, loss: 0.059964265674352646
step: 770, loss: 0.012407097965478897
step: 780, loss: 0.0687202736735344
step: 790, loss: 0.048873282968997955
step: 800, loss: 0.0933794379234314
step: 810, loss: 0.03715626522898674
step: 820, loss: 0.09992019832134247
step: 830, loss: 0.0035666136536747217
step: 840, loss: 0.1999727338552475
step: 850, loss: 0.08638357371091843
step: 860, loss: 0.20430442690849304
step: 870, loss: 0.17314688861370087
step: 880, loss: 0.07519043982028961
step: 890, loss: 0.0469948872923851
step: 900, loss: 0.08231573551893234
step: 910, loss: 0.14676429331302643
step: 920, loss: 0.1385178118944168
step: 930, loss: 0.0006909355870448053
step: 940, loss: 0.08893804997205734
step: 950, loss: 0.06326382607221603
step: 960, loss: 0.06956691294908524
step: 970, loss: 0.08450108766555786
step: 980, loss: 0.10157997161149979
step: 990, loss: 0.05863308161497116
step: 1000, loss: 0.09286630898714066
step: 1010, loss: 0.07534411549568176
step: 1020, loss: 0.10253111273050308
step: 1030, loss: 0.009827270172536373
step: 1040, loss: 0.03142635524272919
step: 1050, loss: 0.010531305335462093
step: 1060, loss: 0.08890816569328308
step: 1070, loss: 0.07221337407827377
epoch 10: dev_f1=0.9338919925512105, f1=0.9228624535315985, best_f1=0.9340710004610421
step: 0, loss: 0.09003917127847672
step: 10, loss: 0.001194228883832693
step: 20, loss: 0.03883076459169388
step: 30, loss: 0.040348026901483536
step: 40, loss: 0.09903168678283691
step: 50, loss: 0.002839964348822832
step: 60, loss: 0.02151125855743885
step: 70, loss: 0.020191583782434464
step: 80, loss: 0.11737098544836044
step: 90, loss: 0.09654463082551956
step: 100, loss: 0.04393972456455231
step: 110, loss: 0.0498640276491642
step: 120, loss: 0.07119043916463852
step: 130, loss: 0.01073050033301115
step: 140, loss: 0.021075496450066566
step: 150, loss: 0.06928372383117676
step: 160, loss: 0.06294651329517365
step: 170, loss: 0.12614797055721283
step: 180, loss: 0.07199370115995407
step: 190, loss: 0.11910516023635864
step: 200, loss: 0.013617775402963161
step: 210, loss: 0.04165398329496384
step: 220, loss: 0.1168145090341568
step: 230, loss: 0.09838742762804031
step: 240, loss: 0.06632652878761292
step: 250, loss: 0.00029057200299575925
step: 260, loss: 0.0405879020690918
step: 270, loss: 0.06335662305355072
step: 280, loss: 0.09498356282711029
step: 290, loss: 0.07008935511112213
step: 300, loss: 0.03449861332774162
step: 310, loss: 0.11004605144262314
step: 320, loss: 0.07654496282339096
step: 330, loss: 0.09246691316366196
step: 340, loss: 0.07701670378446579
step: 350, loss: 0.14909030497074127
step: 360, loss: 0.03490760177373886
step: 370, loss: 8.451672329101712e-05
step: 380, loss: 0.09352067857980728
step: 390, loss: 0.06371152400970459
step: 400, loss: 0.09072326123714447
step: 410, loss: 0.03432273119688034
step: 420, loss: 0.06803464144468307
step: 430, loss: 0.05079883337020874
step: 440, loss: 0.0748496800661087
step: 450, loss: 0.20893648266792297
step: 460, loss: 0.035950589925050735
step: 470, loss: 0.03463888168334961
step: 480, loss: 0.0449797622859478
step: 490, loss: 0.09313113242387772
step: 500, loss: 0.002201502677053213
step: 510, loss: 0.0726562961935997
step: 520, loss: 0.010830561630427837
step: 530, loss: 0.03560870513319969
step: 540, loss: 0.10808249562978745
step: 550, loss: 0.06722760945558548
step: 560, loss: 0.11419567465782166
step: 570, loss: 0.018710797652602196
step: 580, loss: 0.15128499269485474
step: 590, loss: 0.015027499757707119
step: 600, loss: 0.06536749750375748
step: 610, loss: 0.037410538643598557
step: 620, loss: 0.10347426682710648
step: 630, loss: 0.012165136635303497
step: 640, loss: 0.0737607404589653
step: 650, loss: 0.08606097847223282
step: 660, loss: 0.04882403090596199
step: 670, loss: 0.10217086970806122
step: 680, loss: 0.10465984046459198
step: 690, loss: 0.046139199286699295
step: 700, loss: 0.0403703898191452
step: 710, loss: 0.10548066347837448
step: 720, loss: 0.07419253140687943
step: 730, loss: 0.06221790611743927
step: 740, loss: 0.05982246622443199
step: 750, loss: 0.09874282032251358
step: 760, loss: 0.021833745762705803
step: 770, loss: 0.035979773849248886
step: 780, loss: 0.1274821162223816
step: 790, loss: 0.054347340017557144
step: 800, loss: 0.0851326435804367
step: 810, loss: 0.076962411403656
step: 820, loss: 0.07813213765621185
step: 830, loss: 0.07736603170633316
step: 840, loss: 0.11333410441875458
step: 850, loss: 0.08622569590806961
step: 860, loss: 0.019997067749500275
step: 870, loss: 0.15886498987674713
step: 880, loss: 0.06085467338562012
step: 890, loss: 0.04247158765792847
step: 900, loss: 0.05739418417215347
step: 910, loss: 0.011622358113527298
step: 920, loss: 0.056710079312324524
step: 930, loss: 0.03322020545601845
step: 940, loss: 0.09743557870388031
step: 950, loss: 0.09469065815210342
step: 960, loss: 0.10754142701625824
step: 970, loss: 0.057002514600753784
step: 980, loss: 0.19234517216682434
step: 990, loss: 0.06667770445346832
step: 1000, loss: 0.061267588287591934
step: 1010, loss: 0.025646381080150604
step: 1020, loss: 0.1303946077823639
step: 1030, loss: 0.1652078479528427
step: 1040, loss: 0.14211907982826233
step: 1050, loss: 0.043201036751270294
step: 1060, loss: 0.0586039237678051
step: 1070, loss: 0.020096180960536003
epoch 11: dev_f1=0.9322892676186089, f1=0.9280442804428044, best_f1=0.9340710004610421
step: 0, loss: 0.1237221509218216
step: 10, loss: 0.10210718959569931
step: 20, loss: 0.04584605246782303
step: 30, loss: 0.027164600789546967
step: 40, loss: 0.1412273645401001
step: 50, loss: 0.01972498558461666
step: 60, loss: 0.06108890846371651
step: 70, loss: 0.03957263380289078
step: 80, loss: 0.008739600889384747
step: 90, loss: 0.04065283387899399
step: 100, loss: 0.016550924628973007
step: 110, loss: 0.1411249041557312
step: 120, loss: 0.07768426835536957
step: 130, loss: 0.03358157351613045
step: 140, loss: 0.015729747712612152
step: 150, loss: 0.044821806252002716
step: 160, loss: 0.07791796326637268
step: 170, loss: 0.0784263014793396
step: 180, loss: 0.07012815773487091
step: 190, loss: 0.04441921040415764
step: 200, loss: 0.03204800933599472
step: 210, loss: 0.062122441828250885
step: 220, loss: 0.07894811034202576
step: 230, loss: 0.1127871572971344
step: 240, loss: 0.06264374405145645
step: 250, loss: 0.026164598762989044
step: 260, loss: 0.06913198530673981
step: 270, loss: 0.04015904664993286
step: 280, loss: 0.06907467544078827
step: 290, loss: 0.04653593525290489
step: 300, loss: 0.006832743063569069
step: 310, loss: 0.13458171486854553
step: 320, loss: 0.14137789607048035
step: 330, loss: 0.0637606829404831
step: 340, loss: 0.03650109842419624
step: 350, loss: 0.0657489150762558
step: 360, loss: 0.009047675877809525
step: 370, loss: 0.075319804251194
step: 380, loss: 0.10430793464183807
step: 390, loss: 0.08618811517953873
step: 400, loss: 0.01977761834859848
step: 410, loss: 0.033491019159555435
step: 420, loss: 0.05071179196238518
step: 430, loss: 0.09326749294996262
step: 440, loss: 0.04548786208033562
step: 450, loss: 0.10125760734081268
step: 460, loss: 0.01683904230594635
step: 470, loss: 0.006428827997297049
step: 480, loss: 0.015611940994858742
step: 490, loss: 0.03368264064192772
step: 500, loss: 0.04837428405880928
step: 510, loss: 0.14185389876365662
step: 520, loss: 0.05511215701699257
step: 530, loss: 0.18689072132110596
step: 540, loss: 0.05772087350487709
step: 550, loss: 0.12233337014913559
step: 560, loss: 0.0670890137553215
step: 570, loss: 0.11790318787097931
step: 580, loss: 0.06471120566129684
step: 590, loss: 0.06357768177986145
step: 600, loss: 0.06135827302932739
step: 610, loss: 0.12962070107460022
step: 620, loss: 0.08999059349298477
step: 630, loss: 0.031228480860590935
step: 640, loss: 0.07416217029094696
step: 650, loss: 0.06838618218898773
step: 660, loss: 0.08285269141197205
step: 670, loss: 0.03147473558783531
step: 680, loss: 0.10427410900592804
step: 690, loss: 0.011709022335708141
step: 700, loss: 0.018306899815797806
step: 710, loss: 0.027163278311491013
step: 720, loss: 0.10264902561903
step: 730, loss: 0.0563092902302742
step: 740, loss: 0.0844903215765953
step: 750, loss: 0.09101498126983643
step: 760, loss: 0.08551806211471558
step: 770, loss: 0.021278394386172295
step: 780, loss: 0.04282895848155022
step: 790, loss: 0.026665566489100456
step: 800, loss: 0.0612625777721405
step: 810, loss: 0.0636957660317421
step: 820, loss: 0.079753577709198
step: 830, loss: 0.051155079156160355
step: 840, loss: 0.06402935832738876
step: 850, loss: 0.012301892042160034
step: 860, loss: 0.016879061236977577
step: 870, loss: 0.027617814019322395
step: 880, loss: 0.12225997447967529
step: 890, loss: 0.01468326523900032
step: 900, loss: 0.07915501296520233
step: 910, loss: 0.029560666531324387
step: 920, loss: 0.05582132935523987
step: 930, loss: 0.00020710774697363377
step: 940, loss: 0.026527298614382744
step: 950, loss: 0.13680145144462585
step: 960, loss: 0.025244418531656265
step: 970, loss: 0.09320525825023651
step: 980, loss: 0.10939320176839828
step: 990, loss: 0.013070724904537201
step: 1000, loss: 0.1915968805551529
step: 1010, loss: 0.09214521944522858
step: 1020, loss: 0.20217573642730713
step: 1030, loss: 0.10712263733148575
step: 1040, loss: 0.07552403211593628
step: 1050, loss: 0.13324739038944244
step: 1060, loss: 0.023660827428102493
step: 1070, loss: 0.0171347726136446
epoch 12: dev_f1=0.9317343173431735, f1=0.9293302540415704, best_f1=0.9340710004610421
step: 0, loss: 0.011298976838588715
step: 10, loss: 0.05488179624080658
step: 20, loss: 0.07769569754600525
step: 30, loss: 0.14066621661186218
step: 40, loss: 0.060906607657670975
step: 50, loss: 0.023044917732477188
step: 60, loss: 0.04507829621434212
step: 70, loss: 0.05496623367071152
step: 80, loss: 0.0034446432255208492
step: 90, loss: 0.048079848289489746
step: 100, loss: 0.08063120394945145
step: 110, loss: 0.10949410498142242
step: 120, loss: 0.008424758911132812
step: 130, loss: 0.09734361618757248
step: 140, loss: 0.09061484783887863
step: 150, loss: 0.007802546955645084
step: 160, loss: 0.06304524093866348
step: 170, loss: 0.03055977262556553
step: 180, loss: 0.013023791834712029
step: 190, loss: 6.198934715939686e-05
step: 200, loss: 0.007943800650537014
step: 210, loss: 0.04489792138338089
step: 220, loss: 0.06131770461797714
step: 230, loss: 0.04816620796918869
step: 240, loss: 0.07337174564599991
step: 250, loss: 0.10108013451099396
step: 260, loss: 0.018667755648493767
step: 270, loss: 0.11502096056938171
step: 280, loss: 0.09364120662212372
step: 290, loss: 0.07623085379600525
step: 300, loss: 0.048159919679164886
step: 310, loss: 0.028664948418736458
step: 320, loss: 0.11003122478723526
step: 330, loss: 0.09384628385305405
step: 340, loss: 0.021392332389950752
step: 350, loss: 0.05686100944876671
step: 360, loss: 0.0720064640045166
step: 370, loss: 0.10606677085161209
step: 380, loss: 0.0909854844212532
step: 390, loss: 0.0807541012763977
step: 400, loss: 0.059761401265859604
step: 410, loss: 0.030109591782093048
step: 420, loss: 0.10386320948600769
step: 430, loss: 0.06596104055643082
step: 440, loss: 0.038571082055568695
step: 450, loss: 0.039192307740449905
step: 460, loss: 0.07286464422941208
step: 470, loss: 0.08541011065244675
step: 480, loss: 0.07988358289003372
step: 490, loss: 0.0009425143944099545
step: 500, loss: 0.07672248780727386
step: 510, loss: 0.06967633962631226
step: 520, loss: 0.08032844215631485
step: 530, loss: 0.09299369901418686
step: 540, loss: 0.044606830924749374
step: 550, loss: 0.03568243607878685
step: 560, loss: 0.15302619338035583
step: 570, loss: 0.013925801031291485
step: 580, loss: 0.07714375853538513
step: 590, loss: 0.0048771146684885025
step: 600, loss: 0.05303670093417168
step: 610, loss: 0.04576297849416733
step: 620, loss: 0.04633430391550064
step: 630, loss: 0.09997055679559708
step: 640, loss: 0.15167170763015747
step: 650, loss: 0.0575115829706192
step: 660, loss: 0.006989785470068455
step: 670, loss: 0.025159141048789024
step: 680, loss: 0.046647921204566956
step: 690, loss: 0.05885965749621391
step: 700, loss: 0.05623508244752884
step: 710, loss: 0.035135574638843536
step: 720, loss: 0.08407557755708694
step: 730, loss: 0.06423482298851013
step: 740, loss: 0.10347523540258408
step: 750, loss: 0.05079197511076927
step: 760, loss: 0.04682175815105438
step: 770, loss: 0.012362554669380188
step: 780, loss: 0.11065138131380081
step: 790, loss: 0.12362179160118103
step: 800, loss: 0.08920560032129288
step: 810, loss: 0.08560223877429962
step: 820, loss: 0.0046050152741372585
step: 830, loss: 0.08122356235980988
step: 840, loss: 0.0063725421205163
step: 850, loss: 0.09037216752767563
step: 860, loss: 0.04140159860253334
step: 870, loss: 0.11727745085954666
step: 880, loss: 0.07191076874732971
step: 890, loss: 0.12883611023426056
step: 900, loss: 0.014250124804675579
step: 910, loss: 0.06836506724357605
step: 920, loss: 0.06665533035993576
step: 930, loss: 0.02573220059275627
step: 940, loss: 0.0733117163181305
step: 950, loss: 0.014453529380261898
step: 960, loss: 0.05580401048064232
step: 970, loss: 0.09374795854091644
step: 980, loss: 0.05249182879924774
step: 990, loss: 0.028455376625061035
step: 1000, loss: 0.0448005311191082
step: 1010, loss: 0.06572741270065308
step: 1020, loss: 0.01716674491763115
step: 1030, loss: 0.035456135869026184
step: 1040, loss: 0.038945186883211136
step: 1050, loss: 0.10790594667196274
step: 1060, loss: 0.07716907560825348
step: 1070, loss: 0.1023867279291153
epoch 13: dev_f1=0.9291338582677167, f1=0.9279778393351801, best_f1=0.9340710004610421
step: 0, loss: 0.02254081331193447
step: 10, loss: 0.08293699473142624
step: 20, loss: 0.08576998114585876
step: 30, loss: 0.09048483520746231
step: 40, loss: 0.06344319880008698
step: 50, loss: 0.07060206681489944
step: 60, loss: 0.03193189948797226
step: 70, loss: 7.874141010688618e-05
step: 80, loss: 0.05865925922989845
step: 90, loss: 0.1096712276339531
step: 100, loss: 0.06953083723783493
step: 110, loss: 0.023814577609300613
step: 120, loss: 0.12409726530313492
step: 130, loss: 0.0755888819694519
step: 140, loss: 0.04961220175027847
step: 150, loss: 0.016993248835206032
step: 160, loss: 0.018259141594171524
step: 170, loss: 0.04974793642759323
step: 180, loss: 0.06430185586214066
step: 190, loss: 0.041203003376722336
step: 200, loss: 0.02452615648508072
step: 210, loss: 0.03360874578356743
step: 220, loss: 0.07497051358222961
step: 230, loss: 0.0029736761935055256
step: 240, loss: 0.042059414088726044
step: 250, loss: 0.12128869444131851
step: 260, loss: 6.705464329570532e-05
step: 270, loss: 0.1121349036693573
step: 280, loss: 0.2776537835597992
step: 290, loss: 0.06628990918397903
step: 300, loss: 0.03486743941903114
step: 310, loss: 0.018422618508338928
step: 320, loss: 0.05497271195054054
step: 330, loss: 0.047442179173231125
step: 340, loss: 0.05433448404073715
step: 350, loss: 0.10927890241146088
step: 360, loss: 0.13630376756191254
step: 370, loss: 0.09799058735370636
step: 380, loss: 0.04050937294960022
step: 390, loss: 0.020848790183663368
step: 400, loss: 0.08656340092420578
step: 410, loss: 0.06502857804298401
step: 420, loss: 0.1198899894952774
step: 430, loss: 0.10706068575382233
step: 440, loss: 0.08115456253290176
step: 450, loss: 0.15943214297294617
step: 460, loss: 0.014816892333328724
step: 470, loss: 0.12117939442396164
step: 480, loss: 0.04878150299191475
step: 490, loss: 0.06905575841665268
step: 500, loss: 0.022303825244307518
step: 510, loss: 0.15503710508346558
step: 520, loss: 0.07070896029472351
step: 530, loss: 0.017708206549286842
step: 540, loss: 0.054896943271160126
step: 550, loss: 0.049922190606594086
step: 560, loss: 0.041749726980924606
step: 570, loss: 0.09851250052452087
step: 580, loss: 0.011750942096114159
step: 590, loss: 0.06517592817544937
step: 600, loss: 0.01777949184179306
step: 610, loss: 0.05383199080824852
step: 620, loss: 0.07691067457199097
step: 630, loss: 0.010528665035963058
step: 640, loss: 0.007171643897891045
step: 650, loss: 0.24079206585884094
step: 660, loss: 6.763455166947097e-05
step: 670, loss: 0.034322578459978104
step: 680, loss: 0.046341534703969955
step: 690, loss: 0.08267270773649216
step: 700, loss: 0.05002482235431671
step: 710, loss: 0.035791609436273575
step: 720, loss: 0.09591709822416306
step: 730, loss: 0.12048006057739258
step: 740, loss: 0.13983751833438873
step: 750, loss: 0.066839300096035
step: 760, loss: 0.03142219036817551
step: 770, loss: 0.025077255442738533
step: 780, loss: 0.1408945620059967
step: 790, loss: 0.03978360816836357
step: 800, loss: 0.08457202464342117
step: 810, loss: 0.021239997819066048
step: 820, loss: 0.0002893575292546302
step: 830, loss: 0.06159991770982742
step: 840, loss: 0.06893698871135712
step: 850, loss: 0.09333271533250809
step: 860, loss: 0.07633234560489655
step: 870, loss: 0.13740265369415283
step: 880, loss: 0.022056594491004944
step: 890, loss: 0.001182178151793778
step: 900, loss: 0.043884120881557465
step: 910, loss: 0.05730809271335602
step: 920, loss: 0.12765026092529297
step: 930, loss: 0.05488647520542145
step: 940, loss: 0.053016696125268936
step: 950, loss: 0.07234247773885727
step: 960, loss: 0.08858738094568253
step: 970, loss: 0.06466701626777649
step: 980, loss: 0.06909812241792679
step: 990, loss: 0.04762469604611397
step: 1000, loss: 0.09376081079244614
step: 1010, loss: 0.16933023929595947
step: 1020, loss: 0.038042373955249786
step: 1030, loss: 0.01860925555229187
step: 1040, loss: 0.06451679766178131
step: 1050, loss: 0.08188212662935257
step: 1060, loss: 0.016688382253050804
step: 1070, loss: 0.06278703361749649
epoch 14: dev_f1=0.9242076251722553, f1=0.9234997709573981, best_f1=0.9340710004610421
step: 0, loss: 0.11221763491630554
step: 10, loss: 0.04447019845247269
step: 20, loss: 0.04518425092101097
step: 30, loss: 0.019971938803792
step: 40, loss: 0.022541692480444908
step: 50, loss: 0.0959622859954834
step: 60, loss: 0.09979408979415894
step: 70, loss: 0.02317335642874241
step: 80, loss: 0.043767474591732025
step: 90, loss: 0.031198032200336456
step: 100, loss: 0.040498897433280945
step: 110, loss: 0.052660584449768066
step: 120, loss: 0.015119568444788456
step: 130, loss: 0.016145378351211548
step: 140, loss: 0.06768693029880524
step: 150, loss: 0.027866490185260773
step: 160, loss: 0.06468349695205688
step: 170, loss: 0.010118835605680943
step: 180, loss: 0.06502799689769745
step: 190, loss: 0.10486458986997604
step: 200, loss: 0.04415368288755417
step: 210, loss: 0.09835461527109146
step: 220, loss: 0.07822640240192413
step: 230, loss: 0.050120435655117035
step: 240, loss: 0.0940609872341156
step: 250, loss: 0.026762818917632103
step: 260, loss: 0.06748690456151962
step: 270, loss: 0.03934641554951668
step: 280, loss: 0.04147787764668465
step: 290, loss: 0.07743437588214874
step: 300, loss: 0.11609471589326859
step: 310, loss: 0.08116140216588974
step: 320, loss: 0.00020471433526836336
step: 330, loss: 0.027636736631393433
step: 340, loss: 0.06809059530496597
step: 350, loss: 0.0759662613272667
step: 360, loss: 0.06398234516382217
step: 370, loss: 0.03359653428196907
step: 380, loss: 0.00018786451255436987
step: 390, loss: 0.08888673782348633
step: 400, loss: 0.03674543648958206
step: 410, loss: 2.674544339242857e-05
step: 420, loss: 0.01741270162165165
step: 430, loss: 0.15281617641448975
step: 440, loss: 0.030191704630851746
step: 450, loss: 0.09427402168512344
step: 460, loss: 0.11517277359962463
step: 470, loss: 0.07165512442588806
step: 480, loss: 0.059719398617744446
step: 490, loss: 0.023441841825842857
step: 500, loss: 0.05321008339524269
step: 510, loss: 0.10228565335273743
step: 520, loss: 0.07442793995141983
step: 530, loss: 0.032798636704683304
step: 540, loss: 0.056081026792526245
step: 550, loss: 0.07250097393989563
step: 560, loss: 0.01845591329038143
step: 570, loss: 0.024743396788835526
step: 580, loss: 0.09895992279052734
step: 590, loss: 0.07899168878793716
step: 600, loss: 0.02513132430613041
step: 610, loss: 0.01931125856935978
step: 620, loss: 0.06967803090810776
step: 630, loss: 3.931180981453508e-05
step: 640, loss: 0.06479845941066742
step: 650, loss: 0.059572670608758926
step: 660, loss: 0.07107241451740265
step: 670, loss: 0.01663878746330738
step: 680, loss: 0.0006271497695706785
step: 690, loss: 0.06013251096010208
step: 700, loss: 0.001632331288419664
step: 710, loss: 0.07418399304151535
step: 720, loss: 0.08791930973529816
step: 730, loss: 0.2398664802312851
step: 740, loss: 0.045803312212228775
step: 750, loss: 0.1255456805229187
step: 760, loss: 0.06498223543167114
step: 770, loss: 0.021835042163729668
step: 780, loss: 0.03936396539211273
step: 790, loss: 0.05916506052017212
step: 800, loss: 0.0659727081656456
step: 810, loss: 0.03181394189596176
step: 820, loss: 0.03951331600546837
step: 830, loss: 0.02519295923411846
step: 840, loss: 0.0345744751393795
step: 850, loss: 0.03013238124549389
step: 860, loss: 0.04962219297885895
step: 870, loss: 0.022208837792277336
step: 880, loss: 0.023923004046082497
step: 890, loss: 0.09705890715122223
step: 900, loss: 0.028936102986335754
step: 910, loss: 0.04876543954014778
step: 920, loss: 0.039447784423828125
step: 930, loss: 0.025466270744800568
step: 940, loss: 0.05824379622936249
step: 950, loss: 0.05402687191963196
step: 960, loss: 0.17574703693389893
step: 970, loss: 0.017895875498652458
step: 980, loss: 0.06915651261806488
step: 990, loss: 0.04608171433210373
step: 1000, loss: 0.05114934593439102
step: 1010, loss: 0.05508335307240486
step: 1020, loss: 0.05384612828493118
step: 1030, loss: 0.08518001437187195
step: 1040, loss: 0.026777751743793488
step: 1050, loss: 0.015485620126128197
step: 1060, loss: 0.1032465472817421
step: 1070, loss: 0.04003661498427391
epoch 15: dev_f1=0.9286713286713286, f1=0.9254426840633737, best_f1=0.9340710004610421
step: 0, loss: 0.04892488941550255
step: 10, loss: 0.06661223620176315
step: 20, loss: 0.06289152801036835
step: 30, loss: 0.06651652604341507
step: 40, loss: 0.03783312439918518
step: 50, loss: 0.07418670505285263
step: 60, loss: 0.04721152409911156
step: 70, loss: 0.023716023191809654
step: 80, loss: 0.06255679577589035
step: 90, loss: 0.08028174191713333
step: 100, loss: 0.03990651294589043
step: 110, loss: 0.054897915571928024
step: 120, loss: 0.049281999468803406
step: 130, loss: 0.09071192145347595
step: 140, loss: 8.267396333394572e-05
step: 150, loss: 0.00035256033879704773
step: 160, loss: 0.04117126017808914
step: 170, loss: 0.07840688526630402
step: 180, loss: 0.02589084394276142
step: 190, loss: 0.019969042390584946
step: 200, loss: 0.07984942942857742
step: 210, loss: 0.007087371777743101
step: 220, loss: 0.046185582876205444
step: 230, loss: 0.046076711267232895
step: 240, loss: 0.00041521075763739645
step: 250, loss: 0.058228615671396255
step: 260, loss: 0.06618813425302505
step: 270, loss: 0.02597871795296669
step: 280, loss: 0.020092889666557312
step: 290, loss: 0.022620005533099174
step: 300, loss: 0.02685304917395115
step: 310, loss: 0.03286134451627731
step: 320, loss: 0.0787101686000824
step: 330, loss: 0.0003925693454220891
step: 340, loss: 0.01698419637978077
step: 350, loss: 9.381133713759482e-05
step: 360, loss: 0.08004916459321976
step: 370, loss: 0.01690540462732315
step: 380, loss: 0.09011530131101608
step: 390, loss: 0.0006644655950367451
step: 400, loss: 0.008990167640149593
step: 410, loss: 0.08855657279491425
step: 420, loss: 0.007548924069851637
step: 430, loss: 0.0004526178236119449
step: 440, loss: 0.13334843516349792
step: 450, loss: 0.04687005281448364
step: 460, loss: 0.05571594461798668
step: 470, loss: 0.07306291162967682
step: 480, loss: 0.05494089424610138
step: 490, loss: 0.02181776985526085
step: 500, loss: 0.040220409631729126
step: 510, loss: 0.055220358073711395
step: 520, loss: 0.00828293152153492
step: 530, loss: 0.036605026572942734
step: 540, loss: 0.0882054790854454
step: 550, loss: 0.05146300420165062
step: 560, loss: 0.06550285220146179
step: 570, loss: 0.05410241708159447
step: 580, loss: 0.041266415268182755
step: 590, loss: 0.0590035654604435
step: 600, loss: 0.130349263548851
step: 610, loss: 0.005201967898756266
step: 620, loss: 0.06797582656145096
step: 630, loss: 0.09108008444309235
step: 640, loss: 0.033721476793289185
step: 650, loss: 0.04918573424220085
step: 660, loss: 0.034151509404182434
step: 670, loss: 0.024108856916427612
step: 680, loss: 0.12036684900522232
step: 690, loss: 0.055586304515600204
step: 700, loss: 0.023080097511410713
step: 710, loss: 0.1409415900707245
step: 720, loss: 0.05411142855882645
step: 730, loss: 0.029889017343521118
step: 740, loss: 0.05706838145852089
step: 750, loss: 0.03630656376481056
step: 760, loss: 0.07757135480642319
step: 770, loss: 0.030089689418673515
step: 780, loss: 0.03700023889541626
step: 790, loss: 0.024290721863508224
step: 800, loss: 0.04001994431018829
step: 810, loss: 0.022763926535844803
step: 820, loss: 0.1392180174589157
step: 830, loss: 0.058493129909038544
step: 840, loss: 0.01996813714504242
step: 850, loss: 0.06560400128364563
step: 860, loss: 0.0405094251036644
step: 870, loss: 0.035934120416641235
step: 880, loss: 0.06870061159133911
step: 890, loss: 0.0801507979631424
step: 900, loss: 0.002047502202913165
step: 910, loss: 0.02545112743973732
step: 920, loss: 2.0058880181750283e-05
step: 930, loss: 0.06824392825365067
step: 940, loss: 0.07458825409412384
step: 950, loss: 0.05762447044253349
step: 960, loss: 0.08531414717435837
step: 970, loss: 0.0493028499186039
step: 980, loss: 0.0513833686709404
step: 990, loss: 0.11439232528209686
step: 1000, loss: 0.02490745484828949
step: 1010, loss: 0.043097011744976044
step: 1020, loss: 0.07672376930713654
step: 1030, loss: 0.08246340602636337
step: 1040, loss: 0.00976817961782217
step: 1050, loss: 0.07095187902450562
step: 1060, loss: 0.04086049646139145
step: 1070, loss: 0.059351880103349686
epoch 16: dev_f1=0.9288040949278734, f1=0.9240801117838845, best_f1=0.9340710004610421
step: 0, loss: 0.13131757080554962
step: 10, loss: 0.01741250604391098
step: 20, loss: 0.1320478618144989
step: 30, loss: 0.028166037052869797
step: 40, loss: 0.05675916746258736
step: 50, loss: 0.018675534054636955
step: 60, loss: 0.023833630606532097
step: 70, loss: 0.020181871950626373
step: 80, loss: 0.044283997267484665
step: 90, loss: 0.00010140382801182568
step: 100, loss: 0.0569603256881237
step: 110, loss: 0.06203779578208923
step: 120, loss: 0.018534421920776367
step: 130, loss: 0.00025204490520991385
step: 140, loss: 0.12945868074893951
step: 150, loss: 0.030440999194979668
step: 160, loss: 0.039240848273038864
step: 170, loss: 0.05405886471271515
step: 180, loss: 0.05669644847512245
step: 190, loss: 0.039460439234972
step: 200, loss: 0.03405226394534111
step: 210, loss: 0.1902340054512024
step: 220, loss: 0.030530275776982307
step: 230, loss: 0.09893932938575745
step: 240, loss: 0.06559334695339203
step: 250, loss: 0.03150452300906181
step: 260, loss: 0.03330277279019356
step: 270, loss: 0.0406121090054512
step: 280, loss: 0.045430738478899
step: 290, loss: 0.12996694445610046
step: 300, loss: 0.06869909167289734
step: 310, loss: 0.04292513430118561
step: 320, loss: 0.05949994921684265
step: 330, loss: 0.12101045250892639
step: 340, loss: 0.014641582034528255
step: 350, loss: 0.029638459905982018
step: 360, loss: 0.04159851744771004
step: 370, loss: 0.14351500570774078
step: 380, loss: 0.08532824367284775
step: 390, loss: 0.058422014117240906
step: 400, loss: 0.08037376403808594
step: 410, loss: 0.09127839654684067
step: 420, loss: 0.08396817743778229
step: 430, loss: 0.02391013875603676
step: 440, loss: 0.011734678409993649
step: 450, loss: 0.012186473235487938
step: 460, loss: 0.06997565180063248
step: 470, loss: 0.06290730834007263
step: 480, loss: 0.015022797510027885
step: 490, loss: 0.29545801877975464
step: 500, loss: 0.0543648861348629
step: 510, loss: 0.09116701781749725
step: 520, loss: 0.006864008493721485
step: 530, loss: 0.04386231303215027
step: 540, loss: 0.08045093715190887
step: 550, loss: 0.04226599261164665
step: 560, loss: 0.04165184870362282
step: 570, loss: 0.061873044818639755
step: 580, loss: 0.0519019179046154
step: 590, loss: 0.02685816027224064
step: 600, loss: 0.03044867143034935
step: 610, loss: 0.012826456688344479
step: 620, loss: 0.05431989207863808
step: 630, loss: 0.05337464064359665
step: 640, loss: 0.059293653815984726
step: 650, loss: 0.01548249926418066
step: 660, loss: 0.04779963567852974
step: 670, loss: 0.1124684065580368
step: 680, loss: 0.11602485924959183
step: 690, loss: 0.06551698595285416
step: 700, loss: 0.002813067054376006
step: 710, loss: 0.005643386393785477
step: 720, loss: 0.01950935274362564
step: 730, loss: 0.04507959261536598
step: 740, loss: 0.0018633815925568342
step: 750, loss: 0.04857077822089195
step: 760, loss: 0.0480407178401947
step: 770, loss: 0.03049680031836033
step: 780, loss: 0.01822892390191555
step: 790, loss: 0.06356189399957657
step: 800, loss: 0.0001353318803012371
step: 810, loss: 0.09615184366703033
step: 820, loss: 0.04467775672674179
step: 830, loss: 0.06921602040529251
step: 840, loss: 0.05251593887805939
step: 850, loss: 0.05581855773925781
step: 860, loss: 0.021757517009973526
step: 870, loss: 0.06239829212427139
step: 880, loss: 0.06821932643651962
step: 890, loss: 0.08621783554553986
step: 900, loss: 0.0032885950058698654
step: 910, loss: 0.02298353798687458
step: 920, loss: 0.07329847663640976
step: 930, loss: 0.02646207995712757
step: 940, loss: 0.014361766166985035
step: 950, loss: 0.07200256735086441
step: 960, loss: 0.02126597799360752
step: 970, loss: 0.02076452039182186
step: 980, loss: 0.021177131682634354
step: 990, loss: 0.02971799112856388
step: 1000, loss: 0.007178700063377619
step: 1010, loss: 0.0408124215900898
step: 1020, loss: 0.017746396362781525
step: 1030, loss: 0.091886967420578
step: 1040, loss: 0.07235368341207504
step: 1050, loss: 0.04979253187775612
step: 1060, loss: 0.04806877672672272
step: 1070, loss: 0.058821819722652435
epoch 17: dev_f1=0.927806241266884, f1=0.9268518518518517, best_f1=0.9340710004610421
step: 0, loss: 0.01283261924982071
step: 10, loss: 0.000576650956645608
step: 20, loss: 0.0003386801981832832
step: 30, loss: 0.013903561048209667
step: 40, loss: 0.08732350915670395
step: 50, loss: 0.02660353295505047
step: 60, loss: 0.07927541434764862
step: 70, loss: 0.04717594012618065
step: 80, loss: 0.06763159483671188
step: 90, loss: 4.485957106226124e-05
step: 100, loss: 0.021151259541511536
step: 110, loss: 0.05813520774245262
step: 120, loss: 0.11515787988901138
step: 130, loss: 0.032688118517398834
step: 140, loss: 0.07206327468156815
step: 150, loss: 0.10312853008508682
step: 160, loss: 0.0149897001683712
step: 170, loss: 0.12420102208852768
step: 180, loss: 0.021997671574354172
step: 190, loss: 0.04787643998861313
step: 200, loss: 0.0232052281498909
step: 210, loss: 0.03391219675540924
step: 220, loss: 0.023871827870607376
step: 230, loss: 0.019473103806376457
step: 240, loss: 0.07176671922206879
step: 250, loss: 0.0714622214436531
step: 260, loss: 0.018453653901815414
step: 270, loss: 0.0631454735994339
step: 280, loss: 0.12660257518291473
step: 290, loss: 0.054242078214883804
step: 300, loss: 0.03239293023943901
step: 310, loss: 0.21454620361328125
step: 320, loss: 0.069858118891716
step: 330, loss: 0.09677041321992874
step: 340, loss: 0.02318207174539566
step: 350, loss: 0.009273304603993893
step: 360, loss: 0.07958041876554489
step: 370, loss: 0.0267762653529644
step: 380, loss: 0.032045137137174606
step: 390, loss: 0.001017937669530511
step: 400, loss: 0.03627805411815643
step: 410, loss: 0.05382685363292694
step: 420, loss: 0.027449361979961395
step: 430, loss: 0.07332713901996613
step: 440, loss: 0.023243915289640427
step: 450, loss: 0.0021082882303744555
step: 460, loss: 0.03659983351826668
step: 470, loss: 0.0614963099360466
step: 480, loss: 0.057811785489320755
step: 490, loss: 0.012423002161085606
step: 500, loss: 0.01664259284734726
step: 510, loss: 0.036442968994379044
step: 520, loss: 0.028752200305461884
step: 530, loss: 0.00597728043794632
step: 540, loss: 0.05185357853770256
step: 550, loss: 0.08232741057872772
step: 560, loss: 0.05654970183968544
step: 570, loss: 0.026750218123197556
step: 580, loss: 0.021719524636864662
step: 590, loss: 5.095497181173414e-05
step: 600, loss: 0.0001274975365959108
step: 610, loss: 0.024071451276540756
step: 620, loss: 0.08852942287921906
step: 630, loss: 0.012770346365869045
step: 640, loss: 0.05647391453385353
step: 650, loss: 0.021889103576540947
step: 660, loss: 0.00010322260641260073
step: 670, loss: 0.02936333417892456
step: 680, loss: 0.13003748655319214
step: 690, loss: 0.07473895698785782
step: 700, loss: 0.05325086787343025
step: 710, loss: 0.023358074948191643
step: 720, loss: 0.08897698670625687
step: 730, loss: 0.046301815658807755
step: 740, loss: 0.02987126260995865
step: 750, loss: 0.0758197084069252
step: 760, loss: 0.023990647867321968
step: 770, loss: 0.14126652479171753
step: 780, loss: 5.020743265049532e-05
step: 790, loss: 0.049238283187150955
step: 800, loss: 0.09600472450256348
step: 810, loss: 0.026282235980033875
step: 820, loss: 0.007607726845890284
step: 830, loss: 1.2464697647374123e-05
step: 840, loss: 0.08701715618371964
step: 850, loss: 0.024519897997379303
step: 860, loss: 0.03097468800842762
step: 870, loss: 0.04778987169265747
step: 880, loss: 0.05639857426285744
step: 890, loss: 0.07383294403553009
step: 900, loss: 0.02500567026436329
step: 910, loss: 0.030978551134467125
step: 920, loss: 0.03056696057319641
step: 930, loss: 0.013670356944203377
step: 940, loss: 0.02036254107952118
step: 950, loss: 0.03072713129222393
step: 960, loss: 0.022153833881020546
step: 970, loss: 0.022437680512666702
step: 980, loss: 0.027323603630065918
step: 990, loss: 0.05104737728834152
step: 1000, loss: 0.03300144523382187
step: 1010, loss: 0.07374831289052963
step: 1020, loss: 0.0762505754828453
step: 1030, loss: 0.013881474733352661
step: 1040, loss: 0.05541396886110306
step: 1050, loss: 0.1066947802901268
step: 1060, loss: 0.00019341784354764968
step: 1070, loss: 0.07453969866037369
epoch 18: dev_f1=0.9301453352086263, f1=0.9263746505125815, best_f1=0.9340710004610421
step: 0, loss: 0.013869370333850384
step: 10, loss: 0.077125683426857
step: 20, loss: 0.09651123732328415
step: 30, loss: 0.028048401698470116
step: 40, loss: 0.04008030146360397
step: 50, loss: 0.08673522621393204
step: 60, loss: 0.11807437241077423
step: 70, loss: 0.04106725752353668
step: 80, loss: 0.07153016328811646
step: 90, loss: 0.035816490650177
step: 100, loss: 0.015699561685323715
step: 110, loss: 0.020427577197551727
step: 120, loss: 0.044755905866622925
step: 130, loss: 0.027447901666164398
step: 140, loss: 0.01315644383430481
step: 150, loss: 0.04832810163497925
step: 160, loss: 0.02993846870958805
step: 170, loss: 0.045053400099277496
step: 180, loss: 0.010925465263426304
step: 190, loss: 0.09185197204351425
step: 200, loss: 0.03193340450525284
step: 210, loss: 0.03425193205475807
step: 220, loss: 0.07658983767032623
step: 230, loss: 0.044659167528152466
step: 240, loss: 0.05167722329497337
step: 250, loss: 0.09548435360193253
step: 260, loss: 0.06305230408906937
step: 270, loss: 0.04816385358572006
step: 280, loss: 0.014232161454856396
step: 290, loss: 0.00919758714735508
step: 300, loss: 0.00983892660588026
step: 310, loss: 1.7851207303465344e-05
step: 320, loss: 0.02134176902472973
step: 330, loss: 0.02841421775519848
step: 340, loss: 0.015548544935882092
step: 350, loss: 0.034868545830249786
step: 360, loss: 0.07102561742067337
step: 370, loss: 0.04869239777326584
step: 380, loss: 0.08044660091400146
step: 390, loss: 0.03817980736494064
step: 400, loss: 0.04197312146425247
step: 410, loss: 0.0555935837328434
step: 420, loss: 0.08881793171167374
step: 430, loss: 0.022309375926852226
step: 440, loss: 0.03395618498325348
step: 450, loss: 0.033091358840465546
step: 460, loss: 0.03961639851331711
step: 470, loss: 2.7270687496638857e-05
step: 480, loss: 0.031330619007349014
step: 490, loss: 0.10019036382436752
step: 500, loss: 1.9806673662969843e-05
step: 510, loss: 0.016106028109788895
step: 520, loss: 0.05389716476202011
step: 530, loss: 0.100770965218544
step: 540, loss: 0.035605404525995255
step: 550, loss: 0.07343607395887375
step: 560, loss: 0.02717681974172592
step: 570, loss: 0.05259399488568306
step: 580, loss: 0.08514861762523651
step: 590, loss: 0.046070244163274765
step: 600, loss: 0.06184552237391472
step: 610, loss: 0.05415144935250282
step: 620, loss: 0.0003054070984944701
step: 630, loss: 0.021955063566565514
step: 640, loss: 0.053014323115348816
step: 650, loss: 0.031120019033551216
step: 660, loss: 0.08313377946615219
step: 670, loss: 0.040344610810279846
step: 680, loss: 0.0082005076110363
step: 690, loss: 0.08018580824136734
step: 700, loss: 0.03883013501763344
step: 710, loss: 0.07775332778692245
step: 720, loss: 6.132866838015616e-05
step: 730, loss: 0.036027200520038605
step: 740, loss: 0.007533238735049963
step: 750, loss: 0.04286346957087517
step: 760, loss: 0.10180840641260147
step: 770, loss: 0.11651436984539032
step: 780, loss: 0.04869305342435837
step: 790, loss: 0.08461829274892807
step: 800, loss: 0.027608543634414673
step: 810, loss: 0.08504382520914078
step: 820, loss: 0.07924419641494751
step: 830, loss: 0.03179400414228439
step: 840, loss: 0.0007227883324958384
step: 850, loss: 0.0689268484711647
step: 860, loss: 0.01494554802775383
step: 870, loss: 0.0009734773193486035
step: 880, loss: 0.057211730629205704
step: 890, loss: 0.016951607540249825
step: 900, loss: 0.14151032269001007
step: 910, loss: 0.024274392053484917
step: 920, loss: 1.856869312177878e-05
step: 930, loss: 0.09970029443502426
step: 940, loss: 0.03220750391483307
step: 950, loss: 0.014198854565620422
step: 960, loss: 0.061586588621139526
step: 970, loss: 0.02725265733897686
step: 980, loss: 0.08192718029022217
step: 990, loss: 0.023932117968797684
step: 1000, loss: 9.763894013303798e-06
step: 1010, loss: 0.04378942772746086
step: 1020, loss: 0.014612630009651184
step: 1030, loss: 0.05388250574469566
step: 1040, loss: 0.03591598570346832
step: 1050, loss: 5.505228909896687e-05
step: 1060, loss: 0.03637995570898056
step: 1070, loss: 0.00012415257515385747
epoch 19: dev_f1=0.9307116104868914, f1=0.9259431765253843, best_f1=0.9340710004610421
step: 0, loss: 0.09493578225374222
step: 10, loss: 0.03339632973074913
step: 20, loss: 0.027472790330648422
step: 30, loss: 0.0489325225353241
step: 40, loss: 0.021394630894064903
step: 50, loss: 0.003539168508723378
step: 60, loss: 0.06525882333517075
step: 70, loss: 0.048323746770620346
step: 80, loss: 0.009726804681122303
step: 90, loss: 0.06740924715995789
step: 100, loss: 0.009600897319614887
step: 110, loss: 0.010351636447012424
step: 120, loss: 0.04670104756951332
step: 130, loss: 0.036037202924489975
step: 140, loss: 0.05596676468849182
step: 150, loss: 0.044685691595077515
step: 160, loss: 0.022022657096385956
step: 170, loss: 0.025765595957636833
step: 180, loss: 0.05299551412463188
step: 190, loss: 0.0012249049032106996
step: 200, loss: 8.740637713344768e-05
step: 210, loss: 0.019077586010098457
step: 220, loss: 0.023435203358530998
step: 230, loss: 0.008763959631323814
step: 240, loss: 0.08694781363010406
step: 250, loss: 0.05866502597928047
step: 260, loss: 0.06422121077775955
step: 270, loss: 0.020229477435350418
step: 280, loss: 0.0014317400055006146
step: 290, loss: 0.039677999913692474
step: 300, loss: 0.04557349160313606
step: 310, loss: 0.0023227587807923555
step: 320, loss: 3.3752665331121534e-05
step: 330, loss: 0.039047885686159134
step: 340, loss: 0.07311911135911942
step: 350, loss: 0.060913823544979095
step: 360, loss: 0.0036086083855479956
step: 370, loss: 0.027975771576166153
step: 380, loss: 0.04964236542582512
step: 390, loss: 0.14187976717948914
step: 400, loss: 0.013663394376635551
step: 410, loss: 0.06529642641544342
step: 420, loss: 0.028160231187939644
step: 430, loss: 0.04214709252119064
step: 440, loss: 0.005989978089928627
step: 450, loss: 0.07221776992082596
step: 460, loss: 0.018560048192739487
step: 470, loss: 0.019516507163643837
step: 480, loss: 0.018077611923217773
step: 490, loss: 0.0003091534017585218
step: 500, loss: 0.030833624303340912
step: 510, loss: 0.04793879762291908
step: 520, loss: 1.56791338667972e-05
step: 530, loss: 0.03478990122675896
step: 540, loss: 0.026434078812599182
step: 550, loss: 0.06306397169828415
step: 560, loss: 0.05258989706635475
step: 570, loss: 0.03696282207965851
step: 580, loss: 0.07270943373441696
step: 590, loss: 0.09302030503749847
step: 600, loss: 0.0536423958837986
step: 610, loss: 0.017294008284807205
step: 620, loss: 0.019752999767661095
step: 630, loss: 0.02363009564578533
step: 640, loss: 0.00022683024872094393
step: 650, loss: 0.03821204602718353
step: 660, loss: 2.04921598196961e-05
step: 670, loss: 4.782674295711331e-05
step: 680, loss: 0.011747792363166809
step: 690, loss: 0.01210257038474083
step: 700, loss: 0.0002721337659750134
step: 710, loss: 0.049997128546237946
step: 720, loss: 0.05463622882962227
step: 730, loss: 0.017123455181717873
step: 740, loss: 0.0373428612947464
step: 750, loss: 0.04744981229305267
step: 760, loss: 0.05111844837665558
step: 770, loss: 0.01809326931834221
step: 780, loss: 0.04014280065894127
step: 790, loss: 0.09501378238201141
step: 800, loss: 2.3765818696119823e-05
step: 810, loss: 0.12470463663339615
step: 820, loss: 0.09868978708982468
step: 830, loss: 0.03053640015423298
step: 840, loss: 0.0005256011500023305
step: 850, loss: 0.08583033084869385
step: 860, loss: 0.02537854015827179
step: 870, loss: 0.036323320120573044
step: 880, loss: 0.054214026778936386
step: 890, loss: 0.11878501623868942
step: 900, loss: 0.032868798822164536
step: 910, loss: 0.0870942622423172
step: 920, loss: 0.07489574700593948
step: 930, loss: 9.877462434815243e-05
step: 940, loss: 0.08993701636791229
step: 950, loss: 0.030035866424441338
step: 960, loss: 0.04223296791315079
step: 970, loss: 0.06958025693893433
step: 980, loss: 0.023491622880101204
step: 990, loss: 0.06873977184295654
step: 1000, loss: 0.056764133274555206
step: 1010, loss: 0.07999229431152344
step: 1020, loss: 2.741610660450533e-05
step: 1030, loss: 0.0015124082565307617
step: 1040, loss: 0.017165983095765114
step: 1050, loss: 0.06907515227794647
step: 1060, loss: 0.04427918419241905
step: 1070, loss: 0.13842003047466278
epoch 20: dev_f1=0.929840972871843, f1=0.9249417249417249, best_f1=0.9340710004610421
