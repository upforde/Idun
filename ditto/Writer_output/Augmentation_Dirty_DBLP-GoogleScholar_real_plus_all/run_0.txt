cuda
Device: cuda
step: 0, loss: 0.650926947593689
step: 10, loss: 0.37860625982284546
step: 20, loss: 0.6210113167762756
step: 30, loss: 0.3528220057487488
step: 40, loss: 0.15568384528160095
step: 50, loss: 0.2740902304649353
step: 60, loss: 0.23198984563350677
step: 70, loss: 0.14724679291248322
step: 80, loss: 0.1828046292066574
step: 90, loss: 0.2602599859237671
step: 100, loss: 0.2602788805961609
step: 110, loss: 0.15087507665157318
step: 120, loss: 0.3011499345302582
step: 130, loss: 0.19048552215099335
step: 140, loss: 0.33160433173179626
step: 150, loss: 0.2578546702861786
step: 160, loss: 0.1970754712820053
step: 170, loss: 0.5482997894287109
step: 180, loss: 0.25437843799591064
step: 190, loss: 0.1581266075372696
step: 200, loss: 0.26275405287742615
step: 210, loss: 0.1907368153333664
step: 220, loss: 0.23040513694286346
step: 230, loss: 0.1689712256193161
step: 240, loss: 0.1855780929327011
step: 250, loss: 0.18874125182628632
step: 260, loss: 0.060573749244213104
step: 270, loss: 0.2603149116039276
step: 280, loss: 0.16378112137317657
step: 290, loss: 0.18879209458827972
step: 300, loss: 0.14038920402526855
step: 310, loss: 0.15251074731349945
step: 320, loss: 0.13264872133731842
step: 330, loss: 0.21005354821681976
step: 340, loss: 0.1830011010169983
step: 350, loss: 0.19970831274986267
step: 360, loss: 0.16208511590957642
step: 370, loss: 0.09795505553483963
step: 380, loss: 0.1493130922317505
step: 390, loss: 0.11673862487077713
step: 400, loss: 0.28727564215660095
step: 410, loss: 0.17792832851409912
step: 420, loss: 0.02333367057144642
step: 430, loss: 0.12911564111709595
step: 440, loss: 0.05781571567058563
step: 450, loss: 0.05371682718396187
step: 460, loss: 0.18818943202495575
step: 470, loss: 0.1623612344264984
step: 480, loss: 0.27232471108436584
step: 490, loss: 0.20271213352680206
step: 500, loss: 0.08022715896368027
step: 510, loss: 0.13861310482025146
step: 520, loss: 0.1662353128194809
step: 530, loss: 0.09289241582155228
step: 540, loss: 0.13869740068912506
step: 550, loss: 0.1519518941640854
step: 560, loss: 0.15091805160045624
step: 570, loss: 0.10369346290826797
step: 580, loss: 0.35339921712875366
step: 590, loss: 0.08374220877885818
step: 600, loss: 0.10568877309560776
step: 610, loss: 0.09408099949359894
step: 620, loss: 0.13601253926753998
step: 630, loss: 0.07515175640583038
step: 640, loss: 0.1482117623090744
step: 650, loss: 0.1712672859430313
step: 660, loss: 0.1651432365179062
step: 670, loss: 0.1584002673625946
step: 680, loss: 0.12956355512142181
step: 690, loss: 0.29288750886917114
step: 700, loss: 0.07585401087999344
step: 710, loss: 0.12979546189308167
step: 720, loss: 0.13941264152526855
step: 730, loss: 0.12117725610733032
step: 740, loss: 0.17337559163570404
step: 750, loss: 0.4001127779483795
step: 760, loss: 0.07767610251903534
step: 770, loss: 0.15985436737537384
step: 780, loss: 0.16953274607658386
step: 790, loss: 0.20434360206127167
step: 800, loss: 0.2193499058485031
step: 810, loss: 0.08676587790250778
step: 820, loss: 0.0826057568192482
step: 830, loss: 0.04315178096294403
step: 840, loss: 0.1801425814628601
step: 850, loss: 0.1361565887928009
step: 860, loss: 0.15703056752681732
step: 870, loss: 0.09059277176856995
step: 880, loss: 0.14561881124973297
step: 890, loss: 0.09761425107717514
step: 900, loss: 0.08923769742250443
step: 910, loss: 0.271571546792984
step: 920, loss: 0.14323176443576813
step: 930, loss: 0.1233520656824112
step: 940, loss: 0.18931736052036285
step: 950, loss: 0.08286502957344055
step: 960, loss: 0.09413193166255951
step: 970, loss: 0.09823212772607803
step: 980, loss: 0.1308552473783493
step: 990, loss: 0.11710464209318161
step: 1000, loss: 0.25947093963623047
step: 1010, loss: 0.037654630839824677
step: 1020, loss: 0.08555521816015244
step: 1030, loss: 0.15001487731933594
step: 1040, loss: 0.15166494250297546
step: 1050, loss: 0.044241681694984436
step: 1060, loss: 0.14420531690120697
step: 1070, loss: 0.2746628522872925
epoch 1: dev_f1=0.9227906976744187, f1=0.9123783031988874, best_f1=0.9123783031988874
step: 0, loss: 0.11981970816850662
step: 10, loss: 0.07669508457183838
step: 20, loss: 0.10018843412399292
step: 30, loss: 0.08622623234987259
step: 40, loss: 0.12728363275527954
step: 50, loss: 0.09779532998800278
step: 60, loss: 0.11783763021230698
step: 70, loss: 0.11087267845869064
step: 80, loss: 0.08465494215488434
step: 90, loss: 0.13757646083831787
step: 100, loss: 0.1098312959074974
step: 110, loss: 0.07601596415042877
step: 120, loss: 0.07415138185024261
step: 130, loss: 0.1347336620092392
step: 140, loss: 0.011249260045588017
step: 150, loss: 0.1757584810256958
step: 160, loss: 0.10963834822177887
step: 170, loss: 0.15683291852474213
step: 180, loss: 0.13602179288864136
step: 190, loss: 0.07536455243825912
step: 200, loss: 0.21703870594501495
step: 210, loss: 0.0929526761174202
step: 220, loss: 0.08729330450296402
step: 230, loss: 0.142938032746315
step: 240, loss: 0.08979465812444687
step: 250, loss: 0.13761557638645172
step: 260, loss: 0.16300825774669647
step: 270, loss: 0.1166422963142395
step: 280, loss: 0.07379963994026184
step: 290, loss: 0.15775799751281738
step: 300, loss: 0.11050113290548325
step: 310, loss: 0.0448857806622982
step: 320, loss: 0.15531811118125916
step: 330, loss: 0.18681226670742035
step: 340, loss: 0.07719908654689789
step: 350, loss: 0.034377530217170715
step: 360, loss: 0.10667924582958221
step: 370, loss: 0.16306719183921814
step: 380, loss: 0.08396308869123459
step: 390, loss: 0.1908496469259262
step: 400, loss: 0.18151840567588806
step: 410, loss: 0.13367652893066406
step: 420, loss: 0.12417688220739365
step: 430, loss: 0.09903569519519806
step: 440, loss: 0.10128609836101532
step: 450, loss: 0.17584246397018433
step: 460, loss: 0.06487804651260376
step: 470, loss: 0.19333600997924805
step: 480, loss: 0.18997031450271606
step: 490, loss: 0.11642984300851822
step: 500, loss: 0.07350444793701172
step: 510, loss: 0.11955016106367111
step: 520, loss: 0.059890519827604294
step: 530, loss: 0.13639360666275024
step: 540, loss: 0.03876742720603943
step: 550, loss: 0.20214273035526276
step: 560, loss: 0.08696053177118301
step: 570, loss: 0.15459388494491577
step: 580, loss: 0.13024282455444336
step: 590, loss: 0.18441841006278992
step: 600, loss: 0.17289283871650696
step: 610, loss: 0.21431942284107208
step: 620, loss: 0.12233827263116837
step: 630, loss: 0.1249203011393547
step: 640, loss: 0.0696321353316307
step: 650, loss: 0.06869230419397354
step: 660, loss: 0.17877687513828278
step: 670, loss: 0.05832983925938606
step: 680, loss: 0.0942985787987709
step: 690, loss: 0.1590559482574463
step: 700, loss: 0.12058436870574951
step: 710, loss: 0.12262378633022308
step: 720, loss: 0.11713191866874695
step: 730, loss: 0.1149064302444458
step: 740, loss: 0.05944480746984482
step: 750, loss: 0.08902880549430847
step: 760, loss: 0.09943236410617828
step: 770, loss: 0.16280525922775269
step: 780, loss: 0.13014346361160278
step: 790, loss: 0.11539322882890701
step: 800, loss: 0.03263571485877037
step: 810, loss: 0.14090277254581451
step: 820, loss: 0.09683467447757721
step: 830, loss: 0.09559362381696701
step: 840, loss: 0.10089767724275589
step: 850, loss: 0.06760500371456146
step: 860, loss: 0.07538671791553497
step: 870, loss: 0.1677967756986618
step: 880, loss: 0.029831642284989357
step: 890, loss: 0.17518244683742523
step: 900, loss: 0.06962015479803085
step: 910, loss: 0.13955272734165192
step: 920, loss: 0.13303129374980927
step: 930, loss: 0.054242588579654694
step: 940, loss: 0.06398752331733704
step: 950, loss: 0.18988627195358276
step: 960, loss: 0.27874886989593506
step: 970, loss: 0.16071705520153046
step: 980, loss: 0.05879264697432518
step: 990, loss: 0.10085998475551605
step: 1000, loss: 0.1372324675321579
step: 1010, loss: 0.17314589023590088
step: 1020, loss: 0.14456874132156372
step: 1030, loss: 0.1657915562391281
step: 1040, loss: 0.18299253284931183
step: 1050, loss: 0.3901936113834381
step: 1060, loss: 0.19926640391349792
step: 1070, loss: 0.16747687757015228
epoch 2: dev_f1=0.9340710004610421, f1=0.9269195189639223, best_f1=0.9269195189639223
step: 0, loss: 0.053457193076610565
step: 10, loss: 0.09370111674070358
step: 20, loss: 0.1028633862733841
step: 30, loss: 0.2723311483860016
step: 40, loss: 0.11864686757326126
step: 50, loss: 0.05743096396327019
step: 60, loss: 0.10747647285461426
step: 70, loss: 0.072122722864151
step: 80, loss: 0.14447858929634094
step: 90, loss: 0.16215839982032776
step: 100, loss: 0.023360125720500946
step: 110, loss: 0.06160964071750641
step: 120, loss: 0.06425000727176666
step: 130, loss: 0.06907333433628082
step: 140, loss: 0.03927050530910492
step: 150, loss: 0.07672267407178879
step: 160, loss: 0.042187660932540894
step: 170, loss: 0.14181554317474365
step: 180, loss: 0.13006484508514404
step: 190, loss: 0.08760025352239609
step: 200, loss: 0.22527360916137695
step: 210, loss: 0.16860397160053253
step: 220, loss: 0.046507902443408966
step: 230, loss: 0.05019121617078781
step: 240, loss: 0.10740527510643005
step: 250, loss: 0.0823904499411583
step: 260, loss: 0.08525805175304413
step: 270, loss: 0.014435657300055027
step: 280, loss: 0.1808142215013504
step: 290, loss: 0.08701130002737045
step: 300, loss: 0.11041924357414246
step: 310, loss: 0.07389786839485168
step: 320, loss: 0.16830596327781677
step: 330, loss: 0.1494951993227005
step: 340, loss: 0.05194168910384178
step: 350, loss: 0.17021384835243225
step: 360, loss: 0.06210150569677353
step: 370, loss: 0.15408338606357574
step: 380, loss: 0.16567571461200714
step: 390, loss: 0.0854833647608757
step: 400, loss: 0.14976587891578674
step: 410, loss: 0.050601497292518616
step: 420, loss: 0.12134024500846863
step: 430, loss: 0.19309908151626587
step: 440, loss: 0.08038496971130371
step: 450, loss: 0.14918924868106842
step: 460, loss: 0.062279511243104935
step: 470, loss: 0.14217081665992737
step: 480, loss: 0.06639720499515533
step: 490, loss: 0.14488282799720764
step: 500, loss: 0.13020575046539307
step: 510, loss: 0.12095547467470169
step: 520, loss: 0.031354404985904694
step: 530, loss: 0.04244973510503769
step: 540, loss: 0.05565791204571724
step: 550, loss: 0.14741332828998566
step: 560, loss: 0.051597822457551956
step: 570, loss: 0.08884983509778976
step: 580, loss: 0.04837103933095932
step: 590, loss: 0.06465186178684235
step: 600, loss: 0.1031317263841629
step: 610, loss: 0.03922657296061516
step: 620, loss: 0.054828427731990814
step: 630, loss: 0.052823442965745926
step: 640, loss: 0.16473568975925446
step: 650, loss: 0.0407278798520565
step: 660, loss: 0.21006976068019867
step: 670, loss: 0.12791253626346588
step: 680, loss: 0.06346292793750763
step: 690, loss: 0.11182326078414917
step: 700, loss: 0.03090541437268257
step: 710, loss: 0.08008342981338501
step: 720, loss: 0.08695404976606369
step: 730, loss: 0.2264847755432129
step: 740, loss: 0.11351563036441803
step: 750, loss: 0.04372446984052658
step: 760, loss: 0.1065470427274704
step: 770, loss: 0.07257494330406189
step: 780, loss: 0.061358071863651276
step: 790, loss: 0.1850053369998932
step: 800, loss: 0.08970587700605392
step: 810, loss: 0.18206460773944855
step: 820, loss: 0.1368793547153473
step: 830, loss: 0.038716092705726624
step: 840, loss: 0.060303907841444016
step: 850, loss: 0.11130259931087494
step: 860, loss: 0.21880459785461426
step: 870, loss: 0.11085991561412811
step: 880, loss: 0.1298772543668747
step: 890, loss: 0.06995943933725357
step: 900, loss: 0.0922282412648201
step: 910, loss: 0.12632392346858978
step: 920, loss: 0.06976805627346039
step: 930, loss: 0.037869177758693695
step: 940, loss: 0.25155872106552124
step: 950, loss: 0.14101846516132355
step: 960, loss: 0.05479615554213524
step: 970, loss: 0.34724223613739014
step: 980, loss: 0.1617540568113327
step: 990, loss: 0.07726388424634933
step: 1000, loss: 0.07335880398750305
step: 1010, loss: 0.07969412207603455
step: 1020, loss: 0.029409026727080345
step: 1030, loss: 0.03952936455607414
step: 1040, loss: 0.15525606274604797
step: 1050, loss: 0.04649202525615692
step: 1060, loss: 0.12652912735939026
step: 1070, loss: 0.12635143101215363
epoch 3: dev_f1=0.9294990723562152, f1=0.9235074626865672, best_f1=0.9269195189639223
step: 0, loss: 0.03568887710571289
step: 10, loss: 0.06558631360530853
step: 20, loss: 0.06836305558681488
step: 30, loss: 0.006688405759632587
step: 40, loss: 0.03608369454741478
step: 50, loss: 0.1197584941983223
step: 60, loss: 0.11725809425115585
step: 70, loss: 0.03857727348804474
step: 80, loss: 0.11047983169555664
step: 90, loss: 0.08661624044179916
step: 100, loss: 0.12034264951944351
step: 110, loss: 0.27313029766082764
step: 120, loss: 0.05756794661283493
step: 130, loss: 0.033887431025505066
step: 140, loss: 0.11720835417509079
step: 150, loss: 0.09647313505411148
step: 160, loss: 0.1472374051809311
step: 170, loss: 0.17220564186573029
step: 180, loss: 0.06366338580846786
step: 190, loss: 0.10782787948846817
step: 200, loss: 0.03856329247355461
step: 210, loss: 0.09994757175445557
step: 220, loss: 0.09097471833229065
step: 230, loss: 0.11243128031492233
step: 240, loss: 0.00791091937571764
step: 250, loss: 0.037534695118665695
step: 260, loss: 0.1837637722492218
step: 270, loss: 0.021157221868634224
step: 280, loss: 0.10420776158571243
step: 290, loss: 0.0423504039645195
step: 300, loss: 0.017396576702594757
step: 310, loss: 0.04064808413386345
step: 320, loss: 0.10003692656755447
step: 330, loss: 0.07183852046728134
step: 340, loss: 0.10506057739257812
step: 350, loss: 0.0875178799033165
step: 360, loss: 0.0847158432006836
step: 370, loss: 0.07530064135789871
step: 380, loss: 0.18000197410583496
step: 390, loss: 0.21123965084552765
step: 400, loss: 0.09134160727262497
step: 410, loss: 0.07406332343816757
step: 420, loss: 0.03503948822617531
step: 430, loss: 0.11555192619562149
step: 440, loss: 0.12903955578804016
step: 450, loss: 0.10183344781398773
step: 460, loss: 0.08057105541229248
step: 470, loss: 0.14354050159454346
step: 480, loss: 0.09645672142505646
step: 490, loss: 0.01983143761754036
step: 500, loss: 0.022556599229574203
step: 510, loss: 0.08976975828409195
step: 520, loss: 0.04568331688642502
step: 530, loss: 0.048188965767621994
step: 540, loss: 0.07026033103466034
step: 550, loss: 0.05836573243141174
step: 560, loss: 0.1448373794555664
step: 570, loss: 0.0818219929933548
step: 580, loss: 0.11136908084154129
step: 590, loss: 0.11305715888738632
step: 600, loss: 0.11620581150054932
step: 610, loss: 0.05725919455289841
step: 620, loss: 0.06010572239756584
step: 630, loss: 0.055519748479127884
step: 640, loss: 0.039156075567007065
step: 650, loss: 0.06809031218290329
step: 660, loss: 0.10702544450759888
step: 670, loss: 0.09857673197984695
step: 680, loss: 0.05133657902479172
step: 690, loss: 0.16559752821922302
step: 700, loss: 0.07870935648679733
step: 710, loss: 0.13730783760547638
step: 720, loss: 0.08651062846183777
step: 730, loss: 0.0489618293941021
step: 740, loss: 0.06034300848841667
step: 750, loss: 0.1817520260810852
step: 760, loss: 0.14912337064743042
step: 770, loss: 0.07760971784591675
step: 780, loss: 0.03395906835794449
step: 790, loss: 0.0900065079331398
step: 800, loss: 0.06368104368448257
step: 810, loss: 0.16110491752624512
step: 820, loss: 0.07590142637491226
step: 830, loss: 0.11333675682544708
step: 840, loss: 0.10566478222608566
step: 850, loss: 0.09218167513608932
step: 860, loss: 0.024392304942011833
step: 870, loss: 0.10280214995145798
step: 880, loss: 0.09410873055458069
step: 890, loss: 0.05581345409154892
step: 900, loss: 0.11579194664955139
step: 910, loss: 0.04677363485097885
step: 920, loss: 0.1378934681415558
step: 930, loss: 0.0366477333009243
step: 940, loss: 0.06642898172140121
step: 950, loss: 0.03397826477885246
step: 960, loss: 0.07668871432542801
step: 970, loss: 0.11698980629444122
step: 980, loss: 0.02139195427298546
step: 990, loss: 0.06898349523544312
step: 1000, loss: 0.13435955345630646
step: 1010, loss: 0.03562929108738899
step: 1020, loss: 0.09561338275671005
step: 1030, loss: 0.13003021478652954
step: 1040, loss: 0.011411328800022602
step: 1050, loss: 0.05088021606206894
step: 1060, loss: 0.10750873386859894
step: 1070, loss: 0.20303286612033844
epoch 4: dev_f1=0.9310504396112911, f1=0.9218604651162791, best_f1=0.9269195189639223
step: 0, loss: 0.04680913686752319
step: 10, loss: 0.024930935353040695
step: 20, loss: 0.05771196633577347
step: 30, loss: 0.020574236288666725
step: 40, loss: 0.13848862051963806
step: 50, loss: 0.03010895475745201
step: 60, loss: 0.07259905338287354
step: 70, loss: 0.07553419470787048
step: 80, loss: 0.06038542091846466
step: 90, loss: 0.11387624591588974
step: 100, loss: 0.05753066763281822
step: 110, loss: 0.04294305667281151
step: 120, loss: 0.18432196974754333
step: 130, loss: 0.037530072033405304
step: 140, loss: 0.13937968015670776
step: 150, loss: 0.020192984491586685
step: 160, loss: 0.059943292289972305
step: 170, loss: 0.060897938907146454
step: 180, loss: 0.052395228296518326
step: 190, loss: 0.04897331818938255
step: 200, loss: 0.05310910567641258
step: 210, loss: 0.2448391616344452
step: 220, loss: 0.03896164521574974
step: 230, loss: 0.06477265805006027
step: 240, loss: 0.03348306566476822
step: 250, loss: 0.06925792247056961
step: 260, loss: 0.02680986002087593
step: 270, loss: 0.05370606482028961
step: 280, loss: 0.17573443055152893
step: 290, loss: 0.18901537358760834
step: 300, loss: 0.06055161729454994
step: 310, loss: 0.0925525650382042
step: 320, loss: 0.027761489152908325
step: 330, loss: 0.11032075434923172
step: 340, loss: 0.011465353891253471
step: 350, loss: 0.10536117851734161
step: 360, loss: 0.0482245609164238
step: 370, loss: 0.0399765782058239
step: 380, loss: 0.03530696779489517
step: 390, loss: 0.08852262794971466
step: 400, loss: 0.11196564882993698
step: 410, loss: 0.08500838279724121
step: 420, loss: 0.08353381603956223
step: 430, loss: 0.13156132400035858
step: 440, loss: 0.0166176650673151
step: 450, loss: 0.06312397867441177
step: 460, loss: 0.0906389132142067
step: 470, loss: 0.1224759966135025
step: 480, loss: 0.024520844221115112
step: 490, loss: 0.1173933669924736
step: 500, loss: 0.1445816606283188
step: 510, loss: 0.14166894555091858
step: 520, loss: 0.09996549785137177
step: 530, loss: 0.11153793334960938
step: 540, loss: 0.0479375496506691
step: 550, loss: 0.12451958656311035
step: 560, loss: 0.08572467416524887
step: 570, loss: 0.12277119606733322
step: 580, loss: 0.0538913756608963
step: 590, loss: 0.04351704567670822
step: 600, loss: 0.05316441133618355
step: 610, loss: 0.05774398520588875
step: 620, loss: 0.06169569119811058
step: 630, loss: 0.12056980282068253
step: 640, loss: 0.12023601680994034
step: 650, loss: 0.05038588494062424
step: 660, loss: 0.16126348078250885
step: 670, loss: 0.0930141732096672
step: 680, loss: 0.1273978054523468
step: 690, loss: 0.07043898105621338
step: 700, loss: 0.0747586265206337
step: 710, loss: 0.0262170247733593
step: 720, loss: 0.14993631839752197
step: 730, loss: 0.037664543837308884
step: 740, loss: 0.12294727563858032
step: 750, loss: 0.03241642937064171
step: 760, loss: 0.12190494686365128
step: 770, loss: 0.04036542773246765
step: 780, loss: 0.10612805932760239
step: 790, loss: 0.11589498817920685
step: 800, loss: 0.011471794918179512
step: 810, loss: 0.13555383682250977
step: 820, loss: 0.1920245885848999
step: 830, loss: 0.08529531210660934
step: 840, loss: 0.07650996744632721
step: 850, loss: 0.06482090801000595
step: 860, loss: 0.034639280289411545
step: 870, loss: 0.007794972043484449
step: 880, loss: 0.07279606908559799
step: 890, loss: 0.010771876201033592
step: 900, loss: 0.07480360567569733
step: 910, loss: 0.05092554911971092
step: 920, loss: 0.05684966966509819
step: 930, loss: 0.005340295378118753
step: 940, loss: 0.016213376075029373
step: 950, loss: 0.09191765636205673
step: 960, loss: 0.1659197211265564
step: 970, loss: 0.08927173912525177
step: 980, loss: 0.08819480240345001
step: 990, loss: 0.06120605766773224
step: 1000, loss: 0.09679152816534042
step: 1010, loss: 0.0993221178650856
step: 1020, loss: 0.12021996825933456
step: 1030, loss: 0.07167968899011612
step: 1040, loss: 0.09907127916812897
step: 1050, loss: 0.08372105658054352
step: 1060, loss: 0.11663398891687393
step: 1070, loss: 0.1439618617296219
epoch 5: dev_f1=0.9337626494940202, f1=0.9262482821804855, best_f1=0.9269195189639223
step: 0, loss: 0.009466513991355896
step: 10, loss: 0.12097755819559097
step: 20, loss: 0.1497282236814499
step: 30, loss: 0.0424908772110939
step: 40, loss: 0.0719456598162651
step: 50, loss: 0.20984071493148804
step: 60, loss: 0.09449650347232819
step: 70, loss: 0.100460946559906
step: 80, loss: 0.0754753053188324
step: 90, loss: 0.037884656339883804
step: 100, loss: 0.08841793239116669
step: 110, loss: 0.09923911839723587
step: 120, loss: 0.09482812881469727
step: 130, loss: 0.18428324162960052
step: 140, loss: 0.09059163928031921
step: 150, loss: 0.11487964540719986
step: 160, loss: 0.14528018236160278
step: 170, loss: 0.13016819953918457
step: 180, loss: 0.113890640437603
step: 190, loss: 0.04444248974323273
step: 200, loss: 0.11195585131645203
step: 210, loss: 0.05052543431520462
step: 220, loss: 0.08549431711435318
step: 230, loss: 0.040069907903671265
step: 240, loss: 0.11891946941614151
step: 250, loss: 0.15381057560443878
step: 260, loss: 0.018436485901474953
step: 270, loss: 0.08261322975158691
step: 280, loss: 0.07102206349372864
step: 290, loss: 0.06370346248149872
step: 300, loss: 0.04202359542250633
step: 310, loss: 0.11589252203702927
step: 320, loss: 0.1149647906422615
step: 330, loss: 0.08970455825328827
step: 340, loss: 0.14763225615024567
step: 350, loss: 0.1494072526693344
step: 360, loss: 0.07621137797832489
step: 370, loss: 0.01868838630616665
step: 380, loss: 0.014228098094463348
step: 390, loss: 0.039009515196084976
step: 400, loss: 0.08684021979570389
step: 410, loss: 0.09374672174453735
step: 420, loss: 0.06500588357448578
step: 430, loss: 0.08926624804735184
step: 440, loss: 0.11115184426307678
step: 450, loss: 0.015889784321188927
step: 460, loss: 0.04316471517086029
step: 470, loss: 0.171230748295784
step: 480, loss: 0.05594952031970024
step: 490, loss: 0.10945553332567215
step: 500, loss: 0.09817461669445038
step: 510, loss: 0.009902899153530598
step: 520, loss: 0.201956644654274
step: 530, loss: 0.1246814951300621
step: 540, loss: 0.12626062333583832
step: 550, loss: 0.035412758588790894
step: 560, loss: 0.052718788385391235
step: 570, loss: 0.12311206012964249
step: 580, loss: 0.143196702003479
step: 590, loss: 0.12327224761247635
step: 600, loss: 0.11155708879232407
step: 610, loss: 0.03171524778008461
step: 620, loss: 0.04503034055233002
step: 630, loss: 0.10030171275138855
step: 640, loss: 0.056660499423742294
step: 650, loss: 0.01908508501946926
step: 660, loss: 0.04320746660232544
step: 670, loss: 0.11867795884609222
step: 680, loss: 0.20162326097488403
step: 690, loss: 0.0900072529911995
step: 700, loss: 0.07467257231473923
step: 710, loss: 0.09990231692790985
step: 720, loss: 0.08437377959489822
step: 730, loss: 0.06765527278184891
step: 740, loss: 0.018965980038046837
step: 750, loss: 0.15413358807563782
step: 760, loss: 0.08451895415782928
step: 770, loss: 0.14880867302417755
step: 780, loss: 0.11164127290248871
step: 790, loss: 0.06850343197584152
step: 800, loss: 0.08647635579109192
step: 810, loss: 0.2356642484664917
step: 820, loss: 0.0877169668674469
step: 830, loss: 0.07675544172525406
step: 840, loss: 0.06041288748383522
step: 850, loss: 0.06858426332473755
step: 860, loss: 0.027276180684566498
step: 870, loss: 0.0998835563659668
step: 880, loss: 0.05149691179394722
step: 890, loss: 0.07320097088813782
step: 900, loss: 0.07406739145517349
step: 910, loss: 0.02935648337006569
step: 920, loss: 0.44248852133750916
step: 930, loss: 0.08115938305854797
step: 940, loss: 0.10399120301008224
step: 950, loss: 0.10165289044380188
step: 960, loss: 0.2075844556093216
step: 970, loss: 0.09248840808868408
step: 980, loss: 0.16458408534526825
step: 990, loss: 0.09808433800935745
step: 1000, loss: 0.09820666164159775
step: 1010, loss: 0.06968524307012558
step: 1020, loss: 0.1035226359963417
step: 1030, loss: 0.09403999894857407
step: 1040, loss: 0.09946325421333313
step: 1050, loss: 0.10942859947681427
step: 1060, loss: 0.1222466379404068
step: 1070, loss: 0.04509545490145683
epoch 6: dev_f1=0.9245372567631704, f1=0.9253447456015217, best_f1=0.9269195189639223
step: 0, loss: 0.034635093063116074
step: 10, loss: 0.07466356456279755
step: 20, loss: 0.11477379500865936
step: 30, loss: 0.02504812926054001
step: 40, loss: 0.020352892577648163
step: 50, loss: 0.03032183274626732
step: 60, loss: 0.0449804924428463
step: 70, loss: 0.07916944473981857
step: 80, loss: 0.12915484607219696
step: 90, loss: 0.10850393772125244
step: 100, loss: 0.0922621563076973
step: 110, loss: 0.0016047923127189279
step: 120, loss: 0.09762424230575562
step: 130, loss: 0.10864131897687912
step: 140, loss: 0.11067146062850952
step: 150, loss: 0.0021225460804998875
step: 160, loss: 0.1012665331363678
step: 170, loss: 0.049125995486974716
step: 180, loss: 0.04733976349234581
step: 190, loss: 0.03418631851673126
step: 200, loss: 0.10975182801485062
step: 210, loss: 0.07385938614606857
step: 220, loss: 0.09072517603635788
step: 230, loss: 0.1402536779642105
step: 240, loss: 0.07030055671930313
step: 250, loss: 0.19216813147068024
step: 260, loss: 0.07003411650657654
step: 270, loss: 0.1250709891319275
step: 280, loss: 0.01924256607890129
step: 290, loss: 0.07498428225517273
step: 300, loss: 0.05741360783576965
step: 310, loss: 0.07356089353561401
step: 320, loss: 0.07482709735631943
step: 330, loss: 0.15263929963111877
step: 340, loss: 0.13664650917053223
step: 350, loss: 0.15303224325180054
step: 360, loss: 0.18931396305561066
step: 370, loss: 0.041756752878427505
step: 380, loss: 0.10635104030370712
step: 390, loss: 0.08204787224531174
step: 400, loss: 0.08488566428422928
step: 410, loss: 0.0855768695473671
step: 420, loss: 0.1465199738740921
step: 430, loss: 0.12862950563430786
step: 440, loss: 0.07709143310785294
step: 450, loss: 0.04457353428006172
step: 460, loss: 0.1513417363166809
step: 470, loss: 0.06769753992557526
step: 480, loss: 0.11649361997842789
step: 490, loss: 0.2185114622116089
step: 500, loss: 0.0746287927031517
step: 510, loss: 0.057698655873537064
step: 520, loss: 0.06779316067695618
step: 530, loss: 0.067898690700531
step: 540, loss: 0.0657811090350151
step: 550, loss: 0.11338440328836441
step: 560, loss: 0.12810884416103363
step: 570, loss: 0.12247424572706223
step: 580, loss: 0.037476059049367905
step: 590, loss: 0.05828501284122467
step: 600, loss: 0.10732941329479218
step: 610, loss: 0.16385959088802338
step: 620, loss: 0.04828852415084839
step: 630, loss: 0.10269490629434586
step: 640, loss: 0.01201357040554285
step: 650, loss: 0.19721508026123047
step: 660, loss: 0.03844209760427475
step: 670, loss: 0.06134706363081932
step: 680, loss: 0.14100927114486694
step: 690, loss: 0.038802001625299454
step: 700, loss: 0.10411668568849564
step: 710, loss: 0.07179369032382965
step: 720, loss: 0.2132761925458908
step: 730, loss: 0.20413465797901154
step: 740, loss: 0.047808483242988586
step: 750, loss: 0.06479302793741226
step: 760, loss: 0.04156889021396637
step: 770, loss: 0.13264355063438416
step: 780, loss: 0.1316758543252945
step: 790, loss: 0.19539198279380798
step: 800, loss: 0.17464718222618103
step: 810, loss: 0.04421690106391907
step: 820, loss: 0.08507397025823593
step: 830, loss: 0.10486890375614166
step: 840, loss: 0.007909931242465973
step: 850, loss: 0.15956848859786987
step: 860, loss: 0.07252395153045654
step: 870, loss: 0.03484680503606796
step: 880, loss: 0.06201194226741791
step: 890, loss: 0.07160520553588867
step: 900, loss: 0.1356189250946045
step: 910, loss: 0.018165772780776024
step: 920, loss: 0.019937556236982346
step: 930, loss: 0.09302331507205963
step: 940, loss: 0.08088994771242142
step: 950, loss: 0.07118526101112366
step: 960, loss: 0.05686599016189575
step: 970, loss: 0.048095136880874634
step: 980, loss: 0.07601270824670792
step: 990, loss: 0.018920930102467537
step: 1000, loss: 0.11347472667694092
step: 1010, loss: 0.10154931247234344
step: 1020, loss: 0.1813485473394394
step: 1030, loss: 0.15753139555454254
step: 1040, loss: 0.06107863038778305
step: 1050, loss: 0.15310901403427124
step: 1060, loss: 0.08785995095968246
step: 1070, loss: 0.06929849833250046
epoch 7: dev_f1=0.9261176470588235, f1=0.9182033096926715, best_f1=0.9269195189639223
step: 0, loss: 0.08997059613466263
step: 10, loss: 0.015535120852291584
step: 20, loss: 0.01695498824119568
step: 30, loss: 0.038362376391887665
step: 40, loss: 0.04225851967930794
step: 50, loss: 0.11095549911260605
step: 60, loss: 0.0858667865395546
step: 70, loss: 0.03227795660495758
step: 80, loss: 0.1653890162706375
step: 90, loss: 0.05204273387789726
step: 100, loss: 0.11093850433826447
step: 110, loss: 0.08725274354219437
step: 120, loss: 0.09288188070058823
step: 130, loss: 0.01671735756099224
step: 140, loss: 0.04185419902205467
step: 150, loss: 0.09404881298542023
step: 160, loss: 0.11873925477266312
step: 170, loss: 0.043065790086984634
step: 180, loss: 0.10975789278745651
step: 190, loss: 0.06793434917926788
step: 200, loss: 0.11355803161859512
step: 210, loss: 0.058234505355358124
step: 220, loss: 0.10764960944652557
step: 230, loss: 0.03067757934331894
step: 240, loss: 0.14458110928535461
step: 250, loss: 0.04716534540057182
step: 260, loss: 0.049541324377059937
step: 270, loss: 0.05426860600709915
step: 280, loss: 0.1271190345287323
step: 290, loss: 0.06414337456226349
step: 300, loss: 0.02834419533610344
step: 310, loss: 0.04496374353766441
step: 320, loss: 0.12136508524417877
step: 330, loss: 0.09261567145586014
step: 340, loss: 0.049087394028902054
step: 350, loss: 0.11066114902496338
step: 360, loss: 0.07191582769155502
step: 370, loss: 0.055936548858881
step: 380, loss: 0.01949041523039341
step: 390, loss: 0.1366243064403534
step: 400, loss: 0.11043053865432739
step: 410, loss: 0.12430795282125473
step: 420, loss: 0.13672855496406555
step: 430, loss: 0.1884695440530777
step: 440, loss: 0.08110423386096954
step: 450, loss: 0.033175040036439896
step: 460, loss: 0.025662211701273918
step: 470, loss: 0.11332713812589645
step: 480, loss: 0.07198162376880646
step: 490, loss: 0.017382340505719185
step: 500, loss: 0.08183347433805466
step: 510, loss: 0.029888756573200226
step: 520, loss: 0.102076455950737
step: 530, loss: 0.09595491737127304
step: 540, loss: 0.18578732013702393
step: 550, loss: 0.1687898188829422
step: 560, loss: 0.07552623748779297
step: 570, loss: 0.11911047250032425
step: 580, loss: 0.03269190341234207
step: 590, loss: 0.11842410266399384
step: 600, loss: 0.0871569886803627
step: 610, loss: 0.08376623690128326
step: 620, loss: 0.14659561216831207
step: 630, loss: 0.03621069714426994
step: 640, loss: 0.05146094784140587
step: 650, loss: 0.14038018882274628
step: 660, loss: 0.043414775282144547
step: 670, loss: 0.17567017674446106
step: 680, loss: 0.10328533500432968
step: 690, loss: 0.020945215597748756
step: 700, loss: 0.09804339706897736
step: 710, loss: 0.09366562962532043
step: 720, loss: 0.013913804665207863
step: 730, loss: 0.1381019949913025
step: 740, loss: 0.1034868061542511
step: 750, loss: 0.1025574654340744
step: 760, loss: 0.016302283853292465
step: 770, loss: 0.011299792677164078
step: 780, loss: 0.10254783183336258
step: 790, loss: 0.03907303139567375
step: 800, loss: 0.14052584767341614
step: 810, loss: 0.08756940811872482
step: 820, loss: 0.14440929889678955
step: 830, loss: 0.024398861452937126
step: 840, loss: 0.06178047135472298
step: 850, loss: 0.0727214515209198
step: 860, loss: 0.002572650322690606
step: 870, loss: 0.005001291632652283
step: 880, loss: 0.10630432516336441
step: 890, loss: 0.0600040964782238
step: 900, loss: 0.0988437756896019
step: 910, loss: 0.024654818698763847
step: 920, loss: 0.058319251984357834
step: 930, loss: 0.029911670833826065
step: 940, loss: 0.02458871155977249
step: 950, loss: 0.0003303897683508694
step: 960, loss: 0.07358940690755844
step: 970, loss: 0.06168290972709656
step: 980, loss: 0.1272176057100296
step: 990, loss: 0.05516659840941429
step: 1000, loss: 0.11184011399745941
step: 1010, loss: 0.025422487407922745
step: 1020, loss: 0.07298318296670914
step: 1030, loss: 0.007349059451371431
step: 1040, loss: 0.05494438111782074
step: 1050, loss: 0.1148420199751854
step: 1060, loss: 0.02784433588385582
step: 1070, loss: 0.010848578996956348
epoch 8: dev_f1=0.9327691584391161, f1=0.9327691584391161, best_f1=0.9269195189639223
step: 0, loss: 0.06767869740724564
step: 10, loss: 0.06757159531116486
step: 20, loss: 0.058288346976041794
step: 30, loss: 0.030558660626411438
step: 40, loss: 0.16160571575164795
step: 50, loss: 0.07787802070379257
step: 60, loss: 0.038981806486845016
step: 70, loss: 0.10227134078741074
step: 80, loss: 0.03419293835759163
step: 90, loss: 0.05489636957645416
step: 100, loss: 0.04970540851354599
step: 110, loss: 0.058653075248003006
step: 120, loss: 0.011320894584059715
step: 130, loss: 0.016205616295337677
step: 140, loss: 0.032582588493824005
step: 150, loss: 0.056186072528362274
step: 160, loss: 0.11843185126781464
step: 170, loss: 0.13457465171813965
step: 180, loss: 0.06461246311664581
step: 190, loss: 0.016537372022867203
step: 200, loss: 0.08292000740766525
step: 210, loss: 0.08728134632110596
step: 220, loss: 0.1999984234571457
step: 230, loss: 0.09239251166582108
step: 240, loss: 0.0704636499285698
step: 250, loss: 0.011914827860891819
step: 260, loss: 0.027493005618453026
step: 270, loss: 0.12834392488002777
step: 280, loss: 0.01320917159318924
step: 290, loss: 0.1098603755235672
step: 300, loss: 0.11964116245508194
step: 310, loss: 0.08281039446592331
step: 320, loss: 0.008130906149744987
step: 330, loss: 0.0645768791437149
step: 340, loss: 0.03947307541966438
step: 350, loss: 0.11423797160387039
step: 360, loss: 0.04326649755239487
step: 370, loss: 0.013899104669690132
step: 380, loss: 0.1258537322282791
step: 390, loss: 0.06998499482870102
step: 400, loss: 0.04702483117580414
step: 410, loss: 0.11628532409667969
step: 420, loss: 0.04244043305516243
step: 430, loss: 0.04840916395187378
step: 440, loss: 0.016232993453741074
step: 450, loss: 0.07644598931074142
step: 460, loss: 0.11662378162145615
step: 470, loss: 0.08105027675628662
step: 480, loss: 0.07702062278985977
step: 490, loss: 0.1864444762468338
step: 500, loss: 0.006070683244615793
step: 510, loss: 0.03314463049173355
step: 520, loss: 0.10507119446992874
step: 530, loss: 0.036740485578775406
step: 540, loss: 0.0029871403239667416
step: 550, loss: 0.043379899114370346
step: 560, loss: 0.1270415484905243
step: 570, loss: 0.009543092921376228
step: 580, loss: 0.11660309135913849
step: 590, loss: 0.07098519057035446
step: 600, loss: 0.08772485703229904
step: 610, loss: 0.00048608327051624656
step: 620, loss: 0.0641486793756485
step: 630, loss: 0.0387512631714344
step: 640, loss: 0.08755878359079361
step: 650, loss: 0.1135900691151619
step: 660, loss: 0.06932607293128967
step: 670, loss: 0.026056554168462753
step: 680, loss: 0.0652892142534256
step: 690, loss: 0.0704590231180191
step: 700, loss: 0.030212698504328728
step: 710, loss: 0.0023029441945254803
step: 720, loss: 0.021525543183088303
step: 730, loss: 0.11465463042259216
step: 740, loss: 0.023803723976016045
step: 750, loss: 0.07428324222564697
step: 760, loss: 0.020367156714200974
step: 770, loss: 0.13111406564712524
step: 780, loss: 0.12919598817825317
step: 790, loss: 0.032574139535427094
step: 800, loss: 0.05068677291274071
step: 810, loss: 0.10266295075416565
step: 820, loss: 0.16747938096523285
step: 830, loss: 0.07106266170740128
step: 840, loss: 0.05589279159903526
step: 850, loss: 0.023405829444527626
step: 860, loss: 0.06955872476100922
step: 870, loss: 0.07196077704429626
step: 880, loss: 0.026516098529100418
step: 890, loss: 0.2425587773323059
step: 900, loss: 0.11147203296422958
step: 910, loss: 0.21791580319404602
step: 920, loss: 0.06773238629102707
step: 930, loss: 0.06389601528644562
step: 940, loss: 0.06849473714828491
step: 950, loss: 0.07582728564739227
step: 960, loss: 0.05489892140030861
step: 970, loss: 0.034008193761110306
step: 980, loss: 0.21762722730636597
step: 990, loss: 0.05317443609237671
step: 1000, loss: 0.10383035242557526
step: 1010, loss: 0.054058536887168884
step: 1020, loss: 0.05873996019363403
step: 1030, loss: 0.06291474401950836
step: 1040, loss: 0.1169472485780716
step: 1050, loss: 0.1291070282459259
step: 1060, loss: 0.11214837431907654
step: 1070, loss: 0.24368731677532196
epoch 9: dev_f1=0.933826931975937, f1=0.9294990723562152, best_f1=0.9269195189639223
step: 0, loss: 0.07512923330068588
step: 10, loss: 0.07712304592132568
step: 20, loss: 0.07357148826122284
step: 30, loss: 0.037612784653902054
step: 40, loss: 0.05121740698814392
step: 50, loss: 0.20391134917736053
step: 60, loss: 0.11365547776222229
step: 70, loss: 0.030861685052514076
step: 80, loss: 0.06481048464775085
step: 90, loss: 0.06899258494377136
step: 100, loss: 0.041729386895895004
step: 110, loss: 0.010856499895453453
step: 120, loss: 0.15087400376796722
step: 130, loss: 0.09907141327857971
step: 140, loss: 0.058138616383075714
step: 150, loss: 0.015125512145459652
step: 160, loss: 0.18451960384845734
step: 170, loss: 0.1502930074930191
step: 180, loss: 0.10083118081092834
step: 190, loss: 0.038362424820661545
step: 200, loss: 0.17608067393302917
step: 210, loss: 0.044362787157297134
step: 220, loss: 0.0058624777011573315
step: 230, loss: 0.06293855607509613
step: 240, loss: 0.05555111542344093
step: 250, loss: 0.05963650345802307
step: 260, loss: 0.038647282868623734
step: 270, loss: 0.0508880689740181
step: 280, loss: 0.09821818768978119
step: 290, loss: 0.0539705865085125
step: 300, loss: 0.0063409325666725636
step: 310, loss: 0.06058928743004799
step: 320, loss: 0.14634978771209717
step: 330, loss: 0.08720368146896362
step: 340, loss: 0.0707232803106308
step: 350, loss: 0.08412393927574158
step: 360, loss: 0.11345218867063522
step: 370, loss: 0.07344163954257965
step: 380, loss: 0.04883483052253723
step: 390, loss: 0.11233638972043991
step: 400, loss: 0.17670471966266632
step: 410, loss: 0.05316372960805893
step: 420, loss: 0.1573665291070938
step: 430, loss: 0.05867192521691322
step: 440, loss: 0.08513683825731277
step: 450, loss: 0.2676214575767517
step: 460, loss: 0.033508967608213425
step: 470, loss: 0.08235213160514832
step: 480, loss: 0.020695503801107407
step: 490, loss: 0.04025616869330406
step: 500, loss: 0.07417557388544083
step: 510, loss: 0.018251918256282806
step: 520, loss: 0.377664178609848
step: 530, loss: 0.045756272971630096
step: 540, loss: 0.03098372183740139
step: 550, loss: 0.04959039390087128
step: 560, loss: 0.0438920259475708
step: 570, loss: 0.05274704843759537
step: 580, loss: 0.022719351574778557
step: 590, loss: 0.05401031672954559
step: 600, loss: 0.08613615483045578
step: 610, loss: 0.10953716933727264
step: 620, loss: 0.09779080003499985
step: 630, loss: 0.009083103388547897
step: 640, loss: 0.0412471629679203
step: 650, loss: 0.12115730345249176
step: 660, loss: 0.0268191359937191
step: 670, loss: 0.0665428638458252
step: 680, loss: 0.07427351921796799
step: 690, loss: 0.18935421109199524
step: 700, loss: 0.06080660596489906
step: 710, loss: 0.13218721747398376
step: 720, loss: 0.024220088496804237
step: 730, loss: 0.0465116947889328
step: 740, loss: 0.0704316645860672
step: 750, loss: 0.06486332416534424
step: 760, loss: 0.02780301496386528
step: 770, loss: 0.16155987977981567
step: 780, loss: 0.04198966547846794
step: 790, loss: 0.06173674017190933
step: 800, loss: 0.11981445550918579
step: 810, loss: 0.004244661889970303
step: 820, loss: 0.027516823261976242
step: 830, loss: 0.08194651454687119
step: 840, loss: 0.1409899741411209
step: 850, loss: 0.09406290203332901
step: 860, loss: 0.07752565294504166
step: 870, loss: 0.1508655846118927
step: 880, loss: 0.06968352198600769
step: 890, loss: 0.12109997868537903
step: 900, loss: 0.12561309337615967
step: 910, loss: 0.08206000179052353
step: 920, loss: 0.08712855726480484
step: 930, loss: 0.030043911188840866
step: 940, loss: 0.049106284976005554
step: 950, loss: 0.09860222786664963
step: 960, loss: 0.054281726479530334
step: 970, loss: 0.08684705942869186
step: 980, loss: 0.05283435434103012
step: 990, loss: 0.03755741938948631
step: 1000, loss: 0.05238217115402222
step: 1010, loss: 0.07262607663869858
step: 1020, loss: 0.08908845484256744
step: 1030, loss: 0.06299027055501938
step: 1040, loss: 0.10013248771429062
step: 1050, loss: 0.10234249383211136
step: 1060, loss: 0.12503129243850708
step: 1070, loss: 0.008202820084989071
epoch 10: dev_f1=0.930341280972417, f1=0.9234382339126351, best_f1=0.9269195189639223
step: 0, loss: 0.08682771027088165
step: 10, loss: 0.0695984810590744
step: 20, loss: 0.0001308518258156255
step: 30, loss: 0.0038832472637295723
step: 40, loss: 0.04860755056142807
step: 50, loss: 0.14179052412509918
step: 60, loss: 0.038775522261857986
step: 70, loss: 0.07766140252351761
step: 80, loss: 0.0816836729645729
step: 90, loss: 0.11171752214431763
step: 100, loss: 0.020799729973077774
step: 110, loss: 0.015019693411886692
step: 120, loss: 0.05257340520620346
step: 130, loss: 0.13295839726924896
step: 140, loss: 0.022048793733119965
step: 150, loss: 0.02035508304834366
step: 160, loss: 0.09780021756887436
step: 170, loss: 0.09830709546804428
step: 180, loss: 0.05986911803483963
step: 190, loss: 0.05273569002747536
step: 200, loss: 0.09526685625314713
step: 210, loss: 0.14755035936832428
step: 220, loss: 0.0605587512254715
step: 230, loss: 0.05719734728336334
step: 240, loss: 0.1941622793674469
step: 250, loss: 0.027400175109505653
step: 260, loss: 0.004165905527770519
step: 270, loss: 0.012719492428004742
step: 280, loss: 0.09496061503887177
step: 290, loss: 0.09218049049377441
step: 300, loss: 0.027989208698272705
step: 310, loss: 0.062158480286598206
step: 320, loss: 0.0708889365196228
step: 330, loss: 0.06685362011194229
step: 340, loss: 0.021155422553420067
step: 350, loss: 0.056786973029375076
step: 360, loss: 0.11637696623802185
step: 370, loss: 0.07916237413883209
step: 380, loss: 0.03401122987270355
step: 390, loss: 0.03262999281287193
step: 400, loss: 0.11250820010900497
step: 410, loss: 0.07536584883928299
step: 420, loss: 0.0384957417845726
step: 430, loss: 0.06873589754104614
step: 440, loss: 0.08822556585073471
step: 450, loss: 0.022765612229704857
step: 460, loss: 0.16162751615047455
step: 470, loss: 0.03241069242358208
step: 480, loss: 0.02502540498971939
step: 490, loss: 0.011966890655457973
step: 500, loss: 0.09850256145000458
step: 510, loss: 0.03912563994526863
step: 520, loss: 0.029357481747865677
step: 530, loss: 0.07546676695346832
step: 540, loss: 0.0018342618132010102
step: 550, loss: 0.037606652826070786
step: 560, loss: 0.061117105185985565
step: 570, loss: 0.05356912314891815
step: 580, loss: 0.12762826681137085
step: 590, loss: 0.03417494520545006
step: 600, loss: 0.03196381404995918
step: 610, loss: 0.11133821308612823
step: 620, loss: 0.06754934787750244
step: 630, loss: 0.0751556009054184
step: 640, loss: 0.01542355865240097
step: 650, loss: 0.10892437398433685
step: 660, loss: 0.057863373309373856
step: 670, loss: 0.07025052607059479
step: 680, loss: 0.048050347715616226
step: 690, loss: 0.0184848103672266
step: 700, loss: 0.047061655670404434
step: 710, loss: 0.211622416973114
step: 720, loss: 0.018022973090410233
step: 730, loss: 0.09007813781499863
step: 740, loss: 0.07794247567653656
step: 750, loss: 0.03281669691205025
step: 760, loss: 0.000987264676950872
step: 770, loss: 0.02925632894039154
step: 780, loss: 0.10642975568771362
step: 790, loss: 0.05885826796293259
step: 800, loss: 0.0490591824054718
step: 810, loss: 0.02675027772784233
step: 820, loss: 0.05568104237318039
step: 830, loss: 0.08061442524194717
step: 840, loss: 0.01625479757785797
step: 850, loss: 0.031069455668330193
step: 860, loss: 0.06498146057128906
step: 870, loss: 0.059391193091869354
step: 880, loss: 0.07801499217748642
step: 890, loss: 0.047870878130197525
step: 900, loss: 0.02273293398320675
step: 910, loss: 1.4312447092379443e-05
step: 920, loss: 0.055325690656900406
step: 930, loss: 0.016224926337599754
step: 940, loss: 0.03749411553144455
step: 950, loss: 0.061489757150411606
step: 960, loss: 0.03591450676321983
step: 970, loss: 0.04522030055522919
step: 980, loss: 0.09190250188112259
step: 990, loss: 0.09138157963752747
step: 1000, loss: 0.0786237120628357
step: 1010, loss: 0.056777939200401306
step: 1020, loss: 0.15772108733654022
step: 1030, loss: 0.13562096655368805
step: 1040, loss: 0.04984085634350777
step: 1050, loss: 0.08154629915952682
step: 1060, loss: 0.07375212758779526
step: 1070, loss: 0.04179672524333
epoch 11: dev_f1=0.9403606102635228, f1=0.9279404927940492, best_f1=0.9279404927940492
step: 0, loss: 0.003651987062767148
step: 10, loss: 0.04832381382584572
step: 20, loss: 0.02102574333548546
step: 30, loss: 0.004162427969276905
step: 40, loss: 0.18391284346580505
step: 50, loss: 0.14059971272945404
step: 60, loss: 0.03534962236881256
step: 70, loss: 0.029849795624613762
step: 80, loss: 0.11572733521461487
step: 90, loss: 0.0038044508546590805
step: 100, loss: 0.12011650949716568
step: 110, loss: 0.059598129242658615
step: 120, loss: 0.03570151701569557
step: 130, loss: 0.018344802781939507
step: 140, loss: 0.08965498208999634
step: 150, loss: 0.07064345479011536
step: 160, loss: 0.047373443841934204
step: 170, loss: 0.032259728759527206
step: 180, loss: 0.17347487807273865
step: 190, loss: 0.13165640830993652
step: 200, loss: 0.044576846063137054
step: 210, loss: 0.048918288201093674
step: 220, loss: 0.06140077859163284
step: 230, loss: 0.09425631910562515
step: 240, loss: 0.0686560571193695
step: 250, loss: 0.027947552502155304
step: 260, loss: 0.027206018567085266
step: 270, loss: 0.07739654183387756
step: 280, loss: 0.07408434897661209
step: 290, loss: 0.08044296503067017
step: 300, loss: 0.09613997489213943
step: 310, loss: 0.0349465012550354
step: 320, loss: 0.18897520005702972
step: 330, loss: 0.07111833244562149
step: 340, loss: 0.12556593120098114
step: 350, loss: 0.049938686192035675
step: 360, loss: 0.049599457532167435
step: 370, loss: 0.12393876165151596
step: 380, loss: 0.09261832386255264
step: 390, loss: 0.03164784237742424
step: 400, loss: 0.022776074707508087
step: 410, loss: 0.05442657694220543
step: 420, loss: 0.05879712477326393
step: 430, loss: 0.03675971180200577
step: 440, loss: 0.1183190643787384
step: 450, loss: 0.13747934997081757
step: 460, loss: 0.10034966468811035
step: 470, loss: 0.005465024150907993
step: 480, loss: 0.06383178383111954
step: 490, loss: 0.06095506250858307
step: 500, loss: 0.08376043289899826
step: 510, loss: 0.08322478085756302
step: 520, loss: 0.05824664980173111
step: 530, loss: 0.027529675513505936
step: 540, loss: 0.05895740166306496
step: 550, loss: 0.1040472686290741
step: 560, loss: 0.06992207467556
step: 570, loss: 0.10913050174713135
step: 580, loss: 0.021304307505488396
step: 590, loss: 0.20346051454544067
step: 600, loss: 0.08492325991392136
step: 610, loss: 0.04275083914399147
step: 620, loss: 0.09152759611606598
step: 630, loss: 0.07236380875110626
step: 640, loss: 0.043204765766859055
step: 650, loss: 0.02085396833717823
step: 660, loss: 0.06145738810300827
step: 670, loss: 0.04221520572900772
step: 680, loss: 0.07496482133865356
step: 690, loss: 0.05876297503709793
step: 700, loss: 0.038970015943050385
step: 710, loss: 0.1289197951555252
step: 720, loss: 0.06261482834815979
step: 730, loss: 0.05718827247619629
step: 740, loss: 0.06010721996426582
step: 750, loss: 0.0228460431098938
step: 760, loss: 0.05378979444503784
step: 770, loss: 0.11002012342214584
step: 780, loss: 0.13597118854522705
step: 790, loss: 0.012390713207423687
step: 800, loss: 0.017255572602152824
step: 810, loss: 0.04911802336573601
step: 820, loss: 0.07120569050312042
step: 830, loss: 0.08489437401294708
step: 840, loss: 0.039551664143800735
step: 850, loss: 0.06819761544466019
step: 860, loss: 0.11060325056314468
step: 870, loss: 0.0654204785823822
step: 880, loss: 0.07045105844736099
step: 890, loss: 0.15408512949943542
step: 900, loss: 0.07648727297782898
step: 910, loss: 0.007799464277923107
step: 920, loss: 1.4781625395698939e-05
step: 930, loss: 0.04898204654455185
step: 940, loss: 0.05482296645641327
step: 950, loss: 0.05570777505636215
step: 960, loss: 0.06471313536167145
step: 970, loss: 0.05751872807741165
step: 980, loss: 0.034750256687402725
step: 990, loss: 0.07715781033039093
step: 1000, loss: 0.07665400952100754
step: 1010, loss: 0.0009062358876690269
step: 1020, loss: 0.05620342120528221
step: 1030, loss: 0.04096551612019539
step: 1040, loss: 0.022352732717990875
step: 1050, loss: 0.06109204888343811
step: 1060, loss: 0.05444002524018288
step: 1070, loss: 0.04186535254120827
epoch 12: dev_f1=0.9271028037383178, f1=0.9188935771214253, best_f1=0.9279404927940492
step: 0, loss: 0.0511397123336792
step: 10, loss: 0.07008463889360428
step: 20, loss: 0.07871844619512558
step: 30, loss: 0.05074264109134674
step: 40, loss: 0.0001739376166369766
step: 50, loss: 0.10531413555145264
step: 60, loss: 0.03271932527422905
step: 70, loss: 0.07966246455907822
step: 80, loss: 0.046261951327323914
step: 90, loss: 0.08554878830909729
step: 100, loss: 0.11606498807668686
step: 110, loss: 0.06823314726352692
step: 120, loss: 0.054610222578048706
step: 130, loss: 0.05871249735355377
step: 140, loss: 0.030245549976825714
step: 150, loss: 0.09060778468847275
step: 160, loss: 0.2324594408273697
step: 170, loss: 0.0792161300778389
step: 180, loss: 0.11709659546613693
step: 190, loss: 0.04025142639875412
step: 200, loss: 0.014113368466496468
step: 210, loss: 0.10823436081409454
step: 220, loss: 3.6887835449306294e-05
step: 230, loss: 0.08451078832149506
step: 240, loss: 0.0007604456041008234
step: 250, loss: 0.03329592943191528
step: 260, loss: 0.08900244534015656
step: 270, loss: 0.14378128945827484
step: 280, loss: 0.05982734635472298
step: 290, loss: 0.06331402063369751
step: 300, loss: 0.043618135154247284
step: 310, loss: 0.07386238873004913
step: 320, loss: 0.04927884787321091
step: 330, loss: 0.03206869214773178
step: 340, loss: 0.11782417446374893
step: 350, loss: 0.002524270676076412
step: 360, loss: 0.02632402628660202
step: 370, loss: 0.09684227406978607
step: 380, loss: 0.12750153243541718
step: 390, loss: 0.08665463328361511
step: 400, loss: 0.03509454429149628
step: 410, loss: 0.021658213809132576
step: 420, loss: 0.03246370702981949
step: 430, loss: 0.018583647906780243
step: 440, loss: 0.03122374787926674
step: 450, loss: 0.12116316705942154
step: 460, loss: 0.06390970200300217
step: 470, loss: 0.010599947534501553
step: 480, loss: 0.1920464187860489
step: 490, loss: 0.04739600419998169
step: 500, loss: 0.04269978031516075
step: 510, loss: 0.05430760607123375
step: 520, loss: 0.07231351733207703
step: 530, loss: 0.00948970764875412
step: 540, loss: 0.10407047718763351
step: 550, loss: 0.018721258267760277
step: 560, loss: 0.06073194742202759
step: 570, loss: 0.005313871428370476
step: 580, loss: 0.03714217618107796
step: 590, loss: 0.05360819026827812
step: 600, loss: 0.04015197232365608
step: 610, loss: 0.026751721277832985
step: 620, loss: 0.06093765050172806
step: 630, loss: 0.007203210610896349
step: 640, loss: 0.16343894600868225
step: 650, loss: 0.028589554131031036
step: 660, loss: 0.08950185775756836
step: 670, loss: 0.02066894620656967
step: 680, loss: 0.0929461196064949
step: 690, loss: 0.10946230590343475
step: 700, loss: 0.10266429930925369
step: 710, loss: 0.05066538229584694
step: 720, loss: 0.0029574984218925238
step: 730, loss: 0.10935186594724655
step: 740, loss: 0.023079408332705498
step: 750, loss: 0.028012806549668312
step: 760, loss: 0.047207061201334
step: 770, loss: 0.042902249842882156
step: 780, loss: 0.0423957034945488
step: 790, loss: 0.0581546314060688
step: 800, loss: 5.272218550089747e-05
step: 810, loss: 0.02320171147584915
step: 820, loss: 0.002321458188816905
step: 830, loss: 0.08355733007192612
step: 840, loss: 0.02280179224908352
step: 850, loss: 0.08782986551523209
step: 860, loss: 0.020063087344169617
step: 870, loss: 0.06147485971450806
step: 880, loss: 0.10331720113754272
step: 890, loss: 0.08800145983695984
step: 900, loss: 0.08381523936986923
step: 910, loss: 0.13244952261447906
step: 920, loss: 0.00402963487431407
step: 930, loss: 0.032420746982097626
step: 940, loss: 0.0009924463229253888
step: 950, loss: 0.08477675169706345
step: 960, loss: 0.09065669775009155
step: 970, loss: 0.0768204852938652
step: 980, loss: 0.06287690252065659
step: 990, loss: 0.02198098972439766
step: 1000, loss: 0.04744148626923561
step: 1010, loss: 0.06631740927696228
step: 1020, loss: 0.0695868581533432
step: 1030, loss: 0.019130075350403786
step: 1040, loss: 0.0884660929441452
step: 1050, loss: 0.034570951014757156
step: 1060, loss: 0.060504306107759476
step: 1070, loss: 0.09304700046777725
epoch 13: dev_f1=0.9338919925512105, f1=0.9237248479176415, best_f1=0.9279404927940492
step: 0, loss: 0.04519924521446228
step: 10, loss: 0.06717736274003983
step: 20, loss: 0.029662445187568665
step: 30, loss: 0.12322765588760376
step: 40, loss: 0.07809479534626007
step: 50, loss: 0.02331523410975933
step: 60, loss: 0.09689667075872421
step: 70, loss: 0.12146186828613281
step: 80, loss: 0.02145319990813732
step: 90, loss: 0.03594436123967171
step: 100, loss: 0.17464908957481384
step: 110, loss: 0.028475070372223854
step: 120, loss: 0.2173001915216446
step: 130, loss: 0.07418820261955261
step: 140, loss: 0.036666978150606155
step: 150, loss: 0.05447423458099365
step: 160, loss: 0.007712858263403177
step: 170, loss: 0.07497835159301758
step: 180, loss: 0.06886608898639679
step: 190, loss: 0.10184948891401291
step: 200, loss: 0.039459530264139175
step: 210, loss: 0.0759110227227211
step: 220, loss: 0.007741672918200493
step: 230, loss: 0.0758398175239563
step: 240, loss: 0.006738607306033373
step: 250, loss: 0.023171845823526382
step: 260, loss: 0.03458864241838455
step: 270, loss: 0.07459606230258942
step: 280, loss: 0.06353724747896194
step: 290, loss: 0.03529069200158119
step: 300, loss: 0.0831420049071312
step: 310, loss: 0.05410114303231239
step: 320, loss: 0.018773796036839485
step: 330, loss: 0.04900280758738518
step: 340, loss: 0.0030911837238818407
step: 350, loss: 0.005341391544789076
step: 360, loss: 0.10679736733436584
step: 370, loss: 0.036865152418613434
step: 380, loss: 0.008551564067602158
step: 390, loss: 0.011095328256487846
step: 400, loss: 0.02215931937098503
step: 410, loss: 0.05627378448843956
step: 420, loss: 0.10912737995386124
step: 430, loss: 0.021958233788609505
step: 440, loss: 0.08897531032562256
step: 450, loss: 0.017275255173444748
step: 460, loss: 0.02334480546414852
step: 470, loss: 0.04494345933198929
step: 480, loss: 0.07599501311779022
step: 490, loss: 0.07338424772024155
step: 500, loss: 0.03573198989033699
step: 510, loss: 0.02046295255422592
step: 520, loss: 0.01590863987803459
step: 530, loss: 0.01111364271491766
step: 540, loss: 0.007050156127661467
step: 550, loss: 0.027073942124843597
step: 560, loss: 0.0702609047293663
step: 570, loss: 0.02817019820213318
step: 580, loss: 0.06300017982721329
step: 590, loss: 0.03469868004322052
step: 600, loss: 0.05620657652616501
step: 610, loss: 0.01599930413067341
step: 620, loss: 0.017991414293646812
step: 630, loss: 0.004481692332774401
step: 640, loss: 0.08018125593662262
step: 650, loss: 0.01335621066391468
step: 660, loss: 0.07371186465024948
step: 670, loss: 0.0656181052327156
step: 680, loss: 0.07738570868968964
step: 690, loss: 0.04544765502214432
step: 700, loss: 0.0008119895937852561
step: 710, loss: 0.03797938674688339
step: 720, loss: 0.0016572974855080247
step: 730, loss: 0.011061424389481544
step: 740, loss: 8.79120925674215e-05
step: 750, loss: 0.0650610476732254
step: 760, loss: 0.03904685750603676
step: 770, loss: 0.034308385103940964
step: 780, loss: 0.02942766435444355
step: 790, loss: 0.10075470060110092
step: 800, loss: 0.05921858921647072
step: 810, loss: 0.07357852160930634
step: 820, loss: 0.25461575388908386
step: 830, loss: 0.07686023414134979
step: 840, loss: 0.05543842166662216
step: 850, loss: 0.005732269026339054
step: 860, loss: 0.020266691222786903
step: 870, loss: 0.07427816092967987
step: 880, loss: 0.030273959040641785
step: 890, loss: 0.04845176264643669
step: 900, loss: 0.035802677273750305
step: 910, loss: 0.08242380619049072
step: 920, loss: 0.030089382082223892
step: 930, loss: 0.15791259706020355
step: 940, loss: 0.061716705560684204
step: 950, loss: 0.02757595293223858
step: 960, loss: 0.12270592898130417
step: 970, loss: 0.06867095828056335
step: 980, loss: 0.022543255239725113
step: 990, loss: 0.040487054735422134
step: 1000, loss: 0.07048403471708298
step: 1010, loss: 0.12904274463653564
step: 1020, loss: 0.08499642461538315
step: 1030, loss: 0.03678027167916298
step: 1040, loss: 0.11514114588499069
step: 1050, loss: 0.09256505966186523
step: 1060, loss: 0.03653818368911743
step: 1070, loss: 0.0634932890534401
epoch 14: dev_f1=0.931711880261927, f1=0.9242990654205607, best_f1=0.9279404927940492
step: 0, loss: 0.03919164091348648
step: 10, loss: 0.024108055979013443
step: 20, loss: 0.06619702279567719
step: 30, loss: 0.08761516213417053
step: 40, loss: 0.030941711738705635
step: 50, loss: 0.016448242589831352
step: 60, loss: 0.026442088186740875
step: 70, loss: 0.0630204901099205
step: 80, loss: 0.04868984967470169
step: 90, loss: 3.691007805173285e-05
step: 100, loss: 0.052945639938116074
step: 110, loss: 0.026344070211052895
step: 120, loss: 0.013466457836329937
step: 130, loss: 0.013971094973385334
step: 140, loss: 0.02579575590789318
step: 150, loss: 0.029068177565932274
step: 160, loss: 0.0024028171319514513
step: 170, loss: 0.017329759895801544
step: 180, loss: 0.03799181804060936
step: 190, loss: 0.16346220672130585
step: 200, loss: 0.017431121319532394
step: 210, loss: 0.04867599159479141
step: 220, loss: 0.07471755146980286
step: 230, loss: 0.013862837105989456
step: 240, loss: 0.05630767345428467
step: 250, loss: 0.13867776095867157
step: 260, loss: 0.08870787173509598
step: 270, loss: 0.041668884456157684
step: 280, loss: 0.09429953247308731
step: 290, loss: 0.0002109791530529037
step: 300, loss: 0.0651543065905571
step: 310, loss: 0.11865067481994629
step: 320, loss: 0.059474848210811615
step: 330, loss: 0.12478043884038925
step: 340, loss: 0.03788570314645767
step: 350, loss: 0.025985080748796463
step: 360, loss: 0.05110961198806763
step: 370, loss: 0.24148985743522644
step: 380, loss: 0.016162114217877388
step: 390, loss: 0.13195735216140747
step: 400, loss: 0.12278155982494354
step: 410, loss: 0.09651470184326172
step: 420, loss: 0.052563462406396866
step: 430, loss: 0.042811065912246704
step: 440, loss: 0.02635900303721428
step: 450, loss: 0.0009871036745607853
step: 460, loss: 0.01978062465786934
step: 470, loss: 0.1672700196504593
step: 480, loss: 0.0359254889190197
step: 490, loss: 0.054115429520606995
step: 500, loss: 0.001287281047552824
step: 510, loss: 0.07253877073526382
step: 520, loss: 0.05564762279391289
step: 530, loss: 0.0010801771422848105
step: 540, loss: 0.03789651766419411
step: 550, loss: 0.0817013680934906
step: 560, loss: 0.050372567027807236
step: 570, loss: 0.01636725850403309
step: 580, loss: 0.0006324004498310387
step: 590, loss: 0.06981323659420013
step: 600, loss: 0.10242191702127457
step: 610, loss: 0.04697957634925842
step: 620, loss: 0.021068938076496124
step: 630, loss: 0.023448709398508072
step: 640, loss: 0.06105402857065201
step: 650, loss: 0.052085503935813904
step: 660, loss: 0.04401204735040665
step: 670, loss: 0.148237407207489
step: 680, loss: 0.0005330863641574979
step: 690, loss: 0.06594390422105789
step: 700, loss: 0.0454012006521225
step: 710, loss: 0.12130826711654663
step: 720, loss: 0.10660184919834137
step: 730, loss: 0.07118163257837296
step: 740, loss: 0.04992850869894028
step: 750, loss: 0.09221864491701126
step: 760, loss: 0.040521424263715744
step: 770, loss: 0.0004265241732355207
step: 780, loss: 0.00020884000696241856
step: 790, loss: 0.11508031189441681
step: 800, loss: 0.041508495807647705
step: 810, loss: 0.05536315217614174
step: 820, loss: 0.025755619630217552
step: 830, loss: 0.06589215993881226
step: 840, loss: 0.05644233897328377
step: 850, loss: 0.023581862449645996
step: 860, loss: 0.014275265857577324
step: 870, loss: 0.021554984152317047
step: 880, loss: 0.006873423233628273
step: 890, loss: 0.09695206582546234
step: 900, loss: 0.0908525139093399
step: 910, loss: 0.037333834916353226
step: 920, loss: 0.03731193393468857
step: 930, loss: 0.021901780739426613
step: 940, loss: 0.001108578871935606
step: 950, loss: 0.03586795553565025
step: 960, loss: 0.05495603010058403
step: 970, loss: 0.057536061853170395
step: 980, loss: 0.05097807198762894
step: 990, loss: 0.06752873957157135
step: 1000, loss: 0.024593405425548553
step: 1010, loss: 0.012857303954660892
step: 1020, loss: 0.06884261220693588
step: 1030, loss: 0.09613091498613358
step: 1040, loss: 0.04439439997076988
step: 1050, loss: 0.04041629657149315
step: 1060, loss: 9.593339200364426e-05
step: 1070, loss: 0.09183680266141891
epoch 15: dev_f1=0.9301675977653632, f1=0.9207828518173344, best_f1=0.9279404927940492
step: 0, loss: 0.06684060394763947
step: 10, loss: 0.020687930285930634
step: 20, loss: 0.05945276468992233
step: 30, loss: 0.09696325659751892
step: 40, loss: 0.00027275155298411846
step: 50, loss: 0.017929742112755775
step: 60, loss: 0.10364366322755814
step: 70, loss: 0.034493837505578995
step: 80, loss: 0.04915904253721237
step: 90, loss: 0.061201393604278564
step: 100, loss: 0.04252789542078972
step: 110, loss: 0.013060874305665493
step: 120, loss: 0.07017291337251663
step: 130, loss: 0.05321657657623291
step: 140, loss: 0.013503503054380417
step: 150, loss: 0.023279089480638504
step: 160, loss: 0.050735946744680405
step: 170, loss: 0.0013139257207512856
step: 180, loss: 0.05682750791311264
step: 190, loss: 0.09312903881072998
step: 200, loss: 0.023413535207509995
step: 210, loss: 0.017174335196614265
step: 220, loss: 0.020389173179864883
step: 230, loss: 0.07223640382289886
step: 240, loss: 0.08468692749738693
step: 250, loss: 0.0007598900119774044
step: 260, loss: 0.02946196123957634
step: 270, loss: 0.07021640241146088
step: 280, loss: 0.06021174415946007
step: 290, loss: 0.013795305974781513
step: 300, loss: 0.04226534441113472
step: 310, loss: 0.03368823230266571
step: 320, loss: 0.027157548815011978
step: 330, loss: 0.050079748034477234
step: 340, loss: 0.03747108578681946
step: 350, loss: 0.021171245723962784
step: 360, loss: 0.021487321704626083
step: 370, loss: 9.264746040571481e-06
step: 380, loss: 0.0285639725625515
step: 390, loss: 0.08310497552156448
step: 400, loss: 0.04764431715011597
step: 410, loss: 0.060094960033893585
step: 420, loss: 0.034433409571647644
step: 430, loss: 0.03553524985909462
step: 440, loss: 0.06306031346321106
step: 450, loss: 0.04349642992019653
step: 460, loss: 0.08387098461389542
step: 470, loss: 0.07123307138681412
step: 480, loss: 0.03777124360203743
step: 490, loss: 0.1032550111413002
step: 500, loss: 0.02913636341691017
step: 510, loss: 0.035747747868299484
step: 520, loss: 0.08715806901454926
step: 530, loss: 0.02329287864267826
step: 540, loss: 0.058347128331661224
step: 550, loss: 0.32161232829093933
step: 560, loss: 0.07696249336004257
step: 570, loss: 0.03709982708096504
step: 580, loss: 0.09149729460477829
step: 590, loss: 0.07683837413787842
step: 600, loss: 0.06173357367515564
step: 610, loss: 0.023606419563293457
step: 620, loss: 0.0907205268740654
step: 630, loss: 0.03471257537603378
step: 640, loss: 0.07281243801116943
step: 650, loss: 0.03483136370778084
step: 660, loss: 0.07557152211666107
step: 670, loss: 0.07803303748369217
step: 680, loss: 0.13207584619522095
step: 690, loss: 0.052861183881759644
step: 700, loss: 0.10152696073055267
step: 710, loss: 0.0006538902525790036
step: 720, loss: 0.02609919384121895
step: 730, loss: 0.0028831777162849903
step: 740, loss: 0.03910999000072479
step: 750, loss: 0.09226024150848389
step: 760, loss: 0.11114829778671265
step: 770, loss: 0.04041238874197006
step: 780, loss: 0.02154354192316532
step: 790, loss: 0.0011711613042280078
step: 800, loss: 0.02416972443461418
step: 810, loss: 0.01641259901225567
step: 820, loss: 0.04832206666469574
step: 830, loss: 0.05008064582943916
step: 840, loss: 0.0021247302647680044
step: 850, loss: 0.022320028394460678
step: 860, loss: 0.00759897381067276
step: 870, loss: 0.02363300509750843
step: 880, loss: 0.02274370938539505
step: 890, loss: 0.06538353860378265
step: 900, loss: 0.04168972373008728
step: 910, loss: 0.24419355392456055
step: 920, loss: 0.0728939026594162
step: 930, loss: 0.07877898961305618
step: 940, loss: 0.10560836642980576
step: 950, loss: 0.03640231117606163
step: 960, loss: 0.08009790629148483
step: 970, loss: 0.011331035755574703
step: 980, loss: 0.11169391125440598
step: 990, loss: 0.015101782977581024
step: 1000, loss: 0.06366020441055298
step: 1010, loss: 0.04995933920145035
step: 1020, loss: 0.06309296935796738
step: 1030, loss: 0.05803483724594116
step: 1040, loss: 0.07228989899158478
step: 1050, loss: 0.04001385718584061
step: 1060, loss: 0.039372317492961884
step: 1070, loss: 0.016020968556404114
epoch 16: dev_f1=0.9270307480495641, f1=0.9253456221198156, best_f1=0.9279404927940492
step: 0, loss: 0.0359499491751194
step: 10, loss: 0.06359546631574631
step: 20, loss: 0.01819511130452156
step: 30, loss: 0.045661311596632004
step: 40, loss: 0.0002028489689109847
step: 50, loss: 0.0664498582482338
step: 60, loss: 0.05322103574872017
step: 70, loss: 0.04928215965628624
step: 80, loss: 0.0999300479888916
step: 90, loss: 0.0346212238073349
step: 100, loss: 0.16221106052398682
step: 110, loss: 0.019402556121349335
step: 120, loss: 0.03663058206439018
step: 130, loss: 6.811250204918906e-05
step: 140, loss: 0.026867851614952087
step: 150, loss: 0.08518508076667786
step: 160, loss: 0.060785114765167236
step: 170, loss: 0.03751944750547409
step: 180, loss: 0.034689899533987045
step: 190, loss: 0.02737244963645935
step: 200, loss: 0.016571136191487312
step: 210, loss: 0.08256176859140396
step: 220, loss: 0.05207497999072075
step: 230, loss: 0.07569278031587601
step: 240, loss: 0.01771559752523899
step: 250, loss: 0.070301353931427
step: 260, loss: 0.05325447767972946
step: 270, loss: 0.01778283342719078
step: 280, loss: 0.09006872773170471
step: 290, loss: 0.032762348651885986
step: 300, loss: 0.08343469351530075
step: 310, loss: 0.045033931732177734
step: 320, loss: 0.03512025624513626
step: 330, loss: 0.03209948539733887
step: 340, loss: 0.10110675543546677
step: 350, loss: 0.062327638268470764
step: 360, loss: 0.0207646694034338
step: 370, loss: 0.03403274714946747
step: 380, loss: 0.026476526632905006
step: 390, loss: 0.012920860201120377
step: 400, loss: 0.12041729688644409
step: 410, loss: 0.067670539021492
step: 420, loss: 0.060188304632902145
step: 430, loss: 0.08440383523702621
step: 440, loss: 0.02862880565226078
step: 450, loss: 0.06124228984117508
step: 460, loss: 0.021224450320005417
step: 470, loss: 0.06845579296350479
step: 480, loss: 0.03515765815973282
step: 490, loss: 0.028236448764801025
step: 500, loss: 0.041307006031274796
step: 510, loss: 0.14080511033535004
step: 520, loss: 0.02712622657418251
step: 530, loss: 0.0004580657696351409
step: 540, loss: 0.00014920740795787424
step: 550, loss: 0.10591360181570053
step: 560, loss: 0.07849695533514023
step: 570, loss: 0.066016286611557
step: 580, loss: 0.029075603932142258
step: 590, loss: 0.0005623370525427163
step: 600, loss: 4.020072447019629e-05
step: 610, loss: 0.061958421021699905
step: 620, loss: 0.020910387858748436
step: 630, loss: 0.02310699224472046
step: 640, loss: 0.0682663694024086
step: 650, loss: 0.047938272356987
step: 660, loss: 0.01886824145913124
step: 670, loss: 0.03743366152048111
step: 680, loss: 0.05221765488386154
step: 690, loss: 0.06670048087835312
step: 700, loss: 0.055762238800525665
step: 710, loss: 0.01122365053743124
step: 720, loss: 0.08099932223558426
step: 730, loss: 0.060692332684993744
step: 740, loss: 0.05963633954524994
step: 750, loss: 0.031092312186956406
step: 760, loss: 0.0002927668101619929
step: 770, loss: 0.10721468180418015
step: 780, loss: 0.03945077583193779
step: 790, loss: 0.09359024465084076
step: 800, loss: 0.014934001490473747
step: 810, loss: 0.05009053274989128
step: 820, loss: 0.02123231068253517
step: 830, loss: 0.07112177461385727
step: 840, loss: 0.021901637315750122
step: 850, loss: 0.06644174456596375
step: 860, loss: 0.08675424009561539
step: 870, loss: 0.054622720927000046
step: 880, loss: 0.003450971096754074
step: 890, loss: 0.00013764819595962763
step: 900, loss: 0.07724487036466599
step: 910, loss: 0.022668970748782158
step: 920, loss: 0.051266223192214966
step: 930, loss: 0.07588076591491699
step: 940, loss: 0.050332047045230865
step: 950, loss: 0.023153187707066536
step: 960, loss: 0.05399100482463837
step: 970, loss: 0.0994889885187149
step: 980, loss: 0.10780531913042068
step: 990, loss: 0.08917198330163956
step: 1000, loss: 0.04149451106786728
step: 1010, loss: 0.11103932559490204
step: 1020, loss: 0.03327597305178642
step: 1030, loss: 0.0416652075946331
step: 1040, loss: 0.06258171051740646
step: 1050, loss: 0.03905065357685089
step: 1060, loss: 0.09391564875841141
step: 1070, loss: 0.06375672668218613
epoch 17: dev_f1=0.9279026217228464, f1=0.9205607476635514, best_f1=0.9279404927940492
step: 0, loss: 0.02182978019118309
step: 10, loss: 0.056636739522218704
step: 20, loss: 0.057472776621580124
step: 30, loss: 0.012953005731105804
step: 40, loss: 0.03666390851140022
step: 50, loss: 0.031912948936223984
step: 60, loss: 0.06151207163929939
step: 70, loss: 0.04946911334991455
step: 80, loss: 0.01879684254527092
step: 90, loss: 0.05135253444314003
step: 100, loss: 0.07282692193984985
step: 110, loss: 0.03498953953385353
step: 120, loss: 0.14939682185649872
step: 130, loss: 0.03429212421178818
step: 140, loss: 0.0253921952098608
step: 150, loss: 0.03065679967403412
step: 160, loss: 0.07098200172185898
step: 170, loss: 0.013887716457247734
step: 180, loss: 0.02955523505806923
step: 190, loss: 0.019837837666273117
step: 200, loss: 0.06615525484085083
step: 210, loss: 0.03100407123565674
step: 220, loss: 0.00011751649435609579
step: 230, loss: 0.05133926868438721
step: 240, loss: 0.03341424837708473
step: 250, loss: 0.0016872768756002188
step: 260, loss: 0.047371722757816315
step: 270, loss: 0.07968397438526154
step: 280, loss: 0.06037624925374985
step: 290, loss: 0.03477693349123001
step: 300, loss: 0.01171908713877201
step: 310, loss: 0.07891625165939331
step: 320, loss: 9.798134124139324e-05
step: 330, loss: 0.042457468807697296
step: 340, loss: 0.08738332241773605
step: 350, loss: 0.036606792360544205
step: 360, loss: 0.07834015041589737
step: 370, loss: 0.056962497532367706
step: 380, loss: 0.035803187638521194
step: 390, loss: 0.017377952113747597
step: 400, loss: 0.07222242653369904
step: 410, loss: 0.07586704194545746
step: 420, loss: 0.04566650837659836
step: 430, loss: 0.013301948085427284
step: 440, loss: 0.02028142288327217
step: 450, loss: 0.05797022581100464
step: 460, loss: 0.07083578407764435
step: 470, loss: 0.05250577628612518
step: 480, loss: 0.045423369854688644
step: 490, loss: 0.05356832593679428
step: 500, loss: 0.04002286121249199
step: 510, loss: 0.0241109486669302
step: 520, loss: 0.032871052622795105
step: 530, loss: 0.01943269371986389
step: 540, loss: 0.03875628858804703
step: 550, loss: 0.05250641331076622
step: 560, loss: 0.029319703578948975
step: 570, loss: 0.023932218551635742
step: 580, loss: 6.21251092525199e-05
step: 590, loss: 0.065365731716156
step: 600, loss: 0.02332671731710434
step: 610, loss: 0.05186278745532036
step: 620, loss: 0.09122219681739807
step: 630, loss: 0.003853796049952507
step: 640, loss: 0.0856911912560463
step: 650, loss: 0.011685864999890327
step: 660, loss: 0.04249287024140358
step: 670, loss: 0.0707743689417839
step: 680, loss: 0.019741779193282127
step: 690, loss: 0.12418779730796814
step: 700, loss: 0.04961670562624931
step: 710, loss: 0.12510909140110016
step: 720, loss: 0.06585794687271118
step: 730, loss: 0.00022459652973338962
step: 740, loss: 0.08564897626638412
step: 750, loss: 0.002115450566634536
step: 760, loss: 0.08674672991037369
step: 770, loss: 0.030136536806821823
step: 780, loss: 0.06371382623910904
step: 790, loss: 0.0664396658539772
step: 800, loss: 0.12069644033908844
step: 810, loss: 0.07569874078035355
step: 820, loss: 0.06054669991135597
step: 830, loss: 0.0050595724023878574
step: 840, loss: 0.04662669822573662
step: 850, loss: 0.026180630549788475
step: 860, loss: 0.17633415758609772
step: 870, loss: 0.06404288858175278
step: 880, loss: 0.0820532962679863
step: 890, loss: 0.03939291089773178
step: 900, loss: 0.03886675089597702
step: 910, loss: 0.010800900869071484
step: 920, loss: 0.002026224508881569
step: 930, loss: 0.13007965683937073
step: 940, loss: 0.033200327306985855
step: 950, loss: 0.0491529256105423
step: 960, loss: 0.0003291252360213548
step: 970, loss: 0.13441936671733856
step: 980, loss: 0.05581817775964737
step: 990, loss: 0.07656952738761902
step: 1000, loss: 0.04476264491677284
step: 1010, loss: 0.040835365653038025
step: 1020, loss: 0.01047616545110941
step: 1030, loss: 2.985869832627941e-05
step: 1040, loss: 0.09267985820770264
step: 1050, loss: 0.026896465569734573
step: 1060, loss: 0.07971739023923874
step: 1070, loss: 0.08883621543645859
epoch 18: dev_f1=0.9233662435354959, f1=0.91828058573453, best_f1=0.9279404927940492
step: 0, loss: 0.04637504369020462
step: 10, loss: 0.019159488379955292
step: 20, loss: 0.04938341677188873
step: 30, loss: 0.02288465015590191
step: 40, loss: 0.04548218101263046
step: 50, loss: 0.03950076550245285
step: 60, loss: 0.04559413716197014
step: 70, loss: 0.04521080479025841
step: 80, loss: 0.035303715616464615
step: 90, loss: 0.08553911000490189
step: 100, loss: 0.03484842926263809
step: 110, loss: 0.026976121589541435
step: 120, loss: 0.02351616509258747
step: 130, loss: 0.025693032890558243
step: 140, loss: 0.01820170134305954
step: 150, loss: 0.040367696434259415
step: 160, loss: 0.05016655847430229
step: 170, loss: 0.02380121871829033
step: 180, loss: 0.0644587054848671
step: 190, loss: 0.022302651777863503
step: 200, loss: 0.08990415185689926
step: 210, loss: 0.09329342097043991
step: 220, loss: 0.051477622240781784
step: 230, loss: 0.027901673689484596
step: 240, loss: 0.021729273721575737
step: 250, loss: 0.05650017783045769
step: 260, loss: 0.060328830033540726
step: 270, loss: 0.0458889901638031
step: 280, loss: 0.04343680664896965
step: 290, loss: 0.019531264901161194
step: 300, loss: 0.035494375973939896
step: 310, loss: 0.18422071635723114
step: 320, loss: 0.07100164145231247
step: 330, loss: 0.08456967771053314
step: 340, loss: 0.023228244855999947
step: 350, loss: 0.0004443163925316185
step: 360, loss: 0.0024271775037050247
step: 370, loss: 0.02196119725704193
step: 380, loss: 0.01644977182149887
step: 390, loss: 0.029469698667526245
step: 400, loss: 0.039954811334609985
step: 410, loss: 0.03997700288891792
step: 420, loss: 0.08353300392627716
step: 430, loss: 0.05297312140464783
step: 440, loss: 0.1087152510881424
step: 450, loss: 0.008887236006557941
step: 460, loss: 8.712409908184782e-05
step: 470, loss: 4.775188790517859e-05
step: 480, loss: 0.04459543526172638
step: 490, loss: 0.0004710187786258757
step: 500, loss: 0.043037306517362595
step: 510, loss: 0.022436747327446938
step: 520, loss: 0.0590183287858963
step: 530, loss: 0.048305198550224304
step: 540, loss: 0.043177057057619095
step: 550, loss: 0.03582683950662613
step: 560, loss: 0.061958398669958115
step: 570, loss: 0.06857645511627197
step: 580, loss: 0.03319896385073662
step: 590, loss: 0.010531479492783546
step: 600, loss: 0.05669734999537468
step: 610, loss: 0.06703026592731476
step: 620, loss: 1.5995992725947872e-05
step: 630, loss: 0.07276955246925354
step: 640, loss: 0.06237121671438217
step: 650, loss: 0.05435393378138542
step: 660, loss: 0.06725873798131943
step: 670, loss: 0.029904838651418686
step: 680, loss: 0.00023310403048526496
step: 690, loss: 0.04722950607538223
step: 700, loss: 0.04024364426732063
step: 710, loss: 0.0976114571094513
step: 720, loss: 3.6175548302708194e-05
step: 730, loss: 0.02957182750105858
step: 740, loss: 0.027016453444957733
step: 750, loss: 0.05096140131354332
step: 760, loss: 0.031168458983302116
step: 770, loss: 0.0900835245847702
step: 780, loss: 0.09266689419746399
step: 790, loss: 0.04541168734431267
step: 800, loss: 0.07128240913152695
step: 810, loss: 0.04596945270895958
step: 820, loss: 9.399390546604991e-05
step: 830, loss: 0.14069421589374542
step: 840, loss: 0.0033022386487573385
step: 850, loss: 0.0013134729815647006
step: 860, loss: 6.895469414303079e-05
step: 870, loss: 0.0735807716846466
step: 880, loss: 0.0639999732375145
step: 890, loss: 0.024350568652153015
step: 900, loss: 0.11895786225795746
step: 910, loss: 0.055525753647089005
step: 920, loss: 0.08517584949731827
step: 930, loss: 0.02936439961194992
step: 940, loss: 0.042178742587566376
step: 950, loss: 1.809332570701372e-05
step: 960, loss: 0.035706911236047745
step: 970, loss: 0.059463612735271454
step: 980, loss: 0.011439758352935314
step: 990, loss: 0.01976151578128338
step: 1000, loss: 0.00032473908504471183
step: 1010, loss: 0.0804884284734726
step: 1020, loss: 0.0002016739745158702
step: 1030, loss: 0.016612952575087547
step: 1040, loss: 0.08447154611349106
step: 1050, loss: 0.0027050350327044725
step: 1060, loss: 0.045077621936798096
step: 1070, loss: 0.03501478582620621
epoch 19: dev_f1=0.9280677009873061, f1=0.9208294062205465, best_f1=0.9279404927940492
step: 0, loss: 0.00031170545844361186
step: 10, loss: 0.05439598858356476
step: 20, loss: 0.12652291357517242
step: 30, loss: 0.06713677197694778
step: 40, loss: 0.03865068405866623
step: 50, loss: 0.07414723932743073
step: 60, loss: 0.10957761108875275
step: 70, loss: 0.08344490826129913
step: 80, loss: 0.024566108360886574
step: 90, loss: 0.15768711268901825
step: 100, loss: 0.03897233307361603
step: 110, loss: 0.045403189957141876
step: 120, loss: 0.10024124383926392
step: 130, loss: 0.08633127063512802
step: 140, loss: 0.0428798608481884
step: 150, loss: 0.06560735404491425
step: 160, loss: 0.0332426093518734
step: 170, loss: 0.05896543711423874
step: 180, loss: 0.05033757537603378
step: 190, loss: 1.9188071746611968e-05
step: 200, loss: 0.0021474063396453857
step: 210, loss: 7.31499821995385e-05
step: 220, loss: 0.04019464552402496
step: 230, loss: 0.02127140946686268
step: 240, loss: 0.022592267021536827
step: 250, loss: 4.8228226660285145e-05
step: 260, loss: 0.061704881489276886
step: 270, loss: 0.014468745328485966
step: 280, loss: 0.06734965741634369
step: 290, loss: 0.03208640590310097
step: 300, loss: 0.029611235484480858
step: 310, loss: 0.07231662422418594
step: 320, loss: 0.004046677146106958
step: 330, loss: 0.015298963524401188
step: 340, loss: 0.0343644917011261
step: 350, loss: 0.021986035630106926
step: 360, loss: 0.023687012493610382
step: 370, loss: 0.0535254068672657
step: 380, loss: 0.063247449696064
step: 390, loss: 0.06609757989645004
step: 400, loss: 0.018548306077718735
step: 410, loss: 0.02004305273294449
step: 420, loss: 0.020885614678263664
step: 430, loss: 0.05948199704289436
step: 440, loss: 0.004370155278593302
step: 450, loss: 0.0002939244150184095
step: 460, loss: 0.054305244237184525
step: 470, loss: 4.313081080908887e-05
step: 480, loss: 0.08567892760038376
step: 490, loss: 0.03372698649764061
step: 500, loss: 0.01622661203145981
step: 510, loss: 0.032772041857242584
step: 520, loss: 0.00016806636995170265
step: 530, loss: 0.02125859633088112
step: 540, loss: 0.10590242594480515
step: 550, loss: 0.04526764526963234
step: 560, loss: 0.017168579623103142
step: 570, loss: 0.0349341556429863
step: 580, loss: 0.04435300454497337
step: 590, loss: 0.061778757721185684
step: 600, loss: 0.05232197046279907
step: 610, loss: 0.06700548529624939
step: 620, loss: 0.0434502512216568
step: 630, loss: 0.018604831770062447
step: 640, loss: 0.05227598547935486
step: 650, loss: 0.0378657728433609
step: 660, loss: 6.234047032194212e-05
step: 670, loss: 0.021722935140132904
step: 680, loss: 0.05322878062725067
step: 690, loss: 0.047537487000226974
step: 700, loss: 0.06534631550312042
step: 710, loss: 0.040896374732255936
step: 720, loss: 0.023049816489219666
step: 730, loss: 0.08369936794042587
step: 740, loss: 0.01631028577685356
step: 750, loss: 0.042871665209531784
step: 760, loss: 0.00017159580602310598
step: 770, loss: 0.00019764403987210244
step: 780, loss: 0.054050419479608536
step: 790, loss: 0.05246201902627945
step: 800, loss: 0.04493577033281326
step: 810, loss: 0.01628904603421688
step: 820, loss: 0.06266647577285767
step: 830, loss: 0.00900756474584341
step: 840, loss: 0.00014030076272320002
step: 850, loss: 0.029503898695111275
step: 860, loss: 0.07087353616952896
step: 870, loss: 0.03947199136018753
step: 880, loss: 0.02605169452726841
step: 890, loss: 0.01879938691854477
step: 900, loss: 0.10699162632226944
step: 910, loss: 0.04408061131834984
step: 920, loss: 0.04526359960436821
step: 930, loss: 0.024818135425448418
step: 940, loss: 0.030319347977638245
step: 950, loss: 0.03477831557393074
step: 960, loss: 0.017134740948677063
step: 970, loss: 0.012651889584958553
step: 980, loss: 0.06286892294883728
step: 990, loss: 0.03394110128283501
step: 1000, loss: 0.030188051983714104
step: 1010, loss: 0.028494272381067276
step: 1020, loss: 0.07202263176441193
step: 1030, loss: 0.053784169256687164
step: 1040, loss: 0.053229920566082
step: 1050, loss: 0.00048163585597649217
step: 1060, loss: 0.034470587968826294
step: 1070, loss: 0.028934532776474953
epoch 20: dev_f1=0.9288389513108615, f1=0.9212007504690432, best_f1=0.9279404927940492
