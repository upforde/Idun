cuda
Device: cuda
step: 0, loss: 0.6778504252433777
step: 10, loss: 0.3674314618110657
step: 20, loss: 0.6667263507843018
step: 30, loss: 0.6039265394210815
step: 40, loss: 0.3915085196495056
step: 50, loss: 0.1516883373260498
step: 60, loss: 0.3344579041004181
step: 70, loss: 0.2424972951412201
step: 80, loss: 0.20464152097702026
step: 90, loss: 0.19567768275737762
step: 100, loss: 0.33928391337394714
step: 110, loss: 0.32291659712791443
step: 120, loss: 0.1429087072610855
step: 130, loss: 0.11924480646848679
step: 140, loss: 0.31732168793678284
step: 150, loss: 0.27839797735214233
step: 160, loss: 0.148489311337471
step: 170, loss: 0.17005375027656555
step: 180, loss: 0.12218190729618073
step: 190, loss: 0.3361128270626068
step: 200, loss: 0.21708369255065918
step: 210, loss: 0.1965584009885788
step: 220, loss: 0.1644822359085083
step: 230, loss: 0.2644507884979248
step: 240, loss: 0.19045521318912506
step: 250, loss: 0.20120492577552795
step: 260, loss: 0.16143670678138733
step: 270, loss: 0.11514175683259964
step: 280, loss: 0.13921526074409485
step: 290, loss: 0.26458650827407837
step: 300, loss: 0.1848852038383484
step: 310, loss: 0.18886087834835052
step: 320, loss: 0.17428743839263916
step: 330, loss: 0.2406233847141266
step: 340, loss: 0.1130254939198494
step: 350, loss: 0.11058952659368515
step: 360, loss: 0.1588764637708664
step: 370, loss: 0.0678500384092331
step: 380, loss: 0.11127730458974838
step: 390, loss: 0.16127906739711761
step: 400, loss: 0.18238034844398499
step: 410, loss: 0.16887220740318298
step: 420, loss: 0.07099495083093643
step: 430, loss: 0.12990956008434296
step: 440, loss: 0.3020242154598236
step: 450, loss: 0.09279239922761917
step: 460, loss: 0.17263607680797577
step: 470, loss: 0.16119125485420227
step: 480, loss: 0.11117540299892426
step: 490, loss: 0.1835412085056305
step: 500, loss: 0.37716203927993774
step: 510, loss: 0.09918921440839767
step: 520, loss: 0.2521083652973175
step: 530, loss: 0.14455001056194305
step: 540, loss: 0.06127586588263512
step: 550, loss: 0.2403024584054947
step: 560, loss: 0.21127939224243164
step: 570, loss: 0.1254197359085083
step: 580, loss: 0.07821926474571228
step: 590, loss: 0.2438916265964508
step: 600, loss: 0.14785370230674744
step: 610, loss: 0.13265573978424072
step: 620, loss: 0.13169607520103455
step: 630, loss: 0.10991346836090088
step: 640, loss: 0.2016810178756714
step: 650, loss: 0.09547576308250427
step: 660, loss: 0.15083527565002441
step: 670, loss: 0.1904071867465973
step: 680, loss: 0.19808408617973328
step: 690, loss: 0.09754624217748642
step: 700, loss: 0.008107084780931473
step: 710, loss: 0.3735044598579407
step: 720, loss: 0.07460837811231613
step: 730, loss: 0.0999138355255127
step: 740, loss: 0.12556670606136322
step: 750, loss: 0.10551956295967102
step: 760, loss: 0.09036608040332794
step: 770, loss: 0.0939033105969429
step: 780, loss: 0.14827384054660797
step: 790, loss: 0.16369956731796265
step: 800, loss: 0.07742246240377426
step: 810, loss: 0.24168039858341217
step: 820, loss: 0.02762935683131218
step: 830, loss: 0.16410940885543823
step: 840, loss: 0.185028538107872
step: 850, loss: 0.07747010141611099
step: 860, loss: 0.13745732605457306
step: 870, loss: 0.1294420212507248
step: 880, loss: 0.09177709370851517
step: 890, loss: 0.3008458912372589
step: 900, loss: 0.11963824182748795
step: 910, loss: 0.04893551766872406
step: 920, loss: 0.10889790207147598
step: 930, loss: 0.03790801018476486
step: 940, loss: 0.11430468410253525
step: 950, loss: 0.1650737226009369
step: 960, loss: 0.10676178336143494
step: 970, loss: 0.09864149242639542
step: 980, loss: 0.10523860901594162
step: 990, loss: 0.08799088001251221
step: 1000, loss: 0.16654224693775177
step: 1010, loss: 0.1313210129737854
step: 1020, loss: 0.14638707041740417
step: 1030, loss: 0.13345634937286377
step: 1040, loss: 0.08105602860450745
step: 1050, loss: 0.10304800420999527
step: 1060, loss: 0.1849621832370758
step: 1070, loss: 0.08647846430540085
epoch 1: dev_f1=0.9035126722987995, f1=0.9033407572383073, best_f1=0.9033407572383073
step: 0, loss: 0.09680284559726715
step: 10, loss: 0.16673889756202698
step: 20, loss: 0.0859118327498436
step: 30, loss: 0.03755839914083481
step: 40, loss: 0.19779115915298462
step: 50, loss: 0.101639024913311
step: 60, loss: 0.13004779815673828
step: 70, loss: 0.050375644117593765
step: 80, loss: 0.09187232702970505
step: 90, loss: 0.05621020868420601
step: 100, loss: 0.06977254152297974
step: 110, loss: 0.11459269374608994
step: 120, loss: 0.05707891285419464
step: 130, loss: 0.08719160407781601
step: 140, loss: 0.15851663053035736
step: 150, loss: 0.16230984032154083
step: 160, loss: 0.1237368956208229
step: 170, loss: 0.0914558544754982
step: 180, loss: 0.15647298097610474
step: 190, loss: 0.13148409128189087
step: 200, loss: 0.09240728616714478
step: 210, loss: 0.11620419472455978
step: 220, loss: 0.07222346216440201
step: 230, loss: 0.1524013876914978
step: 240, loss: 0.11484416574239731
step: 250, loss: 0.07617952674627304
step: 260, loss: 0.18985126912593842
step: 270, loss: 0.20020140707492828
step: 280, loss: 0.15154072642326355
step: 290, loss: 0.20759184658527374
step: 300, loss: 0.08863939344882965
step: 310, loss: 0.13720335066318512
step: 320, loss: 0.34637346863746643
step: 330, loss: 0.1324043720960617
step: 340, loss: 0.09040877968072891
step: 350, loss: 0.19213666021823883
step: 360, loss: 0.12994284927845
step: 370, loss: 0.14785221219062805
step: 380, loss: 0.09352145344018936
step: 390, loss: 0.04400450363755226
step: 400, loss: 0.055972497910261154
step: 410, loss: 0.1117434874176979
step: 420, loss: 0.302161306142807
step: 430, loss: 0.1769016832113266
step: 440, loss: 0.1630590409040451
step: 450, loss: 0.07778572291135788
step: 460, loss: 0.11445732414722443
step: 470, loss: 0.19293518364429474
step: 480, loss: 0.17768564820289612
step: 490, loss: 0.19786496460437775
step: 500, loss: 0.09310842305421829
step: 510, loss: 0.22107277810573578
step: 520, loss: 0.19880671799182892
step: 530, loss: 0.15214480459690094
step: 540, loss: 0.08655931055545807
step: 550, loss: 0.11433910578489304
step: 560, loss: 0.14714191854000092
step: 570, loss: 0.17869308590888977
step: 580, loss: 0.2609819173812866
step: 590, loss: 0.14986097812652588
step: 600, loss: 0.14961904287338257
step: 610, loss: 0.1111687570810318
step: 620, loss: 0.061475664377212524
step: 630, loss: 0.13196581602096558
step: 640, loss: 0.057540830224752426
step: 650, loss: 0.1436769664287567
step: 660, loss: 0.1397080421447754
step: 670, loss: 0.060780491679906845
step: 680, loss: 0.08542270958423615
step: 690, loss: 0.17557711899280548
step: 700, loss: 0.07260527461767197
step: 710, loss: 0.13689450919628143
step: 720, loss: 0.04656991735100746
step: 730, loss: 0.02582058310508728
step: 740, loss: 0.15537932515144348
step: 750, loss: 0.057356324046850204
step: 760, loss: 0.10490142554044724
step: 770, loss: 0.0983273983001709
step: 780, loss: 0.07998862117528915
step: 790, loss: 0.15962721407413483
step: 800, loss: 0.09730838239192963
step: 810, loss: 0.0486149899661541
step: 820, loss: 0.10023290663957596
step: 830, loss: 0.07748109847307205
step: 840, loss: 0.08621838688850403
step: 850, loss: 0.07535629719495773
step: 860, loss: 0.15318840742111206
step: 870, loss: 0.04344237968325615
step: 880, loss: 0.05849652737379074
step: 890, loss: 0.0857209637761116
step: 900, loss: 0.0490700863301754
step: 910, loss: 0.2319001406431198
step: 920, loss: 0.03413952887058258
step: 930, loss: 0.07070306688547134
step: 940, loss: 0.11257946491241455
step: 950, loss: 0.10708899050951004
step: 960, loss: 0.19061756134033203
step: 970, loss: 0.0767352432012558
step: 980, loss: 0.10988853871822357
step: 990, loss: 0.05838508531451225
step: 1000, loss: 0.06850152462720871
step: 1010, loss: 0.19202294945716858
step: 1020, loss: 0.08988714963197708
step: 1030, loss: 0.11033712327480316
step: 1040, loss: 0.13885729014873505
step: 1050, loss: 0.08420263975858688
step: 1060, loss: 0.02591770701110363
step: 1070, loss: 0.05706702917814255
epoch 2: dev_f1=0.929368029739777, f1=0.9262672811059909, best_f1=0.9262672811059909
step: 0, loss: 0.043414678424596786
step: 10, loss: 0.09936434030532837
step: 20, loss: 0.18065223097801208
step: 30, loss: 0.1868262141942978
step: 40, loss: 0.041231803596019745
step: 50, loss: 0.049206189811229706
step: 60, loss: 0.1782383918762207
step: 70, loss: 0.08192329108715057
step: 80, loss: 0.1059286892414093
step: 90, loss: 0.10563317686319351
step: 100, loss: 0.06802347302436829
step: 110, loss: 0.19875572621822357
step: 120, loss: 0.15689601004123688
step: 130, loss: 0.11670904606580734
step: 140, loss: 0.10388574749231339
step: 150, loss: 0.0843653529882431
step: 160, loss: 0.09131580591201782
step: 170, loss: 0.07289955019950867
step: 180, loss: 0.05617472529411316
step: 190, loss: 0.13782517611980438
step: 200, loss: 0.06207485869526863
step: 210, loss: 0.1671677529811859
step: 220, loss: 0.15643538534641266
step: 230, loss: 0.16314327716827393
step: 240, loss: 0.14507688581943512
step: 250, loss: 0.07495522499084473
step: 260, loss: 0.09923288226127625
step: 270, loss: 0.045625995844602585
step: 280, loss: 0.31063205003738403
step: 290, loss: 0.05568120256066322
step: 300, loss: 0.01918460801243782
step: 310, loss: 0.22967098653316498
step: 320, loss: 0.1596989929676056
step: 330, loss: 0.1145595908164978
step: 340, loss: 0.07251261174678802
step: 350, loss: 0.11931954324245453
step: 360, loss: 0.0930330827832222
step: 370, loss: 0.15746356546878815
step: 380, loss: 0.036162227392196655
step: 390, loss: 0.029082249850034714
step: 400, loss: 0.12448883056640625
step: 410, loss: 0.04908093437552452
step: 420, loss: 0.07018370181322098
step: 430, loss: 0.10363893210887909
step: 440, loss: 0.19390654563903809
step: 450, loss: 0.1985761970281601
step: 460, loss: 0.23869504034519196
step: 470, loss: 0.1500444859266281
step: 480, loss: 0.12550707161426544
step: 490, loss: 0.13116027414798737
step: 500, loss: 0.24644804000854492
step: 510, loss: 0.10915086418390274
step: 520, loss: 0.043685149401426315
step: 530, loss: 0.12005356699228287
step: 540, loss: 0.09599651396274567
step: 550, loss: 0.02539788745343685
step: 560, loss: 0.08530931174755096
step: 570, loss: 0.0982770323753357
step: 580, loss: 0.10630515217781067
step: 590, loss: 0.15956896543502808
step: 600, loss: 0.08811455965042114
step: 610, loss: 0.22621038556098938
step: 620, loss: 0.06848356872797012
step: 630, loss: 0.15184932947158813
step: 640, loss: 0.22436799108982086
step: 650, loss: 0.07803820073604584
step: 660, loss: 0.07055234909057617
step: 670, loss: 0.14220865070819855
step: 680, loss: 0.0683726891875267
step: 690, loss: 0.08046584576368332
step: 700, loss: 0.09140709787607193
step: 710, loss: 0.011666957288980484
step: 720, loss: 0.1717219352722168
step: 730, loss: 0.06174808368086815
step: 740, loss: 0.09580601751804352
step: 750, loss: 0.07284927368164062
step: 760, loss: 0.10803598165512085
step: 770, loss: 0.09724275767803192
step: 780, loss: 0.07320094853639603
step: 790, loss: 0.1287534534931183
step: 800, loss: 0.10816998034715652
step: 810, loss: 0.07523392140865326
step: 820, loss: 0.11741171032190323
step: 830, loss: 0.11784772574901581
step: 840, loss: 0.053865451365709305
step: 850, loss: 0.11800753325223923
step: 860, loss: 0.11308351904153824
step: 870, loss: 0.07012679427862167
step: 880, loss: 0.1274939924478531
step: 890, loss: 0.058784402906894684
step: 900, loss: 0.03560350462794304
step: 910, loss: 0.10515674203634262
step: 920, loss: 0.15574726462364197
step: 930, loss: 0.12327581644058228
step: 940, loss: 0.0858413502573967
step: 950, loss: 0.08848341554403305
step: 960, loss: 0.07875417917966843
step: 970, loss: 0.11908230185508728
step: 980, loss: 0.08004391193389893
step: 990, loss: 0.053809210658073425
step: 1000, loss: 0.09831948578357697
step: 1010, loss: 0.11235038191080093
step: 1020, loss: 0.032213423401117325
step: 1030, loss: 0.014010281302034855
step: 1040, loss: 0.06644412130117416
step: 1050, loss: 0.05346420779824257
step: 1060, loss: 0.053999099880456924
step: 1070, loss: 0.025972215458750725
epoch 3: dev_f1=0.925925925925926, f1=0.9142595139844107, best_f1=0.9262672811059909
step: 0, loss: 0.07934556156396866
step: 10, loss: 0.1035238578915596
step: 20, loss: 0.09230194985866547
step: 30, loss: 0.08555963635444641
step: 40, loss: 0.10259854048490524
step: 50, loss: 0.09359993785619736
step: 60, loss: 0.058966875076293945
step: 70, loss: 0.16192348301410675
step: 80, loss: 0.04566583409905434
step: 90, loss: 0.12664344906806946
step: 100, loss: 0.09844276309013367
step: 110, loss: 0.10847504436969757
step: 120, loss: 0.020620061084628105
step: 130, loss: 0.1341690719127655
step: 140, loss: 0.049666039645671844
step: 150, loss: 0.06773173809051514
step: 160, loss: 0.042946916073560715
step: 170, loss: 0.023882582783699036
step: 180, loss: 0.12227920442819595
step: 190, loss: 0.09322574734687805
step: 200, loss: 0.17081180214881897
step: 210, loss: 0.07666783034801483
step: 220, loss: 0.04957776889204979
step: 230, loss: 0.0845496729016304
step: 240, loss: 0.09825883060693741
step: 250, loss: 0.19985556602478027
step: 260, loss: 0.09541205316781998
step: 270, loss: 0.08801530301570892
step: 280, loss: 0.022022949531674385
step: 290, loss: 0.015584321692585945
step: 300, loss: 0.18992513418197632
step: 310, loss: 0.12221086770296097
step: 320, loss: 0.04402308166027069
step: 330, loss: 0.11142513155937195
step: 340, loss: 0.0740259662270546
step: 350, loss: 0.03808356449007988
step: 360, loss: 0.13425256311893463
step: 370, loss: 0.1376122385263443
step: 380, loss: 0.10577654838562012
step: 390, loss: 0.12984436750411987
step: 400, loss: 0.1330837607383728
step: 410, loss: 0.2037811428308487
step: 420, loss: 0.03697042167186737
step: 430, loss: 0.08060123771429062
step: 440, loss: 0.1435210406780243
step: 450, loss: 0.027123279869556427
step: 460, loss: 0.03226466849446297
step: 470, loss: 0.12023697048425674
step: 480, loss: 0.09913105517625809
step: 490, loss: 0.06752824038267136
step: 500, loss: 0.1383051872253418
step: 510, loss: 0.0669793114066124
step: 520, loss: 0.14257603883743286
step: 530, loss: 0.018367255106568336
step: 540, loss: 0.13864025473594666
step: 550, loss: 0.08313069492578506
step: 560, loss: 0.06691648811101913
step: 570, loss: 0.07372535765171051
step: 580, loss: 0.1268702894449234
step: 590, loss: 0.07546193897724152
step: 600, loss: 0.07221443206071854
step: 610, loss: 0.06238117441534996
step: 620, loss: 0.11164989322423935
step: 630, loss: 0.09952683001756668
step: 640, loss: 0.03506356477737427
step: 650, loss: 0.17332197725772858
step: 660, loss: 0.08657825738191605
step: 670, loss: 0.10682468116283417
step: 680, loss: 0.06385312229394913
step: 690, loss: 0.046331681311130524
step: 700, loss: 0.11736396700143814
step: 710, loss: 0.05826931446790695
step: 720, loss: 0.041644055396318436
step: 730, loss: 0.10446418076753616
step: 740, loss: 0.08003024756908417
step: 750, loss: 0.12303534895181656
step: 760, loss: 0.2812885642051697
step: 770, loss: 0.11625944823026657
step: 780, loss: 0.002510637743398547
step: 790, loss: 0.04263484477996826
step: 800, loss: 0.016964079812169075
step: 810, loss: 0.10581370443105698
step: 820, loss: 0.003716767067089677
step: 830, loss: 0.10787621885538101
step: 840, loss: 0.09420575946569443
step: 850, loss: 0.06505496054887772
step: 860, loss: 0.043845877051353455
step: 870, loss: 0.11720815300941467
step: 880, loss: 0.04909439757466316
step: 890, loss: 0.06942100077867508
step: 900, loss: 0.05923311039805412
step: 910, loss: 0.030447140336036682
step: 920, loss: 0.03259574994444847
step: 930, loss: 0.10502583533525467
step: 940, loss: 0.23890697956085205
step: 950, loss: 0.24744288623332977
step: 960, loss: 0.20201633870601654
step: 970, loss: 0.12690718472003937
step: 980, loss: 0.09020636975765228
step: 990, loss: 0.07923789322376251
step: 1000, loss: 0.10071144253015518
step: 1010, loss: 0.11170979589223862
step: 1020, loss: 0.06353452056646347
step: 1030, loss: 0.09529107064008713
step: 1040, loss: 0.06382627040147781
step: 1050, loss: 0.06156722828745842
step: 1060, loss: 0.02089291624724865
step: 1070, loss: 0.06953055411577225
epoch 4: dev_f1=0.9272311212814646, f1=0.9211956521739131, best_f1=0.9262672811059909
step: 0, loss: 0.0954037681221962
step: 10, loss: 0.10620228946208954
step: 20, loss: 0.18273301422595978
step: 30, loss: 0.08751699328422546
step: 40, loss: 0.09996895492076874
step: 50, loss: 0.06867529451847076
step: 60, loss: 0.13408608734607697
step: 70, loss: 0.14615119993686676
step: 80, loss: 0.14538361132144928
step: 90, loss: 0.026408320292830467
step: 100, loss: 0.09825128316879272
step: 110, loss: 0.15151800215244293
step: 120, loss: 0.12270838022232056
step: 130, loss: 0.026214687153697014
step: 140, loss: 0.05114451050758362
step: 150, loss: 0.08696601539850235
step: 160, loss: 0.020289011299610138
step: 170, loss: 0.05663521587848663
step: 180, loss: 0.020045438781380653
step: 190, loss: 0.060892246663570404
step: 200, loss: 0.10749329626560211
step: 210, loss: 0.14117367565631866
step: 220, loss: 0.07041601091623306
step: 230, loss: 0.08450977504253387
step: 240, loss: 0.08466335386037827
step: 250, loss: 0.14910779893398285
step: 260, loss: 0.02277512103319168
step: 270, loss: 0.10754626989364624
step: 280, loss: 0.047101497650146484
step: 290, loss: 0.029562976211309433
step: 300, loss: 0.10001590102910995
step: 310, loss: 0.041827015578746796
step: 320, loss: 0.09636712074279785
step: 330, loss: 0.03421983867883682
step: 340, loss: 0.06773119419813156
step: 350, loss: 0.1206698790192604
step: 360, loss: 0.11148205399513245
step: 370, loss: 0.12986193597316742
step: 380, loss: 0.10046543180942535
step: 390, loss: 0.15303152799606323
step: 400, loss: 0.08902490884065628
step: 410, loss: 0.12273504585027695
step: 420, loss: 0.09318980574607849
step: 430, loss: 0.08930443227291107
step: 440, loss: 0.07758589833974838
step: 450, loss: 0.1084127202630043
step: 460, loss: 0.11712752282619476
step: 470, loss: 0.08719780296087265
step: 480, loss: 0.1423698216676712
step: 490, loss: 0.0951855406165123
step: 500, loss: 0.1003301814198494
step: 510, loss: 0.0996500626206398
step: 520, loss: 0.03625992685556412
step: 530, loss: 0.06808611750602722
step: 540, loss: 0.1459398716688156
step: 550, loss: 0.11891636997461319
step: 560, loss: 0.09852771461009979
step: 570, loss: 0.08146209269762039
step: 580, loss: 0.0712457075715065
step: 590, loss: 0.050814565271139145
step: 600, loss: 0.07617442309856415
step: 610, loss: 0.06588436663150787
step: 620, loss: 0.056221071630716324
step: 630, loss: 0.024021759629249573
step: 640, loss: 0.11676847189664841
step: 650, loss: 0.06505087018013
step: 660, loss: 0.15903615951538086
step: 670, loss: 0.07144182175397873
step: 680, loss: 0.1144675686955452
step: 690, loss: 0.10544154793024063
step: 700, loss: 0.09622595459222794
step: 710, loss: 0.08498905599117279
step: 720, loss: 0.052190057933330536
step: 730, loss: 0.14272993803024292
step: 740, loss: 0.07847859710454941
step: 750, loss: 0.06097710505127907
step: 760, loss: 0.07297411561012268
step: 770, loss: 0.12060750275850296
step: 780, loss: 0.12500955164432526
step: 790, loss: 0.12359493970870972
step: 800, loss: 0.05753215774893761
step: 810, loss: 0.16962316632270813
step: 820, loss: 0.10423395037651062
step: 830, loss: 0.11813600361347198
step: 840, loss: 0.13671524822711945
step: 850, loss: 0.05938694253563881
step: 860, loss: 0.05375098064541817
step: 870, loss: 0.12840569019317627
step: 880, loss: 0.11987873911857605
step: 890, loss: 0.04125285521149635
step: 900, loss: 0.0361582413315773
step: 910, loss: 0.04641714692115784
step: 920, loss: 0.07473722845315933
step: 930, loss: 0.08617118000984192
step: 940, loss: 0.11209025233983994
step: 950, loss: 0.08390609174966812
step: 960, loss: 0.06190027296543121
step: 970, loss: 0.1338176727294922
step: 980, loss: 0.1428261250257492
step: 990, loss: 0.07074156403541565
step: 1000, loss: 0.0816674456000328
step: 1010, loss: 0.054957807064056396
step: 1020, loss: 0.03451506420969963
step: 1030, loss: 0.15601816773414612
step: 1040, loss: 0.08349516987800598
step: 1050, loss: 0.12463461607694626
step: 1060, loss: 0.12038038671016693
step: 1070, loss: 0.11489110440015793
epoch 5: dev_f1=0.9264305177111716, f1=0.9250225835591689, best_f1=0.9262672811059909
step: 0, loss: 0.03158764913678169
step: 10, loss: 0.14856423437595367
step: 20, loss: 0.07797004282474518
step: 30, loss: 0.10252424329519272
step: 40, loss: 0.078769251704216
step: 50, loss: 0.10182519257068634
step: 60, loss: 0.17846789956092834
step: 70, loss: 0.032082948833703995
step: 80, loss: 0.0727061852812767
step: 90, loss: 0.08440627157688141
step: 100, loss: 0.11942824721336365
step: 110, loss: 0.031975407153367996
step: 120, loss: 0.08950993418693542
step: 130, loss: 0.16534565389156342
step: 140, loss: 0.16044583916664124
step: 150, loss: 0.04114644229412079
step: 160, loss: 0.050131604075431824
step: 170, loss: 0.03325910121202469
step: 180, loss: 0.03745780512690544
step: 190, loss: 0.1396683007478714
step: 200, loss: 0.06762703508138657
step: 210, loss: 0.12673313915729523
step: 220, loss: 0.08793659508228302
step: 230, loss: 0.009156161919236183
step: 240, loss: 0.027240870520472527
step: 250, loss: 0.059102751314640045
step: 260, loss: 0.06398294121026993
step: 270, loss: 0.0907338485121727
step: 280, loss: 0.01869698241353035
step: 290, loss: 0.02900109626352787
step: 300, loss: 0.047076515853405
step: 310, loss: 0.02788766473531723
step: 320, loss: 0.018042899668216705
step: 330, loss: 0.22795844078063965
step: 340, loss: 0.024106387048959732
step: 350, loss: 0.0794772356748581
step: 360, loss: 0.00585532421246171
step: 370, loss: 0.07567392289638519
step: 380, loss: 0.1874871850013733
step: 390, loss: 0.11582879722118378
step: 400, loss: 0.09268040955066681
step: 410, loss: 0.02501344494521618
step: 420, loss: 0.1110389307141304
step: 430, loss: 0.11441850662231445
step: 440, loss: 0.02658648043870926
step: 450, loss: 0.11598069965839386
step: 460, loss: 0.14920347929000854
step: 470, loss: 0.14018328487873077
step: 480, loss: 0.06371262669563293
step: 490, loss: 0.10586277395486832
step: 500, loss: 0.0787254273891449
step: 510, loss: 0.07710051536560059
step: 520, loss: 0.009956905618309975
step: 530, loss: 0.04703986272215843
step: 540, loss: 0.278592586517334
step: 550, loss: 0.020699340850114822
step: 560, loss: 0.05351964384317398
step: 570, loss: 0.031556155532598495
step: 580, loss: 0.10455579310655594
step: 590, loss: 0.05617855489253998
step: 600, loss: 0.04278511181473732
step: 610, loss: 0.07257062196731567
step: 620, loss: 0.0455964058637619
step: 630, loss: 0.17922404408454895
step: 640, loss: 0.12596702575683594
step: 650, loss: 0.1391371488571167
step: 660, loss: 0.042820218950510025
step: 670, loss: 0.0848734974861145
step: 680, loss: 0.0946444645524025
step: 690, loss: 0.0850272923707962
step: 700, loss: 0.034925904124975204
step: 710, loss: 0.1225966289639473
step: 720, loss: 0.060138870030641556
step: 730, loss: 0.10049999505281448
step: 740, loss: 0.07608933001756668
step: 750, loss: 0.022353844717144966
step: 760, loss: 0.09671884775161743
step: 770, loss: 0.05713767558336258
step: 780, loss: 0.06855753064155579
step: 790, loss: 0.08401203900575638
step: 800, loss: 0.09458818286657333
step: 810, loss: 0.07120262086391449
step: 820, loss: 0.1114269271492958
step: 830, loss: 0.03070693463087082
step: 840, loss: 0.10845435410737991
step: 850, loss: 0.06869860738515854
step: 860, loss: 0.11550775915384293
step: 870, loss: 0.09974193572998047
step: 880, loss: 0.15704621374607086
step: 890, loss: 0.0768929123878479
step: 900, loss: 0.03311347961425781
step: 910, loss: 0.09581390023231506
step: 920, loss: 0.04601819068193436
step: 930, loss: 0.049061369150877
step: 940, loss: 0.196885883808136
step: 950, loss: 0.06955399364233017
step: 960, loss: 0.14834262430667877
step: 970, loss: 0.05753513053059578
step: 980, loss: 0.1179487332701683
step: 990, loss: 0.08583260327577591
step: 1000, loss: 0.10093488544225693
step: 1010, loss: 0.1907391995191574
step: 1020, loss: 0.05559138208627701
step: 1030, loss: 0.11026940494775772
step: 1040, loss: 0.07857325673103333
step: 1050, loss: 0.09985329210758209
step: 1060, loss: 0.05106427147984505
step: 1070, loss: 0.05194715037941933
epoch 6: dev_f1=0.9275626423690205, f1=0.920921825576141, best_f1=0.9262672811059909
step: 0, loss: 0.06696534156799316
step: 10, loss: 0.115199014544487
step: 20, loss: 0.1354978382587433
step: 30, loss: 0.052620597183704376
step: 40, loss: 0.019641216844320297
step: 50, loss: 0.12002666294574738
step: 60, loss: 0.06037219613790512
step: 70, loss: 0.009897085838019848
step: 80, loss: 0.0576859675347805
step: 90, loss: 0.11208771169185638
step: 100, loss: 0.13565589487552643
step: 110, loss: 0.14364348351955414
step: 120, loss: 0.05148514360189438
step: 130, loss: 0.08130302280187607
step: 140, loss: 0.10947635024785995
step: 150, loss: 0.011823521926999092
step: 160, loss: 0.07126825302839279
step: 170, loss: 0.06634950637817383
step: 180, loss: 0.05172963812947273
step: 190, loss: 0.09165594726800919
step: 200, loss: 0.13965047895908356
step: 210, loss: 0.05377906188368797
step: 220, loss: 0.005017229821532965
step: 230, loss: 0.13563530147075653
step: 240, loss: 0.16709809005260468
step: 250, loss: 0.13865366578102112
step: 260, loss: 0.0784938782453537
step: 270, loss: 0.015244534239172935
step: 280, loss: 0.10947391390800476
step: 290, loss: 0.03749276325106621
step: 300, loss: 0.11669458448886871
step: 310, loss: 0.0990859642624855
step: 320, loss: 0.028771897777915
step: 330, loss: 0.1458785980939865
step: 340, loss: 0.11566822230815887
step: 350, loss: 0.016725832596421242
step: 360, loss: 0.06915448606014252
step: 370, loss: 0.1587243378162384
step: 380, loss: 0.15365692973136902
step: 390, loss: 0.041312821209430695
step: 400, loss: 0.031384218484163284
step: 410, loss: 0.06789190322160721
step: 420, loss: 0.08070269227027893
step: 430, loss: 0.06722641736268997
step: 440, loss: 0.16721318662166595
step: 450, loss: 0.08576478809118271
step: 460, loss: 0.04134674742817879
step: 470, loss: 0.11327043175697327
step: 480, loss: 0.07474818825721741
step: 490, loss: 0.08391189575195312
step: 500, loss: 0.053941480815410614
step: 510, loss: 0.015943016856908798
step: 520, loss: 0.08076559007167816
step: 530, loss: 0.0763169601559639
step: 540, loss: 0.05136381834745407
step: 550, loss: 0.04363223910331726
step: 560, loss: 0.029155371710658073
step: 570, loss: 0.17142854630947113
step: 580, loss: 0.11084884405136108
step: 590, loss: 0.05133773013949394
step: 600, loss: 0.12349337339401245
step: 610, loss: 0.08207030594348907
step: 620, loss: 0.017596662044525146
step: 630, loss: 0.1722782999277115
step: 640, loss: 0.07537077367305756
step: 650, loss: 0.1592157781124115
step: 660, loss: 0.03418465703725815
step: 670, loss: 0.11211030185222626
step: 680, loss: 0.1296902894973755
step: 690, loss: 0.08977241069078445
step: 700, loss: 0.008551646955311298
step: 710, loss: 0.12119767814874649
step: 720, loss: 0.014906836673617363
step: 730, loss: 0.08743296563625336
step: 740, loss: 0.1292179971933365
step: 750, loss: 0.029335079714655876
step: 760, loss: 0.0332651250064373
step: 770, loss: 0.04052416607737541
step: 780, loss: 0.0776679515838623
step: 790, loss: 0.09862207621335983
step: 800, loss: 0.07127977907657623
step: 810, loss: 0.04241766035556793
step: 820, loss: 0.08979509025812149
step: 830, loss: 0.030298763886094093
step: 840, loss: 0.1469845473766327
step: 850, loss: 0.06802774220705032
step: 860, loss: 0.03941342607140541
step: 870, loss: 0.09344052523374557
step: 880, loss: 0.06151695176959038
step: 890, loss: 0.02252480387687683
step: 900, loss: 0.09514947980642319
step: 910, loss: 0.032670848071575165
step: 920, loss: 0.15733033418655396
step: 930, loss: 0.05672585964202881
step: 940, loss: 0.0955875962972641
step: 950, loss: 0.06937186419963837
step: 960, loss: 0.12604719400405884
step: 970, loss: 0.05132332071661949
step: 980, loss: 0.09186415374279022
step: 990, loss: 0.01978881284594536
step: 1000, loss: 0.018841909244656563
step: 1010, loss: 0.06278632581233978
step: 1020, loss: 0.035987529903650284
step: 1030, loss: 0.015577360987663269
step: 1040, loss: 0.060217536985874176
step: 1050, loss: 0.039921581745147705
step: 1060, loss: 0.0938924178481102
step: 1070, loss: 0.02339787967503071
epoch 7: dev_f1=0.9309225776541493, f1=0.9312906220984216, best_f1=0.9312906220984216
step: 0, loss: 0.18043529987335205
step: 10, loss: 0.07697472721338272
step: 20, loss: 0.06632211059331894
step: 30, loss: 0.03794495761394501
step: 40, loss: 0.12125454097986221
step: 50, loss: 0.14171557128429413
step: 60, loss: 0.04083225503563881
step: 70, loss: 0.05377959460020065
step: 80, loss: 0.17264319956302643
step: 90, loss: 0.004565703682601452
step: 100, loss: 0.0072306920774281025
step: 110, loss: 0.06457071751356125
step: 120, loss: 0.04017516225576401
step: 130, loss: 0.016398634761571884
step: 140, loss: 0.04552318900823593
step: 150, loss: 0.04578156769275665
step: 160, loss: 0.04593424126505852
step: 170, loss: 0.14917674660682678
step: 180, loss: 0.018627023324370384
step: 190, loss: 0.07956390827894211
step: 200, loss: 0.08138050884008408
step: 210, loss: 0.06877118349075317
step: 220, loss: 0.07054711133241653
step: 230, loss: 0.07459903508424759
step: 240, loss: 0.020548459142446518
step: 250, loss: 0.047731708735227585
step: 260, loss: 0.15322288870811462
step: 270, loss: 0.03179934248328209
step: 280, loss: 0.07091092318296432
step: 290, loss: 0.14889732003211975
step: 300, loss: 0.06311935931444168
step: 310, loss: 0.05889534950256348
step: 320, loss: 0.0848139226436615
step: 330, loss: 0.0317700169980526
step: 340, loss: 0.06562124937772751
step: 350, loss: 0.06433724611997604
step: 360, loss: 0.06342161446809769
step: 370, loss: 0.120028056204319
step: 380, loss: 0.14740388095378876
step: 390, loss: 0.08160197734832764
step: 400, loss: 0.05909047648310661
step: 410, loss: 0.12927961349487305
step: 420, loss: 0.1676861196756363
step: 430, loss: 0.06941920518875122
step: 440, loss: 0.04482674226164818
step: 450, loss: 0.20806434750556946
step: 460, loss: 0.04384099692106247
step: 470, loss: 0.03148501366376877
step: 480, loss: 0.023100465536117554
step: 490, loss: 0.01732601225376129
step: 500, loss: 0.026472900062799454
step: 510, loss: 0.031224094331264496
step: 520, loss: 0.09965572506189346
step: 530, loss: 0.07260388135910034
step: 540, loss: 0.10010816901922226
step: 550, loss: 0.1320527046918869
step: 560, loss: 0.013371159322559834
step: 570, loss: 0.08722938597202301
step: 580, loss: 0.04161454364657402
step: 590, loss: 0.1459263116121292
step: 600, loss: 0.13678474724292755
step: 610, loss: 0.11385056376457214
step: 620, loss: 0.05208621919155121
step: 630, loss: 0.08278532326221466
step: 640, loss: 0.1392289698123932
step: 650, loss: 0.11588609963655472
step: 660, loss: 0.011957535520195961
step: 670, loss: 0.12181974947452545
step: 680, loss: 0.23467066884040833
step: 690, loss: 0.055797137320041656
step: 700, loss: 0.09860078990459442
step: 710, loss: 0.023571299389004707
step: 720, loss: 0.01605171151459217
step: 730, loss: 0.0625600516796112
step: 740, loss: 0.06042367219924927
step: 750, loss: 0.04593661054968834
step: 760, loss: 0.055720921605825424
step: 770, loss: 0.12359457463026047
step: 780, loss: 0.02941293828189373
step: 790, loss: 0.059674546122550964
step: 800, loss: 0.07778723537921906
step: 810, loss: 0.05144625902175903
step: 820, loss: 0.11293254792690277
step: 830, loss: 0.05078227072954178
step: 840, loss: 0.09637387841939926
step: 850, loss: 0.1881166696548462
step: 860, loss: 0.06177903711795807
step: 870, loss: 0.03572247177362442
step: 880, loss: 0.10934560745954514
step: 890, loss: 0.057940978556871414
step: 900, loss: 0.05783815309405327
step: 910, loss: 0.029020998626947403
step: 920, loss: 0.16199706494808197
step: 930, loss: 0.009034578688442707
step: 940, loss: 0.05544858053326607
step: 950, loss: 0.12187020480632782
step: 960, loss: 0.01853896863758564
step: 970, loss: 0.024087024852633476
step: 980, loss: 0.06137800216674805
step: 990, loss: 0.12173667550086975
step: 1000, loss: 0.10428149253129959
step: 1010, loss: 0.09309709072113037
step: 1020, loss: 0.07945719361305237
step: 1030, loss: 0.05736672505736351
step: 1040, loss: 0.11189882457256317
step: 1050, loss: 0.04078202322125435
step: 1060, loss: 0.12560799717903137
step: 1070, loss: 0.070330411195755
epoch 8: dev_f1=0.9312839059674503, f1=0.9280217292892712, best_f1=0.9280217292892712
step: 0, loss: 0.03530723229050636
step: 10, loss: 0.01957518979907036
step: 20, loss: 0.04529785364866257
step: 30, loss: 0.05766745284199715
step: 40, loss: 0.07565509527921677
step: 50, loss: 0.05661642551422119
step: 60, loss: 0.10190418362617493
step: 70, loss: 0.15792720019817352
step: 80, loss: 0.00914707686752081
step: 90, loss: 0.03718450292944908
step: 100, loss: 0.032371580600738525
step: 110, loss: 0.07066608965396881
step: 120, loss: 0.03331904485821724
step: 130, loss: 0.014483539387583733
step: 140, loss: 0.16962561011314392
step: 150, loss: 0.07619169354438782
step: 160, loss: 0.07313582301139832
step: 170, loss: 0.04830523952841759
step: 180, loss: 0.058341797441244125
step: 190, loss: 0.00809858925640583
step: 200, loss: 0.08538231998682022
step: 210, loss: 0.005718177650123835
step: 220, loss: 0.04329776018857956
step: 230, loss: 0.010347111150622368
step: 240, loss: 0.11921319365501404
step: 250, loss: 0.0294855497777462
step: 260, loss: 0.05243076756596565
step: 270, loss: 0.20143790543079376
step: 280, loss: 0.060944121330976486
step: 290, loss: 0.03667056933045387
step: 300, loss: 0.018943242728710175
step: 310, loss: 0.052640605717897415
step: 320, loss: 0.3025728166103363
step: 330, loss: 0.1721995323896408
step: 340, loss: 0.01744663342833519
step: 350, loss: 0.050114985555410385
step: 360, loss: 0.053209658712148666
step: 370, loss: 0.14509926736354828
step: 380, loss: 0.017360566183924675
step: 390, loss: 0.07076170295476913
step: 400, loss: 0.01450932677835226
step: 410, loss: 0.03588481992483139
step: 420, loss: 0.07155893743038177
step: 430, loss: 0.03659588471055031
step: 440, loss: 0.02694620005786419
step: 450, loss: 0.13989877700805664
step: 460, loss: 0.04385711997747421
step: 470, loss: 0.05403819680213928
step: 480, loss: 0.023180264979600906
step: 490, loss: 0.04234854504466057
step: 500, loss: 0.013579840771853924
step: 510, loss: 0.14718958735466003
step: 520, loss: 0.12059153616428375
step: 530, loss: 0.07638473063707352
step: 540, loss: 0.03622722253203392
step: 550, loss: 0.20523600280284882
step: 560, loss: 0.1559920310974121
step: 570, loss: 0.11092294007539749
step: 580, loss: 0.12274300307035446
step: 590, loss: 0.0897926613688469
step: 600, loss: 0.055701740086078644
step: 610, loss: 0.055161118507385254
step: 620, loss: 7.362874748650938e-05
step: 630, loss: 0.023206213489174843
step: 640, loss: 0.050948649644851685
step: 650, loss: 0.2767792046070099
step: 660, loss: 0.012676483020186424
step: 670, loss: 0.03907770290970802
step: 680, loss: 0.04536382108926773
step: 690, loss: 0.07390350848436356
step: 700, loss: 0.009397110901772976
step: 710, loss: 0.0332217663526535
step: 720, loss: 0.04522150009870529
step: 730, loss: 0.08261992037296295
step: 740, loss: 0.07631193101406097
step: 750, loss: 0.09081805497407913
step: 760, loss: 0.07767852395772934
step: 770, loss: 0.057334065437316895
step: 780, loss: 0.07010526210069656
step: 790, loss: 0.05488768219947815
step: 800, loss: 0.07394161820411682
step: 810, loss: 0.09594745934009552
step: 820, loss: 0.09455452859401703
step: 830, loss: 0.17341819405555725
step: 840, loss: 0.09810340404510498
step: 850, loss: 0.05274634435772896
step: 860, loss: 0.11263804882764816
step: 870, loss: 0.03520473092794418
step: 880, loss: 0.03999719023704529
step: 890, loss: 0.01281948946416378
step: 900, loss: 0.0823790580034256
step: 910, loss: 0.19848547875881195
step: 920, loss: 0.055318959057331085
step: 930, loss: 0.05388972535729408
step: 940, loss: 0.09821517765522003
step: 950, loss: 0.03624192997813225
step: 960, loss: 0.06772022694349289
step: 970, loss: 0.017943482846021652
step: 980, loss: 0.04086516425013542
step: 990, loss: 0.18713299930095673
step: 1000, loss: 0.19010406732559204
step: 1010, loss: 0.12087841331958771
step: 1020, loss: 0.09656716138124466
step: 1030, loss: 0.007174724247306585
step: 1040, loss: 0.1032136008143425
step: 1050, loss: 0.07881056517362595
step: 1060, loss: 0.08512454479932785
step: 1070, loss: 0.02946067973971367
epoch 9: dev_f1=0.929368029739777, f1=0.9302540415704387, best_f1=0.9280217292892712
step: 0, loss: 0.07719078660011292
step: 10, loss: 0.08239923417568207
step: 20, loss: 0.12965765595436096
step: 30, loss: 0.014490188099443913
step: 40, loss: 0.14645230770111084
step: 50, loss: 0.002567677991464734
step: 60, loss: 0.0482962392270565
step: 70, loss: 0.0456891804933548
step: 80, loss: 0.06917732208967209
step: 90, loss: 0.09374396502971649
step: 100, loss: 0.059214022010564804
step: 110, loss: 0.08437506854534149
step: 120, loss: 0.04777500405907631
step: 130, loss: 0.02283146046102047
step: 140, loss: 0.09178829193115234
step: 150, loss: 0.01742102950811386
step: 160, loss: 0.1002403050661087
step: 170, loss: 0.11787207424640656
step: 180, loss: 0.06967933475971222
step: 190, loss: 0.016041381284594536
step: 200, loss: 0.07394791394472122
step: 210, loss: 0.09704384952783585
step: 220, loss: 0.07660101354122162
step: 230, loss: 0.030198393389582634
step: 240, loss: 0.17457114160060883
step: 250, loss: 0.05356186255812645
step: 260, loss: 0.02945875935256481
step: 270, loss: 0.0816030502319336
step: 280, loss: 0.08685070276260376
step: 290, loss: 0.04008430242538452
step: 300, loss: 0.1944022923707962
step: 310, loss: 0.08276107907295227
step: 320, loss: 0.10561154782772064
step: 330, loss: 0.09646479040384293
step: 340, loss: 0.03863712400197983
step: 350, loss: 0.03214626759290695
step: 360, loss: 0.09553733468055725
step: 370, loss: 0.06980467587709427
step: 380, loss: 0.08834566920995712
step: 390, loss: 0.045633770525455475
step: 400, loss: 0.0401492640376091
step: 410, loss: 0.1368783861398697
step: 420, loss: 0.014895470812916756
step: 430, loss: 0.14570367336273193
step: 440, loss: 0.054583050310611725
step: 450, loss: 0.0638791024684906
step: 460, loss: 0.009199703112244606
step: 470, loss: 0.06059965863823891
step: 480, loss: 0.06488432735204697
step: 490, loss: 0.07349450886249542
step: 500, loss: 0.02850077860057354
step: 510, loss: 0.04408866539597511
step: 520, loss: 0.028142238035798073
step: 530, loss: 0.011696583591401577
step: 540, loss: 0.15628761053085327
step: 550, loss: 0.09469349682331085
step: 560, loss: 0.02195296622812748
step: 570, loss: 0.048422832041978836
step: 580, loss: 0.09621349722146988
step: 590, loss: 0.015116470865905285
step: 600, loss: 0.10579126328229904
step: 610, loss: 0.10156354308128357
step: 620, loss: 0.15048937499523163
step: 630, loss: 0.0005146776675246656
step: 640, loss: 0.05414322018623352
step: 650, loss: 0.014894125051796436
step: 660, loss: 0.1129121407866478
step: 670, loss: 0.05099523067474365
step: 680, loss: 0.058540262281894684
step: 690, loss: 0.04395270720124245
step: 700, loss: 0.05191744118928909
step: 710, loss: 0.078113853931427
step: 720, loss: 0.09684818983078003
step: 730, loss: 0.06675510108470917
step: 740, loss: 0.13211692869663239
step: 750, loss: 0.07648549228906631
step: 760, loss: 0.06870917975902557
step: 770, loss: 0.06944277882575989
step: 780, loss: 0.03224924951791763
step: 790, loss: 0.13555766642093658
step: 800, loss: 0.16012151539325714
step: 810, loss: 0.046202462166547775
step: 820, loss: 0.02705405093729496
step: 830, loss: 0.09522176533937454
step: 840, loss: 0.057619377970695496
step: 850, loss: 0.03945893794298172
step: 860, loss: 0.06594066321849823
step: 870, loss: 0.11548611521720886
step: 880, loss: 0.028664926066994667
step: 890, loss: 0.0907474011182785
step: 900, loss: 0.16186773777008057
step: 910, loss: 0.017986997961997986
step: 920, loss: 0.06919342279434204
step: 930, loss: 0.13315492868423462
step: 940, loss: 0.11595738679170609
step: 950, loss: 0.10506118088960648
step: 960, loss: 0.058052513748407364
step: 970, loss: 0.011008482426404953
step: 980, loss: 0.08384712785482407
step: 990, loss: 0.04065635800361633
step: 1000, loss: 0.06969207525253296
step: 1010, loss: 0.05066557228565216
step: 1020, loss: 1.9147739294567145e-05
step: 1030, loss: 0.07104723155498505
step: 1040, loss: 0.005676378030329943
step: 1050, loss: 0.07650651782751083
step: 1060, loss: 0.15749192237854004
step: 1070, loss: 0.03236320614814758
epoch 10: dev_f1=0.9284064665127021, f1=0.9286700414173953, best_f1=0.9280217292892712
step: 0, loss: 0.033555857837200165
step: 10, loss: 0.10882284492254257
step: 20, loss: 0.10187675803899765
step: 30, loss: 0.003260798752307892
step: 40, loss: 0.03467635437846184
step: 50, loss: 0.1078232005238533
step: 60, loss: 0.02573223225772381
step: 70, loss: 0.11354967951774597
step: 80, loss: 0.06053512543439865
step: 90, loss: 0.02722107246518135
step: 100, loss: 0.01354509312659502
step: 110, loss: 0.0011405161349102855
step: 120, loss: 0.07701452821493149
step: 130, loss: 0.07695650309324265
step: 140, loss: 0.001720235450193286
step: 150, loss: 0.13571062684059143
step: 160, loss: 0.0655968189239502
step: 170, loss: 0.036748141050338745
step: 180, loss: 0.11686249077320099
step: 190, loss: 0.007612176239490509
step: 200, loss: 0.018660351634025574
step: 210, loss: 0.03723442554473877
step: 220, loss: 0.04104061424732208
step: 230, loss: 0.08993944525718689
step: 240, loss: 0.04899578541517258
step: 250, loss: 0.05432070791721344
step: 260, loss: 0.0915970653295517
step: 270, loss: 0.03852766007184982
step: 280, loss: 0.04034898430109024
step: 290, loss: 0.05815654247999191
step: 300, loss: 0.07762324064970016
step: 310, loss: 0.027088938280940056
step: 320, loss: 0.10804569721221924
step: 330, loss: 0.173476904630661
step: 340, loss: 1.66556092153769e-05
step: 350, loss: 0.04243142902851105
step: 360, loss: 0.028229035437107086
step: 370, loss: 0.0014724525390192866
step: 380, loss: 0.07180571556091309
step: 390, loss: 0.06507083028554916
step: 400, loss: 0.0784681960940361
step: 410, loss: 0.035809535533189774
step: 420, loss: 0.10828949511051178
step: 430, loss: 0.07339948415756226
step: 440, loss: 0.03078591451048851
step: 450, loss: 0.021762484684586525
step: 460, loss: 0.0010949114803224802
step: 470, loss: 0.07455655932426453
step: 480, loss: 0.10868241637945175
step: 490, loss: 0.15080741047859192
step: 500, loss: 0.05513570457696915
step: 510, loss: 0.047933969646692276
step: 520, loss: 0.06126809120178223
step: 530, loss: 0.03523446246981621
step: 540, loss: 0.013950017280876637
step: 550, loss: 0.002529079094529152
step: 560, loss: 0.06107720732688904
step: 570, loss: 0.10082966834306717
step: 580, loss: 0.011484303511679173
step: 590, loss: 0.002250839490443468
step: 600, loss: 0.038115814328193665
step: 610, loss: 0.02624199539422989
step: 620, loss: 0.12135271728038788
step: 630, loss: 0.31139838695526123
step: 640, loss: 0.040114887058734894
step: 650, loss: 0.09213339537382126
step: 660, loss: 0.03246038034558296
step: 670, loss: 0.04306444525718689
step: 680, loss: 0.10986955463886261
step: 690, loss: 0.05782702565193176
step: 700, loss: 0.0014583541778847575
step: 710, loss: 0.09674135595560074
step: 720, loss: 0.14474686980247498
step: 730, loss: 0.06445465981960297
step: 740, loss: 0.081965371966362
step: 750, loss: 0.06197533756494522
step: 760, loss: 0.059478309005498886
step: 770, loss: 0.054196733981370926
step: 780, loss: 0.06438301503658295
step: 790, loss: 0.057228732854127884
step: 800, loss: 0.021208738908171654
step: 810, loss: 0.1320062279701233
step: 820, loss: 0.03589174151420593
step: 830, loss: 0.0178031288087368
step: 840, loss: 0.07061455398797989
step: 850, loss: 0.04509545862674713
step: 860, loss: 0.030199790373444557
step: 870, loss: 0.04294232279062271
step: 880, loss: 0.030142076313495636
step: 890, loss: 0.01251818984746933
step: 900, loss: 0.0971793532371521
step: 910, loss: 0.06094484031200409
step: 920, loss: 0.06739386171102524
step: 930, loss: 0.03614272549748421
step: 940, loss: 0.11915957182645798
step: 950, loss: 0.04710015282034874
step: 960, loss: 0.0715828686952591
step: 970, loss: 0.12230712920427322
step: 980, loss: 0.05387042462825775
step: 990, loss: 0.029292332008481026
step: 1000, loss: 0.08989541232585907
step: 1010, loss: 0.2188236266374588
step: 1020, loss: 0.07063470035791397
step: 1030, loss: 0.01072011049836874
step: 1040, loss: 0.04484626650810242
step: 1050, loss: 0.01490765530616045
step: 1060, loss: 0.07358155399560928
step: 1070, loss: 0.12424001842737198
epoch 11: dev_f1=0.9259944495837188, f1=0.9231481481481482, best_f1=0.9280217292892712
step: 0, loss: 0.026346083730459213
step: 10, loss: 0.018227593973279
step: 20, loss: 0.13872778415679932
step: 30, loss: 0.02439916878938675
step: 40, loss: 0.0648302212357521
step: 50, loss: 0.036977726966142654
step: 60, loss: 0.04147714003920555
step: 70, loss: 0.013392763212323189
step: 80, loss: 0.08842621743679047
step: 90, loss: 0.08927087485790253
step: 100, loss: 0.08649030327796936
step: 110, loss: 0.0727061927318573
step: 120, loss: 0.0793873518705368
step: 130, loss: 0.04187113791704178
step: 140, loss: 0.028016475960612297
step: 150, loss: 0.11213506758213043
step: 160, loss: 0.02390807680785656
step: 170, loss: 0.04413982108235359
step: 180, loss: 0.021289533004164696
step: 190, loss: 0.10144207626581192
step: 200, loss: 0.05424260348081589
step: 210, loss: 0.03828603774309158
step: 220, loss: 0.07795210182666779
step: 230, loss: 0.07955560833215714
step: 240, loss: 0.00015798391541466117
step: 250, loss: 0.04717790707945824
step: 260, loss: 0.05505574122071266
step: 270, loss: 0.0022424845956265926
step: 280, loss: 0.05933156982064247
step: 290, loss: 0.13641756772994995
step: 300, loss: 0.13148707151412964
step: 310, loss: 0.017084898427128792
step: 320, loss: 0.06857576966285706
step: 330, loss: 0.000234706632909365
step: 340, loss: 0.09581905603408813
step: 350, loss: 0.049572013318538666
step: 360, loss: 0.03782745078206062
step: 370, loss: 0.03631116822361946
step: 380, loss: 0.22318677604198456
step: 390, loss: 0.04522642493247986
step: 400, loss: 0.08410436660051346
step: 410, loss: 0.03473581746220589
step: 420, loss: 0.00662659527733922
step: 430, loss: 0.06515678763389587
step: 440, loss: 0.13025648891925812
step: 450, loss: 0.08133449405431747
step: 460, loss: 0.03594934567809105
step: 470, loss: 0.0243572685867548
step: 480, loss: 0.1501467078924179
step: 490, loss: 0.059358540922403336
step: 500, loss: 0.07069598138332367
step: 510, loss: 0.04823538661003113
step: 520, loss: 0.11217887699604034
step: 530, loss: 0.0010287058539688587
step: 540, loss: 0.00430704839527607
step: 550, loss: 0.020350169390439987
step: 560, loss: 0.05812900513410568
step: 570, loss: 0.07048491388559341
step: 580, loss: 0.0737047791481018
step: 590, loss: 0.0780683383345604
step: 600, loss: 0.09392928332090378
step: 610, loss: 0.049893878400325775
step: 620, loss: 0.039384789764881134
step: 630, loss: 0.03643827885389328
step: 640, loss: 0.07298172265291214
step: 650, loss: 0.006585119757801294
step: 660, loss: 0.01503391470760107
step: 670, loss: 0.0670006275177002
step: 680, loss: 0.07042057812213898
step: 690, loss: 0.029146943241357803
step: 700, loss: 0.060780979692935944
step: 710, loss: 0.03088478185236454
step: 720, loss: 0.12183105945587158
step: 730, loss: 0.03883408382534981
step: 740, loss: 0.011407796293497086
step: 750, loss: 0.08312398940324783
step: 760, loss: 0.031176969408988953
step: 770, loss: 0.08628220856189728
step: 780, loss: 0.2071342021226883
step: 790, loss: 0.04778366908431053
step: 800, loss: 0.11002200096845627
step: 810, loss: 0.02191837504506111
step: 820, loss: 0.03969329968094826
step: 830, loss: 0.08310673385858536
step: 840, loss: 0.0743068978190422
step: 850, loss: 0.06565433740615845
step: 860, loss: 0.0772223025560379
step: 870, loss: 0.11430421471595764
step: 880, loss: 0.11722306907176971
step: 890, loss: 0.05463061481714249
step: 900, loss: 0.04234236851334572
step: 910, loss: 0.09381610155105591
step: 920, loss: 0.0247853584587574
step: 930, loss: 0.036066509783267975
step: 940, loss: 0.06360257416963577
step: 950, loss: 0.014047075994312763
step: 960, loss: 0.09371078014373779
step: 970, loss: 0.12846587598323822
step: 980, loss: 0.0602535717189312
step: 990, loss: 0.02473747916519642
step: 1000, loss: 0.10820583254098892
step: 1010, loss: 0.10908691585063934
step: 1020, loss: 0.03912894427776337
step: 1030, loss: 0.10272834450006485
step: 1040, loss: 0.0001040921124513261
step: 1050, loss: 0.017420146614313126
step: 1060, loss: 0.07658183574676514
step: 1070, loss: 0.026063932105898857
epoch 12: dev_f1=0.9208831646734131, f1=0.9223702342673403, best_f1=0.9280217292892712
step: 0, loss: 0.10597997158765793
step: 10, loss: 0.09393199533224106
step: 20, loss: 0.008371612057089806
step: 30, loss: 0.019732344895601273
step: 40, loss: 0.046237122267484665
step: 50, loss: 0.04654248058795929
step: 60, loss: 0.0003356439992785454
step: 70, loss: 0.08873549103736877
step: 80, loss: 0.07375873625278473
step: 90, loss: 0.009081457741558552
step: 100, loss: 0.06748638302087784
step: 110, loss: 0.06986558437347412
step: 120, loss: 0.02424963191151619
step: 130, loss: 0.031438518315553665
step: 140, loss: 0.022687576711177826
step: 150, loss: 0.07568696141242981
step: 160, loss: 0.004967206157743931
step: 170, loss: 0.008830574341118336
step: 180, loss: 0.009380326606333256
step: 190, loss: 0.05745764449238777
step: 200, loss: 0.11678892374038696
step: 210, loss: 0.059632014483213425
step: 220, loss: 0.06908269971609116
step: 230, loss: 0.0908597856760025
step: 240, loss: 0.1049526184797287
step: 250, loss: 0.04330316558480263
step: 260, loss: 0.07457368820905685
step: 270, loss: 0.024277346208691597
step: 280, loss: 0.09010785818099976
step: 290, loss: 0.05489638075232506
step: 300, loss: 0.12881654500961304
step: 310, loss: 0.09373858571052551
step: 320, loss: 0.0072874645702540874
step: 330, loss: 0.09522885829210281
step: 340, loss: 0.06849578022956848
step: 350, loss: 0.04751155897974968
step: 360, loss: 0.021885305643081665
step: 370, loss: 0.031223012134432793
step: 380, loss: 0.031907837837934494
step: 390, loss: 0.041881296783685684
step: 400, loss: 0.04230329394340515
step: 410, loss: 0.07966312766075134
step: 420, loss: 0.03165536746382713
step: 430, loss: 0.017958955839276314
step: 440, loss: 0.10208957642316818
step: 450, loss: 0.06340853869915009
step: 460, loss: 0.031148143112659454
step: 470, loss: 0.01972821354866028
step: 480, loss: 0.05131823942065239
step: 490, loss: 0.019849954172968864
step: 500, loss: 0.028470564633607864
step: 510, loss: 0.08530521392822266
step: 520, loss: 0.06712915748357773
step: 530, loss: 0.07012035697698593
step: 540, loss: 0.04115287959575653
step: 550, loss: 0.02477259188890457
step: 560, loss: 0.02053096890449524
step: 570, loss: 0.0558641254901886
step: 580, loss: 0.05135222151875496
step: 590, loss: 0.02099303901195526
step: 600, loss: 0.050695762038230896
step: 610, loss: 0.034798551350831985
step: 620, loss: 0.0007922163931652904
step: 630, loss: 0.024583540856838226
step: 640, loss: 0.022113483399152756
step: 650, loss: 0.054683584719896317
step: 660, loss: 0.049364909529685974
step: 670, loss: 0.029698697850108147
step: 680, loss: 0.03636782243847847
step: 690, loss: 0.1605611890554428
step: 700, loss: 0.07021509110927582
step: 710, loss: 0.016673840582370758
step: 720, loss: 0.03646354749798775
step: 730, loss: 0.10176637023687363
step: 740, loss: 0.07205658406019211
step: 750, loss: 0.013636188581585884
step: 760, loss: 0.0629207119345665
step: 770, loss: 0.09563246369361877
step: 780, loss: 0.022016232833266258
step: 790, loss: 0.06021054834127426
step: 800, loss: 0.037799935787916183
step: 810, loss: 0.03994100168347359
step: 820, loss: 0.013056095689535141
step: 830, loss: 0.013245800510048866
step: 840, loss: 0.06914934515953064
step: 850, loss: 0.028151709586381912
step: 860, loss: 0.19306014478206635
step: 870, loss: 0.05024697631597519
step: 880, loss: 0.06785501539707184
step: 890, loss: 0.09363985806703568
step: 900, loss: 0.11826186627149582
step: 910, loss: 0.015599810518324375
step: 920, loss: 0.08564003556966782
step: 930, loss: 0.1542142778635025
step: 940, loss: 0.04247744381427765
step: 950, loss: 0.025084519758820534
step: 960, loss: 0.06496302783489227
step: 970, loss: 0.04536290466785431
step: 980, loss: 0.06025207042694092
step: 990, loss: 0.0984199047088623
step: 1000, loss: 0.06847041100263596
step: 1010, loss: 0.02275354601442814
step: 1020, loss: 0.0401589572429657
step: 1030, loss: 0.0018460846040397882
step: 1040, loss: 0.025496292859315872
step: 1050, loss: 0.044040221720933914
step: 1060, loss: 0.029378283768892288
step: 1070, loss: 0.08385956287384033
epoch 13: dev_f1=0.9285714285714286, f1=0.9200945626477541, best_f1=0.9280217292892712
step: 0, loss: 0.04461506009101868
step: 10, loss: 0.032405007630586624
step: 20, loss: 0.053326964378356934
step: 30, loss: 0.09147725999355316
step: 40, loss: 0.046904586255550385
step: 50, loss: 0.04182516783475876
step: 60, loss: 0.058480195701122284
step: 70, loss: 0.0006601818022318184
step: 80, loss: 0.026813995093107224
step: 90, loss: 0.03181275352835655
step: 100, loss: 0.04693935438990593
step: 110, loss: 0.03066364675760269
step: 120, loss: 0.07946357876062393
step: 130, loss: 0.06169514358043671
step: 140, loss: 0.014328362420201302
step: 150, loss: 0.13235531747341156
step: 160, loss: 0.015229087322950363
step: 170, loss: 0.06722424179315567
step: 180, loss: 0.06913477927446365
step: 190, loss: 0.016892794519662857
step: 200, loss: 0.057218000292778015
step: 210, loss: 0.05270988121628761
step: 220, loss: 0.031932372599840164
step: 230, loss: 0.0065874564461410046
step: 240, loss: 0.0662144348025322
step: 250, loss: 0.0006708086002618074
step: 260, loss: 0.03920542821288109
step: 270, loss: 0.014389198273420334
step: 280, loss: 0.08688391745090485
step: 290, loss: 0.14432068169116974
step: 300, loss: 0.01743461936712265
step: 310, loss: 0.03231223300099373
step: 320, loss: 0.10348070412874222
step: 330, loss: 0.04110518470406532
step: 340, loss: 0.06606113165616989
step: 350, loss: 0.05656507983803749
step: 360, loss: 0.09531010687351227
step: 370, loss: 0.09101410955190659
step: 380, loss: 0.036444291472435
step: 390, loss: 0.03590524569153786
step: 400, loss: 0.059245675802230835
step: 410, loss: 0.053370412439107895
step: 420, loss: 0.05182722583413124
step: 430, loss: 0.08115490525960922
step: 440, loss: 0.009959468618035316
step: 450, loss: 0.11789465695619583
step: 460, loss: 0.1683252900838852
step: 470, loss: 0.1021207720041275
step: 480, loss: 0.0221250057220459
step: 490, loss: 0.024284610524773598
step: 500, loss: 0.13013209402561188
step: 510, loss: 0.046472858637571335
step: 520, loss: 0.08718408644199371
step: 530, loss: 0.025996902957558632
step: 540, loss: 0.0664004236459732
step: 550, loss: 0.07751801609992981
step: 560, loss: 0.07222869247198105
step: 570, loss: 0.016623083502054214
step: 580, loss: 0.03907555714249611
step: 590, loss: 0.04599340632557869
step: 600, loss: 0.0169404037296772
step: 610, loss: 0.042282626032829285
step: 620, loss: 0.046728383749723434
step: 630, loss: 0.12397371977567673
step: 640, loss: 0.05289265513420105
step: 650, loss: 0.12061753123998642
step: 660, loss: 0.05368754640221596
step: 670, loss: 0.05624183639883995
step: 680, loss: 0.036515865474939346
step: 690, loss: 0.14952248334884644
step: 700, loss: 0.08149118721485138
step: 710, loss: 0.038677580654621124
step: 720, loss: 0.07566395401954651
step: 730, loss: 0.07063601166009903
step: 740, loss: 0.11355558037757874
step: 750, loss: 0.09282813966274261
step: 760, loss: 0.026188325136899948
step: 770, loss: 0.05786443501710892
step: 780, loss: 0.0013822524342685938
step: 790, loss: 0.029645467177033424
step: 800, loss: 0.08648774772882462
step: 810, loss: 0.0001019476039800793
step: 820, loss: 0.029072230681777
step: 830, loss: 0.03653785586357117
step: 840, loss: 0.06425025314092636
step: 850, loss: 0.06649990379810333
step: 860, loss: 0.02529098466038704
step: 870, loss: 0.046084411442279816
step: 880, loss: 0.027387060225009918
step: 890, loss: 0.017573807388544083
step: 900, loss: 0.06166902929544449
step: 910, loss: 0.05979294329881668
step: 920, loss: 0.05343232676386833
step: 930, loss: 0.058244384825229645
step: 940, loss: 0.09422754496335983
step: 950, loss: 0.10385933518409729
step: 960, loss: 0.08759858459234238
step: 970, loss: 0.08201717585325241
step: 980, loss: 0.03228775039315224
step: 990, loss: 0.13997609913349152
step: 1000, loss: 0.048527080565690994
step: 1010, loss: 0.10035086423158646
step: 1020, loss: 0.04503081738948822
step: 1030, loss: 0.07133187353610992
step: 1040, loss: 0.1012592539191246
step: 1050, loss: 0.08731918036937714
step: 1060, loss: 0.06063353642821312
step: 1070, loss: 0.05075368285179138
epoch 14: dev_f1=0.9265054528212423, f1=0.92590844738084, best_f1=0.9280217292892712
step: 0, loss: 0.07479627430438995
step: 10, loss: 0.05963819846510887
step: 20, loss: 0.05649026110768318
step: 30, loss: 0.08625856786966324
step: 40, loss: 0.025901762768626213
step: 50, loss: 0.04368487745523453
step: 60, loss: 0.052592817693948746
step: 70, loss: 0.026798482984304428
step: 80, loss: 0.01900589093565941
step: 90, loss: 0.00374854844994843
step: 100, loss: 0.10660789161920547
step: 110, loss: 0.07886506617069244
step: 120, loss: 0.066950723528862
step: 130, loss: 0.002239240799099207
step: 140, loss: 0.06622036546468735
step: 150, loss: 0.03916851431131363
step: 160, loss: 0.04996802657842636
step: 170, loss: 0.002456884365528822
step: 180, loss: 0.0401177778840065
step: 190, loss: 0.05101076140999794
step: 200, loss: 0.06072510406374931
step: 210, loss: 0.04279981926083565
step: 220, loss: 0.040563419461250305
step: 230, loss: 0.06914468854665756
step: 240, loss: 0.05491774529218674
step: 250, loss: 7.836427539587021e-05
step: 260, loss: 0.09424719959497452
step: 270, loss: 0.05789577588438988
step: 280, loss: 0.06498567014932632
step: 290, loss: 0.032187122851610184
step: 300, loss: 0.028074488043785095
step: 310, loss: 0.03266420587897301
step: 320, loss: 0.055956266820430756
step: 330, loss: 0.008395309560000896
step: 340, loss: 0.043118659406900406
step: 350, loss: 0.019990649074316025
step: 360, loss: 0.03961364924907684
step: 370, loss: 0.0177635308355093
step: 380, loss: 0.0004731316876132041
step: 390, loss: 0.007793912198394537
step: 400, loss: 0.06797818094491959
step: 410, loss: 0.09452465176582336
step: 420, loss: 0.0030963290482759476
step: 430, loss: 0.04775046184659004
step: 440, loss: 0.014251098036766052
step: 450, loss: 0.10140034556388855
step: 460, loss: 0.001140445121563971
step: 470, loss: 0.11189404129981995
step: 480, loss: 0.09934872388839722
step: 490, loss: 0.011587864719331264
step: 500, loss: 0.09421096742153168
step: 510, loss: 0.08009599894285202
step: 520, loss: 0.06556223332881927
step: 530, loss: 0.07613664120435715
step: 540, loss: 0.03228333592414856
step: 550, loss: 0.030374718829989433
step: 560, loss: 0.04751652479171753
step: 570, loss: 0.016418693587183952
step: 580, loss: 0.10211166739463806
step: 590, loss: 0.029275573790073395
step: 600, loss: 4.621444531949237e-05
step: 610, loss: 0.09335999935865402
step: 620, loss: 0.12803612649440765
step: 630, loss: 0.034602563828229904
step: 640, loss: 0.06834015250205994
step: 650, loss: 0.05494977533817291
step: 660, loss: 0.002323758089914918
step: 670, loss: 0.05866395682096481
step: 680, loss: 0.06516362726688385
step: 690, loss: 0.00020265317289158702
step: 700, loss: 0.10053807497024536
step: 710, loss: 0.06597442924976349
step: 720, loss: 0.02787177264690399
step: 730, loss: 0.029346205294132233
step: 740, loss: 3.0411130865104496e-05
step: 750, loss: 0.03792642429471016
step: 760, loss: 0.02048077993094921
step: 770, loss: 0.01795358769595623
step: 780, loss: 0.0452275387942791
step: 790, loss: 0.07408807426691055
step: 800, loss: 0.05729266628623009
step: 810, loss: 0.07266595214605331
step: 820, loss: 0.07512436807155609
step: 830, loss: 0.0718732476234436
step: 840, loss: 0.015437436290085316
step: 850, loss: 0.00015986042853910476
step: 860, loss: 0.06388729065656662
step: 870, loss: 0.03811444714665413
step: 880, loss: 0.02200004830956459
step: 890, loss: 0.024588294327259064
step: 900, loss: 0.060166239738464355
step: 910, loss: 0.05135959014296532
step: 920, loss: 0.045157067477703094
step: 930, loss: 0.030803319066762924
step: 940, loss: 0.08057575672864914
step: 950, loss: 0.017745409160852432
step: 960, loss: 0.05744512751698494
step: 970, loss: 0.08745831996202469
step: 980, loss: 0.0269482284784317
step: 990, loss: 0.05252593010663986
step: 1000, loss: 0.03646618127822876
step: 1010, loss: 0.0493231862783432
step: 1020, loss: 0.08757413178682327
step: 1030, loss: 0.014682519249618053
step: 1040, loss: 0.09877751022577286
step: 1050, loss: 0.06969836354255676
step: 1060, loss: 0.07681412994861603
step: 1070, loss: 0.08979393541812897
epoch 15: dev_f1=0.922279792746114, f1=0.9220657276995305, best_f1=0.9280217292892712
step: 0, loss: 0.052781328558921814
step: 10, loss: 0.01459658145904541
step: 20, loss: 0.1541709154844284
step: 30, loss: 0.008984526619315147
step: 40, loss: 0.03265807777643204
step: 50, loss: 0.08978377282619476
step: 60, loss: 0.07473473995923996
step: 70, loss: 0.03355695679783821
step: 80, loss: 0.13450239598751068
step: 90, loss: 0.0011650450760498643
step: 100, loss: 0.03353945165872574
step: 110, loss: 0.04538869485259056
step: 120, loss: 0.03346218541264534
step: 130, loss: 0.04229692742228508
step: 140, loss: 0.014234085567295551
step: 150, loss: 0.0408756360411644
step: 160, loss: 0.0017511127516627312
step: 170, loss: 0.020519481971859932
step: 180, loss: 0.000991770881228149
step: 190, loss: 0.023991500958800316
step: 200, loss: 0.0410604327917099
step: 210, loss: 0.02565672993659973
step: 220, loss: 0.0004409112734720111
step: 230, loss: 0.05956202745437622
step: 240, loss: 0.0016296551330015063
step: 250, loss: 0.015874775126576424
step: 260, loss: 0.16843430697917938
step: 270, loss: 0.1153298020362854
step: 280, loss: 0.09093911945819855
step: 290, loss: 0.028732312843203545
step: 300, loss: 0.04175013303756714
step: 310, loss: 0.040816955268383026
step: 320, loss: 0.02372576855123043
step: 330, loss: 0.020603403449058533
step: 340, loss: 0.024654973298311234
step: 350, loss: 0.02824748121201992
step: 360, loss: 0.05461930111050606
step: 370, loss: 0.03749062120914459
step: 380, loss: 0.019306009635329247
step: 390, loss: 5.055639485362917e-05
step: 400, loss: 0.01043197326362133
step: 410, loss: 0.08529701083898544
step: 420, loss: 0.021499553695321083
step: 430, loss: 0.15214823186397552
step: 440, loss: 0.1752198040485382
step: 450, loss: 0.08005154877901077
step: 460, loss: 0.0708891898393631
step: 470, loss: 0.09173539280891418
step: 480, loss: 0.07696674019098282
step: 490, loss: 0.01852300576865673
step: 500, loss: 0.06331928819417953
step: 510, loss: 0.018831811845302582
step: 520, loss: 0.04742518439888954
step: 530, loss: 0.03850620985031128
step: 540, loss: 0.048624567687511444
step: 550, loss: 0.03825010359287262
step: 560, loss: 0.058347187936306
step: 570, loss: 0.030017860233783722
step: 580, loss: 0.054798226803541183
step: 590, loss: 0.04261590912938118
step: 600, loss: 0.06486689299345016
step: 610, loss: 0.05669180676341057
step: 620, loss: 9.589733963366598e-05
step: 630, loss: 0.008277365937829018
step: 640, loss: 0.09821271896362305
step: 650, loss: 0.08644863963127136
step: 660, loss: 0.06832899898290634
step: 670, loss: 0.03397015109658241
step: 680, loss: 0.0638786256313324
step: 690, loss: 4.659290789277293e-05
step: 700, loss: 2.2826454369351268e-05
step: 710, loss: 0.09894014149904251
step: 720, loss: 0.018018050119280815
step: 730, loss: 0.04088445007801056
step: 740, loss: 0.017903797328472137
step: 750, loss: 0.024064678698778152
step: 760, loss: 0.026533547788858414
step: 770, loss: 0.16353273391723633
step: 780, loss: 0.04351911321282387
step: 790, loss: 0.019732613116502762
step: 800, loss: 0.08119424432516098
step: 810, loss: 0.11876079440116882
step: 820, loss: 0.06016797944903374
step: 830, loss: 0.03816615790128708
step: 840, loss: 0.051975082606077194
step: 850, loss: 0.047717977315187454
step: 860, loss: 0.01996760442852974
step: 870, loss: 0.06802726536989212
step: 880, loss: 0.023046618327498436
step: 890, loss: 0.07178264111280441
step: 900, loss: 3.74783921870403e-05
step: 910, loss: 0.04303350672125816
step: 920, loss: 0.1252344399690628
step: 930, loss: 0.008238526061177254
step: 940, loss: 0.06321357935667038
step: 950, loss: 0.02993394434452057
step: 960, loss: 0.020207790657877922
step: 970, loss: 0.06701566278934479
step: 980, loss: 0.07796012610197067
step: 990, loss: 0.009742587804794312
step: 1000, loss: 0.04999064281582832
step: 1010, loss: 0.02056882157921791
step: 1020, loss: 0.08208881318569183
step: 1030, loss: 0.15468259155750275
step: 1040, loss: 0.047253821045160294
step: 1050, loss: 0.034486785531044006
step: 1060, loss: 0.005233794450759888
step: 1070, loss: 0.028597233816981316
epoch 16: dev_f1=0.9238770685579196, f1=0.9244486156733928, best_f1=0.9280217292892712
step: 0, loss: 0.1041061133146286
step: 10, loss: 0.028534531593322754
step: 20, loss: 0.1116621121764183
step: 30, loss: 0.08994267880916595
step: 40, loss: 0.027479704469442368
step: 50, loss: 0.008694104850292206
step: 60, loss: 0.08414351940155029
step: 70, loss: 0.044996730983257294
step: 80, loss: 0.07600606232881546
step: 90, loss: 0.041350770741701126
step: 100, loss: 0.07185323536396027
step: 110, loss: 0.0941467359662056
step: 120, loss: 0.06143218278884888
step: 130, loss: 0.00188356579747051
step: 140, loss: 0.07375748455524445
step: 150, loss: 0.08177550882101059
step: 160, loss: 8.566297765355557e-05
step: 170, loss: 0.014171963557600975
step: 180, loss: 0.008766437880694866
step: 190, loss: 0.022396931424736977
step: 200, loss: 0.002673755632713437
step: 210, loss: 0.0990552008152008
step: 220, loss: 0.024453453719615936
step: 230, loss: 0.025206636637449265
step: 240, loss: 0.009951857849955559
step: 250, loss: 0.04570476710796356
step: 260, loss: 0.0909164696931839
step: 270, loss: 0.03408683463931084
step: 280, loss: 0.03328276425600052
step: 290, loss: 0.02336682565510273
step: 300, loss: 0.054617300629615784
step: 310, loss: 0.05259065702557564
step: 320, loss: 0.022256959229707718
step: 330, loss: 0.02852115035057068
step: 340, loss: 0.02762988582253456
step: 350, loss: 0.05879366770386696
step: 360, loss: 0.00015315518248826265
step: 370, loss: 0.041025687009096146
step: 380, loss: 0.043574195355176926
step: 390, loss: 0.0017953853821381927
step: 400, loss: 0.02358265034854412
step: 410, loss: 0.07196133583784103
step: 420, loss: 0.07643439620733261
step: 430, loss: 0.04076346755027771
step: 440, loss: 0.03538847342133522
step: 450, loss: 0.03807033970952034
step: 460, loss: 0.0055439528077840805
step: 470, loss: 0.019179407507181168
step: 480, loss: 0.07544613629579544
step: 490, loss: 0.0332418829202652
step: 500, loss: 0.020170552656054497
step: 510, loss: 0.08009129017591476
step: 520, loss: 0.03394254297018051
step: 530, loss: 0.03689137101173401
step: 540, loss: 0.015061796642839909
step: 550, loss: 0.05222100764513016
step: 560, loss: 0.0063755810260772705
step: 570, loss: 0.07004765421152115
step: 580, loss: 0.03933939337730408
step: 590, loss: 0.04558949917554855
step: 600, loss: 0.01954103261232376
step: 610, loss: 0.07065551728010178
step: 620, loss: 0.10564491152763367
step: 630, loss: 0.031015222892165184
step: 640, loss: 0.12856855988502502
step: 650, loss: 0.03334859386086464
step: 660, loss: 0.06940004229545593
step: 670, loss: 0.06122833490371704
step: 680, loss: 0.024157702922821045
step: 690, loss: 0.0015074923867359757
step: 700, loss: 0.06694842129945755
step: 710, loss: 0.043136611580848694
step: 720, loss: 0.00043025147169828415
step: 730, loss: 0.036824241280555725
step: 740, loss: 0.049723926931619644
step: 750, loss: 0.048986610025167465
step: 760, loss: 0.015260664746165276
step: 770, loss: 0.04001057520508766
step: 780, loss: 0.06231892481446266
step: 790, loss: 0.07543614506721497
step: 800, loss: 0.01206431444734335
step: 810, loss: 0.15442495048046112
step: 820, loss: 0.055869024246931076
step: 830, loss: 0.047612715512514114
step: 840, loss: 0.042899079620838165
step: 850, loss: 0.024671325460076332
step: 860, loss: 0.033101484179496765
step: 870, loss: 0.03419698402285576
step: 880, loss: 0.02379498817026615
step: 890, loss: 0.014453827403485775
step: 900, loss: 0.029515981674194336
step: 910, loss: 0.017308730632066727
step: 920, loss: 0.08728976547718048
step: 930, loss: 0.08322950452566147
step: 940, loss: 0.03884736821055412
step: 950, loss: 0.04244883731007576
step: 960, loss: 0.04984378069639206
step: 970, loss: 0.04233906790614128
step: 980, loss: 0.05181653052568436
step: 990, loss: 0.015221643261611462
step: 1000, loss: 0.021352995187044144
step: 1010, loss: 0.09815124422311783
step: 1020, loss: 0.010686995461583138
step: 1030, loss: 0.041068002581596375
step: 1040, loss: 0.059107888489961624
step: 1050, loss: 0.02820008061826229
step: 1060, loss: 0.05175185203552246
step: 1070, loss: 0.05889245867729187
epoch 17: dev_f1=0.9258741258741259, f1=0.925290023201856, best_f1=0.9280217292892712
step: 0, loss: 0.07418153434991837
step: 10, loss: 0.06744464486837387
step: 20, loss: 0.00020453073375392705
step: 30, loss: 0.0814719870686531
step: 40, loss: 0.01316358707845211
step: 50, loss: 0.011876448057591915
step: 60, loss: 0.06774923205375671
step: 70, loss: 0.08500009030103683
step: 80, loss: 0.01976899988949299
step: 90, loss: 0.052564628422260284
step: 100, loss: 0.028269732370972633
step: 110, loss: 0.05667165294289589
step: 120, loss: 0.0266876257956028
step: 130, loss: 0.0016697924584150314
step: 140, loss: 0.026146385818719864
step: 150, loss: 0.1339210718870163
step: 160, loss: 0.0022125698160380125
step: 170, loss: 0.026033945381641388
step: 180, loss: 0.0656881257891655
step: 190, loss: 0.02785431407392025
step: 200, loss: 0.05636812746524811
step: 210, loss: 0.05690770968794823
step: 220, loss: 0.015051405876874924
step: 230, loss: 0.04208585247397423
step: 240, loss: 0.014040790498256683
step: 250, loss: 0.039493974298238754
step: 260, loss: 0.08901277184486389
step: 270, loss: 0.02823972888290882
step: 280, loss: 0.06674639135599136
step: 290, loss: 1.2274680557311513e-05
step: 300, loss: 0.06719188392162323
step: 310, loss: 0.08057400584220886
step: 320, loss: 0.04189397022128105
step: 330, loss: 0.10226110368967056
step: 340, loss: 0.07399903237819672
step: 350, loss: 1.6036910892580636e-05
step: 360, loss: 0.11569755524396896
step: 370, loss: 0.013619370758533478
step: 380, loss: 0.09313251823186874
step: 390, loss: 0.024137934669852257
step: 400, loss: 0.012917641550302505
step: 410, loss: 0.05621609464287758
step: 420, loss: 0.07202891260385513
step: 430, loss: 0.03078545816242695
step: 440, loss: 0.02108926698565483
step: 450, loss: 0.06335911154747009
step: 460, loss: 0.04205009341239929
step: 470, loss: 8.270874968729913e-05
step: 480, loss: 0.015889091417193413
step: 490, loss: 0.015419685281813145
step: 500, loss: 0.0990392416715622
step: 510, loss: 0.08544828742742538
step: 520, loss: 0.07500047981739044
step: 530, loss: 0.012580810114741325
step: 540, loss: 0.03881646320223808
step: 550, loss: 0.04094982519745827
step: 560, loss: 0.0008785351528786123
step: 570, loss: 0.04127985239028931
step: 580, loss: 0.07157706469297409
step: 590, loss: 0.06591759622097015
step: 600, loss: 0.07897012680768967
step: 610, loss: 0.02217075787484646
step: 620, loss: 0.032939597964286804
step: 630, loss: 0.030790425837039948
step: 640, loss: 0.07781929522752762
step: 650, loss: 0.06157094985246658
step: 660, loss: 0.03341516852378845
step: 670, loss: 0.021380646154284477
step: 680, loss: 0.06223825365304947
step: 690, loss: 0.07283830642700195
step: 700, loss: 0.043074287474155426
step: 710, loss: 0.06520092487335205
step: 720, loss: 0.06327584385871887
step: 730, loss: 6.437871343223378e-05
step: 740, loss: 0.05416771396994591
step: 750, loss: 0.05659322813153267
step: 760, loss: 0.05013265460729599
step: 770, loss: 0.027413571253418922
step: 780, loss: 0.09465029090642929
step: 790, loss: 0.13174331188201904
step: 800, loss: 0.013628924265503883
step: 810, loss: 0.002648088149726391
step: 820, loss: 0.006350926589220762
step: 830, loss: 0.030171368271112442
step: 840, loss: 6.13618831266649e-05
step: 850, loss: 0.045164357870817184
step: 860, loss: 0.022940965369343758
step: 870, loss: 0.019835790619254112
step: 880, loss: 0.07382477074861526
step: 890, loss: 0.04281356930732727
step: 900, loss: 0.03971393406391144
step: 910, loss: 0.10003801435232162
step: 920, loss: 0.07942838221788406
step: 930, loss: 0.011792209930717945
step: 940, loss: 0.057741839438676834
step: 950, loss: 0.017907697707414627
step: 960, loss: 0.029359498992562294
step: 970, loss: 0.021489035338163376
step: 980, loss: 0.06275173276662827
step: 990, loss: 0.027741650119423866
step: 1000, loss: 0.0005189772928133607
step: 1010, loss: 0.03227943927049637
step: 1020, loss: 0.028813239187002182
step: 1030, loss: 0.024253759533166885
step: 1040, loss: 0.11342112720012665
step: 1050, loss: 0.0382012240588665
step: 1060, loss: 0.09710245579481125
step: 1070, loss: 0.06599497050046921
epoch 18: dev_f1=0.9241706161137442, f1=0.9256120527306968, best_f1=0.9280217292892712
step: 0, loss: 0.024763494729995728
step: 10, loss: 0.0025425732601433992
step: 20, loss: 0.0001107504140236415
step: 30, loss: 0.027707712724804878
step: 40, loss: 9.112836414715275e-05
step: 50, loss: 1.120931119658053e-05
step: 60, loss: 0.04416736215353012
step: 70, loss: 0.039027657359838486
step: 80, loss: 0.06638973206281662
step: 90, loss: 0.031657468527555466
step: 100, loss: 0.03198767825961113
step: 110, loss: 0.0029754568822681904
step: 120, loss: 0.08548587560653687
step: 130, loss: 8.086251182248816e-05
step: 140, loss: 0.05006806179881096
step: 150, loss: 0.061727602034807205
step: 160, loss: 0.02173846773803234
step: 170, loss: 0.009491466917097569
step: 180, loss: 0.03352918103337288
step: 190, loss: 0.04663192480802536
step: 200, loss: 0.06892464309930801
step: 210, loss: 0.09217329323291779
step: 220, loss: 0.09160715341567993
step: 230, loss: 0.06585206091403961
step: 240, loss: 0.07760252803564072
step: 250, loss: 0.09004848450422287
step: 260, loss: 0.000985820428468287
step: 270, loss: 0.09981758892536163
step: 280, loss: 0.09158135950565338
step: 290, loss: 0.037528146058321
step: 300, loss: 0.05322925001382828
step: 310, loss: 0.06758778542280197
step: 320, loss: 0.020209334790706635
step: 330, loss: 0.0016207128064706922
step: 340, loss: 0.023082241415977478
step: 350, loss: 0.03242717310786247
step: 360, loss: 0.08910848945379257
step: 370, loss: 0.04629402980208397
step: 380, loss: 0.0011235574493184686
step: 390, loss: 8.121107384795323e-05
step: 400, loss: 0.07028435915708542
step: 410, loss: 0.050869494676589966
step: 420, loss: 0.04398616775870323
step: 430, loss: 0.04483116790652275
step: 440, loss: 0.09206100553274155
step: 450, loss: 0.0002951067581307143
step: 460, loss: 0.009462002664804459
step: 470, loss: 0.05724405497312546
step: 480, loss: 0.0030725968535989523
step: 490, loss: 0.07767201960086823
step: 500, loss: 0.028595421463251114
step: 510, loss: 0.013573992997407913
step: 520, loss: 0.014206207357347012
step: 530, loss: 0.02727648988366127
step: 540, loss: 0.015875903889536858
step: 550, loss: 0.02681463584303856
step: 560, loss: 0.022422781214118004
step: 570, loss: 0.03279169276356697
step: 580, loss: 0.021539147943258286
step: 590, loss: 0.04801499843597412
step: 600, loss: 0.04853569343686104
step: 610, loss: 0.11828939616680145
step: 620, loss: 0.030194371938705444
step: 630, loss: 0.07971688359975815
step: 640, loss: 0.02408369816839695
step: 650, loss: 0.061113856732845306
step: 660, loss: 2.19706489588134e-05
step: 670, loss: 0.06807543337345123
step: 680, loss: 0.03928795084357262
step: 690, loss: 0.024163488298654556
step: 700, loss: 0.014798013493418694
step: 710, loss: 0.03520413860678673
step: 720, loss: 0.039775699377059937
step: 730, loss: 0.08835592120885849
step: 740, loss: 0.02920428104698658
step: 750, loss: 0.01932176947593689
step: 760, loss: 0.03484363108873367
step: 770, loss: 2.833139842550736e-05
step: 780, loss: 0.00032380869379267097
step: 790, loss: 0.006945555564016104
step: 800, loss: 0.016282858327031136
step: 810, loss: 0.08682815730571747
step: 820, loss: 0.06516891717910767
step: 830, loss: 0.018893534317612648
step: 840, loss: 0.03598445653915405
step: 850, loss: 0.07583150267601013
step: 860, loss: 0.03220431134104729
step: 870, loss: 0.03235115855932236
step: 880, loss: 0.0030833063647150993
step: 890, loss: 0.05670733004808426
step: 900, loss: 0.021062562242150307
step: 910, loss: 0.03560885414481163
step: 920, loss: 0.0003063805343117565
step: 930, loss: 0.0003565410734154284
step: 940, loss: 0.07844620198011398
step: 950, loss: 9.913263784255832e-05
step: 960, loss: 0.0529608316719532
step: 970, loss: 0.021352823823690414
step: 980, loss: 0.04877408593893051
step: 990, loss: 0.07909645885229111
step: 1000, loss: 0.04561537131667137
step: 1010, loss: 0.03122471645474434
step: 1020, loss: 0.015537025406956673
step: 1030, loss: 0.19484971463680267
step: 1040, loss: 0.0324760340154171
step: 1050, loss: 0.03422488272190094
step: 1060, loss: 0.03107554279267788
step: 1070, loss: 0.07290428876876831
epoch 19: dev_f1=0.9287054409005628, f1=0.9276039234002802, best_f1=0.9280217292892712
step: 0, loss: 0.12735436856746674
step: 10, loss: 9.781302651390433e-05
step: 20, loss: 0.06357799470424652
step: 30, loss: 0.060310881584882736
step: 40, loss: 0.02601362206041813
step: 50, loss: 3.216544064343907e-05
step: 60, loss: 0.0964624360203743
step: 70, loss: 0.03775596618652344
step: 80, loss: 0.02279185876250267
step: 90, loss: 0.036181941628456116
step: 100, loss: 0.048779360949993134
step: 110, loss: 0.047650858759880066
step: 120, loss: 0.023018917068839073
step: 130, loss: 0.024134254083037376
step: 140, loss: 0.04855914041399956
step: 150, loss: 0.09103897213935852
step: 160, loss: 0.06710400432348251
step: 170, loss: 0.017599530518054962
step: 180, loss: 0.026106353849172592
step: 190, loss: 0.0004551746533252299
step: 200, loss: 0.01828549988567829
step: 210, loss: 0.01326935738325119
step: 220, loss: 0.038865212351083755
step: 230, loss: 0.058976806700229645
step: 240, loss: 0.05638250336050987
step: 250, loss: 0.08594705909490585
step: 260, loss: 0.018182050436735153
step: 270, loss: 0.08275234699249268
step: 280, loss: 0.00014223530888557434
step: 290, loss: 0.05650612711906433
step: 300, loss: 0.05535399168729782
step: 310, loss: 0.012750311754643917
step: 320, loss: 0.05552659556269646
step: 330, loss: 0.04343082010746002
step: 340, loss: 0.010458959266543388
step: 350, loss: 6.282272806856781e-05
step: 360, loss: 7.018282485660166e-05
step: 370, loss: 0.02035658061504364
step: 380, loss: 0.037635501474142075
step: 390, loss: 0.0002329377894056961
step: 400, loss: 0.01165317464619875
step: 410, loss: 5.4478554375236854e-05
step: 420, loss: 0.04809508100152016
step: 430, loss: 0.02911299280822277
step: 440, loss: 0.013179670087993145
step: 450, loss: 0.026924781501293182
step: 460, loss: 0.016958750784397125
step: 470, loss: 0.011731968261301517
step: 480, loss: 0.026002496480941772
step: 490, loss: 0.011097912676632404
step: 500, loss: 0.00947626307606697
step: 510, loss: 0.031824562698602676
step: 520, loss: 0.06847631931304932
step: 530, loss: 0.0536755733191967
step: 540, loss: 0.03704967349767685
step: 550, loss: 0.0001538081851322204
step: 560, loss: 0.017945488914847374
step: 570, loss: 0.020360169932246208
step: 580, loss: 0.01623137854039669
step: 590, loss: 0.0038447657134383917
step: 600, loss: 0.0405711904168129
step: 610, loss: 0.07033508270978928
step: 620, loss: 0.043873462826013565
step: 630, loss: 0.018373694270849228
step: 640, loss: 0.011932209134101868
step: 650, loss: 0.070463165640831
step: 660, loss: 0.019522160291671753
step: 670, loss: 0.012505941092967987
step: 680, loss: 0.020362038165330887
step: 690, loss: 0.0629124864935875
step: 700, loss: 0.00787378940731287
step: 710, loss: 0.04633677378296852
step: 720, loss: 0.08840737491846085
step: 730, loss: 0.06310699135065079
step: 740, loss: 0.0851583182811737
step: 750, loss: 0.024151194840669632
step: 760, loss: 0.04166734591126442
step: 770, loss: 0.011023216880857944
step: 780, loss: 0.023166293278336525
step: 790, loss: 0.05106410011649132
step: 800, loss: 0.07910305261611938
step: 810, loss: 0.08856435120105743
step: 820, loss: 0.011633830145001411
step: 830, loss: 0.09723439067602158
step: 840, loss: 0.04660256579518318
step: 850, loss: 0.06679479032754898
step: 860, loss: 0.0487867146730423
step: 870, loss: 0.02423025108873844
step: 880, loss: 0.0245763398706913
step: 890, loss: 0.148386150598526
step: 900, loss: 0.026996824890375137
step: 910, loss: 0.1510774791240692
step: 920, loss: 0.08919937908649445
step: 930, loss: 0.02019350230693817
step: 940, loss: 0.06368596851825714
step: 950, loss: 0.003196414327248931
step: 960, loss: 0.008355831727385521
step: 970, loss: 0.02158936858177185
step: 980, loss: 0.0910005047917366
step: 990, loss: 0.07701306790113449
step: 1000, loss: 0.05956501141190529
step: 1010, loss: 0.0832422524690628
step: 1020, loss: 0.02701694704592228
step: 1030, loss: 0.0517767071723938
step: 1040, loss: 0.06701596826314926
step: 1050, loss: 0.014178728684782982
step: 1060, loss: 0.04980631172657013
step: 1070, loss: 0.08478067070245743
epoch 20: dev_f1=0.9242424242424242, f1=0.9251059821008009, best_f1=0.9280217292892712
