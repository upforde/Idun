cuda
Device: cuda
step: 0, loss: 0.6663542985916138
step: 10, loss: 0.4745105504989624
step: 20, loss: 0.4606987237930298
step: 30, loss: 0.566474974155426
step: 40, loss: 0.22544948756694794
step: 50, loss: 0.1539067178964615
step: 60, loss: 0.1871066689491272
step: 70, loss: 0.22256146371364594
step: 80, loss: 0.30572018027305603
step: 90, loss: 0.2662011384963989
step: 100, loss: 0.1633157730102539
step: 110, loss: 0.1953512281179428
step: 120, loss: 0.13999100029468536
step: 130, loss: 0.19403521716594696
step: 140, loss: 0.12863874435424805
step: 150, loss: 0.08859860152006149
step: 160, loss: 0.0453803613781929
step: 170, loss: 0.15680989623069763
step: 180, loss: 0.12342578172683716
step: 190, loss: 0.07185328751802444
step: 200, loss: 0.1786683201789856
step: 210, loss: 0.1676013022661209
step: 220, loss: 0.12060447782278061
step: 230, loss: 0.18346606194972992
step: 240, loss: 0.1495322436094284
step: 250, loss: 0.1431557834148407
step: 260, loss: 0.17979198694229126
step: 270, loss: 0.07255175709724426
step: 280, loss: 0.1038382276892662
step: 290, loss: 0.2363162338733673
step: 300, loss: 0.1296142190694809
step: 310, loss: 0.1765318512916565
step: 320, loss: 0.22297483682632446
step: 330, loss: 0.11519911140203476
step: 340, loss: 0.1374734342098236
step: 350, loss: 0.06295052170753479
step: 360, loss: 0.3119947910308838
step: 370, loss: 0.176954448223114
step: 380, loss: 0.20968222618103027
step: 390, loss: 0.1489684283733368
step: 400, loss: 0.06543367356061935
step: 410, loss: 0.18190817534923553
step: 420, loss: 0.1904255896806717
step: 430, loss: 0.11870761215686798
step: 440, loss: 0.07405426353216171
step: 450, loss: 0.2075064480304718
step: 460, loss: 0.08464350551366806
step: 470, loss: 0.09268678724765778
step: 480, loss: 0.0768972858786583
step: 490, loss: 0.10718954354524612
step: 500, loss: 0.18254290521144867
step: 510, loss: 0.11955814808607101
step: 520, loss: 0.17135076224803925
step: 530, loss: 0.14674963057041168
step: 540, loss: 0.02981860376894474
step: 550, loss: 0.15268760919570923
step: 560, loss: 0.17019499838352203
step: 570, loss: 0.3933606743812561
step: 580, loss: 0.06711143255233765
step: 590, loss: 0.179873988032341
step: 600, loss: 0.0944666862487793
step: 610, loss: 0.2100757509469986
step: 620, loss: 0.3861891031265259
step: 630, loss: 0.11543088406324387
step: 640, loss: 0.17430098354816437
step: 650, loss: 0.10837028175592422
step: 660, loss: 0.16030898690223694
step: 670, loss: 0.07100512832403183
step: 680, loss: 0.0440630167722702
step: 690, loss: 0.17344816029071808
step: 700, loss: 0.02756025269627571
step: 710, loss: 0.051126763224601746
step: 720, loss: 0.039470452815294266
step: 730, loss: 0.09215142577886581
step: 740, loss: 0.048115987330675125
step: 750, loss: 0.08237086981534958
step: 760, loss: 0.1257430464029312
step: 770, loss: 0.08068768680095673
step: 780, loss: 0.4230934679508209
step: 790, loss: 0.07286300510168076
step: 800, loss: 0.108708955347538
step: 810, loss: 0.1634596884250641
step: 820, loss: 0.1384785771369934
step: 830, loss: 0.057667262852191925
step: 840, loss: 0.11027063429355621
step: 850, loss: 0.11140952259302139
step: 860, loss: 0.12139402329921722
step: 870, loss: 0.1170770525932312
step: 880, loss: 0.2822328209877014
step: 890, loss: 0.12262070924043655
step: 900, loss: 0.14708253741264343
step: 910, loss: 0.14174102246761322
step: 920, loss: 0.09960763901472092
step: 930, loss: 0.28483933210372925
step: 940, loss: 0.1301712542772293
step: 950, loss: 0.13803039491176605
step: 960, loss: 0.1413249373435974
step: 970, loss: 0.18435068428516388
step: 980, loss: 0.05212360620498657
step: 990, loss: 0.17063000798225403
step: 1000, loss: 0.0910143181681633
step: 1010, loss: 0.23198507726192474
step: 1020, loss: 0.07703392952680588
step: 1030, loss: 0.1989578902721405
step: 1040, loss: 0.1505969762802124
step: 1050, loss: 0.20049336552619934
step: 1060, loss: 0.12155606597661972
step: 1070, loss: 0.14711447060108185
epoch 1: dev_f1=0.9136258660508083, f1=0.9073394495412843, best_f1=0.9073394495412843
step: 0, loss: 0.09091386944055557
step: 10, loss: 0.05333450809121132
step: 20, loss: 0.07286503165960312
step: 30, loss: 0.1333591789007187
step: 40, loss: 0.10230550169944763
step: 50, loss: 0.20828139781951904
step: 60, loss: 0.06628676503896713
step: 70, loss: 0.06958862394094467
step: 80, loss: 0.10579415410757065
step: 90, loss: 0.18930713832378387
step: 100, loss: 0.14915192127227783
step: 110, loss: 0.023295503109693527
step: 120, loss: 0.09965499490499496
step: 130, loss: 0.1555851846933365
step: 140, loss: 0.04245646297931671
step: 150, loss: 0.09527310729026794
step: 160, loss: 0.11878405511379242
step: 170, loss: 0.17951327562332153
step: 180, loss: 0.1891336888074875
step: 190, loss: 0.10845250636339188
step: 200, loss: 0.07626399397850037
step: 210, loss: 0.14686205983161926
step: 220, loss: 0.2128308117389679
step: 230, loss: 0.24826140701770782
step: 240, loss: 0.08297955989837646
step: 250, loss: 0.07098730653524399
step: 260, loss: 0.12729375064373016
step: 270, loss: 0.14706185460090637
step: 280, loss: 0.12426748871803284
step: 290, loss: 0.03697529807686806
step: 300, loss: 0.1306823492050171
step: 310, loss: 0.08675012737512589
step: 320, loss: 0.12731708586215973
step: 330, loss: 0.07186436653137207
step: 340, loss: 0.029961643740534782
step: 350, loss: 0.17286130785942078
step: 360, loss: 0.22141756117343903
step: 370, loss: 0.1381641924381256
step: 380, loss: 0.1510864645242691
step: 390, loss: 0.10219859331846237
step: 400, loss: 0.05908328667283058
step: 410, loss: 0.2089514434337616
step: 420, loss: 0.15451104938983917
step: 430, loss: 0.10203713923692703
step: 440, loss: 0.14278241991996765
step: 450, loss: 0.07900992780923843
step: 460, loss: 0.0948626697063446
step: 470, loss: 0.0665820837020874
step: 480, loss: 0.12012966722249985
step: 490, loss: 0.1493626832962036
step: 500, loss: 0.10310586541891098
step: 510, loss: 0.2500017583370209
step: 520, loss: 0.09003206342458725
step: 530, loss: 0.059886835515499115
step: 540, loss: 0.11601319164037704
step: 550, loss: 0.17999687790870667
step: 560, loss: 0.12189293652772903
step: 570, loss: 0.11601371318101883
step: 580, loss: 0.08705467730760574
step: 590, loss: 0.16657128930091858
step: 600, loss: 0.07770183682441711
step: 610, loss: 0.11295440047979355
step: 620, loss: 0.06316310912370682
step: 630, loss: 0.10699708014726639
step: 640, loss: 0.08487270027399063
step: 650, loss: 0.14359869062900543
step: 660, loss: 0.20052500069141388
step: 670, loss: 0.0838242918252945
step: 680, loss: 0.1377480924129486
step: 690, loss: 0.05769970640540123
step: 700, loss: 0.11066869646310806
step: 710, loss: 0.049581170082092285
step: 720, loss: 0.06348215788602829
step: 730, loss: 0.16751252114772797
step: 740, loss: 0.044438306242227554
step: 750, loss: 0.11152292788028717
step: 760, loss: 0.15017350018024445
step: 770, loss: 0.1605416238307953
step: 780, loss: 0.14582377672195435
step: 790, loss: 0.11734907329082489
step: 800, loss: 0.0935845673084259
step: 810, loss: 0.17272083461284637
step: 820, loss: 0.1278398036956787
step: 830, loss: 0.1293930560350418
step: 840, loss: 0.07265599071979523
step: 850, loss: 0.07509293407201767
step: 860, loss: 0.1368212103843689
step: 870, loss: 0.26138433814048767
step: 880, loss: 0.13682091236114502
step: 890, loss: 0.21767407655715942
step: 900, loss: 0.30935806035995483
step: 910, loss: 0.09213849157094955
step: 920, loss: 0.15665362775325775
step: 930, loss: 0.15050984919071198
step: 940, loss: 0.10474410653114319
step: 950, loss: 0.10479890555143356
step: 960, loss: 0.1629381775856018
step: 970, loss: 0.178427055478096
step: 980, loss: 0.08968938887119293
step: 990, loss: 0.15580211579799652
step: 1000, loss: 0.15789365768432617
step: 1010, loss: 0.15735623240470886
step: 1020, loss: 0.05171851068735123
step: 1030, loss: 0.09987639635801315
step: 1040, loss: 0.24095389246940613
step: 1050, loss: 0.07889728248119354
step: 1060, loss: 0.03569193184375763
step: 1070, loss: 0.08968678116798401
epoch 2: dev_f1=0.9208103130755064, f1=0.9236396890717878, best_f1=0.9236396890717878
step: 0, loss: 0.13903750479221344
step: 10, loss: 0.06583147495985031
step: 20, loss: 0.09589166939258575
step: 30, loss: 0.057613495737314224
step: 40, loss: 0.13735592365264893
step: 50, loss: 0.09076592326164246
step: 60, loss: 0.07828173786401749
step: 70, loss: 0.05317751318216324
step: 80, loss: 0.03593724966049194
step: 90, loss: 0.034893397241830826
step: 100, loss: 0.049144502729177475
step: 110, loss: 0.039553508162498474
step: 120, loss: 0.029223274439573288
step: 130, loss: 0.15074977278709412
step: 140, loss: 0.06999113410711288
step: 150, loss: 0.1319296956062317
step: 160, loss: 0.15545950829982758
step: 170, loss: 0.07093794643878937
step: 180, loss: 0.0826878622174263
step: 190, loss: 0.11690859496593475
step: 200, loss: 0.05289352312684059
step: 210, loss: 0.15236222743988037
step: 220, loss: 0.11508133262395859
step: 230, loss: 0.07047631591558456
step: 240, loss: 0.11143427342176437
step: 250, loss: 0.08087315410375595
step: 260, loss: 0.004170594736933708
step: 270, loss: 0.08859523385763168
step: 280, loss: 0.18216398358345032
step: 290, loss: 0.18421313166618347
step: 300, loss: 0.06449143588542938
step: 310, loss: 0.08479315042495728
step: 320, loss: 0.15810884535312653
step: 330, loss: 0.09308978170156479
step: 340, loss: 0.09595301002264023
step: 350, loss: 0.10269135236740112
step: 360, loss: 0.15803216397762299
step: 370, loss: 0.07455278187990189
step: 380, loss: 0.0487520694732666
step: 390, loss: 0.09957457333803177
step: 400, loss: 0.16127358376979828
step: 410, loss: 0.12529787421226501
step: 420, loss: 0.0379008948802948
step: 430, loss: 0.04881734773516655
step: 440, loss: 0.21093542873859406
step: 450, loss: 0.06712876260280609
step: 460, loss: 0.21014396846294403
step: 470, loss: 0.07861250638961792
step: 480, loss: 0.09350908547639847
step: 490, loss: 0.06503895670175552
step: 500, loss: 0.04378320649266243
step: 510, loss: 0.10164111107587814
step: 520, loss: 0.10925853252410889
step: 530, loss: 0.09159593284130096
step: 540, loss: 0.027927828952670097
step: 550, loss: 0.287668377161026
step: 560, loss: 0.14575521647930145
step: 570, loss: 0.15942034125328064
step: 580, loss: 0.1509729027748108
step: 590, loss: 0.07710998505353928
step: 600, loss: 0.05733407288789749
step: 610, loss: 0.08742121607065201
step: 620, loss: 0.2745738923549652
step: 630, loss: 0.08057166635990143
step: 640, loss: 0.16643652319908142
step: 650, loss: 0.06196749210357666
step: 660, loss: 0.07500637322664261
step: 670, loss: 0.09015554934740067
step: 680, loss: 0.02515864185988903
step: 690, loss: 0.09944219887256622
step: 700, loss: 0.0640016496181488
step: 710, loss: 0.08231757581233978
step: 720, loss: 0.13927003741264343
step: 730, loss: 0.1399534046649933
step: 740, loss: 0.09437914937734604
step: 750, loss: 0.03340457007288933
step: 760, loss: 0.03696025162935257
step: 770, loss: 0.06065128743648529
step: 780, loss: 0.10545897483825684
step: 790, loss: 0.1649511456489563
step: 800, loss: 0.09304970502853394
step: 810, loss: 0.08280511945486069
step: 820, loss: 0.1278793215751648
step: 830, loss: 0.10320739448070526
step: 840, loss: 0.11874797195196152
step: 850, loss: 0.09563863277435303
step: 860, loss: 0.12992030382156372
step: 870, loss: 0.07457567751407623
step: 880, loss: 0.1177934855222702
step: 890, loss: 0.07668454945087433
step: 900, loss: 0.11818163841962814
step: 910, loss: 0.28365710377693176
step: 920, loss: 0.08441478759050369
step: 930, loss: 0.13109363615512848
step: 940, loss: 0.09464489668607712
step: 950, loss: 0.11013724654912949
step: 960, loss: 0.11445362120866776
step: 970, loss: 0.10864948481321335
step: 980, loss: 0.16736264526844025
step: 990, loss: 0.13298730552196503
step: 1000, loss: 0.2119837999343872
step: 1010, loss: 0.018874865025281906
step: 1020, loss: 0.08390854299068451
step: 1030, loss: 0.0695795938372612
step: 1040, loss: 0.2529849708080292
step: 1050, loss: 0.03327493369579315
step: 1060, loss: 0.09251783043146133
step: 1070, loss: 0.043182652443647385
epoch 3: dev_f1=0.9273897058823529, f1=0.9168975069252078, best_f1=0.9168975069252078
step: 0, loss: 0.11361446976661682
step: 10, loss: 0.11209437251091003
step: 20, loss: 0.04053150489926338
step: 30, loss: 0.018083028495311737
step: 40, loss: 0.05357148498296738
step: 50, loss: 0.08146949112415314
step: 60, loss: 0.1667587012052536
step: 70, loss: 0.09585263580083847
step: 80, loss: 0.10141067206859589
step: 90, loss: 0.05279054120182991
step: 100, loss: 0.07517210394144058
step: 110, loss: 0.1549064815044403
step: 120, loss: 0.11620619148015976
step: 130, loss: 0.09229350090026855
step: 140, loss: 0.15580758452415466
step: 150, loss: 0.12784630060195923
step: 160, loss: 0.09095371514558792
step: 170, loss: 0.14415201544761658
step: 180, loss: 0.028585877269506454
step: 190, loss: 0.022832617163658142
step: 200, loss: 0.05956859514117241
step: 210, loss: 0.07524479180574417
step: 220, loss: 0.18215543031692505
step: 230, loss: 0.0632457435131073
step: 240, loss: 0.07600729167461395
step: 250, loss: 0.2062588632106781
step: 260, loss: 0.18286341428756714
step: 270, loss: 0.09964294731616974
step: 280, loss: 0.06133529171347618
step: 290, loss: 0.026334010064601898
step: 300, loss: 0.06928447633981705
step: 310, loss: 0.13513602316379547
step: 320, loss: 0.10301228612661362
step: 330, loss: 0.08360711485147476
step: 340, loss: 0.05156814306974411
step: 350, loss: 0.11190100759267807
step: 360, loss: 0.05317682400345802
step: 370, loss: 0.14987613260746002
step: 380, loss: 0.09743595123291016
step: 390, loss: 0.09160929918289185
step: 400, loss: 0.23809370398521423
step: 410, loss: 0.12783220410346985
step: 420, loss: 0.02244161069393158
step: 430, loss: 0.03135563060641289
step: 440, loss: 0.1009109616279602
step: 450, loss: 0.0846758782863617
step: 460, loss: 0.114870585501194
step: 470, loss: 0.09930189698934555
step: 480, loss: 0.10853143036365509
step: 490, loss: 0.013912614434957504
step: 500, loss: 0.10673070698976517
step: 510, loss: 0.0695866048336029
step: 520, loss: 0.11031873524188995
step: 530, loss: 0.02011577971279621
step: 540, loss: 0.05506162345409393
step: 550, loss: 0.07841469347476959
step: 560, loss: 0.10852251201868057
step: 570, loss: 0.05129348486661911
step: 580, loss: 0.02655741013586521
step: 590, loss: 0.08139865845441818
step: 600, loss: 0.06546373665332794
step: 610, loss: 0.07568982243537903
step: 620, loss: 0.10272034257650375
step: 630, loss: 0.0839296206831932
step: 640, loss: 0.07707709819078445
step: 650, loss: 0.09220362454652786
step: 660, loss: 0.08338233828544617
step: 670, loss: 0.04345091059803963
step: 680, loss: 0.07044344395399094
step: 690, loss: 0.1339547038078308
step: 700, loss: 0.06628802418708801
step: 710, loss: 0.06186813861131668
step: 720, loss: 0.09336275607347488
step: 730, loss: 0.09951351583003998
step: 740, loss: 0.0649346187710762
step: 750, loss: 0.025676831603050232
step: 760, loss: 0.14906127750873566
step: 770, loss: 0.10318426042795181
step: 780, loss: 0.13917167484760284
step: 790, loss: 0.10185757279396057
step: 800, loss: 0.05077026039361954
step: 810, loss: 0.03932338207960129
step: 820, loss: 0.09829656034708023
step: 830, loss: 0.12975384294986725
step: 840, loss: 0.09563279896974564
step: 850, loss: 0.23095308244228363
step: 860, loss: 0.047258514910936356
step: 870, loss: 0.10166317969560623
step: 880, loss: 0.2059967815876007
step: 890, loss: 0.04050350934267044
step: 900, loss: 0.14403660595417023
step: 910, loss: 0.12575742602348328
step: 920, loss: 0.11331558972597122
step: 930, loss: 0.11933502554893494
step: 940, loss: 0.09176915138959885
step: 950, loss: 0.3331731855869293
step: 960, loss: 0.17653074860572815
step: 970, loss: 0.08952129632234573
step: 980, loss: 0.0855269506573677
step: 990, loss: 0.08086978644132614
step: 1000, loss: 0.19148607552051544
step: 1010, loss: 0.11899615079164505
step: 1020, loss: 0.10483403503894806
step: 1030, loss: 0.18967002630233765
step: 1040, loss: 0.1495581865310669
step: 1050, loss: 0.15309099853038788
step: 1060, loss: 0.17362001538276672
step: 1070, loss: 0.034476280212402344
epoch 4: dev_f1=0.9309417040358744, f1=0.9243847874720357, best_f1=0.9243847874720357
step: 0, loss: 0.14954297244548798
step: 10, loss: 0.0383293591439724
step: 20, loss: 0.03199993073940277
step: 30, loss: 0.1219550371170044
step: 40, loss: 0.16287866234779358
step: 50, loss: 0.16094335913658142
step: 60, loss: 0.14928612112998962
step: 70, loss: 0.09172800928354263
step: 80, loss: 0.06418325752019882
step: 90, loss: 0.1943361461162567
step: 100, loss: 0.030861442908644676
step: 110, loss: 0.17170315980911255
step: 120, loss: 0.07925073057413101
step: 130, loss: 0.14686663448810577
step: 140, loss: 0.07854399085044861
step: 150, loss: 0.0587032176554203
step: 160, loss: 0.058279287070035934
step: 170, loss: 0.08731202036142349
step: 180, loss: 0.18397977948188782
step: 190, loss: 0.1916539967060089
step: 200, loss: 0.02824760600924492
step: 210, loss: 0.15241639316082
step: 220, loss: 0.23676924407482147
step: 230, loss: 0.09835970401763916
step: 240, loss: 0.040639687329530716
step: 250, loss: 0.08811943233013153
step: 260, loss: 0.056394681334495544
step: 270, loss: 0.06389036774635315
step: 280, loss: 0.10993050783872604
step: 290, loss: 0.011192827485501766
step: 300, loss: 0.10993639379739761
step: 310, loss: 0.24393321573734283
step: 320, loss: 0.058430761098861694
step: 330, loss: 0.16299021244049072
step: 340, loss: 0.32228127121925354
step: 350, loss: 0.044785164296627045
step: 360, loss: 0.05623333528637886
step: 370, loss: 0.07488294690847397
step: 380, loss: 0.06974896043539047
step: 390, loss: 0.03339917212724686
step: 400, loss: 0.09043581038713455
step: 410, loss: 0.11735434830188751
step: 420, loss: 0.11450410634279251
step: 430, loss: 0.11606749147176743
step: 440, loss: 0.13660520315170288
step: 450, loss: 0.029609156772494316
step: 460, loss: 0.056923363357782364
step: 470, loss: 0.0263289213180542
step: 480, loss: 0.05080823972821236
step: 490, loss: 0.15478838980197906
step: 500, loss: 0.08207441866397858
step: 510, loss: 0.013206769712269306
step: 520, loss: 0.03601288050413132
step: 530, loss: 0.07238952815532684
step: 540, loss: 0.0884537324309349
step: 550, loss: 0.21588179469108582
step: 560, loss: 0.08546727150678635
step: 570, loss: 0.005511113442480564
step: 580, loss: 0.029528388753533363
step: 590, loss: 0.17322607338428497
step: 600, loss: 0.06948480010032654
step: 610, loss: 0.09484697133302689
step: 620, loss: 0.041176773607730865
step: 630, loss: 0.07881840318441391
step: 640, loss: 0.10195321589708328
step: 650, loss: 0.052121326327323914
step: 660, loss: 0.03935220092535019
step: 670, loss: 0.018506327643990517
step: 680, loss: 0.05439068377017975
step: 690, loss: 0.11677154898643494
step: 700, loss: 0.06347650289535522
step: 710, loss: 0.08465304225683212
step: 720, loss: 0.061708804219961166
step: 730, loss: 0.0764535591006279
step: 740, loss: 0.14797744154930115
step: 750, loss: 0.14824499189853668
step: 760, loss: 0.21196086704730988
step: 770, loss: 0.07691116631031036
step: 780, loss: 0.17285090684890747
step: 790, loss: 0.09751775860786438
step: 800, loss: 0.10145292431116104
step: 810, loss: 0.11127690225839615
step: 820, loss: 0.053164586424827576
step: 830, loss: 0.1562473475933075
step: 840, loss: 0.1049712598323822
step: 850, loss: 0.132780984044075
step: 860, loss: 0.04723477363586426
step: 870, loss: 0.016334623098373413
step: 880, loss: 0.13076721131801605
step: 890, loss: 0.18758127093315125
step: 900, loss: 0.07245159894227982
step: 910, loss: 0.08359350264072418
step: 920, loss: 0.11865109205245972
step: 930, loss: 0.0850767195224762
step: 940, loss: 0.2577132284641266
step: 950, loss: 0.16978736221790314
step: 960, loss: 0.06816418468952179
step: 970, loss: 0.054203808307647705
step: 980, loss: 0.09581110626459122
step: 990, loss: 0.14972445368766785
step: 1000, loss: 0.13886158168315887
step: 1010, loss: 0.18677429854869843
step: 1020, loss: 0.12488355487585068
step: 1030, loss: 0.07864130288362503
step: 1040, loss: 0.06631871312856674
step: 1050, loss: 0.11934813857078552
step: 1060, loss: 0.1580783873796463
step: 1070, loss: 0.048789236694574356
epoch 5: dev_f1=0.9388322520852641, f1=0.9283402681460935, best_f1=0.9283402681460935
step: 0, loss: 0.028312772512435913
step: 10, loss: 0.062087737023830414
step: 20, loss: 0.10965066403150558
step: 30, loss: 0.1312016248703003
step: 40, loss: 0.07831230014562607
step: 50, loss: 0.08401677012443542
step: 60, loss: 0.056454289704561234
step: 70, loss: 0.1879599541425705
step: 80, loss: 0.013253581710159779
step: 90, loss: 0.10804373025894165
step: 100, loss: 0.16582760214805603
step: 110, loss: 0.051140181720256805
step: 120, loss: 0.042805302888154984
step: 130, loss: 0.11146792769432068
step: 140, loss: 0.11337325721979141
step: 150, loss: 0.14128287136554718
step: 160, loss: 0.05846153944730759
step: 170, loss: 0.0835920199751854
step: 180, loss: 0.13376428186893463
step: 190, loss: 0.02085944078862667
step: 200, loss: 0.2702288329601288
step: 210, loss: 0.03653968498110771
step: 220, loss: 0.07019416242837906
step: 230, loss: 0.05438985675573349
step: 240, loss: 0.07950608432292938
step: 250, loss: 0.04964879900217056
step: 260, loss: 0.052404772490262985
step: 270, loss: 0.058810263872146606
step: 280, loss: 0.1166297048330307
step: 290, loss: 0.03574545681476593
step: 300, loss: 0.08431915193796158
step: 310, loss: 0.045180097222328186
step: 320, loss: 0.042587194591760635
step: 330, loss: 0.040045250207185745
step: 340, loss: 0.09335930645465851
step: 350, loss: 0.14283710718154907
step: 360, loss: 0.05103133246302605
step: 370, loss: 0.023479318246245384
step: 380, loss: 0.042844511568546295
step: 390, loss: 0.12621340155601501
step: 400, loss: 0.14035680890083313
step: 410, loss: 0.139567032456398
step: 420, loss: 0.059526532888412476
step: 430, loss: 0.17167218029499054
step: 440, loss: 0.04591068997979164
step: 450, loss: 0.20494285225868225
step: 460, loss: 0.0887930616736412
step: 470, loss: 0.07973736524581909
step: 480, loss: 0.09903815388679504
step: 490, loss: 0.10024746507406235
step: 500, loss: 0.03307332843542099
step: 510, loss: 0.04037255048751831
step: 520, loss: 0.026908034458756447
step: 530, loss: 0.02528492733836174
step: 540, loss: 0.04038165882229805
step: 550, loss: 0.1887141466140747
step: 560, loss: 0.0938633531332016
step: 570, loss: 0.09378714114427567
step: 580, loss: 0.1781093180179596
step: 590, loss: 0.023751817643642426
step: 600, loss: 0.03831815719604492
step: 610, loss: 0.04649628698825836
step: 620, loss: 0.06756960600614548
step: 630, loss: 0.03700374811887741
step: 640, loss: 0.00023629749193787575
step: 650, loss: 0.17340527474880219
step: 660, loss: 0.04774098843336105
step: 670, loss: 0.07063915580511093
step: 680, loss: 0.07492445409297943
step: 690, loss: 0.11014555394649506
step: 700, loss: 0.06334810703992844
step: 710, loss: 0.09248662739992142
step: 720, loss: 0.14140115678310394
step: 730, loss: 0.08670148253440857
step: 740, loss: 0.03080981969833374
step: 750, loss: 0.06207030266523361
step: 760, loss: 0.10033145546913147
step: 770, loss: 0.07065188884735107
step: 780, loss: 0.09569796919822693
step: 790, loss: 0.0358264222741127
step: 800, loss: 0.06846396625041962
step: 810, loss: 0.01093834824860096
step: 820, loss: 0.06154468655586243
step: 830, loss: 0.035875510424375534
step: 840, loss: 0.15179060399532318
step: 850, loss: 0.024774320423603058
step: 860, loss: 0.16061758995056152
step: 870, loss: 0.04504552483558655
step: 880, loss: 0.08445199579000473
step: 890, loss: 0.11126778274774551
step: 900, loss: 0.09317760914564133
step: 910, loss: 0.09045945107936859
step: 920, loss: 0.09770825505256653
step: 930, loss: 0.06268366426229477
step: 940, loss: 0.1303853690624237
step: 950, loss: 0.006039924919605255
step: 960, loss: 0.06722164899110794
step: 970, loss: 0.12792764604091644
step: 980, loss: 0.05847970023751259
step: 990, loss: 0.047706685960292816
step: 1000, loss: 0.051177240908145905
step: 1010, loss: 0.05971710756421089
step: 1020, loss: 0.025800634175539017
step: 1030, loss: 0.1577303558588028
step: 1040, loss: 0.02609405294060707
step: 1050, loss: 0.13231247663497925
step: 1060, loss: 0.10822748392820358
step: 1070, loss: 0.027690773829817772
epoch 6: dev_f1=0.9274826789838336, f1=0.9239280774550485, best_f1=0.9283402681460935
step: 0, loss: 0.09849455952644348
step: 10, loss: 0.1435278058052063
step: 20, loss: 0.06157531961798668
step: 30, loss: 0.0928502082824707
step: 40, loss: 0.029421411454677582
step: 50, loss: 0.1632603406906128
step: 60, loss: 0.045857496559619904
step: 70, loss: 0.044898729771375656
step: 80, loss: 0.04791620373725891
step: 90, loss: 0.1113654151558876
step: 100, loss: 0.06582406163215637
step: 110, loss: 0.029663557186722755
step: 120, loss: 0.04400122910737991
step: 130, loss: 0.14761069416999817
step: 140, loss: 0.026196233928203583
step: 150, loss: 0.08105713129043579
step: 160, loss: 0.04571942239999771
step: 170, loss: 0.0621049739420414
step: 180, loss: 0.10325648635625839
step: 190, loss: 0.10500216484069824
step: 200, loss: 0.011254391632974148
step: 210, loss: 0.06035453453660011
step: 220, loss: 0.2027573585510254
step: 230, loss: 0.09726877510547638
step: 240, loss: 0.032641176134347916
step: 250, loss: 0.11203918606042862
step: 260, loss: 0.1139337420463562
step: 270, loss: 0.0716426819562912
step: 280, loss: 0.000983085366897285
step: 290, loss: 0.1024019792675972
step: 300, loss: 0.08685000240802765
step: 310, loss: 0.07673947513103485
step: 320, loss: 0.16364368796348572
step: 330, loss: 0.12116707116365433
step: 340, loss: 0.10545080900192261
step: 350, loss: 0.05163807421922684
step: 360, loss: 0.04228644073009491
step: 370, loss: 0.08337259292602539
step: 380, loss: 0.04882092401385307
step: 390, loss: 0.09342552721500397
step: 400, loss: 0.2226189374923706
step: 410, loss: 0.06906107813119888
step: 420, loss: 0.09842944145202637
step: 430, loss: 0.14785276353359222
step: 440, loss: 0.06005721539258957
step: 450, loss: 0.18766601383686066
step: 460, loss: 0.07627885788679123
step: 470, loss: 0.10357384383678436
step: 480, loss: 0.14479374885559082
step: 490, loss: 0.12240467220544815
step: 500, loss: 0.040691472589969635
step: 510, loss: 0.08072376251220703
step: 520, loss: 0.05518191680312157
step: 530, loss: 0.10744614154100418
step: 540, loss: 0.0015387729508802295
step: 550, loss: 0.022198591381311417
step: 560, loss: 0.08931422978639603
step: 570, loss: 0.02369622513651848
step: 580, loss: 0.11951369792222977
step: 590, loss: 0.13575029373168945
step: 600, loss: 0.09867999702692032
step: 610, loss: 0.1223546713590622
step: 620, loss: 0.096164271235466
step: 630, loss: 0.14533589780330658
step: 640, loss: 0.1299837827682495
step: 650, loss: 0.009605676867067814
step: 660, loss: 0.12255314737558365
step: 670, loss: 0.04183405637741089
step: 680, loss: 0.04055510833859444
step: 690, loss: 0.018519744277000427
step: 700, loss: 0.10876975953578949
step: 710, loss: 0.013213570229709148
step: 720, loss: 0.10417887568473816
step: 730, loss: 0.051252301782369614
step: 740, loss: 0.05761914700269699
step: 750, loss: 0.031295325607061386
step: 760, loss: 0.0910639613866806
step: 770, loss: 0.034713469445705414
step: 780, loss: 0.3222653269767761
step: 790, loss: 0.03708513826131821
step: 800, loss: 0.04188496619462967
step: 810, loss: 0.02017943747341633
step: 820, loss: 0.05560484901070595
step: 830, loss: 0.053477030247449875
step: 840, loss: 0.038545191287994385
step: 850, loss: 0.017848964780569077
step: 860, loss: 0.0461927130818367
step: 870, loss: 0.16257892549037933
step: 880, loss: 0.11625082045793533
step: 890, loss: 0.0826939269900322
step: 900, loss: 0.07042040675878525
step: 910, loss: 0.08945509046316147
step: 920, loss: 0.05149489641189575
step: 930, loss: 0.15987397730350494
step: 940, loss: 0.03404904156923294
step: 950, loss: 0.14068464934825897
step: 960, loss: 0.10811079293489456
step: 970, loss: 0.05592453107237816
step: 980, loss: 0.19104579091072083
step: 990, loss: 0.1453433483839035
step: 1000, loss: 0.04429527744650841
step: 1010, loss: 0.04454050958156586
step: 1020, loss: 0.1333354413509369
step: 1030, loss: 0.07365003973245621
step: 1040, loss: 0.0045033227652311325
step: 1050, loss: 0.045969538390636444
step: 1060, loss: 0.037588704377412796
step: 1070, loss: 0.10683530569076538
epoch 7: dev_f1=0.9261682242990654, f1=0.9214218896164639, best_f1=0.9283402681460935
step: 0, loss: 0.060672786086797714
step: 10, loss: 0.1278732568025589
step: 20, loss: 0.11610476672649384
step: 30, loss: 0.05216686427593231
step: 40, loss: 0.049038659781217575
step: 50, loss: 0.07819856703281403
step: 60, loss: 0.05168860778212547
step: 70, loss: 0.055156391113996506
step: 80, loss: 0.013518388383090496
step: 90, loss: 0.03025609441101551
step: 100, loss: 0.08534075319766998
step: 110, loss: 0.12114577740430832
step: 120, loss: 0.07273659855127335
step: 130, loss: 0.03752737492322922
step: 140, loss: 0.008432270959019661
step: 150, loss: 0.0871724784374237
step: 160, loss: 0.10580768436193466
step: 170, loss: 0.025971105322241783
step: 180, loss: 0.09819407016038895
step: 190, loss: 0.15592390298843384
step: 200, loss: 0.06483016908168793
step: 210, loss: 0.1313125491142273
step: 220, loss: 0.0901886522769928
step: 230, loss: 0.0583144836127758
step: 240, loss: 0.07995191961526871
step: 250, loss: 0.018571527674794197
step: 260, loss: 0.07613088190555573
step: 270, loss: 0.07245946675539017
step: 280, loss: 0.0767378956079483
step: 290, loss: 0.11077191680669785
step: 300, loss: 0.02883605659008026
step: 310, loss: 0.12089986354112625
step: 320, loss: 0.10649187862873077
step: 330, loss: 0.1113976314663887
step: 340, loss: 0.051171205937862396
step: 350, loss: 0.03018396534025669
step: 360, loss: 0.06982379406690598
step: 370, loss: 0.1749599426984787
step: 380, loss: 0.03566328063607216
step: 390, loss: 0.02194010652601719
step: 400, loss: 0.0465489961206913
step: 410, loss: 0.11905218660831451
step: 420, loss: 0.08687494695186615
step: 430, loss: 0.15426388382911682
step: 440, loss: 0.09905894845724106
step: 450, loss: 0.09707780927419662
step: 460, loss: 0.05176708847284317
step: 470, loss: 0.06579211354255676
step: 480, loss: 0.08547405898571014
step: 490, loss: 0.10958658158779144
step: 500, loss: 0.09004658460617065
step: 510, loss: 0.05958017706871033
step: 520, loss: 0.025228986516594887
step: 530, loss: 0.020105887204408646
step: 540, loss: 0.13264797627925873
step: 550, loss: 0.05343921482563019
step: 560, loss: 0.000256403029197827
step: 570, loss: 0.09735725820064545
step: 580, loss: 0.05744342505931854
step: 590, loss: 0.07630784064531326
step: 600, loss: 0.042151015251874924
step: 610, loss: 0.01239054650068283
step: 620, loss: 0.010513600893318653
step: 630, loss: 0.04336234927177429
step: 640, loss: 0.09968535602092743
step: 650, loss: 0.045308876782655716
step: 660, loss: 0.08932295441627502
step: 670, loss: 0.08289503306150436
step: 680, loss: 0.013910694047808647
step: 690, loss: 0.048085324466228485
step: 700, loss: 0.11299998313188553
step: 710, loss: 0.026470636948943138
step: 720, loss: 0.08122678101062775
step: 730, loss: 0.06303497403860092
step: 740, loss: 0.15080754458904266
step: 750, loss: 0.08109623193740845
step: 760, loss: 0.029478048905730247
step: 770, loss: 0.057022929191589355
step: 780, loss: 0.0787377804517746
step: 790, loss: 0.03065367043018341
step: 800, loss: 0.05568612366914749
step: 810, loss: 0.09152135252952576
step: 820, loss: 0.0364384688436985
step: 830, loss: 0.08632399141788483
step: 840, loss: 0.11891405284404755
step: 850, loss: 0.0927024558186531
step: 860, loss: 0.061738669872283936
step: 870, loss: 0.13140006363391876
step: 880, loss: 0.06626914441585541
step: 890, loss: 0.15303990244865417
step: 900, loss: 0.054697103798389435
step: 910, loss: 0.1264830082654953
step: 920, loss: 0.07281031459569931
step: 930, loss: 0.11347861588001251
step: 940, loss: 0.015557806938886642
step: 950, loss: 0.04463636130094528
step: 960, loss: 0.09483720362186432
step: 970, loss: 0.09264529496431351
step: 980, loss: 0.06586343050003052
step: 990, loss: 0.1674155592918396
step: 1000, loss: 0.0693977028131485
step: 1010, loss: 0.09819649904966354
step: 1020, loss: 0.0524926520884037
step: 1030, loss: 0.07035510241985321
step: 1040, loss: 0.14039094746112823
step: 1050, loss: 0.191515251994133
step: 1060, loss: 0.033497270196676254
step: 1070, loss: 0.1777651309967041
epoch 8: dev_f1=0.9300184162062616, f1=0.9263351749539595, best_f1=0.9283402681460935
step: 0, loss: 0.025284966453909874
step: 10, loss: 0.03722892701625824
step: 20, loss: 0.02860969677567482
step: 30, loss: 0.04448742792010307
step: 40, loss: 0.20234613120555878
step: 50, loss: 0.025381505489349365
step: 60, loss: 0.07431287318468094
step: 70, loss: 0.037762872874736786
step: 80, loss: 0.0026917681097984314
step: 90, loss: 0.06263568997383118
step: 100, loss: 0.14808768033981323
step: 110, loss: 0.1342979371547699
step: 120, loss: 0.05576018989086151
step: 130, loss: 0.012971539050340652
step: 140, loss: 0.06069758161902428
step: 150, loss: 0.08522743731737137
step: 160, loss: 0.04441990330815315
step: 170, loss: 0.01779990829527378
step: 180, loss: 0.026941752061247826
step: 190, loss: 0.03930558264255524
step: 200, loss: 0.013754590414464474
step: 210, loss: 0.018340062350034714
step: 220, loss: 0.07453376799821854
step: 230, loss: 0.03189724683761597
step: 240, loss: 0.12310556322336197
step: 250, loss: 0.07156585156917572
step: 260, loss: 0.10220139473676682
step: 270, loss: 3.263245525886305e-05
step: 280, loss: 0.0987725555896759
step: 290, loss: 0.020149800926446915
step: 300, loss: 0.0014172869268804789
step: 310, loss: 0.06761788576841354
step: 320, loss: 0.14890047907829285
step: 330, loss: 0.05869585648179054
step: 340, loss: 0.07380640506744385
step: 350, loss: 0.044569890946149826
step: 360, loss: 0.00018222436483483762
step: 370, loss: 0.09409304708242416
step: 380, loss: 0.142096608877182
step: 390, loss: 0.03173690289258957
step: 400, loss: 0.03888262063264847
step: 410, loss: 0.05887320265173912
step: 420, loss: 0.03335174545645714
step: 430, loss: 0.024190673604607582
step: 440, loss: 0.049178410321474075
step: 450, loss: 0.18354089558124542
step: 460, loss: 0.06845428049564362
step: 470, loss: 0.01479486282914877
step: 480, loss: 0.07459983229637146
step: 490, loss: 0.0190939549356699
step: 500, loss: 0.006221052259206772
step: 510, loss: 0.10479909926652908
step: 520, loss: 0.08709374070167542
step: 530, loss: 0.06276856362819672
step: 540, loss: 0.08172864466905594
step: 550, loss: 0.14229702949523926
step: 560, loss: 0.08267305046319962
step: 570, loss: 0.021439578384160995
step: 580, loss: 0.022133495658636093
step: 590, loss: 0.05625882372260094
step: 600, loss: 0.05285171791911125
step: 610, loss: 0.02060987986624241
step: 620, loss: 0.07108636200428009
step: 630, loss: 0.06464336812496185
step: 640, loss: 0.04309048876166344
step: 650, loss: 0.04469308629631996
step: 660, loss: 0.04414980486035347
step: 670, loss: 0.07787127047777176
step: 680, loss: 0.13825596868991852
step: 690, loss: 0.04064863547682762
step: 700, loss: 0.1352725476026535
step: 710, loss: 0.13094772398471832
step: 720, loss: 0.12039569020271301
step: 730, loss: 0.035209521651268005
step: 740, loss: 0.02906869724392891
step: 750, loss: 0.031616371124982834
step: 760, loss: 0.08193325251340866
step: 770, loss: 0.02223522961139679
step: 780, loss: 0.10259997099637985
step: 790, loss: 0.16340680420398712
step: 800, loss: 0.07991551607847214
step: 810, loss: 0.08778543770313263
step: 820, loss: 0.13034874200820923
step: 830, loss: 0.08242473006248474
step: 840, loss: 0.13367125391960144
step: 850, loss: 4.152002657065168e-05
step: 860, loss: 0.23187512159347534
step: 870, loss: 0.08596077561378479
step: 880, loss: 0.12482588738203049
step: 890, loss: 0.04460190236568451
step: 900, loss: 0.17135989665985107
step: 910, loss: 0.07060609757900238
step: 920, loss: 0.0594894215464592
step: 930, loss: 0.03832564502954483
step: 940, loss: 0.03437218442559242
step: 950, loss: 0.05492950975894928
step: 960, loss: 0.12360647320747375
step: 970, loss: 0.01004316471517086
step: 980, loss: 0.02088177762925625
step: 990, loss: 0.0017418728675693274
step: 1000, loss: 0.12920361757278442
step: 1010, loss: 0.10862117260694504
step: 1020, loss: 0.032013796269893646
step: 1030, loss: 0.0798654854297638
step: 1040, loss: 0.08565879613161087
step: 1050, loss: 0.025894219055771828
step: 1060, loss: 0.0339212492108345
step: 1070, loss: 0.10785701125860214
epoch 9: dev_f1=0.9257356375525455, f1=0.9213691026827011, best_f1=0.9283402681460935
step: 0, loss: 0.1262812316417694
step: 10, loss: 0.026727555319666862
step: 20, loss: 0.09015940874814987
step: 30, loss: 0.05034586414694786
step: 40, loss: 0.062129031866788864
step: 50, loss: 0.09389973431825638
step: 60, loss: 0.05687170475721359
step: 70, loss: 0.10434113442897797
step: 80, loss: 0.03842930495738983
step: 90, loss: 0.2026674747467041
step: 100, loss: 0.08208142220973969
step: 110, loss: 0.18417061865329742
step: 120, loss: 0.06639719009399414
step: 130, loss: 0.029993770644068718
step: 140, loss: 0.06283863633871078
step: 150, loss: 0.0638795718550682
step: 160, loss: 0.05802096053957939
step: 170, loss: 0.16008971631526947
step: 180, loss: 0.07269187271595001
step: 190, loss: 0.05082462728023529
step: 200, loss: 0.044612422585487366
step: 210, loss: 0.07625069469213486
step: 220, loss: 0.056386224925518036
step: 230, loss: 0.07609696686267853
step: 240, loss: 0.06500224769115448
step: 250, loss: 0.03487201780080795
step: 260, loss: 0.028250722214579582
step: 270, loss: 0.14678411185741425
step: 280, loss: 0.12687893211841583
step: 290, loss: 0.006318847648799419
step: 300, loss: 0.23548808693885803
step: 310, loss: 0.03967539593577385
step: 320, loss: 0.058197177946567535
step: 330, loss: 0.09891515970230103
step: 340, loss: 0.10247455537319183
step: 350, loss: 0.12455487996339798
step: 360, loss: 0.021160870790481567
step: 370, loss: 0.2294963151216507
step: 380, loss: 0.040608249604701996
step: 390, loss: 0.06397726386785507
step: 400, loss: 0.076492078602314
step: 410, loss: 0.026191452518105507
step: 420, loss: 0.10732489079236984
step: 430, loss: 0.16070526838302612
step: 440, loss: 0.008646382950246334
step: 450, loss: 0.06953500211238861
step: 460, loss: 0.006765240803360939
step: 470, loss: 0.06548280268907547
step: 480, loss: 0.06814171373844147
step: 490, loss: 0.0752640888094902
step: 500, loss: 0.1010642722249031
step: 510, loss: 0.06294660270214081
step: 520, loss: 0.10834826529026031
step: 530, loss: 0.06101451441645622
step: 540, loss: 0.08837436139583588
step: 550, loss: 0.022240661084651947
step: 560, loss: 0.044302068650722504
step: 570, loss: 0.01331725250929594
step: 580, loss: 0.0009550287504680455
step: 590, loss: 0.0643841102719307
step: 600, loss: 0.04370173066854477
step: 610, loss: 0.06146224960684776
step: 620, loss: 0.05644435063004494
step: 630, loss: 0.022660668939352036
step: 640, loss: 0.08928897976875305
step: 650, loss: 0.11680203676223755
step: 660, loss: 0.15071693062782288
step: 670, loss: 0.04437173530459404
step: 680, loss: 0.11624176800251007
step: 690, loss: 0.14240704476833344
step: 700, loss: 0.0012486043851822615
step: 710, loss: 0.051394764333963394
step: 720, loss: 0.07420620322227478
step: 730, loss: 0.07871101051568985
step: 740, loss: 0.1184631735086441
step: 750, loss: 0.05637196823954582
step: 760, loss: 0.09898577630519867
step: 770, loss: 0.0008510473999194801
step: 780, loss: 0.031058350577950478
step: 790, loss: 0.08990611135959625
step: 800, loss: 0.0520368330180645
step: 810, loss: 0.06136566400527954
step: 820, loss: 0.10821006447076797
step: 830, loss: 0.0831209048628807
step: 840, loss: 0.03915678337216377
step: 850, loss: 0.024163389578461647
step: 860, loss: 0.09484554827213287
step: 870, loss: 0.08282161504030228
step: 880, loss: 0.08237620443105698
step: 890, loss: 0.09142165631055832
step: 900, loss: 0.034769803285598755
step: 910, loss: 0.04153452441096306
step: 920, loss: 0.06240788474678993
step: 930, loss: 0.04469907283782959
step: 940, loss: 0.16646115481853485
step: 950, loss: 0.050928596407175064
step: 960, loss: 0.0966414287686348
step: 970, loss: 0.04803220555186272
step: 980, loss: 0.09823307394981384
step: 990, loss: 0.042846906930208206
step: 1000, loss: 0.13937585055828094
step: 1010, loss: 0.09178756177425385
step: 1020, loss: 0.1093011200428009
step: 1030, loss: 0.01152628194540739
step: 1040, loss: 0.09039076417684555
step: 1050, loss: 0.04504507780075073
step: 1060, loss: 0.06127023696899414
step: 1070, loss: 0.24174489080905914
epoch 10: dev_f1=0.9277601090413449, f1=0.9223080417991822, best_f1=0.9283402681460935
step: 0, loss: 0.059794407337903976
step: 10, loss: 0.05095934122800827
step: 20, loss: 0.040839627385139465
step: 30, loss: 0.05973244085907936
step: 40, loss: 0.08714400976896286
step: 50, loss: 0.00031963083893060684
step: 60, loss: 0.025737982243299484
step: 70, loss: 0.04509562999010086
step: 80, loss: 0.018633250147104263
step: 90, loss: 0.08518637716770172
step: 100, loss: 0.04265306517481804
step: 110, loss: 0.0498608835041523
step: 120, loss: 0.04161500185728073
step: 130, loss: 0.16874921321868896
step: 140, loss: 0.03532388061285019
step: 150, loss: 0.03386962041258812
step: 160, loss: 0.15267731249332428
step: 170, loss: 0.006632894277572632
step: 180, loss: 0.04477088898420334
step: 190, loss: 0.07075047492980957
step: 200, loss: 0.0964612066745758
step: 210, loss: 0.26638948917388916
step: 220, loss: 0.022660518065094948
step: 230, loss: 0.03201945498585701
step: 240, loss: 0.2000800520181656
step: 250, loss: 0.0882510095834732
step: 260, loss: 0.0359576977789402
step: 270, loss: 0.010389973409473896
step: 280, loss: 0.07136749476194382
step: 290, loss: 0.13239459693431854
step: 300, loss: 0.014663483016192913
step: 310, loss: 0.07761068642139435
step: 320, loss: 0.10496879369020462
step: 330, loss: 0.0739026814699173
step: 340, loss: 0.05249009653925896
step: 350, loss: 0.11229372024536133
step: 360, loss: 0.028962459415197372
step: 370, loss: 0.01205168105661869
step: 380, loss: 0.13736531138420105
step: 390, loss: 0.07994962483644485
step: 400, loss: 0.05793638527393341
step: 410, loss: 0.030974337831139565
step: 420, loss: 0.06117085739970207
step: 430, loss: 0.059479668736457825
step: 440, loss: 0.21392004191875458
step: 450, loss: 0.06773746013641357
step: 460, loss: 0.04143398627638817
step: 470, loss: 0.09469705820083618
step: 480, loss: 0.09455543756484985
step: 490, loss: 0.1329026073217392
step: 500, loss: 0.04108436033129692
step: 510, loss: 0.0913207158446312
step: 520, loss: 0.03673604503273964
step: 530, loss: 0.03489479422569275
step: 540, loss: 0.15017130970954895
step: 550, loss: 0.003954603802412748
step: 560, loss: 0.12454120069742203
step: 570, loss: 0.28806740045547485
step: 580, loss: 0.049233898520469666
step: 590, loss: 0.032969072461128235
step: 600, loss: 0.07481622695922852
step: 610, loss: 0.10872005671262741
step: 620, loss: 0.05316862463951111
step: 630, loss: 0.04035443067550659
step: 640, loss: 0.007255127653479576
step: 650, loss: 0.1663595736026764
step: 660, loss: 0.07891713082790375
step: 670, loss: 0.20326116681098938
step: 680, loss: 0.049341846257448196
step: 690, loss: 0.030677132308483124
step: 700, loss: 0.05095518380403519
step: 710, loss: 0.06465613842010498
step: 720, loss: 0.048626843839883804
step: 730, loss: 0.03280489146709442
step: 740, loss: 0.09410413354635239
step: 750, loss: 0.11956559866666794
step: 760, loss: 0.07615140080451965
step: 770, loss: 0.0003567843814380467
step: 780, loss: 0.10400483757257462
step: 790, loss: 0.09178685396909714
step: 800, loss: 0.06813033670186996
step: 810, loss: 2.8304002626100555e-05
step: 820, loss: 0.05477701872587204
step: 830, loss: 0.01593591831624508
step: 840, loss: 0.07239832729101181
step: 850, loss: 0.06685192883014679
step: 860, loss: 0.03953895717859268
step: 870, loss: 0.05780649557709694
step: 880, loss: 0.05250267684459686
step: 890, loss: 0.0973513051867485
step: 900, loss: 0.10454761981964111
step: 910, loss: 0.0942346379160881
step: 920, loss: 0.1005844995379448
step: 930, loss: 0.044187281280756
step: 940, loss: 0.025885673239827156
step: 950, loss: 0.08192034065723419
step: 960, loss: 0.13978302478790283
step: 970, loss: 0.15358194708824158
step: 980, loss: 0.03872368857264519
step: 990, loss: 0.12883691489696503
step: 1000, loss: 0.06371387839317322
step: 1010, loss: 0.05807827413082123
step: 1020, loss: 0.04498564451932907
step: 1030, loss: 0.024976912885904312
step: 1040, loss: 0.14574219286441803
step: 1050, loss: 0.016408700495958328
step: 1060, loss: 0.08166355639696121
step: 1070, loss: 0.12772853672504425
epoch 11: dev_f1=0.9265381083562901, f1=0.9238532110091744, best_f1=0.9283402681460935
step: 0, loss: 0.0859503448009491
step: 10, loss: 0.025492534041404724
step: 20, loss: 0.019911551848053932
step: 30, loss: 0.0514436773955822
step: 40, loss: 0.009953600354492664
step: 50, loss: 0.01497468538582325
step: 60, loss: 0.03715795278549194
step: 70, loss: 0.09438864886760712
step: 80, loss: 0.05223398655653
step: 90, loss: 0.07712970674037933
step: 100, loss: 0.07384538650512695
step: 110, loss: 0.005092339590191841
step: 120, loss: 0.013143283315002918
step: 130, loss: 0.12984687089920044
step: 140, loss: 0.05706242844462395
step: 150, loss: 0.0755826085805893
step: 160, loss: 0.1544315218925476
step: 170, loss: 0.08352576196193695
step: 180, loss: 0.02173256129026413
step: 190, loss: 0.10197572410106659
step: 200, loss: 0.038485657423734665
step: 210, loss: 0.05409354344010353
step: 220, loss: 0.031154165044426918
step: 230, loss: 0.029440533369779587
step: 240, loss: 0.053129274398088455
step: 250, loss: 0.020793050527572632
step: 260, loss: 0.06382216513156891
step: 270, loss: 0.03502918779850006
step: 280, loss: 0.10072318464517593
step: 290, loss: 0.00017421910888515413
step: 300, loss: 0.04237626865506172
step: 310, loss: 0.04126514866948128
step: 320, loss: 0.054757989943027496
step: 330, loss: 0.02669576369225979
step: 340, loss: 0.02060386724770069
step: 350, loss: 0.01833651214838028
step: 360, loss: 0.030486052855849266
step: 370, loss: 0.02267252281308174
step: 380, loss: 0.18296203017234802
step: 390, loss: 0.05856451392173767
step: 400, loss: 0.048111770302057266
step: 410, loss: 0.030650528147816658
step: 420, loss: 0.024784604087471962
step: 430, loss: 0.02895498462021351
step: 440, loss: 0.05957050248980522
step: 450, loss: 0.08613137900829315
step: 460, loss: 0.02438211627304554
step: 470, loss: 0.07570277899503708
step: 480, loss: 0.11294998973608017
step: 490, loss: 0.09935539215803146
step: 500, loss: 0.1174812763929367
step: 510, loss: 0.007821463979780674
step: 520, loss: 0.055162638425827026
step: 530, loss: 0.09240595996379852
step: 540, loss: 0.026173438876867294
step: 550, loss: 0.01209136750549078
step: 560, loss: 0.06787651777267456
step: 570, loss: 0.026662936434149742
step: 580, loss: 0.07822554558515549
step: 590, loss: 0.09076327085494995
step: 600, loss: 0.0875965803861618
step: 610, loss: 0.1449536830186844
step: 620, loss: 0.03728046640753746
step: 630, loss: 0.00789092667400837
step: 640, loss: 0.16767027974128723
step: 650, loss: 0.01274051982909441
step: 660, loss: 0.07905708253383636
step: 670, loss: 0.19164951145648956
step: 680, loss: 0.04879823699593544
step: 690, loss: 0.07367069274187088
step: 700, loss: 0.08477548509836197
step: 710, loss: 0.030023252591490746
step: 720, loss: 0.017126765102148056
step: 730, loss: 0.08707724511623383
step: 740, loss: 0.023195749148726463
step: 750, loss: 0.06261695921421051
step: 760, loss: 0.11561181396245956
step: 770, loss: 0.02893252670764923
step: 780, loss: 0.035019002854824066
step: 790, loss: 0.08793724328279495
step: 800, loss: 0.04673285409808159
step: 810, loss: 0.22044917941093445
step: 820, loss: 0.03383539617061615
step: 830, loss: 0.08864711970090866
step: 840, loss: 0.09416932612657547
step: 850, loss: 0.11102667450904846
step: 860, loss: 0.0673275887966156
step: 870, loss: 0.03583266958594322
step: 880, loss: 0.05807060748338699
step: 890, loss: 0.0450279675424099
step: 900, loss: 0.023796165362000465
step: 910, loss: 0.0455358512699604
step: 920, loss: 0.056019268929958344
step: 930, loss: 0.1088406890630722
step: 940, loss: 0.05689769238233566
step: 950, loss: 0.04508261755108833
step: 960, loss: 0.027801090851426125
step: 970, loss: 0.0026852209120988846
step: 980, loss: 0.15749701857566833
step: 990, loss: 0.00333198718726635
step: 1000, loss: 0.05761450156569481
step: 1010, loss: 0.0023392383009195328
step: 1020, loss: 0.02257283218204975
step: 1030, loss: 0.07653118669986725
step: 1040, loss: 0.04638517647981644
step: 1050, loss: 0.08479683101177216
step: 1060, loss: 0.048873696476221085
step: 1070, loss: 0.018742915242910385
epoch 12: dev_f1=0.9169027384324836, f1=0.9231485794131347, best_f1=0.9283402681460935
step: 0, loss: 0.055436670780181885
step: 10, loss: 0.09798380732536316
step: 20, loss: 0.10429749637842178
step: 30, loss: 0.03617314249277115
step: 40, loss: 0.05500113591551781
step: 50, loss: 0.08664912730455399
step: 60, loss: 0.053218428045511246
step: 70, loss: 0.10372929275035858
step: 80, loss: 0.0017878663493320346
step: 90, loss: 0.07613983005285263
step: 100, loss: 0.04098961874842644
step: 110, loss: 3.5164881410310045e-05
step: 120, loss: 0.015861835330724716
step: 130, loss: 0.05644693598151207
step: 140, loss: 0.00013675125956069678
step: 150, loss: 0.0827602669596672
step: 160, loss: 0.00038277643034234643
step: 170, loss: 0.061379145830869675
step: 180, loss: 0.08953457325696945
step: 190, loss: 0.0113827558234334
step: 200, loss: 0.046391669660806656
step: 210, loss: 0.001558517338708043
step: 220, loss: 0.03803570941090584
step: 230, loss: 0.035496704280376434
step: 240, loss: 0.06315583735704422
step: 250, loss: 0.01712045446038246
step: 260, loss: 0.03194928541779518
step: 270, loss: 0.02795371599495411
step: 280, loss: 0.05244304984807968
step: 290, loss: 0.11350660026073456
step: 300, loss: 0.07483692467212677
step: 310, loss: 0.025341609492897987
step: 320, loss: 0.03731408715248108
step: 330, loss: 0.0012548138620331883
step: 340, loss: 0.003520925994962454
step: 350, loss: 0.0405256412923336
step: 360, loss: 0.0822848305106163
step: 370, loss: 0.11072802543640137
step: 380, loss: 0.0692380964756012
step: 390, loss: 0.0368533693253994
step: 400, loss: 0.0664970800280571
step: 410, loss: 2.7342062821844593e-05
step: 420, loss: 0.18809261918067932
step: 430, loss: 0.06339279562234879
step: 440, loss: 0.22956010699272156
step: 450, loss: 0.07747828960418701
step: 460, loss: 0.06594595313072205
step: 470, loss: 0.06304613500833511
step: 480, loss: 0.09626532346010208
step: 490, loss: 0.025349555537104607
step: 500, loss: 0.053211014717817307
step: 510, loss: 0.025960015133023262
step: 520, loss: 0.001129601150751114
step: 530, loss: 0.006975190714001656
step: 540, loss: 0.0028800726868212223
step: 550, loss: 0.00908088218420744
step: 560, loss: 0.05653145909309387
step: 570, loss: 0.06756626069545746
step: 580, loss: 0.04627816006541252
step: 590, loss: 0.09879929572343826
step: 600, loss: 0.07096466422080994
step: 610, loss: 0.0023932717740535736
step: 620, loss: 0.06712477654218674
step: 630, loss: 0.125454381108284
step: 640, loss: 0.04305147007107735
step: 650, loss: 0.0511271171271801
step: 660, loss: 0.03639714792370796
step: 670, loss: 0.06875169277191162
step: 680, loss: 0.014627430588006973
step: 690, loss: 0.03117808699607849
step: 700, loss: 0.06788437068462372
step: 710, loss: 0.012620781548321247
step: 720, loss: 0.03780094161629677
step: 730, loss: 0.032251469790935516
step: 740, loss: 0.011972025968134403
step: 750, loss: 0.02982456237077713
step: 760, loss: 0.11441866308450699
step: 770, loss: 0.10170798748731613
step: 780, loss: 0.023771345615386963
step: 790, loss: 0.1280861794948578
step: 800, loss: 0.137860506772995
step: 810, loss: 0.10150803625583649
step: 820, loss: 0.036076828837394714
step: 830, loss: 0.028753457590937614
step: 840, loss: 0.06532123684883118
step: 850, loss: 3.805304004345089e-05
step: 860, loss: 0.10054521262645721
step: 870, loss: 0.042213283479213715
step: 880, loss: 0.014410832896828651
step: 890, loss: 0.07243214547634125
step: 900, loss: 0.0600421205163002
step: 910, loss: 0.03979935869574547
step: 920, loss: 0.04988376051187515
step: 930, loss: 0.05247661843895912
step: 940, loss: 0.07436637580394745
step: 950, loss: 0.07950771600008011
step: 960, loss: 0.04051806405186653
step: 970, loss: 0.03174999728798866
step: 980, loss: 0.00021769051090814173
step: 990, loss: 0.02747974917292595
step: 1000, loss: 0.05569131672382355
step: 1010, loss: 0.001821798156015575
step: 1020, loss: 0.018111808225512505
step: 1030, loss: 0.06936386227607727
step: 1040, loss: 0.07419371604919434
step: 1050, loss: 0.0487622506916523
step: 1060, loss: 0.05748576670885086
step: 1070, loss: 0.039563048630952835
epoch 13: dev_f1=0.9186602870813397, f1=0.9267831837505905, best_f1=0.9283402681460935
step: 0, loss: 0.028326185420155525
step: 10, loss: 0.05360492318868637
step: 20, loss: 0.10106132924556732
step: 30, loss: 0.09438253939151764
step: 40, loss: 0.16035784780979156
step: 50, loss: 0.02628747932612896
step: 60, loss: 0.024529796093702316
step: 70, loss: 0.0019089947454631329
step: 80, loss: 0.03955100476741791
step: 90, loss: 0.02205784060060978
step: 100, loss: 0.09214125573635101
step: 110, loss: 0.013104247860610485
step: 120, loss: 0.05137311667203903
step: 130, loss: 0.04191891849040985
step: 140, loss: 0.040675386786460876
step: 150, loss: 0.013874414376914501
step: 160, loss: 0.024338703602552414
step: 170, loss: 0.06220884621143341
step: 180, loss: 0.01889941841363907
step: 190, loss: 0.020509909838438034
step: 200, loss: 0.08141226321458817
step: 210, loss: 0.011974334716796875
step: 220, loss: 0.030854135751724243
step: 230, loss: 0.04695054516196251
step: 240, loss: 0.075594961643219
step: 250, loss: 0.08234511315822601
step: 260, loss: 0.07245347648859024
step: 270, loss: 0.0033419616520404816
step: 280, loss: 0.02309827134013176
step: 290, loss: 0.04873523861169815
step: 300, loss: 0.08192633092403412
step: 310, loss: 0.11296903342008591
step: 320, loss: 0.048103030771017075
step: 330, loss: 0.048061974346637726
step: 340, loss: 0.052084214985370636
step: 350, loss: 0.06712177395820618
step: 360, loss: 0.04149442911148071
step: 370, loss: 0.056525930762290955
step: 380, loss: 0.0989893227815628
step: 390, loss: 0.008831250481307507
step: 400, loss: 0.00516514154151082
step: 410, loss: 0.0905475839972496
step: 420, loss: 0.04535349830985069
step: 430, loss: 0.024046339094638824
step: 440, loss: 0.026229552924633026
step: 450, loss: 0.00549405999481678
step: 460, loss: 0.03608854115009308
step: 470, loss: 0.09214655309915543
step: 480, loss: 0.12235476076602936
step: 490, loss: 0.06412095576524734
step: 500, loss: 0.028077879920601845
step: 510, loss: 0.044209662824869156
step: 520, loss: 0.18052569031715393
step: 530, loss: 0.12473421543836594
step: 540, loss: 0.039590343832969666
step: 550, loss: 0.041994500905275345
step: 560, loss: 0.015421930700540543
step: 570, loss: 0.04569833725690842
step: 580, loss: 0.04728424921631813
step: 590, loss: 0.03332138434052467
step: 600, loss: 0.035603076219558716
step: 610, loss: 0.04660886526107788
step: 620, loss: 0.008089760318398476
step: 630, loss: 0.0001583107077749446
step: 640, loss: 0.026356367394328117
step: 650, loss: 0.045351818203926086
step: 660, loss: 0.0035363242495805025
step: 670, loss: 0.07032071799039841
step: 680, loss: 0.027032822370529175
step: 690, loss: 0.03984357789158821
step: 700, loss: 0.022495487704873085
step: 710, loss: 0.10260967910289764
step: 720, loss: 0.02883521094918251
step: 730, loss: 0.038725920021533966
step: 740, loss: 0.05351648107171059
step: 750, loss: 0.03150295838713646
step: 760, loss: 0.04247389733791351
step: 770, loss: 0.023363227024674416
step: 780, loss: 0.07395785301923752
step: 790, loss: 0.015259811654686928
step: 800, loss: 0.022645490244030952
step: 810, loss: 0.03908192738890648
step: 820, loss: 0.0449356772005558
step: 830, loss: 0.09763775765895844
step: 840, loss: 0.03692849352955818
step: 850, loss: 0.0680830180644989
step: 860, loss: 0.09477707743644714
step: 870, loss: 0.02180313877761364
step: 880, loss: 0.09905052930116653
step: 890, loss: 0.06958398967981339
step: 900, loss: 0.029828369617462158
step: 910, loss: 0.0035352203994989395
step: 920, loss: 0.0810510665178299
step: 930, loss: 0.03522608429193497
step: 940, loss: 0.06759078800678253
step: 950, loss: 0.045456886291503906
step: 960, loss: 0.008596992120146751
step: 970, loss: 0.07766714692115784
step: 980, loss: 0.0856844037771225
step: 990, loss: 0.0279674269258976
step: 1000, loss: 0.036038294434547424
step: 1010, loss: 0.0642879530787468
step: 1020, loss: 0.1447029858827591
step: 1030, loss: 0.028255576267838478
step: 1040, loss: 0.0916937068104744
step: 1050, loss: 0.13335666060447693
step: 1060, loss: 0.050825655460357666
step: 1070, loss: 0.04846615344285965
epoch 14: dev_f1=0.9243140964995269, f1=0.9240150093808631, best_f1=0.9283402681460935
step: 0, loss: 0.019142689183354378
step: 10, loss: 0.06069153919816017
step: 20, loss: 0.027970150113105774
step: 30, loss: 0.10049176961183548
step: 40, loss: 0.0003069559170398861
step: 50, loss: 0.031034832820296288
step: 60, loss: 0.07791977375745773
step: 70, loss: 0.02995656430721283
step: 80, loss: 0.00039294257294386625
step: 90, loss: 0.043259888887405396
step: 100, loss: 0.014254323206841946
step: 110, loss: 0.004481783136725426
step: 120, loss: 0.05074429512023926
step: 130, loss: 0.04428844153881073
step: 140, loss: 0.04802508279681206
step: 150, loss: 0.038403432816267014
step: 160, loss: 0.10136781632900238
step: 170, loss: 0.023146500810980797
step: 180, loss: 0.04710838198661804
step: 190, loss: 0.01638711988925934
step: 200, loss: 0.04433044418692589
step: 210, loss: 0.02541443705558777
step: 220, loss: 0.02353450283408165
step: 230, loss: 0.04610903188586235
step: 240, loss: 0.00016258773393929005
step: 250, loss: 0.07987958192825317
step: 260, loss: 0.008590193465352058
step: 270, loss: 0.032326605170965195
step: 280, loss: 0.040575552731752396
step: 290, loss: 0.00032244945759885013
step: 300, loss: 0.019953439012169838
step: 310, loss: 0.043860141187906265
step: 320, loss: 0.11063691973686218
step: 330, loss: 0.0626756027340889
step: 340, loss: 0.002601487562060356
step: 350, loss: 0.12750399112701416
step: 360, loss: 0.06717977672815323
step: 370, loss: 0.04638740047812462
step: 380, loss: 0.013441980816423893
step: 390, loss: 0.05741411820054054
step: 400, loss: 0.02164214849472046
step: 410, loss: 0.003577521536499262
step: 420, loss: 0.08552923053503036
step: 430, loss: 0.07665520906448364
step: 440, loss: 0.0049403090961277485
step: 450, loss: 0.03907938301563263
step: 460, loss: 0.05789764225482941
step: 470, loss: 0.07964853197336197
step: 480, loss: 0.053092554211616516
step: 490, loss: 0.024845954030752182
step: 500, loss: 0.05885911360383034
step: 510, loss: 0.09591204673051834
step: 520, loss: 0.07013484835624695
step: 530, loss: 0.033148497343063354
step: 540, loss: 0.05340304970741272
step: 550, loss: 0.10978896915912628
step: 560, loss: 0.04272903501987457
step: 570, loss: 0.019312171265482903
step: 580, loss: 0.09352541714906693
step: 590, loss: 0.045154374092817307
step: 600, loss: 0.09919636696577072
step: 610, loss: 0.030236423015594482
step: 620, loss: 0.00015532231191173196
step: 630, loss: 0.03568492457270622
step: 640, loss: 0.03966012969613075
step: 650, loss: 0.06842377781867981
step: 660, loss: 0.021053822711110115
step: 670, loss: 0.06584515422582626
step: 680, loss: 0.0004498792113736272
step: 690, loss: 0.01761803589761257
step: 700, loss: 0.028139546513557434
step: 710, loss: 0.04338233172893524
step: 720, loss: 0.021672654896974564
step: 730, loss: 0.04875107854604721
step: 740, loss: 0.0676196813583374
step: 750, loss: 0.050343990325927734
step: 760, loss: 0.03465697541832924
step: 770, loss: 0.06418734788894653
step: 780, loss: 0.10671140998601913
step: 790, loss: 0.04135506972670555
step: 800, loss: 0.03723277151584625
step: 810, loss: 0.06533373892307281
step: 820, loss: 0.06298539787530899
step: 830, loss: 0.056444086134433746
step: 840, loss: 0.0892813429236412
step: 850, loss: 0.06075011566281319
step: 860, loss: 0.19327394664287567
step: 870, loss: 0.02980773337185383
step: 880, loss: 0.08222101628780365
step: 890, loss: 0.07359349727630615
step: 900, loss: 0.08551936596632004
step: 910, loss: 0.05234180763363838
step: 920, loss: 0.15665893256664276
step: 930, loss: 0.041543927043676376
step: 940, loss: 0.008254925720393658
step: 950, loss: 0.11848441511392593
step: 960, loss: 0.03371760994195938
step: 970, loss: 0.01909237913787365
step: 980, loss: 0.06716276705265045
step: 990, loss: 0.04703299328684807
step: 1000, loss: 0.044011954218149185
step: 1010, loss: 0.0936422348022461
step: 1020, loss: 0.03446730598807335
step: 1030, loss: 0.024915596470236778
step: 1040, loss: 0.058971159160137177
step: 1050, loss: 0.12612301111221313
step: 1060, loss: 6.078337537473999e-05
step: 1070, loss: 0.03011520765721798
epoch 15: dev_f1=0.92814093648586, f1=0.925925925925926, best_f1=0.9283402681460935
step: 0, loss: 0.04886465519666672
step: 10, loss: 0.027478521689772606
step: 20, loss: 0.06790413707494736
step: 30, loss: 0.11230841279029846
step: 40, loss: 0.01589883677661419
step: 50, loss: 0.10275408625602722
step: 60, loss: 0.03137004002928734
step: 70, loss: 0.0017811934230849147
step: 80, loss: 0.023007262498140335
step: 90, loss: 0.07450296729803085
step: 100, loss: 0.06018911674618721
step: 110, loss: 0.1573605090379715
step: 120, loss: 0.014283625409007072
step: 130, loss: 0.046682506799697876
step: 140, loss: 0.06385321915149689
step: 150, loss: 0.008655558340251446
step: 160, loss: 0.06062394753098488
step: 170, loss: 0.08705796301364899
step: 180, loss: 0.0006811519851908088
step: 190, loss: 0.0425981730222702
step: 200, loss: 0.030434658750891685
step: 210, loss: 0.07747025787830353
step: 220, loss: 0.136789008975029
step: 230, loss: 0.06707748770713806
step: 240, loss: 0.04057381674647331
step: 250, loss: 0.06828026473522186
step: 260, loss: 0.0672149807214737
step: 270, loss: 0.011320386081933975
step: 280, loss: 0.007954087108373642
step: 290, loss: 0.01389731839299202
step: 300, loss: 0.00016573067114222795
step: 310, loss: 0.06729380041360855
step: 320, loss: 0.007308426313102245
step: 330, loss: 0.04378633201122284
step: 340, loss: 0.0789165049791336
step: 350, loss: 0.03804819658398628
step: 360, loss: 0.07630454003810883
step: 370, loss: 0.07073788344860077
step: 380, loss: 0.04770127311348915
step: 390, loss: 0.10301989316940308
step: 400, loss: 0.0007842238410376012
step: 410, loss: 0.014059093780815601
step: 420, loss: 0.03147504851222038
step: 430, loss: 0.038065701723098755
step: 440, loss: 0.04191131517291069
step: 450, loss: 0.28320521116256714
step: 460, loss: 0.08194131404161453
step: 470, loss: 0.04930247738957405
step: 480, loss: 0.05021851137280464
step: 490, loss: 0.024818653240799904
step: 500, loss: 0.03740059584379196
step: 510, loss: 0.012714921496808529
step: 520, loss: 0.06513497978448868
step: 530, loss: 0.06178310513496399
step: 540, loss: 0.00014990349882282317
step: 550, loss: 0.003530288813635707
step: 560, loss: 0.02626795507967472
step: 570, loss: 0.0630660429596901
step: 580, loss: 0.03467627242207527
step: 590, loss: 0.03532492369413376
step: 600, loss: 0.07206761091947556
step: 610, loss: 0.026483001187443733
step: 620, loss: 0.014047159813344479
step: 630, loss: 0.03728953003883362
step: 640, loss: 0.022683002054691315
step: 650, loss: 0.021711666136980057
step: 660, loss: 0.18476548790931702
step: 670, loss: 0.08613679558038712
step: 680, loss: 0.02033359184861183
step: 690, loss: 0.11423515528440475
step: 700, loss: 0.01749541610479355
step: 710, loss: 0.046086035668849945
step: 720, loss: 0.03397398442029953
step: 730, loss: 0.04622605815529823
step: 740, loss: 0.02847626991569996
step: 750, loss: 0.03465033695101738
step: 760, loss: 0.050191424787044525
step: 770, loss: 0.05303743854165077
step: 780, loss: 0.028767678886651993
step: 790, loss: 0.05506604164838791
step: 800, loss: 0.05310487747192383
step: 810, loss: 0.05045689642429352
step: 820, loss: 0.023639976978302002
step: 830, loss: 0.10651370137929916
step: 840, loss: 0.05063339322805405
step: 850, loss: 0.11709090322256088
step: 860, loss: 0.14011134207248688
step: 870, loss: 0.011225864291191101
step: 880, loss: 2.5898554667946883e-05
step: 890, loss: 0.0332115963101387
step: 900, loss: 0.09064950048923492
step: 910, loss: 0.05962306261062622
step: 920, loss: 0.0922069177031517
step: 930, loss: 0.05058267340064049
step: 940, loss: 0.11082512140274048
step: 950, loss: 0.06985140591859818
step: 960, loss: 0.021637046709656715
step: 970, loss: 0.020580103620886803
step: 980, loss: 0.04405277967453003
step: 990, loss: 0.06325771659612656
step: 1000, loss: 0.027263248339295387
step: 1010, loss: 0.2348831593990326
step: 1020, loss: 0.039703987538814545
step: 1030, loss: 0.06640608608722687
step: 1040, loss: 0.05965232849121094
step: 1050, loss: 0.06533315777778625
step: 1060, loss: 0.08698470145463943
step: 1070, loss: 0.028625814244151115
epoch 16: dev_f1=0.9247311827956989, f1=0.9219330855018587, best_f1=0.9283402681460935
step: 0, loss: 0.02794830873608589
step: 10, loss: 0.007487545255571604
step: 20, loss: 0.05826090648770332
step: 30, loss: 0.06189442053437233
step: 40, loss: 0.056846536695957184
step: 50, loss: 0.01614338345825672
step: 60, loss: 0.045151565223932266
step: 70, loss: 4.0290047763846815e-05
step: 80, loss: 0.13142365217208862
step: 90, loss: 0.030289681628346443
step: 100, loss: 0.05211515352129936
step: 110, loss: 0.07136962562799454
step: 120, loss: 0.04656648263335228
step: 130, loss: 0.08506802469491959
step: 140, loss: 0.022381935268640518
step: 150, loss: 0.06964859366416931
step: 160, loss: 0.01754625514149666
step: 170, loss: 0.05528793856501579
step: 180, loss: 0.0027120159938931465
step: 190, loss: 0.0003233398892916739
step: 200, loss: 0.0553203709423542
step: 210, loss: 0.07042377442121506
step: 220, loss: 0.08619485795497894
step: 230, loss: 0.00038326100911945105
step: 240, loss: 0.030219299718737602
step: 250, loss: 3.64778570656199e-05
step: 260, loss: 0.044896867126226425
step: 270, loss: 0.03712860494852066
step: 280, loss: 0.03522546961903572
step: 290, loss: 0.029967373237013817
step: 300, loss: 0.06700999289751053
step: 310, loss: 0.01459007803350687
step: 320, loss: 0.034105829894542694
step: 330, loss: 0.019270773977041245
step: 340, loss: 0.05634945258498192
step: 350, loss: 0.025556791573762894
step: 360, loss: 0.07292021065950394
step: 370, loss: 0.01841595396399498
step: 380, loss: 0.026177898049354553
step: 390, loss: 0.047012194991111755
step: 400, loss: 0.0649823397397995
step: 410, loss: 0.11368093639612198
step: 420, loss: 0.31724315881729126
step: 430, loss: 0.07560711354017258
step: 440, loss: 0.04395637288689613
step: 450, loss: 0.047263000160455704
step: 460, loss: 0.07142620533704758
step: 470, loss: 0.0559229739010334
step: 480, loss: 0.05321969836950302
step: 490, loss: 0.03613952174782753
step: 500, loss: 0.018572179600596428
step: 510, loss: 0.04488850012421608
step: 520, loss: 0.07573221623897552
step: 530, loss: 0.07124827802181244
step: 540, loss: 0.014676754362881184
step: 550, loss: 0.051164619624614716
step: 560, loss: 0.08238740265369415
step: 570, loss: 0.08661764115095139
step: 580, loss: 3.7870278902119026e-05
step: 590, loss: 0.13743898272514343
step: 600, loss: 0.015423119068145752
step: 610, loss: 0.04267122596502304
step: 620, loss: 0.03240847587585449
step: 630, loss: 0.08971452713012695
step: 640, loss: 0.021798526868224144
step: 650, loss: 0.08274023234844208
step: 660, loss: 0.0720304325222969
step: 670, loss: 0.06792034953832626
step: 680, loss: 0.02539120987057686
step: 690, loss: 0.0705411359667778
step: 700, loss: 0.04024486243724823
step: 710, loss: 0.07745538651943207
step: 720, loss: 0.031199093908071518
step: 730, loss: 0.04086969792842865
step: 740, loss: 0.02049744501709938
step: 750, loss: 0.07129547744989395
step: 760, loss: 0.05442975461483002
step: 770, loss: 0.03701848164200783
step: 780, loss: 0.09250704199075699
step: 790, loss: 0.06279844045639038
step: 800, loss: 0.078964963555336
step: 810, loss: 0.00022602049284614623
step: 820, loss: 0.03867877647280693
step: 830, loss: 0.05396885424852371
step: 840, loss: 0.030295642092823982
step: 850, loss: 0.024726998060941696
step: 860, loss: 0.018037663772702217
step: 870, loss: 0.04734865576028824
step: 880, loss: 0.03498944267630577
step: 890, loss: 0.06499852240085602
step: 900, loss: 0.025391841307282448
step: 910, loss: 0.036591436713933945
step: 920, loss: 0.0422654002904892
step: 930, loss: 0.05771313235163689
step: 940, loss: 0.09772135317325592
step: 950, loss: 0.03412948548793793
step: 960, loss: 0.026482446119189262
step: 970, loss: 0.050491221249103546
step: 980, loss: 0.01606011763215065
step: 990, loss: 0.0335722379386425
step: 1000, loss: 0.06761347502470016
step: 1010, loss: 0.012827292084693909
step: 1020, loss: 0.11717868596315384
step: 1030, loss: 0.025092359632253647
step: 1040, loss: 0.016110554337501526
step: 1050, loss: 0.03878330811858177
step: 1060, loss: 0.3083384037017822
step: 1070, loss: 0.21485178172588348
epoch 17: dev_f1=0.9244570349386214, f1=0.9274004683840749, best_f1=0.9283402681460935
step: 0, loss: 0.02431512624025345
step: 10, loss: 0.024681266397237778
step: 20, loss: 0.03912894055247307
step: 30, loss: 0.027100443840026855
step: 40, loss: 0.1018754094839096
step: 50, loss: 0.047674115747213364
step: 60, loss: 0.05401347950100899
step: 70, loss: 0.07728215306997299
step: 80, loss: 0.0029800168704241514
step: 90, loss: 0.07570185512304306
step: 100, loss: 0.02875584550201893
step: 110, loss: 0.05526655539870262
step: 120, loss: 0.05880850926041603
step: 130, loss: 0.07356265187263489
step: 140, loss: 0.02058221772313118
step: 150, loss: 0.05470213294029236
step: 160, loss: 0.08587227016687393
step: 170, loss: 0.06843685358762741
step: 180, loss: 0.02763797901570797
step: 190, loss: 0.019441720098257065
step: 200, loss: 0.05053729936480522
step: 210, loss: 0.037291768938302994
step: 220, loss: 0.052913498133420944
step: 230, loss: 0.026688650250434875
step: 240, loss: 0.040035977959632874
step: 250, loss: 0.0410652831196785
step: 260, loss: 0.00046574865700677037
step: 270, loss: 1.4878613001201302e-05
step: 280, loss: 0.035923246294260025
step: 290, loss: 0.02453427202999592
step: 300, loss: 0.04500320553779602
step: 310, loss: 0.032056551426649094
step: 320, loss: 0.018797138705849648
step: 330, loss: 0.06695672869682312
step: 340, loss: 0.045026995241642
step: 350, loss: 0.022078918293118477
step: 360, loss: 0.020008444786071777
step: 370, loss: 0.035482294857501984
step: 380, loss: 0.08658912777900696
step: 390, loss: 0.029975401237607002
step: 400, loss: 0.045827995985746384
step: 410, loss: 0.126460462808609
step: 420, loss: 0.06540055572986603
step: 430, loss: 0.0440727099776268
step: 440, loss: 0.016055090352892876
step: 450, loss: 0.020189711824059486
step: 460, loss: 0.016908442601561546
step: 470, loss: 0.09655319899320602
step: 480, loss: 0.012914260849356651
step: 490, loss: 0.09451471269130707
step: 500, loss: 0.06023750826716423
step: 510, loss: 0.02909877896308899
step: 520, loss: 0.03713769093155861
step: 530, loss: 0.0456230528652668
step: 540, loss: 0.05880730599164963
step: 550, loss: 0.07814542949199677
step: 560, loss: 0.1622508317232132
step: 570, loss: 0.012583022937178612
step: 580, loss: 0.05815985053777695
step: 590, loss: 0.03634921461343765
step: 600, loss: 0.07939425110816956
step: 610, loss: 0.052776236087083817
step: 620, loss: 0.020408615469932556
step: 630, loss: 0.08898653835058212
step: 640, loss: 3.723884219652973e-05
step: 650, loss: 0.0743652805685997
step: 660, loss: 0.09522618353366852
step: 670, loss: 0.02130754105746746
step: 680, loss: 0.044369082897901535
step: 690, loss: 9.06775749172084e-05
step: 700, loss: 0.06549781560897827
step: 710, loss: 0.06890302896499634
step: 720, loss: 0.04243648424744606
step: 730, loss: 0.01714278757572174
step: 740, loss: 0.04941858351230621
step: 750, loss: 0.0426824688911438
step: 760, loss: 0.020440975204110146
step: 770, loss: 0.03374681994318962
step: 780, loss: 4.921184518025257e-05
step: 790, loss: 8.876789070200175e-05
step: 800, loss: 0.03156929090619087
step: 810, loss: 0.05618071183562279
step: 820, loss: 0.06185685098171234
step: 830, loss: 0.017811905592679977
step: 840, loss: 0.0717540830373764
step: 850, loss: 0.016699859872460365
step: 860, loss: 0.09054005891084671
step: 870, loss: 0.04084251448512077
step: 880, loss: 0.09531275928020477
step: 890, loss: 0.09548832476139069
step: 900, loss: 0.025535237044095993
step: 910, loss: 0.056124649941921234
step: 920, loss: 0.1517203003168106
step: 930, loss: 0.07202871888875961
step: 940, loss: 0.015199258923530579
step: 950, loss: 0.04648493975400925
step: 960, loss: 0.05323491618037224
step: 970, loss: 0.037505142390728
step: 980, loss: 0.08880428224802017
step: 990, loss: 0.0313710942864418
step: 1000, loss: 0.04858480021357536
step: 1010, loss: 0.022886132821440697
step: 1020, loss: 0.043971411883831024
step: 1030, loss: 0.0005535575328394771
step: 1040, loss: 0.00264047272503376
step: 1050, loss: 0.017275655642151833
step: 1060, loss: 0.021842563524842262
step: 1070, loss: 0.0788622722029686
epoch 18: dev_f1=0.9256820319849483, f1=0.9219261337073399, best_f1=0.9283402681460935
step: 0, loss: 0.016162093728780746
step: 10, loss: 0.06997518986463547
step: 20, loss: 0.01639975607395172
step: 30, loss: 0.07894506305456161
step: 40, loss: 0.028616541996598244
step: 50, loss: 0.039213698357343674
step: 60, loss: 0.019311286509037018
step: 70, loss: 0.1291084587574005
step: 80, loss: 0.06666228920221329
step: 90, loss: 0.07531460374593735
step: 100, loss: 0.0633467510342598
step: 110, loss: 0.04224621132016182
step: 120, loss: 0.05314743518829346
step: 130, loss: 0.05823121219873428
step: 140, loss: 0.1389271765947342
step: 150, loss: 0.06927680224180222
step: 160, loss: 0.004274735692888498
step: 170, loss: 0.01615312322974205
step: 180, loss: 0.015881076455116272
step: 190, loss: 0.043271660804748535
step: 200, loss: 0.04272441193461418
step: 210, loss: 0.01853816956281662
step: 220, loss: 0.08057481795549393
step: 230, loss: 0.06202184036374092
step: 240, loss: 0.01629510708153248
step: 250, loss: 5.2862113079754636e-05
step: 260, loss: 0.07004529237747192
step: 270, loss: 0.02920520305633545
step: 280, loss: 0.1135246679186821
step: 290, loss: 0.026589244604110718
step: 300, loss: 0.07512109726667404
step: 310, loss: 0.04577788710594177
step: 320, loss: 0.03500894829630852
step: 330, loss: 0.015773922204971313
step: 340, loss: 0.027463354170322418
step: 350, loss: 0.023215211927890778
step: 360, loss: 0.00048583096941001713
step: 370, loss: 0.02619241736829281
step: 380, loss: 0.06402800232172012
step: 390, loss: 0.020139239728450775
step: 400, loss: 0.054498959332704544
step: 410, loss: 1.3481670976034366e-05
step: 420, loss: 0.04568479582667351
step: 430, loss: 0.042628489434719086
step: 440, loss: 0.07326213270425797
step: 450, loss: 0.03443560749292374
step: 460, loss: 0.08565735071897507
step: 470, loss: 0.02446906827390194
step: 480, loss: 0.056903161108493805
step: 490, loss: 0.051861658692359924
step: 500, loss: 0.00014967411698307842
step: 510, loss: 0.0500904880464077
step: 520, loss: 0.043389443308115005
step: 530, loss: 0.08920221030712128
step: 540, loss: 0.030274562537670135
step: 550, loss: 1.2203928235976491e-05
step: 560, loss: 0.034111130982637405
step: 570, loss: 0.048757921904325485
step: 580, loss: 0.0841447114944458
step: 590, loss: 0.03580029308795929
step: 600, loss: 0.06385356187820435
step: 610, loss: 0.06375713646411896
step: 620, loss: 0.008048146031796932
step: 630, loss: 0.056875865906476974
step: 640, loss: 0.024652451276779175
step: 650, loss: 0.04491846263408661
step: 660, loss: 0.03961614519357681
step: 670, loss: 0.0198094230145216
step: 680, loss: 0.05019726604223251
step: 690, loss: 0.12280776351690292
step: 700, loss: 0.03695017099380493
step: 710, loss: 0.08730427920818329
step: 720, loss: 0.019358985126018524
step: 730, loss: 0.08728425204753876
step: 740, loss: 2.358736310270615e-05
step: 750, loss: 0.043394505977630615
step: 760, loss: 1.289680767513346e-05
step: 770, loss: 0.0515088252723217
step: 780, loss: 0.03664093092083931
step: 790, loss: 1.6461057384731248e-05
step: 800, loss: 0.02305346541106701
step: 810, loss: 0.1076805517077446
step: 820, loss: 0.04985399171710014
step: 830, loss: 0.010020380839705467
step: 840, loss: 0.03283600136637688
step: 850, loss: 0.06955379247665405
step: 860, loss: 0.0231300201267004
step: 870, loss: 0.03071041963994503
step: 880, loss: 0.03975241631269455
step: 890, loss: 0.05120614171028137
step: 900, loss: 0.02246171608567238
step: 910, loss: 0.0719517320394516
step: 920, loss: 0.03482288122177124
step: 930, loss: 0.03427664563059807
step: 940, loss: 0.07044191658496857
step: 950, loss: 0.01441599614918232
step: 960, loss: 0.045077282935380936
step: 970, loss: 0.011637253686785698
step: 980, loss: 0.03835710510611534
step: 990, loss: 0.030530454590916634
step: 1000, loss: 0.06758221983909607
step: 1010, loss: 0.025420818477869034
step: 1020, loss: 0.019893480464816093
step: 1030, loss: 0.08351945132017136
step: 1040, loss: 0.045881275087594986
step: 1050, loss: 0.08776123821735382
step: 1060, loss: 0.00022798788268119097
step: 1070, loss: 6.429149652831256e-05
epoch 19: dev_f1=0.9219047619047618, f1=0.9196597353497165, best_f1=0.9283402681460935
step: 0, loss: 0.07364216446876526
step: 10, loss: 0.09871316701173782
step: 20, loss: 0.007786482572555542
step: 30, loss: 0.014103014953434467
step: 40, loss: 0.02335454896092415
step: 50, loss: 0.008595211431384087
step: 60, loss: 0.021246662363409996
step: 70, loss: 0.05632331594824791
step: 80, loss: 0.041746802628040314
step: 90, loss: 0.019427666440606117
step: 100, loss: 1.5783600247232243e-05
step: 110, loss: 0.04667224735021591
step: 120, loss: 0.07993820309638977
step: 130, loss: 0.0359676256775856
step: 140, loss: 0.01783280074596405
step: 150, loss: 0.05444791540503502
step: 160, loss: 1.338467700406909e-05
step: 170, loss: 0.030477076768875122
step: 180, loss: 0.02289857156574726
step: 190, loss: 0.07458332180976868
step: 200, loss: 0.03442518413066864
step: 210, loss: 0.051968298852443695
step: 220, loss: 0.054156649857759476
step: 230, loss: 0.039883557707071304
step: 240, loss: 0.014840861782431602
step: 250, loss: 0.04062560200691223
step: 260, loss: 0.0480639711022377
step: 270, loss: 0.04716365411877632
step: 280, loss: 0.026651861146092415
step: 290, loss: 0.018148235976696014
step: 300, loss: 0.022116264328360558
step: 310, loss: 0.027353346347808838
step: 320, loss: 0.030335683375597
step: 330, loss: 0.038307562470436096
step: 340, loss: 0.06900781393051147
step: 350, loss: 0.02696472965180874
step: 360, loss: 0.05687203258275986
step: 370, loss: 0.014540574513375759
step: 380, loss: 0.047633130103349686
step: 390, loss: 0.025655580684542656
step: 400, loss: 0.0004400022735353559
step: 410, loss: 0.05024288222193718
step: 420, loss: 0.05935759097337723
step: 430, loss: 0.03359653428196907
step: 440, loss: 5.9675272495951504e-05
step: 450, loss: 0.02331257425248623
step: 460, loss: 0.025430526584386826
step: 470, loss: 0.0843580961227417
step: 480, loss: 0.055875346064567566
step: 490, loss: 0.02491014264523983
step: 500, loss: 2.246565964014735e-05
step: 510, loss: 0.06605058908462524
step: 520, loss: 0.022298241034150124
step: 530, loss: 0.03679472953081131
step: 540, loss: 2.2990578145254403e-05
step: 550, loss: 0.0219525545835495
step: 560, loss: 0.045095380395650864
step: 570, loss: 0.06663849949836731
step: 580, loss: 0.02211323007941246
step: 590, loss: 2.637898433022201e-05
step: 600, loss: 0.0740111917257309
step: 610, loss: 0.048914145678281784
step: 620, loss: 1.992157194763422e-05
step: 630, loss: 0.0838104858994484
step: 640, loss: 0.022150658071041107
step: 650, loss: 0.02388937771320343
step: 660, loss: 0.02130291797220707
step: 670, loss: 0.021560130640864372
step: 680, loss: 0.006180580705404282
step: 690, loss: 1.9373586837900802e-05
step: 700, loss: 0.04643941670656204
step: 710, loss: 4.2181607568636537e-05
step: 720, loss: 0.10538006573915482
step: 730, loss: 0.06178836524486542
step: 740, loss: 8.283166971523315e-05
step: 750, loss: 0.024931568652391434
step: 760, loss: 0.0261475071310997
step: 770, loss: 0.029384322464466095
step: 780, loss: 0.07102195918560028
step: 790, loss: 0.11232999712228775
step: 800, loss: 0.12711061537265778
step: 810, loss: 0.04316449165344238
step: 820, loss: 0.036763790994882584
step: 830, loss: 0.030634740367531776
step: 840, loss: 0.010374014265835285
step: 850, loss: 0.015205631963908672
step: 860, loss: 0.015148810110986233
step: 870, loss: 0.05568275973200798
step: 880, loss: 0.02942333184182644
step: 890, loss: 0.011223524808883667
step: 900, loss: 0.00013264510198496282
step: 910, loss: 0.052256740629673004
step: 920, loss: 0.01462674792855978
step: 930, loss: 0.020765800029039383
step: 940, loss: 0.09984218329191208
step: 950, loss: 0.04096800088882446
step: 960, loss: 0.030336910858750343
step: 970, loss: 0.022564560174942017
step: 980, loss: 0.059730298817157745
step: 990, loss: 0.04614183306694031
step: 1000, loss: 0.022284574806690216
step: 1010, loss: 0.015799926593899727
step: 1020, loss: 0.023050526157021523
step: 1030, loss: 0.06747616082429886
step: 1040, loss: 0.07422924041748047
step: 1050, loss: 0.0424446240067482
step: 1060, loss: 0.024910015985369682
step: 1070, loss: 0.024678008630871773
epoch 20: dev_f1=0.9219790675547097, f1=0.91828058573453, best_f1=0.9283402681460935
