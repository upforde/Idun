cuda
Device: cuda
step: 0, loss: 0.7588503360748291
step: 10, loss: 0.5348955988883972
step: 20, loss: 0.32600605487823486
step: 30, loss: 0.5433222651481628
step: 40, loss: 0.46153023838996887
step: 50, loss: 0.4480111598968506
step: 60, loss: 0.32765814661979675
step: 70, loss: 0.36578160524368286
step: 80, loss: 0.25828826427459717
step: 90, loss: 0.2797958254814148
step: 100, loss: 0.16713827848434448
step: 110, loss: 0.1878722757101059
step: 120, loss: 0.2516743242740631
step: 130, loss: 0.11898044496774673
step: 140, loss: 0.23397725820541382
step: 150, loss: 0.18759483098983765
step: 160, loss: 0.24891433119773865
step: 170, loss: 0.20533140003681183
step: 180, loss: 0.08506886661052704
step: 190, loss: 0.0469970777630806
step: 200, loss: 0.0784335806965828
step: 210, loss: 0.333571195602417
step: 220, loss: 0.08096339553594589
step: 230, loss: 0.2323305904865265
step: 240, loss: 0.19873608648777008
step: 250, loss: 0.11888755857944489
step: 260, loss: 0.13000503182411194
step: 270, loss: 0.11493285000324249
step: 280, loss: 0.0695851519703865
step: 290, loss: 0.11455854773521423
step: 300, loss: 0.432647705078125
step: 310, loss: 0.09235081821680069
step: 320, loss: 0.1839035004377365
step: 330, loss: 0.03829892724752426
step: 340, loss: 0.09848511219024658
step: 350, loss: 0.4157734215259552
step: 360, loss: 0.1273871809244156
step: 370, loss: 0.0985349640250206
step: 380, loss: 0.15132632851600647
step: 390, loss: 0.05557454749941826
step: 400, loss: 0.07131409645080566
step: 410, loss: 0.13043206930160522
step: 420, loss: 0.3233603239059448
step: 430, loss: 0.11183179914951324
step: 440, loss: 0.18622486293315887
step: 450, loss: 0.21935464441776276
step: 460, loss: 0.05866819620132446
step: 470, loss: 0.025627441704273224
step: 480, loss: 0.16984185576438904
step: 490, loss: 0.10852871090173721
step: 500, loss: 0.1042679026722908
step: 510, loss: 0.11786031723022461
step: 520, loss: 0.10485584288835526
step: 530, loss: 0.2010081708431244
step: 540, loss: 0.09384331107139587
step: 550, loss: 0.22624103724956512
step: 560, loss: 0.1813167929649353
step: 570, loss: 0.27010631561279297
step: 580, loss: 0.07833635061979294
step: 590, loss: 0.09679211676120758
step: 600, loss: 0.09876903146505356
step: 610, loss: 0.07277625799179077
step: 620, loss: 0.30738475918769836
step: 630, loss: 0.17205080389976501
step: 640, loss: 0.24721255898475647
step: 650, loss: 0.11303504556417465
step: 660, loss: 0.1033485010266304
step: 670, loss: 0.18219974637031555
step: 680, loss: 0.13529987633228302
step: 690, loss: 0.21389737725257874
step: 700, loss: 0.12128426879644394
step: 710, loss: 0.07245555520057678
step: 720, loss: 0.07139472663402557
step: 730, loss: 0.07618643343448639
step: 740, loss: 0.11046448349952698
step: 750, loss: 0.05466405674815178
step: 760, loss: 0.13267679512500763
step: 770, loss: 0.09062700718641281
step: 780, loss: 0.10282404720783234
step: 790, loss: 0.09500974416732788
step: 800, loss: 0.04994993284344673
step: 810, loss: 0.07443851977586746
step: 820, loss: 0.18341317772865295
step: 830, loss: 0.173330619931221
step: 840, loss: 0.17891721427440643
step: 850, loss: 0.10920466482639313
step: 860, loss: 0.10417909920215607
step: 870, loss: 0.13268451392650604
step: 880, loss: 0.1565021425485611
step: 890, loss: 0.1386200338602066
step: 900, loss: 0.14119811356067657
step: 910, loss: 0.16442106664180756
step: 920, loss: 0.11012402921915054
step: 930, loss: 0.06085331365466118
step: 940, loss: 0.05680027976632118
step: 950, loss: 0.25333502888679504
step: 960, loss: 0.2667781412601471
step: 970, loss: 0.10425800085067749
step: 980, loss: 0.34578147530555725
step: 990, loss: 0.13561910390853882
step: 1000, loss: 0.216001495718956
step: 1010, loss: 0.08604692667722702
step: 1020, loss: 0.1992809772491455
step: 1030, loss: 0.15270310640335083
step: 1040, loss: 0.2397109419107437
step: 1050, loss: 0.19063805043697357
step: 1060, loss: 0.12592750787734985
step: 1070, loss: 0.13284561038017273
epoch 1: dev_f1=0.9046345811051693, f1=0.8989266547406083, best_f1=0.8989266547406083
step: 0, loss: 0.13543011248111725
step: 10, loss: 0.05168994143605232
step: 20, loss: 0.20583891868591309
step: 30, loss: 0.05206365883350372
step: 40, loss: 0.16630780696868896
step: 50, loss: 0.05551380291581154
step: 60, loss: 0.09747891873121262
step: 70, loss: 0.03780227527022362
step: 80, loss: 0.04160211235284805
step: 90, loss: 0.1654680371284485
step: 100, loss: 0.28314173221588135
step: 110, loss: 0.09108676016330719
step: 120, loss: 0.14694038033485413
step: 130, loss: 0.11633184552192688
step: 140, loss: 0.08886601775884628
step: 150, loss: 0.03662371635437012
step: 160, loss: 0.16899889707565308
step: 170, loss: 0.16779078543186188
step: 180, loss: 0.19818104803562164
step: 190, loss: 0.0856708511710167
step: 200, loss: 0.25789523124694824
step: 210, loss: 0.2444058507680893
step: 220, loss: 0.07170834392309189
step: 230, loss: 0.14677515625953674
step: 240, loss: 0.07190916687250137
step: 250, loss: 0.05840052664279938
step: 260, loss: 0.052218008786439896
step: 270, loss: 0.1520581990480423
step: 280, loss: 0.1013043075799942
step: 290, loss: 0.1306392252445221
step: 300, loss: 0.09747631847858429
step: 310, loss: 0.10543584078550339
step: 320, loss: 0.11447495222091675
step: 330, loss: 0.17843645811080933
step: 340, loss: 0.12395656108856201
step: 350, loss: 0.1230766698718071
step: 360, loss: 0.040179017931222916
step: 370, loss: 0.08940594643354416
step: 380, loss: 0.17150261998176575
step: 390, loss: 0.16376632452011108
step: 400, loss: 0.03758065029978752
step: 410, loss: 0.05355563387274742
step: 420, loss: 0.10809019207954407
step: 430, loss: 0.07203904539346695
step: 440, loss: 0.12211654335260391
step: 450, loss: 0.16609923541545868
step: 460, loss: 0.13546621799468994
step: 470, loss: 0.09118948131799698
step: 480, loss: 0.07361195981502533
step: 490, loss: 0.07388550788164139
step: 500, loss: 0.08303944766521454
step: 510, loss: 0.033857252448797226
step: 520, loss: 0.12108808755874634
step: 530, loss: 0.031220022588968277
step: 540, loss: 0.2332371026277542
step: 550, loss: 0.12747588753700256
step: 560, loss: 0.20432715117931366
step: 570, loss: 0.08499450981616974
step: 580, loss: 0.10556545108556747
step: 590, loss: 0.07931996881961823
step: 600, loss: 0.20613950490951538
step: 610, loss: 0.20280314981937408
step: 620, loss: 0.09982936829328537
step: 630, loss: 0.20265960693359375
step: 640, loss: 0.20069539546966553
step: 650, loss: 0.24032030999660492
step: 660, loss: 0.08299528062343597
step: 670, loss: 0.17184165120124817
step: 680, loss: 0.09905004501342773
step: 690, loss: 0.0441710539162159
step: 700, loss: 0.09154569357633591
step: 710, loss: 0.16544926166534424
step: 720, loss: 0.082963727414608
step: 730, loss: 0.12002557516098022
step: 740, loss: 0.21529321372509003
step: 750, loss: 0.19963327050209045
step: 760, loss: 0.0994371846318245
step: 770, loss: 0.15603090822696686
step: 780, loss: 0.1594066172838211
step: 790, loss: 0.07970572263002396
step: 800, loss: 0.07750372588634491
step: 810, loss: 0.07461124658584595
step: 820, loss: 0.22547239065170288
step: 830, loss: 0.09764551371335983
step: 840, loss: 0.017908096313476562
step: 850, loss: 0.0389220230281353
step: 860, loss: 0.11133746802806854
step: 870, loss: 0.21877986192703247
step: 880, loss: 0.08392272144556046
step: 890, loss: 0.2267334759235382
step: 900, loss: 0.08458462357521057
step: 910, loss: 0.15090519189834595
step: 920, loss: 0.09649419784545898
step: 930, loss: 0.1406901627779007
step: 940, loss: 0.21304236352443695
step: 950, loss: 0.1314803957939148
step: 960, loss: 0.11230906844139099
step: 970, loss: 0.11704087257385254
step: 980, loss: 0.1998019516468048
step: 990, loss: 0.20395411550998688
step: 1000, loss: 0.06186607480049133
step: 1010, loss: 0.17066322267055511
step: 1020, loss: 0.14553199708461761
step: 1030, loss: 0.17694051563739777
step: 1040, loss: 0.16498002409934998
step: 1050, loss: 0.1364547610282898
step: 1060, loss: 0.08020012080669403
step: 1070, loss: 0.1083507388830185
epoch 2: dev_f1=0.9215955983493811, f1=0.920418371987267, best_f1=0.920418371987267
step: 0, loss: 0.11187968403100967
step: 10, loss: 0.13873672485351562
step: 20, loss: 0.04007206857204437
step: 30, loss: 0.1392386108636856
step: 40, loss: 0.20030462741851807
step: 50, loss: 0.10521592944860458
step: 60, loss: 0.0417252741754055
step: 70, loss: 0.08840415626764297
step: 80, loss: 0.025147035717964172
step: 90, loss: 0.19334916770458221
step: 100, loss: 0.13774584233760834
step: 110, loss: 0.12232132256031036
step: 120, loss: 0.11516253650188446
step: 130, loss: 0.32790407538414
step: 140, loss: 0.093007892370224
step: 150, loss: 0.10776808857917786
step: 160, loss: 0.15047967433929443
step: 170, loss: 0.05318448320031166
step: 180, loss: 0.05298282951116562
step: 190, loss: 0.12637805938720703
step: 200, loss: 0.14290478825569153
step: 210, loss: 0.1898168921470642
step: 220, loss: 0.023524312302470207
step: 230, loss: 0.05441994220018387
step: 240, loss: 0.11171209067106247
step: 250, loss: 0.10860437154769897
step: 260, loss: 0.09826833754777908
step: 270, loss: 0.1666758954524994
step: 280, loss: 0.17064057290554047
step: 290, loss: 0.030233172699809074
step: 300, loss: 0.07453442364931107
step: 310, loss: 0.17896346747875214
step: 320, loss: 0.034806761890649796
step: 330, loss: 0.08681803941726685
step: 340, loss: 0.20163103938102722
step: 350, loss: 0.12429900467395782
step: 360, loss: 0.16527888178825378
step: 370, loss: 0.08873933553695679
step: 380, loss: 0.11875145137310028
step: 390, loss: 0.08381608873605728
step: 400, loss: 0.10369164496660233
step: 410, loss: 0.1034485474228859
step: 420, loss: 0.18079110980033875
step: 430, loss: 0.05957247316837311
step: 440, loss: 0.10080542415380478
step: 450, loss: 0.16284114122390747
step: 460, loss: 0.017886096611618996
step: 470, loss: 0.1457003653049469
step: 480, loss: 0.13996222615242004
step: 490, loss: 0.15006399154663086
step: 500, loss: 0.0972483903169632
step: 510, loss: 0.16727088391780853
step: 520, loss: 0.27420762181282043
step: 530, loss: 0.1643356829881668
step: 540, loss: 0.03620871156454086
step: 550, loss: 0.1256059855222702
step: 560, loss: 0.09387529641389847
step: 570, loss: 0.12891921401023865
step: 580, loss: 0.16477492451667786
step: 590, loss: 0.040512312203645706
step: 600, loss: 0.1043127104640007
step: 610, loss: 0.18355399370193481
step: 620, loss: 0.09039207547903061
step: 630, loss: 0.10703113675117493
step: 640, loss: 0.06083541736006737
step: 650, loss: 0.13350462913513184
step: 660, loss: 0.11254218965768814
step: 670, loss: 0.08343478292226791
step: 680, loss: 0.13318206369876862
step: 690, loss: 0.09288761764764786
step: 700, loss: 0.09932051599025726
step: 710, loss: 0.10575253516435623
step: 720, loss: 0.04800167307257652
step: 730, loss: 0.023970771580934525
step: 740, loss: 0.0831267237663269
step: 750, loss: 0.045283664017915726
step: 760, loss: 0.15987826883792877
step: 770, loss: 0.1318090856075287
step: 780, loss: 0.1124800592660904
step: 790, loss: 0.11334718763828278
step: 800, loss: 0.17050549387931824
step: 810, loss: 0.04587310925126076
step: 820, loss: 0.10125990211963654
step: 830, loss: 0.07344719767570496
step: 840, loss: 0.057700265198946
step: 850, loss: 0.25372353196144104
step: 860, loss: 0.04961661994457245
step: 870, loss: 0.19991037249565125
step: 880, loss: 0.09812837094068527
step: 890, loss: 0.15180344879627228
step: 900, loss: 0.027719857171177864
step: 910, loss: 0.047123029828071594
step: 920, loss: 0.11084818840026855
step: 930, loss: 0.03451894596219063
step: 940, loss: 0.10410451889038086
step: 950, loss: 0.09608078002929688
step: 960, loss: 0.21721051633358002
step: 970, loss: 0.2061520516872406
step: 980, loss: 0.034105636179447174
step: 990, loss: 0.08965995162725449
step: 1000, loss: 0.09446999430656433
step: 1010, loss: 0.13780128955841064
step: 1020, loss: 0.18822617828845978
step: 1030, loss: 0.1452215611934662
step: 1040, loss: 0.08289020508527756
step: 1050, loss: 0.04421868547797203
step: 1060, loss: 0.07647234201431274
step: 1070, loss: 0.0790880098938942
epoch 3: dev_f1=0.9308291342189647, f1=0.9318701417466849, best_f1=0.9318701417466849
step: 0, loss: 0.05697662755846977
step: 10, loss: 0.07434767484664917
step: 20, loss: 0.07161752879619598
step: 30, loss: 0.13574440777301788
step: 40, loss: 0.04936032369732857
step: 50, loss: 0.1149812713265419
step: 60, loss: 0.16294574737548828
step: 70, loss: 0.06578107178211212
step: 80, loss: 0.19974622130393982
step: 90, loss: 0.046456243842840195
step: 100, loss: 0.13190755248069763
step: 110, loss: 0.12671491503715515
step: 120, loss: 0.04559207335114479
step: 130, loss: 0.11181356012821198
step: 140, loss: 0.07653763145208359
step: 150, loss: 0.19473779201507568
step: 160, loss: 0.140206441283226
step: 170, loss: 0.05218692123889923
step: 180, loss: 0.02559073455631733
step: 190, loss: 0.09161804616451263
step: 200, loss: 0.12702617049217224
step: 210, loss: 0.07446998357772827
step: 220, loss: 0.1739087551832199
step: 230, loss: 0.13624246418476105
step: 240, loss: 0.07009724527597427
step: 250, loss: 0.12584587931632996
step: 260, loss: 0.2056410312652588
step: 270, loss: 0.02894437313079834
step: 280, loss: 0.18510475754737854
step: 290, loss: 0.04642609506845474
step: 300, loss: 0.029615433886647224
step: 310, loss: 0.05590318143367767
step: 320, loss: 0.16158677637577057
step: 330, loss: 0.07238200306892395
step: 340, loss: 0.09190481156110764
step: 350, loss: 0.028274985030293465
step: 360, loss: 0.281372994184494
step: 370, loss: 0.04978407919406891
step: 380, loss: 0.10992829501628876
step: 390, loss: 0.15404637157917023
step: 400, loss: 0.03988717123866081
step: 410, loss: 0.09512275457382202
step: 420, loss: 0.07180819660425186
step: 430, loss: 0.17060764133930206
step: 440, loss: 0.10539710521697998
step: 450, loss: 0.09001704305410385
step: 460, loss: 0.0542370043694973
step: 470, loss: 0.0528164803981781
step: 480, loss: 0.08658444881439209
step: 490, loss: 0.2084006667137146
step: 500, loss: 0.09351813048124313
step: 510, loss: 0.0002615954144857824
step: 520, loss: 0.1258821040391922
step: 530, loss: 0.09425479173660278
step: 540, loss: 0.16038088500499725
step: 550, loss: 0.038408130407333374
step: 560, loss: 0.008808756247162819
step: 570, loss: 0.0815761536359787
step: 580, loss: 0.04910526052117348
step: 590, loss: 0.04722825810313225
step: 600, loss: 0.23846320807933807
step: 610, loss: 0.2156558483839035
step: 620, loss: 0.06880304217338562
step: 630, loss: 0.16235090792179108
step: 640, loss: 0.07130581885576248
step: 650, loss: 0.21125143766403198
step: 660, loss: 0.2626636326313019
step: 670, loss: 0.10203871130943298
step: 680, loss: 0.12696348130702972
step: 690, loss: 0.19776102900505066
step: 700, loss: 0.10232481360435486
step: 710, loss: 0.18209731578826904
step: 720, loss: 0.08091574162244797
step: 730, loss: 0.031461987644433975
step: 740, loss: 0.10440821200609207
step: 750, loss: 0.1355724036693573
step: 760, loss: 0.102993443608284
step: 770, loss: 0.1354651153087616
step: 780, loss: 0.12240514904260635
step: 790, loss: 0.06347554922103882
step: 800, loss: 0.09318706393241882
step: 810, loss: 0.14024955034255981
step: 820, loss: 0.11517185717821121
step: 830, loss: 0.03654898703098297
step: 840, loss: 0.14995624125003815
step: 850, loss: 0.07315832376480103
step: 860, loss: 0.08105061948299408
step: 870, loss: 0.09442102909088135
step: 880, loss: 0.138046532869339
step: 890, loss: 0.08237799257040024
step: 900, loss: 0.10586433112621307
step: 910, loss: 0.09154779464006424
step: 920, loss: 0.12142994999885559
step: 930, loss: 0.12213660776615143
step: 940, loss: 0.09865792095661163
step: 950, loss: 0.057787321507930756
step: 960, loss: 0.0723191425204277
step: 970, loss: 0.12535308301448822
step: 980, loss: 0.16141203045845032
step: 990, loss: 0.07024607062339783
step: 1000, loss: 0.10496008396148682
step: 1010, loss: 0.17364297807216644
step: 1020, loss: 0.17652639746665955
step: 1030, loss: 0.0896180123090744
step: 1040, loss: 0.018946541473269463
step: 1050, loss: 0.07179535925388336
step: 1060, loss: 0.17286863923072815
step: 1070, loss: 0.0717964768409729
epoch 4: dev_f1=0.9326568265682658, f1=0.9254143646408841, best_f1=0.9254143646408841
step: 0, loss: 0.0817812904715538
step: 10, loss: 0.09078550338745117
step: 20, loss: 0.05371934920549393
step: 30, loss: 0.005315691232681274
step: 40, loss: 0.13156846165657043
step: 50, loss: 0.21051481366157532
step: 60, loss: 0.06522830575704575
step: 70, loss: 0.13078252971172333
step: 80, loss: 0.039226990193128586
step: 90, loss: 0.09739501774311066
step: 100, loss: 0.12408511340618134
step: 110, loss: 0.016759630292654037
step: 120, loss: 0.0978863313794136
step: 130, loss: 0.21307110786437988
step: 140, loss: 0.03768746927380562
step: 150, loss: 0.10060111433267593
step: 160, loss: 0.09733787178993225
step: 170, loss: 0.02322029322385788
step: 180, loss: 0.1451842486858368
step: 190, loss: 0.04653378948569298
step: 200, loss: 0.12293212115764618
step: 210, loss: 0.07613799721002579
step: 220, loss: 0.10342708975076675
step: 230, loss: 0.142576664686203
step: 240, loss: 0.1226007491350174
step: 250, loss: 0.14354582130908966
step: 260, loss: 0.09773319959640503
step: 270, loss: 0.002719712443649769
step: 280, loss: 0.12058550864458084
step: 290, loss: 0.08660899847745895
step: 300, loss: 0.026305587962269783
step: 310, loss: 0.11018133163452148
step: 320, loss: 0.135822132229805
step: 330, loss: 0.23586353659629822
step: 340, loss: 0.11925391107797623
step: 350, loss: 0.07200652360916138
step: 360, loss: 0.04017742723226547
step: 370, loss: 0.048330869525671005
step: 380, loss: 0.018814854323863983
step: 390, loss: 0.19820627570152283
step: 400, loss: 0.02729271724820137
step: 410, loss: 0.08360578864812851
step: 420, loss: 0.07572168111801147
step: 430, loss: 0.1459755003452301
step: 440, loss: 0.030577782541513443
step: 450, loss: 0.04317659139633179
step: 460, loss: 0.16002002358436584
step: 470, loss: 0.06369071453809738
step: 480, loss: 0.09405338019132614
step: 490, loss: 0.1388322114944458
step: 500, loss: 0.08753146231174469
step: 510, loss: 0.03885350376367569
step: 520, loss: 0.05332145467400551
step: 530, loss: 0.12051820009946823
step: 540, loss: 0.07894831150770187
step: 550, loss: 0.08303137868642807
step: 560, loss: 0.08016546070575714
step: 570, loss: 0.020752185955643654
step: 580, loss: 0.09718240797519684
step: 590, loss: 0.06120677292346954
step: 600, loss: 0.12268083542585373
step: 610, loss: 0.01277828123420477
step: 620, loss: 0.17365141212940216
step: 630, loss: 0.08065444976091385
step: 640, loss: 0.05217041075229645
step: 650, loss: 0.10154865682125092
step: 660, loss: 0.15857703983783722
step: 670, loss: 0.14599446952342987
step: 680, loss: 0.05284115672111511
step: 690, loss: 0.03808915987610817
step: 700, loss: 0.10303390771150589
step: 710, loss: 0.10657718032598495
step: 720, loss: 0.047160860151052475
step: 730, loss: 0.05240090936422348
step: 740, loss: 0.05392824485898018
step: 750, loss: 0.16670015454292297
step: 760, loss: 0.01745399832725525
step: 770, loss: 0.12245290726423264
step: 780, loss: 0.11110684275627136
step: 790, loss: 0.013794909231364727
step: 800, loss: 0.17278379201889038
step: 810, loss: 0.005731058306992054
step: 820, loss: 0.0665782243013382
step: 830, loss: 0.08907780051231384
step: 840, loss: 0.042268041521310806
step: 850, loss: 0.09591112285852432
step: 860, loss: 0.10863839089870453
step: 870, loss: 0.013704894110560417
step: 880, loss: 0.024243734776973724
step: 890, loss: 0.12036396563053131
step: 900, loss: 0.12006982415914536
step: 910, loss: 0.20830778777599335
step: 920, loss: 0.06877880543470383
step: 930, loss: 0.05999825894832611
step: 940, loss: 0.11976771056652069
step: 950, loss: 0.06320393085479736
step: 960, loss: 0.09209038317203522
step: 970, loss: 0.01702382043004036
step: 980, loss: 0.03819321095943451
step: 990, loss: 0.11017195880413055
step: 1000, loss: 0.07753605395555496
step: 1010, loss: 0.0883624404668808
step: 1020, loss: 0.089650958776474
step: 1030, loss: 0.013251053169369698
step: 1040, loss: 0.061994992196559906
step: 1050, loss: 0.030681541189551353
step: 1060, loss: 0.16187429428100586
step: 1070, loss: 0.17170701920986176
epoch 5: dev_f1=0.9305361305361305, f1=0.9232201023731967, best_f1=0.9254143646408841
step: 0, loss: 0.16683675348758698
step: 10, loss: 0.04653075337409973
step: 20, loss: 0.22393083572387695
step: 30, loss: 0.09514963626861572
step: 40, loss: 0.04360920190811157
step: 50, loss: 0.10768626630306244
step: 60, loss: 0.0742916390299797
step: 70, loss: 0.021116511896252632
step: 80, loss: 0.16181139647960663
step: 90, loss: 0.05778835713863373
step: 100, loss: 0.12521636486053467
step: 110, loss: 0.08217264711856842
step: 120, loss: 0.04440321400761604
step: 130, loss: 0.1265418529510498
step: 140, loss: 0.06891869008541107
step: 150, loss: 0.08567420393228531
step: 160, loss: 0.12550850212574005
step: 170, loss: 0.017083873972296715
step: 180, loss: 0.01229153387248516
step: 190, loss: 0.1508127748966217
step: 200, loss: 0.10203773528337479
step: 210, loss: 0.027910403907299042
step: 220, loss: 0.0954093188047409
step: 230, loss: 0.09252853691577911
step: 240, loss: 0.09263025224208832
step: 250, loss: 0.09584671258926392
step: 260, loss: 0.0005194391123950481
step: 270, loss: 0.05467798560857773
step: 280, loss: 0.06500415503978729
step: 290, loss: 0.0983356237411499
step: 300, loss: 0.13726705312728882
step: 310, loss: 0.039270125329494476
step: 320, loss: 0.13591213524341583
step: 330, loss: 0.07035090029239655
step: 340, loss: 0.04769410565495491
step: 350, loss: 0.1787726879119873
step: 360, loss: 0.15975674986839294
step: 370, loss: 0.037842851132154465
step: 380, loss: 0.09314048290252686
step: 390, loss: 0.12577912211418152
step: 400, loss: 0.0864146426320076
step: 410, loss: 0.009026647545397282
step: 420, loss: 0.08939982950687408
step: 430, loss: 0.037752415984869
step: 440, loss: 0.10382404178380966
step: 450, loss: 0.040872685611248016
step: 460, loss: 0.10000357031822205
step: 470, loss: 0.03424858674407005
step: 480, loss: 0.08171096444129944
step: 490, loss: 0.10085946321487427
step: 500, loss: 0.0506388396024704
step: 510, loss: 0.22593334317207336
step: 520, loss: 0.0721677765250206
step: 530, loss: 0.06542040407657623
step: 540, loss: 0.03358759358525276
step: 550, loss: 0.059912025928497314
step: 560, loss: 0.1675112098455429
step: 570, loss: 0.048160307109355927
step: 580, loss: 0.09055473655462265
step: 590, loss: 0.028059082105755806
step: 600, loss: 0.01775510609149933
step: 610, loss: 0.24176014959812164
step: 620, loss: 0.08109065145254135
step: 630, loss: 0.06503738462924957
step: 640, loss: 0.07564018666744232
step: 650, loss: 0.12773020565509796
step: 660, loss: 0.07974071800708771
step: 670, loss: 0.05442066490650177
step: 680, loss: 0.03258553519845009
step: 690, loss: 0.07084831595420837
step: 700, loss: 0.037295203655958176
step: 710, loss: 0.09428557753562927
step: 720, loss: 0.14986471831798553
step: 730, loss: 0.08486220985651016
step: 740, loss: 0.08412694185972214
step: 750, loss: 0.09379830956459045
step: 760, loss: 0.00597421545535326
step: 770, loss: 0.22453893721103668
step: 780, loss: 0.099401094019413
step: 790, loss: 0.11739086359739304
step: 800, loss: 0.10593682527542114
step: 810, loss: 0.09680664539337158
step: 820, loss: 0.028170106932520866
step: 830, loss: 0.017325015738606453
step: 840, loss: 0.00614601606503129
step: 850, loss: 0.05220683291554451
step: 860, loss: 0.07085824757814407
step: 870, loss: 0.10798881947994232
step: 880, loss: 0.10834816098213196
step: 890, loss: 0.09082851558923721
step: 900, loss: 0.04360118880867958
step: 910, loss: 0.06536927074193954
step: 920, loss: 0.09727931022644043
step: 930, loss: 0.23290833830833435
step: 940, loss: 0.0747457817196846
step: 950, loss: 0.09276433289051056
step: 960, loss: 0.11984407901763916
step: 970, loss: 0.06041999161243439
step: 980, loss: 0.051009077578783035
step: 990, loss: 0.08013706654310226
step: 1000, loss: 0.0798376202583313
step: 1010, loss: 0.09383966028690338
step: 1020, loss: 0.11061808466911316
step: 1030, loss: 0.10254186391830444
step: 1040, loss: 0.08012468367815018
step: 1050, loss: 0.0675189420580864
step: 1060, loss: 0.07364968955516815
step: 1070, loss: 0.06713530421257019
epoch 6: dev_f1=0.9295255642561031, f1=0.9255663430420712, best_f1=0.9254143646408841
step: 0, loss: 0.14209532737731934
step: 10, loss: 0.018448082730174065
step: 20, loss: 0.08286749571561813
step: 30, loss: 0.0919610857963562
step: 40, loss: 0.09846767038106918
step: 50, loss: 0.051072511821985245
step: 60, loss: 0.027529973536729813
step: 70, loss: 0.004439090378582478
step: 80, loss: 0.10534399747848511
step: 90, loss: 0.06852899491786957
step: 100, loss: 0.06268879026174545
step: 110, loss: 0.00400754576548934
step: 120, loss: 0.130081444978714
step: 130, loss: 0.03203953057527542
step: 140, loss: 0.0321170873939991
step: 150, loss: 0.10473387688398361
step: 160, loss: 0.04585813730955124
step: 170, loss: 0.15700781345367432
step: 180, loss: 0.13273078203201294
step: 190, loss: 0.16433294117450714
step: 200, loss: 0.12943704426288605
step: 210, loss: 0.08429274708032608
step: 220, loss: 0.016107991337776184
step: 230, loss: 0.09117862582206726
step: 240, loss: 0.23994378745555878
step: 250, loss: 0.07469698786735535
step: 260, loss: 0.02108018845319748
step: 270, loss: 0.12017208337783813
step: 280, loss: 0.06717510521411896
step: 290, loss: 0.11513930559158325
step: 300, loss: 0.10126351565122604
step: 310, loss: 0.09335759282112122
step: 320, loss: 0.18098117411136627
step: 330, loss: 0.050842780619859695
step: 340, loss: 0.01190111879259348
step: 350, loss: 0.01967552863061428
step: 360, loss: 0.03779930621385574
step: 370, loss: 0.032730888575315475
step: 380, loss: 0.02910035103559494
step: 390, loss: 0.12696297466754913
step: 400, loss: 0.05558467283844948
step: 410, loss: 0.012581218034029007
step: 420, loss: 0.124025858938694
step: 430, loss: 0.05232906714081764
step: 440, loss: 0.06333830207586288
step: 450, loss: 0.05662538856267929
step: 460, loss: 0.04035564884543419
step: 470, loss: 0.05144617706537247
step: 480, loss: 0.2846733331680298
step: 490, loss: 0.09146048128604889
step: 500, loss: 0.003729583229869604
step: 510, loss: 0.09503385424613953
step: 520, loss: 0.014887155033648014
step: 530, loss: 0.021336426958441734
step: 540, loss: 0.07282613962888718
step: 550, loss: 0.02953585982322693
step: 560, loss: 0.08901189267635345
step: 570, loss: 0.1304660588502884
step: 580, loss: 0.06492538750171661
step: 590, loss: 0.018810763955116272
step: 600, loss: 0.09931518882513046
step: 610, loss: 0.11963389813899994
step: 620, loss: 0.15711064636707306
step: 630, loss: 0.1046326756477356
step: 640, loss: 0.09586706012487411
step: 650, loss: 0.14006859064102173
step: 660, loss: 0.03505055233836174
step: 670, loss: 0.07085080444812775
step: 680, loss: 0.06505317986011505
step: 690, loss: 0.047315746545791626
step: 700, loss: 0.19089044630527496
step: 710, loss: 0.04220255836844444
step: 720, loss: 0.054036833345890045
step: 730, loss: 0.05608275532722473
step: 740, loss: 0.19418592751026154
step: 750, loss: 0.036903396248817444
step: 760, loss: 0.020258953794836998
step: 770, loss: 0.07379134744405746
step: 780, loss: 0.005332911387085915
step: 790, loss: 0.14563381671905518
step: 800, loss: 0.049739181995391846
step: 810, loss: 0.08904314041137695
step: 820, loss: 0.07861782610416412
step: 830, loss: 0.036879148334264755
step: 840, loss: 0.0018909529317170382
step: 850, loss: 0.18976691365242004
step: 860, loss: 0.06294538080692291
step: 870, loss: 0.03627150505781174
step: 880, loss: 0.09863770753145218
step: 890, loss: 0.07847979664802551
step: 900, loss: 0.05262969806790352
step: 910, loss: 0.08762446790933609
step: 920, loss: 0.15381580591201782
step: 930, loss: 0.13292662799358368
step: 940, loss: 0.16225343942642212
step: 950, loss: 0.041128598153591156
step: 960, loss: 0.028381654992699623
step: 970, loss: 0.01200873963534832
step: 980, loss: 0.11399903148412704
step: 990, loss: 0.04936077818274498
step: 1000, loss: 0.06992064416408539
step: 1010, loss: 0.04041982814669609
step: 1020, loss: 0.05370934307575226
step: 1030, loss: 0.07740622013807297
step: 1040, loss: 0.042923081666231155
step: 1050, loss: 0.13618521392345428
step: 1060, loss: 0.015824491158127785
step: 1070, loss: 0.07123493403196335
epoch 7: dev_f1=0.929384965831435, f1=0.9285714285714285, best_f1=0.9254143646408841
step: 0, loss: 0.041171010583639145
step: 10, loss: 0.10104271024465561
step: 20, loss: 0.011017413809895515
step: 30, loss: 0.1280488222837448
step: 40, loss: 0.014619745314121246
step: 50, loss: 0.195649191737175
step: 60, loss: 0.05546044930815697
step: 70, loss: 0.09437225013971329
step: 80, loss: 0.04336091876029968
step: 90, loss: 0.10142777115106583
step: 100, loss: 0.029239656403660774
step: 110, loss: 0.019320644438266754
step: 120, loss: 0.1383223682641983
step: 130, loss: 0.05717436969280243
step: 140, loss: 0.05101131275296211
step: 150, loss: 0.06316768378019333
step: 160, loss: 0.0911879763007164
step: 170, loss: 0.08445996046066284
step: 180, loss: 0.10243277251720428
step: 190, loss: 0.1043582558631897
step: 200, loss: 0.057513557374477386
step: 210, loss: 0.007075655274093151
step: 220, loss: 0.16554750502109528
step: 230, loss: 0.18038195371627808
step: 240, loss: 0.05822444334626198
step: 250, loss: 0.07070101052522659
step: 260, loss: 0.10795006901025772
step: 270, loss: 0.007525207474827766
step: 280, loss: 0.035288989543914795
step: 290, loss: 0.06751007586717606
step: 300, loss: 0.24351486563682556
step: 310, loss: 0.025448061525821686
step: 320, loss: 0.07675367593765259
step: 330, loss: 0.10288243740797043
step: 340, loss: 0.13379397988319397
step: 350, loss: 0.06965714693069458
step: 360, loss: 0.049540210515260696
step: 370, loss: 0.06260716915130615
step: 380, loss: 0.08667844533920288
step: 390, loss: 0.1308092623949051
step: 400, loss: 4.5315980969462544e-05
step: 410, loss: 0.1011667251586914
step: 420, loss: 0.014233618974685669
step: 430, loss: 0.09474576264619827
step: 440, loss: 0.14320185780525208
step: 450, loss: 0.04272819310426712
step: 460, loss: 0.036769554018974304
step: 470, loss: 0.07977587729692459
step: 480, loss: 0.058496177196502686
step: 490, loss: 0.01953679509460926
step: 500, loss: 0.10060806572437286
step: 510, loss: 0.12606938183307648
step: 520, loss: 0.036609627306461334
step: 530, loss: 0.040917590260505676
step: 540, loss: 0.086392343044281
step: 550, loss: 0.020091867074370384
step: 560, loss: 0.12888140976428986
step: 570, loss: 0.14657273888587952
step: 580, loss: 0.09843546897172928
step: 590, loss: 0.0948028713464737
step: 600, loss: 0.07938257604837418
step: 610, loss: 0.30454394221305847
step: 620, loss: 0.04469290003180504
step: 630, loss: 0.04774019494652748
step: 640, loss: 0.06988458335399628
step: 650, loss: 0.052144721150398254
step: 660, loss: 0.047249723225831985
step: 670, loss: 0.08075962215662003
step: 680, loss: 0.0557008720934391
step: 690, loss: 0.07171491533517838
step: 700, loss: 0.029389947652816772
step: 710, loss: 0.07839552313089371
step: 720, loss: 0.01788056641817093
step: 730, loss: 0.06132654845714569
step: 740, loss: 0.33684518933296204
step: 750, loss: 0.1977427750825882
step: 760, loss: 0.10812235623598099
step: 770, loss: 0.04169485718011856
step: 780, loss: 0.1274748593568802
step: 790, loss: 0.1966622769832611
step: 800, loss: 0.08266142010688782
step: 810, loss: 0.15424342453479767
step: 820, loss: 0.1251877397298813
step: 830, loss: 0.057673003524541855
step: 840, loss: 0.12632878124713898
step: 850, loss: 0.09092800319194794
step: 860, loss: 0.11388205736875534
step: 870, loss: 0.1113228127360344
step: 880, loss: 0.03951035067439079
step: 890, loss: 0.05565319582819939
step: 900, loss: 0.09392577409744263
step: 910, loss: 0.10636904090642929
step: 920, loss: 0.04393618926405907
step: 930, loss: 0.04538339376449585
step: 940, loss: 0.06617671251296997
step: 950, loss: 0.03597922623157501
step: 960, loss: 0.06498594582080841
step: 970, loss: 0.01580694504082203
step: 980, loss: 0.2015943080186844
step: 990, loss: 0.025320962071418762
step: 1000, loss: 0.021308772265911102
step: 1010, loss: 0.0770951583981514
step: 1020, loss: 0.13393545150756836
step: 1030, loss: 0.0508841946721077
step: 1040, loss: 0.016103357076644897
step: 1050, loss: 0.08033943921327591
step: 1060, loss: 0.044220320880413055
step: 1070, loss: 0.05710533633828163
epoch 8: dev_f1=0.9240037071362373, f1=0.9222170470423847, best_f1=0.9254143646408841
step: 0, loss: 0.08745211362838745
step: 10, loss: 0.06253848969936371
step: 20, loss: 0.19121360778808594
step: 30, loss: 0.04499988257884979
step: 40, loss: 0.08451075851917267
step: 50, loss: 0.018800834193825722
step: 60, loss: 0.045345235615968704
step: 70, loss: 0.019836336374282837
step: 80, loss: 0.047298889607191086
step: 90, loss: 0.03761230781674385
step: 100, loss: 0.042667586356401443
step: 110, loss: 0.05241524800658226
step: 120, loss: 0.10022247582674026
step: 130, loss: 0.04853428527712822
step: 140, loss: 0.16910068690776825
step: 150, loss: 0.07226208597421646
step: 160, loss: 0.1355864554643631
step: 170, loss: 0.05499594658613205
step: 180, loss: 0.11844738572835922
step: 190, loss: 0.037692297250032425
step: 200, loss: 0.07754038274288177
step: 210, loss: 0.08949387818574905
step: 220, loss: 0.05807908624410629
step: 230, loss: 0.0038710786029696465
step: 240, loss: 0.0453801155090332
step: 250, loss: 0.08212647587060928
step: 260, loss: 0.0582563541829586
step: 270, loss: 0.1098708063364029
step: 280, loss: 0.1492023915052414
step: 290, loss: 0.05322302505373955
step: 300, loss: 0.04656587913632393
step: 310, loss: 0.03274161368608475
step: 320, loss: 0.050072140991687775
step: 330, loss: 0.08511900901794434
step: 340, loss: 0.025956517085433006
step: 350, loss: 0.062068209052085876
step: 360, loss: 0.06384138762950897
step: 370, loss: 0.17331770062446594
step: 380, loss: 0.030013173818588257
step: 390, loss: 0.0327201709151268
step: 400, loss: 0.021956879645586014
step: 410, loss: 0.017469964921474457
step: 420, loss: 0.07694283872842789
step: 430, loss: 0.05731115862727165
step: 440, loss: 0.1280255764722824
step: 450, loss: 0.05781152471899986
step: 460, loss: 0.06756994873285294
step: 470, loss: 0.061517685651779175
step: 480, loss: 0.0001033516600728035
step: 490, loss: 0.07292818278074265
step: 500, loss: 0.09046142548322678
step: 510, loss: 0.10102210938930511
step: 520, loss: 0.04344174265861511
step: 530, loss: 0.04842114448547363
step: 540, loss: 0.13696809113025665
step: 550, loss: 0.09836053848266602
step: 560, loss: 0.060047637671232224
step: 570, loss: 0.03468666225671768
step: 580, loss: 0.03655417636036873
step: 590, loss: 0.2669716477394104
step: 600, loss: 0.09124135226011276
step: 610, loss: 0.03814025968313217
step: 620, loss: 0.057966504245996475
step: 630, loss: 0.08106137812137604
step: 640, loss: 0.031108364462852478
step: 650, loss: 0.009768492542207241
step: 660, loss: 0.034052904695272446
step: 670, loss: 0.020592402666807175
step: 680, loss: 0.07720629125833511
step: 690, loss: 0.06554047018289566
step: 700, loss: 0.05333844944834709
step: 710, loss: 0.07746855914592743
step: 720, loss: 0.0730644017457962
step: 730, loss: 0.007509211078286171
step: 740, loss: 0.03223569318652153
step: 750, loss: 0.09702255576848984
step: 760, loss: 0.05080417916178703
step: 770, loss: 0.1014455184340477
step: 780, loss: 0.027857284992933273
step: 790, loss: 0.038597479462623596
step: 800, loss: 0.0028345645405352116
step: 810, loss: 0.01912866160273552
step: 820, loss: 0.08699699491262436
step: 830, loss: 0.007400718051940203
step: 840, loss: 0.058379076421260834
step: 850, loss: 0.042475029826164246
step: 860, loss: 0.05709094554185867
step: 870, loss: 0.06118733808398247
step: 880, loss: 0.08800195902585983
step: 890, loss: 0.044084880501031876
step: 900, loss: 0.046546246856451035
step: 910, loss: 0.07926997542381287
step: 920, loss: 0.08995568752288818
step: 930, loss: 0.029622307047247887
step: 940, loss: 0.09915677458047867
step: 950, loss: 0.07356434315443039
step: 960, loss: 0.015052486211061478
step: 970, loss: 0.09855768084526062
step: 980, loss: 0.03627019375562668
step: 990, loss: 0.09238223731517792
step: 1000, loss: 0.0758843794465065
step: 1010, loss: 0.01779959350824356
step: 1020, loss: 0.027000607922673225
step: 1030, loss: 0.039346229285001755
step: 1040, loss: 0.03644183278083801
step: 1050, loss: 0.1388091892004013
step: 1060, loss: 0.047969792038202286
step: 1070, loss: 0.3435961902141571
epoch 9: dev_f1=0.9305361305361305, f1=0.9275496077526535, best_f1=0.9254143646408841
step: 0, loss: 0.012717618606984615
step: 10, loss: 0.0022568509448319674
step: 20, loss: 0.11182668060064316
step: 30, loss: 0.022813772782683372
step: 40, loss: 0.1947758048772812
step: 50, loss: 0.04751326143741608
step: 60, loss: 0.04537104070186615
step: 70, loss: 0.0551360622048378
step: 80, loss: 0.053416330367326736
step: 90, loss: 0.08715394139289856
step: 100, loss: 0.03595982491970062
step: 110, loss: 0.017377499490976334
step: 120, loss: 0.13851574063301086
step: 130, loss: 0.03442489728331566
step: 140, loss: 0.0355362743139267
step: 150, loss: 0.041930608451366425
step: 160, loss: 0.08226358890533447
step: 170, loss: 0.015673279762268066
step: 180, loss: 0.13320569694042206
step: 190, loss: 0.002612512093037367
step: 200, loss: 0.0016488195396959782
step: 210, loss: 0.1356503814458847
step: 220, loss: 0.15259996056556702
step: 230, loss: 0.1529671549797058
step: 240, loss: 0.04390161857008934
step: 250, loss: 0.10214516520500183
step: 260, loss: 0.06602834165096283
step: 270, loss: 0.01019703783094883
step: 280, loss: 0.128775492310524
step: 290, loss: 0.04614335298538208
step: 300, loss: 0.05764641985297203
step: 310, loss: 0.03888382762670517
step: 320, loss: 0.14901013672351837
step: 330, loss: 0.1965252310037613
step: 340, loss: 0.14768601953983307
step: 350, loss: 0.014437985606491566
step: 360, loss: 0.04039572924375534
step: 370, loss: 0.1379285305738449
step: 380, loss: 0.04881659895181656
step: 390, loss: 0.08308744430541992
step: 400, loss: 0.0723198652267456
step: 410, loss: 0.03332846984267235
step: 420, loss: 0.2585688829421997
step: 430, loss: 0.06133841350674629
step: 440, loss: 0.08937323838472366
step: 450, loss: 0.059115588665008545
step: 460, loss: 0.1369602233171463
step: 470, loss: 0.05992712453007698
step: 480, loss: 0.045335348695516586
step: 490, loss: 0.021971818059682846
step: 500, loss: 0.014870673418045044
step: 510, loss: 0.003909323364496231
step: 520, loss: 0.04647665098309517
step: 530, loss: 0.031520143151283264
step: 540, loss: 0.040683213621377945
step: 550, loss: 0.10087617486715317
step: 560, loss: 0.14352943003177643
step: 570, loss: 0.05795866996049881
step: 580, loss: 0.10442513972520828
step: 590, loss: 0.05313195660710335
step: 600, loss: 0.0238393135368824
step: 610, loss: 0.12225518375635147
step: 620, loss: 0.11821991205215454
step: 630, loss: 0.1595141589641571
step: 640, loss: 0.07921330630779266
step: 650, loss: 0.05552539601922035
step: 660, loss: 0.02218051068484783
step: 670, loss: 0.10082079470157623
step: 680, loss: 0.06723861396312714
step: 690, loss: 0.061688460409641266
step: 700, loss: 0.11076103150844574
step: 710, loss: 0.0922766774892807
step: 720, loss: 0.0449291355907917
step: 730, loss: 0.01895034871995449
step: 740, loss: 0.024141330271959305
step: 750, loss: 0.011366457678377628
step: 760, loss: 0.1033027395606041
step: 770, loss: 0.16991466283798218
step: 780, loss: 0.09224042296409607
step: 790, loss: 0.007438417989760637
step: 800, loss: 0.043612200766801834
step: 810, loss: 0.1222233921289444
step: 820, loss: 0.00779735529795289
step: 830, loss: 0.14795418083667755
step: 840, loss: 0.06856032460927963
step: 850, loss: 0.054888270795345306
step: 860, loss: 0.07449164241552353
step: 870, loss: 0.04721852019429207
step: 880, loss: 0.037999603897333145
step: 890, loss: 0.12983907759189606
step: 900, loss: 0.12038523703813553
step: 910, loss: 0.0025550026912242174
step: 920, loss: 0.12132252007722855
step: 930, loss: 0.0020757580641657114
step: 940, loss: 0.10498693585395813
step: 950, loss: 0.15999221801757812
step: 960, loss: 0.0973670706152916
step: 970, loss: 0.04299705848097801
step: 980, loss: 0.09993106871843338
step: 990, loss: 0.029000043869018555
step: 1000, loss: 0.029689956456422806
step: 1010, loss: 0.08768764138221741
step: 1020, loss: 0.03838373348116875
step: 1030, loss: 0.1193310096859932
step: 1040, loss: 0.131988525390625
step: 1050, loss: 0.006588438525795937
step: 1060, loss: 0.08736492693424225
step: 1070, loss: 0.048292871564626694
epoch 10: dev_f1=0.925672594619243, f1=0.9180327868852458, best_f1=0.9254143646408841
step: 0, loss: 0.009003241546452045
step: 10, loss: 0.11573712527751923
step: 20, loss: 0.05554680526256561
step: 30, loss: 0.018618253991007805
step: 40, loss: 0.051575418561697006
step: 50, loss: 0.06642267107963562
step: 60, loss: 0.13564236462116241
step: 70, loss: 0.07961834967136383
step: 80, loss: 0.04719151556491852
step: 90, loss: 0.02356555312871933
step: 100, loss: 0.02849363535642624
step: 110, loss: 0.007953775115311146
step: 120, loss: 0.06640898436307907
step: 130, loss: 0.023641029372811317
step: 140, loss: 0.07033312320709229
step: 150, loss: 0.09044771641492844
step: 160, loss: 0.003263198072090745
step: 170, loss: 0.19439178705215454
step: 180, loss: 0.06432130932807922
step: 190, loss: 0.032526180148124695
step: 200, loss: 0.03266913816332817
step: 210, loss: 0.03398596867918968
step: 220, loss: 0.014199193567037582
step: 230, loss: 0.1333310306072235
step: 240, loss: 0.0697246864438057
step: 250, loss: 0.03473472595214844
step: 260, loss: 0.08300479501485825
step: 270, loss: 0.0819539800286293
step: 280, loss: 0.00036286411341279745
step: 290, loss: 0.10334976017475128
step: 300, loss: 0.03298591449856758
step: 310, loss: 0.05525539815425873
step: 320, loss: 0.150145024061203
step: 330, loss: 0.07491862773895264
step: 340, loss: 0.14125321805477142
step: 350, loss: 0.09097227454185486
step: 360, loss: 0.09327854216098785
step: 370, loss: 0.04861580207943916
step: 380, loss: 0.0580260343849659
step: 390, loss: 0.13403359055519104
step: 400, loss: 0.02484896592795849
step: 410, loss: 0.05897161737084389
step: 420, loss: 0.03349829092621803
step: 430, loss: 0.12329305708408356
step: 440, loss: 0.045989032834768295
step: 450, loss: 0.05187409371137619
step: 460, loss: 0.0512750968337059
step: 470, loss: 0.08854919672012329
step: 480, loss: 0.01807376928627491
step: 490, loss: 0.02766318991780281
step: 500, loss: 0.00922555010765791
step: 510, loss: 0.04942933842539787
step: 520, loss: 0.019928397610783577
step: 530, loss: 0.09818873554468155
step: 540, loss: 0.06733641028404236
step: 550, loss: 0.06971917301416397
step: 560, loss: 0.10697782784700394
step: 570, loss: 0.13863664865493774
step: 580, loss: 0.003901758464053273
step: 590, loss: 0.07442808151245117
step: 600, loss: 0.07833563536405563
step: 610, loss: 0.10853229463100433
step: 620, loss: 0.030506335198879242
step: 630, loss: 0.08741413801908493
step: 640, loss: 0.06497844308614731
step: 650, loss: 0.08352214843034744
step: 660, loss: 0.05015553534030914
step: 670, loss: 0.15223322808742523
step: 680, loss: 0.10236751288175583
step: 690, loss: 0.07576018571853638
step: 700, loss: 4.094119867659174e-05
step: 710, loss: 0.0435105599462986
step: 720, loss: 0.041627611964941025
step: 730, loss: 0.0561596117913723
step: 740, loss: 0.09102880954742432
step: 750, loss: 0.01924048364162445
step: 760, loss: 0.0925038754940033
step: 770, loss: 0.061525873839855194
step: 780, loss: 0.09202568978071213
step: 790, loss: 0.05034496635198593
step: 800, loss: 0.008904126472771168
step: 810, loss: 0.05320926383137703
step: 820, loss: 0.04866839945316315
step: 830, loss: 0.009348826482892036
step: 840, loss: 0.06377778947353363
step: 850, loss: 0.10282266139984131
step: 860, loss: 0.05380287021398544
step: 870, loss: 0.03766651824116707
step: 880, loss: 0.0011365592945367098
step: 890, loss: 0.02952498383820057
step: 900, loss: 0.02695315331220627
step: 910, loss: 0.06731703877449036
step: 920, loss: 0.07839274406433105
step: 930, loss: 0.0992199257016182
step: 940, loss: 0.14086228609085083
step: 950, loss: 0.0786641389131546
step: 960, loss: 0.06058195233345032
step: 970, loss: 0.10892646014690399
step: 980, loss: 0.05337539687752724
step: 990, loss: 0.0896950289607048
step: 1000, loss: 0.035101182758808136
step: 1010, loss: 0.016227765008807182
step: 1020, loss: 0.044711366295814514
step: 1030, loss: 0.004693359602242708
step: 1040, loss: 0.07320491224527359
step: 1050, loss: 0.054687052965164185
step: 1060, loss: 0.08041627705097198
step: 1070, loss: 0.11963602900505066
epoch 11: dev_f1=0.9340761374187557, f1=0.9300602130616026, best_f1=0.9300602130616026
step: 0, loss: 0.10023048520088196
step: 10, loss: 0.051372651010751724
step: 20, loss: 0.02445034496486187
step: 30, loss: 0.08128125965595245
step: 40, loss: 0.05782858654856682
step: 50, loss: 2.295088052051142e-05
step: 60, loss: 0.06511447578668594
step: 70, loss: 0.0020607798360288143
step: 80, loss: 0.057704582810401917
step: 90, loss: 0.046268898993730545
step: 100, loss: 0.05089838057756424
step: 110, loss: 0.11932536214590073
step: 120, loss: 0.04228166863322258
step: 130, loss: 0.03317825868725777
step: 140, loss: 0.06071028858423233
step: 150, loss: 0.06845296919345856
step: 160, loss: 0.08490718901157379
step: 170, loss: 0.07472728192806244
step: 180, loss: 0.06099904701113701
step: 190, loss: 0.11938668042421341
step: 200, loss: 0.0639224499464035
step: 210, loss: 0.0693804994225502
step: 220, loss: 0.04525066167116165
step: 230, loss: 0.10703966021537781
step: 240, loss: 0.04808662831783295
step: 250, loss: 0.0674068033695221
step: 260, loss: 0.08276153355836868
step: 270, loss: 0.038946907967329025
step: 280, loss: 0.03859446197748184
step: 290, loss: 0.04214504733681679
step: 300, loss: 0.10557916760444641
step: 310, loss: 0.09351782500743866
step: 320, loss: 0.015168426558375359
step: 330, loss: 0.0373406745493412
step: 340, loss: 0.05253215879201889
step: 350, loss: 0.0808185338973999
step: 360, loss: 0.03314491733908653
step: 370, loss: 0.1325552612543106
step: 380, loss: 0.0665227472782135
step: 390, loss: 0.05428171902894974
step: 400, loss: 0.07324936985969543
step: 410, loss: 0.0030502283480018377
step: 420, loss: 0.05418149009346962
step: 430, loss: 0.06682058423757553
step: 440, loss: 0.11488258838653564
step: 450, loss: 0.08352212607860565
step: 460, loss: 0.08541218936443329
step: 470, loss: 0.019118845462799072
step: 480, loss: 0.0564417764544487
step: 490, loss: 0.07771266996860504
step: 500, loss: 0.0379464365541935
step: 510, loss: 0.050709981471300125
step: 520, loss: 0.03319159150123596
step: 530, loss: 0.1914558857679367
step: 540, loss: 0.0976327583193779
step: 550, loss: 0.0599508062005043
step: 560, loss: 0.13071152567863464
step: 570, loss: 0.01715034805238247
step: 580, loss: 0.04063261300325394
step: 590, loss: 0.0669010728597641
step: 600, loss: 0.05444522947072983
step: 610, loss: 0.022302445024251938
step: 620, loss: 0.0001905582466861233
step: 630, loss: 0.06884860247373581
step: 640, loss: 0.06860366463661194
step: 650, loss: 0.059767719358205795
step: 660, loss: 0.025312529876828194
step: 670, loss: 0.17461495101451874
step: 680, loss: 0.052368856966495514
step: 690, loss: 0.03945661708712578
step: 700, loss: 0.034924160689115524
step: 710, loss: 0.04319222643971443
step: 720, loss: 0.021823754534125328
step: 730, loss: 0.04304342716932297
step: 740, loss: 0.041560132056474686
step: 750, loss: 0.033158741891384125
step: 760, loss: 0.10844459384679794
step: 770, loss: 0.0166939664632082
step: 780, loss: 0.06034572422504425
step: 790, loss: 0.08465006202459335
step: 800, loss: 0.024653276428580284
step: 810, loss: 0.03400160372257233
step: 820, loss: 0.05521300435066223
step: 830, loss: 0.01851079799234867
step: 840, loss: 0.06215892359614372
step: 850, loss: 0.04941624775528908
step: 860, loss: 0.11743089556694031
step: 870, loss: 0.03808366134762764
step: 880, loss: 0.06906066089868546
step: 890, loss: 0.05401292070746422
step: 900, loss: 0.15656866133213043
step: 910, loss: 0.010959156788885593
step: 920, loss: 0.1451416164636612
step: 930, loss: 0.12941686809062958
step: 940, loss: 0.018649205565452576
step: 950, loss: 0.09842467308044434
step: 960, loss: 0.0683712288737297
step: 970, loss: 0.0073529137298464775
step: 980, loss: 0.0035680183209478855
step: 990, loss: 0.12041639536619186
step: 1000, loss: 0.069959357380867
step: 1010, loss: 0.10464403033256531
step: 1020, loss: 0.03544243797659874
step: 1030, loss: 0.11777658015489578
step: 1040, loss: 0.09811386466026306
step: 1050, loss: 0.05550899729132652
step: 1060, loss: 0.10683545470237732
step: 1070, loss: 0.026865655556321144
epoch 12: dev_f1=0.9259088817303267, f1=0.9211009174311927, best_f1=0.9300602130616026
step: 0, loss: 0.06999152153730392
step: 10, loss: 0.007329207845032215
step: 20, loss: 0.0747143030166626
step: 30, loss: 0.0762193351984024
step: 40, loss: 0.05971849337220192
step: 50, loss: 0.05183468386530876
step: 60, loss: 0.02121436595916748
step: 70, loss: 0.012267237529158592
step: 80, loss: 0.0774519070982933
step: 90, loss: 0.0018329157028347254
step: 100, loss: 0.042618583887815475
step: 110, loss: 0.008450874127447605
step: 120, loss: 0.004719588905572891
step: 130, loss: 0.021218445152044296
step: 140, loss: 0.025634726509451866
step: 150, loss: 0.029560791328549385
step: 160, loss: 0.0014151799259707332
step: 170, loss: 0.09030965715646744
step: 180, loss: 0.03718120604753494
step: 190, loss: 0.003747395006939769
step: 200, loss: 0.010779201053082943
step: 210, loss: 0.10463792830705643
step: 220, loss: 0.022733550518751144
step: 230, loss: 0.008080845698714256
step: 240, loss: 0.017401430755853653
step: 250, loss: 0.03492364659905434
step: 260, loss: 0.007072035223245621
step: 270, loss: 0.13180695474147797
step: 280, loss: 0.12557226419448853
step: 290, loss: 0.07531788945198059
step: 300, loss: 0.0336502306163311
step: 310, loss: 0.0077452277764678
step: 320, loss: 0.01933649182319641
step: 330, loss: 0.05282000079751015
step: 340, loss: 0.09762345254421234
step: 350, loss: 0.0137241892516613
step: 360, loss: 4.004607399110682e-05
step: 370, loss: 0.034286979585886
step: 380, loss: 0.02224653773009777
step: 390, loss: 0.03941184654831886
step: 400, loss: 0.11109409481287003
step: 410, loss: 0.062267005443573
step: 420, loss: 0.07211706787347794
step: 430, loss: 0.02569887973368168
step: 440, loss: 0.03267580643296242
step: 450, loss: 0.15200038254261017
step: 460, loss: 0.050946202129125595
step: 470, loss: 0.012625496834516525
step: 480, loss: 0.03635115176439285
step: 490, loss: 0.032554518431425095
step: 500, loss: 0.038728222250938416
step: 510, loss: 0.09512399882078171
step: 520, loss: 0.021351223811507225
step: 530, loss: 0.06121642887592316
step: 540, loss: 0.028512272983789444
step: 550, loss: 0.009354833513498306
step: 560, loss: 0.0013831340475007892
step: 570, loss: 0.03671380504965782
step: 580, loss: 0.022542862221598625
step: 590, loss: 0.002314851153641939
step: 600, loss: 0.05117632821202278
step: 610, loss: 0.057829100638628006
step: 620, loss: 0.04328801855444908
step: 630, loss: 0.045087315142154694
step: 640, loss: 0.044450294226408005
step: 650, loss: 0.0112907774746418
step: 660, loss: 0.0022778313141316175
step: 670, loss: 0.04133763536810875
step: 680, loss: 0.1458367109298706
step: 690, loss: 0.009142240509390831
step: 700, loss: 0.017425628378987312
step: 710, loss: 0.003005591221153736
step: 720, loss: 0.08658085763454437
step: 730, loss: 0.09598655253648758
step: 740, loss: 0.08713197708129883
step: 750, loss: 0.0935741513967514
step: 760, loss: 0.08392849564552307
step: 770, loss: 0.0011409645667299628
step: 780, loss: 0.060301605612039566
step: 790, loss: 0.03911025449633598
step: 800, loss: 0.07688172906637192
step: 810, loss: 0.03781459107995033
step: 820, loss: 0.07907528430223465
step: 830, loss: 0.11086004972457886
step: 840, loss: 0.00014714096323587
step: 850, loss: 0.04501562938094139
step: 860, loss: 0.03144599124789238
step: 870, loss: 0.08526400476694107
step: 880, loss: 0.16718098521232605
step: 890, loss: 0.04771467298269272
step: 900, loss: 0.06822994351387024
step: 910, loss: 0.06309226900339127
step: 920, loss: 0.01196062471717596
step: 930, loss: 0.09491327404975891
step: 940, loss: 0.0028099361807107925
step: 950, loss: 0.044813450425863266
step: 960, loss: 0.12362800538539886
step: 970, loss: 0.019627943634986877
step: 980, loss: 0.16824428737163544
step: 990, loss: 0.13599948585033417
step: 1000, loss: 0.07055709511041641
step: 1010, loss: 0.07559000700712204
step: 1020, loss: 0.1348070502281189
step: 1030, loss: 0.08601357787847519
step: 1040, loss: 0.08390625566244125
step: 1050, loss: 0.04477314651012421
step: 1060, loss: 0.08583647012710571
step: 1070, loss: 0.08371921628713608
epoch 13: dev_f1=0.9320843091334895, f1=0.9253034547152195, best_f1=0.9300602130616026
step: 0, loss: 0.02387315034866333
step: 10, loss: 0.09191963821649551
step: 20, loss: 0.06078123673796654
step: 30, loss: 0.047636665403842926
step: 40, loss: 0.013690721243619919
step: 50, loss: 0.0745493620634079
step: 60, loss: 0.05332903563976288
step: 70, loss: 0.032680362462997437
step: 80, loss: 0.04026032239198685
step: 90, loss: 0.10933103412389755
step: 100, loss: 0.02272680215537548
step: 110, loss: 0.0739673376083374
step: 120, loss: 0.0018282558303326368
step: 130, loss: 0.04550475254654884
step: 140, loss: 0.03407473489642143
step: 150, loss: 0.14036351442337036
step: 160, loss: 0.06957247853279114
step: 170, loss: 0.09885173290967941
step: 180, loss: 0.04849927872419357
step: 190, loss: 0.155384361743927
step: 200, loss: 0.12199430167675018
step: 210, loss: 0.0011521276319399476
step: 220, loss: 0.07736382633447647
step: 230, loss: 0.0293711107224226
step: 240, loss: 0.02708076871931553
step: 250, loss: 6.312727782642469e-05
step: 260, loss: 0.06282590329647064
step: 270, loss: 0.036487333476543427
step: 280, loss: 0.00915573351085186
step: 290, loss: 0.04575473442673683
step: 300, loss: 0.1266157329082489
step: 310, loss: 0.07031172513961792
step: 320, loss: 0.0003020382428076118
step: 330, loss: 0.030203426256775856
step: 340, loss: 0.023481668904423714
step: 350, loss: 0.0545312836766243
step: 360, loss: 0.049350712448358536
step: 370, loss: 0.040143467485904694
step: 380, loss: 0.019108988344669342
step: 390, loss: 0.04693994298577309
step: 400, loss: 0.1715603470802307
step: 410, loss: 0.05375359579920769
step: 420, loss: 0.034409016370773315
step: 430, loss: 0.10449105501174927
step: 440, loss: 0.0018730700248852372
step: 450, loss: 0.0034668780863285065
step: 460, loss: 0.017682386562228203
step: 470, loss: 0.04356465861201286
step: 480, loss: 0.01601710356771946
step: 490, loss: 0.024424467235803604
step: 500, loss: 0.006301364861428738
step: 510, loss: 0.055293306708335876
step: 520, loss: 0.05284677445888519
step: 530, loss: 0.06444327533245087
step: 540, loss: 0.08913175016641617
step: 550, loss: 0.03551042824983597
step: 560, loss: 0.04670518636703491
step: 570, loss: 4.416428419062868e-05
step: 580, loss: 0.13700230419635773
step: 590, loss: 0.039822764694690704
step: 600, loss: 0.09969065338373184
step: 610, loss: 0.05545511841773987
step: 620, loss: 0.06686663627624512
step: 630, loss: 0.03760422766208649
step: 640, loss: 0.04120994731783867
step: 650, loss: 0.03297995403409004
step: 660, loss: 0.04384910687804222
step: 670, loss: 0.039982814341783524
step: 680, loss: 0.0253465436398983
step: 690, loss: 0.023864300921559334
step: 700, loss: 0.023978307843208313
step: 710, loss: 0.01446655485779047
step: 720, loss: 0.09639351814985275
step: 730, loss: 0.07124598324298859
step: 740, loss: 0.09872256219387054
step: 750, loss: 0.04329043626785278
step: 760, loss: 0.04869150370359421
step: 770, loss: 0.02355216071009636
step: 780, loss: 0.0003731406177394092
step: 790, loss: 0.05772019177675247
step: 800, loss: 0.07186197489500046
step: 810, loss: 0.02641831710934639
step: 820, loss: 0.06356479227542877
step: 830, loss: 0.0616195909678936
step: 840, loss: 0.02573944441974163
step: 850, loss: 0.02123856171965599
step: 860, loss: 0.03674504533410072
step: 870, loss: 0.02861042134463787
step: 880, loss: 0.014115910045802593
step: 890, loss: 0.01621977612376213
step: 900, loss: 0.0541122630238533
step: 910, loss: 0.08154627680778503
step: 920, loss: 0.21681194007396698
step: 930, loss: 0.06039220094680786
step: 940, loss: 0.08148413896560669
step: 950, loss: 0.055728133767843246
step: 960, loss: 0.02732904814183712
step: 970, loss: 0.06712043285369873
step: 980, loss: 0.03935769572854042
step: 990, loss: 0.07404559850692749
step: 1000, loss: 0.06991221755743027
step: 1010, loss: 0.03719956800341606
step: 1020, loss: 0.03166065737605095
step: 1030, loss: 0.046431515365839005
step: 1040, loss: 0.029350610449910164
step: 1050, loss: 0.00014260169700719416
step: 1060, loss: 0.07131082564592361
step: 1070, loss: 0.06836219877004623
epoch 14: dev_f1=0.9270106927010693, f1=0.9246511627906977, best_f1=0.9300602130616026
step: 0, loss: 0.03433723375201225
step: 10, loss: 0.051250990480184555
step: 20, loss: 0.03186969831585884
step: 30, loss: 0.0712861567735672
step: 40, loss: 0.040659599006175995
step: 50, loss: 0.11540621519088745
step: 60, loss: 0.05412382259964943
step: 70, loss: 0.07723046094179153
step: 80, loss: 0.008159617893397808
step: 90, loss: 0.014859248884022236
step: 100, loss: 0.040046438574790955
step: 110, loss: 0.10508302599191666
step: 120, loss: 0.0368063785135746
step: 130, loss: 0.0189492329955101
step: 140, loss: 8.576308755436912e-05
step: 150, loss: 0.11326223611831665
step: 160, loss: 0.043557584285736084
step: 170, loss: 0.047560058534145355
step: 180, loss: 0.1438664197921753
step: 190, loss: 0.04196861758828163
step: 200, loss: 0.001168058137409389
step: 210, loss: 0.015016133897006512
step: 220, loss: 2.300651431141887e-05
step: 230, loss: 0.02836272306740284
step: 240, loss: 0.0005228184163570404
step: 250, loss: 0.00907768402248621
step: 260, loss: 0.09522713720798492
step: 270, loss: 0.07144913077354431
step: 280, loss: 0.022488469257950783
step: 290, loss: 0.06802228838205338
step: 300, loss: 0.03877053037285805
step: 310, loss: 0.03918273746967316
step: 320, loss: 0.07618405669927597
step: 330, loss: 0.10738318413496017
step: 340, loss: 0.022256700322031975
step: 350, loss: 0.004553542006760836
step: 360, loss: 0.05215561017394066
step: 370, loss: 0.04817277193069458
step: 380, loss: 0.08351008594036102
step: 390, loss: 0.019710473716259003
step: 400, loss: 0.12519016861915588
step: 410, loss: 0.04573224112391472
step: 420, loss: 0.019726943224668503
step: 430, loss: 0.028896423056721687
step: 440, loss: 0.02282583713531494
step: 450, loss: 0.07949336618185043
step: 460, loss: 0.029356617480516434
step: 470, loss: 0.05368683114647865
step: 480, loss: 0.010938919149339199
step: 490, loss: 0.013658217154443264
step: 500, loss: 0.05667773261666298
step: 510, loss: 0.06079583615064621
step: 520, loss: 0.04185759276151657
step: 530, loss: 0.005675124004483223
step: 540, loss: 0.020519880577921867
step: 550, loss: 0.1196770966053009
step: 560, loss: 0.06134980171918869
step: 570, loss: 4.6602006477769464e-05
step: 580, loss: 0.00015100908058229834
step: 590, loss: 0.060611844062805176
step: 600, loss: 0.03585292026400566
step: 610, loss: 0.08885184675455093
step: 620, loss: 0.05069104582071304
step: 630, loss: 0.044168222695589066
step: 640, loss: 0.06061897426843643
step: 650, loss: 0.09362445771694183
step: 660, loss: 0.07471857219934464
step: 670, loss: 0.0009725649142637849
step: 680, loss: 0.05590106546878815
step: 690, loss: 0.05042623355984688
step: 700, loss: 0.06550343334674835
step: 710, loss: 0.14395023882389069
step: 720, loss: 0.07343575358390808
step: 730, loss: 0.058413513004779816
step: 740, loss: 0.009944605641067028
step: 750, loss: 0.09059685468673706
step: 760, loss: 0.033284563571214676
step: 770, loss: 0.06392552703619003
step: 780, loss: 0.05047335848212242
step: 790, loss: 0.0534588061273098
step: 800, loss: 0.04477638751268387
step: 810, loss: 0.04529046267271042
step: 820, loss: 0.030506374314427376
step: 830, loss: 0.05913865566253662
step: 840, loss: 0.0663754940032959
step: 850, loss: 0.06445913761854172
step: 860, loss: 0.02136523835361004
step: 870, loss: 0.11556471884250641
step: 880, loss: 0.023253634572029114
step: 890, loss: 0.04842689260840416
step: 900, loss: 0.014184623956680298
step: 910, loss: 0.010418269783258438
step: 920, loss: 0.0944618433713913
step: 930, loss: 7.278363773366436e-05
step: 940, loss: 0.0417548231780529
step: 950, loss: 0.01230157632380724
step: 960, loss: 0.03276662901043892
step: 970, loss: 0.19100284576416016
step: 980, loss: 0.006500508636236191
step: 990, loss: 0.0764872282743454
step: 1000, loss: 0.06709329038858414
step: 1010, loss: 0.05566834285855293
step: 1020, loss: 0.04136187210679054
step: 1030, loss: 0.11065126210451126
step: 1040, loss: 0.07941937446594238
step: 1050, loss: 0.1030379980802536
step: 1060, loss: 0.02630659192800522
step: 1070, loss: 0.05318000912666321
epoch 15: dev_f1=0.9284725426857406, f1=0.9258406264394289, best_f1=0.9300602130616026
step: 0, loss: 0.07798891514539719
step: 10, loss: 0.08091889321804047
step: 20, loss: 0.06627029180526733
step: 30, loss: 0.020966587588191032
step: 40, loss: 0.004017964005470276
step: 50, loss: 0.028024595230817795
step: 60, loss: 0.08501076698303223
step: 70, loss: 0.06461258977651596
step: 80, loss: 0.056586649268865585
step: 90, loss: 0.23435735702514648
step: 100, loss: 0.08104103803634644
step: 110, loss: 0.018062930554151535
step: 120, loss: 0.03712131083011627
step: 130, loss: 0.05167907848954201
step: 140, loss: 0.04933919757604599
step: 150, loss: 0.02172872982919216
step: 160, loss: 0.06853324919939041
step: 170, loss: 0.04446848854422569
step: 180, loss: 0.09971676021814346
step: 190, loss: 0.036566440016031265
step: 200, loss: 0.016300758346915245
step: 210, loss: 0.08100845664739609
step: 220, loss: 0.023939771577715874
step: 230, loss: 0.09461008757352829
step: 240, loss: 0.04808304086327553
step: 250, loss: 0.048038922250270844
step: 260, loss: 0.016719402745366096
step: 270, loss: 0.016862040385603905
step: 280, loss: 0.035285040736198425
step: 290, loss: 0.048159755766391754
step: 300, loss: 0.05410222336649895
step: 310, loss: 0.0003090319223701954
step: 320, loss: 0.06935912370681763
step: 330, loss: 0.044362474232912064
step: 340, loss: 0.0503481961786747
step: 350, loss: 0.01201969850808382
step: 360, loss: 1.694947059149854e-05
step: 370, loss: 0.00016837306611705571
step: 380, loss: 8.246226207120344e-05
step: 390, loss: 0.09467243403196335
step: 400, loss: 0.06076520308852196
step: 410, loss: 0.09357892721891403
step: 420, loss: 0.04855702817440033
step: 430, loss: 0.02500615455210209
step: 440, loss: 0.04737646132707596
step: 450, loss: 0.0447719506919384
step: 460, loss: 0.07253436744213104
step: 470, loss: 0.05100630596280098
step: 480, loss: 0.08431760966777802
step: 490, loss: 0.08021590858697891
step: 500, loss: 0.013978254981338978
step: 510, loss: 0.025876954197883606
step: 520, loss: 0.018600769340991974
step: 530, loss: 0.022085921838879585
step: 540, loss: 0.1010073721408844
step: 550, loss: 0.0714750736951828
step: 560, loss: 0.10690153390169144
step: 570, loss: 0.023518763482570648
step: 580, loss: 0.05008251219987869
step: 590, loss: 0.06658224016427994
step: 600, loss: 0.016821298748254776
step: 610, loss: 0.052715472877025604
step: 620, loss: 0.03594541549682617
step: 630, loss: 0.02650974690914154
step: 640, loss: 0.03853686898946762
step: 650, loss: 0.09202703088521957
step: 660, loss: 0.05449836701154709
step: 670, loss: 0.15187452733516693
step: 680, loss: 0.013230651617050171
step: 690, loss: 0.014057585969567299
step: 700, loss: 0.027585936710238457
step: 710, loss: 0.039608802646398544
step: 720, loss: 0.01546376384794712
step: 730, loss: 0.0031165112741291523
step: 740, loss: 0.1232137680053711
step: 750, loss: 0.0570334866642952
step: 760, loss: 0.08846169710159302
step: 770, loss: 0.06725897639989853
step: 780, loss: 0.06383737176656723
step: 790, loss: 0.011850510723888874
step: 800, loss: 0.022758668288588524
step: 810, loss: 0.07669924199581146
step: 820, loss: 5.820344085805118e-05
step: 830, loss: 0.03271614387631416
step: 840, loss: 0.048024751245975494
step: 850, loss: 0.011318080127239227
step: 860, loss: 0.06730012595653534
step: 870, loss: 0.028938645496964455
step: 880, loss: 0.015888091176748276
step: 890, loss: 0.06833654642105103
step: 900, loss: 0.06968747824430466
step: 910, loss: 0.06915514916181564
step: 920, loss: 0.06507712602615356
step: 930, loss: 0.017230156809091568
step: 940, loss: 0.0723600760102272
step: 950, loss: 0.11510803550481796
step: 960, loss: 0.023059548810124397
step: 970, loss: 0.04070481285452843
step: 980, loss: 0.023543130606412888
step: 990, loss: 0.0006265833508223295
step: 1000, loss: 0.019900411367416382
step: 1010, loss: 0.020368576049804688
step: 1020, loss: 0.06682910025119781
step: 1030, loss: 0.036659710109233856
step: 1040, loss: 0.06312532722949982
step: 1050, loss: 0.05736581236124039
step: 1060, loss: 0.06026918441057205
step: 1070, loss: 0.02403736114501953
epoch 16: dev_f1=0.9267161410018553, f1=0.9200923787528869, best_f1=0.9300602130616026
step: 0, loss: 0.06567436456680298
step: 10, loss: 0.07638433575630188
step: 20, loss: 3.0380539101315662e-05
step: 30, loss: 0.027523500844836235
step: 40, loss: 0.09488770365715027
step: 50, loss: 0.04815139248967171
step: 60, loss: 0.014922007918357849
step: 70, loss: 0.04155276343226433
step: 80, loss: 0.06506204605102539
step: 90, loss: 0.001968153053894639
step: 100, loss: 0.04652603343129158
step: 110, loss: 0.05392596870660782
step: 120, loss: 0.023859523236751556
step: 130, loss: 0.0011378994677215815
step: 140, loss: 0.024535024538636208
step: 150, loss: 0.03135424852371216
step: 160, loss: 0.1241498664021492
step: 170, loss: 0.035422779619693756
step: 180, loss: 0.03550200164318085
step: 190, loss: 0.007115275599062443
step: 200, loss: 0.10598289221525192
step: 210, loss: 0.06265279650688171
step: 220, loss: 0.019470497965812683
step: 230, loss: 0.03697241097688675
step: 240, loss: 0.04747913032770157
step: 250, loss: 0.09847002476453781
step: 260, loss: 0.05040428414940834
step: 270, loss: 0.026703275740146637
step: 280, loss: 0.026574280112981796
step: 290, loss: 0.06916508078575134
step: 300, loss: 0.049911074340343475
step: 310, loss: 0.0664532482624054
step: 320, loss: 0.033715713769197464
step: 330, loss: 0.00018894075765274465
step: 340, loss: 0.0331253819167614
step: 350, loss: 0.012076144106686115
step: 360, loss: 0.024977780878543854
step: 370, loss: 0.027203312143683434
step: 380, loss: 0.0005579499993473291
step: 390, loss: 0.07371802628040314
step: 400, loss: 0.054925430566072464
step: 410, loss: 0.06152254715561867
step: 420, loss: 0.04676133394241333
step: 430, loss: 0.17862845957279205
step: 440, loss: 0.01690296083688736
step: 450, loss: 0.03904712200164795
step: 460, loss: 0.05964759364724159
step: 470, loss: 0.06808572262525558
step: 480, loss: 0.06089108809828758
step: 490, loss: 0.031288158148527145
step: 500, loss: 0.09063538163900375
step: 510, loss: 0.06482186913490295
step: 520, loss: 0.10748530924320221
step: 530, loss: 0.05877305567264557
step: 540, loss: 0.06617383658885956
step: 550, loss: 0.06344732642173767
step: 560, loss: 7.128767902031541e-05
step: 570, loss: 0.025982661172747612
step: 580, loss: 0.04607529938220978
step: 590, loss: 0.027811717242002487
step: 600, loss: 0.0416240394115448
step: 610, loss: 0.03904872015118599
step: 620, loss: 0.05175812542438507
step: 630, loss: 0.11075421422719955
step: 640, loss: 0.07521943002939224
step: 650, loss: 0.02123386412858963
step: 660, loss: 0.09071866422891617
step: 670, loss: 0.012991849333047867
step: 680, loss: 0.03274616226553917
step: 690, loss: 9.651672007748857e-05
step: 700, loss: 0.016118576750159264
step: 710, loss: 6.733968621119857e-05
step: 720, loss: 0.03777797520160675
step: 730, loss: 0.0279383547604084
step: 740, loss: 0.09490548819303513
step: 750, loss: 0.013568541035056114
step: 760, loss: 0.0002690177643671632
step: 770, loss: 0.0001371896651107818
step: 780, loss: 0.04113129898905754
step: 790, loss: 0.011775928549468517
step: 800, loss: 0.05494765564799309
step: 810, loss: 0.0431956946849823
step: 820, loss: 0.16155706346035004
step: 830, loss: 3.7498262827284634e-05
step: 840, loss: 0.005332656670361757
step: 850, loss: 0.04856114089488983
step: 860, loss: 0.031932275742292404
step: 870, loss: 0.04595287889242172
step: 880, loss: 0.03198849782347679
step: 890, loss: 0.03508079797029495
step: 900, loss: 0.018563881516456604
step: 910, loss: 0.00012373653589747846
step: 920, loss: 0.052027396857738495
step: 930, loss: 0.06759624928236008
step: 940, loss: 0.030336299911141396
step: 950, loss: 0.06880626082420349
step: 960, loss: 0.09389451891183853
step: 970, loss: 0.06902802735567093
step: 980, loss: 0.03422825410962105
step: 990, loss: 0.005104202311486006
step: 1000, loss: 0.04797741025686264
step: 1010, loss: 0.026941660791635513
step: 1020, loss: 0.044587455689907074
step: 1030, loss: 0.07655253261327744
step: 1040, loss: 0.011992345564067364
step: 1050, loss: 0.029962686821818352
step: 1060, loss: 0.03611142560839653
step: 1070, loss: 0.13652202486991882
epoch 17: dev_f1=0.9243776420854861, f1=0.9243697478991597, best_f1=0.9300602130616026
step: 0, loss: 0.001664289622567594
step: 10, loss: 0.08609825372695923
step: 20, loss: 0.01161032821983099
step: 30, loss: 0.04137592762708664
step: 40, loss: 0.057878389954566956
step: 50, loss: 0.05536322295665741
step: 60, loss: 0.03771836683154106
step: 70, loss: 0.04341603443026543
step: 80, loss: 0.029675977304577827
step: 90, loss: 0.0017950345063582063
step: 100, loss: 0.04023868590593338
step: 110, loss: 0.03567761182785034
step: 120, loss: 0.04837053269147873
step: 130, loss: 0.1205676943063736
step: 140, loss: 0.00011690437531797215
step: 150, loss: 0.012053314596414566
step: 160, loss: 0.08199339359998703
step: 170, loss: 0.00047039266792126
step: 180, loss: 0.027643777430057526
step: 190, loss: 0.007999422959983349
step: 200, loss: 0.09164334088563919
step: 210, loss: 0.030152618885040283
step: 220, loss: 0.04672110825777054
step: 230, loss: 0.04651845991611481
step: 240, loss: 3.92072724935133e-05
step: 250, loss: 0.06816533207893372
step: 260, loss: 0.011879133991897106
step: 270, loss: 0.08310538530349731
step: 280, loss: 0.0019099705386906862
step: 290, loss: 0.02607111819088459
step: 300, loss: 0.05783233419060707
step: 310, loss: 0.04720578342676163
step: 320, loss: 0.025501195341348648
step: 330, loss: 0.017615975812077522
step: 340, loss: 6.332674092845991e-05
step: 350, loss: 0.019091786816716194
step: 360, loss: 0.04040549695491791
step: 370, loss: 0.038055870682001114
step: 380, loss: 0.04158063977956772
step: 390, loss: 0.07008038461208344
step: 400, loss: 0.019872227683663368
step: 410, loss: 0.018528183922171593
step: 420, loss: 0.021509699523448944
step: 430, loss: 0.053510893136262894
step: 440, loss: 0.02678545191884041
step: 450, loss: 0.0008134131203405559
step: 460, loss: 0.02611427754163742
step: 470, loss: 0.01213075965642929
step: 480, loss: 0.00011739900946849957
step: 490, loss: 0.047360628843307495
step: 500, loss: 0.028424270451068878
step: 510, loss: 1.1745718438760377e-05
step: 520, loss: 0.06348326057195663
step: 530, loss: 0.0009620526107028127
step: 540, loss: 0.13171234726905823
step: 550, loss: 0.018458671867847443
step: 560, loss: 0.04818224161863327
step: 570, loss: 0.016592875123023987
step: 580, loss: 0.039820633828639984
step: 590, loss: 0.08844296634197235
step: 600, loss: 0.005753403063863516
step: 610, loss: 0.08319085836410522
step: 620, loss: 0.027577046304941177
step: 630, loss: 0.12489649653434753
step: 640, loss: 0.07672535628080368
step: 650, loss: 0.029184387996792793
step: 660, loss: 0.037794917821884155
step: 670, loss: 0.05470864847302437
step: 680, loss: 0.07101159542798996
step: 690, loss: 0.019047508016228676
step: 700, loss: 0.05897429957985878
step: 710, loss: 0.06858953833580017
step: 720, loss: 0.06918025761842728
step: 730, loss: 0.0724915936589241
step: 740, loss: 0.07278136909008026
step: 750, loss: 0.020001757889986038
step: 760, loss: 0.08022664487361908
step: 770, loss: 0.019050251692533493
step: 780, loss: 0.08338135480880737
step: 790, loss: 0.0835862010717392
step: 800, loss: 0.050675779581069946
step: 810, loss: 0.02473199926316738
step: 820, loss: 0.02824113890528679
step: 830, loss: 0.038442857563495636
step: 840, loss: 0.051326192915439606
step: 850, loss: 0.0005287898820824921
step: 860, loss: 0.07079069316387177
step: 870, loss: 0.05266168713569641
step: 880, loss: 0.002159343333914876
step: 890, loss: 0.05151895061135292
step: 900, loss: 0.019907712936401367
step: 910, loss: 0.046602241694927216
step: 920, loss: 0.024377264082431793
step: 930, loss: 0.022712238132953644
step: 940, loss: 0.043123967945575714
step: 950, loss: 3.092984115937725e-05
step: 960, loss: 0.005069286562502384
step: 970, loss: 0.032151397317647934
step: 980, loss: 0.010877139866352081
step: 990, loss: 0.05545869469642639
step: 1000, loss: 0.026121672242879868
step: 1010, loss: 0.03214607760310173
step: 1020, loss: 0.10220767557621002
step: 1030, loss: 0.00013321013830136508
step: 1040, loss: 4.094697942491621e-05
step: 1050, loss: 0.05357851833105087
step: 1060, loss: 0.0485999658703804
step: 1070, loss: 0.006318188738077879
epoch 18: dev_f1=0.9273743016759776, f1=0.9253592953175707, best_f1=0.9300602130616026
step: 0, loss: 0.0002669064560905099
step: 10, loss: 0.10664945840835571
step: 20, loss: 0.02532096952199936
step: 30, loss: 0.0014534443616867065
step: 40, loss: 0.05993001163005829
step: 50, loss: 0.01928691752254963
step: 60, loss: 0.03563457354903221
step: 70, loss: 0.031202547252178192
step: 80, loss: 0.050150737166404724
step: 90, loss: 0.007296456955373287
step: 100, loss: 0.02179628796875477
step: 110, loss: 0.016047829762101173
step: 120, loss: 0.05641505494713783
step: 130, loss: 0.030536601319909096
step: 140, loss: 0.0011603905586525798
step: 150, loss: 0.011476214975118637
step: 160, loss: 0.0015927649801597
step: 170, loss: 0.03094864822924137
step: 180, loss: 0.026549354195594788
step: 190, loss: 0.02691527083516121
step: 200, loss: 0.06517690420150757
step: 210, loss: 0.05055803060531616
step: 220, loss: 0.03678516671061516
step: 230, loss: 0.008952037431299686
step: 240, loss: 0.0006800854462198913
step: 250, loss: 0.0032461730297654867
step: 260, loss: 0.018484311178326607
step: 270, loss: 0.045209359377622604
step: 280, loss: 0.03763227164745331
step: 290, loss: 0.024115940555930138
step: 300, loss: 0.0697389543056488
step: 310, loss: 0.06765217334032059
step: 320, loss: 0.0004652401548810303
step: 330, loss: 0.0028732619248330593
step: 340, loss: 0.0016729936469346285
step: 350, loss: 0.061753734946250916
step: 360, loss: 0.008676540106534958
step: 370, loss: 0.12703971564769745
step: 380, loss: 0.0411306768655777
step: 390, loss: 0.03223924711346626
step: 400, loss: 0.04978453740477562
step: 410, loss: 3.285805360064842e-05
step: 420, loss: 0.031138639897108078
step: 430, loss: 0.033817507326602936
step: 440, loss: 0.0346880704164505
step: 450, loss: 0.08798667788505554
step: 460, loss: 0.07322163879871368
step: 470, loss: 0.13504233956336975
step: 480, loss: 0.023090392351150513
step: 490, loss: 0.06921092420816422
step: 500, loss: 0.055300552397966385
step: 510, loss: 0.06234297528862953
step: 520, loss: 0.013394400477409363
step: 530, loss: 0.00017711477994453162
step: 540, loss: 0.05492837354540825
step: 550, loss: 0.08069972693920135
step: 560, loss: 2.0648749341489747e-05
step: 570, loss: 0.031331293284893036
step: 580, loss: 0.016042549163103104
step: 590, loss: 0.048208754509687424
step: 600, loss: 0.09068001806735992
step: 610, loss: 0.0002023687557084486
step: 620, loss: 0.06115920841693878
step: 630, loss: 0.02363603375852108
step: 640, loss: 0.09644424915313721
step: 650, loss: 0.09502910077571869
step: 660, loss: 0.12141560018062592
step: 670, loss: 0.05638466402888298
step: 680, loss: 0.05923560634255409
step: 690, loss: 0.07573483139276505
step: 700, loss: 0.0014097723178565502
step: 710, loss: 0.038967736065387726
step: 720, loss: 0.06279686093330383
step: 730, loss: 0.00015860874555073678
step: 740, loss: 0.016780272126197815
step: 750, loss: 0.05009922385215759
step: 760, loss: 0.07067131251096725
step: 770, loss: 0.03784755617380142
step: 780, loss: 0.05441717058420181
step: 790, loss: 0.00019619773956947029
step: 800, loss: 0.11565887182950974
step: 810, loss: 0.00012936840357724577
step: 820, loss: 0.07755906134843826
step: 830, loss: 0.01355304941534996
step: 840, loss: 0.03738437965512276
step: 850, loss: 0.09103934466838837
step: 860, loss: 0.05763452500104904
step: 870, loss: 0.006079661659896374
step: 880, loss: 0.00015425006859004498
step: 890, loss: 1.696088475000579e-05
step: 900, loss: 0.06428506970405579
step: 910, loss: 0.000594082404859364
step: 920, loss: 0.13526922464370728
step: 930, loss: 0.06995967030525208
step: 940, loss: 0.044424351304769516
step: 950, loss: 0.020727291703224182
step: 960, loss: 0.001974454615265131
step: 970, loss: 0.024712007492780685
step: 980, loss: 0.0187595933675766
step: 990, loss: 0.04395338520407677
step: 1000, loss: 2.424235390208196e-05
step: 1010, loss: 2.50330976996338e-05
step: 1020, loss: 0.04896897077560425
step: 1030, loss: 0.0007764579495415092
step: 1040, loss: 0.01654142513871193
step: 1050, loss: 0.041427746415138245
step: 1060, loss: 0.025091344490647316
step: 1070, loss: 0.08611923456192017
epoch 19: dev_f1=0.9277279168634862, f1=0.9263256687001408, best_f1=0.9300602130616026
step: 0, loss: 0.031783975660800934
step: 10, loss: 0.12792086601257324
step: 20, loss: 0.1003640815615654
step: 30, loss: 0.008522950112819672
step: 40, loss: 5.139941640663892e-05
step: 50, loss: 7.53636923036538e-05
step: 60, loss: 0.03511067107319832
step: 70, loss: 0.0468023382127285
step: 80, loss: 0.03626721352338791
step: 90, loss: 0.03832795470952988
step: 100, loss: 0.0662904605269432
step: 110, loss: 0.040940579026937485
step: 120, loss: 0.057706572115421295
step: 130, loss: 0.051890984177589417
step: 140, loss: 0.09451353549957275
step: 150, loss: 0.04916086047887802
step: 160, loss: 0.03525572270154953
step: 170, loss: 0.014238924719393253
step: 180, loss: 2.7885151212103665e-05
step: 190, loss: 0.026490747928619385
step: 200, loss: 0.035307835787534714
step: 210, loss: 0.05208301171660423
step: 220, loss: 0.0005976758548058569
step: 230, loss: 0.04186580330133438
step: 240, loss: 0.029851041734218597
step: 250, loss: 0.013459430076181889
step: 260, loss: 0.0789082944393158
step: 270, loss: 0.014124410226941109
step: 280, loss: 0.07224005460739136
step: 290, loss: 0.06961272656917572
step: 300, loss: 0.05323261395096779
step: 310, loss: 0.04979541897773743
step: 320, loss: 0.047037191689014435
step: 330, loss: 0.05707406997680664
step: 340, loss: 0.08448667824268341
step: 350, loss: 0.02056250162422657
step: 360, loss: 0.03642242029309273
step: 370, loss: 0.03758975490927696
step: 380, loss: 0.014591408893465996
step: 390, loss: 0.02922387234866619
step: 400, loss: 0.036576297134160995
step: 410, loss: 0.02718532271683216
step: 420, loss: 0.09844186902046204
step: 430, loss: 0.08680685609579086
step: 440, loss: 0.33077380061149597
step: 450, loss: 0.01886703632771969
step: 460, loss: 0.03817914426326752
step: 470, loss: 0.001364403055049479
step: 480, loss: 0.08154327422380447
step: 490, loss: 0.03393273800611496
step: 500, loss: 0.0839281901717186
step: 510, loss: 0.008332379162311554
step: 520, loss: 0.02221488766372204
step: 530, loss: 0.02320919930934906
step: 540, loss: 0.0756349265575409
step: 550, loss: 0.05085703730583191
step: 560, loss: 0.009450842626392841
step: 570, loss: 0.04116322472691536
step: 580, loss: 0.04564277082681656
step: 590, loss: 0.0002896063379012048
step: 600, loss: 3.950484824599698e-05
step: 610, loss: 0.06335166096687317
step: 620, loss: 0.00022187539434526116
step: 630, loss: 0.0439831018447876
step: 640, loss: 0.015422707423567772
step: 650, loss: 0.04529784992337227
step: 660, loss: 0.10964928567409515
step: 670, loss: 0.05972932651638985
step: 680, loss: 3.05414832837414e-05
step: 690, loss: 0.010163070634007454
step: 700, loss: 0.02825072780251503
step: 710, loss: 0.05516061186790466
step: 720, loss: 0.001925295335240662
step: 730, loss: 0.09380444139242172
step: 740, loss: 0.03741725534200668
step: 750, loss: 0.06209798529744148
step: 760, loss: 0.10488779097795486
step: 770, loss: 0.008502254262566566
step: 780, loss: 0.05832661688327789
step: 790, loss: 0.034210264682769775
step: 800, loss: 0.021609559655189514
step: 810, loss: 0.015584534965455532
step: 820, loss: 0.05573825538158417
step: 830, loss: 0.03941650688648224
step: 840, loss: 0.1995851844549179
step: 850, loss: 5.775310637545772e-05
step: 860, loss: 0.05449901893734932
step: 870, loss: 0.011772427707910538
step: 880, loss: 0.00030289238202385604
step: 890, loss: 0.0710068792104721
step: 900, loss: 0.0004815468564629555
step: 910, loss: 8.963290747487918e-05
step: 920, loss: 0.026056908071041107
step: 930, loss: 0.009051412343978882
step: 940, loss: 0.05002686753869057
step: 950, loss: 0.14010000228881836
step: 960, loss: 0.05988841503858566
step: 970, loss: 0.04006881266832352
step: 980, loss: 0.09361032396554947
step: 990, loss: 0.017308436334133148
step: 1000, loss: 0.07015955448150635
step: 1010, loss: 0.018648818135261536
step: 1020, loss: 0.02122814767062664
step: 1030, loss: 0.0006168045219965279
step: 1040, loss: 0.0026820905040949583
step: 1050, loss: 0.05795757845044136
step: 1060, loss: 0.017925206571817398
step: 1070, loss: 4.8501362471142784e-05
epoch 20: dev_f1=0.9266697804764129, f1=0.9281716417910447, best_f1=0.9300602130616026
