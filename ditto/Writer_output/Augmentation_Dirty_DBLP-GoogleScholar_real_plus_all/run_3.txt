cuda
Device: cuda
step: 0, loss: 0.7463399171829224
step: 10, loss: 0.4912237226963043
step: 20, loss: 0.6011382341384888
step: 30, loss: 0.484230101108551
step: 40, loss: 0.2683236002922058
step: 50, loss: 0.18689309060573578
step: 60, loss: 0.45959606766700745
step: 70, loss: 0.22354747354984283
step: 80, loss: 0.23646703362464905
step: 90, loss: 0.22088900208473206
step: 100, loss: 0.300033301115036
step: 110, loss: 0.2622250020503998
step: 120, loss: 0.2155357450246811
step: 130, loss: 0.20143190026283264
step: 140, loss: 0.1186671108007431
step: 150, loss: 0.1453961431980133
step: 160, loss: 0.1563665121793747
step: 170, loss: 0.07331478595733643
step: 180, loss: 0.07719707489013672
step: 190, loss: 0.11889943480491638
step: 200, loss: 0.3374723196029663
step: 210, loss: 0.0941322073340416
step: 220, loss: 0.1443590670824051
step: 230, loss: 0.14278845489025116
step: 240, loss: 0.08614569902420044
step: 250, loss: 0.19867976009845734
step: 260, loss: 0.0917973741889
step: 270, loss: 0.05125872790813446
step: 280, loss: 0.23887580633163452
step: 290, loss: 0.25147923827171326
step: 300, loss: 0.25166088342666626
step: 310, loss: 0.15780609846115112
step: 320, loss: 0.11944004148244858
step: 330, loss: 0.27555882930755615
step: 340, loss: 0.24518656730651855
step: 350, loss: 0.22735561430454254
step: 360, loss: 0.19474318623542786
step: 370, loss: 0.07408066093921661
step: 380, loss: 0.1294790506362915
step: 390, loss: 0.16810177266597748
step: 400, loss: 0.07570512592792511
step: 410, loss: 0.17864543199539185
step: 420, loss: 0.062116097658872604
step: 430, loss: 0.14348658919334412
step: 440, loss: 0.20364978909492493
step: 450, loss: 0.09549301862716675
step: 460, loss: 0.21925491094589233
step: 470, loss: 0.037031788378953934
step: 480, loss: 0.1746649593114853
step: 490, loss: 0.04060196131467819
step: 500, loss: 0.12127939611673355
step: 510, loss: 0.11246490478515625
step: 520, loss: 0.1341450959444046
step: 530, loss: 0.16685259342193604
step: 540, loss: 0.08054027706384659
step: 550, loss: 0.18103326857089996
step: 560, loss: 0.19963741302490234
step: 570, loss: 0.037125732749700546
step: 580, loss: 0.07085847109556198
step: 590, loss: 0.13202820718288422
step: 600, loss: 0.19352301955223083
step: 610, loss: 0.1360504925251007
step: 620, loss: 0.08127027004957199
step: 630, loss: 0.10407813638448715
step: 640, loss: 0.24558240175247192
step: 650, loss: 0.24308057129383087
step: 660, loss: 0.18184320628643036
step: 670, loss: 0.1748269945383072
step: 680, loss: 0.13590401411056519
step: 690, loss: 0.0886126235127449
step: 700, loss: 0.03285399451851845
step: 710, loss: 0.1281747668981552
step: 720, loss: 0.15739907324314117
step: 730, loss: 0.13345123827457428
step: 740, loss: 0.16709332168102264
step: 750, loss: 0.06964536011219025
step: 760, loss: 0.2913513481616974
step: 770, loss: 0.11167936772108078
step: 780, loss: 0.1451464593410492
step: 790, loss: 0.1859903186559677
step: 800, loss: 0.16869427263736725
step: 810, loss: 0.16892993450164795
step: 820, loss: 0.07299608737230301
step: 830, loss: 0.15525859594345093
step: 840, loss: 0.24004147946834564
step: 850, loss: 0.03693845868110657
step: 860, loss: 0.11369498819112778
step: 870, loss: 0.09753244370222092
step: 880, loss: 0.14046917855739594
step: 890, loss: 0.1347525417804718
step: 900, loss: 0.14741574227809906
step: 910, loss: 0.1187274158000946
step: 920, loss: 0.2328893393278122
step: 930, loss: 0.11637482047080994
step: 940, loss: 0.03712949901819229
step: 950, loss: 0.15893340110778809
step: 960, loss: 0.21463769674301147
step: 970, loss: 0.10729788988828659
step: 980, loss: 0.07780702412128448
step: 990, loss: 0.2407604306936264
step: 1000, loss: 0.0846463292837143
step: 1010, loss: 0.12477924674749374
step: 1020, loss: 0.033996567130088806
step: 1030, loss: 0.05142330005764961
step: 1040, loss: 0.19107982516288757
step: 1050, loss: 0.14854323863983154
step: 1060, loss: 0.10215507447719574
step: 1070, loss: 0.03669625148177147
epoch 1: dev_f1=0.9306654257794322, f1=0.9331476323119777, best_f1=0.9331476323119777
step: 0, loss: 0.13483940064907074
step: 10, loss: 0.05891988426446915
step: 20, loss: 0.12391829490661621
step: 30, loss: 0.16033200919628143
step: 40, loss: 0.12207438796758652
step: 50, loss: 0.1831263154745102
step: 60, loss: 0.10528407245874405
step: 70, loss: 0.06476573646068573
step: 80, loss: 0.028565533459186554
step: 90, loss: 0.11610009521245956
step: 100, loss: 0.05292591452598572
step: 110, loss: 0.1500573605298996
step: 120, loss: 0.22253534197807312
step: 130, loss: 0.03832627832889557
step: 140, loss: 0.06645429879426956
step: 150, loss: 0.17835302650928497
step: 160, loss: 0.18305028975009918
step: 170, loss: 0.10940913110971451
step: 180, loss: 0.09484737366437912
step: 190, loss: 0.13609342277050018
step: 200, loss: 0.2054567188024521
step: 210, loss: 0.07611283659934998
step: 220, loss: 0.10043878108263016
step: 230, loss: 0.15340453386306763
step: 240, loss: 0.21783702075481415
step: 250, loss: 0.20444199442863464
step: 260, loss: 0.14139118790626526
step: 270, loss: 0.13410738110542297
step: 280, loss: 0.10341053456068039
step: 290, loss: 0.1954570710659027
step: 300, loss: 0.1608545482158661
step: 310, loss: 0.09859370440244675
step: 320, loss: 0.21012887358665466
step: 330, loss: 0.06698918342590332
step: 340, loss: 0.06367948651313782
step: 350, loss: 0.4043271541595459
step: 360, loss: 0.37717270851135254
step: 370, loss: 0.16147567331790924
step: 380, loss: 0.10177796334028244
step: 390, loss: 0.19786012172698975
step: 400, loss: 0.16505330801010132
step: 410, loss: 0.15626737475395203
step: 420, loss: 0.11888071894645691
step: 430, loss: 0.07702947407960892
step: 440, loss: 0.10926885902881622
step: 450, loss: 0.1361897587776184
step: 460, loss: 0.2742699682712555
step: 470, loss: 0.18623042106628418
step: 480, loss: 0.1617637425661087
step: 490, loss: 0.13633222877979279
step: 500, loss: 0.1214190423488617
step: 510, loss: 0.05402166768908501
step: 520, loss: 0.1317874640226364
step: 530, loss: 0.012576942332088947
step: 540, loss: 0.13574884831905365
step: 550, loss: 0.05697246268391609
step: 560, loss: 0.1256086528301239
step: 570, loss: 0.11672907322645187
step: 580, loss: 0.04841610789299011
step: 590, loss: 0.15089820325374603
step: 600, loss: 0.06212381273508072
step: 610, loss: 0.15865814685821533
step: 620, loss: 0.09156201779842377
step: 630, loss: 0.0664348229765892
step: 640, loss: 0.12152464687824249
step: 650, loss: 0.15527674555778503
step: 660, loss: 0.15839087963104248
step: 670, loss: 0.09782972931861877
step: 680, loss: 0.1258961260318756
step: 690, loss: 0.12565480172634125
step: 700, loss: 0.1528882086277008
step: 710, loss: 0.1295929253101349
step: 720, loss: 0.10748893022537231
step: 730, loss: 0.2985976040363312
step: 740, loss: 0.13385669887065887
step: 750, loss: 0.06484682112932205
step: 760, loss: 0.11143875122070312
step: 770, loss: 0.19759219884872437
step: 780, loss: 0.23459011316299438
step: 790, loss: 0.06778494268655777
step: 800, loss: 0.23483391106128693
step: 810, loss: 0.09368137270212173
step: 820, loss: 0.16516925394535065
step: 830, loss: 0.12992067635059357
step: 840, loss: 0.1396676003932953
step: 850, loss: 0.12085599452257156
step: 860, loss: 0.09586486220359802
step: 870, loss: 0.0866239070892334
step: 880, loss: 0.12110064923763275
step: 890, loss: 0.07306654751300812
step: 900, loss: 0.13902591168880463
step: 910, loss: 0.13583062589168549
step: 920, loss: 0.34420260787010193
step: 930, loss: 0.3080325722694397
step: 940, loss: 0.09633351117372513
step: 950, loss: 0.07178191840648651
step: 960, loss: 0.1664203405380249
step: 970, loss: 0.07699283957481384
step: 980, loss: 0.09769280254840851
step: 990, loss: 0.09562630951404572
step: 1000, loss: 0.19915392994880676
step: 1010, loss: 0.15302984416484833
step: 1020, loss: 0.11870077252388
step: 1030, loss: 0.12254740297794342
step: 1040, loss: 0.12242305278778076
step: 1050, loss: 0.16398660838603973
step: 1060, loss: 0.10509868711233139
step: 1070, loss: 0.12055875360965729
epoch 2: dev_f1=0.9351251158480075, f1=0.9338338808071328, best_f1=0.9338338808071328
step: 0, loss: 0.07667934149503708
step: 10, loss: 0.14785054326057434
step: 20, loss: 0.05988387390971184
step: 30, loss: 0.19586172699928284
step: 40, loss: 0.12849684059619904
step: 50, loss: 0.11312539875507355
step: 60, loss: 0.17051368951797485
step: 70, loss: 0.18090130388736725
step: 80, loss: 0.0610988549888134
step: 90, loss: 0.008454552851617336
step: 100, loss: 0.056188348680734634
step: 110, loss: 0.06085865572094917
step: 120, loss: 0.06984918564558029
step: 130, loss: 0.08963901549577713
step: 140, loss: 0.09676767140626907
step: 150, loss: 0.0779314860701561
step: 160, loss: 0.1494290679693222
step: 170, loss: 0.03845803439617157
step: 180, loss: 0.11097922921180725
step: 190, loss: 0.042874984443187714
step: 200, loss: 0.11810565739870071
step: 210, loss: 0.013206060975790024
step: 220, loss: 0.12066635489463806
step: 230, loss: 0.1336870640516281
step: 240, loss: 0.09639942646026611
step: 250, loss: 0.059342410415410995
step: 260, loss: 0.11572049558162689
step: 270, loss: 0.1618172824382782
step: 280, loss: 0.028152991086244583
step: 290, loss: 0.06640880554914474
step: 300, loss: 0.0521225742995739
step: 310, loss: 0.028714876621961594
step: 320, loss: 0.03421463444828987
step: 330, loss: 0.19633731245994568
step: 340, loss: 0.1064905971288681
step: 350, loss: 0.12709185481071472
step: 360, loss: 0.10870172828435898
step: 370, loss: 0.08894915878772736
step: 380, loss: 0.14187495410442352
step: 390, loss: 0.1320306360721588
step: 400, loss: 0.14073194563388824
step: 410, loss: 0.15020449459552765
step: 420, loss: 0.07851753383874893
step: 430, loss: 0.07189575582742691
step: 440, loss: 0.009565098211169243
step: 450, loss: 0.021774787455797195
step: 460, loss: 0.1576799899339676
step: 470, loss: 0.195830300450325
step: 480, loss: 0.09077112376689911
step: 490, loss: 0.16103726625442505
step: 500, loss: 0.08008460700511932
step: 510, loss: 0.09412702918052673
step: 520, loss: 0.10511784255504608
step: 530, loss: 0.025981023907661438
step: 540, loss: 0.09382350742816925
step: 550, loss: 0.053674668073654175
step: 560, loss: 0.1124219298362732
step: 570, loss: 0.11623448133468628
step: 580, loss: 0.09708192944526672
step: 590, loss: 0.16688382625579834
step: 600, loss: 0.10832851380109787
step: 610, loss: 0.02564219757914543
step: 620, loss: 0.1486360728740692
step: 630, loss: 0.16100822389125824
step: 640, loss: 0.19012650847434998
step: 650, loss: 0.10926838219165802
step: 660, loss: 0.17054247856140137
step: 670, loss: 0.10727949440479279
step: 680, loss: 0.1850065290927887
step: 690, loss: 0.13695651292800903
step: 700, loss: 0.04802987724542618
step: 710, loss: 0.056722719222307205
step: 720, loss: 0.0898117795586586
step: 730, loss: 0.2782425880432129
step: 740, loss: 0.07703543454408646
step: 750, loss: 0.19525954127311707
step: 760, loss: 0.14552998542785645
step: 770, loss: 0.08188304305076599
step: 780, loss: 0.09162416309118271
step: 790, loss: 0.11709275841712952
step: 800, loss: 0.14625144004821777
step: 810, loss: 0.13989077508449554
step: 820, loss: 0.15192611515522003
step: 830, loss: 0.14102177321910858
step: 840, loss: 0.2171141803264618
step: 850, loss: 0.1714043915271759
step: 860, loss: 0.14183831214904785
step: 870, loss: 0.24819427728652954
step: 880, loss: 0.10294201225042343
step: 890, loss: 0.1591230034828186
step: 900, loss: 0.11033397912979126
step: 910, loss: 0.03208260238170624
step: 920, loss: 0.05315535143017769
step: 930, loss: 0.021245453506708145
step: 940, loss: 0.07208926230669022
step: 950, loss: 0.11389337480068207
step: 960, loss: 0.08769778162240982
step: 970, loss: 0.3484274744987488
step: 980, loss: 0.2318369746208191
step: 990, loss: 0.2821611762046814
step: 1000, loss: 0.10373625159263611
step: 1010, loss: 0.06384798884391785
step: 1020, loss: 0.1785917729139328
step: 1030, loss: 0.15650582313537598
step: 1040, loss: 0.06522782891988754
step: 1050, loss: 0.11549393087625504
step: 1060, loss: 0.10674569010734558
step: 1070, loss: 0.24611930549144745
epoch 3: dev_f1=0.9250340754202635, f1=0.9233576642335766, best_f1=0.9338338808071328
step: 0, loss: 0.03805937618017197
step: 10, loss: 0.07164318114519119
step: 20, loss: 0.02383853867650032
step: 30, loss: 0.10035288333892822
step: 40, loss: 0.05737680941820145
step: 50, loss: 0.08567662537097931
step: 60, loss: 0.011044039390981197
step: 70, loss: 0.0570605993270874
step: 80, loss: 0.09745775908231735
step: 90, loss: 0.13658033311367035
step: 100, loss: 0.02706879936158657
step: 110, loss: 0.15954233705997467
step: 120, loss: 0.05209321528673172
step: 130, loss: 0.10931973159313202
step: 140, loss: 0.12797562777996063
step: 150, loss: 0.11762288957834244
step: 160, loss: 0.16751877963542938
step: 170, loss: 0.04685210809111595
step: 180, loss: 0.03974989056587219
step: 190, loss: 0.12574321031570435
step: 200, loss: 0.09621420502662659
step: 210, loss: 0.0686180591583252
step: 220, loss: 0.3916119933128357
step: 230, loss: 0.05549776181578636
step: 240, loss: 0.06271219998598099
step: 250, loss: 0.06694403290748596
step: 260, loss: 0.08696133643388748
step: 270, loss: 0.09774783253669739
step: 280, loss: 0.08287126570940018
step: 290, loss: 0.07257585972547531
step: 300, loss: 0.07644251734018326
step: 310, loss: 0.2420354187488556
step: 320, loss: 0.10139945894479752
step: 330, loss: 0.08233992010354996
step: 340, loss: 0.15884551405906677
step: 350, loss: 0.04669792577624321
step: 360, loss: 0.07767825573682785
step: 370, loss: 0.12007854878902435
step: 380, loss: 0.05995563417673111
step: 390, loss: 0.1391327977180481
step: 400, loss: 0.06331508606672287
step: 410, loss: 0.0861431211233139
step: 420, loss: 0.1707996129989624
step: 430, loss: 0.2211952656507492
step: 440, loss: 0.11405286192893982
step: 450, loss: 0.15448719263076782
step: 460, loss: 0.06174477934837341
step: 470, loss: 0.06368189305067062
step: 480, loss: 0.0781509131193161
step: 490, loss: 0.0801200345158577
step: 500, loss: 0.07309341430664062
step: 510, loss: 0.21758192777633667
step: 520, loss: 0.09993048012256622
step: 530, loss: 0.06041014939546585
step: 540, loss: 0.07107429951429367
step: 550, loss: 0.14394019544124603
step: 560, loss: 0.1906868815422058
step: 570, loss: 0.15739022195339203
step: 580, loss: 0.043461695313453674
step: 590, loss: 0.027561485767364502
step: 600, loss: 0.10550850629806519
step: 610, loss: 0.17958682775497437
step: 620, loss: 0.02906251884996891
step: 630, loss: 0.1518258899450302
step: 640, loss: 0.1532377004623413
step: 650, loss: 0.1660064458847046
step: 660, loss: 0.09649347513914108
step: 670, loss: 0.09151657670736313
step: 680, loss: 0.03741813823580742
step: 690, loss: 0.05652525648474693
step: 700, loss: 0.05570777878165245
step: 710, loss: 0.02575734257698059
step: 720, loss: 0.09959953278303146
step: 730, loss: 0.13371425867080688
step: 740, loss: 0.15065820515155792
step: 750, loss: 0.06710556894540787
step: 760, loss: 0.2019050568342209
step: 770, loss: 0.02211851067841053
step: 780, loss: 0.11154085397720337
step: 790, loss: 0.04943389818072319
step: 800, loss: 0.06246291473507881
step: 810, loss: 0.16431109607219696
step: 820, loss: 0.03879309445619583
step: 830, loss: 0.13437342643737793
step: 840, loss: 0.12378887832164764
step: 850, loss: 0.13331076502799988
step: 860, loss: 0.0761767253279686
step: 870, loss: 0.0815744400024414
step: 880, loss: 0.19731688499450684
step: 890, loss: 0.09476816654205322
step: 900, loss: 0.03587055951356888
step: 910, loss: 0.029860325157642365
step: 920, loss: 0.08211272954940796
step: 930, loss: 0.156357079744339
step: 940, loss: 0.045757945626974106
step: 950, loss: 0.18763066828250885
step: 960, loss: 0.06676581501960754
step: 970, loss: 0.022115008905529976
step: 980, loss: 0.08331544697284698
step: 990, loss: 0.09356100857257843
step: 1000, loss: 0.06032470986247063
step: 1010, loss: 0.03455282375216484
step: 1020, loss: 0.13704779744148254
step: 1030, loss: 0.11398839950561523
step: 1040, loss: 0.01629195548593998
step: 1050, loss: 0.23971882462501526
step: 1060, loss: 0.12715531885623932
step: 1070, loss: 0.15879499912261963
epoch 4: dev_f1=0.9303167420814479, f1=0.929384965831435, best_f1=0.9338338808071328
step: 0, loss: 0.028885208070278168
step: 10, loss: 0.06094275042414665
step: 20, loss: 0.05612855777144432
step: 30, loss: 0.059313446283340454
step: 40, loss: 0.07620658725500107
step: 50, loss: 0.14863251149654388
step: 60, loss: 0.16523028910160065
step: 70, loss: 0.05997984856367111
step: 80, loss: 0.20817983150482178
step: 90, loss: 0.1539754569530487
step: 100, loss: 0.07926341891288757
step: 110, loss: 0.03875265270471573
step: 120, loss: 0.06021310016512871
step: 130, loss: 0.05196802318096161
step: 140, loss: 0.07160203158855438
step: 150, loss: 0.013044488616287708
step: 160, loss: 0.024266237393021584
step: 170, loss: 0.08090899139642715
step: 180, loss: 0.1290069818496704
step: 190, loss: 0.10239677131175995
step: 200, loss: 0.03864353522658348
step: 210, loss: 0.021797334775328636
step: 220, loss: 0.1196221336722374
step: 230, loss: 0.049041107296943665
step: 240, loss: 0.10424304753541946
step: 250, loss: 0.1429082155227661
step: 260, loss: 0.09676432609558105
step: 270, loss: 0.06373026967048645
step: 280, loss: 0.07278834283351898
step: 290, loss: 0.09726467728614807
step: 300, loss: 0.06790255010128021
step: 310, loss: 0.3027099072933197
step: 320, loss: 0.24453121423721313
step: 330, loss: 0.10709986835718155
step: 340, loss: 0.1413935124874115
step: 350, loss: 0.16839374601840973
step: 360, loss: 0.11807796359062195
step: 370, loss: 0.057454030960798264
step: 380, loss: 0.1072661280632019
step: 390, loss: 0.10158159583806992
step: 400, loss: 0.015197329223155975
step: 410, loss: 0.0721445232629776
step: 420, loss: 0.10790184140205383
step: 430, loss: 0.10949521511793137
step: 440, loss: 0.09588826447725296
step: 450, loss: 0.04912147670984268
step: 460, loss: 0.11298245191574097
step: 470, loss: 0.261948823928833
step: 480, loss: 0.11846144497394562
step: 490, loss: 0.08068570494651794
step: 500, loss: 0.035431958734989166
step: 510, loss: 0.04836936295032501
step: 520, loss: 0.09469122439622879
step: 530, loss: 0.08346504718065262
step: 540, loss: 0.18290017545223236
step: 550, loss: 0.023183856159448624
step: 560, loss: 0.0045683071948587894
step: 570, loss: 0.07772555202245712
step: 580, loss: 0.12438063323497772
step: 590, loss: 0.13822290301322937
step: 600, loss: 0.03585034981369972
step: 610, loss: 0.17549331486225128
step: 620, loss: 0.049476753920316696
step: 630, loss: 0.04545506462454796
step: 640, loss: 0.07965543866157532
step: 650, loss: 0.10117614269256592
step: 660, loss: 0.08422592282295227
step: 670, loss: 0.06074425205588341
step: 680, loss: 0.08076551556587219
step: 690, loss: 0.08466513454914093
step: 700, loss: 0.05105498433113098
step: 710, loss: 0.10213609039783478
step: 720, loss: 0.04149000719189644
step: 730, loss: 0.1831461787223816
step: 740, loss: 0.08629240095615387
step: 750, loss: 0.0490243025124073
step: 760, loss: 0.07470893859863281
step: 770, loss: 0.16105356812477112
step: 780, loss: 0.1170826107263565
step: 790, loss: 0.05938548222184181
step: 800, loss: 0.1140698567032814
step: 810, loss: 0.059118375182151794
step: 820, loss: 0.15089961886405945
step: 830, loss: 0.04773414507508278
step: 840, loss: 0.10429482161998749
step: 850, loss: 0.09450593590736389
step: 860, loss: 0.06704594194889069
step: 870, loss: 0.10103430598974228
step: 880, loss: 0.15748319029808044
step: 890, loss: 0.042944543063640594
step: 900, loss: 0.0546254999935627
step: 910, loss: 0.05070602148771286
step: 920, loss: 0.10275966674089432
step: 930, loss: 0.16937141120433807
step: 940, loss: 0.03665211424231529
step: 950, loss: 0.2288433164358139
step: 960, loss: 0.05426967889070511
step: 970, loss: 0.12236591428518295
step: 980, loss: 0.07872051000595093
step: 990, loss: 0.1286221146583557
step: 1000, loss: 0.05929035693407059
step: 1010, loss: 0.038659803569316864
step: 1020, loss: 0.10417190939188004
step: 1030, loss: 0.061829548329114914
step: 1040, loss: 0.027915699407458305
step: 1050, loss: 0.009834205731749535
step: 1060, loss: 0.0967441275715828
step: 1070, loss: 0.05763869732618332
epoch 5: dev_f1=0.9252003561887799, f1=0.9212175470008952, best_f1=0.9338338808071328
step: 0, loss: 0.1091160774230957
step: 10, loss: 0.044041309505701065
step: 20, loss: 0.05518781393766403
step: 30, loss: 0.061911243945360184
step: 40, loss: 0.06111691892147064
step: 50, loss: 0.052882056683301926
step: 60, loss: 0.11118808388710022
step: 70, loss: 0.04476044699549675
step: 80, loss: 0.12712816894054413
step: 90, loss: 0.031177643686532974
step: 100, loss: 0.029987378045916557
step: 110, loss: 0.022433027625083923
step: 120, loss: 0.1893569380044937
step: 130, loss: 0.017108144238591194
step: 140, loss: 0.08733311295509338
step: 150, loss: 0.022107549011707306
step: 160, loss: 0.0567491240799427
step: 170, loss: 0.10023456811904907
step: 180, loss: 0.11012419313192368
step: 190, loss: 0.1811818778514862
step: 200, loss: 0.14204227924346924
step: 210, loss: 0.019110972061753273
step: 220, loss: 0.10069245100021362
step: 230, loss: 0.09127753973007202
step: 240, loss: 0.04003341868519783
step: 250, loss: 0.20437327027320862
step: 260, loss: 0.06683430075645447
step: 270, loss: 0.08308538794517517
step: 280, loss: 0.09841381758451462
step: 290, loss: 0.06521718204021454
step: 300, loss: 0.02575737237930298
step: 310, loss: 0.1623470038175583
step: 320, loss: 0.12250259518623352
step: 330, loss: 0.0914117619395256
step: 340, loss: 0.0529949776828289
step: 350, loss: 0.012602768838405609
step: 360, loss: 0.14408375322818756
step: 370, loss: 0.1117280125617981
step: 380, loss: 0.06250622868537903
step: 390, loss: 0.187993124127388
step: 400, loss: 0.09278319776058197
step: 410, loss: 0.1271955370903015
step: 420, loss: 0.14513139426708221
step: 430, loss: 0.02456437423825264
step: 440, loss: 0.04061518982052803
step: 450, loss: 0.11110664159059525
step: 460, loss: 0.03285800293087959
step: 470, loss: 0.08671493083238602
step: 480, loss: 0.1252559870481491
step: 490, loss: 0.1792316734790802
step: 500, loss: 0.1384945511817932
step: 510, loss: 0.00712135573849082
step: 520, loss: 0.09810838848352432
step: 530, loss: 0.09614558517932892
step: 540, loss: 0.029203133657574654
step: 550, loss: 0.18304656445980072
step: 560, loss: 0.09223724901676178
step: 570, loss: 0.07888546586036682
step: 580, loss: 0.13355962932109833
step: 590, loss: 0.10695677250623703
step: 600, loss: 0.022177569568157196
step: 610, loss: 0.036762986332178116
step: 620, loss: 0.15830391645431519
step: 630, loss: 0.03978085517883301
step: 640, loss: 0.06109181419014931
step: 650, loss: 0.057306915521621704
step: 660, loss: 0.05587237328290939
step: 670, loss: 0.07788112014532089
step: 680, loss: 0.05731886252760887
step: 690, loss: 0.07561870664358139
step: 700, loss: 0.059365544468164444
step: 710, loss: 0.06761222332715988
step: 720, loss: 0.06343398243188858
step: 730, loss: 0.12481145560741425
step: 740, loss: 0.08052024245262146
step: 750, loss: 0.06366970390081406
step: 760, loss: 0.06260865181684494
step: 770, loss: 0.09620741009712219
step: 780, loss: 0.09360750019550323
step: 790, loss: 0.07454060763120651
step: 800, loss: 0.05053214728832245
step: 810, loss: 0.20941439270973206
step: 820, loss: 0.033010877668857574
step: 830, loss: 0.1054554358124733
step: 840, loss: 0.1600492149591446
step: 850, loss: 0.12967507541179657
step: 860, loss: 0.2191188931465149
step: 870, loss: 0.19163750112056732
step: 880, loss: 0.04743557795882225
step: 890, loss: 0.0997261106967926
step: 900, loss: 0.08993242681026459
step: 910, loss: 0.13588199019432068
step: 920, loss: 0.05389659106731415
step: 930, loss: 0.09473125636577606
step: 940, loss: 0.025509968400001526
step: 950, loss: 0.1808864027261734
step: 960, loss: 0.07801300287246704
step: 970, loss: 0.09194191545248032
step: 980, loss: 0.06198285520076752
step: 990, loss: 0.029870813712477684
step: 1000, loss: 0.07608494907617569
step: 1010, loss: 0.0932004377245903
step: 1020, loss: 0.06687998026609421
step: 1030, loss: 0.05374613776803017
step: 1040, loss: 0.03669259324669838
step: 1050, loss: 0.08516722917556763
step: 1060, loss: 0.11114393174648285
step: 1070, loss: 0.09681488573551178
epoch 6: dev_f1=0.9284712482468443, f1=0.9307116104868914, best_f1=0.9338338808071328
step: 0, loss: 0.0503203347325325
step: 10, loss: 0.12142380326986313
step: 20, loss: 0.09115713089704514
step: 30, loss: 0.08387266099452972
step: 40, loss: 0.042066093534231186
step: 50, loss: 0.09980519115924835
step: 60, loss: 0.01871178112924099
step: 70, loss: 0.10891860723495483
step: 80, loss: 0.0898975357413292
step: 90, loss: 0.05785878747701645
step: 100, loss: 0.06339317560195923
step: 110, loss: 0.04116599261760712
step: 120, loss: 0.044850531965494156
step: 130, loss: 0.08893654495477676
step: 140, loss: 0.039669740945100784
step: 150, loss: 0.08310247212648392
step: 160, loss: 0.050442300736904144
step: 170, loss: 0.003680181922391057
step: 180, loss: 0.03516615927219391
step: 190, loss: 0.08850982785224915
step: 200, loss: 0.08347568660974503
step: 210, loss: 0.04800291731953621
step: 220, loss: 0.058729954063892365
step: 230, loss: 0.03357963263988495
step: 240, loss: 0.13330477476119995
step: 250, loss: 0.15392521023750305
step: 260, loss: 0.04876496270298958
step: 270, loss: 0.014955994673073292
step: 280, loss: 0.038306016474962234
step: 290, loss: 0.06907737255096436
step: 300, loss: 0.10944173485040665
step: 310, loss: 0.10680355876684189
step: 320, loss: 0.054294511675834656
step: 330, loss: 0.12529146671295166
step: 340, loss: 0.1277117282152176
step: 350, loss: 0.07175689190626144
step: 360, loss: 0.07322094589471817
step: 370, loss: 0.06859864294528961
step: 380, loss: 0.11863187700510025
step: 390, loss: 0.0429941825568676
step: 400, loss: 0.10993432998657227
step: 410, loss: 0.06204074248671532
step: 420, loss: 0.09746991097927094
step: 430, loss: 0.16374757885932922
step: 440, loss: 0.07857457548379898
step: 450, loss: 0.013053033500909805
step: 460, loss: 0.08747617900371552
step: 470, loss: 0.08335184305906296
step: 480, loss: 0.07172957807779312
step: 490, loss: 0.17546513676643372
step: 500, loss: 0.17614659667015076
step: 510, loss: 0.09394238144159317
step: 520, loss: 0.08792610466480255
step: 530, loss: 0.23610424995422363
step: 540, loss: 0.022486630827188492
step: 550, loss: 0.09347020089626312
step: 560, loss: 0.07579183578491211
step: 570, loss: 0.09235864877700806
step: 580, loss: 0.055598918348550797
step: 590, loss: 0.12150746583938599
step: 600, loss: 0.07953374087810516
step: 610, loss: 0.12284600734710693
step: 620, loss: 0.10074544697999954
step: 630, loss: 0.15984582901000977
step: 640, loss: 0.20439361035823822
step: 650, loss: 0.1511569768190384
step: 660, loss: 0.09401731938123703
step: 670, loss: 0.03203745558857918
step: 680, loss: 0.24061423540115356
step: 690, loss: 0.008279997855424881
step: 700, loss: 0.0715155303478241
step: 710, loss: 0.08587058633565903
step: 720, loss: 0.010594379156827927
step: 730, loss: 0.11095348745584488
step: 740, loss: 0.028011618182063103
step: 750, loss: 0.08499934524297714
step: 760, loss: 0.08316602557897568
step: 770, loss: 0.061250586062669754
step: 780, loss: 0.04071427881717682
step: 790, loss: 0.10024072229862213
step: 800, loss: 0.09912487864494324
step: 810, loss: 0.037917930632829666
step: 820, loss: 0.009992862120270729
step: 830, loss: 0.1351812481880188
step: 840, loss: 0.13402679562568665
step: 850, loss: 0.040050435811281204
step: 860, loss: 0.14156588912010193
step: 870, loss: 0.08225585520267487
step: 880, loss: 0.1050029993057251
step: 890, loss: 0.07350299507379532
step: 900, loss: 0.05697857216000557
step: 910, loss: 0.12926733493804932
step: 920, loss: 0.14267316460609436
step: 930, loss: 0.05920187011361122
step: 940, loss: 0.07181434333324432
step: 950, loss: 0.09188983589410782
step: 960, loss: 0.035903993993997574
step: 970, loss: 0.08745419234037399
step: 980, loss: 0.08858226239681244
step: 990, loss: 0.08253327012062073
step: 1000, loss: 0.04717867821455002
step: 1010, loss: 0.12221988290548325
step: 1020, loss: 0.023482784628868103
step: 1030, loss: 0.03843829780817032
step: 1040, loss: 0.04136472940444946
step: 1050, loss: 0.12053650617599487
step: 1060, loss: 0.09409302473068237
step: 1070, loss: 0.3045273423194885
epoch 7: dev_f1=0.9257722452743199, f1=0.9296947271045328, best_f1=0.9338338808071328
step: 0, loss: 0.014604994095861912
step: 10, loss: 0.14562778174877167
step: 20, loss: 0.04753461107611656
step: 30, loss: 0.05032490938901901
step: 40, loss: 0.06822890043258667
step: 50, loss: 0.03670409694314003
step: 60, loss: 0.02130773849785328
step: 70, loss: 0.13507896661758423
step: 80, loss: 0.1114133968949318
step: 90, loss: 0.03869127854704857
step: 100, loss: 0.07385754585266113
step: 110, loss: 0.0505877323448658
step: 120, loss: 0.031036946922540665
step: 130, loss: 0.018925361335277557
step: 140, loss: 0.03323829174041748
step: 150, loss: 0.08002383261919022
step: 160, loss: 0.032370664179325104
step: 170, loss: 0.06270918250083923
step: 180, loss: 0.1629747897386551
step: 190, loss: 0.04109703749418259
step: 200, loss: 0.05964387208223343
step: 210, loss: 0.07309714704751968
step: 220, loss: 0.07497422397136688
step: 230, loss: 0.09090274572372437
step: 240, loss: 0.12497264891862869
step: 250, loss: 0.10357904434204102
step: 260, loss: 0.02152465283870697
step: 270, loss: 0.056335654109716415
step: 280, loss: 0.10992885380983353
step: 290, loss: 0.03880586102604866
step: 300, loss: 0.09904811531305313
step: 310, loss: 0.08445406705141068
step: 320, loss: 0.05271090194582939
step: 330, loss: 0.028300514444708824
step: 340, loss: 0.003981593064963818
step: 350, loss: 0.0018530450761318207
step: 360, loss: 0.09282829612493515
step: 370, loss: 0.026820026338100433
step: 380, loss: 0.08275077491998672
step: 390, loss: 0.13283127546310425
step: 400, loss: 0.07404366880655289
step: 410, loss: 0.062133993953466415
step: 420, loss: 0.18935354053974152
step: 430, loss: 0.06492748111486435
step: 440, loss: 0.12507256865501404
step: 450, loss: 0.12484878301620483
step: 460, loss: 0.025957271456718445
step: 470, loss: 0.14356060326099396
step: 480, loss: 0.131517231464386
step: 490, loss: 0.06910058110952377
step: 500, loss: 0.09817430377006531
step: 510, loss: 0.11781726777553558
step: 520, loss: 0.061484139412641525
step: 530, loss: 0.07244537025690079
step: 540, loss: 0.03557107597589493
step: 550, loss: 0.10057692229747772
step: 560, loss: 0.08841226994991302
step: 570, loss: 0.06313885003328323
step: 580, loss: 0.05435477942228317
step: 590, loss: 0.06019720807671547
step: 600, loss: 0.07721943408250809
step: 610, loss: 0.04231030493974686
step: 620, loss: 0.05726756900548935
step: 630, loss: 0.08449597656726837
step: 640, loss: 0.05023065581917763
step: 650, loss: 0.1003425344824791
step: 660, loss: 0.01973198913037777
step: 670, loss: 0.08740472048521042
step: 680, loss: 0.015110930427908897
step: 690, loss: 0.06747128069400787
step: 700, loss: 0.06948447972536087
step: 710, loss: 0.08306246250867844
step: 720, loss: 0.008194144815206528
step: 730, loss: 0.056390974670648575
step: 740, loss: 0.0904892310500145
step: 750, loss: 0.04025280848145485
step: 760, loss: 0.05936943367123604
step: 770, loss: 0.0806414783000946
step: 780, loss: 0.029025830328464508
step: 790, loss: 0.08687321096658707
step: 800, loss: 0.011125164106488228
step: 810, loss: 0.06811966001987457
step: 820, loss: 0.038089651614427567
step: 830, loss: 0.049041468650102615
step: 840, loss: 0.17820563912391663
step: 850, loss: 0.06778750568628311
step: 860, loss: 0.0803152397274971
step: 870, loss: 0.016491398215293884
step: 880, loss: 0.10463173687458038
step: 890, loss: 0.064418725669384
step: 900, loss: 0.20178359746932983
step: 910, loss: 0.019387824460864067
step: 920, loss: 0.13068334758281708
step: 930, loss: 0.028540993109345436
step: 940, loss: 0.05509144812822342
step: 950, loss: 0.04084392264485359
step: 960, loss: 0.12528909742832184
step: 970, loss: 0.1132935881614685
step: 980, loss: 0.1224464699625969
step: 990, loss: 0.10848761349916458
step: 1000, loss: 0.12126737087965012
step: 1010, loss: 0.03552974760532379
step: 1020, loss: 0.030837345868349075
step: 1030, loss: 0.10078650712966919
step: 1040, loss: 0.20852889120578766
step: 1050, loss: 0.07624808698892593
step: 1060, loss: 0.04485060274600983
step: 1070, loss: 0.09214304387569427
epoch 8: dev_f1=0.9258753979081401, f1=0.9296551724137931, best_f1=0.9338338808071328
step: 0, loss: 0.05634448677301407
step: 10, loss: 0.16414774954319
step: 20, loss: 0.03489670529961586
step: 30, loss: 0.07660118490457535
step: 40, loss: 0.04461909830570221
step: 50, loss: 0.12909269332885742
step: 60, loss: 0.0362280011177063
step: 70, loss: 0.015909546986222267
step: 80, loss: 0.019404767081141472
step: 90, loss: 0.17136090993881226
step: 100, loss: 0.03947685286402702
step: 110, loss: 0.07720675319433212
step: 120, loss: 0.15241064131259918
step: 130, loss: 0.06271287053823471
step: 140, loss: 0.07707711309194565
step: 150, loss: 0.1056511178612709
step: 160, loss: 0.11015050113201141
step: 170, loss: 0.12993714213371277
step: 180, loss: 0.08599516749382019
step: 190, loss: 0.09142699092626572
step: 200, loss: 0.02616744302213192
step: 210, loss: 0.03301090747117996
step: 220, loss: 0.09597316384315491
step: 230, loss: 0.16497083008289337
step: 240, loss: 0.042898889631032944
step: 250, loss: 0.10236118733882904
step: 260, loss: 0.09342385828495026
step: 270, loss: 0.059500303119421005
step: 280, loss: 0.08759137988090515
step: 290, loss: 0.045062772929668427
step: 300, loss: 0.208261176943779
step: 310, loss: 0.09094971418380737
step: 320, loss: 0.09199641644954681
step: 330, loss: 0.0663537010550499
step: 340, loss: 0.017547203227877617
step: 350, loss: 0.06907565146684647
step: 360, loss: 0.01868787407875061
step: 370, loss: 0.05623127892613411
step: 380, loss: 0.07379388809204102
step: 390, loss: 0.01991228386759758
step: 400, loss: 0.02520674653351307
step: 410, loss: 0.05992617458105087
step: 420, loss: 0.013669460080564022
step: 430, loss: 0.12589319050312042
step: 440, loss: 0.14406315982341766
step: 450, loss: 0.1009727343916893
step: 460, loss: 0.05363582447171211
step: 470, loss: 0.20074529945850372
step: 480, loss: 0.11561767756938934
step: 490, loss: 0.08511834591627121
step: 500, loss: 0.14707110822200775
step: 510, loss: 0.013934682123363018
step: 520, loss: 0.13495953381061554
step: 530, loss: 0.06610261648893356
step: 540, loss: 0.107303187251091
step: 550, loss: 0.013274874538183212
step: 560, loss: 0.09382031857967377
step: 570, loss: 0.07043930143117905
step: 580, loss: 0.044867631047964096
step: 590, loss: 0.04810725525021553
step: 600, loss: 0.13053292036056519
step: 610, loss: 0.11752817779779434
step: 620, loss: 0.04213518649339676
step: 630, loss: 0.11057193577289581
step: 640, loss: 0.07655413448810577
step: 650, loss: 0.015648063272237778
step: 660, loss: 0.1308794915676117
step: 670, loss: 0.12237367779016495
step: 680, loss: 0.019503524526953697
step: 690, loss: 0.08174987137317657
step: 700, loss: 0.09482895582914352
step: 710, loss: 0.05961242690682411
step: 720, loss: 0.14875976741313934
step: 730, loss: 0.01987624168395996
step: 740, loss: 0.07932980358600616
step: 750, loss: 0.06828217208385468
step: 760, loss: 0.005906876176595688
step: 770, loss: 0.11622403562068939
step: 780, loss: 0.07678047567605972
step: 790, loss: 0.02360665425658226
step: 800, loss: 0.1220516636967659
step: 810, loss: 0.15153370797634125
step: 820, loss: 0.0944516584277153
step: 830, loss: 0.016982873901724815
step: 840, loss: 0.08297581225633621
step: 850, loss: 0.06241697072982788
step: 860, loss: 0.06346644461154938
step: 870, loss: 0.0925436019897461
step: 880, loss: 6.534958083648235e-05
step: 890, loss: 0.07500392198562622
step: 900, loss: 0.0268857479095459
step: 910, loss: 0.09388469159603119
step: 920, loss: 0.05997737497091293
step: 930, loss: 0.0906485915184021
step: 940, loss: 0.10047046840190887
step: 950, loss: 0.0636875256896019
step: 960, loss: 0.08831155300140381
step: 970, loss: 0.03761953115463257
step: 980, loss: 0.037981241941452026
step: 990, loss: 0.038816533982753754
step: 1000, loss: 0.09615056216716766
step: 1010, loss: 0.06293126195669174
step: 1020, loss: 0.10811053961515427
step: 1030, loss: 0.164048969745636
step: 1040, loss: 0.03505983576178551
step: 1050, loss: 0.057234782725572586
step: 1060, loss: 0.035816412419080734
step: 1070, loss: 0.04280409961938858
epoch 9: dev_f1=0.9327188940092166, f1=0.9319129226493746, best_f1=0.9338338808071328
step: 0, loss: 0.036070436239242554
step: 10, loss: 0.0513235442340374
step: 20, loss: 0.1463848203420639
step: 30, loss: 0.017286889255046844
step: 40, loss: 0.004048947710543871
step: 50, loss: 0.01768716797232628
step: 60, loss: 0.10110989212989807
step: 70, loss: 0.09300307184457779
step: 80, loss: 0.098594531416893
step: 90, loss: 0.03875148296356201
step: 100, loss: 0.07056272774934769
step: 110, loss: 0.11065538972616196
step: 120, loss: 0.0574573315680027
step: 130, loss: 0.057690709829330444
step: 140, loss: 0.016680998727679253
step: 150, loss: 0.04604976624250412
step: 160, loss: 0.05022932216525078
step: 170, loss: 0.04681059718132019
step: 180, loss: 0.07260199636220932
step: 190, loss: 0.030008435249328613
step: 200, loss: 0.05910249426960945
step: 210, loss: 0.06385590136051178
step: 220, loss: 0.01098347082734108
step: 230, loss: 0.026470715180039406
step: 240, loss: 0.0330592580139637
step: 250, loss: 0.08175372332334518
step: 260, loss: 0.09172292053699493
step: 270, loss: 0.10663321614265442
step: 280, loss: 0.12595877051353455
step: 290, loss: 0.036637548357248306
step: 300, loss: 0.07635724544525146
step: 310, loss: 0.019099116325378418
step: 320, loss: 0.08512617647647858
step: 330, loss: 0.03817619010806084
step: 340, loss: 0.06149855628609657
step: 350, loss: 0.11668037623167038
step: 360, loss: 0.046684034168720245
step: 370, loss: 0.010423303581774235
step: 380, loss: 0.2225327342748642
step: 390, loss: 0.04409891366958618
step: 400, loss: 0.04022405669093132
step: 410, loss: 0.04913053661584854
step: 420, loss: 0.11122968047857285
step: 430, loss: 0.02041005529463291
step: 440, loss: 0.07000638544559479
step: 450, loss: 0.019793907180428505
step: 460, loss: 0.06031784042716026
step: 470, loss: 0.048474427312612534
step: 480, loss: 0.05513465777039528
step: 490, loss: 0.03580864146351814
step: 500, loss: 0.10217081010341644
step: 510, loss: 0.017162058502435684
step: 520, loss: 0.12506847083568573
step: 530, loss: 0.08397018909454346
step: 540, loss: 0.10030624270439148
step: 550, loss: 0.053926803171634674
step: 560, loss: 0.09837570041418076
step: 570, loss: 0.02542271465063095
step: 580, loss: 0.08837105333805084
step: 590, loss: 0.10040903091430664
step: 600, loss: 0.1728445589542389
step: 610, loss: 0.03593582287430763
step: 620, loss: 0.04578007012605667
step: 630, loss: 0.0785820260643959
step: 640, loss: 0.09723075479269028
step: 650, loss: 0.0004954973119311035
step: 660, loss: 0.055193617939949036
step: 670, loss: 0.05753153935074806
step: 680, loss: 0.04586028680205345
step: 690, loss: 0.11704939603805542
step: 700, loss: 0.09793487191200256
step: 710, loss: 0.10107019543647766
step: 720, loss: 0.019164182245731354
step: 730, loss: 0.018312698230147362
step: 740, loss: 0.0677826926112175
step: 750, loss: 0.02548486925661564
step: 760, loss: 0.008207275532186031
step: 770, loss: 0.02105599455535412
step: 780, loss: 0.030943550169467926
step: 790, loss: 0.056303974241018295
step: 800, loss: 0.02914200723171234
step: 810, loss: 0.10367287695407867
step: 820, loss: 0.0429239459335804
step: 830, loss: 0.135654017329216
step: 840, loss: 0.0031913183629512787
step: 850, loss: 0.02732737548649311
step: 860, loss: 0.20018509030342102
step: 870, loss: 0.14683008193969727
step: 880, loss: 0.051604777574539185
step: 890, loss: 0.08786662667989731
step: 900, loss: 0.15054020285606384
step: 910, loss: 0.09141390025615692
step: 920, loss: 0.1102176085114479
step: 930, loss: 0.10332804918289185
step: 940, loss: 0.055262915790081024
step: 950, loss: 0.05710654333233833
step: 960, loss: 0.07302697747945786
step: 970, loss: 0.026411086320877075
step: 980, loss: 0.057672835886478424
step: 990, loss: 0.05760395899415016
step: 1000, loss: 0.03270609304308891
step: 1010, loss: 0.10635434091091156
step: 1020, loss: 0.08688296377658844
step: 1030, loss: 0.10200435668230057
step: 1040, loss: 0.023792171850800514
step: 1050, loss: 0.09292781352996826
step: 1060, loss: 0.0848931223154068
step: 1070, loss: 0.11882327497005463
epoch 10: dev_f1=0.9262482821804855, f1=0.9253456221198156, best_f1=0.9338338808071328
step: 0, loss: 0.05481502413749695
step: 10, loss: 0.05909717082977295
step: 20, loss: 0.11646632850170135
step: 30, loss: 0.0653584748506546
step: 40, loss: 0.06999500840902328
step: 50, loss: 0.19661331176757812
step: 60, loss: 0.0028993794694542885
step: 70, loss: 0.005930056795477867
step: 80, loss: 0.01973741501569748
step: 90, loss: 0.13073670864105225
step: 100, loss: 0.007338900119066238
step: 110, loss: 0.03280657157301903
step: 120, loss: 0.05562635138630867
step: 130, loss: 0.034183625131845474
step: 140, loss: 0.0420590378344059
step: 150, loss: 0.10529272258281708
step: 160, loss: 0.019787250086665154
step: 170, loss: 0.11628971248865128
step: 180, loss: 0.0424790196120739
step: 190, loss: 0.057661641389131546
step: 200, loss: 0.08438740670681
step: 210, loss: 0.0010529536521062255
step: 220, loss: 0.10753709822893143
step: 230, loss: 0.03488645330071449
step: 240, loss: 0.050672028213739395
step: 250, loss: 0.00018215816817246377
step: 260, loss: 0.03967668116092682
step: 270, loss: 0.00014444881526287645
step: 280, loss: 0.028766082599759102
step: 290, loss: 0.05051672086119652
step: 300, loss: 0.00017764847143553197
step: 310, loss: 0.07144343852996826
step: 320, loss: 0.07632463425397873
step: 330, loss: 0.02692529559135437
step: 340, loss: 0.08342712372541428
step: 350, loss: 0.08836789429187775
step: 360, loss: 0.020723402500152588
step: 370, loss: 0.04625708609819412
step: 380, loss: 0.2362353503704071
step: 390, loss: 0.05530199036002159
step: 400, loss: 0.11440600454807281
step: 410, loss: 0.06614653021097183
step: 420, loss: 0.06341389566659927
step: 430, loss: 0.11012056469917297
step: 440, loss: 0.04748588055372238
step: 450, loss: 0.02201998047530651
step: 460, loss: 0.03180202096700668
step: 470, loss: 0.04401039704680443
step: 480, loss: 0.1566653996706009
step: 490, loss: 0.030840350314974785
step: 500, loss: 0.05167901888489723
step: 510, loss: 0.05385499447584152
step: 520, loss: 0.17901188135147095
step: 530, loss: 0.020587963983416557
step: 540, loss: 0.05780654773116112
step: 550, loss: 0.10745731741189957
step: 560, loss: 0.15819823741912842
step: 570, loss: 0.052685000002384186
step: 580, loss: 0.09644893556833267
step: 590, loss: 0.04961739853024483
step: 600, loss: 0.0013880371116101742
step: 610, loss: 0.08862292021512985
step: 620, loss: 0.03652331605553627
step: 630, loss: 0.022130079567432404
step: 640, loss: 0.06403554230928421
step: 650, loss: 0.06760740280151367
step: 660, loss: 0.08613473176956177
step: 670, loss: 0.051294051110744476
step: 680, loss: 0.06813933700323105
step: 690, loss: 0.019663404673337936
step: 700, loss: 0.023360680788755417
step: 710, loss: 0.025879954919219017
step: 720, loss: 0.10183842480182648
step: 730, loss: 0.06825093924999237
step: 740, loss: 0.13206841051578522
step: 750, loss: 0.0641290619969368
step: 760, loss: 0.0974108874797821
step: 770, loss: 0.06410574913024902
step: 780, loss: 0.12484761327505112
step: 790, loss: 0.13784202933311462
step: 800, loss: 0.050119031220674515
step: 810, loss: 0.0009970783721655607
step: 820, loss: 0.05819198861718178
step: 830, loss: 0.012147540226578712
step: 840, loss: 0.019421163946390152
step: 850, loss: 0.04858378693461418
step: 860, loss: 0.05245249718427658
step: 870, loss: 0.10143044590950012
step: 880, loss: 0.00690033845603466
step: 890, loss: 0.004808323457837105
step: 900, loss: 0.04959002882242203
step: 910, loss: 0.021094774827361107
step: 920, loss: 0.0886404812335968
step: 930, loss: 0.1481788158416748
step: 940, loss: 0.09670243412256241
step: 950, loss: 0.029900021851062775
step: 960, loss: 0.036399465054273605
step: 970, loss: 0.02336306869983673
step: 980, loss: 0.0643388107419014
step: 990, loss: 0.026028133928775787
step: 1000, loss: 0.0012849923223257065
step: 1010, loss: 0.07888016104698181
step: 1020, loss: 0.09931827336549759
step: 1030, loss: 0.02119567058980465
step: 1040, loss: 0.12356853485107422
step: 1050, loss: 0.03780890628695488
step: 1060, loss: 0.038101572543382645
step: 1070, loss: 0.051655106246471405
epoch 11: dev_f1=0.9317343173431735, f1=0.9317972350230416, best_f1=0.9338338808071328
step: 0, loss: 0.055237893015146255
step: 10, loss: 0.07606688141822815
step: 20, loss: 0.03902434557676315
step: 30, loss: 0.07056103646755219
step: 40, loss: 0.021117204800248146
step: 50, loss: 0.09890304505825043
step: 60, loss: 0.03204375132918358
step: 70, loss: 0.06695328652858734
step: 80, loss: 0.10495498776435852
step: 90, loss: 0.06483983993530273
step: 100, loss: 0.06875389814376831
step: 110, loss: 0.06491167843341827
step: 120, loss: 0.11241759359836578
step: 130, loss: 0.06485413759946823
step: 140, loss: 0.024722833186388016
step: 150, loss: 0.0459948405623436
step: 160, loss: 0.03664319962263107
step: 170, loss: 0.03893154859542847
step: 180, loss: 0.059747397899627686
step: 190, loss: 0.07183615118265152
step: 200, loss: 0.07679576426744461
step: 210, loss: 0.04495615139603615
step: 220, loss: 0.015537233091890812
step: 230, loss: 0.05187329277396202
step: 240, loss: 0.018602047115564346
step: 250, loss: 0.08929666876792908
step: 260, loss: 0.06274592876434326
step: 270, loss: 0.0581754595041275
step: 280, loss: 0.10204479843378067
step: 290, loss: 0.0204644575715065
step: 300, loss: 0.13187091052532196
step: 310, loss: 0.04963221400976181
step: 320, loss: 0.07148076593875885
step: 330, loss: 0.14255915582180023
step: 340, loss: 0.02977072075009346
step: 350, loss: 0.16757440567016602
step: 360, loss: 0.03606487065553665
step: 370, loss: 0.08854153752326965
step: 380, loss: 0.06525862216949463
step: 390, loss: 0.043118931353092194
step: 400, loss: 0.07585359364748001
step: 410, loss: 0.07590068876743317
step: 420, loss: 0.030793629586696625
step: 430, loss: 0.06540079414844513
step: 440, loss: 0.040009304881095886
step: 450, loss: 0.11925414204597473
step: 460, loss: 0.0695929229259491
step: 470, loss: 0.10275981575250626
step: 480, loss: 0.03672707453370094
step: 490, loss: 0.09334704279899597
step: 500, loss: 2.1397478121798486e-05
step: 510, loss: 0.0910976454615593
step: 520, loss: 0.09913240373134613
step: 530, loss: 0.020963720977306366
step: 540, loss: 0.12791337072849274
step: 550, loss: 0.004084588028490543
step: 560, loss: 0.06003579497337341
step: 570, loss: 0.05609709396958351
step: 580, loss: 0.027785181999206543
step: 590, loss: 0.06484474986791611
step: 600, loss: 0.06247790902853012
step: 610, loss: 0.12378956377506256
step: 620, loss: 0.06612838804721832
step: 630, loss: 0.06729413568973541
step: 640, loss: 0.021131528541445732
step: 650, loss: 0.053543489426374435
step: 660, loss: 0.02967957966029644
step: 670, loss: 0.03547196835279465
step: 680, loss: 0.028303274884819984
step: 690, loss: 0.2677406668663025
step: 700, loss: 0.046981923282146454
step: 710, loss: 0.07326474785804749
step: 720, loss: 0.011517347767949104
step: 730, loss: 0.056541260331869125
step: 740, loss: 0.023556243628263474
step: 750, loss: 0.04488265886902809
step: 760, loss: 0.07879152148962021
step: 770, loss: 0.06734414398670197
step: 780, loss: 0.10941212624311447
step: 790, loss: 0.06272788345813751
step: 800, loss: 0.052087776362895966
step: 810, loss: 0.06264519691467285
step: 820, loss: 0.034939058125019073
step: 830, loss: 0.030918767675757408
step: 840, loss: 0.05787185952067375
step: 850, loss: 0.11210241913795471
step: 860, loss: 0.05866978317499161
step: 870, loss: 0.05860274285078049
step: 880, loss: 0.10498954355716705
step: 890, loss: 0.05192949250340462
step: 900, loss: 0.0332709364593029
step: 910, loss: 0.042324695736169815
step: 920, loss: 0.09601526707410812
step: 930, loss: 0.05095377564430237
step: 940, loss: 0.07455309480428696
step: 950, loss: 0.0406394824385643
step: 960, loss: 0.05078991875052452
step: 970, loss: 0.034312959760427475
step: 980, loss: 0.03781888261437416
step: 990, loss: 0.014778943732380867
step: 1000, loss: 0.04558511823415756
step: 1010, loss: 0.030645286664366722
step: 1020, loss: 0.044845663011074066
step: 1030, loss: 0.05241788178682327
step: 1040, loss: 0.12667548656463623
step: 1050, loss: 0.04281727224588394
step: 1060, loss: 0.052586011588573456
step: 1070, loss: 0.06412255764007568
epoch 12: dev_f1=0.9266697804764129, f1=0.9172510518934082, best_f1=0.9338338808071328
step: 0, loss: 0.0633019208908081
step: 10, loss: 0.0217911284416914
step: 20, loss: 0.02766748145222664
step: 30, loss: 0.07337631285190582
step: 40, loss: 0.05483630299568176
step: 50, loss: 0.04244400933384895
step: 60, loss: 0.056760601699352264
step: 70, loss: 0.0005599942523986101
step: 80, loss: 0.06473296880722046
step: 90, loss: 0.008019223809242249
step: 100, loss: 0.03865745663642883
step: 110, loss: 0.030847126618027687
step: 120, loss: 0.04182853177189827
step: 130, loss: 0.05102718994021416
step: 140, loss: 0.12499237060546875
step: 150, loss: 0.04127851873636246
step: 160, loss: 0.05570337921380997
step: 170, loss: 0.030345670878887177
step: 180, loss: 0.029205800965428352
step: 190, loss: 0.04188450425863266
step: 200, loss: 0.027884643524885178
step: 210, loss: 0.038546957075595856
step: 220, loss: 7.062419899739325e-05
step: 230, loss: 0.09800311923027039
step: 240, loss: 0.025432012975215912
step: 250, loss: 0.019840724766254425
step: 260, loss: 0.08680272847414017
step: 270, loss: 0.03398166969418526
step: 280, loss: 0.00016881071496754885
step: 290, loss: 0.09260925650596619
step: 300, loss: 0.09023912996053696
step: 310, loss: 0.0010480014607310295
step: 320, loss: 0.024096481502056122
step: 330, loss: 0.027844760566949844
step: 340, loss: 0.044404037296772
step: 350, loss: 0.015515264123678207
step: 360, loss: 0.02937871776521206
step: 370, loss: 0.0457909032702446
step: 380, loss: 0.015270794741809368
step: 390, loss: 0.16424952447414398
step: 400, loss: 0.04742260277271271
step: 410, loss: 0.09618755429983139
step: 420, loss: 0.04744298383593559
step: 430, loss: 0.014448236674070358
step: 440, loss: 0.03175300732254982
step: 450, loss: 0.10056265443563461
step: 460, loss: 0.030842456966638565
step: 470, loss: 0.06822369992733002
step: 480, loss: 0.049923017621040344
step: 490, loss: 0.050985146313905716
step: 500, loss: 0.011223204433918
step: 510, loss: 0.12831777334213257
step: 520, loss: 0.03886266425251961
step: 530, loss: 0.06618267297744751
step: 540, loss: 0.04960312694311142
step: 550, loss: 0.011519553139805794
step: 560, loss: 0.053795862942934036
step: 570, loss: 0.0027635928709059954
step: 580, loss: 0.009489168412983418
step: 590, loss: 0.11778395622968674
step: 600, loss: 0.0036647957749664783
step: 610, loss: 0.050755567848682404
step: 620, loss: 0.02141926996409893
step: 630, loss: 0.1353054940700531
step: 640, loss: 0.04297124221920967
step: 650, loss: 0.07570142298936844
step: 660, loss: 0.0001759829610818997
step: 670, loss: 0.08126287907361984
step: 680, loss: 0.0885448306798935
step: 690, loss: 0.029442591592669487
step: 700, loss: 0.0028718833345919847
step: 710, loss: 0.035044290125370026
step: 720, loss: 0.04383130744099617
step: 730, loss: 0.0395190566778183
step: 740, loss: 0.046678025275468826
step: 750, loss: 0.01978832110762596
step: 760, loss: 0.04034651070833206
step: 770, loss: 0.13853368163108826
step: 780, loss: 0.06761892884969711
step: 790, loss: 0.14426442980766296
step: 800, loss: 0.038580041378736496
step: 810, loss: 0.018493525683879852
step: 820, loss: 0.0578300915658474
step: 830, loss: 0.07826065272092819
step: 840, loss: 0.06833112239837646
step: 850, loss: 0.05221479386091232
step: 860, loss: 0.06912990659475327
step: 870, loss: 0.03400386497378349
step: 880, loss: 0.02868354506790638
step: 890, loss: 0.020034784451127052
step: 900, loss: 0.08516863733530045
step: 910, loss: 0.07121661305427551
step: 920, loss: 0.042512405663728714
step: 930, loss: 0.009612923488020897
step: 940, loss: 0.0237888116389513
step: 950, loss: 0.05411998927593231
step: 960, loss: 0.0016548288986086845
step: 970, loss: 0.08048361539840698
step: 980, loss: 0.07420568913221359
step: 990, loss: 0.08318039029836655
step: 1000, loss: 0.052707571536302567
step: 1010, loss: 0.03697330877184868
step: 1020, loss: 0.02257191762328148
step: 1030, loss: 0.04941343516111374
step: 1040, loss: 0.0460420623421669
step: 1050, loss: 0.10529018938541412
step: 1060, loss: 0.03308194875717163
step: 1070, loss: 0.09713483601808548
epoch 13: dev_f1=0.9305555555555556, f1=0.9238625812441968, best_f1=0.9338338808071328
step: 0, loss: 0.05422195419669151
step: 10, loss: 0.03748554363846779
step: 20, loss: 0.02979465015232563
step: 30, loss: 0.030408790335059166
step: 40, loss: 0.024905798956751823
step: 50, loss: 0.03328944370150566
step: 60, loss: 0.06707353889942169
step: 70, loss: 0.025635404512286186
step: 80, loss: 0.05568721890449524
step: 90, loss: 0.001602487056516111
step: 100, loss: 0.03512219712138176
step: 110, loss: 0.08981490880250931
step: 120, loss: 0.03702033683657646
step: 130, loss: 0.02243215963244438
step: 140, loss: 0.03434484824538231
step: 150, loss: 0.08848702162504196
step: 160, loss: 0.018020927906036377
step: 170, loss: 0.03508969023823738
step: 180, loss: 0.04203400760889053
step: 190, loss: 0.050069838762283325
step: 200, loss: 0.09647869318723679
step: 210, loss: 0.05275946110486984
step: 220, loss: 0.06500132381916046
step: 230, loss: 0.06977386772632599
step: 240, loss: 0.12808795273303986
step: 250, loss: 0.12664403021335602
step: 260, loss: 0.035500600934028625
step: 270, loss: 0.06777323782444
step: 280, loss: 0.010411386378109455
step: 290, loss: 0.016889704391360283
step: 300, loss: 0.06010027229785919
step: 310, loss: 0.07831692695617676
step: 320, loss: 0.01919248327612877
step: 330, loss: 0.0508560873568058
step: 340, loss: 0.05453696474432945
step: 350, loss: 5.331243301043287e-05
step: 360, loss: 0.029798274859786034
step: 370, loss: 0.06709705293178558
step: 380, loss: 0.03955938667058945
step: 390, loss: 0.2466931939125061
step: 400, loss: 0.04400746151804924
step: 410, loss: 0.08956287801265717
step: 420, loss: 0.07012654095888138
step: 430, loss: 0.05438186973333359
step: 440, loss: 0.04703379422426224
step: 450, loss: 0.023536410182714462
step: 460, loss: 0.0008400731603614986
step: 470, loss: 0.08227372169494629
step: 480, loss: 0.023186806589365005
step: 490, loss: 0.04344679042696953
step: 500, loss: 0.027793671935796738
step: 510, loss: 0.05170593410730362
step: 520, loss: 0.09391643106937408
step: 530, loss: 0.13077285885810852
step: 540, loss: 0.017576392740011215
step: 550, loss: 0.028764234855771065
step: 560, loss: 0.031531836837530136
step: 570, loss: 0.013989516533911228
step: 580, loss: 0.018358169123530388
step: 590, loss: 0.05616796761751175
step: 600, loss: 0.04129088670015335
step: 610, loss: 0.042450953274965286
step: 620, loss: 0.06513913720846176
step: 630, loss: 0.06806420534849167
step: 640, loss: 0.04387319087982178
step: 650, loss: 0.08345252275466919
step: 660, loss: 0.05778944864869118
step: 670, loss: 0.05727022513747215
step: 680, loss: 0.03558173030614853
step: 690, loss: 0.052526552230119705
step: 700, loss: 0.09554765373468399
step: 710, loss: 0.004567721858620644
step: 720, loss: 0.019961556419730186
step: 730, loss: 0.046855028718709946
step: 740, loss: 0.030673634260892868
step: 750, loss: 0.12333440035581589
step: 760, loss: 0.023433346301317215
step: 770, loss: 0.24226967990398407
step: 780, loss: 0.1411023885011673
step: 790, loss: 0.05655341222882271
step: 800, loss: 0.013667814433574677
step: 810, loss: 0.027530938386917114
step: 820, loss: 0.04635421186685562
step: 830, loss: 0.006139389239251614
step: 840, loss: 0.008368989452719688
step: 850, loss: 0.07270777225494385
step: 860, loss: 0.11147917062044144
step: 870, loss: 0.07567858695983887
step: 880, loss: 0.0313393697142601
step: 890, loss: 1.6807707652333193e-05
step: 900, loss: 0.09458587318658829
step: 910, loss: 0.13485413789749146
step: 920, loss: 0.02811049297451973
step: 930, loss: 0.014342907816171646
step: 940, loss: 0.025312205776572227
step: 950, loss: 0.08943378180265427
step: 960, loss: 0.11781644821166992
step: 970, loss: 1.623054049559869e-05
step: 980, loss: 0.06240079179406166
step: 990, loss: 0.05621954798698425
step: 1000, loss: 0.053961798548698425
step: 1010, loss: 0.08736764639616013
step: 1020, loss: 0.0415547713637352
step: 1030, loss: 0.00013796219718642533
step: 1040, loss: 0.09131822735071182
step: 1050, loss: 0.04109760746359825
step: 1060, loss: 0.02209266647696495
step: 1070, loss: 0.05103379115462303
epoch 14: dev_f1=0.927348449791763, f1=0.9252206223873664, best_f1=0.9338338808071328
step: 0, loss: 0.02794540300965309
step: 10, loss: 0.0770774558186531
step: 20, loss: 0.10947377234697342
step: 30, loss: 0.03893459215760231
step: 40, loss: 0.002204301068559289
step: 50, loss: 0.03774354234337807
step: 60, loss: 0.09424810856580734
step: 70, loss: 0.20266640186309814
step: 80, loss: 0.025155536830425262
step: 90, loss: 0.05909083038568497
step: 100, loss: 0.017983898520469666
step: 110, loss: 0.034273918718099594
step: 120, loss: 0.030238129198551178
step: 130, loss: 0.04593916982412338
step: 140, loss: 0.08456600457429886
step: 150, loss: 0.15484091639518738
step: 160, loss: 0.11314685642719269
step: 170, loss: 0.04230567067861557
step: 180, loss: 0.029227642342448235
step: 190, loss: 0.04754281044006348
step: 200, loss: 0.05537031218409538
step: 210, loss: 0.08945252001285553
step: 220, loss: 0.024295348674058914
step: 230, loss: 0.06814831495285034
step: 240, loss: 0.09071539342403412
step: 250, loss: 0.07748988270759583
step: 260, loss: 0.06894247233867645
step: 270, loss: 0.06284923106431961
step: 280, loss: 0.07003024965524673
step: 290, loss: 0.024266544729471207
step: 300, loss: 0.032415494322776794
step: 310, loss: 0.04211689159274101
step: 320, loss: 0.03517472743988037
step: 330, loss: 0.021589776501059532
step: 340, loss: 0.010113661177456379
step: 350, loss: 0.02622281014919281
step: 360, loss: 0.07119154930114746
step: 370, loss: 0.04233913496136665
step: 380, loss: 0.0423789881169796
step: 390, loss: 0.05176141858100891
step: 400, loss: 0.00018693461606744677
step: 410, loss: 0.029960446059703827
step: 420, loss: 3.0041634090594016e-05
step: 430, loss: 0.031969163566827774
step: 440, loss: 0.07029018551111221
step: 450, loss: 0.032766833901405334
step: 460, loss: 0.05275624245405197
step: 470, loss: 0.15395359694957733
step: 480, loss: 0.027635445818305016
step: 490, loss: 0.06567374616861343
step: 500, loss: 0.07094816118478775
step: 510, loss: 0.07573773711919785
step: 520, loss: 1.1663765690173022e-05
step: 530, loss: 0.05394752696156502
step: 540, loss: 0.10057754069566727
step: 550, loss: 0.05954340845346451
step: 560, loss: 0.03934042155742645
step: 570, loss: 0.01995641551911831
step: 580, loss: 0.1221325546503067
step: 590, loss: 0.046950727701187134
step: 600, loss: 0.04913824424147606
step: 610, loss: 0.08431477844715118
step: 620, loss: 0.1599237024784088
step: 630, loss: 0.07401744276285172
step: 640, loss: 0.024818364530801773
step: 650, loss: 0.1127476617693901
step: 660, loss: 0.06311985850334167
step: 670, loss: 0.0694381594657898
step: 680, loss: 0.07127086073160172
step: 690, loss: 0.07092851400375366
step: 700, loss: 0.05021234601736069
step: 710, loss: 0.07691387832164764
step: 720, loss: 0.1700005829334259
step: 730, loss: 0.056775402277708054
step: 740, loss: 0.03251875564455986
step: 750, loss: 0.10460858047008514
step: 760, loss: 0.04967683181166649
step: 770, loss: 0.17999449372291565
step: 780, loss: 0.04584653675556183
step: 790, loss: 0.013829788193106651
step: 800, loss: 0.04682205617427826
step: 810, loss: 0.04457717016339302
step: 820, loss: 0.07366172224283218
step: 830, loss: 0.05356555059552193
step: 840, loss: 2.2275373339653015e-05
step: 850, loss: 0.08476977050304413
step: 860, loss: 0.04084160178899765
step: 870, loss: 0.021168755367398262
step: 880, loss: 0.02577538602054119
step: 890, loss: 0.016477659344673157
step: 900, loss: 0.013230189681053162
step: 910, loss: 0.09173654019832611
step: 920, loss: 0.03447214141488075
step: 930, loss: 0.023610038682818413
step: 940, loss: 0.10220734030008316
step: 950, loss: 0.05925300344824791
step: 960, loss: 0.05484035611152649
step: 970, loss: 0.04323916509747505
step: 980, loss: 0.13106957077980042
step: 990, loss: 0.034316666424274445
step: 1000, loss: 0.09098755568265915
step: 1010, loss: 0.042751140892505646
step: 1020, loss: 0.0007848552777431905
step: 1030, loss: 0.0005256099393591285
step: 1040, loss: 0.047963716089725494
step: 1050, loss: 0.008644506335258484
step: 1060, loss: 0.017247991636395454
step: 1070, loss: 0.12340948730707169
epoch 15: dev_f1=0.9273897058823529, f1=0.9225776541492814, best_f1=0.9338338808071328
step: 0, loss: 0.00785827450454235
step: 10, loss: 0.05654757842421532
step: 20, loss: 0.06425639241933823
step: 30, loss: 0.04121354967355728
step: 40, loss: 0.0694153681397438
step: 50, loss: 0.03143934905529022
step: 60, loss: 0.0375075563788414
step: 70, loss: 0.11988014727830887
step: 80, loss: 0.10113516449928284
step: 90, loss: 0.060131318867206573
step: 100, loss: 1.7723548808135092e-05
step: 110, loss: 0.04779281094670296
step: 120, loss: 0.0741276741027832
step: 130, loss: 0.015286599285900593
step: 140, loss: 0.06530006229877472
step: 150, loss: 0.00012311864702496678
step: 160, loss: 0.014245669357478619
step: 170, loss: 0.04283726587891579
step: 180, loss: 0.00326678273268044
step: 190, loss: 0.038151003420352936
step: 200, loss: 0.04855548217892647
step: 210, loss: 0.05601578578352928
step: 220, loss: 0.10088988393545151
step: 230, loss: 0.031828373670578
step: 240, loss: 0.025919606909155846
step: 250, loss: 0.026813983917236328
step: 260, loss: 0.01770399697124958
step: 270, loss: 4.388664456200786e-05
step: 280, loss: 0.021777259185910225
step: 290, loss: 0.013889665715396404
step: 300, loss: 0.08298154175281525
step: 310, loss: 0.052683763206005096
step: 320, loss: 0.0005539251142181456
step: 330, loss: 0.124601349234581
step: 340, loss: 0.08361833542585373
step: 350, loss: 0.06490809470415115
step: 360, loss: 0.05252338945865631
step: 370, loss: 0.04527551308274269
step: 380, loss: 0.02541576325893402
step: 390, loss: 0.025285756215453148
step: 400, loss: 0.0006351041374728084
step: 410, loss: 0.044077131897211075
step: 420, loss: 0.021995576098561287
step: 430, loss: 0.0002099805569741875
step: 440, loss: 0.0003384086594451219
step: 450, loss: 0.0751868486404419
step: 460, loss: 0.0796433612704277
step: 470, loss: 0.014011687599122524
step: 480, loss: 0.008262015879154205
step: 490, loss: 0.1161942183971405
step: 500, loss: 0.06668969988822937
step: 510, loss: 0.02983291633427143
step: 520, loss: 0.0791802629828453
step: 530, loss: 0.05956105887889862
step: 540, loss: 0.031046610325574875
step: 550, loss: 0.007734519429504871
step: 560, loss: 0.04848617687821388
step: 570, loss: 0.13570718467235565
step: 580, loss: 0.03556224703788757
step: 590, loss: 0.12959417700767517
step: 600, loss: 0.01709926314651966
step: 610, loss: 0.0001877238682936877
step: 620, loss: 0.034471988677978516
step: 630, loss: 0.05512329563498497
step: 640, loss: 0.07759224623441696
step: 650, loss: 0.03595554083585739
step: 660, loss: 0.0754832774400711
step: 670, loss: 0.11077967286109924
step: 680, loss: 0.02477084845304489
step: 690, loss: 0.32412421703338623
step: 700, loss: 0.00012077211431460455
step: 710, loss: 0.07436597347259521
step: 720, loss: 0.08482693880796432
step: 730, loss: 0.04791776090860367
step: 740, loss: 0.07919049263000488
step: 750, loss: 0.009028010070323944
step: 760, loss: 0.01931893266737461
step: 770, loss: 0.051183369010686874
step: 780, loss: 0.045879118144512177
step: 790, loss: 0.06231408938765526
step: 800, loss: 0.07267975062131882
step: 810, loss: 0.001453446689993143
step: 820, loss: 0.0307666826993227
step: 830, loss: 0.024258581921458244
step: 840, loss: 0.002692108042538166
step: 850, loss: 0.07153016328811646
step: 860, loss: 0.0629006028175354
step: 870, loss: 0.0776800811290741
step: 880, loss: 0.024845920503139496
step: 890, loss: 0.034949105232954025
step: 900, loss: 0.003950369544327259
step: 910, loss: 0.07996248453855515
step: 920, loss: 0.04359101504087448
step: 930, loss: 0.04427959397435188
step: 940, loss: 0.04325391352176666
step: 950, loss: 0.05932864174246788
step: 960, loss: 0.019924061372876167
step: 970, loss: 0.012698999606072903
step: 980, loss: 0.0798426941037178
step: 990, loss: 0.05103752017021179
step: 1000, loss: 0.0385393425822258
step: 1010, loss: 0.062062203884124756
step: 1020, loss: 0.012581241317093372
step: 1030, loss: 0.10177285224199295
step: 1040, loss: 5.1515005907276645e-05
step: 1050, loss: 0.055189426988363266
step: 1060, loss: 0.037312544882297516
step: 1070, loss: 0.049901653081178665
epoch 16: dev_f1=0.9294173377546187, f1=0.923660502607871, best_f1=0.9338338808071328
step: 0, loss: 0.04665793478488922
step: 10, loss: 0.02181629091501236
step: 20, loss: 0.04965478554368019
step: 30, loss: 0.06575214862823486
step: 40, loss: 0.019193071871995926
step: 50, loss: 0.04856564477086067
step: 60, loss: 0.1795448213815689
step: 70, loss: 0.0610254742205143
step: 80, loss: 0.02687326818704605
step: 90, loss: 0.004717483185231686
step: 100, loss: 0.0938555896282196
step: 110, loss: 0.04184244945645332
step: 120, loss: 0.02989957481622696
step: 130, loss: 0.028988292440772057
step: 140, loss: 0.024567708373069763
step: 150, loss: 0.09010113775730133
step: 160, loss: 0.07083379477262497
step: 170, loss: 0.015747204422950745
step: 180, loss: 0.019472558051347733
step: 190, loss: 0.031112149357795715
step: 200, loss: 0.06746779382228851
step: 210, loss: 0.053982216864824295
step: 220, loss: 0.02073056809604168
step: 230, loss: 0.035392411053180695
step: 240, loss: 0.04533522203564644
step: 250, loss: 0.016984669491648674
step: 260, loss: 0.03335496410727501
step: 270, loss: 0.11817841231822968
step: 280, loss: 0.03811163082718849
step: 290, loss: 0.08432722091674805
step: 300, loss: 0.01658918894827366
step: 310, loss: 0.000315405719447881
step: 320, loss: 0.05333290621638298
step: 330, loss: 0.08010274171829224
step: 340, loss: 0.0008670348324812949
step: 350, loss: 0.05165134742856026
step: 360, loss: 0.00024294198374263942
step: 370, loss: 0.06768696755170822
step: 380, loss: 0.01570199988782406
step: 390, loss: 0.08204931020736694
step: 400, loss: 0.07975855469703674
step: 410, loss: 0.041905954480171204
step: 420, loss: 0.04156768321990967
step: 430, loss: 0.04526515677571297
step: 440, loss: 0.04709642007946968
step: 450, loss: 0.03863358497619629
step: 460, loss: 0.04260152950882912
step: 470, loss: 0.06193561479449272
step: 480, loss: 0.037031032145023346
step: 490, loss: 0.03382065147161484
step: 500, loss: 0.050859905779361725
step: 510, loss: 0.13250702619552612
step: 520, loss: 1.1902085134352092e-05
step: 530, loss: 0.17630277574062347
step: 540, loss: 0.021626261994242668
step: 550, loss: 0.06170623376965523
step: 560, loss: 0.02499896101653576
step: 570, loss: 0.12452596426010132
step: 580, loss: 0.01763768121600151
step: 590, loss: 0.02291933074593544
step: 600, loss: 0.0541747622191906
step: 610, loss: 0.028783302754163742
step: 620, loss: 0.034346580505371094
step: 630, loss: 0.008687471970915794
step: 640, loss: 0.08241276443004608
step: 650, loss: 0.04708639532327652
step: 660, loss: 1.2282151146791875e-05
step: 670, loss: 0.06904836744070053
step: 680, loss: 0.0347505547106266
step: 690, loss: 0.079056516289711
step: 700, loss: 0.014389741234481335
step: 710, loss: 0.05997280776500702
step: 720, loss: 0.062088802456855774
step: 730, loss: 0.019996795803308487
step: 740, loss: 0.03075716458261013
step: 750, loss: 0.0168693158775568
step: 760, loss: 0.0026210476644337177
step: 770, loss: 0.016950039193034172
step: 780, loss: 0.051781658083200455
step: 790, loss: 0.02851055935025215
step: 800, loss: 0.029045771807432175
step: 810, loss: 1.098951088351896e-05
step: 820, loss: 0.07409676909446716
step: 830, loss: 0.023217283189296722
step: 840, loss: 0.00011805292160715908
step: 850, loss: 0.017500121146440506
step: 860, loss: 0.12831392884254456
step: 870, loss: 0.04771749675273895
step: 880, loss: 0.06950923055410385
step: 890, loss: 0.05058785527944565
step: 900, loss: 0.022931309416890144
step: 910, loss: 0.061803143471479416
step: 920, loss: 0.07631269097328186
step: 930, loss: 0.0015388245228677988
step: 940, loss: 0.003622379619628191
step: 950, loss: 0.018638696521520615
step: 960, loss: 0.02943016216158867
step: 970, loss: 0.04870595782995224
step: 980, loss: 0.0007476222235709429
step: 990, loss: 0.07825399935245514
step: 1000, loss: 0.12064269930124283
step: 1010, loss: 0.07250073552131653
step: 1020, loss: 6.070145172998309e-05
step: 1030, loss: 0.0005965119344182312
step: 1040, loss: 0.04268554970622063
step: 1050, loss: 0.024828648194670677
step: 1060, loss: 0.05354767665266991
step: 1070, loss: 0.023261522874236107
epoch 17: dev_f1=0.9299065420560748, f1=0.9292740046838408, best_f1=0.9338338808071328
step: 0, loss: 0.04091367870569229
step: 10, loss: 0.05056566745042801
step: 20, loss: 0.06832477450370789
step: 30, loss: 0.10235429555177689
step: 40, loss: 0.13739308714866638
step: 50, loss: 0.10633720457553864
step: 60, loss: 0.007098393049091101
step: 70, loss: 0.05157992243766785
step: 80, loss: 0.028450483456254005
step: 90, loss: 0.000736823829356581
step: 100, loss: 0.08396068215370178
step: 110, loss: 0.05542122200131416
step: 120, loss: 0.03528296947479248
step: 130, loss: 0.011508380062878132
step: 140, loss: 0.04289567470550537
step: 150, loss: 0.02968704141676426
step: 160, loss: 0.059555742889642715
step: 170, loss: 0.019041147083044052
step: 180, loss: 0.031393785029649734
step: 190, loss: 0.0480596125125885
step: 200, loss: 0.0041930763982236385
step: 210, loss: 0.030896566808223724
step: 220, loss: 0.04744299128651619
step: 230, loss: 0.0033617818262428045
step: 240, loss: 0.04923570901155472
step: 250, loss: 0.0254896879196167
step: 260, loss: 0.05462731048464775
step: 270, loss: 0.0330401211977005
step: 280, loss: 0.026094868779182434
step: 290, loss: 0.07161596417427063
step: 300, loss: 0.05134384334087372
step: 310, loss: 0.0565989725291729
step: 320, loss: 0.06220955774188042
step: 330, loss: 0.027386412024497986
step: 340, loss: 0.02151738479733467
step: 350, loss: 0.0183931365609169
step: 360, loss: 0.01537398062646389
step: 370, loss: 0.00026828001136891544
step: 380, loss: 0.01868199184536934
step: 390, loss: 0.004607261624187231
step: 400, loss: 0.03250471502542496
step: 410, loss: 0.05737018212676048
step: 420, loss: 0.00813248660415411
step: 430, loss: 0.058762937784194946
step: 440, loss: 0.016910091042518616
step: 450, loss: 0.06987854838371277
step: 460, loss: 0.051442950963974
step: 470, loss: 0.15094904601573944
step: 480, loss: 0.11105003207921982
step: 490, loss: 0.019864989444613457
step: 500, loss: 0.09214594960212708
step: 510, loss: 0.1336265355348587
step: 520, loss: 0.00022997955966275185
step: 530, loss: 0.0013551694573834538
step: 540, loss: 0.040592167526483536
step: 550, loss: 0.033233892172575
step: 560, loss: 0.0735408291220665
step: 570, loss: 5.366162440623157e-05
step: 580, loss: 0.020946545526385307
step: 590, loss: 0.0274914912879467
step: 600, loss: 0.04852861538529396
step: 610, loss: 0.10174240916967392
step: 620, loss: 0.034404437988996506
step: 630, loss: 0.06251714378595352
step: 640, loss: 0.08699999004602432
step: 650, loss: 0.0207062978297472
step: 660, loss: 0.09907705336809158
step: 670, loss: 0.020809907466173172
step: 680, loss: 5.849207445862703e-05
step: 690, loss: 0.051002927124500275
step: 700, loss: 0.05721021443605423
step: 710, loss: 0.010374453850090504
step: 720, loss: 0.027173476293683052
step: 730, loss: 0.023917295038700104
step: 740, loss: 0.024439366534352303
step: 750, loss: 0.03740030899643898
step: 760, loss: 0.0697336494922638
step: 770, loss: 0.015047024004161358
step: 780, loss: 0.05434208735823631
step: 790, loss: 0.02278265170753002
step: 800, loss: 0.005576130002737045
step: 810, loss: 0.05697277560830116
step: 820, loss: 0.03130347281694412
step: 830, loss: 0.08872058987617493
step: 840, loss: 2.752390173554886e-05
step: 850, loss: 0.06634416431188583
step: 860, loss: 2.668683373485692e-05
step: 870, loss: 5.61129636480473e-05
step: 880, loss: 0.06025569140911102
step: 890, loss: 0.07054450362920761
step: 900, loss: 0.0011366980616003275
step: 910, loss: 0.016787134110927582
step: 920, loss: 0.043085046112537384
step: 930, loss: 0.059283189475536346
step: 940, loss: 8.242703188443556e-05
step: 950, loss: 0.05786199867725372
step: 960, loss: 0.029546428471803665
step: 970, loss: 0.050562597811222076
step: 980, loss: 0.038920387625694275
step: 990, loss: 0.053155817091464996
step: 1000, loss: 0.017118554562330246
step: 1010, loss: 0.05215531215071678
step: 1020, loss: 0.07772009074687958
step: 1030, loss: 0.12528163194656372
step: 1040, loss: 0.0007616051007062197
step: 1050, loss: 0.036504946649074554
step: 1060, loss: 0.04226956143975258
step: 1070, loss: 0.041386693716049194
epoch 18: dev_f1=0.9295380307979467, f1=0.9281716417910447, best_f1=0.9338338808071328
step: 0, loss: 0.01974308490753174
step: 10, loss: 0.12235268205404282
step: 20, loss: 0.05139492079615593
step: 30, loss: 0.025392107665538788
step: 40, loss: 0.025642838329076767
step: 50, loss: 0.0317026786506176
step: 60, loss: 0.027759689837694168
step: 70, loss: 0.018199410289525986
step: 80, loss: 0.0481657013297081
step: 90, loss: 0.04849446937441826
step: 100, loss: 0.10834892839193344
step: 110, loss: 1.8104066839441657e-05
step: 120, loss: 9.212587428919505e-06
step: 130, loss: 0.021163983270525932
step: 140, loss: 0.022128429263830185
step: 150, loss: 0.04266628623008728
step: 160, loss: 2.661753023858182e-05
step: 170, loss: 2.9225213438621722e-05
step: 180, loss: 0.03006809391081333
step: 190, loss: 0.0008896258077584207
step: 200, loss: 0.027291538193821907
step: 210, loss: 0.005263341125100851
step: 220, loss: 0.04740464314818382
step: 230, loss: 0.04730531945824623
step: 240, loss: 0.0042109922505915165
step: 250, loss: 0.029000824317336082
step: 260, loss: 0.07404854148626328
step: 270, loss: 0.09620817005634308
step: 280, loss: 0.03307510167360306
step: 290, loss: 0.015148338861763477
step: 300, loss: 0.1278613954782486
step: 310, loss: 0.07850591838359833
step: 320, loss: 0.031224709004163742
step: 330, loss: 0.0898180902004242
step: 340, loss: 0.005224220454692841
step: 350, loss: 0.0967998206615448
step: 360, loss: 0.09744847565889359
step: 370, loss: 0.008052625693380833
step: 380, loss: 0.001417455030605197
step: 390, loss: 0.045873839408159256
step: 400, loss: 0.021898701786994934
step: 410, loss: 0.027288787066936493
step: 420, loss: 0.016644233837723732
step: 430, loss: 0.026261288672685623
step: 440, loss: 0.11256513744592667
step: 450, loss: 0.05791837349534035
step: 460, loss: 0.029203779995441437
step: 470, loss: 0.06075144186615944
step: 480, loss: 0.10354363918304443
step: 490, loss: 0.00012226594844833016
step: 500, loss: 0.02369696833193302
step: 510, loss: 0.08173754066228867
step: 520, loss: 3.9349695725832134e-05
step: 530, loss: 0.0657288208603859
step: 540, loss: 0.062059417366981506
step: 550, loss: 0.020450415089726448
step: 560, loss: 0.055360399186611176
step: 570, loss: 0.035441793501377106
step: 580, loss: 0.01895962283015251
step: 590, loss: 0.0014636762207373977
step: 600, loss: 0.033086713403463364
step: 610, loss: 0.03298752009868622
step: 620, loss: 0.04185838997364044
step: 630, loss: 0.05018032714724541
step: 640, loss: 0.018612418323755264
step: 650, loss: 0.04041634872555733
step: 660, loss: 0.0197791438549757
step: 670, loss: 0.024287225678563118
step: 680, loss: 0.0344410240650177
step: 690, loss: 0.0480339340865612
step: 700, loss: 0.04419291764497757
step: 710, loss: 0.062405262142419815
step: 720, loss: 0.05056193098425865
step: 730, loss: 0.026791229844093323
step: 740, loss: 2.9866794648114592e-05
step: 750, loss: 0.07171795517206192
step: 760, loss: 0.010837753303349018
step: 770, loss: 2.855890488717705e-05
step: 780, loss: 0.031061740592122078
step: 790, loss: 0.07117734104394913
step: 800, loss: 0.04240361973643303
step: 810, loss: 0.07544922083616257
step: 820, loss: 0.05455087870359421
step: 830, loss: 2.2460122636402957e-05
step: 840, loss: 0.041567474603652954
step: 850, loss: 0.08209677040576935
step: 860, loss: 0.05006597191095352
step: 870, loss: 0.059166740626096725
step: 880, loss: 0.08024773746728897
step: 890, loss: 0.04839488863945007
step: 900, loss: 0.040160052478313446
step: 910, loss: 0.0030557296704500914
step: 920, loss: 0.062886081635952
step: 930, loss: 0.0013882422354072332
step: 940, loss: 0.03709683567285538
step: 950, loss: 0.03933286666870117
step: 960, loss: 0.02292841486632824
step: 970, loss: 0.041093919426202774
step: 980, loss: 0.06807365268468857
step: 990, loss: 0.06187783554196358
step: 1000, loss: 0.07438883930444717
step: 1010, loss: 0.13001403212547302
step: 1020, loss: 0.007013228721916676
step: 1030, loss: 0.045750781893730164
step: 1040, loss: 0.07873579114675522
step: 1050, loss: 0.0009322846890427172
step: 1060, loss: 5.3236246458254755e-05
step: 1070, loss: 0.05972428619861603
epoch 19: dev_f1=0.9271274094969439, f1=0.9283694627709709, best_f1=0.9338338808071328
step: 0, loss: 0.08258726447820663
step: 10, loss: 0.038325488567352295
step: 20, loss: 0.043187618255615234
step: 30, loss: 0.012921844609081745
step: 40, loss: 0.0033317753113806248
step: 50, loss: 0.035567380487918854
step: 60, loss: 5.4800486395834014e-05
step: 70, loss: 4.053753218613565e-05
step: 80, loss: 0.12599065899848938
step: 90, loss: 0.09687721729278564
step: 100, loss: 0.032984547317028046
step: 110, loss: 0.13691319525241852
step: 120, loss: 0.035398125648498535
step: 130, loss: 0.034860629588365555
step: 140, loss: 0.02080214023590088
step: 150, loss: 0.15089714527130127
step: 160, loss: 0.030253564938902855
step: 170, loss: 9.252416202798486e-05
step: 180, loss: 0.04060924053192139
step: 190, loss: 0.034085892140865326
step: 200, loss: 0.004680371843278408
step: 210, loss: 0.013475468382239342
step: 220, loss: 0.033193767070770264
step: 230, loss: 0.10584823787212372
step: 240, loss: 0.0026102494448423386
step: 250, loss: 0.017855221405625343
step: 260, loss: 0.026043083518743515
step: 270, loss: 0.0030612528789788485
step: 280, loss: 0.020805444568395615
step: 290, loss: 0.09042754024267197
step: 300, loss: 0.025510963052511215
step: 310, loss: 4.2705560190370306e-05
step: 320, loss: 0.023579951375722885
step: 330, loss: 0.00012486788909882307
step: 340, loss: 6.021004082867876e-05
step: 350, loss: 0.01830783672630787
step: 360, loss: 0.03357299789786339
step: 370, loss: 0.05495147779583931
step: 380, loss: 0.02632642164826393
step: 390, loss: 0.01201826985925436
step: 400, loss: 0.000228722405154258
step: 410, loss: 0.017954431474208832
step: 420, loss: 0.07326886802911758
step: 430, loss: 0.03722389042377472
step: 440, loss: 0.01139563973993063
step: 450, loss: 0.07703964412212372
step: 460, loss: 0.06398198753595352
step: 470, loss: 0.10179740935564041
step: 480, loss: 0.05426975339651108
step: 490, loss: 0.019855421036481857
step: 500, loss: 0.021399542689323425
step: 510, loss: 4.692768561653793e-05
step: 520, loss: 0.06952422857284546
step: 530, loss: 0.04826511815190315
step: 540, loss: 0.04622320458292961
step: 550, loss: 2.447348742862232e-05
step: 560, loss: 0.019700895994901657
step: 570, loss: 0.04060335457324982
step: 580, loss: 0.10377482324838638
step: 590, loss: 0.04804566502571106
step: 600, loss: 0.050950776785612106
step: 610, loss: 0.0070829838514328
step: 620, loss: 0.012403979897499084
step: 630, loss: 0.021202944219112396
step: 640, loss: 0.018895285204052925
step: 650, loss: 0.02264958620071411
step: 660, loss: 0.03142012283205986
step: 670, loss: 0.06930598616600037
step: 680, loss: 0.031427960842847824
step: 690, loss: 0.04643458127975464
step: 700, loss: 0.04053260758519173
step: 710, loss: 0.0006107271765358746
step: 720, loss: 0.04666445776820183
step: 730, loss: 0.015394438989460468
step: 740, loss: 0.0613551065325737
step: 750, loss: 0.04013640806078911
step: 760, loss: 0.07177585363388062
step: 770, loss: 0.053377266973257065
step: 780, loss: 0.05101074278354645
step: 790, loss: 0.06476570665836334
step: 800, loss: 0.012339222244918346
step: 810, loss: 0.03307495266199112
step: 820, loss: 0.028643779456615448
step: 830, loss: 0.007026207633316517
step: 840, loss: 0.032323844730854034
step: 850, loss: 0.04142741113901138
step: 860, loss: 0.07165401428937912
step: 870, loss: 0.05066153034567833
step: 880, loss: 0.03163541853427887
step: 890, loss: 0.08526608347892761
step: 900, loss: 0.08831129968166351
step: 910, loss: 0.03713884949684143
step: 920, loss: 0.0005563133745454252
step: 930, loss: 0.03547847643494606
step: 940, loss: 0.05106901377439499
step: 950, loss: 0.038729555904865265
step: 960, loss: 0.07906938344240189
step: 970, loss: 0.03754163905978203
step: 980, loss: 0.0695953443646431
step: 990, loss: 0.008945855312049389
step: 1000, loss: 0.07143696397542953
step: 1010, loss: 0.09697849303483963
step: 1020, loss: 0.01534146536141634
step: 1030, loss: 0.0294050145894289
step: 1040, loss: 0.07584553956985474
step: 1050, loss: 0.04193183779716492
step: 1060, loss: 0.04702164977788925
step: 1070, loss: 0.02253705821931362
epoch 20: dev_f1=0.9270588235294117, f1=0.9274952919020715, best_f1=0.9338338808071328
