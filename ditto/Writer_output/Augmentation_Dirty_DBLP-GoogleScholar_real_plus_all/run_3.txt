cuda
Device: cuda
step: 0, loss: 0.7544777393341064
step: 10, loss: 0.6476415991783142
step: 20, loss: 0.6737515926361084
step: 30, loss: 0.2664969563484192
step: 40, loss: 0.301955908536911
step: 50, loss: 0.45894819498062134
step: 60, loss: 0.17572064697742462
step: 70, loss: 0.1699771136045456
step: 80, loss: 0.19229111075401306
step: 90, loss: 0.3452993631362915
step: 100, loss: 0.5426601767539978
step: 110, loss: 0.3314911723136902
step: 120, loss: 0.216887429356575
step: 130, loss: 0.17369820177555084
step: 140, loss: 0.3110738694667816
step: 150, loss: 0.2578544616699219
step: 160, loss: 0.21579332649707794
step: 170, loss: 0.18495754897594452
step: 180, loss: 0.055808719247579575
step: 190, loss: 0.0644790530204773
step: 200, loss: 0.24987860023975372
step: 210, loss: 0.3260859251022339
step: 220, loss: 0.12793290615081787
step: 230, loss: 0.26124948263168335
step: 240, loss: 0.15441274642944336
step: 250, loss: 0.20122507214546204
step: 260, loss: 0.10421991348266602
step: 270, loss: 0.17559459805488586
step: 280, loss: 0.15716031193733215
step: 290, loss: 0.05901170149445534
step: 300, loss: 0.14429160952568054
step: 310, loss: 0.15396635234355927
step: 320, loss: 0.09071125835180283
step: 330, loss: 0.08708886057138443
step: 340, loss: 0.20527614653110504
step: 350, loss: 0.1349375694990158
step: 360, loss: 0.09032541513442993
step: 370, loss: 0.10262269526720047
step: 380, loss: 0.06740082055330276
step: 390, loss: 0.14502839744091034
step: 400, loss: 0.1639043241739273
step: 410, loss: 0.12377618253231049
step: 420, loss: 0.20019352436065674
step: 430, loss: 0.12507030367851257
step: 440, loss: 0.25650134682655334
step: 450, loss: 0.20253919064998627
step: 460, loss: 0.21344059705734253
step: 470, loss: 0.3058016300201416
step: 480, loss: 0.12450095266103745
step: 490, loss: 0.20766790211200714
step: 500, loss: 0.17291203141212463
step: 510, loss: 0.10452627390623093
step: 520, loss: 0.21882495284080505
step: 530, loss: 0.10539643466472626
step: 540, loss: 0.08986704051494598
step: 550, loss: 0.20972871780395508
step: 560, loss: 0.12122123688459396
step: 570, loss: 0.1567409187555313
step: 580, loss: 0.08110662549734116
step: 590, loss: 0.06712593138217926
step: 600, loss: 0.03852745145559311
step: 610, loss: 0.13300153613090515
step: 620, loss: 0.13227903842926025
step: 630, loss: 0.20472364127635956
step: 640, loss: 0.24987781047821045
step: 650, loss: 0.16489703953266144
step: 660, loss: 0.2490132451057434
step: 670, loss: 0.17695586383342743
step: 680, loss: 0.12780746817588806
step: 690, loss: 0.10917896777391434
step: 700, loss: 0.22554855048656464
step: 710, loss: 0.09324486553668976
step: 720, loss: 0.23500381410121918
step: 730, loss: 0.11431416869163513
step: 740, loss: 0.054067570716142654
step: 750, loss: 0.276288777589798
step: 760, loss: 0.16446968913078308
step: 770, loss: 0.10301202535629272
step: 780, loss: 0.19209183752536774
step: 790, loss: 0.1884947419166565
step: 800, loss: 0.13862186670303345
step: 810, loss: 0.13306467235088348
step: 820, loss: 0.2215922772884369
step: 830, loss: 0.08547913283109665
step: 840, loss: 0.11417761445045471
step: 850, loss: 0.25406521558761597
step: 860, loss: 0.19052818417549133
step: 870, loss: 0.14879220724105835
step: 880, loss: 0.18359391391277313
step: 890, loss: 0.0777093842625618
step: 900, loss: 0.09438811987638474
step: 910, loss: 0.09221655875444412
step: 920, loss: 0.14709506928920746
step: 930, loss: 0.10027097165584564
step: 940, loss: 0.12355086207389832
step: 950, loss: 0.08563683927059174
step: 960, loss: 0.23419524729251862
step: 970, loss: 0.0901218056678772
step: 980, loss: 0.2878676950931549
step: 990, loss: 0.15939512848854065
step: 1000, loss: 0.20921599864959717
step: 1010, loss: 0.11252258718013763
step: 1020, loss: 0.05919864401221275
step: 1030, loss: 0.1728963851928711
step: 1040, loss: 0.13068023324012756
step: 1050, loss: 0.01735479012131691
step: 1060, loss: 0.06371333450078964
step: 1070, loss: 0.11138007044792175
epoch 1: dev_f1=0.9014466546112117, f1=0.8908765652951699, best_f1=0.8908765652951699
step: 0, loss: 0.13626134395599365
step: 10, loss: 0.11254554241895676
step: 20, loss: 0.05950472876429558
step: 30, loss: 0.11344625800848007
step: 40, loss: 0.07018937915563583
step: 50, loss: 0.176543191075325
step: 60, loss: 0.16933982074260712
step: 70, loss: 0.14504334330558777
step: 80, loss: 0.1102314442396164
step: 90, loss: 0.14831727743148804
step: 100, loss: 0.1455891728401184
step: 110, loss: 0.1253257840871811
step: 120, loss: 0.12142200022935867
step: 130, loss: 0.12592068314552307
step: 140, loss: 0.13744787871837616
step: 150, loss: 0.22289817035198212
step: 160, loss: 0.1306161880493164
step: 170, loss: 0.12305082380771637
step: 180, loss: 0.05534254014492035
step: 190, loss: 0.16433842480182648
step: 200, loss: 0.06506664305925369
step: 210, loss: 0.16087274253368378
step: 220, loss: 0.10412708669900894
step: 230, loss: 0.08130227774381638
step: 240, loss: 0.2429402619600296
step: 250, loss: 0.16298553347587585
step: 260, loss: 0.018667234107851982
step: 270, loss: 0.1342228204011917
step: 280, loss: 0.049502722918987274
step: 290, loss: 0.16120724380016327
step: 300, loss: 0.16057921946048737
step: 310, loss: 0.07594048976898193
step: 320, loss: 0.09567447006702423
step: 330, loss: 0.1080222800374031
step: 340, loss: 0.06801483035087585
step: 350, loss: 0.09675637632608414
step: 360, loss: 0.10913406312465668
step: 370, loss: 0.1080344095826149
step: 380, loss: 0.09656989574432373
step: 390, loss: 0.12072184681892395
step: 400, loss: 0.08620820939540863
step: 410, loss: 0.10291767120361328
step: 420, loss: 0.10863669216632843
step: 430, loss: 0.10971524566411972
step: 440, loss: 0.14959727227687836
step: 450, loss: 0.06579389423131943
step: 460, loss: 0.28950533270835876
step: 470, loss: 0.11899548768997192
step: 480, loss: 0.15455478429794312
step: 490, loss: 0.1073169931769371
step: 500, loss: 0.22415664792060852
step: 510, loss: 0.13753069937229156
step: 520, loss: 0.0886598601937294
step: 530, loss: 0.14385272562503815
step: 540, loss: 0.162745863199234
step: 550, loss: 0.2321089208126068
step: 560, loss: 0.11887317150831223
step: 570, loss: 0.042758435010910034
step: 580, loss: 0.09588249027729034
step: 590, loss: 0.1612987369298935
step: 600, loss: 0.09405295550823212
step: 610, loss: 0.05824172496795654
step: 620, loss: 0.21812787652015686
step: 630, loss: 0.07345618307590485
step: 640, loss: 0.2720082104206085
step: 650, loss: 0.16687050461769104
step: 660, loss: 0.07348503172397614
step: 670, loss: 0.058559756726026535
step: 680, loss: 0.11031948775053024
step: 690, loss: 0.19201824069023132
step: 700, loss: 0.0974980890750885
step: 710, loss: 0.10926157236099243
step: 720, loss: 0.080776646733284
step: 730, loss: 0.12374500930309296
step: 740, loss: 0.07465355098247528
step: 750, loss: 0.12691383063793182
step: 760, loss: 0.10754469037055969
step: 770, loss: 0.03752145171165466
step: 780, loss: 0.07628457993268967
step: 790, loss: 0.19207729399204254
step: 800, loss: 0.10396843403577805
step: 810, loss: 0.12341833114624023
step: 820, loss: 0.11116024851799011
step: 830, loss: 0.15216447412967682
step: 840, loss: 0.1482073962688446
step: 850, loss: 0.13529105484485626
step: 860, loss: 0.12344682216644287
step: 870, loss: 0.19677868485450745
step: 880, loss: 0.11316277086734772
step: 890, loss: 0.21953752636909485
step: 900, loss: 0.19914031028747559
step: 910, loss: 0.15236808359622955
step: 920, loss: 0.2628430128097534
step: 930, loss: 0.10021931678056717
step: 940, loss: 0.11482745409011841
step: 950, loss: 0.2666018009185791
step: 960, loss: 0.17789654433727264
step: 970, loss: 0.07116753607988358
step: 980, loss: 0.07830043882131577
step: 990, loss: 0.22589917480945587
step: 1000, loss: 0.09481001645326614
step: 1010, loss: 0.19733737409114838
step: 1020, loss: 0.1224106103181839
step: 1030, loss: 0.11176033318042755
step: 1040, loss: 0.048663172870874405
step: 1050, loss: 0.05150463432073593
step: 1060, loss: 0.17526723444461823
step: 1070, loss: 0.08543035387992859
epoch 2: dev_f1=0.9317453046266607, f1=0.9307479224376731, best_f1=0.9307479224376731
step: 0, loss: 0.1661188006401062
step: 10, loss: 0.15358899533748627
step: 20, loss: 0.07564259320497513
step: 30, loss: 0.0767674595117569
step: 40, loss: 0.22322450578212738
step: 50, loss: 0.05325539410114288
step: 60, loss: 0.14255167543888092
step: 70, loss: 0.07578522711992264
step: 80, loss: 0.134908527135849
step: 90, loss: 0.10331873595714569
step: 100, loss: 0.1439657360315323
step: 110, loss: 0.20821070671081543
step: 120, loss: 0.10405846685171127
step: 130, loss: 0.09885737299919128
step: 140, loss: 0.17906954884529114
step: 150, loss: 0.06740863621234894
step: 160, loss: 0.13274157047271729
step: 170, loss: 0.03411351889371872
step: 180, loss: 0.0850505530834198
step: 190, loss: 0.366470068693161
step: 200, loss: 0.03304044157266617
step: 210, loss: 0.13830527663230896
step: 220, loss: 0.06575987488031387
step: 230, loss: 0.07898825407028198
step: 240, loss: 0.36546263098716736
step: 250, loss: 0.1096542701125145
step: 260, loss: 0.1493883728981018
step: 270, loss: 0.09660656750202179
step: 280, loss: 0.09213477373123169
step: 290, loss: 0.049869105219841
step: 300, loss: 0.09849072247743607
step: 310, loss: 0.07905860245227814
step: 320, loss: 0.20569966733455658
step: 330, loss: 0.1597527265548706
step: 340, loss: 0.18431761860847473
step: 350, loss: 0.1011502593755722
step: 360, loss: 0.15010684728622437
step: 370, loss: 0.06730739772319794
step: 380, loss: 0.10893426090478897
step: 390, loss: 0.06750079244375229
step: 400, loss: 0.10379745811223984
step: 410, loss: 0.1257058084011078
step: 420, loss: 0.05289127305150032
step: 430, loss: 0.06844424456357956
step: 440, loss: 0.1455647200345993
step: 450, loss: 0.10691657662391663
step: 460, loss: 0.141684889793396
step: 470, loss: 0.11279652267694473
step: 480, loss: 0.055876150727272034
step: 490, loss: 0.1036313846707344
step: 500, loss: 0.08204740285873413
step: 510, loss: 0.08626870810985565
step: 520, loss: 0.1516379714012146
step: 530, loss: 0.13573579490184784
step: 540, loss: 0.11760491132736206
step: 550, loss: 0.1686324030160904
step: 560, loss: 0.03542803227901459
step: 570, loss: 0.038416165858507156
step: 580, loss: 0.11908134073019028
step: 590, loss: 0.1276601105928421
step: 600, loss: 0.11623579263687134
step: 610, loss: 0.12199446558952332
step: 620, loss: 0.08314629644155502
step: 630, loss: 0.1591176688671112
step: 640, loss: 0.1318611204624176
step: 650, loss: 0.10364985466003418
step: 660, loss: 0.07059419900178909
step: 670, loss: 0.10429102927446365
step: 680, loss: 0.07687363773584366
step: 690, loss: 0.14533661305904388
step: 700, loss: 0.10351918637752533
step: 710, loss: 0.061320096254348755
step: 720, loss: 0.06208476051688194
step: 730, loss: 0.09544535726308823
step: 740, loss: 0.13886120915412903
step: 750, loss: 0.10250937938690186
step: 760, loss: 0.0675661638379097
step: 770, loss: 0.07759083062410355
step: 780, loss: 0.1508556455373764
step: 790, loss: 0.11005700379610062
step: 800, loss: 0.08605936169624329
step: 810, loss: 0.1437462866306305
step: 820, loss: 0.15657466650009155
step: 830, loss: 0.06054265424609184
step: 840, loss: 0.0820908471941948
step: 850, loss: 0.05629522725939751
step: 860, loss: 0.11918789893388748
step: 870, loss: 0.1141207367181778
step: 880, loss: 0.20413514971733093
step: 890, loss: 0.16215984523296356
step: 900, loss: 0.1333538442850113
step: 910, loss: 0.17199736833572388
step: 920, loss: 0.23313157260417938
step: 930, loss: 0.1134236603975296
step: 940, loss: 0.18163302540779114
step: 950, loss: 0.1143399327993393
step: 960, loss: 0.1801309436559677
step: 970, loss: 0.09800111502408981
step: 980, loss: 0.08535321801900864
step: 990, loss: 0.06811637431383133
step: 1000, loss: 0.10170910507440567
step: 1010, loss: 0.13982918858528137
step: 1020, loss: 0.10064491629600525
step: 1030, loss: 0.13631953299045563
step: 1040, loss: 0.03087484836578369
step: 1050, loss: 0.10913001745939255
step: 1060, loss: 0.10629691183567047
step: 1070, loss: 0.05895361304283142
epoch 3: dev_f1=0.9319945230488362, f1=0.9271644525881814, best_f1=0.9271644525881814
step: 0, loss: 0.07561811804771423
step: 10, loss: 0.05828271806240082
step: 20, loss: 0.19281898438930511
step: 30, loss: 0.06356091797351837
step: 40, loss: 0.11062518507242203
step: 50, loss: 0.07784997671842575
step: 60, loss: 0.11232137680053711
step: 70, loss: 0.11031892895698547
step: 80, loss: 0.0031438604928553104
step: 90, loss: 0.03419314697384834
step: 100, loss: 0.10366383194923401
step: 110, loss: 0.13127374649047852
step: 120, loss: 0.02766556665301323
step: 130, loss: 0.1050274595618248
step: 140, loss: 0.07810064405202866
step: 150, loss: 0.11566411703824997
step: 160, loss: 0.09434816241264343
step: 170, loss: 0.1366199404001236
step: 180, loss: 0.07990908622741699
step: 190, loss: 0.037615641951560974
step: 200, loss: 0.038805849850177765
step: 210, loss: 0.1638568937778473
step: 220, loss: 0.09305187314748764
step: 230, loss: 0.027402076870203018
step: 240, loss: 0.07496244460344315
step: 250, loss: 0.07200635969638824
step: 260, loss: 0.07363269478082657
step: 270, loss: 0.06635673344135284
step: 280, loss: 0.18579795956611633
step: 290, loss: 0.12444913387298584
step: 300, loss: 0.13061055541038513
step: 310, loss: 0.11267250031232834
step: 320, loss: 0.17584656178951263
step: 330, loss: 0.14059250056743622
step: 340, loss: 0.07638827711343765
step: 350, loss: 0.10961049795150757
step: 360, loss: 0.03031718172132969
step: 370, loss: 0.12700970470905304
step: 380, loss: 0.120644211769104
step: 390, loss: 0.06000423803925514
step: 400, loss: 0.1180804893374443
step: 410, loss: 0.11760853976011276
step: 420, loss: 0.08697453886270523
step: 430, loss: 0.08021899312734604
step: 440, loss: 0.18351052701473236
step: 450, loss: 0.05174529179930687
step: 460, loss: 0.1308308243751526
step: 470, loss: 0.1314455270767212
step: 480, loss: 0.04772840812802315
step: 490, loss: 0.07130706310272217
step: 500, loss: 0.031991273164749146
step: 510, loss: 0.12641094624996185
step: 520, loss: 0.16729867458343506
step: 530, loss: 0.11778736859560013
step: 540, loss: 0.09275665879249573
step: 550, loss: 0.009344290941953659
step: 560, loss: 0.07784052193164825
step: 570, loss: 0.034384872764348984
step: 580, loss: 0.18922002613544464
step: 590, loss: 0.040827617049217224
step: 600, loss: 0.0549580454826355
step: 610, loss: 0.07590731233358383
step: 620, loss: 0.12522561848163605
step: 630, loss: 0.16278943419456482
step: 640, loss: 0.12679332494735718
step: 650, loss: 0.05778373032808304
step: 660, loss: 0.09834439307451248
step: 670, loss: 0.12572050094604492
step: 680, loss: 0.09527843445539474
step: 690, loss: 0.0794811025261879
step: 700, loss: 0.08797775208950043
step: 710, loss: 0.16722412407398224
step: 720, loss: 0.08183594048023224
step: 730, loss: 0.06204373762011528
step: 740, loss: 0.012733712792396545
step: 750, loss: 0.08245223015546799
step: 760, loss: 0.07650411128997803
step: 770, loss: 0.043168216943740845
step: 780, loss: 0.051396094262599945
step: 790, loss: 0.07982777059078217
step: 800, loss: 0.08373190462589264
step: 810, loss: 0.07746164500713348
step: 820, loss: 0.08833687752485275
step: 830, loss: 0.14402300119400024
step: 840, loss: 0.07476222515106201
step: 850, loss: 0.07297183573246002
step: 860, loss: 0.08274819701910019
step: 870, loss: 0.09125326573848724
step: 880, loss: 0.13398149609565735
step: 890, loss: 0.07134895026683807
step: 900, loss: 0.027799783274531364
step: 910, loss: 0.19834387302398682
step: 920, loss: 0.1505226194858551
step: 930, loss: 0.08357162773609161
step: 940, loss: 0.04532797262072563
step: 950, loss: 0.0632556900382042
step: 960, loss: 0.10948222130537033
step: 970, loss: 0.12909230589866638
step: 980, loss: 0.08684126287698746
step: 990, loss: 0.1379653811454773
step: 1000, loss: 0.08652347326278687
step: 1010, loss: 0.0497187003493309
step: 1020, loss: 0.1347372829914093
step: 1030, loss: 0.09868155419826508
step: 1040, loss: 0.09617328643798828
step: 1050, loss: 0.03852798789739609
step: 1060, loss: 0.17232699692249298
step: 1070, loss: 0.09489795565605164
epoch 4: dev_f1=0.9290444654683065, f1=0.922858495030762, best_f1=0.9271644525881814
step: 0, loss: 0.0721849799156189
step: 10, loss: 0.08914956450462341
step: 20, loss: 0.14897504448890686
step: 30, loss: 0.11164292693138123
step: 40, loss: 0.08864273875951767
step: 50, loss: 7.698171975789592e-05
step: 60, loss: 0.023921510204672813
step: 70, loss: 0.055825117975473404
step: 80, loss: 0.15169119834899902
step: 90, loss: 0.04934462532401085
step: 100, loss: 0.024873245507478714
step: 110, loss: 0.05364219471812248
step: 120, loss: 0.10032065957784653
step: 130, loss: 0.027796709910035133
step: 140, loss: 0.028124086558818817
step: 150, loss: 0.08197105675935745
step: 160, loss: 0.12735338509082794
step: 170, loss: 0.1563836634159088
step: 180, loss: 0.10826417803764343
step: 190, loss: 0.11108236759901047
step: 200, loss: 0.09581351280212402
step: 210, loss: 0.09666663408279419
step: 220, loss: 0.079666867852211
step: 230, loss: 0.2281278818845749
step: 240, loss: 0.09044770151376724
step: 250, loss: 0.12985818088054657
step: 260, loss: 0.09404629468917847
step: 270, loss: 0.07284736633300781
step: 280, loss: 0.09366342425346375
step: 290, loss: 0.09205065667629242
step: 300, loss: 0.1356833577156067
step: 310, loss: 0.07655516266822815
step: 320, loss: 0.12314411252737045
step: 330, loss: 0.08042661100625992
step: 340, loss: 0.0789458230137825
step: 350, loss: 0.10053902119398117
step: 360, loss: 0.046387821435928345
step: 370, loss: 0.2555113732814789
step: 380, loss: 0.07979515194892883
step: 390, loss: 0.13140013813972473
step: 400, loss: 0.07737699896097183
step: 410, loss: 0.17603899538516998
step: 420, loss: 0.02735326625406742
step: 430, loss: 0.09065395593643188
step: 440, loss: 0.0425468347966671
step: 450, loss: 0.0682477355003357
step: 460, loss: 0.0629478171467781
step: 470, loss: 0.10906121879816055
step: 480, loss: 0.07811152189970016
step: 490, loss: 0.15620122849941254
step: 500, loss: 0.12073218077421188
step: 510, loss: 0.03451951593160629
step: 520, loss: 0.045543111860752106
step: 530, loss: 0.07573672384023666
step: 540, loss: 0.039628542959690094
step: 550, loss: 0.0681835189461708
step: 560, loss: 0.14113830029964447
step: 570, loss: 0.11769293248653412
step: 580, loss: 0.14630839228630066
step: 590, loss: 0.12356244027614594
step: 600, loss: 0.06774269789457321
step: 610, loss: 0.0958273708820343
step: 620, loss: 0.20285913348197937
step: 630, loss: 0.1339998096227646
step: 640, loss: 0.001942600472830236
step: 650, loss: 0.10881625860929489
step: 660, loss: 0.10492078959941864
step: 670, loss: 0.13298319280147552
step: 680, loss: 0.09441124647855759
step: 690, loss: 0.14885863661766052
step: 700, loss: 0.08367209136486053
step: 710, loss: 0.049827586859464645
step: 720, loss: 0.07493606209754944
step: 730, loss: 0.11067210882902145
step: 740, loss: 0.05617609620094299
step: 750, loss: 0.04858572036027908
step: 760, loss: 0.11338888108730316
step: 770, loss: 0.026735952123999596
step: 780, loss: 0.13176408410072327
step: 790, loss: 0.057867445051670074
step: 800, loss: 0.07960440963506699
step: 810, loss: 0.1061505675315857
step: 820, loss: 0.137238010764122
step: 830, loss: 0.09978950023651123
step: 840, loss: 0.08983589708805084
step: 850, loss: 0.07967038452625275
step: 860, loss: 0.10261830687522888
step: 870, loss: 0.15840312838554382
step: 880, loss: 0.13148579001426697
step: 890, loss: 0.0507330559194088
step: 900, loss: 0.10421384125947952
step: 910, loss: 0.11522737145423889
step: 920, loss: 0.04189007356762886
step: 930, loss: 0.07719562202692032
step: 940, loss: 0.16002114117145538
step: 950, loss: 0.24253089725971222
step: 960, loss: 0.07897395640611649
step: 970, loss: 0.2884886860847473
step: 980, loss: 0.13118912279605865
step: 990, loss: 0.10486235469579697
step: 1000, loss: 0.08878759294748306
step: 1010, loss: 0.08243727684020996
step: 1020, loss: 0.07108525186777115
step: 1030, loss: 0.032455410808324814
step: 1040, loss: 0.027981940656900406
step: 1050, loss: 0.09357019513845444
step: 1060, loss: 0.07801418751478195
step: 1070, loss: 0.08895929157733917
epoch 5: dev_f1=0.9259606373008434, f1=0.9229332087809435, best_f1=0.9271644525881814
step: 0, loss: 0.05409829691052437
step: 10, loss: 0.05427158251404762
step: 20, loss: 0.016019346192479134
step: 30, loss: 0.06833628565073013
step: 40, loss: 0.1089451014995575
step: 50, loss: 0.13996388018131256
step: 60, loss: 0.07556870579719543
step: 70, loss: 0.030402738600969315
step: 80, loss: 0.09795848280191422
step: 90, loss: 0.11853349953889847
step: 100, loss: 0.18414300680160522
step: 110, loss: 0.04993658512830734
step: 120, loss: 0.015217413194477558
step: 130, loss: 0.06255626678466797
step: 140, loss: 0.06494995951652527
step: 150, loss: 0.0707118809223175
step: 160, loss: 0.047580502927303314
step: 170, loss: 0.03999047353863716
step: 180, loss: 0.01664213463664055
step: 190, loss: 0.020125266164541245
step: 200, loss: 0.12810668349266052
step: 210, loss: 0.1131308376789093
step: 220, loss: 0.09962359070777893
step: 230, loss: 0.024930108338594437
step: 240, loss: 0.11612752079963684
step: 250, loss: 0.05965434014797211
step: 260, loss: 0.08617980778217316
step: 270, loss: 0.13534151017665863
step: 280, loss: 0.041843973100185394
step: 290, loss: 0.14539851248264313
step: 300, loss: 0.08986863493919373
step: 310, loss: 0.0809410810470581
step: 320, loss: 0.14442263543605804
step: 330, loss: 0.10173777490854263
step: 340, loss: 0.05123385041952133
step: 350, loss: 0.11722229421138763
step: 360, loss: 0.16188548505306244
step: 370, loss: 0.18131381273269653
step: 380, loss: 0.11360891908407211
step: 390, loss: 0.20605050027370453
step: 400, loss: 0.023143194615840912
step: 410, loss: 0.11578395217657089
step: 420, loss: 0.16859903931617737
step: 430, loss: 0.0995490550994873
step: 440, loss: 0.06758169829845428
step: 450, loss: 0.12130516022443771
step: 460, loss: 0.12322792410850525
step: 470, loss: 0.13036224246025085
step: 480, loss: 0.11383069306612015
step: 490, loss: 0.031149351969361305
step: 500, loss: 0.000395524111809209
step: 510, loss: 0.10845141112804413
step: 520, loss: 0.010874202474951744
step: 530, loss: 0.10044689476490021
step: 540, loss: 0.07197723537683487
step: 550, loss: 0.013880317099392414
step: 560, loss: 0.1812656968832016
step: 570, loss: 0.1028752401471138
step: 580, loss: 0.11640701442956924
step: 590, loss: 0.05893741175532341
step: 600, loss: 0.17657607793807983
step: 610, loss: 0.01837838813662529
step: 620, loss: 0.09289450198411942
step: 630, loss: 0.08440840244293213
step: 640, loss: 0.07202087342739105
step: 650, loss: 0.12405543029308319
step: 660, loss: 0.05650454759597778
step: 670, loss: 0.07355837523937225
step: 680, loss: 0.16539807617664337
step: 690, loss: 0.1059834286570549
step: 700, loss: 0.055401962250471115
step: 710, loss: 0.0671384334564209
step: 720, loss: 0.16417640447616577
step: 730, loss: 0.10290023684501648
step: 740, loss: 0.08888287097215652
step: 750, loss: 0.1591523140668869
step: 760, loss: 0.09798170626163483
step: 770, loss: 0.16582117974758148
step: 780, loss: 0.03555537387728691
step: 790, loss: 0.023174425587058067
step: 800, loss: 0.05605391785502434
step: 810, loss: 0.09384509921073914
step: 820, loss: 0.05499293655157089
step: 830, loss: 0.08838891983032227
step: 840, loss: 0.0472666472196579
step: 850, loss: 0.24268324673175812
step: 860, loss: 0.0512981116771698
step: 870, loss: 0.06105268746614456
step: 880, loss: 0.16045111417770386
step: 890, loss: 0.11530294269323349
step: 900, loss: 0.04581252858042717
step: 910, loss: 0.11310400813817978
step: 920, loss: 0.07786263525485992
step: 930, loss: 0.1615930199623108
step: 940, loss: 0.09642419964075089
step: 950, loss: 0.03099312260746956
step: 960, loss: 0.05906439200043678
step: 970, loss: 0.0930757001042366
step: 980, loss: 0.09036919474601746
step: 990, loss: 0.08938764780759811
step: 1000, loss: 0.16463126242160797
step: 1010, loss: 0.06456371396780014
step: 1020, loss: 0.014766833744943142
step: 1030, loss: 0.038405898958444595
step: 1040, loss: 0.03519933670759201
step: 1050, loss: 0.022272437810897827
step: 1060, loss: 0.11645570397377014
step: 1070, loss: 0.03986988961696625
epoch 6: dev_f1=0.9381107491856677, f1=0.9334574220567706, best_f1=0.9334574220567706
step: 0, loss: 0.08941304683685303
step: 10, loss: 0.05983120575547218
step: 20, loss: 0.11090454459190369
step: 30, loss: 0.0010798097355291247
step: 40, loss: 0.10926920920610428
step: 50, loss: 0.11156109720468521
step: 60, loss: 0.11697793751955032
step: 70, loss: 0.06816601008176804
step: 80, loss: 0.0660434141755104
step: 90, loss: 0.155210942029953
step: 100, loss: 0.08998094499111176
step: 110, loss: 0.09581256657838821
step: 120, loss: 0.07630764693021774
step: 130, loss: 0.08259861916303635
step: 140, loss: 0.2210618257522583
step: 150, loss: 0.054627370089292526
step: 160, loss: 0.062389180064201355
step: 170, loss: 0.08896065503358841
step: 180, loss: 0.09802302718162537
step: 190, loss: 0.0717543289065361
step: 200, loss: 0.05211983621120453
step: 210, loss: 0.09694348275661469
step: 220, loss: 0.12546205520629883
step: 230, loss: 0.060711394995450974
step: 240, loss: 0.10493987053632736
step: 250, loss: 0.024155210703611374
step: 260, loss: 0.0057670315727591515
step: 270, loss: 0.14770884811878204
step: 280, loss: 0.10871872305870056
step: 290, loss: 0.14708584547042847
step: 300, loss: 0.021399253979325294
step: 310, loss: 0.03678126633167267
step: 320, loss: 0.09973429888486862
step: 330, loss: 0.11823545396327972
step: 340, loss: 0.058254387229681015
step: 350, loss: 0.041296642273664474
step: 360, loss: 0.0311872735619545
step: 370, loss: 0.09630395472049713
step: 380, loss: 0.08011355251073837
step: 390, loss: 0.16831156611442566
step: 400, loss: 0.09438890963792801
step: 410, loss: 0.06462402641773224
step: 420, loss: 0.046121224761009216
step: 430, loss: 0.09709988534450531
step: 440, loss: 0.07463163137435913
step: 450, loss: 0.04608685523271561
step: 460, loss: 0.07302499562501907
step: 470, loss: 0.03044627606868744
step: 480, loss: 0.1281835436820984
step: 490, loss: 0.07497458904981613
step: 500, loss: 0.13034309446811676
step: 510, loss: 0.1546279489994049
step: 520, loss: 0.0790022760629654
step: 530, loss: 0.06823758780956268
step: 540, loss: 0.07771018892526627
step: 550, loss: 0.03927742317318916
step: 560, loss: 0.021983984857797623
step: 570, loss: 0.032251786440610886
step: 580, loss: 0.06806307286024094
step: 590, loss: 0.10729923844337463
step: 600, loss: 0.02704664133489132
step: 610, loss: 0.05310023948550224
step: 620, loss: 0.013355540111660957
step: 630, loss: 0.08138158172369003
step: 640, loss: 0.10351215302944183
step: 650, loss: 0.09939643740653992
step: 660, loss: 0.05781690031290054
step: 670, loss: 0.02015220746397972
step: 680, loss: 0.1827806532382965
step: 690, loss: 0.10810744017362595
step: 700, loss: 0.025357292965054512
step: 710, loss: 0.038359384983778
step: 720, loss: 0.18543384969234467
step: 730, loss: 0.05389225482940674
step: 740, loss: 0.06423434615135193
step: 750, loss: 0.07486281543970108
step: 760, loss: 0.09968778491020203
step: 770, loss: 0.03651663288474083
step: 780, loss: 0.05553159862756729
step: 790, loss: 0.09734796732664108
step: 800, loss: 0.021409451961517334
step: 810, loss: 0.12986303865909576
step: 820, loss: 0.20309339463710785
step: 830, loss: 0.11920575797557831
step: 840, loss: 0.04499540477991104
step: 850, loss: 0.09734192490577698
step: 860, loss: 0.22625507414340973
step: 870, loss: 0.09395085275173187
step: 880, loss: 0.04242059960961342
step: 890, loss: 0.16153164207935333
step: 900, loss: 0.10855717957019806
step: 910, loss: 0.10896005481481552
step: 920, loss: 0.04633428528904915
step: 930, loss: 0.06615974754095078
step: 940, loss: 0.2337113469839096
step: 950, loss: 0.0973120778799057
step: 960, loss: 0.02554669976234436
step: 970, loss: 0.2083483189344406
step: 980, loss: 0.12322933971881866
step: 990, loss: 0.09320086240768433
step: 1000, loss: 0.05964510142803192
step: 1010, loss: 0.12736141681671143
step: 1020, loss: 0.12029065936803818
step: 1030, loss: 0.1613927036523819
step: 1040, loss: 0.08794251829385757
step: 1050, loss: 0.036309972405433655
step: 1060, loss: 0.07510943710803986
step: 1070, loss: 0.04843937233090401
epoch 7: dev_f1=0.9350885156604629, f1=0.9371584699453551, best_f1=0.9334574220567706
step: 0, loss: 0.08366607874631882
step: 10, loss: 5.863305341335945e-05
step: 20, loss: 0.10627929866313934
step: 30, loss: 0.12160289287567139
step: 40, loss: 0.18170949816703796
step: 50, loss: 0.09582018107175827
step: 60, loss: 0.0333271399140358
step: 70, loss: 0.09314559400081635
step: 80, loss: 0.06805538386106491
step: 90, loss: 0.04216400533914566
step: 100, loss: 0.06994352489709854
step: 110, loss: 0.1442040652036667
step: 120, loss: 0.07670082896947861
step: 130, loss: 0.03963688760995865
step: 140, loss: 0.01032910868525505
step: 150, loss: 0.030070913955569267
step: 160, loss: 0.10250648111104965
step: 170, loss: 0.13655009865760803
step: 180, loss: 0.01990140974521637
step: 190, loss: 0.037850722670555115
step: 200, loss: 0.03493596613407135
step: 210, loss: 0.06704150885343552
step: 220, loss: 0.04346761479973793
step: 230, loss: 0.0897471159696579
step: 240, loss: 0.09584849327802658
step: 250, loss: 0.046602290123701096
step: 260, loss: 0.12559519708156586
step: 270, loss: 0.14321154356002808
step: 280, loss: 0.06661199033260345
step: 290, loss: 0.11118151992559433
step: 300, loss: 0.06228720396757126
step: 310, loss: 0.10711710900068283
step: 320, loss: 0.11166415363550186
step: 330, loss: 0.05262859910726547
step: 340, loss: 0.04684148728847504
step: 350, loss: 0.08734486997127533
step: 360, loss: 0.09312485158443451
step: 370, loss: 0.18535731732845306
step: 380, loss: 0.1105792447924614
step: 390, loss: 0.11250267922878265
step: 400, loss: 0.0024513176176697016
step: 410, loss: 0.08250170201063156
step: 420, loss: 0.06250118464231491
step: 430, loss: 0.07912618666887283
step: 440, loss: 0.0469328872859478
step: 450, loss: 0.04527366906404495
step: 460, loss: 0.13215000927448273
step: 470, loss: 0.10038214176893234
step: 480, loss: 0.10117248445749283
step: 490, loss: 0.16035696864128113
step: 500, loss: 0.052229661494493484
step: 510, loss: 0.11675649136304855
step: 520, loss: 0.043814562261104584
step: 530, loss: 0.04547947272658348
step: 540, loss: 0.0822698250412941
step: 550, loss: 0.06741034984588623
step: 560, loss: 0.08335105329751968
step: 570, loss: 0.10000267624855042
step: 580, loss: 0.07454587519168854
step: 590, loss: 0.08613603562116623
step: 600, loss: 0.05141277238726616
step: 610, loss: 0.03638894110918045
step: 620, loss: 0.028585392981767654
step: 630, loss: 0.07591979205608368
step: 640, loss: 0.09436707943677902
step: 650, loss: 0.10147611796855927
step: 660, loss: 0.062474265694618225
step: 670, loss: 0.04087888076901436
step: 680, loss: 0.07130159437656403
step: 690, loss: 0.012087710201740265
step: 700, loss: 0.06897053122520447
step: 710, loss: 0.1044655442237854
step: 720, loss: 0.0892120972275734
step: 730, loss: 0.11677704751491547
step: 740, loss: 0.037073999643325806
step: 750, loss: 0.059036750346422195
step: 760, loss: 0.06195990741252899
step: 770, loss: 0.04964638501405716
step: 780, loss: 0.14123083651065826
step: 790, loss: 0.04292129725217819
step: 800, loss: 0.07403869181871414
step: 810, loss: 0.11953872442245483
step: 820, loss: 0.15693482756614685
step: 830, loss: 0.043222878128290176
step: 840, loss: 0.0700007751584053
step: 850, loss: 0.05349917337298393
step: 860, loss: 0.07407738268375397
step: 870, loss: 0.23450294137001038
step: 880, loss: 0.04832838475704193
step: 890, loss: 0.10015236586332321
step: 900, loss: 0.07598359882831573
step: 910, loss: 0.11160510033369064
step: 920, loss: 0.007439786102622747
step: 930, loss: 0.08289237320423126
step: 940, loss: 0.09500778466463089
step: 950, loss: 0.10219398140907288
step: 960, loss: 0.16919304430484772
step: 970, loss: 0.1645941138267517
step: 980, loss: 0.11809566617012024
step: 990, loss: 0.10531476885080338
step: 1000, loss: 0.18895591795444489
step: 1010, loss: 0.11542883515357971
step: 1020, loss: 0.07460231333971024
step: 1030, loss: 0.13626204431056976
step: 1040, loss: 0.13002383708953857
step: 1050, loss: 0.12742644548416138
step: 1060, loss: 0.06500363349914551
step: 1070, loss: 7.550635928055272e-05
epoch 8: dev_f1=0.9328984156570364, f1=0.929368029739777, best_f1=0.9334574220567706
step: 0, loss: 0.08137260377407074
step: 10, loss: 0.1238294467329979
step: 20, loss: 0.0636327862739563
step: 30, loss: 0.06067764759063721
step: 40, loss: 0.1181616559624672
step: 50, loss: 0.09239311516284943
step: 60, loss: 0.060335349291563034
step: 70, loss: 0.09369063377380371
step: 80, loss: 0.048994723707437515
step: 90, loss: 0.1268814355134964
step: 100, loss: 0.055607907474040985
step: 110, loss: 0.10476171970367432
step: 120, loss: 0.12332265824079514
step: 130, loss: 0.061773233115673065
step: 140, loss: 0.233123779296875
step: 150, loss: 0.1378081738948822
step: 160, loss: 0.10150858759880066
step: 170, loss: 0.04157020151615143
step: 180, loss: 0.02607010491192341
step: 190, loss: 0.03704040125012398
step: 200, loss: 0.03217155858874321
step: 210, loss: 0.08882413059473038
step: 220, loss: 0.04234786704182625
step: 230, loss: 0.1318487524986267
step: 240, loss: 0.06630811840295792
step: 250, loss: 0.039356354624032974
step: 260, loss: 0.11350374668836594
step: 270, loss: 0.025239020586013794
step: 280, loss: 0.12870705127716064
step: 290, loss: 0.023943977430462837
step: 300, loss: 0.0031354373786598444
step: 310, loss: 0.04652043431997299
step: 320, loss: 0.020998075604438782
step: 330, loss: 0.07650487124919891
step: 340, loss: 0.11448061466217041
step: 350, loss: 0.0881933718919754
step: 360, loss: 0.04120933637022972
step: 370, loss: 0.03396642208099365
step: 380, loss: 0.06408601254224777
step: 390, loss: 0.06178765371441841
step: 400, loss: 0.06323417276144028
step: 410, loss: 0.13984757661819458
step: 420, loss: 0.0757468044757843
step: 430, loss: 0.10500778257846832
step: 440, loss: 0.1334226131439209
step: 450, loss: 0.16152670979499817
step: 460, loss: 0.09325943887233734
step: 470, loss: 0.019386282190680504
step: 480, loss: 0.014058224856853485
step: 490, loss: 0.09252886474132538
step: 500, loss: 0.12063433974981308
step: 510, loss: 0.07578328251838684
step: 520, loss: 0.08570549637079239
step: 530, loss: 0.13745427131652832
step: 540, loss: 0.05382484942674637
step: 550, loss: 0.06938228011131287
step: 560, loss: 0.04277325049042702
step: 570, loss: 0.04794054478406906
step: 580, loss: 0.04686964303255081
step: 590, loss: 0.1907740831375122
step: 600, loss: 0.0302658062428236
step: 610, loss: 0.1758861094713211
step: 620, loss: 0.05601482465863228
step: 630, loss: 0.06814133375883102
step: 640, loss: 0.1036686822772026
step: 650, loss: 0.12684205174446106
step: 660, loss: 0.09018781036138535
step: 670, loss: 0.08261292427778244
step: 680, loss: 0.002720349235460162
step: 690, loss: 0.14140833914279938
step: 700, loss: 0.03676895424723625
step: 710, loss: 0.0746532753109932
step: 720, loss: 0.02473345398902893
step: 730, loss: 0.08423390984535217
step: 740, loss: 0.1395634263753891
step: 750, loss: 3.503513289615512e-05
step: 760, loss: 0.03792482987046242
step: 770, loss: 0.11004503071308136
step: 780, loss: 0.08647368103265762
step: 790, loss: 0.06520332396030426
step: 800, loss: 0.07433797419071198
step: 810, loss: 0.03884439170360565
step: 820, loss: 0.01764996536076069
step: 830, loss: 0.08191383630037308
step: 840, loss: 0.0921054407954216
step: 850, loss: 0.06744363158941269
step: 860, loss: 0.067037433385849
step: 870, loss: 0.08781391382217407
step: 880, loss: 0.06915049999952316
step: 890, loss: 0.09878427535295486
step: 900, loss: 0.03407958522439003
step: 910, loss: 0.06556976586580276
step: 920, loss: 0.09389632195234299
step: 930, loss: 0.05843192711472511
step: 940, loss: 0.07174459099769592
step: 950, loss: 0.1277773231267929
step: 960, loss: 0.02233847603201866
step: 970, loss: 0.08302701264619827
step: 980, loss: 0.051863979548215866
step: 990, loss: 0.1204567402601242
step: 1000, loss: 7.356049172813073e-05
step: 1010, loss: 0.06322556734085083
step: 1020, loss: 0.11392248421907425
step: 1030, loss: 0.14281302690505981
step: 1040, loss: 0.01781516708433628
step: 1050, loss: 0.007407960947602987
step: 1060, loss: 0.08319785445928574
step: 1070, loss: 0.09715239703655243
epoch 9: dev_f1=0.9311778290993071, f1=0.9306008383791335, best_f1=0.9334574220567706
step: 0, loss: 0.03430105373263359
step: 10, loss: 0.00010042362555395812
step: 20, loss: 0.09510111063718796
step: 30, loss: 0.11914513260126114
step: 40, loss: 0.044183433055877686
step: 50, loss: 0.06036816164851189
step: 60, loss: 0.18770863115787506
step: 70, loss: 0.024333154782652855
step: 80, loss: 0.15822042524814606
step: 90, loss: 0.03267223387956619
step: 100, loss: 0.013624152168631554
step: 110, loss: 0.09290392696857452
step: 120, loss: 0.032381799072027206
step: 130, loss: 0.10628563910722733
step: 140, loss: 0.0797402486205101
step: 150, loss: 0.008606995455920696
step: 160, loss: 0.035349104553461075
step: 170, loss: 0.022927183657884598
step: 180, loss: 0.24494554102420807
step: 190, loss: 0.019064564257860184
step: 200, loss: 0.052066609263420105
step: 210, loss: 0.11407117545604706
step: 220, loss: 0.11054963618516922
step: 230, loss: 0.09310548007488251
step: 240, loss: 0.3005499839782715
step: 250, loss: 0.07569379359483719
step: 260, loss: 0.07347822934389114
step: 270, loss: 0.014921876601874828
step: 280, loss: 0.0878555029630661
step: 290, loss: 0.08825290203094482
step: 300, loss: 0.055906545370817184
step: 310, loss: 0.10035928338766098
step: 320, loss: 0.04626895487308502
step: 330, loss: 0.06290821731090546
step: 340, loss: 0.09976334869861603
step: 350, loss: 0.05145551264286041
step: 360, loss: 0.015851231291890144
step: 370, loss: 0.03258638456463814
step: 380, loss: 0.09774625301361084
step: 390, loss: 0.06434022635221481
step: 400, loss: 0.11441399902105331
step: 410, loss: 0.21580015122890472
step: 420, loss: 0.11328332871198654
step: 430, loss: 0.11063303798437119
step: 440, loss: 0.06231701746582985
step: 450, loss: 0.04216517135500908
step: 460, loss: 0.13377711176872253
step: 470, loss: 0.07962662726640701
step: 480, loss: 0.05570874363183975
step: 490, loss: 0.00891486369073391
step: 500, loss: 0.06856167316436768
step: 510, loss: 0.04740084707736969
step: 520, loss: 0.11193612962961197
step: 530, loss: 0.11267464607954025
step: 540, loss: 0.12194351851940155
step: 550, loss: 0.1696249395608902
step: 560, loss: 0.15599480271339417
step: 570, loss: 0.017628971487283707
step: 580, loss: 0.07345940917730331
step: 590, loss: 0.08318427205085754
step: 600, loss: 0.023654114454984665
step: 610, loss: 0.10093782842159271
step: 620, loss: 0.04259250685572624
step: 630, loss: 0.18706603348255157
step: 640, loss: 0.018896915018558502
step: 650, loss: 0.05930810049176216
step: 660, loss: 0.09283573180437088
step: 670, loss: 0.03606255725026131
step: 680, loss: 0.07360449433326721
step: 690, loss: 0.100415900349617
step: 700, loss: 0.1923304945230484
step: 710, loss: 0.07409540563821793
step: 720, loss: 0.018920134752988815
step: 730, loss: 0.06960253417491913
step: 740, loss: 0.10809581726789474
step: 750, loss: 0.0667339339852333
step: 760, loss: 0.05002836138010025
step: 770, loss: 0.02438577264547348
step: 780, loss: 0.06425654888153076
step: 790, loss: 0.1037532389163971
step: 800, loss: 0.09619921445846558
step: 810, loss: 0.11604157090187073
step: 820, loss: 0.14131242036819458
step: 830, loss: 0.10669206082820892
step: 840, loss: 0.04649728909134865
step: 850, loss: 0.12054929882287979
step: 860, loss: 0.049694281071424484
step: 870, loss: 0.11481823772192001
step: 880, loss: 0.08453486859798431
step: 890, loss: 0.05884334072470665
step: 900, loss: 0.058425188064575195
step: 910, loss: 0.09275874495506287
step: 920, loss: 0.24724169075489044
step: 930, loss: 0.06755805760622025
step: 940, loss: 0.029162775725126266
step: 950, loss: 0.05317427217960358
step: 960, loss: 0.04697711020708084
step: 970, loss: 0.12388475984334946
step: 980, loss: 0.059456322342157364
step: 990, loss: 0.04824778437614441
step: 1000, loss: 0.044242795556783676
step: 1010, loss: 0.0823906660079956
step: 1020, loss: 0.11776028573513031
step: 1030, loss: 0.0213796254247427
step: 1040, loss: 0.1328648328781128
step: 1050, loss: 0.16445492208003998
step: 1060, loss: 0.10085583478212357
step: 1070, loss: 0.09501335769891739
epoch 10: dev_f1=0.9295904279797514, f1=0.9287696577243294, best_f1=0.9334574220567706
step: 0, loss: 0.07534510642290115
step: 10, loss: 0.02131008170545101
step: 20, loss: 0.0980280190706253
step: 30, loss: 0.09400341659784317
step: 40, loss: 0.09103778004646301
step: 50, loss: 0.11294545233249664
step: 60, loss: 0.018534895032644272
step: 70, loss: 0.032418373972177505
step: 80, loss: 0.08567674458026886
step: 90, loss: 0.05943598598241806
step: 100, loss: 0.044863082468509674
step: 110, loss: 0.04669400677084923
step: 120, loss: 0.10501652956008911
step: 130, loss: 0.031764909625053406
step: 140, loss: 0.07539655268192291
step: 150, loss: 0.028382787480950356
step: 160, loss: 0.04339970648288727
step: 170, loss: 0.06740721315145493
step: 180, loss: 0.03726435825228691
step: 190, loss: 0.044579386711120605
step: 200, loss: 0.04823760688304901
step: 210, loss: 0.056571125984191895
step: 220, loss: 0.07055867463350296
step: 230, loss: 0.09772396087646484
step: 240, loss: 0.1057867705821991
step: 250, loss: 0.03840484097599983
step: 260, loss: 0.013513077050447464
step: 270, loss: 0.11843687295913696
step: 280, loss: 0.018988100811839104
step: 290, loss: 0.08950033038854599
step: 300, loss: 0.04716983065009117
step: 310, loss: 0.0008211221429519355
step: 320, loss: 0.12292955815792084
step: 330, loss: 0.056646257638931274
step: 340, loss: 0.024813853204250336
step: 350, loss: 0.06759554147720337
step: 360, loss: 0.09296315908432007
step: 370, loss: 0.11741556972265244
step: 380, loss: 0.11714912205934525
step: 390, loss: 0.06032008305191994
step: 400, loss: 0.05089149251580238
step: 410, loss: 0.023966308683156967
step: 420, loss: 0.08107610046863556
step: 430, loss: 0.0406220369040966
step: 440, loss: 0.10155089944601059
step: 450, loss: 0.02585361897945404
step: 460, loss: 0.04928069934248924
step: 470, loss: 0.09307020902633667
step: 480, loss: 0.08434240520000458
step: 490, loss: 0.1411946713924408
step: 500, loss: 0.1451423466205597
step: 510, loss: 0.06859365850687027
step: 520, loss: 0.04957938194274902
step: 530, loss: 0.0587933175265789
step: 540, loss: 0.07356588542461395
step: 550, loss: 0.06265627592802048
step: 560, loss: 0.045205242931842804
step: 570, loss: 0.14597642421722412
step: 580, loss: 0.012381985783576965
step: 590, loss: 0.00038983800914138556
step: 600, loss: 0.03387308493256569
step: 610, loss: 0.07484494894742966
step: 620, loss: 0.004359062761068344
step: 630, loss: 0.03784298151731491
step: 640, loss: 0.033329322934150696
step: 650, loss: 0.10619157552719116
step: 660, loss: 0.03390052914619446
step: 670, loss: 0.0584481805562973
step: 680, loss: 0.022809447720646858
step: 690, loss: 0.09440878033638
step: 700, loss: 0.1028776466846466
step: 710, loss: 0.08554144203662872
step: 720, loss: 0.04529981687664986
step: 730, loss: 0.06601962447166443
step: 740, loss: 0.011977407149970531
step: 750, loss: 0.07651226222515106
step: 760, loss: 0.10092928260564804
step: 770, loss: 0.05408976227045059
step: 780, loss: 0.04516515135765076
step: 790, loss: 0.07217417657375336
step: 800, loss: 0.03691885247826576
step: 810, loss: 0.07794402539730072
step: 820, loss: 0.07275991141796112
step: 830, loss: 0.07331192493438721
step: 840, loss: 0.050224531441926956
step: 850, loss: 0.11285319179296494
step: 860, loss: 0.0011992213549092412
step: 870, loss: 0.10873690992593765
step: 880, loss: 0.022501520812511444
step: 890, loss: 0.018112245947122574
step: 900, loss: 0.09091216325759888
step: 910, loss: 0.03686508163809776
step: 920, loss: 0.052962835878133774
step: 930, loss: 0.08818651735782623
step: 940, loss: 0.1051652804017067
step: 950, loss: 0.09367730468511581
step: 960, loss: 0.07823392003774643
step: 970, loss: 0.05753423646092415
step: 980, loss: 0.008970389142632484
step: 990, loss: 0.1381506323814392
step: 1000, loss: 0.0564233772456646
step: 1010, loss: 0.0547497421503067
step: 1020, loss: 0.06115596741437912
step: 1030, loss: 0.006513630505651236
step: 1040, loss: 0.02961212396621704
step: 1050, loss: 0.10818663239479065
step: 1060, loss: 0.002490774029865861
step: 1070, loss: 0.052778858691453934
epoch 11: dev_f1=0.9239332096474954, f1=0.9272388059701492, best_f1=0.9334574220567706
step: 0, loss: 0.06826680153608322
step: 10, loss: 0.1241883933544159
step: 20, loss: 0.09796218574047089
step: 30, loss: 0.10932563245296478
step: 40, loss: 0.09386968612670898
step: 50, loss: 0.05936900153756142
step: 60, loss: 0.018086496740579605
step: 70, loss: 0.09213344752788544
step: 80, loss: 0.058949436992406845
step: 90, loss: 0.013420041650533676
step: 100, loss: 0.10404365509748459
step: 110, loss: 0.13000594079494476
step: 120, loss: 0.03299295902252197
step: 130, loss: 0.0698544979095459
step: 140, loss: 0.009196464903652668
step: 150, loss: 0.007110628765076399
step: 160, loss: 0.06073164939880371
step: 170, loss: 0.05586883798241615
step: 180, loss: 0.054100725799798965
step: 190, loss: 0.09354987740516663
step: 200, loss: 0.020752377808094025
step: 210, loss: 0.025236330926418304
step: 220, loss: 0.08440404385328293
step: 230, loss: 0.019829824566841125
step: 240, loss: 0.02828877419233322
step: 250, loss: 0.03483826294541359
step: 260, loss: 0.017789212986826897
step: 270, loss: 0.0007978958310559392
step: 280, loss: 0.02055531181395054
step: 290, loss: 0.060053158551454544
step: 300, loss: 0.16307751834392548
step: 310, loss: 0.030718592926859856
step: 320, loss: 0.099019855260849
step: 330, loss: 0.06138574704527855
step: 340, loss: 0.01678301952779293
step: 350, loss: 0.05884573981165886
step: 360, loss: 0.030421623960137367
step: 370, loss: 0.024683456867933273
step: 380, loss: 0.09349807351827621
step: 390, loss: 0.04208824411034584
step: 400, loss: 0.13097591698169708
step: 410, loss: 6.254822801565751e-05
step: 420, loss: 0.014336085878312588
step: 430, loss: 0.09780306369066238
step: 440, loss: 0.1128348708152771
step: 450, loss: 0.11284875869750977
step: 460, loss: 0.0452219620347023
step: 470, loss: 0.06414687633514404
step: 480, loss: 0.05577196180820465
step: 490, loss: 0.02884344384074211
step: 500, loss: 0.0015452923253178596
step: 510, loss: 0.040135886520147324
step: 520, loss: 0.09741903096437454
step: 530, loss: 0.05373441055417061
step: 540, loss: 0.0360877700150013
step: 550, loss: 0.010911974124610424
step: 560, loss: 0.01937764137983322
step: 570, loss: 0.07550942897796631
step: 580, loss: 0.14134910702705383
step: 590, loss: 0.10623117536306381
step: 600, loss: 0.0618748813867569
step: 610, loss: 0.08728568255901337
step: 620, loss: 0.1611386239528656
step: 630, loss: 0.1181168407201767
step: 640, loss: 0.046060748398303986
step: 650, loss: 0.013626026920974255
step: 660, loss: 0.02139023318886757
step: 670, loss: 0.06277750432491302
step: 680, loss: 0.04859935864806175
step: 690, loss: 0.06708493828773499
step: 700, loss: 0.06992226839065552
step: 710, loss: 0.08927567303180695
step: 720, loss: 0.10463804006576538
step: 730, loss: 0.17838868498802185
step: 740, loss: 0.027766475453972816
step: 750, loss: 0.19065722823143005
step: 760, loss: 0.14567998051643372
step: 770, loss: 0.02778741531074047
step: 780, loss: 0.06877399981021881
step: 790, loss: 0.0016290267230942845
step: 800, loss: 0.0671241283416748
step: 810, loss: 0.05131097510457039
step: 820, loss: 0.15202876925468445
step: 830, loss: 0.07022588700056076
step: 840, loss: 0.03369179740548134
step: 850, loss: 0.0291959997266531
step: 860, loss: 0.09041522443294525
step: 870, loss: 0.08013054728507996
step: 880, loss: 0.08899523317813873
step: 890, loss: 0.05692475661635399
step: 900, loss: 0.17294462025165558
step: 910, loss: 0.05586428567767143
step: 920, loss: 0.08002613484859467
step: 930, loss: 0.0795457512140274
step: 940, loss: 0.10392612963914871
step: 950, loss: 0.0728052482008934
step: 960, loss: 0.11415824294090271
step: 970, loss: 0.07149890065193176
step: 980, loss: 0.03817472606897354
step: 990, loss: 0.03496458753943443
step: 1000, loss: 0.02267351932823658
step: 1010, loss: 0.09075691550970078
step: 1020, loss: 0.03753567487001419
step: 1030, loss: 0.10882128775119781
step: 1040, loss: 0.039914820343256
step: 1050, loss: 0.0703291967511177
step: 1060, loss: 0.15708157420158386
step: 1070, loss: 0.007302847225219011
epoch 12: dev_f1=0.9287020109689212, f1=0.9308118081180812, best_f1=0.9334574220567706
step: 0, loss: 0.012402505613863468
step: 10, loss: 0.023246383294463158
step: 20, loss: 0.08203065395355225
step: 30, loss: 0.0047494107857346535
step: 40, loss: 0.056070949882268906
step: 50, loss: 0.006716995500028133
step: 60, loss: 0.09757418185472488
step: 70, loss: 0.06490776687860489
step: 80, loss: 0.07490838319063187
step: 90, loss: 0.04674379155039787
step: 100, loss: 0.05776083096861839
step: 110, loss: 0.049287039786577225
step: 120, loss: 0.0005268155946396291
step: 130, loss: 0.04284721240401268
step: 140, loss: 0.042803216725587845
step: 150, loss: 0.05796855688095093
step: 160, loss: 0.056919943541288376
step: 170, loss: 0.07920119166374207
step: 180, loss: 0.15231946110725403
step: 190, loss: 0.016208874061703682
step: 200, loss: 0.11856181919574738
step: 210, loss: 0.027959831058979034
step: 220, loss: 0.049261778593063354
step: 230, loss: 0.039201050996780396
step: 240, loss: 0.02069718763232231
step: 250, loss: 0.04176827520132065
step: 260, loss: 0.09456465393304825
step: 270, loss: 0.06599397212266922
step: 280, loss: 0.06013373285531998
step: 290, loss: 0.0685601457953453
step: 300, loss: 0.06119951233267784
step: 310, loss: 0.04421839863061905
step: 320, loss: 0.06677892059087753
step: 330, loss: 0.055228978395462036
step: 340, loss: 0.06320718675851822
step: 350, loss: 0.04146597906947136
step: 360, loss: 0.04303444176912308
step: 370, loss: 0.004745610058307648
step: 380, loss: 0.05315352603793144
step: 390, loss: 0.12507769465446472
step: 400, loss: 0.05279845744371414
step: 410, loss: 0.07333792001008987
step: 420, loss: 0.013549461960792542
step: 430, loss: 0.006868625991046429
step: 440, loss: 0.10951044410467148
step: 450, loss: 0.11663039773702621
step: 460, loss: 0.0002607525384519249
step: 470, loss: 0.03365769609808922
step: 480, loss: 0.038789551705121994
step: 490, loss: 0.06727928668260574
step: 500, loss: 0.0013376901624724269
step: 510, loss: 0.08332445472478867
step: 520, loss: 0.024343768134713173
step: 530, loss: 0.04650136083364487
step: 540, loss: 0.0896267220377922
step: 550, loss: 0.06366601586341858
step: 560, loss: 0.09651292860507965
step: 570, loss: 0.04966980963945389
step: 580, loss: 0.039791371673345566
step: 590, loss: 0.08687795698642731
step: 600, loss: 0.0742725357413292
step: 610, loss: 0.021586475893855095
step: 620, loss: 0.053582608699798584
step: 630, loss: 0.008666232228279114
step: 640, loss: 0.01753571815788746
step: 650, loss: 0.06925815343856812
step: 660, loss: 0.02034493163228035
step: 670, loss: 0.1862979233264923
step: 680, loss: 0.045194875448942184
step: 690, loss: 0.01652214489877224
step: 700, loss: 0.05627809092402458
step: 710, loss: 0.07832935452461243
step: 720, loss: 0.04547669366002083
step: 730, loss: 0.023479219526052475
step: 740, loss: 0.13626964390277863
step: 750, loss: 0.20256540179252625
step: 760, loss: 0.07286519557237625
step: 770, loss: 0.04498008266091347
step: 780, loss: 0.12271435558795929
step: 790, loss: 0.0849934071302414
step: 800, loss: 0.10361966490745544
step: 810, loss: 0.015941713005304337
step: 820, loss: 0.0666210800409317
step: 830, loss: 0.031649380922317505
step: 840, loss: 0.024880439043045044
step: 850, loss: 0.10839088261127472
step: 860, loss: 0.047769106924533844
step: 870, loss: 0.04751582443714142
step: 880, loss: 0.025623420253396034
step: 890, loss: 0.11959417909383774
step: 900, loss: 0.052129246294498444
step: 910, loss: 0.07943100482225418
step: 920, loss: 0.06008964031934738
step: 930, loss: 0.02606845647096634
step: 940, loss: 0.05390501767396927
step: 950, loss: 0.003892493201419711
step: 960, loss: 0.009309292770922184
step: 970, loss: 0.0033425074070692062
step: 980, loss: 0.09302844852209091
step: 990, loss: 0.08725360035896301
step: 1000, loss: 0.08233028650283813
step: 1010, loss: 0.07916330546140671
step: 1020, loss: 0.1615528166294098
step: 1030, loss: 0.0818987637758255
step: 1040, loss: 0.03826943784952164
step: 1050, loss: 0.03831952065229416
step: 1060, loss: 0.027594031766057014
step: 1070, loss: 0.040477242320775986
epoch 13: dev_f1=0.9301249421564091, f1=0.9302325581395349, best_f1=0.9334574220567706
step: 0, loss: 0.024977874010801315
step: 10, loss: 0.040755897760391235
step: 20, loss: 0.024391988292336464
step: 30, loss: 0.10029871016740799
step: 40, loss: 0.03262636438012123
step: 50, loss: 0.021794339641928673
step: 60, loss: 0.07074034959077835
step: 70, loss: 0.00028585357358679175
step: 80, loss: 0.021901719272136688
step: 90, loss: 0.038288380950689316
step: 100, loss: 0.02439885400235653
step: 110, loss: 0.061076387763023376
step: 120, loss: 0.026769554242491722
step: 130, loss: 0.032649703323841095
step: 140, loss: 0.06422369927167892
step: 150, loss: 0.054531775414943695
step: 160, loss: 0.04500669613480568
step: 170, loss: 0.0975470095872879
step: 180, loss: 0.05243725702166557
step: 190, loss: 0.0006232669693417847
step: 200, loss: 0.03167785704135895
step: 210, loss: 0.04379492253065109
step: 220, loss: 0.0005852093454450369
step: 230, loss: 0.01096399873495102
step: 240, loss: 0.01727508381009102
step: 250, loss: 0.03414217382669449
step: 260, loss: 0.08438868075609207
step: 270, loss: 0.022618960589170456
step: 280, loss: 0.05852440372109413
step: 290, loss: 0.03420119732618332
step: 300, loss: 0.010412435978651047
step: 310, loss: 0.0105294743552804
step: 320, loss: 0.006524223368614912
step: 330, loss: 0.16042892634868622
step: 340, loss: 0.07944105565547943
step: 350, loss: 0.14905931055545807
step: 360, loss: 0.08200917392969131
step: 370, loss: 0.024551577866077423
step: 380, loss: 0.055726297199726105
step: 390, loss: 0.059108514338731766
step: 400, loss: 0.04651745408773422
step: 410, loss: 0.012574762105941772
step: 420, loss: 0.16125187277793884
step: 430, loss: 0.041315943002700806
step: 440, loss: 0.0009198266197927296
step: 450, loss: 0.0074199652299284935
step: 460, loss: 0.02641129121184349
step: 470, loss: 0.05211938917636871
step: 480, loss: 0.028219804167747498
step: 490, loss: 0.007381491828709841
step: 500, loss: 0.04940865561366081
step: 510, loss: 0.05341599881649017
step: 520, loss: 0.03295435011386871
step: 530, loss: 0.024536363780498505
step: 540, loss: 0.026409996673464775
step: 550, loss: 0.0022191526368260384
step: 560, loss: 0.09396205842494965
step: 570, loss: 0.08938101679086685
step: 580, loss: 0.09908122569322586
step: 590, loss: 0.08657220751047134
step: 600, loss: 0.024771539494395256
step: 610, loss: 0.08749851584434509
step: 620, loss: 0.03936078026890755
step: 630, loss: 0.11671381443738937
step: 640, loss: 0.048090022057294846
step: 650, loss: 0.05846604332327843
step: 660, loss: 0.06511589139699936
step: 670, loss: 0.01723448932170868
step: 680, loss: 0.007564184255897999
step: 690, loss: 0.020815759897232056
step: 700, loss: 0.01964567042887211
step: 710, loss: 0.12859012186527252
step: 720, loss: 0.1973492056131363
step: 730, loss: 0.06942634284496307
step: 740, loss: 0.05071869120001793
step: 750, loss: 0.07957897335290909
step: 760, loss: 0.04570678994059563
step: 770, loss: 0.08619170635938644
step: 780, loss: 0.08538752794265747
step: 790, loss: 0.09887820482254028
step: 800, loss: 0.009099660441279411
step: 810, loss: 0.017497926950454712
step: 820, loss: 0.034178171306848526
step: 830, loss: 0.10006080567836761
step: 840, loss: 0.06998979300260544
step: 850, loss: 0.026800092309713364
step: 860, loss: 0.05795643478631973
step: 870, loss: 0.08062389492988586
step: 880, loss: 0.04186280444264412
step: 890, loss: 0.00015941125457175076
step: 900, loss: 0.007791084703058004
step: 910, loss: 0.05619349703192711
step: 920, loss: 0.20862247049808502
step: 930, loss: 0.055874861776828766
step: 940, loss: 0.06129937991499901
step: 950, loss: 0.03465402126312256
step: 960, loss: 0.05784214660525322
step: 970, loss: 0.057401590049266815
step: 980, loss: 0.04340759664773941
step: 990, loss: 0.05111163854598999
step: 1000, loss: 0.061324592679739
step: 1010, loss: 0.01526978425681591
step: 1020, loss: 0.10641863197088242
step: 1030, loss: 0.019990643486380577
step: 1040, loss: 0.023791050538420677
step: 1050, loss: 0.05447481572628021
step: 1060, loss: 0.0018619400216266513
step: 1070, loss: 0.07083271443843842
epoch 14: dev_f1=0.9300373134328358, f1=0.9256120527306968, best_f1=0.9334574220567706
step: 0, loss: 0.1718984991312027
step: 10, loss: 0.14343227446079254
step: 20, loss: 0.10143177956342697
step: 30, loss: 0.16539518535137177
step: 40, loss: 0.06174096092581749
step: 50, loss: 0.1328270584344864
step: 60, loss: 0.031351178884506226
step: 70, loss: 0.10846571624279022
step: 80, loss: 0.031558457762002945
step: 90, loss: 0.0706135481595993
step: 100, loss: 0.09718850255012512
step: 110, loss: 0.03609594330191612
step: 120, loss: 0.04632050171494484
step: 130, loss: 0.0177119392901659
step: 140, loss: 0.10675660520792007
step: 150, loss: 0.09706899523735046
step: 160, loss: 0.03913413733243942
step: 170, loss: 0.11690452694892883
step: 180, loss: 0.09298666566610336
step: 190, loss: 0.07755767554044724
step: 200, loss: 0.08268411457538605
step: 210, loss: 0.03285359963774681
step: 220, loss: 0.06277278810739517
step: 230, loss: 0.017203329131007195
step: 240, loss: 0.001519184559583664
step: 250, loss: 0.0011589208152145147
step: 260, loss: 0.03167489171028137
step: 270, loss: 0.008429751731455326
step: 280, loss: 0.019946357235312462
step: 290, loss: 0.0365874283015728
step: 300, loss: 0.08606330305337906
step: 310, loss: 0.006948214489966631
step: 320, loss: 0.10931872576475143
step: 330, loss: 0.10280018299818039
step: 340, loss: 0.014155090786516666
step: 350, loss: 0.026298772543668747
step: 360, loss: 0.06696517020463943
step: 370, loss: 0.05489441007375717
step: 380, loss: 0.06904977560043335
step: 390, loss: 0.037964146584272385
step: 400, loss: 0.018424957990646362
step: 410, loss: 0.017304494976997375
step: 420, loss: 0.06686832755804062
step: 430, loss: 0.0857808068394661
step: 440, loss: 0.053980980068445206
step: 450, loss: 0.05155177786946297
step: 460, loss: 0.05824584141373634
step: 470, loss: 0.03592616692185402
step: 480, loss: 0.037334028631448746
step: 490, loss: 0.012458570301532745
step: 500, loss: 0.011575152166187763
step: 510, loss: 0.05097811296582222
step: 520, loss: 0.018050825223326683
step: 530, loss: 0.06295911967754364
step: 540, loss: 0.09963752329349518
step: 550, loss: 0.0183300469070673
step: 560, loss: 0.06985477358102798
step: 570, loss: 0.06902669370174408
step: 580, loss: 0.05934496968984604
step: 590, loss: 0.0005221323226578534
step: 600, loss: 0.0038136031944304705
step: 610, loss: 0.04330785572528839
step: 620, loss: 0.015866555273532867
step: 630, loss: 0.06013045459985733
step: 640, loss: 0.09020121395587921
step: 650, loss: 0.037542928010225296
step: 660, loss: 0.07166086882352829
step: 670, loss: 0.03952164202928543
step: 680, loss: 0.010447079315781593
step: 690, loss: 0.10062744468450546
step: 700, loss: 0.06015755981206894
step: 710, loss: 0.06655969470739365
step: 720, loss: 0.05675973370671272
step: 730, loss: 0.06033153831958771
step: 740, loss: 0.06938060373067856
step: 750, loss: 0.05317729711532593
step: 760, loss: 0.0210229754447937
step: 770, loss: 0.05689787492156029
step: 780, loss: 0.022021960467100143
step: 790, loss: 0.010892211459577084
step: 800, loss: 0.007883098907768726
step: 810, loss: 0.023380057886242867
step: 820, loss: 0.04224323853850365
step: 830, loss: 0.025189543142914772
step: 840, loss: 0.11184531450271606
step: 850, loss: 0.11083295196294785
step: 860, loss: 0.06384096294641495
step: 870, loss: 0.05909326300024986
step: 880, loss: 0.018358349800109863
step: 890, loss: 0.04817550629377365
step: 900, loss: 0.006903729867190123
step: 910, loss: 0.03562731668353081
step: 920, loss: 0.05330226942896843
step: 930, loss: 0.061548709869384766
step: 940, loss: 0.0001410378172295168
step: 950, loss: 0.0383777841925621
step: 960, loss: 0.11141771078109741
step: 970, loss: 0.03783644735813141
step: 980, loss: 0.11278900504112244
step: 990, loss: 0.03757229447364807
step: 1000, loss: 0.10731007903814316
step: 1010, loss: 0.045076485723257065
step: 1020, loss: 0.09194212406873703
step: 1030, loss: 0.0028165634721517563
step: 1040, loss: 0.040576476603746414
step: 1050, loss: 0.03189246729016304
step: 1060, loss: 1.2889343452116009e-05
step: 1070, loss: 0.09255655109882355
epoch 15: dev_f1=0.9313047487321346, f1=0.9282385834109972, best_f1=0.9334574220567706
step: 0, loss: 0.02105703018605709
step: 10, loss: 0.05930145084857941
step: 20, loss: 0.022463643923401833
step: 30, loss: 0.0882781371474266
step: 40, loss: 5.4455900681205094e-05
step: 50, loss: 0.052885644137859344
step: 60, loss: 0.03308877348899841
step: 70, loss: 0.016146931797266006
step: 80, loss: 0.10649674385786057
step: 90, loss: 0.00552409328520298
step: 100, loss: 0.04422477260231972
step: 110, loss: 0.03495694324374199
step: 120, loss: 0.0662069022655487
step: 130, loss: 0.08885794132947922
step: 140, loss: 0.0005598588613793254
step: 150, loss: 0.013662507757544518
step: 160, loss: 0.06186250224709511
step: 170, loss: 0.05103641375899315
step: 180, loss: 0.019168946892023087
step: 190, loss: 0.03523316979408264
step: 200, loss: 0.04031315818428993
step: 210, loss: 0.045341331511735916
step: 220, loss: 0.11297448724508286
step: 230, loss: 0.027928311377763748
step: 240, loss: 0.04520034417510033
step: 250, loss: 0.0005181136075407267
step: 260, loss: 0.02870193123817444
step: 270, loss: 0.05040045082569122
step: 280, loss: 0.0036538243293762207
step: 290, loss: 0.05038793012499809
step: 300, loss: 0.04461536183953285
step: 310, loss: 0.023873042315244675
step: 320, loss: 0.04866323247551918
step: 330, loss: 0.06515849381685257
step: 340, loss: 0.12591934204101562
step: 350, loss: 0.11847556382417679
step: 360, loss: 0.0357636883854866
step: 370, loss: 9.322655387222767e-05
step: 380, loss: 0.04236551746726036
step: 390, loss: 0.03147900477051735
step: 400, loss: 0.05014340206980705
step: 410, loss: 0.0774216428399086
step: 420, loss: 0.15836389362812042
step: 430, loss: 0.01861073262989521
step: 440, loss: 0.043336521834135056
step: 450, loss: 0.19215214252471924
step: 460, loss: 0.0628100261092186
step: 470, loss: 0.037849027663469315
step: 480, loss: 0.026418237015604973
step: 490, loss: 0.051210083067417145
step: 500, loss: 0.09024229645729065
step: 510, loss: 0.034621719270944595
step: 520, loss: 0.019430367276072502
step: 530, loss: 0.07609148323535919
step: 540, loss: 0.050631601363420486
step: 550, loss: 0.052104704082012177
step: 560, loss: 0.14884789288043976
step: 570, loss: 0.05588667094707489
step: 580, loss: 0.04121272265911102
step: 590, loss: 0.03583736717700958
step: 600, loss: 0.026605864986777306
step: 610, loss: 0.07480428367853165
step: 620, loss: 0.0953131839632988
step: 630, loss: 0.01348637230694294
step: 640, loss: 0.09597451984882355
step: 650, loss: 0.026661578565835953
step: 660, loss: 0.019752508029341698
step: 670, loss: 0.07911181449890137
step: 680, loss: 0.08815928548574448
step: 690, loss: 0.044696323573589325
step: 700, loss: 0.10021553933620453
step: 710, loss: 0.017840472981333733
step: 720, loss: 0.06612495332956314
step: 730, loss: 0.02842048555612564
step: 740, loss: 0.031306494027376175
step: 750, loss: 0.15056034922599792
step: 760, loss: 5.407204298535362e-05
step: 770, loss: 0.020173367112874985
step: 780, loss: 0.09131420403718948
step: 790, loss: 0.20943206548690796
step: 800, loss: 0.032044846564531326
step: 810, loss: 0.07210294902324677
step: 820, loss: 0.03110293298959732
step: 830, loss: 0.12297256290912628
step: 840, loss: 0.0706382542848587
step: 850, loss: 0.05873896926641464
step: 860, loss: 0.04003879427909851
step: 870, loss: 0.040905918926000595
step: 880, loss: 0.0005437125219032168
step: 890, loss: 0.08972980082035065
step: 900, loss: 0.028495699167251587
step: 910, loss: 0.05694631114602089
step: 920, loss: 0.04965808987617493
step: 930, loss: 6.217252666829154e-05
step: 940, loss: 0.04079700633883476
step: 950, loss: 0.06259740889072418
step: 960, loss: 0.02771080657839775
step: 970, loss: 0.05524159222841263
step: 980, loss: 0.027557536959648132
step: 990, loss: 0.03192843124270439
step: 1000, loss: 0.016100186854600906
step: 1010, loss: 0.10715942084789276
step: 1020, loss: 0.14921784400939941
step: 1030, loss: 0.019209764897823334
step: 1040, loss: 0.06538480520248413
step: 1050, loss: 0.02265325002372265
step: 1060, loss: 0.09133046865463257
step: 1070, loss: 0.09279876202344894
epoch 16: dev_f1=0.92814093648586, f1=0.9305361305361305, best_f1=0.9334574220567706
step: 0, loss: 0.00029141883715055883
step: 10, loss: 0.0064775049686431885
step: 20, loss: 0.018513180315494537
step: 30, loss: 0.09033878892660141
step: 40, loss: 0.07854753732681274
step: 50, loss: 0.10750218480825424
step: 60, loss: 0.09552906453609467
step: 70, loss: 0.025398798286914825
step: 80, loss: 0.00026615458773449063
step: 90, loss: 0.02549630030989647
step: 100, loss: 1.4956375707697589e-05
step: 110, loss: 0.13241596519947052
step: 120, loss: 1.755993434926495e-05
step: 130, loss: 0.03712446242570877
step: 140, loss: 0.022416716441512108
step: 150, loss: 0.10449599474668503
step: 160, loss: 0.016535792499780655
step: 170, loss: 0.01835775002837181
step: 180, loss: 0.030390625819563866
step: 190, loss: 0.018083008006215096
step: 200, loss: 0.06967712938785553
step: 210, loss: 0.050204675644636154
step: 220, loss: 0.05399148538708687
step: 230, loss: 0.013966791331768036
step: 240, loss: 0.021042928099632263
step: 250, loss: 0.07761455327272415
step: 260, loss: 0.00019452429842203856
step: 270, loss: 0.10249883681535721
step: 280, loss: 0.11123696714639664
step: 290, loss: 0.06699811667203903
step: 300, loss: 0.12148647010326385
step: 310, loss: 0.042568180710077286
step: 320, loss: 0.07969027757644653
step: 330, loss: 0.08655353635549545
step: 340, loss: 0.06243862584233284
step: 350, loss: 0.05618327483534813
step: 360, loss: 0.09337416291236877
step: 370, loss: 0.06866373866796494
step: 380, loss: 0.028064094483852386
step: 390, loss: 0.00028705719159916043
step: 400, loss: 0.009945853613317013
step: 410, loss: 0.0580158457159996
step: 420, loss: 0.059762369841337204
step: 430, loss: 0.049578625708818436
step: 440, loss: 0.012413488700985909
step: 450, loss: 0.0220099575817585
step: 460, loss: 0.07821749895811081
step: 470, loss: 0.000363716681022197
step: 480, loss: 8.056523802224547e-05
step: 490, loss: 0.048691194504499435
step: 500, loss: 0.07730263471603394
step: 510, loss: 0.04494943097233772
step: 520, loss: 0.03930066525936127
step: 530, loss: 0.06438450515270233
step: 540, loss: 0.0005420663510449231
step: 550, loss: 0.07681948691606522
step: 560, loss: 0.08422436565160751
step: 570, loss: 4.771004751091823e-05
step: 580, loss: 0.08581192046403885
step: 590, loss: 0.0005263497005216777
step: 600, loss: 0.031201856210827827
step: 610, loss: 0.006360472645610571
step: 620, loss: 0.11055423319339752
step: 630, loss: 0.07419080287218094
step: 640, loss: 0.052800655364990234
step: 650, loss: 0.12775035202503204
step: 660, loss: 0.01686527393758297
step: 670, loss: 0.0582544170320034
step: 680, loss: 0.025821760296821594
step: 690, loss: 0.10188502818346024
step: 700, loss: 0.09552431106567383
step: 710, loss: 0.16755928099155426
step: 720, loss: 0.03719993680715561
step: 730, loss: 0.051325783133506775
step: 740, loss: 0.2129420042037964
step: 750, loss: 0.0504431389272213
step: 760, loss: 0.08089294284582138
step: 770, loss: 0.04490872099995613
step: 780, loss: 0.0075881946831941605
step: 790, loss: 0.014967937022447586
step: 800, loss: 0.056029852479696274
step: 810, loss: 0.019254164770245552
step: 820, loss: 3.798993202508427e-05
step: 830, loss: 0.04014160484075546
step: 840, loss: 0.06286133080720901
step: 850, loss: 0.028737246990203857
step: 860, loss: 0.09207800030708313
step: 870, loss: 0.04825683310627937
step: 880, loss: 0.11015032976865768
step: 890, loss: 0.03866204991936684
step: 900, loss: 0.08534255623817444
step: 910, loss: 0.044145580381155014
step: 920, loss: 0.024544520303606987
step: 930, loss: 0.05931190401315689
step: 940, loss: 0.07595732808113098
step: 950, loss: 0.023640181869268417
step: 960, loss: 0.12395218759775162
step: 970, loss: 0.08911573886871338
step: 980, loss: 0.022165022790431976
step: 990, loss: 0.08018136024475098
step: 1000, loss: 0.007831121794879436
step: 1010, loss: 0.026996714994311333
step: 1020, loss: 0.034167785197496414
step: 1030, loss: 0.026055514812469482
step: 1040, loss: 0.06505167484283447
step: 1050, loss: 0.010268677957355976
step: 1060, loss: 0.031947266310453415
step: 1070, loss: 0.05048748850822449
epoch 17: dev_f1=0.929840972871843, f1=0.9262564584311883, best_f1=0.9334574220567706
step: 0, loss: 0.04570547491312027
step: 10, loss: 0.00041675553075037897
step: 20, loss: 0.04212350398302078
step: 30, loss: 0.04432900622487068
step: 40, loss: 0.04330521821975708
step: 50, loss: 0.07335052639245987
step: 60, loss: 0.16853158175945282
step: 70, loss: 0.02636156789958477
step: 80, loss: 0.02877023257315159
step: 90, loss: 0.11130038648843765
step: 100, loss: 0.05430316925048828
step: 110, loss: 0.013050851412117481
step: 120, loss: 3.255776027799584e-05
step: 130, loss: 0.03257540613412857
step: 140, loss: 0.06756199151277542
step: 150, loss: 0.12416677922010422
step: 160, loss: 0.024951891973614693
step: 170, loss: 0.022145742550492287
step: 180, loss: 0.04763326048851013
step: 190, loss: 0.058629151433706284
step: 200, loss: 0.0469614714384079
step: 210, loss: 0.05141215771436691
step: 220, loss: 2.9758690288872458e-05
step: 230, loss: 0.02138434909284115
step: 240, loss: 0.014231996610760689
step: 250, loss: 0.14043179154396057
step: 260, loss: 0.07128342241048813
step: 270, loss: 0.11298303306102753
step: 280, loss: 0.06913851201534271
step: 290, loss: 0.06698662042617798
step: 300, loss: 0.06468527764081955
step: 310, loss: 0.026638250797986984
step: 320, loss: 0.08072887361049652
step: 330, loss: 0.04472117871046066
step: 340, loss: 0.02244523912668228
step: 350, loss: 0.027045654132962227
step: 360, loss: 0.06305541098117828
step: 370, loss: 6.747021689079702e-05
step: 380, loss: 0.03545384481549263
step: 390, loss: 0.08951517939567566
step: 400, loss: 0.06149234250187874
step: 410, loss: 0.020390011370182037
step: 420, loss: 4.617388913175091e-05
step: 430, loss: 0.08536337316036224
step: 440, loss: 0.08707750588655472
step: 450, loss: 2.0823072190978564e-05
step: 460, loss: 0.03773326426744461
step: 470, loss: 0.0005971579812467098
step: 480, loss: 0.017600029706954956
step: 490, loss: 0.06139218062162399
step: 500, loss: 0.041502129286527634
step: 510, loss: 0.024498794227838516
step: 520, loss: 0.09607148915529251
step: 530, loss: 0.06946823000907898
step: 540, loss: 0.04679093509912491
step: 550, loss: 0.03329207003116608
step: 560, loss: 0.06055142730474472
step: 570, loss: 0.08074092864990234
step: 580, loss: 0.029616031795740128
step: 590, loss: 0.001573473564349115
step: 600, loss: 0.07767399400472641
step: 610, loss: 0.09366979449987411
step: 620, loss: 0.04635711759328842
step: 630, loss: 0.05030379444360733
step: 640, loss: 0.0886833444237709
step: 650, loss: 0.0003517625737003982
step: 660, loss: 2.3978078388608992e-05
step: 670, loss: 0.034594208002090454
step: 680, loss: 0.0011881691170856357
step: 690, loss: 0.05830107629299164
step: 700, loss: 0.024533042684197426
step: 710, loss: 0.02643466182053089
step: 720, loss: 0.02358972281217575
step: 730, loss: 0.020870717242360115
step: 740, loss: 0.07691099494695663
step: 750, loss: 0.029230749234557152
step: 760, loss: 3.0473111110040918e-05
step: 770, loss: 0.003839467652142048
step: 780, loss: 0.06733667105436325
step: 790, loss: 0.13729873299598694
step: 800, loss: 0.03683384880423546
step: 810, loss: 0.02691524848341942
step: 820, loss: 0.05109095200896263
step: 830, loss: 0.05950567126274109
step: 840, loss: 0.04061819612979889
step: 850, loss: 0.07983262091875076
step: 860, loss: 0.025578416883945465
step: 870, loss: 0.16809675097465515
step: 880, loss: 0.03772902488708496
step: 890, loss: 0.08159863203763962
step: 900, loss: 0.16438321769237518
step: 910, loss: 0.06979452818632126
step: 920, loss: 0.03052198514342308
step: 930, loss: 0.027324827387928963
step: 940, loss: 0.07364702224731445
step: 950, loss: 0.033629097044467926
step: 960, loss: 0.052247483283281326
step: 970, loss: 0.0015947167994454503
step: 980, loss: 0.02053949609398842
step: 990, loss: 0.04627251997590065
step: 1000, loss: 0.00984705425798893
step: 1010, loss: 0.026751555502414703
step: 1020, loss: 0.13868901133537292
step: 1030, loss: 0.04410192742943764
step: 1040, loss: 0.020253287628293037
step: 1050, loss: 0.03371782973408699
step: 1060, loss: 0.07385832816362381
step: 1070, loss: 0.06746707111597061
epoch 18: dev_f1=0.9302107728337237, f1=0.9241639189825719, best_f1=0.9334574220567706
step: 0, loss: 0.036907076835632324
step: 10, loss: 0.05081218108534813
step: 20, loss: 0.027675272896885872
step: 30, loss: 0.038181159645318985
step: 40, loss: 0.06361035257577896
step: 50, loss: 0.10646280646324158
step: 60, loss: 0.03645196557044983
step: 70, loss: 0.04743821546435356
step: 80, loss: 0.07978938519954681
step: 90, loss: 0.02141323871910572
step: 100, loss: 0.029460517689585686
step: 110, loss: 0.03052670508623123
step: 120, loss: 0.008366888388991356
step: 130, loss: 2.1683648810721934e-05
step: 140, loss: 1.9687116946442984e-05
step: 150, loss: 0.14196309447288513
step: 160, loss: 0.08034621179103851
step: 170, loss: 0.033272404223680496
step: 180, loss: 0.04218645021319389
step: 190, loss: 0.04015043377876282
step: 200, loss: 0.04267043247818947
step: 210, loss: 0.02521674335002899
step: 220, loss: 0.049107298254966736
step: 230, loss: 0.015730425715446472
step: 240, loss: 0.025138605386018753
step: 250, loss: 0.04253712296485901
step: 260, loss: 0.0674358382821083
step: 270, loss: 3.156076854793355e-05
step: 280, loss: 0.08553443849086761
step: 290, loss: 0.09728454798460007
step: 300, loss: 0.0009660548530519009
step: 310, loss: 0.13383102416992188
step: 320, loss: 0.04735780134797096
step: 330, loss: 0.0005586226470768452
step: 340, loss: 0.02532600611448288
step: 350, loss: 0.03840075433254242
step: 360, loss: 0.037279266864061356
step: 370, loss: 0.017260104417800903
step: 380, loss: 0.026979919523000717
step: 390, loss: 0.017549287527799606
step: 400, loss: 0.12177637219429016
step: 410, loss: 0.07541149854660034
step: 420, loss: 0.014465779066085815
step: 430, loss: 0.0016475131269544363
step: 440, loss: 0.016785193234682083
step: 450, loss: 0.05423079431056976
step: 460, loss: 0.021216781809926033
step: 470, loss: 0.013916300609707832
step: 480, loss: 0.030521327629685402
step: 490, loss: 7.938584894873202e-05
step: 500, loss: 0.04653641954064369
step: 510, loss: 8.152939699357376e-05
step: 520, loss: 0.04014589264988899
step: 530, loss: 0.03505143150687218
step: 540, loss: 0.06749475747346878
step: 550, loss: 0.08243687450885773
step: 560, loss: 0.053870026022195816
step: 570, loss: 0.06863042712211609
step: 580, loss: 0.04303615167737007
step: 590, loss: 0.02587994560599327
step: 600, loss: 0.07168266177177429
step: 610, loss: 0.00023547162709292024
step: 620, loss: 0.05872061103582382
step: 630, loss: 7.53250606067013e-06
step: 640, loss: 0.05984539911150932
step: 650, loss: 1.889677696453873e-05
step: 660, loss: 1.202501243824372e-05
step: 670, loss: 2.405217310297303e-05
step: 680, loss: 0.07496926933526993
step: 690, loss: 0.04106525704264641
step: 700, loss: 0.05638580396771431
step: 710, loss: 0.012082723900675774
step: 720, loss: 0.03180774673819542
step: 730, loss: 0.06485939025878906
step: 740, loss: 0.04787131026387215
step: 750, loss: 3.282151010353118e-05
step: 760, loss: 0.07322754710912704
step: 770, loss: 0.006666412577033043
step: 780, loss: 0.05222209542989731
step: 790, loss: 0.10153604298830032
step: 800, loss: 0.04040989279747009
step: 810, loss: 0.04154553264379501
step: 820, loss: 0.03710493445396423
step: 830, loss: 0.03701766952872276
step: 840, loss: 0.05565803125500679
step: 850, loss: 0.01823817566037178
step: 860, loss: 0.07435351610183716
step: 870, loss: 0.015513909980654716
step: 880, loss: 0.09171000868082047
step: 890, loss: 0.009111102670431137
step: 900, loss: 0.017329083755612373
step: 910, loss: 0.035709332674741745
step: 920, loss: 0.0002439735981170088
step: 930, loss: 0.011824419721961021
step: 940, loss: 9.809360926738009e-05
step: 950, loss: 0.05373481661081314
step: 960, loss: 0.04873617738485336
step: 970, loss: 0.08165806531906128
step: 980, loss: 0.012273846194148064
step: 990, loss: 0.053759485483169556
step: 1000, loss: 4.6768011088715866e-05
step: 1010, loss: 0.050400275737047195
step: 1020, loss: 0.13208630681037903
step: 1030, loss: 0.053888145834207535
step: 1040, loss: 0.025441791862249374
step: 1050, loss: 0.013015950098633766
step: 1060, loss: 0.0677499771118164
step: 1070, loss: 0.0285638440400362
epoch 19: dev_f1=0.9308411214953269, f1=0.9246704331450095, best_f1=0.9334574220567706
step: 0, loss: 0.005029095336794853
step: 10, loss: 0.006396599113941193
step: 20, loss: 0.10721950978040695
step: 30, loss: 0.03780073672533035
step: 40, loss: 0.00928975734859705
step: 50, loss: 0.006932392716407776
step: 60, loss: 0.09233063459396362
step: 70, loss: 0.026265744119882584
step: 80, loss: 0.030038926750421524
step: 90, loss: 0.011170710436999798
step: 100, loss: 0.12953445315361023
step: 110, loss: 0.08320943266153336
step: 120, loss: 0.01560920849442482
step: 130, loss: 0.07118801772594452
step: 140, loss: 2.848509029718116e-05
step: 150, loss: 0.08222508430480957
step: 160, loss: 0.0453353226184845
step: 170, loss: 0.053872887045145035
step: 180, loss: 0.04333275929093361
step: 190, loss: 0.04944993928074837
step: 200, loss: 0.027373578399419785
step: 210, loss: 0.023459365591406822
step: 220, loss: 0.03242233395576477
step: 230, loss: 0.027326153591275215
step: 240, loss: 0.08742735534906387
step: 250, loss: 0.08043938130140305
step: 260, loss: 0.10137630999088287
step: 270, loss: 0.040190454572439194
step: 280, loss: 0.024836350232362747
step: 290, loss: 0.03213725984096527
step: 300, loss: 0.04189414158463478
step: 310, loss: 0.06672441214323044
step: 320, loss: 0.000897912890650332
step: 330, loss: 0.06641583889722824
step: 340, loss: 0.02455025538802147
step: 350, loss: 0.03265300393104553
step: 360, loss: 0.02532058395445347
step: 370, loss: 0.018259910866618156
step: 380, loss: 0.024377401918172836
step: 390, loss: 0.026646094396710396
step: 400, loss: 0.10889887809753418
step: 410, loss: 0.07821249961853027
step: 420, loss: 0.03853658586740494
step: 430, loss: 0.02909872494637966
step: 440, loss: 0.029357559978961945
step: 450, loss: 0.05071357637643814
step: 460, loss: 0.043776024132966995
step: 470, loss: 0.016409149393439293
step: 480, loss: 0.06256765127182007
step: 490, loss: 0.027794525027275085
step: 500, loss: 0.03412433713674545
step: 510, loss: 0.02870195172727108
step: 520, loss: 0.00934439804404974
step: 530, loss: 0.012490186840295792
step: 540, loss: 0.10186435282230377
step: 550, loss: 1.9463848730083555e-05
step: 560, loss: 0.04793061688542366
step: 570, loss: 0.07386481016874313
step: 580, loss: 0.04698997735977173
step: 590, loss: 0.005270387977361679
step: 600, loss: 0.01454758457839489
step: 610, loss: 0.017019042745232582
step: 620, loss: 0.023328958079218864
step: 630, loss: 0.06265639513731003
step: 640, loss: 0.06140667572617531
step: 650, loss: 0.00015134502609726042
step: 660, loss: 0.09610071033239365
step: 670, loss: 0.04704343527555466
step: 680, loss: 0.06678269803524017
step: 690, loss: 0.017487429082393646
step: 700, loss: 0.08630354702472687
step: 710, loss: 0.10944467037916183
step: 720, loss: 0.023678701370954514
step: 730, loss: 0.01604626141488552
step: 740, loss: 0.04013879969716072
step: 750, loss: 0.00011110524064861238
step: 760, loss: 0.04384869709610939
step: 770, loss: 0.02491147816181183
step: 780, loss: 0.020007945597171783
step: 790, loss: 0.027631882578134537
step: 800, loss: 0.04500119388103485
step: 810, loss: 0.025602970272302628
step: 820, loss: 0.04042534902691841
step: 830, loss: 0.017841313034296036
step: 840, loss: 0.05647173151373863
step: 850, loss: 0.011145580559968948
step: 860, loss: 0.04184533655643463
step: 870, loss: 0.06257849931716919
step: 880, loss: 0.029966462403535843
step: 890, loss: 0.05005499720573425
step: 900, loss: 0.03689643740653992
step: 910, loss: 0.03902195394039154
step: 920, loss: 0.07387340068817139
step: 930, loss: 0.015005572699010372
step: 940, loss: 0.05236788094043732
step: 950, loss: 0.10330568999052048
step: 960, loss: 0.07638750225305557
step: 970, loss: 0.06175157055258751
step: 980, loss: 0.06745252013206482
step: 990, loss: 0.05106179416179657
step: 1000, loss: 0.06148771941661835
step: 1010, loss: 8.784027158981189e-05
step: 1020, loss: 0.03359360247850418
step: 1030, loss: 0.022276470437645912
step: 1040, loss: 0.01859196275472641
step: 1050, loss: 0.00011197517596883699
step: 1060, loss: 0.008589965291321278
step: 1070, loss: 0.044106289744377136
epoch 20: dev_f1=0.9294062646096307, f1=0.9251059821008009, best_f1=0.9334574220567706
